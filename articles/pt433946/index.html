<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïé üë©‚Äçüåæ üßòüèª Cheat sheet para intelig√™ncia artificial - jogue fora o excesso, ensine o principal. T√©cnica de processamento da sequ√™ncia de treinamento üçé üéöÔ∏è üêö</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este √© o segundo artigo sobre a an√°lise e estudo de materiais da competi√ß√£o para a busca de navios no mar. Mas agora vamos estudar as propriedades das...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cheat sheet para intelig√™ncia artificial - jogue fora o excesso, ensine o principal. T√©cnica de processamento da sequ√™ncia de treinamento</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/433946/">  Este √© o segundo artigo sobre a an√°lise e estudo de materiais da competi√ß√£o para a busca de navios no mar.  Mas agora vamos estudar as propriedades das sequ√™ncias de treinamento.  Vamos tentar encontrar informa√ß√µes em excesso, redund√¢ncia nos dados de origem e exclu√≠-los. <br><br><img src="https://habrastorage.org/webt/b4/yk/pz/b4ykpzewv86nxd0szou25c_egzg.jpeg"><br><br>  Este artigo tamb√©m √© simplesmente o resultado de curiosidade e interesse ocioso, nada disso √© encontrado na pr√°tica e, para tarefas pr√°ticas, n√£o h√° quase nada para copiar e colar.  Este √© um pequeno estudo das propriedades da sequ√™ncia de treinamento - o racioc√≠nio e o c√≥digo do autor s√£o apresentados, voc√™ pode verificar / complementar / alterar tudo sozinho. <br><br>  A competi√ß√£o de busca marinha kaggle terminou recentemente.  A Airbus prop√¥s analisar imagens de sat√©lite do mar com e sem navios.  Um total de 192555 imagens 768x768x3 - √© 340 720 680 960 bytes se uint8 e essa √© uma quantidade enorme de informa√ß√µes e houve uma suspeita vaga de que nem todas as imagens s√£o necess√°rias para o treinamento da rede e nessa quantidade de repeti√ß√£o e redund√¢ncia s√£o √≥bvias.  Ao treinar uma rede, √© habitual separar alguns dados e n√£o us√°-los no treinamento, mas use-os para verificar a qualidade do treinamento.  E se um e o mesmo trecho do mar caiu em duas imagens diferentes e ao mesmo tempo uma imagem caiu na sequ√™ncia de treinamento e a outra na sequ√™ncia de verifica√ß√£o, a verifica√ß√£o perder√° o significado e a rede ser√° treinada novamente, n√£o verificaremos a capacidade da rede de generalizar informa√ß√µes, porque os dados s√£o os mesmos.  A luta contra esse fen√¥meno levou muito tempo e esfor√ßo da GPU dos participantes.  Como de costume, os vencedores e os premiados n√£o t√™m pressa em mostrar aos seus f√£s os segredos da maestria e definir o c√≥digo, e n√£o h√° como estud√°-lo e aprend√™-lo, por isso vamos retomar a teoria. <br><a name="habracut"></a><br>  Uma simples verifica√ß√£o visual mostrou que realmente h√° muitos dados, o mesmo trecho do mar caiu em fotos diferentes, veja os exemplos <br><br><img src="https://habrastorage.org/webt/b8/wn/tb/b8wntbyikiqqjafizkmc6okundc.png"><br><br><img src="https://habrastorage.org/webt/ph/xh/g1/phxhg1aaqljhnqiaq28h17fktvo.png"><br><br><img src="https://habrastorage.org/webt/7z/pz/ua/7zpzuaapp2rhjfsxqbqe2jip5jk.png"><br><br><img src="https://habrastorage.org/webt/ed/yx/7c/edyx7cyftluhepdskpo7thftvlm.png"><br><br>  √â por esse motivo que n√£o estamos interessados ‚Äã‚Äãem dados reais, existem muitas depend√™ncias esp√∫rias, conex√µes desnecess√°rias conosco, pouca marca√ß√£o e outras defici√™ncias. <br><br>  No <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">primeiro artigo,</a> vimos fotos com elipses e ru√≠do e continuaremos a estud√°-las.  A vantagem dessa abordagem √© que, se voc√™ encontrar algum recurso atraente de uma rede treinada em um conjunto arbitr√°rio de imagens, n√£o est√° claro se essa √© uma propriedade de rede ou de um conjunto de treinamento.  Os par√¢metros estat√≠sticos das seq√º√™ncias retiradas do mundo real s√£o desconhecidos.  Recentemente, o gr√£o-mestre Pleskov Pavel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">paske57</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">falou sobre</a> como √†s vezes √© f√°cil obter uma classifica√ß√£o de segmenta√ß√£o / classifica√ß√£o de imagens, se √© bom investigar os dados, por exemplo, veja os metadados das fotos.  E n√£o h√° garantias de que nos dados reais n√£o existam tais depend√™ncias, deixadas involuntariamente.  Portanto, para estudar as propriedades da rede, tiramos fotos com elipses e ret√¢ngulos e determinamos o local, a cor e outros par√¢metros usando um gerador de n√∫meros aleat√≥rios de um computador (que possui um gerador pseudo-aleat√≥rio, que possui um gerador baseado em outros algoritmos n√£o digitais e propriedades f√≠sicas da subst√¢ncia, Mas n√£o discutiremos isso neste artigo). <br><br>  Portanto, pegue o mar <i>np.random.sample () * 0,75</i> , n√£o precisamos de ondas, vento, costas e outros padr√µes e faces ocultos.  Os navios / elipses tamb√©m ser√£o pintados da mesma cor e, para distinguir o mar do barco e da interfer√™ncia, adicione 0,25 ao mar ou ao barco / jammer, e todos ter√£o a mesma forma - elipses de diferentes tamanhos e orienta√ß√µes.  A interfer√™ncia tamb√©m ser√° apenas ret√¢ngulos da mesma cor que a elipse - isso √© importante, informa√ß√µes e interfer√™ncia da mesma cor no contexto do ru√≠do.  Faremos apenas uma pequena altera√ß√£o na colora√ß√£o e executaremos <i>np.random.sample ()</i> para cada imagem e para cada elipse / ret√¢ngulo, ou seja,  Nem o plano de fundo nem a cor da elipse / ret√¢ngulo s√£o repetidos.  Al√©m disso, no texto, h√° um c√≥digo do programa para criar figuras / m√°scaras e um exemplo de dez pares selecionados aleatoriamente. <br><br>  Pegue uma vers√£o muito comum da rede (voc√™ pode usar sua rede favorita) e tente identificar e mostrar a redund√¢ncia de uma grande sequ√™ncia de treinamento, para obter pelo menos algum tipo de caracter√≠sticas qualitativas e quantitativas de redund√¢ncia.  I.e.  o autor acredita que muitos gigabytes de sequ√™ncias de treinamento s√£o substancialmente redundantes, existem muitas imagens desnecess√°rias, n√£o h√° necessidade de carregar dezenas de GPUs e fazer c√°lculos desnecess√°rios.  A redund√¢ncia de dados se manifesta n√£o apenas e n√£o tanto no fato de que as mesmas partes s√£o exibidas em imagens diferentes, mas tamb√©m na redund√¢ncia de informa√ß√µes nesses dados.  Os dados podem ser redundantes, mesmo que n√£o sejam repetidos exatamente.  Observe que essa n√£o √© uma defini√ß√£o estrita de informa√ß√µes e sua sufici√™ncia ou redund√¢ncia.  Queremos apenas descobrir o quanto voc√™ pode reduzir o trem, quais fotos voc√™ pode tirar da sequ√™ncia de treinamento e quantas fotos s√£o suficientes para um treinamento aceit√°vel (definiremos a precis√£o no programa).  Este √© um programa espec√≠fico, um conjunto de dados espec√≠fico, e √© poss√≠vel que em elipses com tri√¢ngulos, como obst√°culo, nada funcione t√£o bem quanto em elipses com ret√¢ngulos (minha hip√≥tese √© que tudo ser√° o mesmo e o mesmo. Mas n√£o estamos verificando agora) , n√£o realizamos an√°lises e n√£o provamos teoremas). <br><br>  Ent√£o, dado: <br><br><ul><li>  sequ√™ncia de aprendizado de pares de figuras / m√°scaras.  Podemos gerar qualquer n√∫mero de pares de imagens / m√°scaras.  Responderei √† pergunta imediatamente - por que a cor e o fundo s√£o aleat√≥rios?  Responderei de forma simples, breve, clara e abrangente que gosto tanto, que n√£o √© necess√°ria uma entidade extra na forma de uma borda; </li><li>  a rede √© comum, U-net comum, ligeiramente modificada e amplamente utilizada para segmenta√ß√£o. </li></ul><br>  Id√©ia para testar: <br><br><ul><li>  na sequ√™ncia constru√≠da, como em tarefas reais, gigabytes de dados s√£o usados.  O autor acredita que o tamanho da sequ√™ncia de treinamento n√£o √© t√£o cr√≠tico e n√£o deve haver muitos dados, mas eles devem conter "muita" informa√ß√£o.  Essa quantidade, dez mil pares de imagens / m√°scaras, n√£o √© necess√°ria e a rede aprender√° com uma quantidade muito menor de dados. </li></ul><br>  Vamos come√ßar, selecione 10.000 pares e considere-os com cuidado.  Espremeremos toda a √°gua, todos os peda√ßos desnecess√°rios dessa sequ√™ncia de treinamento, usaremos e colocaremos em pr√°tica todo o res√≠duo seco. <br><br>  Agora voc√™ pode testar sua intui√ß√£o e assumir quantos pares de 10.000 s√£o suficientes para treinar e prever outro, mas tamb√©m criou uma sequ√™ncia de 10.000 pares com uma precis√£o de mais de 0,98.  Escreva em um peda√ßo de papel, depois compare. <br><br>  Para uso pr√°tico, leve em considera√ß√£o que o mar e os navios com interfer√™ncia s√£o selecionados artificialmente, √© <i>np.random.sample ()</i> . <br><br><div class="spoiler">  <b class="spoiler_title">Carregamos bibliotecas, determinamos os tamanhos de uma matriz de imagens</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> skimage.draw <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ellipse, polygon <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input,Conv2D,Conv2DTranspose,MaxPooling2D,concatenate <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BatchNormalization,Activation,Add,Dropout <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.losses <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> binary_crossentropy <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> keras w_size = <span class="hljs-number"><span class="hljs-number">128</span></span> train_num = <span class="hljs-number"><span class="hljs-number">10000</span></span> radius_min = <span class="hljs-number"><span class="hljs-number">10</span></span> radius_max = <span class="hljs-number"><span class="hljs-number">20</span></span></code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">determinar as fun√ß√µes de perda e precis√£o</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_coef</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> y_true_f = K.flatten(y_true) y_pred = K.cast(y_pred, <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) y_pred_f = K.cast(K.greater(K.flatten(y_pred), <span class="hljs-number"><span class="hljs-number">0.5</span></span>), <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) intersection = y_true_f * y_pred_f score = <span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smooth = <span class="hljs-number"><span class="hljs-number">1.</span></span> y_true_f = K.flatten(y_true) y_pred_f = K.flatten(y_pred) intersection = y_true_f * y_pred_f score = (<span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bce_dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_iou_vector</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(A, B)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Numpy version batch_size = A.shape[0] metric = 0.0 for batch in range(batch_size): t, p = A[batch], B[batch] true = np.sum(t) pred = np.sum(p) # deal with empty mask first if true == 0: metric += (pred == 0) continue # non empty mask case. Union is never empty # hence it is safe to divide by its number of pixels intersection = np.sum(t * p) union = true + pred - intersection iou = intersection / union # iou metrric is a stepwise approximation of the real iou over 0.5 iou = np.floor(max(0, (iou - 0.45)*20)) / 10 metric += iou # teake the average over all images in batch metric /= batch_size return metric def my_iou_metric(label, pred): # Tensorflow version return tf.py_func(get_iou_vector, [label, pred &gt; 0.5], tf.float64) from keras.utils.generic_utils import get_custom_objects get_custom_objects().update({'bce_dice_loss': bce_dice_loss }) get_custom_objects().update({'dice_loss': dice_loss }) get_custom_objects().update({'dice_coef': dice_coef }) get_custom_objects().update({'my_iou_metric': my_iou_metric })</span></span></code> </pre><br></div></div><br>  Usaremos a m√©trica do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">primeiro artigo</a> .  Deixe-me lembrar aos leitores que preveremos a m√°scara do pixel - este √© o ‚Äúmar‚Äù ou o ‚Äúnavio‚Äù e avaliaremos a verdade ou falsidade da previs√£o.  I.e.  As quatro op√ß√µes a seguir s√£o poss√≠veis - previmos corretamente que um pixel √© um "mar", previmos corretamente que um pixel √© um "navio" ou cometemos um erro ao prever um "mar" ou um "navio".  E assim, para todas as imagens e todos os pixels, estimamos o n√∫mero das quatro op√ß√µes e calculamos o resultado - este ser√° o resultado da rede.  E quanto menos previs√µes err√¥neas e mais verdadeiras, mais preciso o resultado e melhor a rede. <br><br>  E para a pesquisa, vamos optar pela bem estudada U-net, que √© uma excelente rede para segmenta√ß√£o de imagens.  A op√ß√£o U-net n√£o t√£o cl√°ssica foi escolhida, mas a id√©ia √© a mesma: a rede realiza uma opera√ß√£o muito simples com imagens - reduz a dimens√£o da imagem com algumas transforma√ß√µes passo a passo e tenta recuperar a m√°scara da imagem compactada.  I.e.  a dimens√£o da imagem em nosso caso √© aumentada para 16x16 e, em seguida, tentamos restaurar a m√°scara usando dados de todas as camadas de compress√£o anteriores. <br><br>  Examinamos a rede como uma ‚Äúcaixa preta‚Äù, n√£o veremos o que acontece com a rede interna, como os pesos mudam e como os gradientes s√£o escolhidos - esse √© o t√≥pico de outro estudo. <br><br><div class="spoiler">  <b class="spoiler_title">Rede em U com blocos</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">convolution_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, filters, size, strides=</span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">(</span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">,</span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">)</span></span></span></span><span class="hljs-function"><span class="hljs-params">, padding=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'same'</span></span></span></span><span class="hljs-function"><span class="hljs-params">, activation=True)</span></span></span><span class="hljs-function">:</span></span> x = Conv2D(filters, size, strides=strides, padding=padding)(x) x = BatchNormalization()(x) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> activation == <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: x = Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">residual_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(blockInput, num_filters=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">16</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> x = Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(blockInput) x = BatchNormalization()(x) x = convolution_block(x, num_filters, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>) ) x = convolution_block(x, num_filters, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) x = Add()([x, blockInput]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x <span class="hljs-comment"><span class="hljs-comment"># Build model def build_model(input_layer, start_neurons, DropoutRatio = 0.5): conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding="same" )(input_layer) conv1 = residual_block(conv1,start_neurons * 1) conv1 = residual_block(conv1,start_neurons * 1) conv1 = Activation('relu')(conv1) pool1 = MaxPooling2D((2, 2))(conv1) pool1 = Dropout(DropoutRatio/2)(pool1) conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding="same" )(pool1) conv2 = residual_block(conv2,start_neurons * 2) conv2 = residual_block(conv2,start_neurons * 2) conv2 = Activation('relu')(conv2) pool2 = MaxPooling2D((2, 2))(conv2) pool2 = Dropout(DropoutRatio)(pool2) conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding="same")(pool2) conv3 = residual_block(conv3,start_neurons * 4) conv3 = residual_block(conv3,start_neurons * 4) conv3 = Activation('relu')(conv3) pool3 = MaxPooling2D((2, 2))(conv3) pool3 = Dropout(DropoutRatio)(pool3) conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding="same")(pool3) conv4 = residual_block(conv4,start_neurons * 8) conv4 = residual_block(conv4,start_neurons * 8) conv4 = Activation('relu')(conv4) pool4 = MaxPooling2D((2, 2))(conv4) pool4 = Dropout(DropoutRatio)(pool4) # Middle convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding="same")(pool4) convm = residual_block(convm,start_neurons * 16) convm = residual_block(convm,start_neurons * 16) convm = Activation('relu')(convm) deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding="same")(convm) uconv4 = concatenate([deconv4, conv4]) uconv4 = Dropout(DropoutRatio)(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding="same")(uconv4) uconv4 = residual_block(uconv4,start_neurons * 8) uconv4 = residual_block(uconv4,start_neurons * 8) uconv4 = Activation('relu')(uconv4) deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding="same")(uconv4) uconv3 = concatenate([deconv3, conv3]) uconv3 = Dropout(DropoutRatio)(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding="same")(uconv3) uconv3 = residual_block(uconv3,start_neurons * 4) uconv3 = residual_block(uconv3,start_neurons * 4) uconv3 = Activation('relu')(uconv3) deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding="same")(uconv3) uconv2 = concatenate([deconv2, conv2]) uconv2 = Dropout(DropoutRatio)(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding="same")(uconv2) uconv2 = residual_block(uconv2,start_neurons * 2) uconv2 = residual_block(uconv2,start_neurons * 2) uconv2 = Activation('relu')(uconv2) deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding="same")(uconv2) uconv1 = concatenate([deconv1, conv1]) uconv1 = Dropout(DropoutRatio)(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding="same")(uconv1) uconv1 = residual_block(uconv1,start_neurons * 1) uconv1 = residual_block(uconv1,start_neurons * 1) uconv1 = Activation('relu')(uconv1) uconv1 = Dropout(DropoutRatio/2)(uconv1) output_layer = Conv2D(1, (1,1), padding="same", activation="sigmoid")(uconv1) return output_layer # model input_layer = Input((w_size, w_size, 3)) output_layer = build_model(input_layer, 16) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer="adam", metrics=[my_iou_metric]) model.summary()</span></span></code> </pre> <br></div></div><br>  A fun√ß√£o de gerar pares de imagem / m√°scara.  Em uma imagem colorida de 128x128 preenchida com ru√≠do aleat√≥rio com uma selecionada aleatoriamente em dois intervalos, 0,0 ... 0,75 ou 0,25..1,0.  Coloque aleatoriamente uma elipse orientada aleatoriamente na imagem e coloque um ret√¢ngulo no mesmo local.  Verificamos que eles n√£o se cruzam e, se necess√°rio, deslocamos o ret√¢ngulo para o lado.  Cada vez que recalculamos os valores da colora√ß√£o do mar / barco.  Para simplificar, colocaremos a m√°scara com a imagem em uma matriz, como a quarta cor, ou seja,  Red.Green.Blue.Mask, √© mais f√°cil. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> img_l = (np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>))* <span class="hljs-number"><span class="hljs-number">0.75</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) img_h = (np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>))* <span class="hljs-number"><span class="hljs-number">0.75</span></span> + <span class="hljs-number"><span class="hljs-number">0.25</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) img = np.zeros((w_size, w_size, <span class="hljs-number"><span class="hljs-number">4</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>) p = np.random.sample() - <span class="hljs-number"><span class="hljs-number">0.5</span></span> r = np.random.sample()*(w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max c = np.random.sample()*(w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max r_radius = np.random.sample()*(radius_max-radius_min) + radius_min c_radius = np.random.sample()*(radius_max-radius_min) + radius_min rot = np.random.sample()*<span class="hljs-number"><span class="hljs-number">360</span></span> rr, cc = ellipse( r, c, r_radius, c_radius, rotation=np.deg2rad(rot), shape=img_l.shape ) p1 = np.rint(np.random.sample()* (w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max) p2 = np.rint(np.random.sample()* (w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max) p3 = np.rint(np.random.sample()* (<span class="hljs-number"><span class="hljs-number">2</span></span>*radius_max - radius_min) + radius_min) p4 = np.rint(np.random.sample()* (<span class="hljs-number"><span class="hljs-number">2</span></span>*radius_max - radius_min) + radius_min) poly = np.array(( (p1, p2), (p1, p2+p4), (p1+p3, p2+p4), (p1+p3, p2), (p1, p2), )) rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) in_sc_rr = list(set(rr) &amp; set(rr_p)) in_sc_cc = list(set(cc) &amp; set(cc_p)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(in_sc_rr) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> len(in_sc_cc) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(in_sc_rr) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: _delta_rr = np.max(in_sc_rr) - np.min(in_sc_rr) + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> np.mean(rr_p) &gt; np.mean(in_sc_rr): poly[:,<span class="hljs-number"><span class="hljs-number">0</span></span>] += _delta_rr <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: poly[:,<span class="hljs-number"><span class="hljs-number">0</span></span>] -= _delta_rr <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(in_sc_cc) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: _delta_cc = np.max(in_sc_cc) - np.min(in_sc_cc) + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> np.mean(cc_p) &gt; np.mean(in_sc_cc): poly[:,<span class="hljs-number"><span class="hljs-number">1</span></span>] += _delta_cc <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: poly[:,<span class="hljs-number"><span class="hljs-number">1</span></span>] -= _delta_cc rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_l.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_h[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_h[rr_p, cc_p] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_h.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_l[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_l[rr_p, cc_p] img[:,:,<span class="hljs-number"><span class="hljs-number">3</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> img[rr, cc,<span class="hljs-number"><span class="hljs-number">3</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> img</code> </pre><br>  Vamos criar uma sequ√™ncia de treinamento de pares, veja aleatoriamente 10 <br><br><pre> <code class="python hljs">_txy = [next_pair() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num)] f_imgs = np.array(_txy)[:,:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">3</span></span>) f_msks = np.array(_txy)[:,:,:,<span class="hljs-number"><span class="hljs-number">3</span></span>:].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span>(_txy) <span class="hljs-comment"><span class="hljs-comment">#    10   fig, axes = plt.subplots(2, 10, figsize=(20, 5)) for k in range(10): kk = np.random.randint(train_num) axes[0,k].set_axis_off() axes[0,k].imshow(f_imgs[kk]) axes[1,k].set_axis_off() axes[1,k].imshow(f_msks[kk].squeeze())</span></span></code> </pre><br><img src="https://habrastorage.org/webt/42/7w/x6/427wx65rkih5858776eoahbgbhw.png"><br><br><h3>  Primeiro passo  Vamos tentar treinar em um conjunto m√≠nimo </h3><br>  O primeiro passo de nosso experimento √© simples: estamos tentando treinar a rede para prever apenas 11 primeiras fotos. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">10</span></span> val_len = <span class="hljs-number"><span class="hljs-number">11</span></span> precision = <span class="hljs-number"><span class="hljs-number">0.85</span></span> m0_select = np.zeros((f_imgs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(val_len): m0_select[k] = <span class="hljs-number"><span class="hljs-number">1</span></span> t = tqdm() <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: fit = model.fit(f_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], f_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], batch_size=batch_size, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span> ) current_accu = fit.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] current_loss = fit.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] t.set_description(<span class="hljs-string"><span class="hljs-string">"accuracy {0:6.4f} loss {1:6.4f} "</span></span>.\ format(current_accu, current_loss)) t.update(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> current_accu &gt; precision: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> t.close()</code> </pre> <br> <code>accuracy 0.8636 loss 0.0666 : : 47it [00:29, 5.82it/s]</code> <br> <br>  Selecionamos os 11 primeiros da sequ√™ncia inicial e treinamos a rede neles.  Agora, n√£o importa se a rede memoriza essas imagens especificamente ou resume, o principal √© que ela possa reconhecer essas 11 fotos da maneira que precisamos.  Dependendo do conjunto de dados e da precis√£o selecionados, o treinamento em rede pode durar muito, muito tempo.  Mas temos apenas algumas itera√ß√µes.  Repito que agora n√£o √© importante para n√≥s como e o que a rede aprendeu ou aprendeu, o principal √© que atingiu a precis√£o estabelecida da previs√£o. <br><br><h3>  Agora comece o experimento principal </h3><br>  Tiraremos novos pares de foto / m√°scara da sequ√™ncia constru√≠da e tentaremos prediz√™-los pela rede treinada na sequ√™ncia j√° selecionada.  No come√ßo, s√£o apenas 11 pares de imagem / m√°scara e a rede √© treinada, talvez n√£o muito corretamente.  Se em um novo par a m√°scara da imagem √© prevista com precis√£o aceit√°vel, descartamos esse par, ele n√£o possui novas informa√ß√µes para a rede, ele j√° sabe e pode calcular a m√°scara dessa imagem.  Se a precis√£o da previs√£o for insuficiente, adicionamos esta imagem com uma m√°scara √† nossa sequ√™ncia e come√ßamos a treinar a rede at√© que um resultado de precis√£o aceit√°vel seja alcan√ßado na sequ√™ncia selecionada.  I.e.  Esta imagem cont√©m novas informa√ß√µes e as adicionamos √† nossa sequ√™ncia de treinamento e extra√≠mos as informa√ß√µes nele contidas pelo treinamento. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> t_batch_size = <span class="hljs-number"><span class="hljs-number">1024</span></span> raw_len = val_len t = tqdm(<span class="hljs-number"><span class="hljs-number">-1</span></span>) id_train = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#id_select = 1 while True: t.set_description("Accuracy {0:6.4f} loss {1:6.4f}\ selected img {2:5d} tested img {3:5d} ". format(current_accu, current_loss, val_len, raw_len)) t.update(1) if id_train == 1: fit = model.fit(f_imgs[m0_select&gt;0], f_msks[m0_select&gt;0], batch_size=batch_size, epochs=1, verbose=0 ) current_accu = fit.history['my_iou_metric'][0] current_loss = fit.history['loss'][0] if current_accu &gt; precision: id_train = 0 else: t_pred = model.predict( f_imgs[raw_len: min(raw_len+t_batch_size,f_imgs.shape[0])], batch_size=batch_size ) for kk in range(t_pred.shape[0]): val_iou = get_iou_vector( f_msks[raw_len+kk].reshape(1,w_size,w_size,1), t_pred[kk].reshape(1,w_size,w_size,1) &gt; 0.5) if val_iou &lt; precision*0.95: new_img_test = 1 m0_select[raw_len+kk] = 1 val_len += 1 break raw_len += (kk+1) id_train = 1 if raw_len &gt;= train_num: break t.close()</span></span></code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9830 loss 0.0287 selected img 271 tested img 9949 : : 1563it [14:16, 1.01it/s]</code> </pre> <br>  Aqui, a precis√£o √© usada no sentido de "precis√£o", e n√£o como a m√©trica keras padr√£o, e a sub-rotina "my_iou_metric" √© usada para calcular a precis√£o.  √â muito interessante observar a precis√£o e o n√∫mero de imagens investigadas e adicionadas.  No in√≠cio, quase todos os pares de imagens / m√°scaras s√£o adicionados pela rede e, em torno de 70, ela come√ßa a ser descartada.  Mais perto de 8000 joga quase todos os pares. <br><br>  Verifique pares visualmente aleat√≥rios selecionados pela rede: <br><br><pre> <code class="python hljs">fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) t_imgs = f_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>] t_msks = f_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>): kk = np.random.randint(t_msks.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].imshow(t_imgs[kk]) axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].imshow(t_msks[kk].squeeze())</code> </pre><br>  Nada de especial ou sobrenatural: <br><br><img src="https://habrastorage.org/webt/dq/rr/7r/dqrr7rze9sbmmoepvvjuma-tjxu.png"><br><br>  Estes s√£o pares selecionados pela rede em diferentes est√°gios do treinamento.  Quando a rede recebeu um par de entrada dessa sequ√™ncia, n√£o foi poss√≠vel calcular a m√°scara com a precis√£o especificada e esse par foi inclu√≠do na sequ√™ncia de treinamento.  Mas nada de especial, fotos comuns. <br><br><h3>  Verifica√ß√£o de resultado e precis√£o </h3><br>  Verificaremos a qualidade do programa de treinamento em rede, garantiremos que a qualidade n√£o dependa significativamente da ordem da sequ√™ncia inicial, para a qual misturamos a sequ√™ncia inicial de pares de foto / m√°scara, pegamos os outros 11 primeiro e da mesma maneira, treinamos a rede e eliminamos o excesso. <br><br><pre> <code class="python hljs">sh = np.arange(train_num) np.random.shuffle(sh) f0_imgs = f_imgs[sh] f0_msks = f_msks[sh] model.compile(loss=bce_dice_loss, optimizer=<span class="hljs-string"><span class="hljs-string">"adam"</span></span>, metrics=[my_iou_metric]) model.summary()</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">C√≥digo do treino</b> <div class="spoiler_text"><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">10</span></span> val_len = <span class="hljs-number"><span class="hljs-number">11</span></span> precision = <span class="hljs-number"><span class="hljs-number">0.85</span></span> m0_select = np.zeros((f_imgs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(val_len): m0_select[k] = <span class="hljs-number"><span class="hljs-number">1</span></span> t = tqdm() <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: fit = model.fit(f0_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], f0_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], batch_size=batch_size, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span> ) current_accu = fit.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] current_loss = fit.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] t.set_description(<span class="hljs-string"><span class="hljs-string">"accuracy {0:6.4f} loss {1:6.4f} "</span></span>.\ format(current_accu, current_loss)) t.update(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> current_accu &gt; precision: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> t.close()</code> </pre> <br><pre> <code class="bash hljs">accuracy 0.8636 loss 0.0710 : : 249it [01:03, 5.90it/s]</code> </pre> <br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> t_batch_size = <span class="hljs-number"><span class="hljs-number">1024</span></span> raw_len = val_len t = tqdm(<span class="hljs-number"><span class="hljs-number">-1</span></span>) id_train = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#id_select = 1 while True: t.set_description("Accuracy {0:6.4f} loss {1:6.4f}\ selected img {2:5d} tested img {3:5d} ". format(current_accu, current_loss, val_len, raw_len)) t.update(1) if id_train == 1: fit = model.fit(f0_imgs[m0_select&gt;0], f0_msks[m0_select&gt;0], batch_size=batch_size, epochs=1, verbose=0 ) current_accu = fit.history['my_iou_metric'][0] current_loss = fit.history['loss'][0] if current_accu &gt; precision: id_train = 0 else: t_pred = model.predict( f_imgs[raw_len: min(raw_len+t_batch_size,f_imgs.shape[0])], batch_size=batch_size ) for kk in range(t_pred.shape[0]): val_iou = get_iou_vector( f_msks[raw_len+kk].reshape(1,w_size,w_size,1), t_pred[kk].reshape(1,w_size,w_size,1) &gt; 0.5) if val_iou &lt; precision*0.95: new_img_test = 1 m0_select[raw_len+kk] = 1 val_len += 1 break raw_len += (kk+1) id_train = 1 if raw_len &gt;= train_num: break t.close()</span></span></code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9890 loss 0.0224 selected img 408 tested img 9456 : : 1061it [21:13, 2.16s/it]</code> </pre> <br></div></div><br>  O resultado n√£o depende significativamente da ordem dos pares da sequ√™ncia original.  No caso anterior, a rede escolheu 271, agora 408, se voc√™ ainda misturar, a rede poder√° escolher uma quantidade diferente.  N√£o vamos verificar, o autor acredita que sempre haver√° substancialmente menos de 10.000. <br><br>  Verifique a precis√£o da previs√£o de rede em uma nova sequ√™ncia independente <br><br><pre> <code class="python hljs">_txy = [next_pair() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num)] test_imgs = np.array(_txy)[:,:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">3</span></span>) test_msks = np.array(_txy)[:,:,:,<span class="hljs-number"><span class="hljs-number">3</span></span>:].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span>(_txy) test_pred_0 = model.predict(test_imgs) t_val_0 = get_iou_vector(test_msks,test_pred_0) t_val_0</code> </pre> <br><pre> <code class="bash hljs">0.9927799999999938</code> </pre> <br><br><h3>  Resumo e Conclus√µes </h3><br>  Assim, conseguimos extrair menos de trezentos ou quatrocentos selecionados entre 10.000 pares, a precis√£o da previs√£o √© de 0,99278, pegamos todos os pares que cont√™m pelo menos algumas informa√ß√µes √∫teis e jogamos fora o resto.  N√£o alinhamos os par√¢metros estat√≠sticos da sequ√™ncia de treinamento, adicionamos repetibilidade de informa√ß√µes, etc.  e n√£o usou m√©todos estat√≠sticos.  Tiramos uma foto que cont√©m informa√ß√µes ainda desconhecidas da rede e compactamos tudo com o peso da rede.  Se a rede encontrar pelo menos uma imagem ‚Äúmisteriosa‚Äù, ela usar√° tudo nos neg√≥cios. <br><br>  Um total de 271 pares de figuras / m√°scaras cont√©m informa√ß√µes para prever 10.000 pares com uma precis√£o de pelo menos 0,8075 em cada par, ou seja, a precis√£o total de toda a sequ√™ncia √© maior, mas em cada figura n√£o √© inferior a 0,8075, n√£o temos imagens que n√£o temos podemos prever e conhecemos o limite inferior dessa previs√£o.  (√© claro que aqui o autor se vangloriava de que, sem isso, o artigo n√£o verifica essa afirma√ß√£o, cerca de 0,8075, ou evid√™ncia, mas provavelmente isso √© verdade) <br><br>  Para o treinamento em rede, n√£o h√° necessidade de carregar a GPU com tudo o que est√° dispon√≠vel, voc√™ pode retirar o n√∫cleo do trem e treinar a rede nele como o in√≠cio do treinamento.  √Ä medida que obt√©m novas fotos, voc√™ pode marcar manualmente aquelas que a rede n√£o p√¥de prever e adicion√°-las ao n√∫cleo do trem, treinando novamente a rede para extrair todas as informa√ß√µes das novas fotos.  E n√£o √© necess√°rio destacar uma sequ√™ncia de valida√ß√£o; podemos assumir que tudo o resto, exceto o selecionado, √© uma sequ√™ncia de valida√ß√£o. <br><br>  Mais uma observa√ß√£o matematicamente n√£o estrita, mas muito importante.  √â seguro dizer que cada par de foto / m√°scara cont√©m "muita" informa√ß√£o.  Cada par cont√©m "muita" informa√ß√£o, embora na maioria dos pares imagem / m√°scara a informa√ß√£o se cruze ou se repita.  Cada um dos 271 pares de figura / m√°scara cont√©m informa√ß√µes essenciais para a previs√£o e esse par n√£o pode ser simplesmente jogado fora. <br><br>  Bem, uma pequena observa√ß√£o sobre dobras, muitos especialistas e praticantes de kagglers dividem a sequ√™ncia de treinamento em dobras e treinam-nas separadamente, combinando os resultados obtidos de maneiras mais complicadas.  No nosso caso, voc√™ tamb√©m pode dividi-lo em dobras. Se voc√™ remover 271 pares de 10.000, poder√° criar uma nova sequ√™ncia raiz nos restantes, o que obviamente fornecer√° um resultado diferente, mas compar√°vel.  Voc√™ pode simplesmente misturar e pegar os outros 11 iniciais, como mostrado acima. <br><br>  O artigo fornece um c√≥digo e mostra como treinar U-net para segmenta√ß√£o de imagens.  Este √© um exemplo concreto e, no artigo, intencionalmente, n√£o h√° generaliza√ß√µes para outras redes, para outras seq√º√™ncias, n√£o h√° matem√°tica rigorosa, tudo √© dito e mostrado "nos dedos".  Apenas um exemplo de como voc√™ pode aprender a rede enquanto obt√©m uma precis√£o aceit√°vel. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt433946/">https://habr.com/ru/post/pt433946/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt433934/index.html">Estrutura SAFe ou Scaled Agile</a></li>
<li><a href="../pt433936/index.html">Procurando um presente de alta tecnologia para uma crian√ßa? Pense em um playground, n√£o em um cercadinho</a></li>
<li><a href="../pt433938/index.html">Como Yandex e Google resumem o ano</a></li>
<li><a href="../pt433940/index.html">Quanto custa a revis√£o na AppStore</a></li>
<li><a href="../pt433944/index.html">Exce√ß√µes devastadoras</a></li>
<li><a href="../pt433948/index.html">Como tornar o pagamento mais conveniente: a experi√™ncia de um provedor de IaaS</a></li>
<li><a href="../pt433952/index.html">10 raz√µes para escolher uma solu√ß√£o para o SAP HANA da HPE. Parte 2</a></li>
<li><a href="../pt433954/index.html">Oito tecnologias de √°udio e dispositivos de √°udio que entrar√£o no Hall da Fama da TECnology em 2019</a></li>
<li><a href="../pt433956/index.html">Os modders usaram a IA para melhorar a textura nos jogos</a></li>
<li><a href="../pt433958/index.html">Aplicativos TDD no Spring Boot: trabalhando com um banco de dados</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
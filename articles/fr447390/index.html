<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèª üë©‚Äçüë©‚Äçüëß üìâ Consignes de configuration d'AccelStor AFA pour VMware vSphere üí® ‚ìÇÔ∏è üèïÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans cet article, je voudrais parler des fonctionnalit√©s de toutes les baies Flash AccelStor fonctionnant avec l'une des plates-formes de virtualisati...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Consignes de configuration d'AccelStor AFA pour VMware vSphere</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/accelstor/blog/447390/"><p>  Dans cet article, je voudrais parler des fonctionnalit√©s de toutes les baies Flash AccelStor fonctionnant avec l'une des plates-formes de virtualisation les plus populaires - VMware vSphere.  En particulier, se concentrer sur les param√®tres qui aideront √† obtenir le maximum d'effet en utilisant un outil aussi puissant que All Flash. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/di/xc/nq/dixcnqzpdskxe4whal3u7wyxcnw.jpeg"></div><a name="habracut"></a><br><p>  Toutes les baies Flash AccelStor NeoSapphire ‚Ñ¢ sont des p√©riph√©riques √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un</a> ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">deux</a> n≈ìuds bas√©s sur des SSD avec une approche fondamentalement diff√©rente pour impl√©menter le concept de stockage des donn√©es et organiser l'acc√®s √† celles-ci en utilisant sa propre technologie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">FlexiRemap¬Æ</a> au lieu des algorithmes RAID tr√®s populaires.  Les baies fournissent un acc√®s en bloc aux h√¥tes via des interfaces Fibre Channel ou iSCSI.  Pour √™tre honn√™te, nous notons que les mod√®les avec l'interface ISCSI ont √©galement un acc√®s aux fichiers en tant que bon bonus.  Mais dans cet article, nous nous concentrerons sur l'utilisation des protocoles de bloc comme les plus productifs pour All Flash. </p><br><p>  L'ensemble du processus de d√©ploiement puis de configuration de la collaboration entre la baie AccelStor et le syst√®me de virtualisation VMware vSphere peut √™tre divis√© en plusieurs √©tapes: </p><br><p></p><ul><li>  Impl√©mentation de la topologie de connexion et configuration du r√©seau SAN; </li><li>  Configuration de la matrice All Flash; </li><li>  Configurer les h√¥tes ESXi; </li><li>  Configurez les machines virtuelles. </li></ul><br><p>  Les matrices AccelStor NeoSapphire ‚Ñ¢ avec Fibre Channel et iSCSI ont √©t√© utilis√©es comme exemples d'√©quipements.  Le logiciel de base est VMware vSphere 6.7U1. </p><br><p>  Avant de d√©ployer les syst√®mes d√©crits dans cet article, il est fortement recommand√© de vous familiariser avec la documentation de VMware concernant les probl√®mes de performances ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Meilleures pratiques de performance pour VMware vSphere 6.7</a> ) et les param√®tres iSCSI ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Meilleures pratiques pour ex√©cuter VMware vSphere sur iSCSI</a> ) </p><br><h3>  <i><b>Topologie de connexion et configuration SAN</b></i> </h3><br><p>  Les principaux composants d'un r√©seau SAN sont les HBA sur les h√¥tes ESXi, les commutateurs SAN et les n≈ìuds de baie.  Une topologie typique d'un tel r√©seau ressemblerait √† ceci: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/ci/wt/lg/ciwtlgk31rhm06xplvzbbwkxu0y.png"></div><br><p>  Le terme Switch d√©signe ici soit un seul commutateur physique ou un ensemble de commutateurs (Fabric), soit un p√©riph√©rique partag√© entre diff√©rents services (VSAN dans le cas de Fibre Channel et VLAN dans le cas d'iSCSI).  L'utilisation de deux commutateurs / Fabric ind√©pendants √©limine un √©ventuel point de d√©faillance. </p><br><p>  La connexion directe des h√¥tes √† la baie, bien que prise en charge, est fortement d√©conseill√©e.  Les performances de toutes les baies Flash sont assez √©lev√©es.  Et pour une vitesse maximale, vous devez utiliser tous les ports de la baie.  Par cons√©quent, au moins un commutateur entre les h√¥tes et NeoSapphire ‚Ñ¢ est requis. </p><br><p>  La pr√©sence de deux ports sur l'h√¥te HBA est √©galement une condition pr√©alable pour des performances maximales et une tol√©rance aux pannes. </p><br><p>  Si vous utilisez l'interface Fibre Channel, vous devez configurer le zonage pour √©viter d'√©ventuels conflits entre les initiateurs et les cibles.  Les zones sont construites sur le principe de ¬´un port initiateur - un ou plusieurs ports de baie¬ª. </p><br><p>  Si vous utilisez une connexion iSCSI si vous utilisez un commutateur partag√© avec d'autres services, vous devez isoler le trafic iSCSI √† l'int√©rieur d'un VLAN distinct.  Il est √©galement fortement recommand√© d'activer la prise en charge des trames Jumbo (MTU = 9000) pour augmenter la taille des paquets sur le r√©seau et, par cons√©quent, r√©duire la quantit√© de surcharge pendant la transmission.  Cependant, il convient de rappeler que pour un fonctionnement correct, il est n√©cessaire de modifier le param√®tre MTU sur tous les composants du r√©seau le long de la cha√Æne initiateur-commutateur-cible. </p><br><h3>  <i><b>Configuration de tous les tableaux Flash</b></i> </h3><br><p>  La baie est livr√©e aux clients avec des groupes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">FlexiRemap¬Æ</a> d√©j√† constitu√©s.  Par cons√©quent, aucune action n'est n√©cessaire pour int√©grer les disques dans une structure unique.  Il suffit de cr√©er des volumes de la taille et de la quantit√© requises. </p><br><p></p><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/zn/x9/nc/znx9ncuyd2rgm8-jfvwf620zaqg.png"></div><br><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/wx/8l/ua/wx8lualewtdkixfwg0petpxbsre.png"></div><p></p><br><p>  Pour plus de commodit√©, il existe une fonctionnalit√© pour la cr√©ation par lots de plusieurs volumes d'un volume donn√© √† la fois.  Les volumes ¬´minces¬ª sont cr√©√©s par d√©faut, car cela permet une utilisation plus rationnelle de l'espace de stockage disponible (y compris gr√¢ce au support de Space Reclamation).  En termes de performances, la diff√©rence entre volumes fins et √©pais ne d√©passe pas 1%.  Cependant, si vous voulez "extraire tous les jus" de la matrice, vous pouvez toujours convertir n'importe quel volume "fin" en "√©pais".  Mais il ne faut pas oublier qu'une telle op√©ration est irr√©versible. </p><br><p>  Il ne reste plus qu'√† ¬´publier¬ª les volumes cr√©√©s et √† d√©finir les droits d'acc√®s √† ceux-ci √† partir des h√¥tes √† l'aide de l'ACL (adresses IP pour iSCSI et WWPN pour FC) et la s√©paration physique des ports sur la baie.  Pour les mod√®les iSCSI, cela se fait par la cr√©ation de Target. </p><br><p></p><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/mw/8y/cg/mw8ycgqngghoyuelortgysofswi.png"></div><br><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/py/xe/28/pyxe28gnrsxh_cx4ltjleogwsmw.png"></div><p></p><br><p>  Pour les mod√®les FC, la publication s'effectue via la cr√©ation d'un LUN pour chaque port de la baie. </p><br><p></p><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/qh/u3/bx/qhu3bxhm-kqinygguz298izbw7e.png"></div><br><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/oh/al/ey/ohaleyllpb-0bmot9kawc4-ssyg.png"></div><p></p><br><p>  Pour acc√©l√©rer le processus de configuration, les h√¥tes peuvent √™tre regroup√©s.  De plus, si l'h√¥te utilise le HBA FC √† ports multiples (ce qui arrive le plus souvent en pratique), le syst√®me d√©termine automatiquement que les ports de ce HBA appartiennent au m√™me h√¥te en raison du WWPN, qui diff√®rent d'un.  De plus, la cr√©ation par lots de Target / LUN est prise en charge pour les deux interfaces. </p><br><p>  Un point important lors de l'utilisation de l'interface iSCSI est de cr√©er plusieurs cibles pour les volumes √† la fois pour augmenter les performances, car la file d'attente cible ne peut pas √™tre modifi√©e, et ce sera en fait un goulot d'√©tranglement. </p><br><p></p><h3>  Configurer les h√¥tes ESXi </h3><p></p><br><p>  C√¥t√© ESXi, la configuration de base se fait selon le sc√©nario tout √† fait attendu.  Proc√©dure de connexion iSCSI: </p><br><p></p><ol><li>  Ajouter un adaptateur iSCSI logiciel (non requis s'il a d√©j√† √©t√© ajout√© ou si vous utilisez l'adaptateur mat√©riel iSCSI); </li><li>  Cr√©er vSwitch, par lequel le trafic iSCSI passera, et y ajouter une liaison montante physique et VMkernal; </li><li>  Ajout d'adresses de tableau √† Dynamic Discovery; </li><li>  Cr√©ation d'une banque de donn√©es </li></ol><br><p>  <b>Quelques notes importantes:</b> </p><br><blockquote><ul><li>  Dans le cas g√©n√©ral, bien s√ªr, vous pouvez utiliser le vSwitch existant, mais dans le cas d'un vSwitch s√©par√©, la gestion des param√®tres de l'h√¥te sera beaucoup plus simple. </li><li>  Il est n√©cessaire de s√©parer le trafic de gestion et iSCSI en liaisons physiques et / ou VLAN s√©par√©s afin d'√©viter des probl√®mes de performances. </li><li>  Les adresses IP de VMkernal et les ports correspondants de la baie All Flash doivent se trouver sur le m√™me sous-r√©seau, toujours en raison de probl√®mes de performances. </li><li>  Pour garantir la tol√©rance aux pannes de VMware, vSwitch doit avoir au moins deux liaisons montantes physiques </li><li>  Si vous utilisez des trames Jumbo, vous devez changer le MTU de vSwitch et VMkernal </li><li>  Il ne sera pas inutile de rappeler que selon les recommandations VMware pour les adaptateurs physiques qui seront utilis√©s pour travailler avec le trafic iSCSI, il est n√©cessaire de configurer Teaming et Failover.  En particulier, chaque VMkernal ne devrait fonctionner que via une seule liaison montante, la deuxi√®me liaison montante doit √™tre commut√©e en mode inutilis√©.  Pour la tol√©rance aux pannes, vous devez ajouter deux VMkernal, dont chacun fonctionnera via sa liaison montante. </li></ul><br></blockquote><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/_h/jb/va/_hjbvatnuhjwts4duy2epgb7bbi.png"></div><p></p><br><table><tbody><tr><th>  Adaptateur VMkernel (vmk #) </th><th>  Carte r√©seau physique (vmnic #) </th></tr><tr><td>  vmk1 (Storage01) </td><td>  Adaptateurs actifs <br>  vmnic2 <br>  Adaptateurs inutilis√©s <br>  vmnic3 <br></td></tr><tr><td>  vmk2 (Storage02) </td><td>  Adaptateurs actifs <br>  vmnic3 <br>  Adaptateurs inutilis√©s <br>  vmnic2 <br></td></tr></tbody></table><br><p>  Aucune connexion Fibre Channel requise.  Vous pouvez imm√©diatement cr√©er un magasin de donn√©es. </p><br><p>  Apr√®s avoir cr√©√© le magasin de donn√©es, vous devez vous assurer que la strat√©gie Round Robin est utilis√©e pour les chemins vers Target / LUN comme les plus productifs. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/zh/zr/t1/zhzrt15baoc1qlp0w6ds-mys3hu.png"></div><p></p><br><p>  Par d√©faut, les param√®tres VMware pr√©voient l'utilisation de cette strat√©gie selon le sch√©ma: 1000 requ√™tes via le premier chemin, 1000 requ√™tes suivantes via le deuxi√®me chemin, etc.  Cette interaction de l'h√¥te avec une baie √† deux contr√¥leurs sera d√©s√©quilibr√©e.  Par cons√©quent, nous vous recommandons de d√©finir le param√®tre Round Robin policy = 1 via Esxcli / PowerCLI. </p><br><div class="spoiler">  <b class="spoiler_title">Param√®tres</b> <div class="spoiler_text"><p>  Pour Esxcli: </p><br><ul><li>  Imprimer les LUN disponibles </li></ul><br><p>  <b>liste des p√©riph√©riques nmp de stockage esxcli</b> </p><br><ul><li>  Copier le nom du p√©riph√©rique </li><li>  Changer la politique du tournoi √† la ronde </li></ul><br><p>  <b>esxcli storage nmp psp roundrobin deviceconfig set --type = iops --iops = 1 --device = "Device_ID"</b> </p></div></div><br><p>  La plupart des applications modernes sont con√ßues pour √©changer de gros paquets de donn√©es afin de maximiser l'utilisation de la bande passante et de r√©duire la charge du processeur.  Par cons√©quent, ESXi transf√®re par d√©faut les demandes d'E / S vers le p√©riph√©rique de stockage par lots jusqu'√† 32 767 Ko.  Cependant, pour un certain nombre de sc√©narios, l'√©change de petites portions sera plus productif.  Pour les baies AccelStor, voici les sc√©narios suivants: </p><br><ul><li>  La machine virtuelle utilise UEFI au lieu du BIOS h√©rit√© </li><li>  Utilis√© par vSphere Replication </li></ul><br><p>  Pour de tels sc√©narios, il est recommand√© de modifier la valeur du param√®tre Disk.DiskMaxIOSize √† 4096. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/1g/et/3g/1get3g8odkem1onrpkwjdilbnsi.png"></div><p></p><br><p>  Pour les connexions iSCSI, il est recommand√© de modifier le param√®tre D√©lai d'expiration de connexion sur 30 (valeur par d√©faut 5) pour augmenter la stabilit√© de la connexion et d√©sactiver le d√©lai d'acquittement des paquets DelayedAck transf√©r√©s.  Les deux options sont dans vSphere Client: H√¥te ‚Üí Configurer ‚Üí Stockage ‚Üí Adaptateurs de stockage ‚Üí Options avanc√©es pour l'adaptateur iSCSI </p><br><p></p><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/1y/5_/c8/1y5_c80zsijgqtngo-9vt2zbbo8.png"></div><br><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/bh/yi/tv/bhyitvuujofnioaunwhzypx3fe0.png"></div><p></p><br><p>  Un point assez subtil est le nombre de volumes utilis√©s pour la banque de donn√©es.  Il est clair que pour faciliter la gestion, il existe un d√©sir de cr√©er un grand volume pour tout le volume de la baie.  Cependant, la pr√©sence de plusieurs volumes et, par cons√©quent, du magasin de donn√©es a un effet b√©n√©fique sur les performances globales (plus sur les files d'attente un peu plus loin dans le texte).  Par cons√©quent, nous vous recommandons de cr√©er au moins deux volumes. </p><br><p>  Plus r√©cemment, VMware a conseill√© de limiter le nombre de machines virtuelles sur un m√™me magasin de donn√©es, afin d'obtenir les meilleures performances possibles.  Cependant, maintenant, surtout avec la propagation de la VDI, ce probl√®me n'est plus aussi aigu.  Mais cela n'annule pas la r√®gle de longue date - pour distribuer des machines virtuelles qui n√©cessitent des E / S intensives sur diff√©rentes banques de donn√©es.  Il n'y a rien de mieux pour d√©terminer le nombre optimal de machines virtuelles par volume que de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tester la baie All Flash d'AccelStor au</a> sein de son infrastructure. </p><br><h3>  <i><b>Configurer des machines virtuelles</b></i> </h3><br><p>  Il n'y a pas d'exigences particuli√®res lors de la configuration des machines virtuelles, ou plut√¥t, elles sont assez ordinaires: </p><br><ul><li>  Utilisation de la version la plus √©lev√©e possible de VM (compatibilit√©) </li><li>  Il est plus pr√©cis de d√©finir la taille de la RAM lorsque les machines virtuelles sont dens√©ment plac√©es, par exemple, dans VDI (car par d√©faut, au d√©marrage, un fichier d'√©change est cr√©√© qui est comparable √† la taille de la RAM, ce qui consomme de la capacit√© utile et a un effet sur les performances finales) </li><li>  Utilisez les versions d'E / S les plus efficaces des adaptateurs: type de r√©seau VMXNET 3 et type SCSI PVSCSI </li><li>  Utilisez le type de lecteur Heavy Provision Eager Zeroed pour des performances maximales et Thin Provisioning pour une utilisation maximale du stockage </li><li>  Si possible, limitez le travail des machines d'E / S non critiques √† l'aide de Virtual Disk Limit </li><li>  Assurez-vous d'installer VMware Tools </li></ul><br><h3>  <i><b>Notes de file d'attente</b></i> </h3><br><p>  Une file d'attente (ou E / S en attente) est le nombre de demandes d'E / S (commandes SCSI) en attente de traitement √† un moment donn√© √† partir d'un p√©riph√©rique / d'une application particuli√®re.  En cas de d√©passement de file d'attente, des erreurs QFULL sont g√©n√©r√©es, ce qui se traduit finalement par une augmentation du param√®tre de latence.  Lors de l'utilisation de syst√®mes de stockage sur disque (broche), th√©oriquement, plus la file d'attente est √©lev√©e, plus leurs performances sont √©lev√©es.  Cependant, vous ne devez pas en abuser, car il est facile de s'ex√©cuter dans QFULL.  Dans le cas des syst√®mes All Flash, d'une part, tout est un peu plus simple: le tableau a des retards inf√©rieurs de plusieurs ordres de grandeur et donc le plus souvent il n'est pas n√©cessaire d'ajuster s√©par√©ment la taille des files d'attente.  Mais d'un autre c√¥t√©, dans certains sc√©narios d'utilisation (un fort biais dans les exigences d'E / S pour des machines virtuelles sp√©cifiques, des tests de performances maximales, etc.), si vous ne modifiez pas les param√®tres de file d'attente, alors comprenez au moins quels indicateurs peuvent √™tre atteints, et, surtout, de quelles mani√®res. </p><br><p>  L'All Flash Array d'AccelStor lui-m√™me n'a pas de limites sur les volumes ou les ports d'E / S.  Si n√©cessaire, m√™me un seul volume peut obtenir toutes les ressources de la baie.  La seule restriction de file d'attente concerne les cibles iSCSI.  C'est pour cette raison que la n√©cessit√© de cr√©er plusieurs (id√©alement jusqu'√† 8 pi√®ces) cibles pour chaque volume pour d√©passer cette limite a √©t√© indiqu√©e ci-dessus.  De plus, les baies AccelStor sont des solutions hautement productives.  Par cons√©quent, vous devez utiliser tous les ports d'interface du syst√®me pour atteindre la vitesse maximale. </p><br><p>  Du c√¥t√© ESXi de l'h√¥te, la situation est compl√®tement diff√©rente.  L'h√¥te lui-m√™me applique la pratique de l'√©galit√© d'acc√®s aux ressources pour tous les participants.  Par cons√©quent, il existe des files d'attente d'E / S distinctes pour le syst√®me d'exploitation invit√© et le HBA.  Les files d'attente vers le syst√®me d'exploitation invit√© sont combin√©es des files d'attente √† l'adaptateur SCSI virtuel et au disque virtuel: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/pv/gu/sk/pvguskcy3y4yo7whrx8jiuggtdm.png"></div><br><p>  La file d'attente pour HBA d√©pend du type / fournisseur sp√©cifique: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/tn/hs/6h/tnhs6h0wpivfrb5xfv2qms4tzjy.png"></div><br><p>  Les performances finales de la machine virtuelle seront d√©termin√©es par la limite de profondeur de file d'attente la plus basse parmi les composants h√¥tes. </p><br><p>  Gr√¢ce √† ces valeurs, vous pouvez √©valuer les indicateurs de performance que l'on peut obtenir dans l'une ou l'autre configuration.  Par exemple, nous voulons conna√Ætre les performances th√©oriques d'une machine virtuelle (sans liaison √† un bloc) avec une latence de 0,5 ms.  Puis son IOPS = (1000 / latence) * E / S exceptionnelles (limite de profondeur de file d'attente) </p><br><div class="spoiler">  <b class="spoiler_title">Des exemples</b> <div class="spoiler_text"><p>  <b>Exemple 1</b> </p><br><ul><li>  Adaptateur HBA FC Emulex </li><li>  Une machine virtuelle sur le magasin de donn√©es </li><li>  Adaptateur SCSI paravirtuel VMware </li></ul><br><p>  Ici, la limite de profondeur de file d'attente est d√©termin√©e par le Hul Emulex.  Par cons√©quent, IOPS = (1000 / 0,5) * 32 = 64 Ko </p><br><p>  <b>Exemple 2</b> </p><br><ul><li>  Adaptateur logiciel VMware iSCSI </li><li>  Une machine virtuelle sur le magasin de donn√©es </li><li>  Adaptateur SCSI paravirtuel VMware </li></ul><br><p>  Ici, la limite de profondeur de file d'attente est d√©j√† d√©finie par l'adaptateur paravirtuel SCSI.  Par cons√©quent, IOPS = (1000 / 0,5) * 64 = 128 Ko </p></div></div><br><p>  Les meilleures baies All AccelStor All Flash (comme le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">P710</a> ) sont capables de fournir des performances IOPS de 700K pour l'enregistrement en bloc 4K.  Avec une telle taille de bloc, il est √©vident qu'une seule machine virtuelle n'est pas capable de charger un tel tableau.  Pour ce faire, vous aurez besoin de 11 (par exemple 1) ou 6 (par exemple 2) machines virtuelles. </p><br><p>  En cons√©quence, avec la configuration correcte de tous les composants d√©crits du centre de donn√©es virtuel, vous pouvez obtenir des r√©sultats tr√®s impressionnants en termes de performances. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/uj/xy/cs/ujxycs-_fo-zworv8wds9kgp1j4.jpeg"></div><br><p>  <i>4K al√©atoire, 70% lecture / 30% √©criture</i> </p><br><p>  En fait, le monde r√©el est beaucoup plus difficile √† d√©crire avec une formule simple.  Un h√¥te unique poss√®de toujours de nombreuses machines virtuelles avec diff√©rentes configurations et exigences d'E / S.  Oui, et le processeur h√¥te est engag√© dans un traitement d'entr√©e / sortie, dont la puissance n'est pas infinie.  Ainsi, afin de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lib√©rer tout le</a> potentiel du m√™me <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mod√®le, le P710 aura</a> en r√©alit√© besoin de trois h√¥tes.  De plus, les applications s'ex√©cutant dans des machines virtuelles effectuent des ajustements.  Par cons√©quent, pour un dimensionnement pr√©cis, nous vous sugg√©rons d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">utiliser un test dans le cas de mod√®les de test de</a> toutes les baies Flash <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AccelStor</a> √† l'int√©rieur de l'infrastructure du client pour les t√¢ches actuelles r√©elles. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr447390/">https://habr.com/ru/post/fr447390/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr447376/index.html">Hackathon SNA 2019</a></li>
<li><a href="../fr447380/index.html">Exceptions Kotlin et leurs fonctionnalit√©s</a></li>
<li><a href="../fr447382/index.html">Le livre "Unity and C #. Gamedev de l'id√©e √† la mise en ≈ìuvre. 2e √©d.</a></li>
<li><a href="../fr447384/index.html">Les semi-conducteurs de puissance au service de l'√©cologie</a></li>
<li><a href="../fr447388/index.html">TL; DR-digest de l'Universit√© ITMO: admission non classique √† l'universit√©, √©v√©nements √† venir et mat√©riaux les plus int√©ressants</a></li>
<li><a href="../fr447392/index.html">Trois probl√®mes de services pour v√©rifier la grammaire anglaise et s'ils peuvent √™tre r√©solus</a></li>
<li><a href="../fr447394/index.html">Entretien avec Vladimir Likhachev, p√®re de Nikolai Likhachev, mieux connu sous le nom de Chris Kaspersky</a></li>
<li><a href="../fr447396/index.html">Les donn√©es de votre entreprise sont-elles pr√©cieuses √† l'√®re de l'IA?</a></li>
<li><a href="../fr447398/index.html">Automatisation robotis√©e des processus - Un nouveau regard sur les anciennes technologies</a></li>
<li><a href="../fr447402/index.html">Splunk Universal Forwarder dans docker comme enregistreur de syst√®me</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
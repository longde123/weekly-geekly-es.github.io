<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§ì üë©üèº‚Äçüéì üîû Escribir un balanceador simple en Go üßëüèº‚Äçü§ù‚Äçüßëüèª üå∂Ô∏è ü¶í</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los equilibradores de carga juegan un papel clave en la arquitectura web. Le permiten distribuir la carga en varios backends, lo que mejora la escalab...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Escribir un balanceador simple en Go</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/476276/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t8/nm/ze/t8nmzevaswfyxtitu7xpx3ml-ho.jpeg"></div><br>  Los equilibradores de carga juegan un papel clave en la arquitectura web.  Le permiten distribuir la carga en varios backends, lo que mejora la escalabilidad.  Y dado que tenemos varios backends configurados, el servicio se vuelve altamente disponible, porque en caso de falla en un servidor, el equilibrador puede elegir otro servidor que funcione. <br><br>  Despu√©s de jugar con equilibradores profesionales como NGINX, trat√© de crear un equilibrador simple por diversi√≥n.  Lo escrib√≠ en Go, es un lenguaje moderno que admite un paralelismo completo.  La biblioteca est√°ndar en Go tiene muchas caracter√≠sticas y le permite escribir aplicaciones de alto rendimiento con menos c√≥digo.  Adem√°s, para facilitar la distribuci√≥n, genera un √∫nico binario enlazado est√°ticamente. <br><a name="habracut"></a><br><h2>  C√≥mo funciona nuestro equilibrador </h2><br>  Se utilizan diferentes algoritmos para distribuir la carga entre los backends.  Por ejemplo: <br><br><ul><li>  Round Robin: la carga se distribuye de manera uniforme, teniendo en cuenta la misma potencia inform√°tica de los servidores. </li><li>  Robin ponderado: seg√∫n la potencia de procesamiento, a los servidores se les pueden asignar diferentes pesos. </li><li>  Menos conexiones: la carga se distribuye entre los servidores con el menor n√∫mero de conexiones activas. </li></ul><br>  En nuestro equilibrador, implementamos el algoritmo m√°s simple: Round Robin. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b3e/35c/751/b3e35c7510dc44451088756d14739161.png"></div><br><br><h2>  Selecci√≥n en Round Robin </h2><br>  El algoritmo Round Robin es simple.  Ofrece a todos los artistas la misma oportunidad de completar tareas. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3b3/4a7/861/3b34a78610b7c1e2d22b85f0419700d2.png"></div><br>  <i>Seleccione servidores en Round Robin para manejar las solicitudes entrantes.</i> <br><br>  Como se muestra en la ilustraci√≥n, el algoritmo selecciona los servidores en un c√≠rculo, c√≠clicamente.  Pero no podemos seleccionarlos <i>directamente</i> , ¬øverdad? <br><br>  ¬øY si el servidor est√° mintiendo?  Probablemente no necesitemos enviarle tr√°fico.  Es decir, el servidor no se puede usar directamente hasta que lo llevemos al estado deseado.  Es necesario dirigir el tr√°fico solo a los servidores que est√°n en funcionamiento. <br><br><h2>  Definir la estructura </h2><br>  Necesitamos rastrear todos los detalles relacionados con el backend.  Necesita saber si est√° vivo y rastrear la URL.  Para hacer esto, podemos definir la siguiente estructura: <br><br><pre><code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">type</span></span> Backend <span class="hljs-keyword"><span class="hljs-keyword">struct</span></span> { URL *url.URL Alive <span class="hljs-keyword"><span class="hljs-keyword">bool</span></span> mux sync.RWMutex ReverseProxy *httputil.ReverseProxy }</code> </pre> <br>  No se preocupe, explicar√© el significado de los campos en el Backend. <br><br>  Ahora, en el equilibrador, necesita rastrear de alguna manera todos los backends.  Para hacer esto, puede usar Slice y un contador variable.  Def√≠nalo en ServerPool: <br><br><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">type</span></span> ServerPool <span class="hljs-keyword"><span class="hljs-keyword">struct</span></span> { backends []*Backend current <span class="hljs-keyword"><span class="hljs-keyword">uint64</span></span> }</code> </pre> <br><h2>  Usando ReverseProxy </h2><br>  Como ya hemos determinado, la esencia del equilibrador est√° en distribuir el tr√°fico a diferentes servidores y devolver los resultados al cliente.  Como dice la documentaci√≥n de Go: <br><br>  <i>ReverseProxy es un controlador HTTP que toma las solicitudes entrantes y las env√≠a a otro servidor, enviando respuestas al cliente.</i> <br><br>  Exactamente lo que necesitamos.  No es necesario reinventar la rueda.  Simplemente puede transmitir nuestras solicitudes a trav√©s de <code>ReverseProxy</code> . <br><br><pre> <code class="go hljs">u, _ := url.Parse(<span class="hljs-string"><span class="hljs-string">"http://localhost:8080"</span></span>) rp := httputil.NewSingleHostReverseProxy(u) <span class="hljs-comment"><span class="hljs-comment">// initialize your server and add this as handler http.HandlerFunc(rp.ServeHTTP)</span></span></code> </pre> <br>  Con <code>httputil.NewSingleHostReverseProxy(url)</code> puede inicializar <code>ReverseProxy</code> , que transmitir√° las solicitudes a la <code>url</code> pasada.  En el ejemplo anterior, todas las solicitudes se enviaron a localhost: 8080 y los resultados se enviaron al cliente. <br><br>  Si observa la firma del m√©todo ServeHTTP, puede encontrar la firma del controlador HTTP en √©l.  Por lo tanto, puede pasarlo a <code>HandlerFunc</code> en <code>http</code> . <br><br>  Otros ejemplos est√°n en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://golang.org/pkg/net/http/">documentaci√≥n</a> . <br><br>  Para nuestro equilibrador, puede iniciar <code>ReverseProxy</code> con la <code>URL</code> asociada en <code>Backend</code> para que ReverseProxy enrute las solicitudes a la <code>URL</code> . <br><br><h2>  Proceso de selecci√≥n del servidor </h2><br>  Durante la siguiente selecci√≥n de servidor, debemos omitir los servidores subyacentes.  Pero necesitas organizar el conteo. <br><br>  Numerosos clientes se conectar√°n al equilibrador, y cuando cada uno de ellos solicite al siguiente nodo que transfiera tr√°fico, puede ocurrir una condici√≥n de carrera.  Para evitar esto, podemos bloquear <code>ServerPool</code> con <code>mutex</code> .  Pero ser√° redundante, adem√°s no queremos bloquear <code>ServerPool</code> .  Solo necesitamos aumentar el contador en uno. <br><br>  La mejor soluci√≥n para cumplir con estos requisitos ser√≠a el incremento at√≥mico.  Go lo admite con el paquete <code>atomic</code> . <br><br><pre> <code class="go hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(s *ServerPool)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">NextIndex</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">int</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>(atomic.AddUint64(&amp;s.current, <span class="hljs-keyword"><span class="hljs-keyword">uint64</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>)) % <span class="hljs-keyword"><span class="hljs-keyword">uint64</span></span>(<span class="hljs-built_in"><span class="hljs-built_in">len</span></span>(s.backends))) }</code> </pre> <br>  Aumentamos at√≥micamente el valor actual en uno y devolvemos el √≠ndice cambiando la longitud de la matriz.  Esto significa que el valor siempre debe estar en el rango de 0 a la longitud de la matriz.  Al final, nos interesar√° un √≠ndice espec√≠fico, no el contador completo. <br><br><h2>  Elegir un servidor en vivo </h2><br>  Ya sabemos que nuestras solicitudes se rotan c√≠clicamente en todos los servidores.  Y solo necesitamos omitir el inactivo. <br><br>  <code>GetNext()</code> siempre devuelve un valor que var√≠a de 0 a la longitud de la matriz.  En cualquier momento, podemos obtener el siguiente nodo, y si est√° inactivo, necesitamos buscar m√°s a trav√©s de la matriz como parte del ciclo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9c1/7a7/fc5/9c17a7fc56f9bf6c9e4583c29127aa55.png"></div><br>  <i>Recorremos la matriz.</i> <br><br>  Como se muestra en la ilustraci√≥n, queremos pasar del siguiente nodo al final de la lista.  Esto se puede hacer usando <code>next + length</code> .  Pero para seleccionar un √≠ndice, debe limitarlo a la longitud de la matriz.  Esto se puede hacer f√°cilmente usando la operaci√≥n de modificaci√≥n. <br><br>  Despu√©s de encontrar un servidor que funcione durante la b√∫squeda, debe marcarse como actual: <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// GetNextPeer returns next active peer to take a connection func (s *ServerPool) GetNextPeer() *Backend { // loop entire backends to find out an Alive backend next := s.NextIndex() l := len(s.backends) + next // start from next and move a full cycle for i := next; i &lt; l; i++ { idx := i % len(s.backends) // take an index by modding with length // if we have an alive backend, use it and store if its not the original one if s.backends[idx].IsAlive() { if i != next { atomic.StoreUint64(&amp;s.current, uint64(idx)) // mark the current one } return s.backends[idx] } } return nil }</span></span></code> </pre><br><h2>  Evitar la condici√≥n de carrera en la estructura Backend </h2><br>  Aqu√≠ debes recordar un tema importante.  La estructura <code>Backend</code> contiene una variable que varias goroutines pueden modificar o consultar al mismo tiempo. <br><br>  Sabemos que las gorutinas leer√°n la variable m√°s que escribirla.  Por lo tanto, para serializar el acceso a <code>Alive</code> elegimos <code>RWMutex</code> . <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// SetAlive for this backend func (b *Backend) SetAlive(alive bool) { b.mux.Lock() b.Alive = alive b.mux.Unlock() } // IsAlive returns true when backend is alive func (b *Backend) IsAlive() (alive bool) { b.mux.RLock() alive = b.Alive b.mux.RUnlock() return }</span></span></code> </pre><br><h2>  Solicitudes de equilibrio </h2><br>  Ahora podemos formular un m√©todo simple para equilibrar nuestras solicitudes.  Solo fallar√° si todos los servidores caen. <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// lb load balances the incoming request func lb(w http.ResponseWriter, r *http.Request) { peer := serverPool.GetNextPeer() if peer != nil { peer.ReverseProxy.ServeHTTP(w, r) return } http.Error(w, "Service not available", http.StatusServiceUnavailable) }</span></span></code> </pre> <br>  Este m√©todo se puede pasar al servidor HTTP simplemente como <code>HandlerFunc</code> . <br><br><pre> <code class="go hljs">server := http.Server{ Addr: fmt.Sprintf(<span class="hljs-string"><span class="hljs-string">":%d"</span></span>, port), Handler: http.HandlerFunc(lb), }</code> </pre><br><h2>  Enrutamos el tr√°fico solo a servidores en ejecuci√≥n </h2><br>  Nuestro equilibrador tiene un problema grave.  No sabemos si el servidor se est√° ejecutando.  Para averiguarlo, debe verificar el servidor.  Hay dos formas de hacer esto: <br><br><ul><li>  Activo: al ejecutar la solicitud actual, encontramos que el servidor seleccionado no responde y lo marcamos como inactivo. </li><li>  Pasivo: puede hacer ping a los servidores en alg√∫n intervalo y verificar el estado. </li></ul><br><h2>  Comprobaci√≥n activa de servidores en ejecuci√≥n </h2><br>  Si se <code>ReverseProxy</code> alg√∫n error <code>ReverseProxy</code> inicia la funci√≥n de devoluci√≥n de llamada <code>ErrorHandler</code> .  Esto se puede usar para detectar fallas: <br><br><pre> <code class="go hljs">proxy.ErrorHandler = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(writer http.ResponseWriter, request *http.Request, e error)</span></span></span></span> { log.Printf(<span class="hljs-string"><span class="hljs-string">"[%s] %s\n"</span></span>, serverUrl.Host, e.Error()) retries := GetRetryFromContext(request) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> retries &lt; <span class="hljs-number"><span class="hljs-number">3</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">select</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> &lt;-time.After(<span class="hljs-number"><span class="hljs-number">10</span></span> * time.Millisecond): ctx := context.WithValue(request.Context(), Retry, retries+<span class="hljs-number"><span class="hljs-number">1</span></span>) proxy.ServeHTTP(writer, request.WithContext(ctx)) } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-comment"><span class="hljs-comment">// after 3 retries, mark this backend as down serverPool.MarkBackendStatus(serverUrl, false) // if the same request routing for few attempts with different backends, increase the count attempts := GetAttemptsFromContext(request) log.Printf("%s(%s) Attempting retry %d\n", request.RemoteAddr, request.URL.Path, attempts) ctx := context.WithValue(request.Context(), Attempts, attempts+1) lb(writer, request.WithContext(ctx)) }</span></span></code> </pre> <br>  Al desarrollar este controlador de errores, utilizamos las capacidades de los cierres.  Esto nos permite capturar variables externas como las URL del servidor en nuestro m√©todo.  El controlador verifica el contador de reintentos, y si es menor que 3, nuevamente enviamos la misma solicitud al mismo servidor.  Esto se debe a que, debido a errores temporales, el servidor puede descartar nuestras solicitudes, pero pronto estar√° disponible (es posible que el servidor no tenga sockets libres para nuevos clientes).  Por lo tanto, debe configurar el temporizador de retraso para un nuevo intento despu√©s de aproximadamente 10 ms.  Con cada solicitud aumentamos el contador de intentos. <br><br>  Despu√©s del fracaso de cada intento, marcamos el servidor como inactivo. <br><br>  Ahora debe asignar un nuevo servidor para la misma solicitud.  Haremos esto usando el contador de intentos usando el paquete de <code>context</code> .  Despu√©s de aumentar el contador de intentos, lo pasamos a <code>lb</code> para seleccionar un nuevo servidor para procesar la solicitud. <br><br>  No podemos hacer esto indefinidamente, por lo que comprobaremos en <code>lb</code> si se ha alcanzado el n√∫mero m√°ximo de intentos antes de continuar con el procesamiento de la solicitud. <br><br>  Simplemente puede obtener el contador de intentos de la solicitud, si alcanza el m√°ximo, entonces interrumpimos la solicitud. <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// lb load balances the incoming request func lb(w http.ResponseWriter, r *http.Request) { attempts := GetAttemptsFromContext(r) if attempts &gt; 3 { log.Printf("%s(%s) Max attempts reached, terminating\n", r.RemoteAddr, r.URL.Path) http.Error(w, "Service not available", http.StatusServiceUnavailable) return } peer := serverPool.GetNextPeer() if peer != nil { peer.ReverseProxy.ServeHTTP(w, r) return } http.Error(w, "Service not available", http.StatusServiceUnavailable) }</span></span></code> </pre> <br>  Esta es una implementaci√≥n recursiva. <br><br><h2>  Usando el paquete de contexto </h2><br>  El paquete de <code>context</code> permite almacenar datos √∫tiles en solicitudes HTTP.  Utilizaremos esto activamente para rastrear los datos relacionados con las solicitudes: contadores de <code>Retry</code> y <code>Retry</code> . <br><br>  Primero, debe establecer las claves para el contexto.  Se recomienda usar no cadenas, sino valores num√©ricos √∫nicos.  Go tiene una palabra clave <code>iota</code> para la implementaci√≥n incremental de constantes, cada una de las cuales contiene un valor √∫nico.  Esta es una gran soluci√≥n para definir teclas num√©ricas. <br><br><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> ( Attempts <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> = <span class="hljs-literal"><span class="hljs-literal">iota</span></span> Retry )</code> </pre> <br>  Luego puede extraer el valor, como solemos hacer con <code>HashMap</code> .  El valor predeterminado puede depender de la situaci√≥n actual. <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// GetAttemptsFromContext returns the attempts for request func GetRetryFromContext(r *http.Request) int { if retry, ok := r.Context().Value(Retry).(int); ok { return retry } return 0 }</span></span></code> </pre><br><h2>  Validaci√≥n pasiva del servidor </h2><br>  Las verificaciones pasivas identifican y recuperan servidores ca√≠dos.  Los enviamos a un cierto intervalo para determinar su estado. <br><br>  Para hacer ping, intente establecer una conexi√≥n TCP.  Si el servidor responde, lo marcamos funcionando.  Este m√©todo se puede adaptar para llamar a puntos finales espec√≠ficos como <code>/status</code> .  Aseg√∫rese de cerrar la conexi√≥n despu√©s de crearla para reducir la carga adicional en el servidor.  De lo contrario, intentar√° mantener esta conexi√≥n y eventualmente agotar√° sus recursos. <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// isAlive checks whether a backend is Alive by establishing a TCP connection func isBackendAlive(u *url.URL) bool { timeout := 2 * time.Second conn, err := net.DialTimeout("tcp", u.Host, timeout) if err != nil { log.Println("Site unreachable, error: ", err) return false } _ = conn.Close() // close it, we dont need to maintain this connection return true }</span></span></code> </pre> <br>  Ahora puede iterar los servidores y marcar sus estados: <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// HealthCheck pings the backends and update the status func (s *ServerPool) HealthCheck() { for _, b := range s.backends { status := "up" alive := isBackendAlive(b.URL) b.SetAlive(alive) if !alive { status = "down" } log.Printf("%s [%s]\n", b.URL, status) } }</span></span></code> </pre> <br>  Para ejecutar este c√≥digo peri√≥dicamente, puede ejecutar el temporizador en Ir.  Le permitir√° escuchar eventos en el canal. <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// healthCheck runs a routine for check status of the backends every 2 mins func healthCheck() { t := time.NewTicker(time.Second * 20) for { select { case &lt;-tC: log.Println("Starting health check...") serverPool.HealthCheck() log.Println("Health check completed") } } }</span></span></code> </pre> <br>  En este c√≥digo, el canal <code>&lt;-tC</code> devolver√° un valor cada 20 segundos.  <code>select</code> permite definir este evento.  En ausencia de una situaci√≥n <code>default</code> , espera hasta que se pueda ejecutar al menos un caso. <br><br>  Ahora ejecute el c√≥digo en una rutina diferente: <br><br><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">go</span></span> healthCheck()</code> </pre><br><h2>  Conclusi√≥n </h2><br>  En este art√≠culo, examinamos muchas preguntas: <br><br><ul><li>  Round Robin Algorithm </li><li>  ReverseProxy de la biblioteca est√°ndar </li><li>  Mutexes </li><li>  Operaciones at√≥micas </li><li>  Cortocircuitos </li><li>  Devoluciones de llamada </li><li>  Operaci√≥n de selecci√≥n </li></ul><br>  Hay muchas m√°s formas de mejorar nuestro equilibrador.  Por ejemplo: <br><br><ul><li>  Use el mont√≥n para ordenar servidores en vivo para reducir el alcance de b√∫squeda. </li><li>  Recoge estad√≠sticas. </li><li>  Implemente el algoritmo ponderado round-robin con el menor n√∫mero de conexiones. </li><li>  Agregar soporte para archivos de configuraci√≥n. </li></ul><br>  Y as√≠ sucesivamente. <br><br>  El c√≥digo fuente est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/476276/">https://habr.com/ru/post/476276/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../476264/index.html">Telegram bot para aprender idiomas extranjeros: desde api√±ar palabras hasta hablar</a></li>
<li><a href="../476266/index.html">Pr√°cticas en Mars Digital Technologies. C√≥mo aplicamos el aprendizaje profundo en M&M</a></li>
<li><a href="../476268/index.html">Soluciones para los desaf√≠os de b√∫squeda de errores ofrecidos por el equipo de PVS-Studio en las conferencias en 2018-2019</a></li>
<li><a href="../476270/index.html">Nuestro ganado: TopCoder Open 2019</a></li>
<li><a href="../476272/index.html">Respuestas a las tareas del stand de PVS-Studio en las conferencias 2018-2019</a></li>
<li><a href="../476278/index.html">SOMBRERO NEGRO Conferencia de Estados Unidos. Hazte rico o muere: gana dinero en Internet con Black Hat. Parte 3</a></li>
<li><a href="../476280/index.html">A trav√©s de espinas a DOS: cuatro disquetes que cambiaron el mundo</a></li>
<li><a href="../476284/index.html">Formulamos una estrategia para trabajar con errores en React</a></li>
<li><a href="../476286/index.html">Los 5 principales marcos JS para el desarrollo front-end en 2020. Parte 1</a></li>
<li><a href="../476288/index.html">Los 5 principales marcos JS para el desarrollo front-end en 2020. Parte 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👇🏼 👩🏻‍🌾 🙅🏾 Tanque de robô Raspberry Pi com bastão de computador Intel Neural 2 🧑🏼‍🤝‍🧑🏻 🤴🏻 🖕🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Então, uma nova etapa chegou ao desenvolvimento do tanque de framboesa . 

 Na série anterior, verificou-se que a segmentação semântica fora da caixa ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tanque de robô Raspberry Pi com bastão de computador Intel Neural 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/459126/">  Então, uma nova etapa chegou ao desenvolvimento do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tanque de framboesa</a> . <br><br>  Na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">série anterior,</a> verificou-se que a segmentação semântica fora da caixa era muito difícil para o Raspberry. <br><br>  Brainstorming e comentários nos permitiram identificar as seguintes áreas de desenvolvimento: <br><br><ul><li>  treine sua própria rede E-net para o tamanho de imagem desejado </li><li>  transferir o lançamento da rede neural do próprio Raspberry para um hardware especial, do qual o Intel Movidius (também conhecido como Neural Compute Stick ou NCS) foi mencionado com mais frequência. </li></ul><br>  Anexar um novo pedaço de ferro ao robô é a coisa mais interessante da robótica. Portanto, o trabalho meticuloso de treinar a rede neural foi adiado para tempos melhores. <br><br>  Alguns dias - e o milagre pedaço de ferro da Intel em minhas mãos. <br><br>  É muito grande e você não pode colocá-lo no conector USB inferior da framboesa.  Como as portas USB certas foram obscurecidas por um tripé de câmera e a parte superior esquerda foi ocupada pelo módulo GPS, não havia muitas opções. <br><br>  Como resultado, o GPS foi colocado em um cabo, desligado, e o cabo foi enrolado em um tripé, e o NCS entrou em seu lugar. <br><br>  Nesta parte do hardware foi concluída. <br><br><img src="https://habrastorage.org/webt/rr/an/a1/rrana1u2e0uwupybfu4txj6hmmk.jpeg"><br><a name="habracut"></a><br><h2>  Intel NCS </h2><br>  A Intel lançou recentemente a segunda versão do NCS, e a API era completamente incompatível com a versão anterior, que os usuários colocaram muita dor na Internet. <br><br>  Como resultado, atualmente toda a base de conhecimento sobre a versão anterior é apenas lixo informativo. <br><br>  A nova edição oferece a estrutura OpenVino, que inclui o OpenCV e muito mais, incluindo várias ferramentas para trabalhar com redes neurais. <br><br>  Aqui estão alguns artigos introdutórios sobre NCS2 e OpenVino: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Da própria Intel</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Em direção à ciência de dados I</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Rumo à ciência de dados II</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PyImageSearch</a> </li></ul><br>  A introdução ao NCS mostrou-se bastante tranquila. <br><br>  A Intel inicialmente deu suporte ao Raspbian, então não havia necessidade de dançar com um pandeiro. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O documento introdutório</a> também foi muito claro e a instalação da estrutura OpenVino não causou problemas. <br><br>  Acabou sendo um bom bônus o OpenVino incluir o OpenCV 4.1, o que economiza tempo, já que eu tive que criar versões anteriores do OpenCV no Raspberry. <br><br>  Aqui está o que o NCS2 se parece sozinho: <br><br><img src="https://habrastorage.org/webt/ww/dc/by/wwdcbyyaogekp33qbtehz6zp3mo.jpeg"><br><br>  Além disso, acabou sendo mais interessante. <br><br>  O NCS suporta apenas seu próprio formato de rede neural, enquanto a Intel fornece a ferramenta Model Optimizer como parte do OpenVino para a conversão de gráficos das estruturas mais populares: Tensorflow, Caffe, Torch.  Mais sobre isso será o próximo. <br><br>  Além disso, a Intel também fornece <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">modelos de zoológico</a> - um conjunto de modelos prontos para muitas ocasiões. <br><br>  Entre eles, dois modelos para segmentação de rodovias: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Um mais simples</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Outro enganado</a> </li></ul><br><h2>  Redes neurais na NCS </h2><br>  Para executar uma rede neural em um dispositivo, você precisa executar várias etapas. <br><br><h4>  Inicializar dispositivo </h4><br>  O nome MYRIAD, a idéia do plug-in e o carregamento dinâmico dele, o caminho para o qual deve ser especificado no programa - claramente se estendem do passado sombrio. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> openvino.inference_engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IENetwork, IEPlugin ncs_plugin = IEPlugin(device=<span class="hljs-string"><span class="hljs-string">"MYRIAD"</span></span>, plugin_dirs=<span class="hljs-string"><span class="hljs-string">"/opt/intel/openvino/inference_engine/lib/armv7l"</span></span>)</code> </pre> <br><h4>  Download do modelo </h4><br>  Em seguida, você precisa fazer o upload do modelo para o dispositivo. <br><br>  Esta é uma operação difícil.  Esse pequeno modelo que usei para segmentação leva cerca de 15 segundos para carregar. <br><br>  A boa notícia é que você só precisa baixar o modelo uma vez e pode baixar vários modelos. <br><br><pre> <code class="python hljs"> model = IENetwork(model=xml_path, weights=bin_path) net = ncs_plugin.load(network=model)</code> </pre><br><h4>  Executar cálculo </h4><br>  Agora o modelo pode ser usado. <br><br><pre> <code class="python hljs"> input_blob = next(iter(model.inputs)) out_blob = next(iter(model.outputs)) n, c, h, w = model.inputs[input_blob].shape images = np.ndarray(shape=(n, c, h, w)) images[<span class="hljs-number"><span class="hljs-number">0</span></span>] = image res = net.infer(inputs={input_blob: images}) res = res[out_blob]</code> </pre><br><h4>  Processo único </h4><br>  De repente, descobriu-se que você não pode usar o NCS de dois processos diferentes ao mesmo tempo. <br>  Qualquer pessoa atrasada não pode carregar o modelo: <br><br><pre> <code class="bash hljs">E: [ncAPI] [ 684447] resetAll:348 Failed to connect to stalled device, rc: X_LINK_ERROR E: [ncAPI] [ 691700] ncDeviceOpen:672 Failed to find suitable device, rc: X_LINK_DEVICE_NOT_FOUND Traceback (most recent call last): net = ncs_plugin.load(network=model) File <span class="hljs-string"><span class="hljs-string">"ie_api.pyx"</span></span>, line 395, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> openvino.inference_engine.ie_api.IEPlugin.load File <span class="hljs-string"><span class="hljs-string">"ie_api.pyx"</span></span>, line 406, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> openvino.inference_engine.ie_api.IEPlugin.load RuntimeError: Can not init USB device: NC_ERROR</code> </pre><br>  Nem o Google nem o fórum de suporte da Intel tornaram possível entender qual era o problema - ou o dispositivo é realmente exclusivo ou simplesmente não sei como prepará-lo. <br><br><h2>  Segmentação OpenVino </h2><br>  Como já mencionado, pronto para uso, o OpenVino fornece um modelo e exemplos de segmentação de estradas. <br><br>  Os resultados do teste são um tanto contraditórios.  Às vezes é reconhecido de maneira torta, mas na maioria é normal. <br><br>  A Enet funcionou melhor, mas ainda precisamos tentar a Enet no NCS, então vamos tentar com o que temos. <br><br><img src="https://habrastorage.org/webt/gk/ll/sm/gkllsmwznf3smcft_gyxk_gdaos.jpeg"><br><br>  Curiosamente, para aprender mais sobre o modelo no OpenVino e treinar novamente, não é tão simples. <br><br>  Os usuários <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">estão interessados</a> , mas a pessoa da Intel disse estritamente que o código e os dados do modelo estão fechados, e aqueles que desejarem podem usar uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rede neural semelhante no PyTorch</a> , treinar, converter e usá-lo. <br><br>  A vantagem da velocidade é muito significativa: <br>  Se a segmentação da Enet demorar 6 segundos, esse modelo levará 0,8 segundos para processar uma foto (enquanto levava 14 segundos para carregar o modelo no dispositivo, mas isso é feito ao mesmo tempo). <br><br><h3>  Classificação das direções </h3><br>  Para tomar decisões sobre a direção do movimento, o tanque usa uma rede neural simples, conforme descrito no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo correspondente</a> . <br><br>  A rede neural é treinada em Keras e é executada em Raspberry através do Tensorflow, que possui um adaptador interno para esse formato. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O modelo é</a> muito simples e até o Raspberry mostra resultados de velocidade aceitáveis. <br>  (0,35 segundos por foto). <br><br>  No entanto, com a glândula Intel, você pode esperar obter melhores resultados. <br>  Entre os formatos que o Model Optimizer da Intel aceita para conversão, há o Tensorflow, mas não o Keras. <br><br>  Converter Keras para TF é uma coisa bastante popular, há material suficiente sobre esse tópico, fui guiado por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">este artigo</a> . <br><br>  O mesmo autor tem um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo mais extenso</a> , apenas sobre o tópico de como executar o modelo Keras no OpenVino. <br><br>  Você também pode usar as <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">orientações da Intel</a> . <br><br>  Em geral, compilando as fontes, recebi um script para converter o modelo Keras em TF: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.python.framework.graph_util <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> convert_variables_to_constants <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> load_model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> model_from_json <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_keras_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(json_file, model_file)</span></span></span><span class="hljs-function">:</span></span> jf = open(json_file, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) loaded_model_json = jf.read() jf.close() loaded_model = model_from_json(loaded_model_json) loaded_model.load_weights(model_file) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> loaded_model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">freeze_session</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(session, keep_var_names=None, output_names=None, clear_devices=True)</span></span></span><span class="hljs-function">:</span></span> graph = session.graph <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> graph.as_default(): freeze_var_names = list(set(v.op.name <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> v <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tf.global_variables()).difference(keep_var_names <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> [])) output_names = output_names <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> [] output_names += [v.op.name <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> v <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tf.global_variables()] <span class="hljs-comment"><span class="hljs-comment"># Graph -&gt; GraphDef ProtoBuf input_graph_def = graph.as_graph_def() if clear_devices: for node in input_graph_def.node: node.device = "" frozen_graph = convert_variables_to_constants(session, input_graph_def, output_names, freeze_var_names) return frozen_graph model = load_keras_model('./model.json', './model.h5') frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model.outputs]) tf.train.write_graph(frozen_graph, ".", "ktf_model.pb", as_text=False)</span></span></code> </pre><br>  O mesmo código está <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no github</a> . <br><br>  O modelo TF resultante é mais destilado no formato OpenVino: <br><br><pre> <code class="bash hljs">python mo_tf.py --input_model <span class="hljs-string"><span class="hljs-string">"model/ktf_model.pb"</span></span> --log_level=DEBUG -b1 --data_type FP16</code> </pre> <br>  Os testes mostraram que a classificação da imagem leva 0,007 segundos. <br>  Este resultado é muito agradável. <br><br>  Todos os modelos treinados (Keras, TF, OpenVino) também são carregados <a href="">no github</a> . <br><br><h2>  Reconhecimento de Objetos </h2><br>  A tarefa de segmentação não é a única que um robô precisa resolver em sua vida difícil. <br><br>  No começo, havia um detector de gato, que mais tarde se transformou em um detector universal baseado no MobileSSD e OpenCV-DNN. <br><br>  Agora é hora de ativar a mesma tarefa no NCS. <br><br>  No <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">model_zoo</a> da Intel, os detectores de especificidade mais restrita baseados no MobileSSD são suficientes, mas não há analógico exato. <br><br>  No entanto, esta rede está listada como compatível na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">lista de modelos TF suportados</a> . <br><br>  Curiosamente, no momento da redação deste artigo, a versão do MobileSSD 2018_01_28 é indicada aqui. <br><br>  No entanto, o OpenCV se recusa a ler este modelo: <br><br><pre> <code class="bash hljs">cv2.error: OpenCV(4.1.0-openvino) /home/jenkins/workspace/OpenCV/OpenVINO/build/opencv/modules/dnn/src/tensorflow/tf_importer.cpp:530: error: (-2:Unspecified error) Const input blob <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> weights not found <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> <span class="hljs-string"><span class="hljs-string">'getConstBlob'</span></span></code> </pre><br>  (Mas descobrimos que eles usam Jenkins). <br><br>  Ao mesmo tempo, a conversão para o OpenVino é bem-sucedida. <br><br>  Se tentarmos converter a versão do Mobile SSD compatível com o OpenCV-DNN (11_06_2017), obtemos o seguinte: <br><br><pre> <code class="bash hljs">[E0919 main.py:317] Unexpected exception happened during extracting attributes <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/Relu6. Original exception message: operands could not be broadcast together with remapped shapes [original-&gt;remapped]: (0,) and requested shape (1,0,10,256)</code> </pre><br>  Algo assim, tecnicamente OpenVino e OpenCV-DNN estão no mesmo pacote, mas são incompatíveis com as versões das redes neurais usadas. <br><br>  Ou seja, se você quiser usar as duas abordagens simultaneamente, precisará arrastar duas versões do MobileSSD. <br><br>  Em termos de velocidade, a comparação é certamente a favor do NCS: 0,1 segundos versus 1,7. <br><br>  Em termos de qualidade ... (Embora isso não seja uma questão do NCS, mas da evolução do SSD móvel). <br><br><img src="https://habrastorage.org/webt/rz/58/zz/rz58zzzllyd5i3gubv99nz5-b6m.jpeg"><br><br><h2>  Classificação da imagem </h2><br>  O tanque é capaz de classificar imagens através do Tensorflow, usando o Inception no Imagenet. <br>  E eu usei o Inception 05-12-2015, quando era outro. <br><br>  Aconteceu que eu estava muito atrasada na vida, porque os caras do Google não estão à toa comendo o pão e já produziram quatro versões! <br><br>  Mas os caras da Intel não estão por trás deles e todas as quatro versões foram suportadas no OpenVino. <br><br>  Aqui está <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um artigo que</a> descreve várias versões do Inception. <br>  Mas não vamos brincar, baixamos imediatamente o último, quarto. <br><br>  Classificamos a foto com o gato e o laptop em cima da mesa. <br><br>  Lembramos os resultados da versão atual: <br><br><ul><li>  laptop 62% </li><li>  notebook, notebook 11% </li><li>  13 segundos </li><li>  onde esta o gato </li></ul><br>  Agora lemos as <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">instruções</a> para converter o Inception em OpenVino. <br><br>  A conversão foi bem-sucedida, iniciamos o classificador no NCS: <br><br><ul><li>  laptop, computador portátil 85% </li><li>  notebook, notebook 8% </li><li>  0,2 segundos </li><li>  não há gato de novo </li></ul><br><h2>  Conclusão </h2><br>  Assim, todos os cenários que exigiam o Tensorflow foram reproduzidos usando o NCS, e isso significa que você pode optar por não usar o Tensorflow. <br><br>  Mesmo assim, essa estrutura é pesada para o Raspberry. <br><br>  A velocidade com que o NCS digere a rede neural permite expandir seus horizontes. <br><br>  Há tarefas que o robô já realiza, por exemplo, segmentação e classificação semânticas, mas há outras como segmentação de objetos ou transmissão de vídeo com objetos detectados em tempo real.  (que não poderia ter sido pensado na framboesa nua). <br><br>  Os problemas com o multiprocessamento são um pouco confusos, mas mesmo que não possam ser resolvidos, sempre há uma opção na forma de o NCS agrupar um serviço separado. <br><br><h2>  Referências </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Introdução ao Intel OpenVino</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Guia de instalação do Raspbian</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenVino Model Zoo - uma lista de modelos prontos com descrições</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Recurso onde você pode fazer download de modelos OpenVino</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Repo firmware de tanque para OpenVino no github</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt459126/">https://habr.com/ru/post/pt459126/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt459114/index.html">14 Melhores Plugins de SEO para WordPress em 2019</a></li>
<li><a href="../pt459116/index.html">Um passo mais perto do reparo do timo</a></li>
<li><a href="../pt459118/index.html">Como projetamos e implementamos a nova rede na Huawei no escritório de Moscou, parte 2</a></li>
<li><a href="../pt459120/index.html">Computadores modulares incorporados da série UNO-1000/2000</a></li>
<li><a href="../pt459122/index.html">Aleksey Savvateev: Prêmio Nobel de Jean Tyrol por analisar mercados imperfeitos (2014) e reputação coletiva</a></li>
<li><a href="../pt459128/index.html">Interfaces japonesas no mundo real</a></li>
<li><a href="../pt459130/index.html">Manipulação suave de erros em microsserviços</a></li>
<li><a href="../pt459134/index.html">Experiência usando BDD</a></li>
<li><a href="../pt459136/index.html">Pílula azul falsa</a></li>
<li><a href="../pt459138/index.html">Como a chave secreta da Huawei entrou no firmware dos roteadores Cisco</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•™ üëáüèæ üë©üèø‚Äçüéì Ich muss den Kubernetes-Cluster erh√∂hen, bin aber nur ein Code-Programmierer. Es gibt einen Ausweg üìá üë≥üèø üßúüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Guten Tag. Noch ein Hinweis aus meiner Erfahrung. Diesmal geht es oberfl√§chlich um die Basisinfrastruktur , die ich verwende, wenn ich etwas entladen ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ich muss den Kubernetes-Cluster erh√∂hen, bin aber nur ein Code-Programmierer. Es gibt einen Ausweg</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/423481/"><img src="https://habrastorage.org/webt/j9/qc/fb/j9qcfbdq_raamw7rwyt02ci1an8.png"><br><br>  Guten Tag.  Noch ein Hinweis aus meiner Erfahrung.  Diesmal geht es oberfl√§chlich um die <b>Basisinfrastruktur</b> , die ich verwende, wenn ich etwas entladen muss, aber es sind keine <b>Entwickler in der N√§he</b> .  Der derzeitige Abstraktionsgrad in der Technologie erm√∂glicht es jedoch, etwa ein Jahr lang mit dieser Infrastruktur zu leben, die w√§hrend der Nacht mithilfe des Internets und vorgefertigter Dinge aufgebaut wurde. <br><br>  Schl√ºsselw√∂rter - <b>AWS</b> + <b>Terraform</b> + <b>Kops</b> .  Wenn dies f√ºr mich n√ºtzlich ist, wird es wahrscheinlich f√ºr jemand anderen n√ºtzlich sein.  Willkommen zu den Kommentaren. <br><a name="habracut"></a><br><h2>  -1.  Womit wir es zu tun haben </h2><br>  Die klassische Situation - das Projekt wird in eine solche Phase geschrieben, in der es irgendwo entladen und verwendet werden muss.  Und das Projekt ist komplizierter als eine einfache HTML-Seite.  Ich m√∂chte die M√∂glichkeit einer horizontalen Skalierung, die Identit√§t der Umgebung auf lokalen, Test-, Produktst√§nden und einen mehr oder weniger normalen Bereitstellungsprozess. <br><blockquote>  Es geht um eine Anwendung auf <b>Laravel</b> , die den gesamten Prozess von Anfang bis Ende zeigt.  Auf √§hnliche Weise k√∂nnen Sie jedoch eine Reihe von Diensten f√ºr unterwegs, Python-Anwendungen, kleine Websites in WP, HTML-Seiten und vieles mehr bereitstellen.  Bis zu einem gewissen Grad reicht dies aus, und dann erscheint eine separate Person im Team, die es verbessern und erg√§nzen wird. </blockquote>  K√ºrzlich kam ich zu der Tatsache, dass ich <b>GoLand, PhpStorm, Docker, Git</b> auf lokalen Computern installiere und bereit <b>bin</b> zu arbeiten.  Ja, und Sie k√∂nnen von einem einzigen Computer aus in Massenclustern verwalten. Daher werde ich den gesamten Prozess beschreiben, ohne das Betriebssystem zu ber√ºcksichtigen, auf dem Sie arbeiten, und alle Dinge in einen Docker-Container packen. <br><br><h2>  0. Vorbereitungen f√ºr die Arbeit. </h2><br>  Stellen wir uns vor, wir haben bereits ein Konto bei <b>AWS</b> registriert, vom technischen Support gebeten, die Kontolimits um die Anzahl der gleichzeitig ausgef√ºhrten Server zu erh√∂hen, einen <b>IAM-</b> Benutzer erstellt und jetzt haben wir <b>Zugriffsschl√ºssel</b> + <b>Geheimschl√ºssel</b> .  Zone - <b>us-east-1</b> . <br><br>  Was brauchen wir auf dem lokalen Computer?  <b>AWS CLI</b> , <b>Terraform</b> f√ºr die deklarative Verwaltung von <b>AWS</b> , <b>kubectl</b> , <b>kops</b> f√ºr die Konfiguration des Clusters und <b>Helm</b> f√ºr die Bereitstellung einiger Dienste.  Wir sammeln die <b>Docker-Datei</b> (die ich vor langer Zeit irgendwo in der Weite des Githubs gefunden habe, aber ich kann nicht finden, wo).  Wir schreiben unsere <b>docker-compose.yml</b> f√ºr Mount-Verzeichnisse und <b>Makefile</b> f√ºr Aliase. <br><br><div class="spoiler">  <b class="spoiler_title">Dockerfile</b> <div class="spoiler_text"><pre><code class="plaintext hljs">FROM ubuntu:16.04 ARG AWSCLI_VERSION=1.12.1 ARG HELM_VERSION=2.8.2 ARG ISTIO_VERSION=0.6.0 ARG KOPS_VERSION=1.9.0 ARG KUBECTL_VERSION=1.10.1 ARG TERRAFORM_VERSION=0.11.0 # Install generally useful things RUN apt-get update \ &amp;&amp; apt-get -y --force-yes install --no-install-recommends \ curl \ dnsutils \ git \ jq \ net-tools \ ssh \ telnet \ unzip \ vim \ wget \ &amp;&amp; apt-get clean \ &amp;&amp; apt-get autoclean \ &amp;&amp; apt-get autoremove \ &amp;&amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* # Install AWS CLI RUN apt-get update \ &amp;&amp; apt-get -y --force-yes install \ python-pip \ &amp;&amp; pip install awscli==${AWSCLI_VERSION} \ &amp;&amp; apt-get clean \ &amp;&amp; apt-get autoclean \ &amp;&amp; apt-get autoremove \ &amp;&amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* # Install Terraform RUN wget -O terraform.zip https://releases.hashicorp.com/terraform/${TERRAFORM_VERSION}/terraform_${TERRAFORM_VERSION}_linux_amd64.zip \ &amp;&amp; unzip terraform.zip \ &amp;&amp; mv terraform /usr/local/bin/terraform \ &amp;&amp; chmod +x /usr/local/bin/terraform \ &amp;&amp; rm terraform.zip # Install kubectl ADD https://storage.googleapis.com/kubernetes-release/release/v${KUBECTL_VERSION}/bin/linux/amd64/kubectl /usr/local/bin/kubectl RUN chmod +x /usr/local/bin/kubectl # Install Kops ADD https://github.com/kubernetes/kops/releases/download/${KOPS_VERSION}/kops-linux-amd64 /usr/local/bin/kops RUN chmod +x /usr/local/bin/kops # Install Helm RUN wget -O helm.tar.gz https://storage.googleapis.com/kubernetes-helm/helm-v${HELM_VERSION}-linux-amd64.tar.gz \ &amp;&amp; tar xfz helm.tar.gz \ &amp;&amp; mv linux-amd64/helm /usr/local/bin/helm \ &amp;&amp; chmod +x /usr/local/bin/helm \ &amp;&amp; rm -Rf linux-amd64 \ &amp;&amp; rm helm.tar.gz # Create default user "kops" RUN useradd -ms /bin/bash kops WORKDIR /home/kops USER kops # Ensure the prompt doesn't break if we don't mount the ~/.kube directory RUN mkdir /home/kops/.kube \ &amp;&amp; touch /home/kops/.kube/config</code> </pre> <br></div></div><div class="spoiler">  <b class="spoiler_title">docker-compose.yml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">version: '2.1' services: cluster-main: container_name: cluster.com image: cluster.com user: root stdin_open: true volumes: - ./data:/data - ./.ssh:/root/.ssh - ./.kube:/root/.kube - ./.aws:/root/.aws cluster-proxy: container_name: cluster.com-kubectl-proxy image: cluster.com user: root entrypoint: kubectl proxy --address='0.0.0.0' --port=8001 --accept-hosts='.*' ports: - "8001:8001" stdin_open: true volumes: - ./data:/data - ./.ssh:/root/.ssh - ./.kube:/root/.kube - ./.aws:/root/.aws</code> </pre><br></div></div><div class="spoiler">  <b class="spoiler_title">Makefile</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">docker.build: docker build -t cluster.com . docker.run: docker-compose up -d docker.bash: docker exec -it cluster.com bash</code> </pre> <br></div></div><br>  <b>Dockerfile</b> - Nehmen Sie das grundlegende Ubuntu-Image und installieren Sie die gesamte Software.  <b>Makefile</b> - nur zur Vereinfachung k√∂nnen Sie den √ºblichen Aliase-Mechanismus verwenden.  <b>Docker-compose.yml</b> - Wir haben einen zus√§tzlichen Container hinzugef√ºgt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, der</a> uns in den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">K8S Dashboard-</a> Browser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wirft</a> , wenn Sie etwas visuell sehen m√ºssen. <br><br>  Wir erstellen die <b>Ordner</b> <b>data</b> , <b>.ssh</b> , <b>.kube</b> , <b>.aws</b> im Stammverzeichnis und legen dort unsere Konfiguration f√ºr aws, ssh-Schl√ºssel ab. Wir k√∂nnen unseren Container √ºber <b>make docker.build &amp; make docker.run</b> sammeln und <b>ausf√ºhren</b> . <br><br>  Nun, erstellen Sie im <b>Datenordner</b> einen Ordner, in dem wir <b>yaml k8s-</b> Dateien <b>ablegen</b> , und neben dem zweiten, in dem wir den Status der <b>Terraform des</b> Clusters speichern.  Ich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><b>habe das</b></a> ungef√§hre Ergebnis dieser Etappe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><b>auf den Github gelegt</b></a> . <br><br><h2>  1. Erh√∂hen Sie unseren Cluster. </h2><br><blockquote>  Als n√§chstes folgt eine kostenlose √úbersetzung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieser</a> Notiz.  Ich werde viele theoretische Punkte weglassen und versuchen, einen kurzen Druck zu beschreiben.  Trotzdem ist das Format meiner Notiz tldr. </blockquote><br>  In unserem <b>Ordner data / aws-cluster-init-kops-terraform</b> klonen <b>wir,</b> was sich in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem</a> Repository befindet, und gehen √ºber <b>make docker.bash</b> zur Containerkonsole.  Die Streuung langweiliger Teams beginnt. <br><br><h4>  AWS CLI </h4><br>  Wir erstellen die User- <b>Kops</b> , f√ºgen Zugriffsrechte hinzu und konfigurieren die <b>AWS-CLI</b> <b>neu</b> , um keine Befehle vom Superuser auszuf√ºhren. <br><br><pre> <code class="bash hljs">aws iam create-group --group-name kops <span class="hljs-comment"><span class="hljs-comment">#   aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AWSCertificateManagerFullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name kops aws iam create-user --user-name kops aws iam add-user-to-group --user-name kops --group-name kops aws iam create-access-key --user-name kops</span></span></code> </pre><br><pre> <code class="bash hljs">aws configure</code> </pre><br><h4>  Terraform initialisieren </h4><br>  <b>√Ñndern Sie</b> in der Datei <b>data / aws-cluster-init-kops-terraform / variables.tf den</b> Namen des Clusters in den gew√ºnschten.  Vergessen Sie nicht, unsere DNS-Server aus der Datei <b>update.json zu entnehmen</b> und dort zu aktualisieren, wo Sie Ihre Domain gekauft haben. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#    cd /data/aws-cluster-init-kops-terraform #    AWS CLI export AWS_ACCESS_KEY_ID=$(aws configure get aws_access_key_id) export AWS_SECRET_ACCESS_KEY=$(aws configure get aws_secret_access_key) #  terraform terraform init terraform get terraform apply #  NS  cat update-zone.json \ | jq ".Changes[].ResourceRecordSet.Name=\"$(terraform output name).\"" \ | jq ".Changes[].ResourceRecordSet.ResourceRecords=$(terraform output -json name_servers | jq '.value|[{"Value": .[]}]')" \ &gt; update-zone.json</span></span></code> </pre><br><h4>  Kops </h4><br>  Wir erstellen einen Cluster durch <b>Kops</b> und exportieren die Konfiguration in eine <b>.tf-</b> Datei. <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> NAME=$(terraform output cluster_name) <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> KOPS_STATE_STORE=$(terraform output state_store) <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> ZONES=$(terraform output -json availability_zones | jq -r <span class="hljs-string"><span class="hljs-string">'.value|join(",")'</span></span>) kops create cluster \ --master-zones <span class="hljs-variable"><span class="hljs-variable">$ZONES</span></span> \ --zones <span class="hljs-variable"><span class="hljs-variable">$ZONES</span></span> \ --topology private \ --dns-zone $(terraform output public_zone_id) \ --networking calico \ --vpc $(terraform output vpc_id) \ --target=terraform \ --out=. \ <span class="hljs-variable"><span class="hljs-variable">${NAME}</span></span></code> </pre><br><blockquote>  Hier ist eine kleine Bemerkung erforderlich.  <b>Terraform</b> erstellt eine <b>VPC</b> , und wir m√ºssen die Konfiguration, die <b>Kops</b> uns geben <b>,</b> leicht <b>anpassen</b> .  Dies geschieht ganz einfach √ºber das <b>Hilfbild von Ryane / Gensubnets: 0.1</b> <br></blockquote><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#   terraform output -json &gt; subnets.json</span></span></code> </pre><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#     echo subnets.json | docker run --rm -i ryane/gensubnets:0.1</span></span></code> </pre><br>  Sie k√∂nnen sofortige Richtlinien f√ºr route53 hinzuf√ºgen. <br><br><pre> <code class="plaintext hljs">additionalPolicies: master: | [ { "Effect": "Allow", "Action": ["route53:ListHostedZonesByName"], "Resource": ["*"] }, { "Effect": "Allow", "Action": ["elasticloadbalancing:DescribeLoadBalancers"], "Resource": ["*"] }, { "Effect": "Allow", "Action": ["route53:ChangeResourceRecordSets"], "Resource": ["*"] } ] node: | [ { "Effect": "Allow", "Action": ["route53:ListHostedZonesByName"], "Resource": ["*"] }, { "Effect": "Allow", "Action": ["elasticloadbalancing:DescribeLoadBalancers"], "Resource": ["*"] }, { "Effect": "Allow", "Action": ["route53:ChangeResourceRecordSets"], "Resource": ["*"] } ]</code> </pre><br>  Bearbeiten √ºber <b>Kops Bearbeiten Sie Cluster $ {NAME}</b> . <br><br><img src="https://habrastorage.org/webt/yw/wg/w4/ywwgw42_afdmr__elg0og_yjruk.png"><br><br>  Jetzt k√∂nnen wir den Cluster selbst anheben. <br><br><pre> <code class="bash hljs">kops update cluster \ --out=. \ --target=terraform \ <span class="hljs-variable"><span class="hljs-variable">${NAME}</span></span> terraform apply</code> </pre><br>  Alles wird gut gehen, der Kontext von <b>kubectl</b> wird sich √§ndern.  Im Ordner <b>data / aws-cluster-init-kops-terraform</b> speichern wir den Clusterstatus.  Sie k√∂nnen einfach alles in <b>git</b> einf√ºgen und an ein privates Bitpack-Repository senden. <br><br><pre> <code class="bash hljs">$ kubectl get nodes NAME STATUS AGE ip-10-20-101-252.ec2.internal Ready,master 7m ip-10-20-103-232.ec2.internal Ready,master 7m ip-10-20-103-75.ec2.internal Ready 5m ip-10-20-104-127.ec2.internal Ready,master 6m ip-10-20-104-6.ec2.internal Ready 5m</code> </pre><br><h2>  2. Erh√∂hen Sie unsere Anwendung </h2><br>  Nachdem wir etwas haben, k√∂nnen wir unsere Dienste in einem Cluster bereitstellen.  Ich werde ungef√§hre Konfigurationen in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dasselbe Repository stellen</a> .  Sie k√∂nnen in <b>data / k8s</b> in ein Paket <b>gestellt werden</b> . <br><br><h4>  Service-Witze </h4><br>  Beginnen wir mit dem Service.  Wir ben√∂tigen <b>Helm</b> , <b>Route53</b> , <b>Speicherklassen</b> und Zugriff auf unsere private <b>Registrierung</b> unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hub.docker.com</a> .  Nun, oder zu jedem anderen, wenn es einen solchen Wunsch gibt. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># Init helm kubectl create serviceaccount --namespace kube-system tiller kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller kubectl patch deploy --namespace kube-system tiller-deploy -p '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}' helm init</span></span></code> </pre><br><pre> <code class="bash hljs">kubectl apply -f default-namespace.yaml kubectl apply -f storage-classes.yaml kubectl apply -f route53.yaml kubectl apply -f docker-hub-secret.yml kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml</code> </pre><br><h4>  PostgreSQL + Redis </h4><br>  Ich habe so oft mit Docker gebrannt, nicht f√ºr <b>zustandslose</b> Container, aber die letzte Konfiguration hat sich bisher als am besten geeignet erwiesen.  Ich benutze <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><b>Stolon</b></a> , um Skalierbarkeit zu gew√§hrleisten.  Etwa ein Jahr ist der Flug normal. <br><br>  Wir setzen Helmkarten und ein paar schnelle <b>Redis-</b> Konfigurationen ein. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#  etcd  stolon cd etcd-chart helm install --name global-etcd . #   stolon cd stolon-chart helm dep build helm install --name global-postgres . #  redis kubectl apply -f redis</span></span></code> </pre><br><h4>  Nginx + php </h4><br>  Der √ºbliche Haufen.  <b>Nginx</b> und <b>PHP-Fpm</b> .  Ich habe die Konfigurationen nicht besonders bereinigt, aber jeder kann sie selbst konfigurieren.  Bevor Sie sich bewerben, m√ºssen Sie das Bild angeben, von dem wir den Code √ºbernehmen m√∂chten, und eine Zertifikatzeile von <b>AWS Certificate Manager</b> hinzuf√ºgen.  PHP selbst - Sie k√∂nnen es aus dem Dockerhab nehmen, aber ich habe mein privates erstellt, indem ich ein paar Bibliotheken hinzugef√ºgt habe. <br><br><pre> <code class="bash hljs">kubectl apply -f nginx kubectl apply -f php</code> </pre><br>  In unserem Bild mit dem Code speichern wir ihn im Ordner <b>/ crm-code</b> .  Wir ersetzen es durch Ihr Bild und es wird ganz richtig funktionieren.  Die Datei lautet <b>nginx / deploy.yml</b> . <br><br><img src="https://habrastorage.org/webt/xy/0k/0a/xy0k0axs4muxujs3b-dyp8ncske.png"><br><br>  Bringen Sie die Domain heraus.  <b>Der Route53-</b> Dienst nimmt es auf, √§ndert / f√ºgt DNS-Eintr√§ge hinzu, und das Zertifikat wird vom <b>AWS Certificate Manager</b> in <b>ELB hochgeladen</b> .  Die Datei lautet <b>nginx / service.yml</b> . <br><br><img src="https://habrastorage.org/webt/aw/nl/ya/awnlyaieynoajtmb_feavw2_qke.png"><br><br>  Leiten Sie env-Variablen in PHP weiter, um sie darin zu haben und eine Verbindung zu <b>PostgreSQL / Redis herzustellen</b> .  Die Datei ist <b>php / deploy.yml</b> . <br><br><img src="https://habrastorage.org/webt/ry/n9/v4/ryn9v42o_jvzafh16vr3m2rcpo4.png"><br><br>  Als Ergebnis haben wir einen <b>K8S-</b> Cluster, den wir auf einer grundlegenden Ebene skalieren, neue Dienste, neue Server (Knoten) hinzuf√ºgen, die Anzahl der <b>PostgreSQL-, PHP- und Nginx-</b> Instanzen √§ndern und leben k√∂nnen, bevor eine separate Person im Team erscheint, die dies tun wird . <br><br>  Als Teil dieser kurzen Notiz werde ich nicht auf Sicherungs- / √úberwachungsprobleme all dieser Dinge eingehen.  In der Anfangsphase reicht <b>localhost</b> aus <b>: 8001 / ui</b> vom <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">K8S Dashboard-</a> Dienst.  Sp√§ter k√∂nnen <b>Prometheus</b> , <b>Grafana</b> , <b>Barman</b> oder √§hnliche L√∂sungen befestigt werden. <br><br>  Wenn <b>Jenkins</b> ein Terminal oder <b>Teamcity verwendet</b> , aktualisiert er den Code in etwa so. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#     -      Teamcity docker build -t GROUP/crm-code:latest . docker push GROUP/crm-code:latest #   (  ) kubectl set image deployment/php-fpm php-fpm=GROUP/php-fpm kubectl rollout status deployment/php-fpm kubectl set image deployment/php-fpm php-fpm=GROUP/php-fpm:latest kubectl set image deployment/nginx nginx=danday74/nginx-lua kubectl rollout status deployment/nginx kubectl set image deployment/nginx nginx=danday74/nginx-lua:latest kubectl rollout status deployment/php-fpm kubectl rollout status deployment/nginx</span></span></code> </pre><br>  Ich w√ºrde mich freuen, wenn es f√ºr jemanden interessant w√§re und doppelt froh, wenn es jemandem hilft.  Vielen Dank f√ºr Ihre Aufmerksamkeit.  Ich f√ºge noch einmal einen Link zum Repository <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">eins</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zwei hinzu</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de423481/">https://habr.com/ru/post/de423481/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de423467/index.html">Russische Entwickler werden einen Katalog zur Produktkompatibilit√§t ver√∂ffentlichen</a></li>
<li><a href="../de423469/index.html">Schnellste Gleitkommazahlen im Wilden Westen</a></li>
<li><a href="../de423475/index.html">Den Alterungscode hacken: eine neue Wissenschaft √ºber das Altern und was es bedeutet, jung zu bleiben</a></li>
<li><a href="../de423477/index.html">Sei ein Sicherheits-Ninja: Begib dich auf den Weg zu den H√∂hen von IB</a></li>
<li><a href="../de423479/index.html">"Zuerst": ob man zum Mars fliegt</a></li>
<li><a href="../de423483/index.html">Finden des richtigen Weges zum Trennen von Website-Inhalten mithilfe von Webpack</a></li>
<li><a href="../de423485/index.html">Faules Laden von Bildern mit IntersectionObserver</a></li>
<li><a href="../de423487/index.html">Node.js ohne node_modules</a></li>
<li><a href="../de423489/index.html">Ich bin Notarzt und m√∂chte √ºber das neue Apple Watch-Elektrokardiogramm sprechen</a></li>
<li><a href="../de423491/index.html">PHP Digest Nr. 139 (3. - 17. September 2018)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
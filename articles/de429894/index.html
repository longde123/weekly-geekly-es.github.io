<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçå üë∞üèø üÜô Verwenden eines Fischauges auf einem Raspberry Pi 3 mit ROS - Teil 2 üåü üè¶ üë©üèø‚Äçüîß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Guten Tag liebe Leser von Habr! Dies ist der zweite Teil der Geschichte √ºber die Verwendung der Fischaugen-Kamera auf dem Raspberry Pi 3. Der erste Te...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Verwenden eines Fischauges auf einem Raspberry Pi 3 mit ROS - Teil 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429894/">  Guten Tag liebe Leser von Habr!  Dies ist der zweite Teil der Geschichte √ºber die Verwendung der Fischaugen-Kamera auf dem Raspberry Pi 3. Der erste Teil ist hier zu finden.  In diesem Artikel werde ich √ºber das Kalibrieren einer Fischaugen-Kamera und das Verwenden der Kamera zum Erkennen von Objekten mithilfe des Pakets find_object_2d sprechen.  Wen k√ºmmert es bitte unter der Katze. <br><a name="habracut"></a><br>
<h2>  Kalibrieren Sie eine Fischaugen-Kamera mit camera_calibration </h2><br>  Hier beschreibe ich das Kalibrierungsverfahren anhand des offiziellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Handbuchs</a> auf dem ros.org-Portal. <br><br>  F√ºr die Kalibrierung ben√∂tigen wir das Kamerakalibrierungspaket.  Wir k√∂nnen es mit apt installieren: <br><br><pre><code class="bash hljs">sudo apt-get install ros-kinetic-camera-calibration</code> </pre> <br>  Wir ben√∂tigen eine Schachbrettvorlage.  Laden Sie die Vorlage aus dem offiziellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Handbuch</a> auf ros.org herunter und drucken Sie sie aus.  Der Einfachheit halber habe ich es auf eine Sperrholzplatte geklebt: <br><br><img src="https://habrastorage.org/webt/cz/qp/g8/czqpg8rutw1ut-h7ogrjqxwnytk.jpeg" alt="Bild"><br><br>  Lassen Sie uns das Kalibrierungsprogramm ausf√ºhren: <br><br><pre> <code class="bash hljs">rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 image:=/usb_cam/image_raw camera:=/usb_cam</code> </pre><br>  Wir werden ein Bild bekommen: <br><br><img src="https://habrastorage.org/webt/_n/t0/ib/_nt0ib2ohbvxtk8lomsx197swke.png" alt="Bild"><br><br>  Bewegen Sie die Vorlage ein wenig und warten Sie, bis die Vorlage im Rahmen ausgew√§hlt ist (farbige Linien mit Punkten erscheinen nicht auf der Vorlage). <br><br><img src="https://habrastorage.org/webt/dm/du/yn/dmduyniktnl1joqutysbtv9ugf8.png" alt="Bild"><br><br><img src="https://habrastorage.org/webt/ir/w3/fq/irw3fq6yv4z-bfzictvsqlht93c.png" alt="Bild"><br><br>  Bewegen Sie die Vorlage etwas weiter zur Seite.  Um die Kalibrierung erfolgreich durchzuf√ºhren, m√ºssen wir eine Reihe von Bewegungen der Schablone vor der Kamera von einer Seite zur anderen ausf√ºhren, damit die Schablone in alle Winkelpositionen im Sichtfeld der Kamera f√§llt (links, rechts, oben und unten).  Rechts neben dem Kamerabildfenster im Programmfenster befindet sich das Registrierungsfeld mit drei Fortschrittsbalken: <br><br><ul><li>  X erfasst die Bewegung des Musters in der linken / rechten Richtung (horizontal) im Sichtfeld der Kamera </li><li>  Y erfasst die Bewegung des Musters in Aufw√§rts- / Abw√§rtsrichtung (horizontal) im Sichtfeld der Kamera </li><li>  Die Gr√∂√üe erfasst die Ann√§herung / Entfernung der Vorlage von der Kamera und die Neigung in Bezug auf die Kamera. </li><li>  Die Neigung korrigiert die Neigung der Schablone nach links, rechts, oben und unten (Abschr√§gung). </li></ul><br>  F√ºr eine erfolgreiche Kalibrierung ist es daher wichtig, dass die Vorlage in verschiedenen Ecken des Rahmens angezeigt wird, den gesamten Rahmen einnimmt und auch nach links, rechts, oben und unten geneigt ist. <br><br>  Das Kalibrieren einer Fischaugen-Kamera auf Ihrem Raspberry Pi kann eine Weile dauern. Seien Sie also geduldig.  Mein Kalibrierungsvorgang dauerte 20 Minuten. <br><br>  Wenn die Kalibrierung abgeschlossen ist, sollte die Schaltfl√§che Kalibrieren aktiviert sein (farblich hervorgehoben): <br><br><img src="https://habrastorage.org/webt/lq/d-/d2/lqd-d26xbjyaishe5noij5oan1k.png" alt="Bild"><br><br>  Wir k√∂nnen die Kalibrierungsergebnisse auch im Terminal sehen: <br><br><img src="https://habrastorage.org/webt/5c/jv/kt/5cjvktr9rxlpwwfq0kfk1kk3b7o.png" alt="Bild"><br><br>  Wenn Sie mit dem Ergebnis zufrieden sind, dr√ºcken Sie die COMMIT-Taste.  Das Programmfenster wird geschlossen und im Terminal wird die Meldung "Schreiben von Kalibrierungsdaten in ..." angezeigt. <br><br>  √úberpr√ºfen Sie, ob die angegebene Datei erstellt wurde: <br><br><pre> <code class="bash hljs">ll ~/.ros/camera_info/head_camera.yaml -rw-rw-r-- 1 vladimir vladimir 592 Apr 14 14:02 /home/vladimir/.ros/camera_info/head_camera.yaml</code> </pre><br>  Kalibrierung abgeschlossen.  Jetzt k√∂nnen die erhaltenen Kalibrierungsdaten in visuellen Lokalisierungs- und SLAM-Algorithmen in ROS verwendet werden. <br><br><h2>  Erkennen von Objekten mit find_object_2d </h2><br>  Die Installation des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pakets ist</a> recht einfach.  Installieren Sie es aus dem apt-Repository in Ubuntu 16.04 f√ºr ROS Kinetic: <br><br><pre> <code class="bash hljs">sudo apt-get install ros-kinetic-find-object-2d <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> /opt/ros/kinetic/setup.bash</code> </pre><br>  F√ºhren Sie ROS master und rqt_image_view aus: <br><br><pre> <code class="bash hljs">roscore roslaunch usb_cam usb_cam-test.launch</code> </pre><br>  Starten Sie den Detektorknoten mit dem folgenden Befehl: <br><br><pre> <code class="bash hljs">rosrun find_object_2d find_object_2d image:=/usb_cam/image_raw</code> </pre><br>  Das Fenster des Erkennungsprogramms wird ge√∂ffnet: <br><br><img src="https://habrastorage.org/webt/6l/_u/kb/6l_ukb-8wjw2cylfuloapxtpdzk.png" alt="Bild"><br><br>  Hier sehen wir den Strom von der Kamera und das Ergebnis der Erkennung charakteristischer Merkmale auf Objekten. <br>  Zun√§chst werden wir in unseren Einrichtungen Detektorschulungen durchf√ºhren.  Stellen Sie das erste Objekt vor die Kamera: <br><br><img src="https://habrastorage.org/webt/2y/hs/nb/2yhsnbkbcr9452owc41wpl_yzxs.png" alt="Bild"><br><br>  Klicken Sie mit der rechten Maustaste auf das linke Feld der Objekte im Fenster, und die Option Objekte aus Szene hinzuf√ºgen wird ge√∂ffnet.  W√§hlen Sie diese Option und das Fenster zum Hinzuf√ºgen eines Objekts wird ge√∂ffnet: <br><br><img src="https://habrastorage.org/webt/r3/ey/56/r3ey56zvh_td0ap_etfqdi-nvem.png" alt="Bild"><br><br>  Nachdem Sie die beste Position f√ºr das Objekt ausgew√§hlt haben, klicken Sie auf die Schaltfl√§che Bild aufnehmen, um ein Bild des Objekts aufzunehmen: <br><br><img src="https://habrastorage.org/webt/ao/h6/qk/aoh6qkj0aktn86zjxmwlyn-stg4.png" alt="Bild"><br><br>  Wir m√ºssen das Objekt im Bild ausw√§hlen.  Verwenden Sie den Mauszeiger, um das Objekt auszuw√§hlen: <br><br><img src="https://habrastorage.org/webt/ar/l-/6c/arl-6c6qqj88nxbrh1sh7w3fhxw.png" alt="Bild"><br><br>  Klicken Sie auf die Schaltfl√§che Weiter, um das Objekt im Bild auszuschneiden und mit dem n√§chsten Schritt fortzufahren.  Nach dem Zuschneiden des Bildes erhalten wir die Gesamtzahl der am Objekt erkannten charakteristischen Merkmale.  Es bleibt nur die Taste Ende zu dr√ºcken, um das Objekt zur Datenbank der trainierten Detektorobjekte hinzuzuf√ºgen.  Hier sehen wir den letzten Schritt der Prozedur zum Hinzuf√ºgen eines Objekts: <br><br><img src="https://habrastorage.org/webt/ma/jh/pa/majhpayey9z1nntt0i4eaegq6jq.png" alt="Bild"><br><br>  Als Ergebnis haben wir den Detektor auf ein Objekt trainiert.  Jetzt k√∂nnen Sie versuchen, das Objekt in der Szene zu erkennen: <br><br><img src="https://habrastorage.org/webt/q6/vb/7u/q6vb7uerpmydbkvpncoz3buc5d8.png" alt="Bild"><br><br>  Zeichnen wir die Position des erkannten Objekts zum Terminal: <br><br><pre> <code class="bash hljs">rosrun find_object_2d print_objects_detected</code> </pre><br>  Die Ausgabe sieht folgenderma√üen aus: <br><br><pre> <code class="bash hljs">Object 1 detected, Qt corners at (259.387238,103.530960) (448.684052,79.495495) (282.419050,240.049667) (458.438938,199.656717) --- Object 1 detected, Qt corners at (255.340408,104.615120) (451.348079,75.302353) (284.672425,230.382223) (452.696585,197.625600) --- Object 1 detected, Qt corners at (253.440521,102.973320) (447.226440,76.793541) (278.530854,238.918013) (454.377219,197.526599) ---</code> </pre><br>  Lassen Sie uns die Themen auflisten: <br><br><pre> <code class="bash hljs">rostopic list</code> </pre><br>  In der Liste wurden zwei neue Themen angezeigt: / Objekte und / ObjekteStempel. <br><br>  Wir zeigen Informationen zu den erkannten Objekten an: <br><br><pre> <code class="bash hljs">rostopic <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> /objects</code> </pre><br><pre> <code class="bash hljs">layout: dim: [] data_offset: 0 data: [1.0, 266.0, 177.0, 0.7527905702590942, 0.060980819165706635, 0.00022385441116057336, 0.3012462854385376, 0.8929792046546936, 0.0008534671505913138, 334.9065856933594, 182.55294799804688, 1.0] ---</code> </pre><br>  Hier repr√§sentieren der zweite und dritte Wert (266.0, 177.0) die Breite und H√∂he des Objekts.  Alle anderen Werte im Datenfeld stellen eine 3x3-Homografiematrix dar (zur Berechnung der Position und Ausrichtung des Objekts sowie der Skalierungs- und Verschiebungswerte). <br><br>  Wie Beobachtungen zeigen, erkennt find_object_2d Objekte mit einer schwachen Textur oder ohne Textur (texturlos) nur schlecht.  Au√üerdem ist der Detektor unwirksam, wenn ein Objekt in einem gro√üen Winkel zum Objekt (wenn wir das Objekt von der Seite betrachten) oder in gro√üer Entfernung vom Objekt erfasst wird. <br><br><img src="https://habrastorage.org/webt/pk/1f/ot/pk1fotpptvtwoym3g6p5g3lfgty.png" alt="Bild"><br><br>  Nach Abschluss der Arbeit mit dem Detektor bietet find_object_2d an, die hinzugef√ºgten Objekte auf der Festplatte zu speichern. <br><br>  Das ist alles f√ºr jetzt.  Viel Gl√ºck an alle und bis bald! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de429894/">https://habr.com/ru/post/de429894/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de429882/index.html">Steuerung von RGB-LEDs √ºber Cypress UDB Microcontroller PSoC</a></li>
<li><a href="../de429884/index.html">PROSTOR 2018 Konferenz: Fragen und Antworten zur Zukunft der Speicherung</a></li>
<li><a href="../de429888/index.html">Stapelbasierter Taschenrechner auf der Cyclone IV FPGA-Karte</a></li>
<li><a href="../de429890/index.html">Offenes Webinar "Generative gegnerische Netzwerke"</a></li>
<li><a href="../de429892/index.html">xonsh - Python als Shell-Ersatz</a></li>
<li><a href="../de429898/index.html">DMS (Dealership Management System) - Implementierung von Information EcoSystems f√ºr das Dealer Network Management</a></li>
<li><a href="../de429902/index.html">Seitenrang im Web 2.0-Zeitalter - Teil 1</a></li>
<li><a href="../de429904/index.html">Lustige und traurige Geschichten √ºber die Entwicklung von Computerspielen</a></li>
<li><a href="../de429908/index.html">Wie man Coroutinen in Lebensmitteln verwendet und nachts ruhig schl√§ft</a></li>
<li><a href="../de429910/index.html">AppsConf steigt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
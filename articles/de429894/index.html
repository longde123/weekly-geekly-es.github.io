<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🍌 👰🏿 🆙 Verwenden eines Fischauges auf einem Raspberry Pi 3 mit ROS - Teil 2 🌟 🏦 👩🏿‍🔧</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Guten Tag liebe Leser von Habr! Dies ist der zweite Teil der Geschichte über die Verwendung der Fischaugen-Kamera auf dem Raspberry Pi 3. Der erste Te...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Verwenden eines Fischauges auf einem Raspberry Pi 3 mit ROS - Teil 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429894/">  Guten Tag liebe Leser von Habr!  Dies ist der zweite Teil der Geschichte über die Verwendung der Fischaugen-Kamera auf dem Raspberry Pi 3. Der erste Teil ist hier zu finden.  In diesem Artikel werde ich über das Kalibrieren einer Fischaugen-Kamera und das Verwenden der Kamera zum Erkennen von Objekten mithilfe des Pakets find_object_2d sprechen.  Wen kümmert es bitte unter der Katze. <br><a name="habracut"></a><br>
<h2>  Kalibrieren Sie eine Fischaugen-Kamera mit camera_calibration </h2><br>  Hier beschreibe ich das Kalibrierungsverfahren anhand des offiziellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Handbuchs</a> auf dem ros.org-Portal. <br><br>  Für die Kalibrierung benötigen wir das Kamerakalibrierungspaket.  Wir können es mit apt installieren: <br><br><pre><code class="bash hljs">sudo apt-get install ros-kinetic-camera-calibration</code> </pre> <br>  Wir benötigen eine Schachbrettvorlage.  Laden Sie die Vorlage aus dem offiziellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Handbuch</a> auf ros.org herunter und drucken Sie sie aus.  Der Einfachheit halber habe ich es auf eine Sperrholzplatte geklebt: <br><br><img src="https://habrastorage.org/webt/cz/qp/g8/czqpg8rutw1ut-h7ogrjqxwnytk.jpeg" alt="Bild"><br><br>  Lassen Sie uns das Kalibrierungsprogramm ausführen: <br><br><pre> <code class="bash hljs">rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 image:=/usb_cam/image_raw camera:=/usb_cam</code> </pre><br>  Wir werden ein Bild bekommen: <br><br><img src="https://habrastorage.org/webt/_n/t0/ib/_nt0ib2ohbvxtk8lomsx197swke.png" alt="Bild"><br><br>  Bewegen Sie die Vorlage ein wenig und warten Sie, bis die Vorlage im Rahmen ausgewählt ist (farbige Linien mit Punkten erscheinen nicht auf der Vorlage). <br><br><img src="https://habrastorage.org/webt/dm/du/yn/dmduyniktnl1joqutysbtv9ugf8.png" alt="Bild"><br><br><img src="https://habrastorage.org/webt/ir/w3/fq/irw3fq6yv4z-bfzictvsqlht93c.png" alt="Bild"><br><br>  Bewegen Sie die Vorlage etwas weiter zur Seite.  Um die Kalibrierung erfolgreich durchzuführen, müssen wir eine Reihe von Bewegungen der Schablone vor der Kamera von einer Seite zur anderen ausführen, damit die Schablone in alle Winkelpositionen im Sichtfeld der Kamera fällt (links, rechts, oben und unten).  Rechts neben dem Kamerabildfenster im Programmfenster befindet sich das Registrierungsfeld mit drei Fortschrittsbalken: <br><br><ul><li>  X erfasst die Bewegung des Musters in der linken / rechten Richtung (horizontal) im Sichtfeld der Kamera </li><li>  Y erfasst die Bewegung des Musters in Aufwärts- / Abwärtsrichtung (horizontal) im Sichtfeld der Kamera </li><li>  Die Größe erfasst die Annäherung / Entfernung der Vorlage von der Kamera und die Neigung in Bezug auf die Kamera. </li><li>  Die Neigung korrigiert die Neigung der Schablone nach links, rechts, oben und unten (Abschrägung). </li></ul><br>  Für eine erfolgreiche Kalibrierung ist es daher wichtig, dass die Vorlage in verschiedenen Ecken des Rahmens angezeigt wird, den gesamten Rahmen einnimmt und auch nach links, rechts, oben und unten geneigt ist. <br><br>  Das Kalibrieren einer Fischaugen-Kamera auf Ihrem Raspberry Pi kann eine Weile dauern. Seien Sie also geduldig.  Mein Kalibrierungsvorgang dauerte 20 Minuten. <br><br>  Wenn die Kalibrierung abgeschlossen ist, sollte die Schaltfläche Kalibrieren aktiviert sein (farblich hervorgehoben): <br><br><img src="https://habrastorage.org/webt/lq/d-/d2/lqd-d26xbjyaishe5noij5oan1k.png" alt="Bild"><br><br>  Wir können die Kalibrierungsergebnisse auch im Terminal sehen: <br><br><img src="https://habrastorage.org/webt/5c/jv/kt/5cjvktr9rxlpwwfq0kfk1kk3b7o.png" alt="Bild"><br><br>  Wenn Sie mit dem Ergebnis zufrieden sind, drücken Sie die COMMIT-Taste.  Das Programmfenster wird geschlossen und im Terminal wird die Meldung "Schreiben von Kalibrierungsdaten in ..." angezeigt. <br><br>  Überprüfen Sie, ob die angegebene Datei erstellt wurde: <br><br><pre> <code class="bash hljs">ll ~/.ros/camera_info/head_camera.yaml -rw-rw-r-- 1 vladimir vladimir 592 Apr 14 14:02 /home/vladimir/.ros/camera_info/head_camera.yaml</code> </pre><br>  Kalibrierung abgeschlossen.  Jetzt können die erhaltenen Kalibrierungsdaten in visuellen Lokalisierungs- und SLAM-Algorithmen in ROS verwendet werden. <br><br><h2>  Erkennen von Objekten mit find_object_2d </h2><br>  Die Installation des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pakets ist</a> recht einfach.  Installieren Sie es aus dem apt-Repository in Ubuntu 16.04 für ROS Kinetic: <br><br><pre> <code class="bash hljs">sudo apt-get install ros-kinetic-find-object-2d <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> /opt/ros/kinetic/setup.bash</code> </pre><br>  Führen Sie ROS master und rqt_image_view aus: <br><br><pre> <code class="bash hljs">roscore roslaunch usb_cam usb_cam-test.launch</code> </pre><br>  Starten Sie den Detektorknoten mit dem folgenden Befehl: <br><br><pre> <code class="bash hljs">rosrun find_object_2d find_object_2d image:=/usb_cam/image_raw</code> </pre><br>  Das Fenster des Erkennungsprogramms wird geöffnet: <br><br><img src="https://habrastorage.org/webt/6l/_u/kb/6l_ukb-8wjw2cylfuloapxtpdzk.png" alt="Bild"><br><br>  Hier sehen wir den Strom von der Kamera und das Ergebnis der Erkennung charakteristischer Merkmale auf Objekten. <br>  Zunächst werden wir in unseren Einrichtungen Detektorschulungen durchführen.  Stellen Sie das erste Objekt vor die Kamera: <br><br><img src="https://habrastorage.org/webt/2y/hs/nb/2yhsnbkbcr9452owc41wpl_yzxs.png" alt="Bild"><br><br>  Klicken Sie mit der rechten Maustaste auf das linke Feld der Objekte im Fenster, und die Option Objekte aus Szene hinzufügen wird geöffnet.  Wählen Sie diese Option und das Fenster zum Hinzufügen eines Objekts wird geöffnet: <br><br><img src="https://habrastorage.org/webt/r3/ey/56/r3ey56zvh_td0ap_etfqdi-nvem.png" alt="Bild"><br><br>  Nachdem Sie die beste Position für das Objekt ausgewählt haben, klicken Sie auf die Schaltfläche Bild aufnehmen, um ein Bild des Objekts aufzunehmen: <br><br><img src="https://habrastorage.org/webt/ao/h6/qk/aoh6qkj0aktn86zjxmwlyn-stg4.png" alt="Bild"><br><br>  Wir müssen das Objekt im Bild auswählen.  Verwenden Sie den Mauszeiger, um das Objekt auszuwählen: <br><br><img src="https://habrastorage.org/webt/ar/l-/6c/arl-6c6qqj88nxbrh1sh7w3fhxw.png" alt="Bild"><br><br>  Klicken Sie auf die Schaltfläche Weiter, um das Objekt im Bild auszuschneiden und mit dem nächsten Schritt fortzufahren.  Nach dem Zuschneiden des Bildes erhalten wir die Gesamtzahl der am Objekt erkannten charakteristischen Merkmale.  Es bleibt nur die Taste Ende zu drücken, um das Objekt zur Datenbank der trainierten Detektorobjekte hinzuzufügen.  Hier sehen wir den letzten Schritt der Prozedur zum Hinzufügen eines Objekts: <br><br><img src="https://habrastorage.org/webt/ma/jh/pa/majhpayey9z1nntt0i4eaegq6jq.png" alt="Bild"><br><br>  Als Ergebnis haben wir den Detektor auf ein Objekt trainiert.  Jetzt können Sie versuchen, das Objekt in der Szene zu erkennen: <br><br><img src="https://habrastorage.org/webt/q6/vb/7u/q6vb7uerpmydbkvpncoz3buc5d8.png" alt="Bild"><br><br>  Zeichnen wir die Position des erkannten Objekts zum Terminal: <br><br><pre> <code class="bash hljs">rosrun find_object_2d print_objects_detected</code> </pre><br>  Die Ausgabe sieht folgendermaßen aus: <br><br><pre> <code class="bash hljs">Object 1 detected, Qt corners at (259.387238,103.530960) (448.684052,79.495495) (282.419050,240.049667) (458.438938,199.656717) --- Object 1 detected, Qt corners at (255.340408,104.615120) (451.348079,75.302353) (284.672425,230.382223) (452.696585,197.625600) --- Object 1 detected, Qt corners at (253.440521,102.973320) (447.226440,76.793541) (278.530854,238.918013) (454.377219,197.526599) ---</code> </pre><br>  Lassen Sie uns die Themen auflisten: <br><br><pre> <code class="bash hljs">rostopic list</code> </pre><br>  In der Liste wurden zwei neue Themen angezeigt: / Objekte und / ObjekteStempel. <br><br>  Wir zeigen Informationen zu den erkannten Objekten an: <br><br><pre> <code class="bash hljs">rostopic <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> /objects</code> </pre><br><pre> <code class="bash hljs">layout: dim: [] data_offset: 0 data: [1.0, 266.0, 177.0, 0.7527905702590942, 0.060980819165706635, 0.00022385441116057336, 0.3012462854385376, 0.8929792046546936, 0.0008534671505913138, 334.9065856933594, 182.55294799804688, 1.0] ---</code> </pre><br>  Hier repräsentieren der zweite und dritte Wert (266.0, 177.0) die Breite und Höhe des Objekts.  Alle anderen Werte im Datenfeld stellen eine 3x3-Homografiematrix dar (zur Berechnung der Position und Ausrichtung des Objekts sowie der Skalierungs- und Verschiebungswerte). <br><br>  Wie Beobachtungen zeigen, erkennt find_object_2d Objekte mit einer schwachen Textur oder ohne Textur (texturlos) nur schlecht.  Außerdem ist der Detektor unwirksam, wenn ein Objekt in einem großen Winkel zum Objekt (wenn wir das Objekt von der Seite betrachten) oder in großer Entfernung vom Objekt erfasst wird. <br><br><img src="https://habrastorage.org/webt/pk/1f/ot/pk1fotpptvtwoym3g6p5g3lfgty.png" alt="Bild"><br><br>  Nach Abschluss der Arbeit mit dem Detektor bietet find_object_2d an, die hinzugefügten Objekte auf der Festplatte zu speichern. <br><br>  Das ist alles für jetzt.  Viel Glück an alle und bis bald! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de429894/">https://habr.com/ru/post/de429894/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de429882/index.html">Steuerung von RGB-LEDs über Cypress UDB Microcontroller PSoC</a></li>
<li><a href="../de429884/index.html">PROSTOR 2018 Konferenz: Fragen und Antworten zur Zukunft der Speicherung</a></li>
<li><a href="../de429888/index.html">Stapelbasierter Taschenrechner auf der Cyclone IV FPGA-Karte</a></li>
<li><a href="../de429890/index.html">Offenes Webinar "Generative gegnerische Netzwerke"</a></li>
<li><a href="../de429892/index.html">xonsh - Python als Shell-Ersatz</a></li>
<li><a href="../de429898/index.html">DMS (Dealership Management System) - Implementierung von Information EcoSystems für das Dealer Network Management</a></li>
<li><a href="../de429902/index.html">Seitenrang im Web 2.0-Zeitalter - Teil 1</a></li>
<li><a href="../de429904/index.html">Lustige und traurige Geschichten über die Entwicklung von Computerspielen</a></li>
<li><a href="../de429908/index.html">Wie man Coroutinen in Lebensmitteln verwendet und nachts ruhig schläft</a></li>
<li><a href="../de429910/index.html">AppsConf steigt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
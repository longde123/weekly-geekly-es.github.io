<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèΩ‚Äçüöí ‚õèÔ∏è ‚úåüèΩ Cassandra zum Speichern von Metadaten: Erfolge und Misserfolge üë©üèª‚ÄçüöÄ ‚Ñ¢Ô∏è ‚≠êÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Welche Anforderungen sollte der Metadatenspeicher f√ºr einen Cloud-Dienst erf√ºllen? Ja, nicht die √ºblichste, aber f√ºr Unternehmen mit Unterst√ºtzung f√ºr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cassandra zum Speichern von Metadaten: Erfolge und Misserfolge</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/417617/"> Welche Anforderungen sollte der Metadatenspeicher f√ºr einen Cloud-Dienst erf√ºllen?  Ja, nicht die √ºblichste, aber f√ºr Unternehmen mit Unterst√ºtzung f√ºr geografisch verteilte Rechenzentren und Active-Active.  Offensichtlich sollte das System gut <strong>skalierbar sein, fehlertolerant sein und in der Lage sein, anpassbare Betriebskonsistenzen zu implementieren.</strong> <br><br>  Nur Cassandra ist f√ºr all diese Anforderungen geeignet, und nichts anderes ist geeignet.  Es sollte beachtet werden, dass Cassandra wirklich cool ist, aber die Arbeit damit √§hnelt einer Achterbahnfahrt. <br><img src="https://habrastorage.org/webt/zs/tw/jb/zstwjb6bvwlg43rmuphw91_jtrm.jpeg"><br><br>  In einem Bericht auf der Highload ++ 2017 entschied <strong>Andrei Smirnov</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">smira</a> ), dass es nicht interessant sei, √ºber Gutes zu sprechen, aber er sprach ausf√ºhrlich √ºber jedes Problem, mit dem er konfrontiert war: √ºber Datenverlust und Korruption, √ºber Zombies und Leistungsverlust.  Diese Geschichten erinnern wirklich an Achterbahn, aber f√ºr alle Probleme gibt es eine L√∂sung, f√ºr die Sie bei cat willkommen sind. <br><br>  <strong><em>√úber den Sprecher:</em></strong> Andrey Smirnov arbeitet f√ºr Virtustream, ein Unternehmen, das Cloud-Speicher f√ºr Unternehmen implementiert.  Die Idee ist, dass Amazon die Cloud unter bestimmten Bedingungen f√ºr alle bereitstellt und Virtustream die spezifischen Dinge erledigt, die ein gro√ües Unternehmen ben√∂tigt. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/SAyClLjN6Sk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br><h1>  Ein paar Worte zu Virtustream </h1><br>  Wir arbeiten in einem v√∂llig entfernten kleinen Team und arbeiten an einer der Virtustream-Cloud-L√∂sungen.  Dies ist eine Wolke der Datenspeicherung. <br><img src="https://habrastorage.org/webt/bo/rc/jh/borcjhczgtiycqzx8dz0bnh9zim.jpeg"><br><br>  Ganz einfach gesagt, dies ist eine S3-kompatible API, in der Sie Objekte speichern k√∂nnen.  F√ºr diejenigen, die nicht wissen, was S3 ist, ist es nur eine HTTP-API, mit der Sie Objekte irgendwo in die Cloud hochladen, zur√ºckholen, l√∂schen, eine Liste von Objekten abrufen usw.  Weiter - komplexere Funktionen basierend auf diesen einfachen Operationen. <br><br>  Wir haben einige Besonderheiten, die Amazon nicht hat.  Eine davon sind die sogenannten Georegionen.  In der √ºblichen Situation m√ºssen Sie eine Region ausw√§hlen, wenn Sie ein Repository erstellen und angeben, dass Sie Objekte in der Cloud speichern.  Eine Region ist im Wesentlichen ein Rechenzentrum, und Ihre Objekte werden dieses Rechenzentrum niemals verlassen.  Wenn ihm etwas passiert, sind Ihre Objekte nicht mehr verf√ºgbar. <br><br>  Wir bieten Georegionen an, in denen sich Daten gleichzeitig in mehreren Rechenzentren (DC) befinden, mindestens in zwei, wie im Bild.  Der Kunde kann jedes Rechenzentrum kontaktieren, f√ºr ihn ist es transparent.  Die Daten zwischen ihnen werden repliziert, dh wir arbeiten im Aktiv-Aktiv-Modus und st√§ndig.  Dies bietet dem Client zus√§tzliche Funktionen, darunter: <br><br><ol><li>  h√∂here Zuverl√§ssigkeit beim Speichern, Lesen und Schreiben bei Gleichstromausfall oder Verbindungsverlust; <br></li><li>  Datenverf√ºgbarkeit auch dann, wenn einer der DCs ausf√§llt; <br></li><li>  Umleiten von Vorg√§ngen zum ‚Äûn√§chsten‚Äú DC. <br></li></ol><br>  Dies ist eine interessante Gelegenheit - selbst wenn diese DCs geografisch weit voneinander entfernt sind, k√∂nnen einige von ihnen zu unterschiedlichen Zeitpunkten n√§her am Kunden sein.  Der Zugriff auf die Daten zum n√§chsten DC ist einfach schneller. <br><img src="https://habrastorage.org/webt/k-/ry/dl/k-rydl_mt74-eybwakpv1dpqjum.jpeg"><br><br>  Um die Konstruktion, √ºber die wir sprechen werden, in Teile zu unterteilen, werde ich die in der Wolke gespeicherten Objekte als zwei gro√üe Teile pr√§sentieren: <br><br>  1. Das erste einfache Teil eines Objekts sind <strong>Daten</strong> .  Sie sind unver√§ndert, wurden einmal heruntergeladen und das ist alles.  Das einzige, was ihnen sp√§ter passieren kann, ist, dass wir sie entfernen k√∂nnen, wenn sie nicht mehr ben√∂tigt werden. <br><br>  Unser vorheriges Projekt bezog sich auf die Speicherung von Exabyte an Daten, sodass wir keine Probleme mit der Datenspeicherung hatten.  Dies war f√ºr uns bereits eine gel√∂ste Aufgabe. <br><br>  2. <strong>Metadaten</strong> .  Alle Gesch√§ftslogiken, alle die interessantesten, bezogen auf den Wettbewerb: Zugriff, Aufzeichnungen, Umschreibungen - im Metadatenbereich. <br><br>  Die Metadaten √ºber das Objekt nehmen die gr√∂√üte Komplexit√§t des Projekts in sich auf, die Metadaten speichern einen Zeiger auf den Block gespeicherter Daten des Objekts. <br><br>  Aus Sicht des Benutzers ist dies ein einzelnes Objekt, aber wir k√∂nnen es in zwei Teile teilen.  Heute werde ich <strong>nur √ºber Metadaten</strong> sprechen. <br><br><h2>  Zahlen <br></h2><br><ul><li>  <strong>Daten</strong> : 4 Pbytes. </li><li>  <strong>Metadatencluster</strong> : 3. </li><li>  <strong>Objekte</strong> : 40 Milliarden. </li><li>  <strong>Metadatengr√∂√üe</strong> : 160 TB (einschlie√ülich Replikation). </li><li>  <strong>√Ñnderungsrate (Metadaten):</strong> 3000 Objekte / s. </li></ul><br>  Wenn Sie sich diese Indikatoren genau ansehen, f√§llt Ihnen als Erstes die sehr geringe durchschnittliche Gr√∂√üe des gespeicherten Objekts auf.  Wir haben viele Metadaten pro Volumeneinheit der Stammdaten.  F√ºr uns war es nicht weniger √ºberraschend als vielleicht f√ºr Sie jetzt. <br><br>  Wir planten, dass wir mindestens eine Datenreihenfolge haben w√ºrden, wenn nicht 2, mehr als Metadaten.  Das hei√üt, jedes Objekt ist erheblich gr√∂√üer und die Anzahl der Metadaten ist geringer.  Weil das Speichern von Daten billiger ist, weniger Vorg√§nge mit ihnen und Metadaten sowohl im Sinne der Hardware als auch im Sinne der Wartung und Durchf√ºhrung verschiedener Vorg√§nge viel teurer sind. <br><br>  Dar√ºber hinaus √§ndern sich diese Daten mit einer ziemlich hohen Geschwindigkeit.  Ich habe hier den Spitzenwert angegeben, der Nicht-Spitzenwert ist nicht viel geringer, aber dennoch kann zu bestimmten Zeitpunkten eine ziemlich gro√üe Last erhalten werden. <br><br>  Diese Zahlen stammen bereits aus einem funktionierenden System, aber lassen Sie uns ein wenig auf die Zeit des Entwurfs des Cloud-Speichers zur√ºckgehen. <br><br><h1>  Ausw√§hlen eines Repositorys f√ºr Metadaten </h1><br>  Als wir uns der Herausforderung stellten, Georegionen, Active-Active, zu haben und Metadaten irgendwo speichern zu m√ºssen, dachten wir, dass dies m√∂glich sein k√∂nnte? <br><br>  Offensichtlich sollte das Repository (Datenbank) die folgenden Eigenschaften haben: <br><br><ul><li>  <strong>Aktiv-Aktiv-Support</strong> ; </li><li>  <strong>Skalierbarkeit.</strong> </li></ul><br>  Wir m√∂chten wirklich, dass unser Produkt sehr beliebt ist, und wir wissen nicht, wie es gleichzeitig wachsen wird. Daher sollte das System skaliert werden. <br><br><ul><li>  <strong>Das Gleichgewicht zwischen Fehlertoleranz und Speicherzuverl√§ssigkeit.</strong> </li></ul><br>  Metadaten m√ºssen sicher gespeichert werden, denn wenn wir sie verlieren und eine Verkn√ºpfung zu den darin enthaltenen Daten besteht, verlieren wir das gesamte Objekt. <br><br><ul><li>  <strong>Anpassbare Konsistenz der Operationen.</strong> </li></ul><br>  Aufgrund der Tatsache, dass wir in mehreren DCs arbeiten und die M√∂glichkeit zulassen, dass die DCs m√∂glicherweise nicht verf√ºgbar sind, sind die DCs au√üerdem weit voneinander entfernt. W√§hrend der meisten API-Vorg√§nge k√∂nnen wir nicht verlangen, dass dieser Vorgang gleichzeitig ausgef√ºhrt wird zwei DCs.  Es wird einfach zu langsam und unm√∂glich sein, wenn der zweite DC nicht verf√ºgbar ist.  Daher sollte ein Teil der Operationen lokal in einem DC arbeiten. <br><br>  Offensichtlich sollte jedoch irgendwann eine Art Konvergenz auftreten, und nach der L√∂sung aller Konflikte sollten die Daten in beiden Rechenzentren sichtbar sein.  Daher muss die Konsistenz der Operationen angepasst werden. <br><br>  Aus meiner Sicht ist Cassandra f√ºr diese Anforderungen geeignet. <br><br><h1>  Cassandra </h1><br>  Ich w√ºrde mich sehr freuen, wenn wir Cassandra nicht verwenden m√ºssten, denn f√ºr uns war es eine Art neue Erfahrung.  Sonst ist nichts geeignet.  Dies scheint mir die traurigste Situation auf dem Markt f√ºr solche Speichersysteme zu sein - keine <strong>Alternative</strong> . <br><br><img src="https://habrastorage.org/webt/ge/l-/xo/gel-xoykdx5yx1-sb36hjinlsas.jpeg"><br><br><h3>  Was ist Cassandra? <br></h3><br>  Dies ist eine verteilte Schl√ºsselwertdatenbank.  Aus der Sicht der Architektur und der darin eingebetteten Ideen scheint mir alles cool zu sein.  Wenn ich das tun w√ºrde, w√ºrde ich das Gleiche tun.  Als wir anfingen, dachten wir dar√ºber nach, unser eigenes Metadatenspeichersystem zu schreiben.  Aber je weiter, desto mehr wurde uns klar, dass wir etwas sehr √Ñhnliches wie Cassandra tun m√ºssen, und die Anstrengungen, die wir daf√ºr aufwenden werden, sind es nicht wert.  F√ºr die gesamte Entwicklung <strong>hatten wir nur anderthalb Monate</strong> .  Es w√§re seltsam, sie damit zu verbringen, Ihre Datenbank zu schreiben. <br><br>  Wenn Cassandra wie eine Torte geschichtet w√§re, w√ºrde ich drei Schichten ausw√§hlen: <br><br>  1. <strong>Lokaler KV-Speicher auf jedem Knoten.</strong> <br>  Dies ist ein Cluster von Knoten, von denen jeder Schl√ºsselwertdaten lokal speichern kann. <br><br>  2. <strong>Sharding von Daten auf Knoten (konsistentes Hashing).</strong> <br>  Cassandra kann Daten auf die Knoten des Clusters verteilen, einschlie√ülich der Replikation, und zwar so, dass der Cluster gr√∂√üer oder kleiner werden kann und die Daten neu verteilt werden. <br><br>  3. Ein <strong>Koordinator zum Umleiten von Anforderungen an andere Knoten.</strong> <br>  Wenn wir √ºber unsere Anwendung auf Daten f√ºr einige Abfragen zugreifen, kann Cassandra unsere Abfrage auf Knoten verteilen, sodass wir die gew√ºnschten Daten und die erforderliche Konsistenzstufe erhalten - wir m√∂chten sie nur als Quorum lesen. oder Quorum mit zwei DCs usw. wollen. <br><img src="https://habrastorage.org/webt/zs/tw/jb/zstwjb6bvwlg43rmuphw91_jtrm.jpeg"><br><br>  F√ºr uns zwei Jahre bei Cassandra - es ist eine Achterbahn oder Achterbahn - was auch immer Sie wollen.  Alles begann tief im Inneren, wir hatten keine Erfahrung mit Cassandra.  Wir hatten Angst.  Wir fingen an und alles war in Ordnung.  Aber dann beginnen st√§ndige St√ºrze und Starts: Das Problem, alles ist schlecht, wir wissen nicht, was wir tun sollen, wir bekommen Fehler, dann l√∂sen wir das Problem usw. <br><br>  Diese Achterbahnen enden im Prinzip nicht bis heute. <br><br><h1>  Gut </h1><br>  Das erste und letzte Kapitel, in dem ich sage, dass Cassandra cool ist.  Es ist wirklich cool, ein gro√üartiges System, aber wenn ich weiterhin sage, wie gut es ist, werden Sie wahrscheinlich nicht interessiert sein.  Deshalb werden wir dem Schlechten mehr Aufmerksamkeit schenken, aber sp√§ter. <br><br>  Cassandra ist wirklich gut. <br><br><ul><li>  Dies ist eines der Systeme, mit denen wir <strong>eine Reaktionszeit in Millisekunden haben k√∂nnen</strong> , <strong>dh</strong> offensichtlich weniger als 10 ms.  Das ist gut f√ºr uns, denn die Reaktionszeit im Allgemeinen ist uns wichtig.  Die Operation mit Metadaten ist f√ºr uns nur ein Teil einer Operation, die sich auf die Speicherung eines Objekts bezieht, unabh√§ngig davon, ob es empfangen oder aufgezeichnet wird. </li><li>  Aus Sicht der Aufzeichnung wird eine <strong>hohe Skalierbarkeit</strong> erreicht.  Sie k√∂nnen in Cassandra mit einer verr√ºckten Geschwindigkeit schreiben, und in einigen Situationen ist dies beispielsweise erforderlich, wenn wir gro√üe Datenmengen zwischen Datens√§tzen verschieben. </li><li>  Cassandra ist wirklich <strong>fehlertolerant</strong> .  Der Ausfall eines Knotens f√ºhrt nicht sofort zu Problemen, obwohl sie fr√ºher oder sp√§ter beginnen werden.  Cassandra erkl√§rt, dass es keinen einzigen Fehlerpunkt gibt, aber tats√§chlich gibt es √ºberall Fehlerpunkte.  Tats√§chlich wei√ü derjenige, der mit der Datenbank gearbeitet hat, dass selbst ein Knotenabsturz normalerweise erst am Morgen auftritt.  Normalerweise muss diese Situation schneller behoben werden. </li><li>  <strong>Einfachheit.</strong>  Im Vergleich zu anderen relationalen Cassandra-Standarddatenbanken ist es jedoch einfacher zu verstehen, was vor sich geht.  Sehr oft geht etwas schief und wir m√ºssen verstehen, was passiert.  Cassandra hat mehr Chancen, es herauszufinden und wahrscheinlich zur kleinsten Schraube zu gelangen, als mit einer anderen Datenbank. </li></ul><br><h1>  F√ºnf schlechte Geschichten </h1><br>  Ich wiederhole, Cassandra ist gut, es funktioniert f√ºr uns, aber ich werde f√ºnf Geschichten √ºber das Schlechte erz√§hlen.  Ich denke, daf√ºr hast du es gelesen.  Ich werde die Geschichten in chronologischer Reihenfolge geben, obwohl sie nicht sehr miteinander verbunden sind. <br><img src="https://habrastorage.org/webt/ao/15/oa/ao15oaiwdhwvl4w4u5pvcgwolrq.jpeg"><br><br>  Diese Geschichte war die traurigste f√ºr uns.  Da wir Benutzerdaten speichern, ist es das Schlimmste, sie zu verlieren und <strong>sie f√ºr immer</strong> zu verlieren, wie es in dieser Situation geschehen ist.  Wir haben M√∂glichkeiten bereitgestellt, Daten wiederherzustellen, wenn wir sie in Cassandra verlieren, aber wir haben sie verloren, so dass wir sie wirklich nicht wiederherstellen konnten. <br><br>  Um zu erkl√§ren, wie dies geschieht, muss ich ein wenig dar√ºber sprechen, wie alles in uns angeordnet ist. <br><img src="https://habrastorage.org/webt/6i/vf/gk/6ivfgkdspndo3kzyy153iveq4xq.jpeg"><br><br>  Aus S3-Sicht gibt es einige grundlegende Dinge: <br><br><ul><li>  Bucket - Es kann sich ein riesiger Katalog vorstellen, in den der Benutzer ein Objekt hochl√§dt (im Folgenden als Bucket bezeichnet). </li><li>  Jedem Objekt sind ein Name (Schl√ºssel) und Metadaten zugeordnet: Gr√∂√üe, Inhaltstyp und ein Zeiger auf die Daten des Objekts.  Gleichzeitig ist die Gr√∂√üe des Eimers durch nichts begrenzt.  Das hei√üt, es k√∂nnen 10 Schl√ºssel sein, vielleicht 100 Milliarden Schl√ºssel - es gibt keinen Unterschied. </li><li>  Jeder wettbewerbsf√§hige Vorgang ist m√∂glich, dh es k√∂nnen mehrere wettbewerbsf√§hige F√ºllungen im selben Schl√ºssel vorhanden sein, es kann zu einer L√∂schung des Wettbewerbs usw. kommen. </li></ul><br>  In unserer Situation k√∂nnen Aktiv-Aktiv-Operationen stattfinden, auch wettbewerbsf√§hig in verschiedenen DCs, nicht nur in einem.  Daher brauchen wir eine Art Erhaltungsschema, mit dem wir eine solche Logik implementieren k√∂nnen.  Am Ende haben wir eine einfache Richtlinie gew√§hlt: Die zuletzt aufgezeichnete Version gewinnt.  Manchmal finden mehrere Wettbewerbsvorg√§nge statt, aber es ist nicht erforderlich, dass unsere Kunden dies absichtlich tun.  Es kann nur eine Anfrage sein, die gestartet wurde, aber der Client hat nicht auf eine Antwort gewartet, etwas anderes ist passiert, hat es erneut versucht usw. <br><br>  Daher haben wir zwei Basistabellen: <br><br><ol><li>  <strong>Objekttabelle</strong> .  Darin ist ein Paar - der Name des Buckets und der Name des Schl√ºssels - seiner aktuellen Version zugeordnet.  Wenn das Objekt gel√∂scht wird, ist in dieser Version nichts enthalten.  Wenn das Objekt vorhanden ist, gibt es seine aktuelle Version.  Tats√§chlich √§ndern wir in dieser Tabelle nur das Feld der aktuellen Version. <br></li><li>  <strong>Versionstabelle der Objekte</strong> .  Wir f√ºgen nur neue Versionen in diese Tabelle ein.  Jedes Mal, wenn ein neues Objekt heruntergeladen wird, f√ºgen wir eine neue Version in die Versionstabelle ein, geben ihr eine eindeutige Nummer, speichern alle Informationen dazu und aktualisieren am Ende den Link dazu in der Objekttabelle. <br></li></ol><br>  Die Abbildung zeigt ein Beispiel f√ºr die Beziehung zwischen Objekttabellen und Versionen von Objekten. <br><img src="https://habrastorage.org/webt/rv/jm/3y/rvjm3y1ohf-9yiehp1ajlm4zjik.jpeg"><br><br>  Hier ist ein Objekt mit zwei Versionen - eine aktuelle und eine alte, es gibt ein Objekt, das bereits gel√∂scht wurde, und seine Version ist noch vorhanden.  Wir m√ºssen von Zeit zu Zeit unn√∂tige Versionen bereinigen, dh etwas l√∂schen, auf das sich sonst niemand bezieht.  Dar√ºber hinaus m√ºssen wir es nicht sofort l√∂schen, wir k√∂nnen es im verz√∂gerten Modus tun.  Dies ist unsere interne Reinigung, wir l√∂schen nur das, was nicht mehr ben√∂tigt wird. <br><br>  Es gab ein Problem. <br><img src="https://habrastorage.org/webt/md/rc/xy/mdrcxyc9ojwdjuwchg7gsgkspio.jpeg"><br><br>  Das Problem war folgendes: Wir haben Aktiv-Aktiv, zwei DCs.  In jedem DC werden Metadaten in drei Kopien gespeichert, dh wir haben 3 + 3 - nur 6 Replikate.  Wenn Kunden uns kontaktieren, f√ºhren wir Operationen mit Konsistenz durch (aus Sicht von Cassandra hei√üt es LOCAL_QUORUM).  Das hei√üt, es wird garantiert, dass der Datensatz (oder das Lesen) in 2 Replikaten im lokalen DC aufgetreten ist.  Dies ist eine Garantie - andernfalls schl√§gt der Vorgang fehl. <br><br>  Cassandra wird immer versuchen, in allen 6 Zeilen zu schreiben - 99% der Zeit wird alles in Ordnung sein.  Tats√§chlich sind alle 6 Repliken gleich, aber uns garantiert 2. <br><br>  Wir hatten eine schwierige Situation, obwohl es nicht einmal eine Georegion war.  Selbst f√ºr normale Regionen in einem Dom√§nencontroller haben wir die zweite Kopie der Metadaten in einem anderen Dom√§nencontroller gespeichert.  Dies ist eine lange Geschichte, ich werde nicht alle Details geben.  Aber am Ende hatten wir einen Bereinigungsprozess, bei dem unn√∂tige Versionen entfernt wurden. <br><br>  Und dann trat das gleiche Problem auf.  Der Reinigungsprozess funktionierte auch mit der Konsistenz des lokalen Quorums in einem Rechenzentrum, da es keinen Sinn macht, es in zwei Rechenzentren auszuf√ºhren - sie werden sich gegenseitig bek√§mpfen. <br><br>  Alles war in Ordnung, bis sich herausstellte, dass unsere Benutzer manchmal noch in ein anderes Rechenzentrum schreiben, was wir nicht vermuteten.  Alles wurde nur f√ºr den Fall des Feylovers eingerichtet, aber es stellte sich heraus, dass sie es bereits benutzten. <br><img src="https://habrastorage.org/webt/sa/cs/6q/sacs6qjj7og_ay7jbmkhfkjh9ei.jpeg"><br><br>  Meistens war alles in Ordnung, bis eines Tages eine Situation eintrat, in der ein Datensatz in der Versionstabelle in beiden Dom√§nencontrollern repliziert wurde, der Datensatz in der Objekttabelle sich jedoch als nur in einem Dom√§nencontroller befand, jedoch nicht in den zweiten √ºberging.  Dementsprechend stellte das Reinigungsverfahren, das im ersten (oberen) DC gestartet wurde, fest, dass es eine Version gab, auf die sich niemand bezog, und l√∂schte sie.  Und ich habe nicht nur die Version gel√∂scht, sondern nat√ºrlich auch die Daten - alles ist komplett, weil es nur ein unn√∂tiges Objekt ist.  Und diese Entfernung ist unwiderruflich. <br><br>  Nat√ºrlich gibt es einen weiteren ‚ÄûBoom‚Äú, da wir immer noch einen Datensatz in der Objekttabelle haben, der sich auf eine Version bezieht, die nicht mehr existiert. <br><br>  Das erste Mal haben wir Daten verloren, und wir haben sie wirklich unwiderruflich verloren - gut, ein bisschen. <br><br><h3>  L√∂sung </h3><br>  Was zu tun ist?  In unserer Situation ist alles einfach. <br><br>  Da wir Daten in zwei Rechenzentren gespeichert haben, ist der Reinigungsprozess ein Prozess der Konvergenz und Synchronisation.  Wir m√ºssen Daten von beiden DCs lesen.  Dieser Vorgang funktioniert nur, wenn beide DCs verf√ºgbar sind.  Da ich sagte, dass dies ein verz√∂gerter Prozess ist, der w√§hrend der Verarbeitung der API nicht auftritt, ist dies nicht be√§ngstigend. <br><br>  <strong>Konsistenz ALL</strong> ist ein Merkmal von Cassandra 2. In Cassandra 3 ist alles etwas besser - es gibt eine Konsistenzstufe, die in jedem DC als Quorum bezeichnet wird.  Aber auf jeden Fall gibt es das Problem, dass es <strong>langsam ist</strong> , weil wir uns zuerst an den Remote-DC wenden m√ºssen.  Zweitens bedeutet dies im Fall der Konsistenz aller 6 Knoten, dass es mit der Geschwindigkeit des schlechtesten dieser 6 Knoten arbeitet. <br><br>  Gleichzeitig findet jedoch der sogenannte <strong>Read-Repair-</strong> Prozess statt, wenn nicht alle Replikate synchron sind.  Das hei√üt, wenn die Aufzeichnung irgendwo fehlgeschlagen ist, werden sie durch diesen Vorgang gleichzeitig repariert.  So funktioniert Cassandra. <br><br>  In diesem Fall erhielten wir vom Kunden eine Beschwerde, dass das Objekt nicht verf√ºgbar war.  Wir haben es herausgefunden, verstanden warum und als erstes wollten wir herausfinden, wie viele solcher Objekte wir noch haben.  Wir haben ein Skript ausgef√ºhrt, das versucht hat, ein √§hnliches Konstrukt zu finden, wenn in einer Tabelle ein Eintrag vorhanden war, in einer anderen jedoch kein Eintrag. <br><br>  Pl√∂tzlich stellten wir fest, dass wir <strong>10% dieser Aufzeichnungen haben</strong> .  Wahrscheinlich h√§tte nichts Schlimmeres passieren k√∂nnen, wenn wir nicht geahnt h√§tten, dass dies nicht der Fall ist.  Das Problem war anders. <br><br><img src="https://habrastorage.org/webt/kc/jt/_d/kcjt_dh03wmb-6szvtrgxqz-hme.jpeg"><br><br>  Zombies haben sich in unsere Datenbank eingeschlichen.  Dies ist der halboffizielle Name f√ºr dieses Problem.  Um zu verstehen, was es ist, m√ºssen Sie dar√ºber sprechen, wie das Entfernen in Cassandra funktioniert. <br><img src="https://habrastorage.org/webt/k2/sd/2j/k2sd2jvngn9ouhiv6b3yre0s8vs.jpeg"><br><br>  Zum Beispiel haben wir einige Daten <strong><em>x</em></strong> , die aufgezeichnet und perfekt auf alle 6 Replikate repliziert werden.  Wenn wir es l√∂schen m√∂chten, wird das Entfernen wie bei jeder Operation in Cassandra m√∂glicherweise nicht auf allen Knoten durchgef√ºhrt. <br><br>  Zum Beispiel wollten wir die Konsistenz von 2 von 3 in einem DC gew√§hrleisten.  Lassen Sie den L√∂schvorgang auf f√ºnf Knoten ausgef√ºhrt werden, bleiben Sie jedoch in einem Datensatz, z. B. weil der Knoten zu diesem Zeitpunkt nicht verf√ºgbar war. <br><img src="https://habrastorage.org/webt/lu/d5/ot/lud5otv1dguftzwinkrb2wpeaaq.jpeg"><br><br>  Wenn wir dies l√∂schen und dann versuchen, "Ich m√∂chte 2 von 3" mit derselben Konsistenz zu lesen, interpretiert Cassandra den Wert und seine Abwesenheit als das Vorhandensein von Daten.  Das hei√üt, wenn sie zur√ºckliest, wird sie sagen: "Oh, es gibt Daten!", Obwohl wir sie gel√∂scht haben.  Daher k√∂nnen Sie auf diese Weise nicht l√∂schen. <br><img src="https://habrastorage.org/webt/m6/li/ol/m6liolpvsglhmd_9wjg1gvkascw.jpeg"><br><br>  Cassandra entfernt anders.  <strong>Das L√∂schen ist eigentlich ein Datensatz</strong> .  Wenn wir Daten l√∂schen, schreibt Cassandra einen kleinen Marker namens <strong>Tombstone</strong> (Tombstone).  Es markiert, dass die Daten gel√∂scht werden.  Wenn wir also das L√∂schtoken und die Daten gleichzeitig lesen, bevorzugt Cassandra in dieser Situation immer das L√∂schtoken und sagt, dass tats√§chlich keine Daten vorhanden sind.  Das brauchen Sie. <br><br>  <strong>Tombstone ‚Äî   </strong> , , ,      , -     ,     .   Tombstone     .   <strong>Tombstone   gc_grace_period </strong> .   ,   ,   . <br><br>   ? <br><br><h2> Repair <br></h2><br>  Cassandra  ,   Repair ().   ‚Äî  ,     .       ,  ,      ,     , / ,  , -  - ,    ..     . Repair  ,    . <br><img src="https://habrastorage.org/webt/hj/td/x0/hjtdx0thzgak5uhzjd_ejn09s1m.jpeg"><br><br>   , -   , -   .  Repair    ,    ,    .  - ,     ‚Äî     .     ,    . <br><img src="https://habrastorage.org/webt/qe/ee/kj/qeeekjf-dzxokqp6c4zi1aylljm.jpeg"><br><br>     Repair,       ,  ,      ,    ‚Äî ,   .   6     .     ‚Äî ,   ,     . <br><img src="https://habrastorage.org/webt/c7/qo/o2/c7qoo2bykcraic_gbj8fxbxrmoo.jpeg"><br><br>     ,      ‚Äî ,  -  .      ,    .        ,  - ,    ,       ,    . <br><br><h3>  L√∂sung <br></h3><br>   ,   : <br><br><ul><li> <strong>Repair       </strong> . </li></ul><br>    ,      repair.    ,          ,       . <br><br><ul><li> <strong>    ,    Tombstones,   ,   repair.</strong> </li></ul><br>  repair ‚Äî   ,     repair. ,  ,          10-20 , , 3 .    Tombstone     ,     .      ,  ,      -. <br><img src="https://habrastorage.org/webt/18/yp/cc/18ypccovl1xcoxairec6nf3ssx0.jpeg"><br><br>      Cassandra,     .       . <br><br>  S3  .   ,      ‚Äî 10 , 100  .   API,     ‚Äî      .     , ,  , ,   ,         .  ,    ,  ,    ‚Äî     ,    .      . <br><br>    API? <br><img src="https://habrastorage.org/webt/1l/tl/hd/1ltlhdhdtgnwgxezzz8jsnavvky.jpeg"><br><br>   ,     ‚Äî , ,   ‚Äî    ,    ,    .    .              ‚Äî .   ,     ,   .   ,   ,      Cassandra.    ,         ‚Äî  ,  ,    ,      . <br><br>        ,          ,      ,  ,  .          ,      . ,   ,             . ,   - ,           . <br><br> Cassandra ,       .           ,       ,  ,   ,       ,     . <br><img src="https://habrastorage.org/webt/fk/os/a3/fkosa3zozy2gk_dzpgjvxdwm4k8.jpeg"><br><br>    ,   Cassandra  <strong>composite key</strong> .       ,    ‚Äî    ,   - ,      ‚Äî  .    ,   .   ? ,   ,    ! <br><br>      ,    ,  , ,      ‚Äî  ,          . <br><br>     .  Cassandra   ,   <strong>  Cassandra      </strong> .  ,     ,    Cassandra,        :  ,  ,   SQL  ..    ! <br><img src="https://habrastorage.org/webt/8o/_s/ka/8o_ska-swgmzixxiztlblopuze0.jpeg"><br><br>      .     Cassandra  ?    ,     ,   API.  ,   ,     ,   ,     (     )   . <strong>   ,   </strong>   . <br><br>    ,           .        ,   , ,    .   ,     ‚Äî   ‚Äî       . , ,  ,          . <br><br>   Cassandra   ,       .    : ¬´  100 ¬ª,    ,    ,  ,      ,        ,   100,    . <br><br> ,         (   ),    ‚Äî          ,    ,         .         ,   ,   ,   ,     ,   - .     100 ,   - ,     ,  .      ,         SQL    . <br><br> Cassandra       ,     ,     Java,    .  ,  <strong>Large Partition</strong> ,  .    ‚Äî , , ,  ,     ‚Äî  .         ,   , garbage collection    ..     . <br><br>   ,   ,  <strong>    ,   </strong> ,        . <br><br> ,        ,   -  . <br><img src="https://habrastorage.org/webt/qg/o9/oo/qgo9ooa3pgv_zqkv8iyby4ppq9g.jpeg"><br><br>   ,     ,           .      .     ,      Large Partition. <br><br>     : <br><br><ol><li>        ( ,  - ); <br></li><li>   ,    ,       .     ,     . <br></li></ol><br>   ,     ,   ,     key_hash   0.   , <strong>    ,         </strong> .       ,    .       ,      ,      . <br><br>  ,     . <br><img src="https://habrastorage.org/webt/zr/aw/xn/zrawxn-n6hr1huoqkenbqcgpeoo.jpeg"><br><br>    ‚Äî ,    ,    ,      - -      . <br><br>   ‚Äî      ,   N ?    ,  Large Partition,   ‚Äî     .  ,        .   :   .  ,    ,  ,    ,       -  .    ,           .    , ,     . <br><img src="https://habrastorage.org/webt/og/um/4y/ogum4yxqpvbvrdadna7r8adomwm.jpeg"><br><br>     ‚Äî   ,    ,   -  .    -  ,       ,       .    ,    ,    .   ,    ,        .. <br><br>         ‚Äî  ,    ?    ,   .    ? -     md5- ‚Äî      ,   -  30  ‚Äî     ,  - .    .     ,     ,   . <br><img src="https://habrastorage.org/webt/yp/ik/vy/ypikvyolprsxdju5hawmlm6_epq.jpeg"><br><br>      ,    , , ,   .       ‚Äî   ,    .    ,       .   ,    -  -   - ,  -  - ‚Äî  .     ,     .      . <br><br><h2>   </h2><br>    ,    ,     ,    . <br><br><ul><li>   . </li><li>         . </li><li>     Cassandra. </li><li> Online- (     ). </li></ul><br>  Wir haben jetzt einen Zustand des Eimers, der irgendwie in Partitionen unterteilt ist.  Dann verstehen wir, dass einige Partitionen zu gro√ü oder zu klein sind.  Wir m√ºssen eine neue Partition finden, die einerseits optimal ist, dh die Gr√∂√üe jeder Partition liegt unter einigen unserer Grenzen und ist mehr oder weniger einheitlich.  In diesem Fall sollte der √úbergang vom aktuellen in einen neuen Zustand eine Mindestanzahl von Aktionen erfordern.  Es ist klar, dass f√ºr jeden √úbergang Schl√ºssel zwischen Partitionen verschoben werden m√ºssen. Je weniger wir sie verschieben, desto besser. <br><br>  Wir haben es geschafft.  Wahrscheinlich ist der Teil, der sich mit der Auswahl der Verteilung befasst, der schwierigste Teil des gesamten Dienstes, wenn wir √ºber die Arbeit mit Metadaten im Allgemeinen sprechen.  Wir haben es umgeschrieben, √ºberarbeitet und tun es immer noch, weil immer einige Clients oder bestimmte Muster zum Erstellen von Schl√ºsseln gefunden werden, die eine Schwachstelle dieses Schemas treffen. <br><br>  Zum Beispiel haben wir angenommen, dass der Eimer mehr oder weniger gleichm√§√üig wachsen w√ºrde.  Das hei√üt, wir haben eine Art Distribution aufgenommen und gehofft, dass alle Partitionen entsprechend dieser Distribution wachsen w√ºrden.  Aber wir haben einen Kunden gefunden, der am Ende immer schreibt, in dem Sinne, dass seine Schl√ºssel immer in sortierter Reihenfolge sind.  Die ganze Zeit schl√§gt er in der allerletzten Partition, die so schnell w√§chst, dass es in einer Minute 100.000 Tasten sein k√∂nnen.  Und 100.000 ist ungef√§hr der Wert, der in eine Partition passt. <br><br>  Wir h√§tten einfach keine Zeit, eine solche Hinzuf√ºgung von Schl√ºsseln mit unserem Algorithmus zu verarbeiten, und wir mussten eine spezielle vorl√§ufige Verteilung f√ºr diesen Client einf√ºhren.  Da wir wissen, wie seine Schl√ºssel aussehen, beginnen wir, wenn wir sehen, dass er es ist, am Ende im Voraus leere Partitionen zu erstellen, damit er dort ruhig schreiben kann, und wir w√ºrden uns vorerst bis zur n√§chsten Iteration etwas ausruhen, wenn wir es erneut m√ºssen alles neu verteilen. <br><br>  All dies geschieht online in dem Sinne, dass wir den Betrieb nicht stoppen.  Es kann Lese- und Schreibvorg√§nge geben. Sie k√∂nnen jederzeit eine Liste von Schl√ºsseln anfordern.  Es wird immer konsistent sein, auch wenn wir gerade dabei sind, die Partitionierung vorzunehmen. <br><br>  Es ist ziemlich interessant und es stellt sich mit Cassandra heraus.  Hier k√∂nnen Sie mit Tricks spielen, die damit zusammenh√§ngen, dass Cassandra Konflikte l√∂sen kann.  Wenn wir zwei verschiedene Werte in dieselbe Zeile geschrieben haben, gewinnt der Wert mit einem gr√∂√üeren Zeitstempel. <br><br>  Normalerweise ist der Zeitstempel der aktuelle Zeitstempel, er kann jedoch manuell √ºbergeben werden.  Zum Beispiel m√∂chten wir einen Wert in eine Zeichenfolge schreiben, der auf jeden Fall gerieben werden sollte, wenn der Client selbst etwas schreibt.  Das hei√üt, wir kopieren einige Daten, aber wir m√∂chten, dass der Client, wenn er pl√∂tzlich gleichzeitig mit uns schreibt, diese √ºberschreiben kann.  Dann k√∂nnen wir unsere Daten einfach mit einem Zeitstempel aus der Vergangenheit kopieren.  Dann wird jede aktuelle Aufnahme absichtlich ausgefranst, unabh√§ngig von der Reihenfolge, in der die Aufnahme gemacht wurde. <br><br>  Mit solchen Tricks k√∂nnen Sie dies online tun. <br><br><h2>  L√∂sung </h2><br><ul><li>  Lassen Sie niemals <strong>das Erscheinen einer gro√üen Trennwand zu</strong> . </li><li>  <strong>Brechen Sie die Daten</strong> je nach Aufgabe <strong>nach Prim√§rschl√ºssel</strong> auf. </li></ul><br>  Wenn im Datenschema etwas √Ñhnliches wie eine gro√üe Partition geplant ist, sollten Sie sofort versuchen, etwas dagegen zu unternehmen - finden Sie heraus, wie Sie es brechen und wie Sie davon wegkommen.  Fr√ºher oder sp√§ter tritt dies auf, weil jeder invertierte Index fr√ºher oder sp√§ter in fast jeder Aufgabe entsteht.  Ich habe Ihnen bereits von einer solchen Geschichte erz√§hlt - wir haben einen Bucket-Schl√ºssel im Objekt, und wir m√ºssen eine Liste der Schl√ºssel aus dem Bucket abrufen - tats√§chlich ist dies ein Index. <br><br>  Dar√ºber hinaus kann die Partition nicht nur aus den Daten, sondern auch aus Tombstones (L√∂schmarkierungen) gro√ü sein.  Aus Sicht der Cassandra-Interna (wir sehen sie nie von au√üen) sind L√∂schmarkierungen auch Daten, und eine Partition kann gro√ü sein, wenn viele Dinge darin gel√∂scht werden, da das L√∂schen ein Datensatz ist.  Das sollten Sie auch nicht vergessen. <br><img src="https://habrastorage.org/webt/-s/tw/la/-stwlarb11mcy5nlqaqrpxfc-ky.jpeg"><br><br>  Eine andere Geschichte, die tats√§chlich konstant ist, ist, dass von Anfang bis Ende etwas schief geht.  Sie sehen beispielsweise, dass sich die Antwortzeit von Cassandra erh√∂ht hat und langsam reagiert.  Wie kann man das Problem verstehen und verstehen?  Es gibt nie ein externes Signal, dass das Problem vorliegt. <br><img src="https://habrastorage.org/webt/c0/lr/5r/c0lr5rwf9w5zi-nx1ddd5k5blgk.jpeg"><br><br>  Zum Beispiel gebe ich ein Diagramm - dies ist die durchschnittliche Antwortzeit des gesamten Clusters.  Es zeigt, dass wir ein Problem haben - die maximale Antwortzeit betr√§gt 12 Sekunden - dies ist das interne Timeout von Cassandra.  Dies bedeutet, dass sie sich eine Auszeit nehmen wird.  Wenn das Zeitlimit √ºber 12 s liegt, bedeutet dies h√∂chstwahrscheinlich, dass der Garbage Collector funktioniert und Cassandra nicht einmal Zeit hat, zum richtigen Zeitpunkt zu reagieren.  Sie antwortet sich per Timeout, aber die Antwortzeit auf die meisten Anfragen sollte, wie gesagt, im Durchschnitt innerhalb von 10 ms liegen. <br><br>  In der Grafik hat der Durchschnitt bereits Hunderte von Millisekunden √ºberschritten - etwas ist schiefgegangen.  Aber wenn man dieses Bild betrachtet, ist es unm√∂glich zu verstehen, was der Grund ist. <br><br><img src="https://habrastorage.org/webt/e6/t6/qk/e6t6qkz3yw6k80sjw7smsycclrc.jpeg"><br><br>  Wenn Sie jedoch die gleichen Statistiken f√ºr Cassandra-Knoten erweitern, k√∂nnen Sie sehen, dass im Prinzip alle Knoten mehr oder weniger nichts sind, aber die Antwortzeit f√ºr einen Knoten unterscheidet sich um Gr√∂√üenordnungen.  H√∂chstwahrscheinlich gibt es ein Problem mit ihm. <br><br>  Statistiken √ºber Knoten ver√§ndern das Bild vollst√§ndig.  Diese Statistiken stammen von der Anwendungsseite.  Aber hier ist es tats√§chlich sehr oft schwierig zu verstehen, wo das Problem liegt.  Wenn eine Anwendung auf Cassandra zugreift, greift sie auf einen Knoten zu und verwendet ihn als Koordinator.  Das hei√üt, die Anwendung gibt eine Anforderung aus und der Koordinator leitet sie mit den Daten an die Replikate weiter.  Diese antworten bereits und der Koordinator bildet die endg√ºltige Antwort zur√ºck. <br><br>  Aber warum reagiert der Koordinator langsam?  Vielleicht liegt das Problem bei ihm als solchem, das hei√üt, er verlangsamt sich und antwortet langsam?  Oder verlangsamt er sich vielleicht, weil die Repliken langsam auf ihn reagieren?  Wenn die Replikate langsam reagieren, sieht es aus Sicht der Anwendung wie eine langsame Antwort des Koordinators aus, obwohl dies nichts damit zu tun hat. <br><br>  Hier ist eine gl√ºckliche Situation - es ist klar, dass nur ein Knoten langsam reagiert und das Problem h√∂chstwahrscheinlich darin liegt. <br><br><h3>  Komplexit√§t der Interpretation </h3><br><br><ul><li>  Antwortzeit des Koordinators (Knoten vs. Replikat selbst). </li><li>  Eine bestimmte Tabelle oder der gesamte Knoten? </li><li>  GC Pause?  Unzureichender Thread-Pool? </li><li>  Zu viele nicht verdichtete SSTables? </li></ul><br>  Es ist immer schwer zu verstehen, was falsch ist.  Es <strong>braucht</strong> nur <strong>eine Menge Statistiken und √úberwachung</strong> , sowohl von der Anwendungsseite als auch von Cassandra selbst, denn wenn es wirklich schlecht ist, ist von Cassandra nichts sichtbar.  Sie k√∂nnen die Ebene einzelner Abfragen, die Ebene jeder bestimmten Tabelle und jeden bestimmten Knoten anzeigen. <br><br>  Es kann zum Beispiel eine Situation geben, in der eine Tabelle der in Cassandra SSTables (separate Dateien) genannten Dateien zu viel enth√§lt.  Zum Lesen muss Cassandra grob gesagt alle SSTables sortieren.  Wenn es zu viele von ihnen gibt, dauert der Vorgang dieser Sortierung einfach zu lange, und das Lesen beginnt zu sinken. <br><br>  Die L√∂sung ist die Komprimierung, die die Anzahl dieser SSTables verringert. Es sollte jedoch beachtet werden, dass sie sich nur auf einem Knoten f√ºr eine bestimmte Tabelle befinden kann.  Da Cassandra leider in Java geschrieben ist und auf der JVM ausgef√ºhrt wird, ist der Garbage Collector m√∂glicherweise in eine solche Pause geraten, dass er einfach keine Zeit hat, zu antworten.  Wenn der Garbage Collector angehalten wird, verlangsamen sich nicht nur Ihre Anforderungen, sondern auch die <strong>Interaktion innerhalb des Cassandra-Clusters zwischen Knoten</strong> .  Die Knoten voneinander werden als untergegangen, dh gefallen, tot betrachtet. <br><br>  Eine noch unterhaltsamere Situation beginnt, denn wenn ein Knoten ber√ºcksichtigt, dass ein anderer Knoten ausgefallen ist, sendet er erstens keine Anforderungen an ihn und zweitens versucht er, die Daten zu speichern, die er zum Replizieren auf einen anderen Knoten ben√∂tigen w√ºrde sich vor Ort, so dass er beginnt, sich langsam zu t√∂ten, etc. <br><br>  Es gibt Situationen, in denen dieses Problem einfach mit den richtigen Einstellungen gel√∂st werden kann.  Zum Beispiel kann es gen√ºgend Ressourcen geben, alles ist in Ordnung und wunderbar, aber nur ein Thread-Pool, dessen Anzahl eine feste Gr√∂√üe hat, muss erh√∂ht werden. <br><br>  Schlie√ülich m√ºssen wir vielleicht die Wettbewerbsf√§higkeit auf der Fahrerseite einschr√§nken.  Manchmal kommt es vor, dass zu viele wettbewerbsf√§hige Anfragen gesendet werden, und wie bei jeder Datenbank kann Cassandra diese nicht bearbeiten und geht zum Clinch, wenn die Antwortzeit exponentiell zunimmt und wir versuchen, immer mehr Arbeit zu leisten. <br><br><h3>  Verst√§ndnis des Kontextes </h3><br>  Es gibt immer einen Kontext f√ºr das Problem - was passiert im Cluster, ob die Reparatur jetzt funktioniert, auf welchem ‚Äã‚ÄãKnoten, in welchen Schl√ºsselbereichen, in welcher Tabelle. <br><br>  Zum Beispiel hatten wir ziemlich l√§cherliche Probleme mit Eisen.  Wir haben gesehen, dass ein Teil der Knoten langsam ist.  Sp√§ter wurde festgestellt, dass der Grund daf√ºr war, dass sich ihre Prozessoren im BIOS im Energiesparmodus befanden.  Aus irgendeinem Grund geschah dies w√§hrend der Erstinstallation von Eisen, und im Vergleich zu anderen Knoten wurden ungef√§hr 50% der Prozessorressourcen verwendet. <br><br>  Das Verst√§ndnis eines solchen Problems kann in der Tat schwierig sein.  Das Symptom ist folgendes: Es scheint, dass der Knoten die Komprimierung durchf√ºhrt, aber langsam.  Manchmal ist es mit Eisen verbunden, manchmal nicht, aber dies ist nur ein weiterer Cassandra-Fehler. <br><br>  Daher ist die √úberwachung obligatorisch und erfordert viel.  Je komplexer die Funktion in Cassandra ist, je weiter sie vom einfachen Schreiben und Lesen entfernt ist, desto mehr Probleme gibt es und desto schneller kann eine Datenbank mit einer ausreichenden Anzahl von Abfragen beendet werden.  Schauen Sie sich daher nach M√∂glichkeit einige ‚Äûleckere‚Äú Chips nicht an und versuchen Sie, sie zu verwenden. Vermeiden Sie sie so weit wie m√∂glich.  Nicht immer m√∂glich - nat√ºrlich ist es fr√ºher oder sp√§ter notwendig. <br><img src="https://habrastorage.org/webt/mx/m8/lx/mxm8lxirhudrxrdlcq26jpstvle.jpeg"><br><br>  Die neueste Geschichte handelt davon, wie Cassandra die Daten durcheinander gebracht hat.  In dieser Situation passierte es in Cassandra.  Das war interessant <br><br>  Wir haben gesehen, dass ungef√§hr einmal pro Woche in unserer Datenbank mehrere Dutzend besch√§digter Leitungen erscheinen - sie sind buchst√§blich mit M√ºll verstopft.  Dar√ºber hinaus validiert Cassandra die Daten, die zu ihrer Eingabe gehen.  Wenn es sich beispielsweise um eine Zeichenfolge handelt, sollte sie sich in utf8 befinden.  Aber in diesen Zeilen war M√ºll, nicht utf8, und Cassandra gab nicht einmal etwas damit zu tun.  Wenn ich versuche zu l√∂schen (oder etwas anderes zu tun), kann ich keinen Wert l√∂schen, der nicht utf8 ist, da ich ihn insbesondere nicht in WHERE eingeben kann, da der Schl√ºssel utf8 sein muss. <br><br>  Verdorbene Linien erscheinen irgendwann wie ein Blitz und sind dann f√ºr einige Tage oder Wochen wieder verschwunden. <br><br>  Wir suchten nach einem Problem.  Wir dachten, dass es m√∂glicherweise ein Problem in einem bestimmten Knoten gibt, mit dem wir herumspielen, etwas mit Daten tun und SSTables kopieren.  Vielleicht k√∂nnen Sie trotzdem Repliken dieser Daten sehen?  Vielleicht haben diese Replikate einen gemeinsamen Knoten, den kleinsten gemeinsamen Faktor?  Vielleicht st√ºrzt ein Knoten ab?  Nein, nichts dergleichen. <br><br>  Vielleicht etwas mit einer Festplatte?  Sind die Daten auf der Festplatte besch√§digt?  Nein schon wieder. <br><br>  Vielleicht eine Erinnerung?  Nein!  √úber einen Cluster verteilt. <br><br>  Vielleicht ist dies eine Art Replikationsproblem?  Ein Knoten hat alles verdorben und einen schlechten Wert weiter repliziert?  - Nein. <br><br>  Schlie√ülich ist dies vielleicht ein Anwendungsproblem? <br><br>  Dar√ºber hinaus tauchten die besch√§digten Linien irgendwann in zwei Cassandra-Clustern auf.  Einer arbeitete an Version 2.1, der zweite an der dritten.  Es scheint, dass Cassandra anders ist, aber das Problem ist das gleiche.  Vielleicht sendet unser Service schlechte Daten?  Aber es war schwer zu glauben.  Cassandra validiert Eingabedaten und konnte keinen M√ºll schreiben.  Aber pl√∂tzlich? <br><br>  Nichts passt. <br><br><h3>  Eine Nadel wurde gefunden! </h3><br>  Wir haben lange und hart gek√§mpft, bis wir ein kleines Problem entdeckten: Warum haben wir eine Art Crash-Dump von der JVM auf den Knoten, denen wir nicht viel Aufmerksamkeit geschenkt haben?  Und irgendwie sieht es im Stack Trace Garbage Collector verd√§chtig aus ... Und aus irgendeinem Grund sind auch einige Stack Trace mit M√ºll verstopft. <br><br>  Am Ende wurde uns klar - oh, <strong>aus irgendeinem Grund verwenden wir die JVM der alten Version von 2015</strong> .  Dies war die einzige gemeinsame Sache, die Cassandra-Cluster auf verschiedenen Versionen von Cassandra vereinte. <br><br>  Ich wei√ü immer noch nicht, wo das Problem lag, da in den offiziellen Versionshinweisen der JVM nichts dar√ºber geschrieben wurde.  Aber nach dem Update verschwand alles, das Problem trat nicht mehr auf.  Dar√ºber hinaus trat es nicht vom ersten Tag an im Cluster auf, sondern irgendwann, obwohl es lange Zeit mit derselben JVM funktionierte. <br><br><h3>  Datenwiederherstellung </h3><br>  Welche Lektion haben wir daraus gelernt: <br><br>  ‚óè Backup ist nutzlos. <br>  Wie wir herausfanden, waren die Daten in der Sekunde, in der sie aufgezeichnet wurden, besch√§digt.  Zu dem Zeitpunkt, als die Daten in den Koordinator eingegeben wurden, waren sie bereits besch√§digt. <br><br>  ‚óè Eine teilweise Wiederherstellung unbesch√§digter S√§ulen ist m√∂glich. <br>  Einige Spalten wurden nicht besch√§digt, wir konnten diese Daten lesen und teilweise wiederherstellen. <br><br>  ‚óè Am Ende mussten wir eine Wiederherstellung aus verschiedenen Quellen durchf√ºhren. <br>  Wir hatten Backup-Metadaten im Objekt, aber in den Daten selbst.  Um die Verbindung mit dem Objekt wiederherzustellen, haben wir Protokolle usw. verwendet. <br><br>  ‚óè Protokolle sind von unsch√§tzbarem Wert! <br>  Wir konnten alle besch√§digten Daten wiederherstellen, aber am Ende ist es sehr schwierig, der Datenbank zu vertrauen, wenn sie Ihre Daten verliert, auch ohne dass Sie etwas unternehmen m√ºssen. <br><br><h3>  L√∂sung </h3><br><ul><li>  Aktualisieren Sie die JVM nach umfangreichen Tests. </li><li>  JVM-Absturz√ºberwachung. </li><li>  Haben Sie eine Cassandra-unabh√§ngige Kopie der Daten. </li></ul><br><blockquote>  <strong>Als Tipp:</strong> Versuchen Sie, eine Art Cassandra-unabh√§ngige Kopie der Daten zu haben, aus der Sie bei Bedarf wiederherstellen k√∂nnen.  Dies kann die L√∂sung der letzten Ebene sein.  Lassen Sie es viel Zeit und Ressourcen in Anspruch nehmen, aber es sollte eine Option geben, mit der Sie Daten zur√ºckgeben k√∂nnen. </blockquote><br><h1>  Bugs </h1><br>  ‚óè <strong>Schlechte Qualit√§t der Release-Tests</strong> <br>  Wenn Sie anfangen, mit Cassandra zu arbeiten, besteht das st√§ndige Gef√ºhl (insbesondere wenn Sie relativ gesehen von ‚Äûguten‚Äú Datenbanken, z. B. PostgreSQL, wechseln), dass Sie definitiv einen neuen hinzuf√ºgen, wenn Sie einen Fehler in der vorherigen Version behoben haben.  Und der Fehler ist kein Unsinn, es sind normalerweise besch√§digte Daten oder anderes falsches Verhalten. <br><br>  ‚óè <strong>Anhaltende Probleme mit komplexen Funktionen</strong> <br>  Je komplexer die Funktion ist, desto mehr Probleme, Fehler usw. sind damit verbunden. <br><br>  ‚óè <strong>Verwenden Sie in 2.1 keine inkrementelle Reparatur</strong> <br>  Die ber√ºhmte Reparatur, √ºber die ich gesprochen habe und die die Datenkonsistenz im Standardmodus behebt, wenn alle Knoten abgefragt werden, funktioniert gut.  Aber nicht im sogenannten inkrementellen Modus (wenn die Reparatur Daten √ºberspringt, die sich seit der vorherigen Reparatur nicht ge√§ndert haben, was ziemlich logisch ist).  Es wurde vor langer Zeit offiziell angek√ºndigt, da es eine Funktion gibt, aber jeder sagt: ‚ÄûNein, in Version 2.1, benutze sie niemals!  Er wird definitiv etwas vermissen.  In 3 beheben wir es. " <br><br>  ‚óè <strong>Verwenden Sie in 3.x jedoch keine inkrementelle Reparatur</strong> <br>  Als die dritte Version herauskam, sagten sie einige Tage sp√§ter: ‚ÄûNein, Sie k√∂nnen sie in der dritten nicht verwenden.  Es gibt eine Liste mit 15 Fehlern. Verwenden Sie daher in keinem Fall eine inkrementelle Reparatur.  Im 4. werden wir es besser machen! ‚Äú <br><br>  Ich glaube ihnen nicht.  Dies ist ein gro√ües Problem, insbesondere bei zunehmender Clustergr√∂√üe.  Daher m√ºssen Sie ihren Bugtracker st√§ndig √ºberwachen und sehen, was passiert.  Leider ist es unm√∂glich, ohne sie zu leben. <br><br>  ‚óè Sie <strong>m√ºssen JIRA im Auge behalten</strong> <br><img src="https://habrastorage.org/webt/g0/1k/el/g01kela-ibcrrsorr1pjxo-pmdc.jpeg"><br><br><blockquote>  Wenn Sie alle Datenbanken im Vorhersagbarkeitsspektrum verteilen, befindet sich Cassandra f√ºr mich links im roten Bereich.  Das bedeutet nicht, dass es schlecht ist, man muss nur darauf vorbereitet sein, dass Cassandra im wahrsten Sinne des Wortes unvorhersehbar ist: sowohl in der Art und Weise, wie es funktioniert, als auch in der Tatsache, dass etwas passieren kann. </blockquote><br><img src="https://habrastorage.org/webt/je/_1/w0/je_1w0808rlhzxo1bakk0zjj9ee.jpeg"><br><br>  Ich m√∂chte, dass Sie andere Rechen finden und darauf treten, denn aus meiner Sicht ist Cassandra, egal was passiert, gut und sicherlich nicht langweilig.  Denken Sie nur an die Unebenheiten auf der Stra√üe! <br><br><blockquote>  <strong>Offenes Treffen von HighLoad ++ - Aktivisten</strong> <br><br>  Am 31. Juli um 19:00 Uhr findet in Moskau ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Treffen der</a> Redner, des Programmkomitees und der Aktivisten der HighLoad ++ 2018-Konferenz der Entwickler von Hochlastsystemen statt. Wir werden ein kleines Brainstorming √ºber das diesj√§hrige Programm organisieren, um nichts Neues und Wichtiges zu verpassen.  Das Meeting ist offen, aber Sie m√ºssen sich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">registrieren</a> . <br><br>  <strong>Ruf nach Papieren</strong> <br><br>  Aktive <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Annahme von Bewerbungen</a> f√ºr Berichte bei Highload ++ 2018. Das Programmkomitee wartet bis Ende des Sommers auf Ihr Abstract. <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de417617/">https://habr.com/ru/post/de417617/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de417603/index.html">Ank√ºndigung eines mobilen Mitaps: Was tun, wenn die Anwendung gro√ü geworden ist?</a></li>
<li><a href="../de417605/index.html">Grundlagen der 3D-Modellierung f√ºr den 3D-Druck</a></li>
<li><a href="../de417607/index.html">A / B-Tests funktionieren nicht. √úberpr√ºfen Sie, was Sie falsch machen</a></li>
<li><a href="../de417609/index.html">Spezialisierung auf Sportprogrammierung am Cursor</a></li>
<li><a href="../de417615/index.html">Disk Cracker Confessions f√ºr Apple II: 4 Uhr morgens Geheimnisse</a></li>
<li><a href="../de417619/index.html">Win32 / Glupteba ist nicht mehr mit dem Windigo-Betrieb verbunden</a></li>
<li><a href="../de417621/index.html">Was ist passiert, als wir die Ausstellung geknackt haben?</a></li>
<li><a href="../de417627/index.html">Hyper CRM oder Mini ERP? Das Gesch√§ft ist durcheinander</a></li>
<li><a href="../de417629/index.html">Delphi und C ++ Builder Community Edition</a></li>
<li><a href="../de417631/index.html">CSS Grid Video Tutorial</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
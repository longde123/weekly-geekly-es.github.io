<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•£ üçó üîå Como e por que otimizamos o algoritmo para limpar caches SLAB no kernel do Linux üíñ üê≥ ü§æüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A crescente popularidade dos cont√™ineres e seu uso em conjunto com os grupos de controle revelaram um s√©rio problema de escalabilidade, o que leva a u...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como e por que otimizamos o algoritmo para limpar caches SLAB no kernel do Linux</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/virtuozzo/blog/435694/">  A crescente popularidade dos cont√™ineres e seu uso em conjunto com os grupos de controle revelaram um s√©rio problema de escalabilidade, o que leva a uma queda significativa no desempenho de grandes m√°quinas.  O problema √© que o tempo de desvio dos caches SLAB depende quadraticamente do n√∫mero de cont√™ineres e o consumo ativo de grandes quantidades de mem√≥ria em um curto per√≠odo pode fazer com que o sistema entre em um loop ocupado, consumindo 100% do tempo do processador.  Hoje eu gostaria de contar como resolvemos esse problema alterando o algoritmo de contabilidade para usar o grupo de controle memcg para usar objetos de cache SLAB e otimizar a fun√ß√£o shrink_slab (). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/99b/7f3/83b/99b7f383beadeec2c814a6792e507b6c.jpg" alt="Limpeza de mem√≥ria"><br><a name="habracut"></a><br>  Por que surgiu a quest√£o da otimiza√ß√£o de processos no kernel?  Tudo come√ßou com o fato de que um de nossos clientes, usando ativamente cont√™ineres e grupos de controle de mem√≥ria (memcg), chamou a aten√ß√£o para os estranhos picos de consumo de CPU que ocorrem de tempos em tempos.  A carga normal do sistema era de cerca de 50% e, nos hor√°rios de pico, 100% do tempo do processador era gasto, e quase todo era consumido pelo kernel (tempo do sistema). <br>  O n√≥ em si era multiusu√°rio e cerca de 200 cont√™ineres OpenVZ foram lan√ßados nele.  A an√°lise mostrou que um grande n√∫mero de usu√°rios criou cont√™ineres Docker aninhados e hierarquias de v√°rios n√≠veis de grupos de controle de mem√≥ria.  Cada cont√™iner de n√≠vel superior de n√≠vel de usu√°rio continha cerca de 20 pontos de montagem e 20 grupos de mem√≥ria de controle (memcg) criados pelo systemd.  Al√©m disso, havia pontos de montagem e grupos de controle criados pelo Docker mencionado acima.  Simplificando, o n√≥ estava muito carregado e a carga nele era muito maior que a m√©dia para todos os outros clientes.  Est√°vamos interessados ‚Äã‚Äãem descobrir o motivo da apar√™ncia desses picos, pois o mesmo problema poderia aparecer em m√°quinas menos ocupadas, onde era quase impercept√≠vel (por exemplo, fornecer picos com + 5% de tempo do sistema, o que prejudica o desempenho). <br><br>  Ao manipular o perf, consegui pegar o pico e remover a trilha.  Aconteceu que a maior parte do tempo do processador √© gasta na limpeza de caches SLAB, a saber, caches de super bloco: <br><br><pre><code class="markdown hljs"><span class="hljs-bullet"><span class="hljs-bullet">- </span></span>100,00% 0,00% kswapd0 [kernel.vmlinux] [k] kthread - 99,31% balance<span class="hljs-emphasis"><span class="hljs-emphasis">_pgdat - 82,11% shrink_</span></span>zone - 61,69% shrink<span class="hljs-emphasis"><span class="hljs-emphasis">_slab - 58,29% super_</span></span>cache<span class="hljs-emphasis"><span class="hljs-emphasis">_count + 54,56% list_</span></span>lru<span class="hljs-emphasis"><span class="hljs-emphasis">_count_</span></span>one</code> </pre> <br><br>  Aqui vale a pena fazer uma explica√ß√£o e me debru√ßar sobre esse assunto com mais detalhes.  Todo mundo sabe que o kernel armazena em cache dados n√£o utilizados por um tempo antes de finalmente liberar mem√≥ria.  O kernel faz uso extensivo desse princ√≠pio.  Por exemplo, o cache da p√°gina cont√©m p√°ginas de dados relacionados ao arquivo, o que acelera bastante o acesso repetido a eles durante a leitura (porque voc√™ n√£o precisa acessar o disco novamente).  No nosso caso, o problema surgiu com o cache de metadados do superbloco contido em duas listas de LRU: s_dentry_lru e s_inode_lru. <br><br>  <b>LRU (menos usado recentemente)</b> <b><br></b> <br>  struct lru_list aponta para uma matriz de listas vinculadas e cada memcg ativo corresponde a um elemento (list_lru_one) nessa matriz.  Quando um determinado objeto SLAB n√£o √© mais usado pelo kernel, o kernel o adiciona a uma das listas vinculadas da matriz (dependendo de qual memcg o objeto pertence ou, grosso modo, qual memcg o processo usado quando ele criou esse objeto).  A pr√≥pria matriz √© descrita da seguinte forma (lru_list :: node :: memcg_lrus): <br><br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">list_lru_memcg</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">rcu_head</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">rcu</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-comment"><span class="hljs-comment">/* array of per cgroup lists, indexed by memcg_cache_id */</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">list_lru_one</span></span></span><span class="hljs-class"> *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">lru</span></span></span><span class="hljs-class">[0];</span></span> <span class="hljs-comment"><span class="hljs-comment">/*    */</span></span> }; <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">list_lru_one</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">list_head</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">list</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-comment"><span class="hljs-comment">/*    */</span></span> <span class="hljs-comment"><span class="hljs-comment">/* may become negative during memcg reparenting */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">long</span></span> nr_items; <span class="hljs-comment"><span class="hljs-comment">/*     */</span></span> };</code> </pre><br>  lru [0] indica uma lista de objetos relacionados ao memcg com o ID 0; <br>  lru [1] indica uma lista de objetos relacionados ao memcg com o ID 1; <br>  ... <br>  lru [n] indica uma lista de objetos relacionados ao memcg com o ID n; <br><br>  As listas LRU s_dentry_lru e s_inode_lru aparecem no nosso problema e, como o nome sugere, elas cont√™m objetos n√£o utilizados do sistema de arquivos dentry e inode. <br>  No futuro, se n√£o houver mem√≥ria suficiente no sistema ou em um memcg espec√≠fico, alguns dos itens da lista ser√£o finalmente liberados e um mecanismo especial chamado shrinker far√° isso. <br><br>  <b>Encolhedor</b> <b><br></b> <br>  Quando o kernel precisa alocar p√°ginas de mem√≥ria, mas n√£o h√° mem√≥ria livre no n√≥ NUMA ou no sistema, o mecanismo para limp√°-lo √© iniciado.  Ele est√° tentando jogar ou descartar uma certa quantidade de disco: 1) p√°ginas do conte√∫do dos arquivos do cache da p√°gina;  2) p√°ginas relacionadas √† mem√≥ria an√¥nima em uma troca e 3) objetos SLAB em cache (o problema que encontramos est√° relacionado a eles). <br><br>  A elimina√ß√£o de parte dos objetos SLAB em cache n√£o afeta diretamente o lan√ßamento das p√°ginas: seu tamanho, em regra, √© significativamente menor que o tamanho da p√°gina e uma p√°gina cont√©m centenas de objetos.  Quando parte dos objetos √© liberada, as lacunas de mem√≥ria livre s√£o exibidas nas p√°ginas SLAB, que podem ser usadas para criar outros objetos SLAB.  Este algoritmo √© aceito no kernel intencionalmente: √© simples e bastante eficiente.  Um leitor interessado pode ver a f√≥rmula para selecionar uma parte dos objetos para limpeza na fun√ß√£o do_shrink_slab (). <br><br>  Esta fun√ß√£o executa a limpeza real de parte dos objetos, guiada pela descri√ß√£o passada a ela no encolhedor de estrutura: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">unsigned</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">long</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">do_shrink_slab</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(struct shrink_control *shrinkctl, struct shrinker *shrinker, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> priority)</span></span></span><span class="hljs-function"> </span></span>{ ‚Ä¶ <span class="hljs-comment"><span class="hljs-comment">/*   */</span></span> freeable = shrinker-&gt;count_objects(shrinker, shrinkctl); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (freeable == <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>; total_scan = _(freeable); <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (total_scan &gt;= batch_size) { <span class="hljs-comment"><span class="hljs-comment">/*   */</span></span> ret = shrinker-&gt;scan_objects(shrinker, shrinkctl); total_scan -= shrinkctl-&gt;nr_scanned; } ... }</code> </pre> <br>  Em rela√ß√£o ao superbloco de retra√ß√£o, essas fun√ß√µes s√£o implementadas da seguinte maneira.  Cada superbloco mant√©m suas pr√≥prias listas s_dentry_lru e s_inode_lru de objetos n√£o utilizados relacionados a ele: <br><br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">super_block</span></span></span><span class="hljs-class"> {</span></span> ... <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">shrinker</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">s_shrink</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-comment"><span class="hljs-comment">/* per-sb shrinker handle */</span></span> ... <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">list_lru</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">s_dentry_lru</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">list_lru</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">s_inode_lru</span></span></span><span class="hljs-class">;</span></span> ‚Ä¶ };</code> </pre> <br><br>  O m√©todo .count_objects retorna o n√∫mero de objetos: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">unsigned</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">long</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">super_cache_count</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(struct shrinker *shrink, struct shrink_control *sc)</span></span></span><span class="hljs-function"> </span></span>{ total_objects += list_lru_shrink_count(&amp;sb-&gt;s_dentry_lru, sc); total_objects += list_lru_shrink_count(&amp;sb-&gt;s_inode_lru, sc); <span class="hljs-comment"><span class="hljs-comment">/*     ) */</span></span> total_objects = vfs_pressure_ratio(total_objects); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> total_objects; }</code> </pre> <br><br>  O m√©todo .scan_objects realmente libera objetos: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">unsigned</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">long</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">super_cache_scan</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(struct shrinker *shrink, struct shrink_control *sc)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">/*     s_dentry_lru */</span></span> prune_dcache_sb(sb, sc); <span class="hljs-comment"><span class="hljs-comment">/*     s_inode_lru */</span></span> prune_icache_sb(sb, sc); }</code> </pre> <br>  O n√∫mero de objetos a serem liberados √© passado no par√¢metro sc.  Al√©m disso, o memcg √© indicado l√°, cujos objetos devem ser jogados para fora da LRU: <br><br><pre> <b><code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">shrink_control</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> nid; <span class="hljs-comment"><span class="hljs-comment">/* ID NUMA  */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">long</span></span> nr_to_scan; <span class="hljs-comment"><span class="hljs-comment">/*   */</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">mem_cgroup</span></span></span><span class="hljs-class"> *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">memcg</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-comment"><span class="hljs-comment">/* memcg */</span></span> };</code></b> </pre><br>  Portanto, prune_dcache_sb () seleciona uma lista vinculada da estrutura struct list_lru_memcg :: lru [] e trabalha com ela.  Prune_icache_sb () faz o mesmo. <br><br>  <b>Algoritmo velho do desvio do shrinker</b> <b><br></b> <br>  Com a abordagem padr√£o, ‚Äúejetar‚Äù objetos do SLAB com falta de mem√≥ria no <br>  sc-&gt; target_mem_cgroup acontece da seguinte maneira: <br><br><pre> <code class="cpp hljs">shrink_node() { ‚Ä¶ <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">mem_cgroup</span></span></span><span class="hljs-class"> *</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">root</span></span></span><span class="hljs-class"> = </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">sc</span></span></span><span class="hljs-class">-&gt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">target_mem_cgroup</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-comment"><span class="hljs-comment">/*      sc-&gt;target_mem_cgroup  */</span></span> memcg = mem_cgroup_iter(root, <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>, &amp;reclaim); <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> { ‚Ä¶ shrink_slab(memcg, ...); ‚Ä¶ } <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> ((memcg = mem_cgroup_iter(root, memcg, &amp;reclaim))); ... }</code> </pre><br>  Examinamos todo o memcg filho e chamamos shrink_slab () para cada um deles.  Em seguida, na fun√ß√£o shrink_slab (), examinamos todos os encolhedores e, para cada um deles, chamamos do_shrink_slab (): <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">unsigned</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">long</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">shrink_slab</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">gfp_t</span></span></span></span><span class="hljs-function"><span class="hljs-params"> gfp_mask, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> nid, struct mem_cgroup *memcg, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> priority)</span></span></span><span class="hljs-function"> </span></span>{ list_for_each_entry(shrinker, &amp;shrinker_list, <span class="hljs-built_in"><span class="hljs-built_in">list</span></span>) { <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">shrink_control</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">sc</span></span></span><span class="hljs-class"> = {</span></span> .nid = nid, .memcg = memcg, }; ret = do_shrink_slab(&amp;sc, shrinker, ...); } }</code> </pre><br>  Lembre-se de que para cada superbloco, seu pr√≥prio encolhedor √© adicionado a esta lista.  Vamos contar quantas vezes o do_shrink_slab () ser√° chamado para o caso com 200 cont√™ineres de 20 memcg e 20 pontos de montagem em cada um.  No total, temos 200 * 20 pontos de montagem e 200 * 20 grupos de controle.  Se n√£o houver mem√≥ria suficiente no memcg superior, seremos for√ßados a ignorar todo o memcg filho (isto √©, tudo em geral) e, para cada um deles, chamar cada um dos shrinkers da shrinker_list.  Assim, o kernel far√° 200 * 20 * 200 * 20 = 16000000 chamadas para a fun√ß√£o do_shrink_slab (). <br><br>  Al√©m disso, o grande n√∫mero de chamadas para essa fun√ß√£o ser√° in√∫til: os cont√™ineres geralmente s√£o isolados entre si, e a probabilidade de o CT1 usar o super_block2 criado no CT2 √© geralmente baixa.  Ou, o que √© o mesmo, se memcg1 for um grupo de controle do CT1, o elemento correspondente da matriz super_block2-&gt; s_dentry_lru-&gt; node-&gt; memcg_lrus-&gt; lru [memcg1_id] ser√° uma lista vazia e n√£o h√° sentido em chamar do_shrink_slab (). <br><br>  Esse problema pode ser modelado usando um script bash simples (dados do patchset, que foram posteriormente passados ‚Äã‚Äãpara o kernel, s√£o usados ‚Äã‚Äãaqui): <br><pre> <code class="bash hljs"><span class="hljs-variable"><span class="hljs-variable">$echo</span></span> 1 &gt; /sys/fs/cgroup/memory/memory.use_hierarchy <span class="hljs-variable"><span class="hljs-variable">$mkdir</span></span> /sys/fs/cgroup/memory/ct <span class="hljs-variable"><span class="hljs-variable">$echo</span></span> 4000M &gt; /sys/fs/cgroup/memory/ct/memory.kmem.limit_in_bytes <span class="hljs-variable"><span class="hljs-variable">$for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> `seq 0 4000`; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> mkdir /sys/fs/cgroup/memory/ct/<span class="hljs-variable"><span class="hljs-variable">$i</span></span>; <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> $$ &gt; /sys/fs/cgroup/memory/ct/<span class="hljs-variable"><span class="hljs-variable">$i</span></span>/cgroup.procs; mkdir -ps/<span class="hljs-variable"><span class="hljs-variable">$i</span></span>; mount -t tmpfs <span class="hljs-variable"><span class="hljs-variable">$is</span></span>/<span class="hljs-variable"><span class="hljs-variable">$i</span></span>; touch s/<span class="hljs-variable"><span class="hljs-variable">$i</span></span>/file; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span></code> </pre><br>  Vamos ver o que acontece se voc√™ chamar o procedimento de redefini√ß√£o de cache 5 vezes seguidas: <br><pre> <code class="bash hljs"><span class="hljs-variable"><span class="hljs-variable">$time</span></span> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> 3 &gt; /proc/sys/vm/drop_caches</code> </pre> <br>  A primeira itera√ß√£o dura 14 segundos, porque os objetos em cache realmente est√£o na mem√≥ria: <i>0,00 usu√°rio 13,78 system <b>0: 13.78 decorrido</b> 99% da CPU.</i> <br>  A segunda itera√ß√£o leva 5 segundos, embora n√£o haja mais objetos: <i>0.00user 5.59system <b>0: 05.60capsed</b> 99% CPU.</i> <br>  A terceira itera√ß√£o leva 5 segundos: <i>0.00user 5.48system <b>0: 05.48elapse</b> CPU 99%</i> <br>  A quarta itera√ß√£o leva 8 segundos: <i>0.00user 8.35system <b>0: 08.35elapsed</b> 99% CPU</i> <br>  A quinta itera√ß√£o leva 8 segundos: <i>0.00user 8.34system <b>0: 08.35elapsed</b> 99% CPU</i> <br><br>  Tornou-se √≥bvio que o algoritmo de desvio de encolhimento usado pelo n√∫cleo de baunilha n√£o √© ideal, e precisamos alter√°-lo para melhor em termos de escalabilidade. <br><br>  <b>Novo algoritmo de desvio de encolhimento</b> <b><br></b> <br>  Com o novo algoritmo, eu queria obter o seguinte: <br><br><ol><li>  libert√°-lo das falhas dos antigos e </li><li>  N√£o adicione novos bloqueios.  Chame do_shrink_slab () apenas quando fizer sentido (ou seja, a lista vinculada correspondente da matriz s_dentry_lru ou da matriz s_inode_lru n√£o estiver vazia), mas n√£o acesse diretamente a mem√≥ria da lista vinculada. </li></ol><br>  Ficou claro que isso poderia ser fornecido apenas por uma nova estrutura de dados sobre encolhedores heterog√™neos (existem encolhedores n√£o apenas do superbloco, mas tamb√©m de outros objetos de dados n√£o descritos neste artigo. O leitor pode se familiarizar com eles pesquisando a palavra-chave prealloc_shrinker () no c√≥digo do kernel).  A nova estrutura de dados deve permitir a codifica√ß√£o de dois estados: ‚Äúfaz sentido chamar do_shrink_slab ()‚Äù e ‚Äún√£o faz sentido chamar do_shrink_slab ()‚Äù. <br><br>  As estruturas de dados do tipo IDA foram rejeitadas porque  eles usam bloqueios dentro de si.  A estrutura de dados do campo de bits √© totalmente adequada para essa fun√ß√£o: permite a modifica√ß√£o at√¥mica de bits individuais e, em combina√ß√£o com barreiras de mem√≥ria, permite a cria√ß√£o de um algoritmo eficiente sem o uso de bloqueios. <br><br>  Cada shrinker obt√©m seu pr√≥prio ID exclusivo (shrinker :: id) e cada memcg obt√©m um bitmap capaz de conter o maior ID dos atualmente registrados.  Quando o primeiro elemento √© adicionado √† lista s_dentry_lru-&gt; node-&gt; memcg_lrus-&gt; lru [memcg_id], o bitmap memcg correspondente √© definido como 1 bit com o n√∫mero shrinker-&gt; id.  A mesma coisa com s_inode_id. <br><br>  Agora o loop em shrink_slab () pode ser otimizado para ignorar apenas os shrinkers necess√°rios: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">unsigned</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">long</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">shrink_slab</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ ‚Ä¶ for_each_set_bit(i, <span class="hljs-built_in"><span class="hljs-built_in">map</span></span>, shrinker_nr_max) { ‚Ä¶ shrinker = idr_find(&amp;shrinker_idr, i); ‚Ä¶ do_shrink_slab(&amp;sc, shrinker, priority); ‚Ä¶ } }</code> </pre><br>  (A limpeza de bits tamb√©m √© implementada quando o shrinker entra no estado "n√£o faz sentido chamar do_shrink_slab (). Consulte o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">commit</a> do Github para obter mais detalhes. <br><br>  Se voc√™ repetir o teste de redefini√ß√£o de cache, usando o novo algoritmo, ele mostra resultados significativamente melhores: <br><pre> <code class="bash hljs"><span class="hljs-variable"><span class="hljs-variable">$time</span></span> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> 3 &gt; /proc/sys/vm/drop_caches</code> </pre> <br>  Primeira itera√ß√£o: <i>0.00user 1.10system <b>0: 01.10</b> CPU <b>decorrida de</b> 99%</i> <i><br></i>  Segunda itera√ß√£o: <i>0.00user 0.00system <b>0: 00.01apps</b> 64% CPU</i> <i><br></i>  Terceira itera√ß√£o: <i>0.00user 0.01system <b>0: 00.01elapse</b> 82% CPU</i> <i><br></i>  Quarta itera√ß√£o: <i>0.00user 0.00system <b>0: 00.01apps</b> 64% CPU</i> <i><br></i>  Quinta itera√ß√£o: <i>0.00user 0.01system <b>0: 00.01elapse</b> 82% CPU</i> <br>  A dura√ß√£o da segunda √† quinta itera√ß√µes √© de 0,01 segundos, <b>548 vezes mais r√°pido que antes.</b> <br><br>  Como a√ß√µes semelhantes para redefinir os caches ocorrem com cada falta de mem√≥ria na m√°quina, essa otimiza√ß√£o melhora significativamente a opera√ß√£o de m√°quinas com um grande n√∫mero de cont√™ineres e grupos de controle de mem√≥ria.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Um conjunto de patches</a> (17 pe√ßas) foi aceito no n√∫cleo da baunilha e voc√™ pode encontr√°-lo l√° a partir da vers√£o 4.19. <br><br>  No processo de revis√£o dos patches, um funcion√°rio do Google apareceu, e descobriu-se que eles tinham o mesmo problema.  Portanto, os patches foram testados em um tipo diferente de carga. <br>  Como resultado, o patchset foi adotado na 9¬™ itera√ß√£o;  e sua entrada no n√∫cleo da baunilha levou cerca de 4 meses.  Ainda hoje, o patchset est√° inclu√≠do em nosso pr√≥prio kernel Virtuozzo 7, come√ßando com a vers√£o vz7.71.9 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt435694/">https://habr.com/ru/post/pt435694/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt435684/index.html">O Laborat√≥rio Nacional de Oak Ridge resolveu o principal problema dos desenvolvedores de dispositivos espaciais: defici√™ncia de plut√¥nio-238</a></li>
<li><a href="../pt435686/index.html">Pavel Durov liquida o Telegram Messenger LLP</a></li>
<li><a href="../pt435688/index.html">Exemplo de aplicativo Flutter Client Server</a></li>
<li><a href="../pt435690/index.html">[O que h√° de errado com o GraphQL] ... E como lidar com isso</a></li>
<li><a href="../pt435692/index.html">Y Combinator: ‚ÄúNo come√ßo, algumas das maiores empresas de tecnologia parecem brinquedos‚Äù</a></li>
<li><a href="../pt435696/index.html">Antiguidades: 1997 Publicidade em computador</a></li>
<li><a href="../pt435700/index.html">8 Piores perguntas da entrevista no Vue.js.</a></li>
<li><a href="../pt435702/index.html">Trolls de patentes come√ßam e ganham: como eu fiquei sem jogo</a></li>
<li><a href="../pt435704/index.html">Solu√ß√µes arquitet√¥nicas para um jogo para celular. Parte 2: Comando e suas filas</a></li>
<li><a href="../pt435706/index.html">Usamos o rcm para implantar a configura√ß√£o em qualquer pasta</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
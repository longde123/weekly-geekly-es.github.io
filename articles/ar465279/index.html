<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💤 🏇🏼 🌠 التعرف على الوجوه باستخدام شبكات سيامي 🤙🏻 🚀 👨🏽‍🔧</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="تعتبر الشبكة العصبية السيامية واحدة من أبسط خوارزميات التعلم الفردية وأكثرها شعبية. الأساليب التي تؤخذ لكل فصل دراسة حالة واحدة فقط. وبالتالي ، عادةً ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>التعرف على الوجوه باستخدام شبكات سيامي</h1><div class="post__body post__body_full" style=";text-align:right;direction:rtl"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/jetinfosystems/blog/465279/" style=";text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/mg/dh/mb/mgdhmb0xf-4onn6dny1renuuhla.jpeg"><br><br>  تعتبر الشبكة العصبية السيامية واحدة من أبسط خوارزميات التعلم الفردية وأكثرها شعبية.  الأساليب التي تؤخذ لكل فصل دراسة حالة واحدة فقط.  وبالتالي ، عادةً ما يتم استخدام شبكة Siamese في التطبيقات التي لا توجد فيها وحدات بيانات كثيرة في كل فئة. <br><br>  لنفترض أننا بحاجة إلى إنشاء نموذج للتعرف على الوجوه لمنظمة توظف حوالي 500 شخص.  إذا قمت بإنشاء مثل هذا النموذج من نقطة الصفر بناءً على الشبكة العصبية التلافيفية (CNN) ، ثم لتدريب النموذج وتحقيق دقة جيدة في التعرف ، فسنحتاج إلى العديد من الصور لكل 500 شخص.  لكن من الواضح أننا لا نستطيع جمع مجموعة البيانات هذه ، لذلك يجب ألا تصنع نموذجًا يستند إلى شبكة CNN أو أي خوارزمية أخرى <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">للتعلم العميق</a> إذا لم يكن لدينا بيانات كافية.  في مثل هذه الحالات ، يمكنك استخدام خوارزمية التعلم المعقدة لمرة واحدة ، مثل شبكة Siamese ، والتي يمكن تدريبها على بيانات أقل. <br><a name="habracut"></a><br>  في الواقع ، تتكون شبكات Siamese من شبكتين عصبيتين متماثلتين ، لهما نفس الأوزان والهندسة المعمارية ، التي تجمع في النهاية وتستخدم وظيفة الطاقة - E. <br>  دعونا ننظر إلى شبكة سيامي ، وخلق نموذج التعرف على الوجوه على أساس ذلك.  سوف نعلمها تحديد متى يكون وجهان متماثلان ومتى لا.  وبالنسبة للمبتدئين ، سوف نستخدم مجموعة بيانات AT&amp;T Database of Faces ، والتي يمكن تنزيلها من موقع <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">مختبر الكمبيوتر بجامعة Cambridge</a> . <br><br>  قم بتنزيل المجلدات وإزالتها ورؤيتها من s1 إلى s40: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/152/0fc/158/1520fc1584e7ba6335ba2ea99460d8f6.png"><br><br>  يحتوي كل مجلد على 10 صور مختلفة لشخص واحد مأخوذة من زوايا مختلفة.  فيما يلي محتويات المجلد s1: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5d4/02b/86f/5d402b86fc12e1b23512b1a54c7fea57.png"><br><br>  وإليك ما يوجد في مجلد s13: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b7c/819/716/b7c8197164861f8568e86d32a2294bc2.png"><br><br>  تحتاج شبكات Siamese إلى إدخال قيم مقترنة بعلامات ، لذلك دعونا ننشئ مثل هذه المجموعات.  التقط صورتين عشوائيتين من نفس المجلد وقم بتمييزهما كزوج "أصلي".  ثم نلتقط صورتين من مجلدات مختلفة ونضع علامة عليها كزوج "خطأ" (غير صحيح): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5b3/1f3/8bf/5b31f38bf3363aaa53110772b7643e3b.png"><br><br>  بعد توزيع جميع الصور على أزواج ملحوظة ، سنقوم بدراسة الشبكة.  من كل زوج ، سننقل صورة واحدة إلى الشبكة A ، والثانية إلى الشبكة B. كلا الشبكتين تستخرج متجهات الخصائص فقط.  للقيام بذلك ، نستخدم طبقتين تلافيفيين مع تنشيط الوحدة الخطية المصححة (ReLU).  بعد دراسة الخصائص ، نقوم بنقل المتجهات الناتجة عن كلتا الشبكتين إلى دالة طاقة تقدر التشابه.  نستخدم المسافة الإقليدية كدالة. <br><br>
<h2 style=";text-align:right;direction:rtl">  الآن النظر في كل هذه الخطوات بمزيد من التفصيل. </h2><br>  أولاً ، قم باستيراد المكتبات الضرورية: <br><br><pre style=";text-align:right;direction:rtl"><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Activation <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential, Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RMSprop</code> </pre> <br>  الآن نحدد وظيفة لقراءة الصور المدخلة.  تقوم وظيفة <code>read_image</code> بالتقاط صورة وإرجاع صفيف NumPy: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">read_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename, byteorder=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'&gt;'</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#first we read the image, as a raw file to the buffer with open(filename, 'rb') as f: buffer = f.read() #using regex, we extract the header, width, height and maxval of the image header, width, height, maxval = re.search( b"(^P5\s(?:\s*#.*[\r\n])*" b"(\d+)\s(?:\s*#.*[\r\n])*" b"(\d+)\s(?:\s*#.*[\r\n])*" b"(\d+)\s(?:\s*#.*[\r\n]\s)*)", buffer).groups() #then we convert the image to numpy array using np.frombuffer which interprets buffer as one dimensional array return np.frombuffer(buffer, dtype='u1' if int(maxval)</span></span></code> </pre> <br>  على سبيل المثال ، افتح هذه الصورة: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">Image.open(<span class="hljs-string"><span class="hljs-string">"data/orl_faces/s1/1.pgm"</span></span>)</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/ee2/954/697/ee2954697908ce55ffaf4fc8080914c7.png"><br><br>  نقوم <code>read_image</code> الدالة <code>read_image</code> والحصول على مجموعة NumPy: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">img = read_image(<span class="hljs-string"><span class="hljs-string">'data/orl_faces/s1/1.pgm'</span></span>) img.shape (<span class="hljs-number"><span class="hljs-number">112</span></span>, <span class="hljs-number"><span class="hljs-number">92</span></span>)</code> </pre> <br>  الآن نحدد وظيفة <code>get_data</code> التي ستنشئ البيانات.  اسمحوا لي أن أذكركم بأن شبكات Siamese تحتاج إلى تقديم أزواج من البيانات (أصلية وغير دقيقة) مع وضع علامة ثنائية. <br><br>  أولاً ، اقرأ الصور ( <code>img1</code> ، <code>img2</code> ) من دليل واحد ، واحفظها في صفيف <code>x_genuine_pair,</code> اضبط <code>y_genuine</code> على <code>1</code> .  ثم نقرأ الصور ( <code>img1</code> ، <code>img2</code> ) من أدلة مختلفة ، <code>x_imposite,</code> زوج <code>x_imposite,</code> <code>y_imposite</code> على <code>0</code> . <br><br>  لسَلسَلة <code>x_genuine_pair</code> و <code>x_imposite</code> في <code>X</code> ، و <code>y_genuine</code> و <code>y_imposite</code> في <code>Y</code> : <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">size = <span class="hljs-number"><span class="hljs-number">2</span></span> total_sample_size = <span class="hljs-number"><span class="hljs-number">10000</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(size, total_sample_size)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#read the image image = read_image('data/orl_faces/s' + str(1) + '/' + str(1) + '.pgm', 'rw+') #reduce the size image = image[::size, ::size] #get the new size dim1 = image.shape[0] dim2 = image.shape[1] count = 0 #initialize the numpy array with the shape of [total_sample, no_of_pairs, dim1, dim2] x_geuine_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2]) # 2 is for pairs y_genuine = np.zeros([total_sample_size, 1]) for i in range(40): for j in range(int(total_sample_size/40)): ind1 = 0 ind2 = 0 #read images from same directory (genuine pair) while ind1 == ind2: ind1 = np.random.randint(10) ind2 = np.random.randint(10) # read the two images img1 = read_image('data/orl_faces/s' + str(i+1) + '/' + str(ind1 + 1) + '.pgm', 'rw+') img2 = read_image('data/orl_faces/s' + str(i+1) + '/' + str(ind2 + 1) + '.pgm', 'rw+') #reduce the size img1 = img1[::size, ::size] img2 = img2[::size, ::size] #store the images to the initialized numpy array x_geuine_pair[count, 0, 0, :, :] = img1 x_geuine_pair[count, 1, 0, :, :] = img2 #as we are drawing images from the same directory we assign label as 1. (genuine pair) y_genuine[count] = 1 count += 1 count = 0 x_imposite_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2]) y_imposite = np.zeros([total_sample_size, 1]) for i in range(int(total_sample_size/10)): for j in range(10): #read images from different directory (imposite pair) while True: ind1 = np.random.randint(40) ind2 = np.random.randint(40) if ind1 != ind2: break img1 = read_image('data/orl_faces/s' + str(ind1+1) + '/' + str(j + 1) + '.pgm', 'rw+') img2 = read_image('data/orl_faces/s' + str(ind2+1) + '/' + str(j + 1) + '.pgm', 'rw+') img1 = img1[::size, ::size] img2 = img2[::size, ::size] x_imposite_pair[count, 0, 0, :, :] = img1 x_imposite_pair[count, 1, 0, :, :] = img2 #as we are drawing images from the different directory we assign label as 0. (imposite pair) y_imposite[count] = 0 count += 1 #now, concatenate, genuine pairs and imposite pair to get the whole data X = np.concatenate([x_geuine_pair, x_imposite_pair], axis=0)/255 Y = np.concatenate([y_genuine, y_imposite], axis=0) return X, Y</span></span></code> </pre> <br>  الآن سنقوم بإنشاء البيانات والتحقق من حجمها.  لدينا 20.000 صورة ، تم جمع 10000 منها من خلال 10000 زوج أصلي: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">X, Y = get_data(size, total_sample_size) X.shape (<span class="hljs-number"><span class="hljs-number">20000</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">56</span></span>, <span class="hljs-number"><span class="hljs-number">46</span></span>) Y.shape (<span class="hljs-number"><span class="hljs-number">20000</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  سوف نشارك مجموعة كاملة من المعلومات: 75 ٪ من أزواج سوف تذهب إلى التدريب ، و 25 ٪ - لاختبار: <br> <code>x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25)</code> <br> <br>  الآن إنشاء شبكة سيامي.  أولاً نحدد الشبكة الأساسية - ستكون شبكة عصبية تلافيفية لاستخراج الخصائص.  قم بإنشاء طبقتين تلافيفيًا باستخدام تنشيطات ReLU وطبقة ذات تجمع أقصى بعد طبقة مسطحة: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_base_network</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(input_shape)</span></span></span><span class="hljs-function">:</span></span> seq = Sequential() nb_filter = [<span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>] kernel_size = <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-comment"><span class="hljs-comment">#convolutional layer 1 seq.add(Convolution2D(nb_filter[0], kernel_size, kernel_size, input_shape=input_shape, border_mode='valid', dim_ordering='th')) seq.add(Activation('relu')) seq.add(MaxPooling2D(pool_size=(2, 2))) seq.add(Dropout(.25)) #convolutional layer 2 seq.add(Convolution2D(nb_filter[1], kernel_size, kernel_size, border_mode='valid', dim_ordering='th')) seq.add(Activation('relu')) seq.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='th')) seq.add(Dropout(.25)) #flatten seq.add(Flatten()) seq.add(Dense(128, activation='relu')) seq.add(Dropout(0.1)) seq.add(Dense(50, activation='relu')) return seq</span></span></code> </pre> <br><br>  بعد ذلك ، سننقل زوجًا من صور الشبكة الأساسية ، والتي ستُرجع تمثيلات المتجهات ، أي متجهات الممتلكات: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">input_dim = x_train.shape[<span class="hljs-number"><span class="hljs-number">2</span></span>:] img_a = Input(shape=input_dim) img_b = Input(shape=input_dim) base_network = build_base_network(input_dim) feat_vecs_a = base_network(img_a) feat_vecs_b = base_network(img_b)</code> </pre><br>  <code>feat_vecs_a</code> و <code>feat_vecs_b</code> هما <code>feat_vecs_b</code> لخاصية زوج من الصور.  لنقم بتمرير وظائف الطاقة الخاصة بهم لحساب المسافة بينهما.  وكدالة للطاقة ، نستخدم المسافة الإقليدية: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">euclidean_distance</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(vects)</span></span></span><span class="hljs-function">:</span></span> x, y = vects <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> K.sqrt(K.sum(K.square(x - y), axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, keepdims=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">eucl_dist_output_shape</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(shapes)</span></span></span><span class="hljs-function">:</span></span> shape1, shape2 = shapes <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (shape1[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])</code> </pre> <br>  قمنا بتعيين عدد الحلقات إلى 13 ، ونطبق خاصية RMS لتحسينها ونعلن النموذج: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">epochs = <span class="hljs-number"><span class="hljs-number">13</span></span> rms = RMSprop() model = Model(input=[input_a, input_b], output=distance)</code> </pre> <br>  الآن نقوم بتعريف دالة الخسارة دالة <code>contrastive_loss</code> وتجميع النموذج: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">contrastive_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> margin = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> K.mean(y_true * K.square(y_pred) + (<span class="hljs-number"><span class="hljs-number">1</span></span> - y_true) * K.square(K.maximum(margin - y_pred, <span class="hljs-number"><span class="hljs-number">0</span></span>))) model.compile(loss=contrastive_loss, optimizer=rms)</code> </pre> <br>  دعنا ندرس النموذج: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">img_1 = x_train[:, <span class="hljs-number"><span class="hljs-number">0</span></span>] img_2 = x_train[:, <span class="hljs-number"><span class="hljs-number">1</span></span>] model.fit([img_1, img_2], y_train, validation_split=<span class="hljs-number"><span class="hljs-number">.25</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">128</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">2</span></span>, nb_epoch=epochs)</code> </pre> <br>  ترى كيف تنخفض الخسائر مع مرور العصور: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">Train on <span class="hljs-number"><span class="hljs-number">11250</span></span> samples, validate on <span class="hljs-number"><span class="hljs-number">3750</span></span> samples Epoch <span class="hljs-number"><span class="hljs-number">1</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">60</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.2179</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.2156</span></span> Epoch <span class="hljs-number"><span class="hljs-number">2</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">53</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.1520</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.2102</span></span> Epoch <span class="hljs-number"><span class="hljs-number">3</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">53</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.1190</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.1545</span></span> Epoch <span class="hljs-number"><span class="hljs-number">4</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">55</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0959</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.1705</span></span> Epoch <span class="hljs-number"><span class="hljs-number">5</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0801</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.1181</span></span> Epoch <span class="hljs-number"><span class="hljs-number">6</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0684</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0821</span></span> Epoch <span class="hljs-number"><span class="hljs-number">7</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0591</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0762</span></span> Epoch <span class="hljs-number"><span class="hljs-number">8</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0526</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0655</span></span> Epoch <span class="hljs-number"><span class="hljs-number">9</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0475</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0662</span></span> Epoch <span class="hljs-number"><span class="hljs-number">10</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0444</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0469</span></span> Epoch <span class="hljs-number"><span class="hljs-number">11</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0408</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0478</span></span> Epoch <span class="hljs-number"><span class="hljs-number">12</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0381</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0498</span></span> Epoch <span class="hljs-number"><span class="hljs-number">13</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">54</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0356</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0363</span></span></code> </pre> <br>  والآن لنختبر النموذج على بيانات الاختبار: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">pred = model.predict([x_test[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], x_test[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]])</code> </pre> <br>  حدد وظيفة لحساب الدقة: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">compute_accuracy</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(predictions, labels)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> labels[predictions.ravel()</code> </pre> <br>  نحسب دقة: <br><br><pre style=";text-align:right;direction:rtl"> <code class="plaintext hljs">compute_accuracy(pred, y_test) 0.9779092702169625</code> </pre><br><h2 style=";text-align:right;direction:rtl">  النتائج </h2><br>  في هذا الدليل ، تعلمنا كيفية إنشاء نماذج للتعرف على الوجوه استنادًا إلى شبكات Siamese.  تتكون بنية هذه الشبكات من شبكتين عصبيتين متطابقتين لهما نفس الوزن والهيكل ، ويتم نقل نتائج عملها إلى وظيفة طاقة واحدة - وهذا يحدد هوية بيانات الإدخال.  لمزيد من المعلومات حول التعليم التلوي باستخدام <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">Python ،</a> راجع <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">التدريب العملي على Meta-Learning مع Python.</a> <br><br><h2 style=";text-align:right;direction:rtl">  تعليقي </h2><br>  مطلوب حاليا معرفة شبكات سيامي عند العمل مع الصور.  هناك العديد من الأساليب لشبكات التدريب في عينات صغيرة ، وتوليد البيانات الجديدة ، وطرق التعزيز.  تتيح هذه الطريقة "رخيصة" نسبيًا لتحقيق نتائج جيدة ، وإليك مثال كلاسيكي على شبكة سيامي على "Hello world" للشبكات العصبية - dataset <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">MNIST keras.io/examples/mnist_siamese</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/ar465279/">https://habr.com/ru/post/ar465279/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ar465269/index.html">تدريب Cisco 200-125 CCNA v3.0. يوم 26. DNS و DHCP</a></li>
<li><a href="../ar465271/index.html">قراصنة سرقة وغسل الأموال من خلال تقديم الطعام وخدمات حجز الفنادق.</a></li>
<li><a href="../ar465273/index.html">كيف يحمي مطورو البرامج Microgaming المستخدمين من الاختراقات</a></li>
<li><a href="../ar465275/index.html">أليس تحصل على مهارة</a></li>
<li><a href="../ar465277/index.html">تحليل وتحليل دلالات SEO: 5 قوالب مجانية لأوراق Google</a></li>
<li><a href="../ar465281/index.html">مراقبة الجلوكوز المستمرة (NMH) مع مضخة Medtronic 640g</a></li>
<li><a href="../ar465283/index.html">"هناك كل ما هو مطلوب ، ولا شيء يثير غضب" - الحقيقة تتحدث من خلال شفاه العميل</a></li>
<li><a href="../ar465285/index.html">كما كتبنا ، الواجهة الأمامية من لوحة تحكم الاستضافة الخاصة بنا: الإطار والخلفيات</a></li>
<li><a href="../ar465289/index.html">ملخص الأحداث لمحترفي الموارد البشرية في مجال تكنولوجيا المعلومات لشهر سبتمبر 2019</a></li>
<li><a href="../ar465291/index.html">الأقرب إلى الأرض: كيف غيرت العمل إلى منزل القرية</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
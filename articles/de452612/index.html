<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëü üê¶ ü¶ä Verst√§rktes maschinelles Lernen in tiefen neuronalen Netzen auf tensorflow.js: Tricks ü§±üèº üé£ üåè</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Es ist keine leichte Aufgabe, tiefe neuronale Netze von Grund auf zu trainieren. 

 Es braucht viel Daten und Zeit, um zu lernen, aber einige Tricks k...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Verst√§rktes maschinelles Lernen in tiefen neuronalen Netzen auf tensorflow.js: Tricks</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/452612/">  Es ist keine leichte Aufgabe, tiefe neuronale Netze von Grund auf zu trainieren. <br><br>  Es braucht viel Daten und Zeit, um zu lernen, aber einige Tricks k√∂nnen helfen, den Prozess zu beschleunigen, √ºber den ich unter dem Schnitt sprechen werde. <br><br>  Demonstration des Durchgangs eines einfachen Labyrinths mit Tricks.  Dauer des Netzwerktrainings: 1 Stunde 06 Minuten.  Aufnahme um das 8-fache beschleunigt. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/KbuNjZKidpw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br>  F√ºr jede Aufgabe m√ºssen Sie Ihre eigenen Tricks entwickeln, um das Lernen im Netzwerk zu beschleunigen.  Ich werde ein paar Tricks teilen, die mir geholfen haben, das Netzwerk viel schneller zu trainieren. <br><br>  Aus theoretischen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gr√ºnden</a> empfehle ich, auf den Kanal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sim0nsays</a> zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wechseln</a> . <br>  Und ich werde √ºber meine bescheidenen Erfolge beim Training neuronaler Netze berichten. <br><br><h2>  Erkl√§rung des Problems </h2><br>  <i>Ann√§herung der Konvergenzfunktion durch Minimierung der quadratischen Verlustfunktion durch R√ºckw√§rtsausbreitung von Fehlern durch tiefe neuronale Netze.</i> <br><br>  Ich hatte die Wahl, wie ich ein neuronales Netzwerk trainieren sollte. <br>  Ermutigen Sie zum erfolgreichen Abschluss der Aufgabe oder ermutigen Sie, wenn Sie sich dem Abschluss der Aufgabe n√§hern. <br><br>  Ich habe die zweite Methode aus zwei Gr√ºnden gew√§hlt: <br><br><ul><li>  Die Wahrscheinlichkeit, dass das Netzwerk jemals alleine die Ziellinie erreicht, ist sehr gering, so dass es zum Scheitern verurteilt ist, viel negative Verst√§rkung zu erhalten.  Dadurch werden die Gewichte aller Neuronen zur√ºckgesetzt, und das Netzwerk kann nicht weiter trainiert werden. <br></li><li>  Tiefe neuronale Netze sind m√§chtig.  Ich schlie√üe nicht aus, dass die erste Methode erfolgreich gewesen w√§re, wenn ich eine enorme Rechenleistung und viel Zeit f√ºr das Training gehabt h√§tte.  Ich bin den Weg der geringsten Kosten gegangen, indem ich Tricks entwickelt habe. <br></li></ul><br><h2>  Neuronale Netzwerkarchitektur </h2><br>  Architektur wird experimentell entwickelt, basierend auf der Erfahrung des Architekten und viel Gl√ºck. <br><br>  Architektur zur L√∂sung des Problems: <br><br><ul><li>  3 Eingangsneuronen - die Koordinaten des Agenten und der Wert der √ºbergebenen Zelle (wir normalisieren im Bereich von 0 bis 1). <br></li><li>  2 versteckte Schichten von 256 und 128 Neuronen (wir reduzieren die Dimension der Schichten in Richtung der Netzwerkausgabe). <br></li><li>  1 Schicht, die zuf√§llige Neuronen f√ºr das Lernnetzwerk f√ºr Nachhaltigkeit fallen l√§sst. <br></li><li>  4 Ausgangsneuronen - die Wahrscheinlichkeit, zu entscheiden, welche Seite f√ºr den n√§chsten Schritt ausgew√§hlt werden soll. <br></li><li>  Neuronaktivierungsfunktion: Sigmoid.  Optimierer: Adam. <br></li></ul><br>  Sigmoid gibt 4 Wahrscheinlichkeiten am Ausgang im Bereich von 0 bis 1 an, wobei die maximale ausgew√§hlt wird. Wir erhalten die Seite f√ºr den n√§chsten Schritt: [jumpTop, jumpRight, jumpBottom, jumpLeft]. <br><br><h2>  Architekturentwicklung </h2><br>  Eine Umschulung erfolgt bei Verwendung zu komplexer Modelle. <br><br>  Zu diesem Zeitpunkt erinnerte sich das Netzwerk an die Trainingsdaten und f√ºr neue Daten, die das Netzwerk noch nicht gesehen hat, funktioniert es schlecht, da das Netzwerk nicht nach Verallgemeinerungen suchen musste, da es √ºber gen√ºgend Speicher zum Speichern verf√ºgte. <br><br>  Mangel an Bildung - mit unzureichend komplexen Modellen.  Zu diesem Zeitpunkt verf√ºgte das Netzwerk nur √ºber wenige Trainingsdaten, um Verallgemeinerungen zu finden. <br><br>  <b>Fazit:</b> Je mehr Schichten und Neuronen sich in ihnen befinden, desto mehr Daten werden f√ºr das Training ben√∂tigt. <br><br><h2>  Spielfeld </h2><br><img src="https://habrastorage.org/webt/3n/we/ck/3nweckh5jsx0-pfebojf_yq3n3k.png"><br><br><h3>  Spielregel </h3><br>  0 - Beim Betreten dieser Zelle wird der Agent zerst√∂rt. <br>  1..44 - Zellen, deren Werte mit jedem Schritt zunehmen. <br>  Je weiter der Agent geht, desto mehr Belohnung erh√§lt er. <br>  45 - Fertig stellen.  Gleichzeitig findet kein Training statt, sondern nur, wenn alle Agenten zerst√∂rt sind, und das Ziel ist eine Ausnahme, bei der das bereits trainierte Netzwerk einfach f√ºr die n√§chste Vorhersage vom Beginn des Labyrinths an verwendet wird. <br><br><h2>  Beschreibung der Parameter </h2><br>  Der Agent hat eine "Antenne" in vier Richtungen - sie spielen die Rolle der Umweltintelligenz und beschreiben die Koordinaten des Agenten und den Wert der Zelle, auf der er steht. <br><br>  Die Beschreibung spielt die Rolle der Vorhersage der n√§chsten Richtung f√ºr die Bewegung des Agenten.  Das hei√üt, der Agent scannt voraus, was als n√§chstes kommt, und dementsprechend lernt das Netzwerk im Laufe der Zeit, sich in Richtung einer Erh√∂hung des Zellenwerts zu bewegen und die Grenzen der zul√§ssigen Bewegung nicht zu √ºberschreiten. <br><br>  <b>Der Zweck des neuronalen Netzwerks:</b> mehr Belohnungen zu erhalten. <br>  <b>Lernzweck:</b> Um korrekte Aktionen <b>zu</b> f√∂rdern, ist die Belohnung f√ºr das neuronale Netzwerk umso h√∂her, je n√§her der Agent an der L√∂sung der Aufgabe ist. <br><br><h2>  Tricks </h2><br>  Die ersten Versuche, ohne Tricks zu lernen, dauerten mehrere Stunden Training und das Ergebnis war bei weitem nicht vollst√§ndig.  Mit bestimmten Techniken wurde das Ergebnis in nur einer Stunde und sechs Minuten erzielt! <br><br><h3>  Agentenschleife </h3><br>  W√§hrend des Trainings begann das Netzwerk, Entscheidungen zu treffen, sich hin und her zu bewegen - das Problem der ‚ÄûNutzung‚Äú.  Beide Schritte geben dem Netzwerk eine positive Belohnung, die den Prozess der Erkundung des Labyrinths stoppte und es nicht erlaubte, das lokale Minimum zu verlassen. <br><br>  Der erste L√∂sungsversuch bestand darin, die Anzahl der Bewegungen des Agenten zu begrenzen. Dies war jedoch nicht optimal, da der Agent vor der Selbstzerst√∂rung viel Zeit in einer Schleife verbrachte.  Die beste L√∂sung bestand darin, den Agenten zu zerst√∂ren, wenn er mit einem niedrigeren Wert als dem, auf dem er stand, in die Zelle ging - das Verbot, in die entgegengesetzte Richtung zu gehen. <br><br><h3>  Forschung oder Verwendung </h3><br>  Ein einfacher Trick wurde verwendet, um die Pfade um die aktuelle Position des Agenten zu erkunden: Bei jedem Schritt werden 5 Agenten ‚Äûfreiwillige‚Äú Forscher sein.  Der Verlauf dieser Agenten wird zuf√§llig ausgew√§hlt und nicht die Vorhersage des neuronalen Netzwerks. <br><br>  Wir haben daher eine erh√∂hte Wahrscheinlichkeit, dass einer der f√ºnf Agenten weiter voranschreitet als die anderen und dabei hilft, das Netzwerk mit besseren Ergebnissen zu trainieren. <br><br><h3>  Genetischer Algorithmus </h3><br>  In jeder √Ñra nehmen 500 Agenten am Spielfeld teil.  Vorhersagen f√ºr alle Agenten werden im asynchronen Modus f√ºr alle Agenten gleichzeitig durchgef√ºhrt. Au√üerdem werden die Berechnungen an gpu delegiert.  Auf diese Weise k√∂nnen wir die Rechenleistung des Computers effizienter nutzen, was zu einer Verk√ºrzung der Zeit f√ºhrt, um ein neuronales Netzwerk f√ºr 500 Agenten gleichzeitig vorherzusagen. <br><br>  Die Vorhersage funktioniert schneller als das Training, sodass das Netzwerk mehr Chancen hat, sich mit der geringsten Zeit und dem besten Ergebnis weiter durch das Labyrinth zu bewegen. <br><br><h3>  Das Beste in der Generation lernen </h3><br>  W√§hrend der gesamten √Ñra bleiben f√ºr 500 Agenten die Ergebnisse ihres Fortschritts durch das Labyrinth erhalten.  Wenn der letzte Agent zerst√∂rt ist, werden die 5 besten Agenten aus 500 ausgew√§hlt - die das Labyrinth am weitesten erreicht haben. <br><br>  Basierend auf den besten Ergebnissen der √Ñra wird ein neuronales Netzwerk trainiert. <br><br>  Auf diese Weise reduzieren wir den Speicherbedarf, indem wir das Netzwerk nicht auf Agenten speichern und nicht trainieren, die das Netzwerk nicht weiterentwickeln. <br><br><h2>  Fertigstellung </h2><br>  Da ich kein Spezialist auf diesem Gebiet bin, habe ich es geschafft, einige Erfolge beim Training des neuronalen Netzwerks zu erzielen, und Sie werden Erfolg haben - machen Sie es! <br><br>  Bem√ºhen Sie sich, schneller als Computer zu lernen, w√§hrend wir es besser machen. <br><br><h3>  Material </h3><br>  <a href="">Repository mit Code</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Starten Sie das Browsertraining</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">In der Dokumentation zu tensorflow.js</a> finden Sie auch zus√§tzliche Ressourcen zum Lernen. <br><br><h3>  B√ºcher </h3><br><ul><li>  Tiefes Lernen.  Eintauchen in die Welt der neuronalen Netze <br>  S. Nikolenko, A. Kadurin, E. Arkhangelskaya <br></li><li>  Maschinelles Lernen und TensorFlow <br>  N. Shakla <br></li><li>  Selbstlernende Systeme <br>  S. I. Nikolenko, A. L. Tulupyev <br></li><li>  Verst√§rkungstraining <br>  R. S. Sutton, E. G. Barto <br></li><li>  Selbstorganisierende Karten <br>  T. Kohonen <br></li></ul><br><h2>  Vielen Dank f√ºr Ihre Aufmerksamkeit! </h2></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de452612/">https://habr.com/ru/post/de452612/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de452598/index.html">Management eines Programmierteams: Wie und wie kann man sie richtig motivieren? Teil eins</a></li>
<li><a href="../de452602/index.html">Cisco Hyperflex f√ºr Datenbankmanagementsysteme mit hoher Auslastung</a></li>
<li><a href="../de452606/index.html">UDB. Was ist das Teil 8. Adressierung von UDB</a></li>
<li><a href="../de452608/index.html">Teil 1. QInst: Es ist besser, einen Tag zu verlieren und dann in f√ºnf Minuten zu fliegen (Schreibger√§te sind trivial)</a></li>
<li><a href="../de452610/index.html">Hilfe und Bitte f√ºr sie. Artikel √ºber Informationssicherheit f√ºr normale Benutzer</a></li>
<li><a href="../de452614/index.html">So starten Sie die Programmierung in Adobe Illustrator. Teil zwei</a></li>
<li><a href="../de452618/index.html">Was auf Google I / O 2019 gesagt wurde: Android 10, AR-Anwendungen und vieles mehr</a></li>
<li><a href="../de452620/index.html">Ableiten eines Aktionstyps mithilfe von Typescript</a></li>
<li><a href="../de452622/index.html">Einf√ºhrung in die Genomik f√ºr Programmierer</a></li>
<li><a href="../de452624/index.html">Einf√ºhrung in Spring Boot Actuator</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
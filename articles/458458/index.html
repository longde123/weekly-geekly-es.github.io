<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôéüèø ü•ê üî° C√°maras de profundidad: revoluci√≥n silenciosa (cuando los robots lo ver√°n) Parte 2 üçø ü§∞üèæ üê¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En la primera parte de este texto, examinamos c√°maras de profundidad basadas en luz estructural y mediciones de retardo de luz de ida y vuelta, que ut...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√°maras de profundidad: revoluci√≥n silenciosa (cuando los robots lo ver√°n) Parte 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458458/"><img src="https://habrastorage.org/webt/uy/lx/0t/uylx0tpbzxlqa5hnxqzjnriruoy.png"><br><br>  En la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">primera parte de</a> este texto, examinamos c√°maras de profundidad basadas en luz estructural y mediciones de retardo de luz de ida y vuelta, que utilizan principalmente iluminaci√≥n infrarroja.  Funcionan muy bien en interiores a distancias de 10 cent√≠metros a 10 metros, y lo m√°s importante: son muy baratos.  De ah√≠ la ola masiva de su uso actual en tel√©fonos inteligentes.  Pero ... Tan pronto como salimos, el sol, incluso a trav√©s de las nubes, ilumina la luz infrarroja y su trabajo se deteriora bruscamente. <br><br>  Como dice Steve Blank (sin embargo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">por otra raz√≥n</a> ): "Si quieres tener √©xito, sal del edificio".  A continuaci√≥n hablaremos sobre c√°maras de profundidad que trabajan al aire libre.  Hoy este tema est√° fuertemente impulsado por los autom√≥viles aut√≥nomos, pero, como veremos, no solo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/659/8b4/4b2/6598b44b2d0a420dd83a434753cc6ffb.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Innoviz prev√© autos aut√≥nomos producidos en masa con LiDAR de estado s√≥lido</a></i> <br><br>  Entonces, c√°maras de profundidad, es decir  dispositivos que graban video, en cada p√≠xel de los cuales la distancia al objeto de la escena, ¬°funcionan a la luz del sol! <br><br>  ¬øA qui√©n le importa? ¬°Bienvenido a Kat! <br><a name="habracut"></a><br>  Comencemos con los cl√°sicos atemporales ... <br><br><h1>  M√©todo 3: Profundidad de la c√°mara est√©reo + </h1><br>  La construcci√≥n de un mapa de profundidad desde est√©reo es bien conocida y se ha utilizado durante <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">m√°s de 40 a√±os</a> .  A continuaci√≥n se muestra un ejemplo de una c√°mara compacta por $ 450, que se puede utilizar para controlar los gestos, junto con la fotograf√≠a profesional o con cascos de realidad virtual: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/594/0ab/3b0/5940ab3b0cbc72369d80083d8d32be57.png"><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Fuente</a></i> <br><br>  La principal ventaja de estas c√°maras es que la luz solar no solo no las molesta, sino que viceversa, mejora sus resultados y, como resultado, el uso activo de tales c√°maras para todo tipo de casos en la calle, por ejemplo, es un gran ejemplo de c√≥mo disparar un modelo tridimensional de un antiguo fuerte en un par de minutos: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/AFH2yN3rM78" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Un ejemplo del uso en la calle de la c√°mara ZED</a></i> <br><br>  El dinero notable en la traducci√≥n de la construcci√≥n de la profundidad del est√©reo a un nuevo nivel fue influenciado, por supuesto, por el tema de los autom√≥viles aut√≥nomos.  De los 5 m√©todos considerados para construir un video de profundidad, solo dos: este y el siguiente (est√©reo y ple√≥ptico) no interfieren con el sol y no interfieren con los autom√≥viles vecinos.  Al mismo tiempo, los ple√≥pticos son muchas veces m√°s caros y menos precisos a largas distancias.  De todos modos, las cosas pueden suceder de todos modos; es dif√≠cil hacer pron√≥sticos, pero en este caso vale la pena estar de acuerdo con Elon Mask: el est√©reo de los 5 m√©todos tiene las mejores perspectivas.  Y los resultados actuales son muy alentadores: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/12e/cec/e3f/12ecece3f83fc654f64023e1391c38bb.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SLAM directo a gran escala con c√°maras est√©reo</a></i> <br><br>  Pero es interesante que parezca que no los veh√≠culos no tripulados (de los cuales pocos se han producido hasta ahora), sino dispositivos mucho m√°s masivos, donde se est√° construyendo un mapa de profundidad est√©reo ahora, tendr√°n una influencia a√∫n m√°s fuerte en el desarrollo de la profundidad de construcci√≥n desde est√©reo, es decir ... ¬°Eso es correcto!  Smartphones! <br><br>  Hace tres a√±os, simplemente se produjo el auge de los tel√©fonos inteligentes "de dos ojos", en los que se notaron pr√°cticamente todas las marcas, porque la calidad de las fotos tomadas con una c√°mara y la calidad de las fotos tomadas con dos difer√≠an dr√°sticamente, pero desde el punto de vista de aumentar el precio de un tel√©fono inteligente esto no fue tan significativo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ab7/6b4/b3e/ab76b4b3e9696443e5191d293b59e663.png"><br><br>  Adem√°s, el a√±o pasado el proceso fue a√∫n m√°s lejos: "¬øTiene 2 c√°maras en su tel√©fono inteligente?  Apesta  Tengo <s>tres</s> cuatro !!! ": <br><br><img src="https://habrastorage.org/getpro/habr/post_images/48f/905/554/48f905554fab15bcc6ce668c0c5f9ef7.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Samsung Galaxy A8 y A9</a></i> <br><br>  El futuro Sony de seis ojos fue mencionado en la primera parte.  En general, los tel√©fonos inteligentes con m√∫ltiples ojos est√°n ganando bastante popularidad entre los fabricantes. <br><br>  Las causas fundamentales de este fen√≥meno son simples: <br><br><ul><li>  La resoluci√≥n de los tel√©fonos con c√°mara est√° creciendo y el tama√±o de la lente es peque√±o.  Como resultado, a pesar de numerosos trucos, el nivel de ruido aumenta y la calidad disminuye, especialmente cuando se dispara en la oscuridad. <br></li><li>  Adem√°s, en la segunda c√°mara, podemos eliminar el llamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">filtro Bayer</a> de la matriz, es decir.  una c√°mara ser√° en blanco y negro, y el segundo color.  Esto aumenta la sensibilidad en blanco y negro en aproximadamente 3 veces.  Es decir  la sensibilidad de 2 c√°maras crece condicionalmente no 2, sino 4 veces (!).  Existen numerosos matices, pero tal aumento en la sensibilidad es realmente claramente visible a simple vista. <br></li><li>  Entre otras cosas, cuando aparece un par est√©reo, tenemos la oportunidad de cambiar program√°ticamente la profundidad de campo, es decir.  difumina el fondo, del cual muchas fotos se benefician significativamente (escribimos sobre esto en la segunda mitad <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> ).  Esta opci√≥n de nuevos modelos de tel√©fonos inteligentes se hizo r√°pidamente muy popular. <br></li><li>  Con un aumento en la cantidad de c√°maras, tambi√©n es posible usar otras lentes: m√°s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">gran angular</a> (enfoque corto) y, por el contrario, enfoque largo, lo que puede mejorar significativamente la calidad al "acercarse" a objetos. <br></li><li>  Curiosamente, un aumento en el n√∫mero de c√°maras nos acerca al tema de un campo de luz enrarecido, que tiene muchas de sus caracter√≠sticas y ventajas, sin embargo, esta es una historia diferente. <br></li><li>  Tambi√©n observamos que aumentar el n√∫mero de c√°maras le permite aumentar la resoluci√≥n mediante m√©todos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">recuperaci√≥n de resoluci√≥n</a> . <br></li></ul><br>  En general, hay tantas ventajas que, cuando las personas los conocen, comienzan a preguntarse por qu√© no se han configurado al menos 2 c√°maras durante mucho tiempo. <br><br>  Y luego resulta que no todo es tan simple.  Para utilizar significativamente c√°maras adicionales para mejorar la imagen (y no solo cambiar a una c√°mara con una lente diferente), estamos obligados a construir un llamado mapa de disparidad, que se convierte directamente en un mapa de profundidad.  Y esta es una tarea muy trivial, a cuya soluci√≥n acaba de llegar el poder de los tel√©fonos inteligentes.  E incluso ahora, los mapas de profundidad son a menudo de una calidad bastante dudosa.  Es decir, antes de que la coincidencia exacta "p√≠xel en la imagen de la derecha con el p√≠xel de la izquierda" todav√≠a necesite sobrevivir.  Por ejemplo, aqu√≠ hay ejemplos reales de mapas de profundidad para iPhone: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/221/1f2/7d2/2211f27d2bfb2dc01da93559e8d1d8d1.png"><br>  <i>Fuente: <a href="">Comparaci√≥n de mapas de profundidad de iPhone XS y XR</a></i> <br><br>  Incluso a simple vista, los problemas de masas son claramente visibles en el fondo, en los bordes, no digo nada sobre el cabello <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">transl√∫cido</a> .  Por lo tanto, existen numerosos problemas que surgen tanto al transferir el color de una c√°mara en blanco y negro a una de color como durante el procesamiento posterior. <br><br>  Por ejemplo, aqu√≠ hay un buen ejemplo de un informe sobre "Creaci√≥n de efectos de fotos y videos usando la profundidad" de Apple: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/83c/38f/efc/83c38fefc85d9e1ddef931b594e20469.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Creaci√≥n de efectos de foto y video ‚Ä¢ Uso de profundidad, Apple, WWDC18</a></i> <br><br>  Puede ver claramente c√≥mo la profundidad tiene errores debajo del cabello y, de hecho, contra un fondo m√°s o menos uniforme, pero lo que es m√°s importante, en el mapa de alfombrilla derecho el collar qued√≥ en el fondo (es decir, estar√° borroso).  Otro problema es la resoluci√≥n real de la profundidad y el mapa mate es significativamente menor que la resoluci√≥n de la imagen, lo que tambi√©n afecta la calidad durante el procesamiento: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/848/dcb/5cf/848dcb5cf62ea5991a85b23160fc1ce9.png"><br><br>  Sin embargo, todo esto es un problema de crecimiento.  Si hace 4 a√±os no hab√≠a dudas sobre los efectos graves en el video, el tel√©fono simplemente "no los tir√≥", pero hoy el procesamiento de video con profundidad se muestra en los principales tel√©fonos seriales (fue en la misma presentaci√≥n de Apple): <br><br><img width="25%" src="https://habrastorage.org/getpro/habr/post_images/481/5fe/6f8/4815fe6f8f9e7fd837a4e410df01a0da.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Creaci√≥n de efectos de foto y video ‚Ä¢ Uso de profundidad, Apple, WWDC18</a></i> <br><br>  En general, el tema de los tel√©fonos multi-multi-celulares y, como resultado, el tema de obtener profundidad del est√©reo en los tel√©fonos m√≥viles, conquista a las masas sin luchar: <br><br><img width="66%" src="https://habrastorage.org/webt/t2/ba/sz/t2basz3pj6tskae0fqox5ol3x-q.png"><br>  <i>Fuente: "encontrado en estos de su internet"</i> <br><br>  Hallazgos clave: <br><br><ul><li>  La profundidad del est√©reo, en t√©rminos del costo del equipo, es la forma m√°s econ√≥mica de obtener profundidad, ya que las c√°maras ahora son econ√≥micas y contin√∫an haci√©ndose m√°s baratas r√°pidamente.  La dificultad es que el procesamiento adicional requiere muchos m√°s recursos que otros m√©todos. <br></li><li>  En los tel√©fonos m√≥viles no puede aumentar el di√°metro de la lente, mientras que la resoluci√≥n crece r√°pidamente.  Como resultado, el uso de dos o m√°s c√°maras puede mejorar significativamente la calidad de la foto, reducir el ruido en condiciones de poca luz y aumentar la resoluci√≥n.  Dado que hoy en d√≠a se elige un tel√©fono m√≥vil por la calidad de la c√°mara, esta es una ventaja extremadamente tangible.  La construcci√≥n de un mapa de profundidad es una ventaja adicional discreta. <br></li><li>  Las principales desventajas de construir profundidad desde est√©reo: <br><ul><li>  Tan pronto como la textura desaparece o simplemente se vuelve menos contrastante, el ruido aumenta bruscamente en profundidad, como resultado, incluso en objetos planos, la profundidad a menudo se usa de manera deficiente (son posibles errores graves). <br></li><li>  Adem√°s, la profundidad est√° mal determinada en objetos delgados y peque√±os (dedos "cortados", o incluso manos, columnas hundidas, etc.) <br></li></ul></li><li>  Tan pronto como el poder del hierro le permita construir un mapa de profundidad para video, la profundidad en los tel√©fonos inteligentes dar√° un poderoso impulso al desarrollo de AR (en alg√∫n momento, completamente inesperado para el p√∫blico, la calidad de las aplicaciones de AR en todos los nuevos modelos de tel√©fonos, incluidos los econ√≥micos, de repente se volver√° notablemente m√°s alta y una nueva ola ir√°) .  Totalmente inesperado! <br></li></ul><br>  El siguiente m√©todo es menos trivial y famoso, pero muy bueno.  Conoceme <br><br><h1>  M√©todo 4: c√°maras de profundidad de campo claro </h1><br>  El tema de los ple√≥pticos (del lat√≠n plenus - full y optikos - visual) o campos ligeros todav√≠a es relativamente poco conocido por las masas, aunque los profesionales comenzaron a tratarlo muy densamente.  Se asignaron secciones separadas para art√≠culos sobre Light Field en muchas de las principales conferencias (el autor se sorprendi√≥ una vez por el n√∫mero de investigadores asi√°ticos en la Conferencia Internacional de IEEE sobre Multimedia y Expo que est√°n estrechamente involucrados en este tema). <br><br>  Google Trends dice que Estados Unidos y Australia lideran en inter√©s en Light Field, seguidos de Singapur y Corea.  Gran breta√±a  Rusia est√° en el lugar 32 ... Vamos a corregir el retraso de la India y Sud√°frica: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/651/993/87b/65199387b858541acc6ff99a129c2fe3.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tendencias de Google</a></i> <br><br>  Su humilde servidor hace alg√∫n tiempo hizo un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo detallado sobre Habr√©</a> con una descripci√≥n detallada de c√≥mo funciona y qu√© ofrece, as√≠ que repasemos brevemente. <br><br>  La idea principal es tratar de arreglar en cada punto no solo la luz, sino una matriz bidimensional de rayos de luz, haciendo que cada cuadro sea tetradimensional.  En la pr√°ctica, esto se hace usando una variedad de microlentes: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/90f/203/fb4/90f203fb49d7e464638a4f164e96fb26.gif"></a> <br>  <i>Fuente: <a href="">plenoptic.inf¬Æ (se recomienda hacer clic y ver en resoluci√≥n completa)</a></i> <br><br>  Como resultado, tenemos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">muchas nuevas oportunidades</a> , pero la resoluci√≥n est√° cayendo seriamente.  Despu√©s de resolver muchos problemas t√©cnicos complicados, aumentaron radicalmente la resoluci√≥n en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lytro</a> (comprado por Google), donde en Lytro Cinema la resoluci√≥n del sensor de la c√°mara se increment√≥ a 755 megap√≠xeles de datos RAW, y se ve√≠a voluminosa como las primeras c√°maras: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3ec/631/027/3ec6310271829f9272a4d3ef41462bde.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">NAB: se presenta la nueva c√°mara Lytro Light-Field que podr√≠a traer grandes cambios al trabajo de efectos visuales</a></i> <br><br>  Es interesante que incluso los profesionales eval√∫en incorrectamente con regularidad la ca√≠da de resoluci√≥n de las c√°maras ple√≥pticas, porque subestiman lo bien que pueden trabajar en algoritmos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Super Resoluci√≥n</a> que realmente restauran perfectamente muchos detalles de los micro-cambios de la imagen en el campo de luz (preste atenci√≥n a agujas de tejer borrosas y movimientos de fondo en movimiento) : <br><br><img width="200%" src="https://habrastorage.org/getpro/habr/post_images/bc9/6cd/e55/bc96cde55e276f4420757de5359467b1.gif"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Restauraci√≥n de cuadros ple√≥pticos ingenuos, inteligentes y de s√∫per resoluci√≥n</a> del Informe t√©cnico de Adobe "Superresoluci√≥n con c√°mara plenoptic 2.0"</i> <br><br>  Todo esto ser√≠a de inter√©s relativamente te√≥rico si Google no hubiera implementado los ple√≥pticos en Pixel 2 al <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cubrir 2 p√≠xeles con una lente</a> : <br><br><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/852/c36/209/852c36209a7528f576e20dc37e0ef1f3.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AI Google Blog</a></i> <br><br>  Como resultado, se form√≥ un micro estereopar, que permiti√≥ MEDIR la profundidad a la que Google, fiel a las nuevas tradiciones, agreg√≥ redes neuronales, y en general result√≥ notablemente: <br><br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/429/442/99e/42944299e72b7eb720f3babc5a757b79.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/da3/fe1/3ea/da3fe13eacb3cd5b0a558db1d843b686.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/c6f/a27/c4b/c6fa27c4bac8b9c5cb122e0c69ab814d.png"><br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/2ba/e97/e67/2bae97e67ae10cd150ef28ccdc6cc458.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/88a/159/34f/88a15934f1192deb0da889a630fed232.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/d7d/eab/811/d7deab81164e7e886b42a95173c58641.png"><br><br>  M√°s ejemplos de profundidad en resoluci√≥n completa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en una galer√≠a especial</a> . <br><br>  Curiosamente, la profundidad es almacenada por Google (como Huawei y otros) en la imagen misma, por lo que puede extraerla desde all√≠ y ver: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d63/958/b09/d63958b09a9584752a90f014adfadc24.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tres caracter√≠sticas secretas de la nueva aplicaci√≥n de c√°mara de Google que te dejar√°n boquiabierto</a></i> <br><br>  Y luego puedes convertir la foto en tridimensional: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/48b/3a5/e71/48b3a5e7156a14dcf60c600472154f6c.gif"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tres caracter√≠sticas secretas de la nueva aplicaci√≥n de c√°mara de Google que te dejar√°n boquiabierto</a></i> <br><br>  Puedes experimentar de forma independiente con esto en el sitio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://depthy.me</a> , donde puedes subir tu foto.  Curiosamente, el sitio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">est√° disponible en la fuente</a> , es decir  el procesamiento en profundidad se puede mejorar, hay muchas oportunidades para esto, ahora los algoritmos de procesamiento m√°s simples se aplican all√≠. <br><br>  Puntos clave: <br><br><ul><li>  En una de las conferencias de Google, se anunci√≥ que, quiz√°s, 4 p√≠xeles se cubrir√≠an con una lente.  Esto reducir√° la resoluci√≥n directa del sensor, pero mejorar√° dr√°sticamente el mapa de profundidad.  En primer lugar, debido a la aparici√≥n de pares est√©reo en dos direcciones perpendiculares, y en segundo lugar, debido al hecho de que la base est√©reo aumentar√° condicionalmente en 1,4 veces (dos diagonales).  Esto tambi√©n significa una mejora notable en la precisi√≥n de profundidad a distancia. <br></li><li>  Plenoptics en s√≠ (tambi√©n es una fotograf√≠a calculada) hace posible: <br><ul><li>  El cambio "honesto" de enfoque y profundidad de campo despu√©s del disparo es la capacidad m√°s conocida de los sensores ple√≥pticos. <br></li><li>  Calcular la forma de apertura. <br></li><li>  Calcule la iluminaci√≥n de la escena. <br></li><li>  Cambie un poco el punto de disparo, incluida la recepci√≥n de est√©reo (o marco de m√∫ltiples √°ngulos) con una lente. <br></li><li>  Calcule la resoluci√≥n, porque utilizando la gran complejidad computacional de los algoritmos de Super Resoluci√≥n, en realidad puede restaurar el marco. <br></li><li>  Calcular un mapa de transparencia para bordes transl√∫cidos. <br></li><li>  Y finalmente, construya un mapa de profundidad, que es importante hoy. <br></li></ul></li><li>  Potencialmente, <b>cuando la c√°mara principal del tel√©fono puede construir un mapa de profundidad de alta calidad en tiempo real en paralelo con el disparo, esto crear√° una revoluci√≥n</b> .  Esto depende en gran medida de la potencia inform√°tica a bordo (esto es lo que nos impide hacer mapas de profundidad mejores y de mayor resoluci√≥n en tiempo real hoy).  Esto es muy interesante para AR, por supuesto, pero habr√° muchas oportunidades para cambiar las fotos. <br></li></ul><br>  Y finalmente, pasamos al √∫ltimo en este m√©todo de revisi√≥n para medir la profundidad. <br><br><h1>  M√©todo 5: c√°maras en tecnolog√≠as LIDAR </h1><br>  En general, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">los tel√©metros l√°ser est√°n</a> firmemente arraigados en nuestras vidas, son econ√≥micos y proporcionan una alta precisi√≥n.  Los primeros lidares (de LIDaR - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Light Identification Detection and Ranging</a> ), construidos como paquetes de dispositivos similares que giran alrededor de un eje horizontal, fueron utilizados por primera vez por los militares, luego fueron probados en pilotos autom√°ticos de autom√≥viles.  Result√≥ ser bastante bueno all√≠, lo que provoc√≥ un fuerte aumento de la inversi√≥n en la regi√≥n.  Inicialmente, los lidares giraron, dando una imagen similar varias veces por segundo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ed4/984/265/ed49842653721c8d7e6dae51c290166d.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Introducci√≥n a LIDAR: el sensor clave del autom√≥vil aut√≥nomo</a></i> <br><br>  Era inc√≥modo, poco confiable debido a las partes m√≥viles y bastante costoso.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tony Ceba</a> en sus conferencias proporciona datos interesantes sobre la tasa de disminuci√≥n en el costo de los lidares.  Si los lidares cuestan $ 70 mil para las primeras m√°quinas aut√≥nomas de Google (por ejemplo, el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">HDL-64E especializado</a> utilizado en las primeras m√°quinas cuesta 75 mil): <br><img src="https://habrastorage.org/webt/w7/n4/4x/w7n44xwcg5gmcyi8v_dxc-yefd4.png"><br>  <i>Fuente: Esto y lo siguiente del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">estacionamiento a los parques: Bellevue y la interrupci√≥n del transporte</a></i> <br><br>  Luego, en la producci√≥n en masa, los nuevos modelos de las pr√≥ximas generaciones amenazan con reducir el precio significativamente menos de $ 1000: <br><img src="https://habrastorage.org/getpro/habr/post_images/178/fb1/712/178fb1712f85c4534ff25d11e54ad098.png"><br><br>  Uno puede discutir sobre el ejemplo de Tony (la promesa de una startup no es el costo final), pero que hay un auge en la investigaci√≥n en esta √°rea, el r√°pido aumento en las corridas de producci√≥n, la aparici√≥n de productos completamente nuevos y una disminuci√≥n general en los precios son indiscutibles.  Un poco m√°s tarde en 2017, el pron√≥stico para una ca√≠da en los precios fue el siguiente (y el momento de la verdad llegar√° cuando se los ponga en los autos): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d75/c6c/5b0/d75c6c5b04e509f698a5d967776ff68c.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LiDAR completa la detecci√≥n del triunvirato</a></i> <br><br>  En particular, relativamente recientemente, varios fabricantes lanzaron de inmediato el llamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lidar de estado s√≥lido</a> , que b√°sicamente no tiene partes m√≥viles que muestren una confiabilidad radicalmente m√°s alta, especialmente cuando se sacude, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cuesta menos</a> , etc.  Recomiendo ver este video, donde su dispositivo se explica en 84 segundos con mucha claridad: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/yQi7J0ehKAA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Sensor Lidar de estado s√≥lido</a></i> <br><br>  Lo importante para nosotros es que Lidar de estado s√≥lido da una imagen rectangular, es decir  de hecho, comienza a funcionar como una c√°mara de profundidad "normal": <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1f6/90e/e65/1f690ee65f60f431037d6c9191896005.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Innoviz prev√© autos aut√≥nomos producidos en masa con LiDAR de estado s√≥lido</a></i> <br><br>  El ejemplo anterior ofrece un video de aproximadamente 1024x256, 25 FPS, 12 bits por componente.  Dichos lidares se montar√°n debajo de la parrilla de la campana (ya que el dispositivo se calienta bien) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18b/8dc/a13/18b8dca13a096a2337ad38b5728b26ea.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LiDAR Magna Electronics de estado s√≥lido</a></i> <br><br>  Como de costumbre, los chinos est√°n encendidos, quienes est√°n hoy en primer lugar en el mundo en la producci√≥n de veh√≠culos el√©ctricos y claramente apuntan al primer lugar en el mundo en autos aut√≥nomos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c59/b26/b00/c59b26b009b05ce5a872f3203c720a3d.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Alibaba, RoboSense lanza veh√≠culo no tripulado utilizando LIDAR de estado s√≥lido</a></i> <br><br>  En particular, sus experimentos con un "p√≠xel" de profundidad no cuadrado son interesantes, si realiza un procesamiento conjunto con una c√°mara RGB, puede aumentar la resoluci√≥n y esto es un compromiso bastante interesante (el "cuadrado" de p√≠xeles es importante, de hecho, solo para una persona): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7e9/13f/af2/7e913faf27197e1b893b56f13873e1d6.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MEMS Lidar para veh√≠culos sin conductor da otro gran paso</a></i> <br><br>  Los lidares se montan en diferentes esquemas dependiendo del costo del kit y la potencia del sistema de a bordo, que necesitar√° procesar todos estos datos.  En consecuencia, las caracter√≠sticas generales del piloto autom√°tico tambi√©n cambian.  Como resultado, los autos m√°s caros estar√°n mejor transportando carreteras polvorientas y m√°s f√°ciles de "esquivar" los autos que ingresan a los autos en las intersecciones laterales, los baratos solo ayudar√°n a reducir la cantidad de (numerosos) embotellamientos est√∫pidos: <br><br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/00d/dd1/d4e/00ddd1d4e9f980216796306e4a62fe2e.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/025/548/1df/0255481dfb9f5dcd102a9a5979ca2fb8.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/7bf/842/4bf/7bf8424bf82edc861dc15434a03bfcbe.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Descripci√≥n RoboSense RS-LiDAR-M1</a></i> <br><br>  Tenga en cuenta que, adem√°s de los bajos precios en estado s√≥lido, prometen un par de √°reas m√°s en las que se est√°n desarrollando los lidars.  Predecir algo aqu√≠ es una tarea ingrata, ya que demasiado depender√° no de las caracter√≠sticas potenciales de ingenier√≠a de la tecnolog√≠a, sino, por ejemplo, de las patentes.  Es solo que varias compa√±√≠as ya est√°n involucradas en estado s√≥lido, por lo que el tema parece m√°s prometedor.  Pero no decir nada sobre el resto ser√≠a injusto: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3f9/3aa/265/3f93aa2653a9dde4393c007b925d07a2.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Este cuello de botella LiDAR 2017 est√° causando una fiebre del oro moderna</a></i> <br><br>  Si hablamos de lidars como c√°maras, vale la pena mencionar otra caracter√≠stica importante que es importante cuando se usan lidars de estado s√≥lido.  Por su naturaleza, funcionan como c√°maras con un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">obturador en</a> movimiento ya olvidado, que introduce distorsiones notables al disparar objetos en movimiento: <br><br><img width="66%" src="https://habrastorage.org/getpro/habr/post_images/b83/2e7/2a8/b832e72a8f8c67c65401da694df03c8e.gif"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">¬øCu√°l es la diferencia entre una persiana global (global) y una persiana enrollable</a> ?</i> <br><br>  Dado que en la carretera, especialmente en la autopista a una velocidad de 150 km / h, todo cambia bastante r√°pido, esta caracter√≠stica de los lidars distorsionar√° en gran medida los objetos, incluidos los que vuelan r√°pidamente hacia nosotros ... Incluyendo en profundidad ... Tenga en cuenta que los dos m√©todos anteriores obtener profundidad no es tal problema. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9b9/15b/979/9b915b9799869f23dcf7b2b3e1f5f1ca.gif"><br>  <i>Fuente: <a href="">bonita animaci√≥n de Wikipedia que muestra la distorsi√≥n del autom√≥vil</a></i> <br><br>  ,    FPS    ,       ,           . <br><br> ,               ,  -         .  ,     FPS,    .        ,        Lytro Cinema (     ‚Äî   ,   300 FPS,     <s></s> ): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c1/eb9/ede/5c1eb9edeca7d67133487e93290435cd.png"><br> <i>: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lytro poised to forever change filmmaking: debuts Cinema prototype and short film at NAB</a></i> <br><br>        ,     (   )      ,   . <br><br>  -   ‚Äî    ,        1.5   (     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">10   6 </a>      ,     ): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e07/fd6/3ae/e07fd63aee838e9a5c8958b0527ac4e9.png"><br> <i>: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">        Techcrunch</a></i> <br><br>         ‚Äî 1.5-2 ,        .      . <br><br>  : <br><br><ul><li>  : <br><ul><li>   ,          , <br></li><li>      ,     , <br></li><li>    , <br></li></ul></li><li>  : <br><ul><li>  , <br></li><li>    , <br></li><li> el obturador en funcionamiento y la necesidad de compensarlo durante el procesamiento, <br></li><li>  los lidares cercanos interfieren entre s√≠, lo que no es tan f√°cil de compensar. <br></li></ul></li><li>  Sin embargo, estamos observando c√≥mo, literalmente en 2 a√±os, esencialmente ha aparecido un nuevo tipo de c√°maras de profundidad con excelentes perspectivas y un enorme mercado potencial.  En los pr√≥ximos a√±os, podemos esperar una seria reducci√≥n en los precios, incluida la aparici√≥n de peque√±os lidares universales para robots industriales. <br></li></ul><br><h1>  Procesamiento de video con profundidad </h1><br>  En pocas palabras, considere por qu√© la profundidad no es tan f√°cil de manejar. <br><br>  A continuaci√≥n se muestra un ejemplo de datos sin procesar en profundidad de una muy buena l√≠nea de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">c√°maras Intel RealSense</a> .  En los dedos de este video, puede evaluar relativamente f√°cilmente "a simple vista" el funcionamiento de la c√°mara y los algoritmos de procesamiento: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6b2/319/b14/6b2319b143f48bdf0c57ffbe2acbc891.png"><br>  <i>Fuente: en adelante - los materiales del autor</i> <br><br>  Los problemas t√≠picos de las c√°maras de profundidad son claramente visibles: <br><br><ul><li>  El valor de los datos es inestable, los p√≠xeles "ruido" en profundidad. <br></li><li>  A lo largo de los l√≠mites en un ancho bastante grande, los datos tambi√©n son muy ruidosos (por esta misma raz√≥n, los valores de profundidad a lo largo de los bordes a menudo simplemente se enmascaran para no interferir con el trabajo). <br></li><li>  Alrededor de la cabeza se pueden ver muchos p√≠xeles de "caminar" (aparentemente, la proximidad a la pared en la parte posterior + cabello comienza a influir). <br></li></ul><br>  Pero eso no es todo.  Si miramos los datos m√°s de cerca, est√° claro que en algunos lugares los datos m√°s profundos "brillan" a los m√°s cercanos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a30/c5a/911/a30c5a911123f7a8f6ff8ebd8893163a.png"><br><br>  Esto se debe a que, para la conveniencia del procesamiento, la imagen se reduce a la imagen de la c√°mara RGB, y dado que los l√≠mites no se determinan con precisi√≥n, se hace necesario procesar especialmente tales "superposiciones", de lo contrario surgen problemas, tales como "agujeros" en profundidad en el brazo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/22f/1a3/5df/22f1a35dfdb61edcabe8a1675f5c855f.png"><br><br>  Al procesar, hay muchos problemas, por ejemplo: <br><br><ul><li>  "Fuga" de profundidad de un objeto a otro. <br></li><li>  Inestabilidad de la profundidad en el tiempo. <br></li><li>  Aliasing (la formaci√≥n de una "escalera"), cuando la supresi√≥n del ruido en profundidad conduce a la discretizaci√≥n de los valores de profundidad: <br></li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/e3d/7a4/c10/e3d7a4c10e13824f1d79815661e17773.png"><br><br>  Sin embargo, est√° claro que la imagen ha mejorado mucho.  Tenga en cuenta que los algoritmos m√°s lentos a√∫n pueden mejorar significativamente la calidad. <br><br>  En general, el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">procesamiento de video en profundidad</a> es un gran tema separado, que hasta ahora no est√° involucrado en tanta gente, pero que est√° ganando popularidad r√°pidamente.  El mercado anterior, que cambi√≥ por completo, es la conversi√≥n de pel√≠culas de 2D a 3D.  El resultado de la construcci√≥n manual de est√©reo a partir de video 2D mejor√≥ tan r√°pidamente, mostr√≥ un resultado mucho m√°s predecible, caus√≥ menos dolor de cabeza y menos costo que en el cine 3D, despu√©s de casi 100 a√±os de filmaci√≥n (!), Bastante r√°pidamente dejaron de filmar casi por completo y comenzaron a convertir solo .  Incluso hab√≠a una especialidad separada: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">artista de profundidad</a> , y los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">estere√≥grafos de</a> la vieja escuela estaban en estado de shock ("ka-ak-a-ak?").  Y el papel clave en esta revoluci√≥n fue jugado por la r√°pida mejora de los algoritmos de procesamiento de video.  Quiz√°s alg√∫n d√≠a encuentre tiempo para escribir sobre esto una serie separada de art√≠culos, porque mi material est√° en grandes cantidades. <br><br>  Se puede esperar casi lo mismo en el futuro cercano para c√°maras de profundidad de robots, tel√©fonos inteligentes y autom√≥viles aut√≥nomos. <br><br>  <b>¬°Despierta!</b>  <b>La revoluci√≥n se acerca!</b> <br><br><h1>  En lugar de una conclusi√≥n </h1><br>  Hace un par de a√±os, su humilde servidor trajo una comparaci√≥n de diferentes enfoques para obtener videos con profundidad en una sola placa.  En general, durante este tiempo la situaci√≥n no ha cambiado.  La separaci√≥n aqu√≠ es bastante arbitraria, ya que los fabricantes son conscientes de las desventajas de las tecnolog√≠as y tratan de compensarlas (a veces de manera extremadamente exitosa).  Sin embargo, en general, se puede utilizar para comparar diferentes enfoques: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/34d/491/11f/34d49111ff8005f743a89d9078864f1b.png"><br>  <i>Fuente: materiales del autor.</i> <br><br>  Repasemos la mesa: <br><br><ul><li>  <b>Por resoluci√≥n, la</b> profundidad del est√©reo est√° a la cabeza, pero todo depende mucho de la escena (si es monof√≥nico, la cosa es una tuber√≠a). <br></li><li>  <b>En t√©rminos de precisi√≥n</b> , los lidares est√°n m√°s all√° de la competencia, la situaci√≥n con los ple√≥pticos es la peor, por cierto. <br></li><li>  <b>Por la complejidad del procesamiento</b> , solo ToF y lidars obtienen la "profundidad" directamente, obtener profundidad de est√©reo y ple√≥pticos requiere muchos c√°lculos muy no triviales. <br></li><li>  <b>Seg√∫n FPS,</b> las c√°maras ToF son estructuralmente buenas y en el futuro cercano, cuando se levante la plancha, se ver√°n atrapadas con c√°maras est√©reo (capaces de entregar hasta 300 fps).  Lidaram hasta ahora solo sue√±a. <br></li><li>  <b>Seg√∫n los resultados en condiciones de poca luz,</b> se espera que el est√©reo y los ple√≥pticos pierdan. <br></li><li>  <b>Cuando trabaje al aire libre</b> : las c√°maras ToF y de luz estructurada no funcionan bien. <br></li></ul><br>  Al mismo tiempo, es importante comprender bien la situaci√≥n en mercados espec√≠ficos.  Por ejemplo, el enfoque ple√≥ptico parece claramente rezagado.  Sin embargo, si resulta ser el mejor para AR (y esto quedar√° claro en los pr√≥ximos 3-4 a√±os), ocupar√° el lugar que le corresponde en <i>cada</i> tel√©fono y tableta.  Tambi√©n se ve que los lidares de estado s√≥lido se ven mejor (los "m√°s verdes"), pero esta es la tecnolog√≠a m√°s joven, y estos son sus propios riesgos, principalmente los patentes (en el campo hay una gran cantidad de patentes nuevas que no caducar√°n pronto): <br><img src="https://habrastorage.org/getpro/habr/post_images/94e/905/f90/94e905f90cdd1e525f148f983c557b00.png"><br>  <i>Fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LiDAR: una visi√≥n general del panorama de patentes</a></i> <br><br>  Sin embargo, no lo olvidamos: el mercado de sensores de profundidad para tel√©fonos inteligentes est√° planeado en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">$ 6 mil millones el</a> pr√≥ximo a√±o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">,</a> y no puede ser inferior a 4, ya que el a√±o pasado ascendi√≥ a m√°s de 3 mil millones.  Esta es una gran cantidad de dinero que no solo se destinar√° al retorno de la inversi√≥n (a los inversores m√°s exitosos), sino tambi√©n al desarrollo de nuevas generaciones de sensores.  Todav√≠a no hay un crecimiento similar en los lidares, pero seg√∫n todos los indicios, ir√° literalmente en los pr√≥ximos 3 a√±os.  Y entonces este es un proceso exponencial ordinario similar a una avalancha, que ya ha sucedido m√°s de una vez. <br><br>  ¬°El futuro cercano de las c√°maras de profundidad se ve extremadamente interesante! <br><br>  <b><s>Cartago debe estar roto ... ¬°</s> Todo el video ser√° tridimensional para fines de siglo!</b> <br><br>  Est√©n atentos! <br><br>  ¬øQui√©n no ha le√≠do - la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">primera parte del texto</a> ! <br><br><div class="spoiler">  <b class="spoiler_title">Agradecimientos</b> <div class="spoiler_text">  Me gustar√≠a agradecerle cordialmente: <br><ul><li>  Laboratorio de Computaci√≥n Gr√°fica VMK Universidad Estatal de Mosc√∫  MV Lomonosov por su contribuci√≥n al desarrollo de gr√°ficos por computadora en Rusia y no solo <br></li><li>  Google, Apple e Intel para grandes soluciones compactas, y todos los fabricantes de LIDAR para un r√°pido progreso, <br></li><li>  personalmente Konstantin Kozhemyakov, quien hizo mucho para hacer este art√≠culo mejor y m√°s visual, <br></li><li>  y finalmente, muchas gracias a Roman Kazantsev, Eugene Lyapustin y Yegor Sklyarov por una gran cantidad de comentarios y correcciones razonables que hicieron que este texto fuera mucho mejor. <br></li></ul><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/458458/">https://habr.com/ru/post/458458/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../458442/index.html">¬øPor qu√© LLVM puede llamar a una funci√≥n nunca llamada?</a></li>
<li><a href="../458444/index.html">Internet para el residente de verano. Parte 4. Una tarjeta SIM es suficiente</a></li>
<li><a href="../458450/index.html">Caracter√≠sticas de las computadoras cu√°nticas.</a></li>
<li><a href="../458452/index.html">C√≥mo hacer una cocina de oficina a trav√©s de un enfoque de supermercado</a></li>
<li><a href="../458454/index.html">Alexey Savvateev: Modelos de Internet y redes sociales.</a></li>
<li><a href="../458462/index.html">Profundice en los espacios de nombres de Linux</a></li>
<li><a href="../458464/index.html">Enlace gigabit de 3 km en m√≥dems l√°ser</a></li>
<li><a href="../458468/index.html">¬øC√≥mo ejecutar una impresionante reuni√≥n de Kanban StandUp?</a></li>
<li><a href="../458470/index.html">Texturizado, o lo que necesitas saber para convertirte en un Artista de Surface. Parte 2. M√°scaras y texturas.</a></li>
<li><a href="../458472/index.html">Compilaci√≥n de una clasificaci√≥n de territorios por el m√©todo de potenciales t√©rmicos utilizando datos abiertos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë≤üèæ ‚úãüèº üë£ 50 tonos de apio üë©üèº‚Äçüéì üì• üëàüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Est√°s aqu√≠ si quieres saber c√≥mo domar un marco que es ampliamente conocido en los c√≠rculos de desarrolladores de Python llamado Celery. E incluso si ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>50 tonos de apio</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/433476/">  Est√°s aqu√≠ si quieres saber c√≥mo domar un marco que es ampliamente conocido en los c√≠rculos de desarrolladores de Python llamado Celery.  E incluso si Celery ejecuta con confianza comandos b√°sicos en su proyecto, entonces la experiencia fintech puede abrir lados desconocidos para usted.  Porque fintech siempre es Big Data, y con ello la necesidad de tareas en segundo plano, procesamiento por lotes, API as√≠ncrona, etc. <br><img src="https://habrastorage.org/webt/oc/8a/rn/oc8arnnknqs37365anrx9mvuuru.jpeg"><br><br>  La belleza de la historia de Oleg Churkin sobre el apio en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Mosc√∫ Python Conf ++,</a> adem√°s de instrucciones detalladas sobre c√≥mo configurar el apio bajo carga y c√≥mo monitorearlo, es que puede tomar prestadas ideas √∫tiles. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/SxgzHz-zE-c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <strong>Sobre el orador y el proyecto:</strong> Oleg Churkin ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">Bahusss</a> ) ha estado desarrollando proyectos de Python de diversa complejidad durante 8 a√±os, ha trabajado en muchas compa√±√≠as conocidas: Yandex, Rambler, RBC, Kaspersky Lab.  Ahora techlide en el inicio fintech-StatusPoney. <br><a name="habracut"></a><br>  El proyecto funciona con una gran cantidad de datos financieros de los usuarios (1,5 terabytes): cuentas, transacciones, comerciantes, etc.  Ejecuta hasta un mill√≥n de tareas todos los d√≠as.  Tal vez este n√∫mero no le parecer√° muy grande a alguien, pero para una peque√±a empresa con capacidades modestas esta es una cantidad significativa de datos, y los desarrolladores tuvieron que enfrentar varios problemas en el camino hacia un proceso estable. <br><br>  Oleg habl√≥ sobre los puntos clave de trabajo: <br><br><ul><li>  ¬øQu√© tareas quer√≠a resolver con el marco, por qu√© eligi√≥ Celery? </li><li>  C√≥mo ayud√≥ el apio. </li><li>  C√≥mo configurar el apio bajo carga. </li><li>  C√≥mo monitorear el estado del apio. </li></ul><br>  Y comparti√≥ un par de utilidades de dise√±o que implementan la funcionalidad que falta en Celery.  Como result√≥, en 2018, y esto puede ser.  La siguiente es una versi√≥n de texto del informe en primera persona. <br><br><h2>  Problema <br></h2><br>  Fue necesario para resolver las siguientes tareas: <br><br><ul><li>  Ejecute <strong>tareas en segundo plano separadas</strong> . </li><li>  Realice el <strong>procesamiento por lotes de tareas</strong> , es decir, ejecute muchas tareas a la vez. </li><li>  Incrustar el proceso <strong>Extraer, Transformar, Cargar</strong> . </li><li>  Implemente la <strong>API asincr√≥nica</strong> .  Resulta que la API asincr√≥nica se puede implementar no solo usando marcos asincr√≥nicos, sino tambi√©n completamente sincr√≥nicos; </li><li> Realizar <strong>tareas peri√≥dicas</strong> .  Ning√∫n proyecto puede prescindir de tareas peri√≥dicas; para algunos, se puede prescindir de Cron, pero tambi√©n hay herramientas m√°s convenientes. </li><li>  Cree una <strong>arquitectura de desencadenante</strong> : para desencadenar un desencadenador, ejecute una tarea que actualice los datos.  Esto se hace para compensar la falta de potencia de tiempo de ejecuci√≥n calculando previamente los datos en segundo plano. </li></ul><br>  <strong>Las tareas en segundo plano</strong> incluyen cualquier tipo de notificaci√≥n: correo electr√≥nico, inserci√≥n, escritorio: todo esto se env√≠a en tareas en segundo plano mediante un disparador.  Del mismo modo, se inicia una actualizaci√≥n peri√≥dica de datos financieros. <br><br>  En segundo plano, se realizan varias comprobaciones espec√≠ficas, por ejemplo, la comprobaci√≥n de un usuario por fraude.  En las startups financieras, se <strong>presta mucho esfuerzo y atenci√≥n espec√≠ficamente a la seguridad de los datos</strong> , ya que permitimos a los usuarios agregar sus cuentas bancarias a nuestro sistema, y ‚Äã‚Äãpodemos ver todas sus transacciones.  Los estafadores pueden intentar usar nuestro servicio para algo malo, por ejemplo, para verificar el saldo de una cuenta robada. <br><br>  La √∫ltima categor√≠a de tareas en segundo plano son <strong>las tareas de mantenimiento</strong> : ajustar algo, ver, arreglar, monitorear, etc. <br><br>  Para notificaciones masivas, <strong>se utiliza el procesamiento por lotes</strong> .  Una gran cantidad de datos que recibimos de nuestros usuarios debe calcularse y procesarse de cierta manera, incluyendo  en modo por lotes. <br><br>  El mismo concepto incluye el cl√°sico <strong>Extraer, Transformar, Cargar</strong> : <br><br><ul><li>  cargar datos de fuentes externas (API externa); </li><li>  mantener sin procesar; </li><li>  ejecutar tareas que leen y procesan datos; </li><li>  guardamos los datos procesados ‚Äã‚Äãen el lugar correcto en el formato correcto, para que luego sea conveniente usarlos en la interfaz de usuario, por ejemplo. </li></ul><br>  No es ning√∫n secreto que la API asincr√≥nica se puede hacer mediante solicitudes de sondeo simples: el front-end inicia el proceso en el back-end, el back-end inicia una tarea que se inicia peri√≥dicamente, "vierte" los resultados y actualiza el estado en la base de datos.  La interfaz muestra al usuario este estado interactivo: el estado est√° cambiando.  Esto le permite: <br><br><ul><li>  ejecutar tareas de sondeo desde otras tareas; </li><li>  ejecutar diferentes tareas seg√∫n las condiciones. </li></ul><br>  En nuestro servicio, esto es suficiente por ahora, pero en el futuro probablemente tendremos que reescribir algo m√°s. <br><br><h2>  Requerimientos de herramientas <br></h2><br>  Para implementar estas tareas, ten√≠amos los siguientes requisitos para las herramientas: <br><br><ul><li>  Funcionalidad necesaria para realizar nuestras ambiciones. </li><li>  <strong>Escalabilidad</strong> sin muletas. </li><li>  <strong>Monitoreo del</strong> sistema para entender c√≥mo funciona.  Utilizamos informes de errores, por lo que la integraci√≥n con Sentry no estar√° fuera de lugar, con Django tambi√©n. </li><li>  <strong>Rendimiento</strong> , porque tenemos muchas tareas. </li><li>  La madurez, la fiabilidad y el desarrollo activo son cosas obvias.  Est√°bamos buscando una herramienta que sea compatible y desarrollada. </li><li>  Adecuaci√≥n de la documentaci√≥n: <strong>no hay documentaci√≥n en ning√∫n lado</strong> . </li></ul><br><h2>  ¬øQu√© herramienta elegir? <br></h2><br>  ¬øCu√°les son las opciones en el mercado en 2018 para resolver estos problemas? <br><br>  √ârase una vez para tareas menos ambiciosas, escrib√≠ una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">biblioteca</a> √∫til que todav√≠a se usa en algunos proyectos.  Es f√°cil de operar y realiza tareas en segundo plano.  Pero al mismo tiempo, no se necesitan corredores (ni Celery, ni otros), solo el servidor de aplicaciones <strong>uwsgi</strong> , que tiene una cola de impresi√≥n, es algo que comienza como un trabajador independiente.  Esta es una soluci√≥n muy simple: todas las tareas se almacenan condicionalmente en archivos.  Para proyectos simples, esto es suficiente, pero para los nuestros no fue suficiente. <br><br>  De alguna manera consideramos: <br><br><ul><li>  Apio (10K estrellas en GitHub); </li><li>  RQ (5K estrellas en GitHub); </li><li>  Huey (2K estrellas en GitHub); </li><li>  Dramatiq (1K estrellas en GitHub); </li><li>  Tasktiger (0.5K estrellas en GitHub); </li><li>  Flujo de aire?  Luigi </li></ul><br><h2>  Candidato prometedor 2018 <br></h2><br>  Ahora me gustar√≠a llamar su atenci√≥n sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dramatiq</a> .  Esta es una biblioteca del experto Apio, que conoc√≠a todas las desventajas de Apio y decidi√≥ reescribir todo, solo que muy bien.  Beneficios de Dramatiq: <br><br><ul><li>  Un conjunto de todas las caracter√≠sticas necesarias. </li><li>  Afilado de la productividad. </li><li>  Soporte centinela y m√©trico para Prometheus listo para usar </li><li>  Una base de c√≥digo peque√±a y claramente escrita, carga autom√°tica de c√≥digo. </li></ul><br>  Hace alg√∫n tiempo, Dramatiq tuvo problemas con las licencias: primero hubo AGPL, luego fue reemplazado por LGPL.  Pero ahora puedes intentarlo. <br><br>  Pero en 2016, adem√°s del apio, no hab√≠a nada especial que tomar.  Nos gust√≥ su rica funcionalidad, y luego se adaptaba perfectamente a nuestras tareas, porque incluso entonces era maduro y funcional: <br><br><ul><li>  ten√≠a tareas peri√≥dicas fuera de la caja; </li><li>  apoy√≥ a varios corredores; </li><li>  Integrado con Django y Sentry. </li></ul><br><h2>  Caracter√≠sticas del proyecto <br></h2><br>  Te contar√© sobre nuestro contexto, para que la historia adicional sea m√°s clara. <br><br>  Usamos <strong>Redis como agente de mensajes</strong> .  He escuchado muchas historias y rumores de que Redis est√° perdiendo mensajes, que no est√° adaptado para ser un agente de mensajes.  En la experiencia de producci√≥n, esto no est√° confirmado, pero, como resultado, Redis ahora funciona de manera m√°s eficiente que RabbitMQ (es con Celery, al menos, aparentemente, el problema est√° en el c√≥digo de integraci√≥n con los corredores).  En la versi√≥n 4, se corrigi√≥ el agente de Redis, realmente dej√≥ de perder tareas durante los reinicios y funciona de manera bastante estable.  En 2016, Celery iba a abandonar Redis y centrarse en la integraci√≥n con RabbitMQ, pero, afortunadamente, esto no sucedi√≥. <br><br>  En caso de problemas con Redis, si necesitamos una alta disponibilidad seria, nosotros, debido a que usamos el poder de Amazon, cambiaremos a Amazon SQS o Amazon MQ. <br><br>  No <strong>utilizamos el backend de resultados para almacenar los resultados</strong> , porque preferimos almacenar los resultados nosotros mismos donde queremos y verificarlos de la manera que queramos.  No queremos que Celery haga esto por nosotros. <br><br>  Utilizamos un <strong>grupo de pefork</strong> , es decir, trabajadores de procesos que crean bifurcaciones separadas de procesos para concurrencia adicional. <br><br><h2>  Unidad de trabajo <br></h2><br>  Discutiremos los elementos b√°sicos para actualizar a aquellos que no han probado el apio, pero que solo lo har√°n.  <strong>La unidad de trabajo para el apio es un desaf√≠o</strong> .  Dar√© un ejemplo de una tarea simple que env√≠a un correo electr√≥nico. <br><br>  Funci√≥n simple y decorador: <br><br><pre><code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@current_app.task def send_email(email: str): print(f'Sending email to email={email}')</span></span></code> </pre> <br>  El inicio de la tarea es simple: llamamos a la funci√≥n y la tarea se ejecutar√° en tiempo de ejecuci√≥n (send_email (email = "python@example.com")) o en el trabajador, es decir, el efecto mismo de la tarea en segundo plano: <br><br><pre> <code class="python hljs">send_email.delay(email=<span class="hljs-string"><span class="hljs-string">"python@example.com"</span></span>) send_email.apply_async( kwargs={email: <span class="hljs-string"><span class="hljs-string">"python@example.com"</span></span>} )</code> </pre><br>  Durante dos a√±os de trabajo con apio bajo cargas elevadas, hemos ideado las reglas de buena forma.  Hubo muchos rastrillos, aprendimos c√≥mo sortearlos y compartir√© c√≥mo. <br><br><h4>  Dise√±o de c√≥digo <br></h4><br>  La tarea puede contener una l√≥gica diferente.  En general, Celery le ayuda a mantener tareas en archivos o paquetes, o importarlas desde alg√∫n lugar.  A veces obtienes un mont√≥n de l√≥gica de negocios en un m√≥dulo.  En nuestra opini√≥n, el enfoque correcto desde el punto de vista de la modularidad de la aplicaci√≥n es mantener un <strong>m√≠nimo de l√≥gica en la tarea</strong> .  Usamos rompecabezas solo como "disparadores" del c√≥digo.  Es decir, la tarea no lleva l√≥gica en s√≠ misma, sino que desencadena el lanzamiento de c√≥digo en segundo plano. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@celery_app.task(queue='...') def run_regular_update(provider_account_id, *args, **kwargs): """...""" flow = flows.RegularSyncProviderAccountFlow(provider_account_id) return flow.run(*args, **kwargs)</span></span></code> </pre><br>  Ponemos todo el c√≥digo en clases externas que usan algunas otras clases.  Todas las tareas consisten esencialmente en dos l√≠neas. <br><br><h4>  Objetos simples en par√°metros <br></h4><br>  En el ejemplo anterior, se pasa una determinada identificaci√≥n a la tarea.  En todas las tareas que utilizamos, <strong>transferimos solo datos escalares peque√±os</strong> , id.  No serializamos modelos Django para transmitirlos.  Incluso en ETL, cuando un gran blob de datos proviene de un servicio externo, primero lo guardamos y luego ejecutamos una tarea que lee todo este blob por id y lo procesa. <br><br>  Si no hace esto, vimos una gran mezcla de memoria consumida en Redis.  El mensaje comienza a ocupar m√°s memoria, la red est√° muy cargada, la cantidad de tareas procesadas (rendimiento) disminuye.  Mientras el objeto llegue a su fin, las tareas se vuelven irrelevantes, el objeto ya ha sido eliminado.  Los datos deb√≠an ser serializados; no todo est√° bien serializado en JSON en Python.  Cuando volvimos a intentar las tareas, necesit√°bamos la oportunidad de decidir r√°pidamente qu√© hacer con estos datos, obtenerlos nuevamente y realizar algunas verificaciones. <br><br><blockquote>  Si transfieres datos grandes en par√°metros, ¬°pi√©nsalo de nuevo!  Es mejor transferir un escalar peque√±o con una peque√±a cantidad de informaci√≥n sobre el problema, y ‚Äã‚Äãde esta informaci√≥n en la tarea para obtener todo lo que necesita. <br></blockquote><br><h4>  Problemas idempotentes <br></h4><br>  Los propios desarrolladores de apio recomiendan este enfoque.  Cuando se repite la secci√≥n del c√≥digo, no deben producirse efectos secundarios, el resultado debe ser el mismo.  Esto no siempre es f√°cil de lograr, especialmente si hay una interacci√≥n con muchos servicios o compromisos de dos fases. <br><br>  Pero cuando hace todo localmente, siempre puede verificar que los datos entrantes existan y sean relevantes, realmente puede trabajar en ellos y usar transacciones.  Si hay muchas consultas en la base de datos para una tarea y algo puede salir mal en el tiempo de ejecuci√≥n, use las transacciones para revertir los cambios innecesarios. <br><br><h4>  Compatibilidad con versiones anteriores <br></h4><br>  Tuvimos algunos efectos secundarios interesantes cuando implementamos la aplicaci√≥n.  No importa qu√© tipo de implementaci√≥n use (azul + verde o actualizaci√≥n continua), siempre habr√° una situaci√≥n en la que el c√≥digo de servicio anterior crea mensajes para el nuevo c√≥digo de trabajador, y viceversa, el antiguo trabajador recibe mensajes del nuevo c√≥digo de servicio, porque se implement√≥ "primero" y all√≠ se fue el tr√°fico. <br><br>  Detectamos errores y perdimos tareas hasta que aprendimos c√≥mo mantener la <strong>compatibilidad con versiones anteriores</strong> .  La compatibilidad con versiones anteriores es que entre las versiones las tareas deber√≠an funcionar de manera segura, sin importar qu√© par√°metros entren en esta tarea.  Por lo tanto, en todas las tareas ahora estamos haciendo una firma "de goma" (** kwargs).  Cuando necesite agregar un nuevo par√°metro en la pr√≥xima versi√≥n, lo tomar√° de ** kwargs en la nueva versi√≥n, pero no lo tomar√° en el anterior, nada se romper√°.  Tan pronto como la firma cambia, y Celery no lo sabe, se bloquea y da un error de que no hay tal par√°metro en la tarea. <br><br>  Una forma m√°s rigurosa de evitar tales problemas es versionar las colas de tareas entre versiones, pero es bastante dif√≠cil de implementar y lo dejamos en el trabajo pendiente por ahora. <br><br><h4>  Tiempos de espera <br></h4><br>  Pueden surgir problemas debido a n√∫meros insuficientes o tiempos de espera incorrectos. <br><br><blockquote>  No establecer un tiempo de espera para una tarea es malo.  Esto significa que no comprende lo que est√° sucediendo en la tarea, c√≥mo deber√≠a funcionar la l√≥gica empresarial. <br></blockquote><br>  Por lo tanto, todas nuestras tareas est√°n colgadas con tiempos de espera, incluidos los globales para todas las tareas, y tambi√©n se establecen tiempos de espera para cada tarea espec√≠fica. <br><br>  <strong>Debe colocarse: soft_limit_timeout</strong> y <strong>caduca.</strong> <br><br>  Expira es cu√°nto puede vivir una tarea en l√≠nea.  Es necesario que las tareas no se acumulen en las colas en caso de problemas.  Por ejemplo, si ahora queremos informar algo al usuario, pero sucedi√≥ algo y la tarea se puede completar solo ma√±ana, esto no tiene sentido, ma√±ana el mensaje ya no ser√° relevante.  Por lo tanto, para las notificaciones tenemos un vencimiento bastante peque√±o. <br><br>  Tenga en cuenta el uso de <strong>eta (cuenta atr√°s) + visibilidad</strong> <strong>_timeout</strong> .  Las preguntas frecuentes describen tal problema con Redis: el llamado tiempo de espera de visibilidad del agente de Redis.  Por defecto, su valor es de una hora: si despu√©s de una hora el trabajador ve que nadie ha llevado la tarea a ejecuci√≥n, la vuelve a agregar a la cola.  Por lo tanto, si la cuenta regresiva es de dos horas, despu√©s de una hora, el corredor descubrir√° que esta tarea a√∫n no se ha completado y crear√° otra de la misma.  Y en dos horas, se completar√°n dos tareas id√©nticas. <br><br><blockquote>  Si el tiempo estimado o la cuenta regresiva excede 1 hora, lo m√°s probable es que el uso de Redis d√© como resultado la duplicaci√≥n de tareas, a menos, por supuesto, que haya cambiado el valor de visibilidad_tiempo de espera en la configuraci√≥n para conectarse al corredor. <br></blockquote><br><h4>  Pol√≠tica de reintento <br></h4><br>  Para aquellas tareas que pueden repetirse o que pueden fallar, utilizamos la pol√≠tica Reintentar.  Pero lo usamos con cuidado para no abrumar los servicios externos.  Si repite r√°pidamente las tareas sin especificar un retroceso exponencial, entonces un servicio externo, o quiz√°s uno interno, simplemente no lo soportar√°. <br><br>  Ser√≠a bueno especificar expl√≠citamente los par√°metros <strong>retry_backoff</strong> , <strong>retry_jitter</strong> y <strong>max_retries</strong> , especialmente max_retries.  retry_jitter: un par√°metro que le permite generar un poco de caos para que las tareas no comiencen a repetirse al mismo tiempo. <br><br><h4>  Fugas de memoria <br></h4><br><blockquote>  Desafortunadamente, las p√©rdidas de memoria son muy f√°ciles, y encontrarlas y solucionarlas es dif√≠cil. </blockquote><br>  En general, trabajar con memoria en Python es muy controvertido.  Pasar√° mucho tiempo y nervios para comprender por qu√© ocurre la fuga, y luego resulta que ni siquiera est√° en su c√≥digo.  Por lo tanto, siempre, al iniciar un proyecto, ponga un <strong>l√≠mite de memoria en el trabajador</strong> : worker_max_memory_per_child. <br><br>  Esto asegura que OOM Killer no venga un d√≠a, no mate a todos los trabajadores y no pierda todas las tareas.  El apio reiniciar√° a los trabajadores cuando sea necesario. <br><br><h4>  Tareas prioritarias <br></h4><br>  Siempre hay tareas que deben completarse antes que los dem√°s, m√°s r√°pido que nadie: ¬°deben completarse ahora mismo!  Hay tareas que no son tan importantes: deje que se completen durante el d√≠a.  Para esto, la tarea tiene un par√°metro de <strong>prioridad.</strong>  En Redis, funciona bastante interesante: se crea una nueva cola con un nombre en el que se agrega prioridad. <br><br>  Utilizamos un enfoque diferente: <strong>trabajadores separados para las prioridades</strong> , es decir  a la antigua usanza, creamos trabajadores de apio con diferente "importancia": <br><br><pre> <code class="python hljs">celery multi start high_priority low_priority -c:high_priority <span class="hljs-number"><span class="hljs-number">2</span></span> -c:low_priority <span class="hljs-number"><span class="hljs-number">6</span></span> -Q:high_priority urgent_notifications -Q:low_priority emails,urgent_notifications</code> </pre><br>  Celery multi start es un ayudante que lo ayuda a ejecutar toda la configuraci√≥n de Celery en una m√°quina y desde la misma l√≠nea de comando.  En este ejemplo, creamos nodos (o trabajadores): high_priority y low_priority, 2 y 6 son concurrencia. <br><br>  Dos trabajadores de alta prioridad procesan constantemente la cola de notificaciones urgentes.  Nadie m√°s tomar√° estos trabajadores, solo leer√°n tareas importantes de la cola de notificaciones urgentes. <br><br>  Para tareas sin importancia hay una cola de baja prioridad.  Hay 6 trabajadores que reciben mensajes de todas las dem√°s colas.  Tambi√©n suscribimos a los trabajadores de baja prioridad a notificaciones urgentes para que puedan ayudar si los trabajadores de alta prioridad no pueden hacer frente. <br><br>  Utilizamos este esquema cl√°sico para priorizar tareas. <br><br><h4>  Extraer, transformar, cargar <br></h4><br>  Muy a menudo, ETL parece una cadena de tareas, cada una de las cuales recibe informaci√≥n de la tarea anterior. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@task def download_account_data(account_id) ‚Ä¶ return account_id @task def process_account_data(account_id, processing_type) ‚Ä¶ return account_data @task def store_account_data(account_data) ‚Ä¶</span></span></code> </pre><br>  El ejemplo tiene tres tareas.  Apio tiene un enfoque para el procesamiento distribuido y varias utilidades √∫tiles, incluida la funci√≥n de <strong>cadena</strong> , que hace que una de cada tres tareas: <br><br><pre> <code class="python hljs">chain( download_account_data.s(account_id), process_account_data.s(processing_type=<span class="hljs-string"><span class="hljs-string">'fast'</span></span>), store_account_data.s() ).delay()</code> </pre><br>  Apio desarmar√° la tuber√≠a, realizar√° la primera tarea en orden, luego transferir√° los datos recibidos a la segunda y transferir√° los datos que la segunda tarea devuelve a la tercera.  As√≠ es como implementamos tuber√≠as ETL simples. <br><br>  Para cadenas m√°s complejas, debe conectar l√≥gica adicional.  Pero es importante tener en cuenta que si surge un problema en esta cadena en una tarea, entonces <strong>toda la cadena se vendr√° abajo</strong> .  Si no desea este comportamiento, maneje la excepci√≥n y contin√∫e la ejecuci√≥n, o detenga toda la cadena por excepci√≥n. <br><br>  De hecho, esta cadena en el interior parece una gran tarea, que contiene todas las tareas con todos los par√°metros.  Por lo tanto, si abusa de la cantidad de tareas en la cadena, obtendr√° un consumo de memoria muy alto y una desaceleraci√≥n del proceso general.  <strong>Crear cadenas de miles de tareas es una mala idea.</strong> <br><br><h2>  Procesamiento de tareas por lotes <br></h2><br>  Ahora lo m√°s interesante: qu√© sucede cuando necesita enviar un correo electr√≥nico a dos millones de usuarios. <br><br>  Escribes una funci√≥n para evitar a todos los usuarios: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@task def send_report_emails_to_users(): for user_id in User.get_active_ids(): send_report_email.delay(user_id=user_id)</span></span></code> </pre><br>  Sin embargo, la mayor√≠a de las veces la funci√≥n recibir√° no solo la identificaci√≥n del usuario, sino que tambi√©n eliminar√° toda la tabla de usuarios en general.  Cada usuario tendr√° su propia tarea. <br><br>  Hay varios problemas en esta tarea: <br><br><ul><li>  Las tareas se inician secuencialmente, es decir, la √∫ltima tarea (dos millones de usuarios) comenzar√° en 20 minutos y tal vez para este tiempo de espera ya funcione. </li><li>  Todos los ID de usuario se cargan primero en la memoria de la aplicaci√≥n y luego en la cola: delay () realizar√° 2 millones de tareas. </li></ul><br>  Lo llam√© Tarea de inundaci√≥n, el gr√°fico se parece a esto. <br><img src="https://habrastorage.org/webt/j_/ya/6r/j_ya6r359licn16439uohbpoaow.png"><br>  Hay una afluencia de tareas que los trabajadores comienzan a procesar lentamente.  Lo siguiente sucede si las tareas usan una r√©plica maestra, todo el proyecto comienza a resquebrajarse, nada funciona.  A continuaci√≥n se muestra un ejemplo de nuestra pr√°ctica, donde el uso de la CPU de la base de datos fue del 100% durante varias horas, para ser honesto, logramos asustarnos. <br><img src="https://habrastorage.org/webt/ac/wh/jy/acwhjy96edpu3dry_vatxj5z7yw.png"><br>  El problema es que el sistema est√° muy degradado con un aumento en el n√∫mero de usuarios.  La tarea que se ocupa de la programaci√≥n: <br><br><ul><li>  requiere m√°s y m√°s memoria; </li><li>  corre m√°s tiempo y puede ser "asesinado" por tiempo de espera. </li></ul><br>  Se produce una inundaci√≥n de tareas: las tareas se acumulan en colas y crean una gran carga no solo en los servicios internos, sino tambi√©n en los externos. <br><br>  Intentamos <strong>reducir la competitividad de los trabajadores</strong> , esto ayuda en cierto sentido: se reduce la carga del servicio.  O puede <strong>escalar los servicios internos</strong> .  Pero esto no resolver√° el problema del problema del generador, que todav√≠a tiene mucho.  Y de ninguna manera afecta la dependencia del desempe√±o de los servicios externos. <br><br><h3>  Generaci√≥n de tareas <br></h3><br>  Decidimos tomar un camino diferente.  Con mucha frecuencia, no necesitamos ejecutar los 2 millones de tareas en este momento.  Es normal que el env√≠o de notificaciones a todos los usuarios demore, por ejemplo, 4 horas si estas cartas no son tan importantes. <br><br>  Primero intentamos usar <strong>Celery.chunks</strong> : <br><br><pre> <code class="python hljs">send_report_email.chunks( ({<span class="hljs-string"><span class="hljs-string">'user_id'</span></span>: user.id} <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> user <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> User.objects.active()), n=<span class="hljs-number"><span class="hljs-number">100</span></span> ).apply_async()</code> </pre><br>  Esto no cambi√≥ la situaci√≥n, porque, a pesar del iterador, todo user_id se cargar√° en la memoria.  Y todos los trabajadores obtienen una cadena de tareas, y aunque los trabajadores se relajar√°n un poco, al final no quedamos satisfechos con esta decisi√≥n. <br><br>  Intentamos establecer <strong>rate_limit</strong> a los trabajadores para que solo procesen un cierto n√∫mero de tareas por segundo, y descubrimos que en realidad rate_limit especificado para la tarea es rate_limit para el trabajador.  Es decir, si especifica rate_limit para la tarea, esto no significa que la tarea se realizar√° 70 veces por segundo.  Esto significa que el trabajador lo ejecutar√° 70 veces por segundo, y dependiendo de lo que tenga con los trabajadores, este l√≠mite puede cambiar din√°micamente, es decir.  l√≠mite real rate_limit * len (trabajadores). <br><br>  Si el trabajador comienza o se detiene, entonces el l√≠mite de velocidad total cambia.  Adem√°s, si sus tareas son lentas, toda la captaci√≥n previa en la cola que llena al trabajador se obstruir√° con estas tareas lentas.  El trabajador mira: ‚ÄúOh, tengo esta tarea en rate_limit, ya no puedo realizarla.  Y todas las siguientes tareas en la cola son exactamente las mismas: ¬°d√©jenlas colgar!  - Y esperando. <br><br><h3>  Chunkificator <br></h3><br>  Al final, decidimos que escribir√≠amos la nuestra, e hicimos una peque√±a biblioteca, que se llamaba Chunkificator. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@task @chunkify_task(sleep_timeout=...l initial_chunk=...) def send_report_emails_to_users(chunk: Chunk): for user_id in User.get_active_ids(chunk=chunk): send_report_email.delay(user_id=user_id)</span></span></code> </pre><br>  Toma sleep_timeout e initial_chunk, y se llama a s√≠ mismo con un nuevo fragmento.  Chunk es una abstracci√≥n sobre listas enteras o sobre listas de fecha o fecha y hora.  Pasamos un fragmento a una funci√≥n que recibe a los usuarios solo con este fragmento y ejecuta tareas solo para ese fragmento. <br><br>  Por lo tanto, el generador de tareas ejecuta solo la cantidad de tareas que se necesitan y no consume mucha memoria.  La imagen se ha vuelto as√≠. <br><img src="https://habrastorage.org/webt/yh/gg/h_/yhggh__vbzgiexxwskakp1nltrw.png"><br>  Lo m√°s destacado es que usamos un fragmento disperso, es decir, utilizamos instancias en la base de datos como identificaci√≥n del fragmento (algunos de ellos pueden omitirse, por lo que puede haber menos tareas).  Como resultado, la carga result√≥ ser m√°s uniforme, el proceso se hizo m√°s largo, pero todos est√°n vivos y bien, la base no se esfuerza. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La biblioteca est√°</a> implementada para Python 3.6+ y est√° disponible en GitHub.  Hay un matiz que planeo arreglar, pero por ahora datetime-chunk necesita un serializador de pepinillos, muchos no podr√°n hacerlo. <br><br>  Un par de preguntas ret√≥ricas: ¬øde d√≥nde vino toda esta informaci√≥n?  ¬øC√≥mo descubrimos que ten√≠amos problemas?  ¬øC√≥mo sabe que un problema pronto se volver√° cr√≠tico y necesita comenzar a resolverlo? <br><br>  La respuesta es, por supuesto, el monitoreo. <br><br><h2>  Monitoreo <br></h2><br>  Realmente me gusta monitorear, me gusta monitorear todo y mantener mi dedo en el pulso.  Si no mantiene el dedo en el pulso, pisar√° constantemente el rastrillo. <br><br>  Preguntas de monitoreo est√°ndar: <br><br><ul><li>  ¬øLa configuraci√≥n actual de trabajador / concurrencia maneja la carga? </li><li>  ¬øCu√°l es la degradaci√≥n del tiempo de ejecuci√≥n de la tarea? </li><li>  ¬øCu√°nto tiempo duran las tareas en l√≠nea?  De repente, la l√≠nea ya est√° llena? </li></ul><br>  Intentamos varias opciones.  El apio tiene una interfaz <strong>CLI</strong> , es bastante rico y ofrece: <br><br><ul><li>  inspeccionar - informaci√≥n sobre el sistema; </li><li>  control: administra la configuraci√≥n del sistema; </li><li>  purga - colas claras (fuerza mayor); </li><li>  eventos: interfaz de usuario de la consola para mostrar informaci√≥n sobre las tareas que se realizan. </li></ul><br>  Pero es dif√≠cil realmente monitorear algo.  Es m√°s adecuado para volantes locales, o si desea cambiar alg√∫n rate_limit en tiempo de ejecuci√≥n. <br><br>  <strong>NB:</strong> necesita acceso al agente de producci√≥n para usar la interfaz CLI. <br><br>  <strong>Celery Flower le</strong> permite hacer lo mismo que la CLI, solo a trav√©s de la interfaz web, y eso no es todo.  Pero crea algunos gr√°ficos simples y le permite cambiar la configuraci√≥n sobre la marcha. <br><br>  En general, Celery Flower es adecuada para ver c√≥mo funciona todo en configuraciones peque√±as.  Adem√°s, admite la API HTTP, que es conveniente si est√° escribiendo automatizaci√≥n. <br><br>  Pero nos <strong>instalamos en Prometeo.</strong>  Se llevaron al <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">exportador</a> actual: repar√≥ p√©rdidas de memoria;  m√©tricas agregadas para tipos de excepci√≥n;  m√©tricas agregadas para la cantidad de mensajes en las colas;  Integrado con alertas en Grafana y regocijo.  Tambi√©n est√° publicado en GitHub, puedes verlo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><br><h4>  Ejemplos en Grafana <br></h4><br><img src="https://habrastorage.org/webt/wa/i3/yt/wai3ytvm4ewoiumfrlvn2gzq9eg.png"><br>  Estad√≠sticas anteriores para todas las excepciones: qu√© excepciones para qu√© tareas.  A continuaci√≥n se muestra el tiempo para completar las tareas. <br><img src="https://habrastorage.org/webt/ae/l3/sf/ael3sfmjeve51s5jtui9fh_7ydq.png"><br><h2>  ¬øQu√© falta en el apio? <br></h2><br>  Este es un marco frondoso, tiene muchas cosas, ¬°pero nos falta!  No hay suficientes caracter√≠sticas peque√±as, como: <br><br><ul><li>  <strong>Recarga autom√°tica de c√≥digo durante el desarrollo</strong> , no es compatible con este Celery, reinicie. </li><li>  <strong>Las m√©tricas para Prometheus est√°n listas para usar</strong> , pero Dramatiq s√≠. </li><li>  <strong>Soporte para el</strong> <strong>bloqueo de tareas</strong> , de modo que solo se ejecute una tarea a la vez.  Puede hacerlo usted mismo, pero Dramatiq y Tasktiger tienen un decorador conveniente que garantiza que todas las dem√°s tareas similares se bloqueen. </li><li>  <strong>Rate_limit para una tarea</strong> , no para el trabajador. </li></ul><br><h2>  Conclusiones <br></h2><br>  A pesar de que el apio es un marco que muchos usan en la producci√≥n, consta de 3 bibliotecas: apio, kombu y billar.  Las tres bibliotecas est√°n desarrolladas por co-desarrolladores, y pueden liberar una dependencia y romper su ensamblaje. <br><img src="https://habrastorage.org/webt/dv/np/52/dvnp52xxgjcwsbdwr3c15a86-ac.png"><br>  Por lo tanto, espero que ya lo haya resuelto de alguna manera y haya hecho que sus asambleas sean deterministas. <br><br>  De hecho, las conclusiones no son tan tristes.  <strong>El apio hace frente a sus tareas</strong> en nuestro proyecto fintech bajo nuestra carga.  Hemos adquirido experiencia que compart√≠ con usted, y puede aplicar nuestras soluciones o refinarlas y tambi√©n superar todas sus dificultades. <br><br>  No olvide que el <strong>monitoreo debe ser una parte esencial de su proyecto</strong> .  Solo a trav√©s del monitoreo puede descubrir d√≥nde tiene algo mal, qu√© necesita ser reparado, agregado, reparado. <br><br>  <strong>Ponente de contacto Oleg Churkin</strong> : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">Bahusss</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">facebook</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github</a> . <br><br><blockquote>  La pr√≥xima gran <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Python Conf ++</a> de Mosc√∫ se celebrar√° en Mosc√∫ <b>el 5 de abril</b> .  Este a√±o intentaremos ajustar todos los beneficios en un d√≠a en modo experimental.  No habr√° menos informes, asignaremos una secuencia completa a desarrolladores extranjeros de bibliotecas y productos conocidos.  Adem√°s, el viernes es un d√≠a ideal para fiestas posteriores, que, como saben, es una parte integral de la conferencia sobre comunicaci√≥n. <br><br>  √önase a nuestra conferencia profesional de Python: env√≠e su informe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> , reserve su boleto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> .  Mientras tanto, los preparativos est√°n en marcha, los art√≠culos sobre Moscow Python Conf ++ 2018 aparecer√°n aqu√≠. <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es433476/">https://habr.com/ru/post/es433476/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es433460/index.html">Simplifique las construcciones de edificios en Unity3D</a></li>
<li><a href="../es433466/index.html">Compara p√°ginas. Complemento simple para Atlassian Confluence</a></li>
<li><a href="../es433468/index.html">Inyecci√≥n de fallas: su sistema no es confiable si no ha intentado romperlo</a></li>
<li><a href="../es433472/index.html">Lanzamiento de Unity 2018.3</a></li>
<li><a href="../es433474/index.html">Pylint de adentro hacia afuera. Como lo hace</a></li>
<li><a href="../es433478/index.html">Por qu√© Django es elegido en la revista Tinkoff</a></li>
<li><a href="../es433480/index.html">Holivarny historia sobre linter</a></li>
<li><a href="../es433482/index.html">Django bajo microscopio</a></li>
<li><a href="../es433486/index.html">Que otra vez La reactivaci√≥n de las tarjetas de d√©bito no bancarias</a></li>
<li><a href="../es433488/index.html">Christmas Scrum Meetup UPD Broadcast mitap</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï¥üèø üßóüèæ üïò Uma introdu√ß√£o ao Kubernetes para usu√°rios do VMware. Parte 1. Teoria üíû üïµüèª üî™</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Esta √© a segunda parte dos meus Kubernetes na s√©rie de postagens Enterprise . Como mencionei na minha √∫ltima postagem, √© muito importante, ao passar p...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Uma introdu√ß√£o ao Kubernetes para usu√°rios do VMware. Parte 1. Teoria</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dataline/blog/436028/">  Esta √© a segunda parte dos meus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kubernetes na</a> s√©rie de postagens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Enterprise</a> .  Como mencionei na minha √∫ltima postagem, √© muito importante, ao passar para os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">"Guias de design e implementa√ß√£o", que</a> todos estejam no mesmo n√≠vel de entendimento dos Kubernetes (K8s). <br><br>  N√£o quero usar a abordagem tradicional aqui para explicar a arquitetura e as tecnologias do Kubernetes, mas explicarei tudo por meio de uma compara√ß√£o com a plataforma vSphere, com a qual voc√™, como usu√°rio do VMware, conhece.  Isso permitir√° que voc√™ supere a aparente confus√£o e o peso da compreens√£o do Kubernetes.  Usei essa abordagem dentro da VMware para apresentar o Kubernetes a diferentes p√∫blicos de ouvintes, e provou que funciona muito bem e ajuda as pessoas a se acostumarem aos conceitos-chave mais rapidamente. <br><br>  Nota importante antes de come√ßarmos.  N√£o uso essa compara√ß√£o para provar semelhan√ßas ou diferen√ßas entre o vSphere e o Kubernetes.  Tanto esse como outro, em ess√™ncia, s√£o sistemas distribu√≠dos e, portanto, devem ter semelhan√ßas com qualquer outro sistema semelhante.  Portanto, no final, tento introduzir uma tecnologia maravilhosa como o Kubernetes em uma ampla comunidade de usu√°rios. <br><img src="https://habrastorage.org/webt/2x/8j/gn/2x8jgnlfylvf_sfzkylizlg3huk.png"><a name="habracut"></a><br><br><h3>  Um pouco de hist√≥ria </h3><br>  A leitura deste post envolve conhecer os cont√™ineres.  N√£o descreverei os conceitos b√°sicos de cont√™ineres, pois h√° muitos recursos que falam sobre isso.  Conversando com os clientes com muita frequ√™ncia, vejo que eles n√£o conseguem entender por que os cont√™ineres conquistaram nossa ind√∫stria e se tornaram muito populares em tempo recorde.  Para responder a essa pergunta, falarei sobre minha experi√™ncia pr√°tica no entendimento das mudan√ßas que est√£o ocorrendo em nosso setor. <br><br>  Antes de explorar o mundo das telecomunica√ß√µes, fui desenvolvedor da Web (2003). <br><br>  Este foi meu segundo trabalho remunerado depois que trabalhei como engenheiro / administrador de rede (eu sei que eu era o melhor de todos os neg√≥cios).  Eu desenvolvi em PHP.  Desenvolvi todos os tipos de aplicativos, come√ßando pelos pequenos que meu empregador usava, terminando com um aplicativo de vota√ß√£o profissional para programas de televis√£o e at√© aplicativos de telecomunica√ß√µes que interagem com hubs VSAT e sistemas de sat√©lite.  A vida foi √≥tima, com exce√ß√£o de um grande obst√°culo que todo desenvolvedor conhece: seus v√≠cios. <br><br>  No come√ßo, desenvolvi o aplicativo no meu laptop, usando algo como a pilha LAMP, quando funcionou bem no meu laptop, baixei o c√≥digo-fonte para os servidores host (todo mundo se lembra do RackShack?) Ou para os clientes privados.  Voc√™ pode imaginar que, assim que eu fiz isso, o aplicativo travou e n√£o funcionou nesses servidores.  A raz√£o para isso √© o v√≠cio.  Os servidores tinham outras vers√µes do software (Apache, PHP, MySQL, etc.) al√©m daquelas usadas por mim no laptop.  Ent√£o, eu precisava encontrar uma maneira de atualizar as vers√µes do software nos servidores remotos (m√° ideia) ou reescrever o c√≥digo no meu laptop para corresponder √†s vers√µes nos servidores remotos (pior id√©ia).  Era um pesadelo, √†s vezes eu me odiava e me perguntava por que √© assim que eu ganho a vida. <br><br>  10 anos se passaram, a empresa Docker apareceu.  Como consultor da VMware na Professional Services (2013), ouvi falar do Docker e deixe-me dizer que n√£o conseguia entender essa tecnologia naquela √©poca.  Continuei dizendo algo como: por que usar cont√™ineres se houver m√°quinas virtuais.  Por que desistir de tecnologias importantes como o vSphere HA, DRS ou vMotion devido a vantagens estranhas como o lan√ßamento instant√¢neo de cont√™ineres ou a elimina√ß√£o da sobrecarga do hipervisor.  Afinal, todo mundo trabalha com m√°quinas virtuais e funciona perfeitamente.  Em resumo, eu olhei para ele em termos de infraestrutura. <br><br>  Mas ent√£o comecei a olhar de perto e me dei conta.  Tudo relacionado ao Docker est√° relacionado aos desenvolvedores.  Apenas come√ßando a pensar como desenvolvedor, percebi imediatamente que, se tivesse essa tecnologia em 2003, poderia empacotar todas as minhas depend√™ncias.  Meus aplicativos da Web podem funcionar independentemente do servidor usado.  Al√©m disso, n√£o seria necess√°rio fazer o download do c√≥digo-fonte ou configurar algo.  Voc√™ pode simplesmente "empacotar" meu aplicativo em uma imagem e solicitar aos clientes que baixem e executem essa imagem.  Este √© o sonho de qualquer desenvolvedor da Web! <br><br>  Tudo isso √© √≥timo.  O Docker resolveu o enorme problema de intera√ß√£o e empacotamento, mas e agora?  Como cliente corporativo, posso gerenciar esses aplicativos durante o dimensionamento?  Ainda quero usar HA, DRS, vMotion e DR.  O Docker resolveu os problemas dos meus desenvolvedores e criou v√°rios problemas para os meus administradores (equipe do DevOps).  Eles precisam de uma plataforma para o lan√ßamento de cont√™ineres, a mesma que para o lan√ßamento de m√°quinas virtuais.  E voltamos novamente ao come√ßo. <br><br>  Mas ent√£o o Google apareceu, dizendo ao mundo sobre o uso de cont√™ineres por muitos anos (na verdade, os cont√™ineres foram inventados pelo Google: cgroups) e o m√©todo correto de us√°-los, por meio de uma plataforma que eles chamavam de Kubernetes.  Ent√£o eles abriram o c√≥digo fonte do Kubernetes.  Apresentado √† comunidade Kubernetes.  E isso mudou tudo novamente. <br><br><h3>  Compreendendo o Kubernetes versus o vSphere </h3><br>  Ent√£o, o que √© o Kubernetes?  Simplificando, o Kubernetes para cont√™ineres √© o mesmo que o vSphere para m√°quinas virtuais em um datacenter moderno.  Se voc√™ usou o VMware Workstation no in√≠cio dos anos 2000, sabe que essa solu√ß√£o foi seriamente considerada uma solu√ß√£o para data centers.  Quando o VI / vSphere com hosts vCenter e ESXi apareceu, o mundo das m√°quinas virtuais mudou drasticamente.  Hoje, a Kubernetes est√° fazendo a mesma coisa com o mundo dos cont√™ineres, trazendo a capacidade de lan√ßar e gerenciar cont√™ineres na produ√ß√£o.  E √© por isso que come√ßaremos a comparar o vSphere lado a lado com o Kubernetes para explicar os detalhes desse sistema distribu√≠do e entender suas fun√ß√µes e tecnologias. <br><img src="https://habrastorage.org/webt/2l/ke/vg/2lkevgzxfllfuhfd29vtofvm4ii.png"><br><br><h3>  Vis√£o geral do sistema </h3><br>  Como no vSphere, existem hosts vCenter e ESXi no conceito de Kubernetes, existem Master e Node.  Nesse contexto, o mestre em K8s √© equivalente ao vCenter, no sentido de que √© o plano de gerenciamento de um sistema distribu√≠do.  √â tamb√©m o ponto de entrada da API com a qual voc√™ interage ao gerenciar sua carga de trabalho.  Da mesma forma, os n√≥s do K8s funcionam como recursos de computa√ß√£o, semelhantes aos hosts ESXi.  √â neles que voc√™ executa cargas de trabalho (no caso dos K8s, os chamamos de Pods).  Os n√≥s podem ser m√°quinas virtuais ou servidores f√≠sicos.  Obviamente, com o vSphere ESXi, os hosts sempre devem ser f√≠sicos. <br><img src="https://habrastorage.org/webt/to/va/hq/tovahqozye9ym14sljwpbilywto.png"><br><br>  Voc√™ pode ver que o K8s possui um armazenamento de valores-chave chamado ‚Äúetcd‚Äù.  Esse armazenamento √© semelhante ao banco de dados do vCenter, onde voc√™ salva a configura√ß√£o de cluster desejada √† qual deseja aderir. <br><br>  Quanto √†s diferen√ßas: no Master K8s voc√™ tamb√©m pode executar cargas de trabalho, mas no vCenter, n√£o.  O vCenter √© um dispositivo virtual dedicado apenas ao gerenciamento.  No caso dos K8s, o Master √© considerado um recurso de computa√ß√£o, mas executar aplicativos Enterprise nele n√£o √© uma boa ideia. <br><br>  Ent√£o, como ser√° a realidade?  Voc√™ usar√° principalmente a CLI para interagir com o Kubernetes (mas a GUI ainda √© uma op√ß√£o muito vi√°vel).  A captura de tela abaixo mostra que estou usando uma m√°quina Windows para conectar-me ao meu cluster Kubernetes atrav√©s da linha de comando (eu uso o cmder se voc√™ estiver interessado).  Na captura de tela, tenho um n√≥ mestre e 4 n√≥s.  Eles funcionam sob o controle do K8s v1.6.5, e o sistema operacional (SO) Ubuntu 16.04 √© instalado nos n√≥s.  No momento em que escrevemos este post, viv√≠amos principalmente no mundo Linux, onde o Master e o Node sempre executavam uma distribui√ß√£o Linux. <br><br><img src="https://habrastorage.org/webt/gm/qn/gj/gmqngjq1mraqces6uo1sectxm6i.png"><br>  <i>Gerenciamento de cluster K8s por meio de CLI e GUI.</i> <br><br><h3>  Fator de forma da carga de trabalho </h3><br>  No vSphere, a m√°quina virtual √© o limite l√≥gico do sistema operacional.  No Kubernetes, os Pods s√£o limites de cont√™iner, assim como o host ESXi, que pode executar v√°rias m√°quinas virtuais simultaneamente.  Cada n√≥ pode executar v√°rios pods.  Cada Pod recebe um endere√ßo IP rote√°vel, como m√°quinas virtuais, para que os Pods se comuniquem. <br><br>  No vSphere, os aplicativos s√£o executados dentro do sistema operacional e, no Kubernetes, os aplicativos s√£o executados dentro de cont√™ineres.  Uma m√°quina virtual pode trabalhar apenas com um sistema operacional por vez e um Pod pode executar v√°rios cont√™ineres. <br><img src="https://habrastorage.org/webt/hv/cv/9b/hvcv9bj4gw6wsunhhqeqvvfx5d4.png"><br><br>  √â assim que voc√™ pode listar os Pods dentro do cluster K8s usando a ferramenta kubectl por meio da CLI, verificar a capacidade de trabalho dos Pods, sua idade, endere√ßo IP e N√≥s nos quais eles est√£o trabalhando atualmente. <br><img src="https://habrastorage.org/webt/0u/qj/_0/0uqj_0gl0qmxiqbby9gd8ln98nc.png"><br><br><h3>  Ger√™ncia </h3><br>  Ent√£o, como gerenciamos nossos mestres, n√≥s e pods?  No vSphere, usamos o cliente da Web para gerenciar a maioria (se n√£o todos) os componentes de nossa infraestrutura virtual.  Para o Kubernetes, da mesma forma, usando o Painel.  Este √© um bom portal da Web baseado em GUI que voc√™ pode acessar atrav√©s do navegador da mesma maneira que no vSphere Web Client.  Nas se√ß√µes anteriores, voc√™ pode ver que √© poss√≠vel gerenciar seu cluster K8s usando o comando kubeclt da CLI.  √â sempre discut√≠vel onde voc√™ passar√° a maior parte do tempo na CLI ou no painel gr√°fico.  Como o √∫ltimo est√° se tornando uma ferramenta cada vez mais poderosa todos os dias (voc√™ pode ver este v√≠deo, com certeza).  Pessoalmente, acho que o Painel √© muito conveniente para monitorar rapidamente o status ou exibir os detalhes de v√°rios componentes do K8s, eliminando a necessidade de inserir comandos longos na CLI.  Voc√™ encontrar√° um equil√≠brio entre eles de uma maneira natural. <br><br><img src="https://habrastorage.org/webt/hi/hu/cj/hihucj_bhrydsrgy0ad5xifupuc.png"><br><br><h3>  Configura√ß√µes </h3><br>  Um dos conceitos muito importantes no Kubernetes √© o estado desejado das configura√ß√µes.  Voc√™ declara o que deseja para quase qualquer componente do Kubernetes atrav√©s de um arquivo YAML e cria tudo isso usando o kubectl (ou atrav√©s de um painel gr√°fico) como o estado desejado.  A partir de agora, o Kubernetes sempre se esfor√ßar√° para manter o ambiente em um determinado estado operacional.  Por exemplo, se voc√™ quiser ter 4 r√©plicas de um Pod, o K8s continuar√° monitorando esses Pods e, se um deles morrer ou o N√≥ no qual ele trabalhou tiver problemas, o K8s se recuperar√° automaticamente e criar√° automaticamente Pod em outro lugar. <br><br>  Voltando aos nossos arquivos de configura√ß√£o YAML, voc√™ pode consider√°-los como um arquivo .VMX para uma m√°quina virtual ou um descritor .OVF para um dispositivo virtual que deseja implantar no vSphere.  Esses arquivos definem a configura√ß√£o da carga de trabalho / componente que voc√™ deseja executar.  Ao contr√°rio dos arquivos VMX / OVF, exclusivos das VMs / Appliances virtuais, os arquivos de configura√ß√£o YAML s√£o usados ‚Äã‚Äãpara definir qualquer componente do K8s, como ReplicaSets, Services, Deployments, etc.  Considere isso nas se√ß√µes a seguir. <br><img src="https://habrastorage.org/webt/qg/2w/np/qg2wnppfqeu9ksyev67haaiz19m.png"><br><br><h3>  Clusters virtuais </h3><br>  No vSphere, temos hosts f√≠sicos do ESXi agrupados logicamente em clusters.  Esses clusters podem ser divididos em outros clusters virtuais chamados "Pools de Recursos".  Esses "pools" s√£o usados ‚Äã‚Äãprincipalmente para limitar recursos.  No Kubernetes, temos algo muito semelhante.  N√≥s os chamamos de "Namespaces", eles tamb√©m podem ser usados ‚Äã‚Äãpara fornecer limites de recursos, que ser√£o refletidos na pr√≥xima se√ß√£o.  No entanto, na maioria das vezes, ‚ÄúNamespaces‚Äù s√£o usados ‚Äã‚Äãcomo uma ferramenta de multiloca√ß√£o para aplicativos (ou usu√°rios, se voc√™ usar clusters K8s comuns).  Essa tamb√©m √© uma das op√ß√µes com as quais voc√™ pode executar a segmenta√ß√£o de rede usando o NSX-T.  Considere isso nas seguintes publica√ß√µes. <br><img src="https://habrastorage.org/webt/n6/ve/kr/n6vekro9uz1bx9i_0kqgxquyduw.png"><br><br><h3>  Gerenciamento de recursos </h3><br>  Como mencionei na se√ß√£o anterior, os espa√ßos para nome no Kubernetes s√£o comumente usados ‚Äã‚Äãcomo um meio de segmenta√ß√£o.  Outro uso de namespaces √© a aloca√ß√£o de recursos.  Esta op√ß√£o √© chamada "Cotas de recursos".  Como segue nas se√ß√µes anteriores, a defini√ß√£o disso ocorre nos arquivos YAML de configura√ß√£o, nos quais o estado desejado √© declarado.  No vSphere, como pode ser visto na captura de tela abaixo, determinamos isso nas configura√ß√µes de pools de recursos. <br><img src="https://habrastorage.org/webt/jq/oy/nl/jqoynlerkguited5ozdgsndtj4w.png"><br><br><h3>  Identifica√ß√£o da carga de trabalho </h3><br>  Isso √© bastante simples e quase o mesmo para vSphere e Kubernetes.  No primeiro caso, usamos os conceitos de Tags para definir (ou agrupar) cargas de trabalho semelhantes e, no segundo, usamos o termo "Labels".  No caso do Kubernetes, a identifica√ß√£o da carga de trabalho √© obrigat√≥ria. <br><img src="https://habrastorage.org/webt/j_/2s/go/j_2sgoekii7mwswdmhspterznoq.png"><br><br><h3>  Reserva </h3><br>  Agora para se divertir de verdade.  Se voc√™ era ou √© um grande f√£ do vSphere FT, como eu, adorar√° esse recurso no Kubernetes, apesar de algumas diferen√ßas nas duas tecnologias.  No vSphere, √© uma m√°quina virtual com uma inst√¢ncia de sombra em execu√ß√£o em um host diferente.  Registramos instru√ß√µes na m√°quina virtual principal e as reproduzimos na m√°quina virtual sombra.  Se a m√°quina principal parar de funcionar, a m√°quina virtual sombra ser√° ligada imediatamente.  Em seguida, o vSphere tenta encontrar outro host ESXi para criar uma nova inst√¢ncia de sombra da m√°quina virtual para manter a mesma redund√¢ncia.  No Kubernetes, temos algo muito semelhante.  ReplicaSets √© a quantia especificada para executar v√°rias inst√¢ncias dos Pods.  Se um Pod falhar, outras inst√¢ncias estar√£o dispon√≠veis para veicular tr√°fego.  Ao mesmo tempo, o K8s tentar√° iniciar um novo Pod em qualquer n√≥ dispon√≠vel para manter o estado de configura√ß√£o desejado.  A principal diferen√ßa, como voc√™ j√° deve ter notado, √© que, no caso dos K8s, os Pods sempre funcionam e atendem ao tr√°fego.  Eles n√£o s√£o cargas de trabalho de sombra. <br><img src="https://habrastorage.org/webt/29/u-/sd/29u-sdyxbg1n0qdzwpkwjmcyuxe.png"><br><br><h3>  Balanceamento de carga </h3><br>  Embora isso possa n√£o ser uma fun√ß√£o interna do vSphere, √© muito, muitas vezes necess√°rio, executar balanceadores de carga na plataforma.  No mundo do vSphere, existem balanceadores de carga f√≠sicos ou virtuais para distribuir o tr√°fego de rede entre v√°rias m√°quinas virtuais.  Pode haver muitos modos de configura√ß√£o diferentes, mas vamos supor que queremos dizer configura√ß√£o One-Armed.  Nesse caso, voc√™ equilibra a carga do tr√°fego Leste-Oeste em suas m√°quinas virtuais. <br><br>  Da mesma forma, o Kubernetes tem o conceito de "Servi√ßos".  O servi√ßo no K8s tamb√©m pode ser usado em diferentes modos de configura√ß√£o.  Vamos escolher a configura√ß√£o ‚ÄúClusterIP‚Äù para compar√°-la com o One-Armed Load Balancer.  Nesse caso, o Servi√ßo no K8s ter√° um endere√ßo IP virtual (VIP), que √© sempre est√°tico e n√£o muda.  Este VIP distribuir√° o tr√°fego entre v√°rios Pods.  Isso √© especialmente importante no mundo Kubernetes, onde por natureza os Pods s√£o ef√™meros, voc√™ perde o endere√ßo IP do Pod no momento em que morre ou √© exclu√≠do.  Portanto, voc√™ sempre deve fornecer um VIP est√°tico. <br><br>  Como j√° mencionei, o Servi√ßo possui muitas outras configura√ß√µes, por exemplo, "NodePort", nas quais voc√™ atribui uma porta no n√≠vel do N√≥ e executa a tradu√ß√£o de convers√£o de endere√ßo de porta para os Pods.  H√° tamb√©m um ‚ÄúLoadBalancer‚Äù em que voc√™ executa uma inst√¢ncia do Load Balancer de um provedor de terceiros ou na nuvem. <br><img src="https://habrastorage.org/webt/s9/4g/my/s94gmy5frfcjkyxeywlp3gcwtkm.png"><br><br>  Kuberentes tem outro mecanismo de balanceamento de carga muito importante chamado "Controlador de ingresso".  Voc√™ pode consider√°-lo um balanceador de carga de aplicativos em linha.  A id√©ia principal √© que o Ingress Controller (na forma de um Pod) seja iniciado com um endere√ßo IP vis√≠vel de fora.  Esse endere√ßo IP pode ter algo como registros DNS curinga.  Quando o tr√°fego chega ao Ingress Controller usando um endere√ßo IP externo, ele verifica os cabe√ßalhos e determina o conjunto de regras que voc√™ definiu anteriormente a qual Pod esse nome pertence.  Por exemplo: sphinx-v1.esxcloud.net ser√° direcionado ao Servi√ßo sphinx-svc-1 e sphinx-v2.esxcloud.net ser√° direcionado ao Servi√ßo sphinx-svc2, etc. <br><img src="https://habrastorage.org/webt/fk/jr/t_/fkjrt_3ho51djc-euoshgcjccas.png"><br><br><h3>  Armazenamento e Rede </h3><br>  Armazenamento e rede s√£o t√≥picos muito, muito amplos, quando se trata do Kubernetes.  √â quase imposs√≠vel falar brevemente sobre esses dois t√≥picos em um post introdut√≥rio, mas em breve irei falar detalhadamente sobre os diferentes conceitos e op√ß√µes para cada um desses t√≥picos.  Enquanto isso, vamos ver rapidamente como a pilha de rede funciona no Kubernetes, pois precisaremos dela na pr√≥xima se√ß√£o. <br><br>  O Kubernetes possui v√°rios "plug-ins" de rede que voc√™ pode usar para configurar a rede de seus n√≥s e pods.  Um plug-in comum √© o ‚Äúkubenet‚Äù, atualmente usado em mega-nuvens, como GCP e AWS.  Aqui, falarei brevemente sobre a implementa√ß√£o do GCP e depois mostrarei um exemplo pr√°tico de implementa√ß√£o no GKE. <br><img src="https://habrastorage.org/webt/vc/vh/n6/vcvhn6ll9s46qdbwvurxheaykg8.png"><br><br>  √Ä primeira vista, isso pode parecer muito complicado, mas espero que voc√™ possa entender tudo isso at√© o final deste post.  Primeiramente, vemos que temos dois n√≥s Kubernetes: N√≥ 1 e N√≥ (m).  Cada n√≥ tem uma interface eth0, como qualquer m√°quina Linux.  Essa interface possui um endere√ßo IP para o mundo exterior, no nosso caso, na sub-rede 10.140.0.0/24.  O dispositivo Upstream L3 atua como o Gateway padr√£o para rotear nosso tr√°fego.  Pode ser um switch L3 no seu datacenter ou um roteador VPC na nuvem, como o GCP, como veremos mais adiante.  Est√° tudo bem? <br><br>  Al√©m disso, vemos que temos a interface Bridge cbr0 dentro do n√≥.  Essa interface √© o Gateway Padr√£o da sub-rede IP 10.40.1.0/24 no caso do N√≥ 1. Essa sub-rede √© atribu√≠da pelo Kubernetes a cada N√≥.  Os n√≥s geralmente obt√™m uma sub-rede / 24, mas voc√™ pode alterar isso usando o NSX-T (abordaremos isso nas pr√≥ximas postagens).  No momento, √© essa sub-rede a partir da qual emitiremos endere√ßos IP para os Pods.  Dessa forma, qualquer Pod dentro do N√≥ 1 obter√° um endere√ßo IP dessa sub-rede.  No nosso caso, o Pod 1 tem um endere√ßo IP 10.40.1.10.  No entanto, voc√™ percebe que existem dois cont√™ineres aninhados neste Pod.  J√° dissemos que em um Pod um ou v√°rios cont√™ineres podem ser lan√ßados, que est√£o intimamente relacionados entre si em termos de funcionalidade.  √â o que vemos na figura.  O cont√™iner 1 escuta na porta 80 e o cont√™iner 2 escuta na porta 90. Os dois cont√™ineres t√™m o mesmo endere√ßo IP 10.40.1.10, mas n√£o possuem o Espa√ßo de Nomes de Rede.  OK, ent√£o quem √© o dono dessa pilha de rede?  Na verdade, existe um cont√™iner especial chamado "Pausar cont√™iner".  O diagrama mostra que seu endere√ßo IP √© o endere√ßo IP do Pod para comunica√ß√£o com o mundo exterior.  Portanto, o Pause Container possui essa pilha de rede, incluindo o pr√≥prio endere√ßo IP 10.40.1.10 e, √© claro, redireciona o tr√°fego para o cont√™iner 1 para a porta 80 e tamb√©m redireciona o tr√°fego para o cont√™iner 2 para a porta 90. <br><br>  Agora voc√™ precisa perguntar como o tr√°fego √© redirecionado para o mundo exterior?  Temos o encaminhamento de IP padr√£o do Linux habilitado para encaminhar o tr√°fego de cbr0 para eth0.  Isso √© √≥timo, mas n√£o est√° claro como o dispositivo L3 pode aprender a encaminhar o tr√°fego para o destino.  Neste exemplo espec√≠fico, n√£o temos roteamento din√¢mico para o an√∫ncio desta rede.  Portanto, devemos ter algum tipo de rota est√°tica no dispositivo L3.  Para alcan√ßar a sub-rede 10.40.1.0/24, √© necess√°rio encaminhar o tr√°fego para o endere√ßo IP do N√≥ 1 (10.140.0.11) e para alcan√ßar a sub-rede 10.40.2.0/24 a pr√≥xima esperan√ßa - N√≥ (m) com o endere√ßo IP 10.140.0.12. <br><br>  Tudo isso √© √≥timo, mas √© uma maneira muito impratic√°vel de gerenciar suas redes.  O suporte a todas essas rotas ao escalonar seu cluster ser√° um pesadelo absoluto para os administradores de rede.  √â por isso que algumas solu√ß√µes, como CNI (Container Network Interface) em Kuberentes, s√£o necess√°rias para gerenciar a conectividade de rede.  O NSX-T √© uma dessas solu√ß√µes com funcionalidade muito ampla para intera√ß√£o e seguran√ßa da rede. <br><br>  Lembre-se de que analisamos o plugin kubenet, n√£o a CNI.  O plug-in kubenet √© o que o Google Container Engine (GKE) usa, e a maneira como eles fazem isso √© bastante divertida porque √© totalmente definido por software e automatizado em sua nuvem.  ,            GCP.     . <br><br><h3>  O que vem a seguir? </h3><br>     Kuberentes.        ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">   </a> . <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A segunda parte.</a> <br><br>     .    . <br>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt436028/">https://habr.com/ru/post/pt436028/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt436016/index.html">IVR de reconhecimento de voz do Asterisk - r√°pido, f√°cil e gratuito</a></li>
<li><a href="../pt436020/index.html">Magento 2: importando produtos de fontes externas</a></li>
<li><a href="../pt436022/index.html">Como desenvolvemos completamente o Librem 5 DevKit em software livre</a></li>
<li><a href="../pt436024/index.html">Como n√£o jogar lixo em Java</a></li>
<li><a href="../pt436026/index.html">Info Desk: ‚ÄúInternet Archive‚Äù - hist√≥ria, miss√£o e projetos subsidi√°rios</a></li>
<li><a href="../pt436032/index.html">Tutorial Reagir Parte 9: Propriedades do componente</a></li>
<li><a href="../pt436036/index.html">Os pesquisadores de intelig√™ncia artificial podem confiar a ele um teste de seu trabalho?</a></li>
<li><a href="../pt436038/index.html">O som do sil√™ncio: quantos gadgets malucos s√£o necess√°rios para alcan√ßar um ambiente ideal para dormir?</a></li>
<li><a href="../pt436040/index.html">Otimiza√ß√£o de gr√°ficos. Casco c√¥ncavo interessante</a></li>
<li><a href="../pt436042/index.html">Painel de ferramentas adicionais para o desenvolvedor no InterSystems IRIS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
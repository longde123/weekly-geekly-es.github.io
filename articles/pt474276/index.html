<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ö∞Ô∏è ü§úüèª üöî ‚ÄúTreinamento de refor√ßo profundo. AlphaGo e outras tecnologias ": o an√∫ncio do livro üßëüèø üé¥ üßõüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√° pessoal! 

 Temos um dos melhores livros sobre treinamento de refor√ßo dispon√≠veis para pr√©-encomenda, originalmente chamado de " Deep Reforcement ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>‚ÄúTreinamento de refor√ßo profundo. AlphaGo e outras tecnologias ": o an√∫ncio do livro</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/474276/">  Ol√° pessoal! <br><br>  Temos um dos melhores livros sobre treinamento de refor√ßo dispon√≠veis para pr√©-encomenda, originalmente chamado de " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Deep Reforcement Learning Hands-on</a> " de Maxim Lapan.  Aqui est√° a capa da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tradu√ß√£o para</a> o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">russo</a> : <br><br><img src="https://habrastorage.org/webt/av/ig/n-/avign-oqnxjpgpptv7irkkwsope.jpeg"><br><br>  Para que voc√™ possa apreciar o resumo do livro, oferecemos uma tradu√ß√£o da resenha escrita pelo autor at√© o lan√ßamento do original. <br><a name="habracut"></a><br><br>  Oi <br><br>  Sou um entusiasta autodidata que gosta de aprender profundamente.  Portanto, quando representantes da editora Packt entraram em contato comigo e sugeriram escrever um livro pr√°tico sobre o estado atual do aprendizado profundo com refor√ßo, fiquei um pouco assustado, mas depois de alguma hesita√ß√£o, concordei, assumindo com otimismo: "Oh, haver√° uma experi√™ncia interessante". <br>  N√£o direi que esse trabalho me foi dado como uma caminhada f√°cil, claro que n√£o.  Voc√™ n√£o tem dias de folga, tempo livre, medo constante de "estupidez congelante" e a busca de prazos para cada cap√≠tulo (duas semanas por cap√≠tulo e c√≥digo de exemplo).  No entanto, em geral, tudo correu de forma positiva e muito interessante. <br><br>  Antes de descrever brevemente o conte√∫do de cada cap√≠tulo, vamos descrever a <i>id√©ia de todo o livro</i> . <br>  Quando comecei a experimentar RL h√° mais de quatro anos, eu tinha √† minha disposi√ß√£o as seguintes fontes de informa√ß√£o: <br><br><ul><li>  Livro de Sutton e Barto sobre o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aprendizado por refor√ßo: uma introdu√ß√£o</a> </li><li>  Artigos cient√≠ficos em <a href="">arxiv.org</a> </li><li>  O curso de David Silver. </li></ul><br><br>  Talvez houvesse algo mais, mas essas eram as fontes de informa√ß√£o mais importantes.  Todos eles est√£o muito longe da pr√°tica: <br><br><ul><li>  O livro de Sutton e Barto, tamb√©m conhecido como "O livro da RL", fornece apenas os fundamentos te√≥ricos dessa disciplina. </li><li>  Os artigos relacionados √† RL s√£o publicados quase diariamente, mas ainda raramente cont√™m links para c√≥digo espec√≠fico.  Somente f√≥rmulas e algoritmos.  Se voc√™ tiver sorte, ser√£o indicados hiper par√¢metros. </li><li>  O curso de David Silver foi ministrado na University College London (UCL) em 2015.  Ele fornece uma vis√£o geral muito boa dos m√©todos que existiam na √©poca, permitindo que eles sejam dominados intuitivamente; no entanto, aqui a teoria novamente prevalece sobre a pr√°tica. </li></ul><br><br>  Ao mesmo tempo, fiquei profundamente viciado no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo DeepMind</a> ("Uma rede neural pode aprender a jogar jogos da Atari em pixels! WOW!"), E senti que essa teoria seca esconde um enorme valor pr√°tico.  Ent√£o, passei muito tempo estudando a teoria, implementando v√°rios m√©todos e depurando-os.  Como voc√™ provavelmente adivinhou, n√£o foi f√°cil: voc√™ pode passar algumas semanas aprimorando o m√©todo e depois descobrir que sua implementa√ß√£o est√° incorreta (ou, pior ainda, voc√™ n√£o entendeu a f√≥rmula).  N√£o considero esse treinamento uma perda de tempo - pelo contr√°rio, acho que essa √© a maneira mais correta de aprender alguma coisa.  No entanto, isso leva muito tempo. <br><br>  Dois anos depois, quando comecei a trabalhar no texto, meu objetivo principal era o seguinte: fornecer informa√ß√µes pr√°ticas completas sobre m√©todos de RL a um leitor que esteja familiarizado apenas com essa disciplina fascinante - como fiz uma vez. <br><br>  Agora um pouco sobre o livro.  Ele √© focado principalmente na pr√°tica, e tentei minimizar o volume de teoria e f√≥rmulas.  Ele cont√©m f√≥rmulas principais, mas nenhuma evid√™ncia √© fornecida.  Basicamente, tento dar uma compreens√£o intuitiva do que est√° acontecendo, sem buscar o m√°ximo rigor da apresenta√ß√£o. <br><br>  Ao mesmo tempo, sup√µe-se que o leitor tenha conhecimentos b√°sicos de aprendizado profundo e estat√≠stica.  H√° um cap√≠tulo no livro com uma vis√£o geral da biblioteca PyTorch (j√° que todos os exemplos s√£o dados usando o PyTorch), mas este cap√≠tulo n√£o pode ser considerado uma fonte auto-suficiente de informa√ß√µes sobre redes neurais.  Se voc√™ nunca ouviu falar das fun√ß√µes de perda e ativa√ß√£o antes, comece olhando para outros livros, hoje existem muitos.  (Nota: por exemplo, o livro " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Deep learning</a> "). <br><br>  No meu livro, voc√™ encontrar√° muitos exemplos de complexidade vari√°vel, come√ßando pelos mais simples (o m√©todo <code>CrossEntropy</code> no ambiente <code>CartPole</code> cont√©m ~ 100 linhas em python), terminando com projetos bastante grandes, por exemplo, aprendendo o AlphGo Zero ou um agente RL para negocia√ß√£o na bolsa.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O c√≥digo de amostra √© totalmente carregado no GitHub</a> ; existem mais de 14 mil linhas de c√≥digo no Python. <br><br>  O livro consiste em 18 cap√≠tulos que cobrem os aspectos mais importantes do aprendizado profundo moderno com refor√ßo: <br><br><ul><li>  <b>Cap√≠tulo 1</b> : fornece informa√ß√µes introdut√≥rias sobre o paradigma de aprendizado refor√ßado, demonstra como ele difere do aprendizado com e sem um professor.  Aqui, consideramos o modelo matem√°tico central relacionado ao aprendizado por refor√ßo: processos de tomada de decis√£o de Markov: (MPPR).  O conhecimento do MPNR foi feito passo a passo: falo sobre cadeias de Markov, que s√£o transformadas em processos de refor√ßo de Markov (com a adi√ß√£o de um componente de refor√ßo) e, finalmente, em processos de tomada de decis√£o de Markov de pleno direito, onde as a√ß√µes do agente tamb√©m s√£o levadas em conta no quadro geral. </li><li>  <b>Cap√≠tulo 2</b> : fala sobre o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenAI Gym</a> , uma API generalizada para RL, projetada para funcionar em uma variedade de ambientes, incluindo o Atari, resolvendo problemas cl√°ssicos, como CartPole, tarefas de aprendizado cont√≠nuo, etc. </li><li>  <b>Cap√≠tulo 3</b> : fornece uma vis√£o geral expressa da API do PyTorch.  Este cap√≠tulo n√£o pretendia ser um guia completo para a DL, no entanto, estabelece as bases para a compreens√£o de outros cap√≠tulos.  Se voc√™ usar outras ferramentas para resolver problemas profundos de aprendizado, ele dever√° servir como uma boa introdu√ß√£o ao belo modelo PyTorch, para facilitar a compreens√£o dos exemplos dos cap√≠tulos seguintes.  No final deste cap√≠tulo, ensinaremos um GAN simples que ir√° gerar e distinguir as capturas de tela do Atari de diferentes jogos. </li><li>  <b>Cap√≠tulo 4</b> : examina um dos m√©todos mais simples e poderosos: CrossEntropy.  Neste cap√≠tulo, ensinaremos a primeira rede que pode resolver problemas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ambiente CartPole</a> . </li><li>  <b>Cap√≠tulo 5</b> : Este cap√≠tulo inicia a <b>segunda parte do livro</b> sobre o algoritmo de itera√ß√£o para valores.  O Cap√≠tulo 5 discute uma maneira simples de treinar planilhas usando a equa√ß√£o de Bellman para resolver problemas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no ambiente FrozenLake</a> . </li><li>  <b>Cap√≠tulo 6</b> : Este cap√≠tulo apresenta os DQNs que jogam o jogo Atari.  A arquitetura do agente √© exatamente a mesma do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">famoso artigo DeepMind</a> . </li><li>  <b>Cap√≠tulo 7</b> : apresenta v√°rias extens√µes modernas de DQN para ajudar a melhorar a estabilidade e o desempenho do DQN subjacente.  Neste cap√≠tulo, os m√©todos do artigo " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Arco-√≠ris: combinando melhorias no Deep RL</a> ";  todos esses m√©todos s√£o implementados no cap√≠tulo e explico as id√©ias subjacentes a eles.  Esses m√©todos s√£o: DQN em uma etapa, DQN duplo, redes ruidosas, buffer de reprodu√ß√£o priorit√°rio, redes de duelo e redes de categorias.  No final do cap√≠tulo, todos os m√©todos s√£o combinados em um exemplo de c√≥digo comum, exatamente como foi feito no "artigo do arco-√≠ris". </li><li>  <b>Cap√≠tulo 8</b> : descreve o primeiro projeto de tamanho m√©dio, ilustrando o lado pr√°tico da RL na solu√ß√£o de problemas do mundo real.  Neste cap√≠tulo, usando o DQN, um agente √© treinado para executar opera√ß√µes na central. </li><li>  <b>Cap√≠tulo 9</b> : Este cap√≠tulo inicia a <b>terceira parte do</b> livro sobre t√©cnicas de gradiente de pol√≠ticas.  Nele nos familiarizamos com esses m√©todos, seus pontos fortes e fracos em compara√ß√£o com os m√©todos de enumera√ß√£o por valores j√° considerados acima.  O primeiro m√©todo nesta fam√≠lia √© chamado REFOR√áAR. </li><li>  <b>Cap√≠tulo 10</b> : descreve como lidar com um dos problemas mais s√©rios da RL: variabilidade do gradiente de pol√≠ticas.  Depois de experimentar os n√≠veis b√°sicos de PG, voc√™ se familiarizar√° com o m√©todo cr√≠tico de ator. </li><li>  <b>Cap√≠tulo 11</b> : fala sobre como paralelizar o m√©todo ator-cr√≠tico no hardware moderno. </li><li>  <b>Cap√≠tulo 12</b> : um segundo exemplo pr√°tico que descreve como resolver problemas associados ao processamento de linguagem natural.  Neste cap√≠tulo, ensinamos um chatbot simples a usar m√©todos RL no material da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">caixa de di√°logo do cinema Cornell</a> . </li><li>  <b>Cap√≠tulo 13</b> : outro exemplo pr√°tico de automa√ß√£o da web: o MiniWoB √© usado como plataforma.  Infelizmente, o OpenAI se recusou a usar o MiniWoB, por isso √© dif√≠cil encontrar informa√ß√µes sobre ele ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">est√£o</a> alguns gr√£os).  Mas a ideia do MiniWoB √© brilhante, portanto, neste cap√≠tulo, mostro como configurar e treinar o agente para resolver alguns dos problemas associados a ele. </li><li>  <b>Cap√≠tulo 14</b> : a √∫ltima, <b>quarta parte do</b> livro, dedicada a m√©todos e t√©cnicas mais avan√ßadas, come√ßa com ele.  O cap√≠tulo 14 se concentra nas tarefas de gerenciamento cont√≠nuo e descreve os m√©todos A3C, DDPG e D4PG para resolver problemas em alguns ambientes PyBullet. </li><li>  <b>Cap√≠tulo 15</b> : fala mais sobre problemas de gerenciamento cont√≠nuo e apresenta o fen√¥meno Trust Region usando TRPO, PPO e ACKTR como exemplos. </li><li>  <b>Cap√≠tulo 16</b> : dedicado a m√©todos de ensino com refor√ßo sem gradientes (trabalhando no princ√≠pio da "caixa preta");  eles s√£o posicionados como alternativas mais escalon√°veis ‚Äã‚Äãpara os m√©todos DQN e PG.  Estrat√©gias evolutivas e algoritmos gen√©ticos s√£o aplicados aqui para resolver v√°rios problemas de controle cont√≠nuo. </li><li>  <b>Cap√≠tulo 17</b> : examina abordagens de RL baseadas em modelo e descreve <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a tentativa do DeepMind de</a> preencher a lacuna entre m√©todos baseados em modelo e n√£o baseados em modelo.  Este cap√≠tulo implementa o agente I2A para Breakout. </li><li>  <b>Cap√≠tulo 18</b> : O cap√≠tulo final do livro discute o m√©todo AlphaGo Zero usado ao jogar o Connect4.  Em seguida, o agente finalizado √© usado como parte do bot de telegrama para verificar os resultados. </li></ul><br><br><br>  Isso √© tudo!  Espero que voc√™ goste do livro. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt474276/">https://habr.com/ru/post/pt474276/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt474252/index.html">Anima√ß√£o realista de personagens em jogos usando IA</a></li>
<li><a href="../pt474254/index.html">Criando um efeito pegajoso legal para um controle deslizante no React</a></li>
<li><a href="../pt474256/index.html">A ideia de encontrar pessoas na floresta</a></li>
<li><a href="../pt474268/index.html">Reconhecimento de circuitos digitais. Gatilho de contagem ass√≠ncrona</a></li>
<li><a href="../pt474274/index.html">Gr√°fico de conhecimento. Pluralidade, temporalidade, abordagem da atividade</a></li>
<li><a href="../pt474278/index.html">Python v3.x: como aumentar a velocidade do decorador sem registro e sms</a></li>
<li><a href="../pt474280/index.html">Deseja DBMS em primeira m√£o? Uma reuni√£o aberta em N√≠jni Novgorod - a ser</a></li>
<li><a href="../pt474282/index.html">Datacenter TCP explicado</a></li>
<li><a href="../pt474284/index.html">N√£o apenas futuros e op√ß√µes: que outros instrumentos financeiros secund√°rios existem nas bolsas e n√£o apenas</a></li>
<li><a href="../pt474286/index.html">An√°lise detalhada do m√©todo simplex</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
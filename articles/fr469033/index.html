<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶Å üçë ü•à Lancement de la plateforme Elbrus pour les r√©seaux neuronaux PuzzleLib ‚õ™Ô∏è üï∫üèΩ üëê</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="AI sur le fer domestique 
 Nous parlons de la fa√ßon dont nous avons port√© notre cadre pour les r√©seaux de neurones et le syst√®me de reconnaissance fac...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Lancement de la plateforme Elbrus pour les r√©seaux neuronaux PuzzleLib</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ashmanov_net/blog/469033/"><h3>  AI sur le fer domestique </h3><br>  Nous parlons de la fa√ßon dont nous avons port√© notre cadre pour les r√©seaux de neurones et le syst√®me de reconnaissance faciale sur les processeurs Elbrus russes. <br><br><img src="https://habrastorage.org/webt/e3/sq/qz/e3sqqz_1suglr-i19vtkvjaj3l4.png" alt="image"><br><br>  C'√©tait une t√¢che int√©ressante, au printemps 2019, nous en avons parl√© au bureau de Yandex lors de la grande r√©union sur Elbrus, que nous partageons maintenant avec Habr. <br><a name="habracut"></a><br><h3>  En bref - qu'est-ce que Elbrus </h3><br>  Il s'agit d'un processeur russe avec sa propre architecture, d√©velopp√© au <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MCST</a> .  Maxim Gorshenin parle bien de lui sur sa cha√Æne: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.youtube.com/watch?v=H8eBgJ58EPY</a> <br><br><h3>  En bref - qu'est-ce que PuzzleLib </h3><br>  Il s'agit de notre plateforme pour les r√©seaux de neurones, que nous d√©veloppons et utilisons depuis 2015.  Analogue de Google TensorFlow et Facebook PyTorch.  Fait int√©ressant, PuzzleLib prend en charge non seulement les processeurs NVIDIA et Intel, mais √©galement les cartes vid√©o AMD. <br><br>  Bien que nous ayons une petite biblioth√®que (TensorFlow a environ 2 millions de lignes, nous en avons 100 000), nous sommes meilleurs en vitesse - un peu, mais mieux =) <br><br>  Nous ne sommes pas encore en open source, la biblioth√®que est utilis√©e pour nos projets.  La biblioth√®que est compl√®te: elle prend en charge √† la fois la phase d'apprentissage et la phase d'inf√©rence des r√©seaux de neurones.  Vous pouvez cr√©er des r√©seaux de neurones convolutifs r√©currents, il existe √©galement une interface pour cr√©er des graphiques arbitraires de calculs. <br><br><h4>  PuzzleLib a </h4><br><ul><li>  Modules d'assemblage de r√©seaux de neurones (Activation (Sigmoid, Tanh, ReLU, ELU, LeakyReLU, SoftMaxPlus), AvgPool (1D, 2D, 3D), BatchNorm (1D, 2D, 3D, ND), Conv (1D, 2D, 3D, ND) , CrossMapLRN, Deconv (1D, 2D, 3D, ND), Dropout (1D, 2D), etc.) </li><li>  Optimiseurs (AdaDelta, AdaGrad, Adam, Hooks, LBFGS, MomentumSGD, NesterovSGD, RMSProp, etc.) </li><li>  R√©seaux de neurones pr√™ts √† l'emploi (Resnet, Inception, YOLO, U-Net, etc.) </li></ul><br>  Ce sont les blocs familiers, familiers √† tous ceux qui sont impliqu√©s dans les r√©seaux de neurones, pour les concepteurs de r√©seaux de neurones (puisque tous les cadres sont des constructeurs compos√©s de blocs de calcul et d'algorithmes typiques). <br><br>  <b>Nous avons eu l'id√©e de lancer notre biblioth√®que sur l'architecture Elbrus.</b> <b><br></b> <br><br><h3>  Pourquoi voulions-nous soutenir Elbrus? </h3><br><ol><li>  Ceci est le seul processeur russe, je voulais comprendre comment les choses vont avec, comment c'est facile de travailler avec. </li><li>  Nous avons pens√© qu'il pourrait √™tre int√©ressant pour les organisations √©tatiques que le logiciel russe que nous d√©veloppons fonctionne sur du mat√©riel russe. </li><li>  Et bien s√ªr, nous √©tions simplement int√©ress√©s, car Elbrus est un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">processeur VLIW</a> , c'est-√†-dire un processeur avec de longues instructions, et il n'y a pas de tels processeurs polyvalents √† part enti√®re dans le monde. </li></ol><br>  Tout a commenc√© avec le fait que nous avons rencontr√© le MCST, discut√© et pr√™t√© l'ordinateur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Elbrus 401</a> pour le d√©veloppement. <br><br>  <b>Ce que j'ai aim√©</b> : Linux fonctionne sur Elbrus, il y a du python dans ce Linux, et cela ne fonctionne pas en mode d'√©mulation - c'est un python natif √† part enti√®re, assembl√© pour Elbrus.  Il existe √©galement un ensemble de biblioth√®ques python standard, par exemple numpy, que tous les d√©veloppeurs adorent beaucoup. <br><br>  Il y avait certaines t√¢ches pour lesquelles nous devions √©galement collecter des biblioth√®ques: par exemple, dans PuzzleLib, nous utilisons le format hdf pour stocker les poids des r√©seaux de neurones, et, en cons√©quence, nous avons d√ª construire les biblioth√®ques libhdf et h5py √† l'aide du compilateur lcc.  Mais nous n'avons eu aucun probl√®me d'assemblage. <br><br>  La biblioth√®que de vision par ordinateur OpenCV √©tait √©galement d√©j√† compil√©e, mais il n'y avait aucune liaison pour python - nous l'avons construite s√©par√©ment. <br><br>  La c√©l√®bre biblioth√®que dlib est √©galement assez facile √† compiler.  Il n'y a eu que des difficult√©s mineures: certains fichiers de ce projet open source √©taient sans bom-marker pour d√©terminer utf-8, ce qui a boulevers√© le lexer lcc.  En fait, il y avait simplement un format de fichier incorrect, qui devait √™tre corrig√© dans la source. <br><br>  Nous avons d√©cid√© de commencer par la reconnaissance faciale.  Il s'agit d'un cas d'utilisation compr√©hensible pour beaucoup, o√π cette technologie est utilis√©e.  PuzzleLib, comme d'autres biblioth√®ques, a une partie backend assez grande, c'est-√†-dire une base de code sp√©cifique aux diff√©rentes architectures de processeur. <br><br>  <b>Nos backends:</b> <br><br><ul><li>  CUDA (NVIDIA) </li><li>  Ouvert CL + MI Ouvert (AMD) </li><li>  mlkDNN (Intel) </li><li>  CPU (numpy) </li></ul><br>  Sur Elbrus, nous avons lanc√© un backend numpy, ce qui √©tait tr√®s simple, car la plateforme n√©cessite un minimum de tout: <br><br>  <i>Plateforme -&gt; compilateur c90 -&gt; python -&gt; numpy</i> <br><br>  Nous avons une biblioth√®que sans complication (par exemple, sans aucun syst√®me d'assemblage sp√©cial) - en plus du fait que nous devions collecter certains classeurs.  Nous avons effectu√© les tests, tout fonctionne - les grilles convolutives et r√©currentes.  La reconnaissance faciale que nous avons lanc√©e est assez simple, bas√©e sur Inception-ResNet. <br><br>  <b>Premiers r√©sultats de travail</b> <br><br>  Sur Intel Core i7 7700, le temps de traitement pour une image √©tait de 0,1 seconde, et ici - 15. Il fallait optimiser. <br><br>  Bien s√ªr, esp√©rer que numpy fonctionnerait bien √† la vol√©e serait faux. <br><br><h3>  Comment nous avons optimis√© l'informatique </h3><br>  Nous avons mesur√© la vitesse d'inf√©rence √† travers le profileur python et d√©couvert que presque tout le temps √©tait consacr√© √† la multiplication des matrices en numpy.  Pour l'√©chantillon, ils ont √©crit la multiplication manuelle la plus simple de la matrice, et elle s'est d√©j√† av√©r√©e plus rapide, m√™me si on ne savait pas pourquoi. <br><br>  Il semblerait que numpy.dot aurait d√ª √™tre √©crit un peu moins na√Øf qu'une multiplication aussi simple.  N√©anmoins, nous avons convaincu, v√©rifi√© - cela s'est av√©r√© plus rapide (12 secondes par image au lieu de 15). <br><br>  Ensuite, nous avons d√©couvert la biblioth√®que d'alg√®bre lin√©aire EML, qui est en cours de d√©veloppement √† ICST, et avons remplac√© les appels np.dot par cblas_sgemm.  Il est devenu 10 fois plus rapide (1,5 seconde) - nous avons √©t√© tr√®s satisfaits. <br><br>  Cela a √©t√© suivi de plusieurs optimisations pas √† pas.  √âtant donn√© que nous n'utilisons que la reconnaissance des visages, et non des donn√©es g√©n√©ralement arbitraires, nous avons d√©cid√© d'affiner nos op√©rations uniquement sous les tenseurs 4d et de faire de Fusion - apr√®s quoi le temps de traitement a diminu√© de 2 fois - √† 0,75 seconde. <br><br>  Explication: La fusion est lorsque plusieurs op√©rations sont combin√©es en une seule, par exemple, la convolution, la normalisation et l'activation.  Au lieu de faire une passe en trois cycles, une passe est effectu√©e. <br><br>  Ces biblioth√®ques sont disponibles aupr√®s de NVIDIA ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TensorRT</a> ).  Un graphe de calcul y est charg√© et la biblioth√®que produit un graphe optimis√© et acc√©l√©r√©, en particulier du fait qu'elle peut regrouper les op√©rations en une seule.  Intel en a √©galement un similaire (nGraph et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenVINO</a> ). <br><br>  Ensuite, nous avons vu que, comme il y avait beaucoup de convolutions 1x1 dans Inception-ResNet, nous avions une copie de donn√©es suppl√©mentaire.  Nous avons d√©cid√© de nous sp√©cialiser dans le fait que nous travaillons sur des lots √† partir d'une photo (c'est-√†-dire que nous ne traitons pas 100 photos par lots, mais fournissons le mode de streaming) - il existe de tels cas d'utilisation lorsque vous devez travailler non pas avec des archives, mais avec un flux (par exemple, pour la surveillance vid√©o ou ACS).  Nous avons cr√©√© un passage sp√©cialis√© sans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">im2col</a> (retir√© les grandes copies) - il est devenu 0,45 seconde. <br><br>  Ensuite, nous avons regard√© √† nouveau le profileur, nous avions tout de la m√™me mani√®re - bien que toutes les √©tapes aient diminu√© dans le temps, nous avons encore 80% du temps consacr√© au calcul des blocs d'inf√©rence convolutionnels. <br>  Nous avons r√©alis√© que nous devions parall√©liser le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">gemm</a> (multiplication matricielle g√©n√©rale).  Ce gemme, qui en EML, s'est av√©r√© √™tre monothread.  En cons√©quence, nous avons d√ª √©crire nous-m√™mes le gemm multi-thread.  L'id√©e est la suivante: une grande matrice est divis√©e en sous-blocs, puis il y a une multiplication de ces petites matrices.  Nous avons √©crit un gemm avec OpenMP, mais cela n'a pas fonctionn√©, des erreurs se sont √©cras√©es.  Nous avons pris un pool manuel de threads, la parall√©lisation a donn√© 0,33 seconde par image. <br><br>  Ensuite, nous avons eu acc√®s √† distance √† un serveur plus puissant avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Elbrus 8C</a> , √† une vitesse augment√©e √† 0,2 seconde par image. <br><br>  La vid√©o suivante montre le travail du stand de d√©monstration avec reconnaissance faciale sur un ordinateur Elbrus 401-PC avec un processeur Elbrus 4C: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/iNMRKQqNM1Q" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Conclusions et plans futurs </h3><br><ul><li>  Nous travaillons non seulement la reconnaissance faciale, mais en principe un cadre de r√©seau de neurones, afin que nous puissions collecter tous les d√©tecteurs, classificateurs et les ex√©cuter sur Elbrus. </li><li>  Nous avons assembl√© un stand de d√©monstration avec Web-UI pour d√©montrer la reconnaissance faciale sur PuzzleLib. <br></li><li>  La reconnaissance faciale sur Elbrus est d√©j√† assez rapide pour les t√¢ches pratiques, alors vous pouvez l'acc√©l√©rer si n√©cessaire. </li><li>  Vous pouvez travailler avec Elbrus.  Nous avions l'habitude de travailler avec des processeurs exotiques - par exemple, avec des processeurs tenseur russes encore en d√©veloppement, avec des cartes vid√©o AMD et leurs logiciels.  Tout n'est pas si bon et simple l√†-bas.  Autrement dit, si nous prenons la biblioth√®que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MI Open</a> d'AMD, il s'agit d'une biblioth√®que tr√®s mal √©crite dans laquelle toutes les combinaisons de pas, de rembourrages et de tailles de filtre ne m√®nent pas √† des calculs r√©ussis.  La qualit√© des outils d'Elbrus est bonne - si vous avez un projet en Python, C ou C ++, l'ex√©cuter sur Elbrus n'est pas difficile du tout. </li><li>  Il convient √©galement de noter que le travail d'optimisation √©tape par √©tape dont nous avons parl√© n'est pas des op√©rations sp√©cifiques pour travailler dans Elbrus.  Il s'agit d'op√©rations de processeur multic≈ìur standard.  √Ä notre avis, c'est un bon signe que le processeur peut √™tre utilis√© comme avec un processeur r√©gulier d'Intel / NVIDIA. <br></li></ul><br><h4>  Plans: </h4><br><ul><li>  Elbrus ayant la particularit√© d'√™tre un processeur VLIW, certaines optimisations sp√©cifiques √† Elbrus peuvent √™tre effectu√©es. <br></li><li>  Effectuez une quantification (en travaillant avec int8 au lieu de float32), ce qui √©conomise de la m√©moire et augmente la vitesse.  Par cons√©quent, dans ce cas, bien s√ªr, il peut y avoir une baisse de la qualit√© des calculs - mais ce n'est peut-√™tre pas le cas.  Nous avons remarqu√© les deux cas dans la pratique. </li></ul><br>  Nous pr√©voyons de mieux comprendre et d'explorer les capacit√©s du processeur VLIW.  En fait, pour l'instant, nous venons de faire confiance au compilateur en ce sens que si nous √©crivons du bon code, le compilateur l'optimise bien, car il conna√Æt les fonctionnalit√©s d'Elbrus. <br><br>  En g√©n√©ral, c'√©tait int√©ressant, on comprendra mieux.  Cela n'a pas pris beaucoup de temps - toutes les op√©rations de portage ont pris au total une semaine. <br><br>  En janvier 2020, nous pr√©voyons de mettre PuzzleLib en open source, nous en √©crirons plus ici =) <br>  Merci de votre attention! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr469033/">https://habr.com/ru/post/fr469033/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr469021/index.html">D√©veloppement en monorepositaire. Rapport Yandex</a></li>
<li><a href="../fr469023/index.html">Comment trouver un emploi avec d√©localisation en Europe: un guide pratique pour les professionnels de l'informatique</a></li>
<li><a href="../fr469025/index.html">Refroidissez le vin rapidement! Invention russe</a></li>
<li><a href="../fr469027/index.html">Ivanovo! Mitap: Comment construire une carri√®re dans le num√©rique?</a></li>
<li><a href="../fr469031/index.html">12 nouvelles intelligence artificielle Azure Media Services</a></li>
<li><a href="../fr469035/index.html">Les nouvelles innovations d'Azure Media Services bas√©es sur l'IA</a></li>
<li><a href="../fr469037/index.html">Contr√¥leur industriel. Syst√®me de collecte de donn√©es. ACS</a></li>
<li><a href="../fr469039/index.html">Plus qu'un jeu: ma√Ætriser le Mahjong avec l'IA et l'apprentissage automatique</a></li>
<li><a href="../fr469041/index.html">Comment prot√©ger votre syst√®me ERP?</a></li>
<li><a href="../fr469043/index.html">C / C ++ de Python (API C)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
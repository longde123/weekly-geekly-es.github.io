<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👷 👷🏻 🤥 T2F：一个通过深度学习将文本转换为面部图画的项目 🏨 👼🏽 🛴</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="项目代码在存储库中可用。 

 引言 
 当我阅读书中人物形象的描述时，我总是对它们在生活中的样子很感兴趣。 完全可以想象一个人，但是描述最引人注意的细节是一项艰巨的任务，结果因人而异。 很多时候，直到工作结束时，我都无法想象除了角色的非常模糊的面孔。 只有当这本书变成电影时，模糊的面孔才会充满细节...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>T2F：一个通过深度学习将文本转换为面部图画的项目</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420709/"><img src="https://habrastorage.org/getpro/habr/post_images/5ae/703/0df/5ae7030df8270466b01b81aad0ace49f.jpg"><br><br>  <i>项目代码在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">存储库中</a>可用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">。</a></i> <br><br><h2> 引言 </h2><br> 当我阅读书中人物形象的描述时，我总是对它们在生活中的样子很感兴趣。 完全可以想象一个人，但是描述最引人注意的细节是一项艰巨的任务，结果因人而异。 很多时候，直到工作结束时，我都无法想象除了角色的非常模糊的面孔。 只有当这本书变成电影时，模糊的面孔才会充满细节。 例如，我无法想象从《 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">火车上的女孩</a> 》这本书中，蕾切尔的脸是怎样的。 但是当电影上映时，我能够使艾米莉·布朗特（Emily Blunt）的脸与雷切尔（Rachel）的角色相匹配。 当然，参与演员选择的人会花费大量时间正确描绘剧本中的角色。 <br><a name="habracut"></a><br> 这个问题启发并激励着我寻找解决方案。 之后，我开始研究有关深度学习的文献，以寻找类似的东西。 幸运的是，已经有许多关于从文本合成图像的研究。 这是我建立的一些工具： <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">arxiv.org/abs/1605.05396</a> “生成对抗性文本以进行图像合成” </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">arxiv.org/abs/1612.03242</a> “ StackGAN：使用堆叠式生成对抗网络的文本到逼真的图像合成” </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">arxiv.org/abs/1710.10916</a> “ StackGAN ++：具有堆叠式生成对抗网络的逼真的图像合成” </li></ul><br>  [ <i>项目使用生成对抗网络，GSS（生成对抗网络，GAN）/大约。</i>  <i>佩雷夫</i>  ] <br><br> 在研究了文献之后，我选择了一种与StackGAN ++相比得到简化的体系结构，并且很好地解决了我的问题。 在以下各节中，我将解释如何解决此问题并分享初步结果。 我还将描述我花费大量时间的一些编程和培训细节。 <br><br><h2> 资料分析 </h2><br> 毫无疑问，这项工作最重要的方面是用于训练模型的数据。 正如Andrew Eun教授在他的deeplearning.ai课程中所说：“在机器学习领域，并不是拥有最好算法的人，而是拥有最好数据的人。” 因此，我开始搜索具有良好，丰富和多种文字描述的面部数据集。 我遇到了不同的数据集-要么只是脸，要么是带有名称的脸，要么是带有眼睛颜色和脸形的描述的脸。 但是我不需要任何东西。 我的最后一个选择是使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">一个早期的项目</a> -用自然语言生成结构数据的描述。 但是这样的选择会给已经非常嘈杂的数据集增加额外的噪音。 <br><br> 时间流逝，在某个时候<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">出现</a>了一个新的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Face2Text</a>项目。 它是一个详细的人员文字描述数据库的集合。 我感谢该项目的作者提供的数据集。 <br><br> 数据集包含来自LFW数据库的400张随机选择的图像的文本描述（带标签的脸部）。 清理说明以消除歧义和次要特征。 一些描述不仅包含有关面部的信息，而且还包含基于图像得出的一些结论-例如，“照片中的人可能是罪犯”。 所有这些因素以及数据集的小规模导致了这样一个事实，即到目前为止，我的项目仅证明了该体系结构的可操作性。 随后，可以将该模型扩展为更大，更多样化的数据集。 <br><br><h2> 建筑学 </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/c70/ea1/6de/c70ea16de2bbfb674e618fa556cfc9ff.jpg"><br><br>  T2F项目的架构结合了两个stackGAN架构和ProGAN（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">渐进式GSS增长</a> ），用于合成有条件的增量文本，该GAN架构用于对有条件的增量文本进行编码。 最初的stackgan ++体系结构使用了几个具有不同空间分辨率的GSS，因此我认为对于任何通信分发任务而言，这都是一种过于严肃的方法。 但是ProGAN仅使用一个GSS，并以更详细的分辨率进行逐步培训。 我决定将这两种方法结合起来。 <br><br> 这里有一个数据流的解释：通过将文本描述嵌入到网络LSTM（嵌入）（psy_t）中，将文本描述编码为最终向量（参见图）。 然后，通过条件增强块（一个线性层）传输嵌入，以获取GSS作为输入的特征向量的文本部分（使用VAE重新参数化技术）。 特征向量的第二部分是随机高斯噪声。 所得的特征向量被馈送到GSS生成器，并且嵌入被馈送到最后的鉴别器层，以进行对应的条件分布。  GSS过程的培训与ProGAN上的文章完全相同-分层，但空间分辨率有所提高。 使用淡入技术引入了一个新层，以避免擦除以前的学习结果。 <br><br><h2> 实施及其他细节 </h2><br> 该应用程序是使用PyTorch框架以python编写的。 我曾经使用过tensorflow和keras软件包，但现在我想尝试使用PyTorch。 我喜欢使用内置的python调试器来处理网络体系结构-这一切都要归功于早期执行策略。  Tensorflow最近还开启了渴望执行模式。 但是，我不想判断哪个框架更好，我只是想强调一下该项目的代码是使用PyTorch编写的。 <br><br> 在我看来，该项目的相当一部分是可重用的，尤其是ProGAN。 因此，我为它们编写了单独的代码，作为PyTorch模块的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">扩展</a> ，它也可以用于其他数据集。 仅需要指出GSS功能的深度和大小。 可以针对任何数据集逐步训练GSS。 <br><br><h2> 训练细节 </h2><br> 我使用不同的超参数训练了很多网络版本。 工作细节如下： <br><br><ol><li> 鉴别器没有批处理或分层处理，因此WGAN-GP的损失会爆炸性增长。 我使用的λ等于0.001的漂移罚分。 </li><li> 为了控制从编码文本中获得的自己的多样性，有必要在生成器损耗中使用Kullback-Leibler距离。 </li><li> 为了使生成的图像更好地匹配传入的文本分布，最好使用相应的（匹配感知）鉴别器的WGAN版本。 </li><li> 较高级别的淡入时间应超过较低级别的淡入时间。 训练时，我使用85％作为淡入值。 </li><li> 我发现分辨率较高的示例（32 x 32和64 x 64）比分辨率较低的示例产生更多的背景噪声。 我认为这是由于缺乏数据所致。 </li><li> 在进行渐进式锻炼时，最好将更多的时间花费在较低的分辨率上，并减少花费在较高分辨率上的时间。 </li></ol><br> 视频显示了发电机的运行时间。 该视频是根据GSS训练期间获得的具有不同空间分辨率的图像进行编译的。 <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/NO_l87rPDb8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2> 结论 </h2><br> 根据初步结果，可以判断T2F项目是可行的并且具有有趣的应用。 假设它可以用来组成照片机器人。 或者在需要增强想象力的情况下。 我将继续在Flicker8K，Coco字幕等数据集上扩展该项目。 <br><br>  GSS逐步增长是一项用于更快，更稳定的GSS训练的惊人技术。 它可以与其他文章中提到的各种现代技术相结合。  GSS可以在MO的不同区域中使用。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN420709/">https://habr.com/ru/post/zh-CN420709/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN420697/index.html">PHP和MySQL的永恒主题</a></li>
<li><a href="../zh-CN420701/index.html">汇丰银行邀请参加8月29日举行的游戏设计讲座晚会</a></li>
<li><a href="../zh-CN420703/index.html">“谈判不败。 哈佛法</a></li>
<li><a href="../zh-CN420705/index.html">蒂姆·费里斯（Tim Ferris）的“导师部落”提出了8个深层想法</a></li>
<li><a href="../zh-CN420707/index.html">JITX初创公司使用AI自动化复杂印刷电路板的开发</a></li>
<li><a href="../zh-CN420711/index.html">莫斯科数据科学专业：公告和注册</a></li>
<li><a href="../zh-CN420713/index.html">Chuck Hull如何发明3D打印</a></li>
<li><a href="../zh-CN420715/index.html">关于学习严重性的硬道理</a></li>
<li><a href="../zh-CN420725/index.html">我如何教AI玩NES玩俄罗斯方块。 第1部分：游戏代码分析</a></li>
<li><a href="../zh-CN420729/index.html">公开网络研讨会“朴素贝叶斯分类器”</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
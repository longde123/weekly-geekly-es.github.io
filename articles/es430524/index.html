<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§ûüèª üë≤üèæ üö° Arquitectura de red neuronal üë©üèæ‚Äçüè≠ ‚è¨ ‚úãüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Traducci√≥n de arquitecturas de redes neuronales 

 Los algoritmos de las redes neuronales profundas han ganado gran popularidad hoy, lo que est√° garan...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Arquitectura de red neuronal</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nix/blog/430524/">  <i>Traducci√≥n de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arquitecturas de redes neuronales</a></i> <br><br>  Los algoritmos de las redes neuronales profundas han ganado gran popularidad hoy, lo que est√° garantizado en gran medida por la arquitectura bien pensada.  Veamos la historia de su desarrollo en los √∫ltimos a√±os.  Si est√° interesado en un an√°lisis m√°s profundo, consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este trabajo</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/29b/f51/960/29bf5196085373528be31e27f2489bdd.jpg"><br>  <i>Comparaci√≥n de arquitecturas populares para la precisi√≥n de un cultivo Top-1 y el n√∫mero de operaciones requeridas para un pase directo.</i>  <i>M√°s detalles <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> .</i> <br><a name="habracut"></a><br><h3>  Lenet5 </h3><br>  En 1994, se desarroll√≥ una de las primeras redes neuronales convolucionales, que sent√≥ las bases para el aprendizaje profundo.  Este trabajo pionero de Yann LeCun, despu√©s de muchas iteraciones exitosas desde 1988, se llam√≥ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LeNet5</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b19/9c3/8f2/b199c38f21a72c44d7cd3afbca1c94eb.jpg"><br><br>  La arquitectura LeNet5 se ha convertido en fundamental para el aprendizaje profundo, especialmente en t√©rminos de la distribuci√≥n de las propiedades de la imagen en toda la imagen.  Las convoluciones con los par√°metros de aprendizaje permitieron usar varios par√°metros para extraer eficientemente las mismas propiedades de diferentes lugares.  En esos a√±os, no hab√≠a tarjetas de video que pudieran acelerar el proceso de aprendizaje, e incluso los procesadores centrales eran lentos.  Por lo tanto, la ventaja clave de la arquitectura era la capacidad de guardar par√°metros y resultados de c√°lculo, en contraste con el uso de cada p√≠xel como datos de entrada separados para una gran red neuronal multicapa.  En LeNet5, los p√≠xeles no se usan en la primera capa, ya que las im√°genes est√°n fuertemente correlacionadas espacialmente, por lo que usar p√≠xeles individuales como propiedades de entrada no le permitir√° aprovechar estas correlaciones. <br><br>  Caracter√≠sticas de LeNet5: <br><br><ul><li>  Una red neuronal convolucional que utiliza una secuencia de tres capas: capas de convoluci√≥n, capas de agrupaci√≥n y capas de no linealidad -&gt; desde la publicaci√≥n del trabajo de Lekun, esta es quiz√°s una de las principales caracter√≠sticas del aprendizaje profundo en relaci√≥n con las im√°genes. </li><li>  Utiliza convoluci√≥n para recuperar propiedades espaciales. </li><li>  Submuestreo usando promedios de mapas espaciales. </li><li>  No linealidad en forma de tangente hiperb√≥lica o sigmoidea. </li><li>  El clasificador final en forma de red neuronal multicapa (MLP). </li><li>  La escasa matriz de conectividad entre las capas reduce la cantidad de c√≥mputo. </li></ul><br>  Esta red neuronal form√≥ la base de muchas arquitecturas posteriores e inspir√≥ a muchos investigadores. <br><br><h3>  Desarrollo </h3><br>  De 1998 a 2010, las redes neuronales estuvieron en estado de incubaci√≥n.  La mayor√≠a de las personas no notaron sus capacidades de crecimiento, aunque muchos desarrolladores gradualmente perfeccionaron sus algoritmos.  Gracias al apogeo de las c√°maras de tel√©fonos m√≥viles y el abaratamiento de las c√°maras digitales, cada vez hay m√°s datos de capacitaci√≥n disponibles para nosotros.  Al mismo tiempo, las capacidades inform√°ticas crecieron, los procesadores se volvieron m√°s potentes y las tarjetas de video se convirtieron en la principal herramienta inform√°tica.  Todos estos procesos permitieron el desarrollo de redes neuronales, aunque bastante lento.  El inter√©s en las tareas que podr√≠an resolverse con la ayuda de las redes neuronales fue creciendo, y finalmente la situaci√≥n se hizo evidente ... <br><br><h3>  Dan ciresan net </h3><br>  En 2010, Dan Claudiu Ciresan y Jurgen Schmidhuber publicaron una de las primeras descripciones de la implementaci√≥n de <a href="">redes neuronales</a> de <a href="">GPU</a> .  Su trabajo conten√≠a la implementaci√≥n directa e inversa de una red neuronal de 9 capas en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">NVIDIA GTX 280</a> . <br><br><h3>  Alexnet </h3><br>  En 2012, Alexei Krizhevsky public√≥ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AlexNet</a> , una versi√≥n en profundidad y extendida de LeNet, que gan√≥ por un amplio margen en la dif√≠cil competencia de ImageNet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aad/4ad/3ca/aad4ad3ca7345f8d7e198c2b131298d1.png"><br><br>  En AlexNet, los resultados de los c√°lculos de LeNet se escalan en una red neuronal mucho m√°s grande, que puede estudiar objetos mucho m√°s complejos y sus jerarqu√≠as.  Caracter√≠sticas de esta soluci√≥n: <br><br><ul><li>  Uso de unidades de rectificaci√≥n lineal (ReLU) como no linealidades. </li><li>  El uso de t√©cnicas de descarte para ignorar selectivamente las neuronas individuales durante el entrenamiento, lo que evita el sobreentrenamiento del modelo. </li><li>  Superposici√≥n de agrupaci√≥n m√°xima, lo que evita los efectos de promediar la agrupaci√≥n promedio. </li><li>  Usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">NVIDIA GTX 580</a> para acelerar el aprendizaje. </li></ul><br>  En ese momento, el n√∫mero de n√∫cleos en las tarjetas de video hab√≠a crecido significativamente, lo que permiti√≥ reducir el tiempo de entrenamiento en aproximadamente 10 veces, y como resultado fue posible usar conjuntos de datos e im√°genes mucho m√°s grandes. <br><br>  El √©xito de AlexNet lanz√≥ una peque√±a revoluci√≥n, las redes neuronales convolucionales se han convertido en un caballo de batalla del aprendizaje profundo: este t√©rmino ahora significa "grandes redes neuronales que pueden resolver tareas √∫tiles". <br><br><h3>  Sobrepeso </h3><br>  En diciembre de 2013, el laboratorio de la NYU de Jan Lekun public√≥ una descripci√≥n de <a href="">Overfeat</a> , una variante de AlexNet.  Adem√°s, el art√≠culo describ√≠a los cuadros delimitadores entrenados, y posteriormente se publicaron muchos otros trabajos sobre este tema.  Creemos que es mejor aprender a segmentar objetos, en lugar de usar cajas de l√≠mite artificiales. <br><br><h3>  Vgg </h3><br>  En las redes <a href="">VGG</a> desarrolladas en Oxford, en cada capa convolucional, por primera vez, se usaron filtros 3x3, e incluso estas capas se combinaron en una secuencia de convoluciones. <br><br>  Esto contradice los principios establecidos en LeNet, seg√∫n los cuales se utilizaron grandes convoluciones para extraer las mismas propiedades de imagen.  En lugar de los filtros 9x9 y 11x11 utilizados en AlexNet, comenzaron a usarse filtros mucho m√°s peque√±os, peligrosamente cercanos a convoluciones 1x1, que los autores de LeNet intentaron evitar, al menos en las primeras capas de la red.  Pero la gran ventaja de VGG fue el hallazgo de que varias convoluciones 3x3 combinadas en una secuencia pueden emular campos receptivos m√°s grandes, por ejemplo, 5x5 o 7x7.  Estas ideas luego se utilizar√°n en las arquitecturas Inception y ResNet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dec/e8b/308/dece8b308f74450222deece6fcf9d357.jpg"><br><br>  Las redes VGG usan m√∫ltiples capas convolucionales de 3x3 para representar propiedades complejas.  Preste atenci√≥n a los bloques 3, 4 y 5 en VGG-E: para extraer propiedades m√°s complejas y combinarlas, se utilizan secuencias de filtro 256 √ó 256 y 512 √ó 512 3 √ó 3.  ¬°Esto es equivalente a un clasificador convolucional grande 512x512 con tres capas!  Esto nos da una gran cantidad de par√°metros y excelentes habilidades de aprendizaje.  Pero fue dif√≠cil aprender tales redes; tuve que dividirlas en otras m√°s peque√±as, agregando capas una por una.  La raz√≥n fue la falta de formas efectivas para regularizar modelos o algunos m√©todos para limitar un gran espacio de b√∫squeda, que es promovido por muchos par√°metros. <br><br>  VGG en muchas capas utiliza una gran cantidad de propiedades, por lo que la capacitaci√≥n fue <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">computacionalmente costosa</a> .  La carga se puede reducir reduciendo el n√∫mero de propiedades, como se hace en las capas de cuello de botella de la arquitectura Inception. <br><br><h3>  Red en red </h3><br>  La arquitectura de <a href="">red en red</a> (NiN) se basa en una idea simple: usar convoluciones 1x1 para aumentar la combinatoria de propiedades en capas convolucionales. <br><br>  En NiN, despu√©s de cada convoluci√≥n, se utilizan capas espaciales de MLP para combinar mejor las propiedades antes de alimentar a la siguiente capa.  Puede parecer que el uso de convoluciones 1x1 contradice los principios LeNet originales, pero en realidad permite combinar propiedades mejor que simplemente rellenar m√°s capas convolucionales.  Este enfoque es diferente del uso de p√≠xeles desnudos como entrada para la siguiente capa.  En este caso, las convoluciones 1x1 se usan para la combinaci√≥n espacial de propiedades despu√©s de la convoluci√≥n dentro del marco de los mapas de propiedades, por lo que puede usar muchos menos par√°metros que son comunes a todos los p√≠xeles de estas propiedades. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d9a/d08/e5c/d9ad08e5c699a2a9cf320c4b8b622ba3.jpg"><br><br>  MLP puede aumentar en gran medida la eficacia de las capas convolucionales individuales combin√°ndolas en grupos m√°s complejos.  Esta idea fue utilizada m√°s tarde en otras arquitecturas, como ResNet, Inception y sus variantes. <br><br><h3>  GoogLeNet e Inception </h3><br>  Google Christian Szegedy est√° preocupado por reducir los c√°lculos en redes neuronales profundas y, como resultado, cre√≥ <a href="">GoogLeNet, la primera arquitectura de inicio</a> . <br><br>  Para el oto√±o de 2014, los modelos de aprendizaje profundo se hab√≠an vuelto muy √∫tiles para categorizar contenido de im√°genes y marcos de videos.  Muchos esc√©pticos han reconocido los beneficios del aprendizaje profundo y las redes neuronales, y los gigantes de Internet, incluido Google, se han interesado mucho en desplegar redes eficientes y grandes en sus capacidades de servidor. <br><br>  Christian estaba buscando formas de reducir la carga computacional en las redes neuronales, logrando el mayor rendimiento (por ejemplo, en ImageNet).  O preservar la cantidad de c√≥mputo, pero a√∫n as√≠ aumentar la productividad. <br><br>  Como resultado, el comando cre√≥ un m√≥dulo Inception: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/abf/d01/a92/abfd01a92262ff6e5b9f23380ba8d9cc.jpg"><br><br>  A primera vista, esta es una combinaci√≥n paralela de filtros convolucionales 1x1, 3x3 y 5x5.  Pero lo m√°s destacado fue el uso de bloques de convoluci√≥n 1x1 (NiN) para reducir el n√∫mero de propiedades antes de servir en los bloques paralelos "caros".  Por lo general, esta parte se llama cuello de botella, se describe con m√°s detalle en el pr√≥ximo cap√≠tulo. <br><br>  GoogLeNet usa un v√°stago sin m√≥dulos de inicio como la capa inicial, y tambi√©n usa una agrupaci√≥n promedio y un clasificador softmax similar a NiN.  Este clasificador realiza muy pocas operaciones en comparaci√≥n con AlexNet y VGG.  Tambi√©n ayud√≥ a crear una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arquitectura de red neuronal muy eficiente</a> . <br><br><h3>  Capa de cuello de botella </h3><br>  Esta capa reduce el n√∫mero de propiedades (y, por lo tanto, operaciones) en cada capa, de modo que la velocidad de obtenci√≥n del resultado se puede mantener a un nivel alto.  Antes de transferir datos a m√≥dulos convolucionales "costosos", el n√∫mero de propiedades se reduce, por ejemplo, 4 veces.  Esto reduce en gran medida la cantidad de c√≥mputo, lo que ha hecho que la arquitectura sea popular. <br><br>  Vamos a resolverlo.  Supongamos que tenemos 256 propiedades en la entrada y 256 en la salida, y dejamos que la capa de inicio realice solo convoluciones de 3x3.  Obtenemos convoluciones de 256x256x3x3 (589,000 operaciones de multiplicaci√≥n de acumulaci√≥n, es decir, operaciones MAC).  Esto puede ir m√°s all√° de nuestros requisitos de velocidad computacional; digamos que una capa se procesa en 0.5 milisegundos en Google Server.  Luego reduzca el n√∫mero de propiedades para plegar a 64 (256/4).  En este caso, primero realizamos una convoluci√≥n 1x1 de 256 -&gt; 64, luego otra convoluci√≥n 64 en todas las ramas de inicio, y luego nuevamente aplicamos una convoluci√≥n 1x1 de 64 -&gt; 256 propiedades.  N√∫mero de operaciones: <br><br><ul><li>  256 √ó 64 √ó 1 √ó 1 = 16,000 </li><li>  64 √ó 64 √ó 3 √ó 3 = 36,000 </li><li>  64 √ó 256 √ó 1 √ó 1 = 16,000 </li></ul><br>  ¬°Solo alrededor de 70,000, redujeron el n√∫mero de operaciones en casi 10 veces!  Pero al mismo tiempo, no perdimos la generalizaci√≥n en esta capa.  Las capas de cuello de botella han demostrado un excelente rendimiento en el conjunto de datos de ImageNet y se han utilizado en arquitecturas posteriores como ResNet.  La raz√≥n de su √©xito es que las propiedades de entrada est√°n correlacionadas, lo que significa que puede deshacerse de la redundancia combinando correctamente propiedades con convoluciones 1x1.  Y despu√©s de doblar con menos propiedades, puede volver a implementarlas en una combinaci√≥n significativa en la siguiente capa. <br><br><h3>  Inicio V3 (y V2) </h3><br>  Christian y su equipo han demostrado ser investigadores muy efectivos.  En febrero de 2015, se introdujo la arquitectura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Inception normalizada por lotes</a> como la segunda versi√≥n de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Inception</a> .  La normalizaci√≥n por lotes calcula la media y la desviaci√≥n est√°ndar de todos los mapas de distribuci√≥n de propiedades en la capa de salida, y normaliza sus respuestas con estos valores.  Esto corresponde al "blanqueamiento" de los datos, es decir, las respuestas de todos los mapas neuronales se encuentran en el mismo rango y con una media cero.  Este enfoque facilita el aprendizaje, ya que la siguiente capa no requiere recordar desplazamientos de datos de entrada y solo puede buscar las mejores combinaciones de propiedades. <br><br>  En diciembre de 2015, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">se lanz√≥</a> una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">nueva versi√≥n de los m√≥dulos Inception y la arquitectura correspondiente</a> .  El art√≠culo del autor explica mejor la arquitectura original de GoogLeNet, que cuenta mucho m√°s sobre las decisiones tomadas.  Ideas clave <br><br><ul><li>  Maximizando el flujo de informaci√≥n en la red debido al cuidadoso equilibrio entre su profundidad y ancho.  Antes de cada agrupaci√≥n, los mapas de propiedades aumentan. </li><li>  Con el aumento de la profundidad, el n√∫mero de propiedades o el ancho de la capa tambi√©n aumenta sistem√°ticamente. </li><li>  El ancho de cada capa aumenta para aumentar la combinaci√≥n de propiedades antes de la siguiente capa. </li><li>  En la medida de lo posible, solo se utilizan convoluciones 3x3.  Dado que los filtros 5x5 y 7x7 se pueden descomponer usando m√∫ltiples 3x3 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/849/96f/d8c/84996fd8cb1040fbf0a18187313a8a81.jpg"><br><br>  El nuevo m√≥dulo de inicio se ve as√≠: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/975/b0b/ad7/975b0bad7d65a0b37aedf0dc119d03b8.jpg"></li><li>  Los filtros tambi√©n se pueden descomponer mediante <a href="">convoluciones suavizadas</a> en m√≥dulos m√°s complejos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bb5/c32/21c/bb5c3221cc8f478de3ac5ef504a13357.jpg"></li><li>  Los m√≥dulos de inicio pueden reducir el tama√±o de los datos mediante la agrupaci√≥n durante los c√°lculos de inicio.  Esto es similar a realizar una convoluci√≥n con zancadas en paralelo con una capa de agrupaci√≥n simple: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f8b/4c1/263/f8b4c1263b3883d751c7dfe3788110ca.jpg"></li></ul><br>  Inception usa la capa de agrupaci√≥n con softmax como el clasificador final. <br><br><h3>  Resnet </h3><br>  En diciembre de 2015, aproximadamente al mismo tiempo que se introdujo la arquitectura Inception v3, se produjo una revoluci√≥n: publicaron <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ResNet</a> .  Contiene ideas simples: env√≠e la salida de dos capas convolucionales exitosas ¬°Y omita la entrada para la siguiente capa! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b8a/05d/8b8/b8a05d8b89f55e8d06bb2eae79bd648b.jpg"><br><br>  Tales ideas ya se han propuesto, por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> .  Pero en este caso, los autores omiten DOS capas y aplican el enfoque a gran escala.  Omitir una capa no ofrece muchos beneficios, y omitir dos es un hallazgo clave.  ¬°Esto puede verse como un peque√±o clasificador, como red en red! <br><br>  Tambi√©n fue el primer ejemplo de entrenamiento de una red de varios cientos, incluso miles de capas. <br>  ResNet multicapa utiliz√≥ una capa de cuello de botella similar a la utilizada en Inception: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0d0/ecf/124/0d0ecf1248874511ae4dbca5f23afcec.jpg"><br><br>  Esta capa reduce el n√∫mero de propiedades en cada capa, primero usando una convoluci√≥n 1x1 con una salida m√°s baja (generalmente una cuarta parte de la entrada), luego una capa 3x3, y luego convolucionando 1x1 en una mayor cantidad de propiedades.  Como en el caso de los m√≥dulos Inception, esto ahorra recursos computacionales mientras mantiene una gran cantidad de combinaciones de propiedades.  Compare con los tallos m√°s complejos y menos obvios en Inception V3 y V4. <br><br>  ResNet usa una capa de agrupaci√≥n con softmax como el clasificador final. <br>  Todos los d√≠as, aparece informaci√≥n adicional sobre la arquitectura ResNet: <br><br><ul><li>  Se puede considerar como un sistema de m√≥dulos simult√°neos paralelos y en serie: en muchos m√≥dulos, la se√±al de entrada viene en paralelo, y las se√±ales de salida de cada m√≥dulo est√°n conectadas en serie. </li><li>  ResNet se puede considerar como varios <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">conjuntos de m√≥dulos paralelos o seriales</a> . </li><li>  Result√≥ que ResNet generalmente opera con bloques de profundidad relativamente peque√±os de 20-30 capas que trabajan en paralelo, en lugar de ejecutarse secuencialmente a lo largo de toda la red. </li><li>  Dado que la se√±al de salida vuelve y se alimenta como entrada, como se hace en RNN, ResNet puede considerarse un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">modelo plausible</a> mejorado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de la corteza cerebral</a> . </li></ul><br><h3>  Inicio V4 </h3><br>  Christian y su equipo se destacaron nuevamente con una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">nueva versi√≥n de Inception</a> . <br><br>  El m√≥dulo de inicio que sigue la ra√≠z es el mismo que en Inception V3: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/48b/955/f38/48b955f385c72d21a20af8517d941580.jpg"><br><br>  En este caso, el m√≥dulo Inception se combina con el m√≥dulo ResNet: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f4c/5f2/bd7/f4c5f2bd765082fe56dac5710fc30221.jpg"><br><br>  Esta arquitectura result√≥, a mi gusto, m√°s complicada, menos elegante y tambi√©n llena de soluciones heur√≠sticas opacas.  Es dif√≠cil entender por qu√© los autores tomaron estas o aquellas decisiones, y es igualmente dif√≠cil darles alg√∫n tipo de evaluaci√≥n. <br><br>  Por lo tanto, el premio para una red neuronal limpia y simple, f√°cil de entender y modificar, es para ResNet. <br><br><h3>  Squeezenet </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SqueezeNet</a> publicado recientemente.  Este es un remake en una nueva forma de muchos conceptos de ResNet e Inception.  Los autores demostraron que mejorar la arquitectura reduce el tama√±o de la red y la cantidad de par√°metros sin algoritmos de compresi√≥n complejos. <br><br><h3>  ENet </h3><br>  Todas las caracter√≠sticas de las arquitecturas recientes se combinan en una red muy eficiente y compacta, que utiliza muy pocos par√°metros y potencia inform√°tica, pero al mismo tiempo ofrece excelentes resultados.  La arquitectura se llamaba <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ENet</a> , fue desarrollada por Adam Paszke ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Adam Paszke</a> ).  Por ejemplo, lo usamos para marcar con mucha precisi√≥n objetos en la pantalla y analizar escenas.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Algunos ejemplos de Enet</a> .  Estos videos no est√°n relacionados con el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">conjunto de datos de capacitaci√≥n</a> . <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aqu√≠</a> puede encontrar los detalles t√©cnicos de ENet.  Es una red basada en codificador y decodificador.  El codificador se basa en el esquema de categorizaci√≥n CNN habitual, y el decodificador es un netowrk de muestreo superior dise√±ado para la segmentaci√≥n mediante la difusi√≥n de las categor√≠as a la imagen de tama√±o original.  Para la segmentaci√≥n de im√°genes, solo se usaron redes neuronales, no otros algoritmos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18d/c54/7fa/18dc547fade22215961a848b2170b104.png"><br><br>  Como puede ver, ENet tiene la mayor precisi√≥n espec√≠fica en comparaci√≥n con todas las dem√°s redes neuronales. <br><br>  ENet fue dise√±ado para usar la menor cantidad de recursos posible desde el principio.  Como resultado, el codificador y el decodificador juntos ocupan solo 0.7 MB con precisi√≥n fp16.  Y con un tama√±o tan peque√±o, ENet no es inferior a la precisi√≥n de segmentaci√≥n ni superior a otras soluciones de red puramente neuronales. <br><br><h3>  An√°lisis de m√≥dulos </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Public√≥ una</a> evaluaci√≥n sistem√°tica de los m√≥dulos CNN.  Result√≥ ser beneficioso: <br><br><ul><li>  Utilice la no linealidad ELU sin normalizaci√≥n de lote (batchnorm) o ReLU con normalizaci√≥n. </li><li>  Aplicar la transformaci√≥n aprendida del espacio de color RGB. </li><li>  Use una pol√≠tica de disminuci√≥n de la tasa de aprendizaje lineal. </li><li>  Use la suma de la capa de agrupaci√≥n media y m√°xima. </li><li>  Use un mini paquete de 128 o 256. Si esto es demasiado para su tarjeta de video, reduzca la velocidad de aprendizaje en proporci√≥n al tama√±o del paquete. </li><li>  Use capas completamente conectadas como capas convolucionales y pron√≥sticos promedio para dar la soluci√≥n final. </li><li>  Si aumenta el tama√±o del conjunto de datos de entrenamiento, aseg√∫rese de no haber alcanzado una meseta en el entrenamiento.  La limpieza de datos es m√°s importante que el tama√±o. </li><li>  Si no puede aumentar el tama√±o de la imagen de entrada, reduzca el paso en las capas posteriores, el efecto ser√° aproximadamente el mismo. </li><li>  Si su red tiene una arquitectura compleja y altamente optimizada, como en GoogLeNet, modif√≠quela con precauci√≥n. </li></ul><br><h3>  Xception </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Xception</a> introdujo una arquitectura m√°s simple y elegante en el m√≥dulo Inception, que no es menos eficiente que ResNet e Inception V4. <br>  As√≠ es como se ve el m√≥dulo Xception: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/632/40a/deb/63240adebe962726f6d035b5a5d16099.jpg"><br><br>  A cualquiera le gustar√° esta red debido a la simplicidad y elegancia de su arquitectura: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d64/f09/933/d64f099330f0b9290a99202a50863868.jpg"><br><br>  Contiene 36 pasos de convoluci√≥n, y esto es similar a ResNet-34.  Al mismo tiempo, el modelo y el c√≥digo son simples, como en ResNet, y mucho m√°s agradables que en Inception V4. <br><br>  Una implementaci√≥n de antorcha7 de esta red est√° disponible <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> , mientras que una implementaci√≥n de Keras / TF est√° disponible aqu√≠. <br><br>  Curiosamente, los autores de la reciente arquitectura Xception tambi√©n se inspiraron en <a href="">nuestro trabajo sobre filtros convolucionales separables</a> . <br><br><h3>  MobileNets </h3><br>  La nueva arquitectura de M <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">obileNets</a> se lanz√≥ en abril de 2017.  Para reducir el n√∫mero de par√°metros, utiliza convoluciones desmontables, lo mismo que en Xception.  Tambi√©n se afirma en el trabajo que los autores pudieron reducir en gran medida el n√∫mero de par√°metros: aproximadamente la mitad en el caso de FaceNet.   : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/689/04b/c1e/68904bc1e353888d4fcd54975a064362.jpg"><br><br>         ,         1 (batch of 1)   Titan Xp.      : <br><br><ul><li> resnet18: 0,002871 </li><li> alexnet: 0,001003 </li><li> vgg16: 0,001698 </li><li> squeezenet: 0,002725 </li><li> mobilenet: 0,033251 </li></ul><br>     !        ,     . <br><br><h3>    </h3><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">FractalNet</a>   ,      ImageNet        ResNet. <br><br><h3>  </h3><br>  ,           .         ,  . <br><br>   ,         ,       ,   ,       ?  ,       . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>    . <br>  ,        .      ,         . <br><br>         , . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">  </a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es430524/">https://habr.com/ru/post/es430524/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es430512/index.html">C√≥mo viven los freelancers: no trabaje con clientes que lo saben todo y perm√≠tase postergar</a></li>
<li><a href="../es430514/index.html">Blockchain Charity - DataArt gana el Hackathon de la Cumbre Blockchain de Malta</a></li>
<li><a href="../es430518/index.html">C√≥mo renderizar el marco de la Tierra Media: Shadow of Mordor</a></li>
<li><a href="../es430520/index.html">Presentamos Spring Data MongoDB</a></li>
<li><a href="../es430522/index.html">¬øNecesitas una cultura corporativa en TI? Confesi√≥n del gerente de marca del estudio Krasnodar Plarium</a></li>
<li><a href="../es430526/index.html">M√°quinas tragamonedas: de d√≥nde vinieron en la URSS y c√≥mo est√°n organizadas</a></li>
<li><a href="../es430528/index.html">Programaci√≥n con PyUSB 1.0</a></li>
<li><a href="../es430530/index.html">Servidor simulado para la automatizaci√≥n de pruebas m√≥viles</a></li>
<li><a href="../es430532/index.html">Seguridad en aplicaciones iOS</a></li>
<li><a href="../es430534/index.html">Crear una plantilla para Zabbix usando el SDK Trassir de DVR como ejemplo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
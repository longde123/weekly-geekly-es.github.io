<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õÖÔ∏è üõãÔ∏è üè£ Vis√£o geral do NeurIPS-2018 (ex. NIPS) üëÉ üßïüèΩ üè∑Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="No in√≠cio de dezembro, Montreal sediou a 32¬™ confer√™ncia anual de Sistemas de processamento de informa√ß√µes neurais sobre aprendizado de m√°quina. De ac...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vis√£o geral do NeurIPS-2018 (ex. NIPS)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ru_mts/blog/434694/"> No in√≠cio de dezembro, Montreal sediou a 32¬™ confer√™ncia anual de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Sistemas de processamento de informa√ß√µes neurais</a> sobre aprendizado de m√°quina.  De acordo com uma tabela de classifica√ß√£o n√£o oficial, esta confer√™ncia √© o evento top 1 deste formato no mundo.  Todos os ingressos para a confer√™ncia deste ano foram esgotados em um recorde de 13 minutos.  Temos uma grande equipe de cientistas de dados do MTS, mas apenas um deles - Marina Yaroslavtseva ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">magoli</a> ) - teve a sorte de chegar a Montreal.  Juntamente com Danila Savenkov ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">danila_savenkov</a> ), que ficou sem visto e acompanhou a confer√™ncia de Moscou, falaremos sobre os trabalhos que nos pareciam mais interessantes.  Esta amostra √© muito subjetiva, mas espero que lhe interesse. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c10/868/6af/c108686af497e18c338a44c475d6d64e.png" alt="imagem"><br><a name="habracut"></a><br>  <b>Redes neurais recorrentes relacionais</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Resumo</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√≥digo</a> <br><br>  Ao trabalhar com sequ√™ncias, geralmente √© muito importante como os elementos da sequ√™ncia se relacionam.  A arquitetura padr√£o de redes de recorr√™ncia (GRU, LSTM) dificilmente pode modelar o relacionamento entre dois elementos que s√£o bastante remotos um do outro.  At√© certo ponto, a aten√ß√£o ajuda a lidar com isso ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://youtu.be/SysgYptB198</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://youtu.be/quoGRI-1l0A</a> ), mas ainda assim n√£o est√° certo.  Aten√ß√£o permite determinar o peso com o qual o estado oculto de cada uma das etapas da sequ√™ncia afetar√° o estado oculto final e, consequentemente, a previs√£o.  Estamos interessados ‚Äã‚Äãna rela√ß√£o dos elementos da sequ√™ncia. <br><br>  No ano passado, novamente no NIPS, o Google sugeriu abandonar completamente a recorr√™ncia e usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a aten√ß√£o pessoal</a> .  A abordagem mostrou-se muito boa, embora principalmente em tarefas seq2seq (o artigo fornece resultados sobre tradu√ß√£o autom√°tica). <br><br>  O artigo deste ano usa a ideia de aten√ß√£o pr√≥pria como parte do LSTM.  N√£o h√° muitas mudan√ßas: <br><br><ol><li>  Alteramos o vetor de estado celular para a matriz "mem√≥ria" M. At√© certo ponto, a matriz de mem√≥ria √© composta por muitos vetores de estado celular (muitas c√©lulas de mem√≥ria).  Obtendo um novo elemento da sequ√™ncia, determinamos o quanto esse elemento deve atualizar cada uma das c√©lulas da mem√≥ria. </li><li>  Para cada elemento da sequ√™ncia, atualizaremos essa matriz usando a aten√ß√£o ao produto com v√°rios pontos de cabe√ßa (MHDPA, voc√™ pode ler sobre esse m√©todo no artigo mencionado no google).  O resultado do MHPDA para o elemento atual da sequ√™ncia e da matriz M √© executado atrav√©s de uma malha totalmente conectada, o sigm√≥ide e a matriz M s√£o atualizados da mesma maneira que o estado da c√©lula no LSTM </li></ol><br>  Argumenta-se que √© devido ao MHDPA que a rede pode levar em considera√ß√£o a interconex√£o dos elementos de sequ√™ncia, mesmo quando eles s√£o removidos um do outro. <br><br>  Como um problema de brinquedo, o modelo √© solicitado na sequ√™ncia de vetores para encontrar o vetor en√©simo por dist√¢ncia do en√©simo em termos de dist√¢ncia euclidiana.  Por exemplo, h√° uma sequ√™ncia de 10 vetores e pedimos que voc√™ encontre um que esteja em terceiro lugar, pr√≥ximo ao quinto.  √â claro que, para responder a essa pergunta do modelo, √© necess√°rio avaliar de alguma forma as dist√¢ncias de todos os vetores ao quinto e classific√°-los.  Aqui, o modelo proposto pelos autores derrota com confian√ßa LSTM e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">DNC</a> .  Al√©m disso, os autores comparam seu modelo com outras arquiteturas em Learning to Execute (aprendemos a executar algumas linhas de c√≥digo, fornecemos o resultado), Mini-Pacman, Language Modeling e em todos os lugares relatamos os melhores resultados. <br><br>  <b>Imputa√ß√£o multivariada de s√©ries temporais com redes adversas generativas</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Resumo</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√≥digo</a> (embora eles n√£o estejam vinculados aqui no artigo) <br><br>  Em s√©ries temporais multidimensionais, como regra, h√° um grande n√∫mero de omiss√µes, o que impede o uso de m√©todos estat√≠sticos avan√ßados.  Solu√ß√µes padr√£o - preenchendo com m√©dia / zero, excluindo casos incompletos, restaurando dados com base em expans√µes de matriz nessa situa√ß√£o, geralmente n√£o funcionam, porque n√£o podem reproduzir depend√™ncias de tempo e a distribui√ß√£o complexa de s√©ries temporais multidimensionais. <br><br>  A capacidade das redes contradit√≥rias generativas (GANs) de imitar qualquer distribui√ß√£o de dados, em particular nas tarefas de "desenhar" faces e gerar senten√ßas, √© amplamente conhecida.  Mas, como regra, esses modelos requerem treinamento inicial em um conjunto de dados completo, sem lacunas, ou n√£o levam em considera√ß√£o a natureza consistente dos dados. <br><br>  Os autores prop√µem complementar o GAN com um novo elemento - a Unidade Recorrente Fechada de Imputa√ß√£o (GRUI).  A principal diferen√ßa do GRU usual √© que o GRUI pode aprender com dados em intervalos de diferentes comprimentos entre as observa√ß√µes e ajustar o efeito das observa√ß√µes, dependendo da dist√¢ncia no tempo a partir do ponto atual.  Um par√¢metro de atenua√ß√£o especial Œ≤ √© calculado, cujo valor varia de 0 a 1 e quanto menor, maior o intervalo de tempo entre a observa√ß√£o atual e a anterior n√£o vazia. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6ab/c71/63b/6abc7163bf3ff1b16310104100b53236.png" alt="imagem"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/203/a64/599/203a6459932c852ad827db0d9574ef2c.png" alt="imagem"><br><br>  O discriminador e o gerador GAN consistem em uma camada GRUI e uma camada totalmente conectada.  Como de costume nos GANs, o gerador aprende a simular os dados de origem (nesse caso, basta preencher as lacunas nas linhas), e o discriminador aprende a distinguir as linhas preenchidas com o gerador das reais. <br><br>  Como se viu, essa abordagem restaura os dados de maneira muito adequada, mesmo em s√©ries temporais, com uma parcela muito grande de omiss√µes (na tabela abaixo - recupera√ß√£o de dados MSE no conjunto de dados KDD, dependendo da porcentagem de omiss√µes e m√©todo de recupera√ß√£o. Na maioria dos casos, o m√©todo baseado em GAN oferece a maior precis√£o recupera√ß√£o). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/188/737/e57/188737e575173058d1c0a79482b8679d.png" alt="imagem"><br><br>  <b>Sobre a dimensionalidade da incorpora√ß√£o de palavras</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Resumo</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√≥digo</a> <br><br>  A incorpora√ß√£o de palavras / representa√ß√£o vetorial de palavras √© uma abordagem amplamente usada para v√°rias aplica√ß√µes da PNL: de sistemas de recomenda√ß√£o √† an√°lise da colora√ß√£o emocional de textos e tradu√ß√£o autom√°tica. <br><br>  Al√©m disso, a quest√£o de como definir otimamente um hiperpar√¢metro t√£o importante quanto a dimens√£o dos vetores permanece em aberto.  Na pr√°tica, na maioria das vezes √© selecionado por pesquisa emp√≠rica exaustiva ou definido por padr√£o, por exemplo, no n√≠vel 300. Ao mesmo tempo, uma dimens√£o muito pequena n√£o permite refletir todas as rela√ß√µes significativas entre as palavras e muito grande pode levar √† reciclagem. <br><br>  Os autores do estudo prop√µem sua solu√ß√£o para esse problema, minimizando o par√¢metro de perda de PIP, uma nova medida da diferen√ßa entre as duas op√ß√µes de incorpora√ß√£o. <br>  O c√°lculo √© baseado em matrizes PIP que cont√™m os produtos escalares de todos os pares de representa√ß√µes vetoriais de palavras no corpus.  A perda de PIP √© calculada como a norma Frobenius entre as matrizes PIP de duas incorpora√ß√µes: treinadas em dados (incorpora√ß√£o treinada E_hat) e ideal, treinadas em dados ruidosos (incorpora√ß√£o de or√°culo E). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/135/a0a/1f2/135a0a1f216137c64ab73f9d2b86f0dc.png" alt="imagem" width="300" height="200"></div><br><br>  Parece simples: voc√™ precisa escolher uma dimens√£o que minimize a perda de PIP, o √∫nico momento incompreens√≠vel √© onde obter a incorpora√ß√£o do or√°culo.  Em 2015-2017, foram publicados v√°rios trabalhos nos quais foi demonstrado que v√°rios m√©todos para a constru√ß√£o de incorporamentos (word2vec, GloVe, LSA) fatoram implicitamente (diminuem a dimens√£o) a matriz de sinais do caso.  No caso do word2vec (skip-gram), a matriz do sinal √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PMI</a> , no caso do GloVe, √© a matriz de contagens de log.  √â proposto pegar um dicion√°rio de tamanho n√£o muito grande, construir uma matriz de sinal e usar SVD para obter a incorpora√ß√£o do or√°culo.  Assim, a dimens√£o de incorpora√ß√£o do or√°culo √© igual √† classifica√ß√£o da matriz de sinal (na pr√°tica, para um dicion√°rio de 10k palavras, a dimens√£o ser√° da ordem de 2k).  Entretanto, nossa matriz emp√≠rica de sinais √© sempre barulhenta e temos que recorrer a esquemas complicados para obter a incorpora√ß√£o do or√°culo e estimar a perda de PIP por uma matriz barulhenta. <br><br>  Os autores argumentam que, para selecionar a dimens√£o de incorpora√ß√£o ideal, basta usar um dicion√°rio de 10 mil palavras, o que n√£o √© muito e permite executar esse procedimento em um per√≠odo de tempo razo√°vel. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/454/806/a20/454806a208dd7c10df8b9cbd365c440a.png" alt="imagem"><br><br>  Como se viu, a dimens√£o de incorpora√ß√£o calculada dessa maneira na maioria dos casos com um erro de at√© 5% coincide com a dimens√£o ideal determinada com base em estimativas de especialistas.  Aconteceu (esperado) que o Word2Vec e o GloVe praticamente n√£o foram treinados novamente (a perda de PIP n√£o cai em dimens√µes muito grandes), mas o LSA √© treinado com muita for√ßa. <br><br>  Usando o c√≥digo publicado no github pelos autores, √© poss√≠vel procurar a dimens√£o ideal do Word2Vec (skip-gram), GloVe, LSA. <br><br>  <b>FRAGE: Representa√ß√£o Agn√≥stica de Palavras com Frequ√™ncia</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Resumo</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√≥digo</a> <br><br>  Os autores falam sobre como os casamentos funcionam de maneira diferente para palavras raras e populares.  Por popular, quero dizer n√£o parar palavras (n√£o as consideramos), mas palavras informativas que n√£o s√£o muito raras. <br><br>  As observa√ß√µes s√£o as seguintes: <br><br>  Se falamos de palavras populares, sua proximidade na medida do cosseno reflete muito bem <br><br><ol><li>  sua afinidade sem√¢ntica.  Para palavras raras, isso n√£o √© verdade (o que √© esperado) e (o que √© menos esperado) o topo das palavras de cosseno mais pr√≥ximas de uma palavra rara tamb√©m s√£o raras e, ao mesmo tempo, semanticamente sem rela√ß√£o.  Ou seja, palavras raras e frequentes no espa√ßo dos casamentos vivem em lugares diferentes (em cones diferentes, se estamos falando de cosseno) </li><li>  Durante o treinamento, os vetores de palavras populares s√£o atualizados com muito mais frequ√™ncia e, em m√©dia, ficam duas vezes mais longe da inicializa√ß√£o do que os vetores de palavras raras.  Isso leva ao fato de que a incorpora√ß√£o de palavras raras √©, em m√©dia, mais pr√≥xima da origem.  Para ser sincero, sempre acreditei que, pelo contr√°rio, palavras raras s√£o geralmente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mais longas</a> e n√£o sei como me relacionar com a afirma√ß√£o dos autores =) </li></ol><br>  Qualquer que seja a rela√ß√£o entre as normas L2 dos casamentos, a separabilidade de palavras populares e raras n√£o √© um fen√¥meno muito bom.  Queremos que os casamentos reflitam a sem√¢ntica de uma palavra, n√£o sua frequ√™ncia. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c7e/f4d/e70/c7ef4de7034a8347269fa40d6bdc7005.png" alt="imagem"><br><br>  A imagem mostra as palavras populares (vermelhas) e raras (azuis) do Word2Vec ap√≥s SVD.  Popular aqui refere-se aos 20% principais de palavras em frequ√™ncia. <br><br>  Se o problema estivesse apenas nas normas L2 de casamentos, poder√≠amos normaliz√°-las e viver felizes, mas, como eu disse no primeiro par√°grafo, palavras raras tamb√©m s√£o separadas das populares pela proximidade do cosseno (em coordenadas polares). <br><br>  Os autores sugerem, √© claro, GAN.  Vamos fazer o mesmo que antes, mas adicione um discriminador que tentar√° distinguir entre palavras populares e raras (novamente, consideramos popular o% n das palavras na frequ√™ncia). <br><br>  Parece algo como isto: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f0e/0a3/0b7/f0e0a30b77a9071ff63fa208401fad56.png" alt="imagem"><br><br>  Os autores testam a abordagem nas tarefas de similaridade de palavras, tradu√ß√£o autom√°tica, classifica√ß√£o de texto e modelagem de idiomas e em todos os lugares com desempenho superior √† linha de base.  Na semelhan√ßa de palavras, afirma-se que a qualidade cresce especialmente de maneira not√°vel em palavras raras. <br><br>  Um exemplo: cidadania.  Quest√µes de pular grama: felicidade, pakistans, demitir, refor√ßar.  Quest√µes de FRAGE: popula√ß√£o, status, dignidade, b√ºrger.  As palavras cidad√£o e cidad√£os em FRAGE est√£o em 79¬∫ e 7¬∫ lugares, respectivamente (na proximidade da cidadania); em pular grama, eles n√£o est√£o entre os 10000 melhores. <br><br>  Por alguma raz√£o, os autores postaram o c√≥digo apenas para tradu√ß√£o autom√°tica e modelagem de linguagem, similaridade de palavras e tarefas de classifica√ß√£o de texto no reposit√≥rio, infelizmente, n√£o s√£o representadas. <br><br>  <b>Alinhamento n√£o modal supervisionado dos espa√ßos de incorpora√ß√£o de fala e texto</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Resumo</a> <br>  C√≥digo: sem c√≥digo, mas eu gostaria <br><br>  Estudos recentes mostraram que dois espa√ßos vetoriais treinados usando algoritmos de incorpora√ß√£o (por exemplo, word2vec) em corpos de texto em dois idiomas diferentes podem ser comparados entre si sem marca√ß√£o e correspond√™ncia de conte√∫do entre os dois edif√≠cios.  Em particular, essa abordagem √© usada para tradu√ß√£o autom√°tica no Facebook.  Uma das principais propriedades dos espa√ßos de incorpora√ß√£o √© usada: dentro deles, palavras semelhantes devem estar geometricamente pr√≥ximas e palavras diferentes, pelo contr√°rio, devem estar longe uma da outra.  Sup√µe-se que, em geral, a estrutura do espa√ßo vetorial seja preservada, independentemente do idioma em que o corpus se destinava ao ensino. <br><br>  Os autores do artigo foram al√©m e aplicaram uma abordagem semelhante ao campo do reconhecimento e tradu√ß√£o autom√°ticos de fala.  Prop√µe-se treinar o espa√ßo vetorial separadamente para o corpus de texto no idioma de interesse (por exemplo, Wikipedia), separadamente para o corpus de fala gravada (em formato de √°udio), possivelmente em outro idioma, previamente dividido em palavras, e depois comparar esses dois espa√ßos da mesma maneira que em dois casos de texto. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d07/950/b6f/d07950b6f9bac05e9ce48dd80bb24838.png" alt="imagem"><br><br>  Para o corpus de texto, o word2vec √© usado e, para a fala, uma abordagem semelhante, chamada por Speech2vec, √© baseada no LSTM e nas metodologias usadas para o word2vec (CBOW / skip-gram), portanto, pressup√µe-se que ele combine palavras precisamente por caracter√≠sticas contextuais e sem√¢nticas, e n√£o est√° soando. <br><br>  Depois que os dois espa√ßos vetoriais s√£o treinados e h√° dois conjuntos de incorpora√ß√µes - S (no corpo da fala), consistindo em n incorpora√ß√µes da dimens√£o d1 e T (no corpo do texto), consistindo em m incorpora√ß√µes da dimens√£o d2, √© necess√°rio compar√°-las.  Idealmente, temos um dicion√°rio que determina qual vetor de S corresponde a qual vetor de T. Em seguida, duas matrizes s√£o formadas para compara√ß√£o: k combina√ß√µes s√£o selecionadas de S, que formam uma matriz X do tamanho d1 xk;  a partir de T, k tamb√©m s√£o selecionados casamentos correspondentes (de acordo com o dicion√°rio) previamente selecionados de S, e √© obtida uma matriz Y de tamanho d2 x k.  Em seguida, voc√™ precisa encontrar um mapeamento linear W de modo que: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/db3/59e/e40/db359ee40ad9f907c6461d378db3d7aa.png" alt="imagem" width="300" height="200"></div><br><br>  Por√©m, como o artigo considera a abordagem n√£o supervisionada, inicialmente n√£o h√° dicion√°rio; portanto, √© proposto um procedimento para gerar um dicion√°rio sint√©tico, composto de duas partes.  Primeiro, obtemos a primeira aproxima√ß√£o de W usando treinamento de dom√≠nio-advers√°rio (um modelo competitivo como GAN, mas em vez do gerador - um mapeamento linear de W, com o qual tentamos tornar S e T indistingu√≠veis um do outro, e o discriminador tenta determinar a origem real da incorpora√ß√£o).  Em seguida, com base nas palavras cujas incorpora√ß√µes mostraram a melhor correspond√™ncia entre si e s√£o mais frequentemente encontradas nos dois edif√≠cios, um dicion√°rio √© formado.  Depois disso, ocorre o refinamento de W de acordo com a f√≥rmula acima. <br><br>  Essa abordagem fornece resultados compar√°veis ‚Äã‚Äãao aprendizado dos dados rotulados, o que pode ser muito √∫til na tarefa de reconhecer e traduzir a fala de idiomas raros para os quais h√° muito poucos casos paralelos de texto de fala ou est√£o ausentes. <br><br>  <b>Detec√ß√£o de anomalias profundas usando transforma√ß√µes geom√©tricas</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Resumo</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√≥digo</a> <br><br>  Uma abordagem bastante incomum na detec√ß√£o de anomalias, que, segundo os autores, derrota bastante outras abordagens. <br><br>  A id√©ia √© a seguinte: vamos apresentar K diferentes transforma√ß√µes geom√©tricas (uma combina√ß√£o de turnos, rota√ß√£o de 90 graus e reflex√£o) e aplic√°-las a cada imagem do conjunto de dados original.  A imagem obtida como resultado da i-√©sima transforma√ß√£o agora pertencer√° √† classe i, ou seja, haver√° K classes no total, cada uma delas ser√° representada pelo n√∫mero de imagens originalmente no conjunto de dados.  Agora, ensinaremos uma classifica√ß√£o multiclasse sobre essa marca√ß√£o (os autores escolheram ampla resnet). <br><br>  Agora podemos obter vetores K y (Ti (x)) da dimens√£o K para uma nova imagem, onde Ti √© a i-√©sima transforma√ß√£o, x √© a imagem, y √© a sa√≠da do modelo.  A defini√ß√£o b√°sica de "normalidade" √© a seguinte: <br><br>  Aqui, para a imagem x, adicionamos as probabilidades previstas das classes corretas para todas as transforma√ß√µes.  Quanto maior a "normalidade", maior a probabilidade de a imagem ser tirada da mesma distribui√ß√£o que a amostra de treinamento.  Os autores afirmam que isso j√° funciona muito bem, mas, no entanto, oferecem uma maneira mais complexa que funciona ainda um pouco melhor.  Assumiremos que o vetor y (Ti (x)) para cada transforma√ß√£o de Ti √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Dirichlet</a> distribu√≠do e tomaremos o logaritmo de probabilidade como uma medida da ‚Äúnormalidade‚Äù da imagem.  Os par√¢metros de distribui√ß√£o do Dirichlet s√£o estimados em um conjunto de treinamento. <br><br>  Os autores relatam o incr√≠vel aumento de desempenho em compara√ß√£o com outras abordagens. <br><br>  <b>Uma estrutura unificada simples para detectar amostras fora de distribui√ß√£o e ataques adversos</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Resumo</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√≥digo</a> <br><br>  A identifica√ß√£o na amostra para a aplica√ß√£o do modelo de casos significativamente diferente da distribui√ß√£o da amostra de treinamento √© um dos principais requisitos para a obten√ß√£o de resultados confi√°veis ‚Äã‚Äãde classifica√ß√£o.  Ao mesmo tempo, as redes neurais s√£o conhecidas por seu recurso com um alto grau de confian√ßa (e incorretamente) para classificar objetos que n√£o foram encontrados no treinamento ou intencionalmente corrompidos (exemplos advers√°rios). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1e0/780/f35/1e0780f3540fcb4ba894f38a40c31cbb.png" alt="imagem"><br><br>  Os autores do artigo oferecem um novo m√©todo para identificar esses e outros casos "ruins".  A abordagem √© implementada da seguinte forma: primeiro, uma rede neural com a sa√≠da softmax usual √© treinada, depois a sa√≠da de sua pen√∫ltima camada √© obtida e o classificador generativo √© treinado nela.  Seja x - que √© alimentado na entrada do modelo para um objeto de classifica√ß√£o espec√≠fico, y - o r√≥tulo da classe correspondente, suponha que tenhamos um classificador softmax pr√©-treinado no formato: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/223/898/826/223898826445e2677c03a2078b182208.png" alt="imagem" width="300" height="200"></div><br><br>  Onde wc e bc s√£o os pesos e constantes da camada softmax para as classes cef (.) √â a sa√≠da do pen√∫ltimo DNN da soja. <br><br>  Al√©m disso, sem nenhuma altera√ß√£o no classificador pr√©-treinado, √© feita uma transi√ß√£o para o classificador generativo, a saber, an√°lise discriminante.  Sup√µe-se que os recursos extra√≠dos da pen√∫ltima camada do classificador softmax tenham uma distribui√ß√£o normal multidimensional, cada componente correspondente a uma classe.  Ent√£o a distribui√ß√£o condicional pode ser especificada atrav√©s do vetor de m√©dias da distribui√ß√£o multidimensional e sua matriz de covari√¢ncia: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ada/0d8/e70/ada0d8e70536c7993a6061b154f3c0eb.png" alt="imagem" width="300" height="200"></div><br><br>  Para avaliar os par√¢metros do classificador generativo, as m√©dias emp√≠ricas s√£o calculadas para cada classe, bem como a covari√¢ncia dos casos da amostra de treinamento {(x1, y1), ..., (xN, yN)}: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ada/0d8/e70/ada0d8e70536c7993a6061b154f3c0eb.png" alt="imagem" width="300" height="200"></div><br><br>  onde N √© o n√∫mero de casos da classe correspondente no conjunto de treinamento.  Ent√£o, uma medida de confiabilidade √© calculada na amostra de teste - a dist√¢ncia de Mahalanobis entre o caso de teste e a distribui√ß√£o de classe normal mais pr√≥xima desse caso. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/095/928/03b/09592803b18f664fad5940fc81d47f77.png" alt="imagem" width="400" height="300"></div><br><br>  Como se viu, essa m√©trica funciona de maneira muito mais confi√°vel em objetos at√≠picos ou danificados, sem fornecer estimativas elevadas, como a camada softmax.  Na maioria das compara√ß√µes de dados diferentes, o m√©todo proposto mostrou resultados que excederam o estado da arte atual ao encontrar os dois casos que n√£o estavam no treinamento e estragaram intencionalmente. <br><br>  Al√©m disso, os autores consideram outra aplica√ß√£o interessante de sua metodologia: use o classificador generativo para destacar novas classes no teste que n√£o estava em treinamento e atualize os par√¢metros do pr√≥prio classificador para que possa determinar essa nova classe no futuro. <br><br>  <b>Exemplos Advers√°rios que Enganam a Vis√£o por Computador e os Humanos por Tempo Limitado</b> <br>  Resumo: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://arxiv.org/abs/1802.08195</a> <br><br>     adversarial examples     .     ,           .          adversarial example      . ,         ,   , ,         , ,  ,      adversarial attacks. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/859/b13/cf0/859b13cf0bb3c14ac58eeab39b5a0945.png" alt="imagem"><br><br>         adversarial examples.   adversarial examples  ,         (   ,           ). <br><br> ,   adversarial example,        . ,        ,         63          .    accuracy      10% ,   adversarial.        ,  adversarial             ,     .   ,     perturbation   perturbation   ,  accuracy        . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/966/f4d/e03/966f4de0389283dd83f73a1be2cf36cb.png" alt="imagem"><br><br>   adv ‚Äî adversarial example, image ‚Äî  , flip ‚Äî   + adversarial perturbation,   . <br><br> <b>Sanity Checks for Saliency Maps</b> <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Abstract</a> <br><br>   ‚Äî      .     deep learning,     saliency maps. Saliency maps                 .    saliency map,       ,      ‚Äú‚Äù. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aa5/2c5/659/aa52c5659d4c00d7666661797671c4b9.png" alt="imagem"><br><br>     : ‚Äú      saliency maps?‚Äù    ,   : <br><br><ol><li> Saliency map      </li><li> Saliency map    ,     </li></ol><br>     ,      : cascading randomization ( ,     ,   saliency map)  independent randomization (  ).     :      ,     saliency maps. <br>    saliency map     ,   ,       saliency maps. : ‚ÄúTo our surprise, some widely deployed saliency methods are independent of both the data the model was trained on, and the model parameters‚Äù, ‚Äî  . , ,   saliency maps,     ,  cascading randomization: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/965/eaa/ca7/965eaaca7902d24ef5369a63d493b4ff.png" alt="imagem"><br><br>      ,           .     ,   saliency maps    . <br><br>    ,  ‚Äî  saliency maps          ,      ,      confirmation bias.         ,          . <br><br> <b>An intriguing failing of convolutional neural networks and the CoordConv solution</b> <br> Abstract: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://arxiv.org/abs/1807.03247</a> <br> :           ,     10 . <br><br>        Uber.        ,  ,     ,     .           ,           : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6ed/408/c14/6ed408c1456a509c86a6260df5c5a23b.png" alt="imagem"><br><br>    :    (     CoodrConv )   i  j,          : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a2a/87e/8cb/a2a87e8cb6b7d283396a0fb3ef11fe30.png" alt="imagem"><br><br> , : <br><br><ol><li>       ImageNet'.         , ,   ,    ,         </li><li> CoordConv   object detection.        MNIST,      Faster R-CNN,    IoU  21% </li><li>   CoordConv  GAN    . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fee/a18/425/feea18425335abbb7d784669a1b82bcd.png" alt="imagem"><br><br>  GAN'   :                 LSUN.       ,     ‚Äî     c.  ,   GAN'    , ,         .   CoordConv         ,      .    LSUN   d ,     ,  CoordConv GAN,    <br></li><li> 4.  CoordConv  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A2C</a>     (  ) . </li></ol><br>        ,       ,     .   CoordConv      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">U-net</a> : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://arxiv.org/abs/1812.01429,%2520">https://arxiv.org/abs/1812.01429, https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/69274</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://github.com/mjDelta/Kaggle-RSNA-Pneumonia-Detection-Challenge</a> . <br><br>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">  </a> . <br><br> <b>Regularizing by the Variance of the Activations' Sample-Variances</b> <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Abstract</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> <br><br>     batch normalization.          - .      :       S1  S2    : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e5f/2ea/97a/e5f2ea97aaebf6af472880bc2190b2cc.png" alt="imagem" width="300" height="200"></div><br><br>  onde œÉ2 s√£o varia√ß√µes da amostra em S1 e S2, respectivamente, Œ≤ √© o coeficiente positivo treinado.  Os autores chamam isso de perda de const√¢ncia de varia√ß√£o (VCL) e a adicionam √† perda total. <br><br>  Na se√ß√£o sobre experimentos, os autores reclamam de como os resultados dos artigos de outras pessoas n√£o s√£o reproduzidos e se comprometem a definir um c√≥digo reproduz√≠vel (apresentado).  Primeiro, eles experimentaram uma pequena malha de 11 camadas no conjunto de dados de imagens pequenas (CIFAR-10 e CIFAR-100).  Conclu√≠mos que a VCL est√° provando, se voc√™ usar Leaky ReLU ou ELU como ativa√ß√µes, mas a normaliza√ß√£o em lote funcionar√° melhor com ReLU.  Em seguida, aumentam o n√∫mero de camadas em 2 vezes e passam para o Tiny Imagenet - uma vers√£o simplificada do Imagenet com 200 classes e uma resolu√ß√£o de 64x64.  Na valida√ß√£o, o VCL supera a normaliza√ß√£o de lote na grade com ELU, assim como ResNet-110 e DenseNet-40, mas supera Wide-ResNet-32.  Um ponto interessante √© que os melhores resultados s√£o obtidos quando os subconjuntos S1 e S2 consistem em duas amostras. <br><br>  Al√©m disso, os autores testam o VCL em redes feed-forward e o VCL ganha um pouco mais frequentemente do que uma rede com normaliza√ß√£o em lote ou sem regulariza√ß√£o. <br><br>  <b>DropMax: Softmax variacional adapt√°vel</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Resumo</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√≥digo</a> <br><br>  √â proposto no problema de classifica√ß√£o em v√°rias classes a cada itera√ß√£o da descida do gradiente para cada amostra eliminar aleatoriamente algum n√∫mero de classes incorretas.  Al√©m disso, a probabilidade com a qual abandonamos uma ou outra classe para um ou outro objeto tamb√©m est√° sendo treinada.  Como resultado, a rede ‚Äúse concentra‚Äù em distinguir as classes mais dif√≠ceis de separar. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2d/f45/914/b2df45914519d3b6dd1d4f12d5513775.png" alt="imagem"><br><br>  Experimentos nos subconjuntos MNIST, CIFAR e Imagenet mostram que o DropMax tem um desempenho melhor que o SoftMax padr√£o e algumas de suas modifica√ß√µes. <br><br>  <b>Modelos inteligentes precisos com intera√ß√µes em pares</b> <br>  (Amigos n√£o deixam amigos implantar modelos de caixa preta: a import√¢ncia da inteligibilidade no aprendizado de m√°quina) <br><br>  Resumo: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">http://www.cs.cornell.edu/~yinlou/papers/lou-kdd13.pdf</a> <br>  C√≥digo: n√£o est√° l√°.  Estou muito interessado em saber como os autores atribuem um nome t√£o imperativo √† falta de c√≥digo.  Acad√™micos, senhor =) <br><br>  Voc√™ pode olhar para este pacote, por exemplo: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://github.com/dswah/pyGAM</a> .  As intera√ß√µes entre os recursos foram adicionadas h√° pouco tempo (o que realmente distingue o GAM do GA2M). <br><br>  Este artigo foi apresentado no √¢mbito do workshop ‚ÄúInterpretabilidade e robustez em √°udio, fala e linguagem‚Äù, embora seja dedicado √† interpretabilidade dos modelos em geral, e n√£o ao campo da an√°lise de som e fala. Provavelmente, todos foram confrontados, em certa medida, com o dilema de escolher entre a interpretabilidade do modelo e sua precis√£o.  Se usarmos a regress√£o linear usual, podemos entender pelos coeficientes como cada vari√°vel independente afeta o dependente.  Se usarmos modelos de "caixa preta", por exemplo, aumento de gradiente sem restri√ß√µes de complexidade ou redes neurais profundas, um modelo ajustado corretamente em dados adequados ser√° muito preciso, mas rastrear e explicar todos os padr√µes que o modelo encontrado nos dados ser√° problem√°tico.  Portanto, ser√° dif√≠cil explicar o modelo ao cliente e rastrear se ele aprendeu algo que n√£o gostar√≠amos.  A tabela abaixo fornece estimativas da interpretabilidade e precis√£o relativas de v√°rios tipos de modelos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fca/429/548/fca42954836ae74af472d4baacf732f1.png" alt="imagem"><br><br>  Um exemplo de situa√ß√£o em que a baixa interpretabilidade do modelo est√° associada a grandes riscos: em um dos conjuntos de dados m√©dicos, foi resolvido o problema de prever a probabilidade de o paciente morrer de pneumonia.  O seguinte padr√£o interessante foi encontrado nos dados: se uma pessoa tem asma br√¥nquica, a probabilidade de morrer de pneumonia √© menor do que nas pessoas sem essa doen√ßa.  Quando os pesquisadores se voltaram para a pr√°tica de m√©dicos, descobriu-se que esse padr√£o realmente existe, pois as pessoas com asma no caso de pneumonia recebem a ajuda mais imediata e medicamentos fortes.  Se trein√°ssemos o xgboost nesse conjunto de dados, provavelmente ele teria capturado esse padr√£o, e nosso modelo classificaria os pacientes com asma como um grupo de baixo risco e, consequentemente, recomendaria uma prioridade e intensidade de tratamento mais baixas para eles. <br><br>  Os autores do artigo oferecem uma alternativa que √© interpret√°vel e precisa ao mesmo tempo - este √© o GA2M, uma subesp√©cie de modelos aditivos generalizados. <br><br>  O GAM cl√°ssico pode ser considerado como uma generaliza√ß√£o adicional do GLM: um modelo √© uma soma, cujo termo reflete a influ√™ncia de apenas uma vari√°vel independente no dependente, mas a influ√™ncia √© expressa n√£o por um coeficiente de peso, como no GLM, mas por uma fun√ß√£o n√£o param√©trica suave (como regra definida em partes) fun√ß√µes - estrias ou √°rvores de pequena profundidade, incluindo "tocos").  Devido a esse recurso, os GAMs podem modelar relacionamentos mais complexos do que um modelo linear simples.  Por outro lado, as depend√™ncias aprendidas (fun√ß√µes) podem ser visualizadas e interpretadas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/643/828/ca8/643828ca8aaeb0f0728ba2d094de7e43.png" alt="imagem"><br><br>  No entanto, os GAMs padr√£o ainda frequentemente n√£o atingem a precis√£o dos algoritmos de caixa preta.  Para corrigir isso, os autores do artigo oferecem um compromisso - para adicionar √† equa√ß√£o do modelo, al√©m das fun√ß√µes de uma vari√°vel, um pequeno n√∫mero de fun√ß√µes de duas vari√°veis ‚Äã‚Äã- pares cuidadosamente selecionados cuja intera√ß√£o √© significativa para prever a vari√°vel dependente.  Assim, o GA2M √© obtido. <br><br>  Primeiro, um GAM padr√£o √© criado (sem levar em considera√ß√£o a intera√ß√£o das vari√°veis) e, em seguida, pares de vari√°veis ‚Äã‚Äãs√£o adicionados passo a passo (o GAM restante √© usado como vari√°vel de destino).  Para o caso em que h√° muitas vari√°veis ‚Äã‚Äãe a atualiza√ß√£o do modelo ap√≥s cada etapa √© computacionalmente dif√≠cil, √© proposto um algoritmo de classifica√ß√£o FAST, com o qual voc√™ pode pr√©-selecionar pares potencialmente √∫teis e evitar enumera√ß√£o completa. <br><br>  Essa abordagem permite obter qualidade pr√≥xima a modelos de complexidade ilimitada.  A tabela mostra a taxa de erro dos modelos de aditivos generalizados em compara√ß√£o com uma floresta aleat√≥ria para resolver o problema de classifica√ß√£o em diferentes conjuntos de dados e, na maioria dos casos, a qualidade da previs√£o para o GA2M com o FAST e para florestas aleat√≥rias n√£o √© significativamente diferente. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e5b/809/a50/e5b809a50067cbfcd2f7bbb04f98630e.png" alt="imagem"><br><br>  Gostaria de chamar a aten√ß√£o para as caracter√≠sticas do trabalho dos acad√™micos que se oferecem para enviar esses aprimoramentos e leituras profundas ao forno.  Observe que os conjuntos de dados nos quais os resultados s√£o apresentados n√£o cont√™m mais de 20 mil objetos (todos os conjuntos de dados do reposit√≥rio UCI).  Surge uma pergunta natural: n√£o h√° realmente nenhum conjunto de dados aberto de tamanho normal para tais experimentos em 2018?  Voc√™ pode ir al√©m e comparar em um conjunto de dados de 50 objetos - existe a chance de o modelo constante n√£o diferir significativamente de uma floresta aleat√≥ria. <br><br>  O pr√≥ximo ponto √© a regulariza√ß√£o.  Em um grande n√∫mero de sinais, √© muito f√°cil treinar mesmo sem intera√ß√µes.  Os autores podem acreditar que esse problema n√£o existe, e o √∫nico problema √© o modelo de caixa preta.  Pelo menos no artigo, a regulariza√ß√£o n√£o √© mencionada em nenhum lugar, embora seja obviamente necess√°rio. <br><br>  E o √∫ltimo, sobre interpretabilidade.  Mesmo modelos lineares n√£o s√£o interpret√°veis ‚Äã‚Äãse tivermos muitos recursos.  Quando voc√™ tem 10 mil pesos normalmente distribu√≠dos (no caso de usar a regulariza√ß√£o L2, ser√° algo assim), √© imposs√≠vel dizer exatamente quais sinais s√£o respons√°veis ‚Äã‚Äãpelo fato de o predizerprproba dar 0,86.  Para interpretabilidade, queremos n√£o apenas um modelo linear, mas um modelo linear com pesos esparsos.  Parece que isso pode ser alcan√ßado pela regulariza√ß√£o de L1, mas aqui tamb√©m n√£o √© t√£o simples.  De um conjunto de recursos fortemente correlacionados, a regulariza√ß√£o L1 escolher√° um quase por acidente.  O restante ter√° um peso 0, embora, se um desses recursos tiver capacidade preditiva, os outros claramente n√£o sejam apenas ru√≠do.  Em termos de interpreta√ß√£o do modelo, isso pode ser bom; em termos de entendimento do relacionamento dos recursos e da vari√°vel de destino, isso √© muito ruim.  Ou seja, mesmo com modelos lineares, nem tudo √© t√£o simples, mais detalhes sobre modelos interpret√°veis ‚Äã‚Äãe cred√≠veis podem ser encontrados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br>  <b>Visualiza√ß√£o para aprendizado de m√°quina: UMAP</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Absract</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√≥digo</a> <br><br>  No dia dos tutoriais, um dos primeiros a ser apresentado foi o "Visualization for Machine Learning", do Google Brain.  Como parte do tutorial, fomos informados sobre a hist√≥ria das visualiza√ß√µes, a partir do criador dos primeiros gr√°ficos, bem como sobre v√°rios recursos do c√©rebro humano, al√©m de percep√ß√µes e t√©cnicas que podem ser usadas para chamar a aten√ß√£o para a coisa mais importante da imagem, mesmo contendo muitos pequenos detalhes - por exemplo, destacando forma, cor, moldura, etc., como na figura abaixo.  Vou pular esta parte, mas h√° uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">boa revis√£o</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/751/f0f/c31/751f0fc318a4bb3edadf59e35ecc7ba9.png" alt="imagem"><br><br>  Pessoalmente, eu estava mais interessado no t√≥pico de visualiza√ß√£o de conjuntos de dados multidimensionais, em particular, a abordagem de aproxima√ß√£o e proje√ß√£o de coletores uniformes (UMAP) - um novo m√©todo n√£o linear de redu√ß√£o de dimens√£o.  Foi proposto em fevereiro deste ano, poucas pessoas o utilizam ainda, mas parece promissor tanto em termos de tempo de trabalho quanto em termos de qualidade da separa√ß√£o de classes em visualiza√ß√µes bidimensionais.  Portanto, em diferentes conjuntos de dados, o UMAP est√° 2-10 vezes √† frente do t-SNE e de outros m√©todos em termos de velocidade, e quanto maior a dimens√£o dos dados, maior a diferen√ßa no desempenho: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b82/045/a12/b82045a12b1cb8782c5c9fb64dfa46b9.png" alt="imagem"><br><br>  Al√©m disso, diferentemente do t-SNE, o tempo de opera√ß√£o do UMAP √© quase independente da dimens√£o do novo espa√ßo no qual incorporaremos nosso conjunto de dados (veja a figura abaixo), o que o torna uma ferramenta adequada para outras tarefas (al√©m da visualiza√ß√£o) - em particular, para reduzir a dimens√£o antes de treinar o modelo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0c6/f14/56a/0c6f1456a68537b5e12f58f6e1dfb740.png" alt="imagem"><br><br>  Ao mesmo tempo, os testes em diferentes conjuntos de dados mostraram que o UMAP n√£o funciona pior para visualiza√ß√£o, e o t-SNE √© melhor em alguns locais: por exemplo, nos conjuntos de dados MNIST e Fashion MNIST, as classes s√£o melhor separadas na vers√£o com UMAP: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f35/4b4/869/f354b48691226fd262e3f92af9fe398f.png" alt="imagem"><br><br>  Uma vantagem adicional √© uma implementa√ß√£o conveniente: a classe UMAP herda das classes sklearn, para que voc√™ possa us√°-lo como um transformador regular no pipeline sklearn.  Al√©m disso, argumenta-se que o UMAP √© mais interpret√°vel que o t-SNE, como  mant√©m melhor uma estrutura de dados global. <br><br>  No futuro, os autores planejam adicionar suporte para treinamento semi-supervisionado - ou seja, se tivermos tags para pelo menos alguns dos objetos, podemos criar o UMAP com base nessas informa√ß√µes. <br><br>  Quais artigos voc√™ gostou?  Escreva coment√°rios, fa√ßa perguntas, n√≥s responderemos a eles. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt434694/">https://habr.com/ru/post/pt434694/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt434684/index.html">Rust 2019 e al√©m: restri√ß√µes de crescimento</a></li>
<li><a href="../pt434686/index.html">Curso de Palestra sobre JavaScript e Node.js no KPI</a></li>
<li><a href="../pt434688/index.html">O FreeBSD planeja mudar para o ZFSonLinux</a></li>
<li><a href="../pt434690/index.html">Sistema operacional Haiku: portando aplicativos e criando pacotes</a></li>
<li><a href="../pt434692/index.html">As 25 startups mais caras dos EUA a morrer em 2018</a></li>
<li><a href="../pt434696/index.html">Funcion√°rios de gigantes de TI descobriram como influenciar as pol√≠ticas de suas empresas</a></li>
<li><a href="../pt434698/index.html">Pessimismo sobre multithreading</a></li>
<li><a href="../pt434700/index.html">Vantagens de seguir as guias de estilo ao desenvolver aplicativos Angular</a></li>
<li><a href="../pt434702/index.html">Por que o SSD moderno me trava</a></li>
<li><a href="../pt434704/index.html">Raz√µes para o decl√≠nio no custo do tr√°fego m√≥vel na R√∫ssia e a previs√£o para 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
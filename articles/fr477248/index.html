<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👐🏿 ➿ 👋🏾 Ma première expérience de récupération d'une base de données Postgres après un crash (page invalide dans le bloc 4123007 de relatton base / 16490) 🤦🏻 🔐 ↕️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Je veux partager avec vous ma première expérience réussie dans la restauration de toutes les fonctionnalités de la base de données Postgres. J'ai renc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ma première expérience de récupération d'une base de données Postgres après un crash (page invalide dans le bloc 4123007 de relatton base / 16490)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/477248/"> Je veux partager avec vous ma première expérience réussie dans la restauration de toutes les fonctionnalités de la base de données Postgres.  J'ai rencontré Postgres DBMS il y a six mois, avant cela, je n'avais aucune expérience en administration de base de données. <br><br><img src="https://habrastorage.org/webt/zf/35/tb/zf35tb0kz_lvnsdbyagxaueaffy.jpeg"><br><br>  Je travaille en tant qu'ingénieur semi-DevOps dans une grande entreprise informatique.  Notre entreprise développe des logiciels pour des services très chargés, mais je suis responsable des performances, de la maintenance et du déploiement.  Ils m'ont fixé une tâche standard: mettre à jour l'application sur un serveur.  L'application est écrite dans Django, pendant la mise à niveau, des migrations sont effectuées (modification de la structure de la base de données), et avant ce processus, nous supprimons le vidage complet de la base de données via le programme pg_dump standard au cas où. <br><br>  Une erreur inattendue s'est produite lors de la suppression du vidage (la version Postgres est 9.5): <br><br><pre><code class="plaintext hljs">pg_dump: Oumping the contents of table “ws_log_smevlog” failed: PQgetResult() failed. pg_dump: Error message from server: ERROR: invalid page in block 4123007 of relatton base/16490/21396989 pg_dump: The command was: COPY public.ws_log_smevlog [...] pg_dunp: [parallel archtver] a worker process dled unexpectedly</code> </pre> <br>  L'erreur <i>"page non valide dans le bloc"</i> indique des problèmes au niveau du système de fichiers, ce qui est très mauvais.  Sur divers forums, ils ont suggéré de créer <i>FULL</i> <i>VACUUM</i> avec l'option <i>zero_damaged_pages</i> pour résoudre ce problème.  Eh bien, popprobeum ... <br><a name="habracut"></a><br><h4>  Préparation de la récupération </h4><br>  <b>ATTENTION!</b>  Assurez-vous de sauvegarder Postgres avant toute tentative de restauration de la base de données.  Si vous avez une machine virtuelle, arrêtez la base de données et prenez un instantané.  S'il n'est pas possible de prendre un instantané, arrêtez la base de données et copiez le contenu du répertoire Postgres (y compris les fichiers wal) dans un endroit sûr.  L'essentiel de notre métier n'est pas d'aggraver les choses.  Lisez <a href="https://wiki.postgresql.org/wiki/Corruption">ceci</a> . <br><br>  Étant donné que la base de données fonctionnait pour moi dans son ensemble, je me suis limité au vidage de base de données habituel, mais j'ai exclu la table avec des données endommagées (option <i>-T, --exclude-table = TABLE</i> dans pg_dump). <br><br>  Le serveur était physique, il était impossible de prendre un instantané.  La sauvegarde est supprimée, continuez. <br><br><h4>  Vérification du système de fichiers </h4><br>  Avant de tenter de restaurer la base de données, vous devez vous assurer que tout est en ordre avec le système de fichiers lui-même.  Et en cas d'erreurs, corrigez-les, sinon vous ne pourrez qu'aggraver les choses. <br><br>  Dans mon cas, le système de fichiers avec la base de données a été monté dans <i>«/ srv»</i> et le type était ext4. <br><br>  Nous arrêtons la base de données: <i>systemctl stop postgresql@9.5-main.service</i> et vérifions que le système de fichiers n'est utilisé par personne et qu'il peut être démonté à l'aide de la <i>commande lsof</i> : <br>  <i>lsof + D / srv</i> <br><br>  J'ai quand même dû arrêter la base de données redis, car elle utilisait également <i>"/ srv"</i> .  Ensuite, j'ai démonté <i>/ srv</i> (umount). <br><br>  La vérification du système de fichiers a été effectuée à l'aide de l'utilitaire <i>e2fsck</i> avec l'option -f ( <i>Forcer la vérification même si le système de fichiers est marqué comme propre</i> ): <br><br><img src="https://habrastorage.org/webt/8_/zj/d_/8_zjd_jjdoiq_kg_qgndbq3mjpm.png"><br><br>  Ensuite, en utilisant l'utilitaire <i>dumpe2fs</i> ( <i>sudo dumpe2fs / dev / mapper / gu2 - sys-srv | grep vérifié</i> ), vous pouvez vérifier que la vérification a bien été effectuée: <br><br><img src="https://habrastorage.org/webt/i7/on/oe/i7onoelytrz8ihbjndgqrmkn37i.png"><br><br>  <i>e2fsck</i> indique qu'aucun problème n'a été trouvé au niveau du système de fichiers ext4, ce qui signifie que vous pouvez continuer à essayer de restaurer la base de données, ou plutôt revenir au <i>vide complet</i> (bien sûr, vous devez remonter le système de fichiers et démarrer la base de données). <br><br>  Si votre serveur est physique, assurez-vous de vérifier l'état des disques (via <i>smartctl -a / dev / XXX</i> ) ou le contrôleur RAID pour vous assurer que le problème n'est pas au niveau matériel.  Dans mon cas, le RAID s'est avéré être «ironique», j'ai donc demandé à l'administrateur local de vérifier l'état du RAID (le serveur était à plusieurs centaines de kilomètres de moi).  Il a dit qu'il n'y avait pas d'erreur, ce qui signifie que nous pouvons certainement commencer la restauration. <br><br><h4>  Tentative 1: zero_damaged_pages </h4><br>  Nous nous connectons à la base de données via le compte psql avec des droits de superutilisateur.  Nous avons besoin exactement du superutilisateur, car  lui seul peut changer l'option <i>zero_damaged_pages</i> .  Dans mon cas, ce sont des postgres: <br><br>  <i>psql -h 127.0.0.1 -U postgres -s [nom_base_de_données]</i> <br><br>  L'option <i>zero_damaged_pages est</i> nécessaire pour ignorer les erreurs de lecture (depuis le site Web de postgrespro): <br><blockquote>  Lorsqu'un titre de page endommagé est détecté, Postgres Pro signale généralement une erreur et abandonne la transaction en cours.  Si le paramètre zero_damaged_pages est activé, le système émet à la place un avertissement, efface la page endommagée en mémoire et poursuit le traitement.  Ce comportement détruit les données, à savoir toutes les lignes de la page endommagée. </blockquote>  Activez l'option et essayez de créer des tables de vide complètes: <br><br><pre> <code class="plaintext hljs">VACUUM FULL VERBOSE</code> </pre> <br><img src="https://habrastorage.org/webt/ft/ym/m1/ftymm1cwyqwpdunlfmecfa1seas.png"><br>  Malheureusement, l'échec. <br><br>  Nous avons rencontré une erreur similaire: <br><br><pre> <code class="plaintext hljs">INFO: vacuuming "“public.ws_log_smevlog” WARNING: invalid page in block 4123007 of relation base/16400/21396989; zeroing out page ERROR: unexpected chunk number 573 (expected 565) for toast value 21648541 in pg_toast_106070</code> </pre> <br>  <i><a href="https://postgrespro.ru/docs/postgrespro/9.5/storage-toast">pg_toast</a></i> - le mécanisme de stockage des "données longues" dans Postgres, si elles ne tiennent pas sur la même page (8 Ko par défaut). <br><br><h4>  Tentative 2: réindexer </h4><br>  Le premier conseil google n'a pas aidé.  Après quelques minutes de recherche, j'ai trouvé une deuxième astuce - pour faire <i>réindexer une</i> table endommagée.  J'ai rencontré ce conseil dans de nombreux endroits, mais il n'a pas inspiré confiance.  Faire réindexer: <br><br><pre> <code class="plaintext hljs">reindex table ws_log_smevlog</code> </pre> <br><img src="https://habrastorage.org/webt/km/kx/ny/kmkxnywf16bm7hywt5wu-zchofq.png"><br><br>  <i>réindexation</i> terminée sans problème. <br><br>  Cependant, cela n'a pas aidé, <i>VACUUM FULL</i> s'est écrasé avec une erreur similaire.  Comme j'avais l'habitude des échecs, j'ai commencé à chercher des conseils sur Internet et suis tombé sur un <a href="https://newbiedba.wordpress.com/2015/07/07/postgresql-missing-chunk-0-for-toast-value-in-pg_toast/">article</a> assez intéressant. <br><br><h4>  Tentative 3: SELECT, LIMIT, OFFSET </h4><br>  L'article ci-dessus suggère de regarder le tableau ligne par ligne et de supprimer les données problématiques.  Pour commencer, il fallait regarder toutes les lignes: <br><br><pre> <code class="plaintext hljs">for ((i=0; i&lt;"Number_of_rows_in_nodes"; i++ )); do psql -U "Username" "Database Name" -c "SELECT * FROM nodes LIMIT 1 offset $i" &gt;/dev/null || echo $i; done</code> </pre> <br>  Dans mon cas, le tableau contenait 1 <i>628 991</i> lignes!  Dans le bon sens, il fallait s'occuper du <a href="https://postgrespro.ru/docs/postgresql/10/ddl-partitioning">partitionnement des données</a> , mais c'est un sujet à discuter séparément.  C'était samedi, j'ai exécuté cette commande dans tmux et je me suis endormi: <br><br><pre> <code class="plaintext hljs">for ((i=0; i&lt;1628991; i++ )); do psql -U my_user -d my_database -c "SELECT * FROM ws_log_smevlog LIMIT 1 offset $i" &gt;/dev/null || echo $i; done</code> </pre> <br>  Le matin, j'ai décidé de vérifier comment les choses se passaient.  À ma grande surprise, j'ai trouvé qu'en 2 heures seulement 2% des données étaient scannées!  Je ne voulais pas attendre 50 jours.  Un autre échec complet. <br><br>  Mais je n'ai pas abandonné.  Je me demandais pourquoi l'analyse avait pris autant de temps.  À partir de la documentation (toujours sur postgrespro), j'ai découvert: <br><blockquote>  OFFSET indique de sauter le nombre de lignes spécifié avant de commencer à produire des lignes. <br>  Si OFFSET et LIMIT sont spécifiés, le système saute d'abord les lignes OFFSET puis commence à compter les lignes pour limiter LIMIT. <br><br>  Lorsque vous utilisez LIMIT, il est également important d'utiliser la clause ORDER BY pour que les lignes de résultat soient renvoyées dans un ordre spécifique.  Sinon, des sous-ensembles de chaînes imprévisibles seront retournés. </blockquote>  De toute évidence, la commande ci-dessus était erronée: tout d'abord, il n'y avait pas d' <i>ordre par</i> , le résultat pouvait être erroné.  Deuxièmement, Postgres a d'abord dû balayer et ignorer les lignes OFFSET, et avec une augmentation de <i>OFFSET, les</i> performances diminueraient encore plus. <br><br><h4>  Tentative 4: supprimer le vidage sous forme de texte </h4><br>  De plus, une idée apparemment brillante m'est venue à l'esprit: supprimer le vidage sous forme de texte et analyser la dernière ligne enregistrée. <br><br>  Mais d'abord, regardons la <i>structure de la</i> table <i>ws_log_smevlog</i> : <br><br><img src="https://habrastorage.org/webt/hv/_u/qk/hv_uqkxblnoxsivawvjrwepqyz8.png"><br><br>  Dans notre cas, nous avons une colonne <i>«id»</i> , qui contenait un identifiant unique (compteur) pour la ligne.  Le plan était le suivant: <br><br><ol><li>  Nous commençons à supprimer le vidage sous forme de texte (sous la forme de commandes sql) </li><li>  À un certain moment, le vidage serait interrompu en raison d'une erreur, mais le fichier texte serait toujours enregistré sur le disque </li><li>  Nous regardons la fin du fichier texte, ainsi nous trouvons l'identifiant (id) de la dernière ligne qui a été tournée avec succès </li></ol><br>  J'ai commencé à supprimer le vidage sous forme de texte: <br><br><pre> <code class="plaintext hljs">pg_dump -U my_user -d my_database -F p -t ws_log_smevlog -f ./my_dump.dump</code> </pre> <br>  Le vidage de vidage, comme prévu, a été interrompu avec la même erreur: <br><br><pre> <code class="plaintext hljs">pg_dump: Error message from server: ERROR: invalid page in block 4123007 of relatton base/16490/21396989</code> </pre> <br>  De plus, à travers <i>tail,</i> j'ai regardé la fin du vidage ( <i>tail -5 ./my_dump.dump</i> ) et <i>j'ai</i> constaté que le vidage était interrompu sur la ligne avec l'ID <i>186 525</i> .  "Donc, le problème est dans la ligne avec l'ID 186 526, il est cassé, et il doit être supprimé!" J'ai pensé.  Mais en faisant une demande à la base de données: <br>  " <i>Sélectionnez * dans ws_log_smevlog où id = 186529</i> ", il s'est avéré que tout allait bien avec cette ligne ... Les lignes avec les indices 186 530 - 186 540 ont également fonctionné sans problème.  Une autre «brillante idée» a échoué.  Plus tard, j'ai réalisé pourquoi cela s'est produit: lors de la suppression / modification de données de la table, elles ne sont pas physiquement supprimées, mais sont marquées comme «tuples morts», puis l' <i>autovacuum</i> vient et marque ces lignes comme supprimées et permet à nouveau l'utilisation de ces lignes.  Pour comprendre, si les données du tableau sont modifiées et que le vide automatique est activé, elles ne sont pas stockées séquentiellement. <br><br><h4>  Tentative 5: SELECT, FROM, WHERE id = </h4><br>  Les échecs nous rendent plus forts.  Vous ne devez jamais abandonner, vous devez aller jusqu'au bout et croire en vous et en vos capacités.  Par conséquent, j'ai décidé d'essayer une autre option: il suffit de visualiser toutes les entrées de la base de données une par une.  Connaissant la structure de ma table (voir ci-dessus), nous avons un champ id unique (clé primaire).  Dans le tableau, nous avons 1 628 991 lignes et <i>id</i> passe dans l'ordre, ce qui signifie que nous pouvons simplement les parcourir une par une: <br><br><pre> <code class="plaintext hljs">for ((i=1; i&lt;1628991; i=$((i+1)) )); do psql -U my_user -d my_database -c "SELECT * FROM ws_log_smevlog where id=$i" &gt;/dev/null || echo $i; done</code> </pre> <br>  Si quelqu'un ne comprend pas, la commande fonctionne comme suit: elle analyse la table ligne par ligne et envoie stdout à <i>/ dev / null</i> , mais si la commande SELECT échoue, le texte d'erreur s'affiche (stderr est envoyé à la console) et une ligne contenant l'erreur est sortie (grâce à ||, qui signifie que select a eu des problèmes (le code retour de la commande n'est pas 0)). <br><br>  J'ai eu de la chance, j'ai fait créer des index sur le champ <i>id</i> : <br><br><img src="https://habrastorage.org/webt/k2/yf/tp/k2yftpsxvdq0rtcq_vvrscn0xoq.png"><br><br>  Cela signifie que la recherche de la ligne avec l'ID souhaité ne devrait pas prendre beaucoup de temps.  En théorie, cela devrait fonctionner.  Eh bien, exécutez la commande dans <i>tmux</i> et allez dormir. <br><br>  Le matin, j'ai constaté qu'environ 90 000 enregistrements ont été consultés, ce qui représente un peu plus de 5%.  Excellent résultat par rapport à la méthode précédente (2%)!  Mais je ne voulais pas attendre 20 jours ... <br><br><h4>  Tentative 6: SELECT, FROM, WHERE id&gt; = et id &lt; </h4><br>  Un excellent serveur a été attribué au client dans la base de données: <i>Intel Xeon E5-2697 v2</i> à double processeur, dans notre emplacement il y avait jusqu'à 48 threads!  La charge du serveur était moyenne, nous pouvions prendre environ 20 threads sans aucun problème.  La RAM était également suffisante: jusqu'à 384 gigaoctets! <br><br>  Par conséquent, la commande devait être parallélisée: <br><br><pre> <code class="plaintext hljs">for ((i=1; i&lt;1628991; i=$((i+1)) )); do psql -U my_user -d my_database -c "SELECT * FROM ws_log_smevlog where id=$i" &gt;/dev/null || echo $i; done</code> </pre> <br>  Ici, il était possible d'écrire un script beau et élégant, mais j'ai choisi le moyen le plus rapide de paralléliser: décomposer manuellement la plage 0-1628991 en intervalles de 100 000 enregistrements et exécuter 16 commandes du formulaire séparément: <br><br><pre> <code class="plaintext hljs">for ((i=N; i&lt;M; i=$((i+1)) )); do psql -U my_user -d my_database -c "SELECT * FROM ws_log_smevlog where id=$i" &gt;/dev/null || echo $i; done</code> </pre> <br>  Mais ce n’est pas tout.  En théorie, la connexion à une base de données prend également du temps et des ressources système.  Connecter 1 628 991 n'était pas très raisonnable, d'accord.  Par conséquent, extrayons 1000 lignes dans une connexion au lieu d'une.  En conséquence, l'équipe s'est transformée en ceci: <br><br><pre> <code class="plaintext hljs">for ((i=N; i&lt;M; i=$((i+1000)) )); do psql -U my_user -d my_database -c "SELECT * FROM ws_log_smevlog where id&gt;=$i and id&lt;$((i+1000))" &gt;/dev/null || echo $i; done</code> </pre> <br>  Ouvrez 16 fenêtres dans la session tmux et exécutez les commandes: <br><blockquote><pre> <code class="plaintext hljs">1) for ((i=0; i&lt;100000; i=$((i+1000)) )); do psql -U my_user -d my_database -c "SELECT * FROM ws_log_smevlog where id&gt;=$i and id&lt;$((i+1000))" &gt;/dev/null || echo $i; done 2) for ((i=100000; i&lt;200000; i=$((i+1000)) )); do psql -U my_user -d my_database -c "SELECT * FROM ws_log_smevlog where id&gt;=$i and id&lt;$((i+1000))" &gt;/dev/null || echo $i; done … 15) for ((i=1400000; i&lt;1500000; i=$((i+1000)) )); do psql -U my_user -d my_database -c "SELECT * FROM ws_log_smevlog where id&gt;=$i and id&lt;$((i+1000))" &gt;/dev/null || echo $i; done 16) for ((i=1500000; i&lt;1628991; i=$((i+1000)) )); do psql -U my_user -d my_database -c "SELECT * FROM ws_log_smevlog where id&gt;=$i and id&lt;$((i+1000))" &gt;/dev/null || echo $i; done</code> </pre> </blockquote>  Un jour plus tard, j'ai obtenu les premiers résultats!  A savoir (les valeurs XXX et ZZZ n'ont pas été conservées): <br><br><pre> <code class="plaintext hljs">ERROR: missing chunk number 0 for toast value 37837571 in pg_toast_106070 829000 ERROR: missing chunk number 0 for toast value XXX in pg_toast_106070 829000 ERROR: missing chunk number 0 for toast value ZZZ in pg_toast_106070 146000</code> </pre> <br>  Cela signifie que nous avons trois lignes contenant une erreur.  L'ID des premier et deuxième enregistrements de problème se situait entre 829 000 et 830 000, l'ID du troisième se situait entre 146 000 et 147 000. Ensuite, nous devions simplement trouver la valeur d'ID exacte des enregistrements de problème.  Pour ce faire, parcourez notre gamme avec les enregistrements de problèmes à l'étape 1 et identifiez l'id: <br><blockquote><pre> <code class="plaintext hljs">for ((i=829000; i&lt;830000; i=$((i+1)) )); do psql -U my_user -d my_database -c "SELECT * FROM ws_log_smevlog where id=$i" &gt;/dev/null || echo $i; done 829417 ERROR: unexpected chunk number 2 (expected 0) for toast value 37837843 in pg_toast_106070 829449 for ((i=146000; i&lt;147000; i=$((i+1)) )); do psql -U my_user -d my_database -c "SELECT * FROM ws_log_smevlog where id=$i" &gt;/dev/null || echo $i; done 829417 ERROR: unexpected chunk number ZZZ (expected 0) for toast value XXX in pg_toast_106070 146911</code> </pre> </blockquote><h4>  Fin heureuse </h4><br>  Nous avons trouvé les lignes problématiques.  Nous allons dans la base de données via psql et essayons de les supprimer: <br><br><pre> <code class="plaintext hljs">my_database=# delete from ws_log_smevlog where id=829417; DELETE 1 my_database=# delete from ws_log_smevlog where id=829449; DELETE 1 my_database=# delete from ws_log_smevlog where id=146911; DELETE 1</code> </pre> <br>  À ma grande surprise, les entrées ont été supprimées sans aucun problème, même sans l'option <i>zero_damaged_pages</i> . <br><br>  Ensuite, je me suis connecté à la base de données, j'ai créé <i>VACUUM FULL</i> (je pense que ce n'était pas nécessaire) et j'ai finalement réussi à supprimer la sauvegarde à l'aide de <i>pg_dump</i> .  La décharge a joué sans aucune erreur!  Le problème a été résolu d'une manière si stupide.  Il n'y avait pas de limite à la joie, après tant d'échecs, nous avons réussi à trouver une solution! <br><br><h4>  Remerciements et conclusions </h4><br>  C'est ma première expérience dans la restauration d'une vraie base de données Postgres.  Je me souviendrai longtemps de cette expérience. <br><br>  Et enfin, je voudrais remercier PostgresPro pour la documentation traduite en russe et pour les <a href="https://postgrespro.ru/education/courses/DBA1">cours en ligne entièrement gratuits</a> qui ont beaucoup aidé lors de l'analyse du problème. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr477248/">https://habr.com/ru/post/fr477248/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr477234/index.html">La souris qui a mis fin aux frères de fil</a></li>
<li><a href="../fr477236/index.html">Un tribunal américain autorise les États à rétablir la neutralité du Net</a></li>
<li><a href="../fr477238/index.html">Plus à Karma: pourquoi le débordement de pile est critiqué et pourquoi beaucoup se plaignent de la toxicité communautaire</a></li>
<li><a href="../fr477242/index.html">Comment nous avons choisi ServiceDesk. 3e partie</a></li>
<li><a href="../fr477244/index.html">RayTracing compréhensible en 256 lignes de C ++ nu</a></li>
<li><a href="../fr477250/index.html">Vous souhaitez donc exécuter Windows 10 sur une calculatrice? Ok</a></li>
<li><a href="../fr477252/index.html">Comment les incubateurs et les accélérateurs d'entreprises se sont développés: du laboratoire de Thomas Edison au combinateur Y</a></li>
<li><a href="../fr477254/index.html">Authentification XSS, CSRF et Flash. Résolution de problèmes avec r0ot-mi Web - Client. 2e partie</a></li>
<li><a href="../fr477256/index.html">Le premier lancement à part entière de OneWeb sur le lanceur Soyouz est reporté l'année prochaine, ainsi que le lancement du lanceur Angara</a></li>
<li><a href="../fr477262/index.html">Androïdes de la société Promobot. Vue latérale</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
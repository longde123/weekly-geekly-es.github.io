<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úåüèº üßôüèº üë©üèæ‚Äçü§ù‚Äçüë®üèø D√©ploiement d'applications sur VM, Nomad et Kubernetes üë®üèæ‚Äçüç≥ üßîüèø üíß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour √† tous! Je m'appelle Pavel Agaletsky. Je travaille en tant que chef d'√©quipe dans une √©quipe qui d√©veloppe un syst√®me de livraison Lamoda. En ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>D√©ploiement d'applications sur VM, Nomad et Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lamoda/blog/451644/">  Bonjour √† tous!  Je m'appelle Pavel Agaletsky.  Je travaille en tant que chef d'√©quipe dans une √©quipe qui d√©veloppe un syst√®me de livraison Lamoda.  En 2018, j'ai pris la parole lors de la conf√©rence HighLoad ++, et aujourd'hui je veux pr√©senter une transcription de mon rapport. <br><br>  Mon sujet est d√©di√© √† l'exp√©rience de notre entreprise dans le d√©ploiement de syst√®mes et services dans diff√©rents environnements.  √Ä partir de notre √©poque pr√©historique, lorsque nous avons d√©ploy√© tous les syst√®mes sur des serveurs virtuels r√©guliers, pour finir par une transition progressive de Nomad vers un d√©ploiement vers Kubernetes.  Je vais vous dire pourquoi nous avons fait cela et quels probl√®mes nous avons rencontr√©s dans le processus. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/oqrb7dWECSo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br><h1>  D√©ployer des applications sur VM </h1><br>  Pour commencer, il y a 3 ans, tous les syst√®mes et services de l'entreprise √©taient d√©ploy√©s sur des serveurs virtuels ordinaires.  Techniquement, il a √©t√© organis√© de mani√®re √† ce que tout le code de nos syst√®mes soit d√©pos√© et assembl√© √† l'aide d'outils de construction automatique utilisant jenkins.  Avec Ansible, il d√©ployait notre syst√®me de contr√¥le de version sur des serveurs virtuels.  De plus, chaque syst√®me qui √©tait dans notre entreprise a √©t√© d√©ploy√© au moins sur 2 serveurs: l'un d'eux √©tait en t√™te, le second en queue.  Ces deux syst√®mes √©taient absolument identiques l'un √† l'autre dans tous leurs param√®tres, alimentation, configuration, etc.  La seule diff√©rence entre eux est que head a re√ßu du trafic utilisateur, tandis que tail n'a jamais re√ßu de trafic utilisateur. <br><br>  Pourquoi cela at-il √©t√© fait? <br><br>  Lorsque nous avons d√©ploy√© de nouvelles versions de notre application, nous voulions offrir la possibilit√© d'un d√©ploiement transparent, c'est-√†-dire sans cons√©quences notables pour les utilisateurs.  Cela a √©t√© r√©alis√© en raison du fait que la prochaine version assembl√©e utilisant Ansible a √©t√© d√©ploy√©e sur la queue.  L√†-bas, les personnes impliqu√©es dans le d√©ploiement pouvaient v√©rifier et s'assurer que tout allait bien: toutes les mesures, sections et applications fonctionnaient;  les scripts n√©cessaires sont lanc√©s.  Ce n'est qu'apr√®s avoir √©t√© convaincu que tout allait bien que le trafic a √©t√© invers√©.  Il a commenc√© √† aller vers le serveur qui √©tait la queue avant.  Et celui qui √©tait la t√™te avant, a √©t√© laiss√© sans trafic utilisateur, alors qu'avec la version pr√©c√©dente de notre application. <br><br>  Ainsi, pour les utilisateurs, c'√©tait transparent.  Parce que la commutation est simultan√©e, car il s'agit simplement d'une commutation d'√©quilibrage.  Il est tr√®s facile de revenir √† la version pr√©c√©dente en r√©tablissant simplement l'√©quilibreur.  Nous pouvions √©galement voir la capacit√© de production de l‚Äôapplication avant m√™me que le trafic des utilisateurs ne s‚Äôy rende, ce qui √©tait assez pratique. <br><br>  Quels avantages avons-nous vu dans tout cela? <br><br><ol><li>  Tout d'abord, cela <b>fonctionne</b> tout <b>simplement.</b>  Tout le monde comprend le fonctionnement de ce sch√©ma de d√©ploiement, car la plupart des gens ont d√©j√† d√©ploy√© sur des serveurs virtuels ordinaires. </li><li> C'est assez <b>fiable</b> , car la technologie de d√©ploiement est simple, test√©e par des milliers d'entreprises.  Des millions de serveurs sont d√©ploy√©s de cette fa√ßon.  Il est difficile de casser quelque chose. </li><li>  Et enfin, nous pourrions obtenir <b>des d√©ploiements atomiques</b> .  D√©ploiements qui se produisent simultan√©ment pour les utilisateurs, sans √©tape notable de basculement entre l'ancienne version et la nouvelle. </li></ol><br>  Mais en cela, nous avons √©galement constat√© plusieurs lacunes: <br><br><ol><li>  Outre l'environnement de production, l'environnement de d√©veloppement, il existe d'autres environnements.  Par exemple, qa et pr√©production.  A cette √©poque, nous disposions de nombreux serveurs et d'une soixantaine de services.  Pour cette raison, il √©tait n√©cessaire <b>que chaque service maintienne la version de la</b> machine virtuelle <b>qui lui √©tait pertinente</b> .  De plus, si vous souhaitez mettre √† jour des biblioth√®ques ou installer de nouvelles d√©pendances, vous devez le faire dans tous les environnements.  Il √©tait √©galement n√©cessaire de synchroniser l'heure √† laquelle vous alliez d√©ployer la prochaine nouvelle version de votre application avec l'heure √† laquelle devops a effectu√© les r√©glages d'environnement n√©cessaires.  Dans ce cas, il est facile de se retrouver dans une situation o√π notre environnement sera l√©g√®rement diff√©rent √† la fois dans tous les environnements cons√©cutifs.  Par exemple, dans l'environnement QA, il y aura certaines versions de biblioth√®ques, et en production - d'autres, ce qui entra√Ænera des probl√®mes. </li><li>  <b>Difficult√© √† mettre √† jour les d√©pendances de</b> votre application.  Cela ne d√©pend pas de vous, mais de l'autre √©quipe.  √Ä savoir, √† partir de la commande devops, qui prend en charge le serveur.  Vous devez d√©finir une t√¢che appropri√©e pour eux et donner une description de ce que vous voulez faire. </li><li>  √Ä cette √©poque, nous voulions √©galement diviser les grands grands monolithes que nous avions en petits services s√©par√©s, car nous comprenions qu'il y en aurait de plus en plus.  √Ä l'√©poque, nous en avions d√©j√† plus de 100. Il √©tait n√©cessaire pour chaque nouveau service de cr√©er une nouvelle machine virtuelle distincte, qui doit √©galement √™tre entretenue et d√©ploy√©e.  De plus, vous n'avez pas besoin d'une voiture, mais d'au moins deux.  √Ä cela, l'environnement QA est toujours en train d'√™tre ajout√©.  Cela pose des probl√®mes et rend la cr√©ation et le lancement de nouveaux syst√®mes plus <b>difficiles, co√ªteux et longs pour vous.</b> </li></ol><br>  Par cons√©quent, nous avons d√©cid√© qu'il serait plus pratique de passer du d√©ploiement de machines virtuelles ordinaires au d√©ploiement de nos applications dans le conteneur Docker.  Si vous avez un docker, vous avez besoin d'un syst√®me capable d'ex√©cuter l'application dans le cluster, car vous ne pouvez pas simplement soulever le conteneur.  Habituellement, vous souhaitez garder une trace du nombre de conteneurs lev√©s afin qu'ils montent automatiquement.  Pour cette raison, nous avons d√ª choisir un syst√®me de contr√¥le. <br><br>  Nous avons longuement r√©fl√©chi √† celui qui pouvait √™tre pris.  Le fait est qu'√† cette √©poque, cette pile de d√©ploiements sur des serveurs virtuels ordinaires √©tait quelque peu d√©pass√©e, car il n'y avait pas les derni√®res versions des syst√®mes d'exploitation.  √Ä un moment donn√©, m√™me FreeBSD √©tait l√†, ce qui n'√©tait pas tr√®s pratique √† maintenir.  Nous avons compris que vous devez migrer vers Docker le plus rapidement possible.  Nos d√©veloppeurs ont examin√© leur exp√©rience existante avec diff√©rentes solutions et ont choisi un syst√®me comme Nomad. <br><br><h1>  Passer √† Nomad </h1><br>  Nomad est un produit HashiCorp.  Ils sont √©galement connus pour leurs autres d√©cisions: <br><br><img src="https://habrastorage.org/webt/4e/vz/4e/4evz4entvdaauztnu558tb-2z9u.jpeg" alt="image"><br><br>  <b>Consul</b> est un outil de d√©couverte de services. <br><br>  <b>Terraform</b> est un syst√®me de gestion de serveur qui vous permet de les configurer via une configuration appel√©e infrastructure en tant que code. <br><br>  <b>Vagrant</b> vous permet de d√©ployer des machines virtuelles localement ou dans le cloud via des fichiers de configuration sp√©cifiques. <br><br>  Nomad √† cette √©poque semblait une solution assez simple √† laquelle vous pouvez rapidement passer sans changer l'infrastructure enti√®re.  De plus, il est assez facilement ma√Ætris√©.  Par cons√©quent, nous l'avons choisi comme syst√®me de filtrage pour notre conteneur. <br><br>  Que faut-il pour d√©ployer compl√®tement votre syst√®me sur Nomad? <br><br><ol><li>  Tout d'abord, vous avez besoin de l' <b>image docker de</b> votre application.  Vous devez le cr√©er et le mettre dans le stockage d'images Docker.  Dans notre cas, c'est artificiel - un tel syst√®me qui vous permet d'y ins√©rer divers artefacts de diff√©rents types.  Il peut stocker des archives, des images de docker, des packages de compositeur PHP, des packages NPM, etc. </li><li>  Vous avez √©galement besoin d'un <b>fichier de configuration</b> qui indique √† Nomad quoi, o√π et combien vous souhaitez d√©ployer. </li></ol><br>  Lorsque nous parlons de Nomad, il utilise le langage HCL comme format de fichier d'informations, qui signifie <i>HashiCorp Configuration Language</i> .  Il s'agit d'un sur-ensemble de Yaml qui vous permet de d√©crire votre service en termes de nomade. <br><br><img src="https://habrastorage.org/webt/vg/q9/vb/vgq9vb_izh4i890ro7giihibz6g.jpeg" alt="image"><br><br>  Il vous permet de dire combien de conteneurs vous souhaitez d√©ployer, √† partir de quelles images les transf√©rer divers param√®tres lors du d√©ploiement.  Ainsi, vous alimentez ce fichier Nomad, et il lance des conteneurs en production conform√©ment √† celui-ci. <br><br>  Dans notre cas, nous avons r√©alis√© que le simple fait d'√©crire exactement les m√™mes fichiers HLC identiques pour chaque service ne serait pas tr√®s pratique, car il existe de nombreux services et parfois vous souhaitez les mettre √† jour.  Il arrive qu'un service soit d√©ploy√© non pas dans un cas, mais dans les plus diff√©rents.  Par exemple, l'un des syst√®mes que nous avons en production compte plus de 100 instances dans la production.  Ils sont lanc√©s √† partir des m√™mes images, mais diff√®rent dans les param√®tres de configuration et les fichiers de configuration. <br><br>  Par cons√©quent, nous avons d√©cid√© qu'il serait pratique pour nous de stocker tous nos fichiers de configuration pour le d√©ploiement dans un r√©f√©rentiel commun.  Ainsi, ils sont devenus observables: ils √©taient faciles √† entretenir et il √©tait possible de voir quels syst√®mes nous avions.  Si n√©cessaire, il est √©galement facile de mettre √† jour ou de modifier quelque chose.  L'ajout d'un nouveau syst√®me n'est pas non plus difficile - entrez simplement le fichier de configuration dans le nouveau r√©pertoire.  √Ä l'int√©rieur, il y a les fichiers: service.hcl, qui contient une description de notre service, et quelques fichiers env qui permettent √† ce service, d√©ploy√© en production, de configurer. <br><br><img src="https://habrastorage.org/webt/-g/l7/8h/-gl78hl7nbmdbhbuacuntgxw4ow.jpeg" alt="image"><br><br>  Cependant, certains de nos syst√®mes sont d√©ploy√©s dans le prod non pas en un seul exemplaire, mais en plusieurs √† la fois.  Par cons√©quent, nous avons d√©cid√© qu'il serait pratique pour nous de ne pas stocker les configurations sous leur forme pure, mais sous forme de mod√®le.  Et comme langue de mod√®le, nous avons choisi <i>jinja 2</i> .  Dans ce format, nous stockons √† la fois les configurations du service lui-m√™me et les fichiers env n√©cessaires. <br><br>  De plus, nous avons plac√© dans le r√©f√©rentiel un script commun de d√©ploiement pour tous les projets, qui vous permet de lancer et d√©ployer votre service en production, dans l'environnement souhait√©, dans la cible souhait√©e.  Dans le cas o√π nous avons transform√© notre configuration HCL en mod√®le, le fichier HCL, qui √©tait auparavant une configuration Nomad normale, a dans ce cas commenc√© √† avoir un aspect l√©g√®rement diff√©rent. <br><br><img src="https://habrastorage.org/webt/9a/ib/zv/9aibzvsme34ra2eg53bjfbqt1tw.jpeg" alt="image"><br><br>  Autrement dit, nous avons remplac√© certaines variables dans le fichier de configuration par des insertions de variables, qui sont extraites de fichiers env ou d'autres sources.  De plus, nous avons pu collecter des fichiers HL de mani√®re dynamique, c'est-√†-dire que nous pouvons utiliser non seulement les insertions de variables habituelles.  √âtant donn√© que jinja prend en charge les boucles et les conditions, vous pouvez √©galement y cr√©er des fichiers de configuration, qui varient en fonction de l'emplacement exact o√π vous d√©ployez vos applications. <br><br>  Par exemple, vous souhaitez d√©ployer votre service en pr√©-production et en production.  Supposons qu'en pr√©-production, vous ne souhaitiez pas ex√©cuter les scripts de couronne, vous souhaitiez simplement voir le service sur un domaine distinct pour vous assurer qu'il fonctionne.  Pour toute personne d√©ployant un service, le processus semble tr√®s simple et transparent.  Il suffit d'ex√©cuter le fichier deploy.sh, de sp√©cifier le service que vous souhaitez d√©ployer et dans quelle cible.  Par exemple, vous souhaitez d√©ployer un certain syst√®me en Russie, en Bi√©lorussie ou au Kazakhstan.  Pour ce faire, modifiez simplement l'un des param√®tres et vous obtiendrez le fichier de configuration correct. <br><br>  Lorsque le service Nomad est d√©j√† d√©ploy√© dans votre cluster, il ressemble √† ceci. <br><br><img src="https://habrastorage.org/webt/nu/au/8d/nuau8dqdcwft0boyw57x37wrkcm.jpeg" alt="image"><br><br>  Vous avez d'abord besoin d'un √©quilibreur ext√©rieur qui prendra tout le trafic utilisateur en lui-m√™me.  Il travaillera avec le consul et d√©couvrira aupr√®s de lui o√π, sur quel n≈ìud, √† quelle adresse IP, il existe un service sp√©cifique qui correspond √† un nom de domaine particulier.  Les services au Consul proviennent de Nomad lui-m√™me.  Comme ce sont des produits de la m√™me entreprise, ils sont bien connect√©s.  Nous pouvons dire que Nomad pr√™t √† l'emploi peut enregistrer tous les services qui y sont lanc√©s au sein du Consul. <br><br>  Une fois que votre √©quilibreur externe a d√©couvert le service auquel envoyer le trafic, il le redirige vers le conteneur appropri√© ou vers plusieurs conteneurs correspondant √† votre application.  Naturellement, il faut aussi penser √† la s√©curit√©.  M√™me si tous les services s'ex√©cutent sur les m√™mes machines virtuelles dans des conteneurs, cela n√©cessite g√©n√©ralement l'interdiction de l'acc√®s gratuit de tout service √† tout autre.  Nous y sommes parvenus gr√¢ce √† la segmentation.  Chaque service a √©t√© lanc√© dans son propre r√©seau virtuel, sur lequel des r√®gles de routage et des r√®gles pour autoriser / refuser l'acc√®s √† d'autres syst√®mes et services ont √©t√© prescrites.  Ils pourraient √™tre situ√©s √† l'int√©rieur et √† l'ext√©rieur de ce cluster.  Par exemple, si vous souhaitez emp√™cher un service de se connecter √† une base de donn√©es sp√©cifique, cela peut √™tre fait par segmentation au niveau du r√©seau.  Autrement dit, m√™me par erreur, vous ne pouvez pas vous connecter accidentellement d'un environnement de test √† votre base de production. <br><br>  Combien nous a co√ªt√© la transition en termes de ressources humaines? <br><br>  La transition de l'ensemble de l'entreprise vers Nomad a pris environ 5-6 mois.  Nous avons chang√© de service, mais √† un rythme assez rapide.  Chaque √©quipe a d√ª cr√©er ses propres conteneurs de services. <br><br>  Nous avons adopt√© une telle approche que chaque √©quipe est responsable des images docker de leurs syst√®mes de mani√®re ind√©pendante.  Les devops fournissent √©galement l'infrastructure g√©n√©rale n√©cessaire au d√©ploiement, c'est-√†-dire la prise en charge du cluster lui-m√™me, la prise en charge du syst√®me CI, etc.  Et √† cette √©poque, plus de 60 syst√®mes avaient √©t√© d√©plac√©s vers Nomad, il s'est av√©r√© qu'environ 2 000 conteneurs. <br><br>  Devops est responsable de l'infrastructure globale de tout ce qui est li√© au d√©ploiement, aux serveurs.  Et chaque √©quipe de d√©veloppement, √† son tour, est responsable de la mise en ≈ìuvre des conteneurs pour son syst√®me sp√©cifique, car c'est l'√©quipe qui sait ce dont elle a g√©n√©ralement besoin dans un conteneur particulier. <br><br><h1>  Raisons d'abandonner Nomad </h1><br>  Quels avantages avons-nous obtenus en passant au d√©ploiement √† l'aide de Nomad et de Docker √©galement? <br><br><ol><li>  Nous avons <b>fourni les m√™mes conditions</b> pour tous les environnements.  Dans une entreprise de d√©veloppement, QA-environnement, pr√©-production, production, les m√™mes images conteneurs sont utilis√©es, avec les m√™mes d√©pendances.  Par cons√©quent, vous n'avez pratiquement aucune chance que la production se r√©v√®le diff√©rente de ce que vous avez pr√©c√©demment test√© localement ou sur un environnement de test. </li><li>  Nous avons √©galement constat√© qu'il est assez <b>facile d'ajouter un nouveau service</b> .  Du point de vue du d√©ploiement, tout nouveau syst√®me est lanc√© tr√®s simplement.  Il suffit d'aller dans le r√©f√©rentiel qui stocke les configurations, d'y ajouter la configuration suivante pour votre syst√®me et vous √™tes pr√™t.  Vous pouvez d√©ployer votre syst√®me en production sans effort suppl√©mentaire de devops. </li><li>  Tous <b>les fichiers de configuration</b> dans un r√©f√©rentiel commun <b>se sont av√©r√©s √™tre surveill√©s</b> .  √Ä ce moment, lorsque nous avons d√©ploy√© nos syst√®mes √† l'aide de serveurs virtuels, nous avons utilis√© Ansible, dans lequel les configurations se trouvaient dans le m√™me r√©f√©rentiel.  Cependant, pour la plupart des d√©veloppeurs, il √©tait un peu plus difficile de travailler avec.  Ici, le volume de configurations et de code que vous devez ajouter pour d√©ployer le service est devenu beaucoup plus petit.  De plus, pour les devops, il est tr√®s facile de le r√©parer ou de le changer.  Dans le cas de transitions, par exemple, sur la nouvelle version de Nomad, ils peuvent prendre et mettre √† jour massivement tous les fichiers d'exploitation se trouvant au m√™me endroit. </li></ol><br>  Mais nous avons √©galement fait face √† plusieurs lacunes: <br><br>  Il s'est av√©r√© que nous <b>ne pouvions pas r√©aliser des d√©ploiements homog√®nes</b> dans le cas de Nomad.  En d√©pla√ßant des conteneurs dans des conditions diff√©rentes, il pouvait s'av√©rer qu'il fonctionnait et Nomad le percevait comme un conteneur pr√™t √† accepter le trafic.  Cela s'est produit avant m√™me que l'application √† l'int√©rieur ne parvienne √† d√©marrer.  Pour cette raison, le syst√®me a commenc√© pendant une courte p√©riode √† produire 500 erreurs, car le trafic a commenc√© √† aller vers le conteneur, qui n'est pas encore pr√™t √† le recevoir. <br><br>  Nous avons rencontr√© quelques <b>bugs</b> .  Le bogue le plus important est que Nomad n'accepte pas tr√®s bien un grand cluster si vous avez de nombreux syst√®mes et conteneurs.  Lorsque vous souhaitez mettre en service l'un des serveurs inclus dans le cluster Nomad, il y a une forte probabilit√© que le cluster ne se sente pas tr√®s bien et se d√©sagr√®ge.  Une partie des conteneurs peut par exemple tomber et ne pas monter - cela vous co√ªtera par la suite tr√®s cher si tous vos syst√®mes de production sont situ√©s dans un cluster g√©r√© par Nomad. <br><br>  Par cons√©quent, nous avons d√©cid√© de r√©fl√©chir √† la prochaine √©tape.  √Ä cette √©poque, nous sommes devenus beaucoup plus conscients de ce que nous voulons r√©aliser.  √Ä savoir: nous voulons de la fiabilit√©, un peu plus de fonctions que Nomad et un syst√®me plus mature et plus stable. <br><br>  √Ä cet √©gard, notre choix s'est port√© sur Kubernetes comme plate-forme la plus populaire pour le lancement de clusters.  Surtout √† condition que la taille et la quantit√© de nos conteneurs soient assez importantes.  √Ä ces fins, Kubernetes semblait le syst√®me le plus appropri√© de ceux que nous pouvions voir. <br><br><h1>  Aller √† Kubernetes </h1><br>  Je vais parler un peu des concepts de base de Kubernetes et en quoi ils diff√®rent de Nomad. <br><br><img src="https://habrastorage.org/webt/pv/eh/va/pvehvavusoxszoxum9bsuwyjqbc.jpeg" alt="image"><br><br>  Tout d'abord, le concept le plus √©l√©mentaire de Kubernetes est le concept de pod.  <b>Un pod</b> est un groupe d'un ou plusieurs conteneurs qui fonctionnent toujours ensemble.  Et ils semblent toujours fonctionner strictement sur la m√™me machine virtuelle.  Ils sont disponibles entre eux via IP 127.0.0.1 sur diff√©rents ports. <br><br>  Supposons que vous ayez une application PHP compos√©e de nginx et php-fpm - un circuit classique.  Tr√®s probablement, vous voulez que les conteneurs nginx et php-fpm soient toujours ensemble.  Kubernetes le fait en les d√©crivant comme une seule gousse commune.  C'est exactement ce que nous n'avons pas pu obtenir avec l'aide de Nomad. <br><br>  Le deuxi√®me concept est le <b>d√©ploiement</b> .  Le fait est que la cosse elle-m√™me est une chose √©ph√©m√®re, elle d√©marre et dispara√Æt.  Que vous souhaitiez d'abord supprimer tous vos conteneurs pr√©c√©dents, puis lancer de nouvelles versions en m√™me temps, ou que vous souhaitiez les d√©ployer progressivement - c'est le concept m√™me dont le d√©ploiement est responsable.  Il d√©crit comment vous d√©ployez vos pods, en combien et comment les mettre √† jour. <br><br>  Le troisi√®me concept est le <b>service</b> .  Votre service est en fait votre syst√®me, qui re√ßoit du trafic, puis le dirige vers un ou plusieurs pods correspondant √† votre service.  Autrement dit, cela vous permet de dire que tout le trafic entrant vers un tel service avec un tel nom doit √™tre envoy√© √† ces pods particuliers.  Et en m√™me temps, il vous offre un √©quilibrage du trafic.  Autrement dit, vous pouvez ex√©cuter deux modules de votre application, et tout le trafic entrant sera √©quilibr√© de mani√®re √©gale entre les modules li√©s √† ce service. <br><br>  Et le quatri√®me concept de base est <b>Ingress</b> .  Il s'agit d'un service qui s'ex√©cute dans un cluster Kubernetes.  Il agit comme un √©quilibreur de charge externe, qui prend en charge toutes les demandes.  En raison de l'API, Kubernetes Ingress peut d√©terminer o√π ces demandes doivent √™tre envoy√©es.  Et il le fait de mani√®re tr√®s flexible.  Vous pouvez dire que toutes les demandes adress√©es √† cet h√¥te et √† cette URL sont envoy√©es √† ce service.  Et nous envoyons ces demandes venant √† cet h√¥te et √† une autre URL vers un autre service. <br><br>  La chose la plus cool du point de vue de celui qui d√©veloppe l'application est que vous √™tes capable de tout g√©rer vous-m√™me.  Apr√®s avoir d√©fini la configuration Ingress, vous pouvez envoyer tout le trafic provenant d'une telle API vers des conteneurs distincts enregistr√©s, par exemple, vers Go.  Mais ce trafic venant du m√™me domaine, mais vers une URL diff√©rente, devrait √™tre envoy√© vers des conteneurs √©crits en PHP, o√π il y a beaucoup de logique, mais ils ne sont pas tr√®s rapides. <br><br>  Si nous comparons tous ces concepts avec Nomad, alors nous pouvons dire que les trois premiers concepts sont tous ensemble Service.  Et le dernier concept de Nomad lui-m√™me manque.  Nous avons utilis√© un √©quilibreur externe comme √ßa: il peut √™tre haproxy, nginx, nginx + et ainsi de suite.  Dans le cas d'un cube, vous n'avez pas besoin d'introduire ce concept suppl√©mentaire s√©par√©ment.  Cependant, si vous regardez Ingress √† l'int√©rieur, c'est soit nginx, soit haproxy, soit traefik, mais comme s'il √©tait int√©gr√© √† Kubernetes. <br><br>  Tous les concepts que j'ai d√©crits sont essentiellement les ressources qui existent au sein du cluster Kubernetes.  Pour les d√©crire dans le cube, le format yaml est utilis√©, plus lisible et familier que les fichiers HCl dans le cas de Nomad.  Mais structurellement, ils d√©crivent dans le cas, par exemple, de la m√™me chose.  Ils disent - je veux d√©ployer tel ou tel pod ici et l√†, avec telle ou telle image, en telle ou telle quantit√©. <br><br><img src="https://habrastorage.org/webt/2k/ka/53/2kka53a1vp1lm0rnl4xbhmcpyu4.jpeg" alt="image"><br><br>  De plus, nous avons r√©alis√© que nous ne voulions pas cr√©er chaque ressource individuelle de nos propres mains: d√©ploiement, services, Ingress, etc.  Au lieu de cela, nous voulions d√©crire chaque syst√®me d√©ploy√© en termes de Kubernetes pendant le d√©ploiement afin de ne pas avoir √† recr√©er manuellement toutes les d√©pendances de ressources n√©cessaires dans le bon ordre.  Helm a √©t√© choisi comme syst√®me qui nous a permis de le faire. <br><br><h1>  Concepts cl√©s √† la barre </h1><br>  Helm est un <b>gestionnaire</b> de packages pour Kubernetes.  Il est tr√®s similaire √† la fa√ßon dont les gestionnaires de packages fonctionnent dans les langages de programmation.  Ils vous permettent de stocker un service compos√©, par exemple, de d√©ploiement nginx, de d√©ploiement php-fpm, d'une configuration pour Ingress, de configmaps (il s'agit d'une entit√© qui vous permet de d√©finir env et d'autres param√®tres pour votre syst√®me) sous la forme de soi-disant graphiques.  En m√™me temps, Helm <b>court au-dessus de Kubernetes</b> .  Autrement dit, ce n'est pas une sorte de syst√®me qui se d√©marque, mais juste un autre service qui s'ex√©cute √† l'int√©rieur du cube.  Vous interagissez avec lui via son API via une commande de console.  Sa commodit√© et son charme sont que m√™me si la barre se casse ou que vous la supprimez du cluster, vos services ne dispara√Ætront pas, car la barre ne sert essentiellement qu'√† d√©marrer le syst√®me.  Kubernetes lui-m√™me est responsable de la disponibilit√© et de l'√©tat des services. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons √©galement r√©alis√© que la </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">standardisation</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , qui auparavant devait √™tre effectu√©e de mani√®re ind√©pendante par l'introduction de jinja dans nos configurations, est l'une des principales caract√©ristiques de Helm. Toutes les configurations que vous cr√©ez pour vos syst√®mes sont stock√©es dans helm sous la forme de mod√®les similaires un peu comme jinja, mais, en fait, en utilisant le mod√®le de langage Go dans lequel helm est √©crit, comme Kubernetes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Helm nous ajoute quelques concepts suppl√©mentaires. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le graphique</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> est une description de votre service. D'autres gestionnaires de packages l'appelleraient package, bundle ou quelque chose comme √ßa. C'est ce qu'on appelle le graphique ici. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les valeurs</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sont les variables que vous souhaitez utiliser pour cr√©er vos configurations √† partir de mod√®les. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rel√¢chez</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Chaque fois qu'un service d√©ploy√© √† l'aide de helm re√ßoit une version incr√©mentielle de la version. Helm se souvient de la configuration du service dans la pr√©c√©dente, l'ann√©e pr√©c√©dant la derni√®re version, etc. Par cons√©quent, si vous devez annuler, ex√©cutez simplement la commande de rappel de barre, en lui indiquant la version pr√©c√©dente de la version. M√™me si au moment de la restauration, la configuration correspondante dans votre r√©f√©rentiel n'est pas disponible, helm se souvient toujours de ce qu'elle √©tait et restaure votre syst√®me dans l'√©tat o√π il √©tait dans la version pr√©c√©dente. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans le cas o√π nous utilisons helm, les configurations habituelles pour Kubernetes se transforment √©galement en mod√®les, dans lesquels il est possible d'utiliser des variables, des fonctions, d'appliquer des op√©rateurs conditionnels. Ainsi, vous pouvez collecter la configuration de votre service en fonction de l'environnement.</font></font><br><br><img src="https://habrastorage.org/webt/dc/lr/fh/dclrfhbdr29ms0gouz_pvd8xz44.jpeg" alt="image"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans la pratique, nous avons d√©cid√© de faire un peu diff√©remment que dans le cas de Nomad. Si, dans Nomad dans le m√™me r√©f√©rentiel, les deux configurations pour le d√©ploiement et les n-variables n√©cessaires au d√©ploiement de notre service √©taient stock√©es, nous avons d√©cid√© de les diviser en deux r√©f√©rentiels distincts. Seules les n-variables n√©cessaires au d√©ploiement sont stock√©es dans le r√©f√©rentiel de d√©ploiement et les configurations ou les graphiques sont stock√©s dans le r√©f√©rentiel de barre. </font></font><br><br><img src="https://habrastorage.org/webt/2r/lo/yt/2rloytnvlrj6nri8vj7e9-hccg8.jpeg" alt="image"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Qu'est-ce que cela nous a apport√©?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Malgr√© le fait que nous ne stockons aucune donn√©e vraiment sensible dans les fichiers de configuration eux-m√™mes. Par exemple, les mots de passe de base de donn√©es. Ils sont stock√©s en tant que secrets dans Kubernetes, mais n√©anmoins, il y a encore des choses que nous ne voulons pas donner √† tout le monde de suite. Par cons√©quent, l'acc√®s au r√©f√©rentiel de d√©ploiement est plus limit√© et le r√©f√©rentiel de barre contient simplement une description du service. Pour cette raison, il est possible de donner acc√®s √† un plus grand cercle de personnes en toute s√©curit√©. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√âtant donn√© que nous avons non seulement la production, mais aussi d'autres environnements, gr√¢ce √† cette s√©paration, nous pouvons r√©utiliser nos cartes de barre pour d√©ployer des services non seulement en production, mais aussi, par exemple, en environnement QA. M√™me les d√©ployer localement √† l'aide de </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Minikube</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> est une telle chose pour ex√©cuter Kubernetes localement.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Ä l'int√©rieur de chaque r√©f√©rentiel, nous avons laiss√© une s√©paration dans des r√©pertoires s√©par√©s pour chaque service. Autrement dit, √† l'int√©rieur de chaque r√©pertoire, il y a des mod√®les li√©s au graphique correspondant et d√©crivant les ressources qui doivent √™tre d√©ploy√©es pour lancer notre syst√®me. Dans le r√©f√©rentiel de d√©ploiement, nous n'avons laiss√© que des enves. Dans ce cas, nous n'avons pas utilis√© de mod√®les avec jinja, car la barre elle-m√™me donne des mod√®les hors de la bo√Æte - c'est l'une de ses principales fonctions.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons laiss√© le script de d√©ploiement, deploy.sh, qui simplifie et standardise le lancement pour le d√©ploiement √† l'aide de helm. </font><font style="vertical-align: inherit;">Ainsi, pour quiconque souhaite se d√©ployer, l'interface de d√©ploiement est exactement la m√™me que dans le cas du d√©ploiement via Nomad. </font><font style="vertical-align: inherit;">Le m√™me deploy.sh, le nom de votre service et l'endroit o√π vous souhaitez le d√©ployer. </font><font style="vertical-align: inherit;">Cela fait d√©marrer la barre √† l'int√©rieur. </font><font style="vertical-align: inherit;">Il, √† son tour, recueille les configurations √† partir de mod√®les, y substitue les fichiers de valeurs n√©cessaires, puis les d√©ploie, les mettant dans Kubernetes.</font></font><br><br><h1>  Conclusions </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Le service Kubernetes semble plus complexe que Nomad. </font></font><br><br><img src="https://habrastorage.org/webt/fe/p6/qi/fep6qibp6hhnbsmqifk2jnmg20a.jpeg" alt="image"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C'est l√† que le trafic sortant arrive √† Ingress. Il s'agit simplement du contr√¥leur frontal, qui re√ßoit toutes les demandes et les envoie ensuite aux services correspondant aux donn√©es de demande. Il les d√©finit sur la base de configurations, qui font partie de la description de votre application dans Helm et que les d√©veloppeurs d√©finissent ind√©pendamment. Le service envoie des demandes √† ses pods, c'est-√†-dire des conteneurs sp√©cifiques, en √©quilibrant le trafic entrant entre tous les conteneurs qui appartiennent √† ce service. Eh bien, bien s√ªr, n'oubliez pas que nous ne devons aller nulle part de la s√©curit√© au niveau du r√©seau. Par cons√©quent, le cluster Kubernetes op√®re la segmentation, qui est bas√©e sur le balisage. Tous les services ont certaines balises auxquelles les droits d'acc√®s des services √† certaines ressources externes / internes sont attach√©s √† l'int√©rieur ou √† l'ext√©rieur du cluster.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Ä la fin de la transition, nous avons vu que Kubernetes poss√®de toutes les fonctionnalit√©s de Nomad, que nous avons utilis√©es auparavant, et ajoute √©galement beaucoup de nouvelles choses. Il peut √™tre d√©velopp√© via des plugins, et en fait via des types de ressources personnalis√©s. Autrement dit, vous avez la possibilit√© non seulement d'utiliser quelque chose qui va dans Kubernetes hors de la bo√Æte, mais de cr√©er votre propre ressource et service qui lira votre ressource. Cela fournit des options suppl√©mentaires pour √©tendre votre syst√®me sans avoir √† r√©installer Kubernetes et sans avoir besoin de modifications.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Prometheus en est un exemple, qui s'ex√©cute √† l'int√©rieur de notre cluster Kubernetes. Pour qu'il puisse commencer √† collecter des m√©triques d'un service particulier, nous devons ajouter un type de ressource suppl√©mentaire, le soi-disant moniteur de service, √† la description du service. Prometheus, du fait qu'il peut lire, lanc√© dans Kubernetes, un type de ressources personnalis√©, commence automatiquement √† collecter des m√©triques √† partir du nouveau syst√®me. C'est assez pratique.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le premier d√©ploiement que nous avons fait √† Kubernetes a eu lieu en mars 2018. </font><font style="vertical-align: inherit;">Et pendant ce temps, nous n'avons jamais rencontr√© de probl√®me avec lui. </font><font style="vertical-align: inherit;">Il fonctionne de mani√®re suffisamment stable sans bugs importants. </font><font style="vertical-align: inherit;">De plus, nous pouvons l'√©tendre davantage. </font><font style="vertical-align: inherit;">Aujourd'hui, nous en avons suffisamment des opportunit√©s et nous aimons vraiment le rythme de d√©veloppement de Kubernetes. </font><font style="vertical-align: inherit;">Actuellement, plus de 3 000 conteneurs sont situ√©s √† Kubernetes. </font><font style="vertical-align: inherit;">Le cluster prend plusieurs n≈ìuds. </font><font style="vertical-align: inherit;">En m√™me temps, il est entretenu, stable et tr√®s contr√¥l√©.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr451644/">https://habr.com/ru/post/fr451644/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr451634/index.html">Comment nous sommes analys√©s dans les magasins et les restaurants</a></li>
<li><a href="../fr451636/index.html">Cinq ans d'esclavage</a></li>
<li><a href="../fr451638/index.html">Animation dans les applications mobiles: tester Lottie</a></li>
<li><a href="../fr451640/index.html">Game of Thrones: Construire des infographies sur les meurtres, le sexe, voyager Westeros et plus</a></li>
<li><a href="../fr451642/index.html">Trouver un moyen parmi les obstacles ronds</a></li>
<li><a href="../fr451646/index.html">La production de la coque du vaisseau spatial de la F√©d√©ration a commenc√©</a></li>
<li><a href="../fr451648/index.html">Comment avons-nous cherch√© un tourisme inhabituel en Russie et quel genre d'aventures se produisent g√©n√©ralement</a></li>
<li><a href="../fr451650/index.html">Partie I. Demandez √† votre m√®re: comment communiquer avec les clients et confirmer l'exactitude de leur id√©e d'entreprise, si tout le monde est l√†?</a></li>
<li><a href="../fr451652/index.html">Partie II Demandez √† votre m√®re: comment communiquer avec les clients et confirmer l'exactitude de leur id√©e d'entreprise, si tout le monde est l√†?</a></li>
<li><a href="../fr451654/index.html">Nouvel employ√© - mort ou vivant</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ© ğŸ‘©ğŸ¿â€ğŸ¤â€ğŸ‘¨ğŸ¾ ğŸ–Œï¸ Le livre Kafka Streams en action. Applications et microservices en temps rÃ©el Â» ğŸ¤¶ğŸ¿ ğŸ’†ğŸ¾ ğŸ¥‘</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Salut, habrozhiteli! Ce livre convient Ã  tout dÃ©veloppeur qui souhaite comprendre le traitement en streaming. Comprendre la programmation distribuÃ©e v...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le livre Kafka Streams en action. Applications et microservices en temps rÃ©el Â»</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/457756/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/na/mw/fb/namwfbeornc4ba8jkaodlvjlm68.jpeg" align="left" alt="image"></a>  Salut, habrozhiteli!  Ce livre convient Ã  tout dÃ©veloppeur qui souhaite comprendre le traitement en streaming.  Comprendre la programmation distribuÃ©e vous aidera Ã  mieux comprendre Kafka et Kafka Streams.  Ce serait bien de connaÃ®tre le framework Kafka lui-mÃªme, mais ce n'est pas nÃ©cessaire: je vais vous dire tout ce dont vous avez besoin.  GrÃ¢ce Ã  ce livre, les dÃ©veloppeurs Kafka expÃ©rimentÃ©s, comme les novices, apprendront Ã  crÃ©er des applications de streaming intÃ©ressantes Ã  l'aide de la bibliothÃ¨que Kafka Streams.  Les dÃ©veloppeurs Java intermÃ©diaires et de haut niveau familiarisÃ©s avec des concepts tels que la sÃ©rialisation apprendront Ã  appliquer leurs compÃ©tences pour crÃ©er des applications Kafka Streams.  Le code source du livre est Ã©crit en Java 8 et utilise essentiellement la syntaxe des expressions lambda de Java 8, donc la possibilitÃ© de travailler avec des fonctions lambda (mÃªme dans un autre langage de programmation) vous est utile. <br><a name="habracut"></a><br><h3>  Extrait.  5.3.  OpÃ©rations d'agrÃ©gation et de fenÃªtres </h3><br>  Dans cette section, nous passons aux parties les plus prometteuses de Kafka Streams.  Jusqu'Ã  prÃ©sent, nous avons couvert les aspects suivants des flux Kafka: <br><br><ul><li>  crÃ©er une topologie de traitement; </li><li>  utilisation de l'Ã©tat dans les applications de streaming; </li><li>  Ã©tablir des connexions de flux de donnÃ©es; </li><li>  diffÃ©rences entre les flux d'Ã©vÃ©nements (KStream) et les flux de mise Ã  jour (KTable). </li></ul><br>  Dans les exemples suivants, nous allons rassembler tous ces Ã©lÃ©ments.  De plus, vous serez initiÃ© aux opÃ©rations sur les fenÃªtres - une autre grande fonctionnalitÃ© des applications de streaming.  Notre premier exemple sera l'agrÃ©gation simple. <br><br>
<h3>  5.3.1.  AgrÃ©gation des ventes d'actions par industrie </h3><br>  L'agrÃ©gation et le regroupement sont des outils essentiels pour travailler avec des donnÃ©es en streaming.  L'examen des dossiers individuels sur une base d'admission n'est souvent pas suffisant.  Pour extraire des informations supplÃ©mentaires des donnÃ©es, leur regroupement et leur combinaison sont nÃ©cessaires. <br><br>  Dans cet exemple, vous devez essayer la combinaison d'un trader intrajournalier qui doit suivre le volume des ventes d'actions de sociÃ©tÃ©s dans plusieurs secteurs.  En particulier, vous vous intÃ©ressez aux cinq sociÃ©tÃ©s qui rÃ©alisent les plus grandes parts de ventes dans chaque industrie. <br><br>  Pour une telle agrÃ©gation, vous aurez besoin de plusieurs des Ã©tapes suivantes pour traduire les donnÃ©es sous la forme souhaitÃ©e (en termes gÃ©nÃ©raux). <br><br><ol><li>  CrÃ©ez une source thÃ©matique qui publie des informations brutes sur les transactions boursiÃ¨res.  Nous devrons mapper un objet de type StockTransaction Ã  un objet de type ShareVolume.  Le fait est que l'objet StockTransaction contient des mÃ©tadonnÃ©es de vente, et nous n'avons besoin que de donnÃ©es sur le nombre d'actions vendues. </li><li>  Groupez les donnÃ©es de volume de partage par symboles boursiers.  AprÃ¨s avoir regroupÃ© par symboles, vous pouvez rÃ©duire ces donnÃ©es en sous-totaux des ventes d'actions.  Il convient de noter que la mÃ©thode KStream.groupBy renvoie une instance de type KGroupedStream.  Et vous pouvez obtenir une instance de KTable en appelant la mÃ©thode KGroupedStream.reduce plus tard. </li></ol><br><blockquote>  <b>Qu'est-ce que l'interface KGroupedStream</b> <br><br>  Les mÃ©thodes KStream.groupBy et KStream.groupByKey renvoient une instance de KGroupedStream.  KGroupedStream est une reprÃ©sentation intermÃ©diaire du flux d'Ã©vÃ©nements aprÃ¨s regroupement par clÃ©.  Il n'est pas du tout destinÃ© Ã  fonctionner directement avec lui.  Au lieu de cela, KGroupedStream est utilisÃ© pour les opÃ©rations d'agrÃ©gation, dont le rÃ©sultat est toujours KTable.  Et comme le rÃ©sultat des opÃ©rations d'agrÃ©gation est KTable et qu'elles utilisent le stockage d'Ã©tat, il est possible que toutes les mises Ã  jour en consÃ©quence ne soient pas envoyÃ©es plus loin dans le pipeline. <br><br>  La mÃ©thode KTable.groupBy renvoie un KGroupedTable similaire - une reprÃ©sentation intermÃ©diaire du flux de mises Ã  jour regroupÃ©es par clÃ©. </blockquote><br>  Prenons une courte pause et regardons la fig.  5.9, qui montre ce que nous avons accompli.  Cette topologie devrait dÃ©jÃ  vous Ãªtre familiÃ¨re. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9v/p3/ne/9vp3ne2cqpquhvlkmjo6wncqwsm.png" alt="image"></div><br>  Voyons maintenant le code de cette topologie (il se trouve dans le fichier src / main / java / bbejeck / chapter_5 / AggregationsAndReducingExample.java) (Listing 5.2). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/8w/cz/lz/8wczlzab4gf5y7sjluyyu2f1vdi.png" alt="image"></div><br>  Le code donnÃ© diffÃ¨re par sa briÃ¨vetÃ© et un grand volume d'actions effectuÃ©es sur plusieurs lignes.  Dans le premier paramÃ¨tre de la mÃ©thode builder.stream, vous pouvez remarquer quelque chose de nouveau par vous-mÃªme: la valeur du type Ã©numÃ©rÃ© AutoOffsetReset.EARLIEST (il existe Ã©galement LATEST), dÃ©finie Ã  l'aide de la mÃ©thode Consumed.withOffsetResetPolicy.  En utilisant ce type Ã©numÃ©rÃ©, vous pouvez spÃ©cifier une stratÃ©gie de rÃ©initialisation des dÃ©calages pour chacun de KStream ou KTable; il a prioritÃ© sur le paramÃ¨tre de rÃ©initialisation des dÃ©calages de la configuration. <br><br><blockquote>  <b>GroupByKey et GroupBy</b> <br><br>  L'interface KStream propose deux mÃ©thodes de regroupement des enregistrements: GroupByKey et GroupBy.  Les deux renvoient KGroupedTable, vous pourriez donc avoir une question lÃ©gitime: quelle est la diffÃ©rence entre eux et quand utiliser lequel? <br><br>  La mÃ©thode GroupByKey est utilisÃ©e lorsque les clÃ©s de KStream sont dÃ©jÃ  non vides.  Et surtout, l'indicateur Â«nÃ©cessite une nouvelle partitionÂ» n'a jamais Ã©tÃ© dÃ©fini. <br><br>  La mÃ©thode GroupBy suppose que vous avez modifiÃ© les clÃ©s de regroupement, donc l'indicateur de re-partitionnement est dÃ©fini sur true.  Effectuer des connexions, des agrÃ©gations, etc. aprÃ¨s la mÃ©thode GroupBy entraÃ®nera un re-partitionnement automatique. <br>  RÃ©sumÃ©: Vous devez utiliser GroupByKey plutÃ´t que GroupBy dans la mesure du possible. </blockquote><br>  Ce que font les mÃ©thodes mapValues â€‹â€‹et groupBy est comprÃ©hensible, alors jetez un Å“il Ã  la mÃ©thode sum () (elle se trouve dans le fichier src / main / java / bbejeck / model / ShareVolume.java) (Listing 5.3). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/va/bb/e5/vabbe54p2ntwmyk1yllak6s4m4q.png" alt="image"></div><br>  La mÃ©thode ShareVolume.sum renvoie le sous-total du volume des ventes d'actions et le rÃ©sultat de toute la chaÃ®ne de calcul est un objet KTable &lt;String, ShareVolume&gt;.  Vous comprenez maintenant quel rÃ´le joue KTable.  Lorsque les objets ShareVolume arrivent, la derniÃ¨re mise Ã  jour actuelle est enregistrÃ©e dans le KTable correspondant.  Il est important de ne pas oublier que toutes les mises Ã  jour sont reflÃ©tÃ©es dans le prÃ©cÃ©dent shareVolumeKTable, mais toutes ne sont pas envoyÃ©es plus loin. <br><br>  De plus, avec l'aide de ce tableau, nous effectuons une agrÃ©gation (par le nombre d'actions vendues) afin d'obtenir les cinq sociÃ©tÃ©s avec les ventes d'actions les plus Ã©levÃ©es dans chaque industrie.  Nos actions dans ce cas seront similaires aux actions lors de la premiÃ¨re agrÃ©gation. <br><br><ol><li>  Effectuez une autre opÃ©ration groupBy pour regrouper des objets ShareVolume individuels par secteur. </li><li>  Passez Ã  rÃ©sumer les objets ShareVolume.  Cette fois, l'objet d'agrÃ©gation est une file d'attente prioritaire de taille fixe.  Seules cinq sociÃ©tÃ©s avec le plus grand nombre d'actions vendues sont conservÃ©es dans une telle file d'attente de taille fixe. </li><li>  Affichez les lignes du paragraphe prÃ©cÃ©dent dans une valeur de chaÃ®ne et retournez les cinq meilleures ventes par le nombre d'actions par industrie. </li><li>  Ã‰crivez les rÃ©sultats sous forme de chaÃ®ne dans la rubrique. </li></ol><br>  Dans la fig.  5.10 montre un graphique de la topologie du mouvement des donnÃ©es.  Comme vous pouvez le voir, le deuxiÃ¨me cycle de traitement est assez simple. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4q/3p/j5/4q3pj5lkggxqnu6lpcmtgo52dqq.png" alt="image"></div><br>  Maintenant, aprÃ¨s avoir bien compris la structure de ce deuxiÃ¨me cycle de traitement, vous pouvez vous rÃ©fÃ©rer Ã  son code source (vous le trouverez dans le fichier src / main / java / bbejeck / chapter_5 / AggregationsAndReducingExample.java) (Listing 5.4). <br><br>  Il existe une variable fixedQueue dans cet initialiseur.  Il s'agit d'un objet personnalisÃ© - un adaptateur pour java.util.TreeSet, qui est utilisÃ© pour suivre les rÃ©sultats les plus Ã©levÃ©s dans l'ordre dÃ©croissant du nombre de parts vendues. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/03/mn/nm/03mnnmhuvjpivozqptxxzpkdrmu.png" alt="image"></div><br>  Vous avez dÃ©jÃ  rencontrÃ© des appels Ã  groupBy et mapValues, nous ne nous arrÃªterons donc pas sur eux (nous appelons la mÃ©thode KTable.toStream, car la mÃ©thode KTable.print est dÃ©conseillÃ©e).  Mais vous n'avez pas encore vu la version KTable de la mÃ©thode d'agrÃ©gat (), nous allons donc passer un peu de temps Ã  en discuter. <br><br>  Comme vous vous en souvenez, KTable se distingue par le fait que les enregistrements avec les mÃªmes clÃ©s sont considÃ©rÃ©s comme des mises Ã  jour.  KTable remplace l'ancien enregistrement par le nouveau.  L'agrÃ©gation se dÃ©roule de la mÃªme maniÃ¨re: les derniers enregistrements avec une clÃ© sont agrÃ©gÃ©s.  Lorsqu'un enregistrement arrive, il est ajoutÃ© Ã  une instance de la classe FixedSizePriorityQueue Ã  l'aide d'un additionneur (le deuxiÃ¨me paramÃ¨tre de l'appel Ã  la mÃ©thode d'agrÃ©gation), mais si un autre enregistrement avec la mÃªme clÃ© existe dÃ©jÃ , l'ancien enregistrement est supprimÃ© Ã  l'aide du soustracteur (le troisiÃ¨me paramÃ¨tre de l'appel Ã  la mÃ©thode d'agrÃ©gation). <br><br>  Cela signifie que notre agrÃ©gateur, FixedSizePriorityQueue, n'agrÃ¨ge pas toutes les valeurs avec une seule clÃ©, mais stocke la somme mobile des quantitÃ©s N des types de stocks les plus vendus.  Chaque entrÃ©e contient le nombre total d'actions vendues jusqu'Ã  prÃ©sent.  KTable vous fournira des informations sur les actions des sociÃ©tÃ©s qui sont actuellement les plus vendues; l'agrÃ©gation continue de chaque mise Ã  jour n'est pas requise. <br><br>  Nous avons appris Ã  faire deux choses importantes: <br><br><ul><li>  regrouper les valeurs dans KTable par une clÃ© qui leur est commune; </li><li>  Effectuez des opÃ©rations utiles telles que la convolution et l'agrÃ©gation sur ces valeurs groupÃ©es. </li></ul><br>  La capacitÃ© d'effectuer ces opÃ©rations est importante pour comprendre la signification des donnÃ©es qui transitent par l'application Kafka Streams et dÃ©terminer quelles informations elles contiennent. <br><br>  Nous avons Ã©galement rassemblÃ© certains des concepts clÃ©s discutÃ©s plus haut dans ce livre.  Au chapitre 4, nous avons parlÃ© de l'importance d'un Ã©tat local Ã  sÃ©curitÃ© intÃ©grÃ©e pour une application de streaming.  Le premier exemple de ce chapitre a montrÃ© pourquoi l'Ã‰tat local est si important - il permet de suivre les informations que vous avez dÃ©jÃ  vues.  L'accÃ¨s local Ã©vite les retards rÃ©seau, rendant l'application plus productive et rÃ©sistante aux erreurs. <br><br>  Lorsque vous effectuez une opÃ©ration de convolution ou d'agrÃ©gation, vous devez spÃ©cifier le nom du magasin d'Ã©tat.  Les opÃ©rations de convolution et d'agrÃ©gation renvoient une instance de KTable, et KTable utilise un magasin d'Ã©tat pour remplacer les anciens rÃ©sultats par de nouveaux.  Comme vous l'avez vu, toutes les mises Ã  jour ne sont pas envoyÃ©es plus loin dans le pipeline, ce qui est important, car les opÃ©rations d'agrÃ©gation sont conÃ§ues pour obtenir les informations finales.  Si l'Ã©tat local n'est pas appliquÃ©, KTable enverra en outre tous les rÃ©sultats d'agrÃ©gation et de convolution. <br><br>  Ensuite, nous examinons l'exÃ©cution d'opÃ©rations telles que l'agrÃ©gation, dans une pÃ©riode de temps spÃ©cifique - les opÃ©rations dites de fenÃªtrage. <br><br><h3>  5.3.2.  OpÃ©rations de fenÃªtre </h3><br>  Dans la section prÃ©cÃ©dente, nous avons introduit la convolution et l'agrÃ©gation Â«roulanteÂ».  L'application a effectuÃ© une convolution continue des ventes d'actions avec l'agrÃ©gation subsÃ©quente des cinq actions les plus vendues. <br><br>  Parfois, une telle agrÃ©gation continue et convolution des rÃ©sultats est nÃ©cessaire.  Et parfois, vous devez effectuer des opÃ©rations uniquement sur une pÃ©riode de temps donnÃ©e.  Par exemple, calculez combien de transactions boursiÃ¨res ont Ã©tÃ© effectuÃ©es avec des actions d'une entreprise particuliÃ¨re au cours des 10 derniÃ¨res minutes.  Ou combien d'utilisateurs ont cliquÃ© sur une nouvelle banniÃ¨re publicitaire au cours des 15 derniÃ¨res minutes.  Une application peut effectuer de telles opÃ©rations plusieurs fois, mais avec des rÃ©sultats liÃ©s uniquement Ã  des intervalles de temps spÃ©cifiÃ©s (fenÃªtres de temps). <br><br><h3>  Comptage des transactions d'Ã©change par acheteur </h3><br>  Dans l'exemple suivant, nous serons engagÃ©s dans le suivi des transactions de change pour plusieurs commerÃ§ants - soit de grandes organisations, soit de simples financiers intelligents. <br><br>  Il y a deux raisons possibles Ã  ce suivi.  L'un d'eux est la nÃ©cessitÃ© de savoir ce que les leaders du marchÃ© achÃ¨tent / vendent.  Si ces grands acteurs et investisseurs avertis voient des opportunitÃ©s par eux-mÃªmes, il est logique de suivre leur stratÃ©gie.  La deuxiÃ¨me raison est le dÃ©sir de remarquer tout signe possible de transactions illÃ©gales utilisant des informations privilÃ©giÃ©es.  Pour ce faire, vous devrez analyser la corrÃ©lation des fortes hausses des ventes avec les communiquÃ©s de presse importants. <br><br>  Un tel suivi comprend des Ã©tapes telles que: <br><br><ul><li>  crÃ©er un flux pour la lecture du sujet des transactions boursiÃ¨res; </li><li>  regroupement des enregistrements entrants par ID client et symbole boursier du stock.  Un appel Ã  la mÃ©thode groupBy renvoie une instance de la classe KGroupedStream; </li><li>  KGroupedStream.windowedBy renvoie un flux de donnÃ©es dÃ©limitÃ© par une fenÃªtre temporaire, qui permet l'agrÃ©gation de fenÃªtres.  Selon le type de fenÃªtre, TimeWindowedKStream ou SessionWindowedKStream est renvoyÃ©; </li><li>  Comptage des transactions pour une opÃ©ration d'agrÃ©gation.  Le flux de donnÃ©es de fenÃªtre dÃ©termine si un enregistrement particulier est pris en compte dans ce calcul; </li><li>  Ã©crire des rÃ©sultats dans une rubrique ou les afficher sur la console pendant le dÃ©veloppement. </li></ul><br>  La topologie de cette application est simple, mais son image visuelle ne fait pas de mal.  Jetez un oeil Ã  la photo.  5.11. <br><br>  De plus, nous considÃ©rerons la fonctionnalitÃ© des opÃ©rations de fenÃªtre et le code correspondant. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1h/bd/fi/1hbdfi2s0x4x4up8kkcomwg_omq.png" alt="image"></div><br><h3>  Types de fenÃªtres </h3><br>  Il existe trois types de fenÃªtres dans Kafka Streams: <br><br><ul><li>  session </li><li>  Tumbling (tumbling); </li><li>  glissement / "saut" (glissement / saut). </li></ul><br>  Le choix dÃ©pend des besoins de l'entreprise.  Les fenÃªtres "Tumbling" et "jumping" sont limitÃ©es dans le temps, tandis que les restrictions de session sont associÃ©es aux actions de l'utilisateur - la durÃ©e de la ou des sessions est dÃ©terminÃ©e uniquement par le comportement actif de l'utilisateur.  L'essentiel est de ne pas oublier que tous les types de fenÃªtres sont basÃ©s sur les horodatages des enregistrements et non sur l'heure systÃ¨me. <br><br>  Ensuite, nous implÃ©mentons notre topologie avec chacun des types de fenÃªtres.  Le code complet ne sera donnÃ© que dans le premier exemple, rien ne changera pour les autres types de fenÃªtres, Ã  l'exception du type d'opÃ©ration de fenÃªtre. <br><br><h3>  FenÃªtres de session </h3><br>  Les fenÃªtres de session sont trÃ¨s diffÃ©rentes de tous les autres types de fenÃªtres.  Ils sont limitÃ©s non pas tant par le temps que par l'activitÃ© de l'utilisateur (ou l'activitÃ© de l'entitÃ© que vous souhaitez suivre).  Les fenÃªtres de session sont dÃ©limitÃ©es par des pÃ©riodes d'inactivitÃ©. <br><br>  La figure 5.12 illustre le concept des fenÃªtres de session.  Une session plus petite fusionnera avec la session Ã  sa gauche.  Et la session de droite sera sÃ©parÃ©e, car elle suit une longue pÃ©riode d'inactivitÃ©.  Les fenÃªtres de session sont basÃ©es sur les actions de l'utilisateur, mais appliquent des horodatages Ã  partir des enregistrements pour dÃ©terminer Ã  quelle session l'enregistrement appartient. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/js/c7/z5/jsc7z525p9wrj_tlmrfa5e3vj_u.png" alt="image"></div><br><br><h3>  Utilisation des fenÃªtres de session pour suivre les transactions Exchange </h3><br>  Nous utiliserons des fenÃªtres de session pour capturer des informations sur les transactions d'Ã©change.  L'implÃ©mentation des fenÃªtres de session est prÃ©sentÃ©e dans le Listing 5.5 (qui se trouve dans src / main / java / bbejeck / chapter_5 / CountingWindowingAndKTableJoinExample.java). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vs/vq/va/vsvqvaqddc3hgy-77fpniuwcbxm.png" alt="image"></div><br>  Vous avez dÃ©jÃ  rencontrÃ© la plupart des opÃ©rations de cette topologie, il n'est donc pas nÃ©cessaire de les considÃ©rer ici Ã  nouveau.  Mais il y a plusieurs nouveaux Ã©lÃ©ments que nous allons discuter maintenant. <br><br>  Pour toute opÃ©ration groupBy, une sorte d'opÃ©ration d'agrÃ©gation (agrÃ©gation, convolution ou comptage) est gÃ©nÃ©ralement effectuÃ©e.  Vous pouvez effectuer une agrÃ©gation cumulative avec un total cumulÃ© ou une agrÃ©gation de fenÃªtres, dans laquelle les enregistrements sont pris en compte dans une fenÃªtre de temps donnÃ©e. <br><br>  Le code du Listing 5.5 compte le nombre de transactions dans les fenÃªtres de session.  Dans la fig.  5.13 ces actions sont analysÃ©es Ã©tape par Ã©tape. <br><br>  En appelant windowedBy (SessionWindows. With (vingt secondes). Jusqu'Ã  (quinze minutes)), nous crÃ©ons une fenÃªtre de session avec un intervalle d'inactivitÃ© de 20 secondes et un intervalle de rÃ©tention de 15 minutes.  Un intervalle d'inactivitÃ© de 20 secondes signifie que l'application inclura tout enregistrement qui arrive dans les 20 secondes suivant la fin ou le dÃ©but de la session en cours dans la session en cours (active). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jh/mk/qv/jhmkqvxrrnrd5mxavzltcu-uglq.png" alt="image"></div><br>  Ensuite, nous indiquons quelle opÃ©ration d'agrÃ©gation effectuer dans la fenÃªtre de session - dans ce cas, comptez.  Si l'enregistrement entrant tombe en dehors de l'intervalle d'inactivitÃ© (de chaque cÃ´tÃ© du cachet de date / heure), l'application crÃ©e une nouvelle session.  Un intervalle de sauvegarde signifie le maintien d'une session pendant un certain temps et permet des donnÃ©es en retard qui vont au-delÃ  de la pÃ©riode d'inactivitÃ© de la session mais peuvent toujours Ãªtre attachÃ©es.  De plus, le dÃ©but et la fin d'une nouvelle session rÃ©sultant de la fusion correspondent Ã  l'horodatage le plus ancien et le plus rÃ©cent. <br><br>  Examinons quelques entrÃ©es de la mÃ©thode count pour voir comment les sessions fonctionnent (tableau 5.1). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/p-/_f/pn/p-_fpnxaicjsj0ivwzrcxthi77g.png" alt="image"></div><br>  Lors de la rÃ©ception des enregistrements, nous recherchons les sessions dÃ©jÃ  existantes avec la mÃªme clÃ©, l'heure de fin est infÃ©rieure Ã  la date / heure actuelle - l'intervalle d'inactivitÃ© et l'heure de dÃ©but sont supÃ©rieures Ã  la date / heure actuelle + intervalle d'inactivitÃ©.  Dans cet esprit, quatre enregistrements de la table.  5.1 fusionner en une seule session comme suit. <br><br>  1. L'enregistrement 1 vient en premier, donc l'heure de dÃ©but est Ã©gale Ã  l'heure de fin et est 00:00:00. <br><br>  2. Vient ensuite l'enregistrement 2, et nous recherchons des sessions qui se terminent au plus tÃ´t Ã  23:59:55 et commencent au plus tard Ã  00:00:35.  Recherchez l'enregistrement 1 et combinez les sessions 1 et 2. Prenez l'heure de dÃ©but de la session 1 (plus tÃ´t) et l'heure de fin de la session 2 (plus tard), de sorte que notre nouvelle session commence Ã  00:00:00 et se termine Ã  00:00:15. <br><br>  3. L'enregistrement 3 arrive, nous recherchons des sessions entre 00:00:30 et 00:01:10 et n'en trouvons aucune.  Ajoutez une deuxiÃ¨me session pour la clÃ© 123-345-654, FFBE, commenÃ§ant et se terminant Ã  00:00:50. <br><br>  4. L'enregistrement 4 arrive et nous recherchons des sessions entre 23:59:45 et 00:00:25.  Cette fois, il y a deux sessions - 1 et 2. Les trois sessions sont combinÃ©es en une seule, avec une heure de dÃ©but de 00:00:00 et une heure de fin de 00:00:15. <br><br>  D'aprÃ¨s ce qui est dit dans cette section, il convient de se rappeler les nuances importantes suivantes: <br><br><ul><li>  Les sessions ne sont pas des fenÃªtres de taille fixe.  La durÃ©e d'une session est dÃ©terminÃ©e par l'activitÃ© dans une pÃ©riode de temps donnÃ©e; </li><li>  Les horodatages dans les donnÃ©es dÃ©terminent si un Ã©vÃ©nement tombe dans une session existante ou dans une pÃ©riode d'inactivitÃ©. </li></ul><br>  Plus loin, nous discuterons du type de fenÃªtres suivant - les fenÃªtres de "saut pÃ©rilleux". <br><br><h3>  FenÃªtres Ã  bascule </h3><br>  Les fenÃªtres Â«tumblingÂ» capturent les Ã©vÃ©nements qui se produisent dans une certaine pÃ©riode de temps.  Imaginez que vous devez capturer toutes les transactions d'Ã©change d'une entreprise toutes les 20 secondes, afin de collecter tous les Ã©vÃ©nements de cette pÃ©riode.  Ã€ la fin de l'intervalle de 20 secondes, la fenÃªtre Â«basculeÂ» et passe Ã  un nouvel intervalle d'observation de 20 secondes.  La figure 5.14 illustre cette situation. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ge/sb/jh/gesbjhkrk4wfpsj94edv21lcgzk.png" alt="image"></div><br>  Comme vous pouvez le voir, tous les Ã©vÃ©nements reÃ§us au cours des 20 derniÃ¨res secondes sont inclus dans la fenÃªtre.  Ã€ la fin de cette pÃ©riode, une nouvelle fenÃªtre est crÃ©Ã©e. <br><br>  Le listing 5.6 montre le code qui illustre l'utilisation de fenÃªtres tumbling pour capturer les transactions d'Ã©change toutes les 20 secondes (vous pouvez le trouver dans src / main / java / bbejeck / chapter_5 / CountingWindowingAndKtableJoinExample.java). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ej/gw/ba/ejgwbaxfd9vzmdok1u6vl7gqjt4.png" alt="image"></div><br>  GrÃ¢ce Ã  cette petite modification de l'appel Ã  la mÃ©thode TimeWindows.of, vous pouvez utiliser la fenÃªtre tumbling.  Dans cet exemple, il n'y a aucun appel Ã  la mÃ©thode until (), Ã  la suite de quoi l'intervalle de sauvegarde par dÃ©faut de 24 heures sera utilisÃ©. <br><br>  Enfin, il est temps de passer Ã  la derniÃ¨re des options de fenÃªtre - saut de fenÃªtres. <br><br><h3>  FenÃªtres coulissantes ("sautantes") </h3><br>  Les fenÃªtres coulissantes / Â«sautillantesÂ» sont similaires au Â«culbutageÂ», mais avec une lÃ©gÃ¨re diffÃ©rence.  Les fenÃªtres coulissantes n'attendent pas la fin de l'intervalle de temps avant de crÃ©er une nouvelle fenÃªtre pour gÃ©rer les Ã©vÃ©nements rÃ©cents.  Ils commencent de nouveaux calculs aprÃ¨s un intervalle d'attente plus court que la durÃ©e de la fenÃªtre. <br><br>  Pour illustrer les diffÃ©rences entre les fenÃªtres Â«saut pÃ©rilleuxÂ» et Â«sautantÂ», revenons Ã  l'exemple du calcul des opÃ©rations de change.  Notre objectif, comme prÃ©cÃ©demment, est de compter le nombre de transactions, mais nous ne voudrions pas attendre tout le temps avant de mettre Ã  jour le compteur.  Au lieu de cela, nous mettrons Ã  jour le compteur Ã  des intervalles plus courts.  Par exemple, nous continuerons Ã  compter le nombre de transactions toutes les 20 secondes, mais Ã  mettre Ã  jour le compteur toutes les 5 secondes, comme le montre la Fig.  5.15.  Dans le mÃªme temps, nous avons trois fenÃªtres de rÃ©sultats avec des donnÃ©es qui se chevauchent. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/f_/rz/km/f_rzkmhyoxehblurxwysauk3j2k.png" alt="image"></div><br>  Le listing 5.7 montre le code pour spÃ©cifier les fenÃªtres coulissantes (il peut Ãªtre trouvÃ© dans src / main / java / bbejeck / chapter_5 / CountingWindowingAndKtableJoinExample.java). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/oa/xr/hn/oaxrhnrcxi78qoylbaatcegq__q.png" alt="image"></div><br> Â«Â»     Â«Â»      advanceBy().       15 . <br><br>     ,      .  ,  ,         : <br><br><ul><li>       ,   ; </li><li> Â«Â»          ; </li><li>   Â«Â»  ,            . </li></ul><br>   ,   KTable   KStream  . <br><br><h3> 5.3.3.   KStream  KTable </h3><br>   4      KStream.      KTable  KStream.       . KStream â€”  ,  KTable â€”   ,                KTable. <br><br>                .    ,        . <br><br><ol><li>   KTable        KStream      ,   ,    . </li><li>   KTable,       .   KTable     . </li><li>            . </li></ol><br>  ,     . <br><br><h3>  KTable  KStream </h3><br>   KTable  KStream   . <br><br><ol><li>   KTable.toStream(). </li><li>     KStream.map     ,      Windowed  TransactionSummary. </li></ol><br>        (     src/main/java/bbejeck/chapter_5/CountingWindowingAndKtableJoinExample.java) ( 5.8). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jx/_b/9f/jx_b9frqyde6wj2yvo5nk3palwq.png" alt="image"></div><br>     KStream.map,       KStream       . <br><br>    ,      KTable    . <br><br><h3>  KTable    </h3><br>  ,    KTable     (      src/main/java/bbejeck/chapter_5/CountingWindowingAndKtableJoinExample.java) ( 5.9). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vb/g5/2w/vbg52wycfxm6ojk2jgpkochuvii.png" alt="image"></div><br>  ,    Serde   ,      Serde.     EARLIEST      . <br><br>        â€” . <br><br><h3>         </h3><br>     .      ,         (      src/main/java/bbejeck/chapter_5/CountingWindowingAndKtableJoinExample.java) ( 5.10). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nk/8r/zw/nk8rzwzgk7qtaxv0uq3p_sjaipm.png" alt="image"></div><br>   leftJoin  .       4,  JoinWindow  ,     KStream-KTable     KTable    .      :     KTable,  .  :    KTable   KStream    . <br><br>           KStream. <br><br><h3> 5.3.4.  GlobalKTable </h3><br>   ,          .   4      KStream,     â€”  KStream  KTable.                 .      ,   Kafka Streams   .   ,          ,     (    4,   Â«  Â»  4.2.4). <br><br><h3>      </h3><br>     â€”       ,       ;            .  ,               ,           . <br><br><h3>       </h3><br>      ,    ,  ,             .     Kafka Streams   GlobalKTable. <br><br>  GlobalKTable ,         .         ,         ,      .    GlobalKTable     .          . <br><br><h3>   KStream   GlobalKTable </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans la sous-section 5.3.2, nous avons procÃ©dÃ© Ã  l'agrÃ©gation des fenÃªtres des transactions d'Ã©change par les clients. </font><font style="vertical-align: inherit;">Les rÃ©sultats de cette agrÃ©gation ressemblaient Ã  ceci:</font></font><br><br><pre><code class="plaintext hljs">{customerId='074-09-3705', stockTicker='GUTM'}, 17 {customerId='037-34-5184', stockTicker='CORK'}, 16</code> </pre> <br>  Bien que ces rÃ©sultats soient conformes Ã  l'objectif, il serait plus pratique d'afficher Ã©galement le nom du client et le nom complet de l'entreprise.  Pour ajouter le nom d'un client et le nom d'une entreprise, vous pouvez effectuer des connexions normales, mais vous devrez effectuer deux mappages de clÃ©s et re-partitionner.  Avec GlobalKTable, vous pouvez Ã©viter le coÃ»t de telles opÃ©rations. <br><br>  Pour ce faire, nous allons utiliser l'objet countStream du Listing 5.11 (le code correspondant peut Ãªtre trouvÃ© dans le fichier src / main / java / bbejeck / chapter_5 / GlobalKTableExample.java), en le connectant avec deux objets GlobalKTable. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/et/ds/zj/etdszjjzni9snwmxxbi21xph8e4.png" alt="image"></div><br>  Nous en avons dÃ©jÃ  discutÃ© auparavant, donc je ne le rÃ©pÃ©terai pas.  Mais je note que le code dans la fonction toStream (). Map est abstrait dans l'objet fonction pour des raisons de lisibilitÃ© au lieu de l'expression lambda intÃ©grÃ©e. <br><br>  L'Ã©tape suivante consiste Ã  dÃ©clarer deux instances de GlobalKTable (le code affichÃ© peut Ãªtre trouvÃ© dans src / main / java / bbejeck / chapter_5 / GlobalKTableExample.java) (Listing 5.12). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ut/ca/gd/utcagdf_iab9zjefezaiy2dxt80.png" alt="image"></div><br><br>  Notez que les noms de rubrique sont dÃ©crits Ã  l'aide de types Ã©numÃ©rÃ©s. <br><br>  Maintenant que nous avons prÃ©parÃ© tous les composants, il reste Ã  Ã©crire le code de la connexion (qui se trouve dans le fichier src / main / java / bbejeck / chapter_5 / GlobalKTableExample.java) (Listing 5.13). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/av/yr/oe/avyroeehcpkzq9rzeiqlernoum8.png" alt="image"></div><br>  Bien qu'il existe deux composÃ©s dans ce code, ils sont organisÃ©s en chaÃ®ne, car aucun de leurs rÃ©sultats n'est utilisÃ© sÃ©parÃ©ment.  Les rÃ©sultats sont affichÃ©s Ã  la fin de toute l'opÃ©ration. <br><br>  Lorsque vous dÃ©marrez l'opÃ©ration de connexion ci-dessus, vous obtiendrez les rÃ©sultats suivants: <br><br><pre> <code class="plaintext hljs">{customer='Barney, Smith' company="Exxon", transactions= 17}</code> </pre> <br>  L'essence n'a pas changÃ©, mais ces rÃ©sultats semblent plus clairs. <br><br>  En comptant le chapitre 4, vous avez dÃ©jÃ  vu plusieurs types de connexions en action.  Ils sont rÃ©pertoriÃ©s dans le tableau.  5.2.  Ce tableau reflÃ¨te la connectivitÃ© pertinente Ã  la version 1.0.0 de Kafka Streams;  quelque chose va changer dans les prochaines versions. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_u/ka/gh/_ukaghteoopcpk9i5ljf4cjrwju.png" alt="image"></div><br>  En conclusion, je vous rappelle l'essentiel: vous pouvez connecter des flux d'Ã©vÃ©nements (KStream) et des flux de mise Ã  jour (KTable) en utilisant l'Ã©tat local.  De plus, si la taille des donnÃ©es de rÃ©fÃ©rence n'est pas trop grande, vous pouvez utiliser l'objet GlobalKTable.  GlobalKTable rÃ©plique toutes les sections sur chacun des nÅ“uds de l'application Kafka Streams, garantissant ainsi la disponibilitÃ© de toutes les donnÃ©es quelle que soit la section Ã  laquelle la clÃ© correspond. <br><br>  Ensuite, nous verrons la possibilitÃ© de flux Kafka, grÃ¢ce auxquels vous pouvez observer les changements d'Ã©tat sans consommer les donnÃ©es du sujet Kafka. <br><br><h3>  5.3.5.  Statut de la demande </h3><br>  Nous avons dÃ©jÃ  effectuÃ© plusieurs opÃ©rations impliquant l'Ã©tat et toujours restituer les rÃ©sultats Ã  la console (Ã  des fins de dÃ©veloppement) ou les Ã©crire dans le sujet (pour une opÃ©ration industrielle).  Lorsque vous Ã©crivez des rÃ©sultats dans un sujet, vous devez utiliser le consommateur Kafka pour les afficher. <br><br>  La lecture des donnÃ©es de ces sujets peut Ãªtre considÃ©rÃ©e comme une sorte de vues matÃ©rialisÃ©es.  Pour nos tÃ¢ches, nous pouvons utiliser la dÃ©finition d'une vue matÃ©rialisÃ©e de Wikipedia: Â«... un objet de base de donnÃ©es physique contenant les rÃ©sultats d'une requÃªte.  Par exemple, il peut s'agir d'une copie locale des donnÃ©es supprimÃ©es, ou d'un sous-ensemble des lignes et / ou colonnes d'une table ou des rÃ©sultats de jointure, ou d'un tableau croisÃ© dynamique obtenu Ã  l'aide de l'agrÃ©gation Â»(https://en.wikipedia.org/wiki/Materialized_view). <br><br>  Kafka Streams vous permet Ã©galement d'effectuer des requÃªtes interactives sur les magasins d'Ã©tat, ce qui vous permet de lire directement ces vues matÃ©rialisÃ©es.  Il est important de noter que la demande au magasin d'Ã©tat est de la nature d'une opÃ©ration en lecture seule.  GrÃ¢ce Ã  cela, vous ne pouvez pas avoir peur de rendre accidentellement l'Ã©tat d'une application incohÃ©rente lors du traitement des donnÃ©es. <br><br>  La possibilitÃ© d'interroger directement les magasins d'Ã©tat est importante.  Cela signifie que vous pouvez crÃ©er des applications - des tableaux de bord sans avoir Ã  recevoir au prÃ©alable les donnÃ©es d'un consommateur Kafka.  Il augmente l'efficacitÃ© de l'application, car il n'est pas nÃ©cessaire d'enregistrer Ã  nouveau les donnÃ©es: <br><br><ul><li>  En raison de la localisation des donnÃ©es, vous pouvez y accÃ©der rapidement; </li><li>  La duplication des donnÃ©es est exclue, car elles ne sont pas Ã©crites sur un stockage externe. </li></ul><br>  La chose principale dont je voudrais que vous vous souveniez: vous pouvez exÃ©cuter directement les requÃªtes d'Ã©tat depuis l'application.  Vous ne pouvez pas surestimer les opportunitÃ©s que cela vous offre.  Au lieu de consommer des donnÃ©es de Kafka et de stocker des enregistrements dans la base de donnÃ©es pour l'application, vous pouvez interroger les magasins d'Ã©tat avec le mÃªme rÃ©sultat.  Les demandes directes aux magasins d'Ã©tat signifient moins de code (pas de consommateur) et moins de logiciel (pas besoin d'une table de base de donnÃ©es pour stocker les rÃ©sultats). <br><br>  Nous avons couvert une quantitÃ© considÃ©rable d'informations dans ce chapitre, nous allons donc arrÃªter temporairement notre discussion sur les requÃªtes interactives aux magasins d'Ã‰tat.  Mais ne vous inquiÃ©tez pas: au chapitre 9, nous allons crÃ©er une application simple - un panneau d'informations avec des requÃªtes interactives.  Pour dÃ©montrer les requÃªtes interactives et les possibilitÃ©s de les ajouter aux applications Kafka Streams, il utilisera certains des exemples de ce chapitre et des prÃ©cÃ©dents. <br><br><h3>  RÃ©sumÃ© </h3><br><ul><li>  Les objets KStream reprÃ©sentent des flux d'Ã©vÃ©nements comparables aux insertions de base de donnÃ©es.  Les objets KTable reprÃ©sentent des flux de mise Ã  jour, ils sont plus similaires aux mises Ã  jour de la base de donnÃ©es.  La taille de l'objet KTable n'augmente pas; les anciens enregistrements sont remplacÃ©s par de nouveaux. </li><li>  Les objets KTable sont requis pour les opÃ©rations d'agrÃ©gation. </li><li>  Ã€ l'aide des opÃ©rations de fenÃªtre, vous pouvez diviser les donnÃ©es agrÃ©gÃ©es en paniers de temps. </li><li>  GrÃ¢ce aux objets GlobalKTable, vous pouvez accÃ©der aux donnÃ©es de rÃ©fÃ©rence n'importe oÃ¹ dans l'application, indÃ©pendamment de la section. </li><li>  Les connexions entre les objets KStream, KTable et GlobalKTable sont possibles. </li></ul><br>  Jusqu'Ã  prÃ©sent, nous nous sommes concentrÃ©s sur la crÃ©ation d'applications Kafka Streams Ã  l'aide du DSL de haut niveau KStream.  Bien qu'une approche de haut niveau vous permette de crÃ©er des programmes soignÃ©s et concis, son utilisation est un compromis certain.  Travailler avec DSL KStream signifie augmenter la concision du code en rÃ©duisant le degrÃ© de contrÃ´le.  Dans le chapitre suivant, nous allons examiner l'API de bas niveau des nÅ“uds de gestionnaire et essayer d'autres compromis.  Les programmes deviendront plus longs qu'ils ne l'Ã©taient jusqu'Ã  prÃ©sent, mais nous aurons la possibilitÃ© de crÃ©er presque tous les nÅ“uds de traitement dont nous pourrions avoir besoin. <br><br>  â†’ Plus de dÃ©tails sur le livre peuvent Ãªtre trouvÃ©s sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le site Web de l'Ã©diteur</a> <br><br>  â†’ Pour Khabrozhiteley 25% de rÃ©duction sur le coupon - <b>Kafka Streams</b> <br><br>  â†’ Lors du paiement de la version papier du livre, un livre Ã©lectronique est envoyÃ© par e-mail. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr457756/">https://habr.com/ru/post/fr457756/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr457744/index.html">CrÃ©ation d'un systÃ¨me d'extension sur la bibliothÃ¨que Qt - Partie 2</a></li>
<li><a href="../fr457746/index.html">MÃ©tÃ©orologie et vols</a></li>
<li><a href="../fr457750/index.html">Travailler avec JSON RPC dans Symfony 4</a></li>
<li><a href="../fr457752/index.html">Pas des rovers lunaires et pas des farceurs. Que savons-nous des robots Ã  Fukushima</a></li>
<li><a href="../fr457754/index.html">State et T-killers</a></li>
<li><a href="../fr457758/index.html">Les ingÃ©nieurs sauvent les gens perdus dans la forÃªt, mais la forÃªt ne s'est pas encore rendue</a></li>
<li><a href="../fr457760/index.html">Comment rendre les conteneurs encore plus isolÃ©s: un examen des technologies de bac Ã  sable pour conteneurs</a></li>
<li><a href="../fr457762/index.html">RÃ¨gle CCD: avec quoi il est mangÃ©</a></li>
<li><a href="../fr457764/index.html">10 erreurs de PO jeune (partie II)</a></li>
<li><a href="../fr457766/index.html">Nous gÃ©nÃ©rons des niveaux de tuiles et cachons des carrÃ©s au joueur</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
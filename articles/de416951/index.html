<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üñïüèª üë©üèª‚Äçüöí üë©üèº‚Äçü§ù‚Äçüë®üèæ Kubernetes-Cluster im VPC-Dienst üí≠ üë®üèæ‚Äçü§ù‚Äçüë®üèº üì®</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir haben die M√∂glichkeit hinzugef√ºgt, Kubernetes im Virtual Private Cloud-Dienst im fr√ºhen Beta-Testmodus bequem zu starten. 


 Diese Funktionalit√§t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kubernetes-Cluster im VPC-Dienst</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/416951/"><img src="https://habrastorage.org/webt/bc/b6/cy/bcb6cykv49fwewsnhfr-7ny-0uc.png"><br><p><br>  Wir haben die M√∂glichkeit hinzugef√ºgt, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">Kubernetes</a> im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">Virtual Private Cloud-Dienst</a> im fr√ºhen Beta-Testmodus bequem zu starten. </p><br><p>  Diese Funktionalit√§t ist n√ºtzlich f√ºr Benutzer, die eine bequeme Verwaltung einer gro√üen Anzahl von Anwendungen ben√∂tigen, die als Container ausgef√ºhrt werden.  Kubernetes bietet Tools zur Skalierung, Selbstheilung und zum Lastausgleich f√ºr Container, die in einem Cluster ausgef√ºhrt werden. </p><br><p>  Da der <strong>Virtual Private Cloud-Dienst</strong> auf OpenStack basiert, verwenden wir eine seiner Komponenten - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">OpenStack Magnum</a> .  Sie k√∂nnen damit schnell private Kubernetes-Cluster mit der gew√ºnschten Anzahl von Knoten erstellen. </p><br><p>  Derzeit kann jeder Benutzer unseres Dienstes mehrere unabh√§ngige Cluster in seinem Projekt erstellen.  Als Clusterknoten werden virtuelle Maschinen verwendet, deren Konfiguration ausgew√§hlt und ge√§ndert werden kann. </p><br><p>  In diesem Artikel werden wir uns mit den Hauptobjekten des Kubernetes-Clusters befassen und anhand der Beispiele den Prozess zum Erstellen eines Clusters mit OpenStack Magnum untersuchen. </p><a name="habracut"></a><br><h2>  Erstellen und verwalten Sie einen Kubernetes-Cluster </h2><br><p>  Derzeit ist die Erstellung eines Kubernetes-Clusters nur √ºber Konsolendienstprogramme oder die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">OpenStack-API</a> in den Verf√ºgbarkeitszonen <strong>ru-1a</strong> und <strong>ru-1b</strong> (St. Petersburg) m√∂glich. </p><br><p>  Um loszulegen, ben√∂tigen Sie: </p><br><ul><li>  Erstellen Sie ein neues oder verwenden Sie ein vorhandenes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">VPC-</a> Projekt. </li><li>  Erstellen Sie einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">Benutzer mit einem SSH-Schl√ºssel</a> . </li><li>  F√ºgen Sie dem erstellten Projekt auf der Projektverwaltungsseite einen Benutzer hinzu. </li><li>  Gehen Sie zum Projekt und rufen Sie die Zugriffsdatei auf der Registerkarte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">Zugriff ab</a> . </li><li>  Installieren Sie den <strong>Openstack-</strong> Konsolenclient mit der <strong>Python-Magnumclient-Bibliothek</strong> . </li><li>  Installieren Sie den <strong>kubectl-</strong> Konsolenclient. </li></ul><br><p>  Um den <strong>Openstack-</strong> Konsolen-Client zu installieren, k√∂nnen <strong>Sie</strong> die Anweisungen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">auf dem Link verwenden.</a> <strong>Beachten Sie</strong> jedoch, dass Sie f√ºr diesen Client auch die <strong>Python-Magnumclient-</strong> Bibliothek installieren <strong>m√ºssen</strong> , um die Erstellung von Kubernetes-Clustern zu unterst√ºtzen. </p><br><p>  Der vollst√§ndige Befehlssatz zum Installieren eines Openstack-Clients mit dem erforderlichen Plug-In f√ºr Betriebssysteme der Ubuntu / Debian-Familie: </p><br><pre><code class="bash hljs">$ sudo apt update $ sudo apt -y install curl python-pip python-dev python3-dev git libxml2-dev libxslt1-dev python-openssl python3-openssl python-pyasn1 libffi-dev libssl-dev build-essential $ sudo pip install -UI pbr setuptools pytz $ sudo pip install -UI git+https://github.com/openstack/python-openstackclient $ sudo pip install -UI git+https://github.com/openstack/python-magnumclient</code> </pre> <br><p>  Vollst√§ndiger Befehlssatz f√ºr die Installation des Openstack-Clients mit dem erforderlichen Plug-In f√ºr Betriebssysteme der Fedora / CentOS-Familie: </p><br><pre> <code class="bash hljs">$ sudo yum -y install python-pip gcc libffi-devel python-devel libxslt-devel openssl-devel git libffi-devel $ sudo pip install -UI pbr setuptools pytz $ sudo pip install -UI git+https://github.com/openstack/python-openstackclient $ sudo pip install -UI git+https://github.com/openstack/python-magnumclient</code> </pre> <br><p>  Zum Verwalten von Kubernetes-Objekten ben√∂tigen Sie den <strong>kubectl-</strong> Konsolenclient.  Installationsmethoden f√ºr verschiedene Betriebssysteme sind in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">offiziellen Dokumentation beschrieben</a> . </p><br><p>  Um einen Cluster zu erstellen, m√ºssen Sie vorhandene erstellen oder verwenden: </p><br><ul><li>  Cluster- <strong>Vorlage</strong> ; </li><li>  Eine Reihe von Parametern f√ºr die CPU und den RAM virtueller Maschinen ( <strong>Variante</strong> ). </li></ul><br><p>  Sie k√∂nnen Cluster-Vorlagen erstellen und selbst eine Version erstellen oder √∂ffentliche vorab erstellte Vorlagen verwenden. </p><br><p>  Sie m√ºssen auch die Verf√ºgbarkeitszone, den Festplattentyp f√ºr Ihren Cluster und die Anzahl der Knoten ermitteln.  Es ist zu bedenken, dass wir die M√∂glichkeit, einen Cluster in mehreren Zonen zu erstellen, noch nicht unterst√ºtzen.  Sie k√∂nnen einen beliebigen Netzwerktyp ausw√§hlen (schnell, universell oder einfach). <br>  Weitere Informationen zu Laufwerkstypen finden Sie in unserer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">Wissensdatenbank</a> . </p><br><p>  Die Anzahl der Knoten kann f√ºr <strong>Master-</strong> und <strong>Minion-</strong> Rollen unterschiedlich sein.  Auf den Knoten, die die Hauptrolle ausf√ºhren, werden die Cluster-Steuerelemente gestartet - <strong>Controller-Manager</strong> , <strong>Scheduler</strong> , <strong>API</strong> .  Auf den anderen Knoten werden <strong>Kubelet-</strong> , <strong>Kube-Proxy-</strong> Dienste und alle Anwendungscontainer gestartet.  Weitere Informationen zu den Komponenten, die auf Clusterknoten ausgef√ºhrt werden, finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><p>  Um √ºber SSH auf Knoten zuzugreifen, m√ºssen Sie den zuvor erstellten SSH-Schl√ºssel verwenden.  Die Beispielbefehle verwenden einen Schl√ºssel namens <strong>ssh-test</strong> . </p><br><p>  Wir werden die Vorlage und Variante des √∂ffentlichen Clusters, den schnellen Festplattentyp und die Verf√ºgbarkeitszone <strong>ru-1b verwenden</strong> . <br>  In unserem Cluster werden zun√§chst 2 Masterknoten und 3 Minionknoten gestartet. </p><br><p>  Um diese Parameter zu √ºberpr√ºfen, verwenden wir die openstackclient-Befehle und die heruntergeladene Zugriffsdatei ( <strong>rc.sh</strong> ): </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#          . $ source rc.sh #  ,         $ openstack flavor show BL1.2-4096 -c ram -c vcpus +-------+-------+ | Field | Value | +-------+-------+ | ram | 4096 | | vcpus | 2 | +-------+-------+ #       ru-1b $ openstack volume type show fast.ru-1b -c name +-------+------------+ | Field | Value | +-------+------------+ | name | fast.ru-1b | +-------+------------+ #    Kubernetes $ openstack coe cluster template list -c name +---------------------------------------+ | name | +---------------------------------------+ | kubernetes-nofloatingips-ru-1b-v1.9.3 | | kubernetes-nofloatingips-ru-1b-v1.9.6 | | kubernetes-nofloatingips-ru-1b-v1.9.9 | | kubernetes-floatingips-ru-1b-v1.9.3 | | kubernetes-floatingips-ru-1b-v1.9.6 | | kubernetes-floatingips-ru-1b-v1.9.9 | | kubernetes-nofloatingips-ru-1a-v1.9.3 | | kubernetes-nofloatingips-ru-1a-v1.9.6 | | kubernetes-nofloatingips-ru-1a-v1.9.9 | | kubernetes-floatingips-ru-1a-v1.9.3 | | kubernetes-floatingips-ru-1a-v1.9.6 | | kubernetes-floatingips-ru-1a-v1.9.9 | +---------------------------------------+</span></span></code> </pre> <br><p>  Als Beispiel w√§hlen wir die zweite Cluster-Vorlage aus, aus der nicht √∂ffentlich zug√§ngliche Floating-Adressen f√ºr jeden der Knoten erstellt werden.  Wir werden sie nicht brauchen. </p><br><pre> <code class="plaintext hljs">#   Kubernetes   test-cluster #   keypair   ,   $ openstack coe cluster create \ --cluster-template kubernetes-nofloatingips-ru-1b-v1.9.9 \ --master-count 2 \ --node-count 3 \ --keypair ssh-test \ --master-flavor BL1.2-4096 \ --flavor BL1.2-4096 \ test-cluster</code> </pre> <br><p>  <em>Bitte beachten Sie, dass wir dieselbe Konfiguration f√ºr verschiedene Knoten ausgew√§hlt haben (Master-Flavour- und Flavour-Parameter). Sie k√∂nnen je nach den Anforderungen des Clusters unterschiedliche Konfigurationss√§tze ausw√§hlen.</em>  <em>Ihre √Ñnderung ist nach ihrer Schaffung m√∂glich.</em> </p><br><p>  Beachten Sie auch, dass beim Erstellen eines Clusters mit mehreren Masterknoten automatisch ein Load Balancer erstellt wird, um auf die Kubernetes-API zuzugreifen. </p><br><p>  Nach einigen Minuten wird in Ihrem Projekt ein Kubernetes-Cluster angezeigt.  In der Projektsteuerung sehen Sie neue virtuelle Maschinen, Festplatten und Netzwerkobjekte. </p><br><p>  Sie k√∂nnen den Status Ihres Clusters √ºber openstackclient √ºberpr√ºfen: </p><br><pre> <code class="bash hljs">openstack coe cluster list -c name -c status +--------------+--------------------+ | name | status | +--------------+--------------------+ | <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster | CREATE_IN_PROGRESS | +--------------+--------------------+</code> </pre> <br><p>  Nachdem der Cluster in den Status CREATE_COMPLETE eingetreten ist, k√∂nnen Sie seine Objekte √ºber das Dienstprogramm kubectl verwalten, indem Sie die Konfigurationsdatei mit den folgenden Befehlen herunterladen: </p><br><pre> <code class="bash hljs">$ mkdir -p ~/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster $ openstack coe cluster config <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster --dir ~/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster</code> </pre> <br><p>  Danach k√∂nnen Sie mit dem Dienstprogramm kubectl mit dem Cluster arbeiten: </p><br><pre> <code class="bash hljs">$ <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> KUBECONFIG=~/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster/config $ kubectl get pods --all-namespaces -o=custom-columns=NAME:.metadata.name,STATUS:.status.phase NAME STATUS coredns-785dcf9c58-6gnfp Running heapster-6846cdc674-rm4k6 Running kube-dns-autoscaler-6b94f7bbf8-x5clt Running kubernetes-dashboard-747575c864-wlg6p Running monitoring-grafana-84b4596dd7-zf5rx Running monitoring-influxdb-c8486fc95-bqqb6 Running node-exporter-test-cluster-robvp4cvwpt7-minion-0 Running</code> </pre> <br><p>  Bei Bedarf k√∂nnen Sie die Anzahl der Minion-Knoten im Cluster √ºber openstackclient erh√∂hen oder verringern, indem Sie den neuen Wert f√ºr node_count √ºbergeben: </p><br><pre> <code class="bash hljs">$ openstack coe cluster update <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster replace node_count=4</code> </pre> <br><h2>  Wichtige Kubernetes-Clusterobjekte </h2><br><h3>  Pods </h3><br><p>  Obwohl Kubernetes eine Reihe von Containern verwaltet, ist die zugrunde liegende Entit√§t, die Kubernetes verwaltet, kein Container, sondern ein <strong>Pod</strong> . </p><br><p>  Pod ist eine Reihe von Linux-Kernel-Namespaces und Netzwerkstapel-Einstellungen, mit denen Sie eine Reihe von Containern zu einer einzigen Entit√§t zusammenstellen k√∂nnen. <br>  Meistens wird ein Container mit der Anwendung in einem separaten Pod gestartet. <br>  Bei Bedarf k√∂nnen Sie mehrere Container in einem Pod ausf√ºhren. Dies kann hilfreich sein, wenn Sie √ºber die localhost-Netzwerkschnittstelle Zugriff von einem Container auf einen anderen gew√§hren m√ºssen oder aus einem anderen Grund mehrere Container auf demselben Host ausf√ºhren m√ºssen. <br>  Alle Container, die im selben Pod ausgef√ºhrt werden, haben einen Hostnamen, eine IP-Adresse, eine Routing-Tabelle und Festplatten. </p><br><p>  Beachten Sie, dass beim Skalieren der Anzahl der Instanzen Ihrer Anwendung in Kubernetes die Anzahl der Pods und nicht die Anzahl der Container in einem bestimmten Pod erh√∂ht werden muss. <br>  Weitere Details in der offiziellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">Pods-</a> Dokumentation. </p><br><p>  Erstellen Sie beispielsweise den einfachsten Pod mit Nginx anhand der Beschreibung im Yaml-Format: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-basic.yaml apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80</span></span></code> </pre> <br><p>  Um einen Pod zu erstellen, k√∂nnen wir das Dienstprogramm <strong>kubectl verwenden</strong> . <br>  Wir haben alle im Artikel vorgestellten Beispiele zu unserer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">Github-Gruppe</a> hinzugef√ºgt, sodass Sie keine Dateien auf Ihrem Computer erstellen k√∂nnen, sondern die Datei-URL aus dem √∂ffentlichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">Repository verwenden</a> : </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/pods/nginx-basic.yaml</code> </pre> <br><p>  Nach der Erstellung k√∂nnen wir mit dem Befehl kubectl description vollst√§ndige Informationen zum Status des Pods anfordern: </p><br><pre> <code class="bash hljs">$ kubectl describe pod nginx Name: nginx Namespace: default Node: <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0/10.0.0.5 Start Time: Sun, 17 Jun 2018 12:29:03 +0000 Labels: &lt;none&gt; Annotations: &lt;none&gt; Status: Running IP: 10.100.88.9 Containers: nginx: Container ID: docker://6ca6383b66686c05c61c1f690737110e0f8994eda393f44a7ebfbbf2b2026267 Image: library/nginx:1.14-alpine Image ID: docker-pullable://docker.io/nginx@sha256:944b79ca7dbe456ce72e73e70816c1990e39967c8f010349a388c00b77ec519c Port: 80/TCP Host Port: 0/TCP State: Running Started: Sun, 17 Jun 2018 12:29:16 +0000 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-rp5ls (ro) Conditions: Type Status Initialized True Ready True PodScheduled True Volumes: default-token-rp5ls: Type: Secret (a volume populated by a Secret) SecretName: default-token-rp5ls Optional: <span class="hljs-literal"><span class="hljs-literal">false</span></span> QoS Class: BestEffort Node-Selectors: &lt;none&gt; Tolerations: &lt;none&gt; Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 52s default-scheduler Successfully assigned nginx to <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Normal SuccessfulMountVolume 51s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 MountVolume.SetUp succeeded <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> volume <span class="hljs-string"><span class="hljs-string">"default-token-rp5ls"</span></span> Normal Pulling 50s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 pulling image <span class="hljs-string"><span class="hljs-string">"library/nginx:1.14-alpine"</span></span> Normal Pulled 39s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Successfully pulled image <span class="hljs-string"><span class="hljs-string">"library/nginx:1.14-alpine"</span></span> Normal Created 39s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Created container Normal Started 39s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Started container</code> </pre> <br><p>  Wie Sie sehen k√∂nnen, wurde Pod auf einem Knoten mit dem Namen test-cluster-nd5c5y6lsfxb-minion-0 gestartet und erhielt eine interne IP-Adresse von 10.100.88.9. </p><br><p>  Im Abschnitt "Ereignisse" k√∂nnen Sie die wichtigsten Startereignisse anzeigen. W√§hlen Sie einen Knoten zum Starten aus und laden Sie das Image herunter. </p><br><p>  Wir k√∂nnen in den Pod gelangen und den Status der Prozesse im Container √ºberpr√ºfen: </p><br><pre> <code class="bash hljs">$ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> -it nginx sh ps aux PID USER TIME COMMAND 1 root 0:00 nginx: master process nginx -g daemon off; 7 nginx 0:00 nginx: worker process 20 root 0:00 sh 24 root 0:00 ps aux <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> <br><p>  Es ist zu beachten, dass die IP-Adresse 10.100.88.9 nicht f√ºr andere Anwendungen innerhalb und au√üerhalb des Kubernetes-Clusters verf√ºgbar ist. Der Zugriff auf das laufende Nginx ist nur √ºber den Pod selbst m√∂glich: </p><br><pre> <code class="bash hljs">$ ping -c 1 10.100.88.9 PING 10.100.88.9 (10.100.88.9): 56 data bytes --- 10.100.88.9 ping statistics --- 1 packets transmitted, 0 packets received, 100% packet loss $ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> nginx -- ping -c1 10.100.88.9 PING 10.100.88.9 (10.100.88.9): 56 data bytes 64 bytes from 10.100.88.9: seq=0 ttl=64 time=0.075 ms --- 10.100.88.9 ping statistics --- 1 packets transmitted, 1 packets received, 0% packet loss round-trip min/avg/max = 0.075/0.075/0.075 ms</code> </pre> <br><p>  Neben der Tatsache, dass auf die angegebene IP-Adresse nur vom Container aus zugegriffen werden kann, ist sie auch nicht permanent.  Dies bedeutet, dass dieser Pod bei einer Neuerstellung eine andere IP-Adresse erhalten kann. </p><br><p>  Um diese Probleme zu l√∂sen, k√∂nnen Sie ein Objekt namens Service verwenden. </p><br><h3>  Dienstleistungen </h3><br><p>  Mit dem Dienst k√∂nnen Sie Pods permanente IP-Adressen zuweisen, ihnen Zugriff von externen Netzwerken gew√§hren und Anforderungen zwischen Pods ausgleichen. <br>  Weitere Informationen zum Service finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><p>  Zum Beispiel m√ºssen wir den laufenden Pod entfernen: </p><br><pre> <code class="bash hljs">$ kubectl delete pod nginx</code> </pre> <br><p>  F√ºgen Sie der Beschreibung des Pods ein Etikett (Label) hinzu, das f√ºr den Service erforderlich ist: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-labeled.yaml apiVersion: v1 kind: Pod metadata: name: nginx labels: app: webservice spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80</span></span></code> </pre> <br><p>  Wir ben√∂tigen auch eine Beschreibung des Service: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-nodeport.yaml apiVersion: v1 kind: Service metadata: name: nginx-nodeport labels: app: webservice spec: type: NodePort ports: - port: 80 nodePort: 30001 protocol: TCP selector: app: webservice</span></span></code> </pre> <br><p>  Pod und Service erstellen: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/pods/nginx-labeled.yaml \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/services/nginx-nodeport.yaml</code> </pre> <br><p>  Da der erstellte Dienst vom Typ NodePort ist, wird der von uns auf allen Netzwerkschnittstellen angegebene Port 30001 auf allen Knoten des Clusters ge√∂ffnet. <br>  Dies bedeutet, dass wir, wenn wir einem Knoten eine externe IP-Adresse hinzuf√ºgen, √ºber ein externes Netzwerk mit Nginx auf den laufenden Pod zugreifen k√∂nnen. </p><br><p>  Um die externen Adressen der Clusterknoten nicht f√ºr den Zugriff auf den Service zu verwenden, k√∂nnen Sie anstelle von NodePort den Typ LoadBalancer verwenden. <br>  Wir ben√∂tigen eine neue Beschreibung des Dienstes: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-loadbalancer.yaml apiVersion: v1 kind: Service metadata: name: nginx-loadbalancer labels: app: webservice spec: type: LoadBalancer ports: - port: 80 protocol: TCP selector: app: webservice</span></span></code> </pre> <br><p>  L√∂schen Sie den aktuellen Dienst und wenden Sie die neue Beschreibung an: </p><br><pre> <code class="bash hljs">$ kubectl delete service nginx-service $ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/services/nginx-loadbalancer.yaml</code> </pre> <br><p>  Nach dem Starten des Dienstes ist Nginx auf TCP-Port 80 √ºber ein externes Netzwerk verf√ºgbar, und es ist nicht erforderlich, externe Adressen f√ºr Clusterknoten zuzuweisen und zu verwenden.  Der Dienst vom Typ LoadBalancer weist Ihrem VPC-Projekt automatisch eine neue externe Adresse zu und beginnt mit deren Verwendung. </p><br><p>  Informationen zur hervorgehobenen externen Adresse erhalten Sie mit kubectl: </p><br><pre> <code class="bash hljs">$ kubectl get service nginx-service -o=custom-columns=IP:status.loadBalancer.ingress[0].ip IP xxx.xxx.xxx.xxx</code> </pre> <br><p>  In unseren Beispielen wurde nur ein Pod mit Nginx gestartet.  Um die Anwendung auf mehrere Pods zu skalieren, k√∂nnen wir die Bereitstellung verwenden. </p><br><h3>  Bereitstellungen </h3><br><p>  Die Bereitstellung ist die Essenz des Kubernetes-Clusters, mit dem Sie Pods skalieren und Versionen f√ºr eine gro√üe Anzahl von Pods bequem aktualisieren oder zur√ºcksetzen k√∂nnen. <br>  Anstelle der Bereitstellung k√∂nnen Sie auch das ReplicaSet-Objekt verwenden. In unseren Beispielen wird darauf jedoch nicht eingegangen. <br>  Weitere Informationen zur Bereitstellung finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><p>  Wir m√ºssen den Pod erneut entfernen (wir m√ºssen den Service nicht entfernen): </p><br><pre> <code class="bash hljs">$ kubectl delete pod nginx</code> </pre> <br><p>  F√ºgen Sie die folgende Bereitstellungsbeschreibung hinzu: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-1.14.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 10 selector: matchLabels: app: webservice minReadySeconds: 10 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 maxSurge: 1 template: metadata: labels: app: webservice spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80</span></span></code> </pre> <br><p>  Erstellen Sie die angegebene Bereitstellung: </p><br><pre> <code class="bash hljs">$ kubectl create -f \ https://raw.githubusercontent.com/selectel/kubernetes-examples/master/deployments/nginx-1.14.yaml</code> </pre> <br><p>  Wir haben 10 als Replikat-Parameter ausgew√§hlt, sodass 10 Pods mit der Nginx-Anwendung in unserem Cluster erstellt werden: </p><br><pre> <code class="bash hljs">$ kubectl get pods --selector app=webservice NAME READY STATUS RESTARTS AGE nginx-deployment-54bfdc4489-42rrb 1/1 Running 0 4m nginx-deployment-54bfdc4489-5lvtc 1/1 Running 0 4m nginx-deployment-54bfdc4489-g7rk2 1/1 Running 0 4m nginx-deployment-54bfdc4489-h5rxp 1/1 Running 0 4m nginx-deployment-54bfdc4489-l9l2d 1/1 Running 0 4m nginx-deployment-54bfdc4489-pjpvg 1/1 Running 0 4m nginx-deployment-54bfdc4489-q8dnp 1/1 Running 0 4m nginx-deployment-54bfdc4489-s4wzf 1/1 Running 0 4m nginx-deployment-54bfdc4489-tfxf9 1/1 Running 0 4m nginx-deployment-54bfdc4489-xjzb5 1/1 Running 0 4m</code> </pre> <br><p>  Sie k√∂nnen √ºber das externe Netzwerk mit dem im vorherigen Abschnitt erstellten Dienst auf die ausgef√ºhrte Anwendung zugreifen.  Der Dienst gleicht automatisch Anforderungen aus dem externen Netzwerk zwischen 10 Nginx-Instanzen aus. </p><br><p>  Bei Bedarf k√∂nnen wir die Version von Nginx aktualisieren.  Aktualisieren Sie die Bereitstellungsbeschreibung, indem Sie die Version des Bildes von 1.14-alpine auf 1.15-alpine √§ndern: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-1.15.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 10 selector: matchLabels: app: webservice minReadySeconds: 10 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 maxSurge: 1 template: metadata: labels: app: webservice spec: containers: - name: nginx image: library/nginx:1.15-alpine # &lt;-- changed ports: - containerPort: 80</span></span></code> </pre> <br><p>  Um den Prozess der Aktualisierung von Pods zu starten, verwenden wir den Befehl kubectl.  Achten Sie auf das Argument --record, es ist n√ºtzlich f√ºr das sp√§tere bequeme Rollback der Nginx-Version: </p><br><pre> <code class="bash hljs">$ kubectl apply -f \ https://raw.githubusercontent.com/selectel/kubernetes-examples/master/deployments/nginx-1.15.yaml \ --record</code> </pre> <br><p>  Sie k√∂nnen den Fortschritt der Aktualisierung mit dem folgenden Befehl √ºberwachen: </p><br><pre> <code class="bash hljs">$ kubectl rollout status deployment nginx-deployment Waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> rollout to finish: 4 out of 10 new replicas have been updated...</code> </pre> <br><p>  Kubernetes wartet 10 Sekunden nach einer erfolgreichen Aktualisierung eines Pods, da wir in der Deployment-Beschreibung den Wert 10 f√ºr den Parameter minReadySeconds angegeben haben. </p><br><p>  Nach Abschluss des Updates werden alle Pods f√ºr die Bereitstellung in einen aktiven Zustand versetzt: </p><br><pre> <code class="bash hljs">$ kubectl get deployment --selector app=webservice NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 10 10 10 10 23m</code> </pre> <br><p>  Wir k√∂nnen die Version der Anwendung zur√ºcksetzen, wenn ein Fehler aufgetreten ist.  Dazu m√ºssen wir die gew√ºnschte Bereitstellungsversion ausw√§hlen: </p><br><pre> <code class="bash hljs">$ kubectl rollout <span class="hljs-built_in"><span class="hljs-built_in">history</span></span> deployment nginx-deployment deployments <span class="hljs-string"><span class="hljs-string">"nginx-deployment"</span></span> REVISION CHANGE-CAUSE 1 &lt;none&gt; 2 kubectl apply --filename=https://raw.githubusercontent.com/selectel/kubernetes-examples/master/deployments/nginx-1.15.yaml --record=<span class="hljs-literal"><span class="hljs-literal">true</span></span></code> </pre> <br><p>  Die Befehlsausgabe enth√§lt zwei Revisionen: Die erste ist die urspr√ºngliche Erstellung der Bereitstellung, die zweite ist das Update.  Da wir beim Aktualisieren das Argument --record verwendet haben, wird der Befehl angezeigt, mit dem die zweite Revision von Deployment erstellt wurde. </p><br><p>  Verwenden Sie den folgenden Befehl, um die Version zur√ºckzusetzen: </p><br><pre> <code class="bash hljs">$ kubectl rollout undo deployment nginx-deployment --to-revision=1</code> </pre> <br><p>  Ebenso k√∂nnen wir mit dem Update das Rollback der Version mit dem folgenden Befehl √ºberwachen: </p><br><pre> <code class="bash hljs">$ kubectl rollout status deployment nginx-deployment Waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> rollout to finish: 6 out of 10 new replicas have been updated‚Ä¶</code> </pre> <br><p>  In all unseren Beispielen haben wir Container ohne persistenten Datenspeicher verwendet.  Im n√§chsten Abschnitt werden wir das Problem beheben. </p><br><h2>  Datenspeicherung </h2><br><p>  Standardm√§√üig sind alle Daten von Containern, die in Pods ausgef√ºhrt werden, kurzlebig und gehen verloren, wenn Pods abst√ºrzen. </p><br><p>  Mit dem PersistentVolumeClaim-Objekt k√∂nnen Sie Pods mit einem persistenten Data Warehouse ausf√ºhren. </p><br><p>  Das Erstellen eines solchen Objekts in einem Cluster ist sehr einfach. F√ºgen Sie einfach seine Beschreibung hinzu, √§hnlich wie wir in den vorherigen Abschnitten Pod, Service oder Bereitstellung erstellt haben. </p><br><p>  Weitere Informationen finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><p>  Beispielbeschreibung von PersistentVolumeClaim beim Erstellen einer 10-GB-Festplatte: </p><br><pre> <code class="bash hljs">apiVersion: v1 kind: PersistentVolumeClaim metadata: name: my-pv-claim spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi</code> </pre> <br><p>  Wir k√∂nnen es als Datentr√§ger mit unserem Pod verbinden, indem wir die Beschreibung des Pods mit Nginx aktualisieren, das zuvor erstellt wurde: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-with-volume.yaml apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80 volumeMounts: - mountPath: "/var/www/html" name: data volumes: - name: data persistentVolumeClaim: claimName: my-pv-claim</span></span></code> </pre> <br><p>  Damit der Datentr√§ger erstellt werden kann, m√ºssen Sie jedoch die Eigenschaften des erstellten Datentr√§gers in Form von StorageClass angeben.  Im Dienst "Virtual Private Cloud" k√∂nnen Sie Netzlaufwerke schneller, universeller und grundlegender Typen als permanente Speicherung von Kubernetes Pod-Daten verwenden. </p><br><p>  Um beispielsweise eine StorageClass zu erstellen, mit der Sie schnelle Festplatten in der Verf√ºgbarkeitszone ru-1b verwenden k√∂nnen, ben√∂tigen Sie die folgende Beschreibung: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># fast.ru-1b.yaml kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: fast.ru-1b annotations: storageclass.beta.kubernetes.io/is-default-class: "true" provisioner: kubernetes.io/cinder parameters: type: fast.ru-1b availability: ru-1b</span></span></code> </pre> <br><p>  L√∂schen Sie vor dem Erstellen der angegebenen Objekte die zuvor erstellte Bereitstellung: </p><br><pre> <code class="bash hljs">$ kubectl delete deployment nginx-deployment</code> </pre> <br><p>  Lassen Sie uns zun√§chst eine StorageClass erstellen, damit sie zur Standardklasse wird, und sp√§ter erstellte PersistentVolumeClaim verwendet sie: </p><br><pre> <code class="bash hljs">$ kubectl create -f \ https://raw.githubusercontent.com/selectel/kubernetes-examples/master/storageclasses/fast.ru-1b.yaml</code> </pre> <br><p>  Erstellen Sie PersistentVolumeClaim und Pod: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/persistentvolumeclaims/my-pv-claim.yaml \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/pods/nginx-with-volume.yaml</code> </pre> <br><p>  Danach wird in Ihrem Projekt automatisch eine Festplatte erstellt, die mit einem der Minion-Knoten des Clusters verbunden wird.  Wenn es herunterf√§llt, wechselt die Festplatte automatisch zu einem anderen Knoten. </p><br><p>  Wir k√∂nnen die Festplatte im Container mit Nginx sehen: </p><br><pre> <code class="bash hljs">$ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> -it nginx sh mount | grep <span class="hljs-string"><span class="hljs-string">"/var/www/html"</span></span> /dev/sdc on /var/www/html <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> ext4 (rw,seclabel,relatime,data=ordered) <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> <br><p>  Sie k√∂nnen das Laufwerk mit Deployment verbinden.  Ein entsprechendes Beispiel finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><h2>  Kubernetes-Systemsteuerung </h2><br><p>  Sie k√∂nnen das integrierte Dashboard von Kubernetes selbst verwenden, um den Status von Clusterobjekten und deren Verwaltung anzuzeigen. </p><br><p>  Um auf alle Funktionen des Panels zugreifen zu k√∂nnen, m√ºssen Sie ein Konto mit der Administratorrolle in Ihrem Cluster erstellen. </p><br><p>  Dazu ben√∂tigen wir eine Kontobeschreibung: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># admin-user.yaml apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kube-system</span></span></code> </pre> <br><p>  Und Rollenbeschreibung: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># cluster-admin.yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kube-system</span></span></code> </pre> <br><p>  Erstellen Sie die angegebenen Objekte: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/accounts/admin-user.yaml \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/clusterrolebindings/cluster-admin.yaml</code> </pre> <br><p>  Als N√§chstes m√ºssen Sie den Wert des generierten Tokens f√ºr dieses Konto ermitteln. <br>  Suchen Sie dazu das entsprechende Secret-Objekt im Cluster: </p><br><pre> <code class="bash hljs">$ kubectl get secret --namespace=kube-system | grep <span class="hljs-string"><span class="hljs-string">"admin-user-token"</span></span> admin-user-token-bkfhb kubernetes.io/service-account-token 3 22m</code> </pre> <br><p>  Und schauen Sie sich den Token-Wert des gefundenen Geheimnisses mit dem Namen admin-user-token-bkfhb an: </p><br><pre> <code class="bash hljs">$ kubectl describe secret admin-user-token-bkfhb --namespace=kube-system | grep <span class="hljs-string"><span class="hljs-string">"token:"</span></span> token: XXXXXX...</code> </pre> <br><p>  Als Antwort erhalten Sie den Wert des Tokens, speichern ihn, er wird uns in Zukunft n√ºtzlich sein. <br>  Einzelheiten zur Zugriffskontrolle f√ºr Kubernetes-Objekte finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><p>  F√ºr den Fall, dass Sie einen Cluster aus einer √∂ffentlichen Vorlage erstellt haben, sind Pod und Service bereits vorhanden, um den Betrieb des Panels sicherzustellen: </p><br><pre> <code class="bash hljs">$ kubectl get svc kubernetes-dashboard --namespace=kube-system 206ms Tue Jun 19 14:35:19 2018 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes-dashboard ClusterIP 10.254.122.245 &lt;none&gt; 443/TCP 2d $ kubectl get pod --namespace=kube-system --selector k8s-app=kubernetes-dashboard 119ms Tue Jun 19 14:36:48 2018 NAME READY STATUS RESTARTS AGE kubernetes-dashboard-747575c864-jpxvt 1/1 Running 0 2d</code> </pre> <br><p>  Da der Dienst vom Typ ClusterIP ist, ist er nur innerhalb des Clusters selbst verf√ºgbar. <br>  Sie k√∂nnen mit der Cluster-Konfigurationsdatei von Ihrem Arbeitscomputer aus mit dem Befehl kubectl auf das Panel zugreifen: </p><br><pre> <code class="bash hljs">$ kubectl proxy Starting to serve on 127.0.0.1:8001</code> </pre> <br><p>  Testen Sie den Proxy, indem Sie die angegebene Adresse im Browser √∂ffnen: </p><br><img src="https://habrastorage.org/webt/lc/zm/k1/lczmk1ud4tjatfu3lthvkrcu66e.png"><br><p>  Wenn Sie eine Antwort √§hnlich dem Screenshot sehen, k√∂nnen Sie unter der folgenden Adresse zum Bedienfeldbildschirm wechseln: </p><br><pre> <code class="bash hljs">http://127.0.0.1:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</code> </pre> <br><p>  Wenn Sie es durchgehen, sollte der Anmeldebildschirm im Bedienfeld angezeigt werden: </p><br><img src="https://habrastorage.org/webt/60/fj/p5/60fjp5-2xjyn_p5mz-jh_ozwzxe.png"><br><p>  Sie m√ºssen das zuvor empfangene Token angeben.  Nach dem Anmelden k√∂nnen Sie das Bedienfeld verwenden: </p><br><img src="https://habrastorage.org/webt/38/ry/dr/38rydrraxndpo0hyqhnm-k1nb_k.png"><br><p>  Informationen zu allen Funktionen des Bedienfelds finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><h2>  √úberwachen von Kubernetes-Objekten </h2><br><p>  Wenn Sie die Vorlage f√ºr √∂ffentliche Cluster verwenden, f√ºhren Sie automatisch die Komponenten zum Sammeln und Anzeigen von Metriken aus - Prometheus und Grafana. </p><br><p>  √Ñhnlich wie in der Systemsteuerung wird ClusterIP als Diensttyp installiert. Der Zugriff darauf ist nur innerhalb des Clusters oder √ºber den kubectl-Proxy m√∂glich.  Sie k√∂nnen von Ihrem Arbeitscomputer aus unter der folgenden Adresse auf Grafana zugreifen: </p><br><pre> <code class="bash hljs">http://127.0.0.1:8001/api/v1/proxy/namespaces/kube-system/services/monitoring-grafana:80</code> </pre> <br><img src="https://habrastorage.org/webt/p3/7e/go/p37egoksdoz8bvp8tsq2fgpsuru.png"><br><h2>  Fazit </h2><br><p>  In diesem Artikel haben wir die am h√§ufigsten verwendeten Kubernetes-Objekte untersucht und Beispiele zum Starten und Verwalten eines Clusters mit OpenStack Magnum untersucht. </p><br><p>  In naher Zukunft wird es m√∂glich sein, die neuesten Kubernetes-Versionen zu verwenden, und die Clusterverwaltung wird √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das Control Panel</a> verf√ºgbar sein. </p><br><p>  Wir freuen uns, wenn Sie unseren Service im Testmodus nutzen und Feedback geben. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de416951/">https://habr.com/ru/post/de416951/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de416941/index.html">Theorie des Gl√ºcks. Einf√ºhrung in die Merphologie</a></li>
<li><a href="../de416943/index.html">N√ºtzliche Materialien zum Entwerfen von Sprachschnittstellen</a></li>
<li><a href="../de416945/index.html">Wie wir BelAZ gemacht haben. Teil 1 - Eisen</a></li>
<li><a href="../de416947/index.html">Spielen Sie das Spiel vor den Olympischen Spielen: eSports wird offiziell</a></li>
<li><a href="../de416949/index.html">Das umfassende Upgrade von Herrn Steven zur Installation eines vierfach gr√∂√üeren Jagdnetzwerks wurde abgeschlossen</a></li>
<li><a href="../de416953/index.html">Erstellen Sie einen Cartoon-Water-Shader f√ºr das Web. Teil 1</a></li>
<li><a href="../de416955/index.html">Kleine Tricks mit Elasticsearch</a></li>
<li><a href="../de416957/index.html">Welche Lasermaschine kaufen? Zuverl√§ssiger Raylogic 11G Lasermaschinen-Test</a></li>
<li><a href="../de416959/index.html">Apple f√ºhrt neue iOS-Diebstahlschutzfunktion ein</a></li>
<li><a href="../de416961/index.html">Automatische Konfliktl√∂sung mithilfe operativer Transformationen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
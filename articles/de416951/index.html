<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🖕🏻 👩🏻‍🚒 👩🏼‍🤝‍👨🏾 Kubernetes-Cluster im VPC-Dienst 💭 👨🏾‍🤝‍👨🏼 📨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir haben die Möglichkeit hinzugefügt, Kubernetes im Virtual Private Cloud-Dienst im frühen Beta-Testmodus bequem zu starten. 


 Diese Funktionalität...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kubernetes-Cluster im VPC-Dienst</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/416951/"><img src="https://habrastorage.org/webt/bc/b6/cy/bcb6cykv49fwewsnhfr-7ny-0uc.png"><br><p><br>  Wir haben die Möglichkeit hinzugefügt, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">Kubernetes</a> im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">Virtual Private Cloud-Dienst</a> im frühen Beta-Testmodus bequem zu starten. </p><br><p>  Diese Funktionalität ist nützlich für Benutzer, die eine bequeme Verwaltung einer großen Anzahl von Anwendungen benötigen, die als Container ausgeführt werden.  Kubernetes bietet Tools zur Skalierung, Selbstheilung und zum Lastausgleich für Container, die in einem Cluster ausgeführt werden. </p><br><p>  Da der <strong>Virtual Private Cloud-Dienst</strong> auf OpenStack basiert, verwenden wir eine seiner Komponenten - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">OpenStack Magnum</a> .  Sie können damit schnell private Kubernetes-Cluster mit der gewünschten Anzahl von Knoten erstellen. </p><br><p>  Derzeit kann jeder Benutzer unseres Dienstes mehrere unabhängige Cluster in seinem Projekt erstellen.  Als Clusterknoten werden virtuelle Maschinen verwendet, deren Konfiguration ausgewählt und geändert werden kann. </p><br><p>  In diesem Artikel werden wir uns mit den Hauptobjekten des Kubernetes-Clusters befassen und anhand der Beispiele den Prozess zum Erstellen eines Clusters mit OpenStack Magnum untersuchen. </p><a name="habracut"></a><br><h2>  Erstellen und verwalten Sie einen Kubernetes-Cluster </h2><br><p>  Derzeit ist die Erstellung eines Kubernetes-Clusters nur über Konsolendienstprogramme oder die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">OpenStack-API</a> in den Verfügbarkeitszonen <strong>ru-1a</strong> und <strong>ru-1b</strong> (St. Petersburg) möglich. </p><br><p>  Um loszulegen, benötigen Sie: </p><br><ul><li>  Erstellen Sie ein neues oder verwenden Sie ein vorhandenes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">VPC-</a> Projekt. </li><li>  Erstellen Sie einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">Benutzer mit einem SSH-Schlüssel</a> . </li><li>  Fügen Sie dem erstellten Projekt auf der Projektverwaltungsseite einen Benutzer hinzu. </li><li>  Gehen Sie zum Projekt und rufen Sie die Zugriffsdatei auf der Registerkarte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">Zugriff ab</a> . </li><li>  Installieren Sie den <strong>Openstack-</strong> Konsolenclient mit der <strong>Python-Magnumclient-Bibliothek</strong> . </li><li>  Installieren Sie den <strong>kubectl-</strong> Konsolenclient. </li></ul><br><p>  Um den <strong>Openstack-</strong> Konsolen-Client zu installieren, können <strong>Sie</strong> die Anweisungen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">auf dem Link verwenden.</a> <strong>Beachten Sie</strong> jedoch, dass Sie für diesen Client auch die <strong>Python-Magnumclient-</strong> Bibliothek installieren <strong>müssen</strong> , um die Erstellung von Kubernetes-Clustern zu unterstützen. </p><br><p>  Der vollständige Befehlssatz zum Installieren eines Openstack-Clients mit dem erforderlichen Plug-In für Betriebssysteme der Ubuntu / Debian-Familie: </p><br><pre><code class="bash hljs">$ sudo apt update $ sudo apt -y install curl python-pip python-dev python3-dev git libxml2-dev libxslt1-dev python-openssl python3-openssl python-pyasn1 libffi-dev libssl-dev build-essential $ sudo pip install -UI pbr setuptools pytz $ sudo pip install -UI git+https://github.com/openstack/python-openstackclient $ sudo pip install -UI git+https://github.com/openstack/python-magnumclient</code> </pre> <br><p>  Vollständiger Befehlssatz für die Installation des Openstack-Clients mit dem erforderlichen Plug-In für Betriebssysteme der Fedora / CentOS-Familie: </p><br><pre> <code class="bash hljs">$ sudo yum -y install python-pip gcc libffi-devel python-devel libxslt-devel openssl-devel git libffi-devel $ sudo pip install -UI pbr setuptools pytz $ sudo pip install -UI git+https://github.com/openstack/python-openstackclient $ sudo pip install -UI git+https://github.com/openstack/python-magnumclient</code> </pre> <br><p>  Zum Verwalten von Kubernetes-Objekten benötigen Sie den <strong>kubectl-</strong> Konsolenclient.  Installationsmethoden für verschiedene Betriebssysteme sind in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">offiziellen Dokumentation beschrieben</a> . </p><br><p>  Um einen Cluster zu erstellen, müssen Sie vorhandene erstellen oder verwenden: </p><br><ul><li>  Cluster- <strong>Vorlage</strong> ; </li><li>  Eine Reihe von Parametern für die CPU und den RAM virtueller Maschinen ( <strong>Variante</strong> ). </li></ul><br><p>  Sie können Cluster-Vorlagen erstellen und selbst eine Version erstellen oder öffentliche vorab erstellte Vorlagen verwenden. </p><br><p>  Sie müssen auch die Verfügbarkeitszone, den Festplattentyp für Ihren Cluster und die Anzahl der Knoten ermitteln.  Es ist zu bedenken, dass wir die Möglichkeit, einen Cluster in mehreren Zonen zu erstellen, noch nicht unterstützen.  Sie können einen beliebigen Netzwerktyp auswählen (schnell, universell oder einfach). <br>  Weitere Informationen zu Laufwerkstypen finden Sie in unserer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener noreferrer">Wissensdatenbank</a> . </p><br><p>  Die Anzahl der Knoten kann für <strong>Master-</strong> und <strong>Minion-</strong> Rollen unterschiedlich sein.  Auf den Knoten, die die Hauptrolle ausführen, werden die Cluster-Steuerelemente gestartet - <strong>Controller-Manager</strong> , <strong>Scheduler</strong> , <strong>API</strong> .  Auf den anderen Knoten werden <strong>Kubelet-</strong> , <strong>Kube-Proxy-</strong> Dienste und alle Anwendungscontainer gestartet.  Weitere Informationen zu den Komponenten, die auf Clusterknoten ausgeführt werden, finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><p>  Um über SSH auf Knoten zuzugreifen, müssen Sie den zuvor erstellten SSH-Schlüssel verwenden.  Die Beispielbefehle verwenden einen Schlüssel namens <strong>ssh-test</strong> . </p><br><p>  Wir werden die Vorlage und Variante des öffentlichen Clusters, den schnellen Festplattentyp und die Verfügbarkeitszone <strong>ru-1b verwenden</strong> . <br>  In unserem Cluster werden zunächst 2 Masterknoten und 3 Minionknoten gestartet. </p><br><p>  Um diese Parameter zu überprüfen, verwenden wir die openstackclient-Befehle und die heruntergeladene Zugriffsdatei ( <strong>rc.sh</strong> ): </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#          . $ source rc.sh #  ,         $ openstack flavor show BL1.2-4096 -c ram -c vcpus +-------+-------+ | Field | Value | +-------+-------+ | ram | 4096 | | vcpus | 2 | +-------+-------+ #       ru-1b $ openstack volume type show fast.ru-1b -c name +-------+------------+ | Field | Value | +-------+------------+ | name | fast.ru-1b | +-------+------------+ #    Kubernetes $ openstack coe cluster template list -c name +---------------------------------------+ | name | +---------------------------------------+ | kubernetes-nofloatingips-ru-1b-v1.9.3 | | kubernetes-nofloatingips-ru-1b-v1.9.6 | | kubernetes-nofloatingips-ru-1b-v1.9.9 | | kubernetes-floatingips-ru-1b-v1.9.3 | | kubernetes-floatingips-ru-1b-v1.9.6 | | kubernetes-floatingips-ru-1b-v1.9.9 | | kubernetes-nofloatingips-ru-1a-v1.9.3 | | kubernetes-nofloatingips-ru-1a-v1.9.6 | | kubernetes-nofloatingips-ru-1a-v1.9.9 | | kubernetes-floatingips-ru-1a-v1.9.3 | | kubernetes-floatingips-ru-1a-v1.9.6 | | kubernetes-floatingips-ru-1a-v1.9.9 | +---------------------------------------+</span></span></code> </pre> <br><p>  Als Beispiel wählen wir die zweite Cluster-Vorlage aus, aus der nicht öffentlich zugängliche Floating-Adressen für jeden der Knoten erstellt werden.  Wir werden sie nicht brauchen. </p><br><pre> <code class="plaintext hljs">#   Kubernetes   test-cluster #   keypair   ,   $ openstack coe cluster create \ --cluster-template kubernetes-nofloatingips-ru-1b-v1.9.9 \ --master-count 2 \ --node-count 3 \ --keypair ssh-test \ --master-flavor BL1.2-4096 \ --flavor BL1.2-4096 \ test-cluster</code> </pre> <br><p>  <em>Bitte beachten Sie, dass wir dieselbe Konfiguration für verschiedene Knoten ausgewählt haben (Master-Flavour- und Flavour-Parameter). Sie können je nach den Anforderungen des Clusters unterschiedliche Konfigurationssätze auswählen.</em>  <em>Ihre Änderung ist nach ihrer Schaffung möglich.</em> </p><br><p>  Beachten Sie auch, dass beim Erstellen eines Clusters mit mehreren Masterknoten automatisch ein Load Balancer erstellt wird, um auf die Kubernetes-API zuzugreifen. </p><br><p>  Nach einigen Minuten wird in Ihrem Projekt ein Kubernetes-Cluster angezeigt.  In der Projektsteuerung sehen Sie neue virtuelle Maschinen, Festplatten und Netzwerkobjekte. </p><br><p>  Sie können den Status Ihres Clusters über openstackclient überprüfen: </p><br><pre> <code class="bash hljs">openstack coe cluster list -c name -c status +--------------+--------------------+ | name | status | +--------------+--------------------+ | <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster | CREATE_IN_PROGRESS | +--------------+--------------------+</code> </pre> <br><p>  Nachdem der Cluster in den Status CREATE_COMPLETE eingetreten ist, können Sie seine Objekte über das Dienstprogramm kubectl verwalten, indem Sie die Konfigurationsdatei mit den folgenden Befehlen herunterladen: </p><br><pre> <code class="bash hljs">$ mkdir -p ~/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster $ openstack coe cluster config <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster --dir ~/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster</code> </pre> <br><p>  Danach können Sie mit dem Dienstprogramm kubectl mit dem Cluster arbeiten: </p><br><pre> <code class="bash hljs">$ <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> KUBECONFIG=~/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster/config $ kubectl get pods --all-namespaces -o=custom-columns=NAME:.metadata.name,STATUS:.status.phase NAME STATUS coredns-785dcf9c58-6gnfp Running heapster-6846cdc674-rm4k6 Running kube-dns-autoscaler-6b94f7bbf8-x5clt Running kubernetes-dashboard-747575c864-wlg6p Running monitoring-grafana-84b4596dd7-zf5rx Running monitoring-influxdb-c8486fc95-bqqb6 Running node-exporter-test-cluster-robvp4cvwpt7-minion-0 Running</code> </pre> <br><p>  Bei Bedarf können Sie die Anzahl der Minion-Knoten im Cluster über openstackclient erhöhen oder verringern, indem Sie den neuen Wert für node_count übergeben: </p><br><pre> <code class="bash hljs">$ openstack coe cluster update <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster replace node_count=4</code> </pre> <br><h2>  Wichtige Kubernetes-Clusterobjekte </h2><br><h3>  Pods </h3><br><p>  Obwohl Kubernetes eine Reihe von Containern verwaltet, ist die zugrunde liegende Entität, die Kubernetes verwaltet, kein Container, sondern ein <strong>Pod</strong> . </p><br><p>  Pod ist eine Reihe von Linux-Kernel-Namespaces und Netzwerkstapel-Einstellungen, mit denen Sie eine Reihe von Containern zu einer einzigen Entität zusammenstellen können. <br>  Meistens wird ein Container mit der Anwendung in einem separaten Pod gestartet. <br>  Bei Bedarf können Sie mehrere Container in einem Pod ausführen. Dies kann hilfreich sein, wenn Sie über die localhost-Netzwerkschnittstelle Zugriff von einem Container auf einen anderen gewähren müssen oder aus einem anderen Grund mehrere Container auf demselben Host ausführen müssen. <br>  Alle Container, die im selben Pod ausgeführt werden, haben einen Hostnamen, eine IP-Adresse, eine Routing-Tabelle und Festplatten. </p><br><p>  Beachten Sie, dass beim Skalieren der Anzahl der Instanzen Ihrer Anwendung in Kubernetes die Anzahl der Pods und nicht die Anzahl der Container in einem bestimmten Pod erhöht werden muss. <br>  Weitere Details in der offiziellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">Pods-</a> Dokumentation. </p><br><p>  Erstellen Sie beispielsweise den einfachsten Pod mit Nginx anhand der Beschreibung im Yaml-Format: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-basic.yaml apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80</span></span></code> </pre> <br><p>  Um einen Pod zu erstellen, können wir das Dienstprogramm <strong>kubectl verwenden</strong> . <br>  Wir haben alle im Artikel vorgestellten Beispiele zu unserer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">Github-Gruppe</a> hinzugefügt, sodass Sie keine Dateien auf Ihrem Computer erstellen können, sondern die Datei-URL aus dem öffentlichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">Repository verwenden</a> : </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/pods/nginx-basic.yaml</code> </pre> <br><p>  Nach der Erstellung können wir mit dem Befehl kubectl description vollständige Informationen zum Status des Pods anfordern: </p><br><pre> <code class="bash hljs">$ kubectl describe pod nginx Name: nginx Namespace: default Node: <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0/10.0.0.5 Start Time: Sun, 17 Jun 2018 12:29:03 +0000 Labels: &lt;none&gt; Annotations: &lt;none&gt; Status: Running IP: 10.100.88.9 Containers: nginx: Container ID: docker://6ca6383b66686c05c61c1f690737110e0f8994eda393f44a7ebfbbf2b2026267 Image: library/nginx:1.14-alpine Image ID: docker-pullable://docker.io/nginx@sha256:944b79ca7dbe456ce72e73e70816c1990e39967c8f010349a388c00b77ec519c Port: 80/TCP Host Port: 0/TCP State: Running Started: Sun, 17 Jun 2018 12:29:16 +0000 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-rp5ls (ro) Conditions: Type Status Initialized True Ready True PodScheduled True Volumes: default-token-rp5ls: Type: Secret (a volume populated by a Secret) SecretName: default-token-rp5ls Optional: <span class="hljs-literal"><span class="hljs-literal">false</span></span> QoS Class: BestEffort Node-Selectors: &lt;none&gt; Tolerations: &lt;none&gt; Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 52s default-scheduler Successfully assigned nginx to <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Normal SuccessfulMountVolume 51s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 MountVolume.SetUp succeeded <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> volume <span class="hljs-string"><span class="hljs-string">"default-token-rp5ls"</span></span> Normal Pulling 50s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 pulling image <span class="hljs-string"><span class="hljs-string">"library/nginx:1.14-alpine"</span></span> Normal Pulled 39s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Successfully pulled image <span class="hljs-string"><span class="hljs-string">"library/nginx:1.14-alpine"</span></span> Normal Created 39s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Created container Normal Started 39s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Started container</code> </pre> <br><p>  Wie Sie sehen können, wurde Pod auf einem Knoten mit dem Namen test-cluster-nd5c5y6lsfxb-minion-0 gestartet und erhielt eine interne IP-Adresse von 10.100.88.9. </p><br><p>  Im Abschnitt "Ereignisse" können Sie die wichtigsten Startereignisse anzeigen. Wählen Sie einen Knoten zum Starten aus und laden Sie das Image herunter. </p><br><p>  Wir können in den Pod gelangen und den Status der Prozesse im Container überprüfen: </p><br><pre> <code class="bash hljs">$ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> -it nginx sh ps aux PID USER TIME COMMAND 1 root 0:00 nginx: master process nginx -g daemon off; 7 nginx 0:00 nginx: worker process 20 root 0:00 sh 24 root 0:00 ps aux <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> <br><p>  Es ist zu beachten, dass die IP-Adresse 10.100.88.9 nicht für andere Anwendungen innerhalb und außerhalb des Kubernetes-Clusters verfügbar ist. Der Zugriff auf das laufende Nginx ist nur über den Pod selbst möglich: </p><br><pre> <code class="bash hljs">$ ping -c 1 10.100.88.9 PING 10.100.88.9 (10.100.88.9): 56 data bytes --- 10.100.88.9 ping statistics --- 1 packets transmitted, 0 packets received, 100% packet loss $ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> nginx -- ping -c1 10.100.88.9 PING 10.100.88.9 (10.100.88.9): 56 data bytes 64 bytes from 10.100.88.9: seq=0 ttl=64 time=0.075 ms --- 10.100.88.9 ping statistics --- 1 packets transmitted, 1 packets received, 0% packet loss round-trip min/avg/max = 0.075/0.075/0.075 ms</code> </pre> <br><p>  Neben der Tatsache, dass auf die angegebene IP-Adresse nur vom Container aus zugegriffen werden kann, ist sie auch nicht permanent.  Dies bedeutet, dass dieser Pod bei einer Neuerstellung eine andere IP-Adresse erhalten kann. </p><br><p>  Um diese Probleme zu lösen, können Sie ein Objekt namens Service verwenden. </p><br><h3>  Dienstleistungen </h3><br><p>  Mit dem Dienst können Sie Pods permanente IP-Adressen zuweisen, ihnen Zugriff von externen Netzwerken gewähren und Anforderungen zwischen Pods ausgleichen. <br>  Weitere Informationen zum Service finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><p>  Zum Beispiel müssen wir den laufenden Pod entfernen: </p><br><pre> <code class="bash hljs">$ kubectl delete pod nginx</code> </pre> <br><p>  Fügen Sie der Beschreibung des Pods ein Etikett (Label) hinzu, das für den Service erforderlich ist: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-labeled.yaml apiVersion: v1 kind: Pod metadata: name: nginx labels: app: webservice spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80</span></span></code> </pre> <br><p>  Wir benötigen auch eine Beschreibung des Service: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-nodeport.yaml apiVersion: v1 kind: Service metadata: name: nginx-nodeport labels: app: webservice spec: type: NodePort ports: - port: 80 nodePort: 30001 protocol: TCP selector: app: webservice</span></span></code> </pre> <br><p>  Pod und Service erstellen: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/pods/nginx-labeled.yaml \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/services/nginx-nodeport.yaml</code> </pre> <br><p>  Da der erstellte Dienst vom Typ NodePort ist, wird der von uns auf allen Netzwerkschnittstellen angegebene Port 30001 auf allen Knoten des Clusters geöffnet. <br>  Dies bedeutet, dass wir, wenn wir einem Knoten eine externe IP-Adresse hinzufügen, über ein externes Netzwerk mit Nginx auf den laufenden Pod zugreifen können. </p><br><p>  Um die externen Adressen der Clusterknoten nicht für den Zugriff auf den Service zu verwenden, können Sie anstelle von NodePort den Typ LoadBalancer verwenden. <br>  Wir benötigen eine neue Beschreibung des Dienstes: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-loadbalancer.yaml apiVersion: v1 kind: Service metadata: name: nginx-loadbalancer labels: app: webservice spec: type: LoadBalancer ports: - port: 80 protocol: TCP selector: app: webservice</span></span></code> </pre> <br><p>  Löschen Sie den aktuellen Dienst und wenden Sie die neue Beschreibung an: </p><br><pre> <code class="bash hljs">$ kubectl delete service nginx-service $ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/services/nginx-loadbalancer.yaml</code> </pre> <br><p>  Nach dem Starten des Dienstes ist Nginx auf TCP-Port 80 über ein externes Netzwerk verfügbar, und es ist nicht erforderlich, externe Adressen für Clusterknoten zuzuweisen und zu verwenden.  Der Dienst vom Typ LoadBalancer weist Ihrem VPC-Projekt automatisch eine neue externe Adresse zu und beginnt mit deren Verwendung. </p><br><p>  Informationen zur hervorgehobenen externen Adresse erhalten Sie mit kubectl: </p><br><pre> <code class="bash hljs">$ kubectl get service nginx-service -o=custom-columns=IP:status.loadBalancer.ingress[0].ip IP xxx.xxx.xxx.xxx</code> </pre> <br><p>  In unseren Beispielen wurde nur ein Pod mit Nginx gestartet.  Um die Anwendung auf mehrere Pods zu skalieren, können wir die Bereitstellung verwenden. </p><br><h3>  Bereitstellungen </h3><br><p>  Die Bereitstellung ist die Essenz des Kubernetes-Clusters, mit dem Sie Pods skalieren und Versionen für eine große Anzahl von Pods bequem aktualisieren oder zurücksetzen können. <br>  Anstelle der Bereitstellung können Sie auch das ReplicaSet-Objekt verwenden. In unseren Beispielen wird darauf jedoch nicht eingegangen. <br>  Weitere Informationen zur Bereitstellung finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><p>  Wir müssen den Pod erneut entfernen (wir müssen den Service nicht entfernen): </p><br><pre> <code class="bash hljs">$ kubectl delete pod nginx</code> </pre> <br><p>  Fügen Sie die folgende Bereitstellungsbeschreibung hinzu: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-1.14.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 10 selector: matchLabels: app: webservice minReadySeconds: 10 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 maxSurge: 1 template: metadata: labels: app: webservice spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80</span></span></code> </pre> <br><p>  Erstellen Sie die angegebene Bereitstellung: </p><br><pre> <code class="bash hljs">$ kubectl create -f \ https://raw.githubusercontent.com/selectel/kubernetes-examples/master/deployments/nginx-1.14.yaml</code> </pre> <br><p>  Wir haben 10 als Replikat-Parameter ausgewählt, sodass 10 Pods mit der Nginx-Anwendung in unserem Cluster erstellt werden: </p><br><pre> <code class="bash hljs">$ kubectl get pods --selector app=webservice NAME READY STATUS RESTARTS AGE nginx-deployment-54bfdc4489-42rrb 1/1 Running 0 4m nginx-deployment-54bfdc4489-5lvtc 1/1 Running 0 4m nginx-deployment-54bfdc4489-g7rk2 1/1 Running 0 4m nginx-deployment-54bfdc4489-h5rxp 1/1 Running 0 4m nginx-deployment-54bfdc4489-l9l2d 1/1 Running 0 4m nginx-deployment-54bfdc4489-pjpvg 1/1 Running 0 4m nginx-deployment-54bfdc4489-q8dnp 1/1 Running 0 4m nginx-deployment-54bfdc4489-s4wzf 1/1 Running 0 4m nginx-deployment-54bfdc4489-tfxf9 1/1 Running 0 4m nginx-deployment-54bfdc4489-xjzb5 1/1 Running 0 4m</code> </pre> <br><p>  Sie können über das externe Netzwerk mit dem im vorherigen Abschnitt erstellten Dienst auf die ausgeführte Anwendung zugreifen.  Der Dienst gleicht automatisch Anforderungen aus dem externen Netzwerk zwischen 10 Nginx-Instanzen aus. </p><br><p>  Bei Bedarf können wir die Version von Nginx aktualisieren.  Aktualisieren Sie die Bereitstellungsbeschreibung, indem Sie die Version des Bildes von 1.14-alpine auf 1.15-alpine ändern: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-1.15.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 10 selector: matchLabels: app: webservice minReadySeconds: 10 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 maxSurge: 1 template: metadata: labels: app: webservice spec: containers: - name: nginx image: library/nginx:1.15-alpine # &lt;-- changed ports: - containerPort: 80</span></span></code> </pre> <br><p>  Um den Prozess der Aktualisierung von Pods zu starten, verwenden wir den Befehl kubectl.  Achten Sie auf das Argument --record, es ist nützlich für das spätere bequeme Rollback der Nginx-Version: </p><br><pre> <code class="bash hljs">$ kubectl apply -f \ https://raw.githubusercontent.com/selectel/kubernetes-examples/master/deployments/nginx-1.15.yaml \ --record</code> </pre> <br><p>  Sie können den Fortschritt der Aktualisierung mit dem folgenden Befehl überwachen: </p><br><pre> <code class="bash hljs">$ kubectl rollout status deployment nginx-deployment Waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> rollout to finish: 4 out of 10 new replicas have been updated...</code> </pre> <br><p>  Kubernetes wartet 10 Sekunden nach einer erfolgreichen Aktualisierung eines Pods, da wir in der Deployment-Beschreibung den Wert 10 für den Parameter minReadySeconds angegeben haben. </p><br><p>  Nach Abschluss des Updates werden alle Pods für die Bereitstellung in einen aktiven Zustand versetzt: </p><br><pre> <code class="bash hljs">$ kubectl get deployment --selector app=webservice NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 10 10 10 10 23m</code> </pre> <br><p>  Wir können die Version der Anwendung zurücksetzen, wenn ein Fehler aufgetreten ist.  Dazu müssen wir die gewünschte Bereitstellungsversion auswählen: </p><br><pre> <code class="bash hljs">$ kubectl rollout <span class="hljs-built_in"><span class="hljs-built_in">history</span></span> deployment nginx-deployment deployments <span class="hljs-string"><span class="hljs-string">"nginx-deployment"</span></span> REVISION CHANGE-CAUSE 1 &lt;none&gt; 2 kubectl apply --filename=https://raw.githubusercontent.com/selectel/kubernetes-examples/master/deployments/nginx-1.15.yaml --record=<span class="hljs-literal"><span class="hljs-literal">true</span></span></code> </pre> <br><p>  Die Befehlsausgabe enthält zwei Revisionen: Die erste ist die ursprüngliche Erstellung der Bereitstellung, die zweite ist das Update.  Da wir beim Aktualisieren das Argument --record verwendet haben, wird der Befehl angezeigt, mit dem die zweite Revision von Deployment erstellt wurde. </p><br><p>  Verwenden Sie den folgenden Befehl, um die Version zurückzusetzen: </p><br><pre> <code class="bash hljs">$ kubectl rollout undo deployment nginx-deployment --to-revision=1</code> </pre> <br><p>  Ebenso können wir mit dem Update das Rollback der Version mit dem folgenden Befehl überwachen: </p><br><pre> <code class="bash hljs">$ kubectl rollout status deployment nginx-deployment Waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> rollout to finish: 6 out of 10 new replicas have been updated…</code> </pre> <br><p>  In all unseren Beispielen haben wir Container ohne persistenten Datenspeicher verwendet.  Im nächsten Abschnitt werden wir das Problem beheben. </p><br><h2>  Datenspeicherung </h2><br><p>  Standardmäßig sind alle Daten von Containern, die in Pods ausgeführt werden, kurzlebig und gehen verloren, wenn Pods abstürzen. </p><br><p>  Mit dem PersistentVolumeClaim-Objekt können Sie Pods mit einem persistenten Data Warehouse ausführen. </p><br><p>  Das Erstellen eines solchen Objekts in einem Cluster ist sehr einfach. Fügen Sie einfach seine Beschreibung hinzu, ähnlich wie wir in den vorherigen Abschnitten Pod, Service oder Bereitstellung erstellt haben. </p><br><p>  Weitere Informationen finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><p>  Beispielbeschreibung von PersistentVolumeClaim beim Erstellen einer 10-GB-Festplatte: </p><br><pre> <code class="bash hljs">apiVersion: v1 kind: PersistentVolumeClaim metadata: name: my-pv-claim spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi</code> </pre> <br><p>  Wir können es als Datenträger mit unserem Pod verbinden, indem wir die Beschreibung des Pods mit Nginx aktualisieren, das zuvor erstellt wurde: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-with-volume.yaml apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80 volumeMounts: - mountPath: "/var/www/html" name: data volumes: - name: data persistentVolumeClaim: claimName: my-pv-claim</span></span></code> </pre> <br><p>  Damit der Datenträger erstellt werden kann, müssen Sie jedoch die Eigenschaften des erstellten Datenträgers in Form von StorageClass angeben.  Im Dienst "Virtual Private Cloud" können Sie Netzlaufwerke schneller, universeller und grundlegender Typen als permanente Speicherung von Kubernetes Pod-Daten verwenden. </p><br><p>  Um beispielsweise eine StorageClass zu erstellen, mit der Sie schnelle Festplatten in der Verfügbarkeitszone ru-1b verwenden können, benötigen Sie die folgende Beschreibung: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># fast.ru-1b.yaml kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: fast.ru-1b annotations: storageclass.beta.kubernetes.io/is-default-class: "true" provisioner: kubernetes.io/cinder parameters: type: fast.ru-1b availability: ru-1b</span></span></code> </pre> <br><p>  Löschen Sie vor dem Erstellen der angegebenen Objekte die zuvor erstellte Bereitstellung: </p><br><pre> <code class="bash hljs">$ kubectl delete deployment nginx-deployment</code> </pre> <br><p>  Lassen Sie uns zunächst eine StorageClass erstellen, damit sie zur Standardklasse wird, und später erstellte PersistentVolumeClaim verwendet sie: </p><br><pre> <code class="bash hljs">$ kubectl create -f \ https://raw.githubusercontent.com/selectel/kubernetes-examples/master/storageclasses/fast.ru-1b.yaml</code> </pre> <br><p>  Erstellen Sie PersistentVolumeClaim und Pod: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/persistentvolumeclaims/my-pv-claim.yaml \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/pods/nginx-with-volume.yaml</code> </pre> <br><p>  Danach wird in Ihrem Projekt automatisch eine Festplatte erstellt, die mit einem der Minion-Knoten des Clusters verbunden wird.  Wenn es herunterfällt, wechselt die Festplatte automatisch zu einem anderen Knoten. </p><br><p>  Wir können die Festplatte im Container mit Nginx sehen: </p><br><pre> <code class="bash hljs">$ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> -it nginx sh mount | grep <span class="hljs-string"><span class="hljs-string">"/var/www/html"</span></span> /dev/sdc on /var/www/html <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> ext4 (rw,seclabel,relatime,data=ordered) <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> <br><p>  Sie können das Laufwerk mit Deployment verbinden.  Ein entsprechendes Beispiel finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><h2>  Kubernetes-Systemsteuerung </h2><br><p>  Sie können das integrierte Dashboard von Kubernetes selbst verwenden, um den Status von Clusterobjekten und deren Verwaltung anzuzeigen. </p><br><p>  Um auf alle Funktionen des Panels zugreifen zu können, müssen Sie ein Konto mit der Administratorrolle in Ihrem Cluster erstellen. </p><br><p>  Dazu benötigen wir eine Kontobeschreibung: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># admin-user.yaml apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kube-system</span></span></code> </pre> <br><p>  Und Rollenbeschreibung: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># cluster-admin.yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kube-system</span></span></code> </pre> <br><p>  Erstellen Sie die angegebenen Objekte: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/accounts/admin-user.yaml \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/clusterrolebindings/cluster-admin.yaml</code> </pre> <br><p>  Als Nächstes müssen Sie den Wert des generierten Tokens für dieses Konto ermitteln. <br>  Suchen Sie dazu das entsprechende Secret-Objekt im Cluster: </p><br><pre> <code class="bash hljs">$ kubectl get secret --namespace=kube-system | grep <span class="hljs-string"><span class="hljs-string">"admin-user-token"</span></span> admin-user-token-bkfhb kubernetes.io/service-account-token 3 22m</code> </pre> <br><p>  Und schauen Sie sich den Token-Wert des gefundenen Geheimnisses mit dem Namen admin-user-token-bkfhb an: </p><br><pre> <code class="bash hljs">$ kubectl describe secret admin-user-token-bkfhb --namespace=kube-system | grep <span class="hljs-string"><span class="hljs-string">"token:"</span></span> token: XXXXXX...</code> </pre> <br><p>  Als Antwort erhalten Sie den Wert des Tokens, speichern ihn, er wird uns in Zukunft nützlich sein. <br>  Einzelheiten zur Zugriffskontrolle für Kubernetes-Objekte finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><p>  Für den Fall, dass Sie einen Cluster aus einer öffentlichen Vorlage erstellt haben, sind Pod und Service bereits vorhanden, um den Betrieb des Panels sicherzustellen: </p><br><pre> <code class="bash hljs">$ kubectl get svc kubernetes-dashboard --namespace=kube-system 206ms Tue Jun 19 14:35:19 2018 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes-dashboard ClusterIP 10.254.122.245 &lt;none&gt; 443/TCP 2d $ kubectl get pod --namespace=kube-system --selector k8s-app=kubernetes-dashboard 119ms Tue Jun 19 14:36:48 2018 NAME READY STATUS RESTARTS AGE kubernetes-dashboard-747575c864-jpxvt 1/1 Running 0 2d</code> </pre> <br><p>  Da der Dienst vom Typ ClusterIP ist, ist er nur innerhalb des Clusters selbst verfügbar. <br>  Sie können mit der Cluster-Konfigurationsdatei von Ihrem Arbeitscomputer aus mit dem Befehl kubectl auf das Panel zugreifen: </p><br><pre> <code class="bash hljs">$ kubectl proxy Starting to serve on 127.0.0.1:8001</code> </pre> <br><p>  Testen Sie den Proxy, indem Sie die angegebene Adresse im Browser öffnen: </p><br><img src="https://habrastorage.org/webt/lc/zm/k1/lczmk1ud4tjatfu3lthvkrcu66e.png"><br><p>  Wenn Sie eine Antwort ähnlich dem Screenshot sehen, können Sie unter der folgenden Adresse zum Bedienfeldbildschirm wechseln: </p><br><pre> <code class="bash hljs">http://127.0.0.1:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</code> </pre> <br><p>  Wenn Sie es durchgehen, sollte der Anmeldebildschirm im Bedienfeld angezeigt werden: </p><br><img src="https://habrastorage.org/webt/60/fj/p5/60fjp5-2xjyn_p5mz-jh_ozwzxe.png"><br><p>  Sie müssen das zuvor empfangene Token angeben.  Nach dem Anmelden können Sie das Bedienfeld verwenden: </p><br><img src="https://habrastorage.org/webt/38/ry/dr/38rydrraxndpo0hyqhnm-k1nb_k.png"><br><p>  Informationen zu allen Funktionen des Bedienfelds finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener noreferrer">offiziellen Dokumentation</a> . </p><br><h2>  Überwachen von Kubernetes-Objekten </h2><br><p>  Wenn Sie die Vorlage für öffentliche Cluster verwenden, führen Sie automatisch die Komponenten zum Sammeln und Anzeigen von Metriken aus - Prometheus und Grafana. </p><br><p>  Ähnlich wie in der Systemsteuerung wird ClusterIP als Diensttyp installiert. Der Zugriff darauf ist nur innerhalb des Clusters oder über den kubectl-Proxy möglich.  Sie können von Ihrem Arbeitscomputer aus unter der folgenden Adresse auf Grafana zugreifen: </p><br><pre> <code class="bash hljs">http://127.0.0.1:8001/api/v1/proxy/namespaces/kube-system/services/monitoring-grafana:80</code> </pre> <br><img src="https://habrastorage.org/webt/p3/7e/go/p37egoksdoz8bvp8tsq2fgpsuru.png"><br><h2>  Fazit </h2><br><p>  In diesem Artikel haben wir die am häufigsten verwendeten Kubernetes-Objekte untersucht und Beispiele zum Starten und Verwalten eines Clusters mit OpenStack Magnum untersucht. </p><br><p>  In naher Zukunft wird es möglich sein, die neuesten Kubernetes-Versionen zu verwenden, und die Clusterverwaltung wird über <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das Control Panel</a> verfügbar sein. </p><br><p>  Wir freuen uns, wenn Sie unseren Service im Testmodus nutzen und Feedback geben. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de416951/">https://habr.com/ru/post/de416951/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de416941/index.html">Theorie des Glücks. Einführung in die Merphologie</a></li>
<li><a href="../de416943/index.html">Nützliche Materialien zum Entwerfen von Sprachschnittstellen</a></li>
<li><a href="../de416945/index.html">Wie wir BelAZ gemacht haben. Teil 1 - Eisen</a></li>
<li><a href="../de416947/index.html">Spielen Sie das Spiel vor den Olympischen Spielen: eSports wird offiziell</a></li>
<li><a href="../de416949/index.html">Das umfassende Upgrade von Herrn Steven zur Installation eines vierfach größeren Jagdnetzwerks wurde abgeschlossen</a></li>
<li><a href="../de416953/index.html">Erstellen Sie einen Cartoon-Water-Shader für das Web. Teil 1</a></li>
<li><a href="../de416955/index.html">Kleine Tricks mit Elasticsearch</a></li>
<li><a href="../de416957/index.html">Welche Lasermaschine kaufen? Zuverlässiger Raylogic 11G Lasermaschinen-Test</a></li>
<li><a href="../de416959/index.html">Apple führt neue iOS-Diebstahlschutzfunktion ein</a></li>
<li><a href="../de416961/index.html">Automatische Konfliktlösung mithilfe operativer Transformationen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
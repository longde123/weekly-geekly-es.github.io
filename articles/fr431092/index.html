<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöâ üï∫ üë©üèº ROS: carte de profondeur sur le Raspberry Pi "low blood" üìÅ üë®üèΩ‚Äç‚úàÔ∏è üïì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Si vous utilisez ROS lors de la cr√©ation de robots, vous savez probablement qu'il prend en charge le travail avec des cam√©ras st√©r√©o. Vous pouvez par ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>ROS: carte de profondeur sur le Raspberry Pi "low blood"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/431092/"><img src="https://habrastorage.org/webt/jl/ks/vn/jlksvndgnvhxzgvr_jmo19ni580.jpeg" alt="image"><br><br>  Si vous utilisez ROS lors de la cr√©ation de robots, vous savez probablement qu'il prend en charge le travail avec des cam√©ras st√©r√©o.  Vous pouvez par exemple cr√©er une carte de profondeur de la partie visible de l'espace ou un nuage de points.  Et je me demandais √† quel point il serait facile d'utiliser une cam√©ra st√©r√©o StereoPi √† base de framboise dans ROS.  Plus t√¥t, j'√©tais d√©j√† convaincu que la carte de profondeur √©tait parfaitement construite par OpenCV, mais je n'ai jamais trait√© de ROS.  Et j'ai d√©cid√© de l'essayer.  Je veux parler de mes aventures dans la recherche d'une solution. <br><a name="habracut"></a><br><h3>  1. Y a-t-il un ROS sur le Raspberry Pi? </h3><br>  Au d√©but, j'ai d√©cid√© de d√©couvrir s'il √©tait possible de construire ROS pour le Raspberry Pi.  La premi√®re chose que Google m'a dit √©tait une liste d'instructions pour l'installation de diff√©rentes versions de ROS sur le Raspberry Pi, √† savoir cette page <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">wiki ROS</a> <br><br>  Eh bien, il y a d√©j√† quelque chose pour commencer!  Je me suis bien souvenu du temps qu'il a fallu pour cr√©er OpenCV sur Raspberry (environ huit heures), j'ai donc d√©cid√© de rechercher des images de carte MicroSD pr√™tes √† l'emploi pour gagner du temps. <br><br><h3>  2. Existe-t-il des images de cartes microSD pr√™tes √† l'emploi avec ROS pour Raspberry? </h3><br>  Il s'est av√©r√© que ce probl√®me avait d√©j√† √©t√© r√©solu par plusieurs √©quipes de d√©veloppement.  Si vous ne prenez pas de versions uniques par des passionn√©s, deux images se sont d√©marqu√©es qui sont constamment mises √† jour avec la sortie de nouvelles versions du syst√®me d'exploitation et de ROS. <br><br>  La premi√®re option est ROS install√© sur le syst√®me d'exploitation Raspbian natif de l'√©quipe ROSbots, voici une page avec un lien d'image mis √† jour: image <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pr√™te √† l'emploi-raspbian-stretch-ros-opencv</a> <br><br>  La seconde est les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">images d'Ubiquiti Robotics sur Ubuntu</a> . <br><br>  Eh bien, la deuxi√®me question a √©galement √©t√© assez rapidement close.  Il est temps de plonger plus profond√©ment. <br><br><h3>  3. Comment fonctionne ROS avec la cam√©ra Raspberry Pi? </h3><br>  Et quelles cam√©ras st√©r√©o sont g√©n√©ralement prises en charge dans ROS?  J'ai regard√© la page avec les cam√©ras st√©r√©o, pour laquelle la disponibilit√© de pilotes pr√™ts √† l'emploi pour ROS a √©t√© d√©clar√©e, celle-ci: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">wiki.ros.org/Sensors</a> <br><br>  Il y avait deux sections: <br>  <i><b>2.3 Capteurs 3D (t√©l√©m√®tres et cam√©ras RGB-D)</b></i> <i><br></i>  <i><b>2.5 Cam√©ras</b></i> <br>  Il s'est av√©r√© que dans la premi√®re section, non seulement les cam√©ras st√©r√©o, mais aussi les capteurs TOF et les lidars √† balayage sont r√©pertori√©s - en g√©n√©ral, tout ce qui peut donner imm√©diatement des informations en 3D.  Et dans le second, il y a d√©j√† des cam√©ras st√©r√©o.  Essayer de voir les pilotes de plusieurs cam√©ras st√©r√©o n'a pas ajout√© √† ma joie, car cela faisait allusion √† une s√©rieuse immersion dans le code. <br><br>  D'accord, reculez d'une √©tape.  Comment √ßa marche avec une seule cam√©ra Raspberry Pi dans ROS? <br><br>  Trois agr√©ables surprises m'attendaient ici: <br><br><ul><li>  il se trouve que pour ROS il y a un n≈ìud sp√©cial <b><i>raspicam_node</i></b> juste pour travailler avec la cam√©ra Raspberry Pi </li><li>  sortes de n≈ìuds se trouvent sur le github, le code est activement maintenu et bien document√©: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">github.com/UbiquityRobotics/raspicam_node</a> </li><li>  l'auteur du n≈ìud Rohan Agrawal ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">@Rohbotics</a> ) travaille pour une entreprise qui prend activement en charge l'une des images pr√™tes √† l'emploi pour le Raspberry Pi </li></ul><br>  J'ai regard√© le d√©p√¥t gaspub raspicam_node et j'ai regard√© les probl√®mes.  L√†, j'ai trouv√© un probl√®me ouvert avec le nom volumineux "mode st√©r√©o" il y a pr√®s de sept mois, sans r√©ponses ni commentaires.  En fait, tous les √©v√©nements s'y sont d√©velopp√©s davantage. <br><br><h3>  4. Hardcore ou pas? </h3><br>  Afin de ne pas poser de questions aux enfants aux auteurs, j'ai d√©cid√© de regarder le code source et d'√©valuer ce qui menace l'ajout du mode st√©r√©o.  J'√©tais plus int√©ress√© par la partie syst√®me ici: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">github.com/UbiquityRobotics/raspicam_node/tree/kinetic/src</a> <br>  Eh bien, les gars ont √©crit le pilote plongeant dans le niveau MMAL.  Je me suis √©galement souvenu que le code source des framboises en mode st√©r√©o est √©galement ouvert (l'√©volution peut √™tre retrac√©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici sur le forum framboise</a> ), et la t√¢che d'√©crire un pilote st√©r√©o √† part enti√®re est r√©soluble, mais √† grande √©chelle.  En regardant la description des pilotes d'autres cam√©ras, j'ai r√©alis√© qu'il √©tait n√©cessaire de publier non seulement les images de gauche et de droite, mais aussi de donner les param√®tres des deux cam√©ras, d'appliquer des r√©sultats d'√©talonnage √† chacune et de faire bien d'autres choses.  Cela a attir√© des exp√©riences d'un mois ou deux.  Par cons√©quent, j'ai d√©cid√© de parall√©liser l'approche, √† savoir: √©crire √† l'auteur une question sur le support st√©r√©o et rechercher moi-m√™me une solution plus simple mais fonctionnelle. <br><br><h3>  5. Dialogues avec l'auteur </h3><br>  Dans le fil sur le mode st√©r√©o sur le github, j'ai pos√© une question √† l'auteur, mentionnant que la st√©r√©o est support√©e par les framboises depuis 2014, et lui ai sugg√©r√©, si n√©cessaire, de lui envoyer une carte de d√©bogage pour des exp√©riences.  Permettez-moi de vous rappeler que je doutais encore que dans cette distribution, la st√©r√©o fonctionnera comme dans le Raspbian natif. <br><br>  Rohan a r√©pondu √©tonnamment rapidement, disant que leur distribution utilise un noyau de framboise et que tout devrait fonctionner.  Et a demand√© de le v√©rifier sur l'un de leurs assembl√©es. <br><br>  Noyau de framboise!  Hourra!  Th√©oriquement, une image st√©r√©o doit √™tre captur√©e sans danser avec un tambourin! <br><br>  J'ai t√©l√©charg√© et d√©ploy√© leur derni√®re image en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">utilisant un lien de Rohan</a> et j'ai ex√©cut√© un simple script python pour capturer une paire st√©r√©o.  √áa a march√©! <br><br><img src="https://habrastorage.org/webt/vh/6i/fg/vh6ifg37hbuzr0khcyxnuxpq5fa.jpeg" alt="image"><br><br>  Apr√®s cela, Rohan a √©crit qu'il examinerait le code du pilote pour le mode st√©r√©o et a √©crit quelques questions.  Par exemple, notre mode st√©r√©o produit une image coll√©e, et nous aurions besoin de la couper en deux - gauche et droite.  Et la deuxi√®me question sur les param√®tres d'√©talonnage de chaque cam√©ra est de savoir comment y faire face. <br><br>  J'ai dit que dans un premier temps, vous pouvez prendre des photos √† partir d'appareils photo ind√©pendamment.  Oui, ils ne seront pas synchronis√©s dans le temps de capture et les param√®tres (tels que la luminosit√©, le contraste et la balance des blancs), mais dans un premier temps, cela pourrait bien se produire. <br><br>  Rohan a rapidement <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©ploy√© un correctif</a> qui vous permet de sp√©cifier directement √† partir de ROS l'appareil photo √† partir duquel prendre des photos.  Je l'ai v√©rifi√© - le choix d'un appareil photo fonctionne, c'est d√©j√† un excellent r√©sultat. <br><br><h3>  6. Aide inattendue </h3><br>  Et puis un commentaire de l'utilisateur Wezzoid appara√Æt dans le fil.  Il a dit qu'il faisait un projet bas√© sur une cam√©ra st√©r√©o sur un Pi Compute 3 utilisant des devboards framboises.  Son robot marchant √† quatre pattes a suivi la position d'un objet dans l'espace, a chang√© la position des cam√©ras et a gard√© une distance pr√©d√©termin√©e par rapport √† celui-ci (le projet est affich√© sur hackaday.io <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ). <br><br><img src="https://habrastorage.org/webt/og/sp/iy/ogspiywmjvs67yhodxpbes0pd-8.jpeg" alt="image"><br><br>  Et il a partag√© le code dans lequel il a saisi l'image, l'a coup√©e en deux avec des moyens python et l'a partag√©e comme des n≈ìuds des cam√©ras gauche et droite. <br>  Python n'est pas un ami tr√®s rapide dans ces domaines, il a donc utilis√© une faible r√©solution de 320x240 et un bon hack de vie.  Si nous capturons une image st√©r√©o c√¥te √† c√¥te (une cam√©ra √† gauche de l'image st√©r√©o, la seconde √† droite), le python doit couper chacune des 240 lignes en deux.  Mais si vous faites une image de haut en bas (la cam√©ra de gauche est la moiti√© sup√©rieure du cadre, la droite est en bas), le python coupe le tableau en deux en une seule op√©ration.  Ce qui a √©t√© fait avec succ√®s par l'utilisateur Wezzoid. <br>  De plus, il a publi√© son code python sur Pastebin, qui a effectu√© cette op√©ration.  Le voici: <br><br><div class="spoiler">  <b class="spoiler_title">Code Wezzoid pour publier les n≈ìuds de deux cam√©ras √† partir d'une paire st√©r√©o</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#!/usr/bin/env python # picamera stereo ROS node using dual CSI Pi CS3 board # Wes Freeman 2018 # modified from code by Adrian Rosebrock, pyimagesearch.com # and jensenb, https://gist.github.com/jensenb/7303362 from picamera.array import PiRGBArray from picamera import PiCamera import time import rospy from sensor_msgs.msg import CameraInfo, Image import yaml import io import signal # for ctrl-C handling import sys def parse_calibration_yaml(calib_file): with file(calib_file, 'r') as f: params = yaml.load(f) cam_info = CameraInfo() cam_info.height = params['image_height'] cam_info.width = params['image_width'] cam_info.distortion_model = params['distortion_model'] cam_info.K = params['camera_matrix']['data'] cam_info.D = params['distortion_coefficients']['data'] cam_info.R = params['rectification_matrix']['data'] cam_info.P = params['projection_matrix']['data'] return cam_info # cam resolution res_x = 320 #320 # per camera res_y = 240 #240 target_FPS = 15 # initialize the camera print "Init camera..." camera = PiCamera(stereo_mode = 'top-bottom',stereo_decimate=False) camera.resolution = (res_x, res_y*2) # top-bottom stereo camera.framerate = target_FPS # using several camera options can cause instability, hangs after a while camera.exposure_mode = 'antishake' #camera.video_stabilization = True # fussy about res? stream = io.BytesIO() # ---------------------------------------------------------- #setup the publishers print "init publishers" # queue_size should be roughly equal to FPS or that causes lag? left_img_pub = rospy.Publisher('left/image_raw', Image, queue_size=1) right_img_pub = rospy.Publisher('right/image_raw', Image, queue_size=1) left_cam_pub = rospy.Publisher('left/camera_info', CameraInfo, queue_size=1) right_cam_pub = rospy.Publisher('right/camera_info', CameraInfo, queue_size=1) rospy.init_node('stereo_pub') # init messages left_img_msg = Image() left_img_msg.height = res_y left_img_msg.width = res_x left_img_msg.step = res_x*3 # bytes per row: pixels * channels * bytes per channel (1 normally) left_img_msg.encoding = 'rgb8' left_img_msg.header.frame_id = 'stereo_camera' # TF frame right_img_msg = Image() right_img_msg.height = res_y right_img_msg.width = res_x right_img_msg.step = res_x*3 right_img_msg.encoding = 'rgb8' right_img_msg.header.frame_id = 'stereo_camera' imageBytes = res_x*res_y*3 # parse the left and right camera calibration yaml files left_cam_info = parse_calibration_yaml('/home/pi/catkin_ws/src/mmstereocam/camera_info/left.yaml') right_cam_info = parse_calibration_yaml('/home/pi/catkin_ws/src/mmstereocam/camera_info/right.yaml') # --------------------------------------------------------------- # this is supposed to shut down gracefully on CTRL-C but doesn't quite work: def signal_handler(signal, frame): print 'CTRL-C caught' print 'closing camera' camera.close() time.sleep(1) print 'camera closed' sys.exit(0) signal.signal(signal.SIGINT, signal_handler) #----------------------------------------------------------- print "Setup done, entering main loop" framecount=0 frametimer=time.time() toggle = True # capture frames from the camera for frame in camera.capture_continuous(stream, format="rgb", use_video_port=True): framecount +=1 stamp = rospy.Time.now() left_img_msg.header.stamp = stamp right_img_msg.header.stamp = stamp left_cam_info.header.stamp = stamp right_cam_info.header.stamp = stamp left_cam_pub.publish(left_cam_info) right_cam_pub.publish(right_cam_info) frameBytes = stream.getvalue() left_img_msg.data = frameBytes[:imageBytes] right_img_msg.data = frameBytes[imageBytes:] #publish the image pair left_img_pub.publish(left_img_msg) right_img_pub.publish(right_img_msg) # console info if time.time() &gt; frametimer +1.0: if toggle: indicator = ' o' # just so it's obviously alive if values aren't changing else: indicator = ' -' toggle = not toggle print 'approx publish rate:', framecount, 'target FPS:', target_FPS, indicator frametimer=time.time() framecount=0 # clear the stream ready for next frame stream.truncate(0) stream.seek(0)</span></span></code> </pre> <br></div></div><br><h3>  7. Commencez √† publier les n≈ìuds des cam√©ras gauche et droite </h3><br>  Au premier d√©marrage, le code a maudit qu'il n'y avait pas d'acc√®s aux fichiers YML avec les param√®tres de la cam√©ra.  J'ai utilis√© des cam√©ras V2 de couleur framboise et je me suis souvenu que des fichiers pr√™ts avec des r√©sultats d'√©talonnage pour diff√©rents mod√®les de cam√©ras √©taient arriv√©s √† <i><b>raspicam_node</b></i> sur le github: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">github.com/UbiquityRobotics/raspicam_node/tree/kinetic/camera_info</a> <br>  J'ai pris l'un d'eux, en ai fait deux copies et je l'ai enregistr√© sous les noms left.yml et right.yml, en y inscrivant la r√©solution de la cam√©ra √† partir du script de l'auteur.  Voici ce qui s'est pass√© pour la cam√©ra de gauche: <br><br><div class="spoiler">  <b class="spoiler_title">left.yml</b> <div class="spoiler_text"><pre> <code class="xml hljs">image_width: 320 image_height: 240 camera_name: left camera_matrix: rows: 3 cols: 3 data: [1276.704618338571, 0, 634.8876509199106, 0, 1274.342831275509, 379.8318028940378, 0, 0, 1] distortion_model: plumb_bob distortion_coefficients: rows: 1 cols: 5 data: [0.1465167016954302, -0.2847343180128725, 0.00134017721235817, -0.004309553450829512, 0] rectification_matrix: rows: 3 cols: 3 data: [1, 0, 0, 0, 1, 0, 0, 0, 1] projection_matrix: rows: 3 cols: 4 data: [1300.127197265625, 0, 630.215390285608, 0, 0, 1300.670166015625, 380.1702884455881, 0, 0, 0, 1, 0]</code> </pre> <br></div></div><br>  Pour la droite, le nom de la cam√©ra est remplac√© par droite et le fichier lui-m√™me est nomm√© right.yml.  Le reste du fichier est identique. <br><br>  Comme je n'avais pas pr√©vu de faire un projet complexe, je n'ai pas r√©p√©t√© les longs chemins de l'auteur avec des sous-dossiers et j'ai simplement mis les fichiers √† la racine du dossier personnel √† c√¥t√© du script python.  Le code a d√©marr√© avec succ√®s, affichant des messages d'√©tat dans la console. <br><br><img src="https://habrastorage.org/webt/sz/oi/my/szoimymcugjmfggyfdez98l3kku.jpeg" alt="image"><br><br>  Il ne restait plus qu'√† voir ce qui a finalement √©t√© publi√© par nos cam√©ras gauche et droite.  Pour ce faire, j'ai lanc√© rqt_image_view.  Les √©l√©ments / left / image_raw et / right / image_raw sont apparus dans le menu d√©roulant. Lorsque je les ai s√©lectionn√©s, j'ai vu des images des cam√©ras gauche et droite. <br><br><img src="https://habrastorage.org/webt/og/1i/du/og1iduqsqdfjq_j2ijp-fkzfxhm.jpeg" alt="image"><br><br>  Eh bien, cette chose a gagn√©!  Maintenant, la partie amusante. <br><br><h3>  8. Nous regardons la carte des profondeurs. </h3><br>  Pour voir la carte de profondeur, je n'ai pas trouv√© ma propre approche et j'ai parcouru le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">manuel ROS</a> classique <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pour r√©gler les param√®tres st√©r√©o</a> . <br>  √Ä partir de l√†, j'ai d√©couvert qu'il serait bien de publier les deux n≈ìuds dans un espace de noms sp√©cifique, et non √† la racine comme l'a fait Wezzoid.  En cons√©quence, les anciennes lignes de publication du formulaire <br><br><pre> <code class="python hljs">left_img_pub = rospy.Publisher(<span class="hljs-string"><span class="hljs-string">'left/image_raw'</span></span>, Image, queue_size=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  a commenc√© √† ressembler √† ceci: <br><br><pre> <code class="python hljs">left_img_pub = rospy.Publisher(<span class="hljs-string"><span class="hljs-string">'stereo/right/image_raw'</span></span>, Image, queue_size=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  Apr√®s cela, nous lan√ßons le n≈ìud de traitement du mode st√©r√©o stereo_image_proc: <br><br><pre> <code class="bash hljs">ROS_NAMESPACE=stereo rosrun stereo_image_proc stereo_ige_proc</code> </pre> <br>  Eh bien, nous voulons √©galement regarder le r√©sultat, alors nous commen√ßons l'observateur: <br><br><pre> <code class="bash hljs">rosrun image_view stereo_view stereo:=/stereo image:=image_rect_color</code> </pre> <br>  Et pour configurer les param√®tres de la carte de profondeur, ex√©cutez l'utilitaire de configuration: <br><br><pre> <code class="bash hljs">rosrun rqt_reconfigure rqt_reconfigure</code> </pre> <br>  En cons√©quence, nous voyons l'image au tout d√©but de l'article.  Voici un peu plus grand: <br><br><img src="https://habrastorage.org/webt/qc/oy/s8/qcoys8o4-yrwfxgc7kynjrxhd9m.jpeg" alt="image"><br><br>  Tous les fichiers que j'ai post√©s sur le github: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">github.com/realizator/StereoPi-ROS-depth-map-test</a> <br><br><h3>  9. Plans imm√©diats </h3><br>  Apr√®s ma publication du r√©sultat dans une discussion sur le github, Rohan a √©crit ¬´Cool!  Je dois aller chercher mon StereoPi. "  Nous lui avons √©crit par mail, je lui ai envoy√© des honoraires.  J'esp√®re qu'avec le mat√©riel de travail entre ses mains, il lui sera plus facile de terminer et de d√©boguer un pilote st√©r√©o √† part enti√®re pour ROS et Raspberry. <br><br><h3>  10. R√©sum√© </h3><br>  Une carte de profondeur √† partir d'une image st√©r√©o sur des framboises dans ROS peut √™tre obtenue de plusieurs fa√ßons.  Le chemin choisi pour une v√©rification rapide n'est pas le plus optimal en termes de performances, mais peut √™tre utilis√© √† des fins d'application.  La beaut√© de sa simplicit√© et la possibilit√© de commencer imm√©diatement des exp√©riences. <br><br>  Eh bien, du dr√¥le: apr√®s avoir re√ßu les r√©sultats, j'ai remarqu√© que Wezzoid, qui a propos√© sa solution, √©tait l'auteur de la question sur la publication de deux images st√©r√©o.  Il s'est demand√©, il a d√©cid√©. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr431092/">https://habr.com/ru/post/fr431092/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr431082/index.html">Kotlin: √† la recherche d'un responsable marketing</a></li>
<li><a href="../fr431084/index.html">Dans toute situation incompr√©hensible - √©crire des scripts</a></li>
<li><a href="../fr431086/index.html">Tout ce que vous vouliez savoir sur PVS-Studio et n'h√©sitez pas √† demander</a></li>
<li><a href="../fr431088/index.html">La gestion des fichiers a mal tourn√© - Partie 1: √† l'origine des ann√©es 90</a></li>
<li><a href="../fr431090/index.html">Un bot VK, un C # et une orange</a></li>
<li><a href="../fr431094/index.html">Tri solitaire</a></li>
<li><a href="../fr431096/index.html">Comment cr√©er un produit de chat bot</a></li>
<li><a href="../fr431098/index.html">M√™me un incendie n'est pas un obstacle, ou Zimbra Speed ‚Äã‚ÄãRecovery apr√®s une catastrophe</a></li>
<li><a href="../fr431102/index.html">Comment l'adresse physique est affich√©e dans les cha√Ænes DRAM et les banques</a></li>
<li><a href="../fr431104/index.html">Comment nous, chez Neoflex, d√©veloppons l'expertise DevOps</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
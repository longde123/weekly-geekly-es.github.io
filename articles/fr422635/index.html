<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏼 👨🏻‍⚕️ 🎅🏿 Vous n’avez pas encore dit le mot «bonjour», et nous savons déjà qui vous êtes 🙏🏽 🤽🏿 👃🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Notre réseau de neurones peut le faire en reconnaissant une personne par une syllabe prononcée. Cependant, le sujet de cet article n'est pas directeme...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vous n’avez pas encore dit le mot «bonjour», et nous savons déjà qui vous êtes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/neurodatalab/blog/422635/">  Notre réseau de neurones peut le faire en reconnaissant une personne par une syllabe prononcée.  Cependant, le sujet de cet article n'est pas directement lié à l'identification vocale, bien qu'il y soit lié.  Nous parlerons des caractéristiques du réseau neuronal, le soi-disant d-vecteur, qui peut être utilisé dans des tâches de traitement du son: de la vérification à la reconnaissance vocale et aux émotions. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/eo/h5/k8/eoh5k8gwhm9ep4wpove1up9gljg.jpeg" alt="image"></div><br><a name="habracut"></a><br><h4>  <b>Matériel</b> </h4><br>  Selon le taux d'échantillonnage, une seconde de son peut contenir de 8 à 48 000 nombres.  Ils peuvent être représentés comme des écarts par rapport à la position d'équilibre de la membrane du haut-parleur ou du microphone.  En fait, une telle description du son est redondante: l'amplitude du signal au moment suivant dépend fortement de la précédente, ce qui laisse entendre que ce signal peut être efficacement compressé sans trop de perte d'informations.  Il existe un grand nombre de façons de réduire la dimension d'un signal, et la plupart d'entre elles sont basées sur les propriétés physiques du son et les caractéristiques de l'audition humaine. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fh/n4/qj/fhn4qjskpumyiosbtjxzik7e9yg.jpeg" alt="image"></div><br>  <i>Meme 1.</i> <br><br>  Avant que les réseaux de neurones fonctionnent bien (au sens large), la communauté travaillait avec les soi-disant attributs fabriqués à la main.  Les plus célèbres et les plus utilisés sont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pitch</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MFCC</a> .  Le premier a une signification physique de la fréquence des oscillations des cordes vocales, qui diffèrent, par exemple, pour différentes personnes, et dépendent également de l'intonation.  L'idée des coefficients cepstraux (MFCC) est basée sur la non-linéarité de la perception humaine du son, à savoir la fréquence et le volume.  Il semble à une personne qu'un son est plus élevé qu'un autre dans une certaine mesure, si en réalité leurs fréquences diffèrent d'un certain nombre de fois. <br><br>  Ces caractéristiques et d'autres fonctions calculées manuellement sont irréversibles dans le sens où une partie du signal est perdue à jamais.  Dans certaines tâches, ce n'est pas critique, mais je voudrais proposer une approche plus universelle et plus fonctionnelle. <br><br>  La clé pour résoudre ce problème est la transformée de Fourier.  En l'utilisant, vous pouvez imaginer un signal audio comme la somme des ondes avec différentes fréquences et amplitudes.  En fait, la parole n'est pas stationnaire dans le sens où son spectre sera qualitativement différent à différents moments.  Cela nous permet de le considérer dans la représentation temps-fréquence, à l'aide de <i>spectrogrammes</i> . <br><br>  Pour construire un spectrogramme, vous devez diviser le son en sections entrecroisées (images qui se chevauchent) de plusieurs dizaines de millisecondes de longueur, pour chacune d'elles calculer la transformée de Fourier et écrire leurs modules dans des colonnes sur les spectrogrammes.  De plus, une telle transformation est presque mutuellement inverse, c'est-à-dire qu'en utilisant la transformée de Fourier inverse et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'algorithme Griffin-Lim,</a> vous pouvez restaurer le signal sonore d'origine (en fait, il y a une perte d'informations, car la transformée de Fourier est complexe dans le cas général, et le spectrogramme a une valeur réelle, et, pour approximer la récupération de phase, l'algorithme itératif Griffin-Lim est généralement utilisé).  Au total, si nous prenons le logarithme des amplitudes, nous obtenons ces images: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ux/ig/xz/uxigxzafbu938strrzeepi8s-ro.png" alt="image"></div><br>  <i>Spectrogramme 5 secondes de parole.</i> <br><br>  Et ils sont commodément traités par des filets convolutifs. <br><br>  Un tel hack est souvent utilisé dans les tâches de traitement d'image: il existe de grandes bases de données avec des exemples d'objets différents (par exemple, ImageNet).  Vous pouvez former une grande grille pour les reconnaître, puis la recycler sur notre tâche spécifique, ou prendre le résultat de sortie de l'une des couches internes entièrement connectées.  On pense qu'une telle architecture calculera de bonnes caractéristiques informatives pour les images d'entrée.  L'expérience suggère que presque toujours les résultats seront meilleurs que si nous formions le réseau neuronal à partir de zéro. <br><br>  L'idée des vecteurs d (généralement des vecteurs d, mais parfois appelés vecteurs x) est similaire à l'utilisation de grilles pré-entraînées sur ImageNet, sauf qu'il n'y a pas de bases similaires pour les spectrogrammes.  Comme moyen de sortie possible, les auto-encodeurs peuvent être envisagés, mais ils ne savent a priori pas quoi rechercher dans le spectrogramme, ils fonctionnent donc de manière insatisfaisante. <br><br><h4>  <b>Nous devons aller plus loin</b> </h4><br>  Attention, la partie principale de cet article commence. <br><br>  La tâche de vérifier une personne par la voix est largement connue, où il est nécessaire de déterminer par le segment d'entrée de la parole laquelle des personnes dans la base de données l'a dit.  En fait, la construction de tels systèmes est une science distincte, et il existe de nombreux modules complémentaires (durée du discours; est-il nécessaire que tout le monde parle le même texte; mise en scène un contre un ou un contre tous), qui sont critiques dans différentes conditions, mais pour nous vous devez faire attention à autre chose. <br><br>  À savoir: à quel point les fonctionnalités seront bonnes si nous pré-formons la grille pour reconnaître une personne.  Tout est fait pour des signes. <br><br>  Cela nous aidera à l'intuition et à l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article de</a> 2015.  Dans ce document, les auteurs enseignent la grille pour reconnaître une personne par le visage (reconnaissance du visage).  La clé de ce travail consiste à utiliser Triplet Loss. <br><br>  Son idée est très simple: nous normalisons les entités de l'avant-dernière couche afin qu'elles se trouvent sur une sphère unitaire, et exigeons que les points d'une classe soient proches et éloignés de différents.  Ceci peut être réalisé comme suit: pour chaque exemple de formation (ancre), nous trouvons deux autres de la même classe et d'une autre classe dans l'échantillon - positif et négatif.  Ensuite, pour ces triplets de points, nous formons une perte: <br><br>  \ commencer {équation} <br>  \ Big [\ Vert f (x ^ a) - f (x ^ p) \ Vert - \ Vert f (x ^ a) - f (x ^ n) \ Vert + \ alpha \ Big] _ +, <br>  \ end {équation} <br><br>  où x est l'image d'entrée, f est la sortie de la grille après normalisation, alpha est le paramètre sélectionné manuellement, [] _ ​​{+} est la fonction ReLU.  Qualitativement, la valeur de cette perte est nulle si la distance entre l'ancre et les points positifs est supérieure à la distance entre l'ancre et le négatif d'au moins alpha, et plus grande est la différence entre deux classes différentes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fp/k6/yy/fpk6yyh_hd1hb00bsdcg39xyuqc.png" alt="image"></div><br>  <i>Une illustration de ce qui arrive aux fonctionnalités après l'entraînement avec Triplet Loss.</i> <br><br>  Soit dit en passant, vous pouvez former des triplets de manière intelligente.  À un certain point, l'ampleur de la perte deviendra petite et pour accélérer l'apprentissage, vous pouvez rechercher des exemples négatifs non pas parmi toutes les autres classes, mais ne considérer que ceux proches de l'ancre.  Mais pour les grands ensembles de données, cela est difficile, car vous devez considérer les distances par paire entre les classes qui changent après chaque itération de l'apprentissage réseau. <br><br>  La perte de triplet a un avantage sur la crossentropie catégorielle, qui est utilisée dans la classification conventionnelle.  Un modèle formé à l'entropie croisée tentera de regrouper tous les points d'une classe dans une zone de plus en plus petite, et les informations qui sont superflues pour une tâche particulière peuvent être perdues.  Mais nous ne voulons pas cela, car nous allons utiliser le réseau neuronal comme générateur de fonctionnalités, et non pour la vérification.  La perte de triplet a cette propriété dans une bien moindre mesure: il est plus important pour elle de répartir différentes classes dans différentes zones sur une seule sphère que de porter une classe. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pn/pt/nz/pnptnzxqejabade7orpavbtx5se.jpeg" alt="image"></div><br>  <i>Meme 2.</i> <br><br>  La dernière chose à faire avant d'entraîner le générateur de fonctionnalités sur les spectrogrammes est de déterminer leurs tailles.  De toute évidence, la précision de la classification sera la plus élevée, plus la période de temps que nous considérerons sera grande, mais plus les signes «moyens» se révéleront.  Par conséquent, il est raisonnable d'utiliser une telle longueur de signal afin que 1 à 3 phonèmes (syllabes) y tombent - une demi-seconde semble appropriée. <br><br>  Pour la formation, nous prenons le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">jeu de</a> données <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VoxCeleb2</a> , où pour chacun des 6300 haut-parleurs il y a plusieurs enregistrements audio séparés de plusieurs minutes chacun (réalisés dans des conditions différentes).  Nous utilisons une partie des fichiers audio pour la formation et le reste pour la validation, sélectionnez l'architecture du réseau de convolution, ajoutez-y Triplet Loss et apprenez. <br><br>  Les résultats ont été très sympas.  En près de 2 semaines d'entraînement à 1080Ti (oui, depuis si longtemps), la précision de classification a atteint 55%.  Il semblerait que ce ne soit pas beaucoup, mais la précision du top-5 est de 78%, et si nous considérons uniquement la moitié la plus forte des fragments, qui sont principalement des voyelles accentuées, alors la précision du top-5 augmentera à 91%.  Nous pouvons dire que nous pouvons identifier une personne par l'une de ses phrases avec une précision décente.  Mais cela n'a pas d'importance. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vz/el/21/vzel21arcsvyrco_kg_95usxziy.jpeg" alt="image"></div><br>  <i>Meme 3.</i> <br><br>  Après tout, tout a été lancé pour les fonctionnalités qui peuvent être obtenues pour sortir de l'avant-dernière avant de classer la couche de réseau neuronal.  Nous les avons testés sur nos tâches, et partout les résultats étaient meilleurs que l'utilisation d'approches classiques pour calculer les attributs.  Par exemple, dans le problème de la reconnaissance des émotions, l'utilisation de vecteurs d nous a permis de contourner l'état de l'art de 4%, et l'article correspondant a été accepté lors de la conférence FICC 2019. Cependant, la reconnaissance des émotions est une histoire complètement différente, dont nous parlerons plus tard. <br><br>  Publié par <b>Gregory Sterling</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">sterling239</a> , expert en apprentissage profond, Neurodata Lab. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr422635/">https://habr.com/ru/post/fr422635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr422625/index.html">Nous avons parlé avec Troy Miles - le programmeur de "Neuromancer"</a></li>
<li><a href="../fr422627/index.html">Recherche sur le marché du travail MongoDB et IT</a></li>
<li><a href="../fr422629/index.html">Arrêtez de nourrir les bûcherons! Donnez plus de modificateurs! Champs finaux statiques paresseux. Projet d'esquisse d'objet</a></li>
<li><a href="../fr422631/index.html">Terminaux QIWI. Comment tirer le meilleur parti des technologies simples</a></li>
<li><a href="../fr422633/index.html">Comment nous avons automatisé la surveillance du travail des employés du réseau fédéral de stations-service</a></li>
<li><a href="../fr422637/index.html">Cadeau de geek: Protection Auto-Alkash</a></li>
<li><a href="../fr422641/index.html">Nuit polaire, pompage d'eau et coffre-fort intelligent: 5 projets étudiants dans le domaine de l'IoT</a></li>
<li><a href="../fr422643/index.html">Nouveaux appareils avec IFA 2018</a></li>
<li><a href="../fr422645/index.html">Quelle est l'importance de 196 884 = 196 883 + 1? Comment l'expliquer sur les doigts?</a></li>
<li><a href="../fr422649/index.html">VR multijoueur: comment l'implémenter?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
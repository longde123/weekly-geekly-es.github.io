<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèº üë®üèª‚Äç‚öïÔ∏è üéÖüèø Vous n‚Äôavez pas encore dit le mot ¬´bonjour¬ª, et nous savons d√©j√† qui vous √™tes üôèüèΩ ü§Ωüèø üëÉüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Notre r√©seau de neurones peut le faire en reconnaissant une personne par une syllabe prononc√©e. Cependant, le sujet de cet article n'est pas directeme...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vous n‚Äôavez pas encore dit le mot ¬´bonjour¬ª, et nous savons d√©j√† qui vous √™tes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/neurodatalab/blog/422635/">  Notre r√©seau de neurones peut le faire en reconnaissant une personne par une syllabe prononc√©e.  Cependant, le sujet de cet article n'est pas directement li√© √† l'identification vocale, bien qu'il y soit li√©.  Nous parlerons des caract√©ristiques du r√©seau neuronal, le soi-disant d-vecteur, qui peut √™tre utilis√© dans des t√¢ches de traitement du son: de la v√©rification √† la reconnaissance vocale et aux √©motions. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/eo/h5/k8/eoh5k8gwhm9ep4wpove1up9gljg.jpeg" alt="image"></div><br><a name="habracut"></a><br><h4>  <b>Mat√©riel</b> </h4><br>  Selon le taux d'√©chantillonnage, une seconde de son peut contenir de 8 √† 48 000 nombres.  Ils peuvent √™tre repr√©sent√©s comme des √©carts par rapport √† la position d'√©quilibre de la membrane du haut-parleur ou du microphone.  En fait, une telle description du son est redondante: l'amplitude du signal au moment suivant d√©pend fortement de la pr√©c√©dente, ce qui laisse entendre que ce signal peut √™tre efficacement compress√© sans trop de perte d'informations.  Il existe un grand nombre de fa√ßons de r√©duire la dimension d'un signal, et la plupart d'entre elles sont bas√©es sur les propri√©t√©s physiques du son et les caract√©ristiques de l'audition humaine. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fh/n4/qj/fhn4qjskpumyiosbtjxzik7e9yg.jpeg" alt="image"></div><br>  <i>Meme 1.</i> <br><br>  Avant que les r√©seaux de neurones fonctionnent bien (au sens large), la communaut√© travaillait avec les soi-disant attributs fabriqu√©s √† la main.  Les plus c√©l√®bres et les plus utilis√©s sont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pitch</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MFCC</a> .  Le premier a une signification physique de la fr√©quence des oscillations des cordes vocales, qui diff√®rent, par exemple, pour diff√©rentes personnes, et d√©pendent √©galement de l'intonation.  L'id√©e des coefficients cepstraux (MFCC) est bas√©e sur la non-lin√©arit√© de la perception humaine du son, √† savoir la fr√©quence et le volume.  Il semble √† une personne qu'un son est plus √©lev√© qu'un autre dans une certaine mesure, si en r√©alit√© leurs fr√©quences diff√®rent d'un certain nombre de fois. <br><br>  Ces caract√©ristiques et d'autres fonctions calcul√©es manuellement sont irr√©versibles dans le sens o√π une partie du signal est perdue √† jamais.  Dans certaines t√¢ches, ce n'est pas critique, mais je voudrais proposer une approche plus universelle et plus fonctionnelle. <br><br>  La cl√© pour r√©soudre ce probl√®me est la transform√©e de Fourier.  En l'utilisant, vous pouvez imaginer un signal audio comme la somme des ondes avec diff√©rentes fr√©quences et amplitudes.  En fait, la parole n'est pas stationnaire dans le sens o√π son spectre sera qualitativement diff√©rent √† diff√©rents moments.  Cela nous permet de le consid√©rer dans la repr√©sentation temps-fr√©quence, √† l'aide de <i>spectrogrammes</i> . <br><br>  Pour construire un spectrogramme, vous devez diviser le son en sections entrecrois√©es (images qui se chevauchent) de plusieurs dizaines de millisecondes de longueur, pour chacune d'elles calculer la transform√©e de Fourier et √©crire leurs modules dans des colonnes sur les spectrogrammes.  De plus, une telle transformation est presque mutuellement inverse, c'est-√†-dire qu'en utilisant la transform√©e de Fourier inverse et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'algorithme Griffin-Lim,</a> vous pouvez restaurer le signal sonore d'origine (en fait, il y a une perte d'informations, car la transform√©e de Fourier est complexe dans le cas g√©n√©ral, et le spectrogramme a une valeur r√©elle, et, pour approximer la r√©cup√©ration de phase, l'algorithme it√©ratif Griffin-Lim est g√©n√©ralement utilis√©).  Au total, si nous prenons le logarithme des amplitudes, nous obtenons ces images: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ux/ig/xz/uxigxzafbu938strrzeepi8s-ro.png" alt="image"></div><br>  <i>Spectrogramme 5 secondes de parole.</i> <br><br>  Et ils sont commod√©ment trait√©s par des filets convolutifs. <br><br>  Un tel hack est souvent utilis√© dans les t√¢ches de traitement d'image: il existe de grandes bases de donn√©es avec des exemples d'objets diff√©rents (par exemple, ImageNet).  Vous pouvez former une grande grille pour les reconna√Ætre, puis la recycler sur notre t√¢che sp√©cifique, ou prendre le r√©sultat de sortie de l'une des couches internes enti√®rement connect√©es.  On pense qu'une telle architecture calculera de bonnes caract√©ristiques informatives pour les images d'entr√©e.  L'exp√©rience sugg√®re que presque toujours les r√©sultats seront meilleurs que si nous formions le r√©seau neuronal √† partir de z√©ro. <br><br>  L'id√©e des vecteurs d (g√©n√©ralement des vecteurs d, mais parfois appel√©s vecteurs x) est similaire √† l'utilisation de grilles pr√©-entra√Æn√©es sur ImageNet, sauf qu'il n'y a pas de bases similaires pour les spectrogrammes.  Comme moyen de sortie possible, les auto-encodeurs peuvent √™tre envisag√©s, mais ils ne savent a priori pas quoi rechercher dans le spectrogramme, ils fonctionnent donc de mani√®re insatisfaisante. <br><br><h4>  <b>Nous devons aller plus loin</b> </h4><br>  Attention, la partie principale de cet article commence. <br><br>  La t√¢che de v√©rifier une personne par la voix est largement connue, o√π il est n√©cessaire de d√©terminer par le segment d'entr√©e de la parole laquelle des personnes dans la base de donn√©es l'a dit.  En fait, la construction de tels syst√®mes est une science distincte, et il existe de nombreux modules compl√©mentaires (dur√©e du discours; est-il n√©cessaire que tout le monde parle le m√™me texte; mise en sc√®ne un contre un ou un contre tous), qui sont critiques dans diff√©rentes conditions, mais pour nous vous devez faire attention √† autre chose. <br><br>  √Ä savoir: √† quel point les fonctionnalit√©s seront bonnes si nous pr√©-formons la grille pour reconna√Ætre une personne.  Tout est fait pour des signes. <br><br>  Cela nous aidera √† l'intuition et √† l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article de</a> 2015.  Dans ce document, les auteurs enseignent la grille pour reconna√Ætre une personne par le visage (reconnaissance du visage).  La cl√© de ce travail consiste √† utiliser Triplet Loss. <br><br>  Son id√©e est tr√®s simple: nous normalisons les entit√©s de l'avant-derni√®re couche afin qu'elles se trouvent sur une sph√®re unitaire, et exigeons que les points d'une classe soient proches et √©loign√©s de diff√©rents.  Ceci peut √™tre r√©alis√© comme suit: pour chaque exemple de formation (ancre), nous trouvons deux autres de la m√™me classe et d'une autre classe dans l'√©chantillon - positif et n√©gatif.  Ensuite, pour ces triplets de points, nous formons une perte: <br><br>  \ commencer {√©quation} <br>  \ Big [\ Vert f (x ^ a) - f (x ^ p) \ Vert - \ Vert f (x ^ a) - f (x ^ n) \ Vert + \ alpha \ Big] _ +, <br>  \ end {√©quation} <br><br>  o√π x est l'image d'entr√©e, f est la sortie de la grille apr√®s normalisation, alpha est le param√®tre s√©lectionn√© manuellement, [] _ ‚Äã‚Äã{+} est la fonction ReLU.  Qualitativement, la valeur de cette perte est nulle si la distance entre l'ancre et les points positifs est sup√©rieure √† la distance entre l'ancre et le n√©gatif d'au moins alpha, et plus grande est la diff√©rence entre deux classes diff√©rentes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fp/k6/yy/fpk6yyh_hd1hb00bsdcg39xyuqc.png" alt="image"></div><br>  <i>Une illustration de ce qui arrive aux fonctionnalit√©s apr√®s l'entra√Ænement avec Triplet Loss.</i> <br><br>  Soit dit en passant, vous pouvez former des triplets de mani√®re intelligente.  √Ä un certain point, l'ampleur de la perte deviendra petite et pour acc√©l√©rer l'apprentissage, vous pouvez rechercher des exemples n√©gatifs non pas parmi toutes les autres classes, mais ne consid√©rer que ceux proches de l'ancre.  Mais pour les grands ensembles de donn√©es, cela est difficile, car vous devez consid√©rer les distances par paire entre les classes qui changent apr√®s chaque it√©ration de l'apprentissage r√©seau. <br><br>  La perte de triplet a un avantage sur la crossentropie cat√©gorielle, qui est utilis√©e dans la classification conventionnelle.  Un mod√®le form√© √† l'entropie crois√©e tentera de regrouper tous les points d'une classe dans une zone de plus en plus petite, et les informations qui sont superflues pour une t√¢che particuli√®re peuvent √™tre perdues.  Mais nous ne voulons pas cela, car nous allons utiliser le r√©seau neuronal comme g√©n√©rateur de fonctionnalit√©s, et non pour la v√©rification.  La perte de triplet a cette propri√©t√© dans une bien moindre mesure: il est plus important pour elle de r√©partir diff√©rentes classes dans diff√©rentes zones sur une seule sph√®re que de porter une classe. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pn/pt/nz/pnptnzxqejabade7orpavbtx5se.jpeg" alt="image"></div><br>  <i>Meme 2.</i> <br><br>  La derni√®re chose √† faire avant d'entra√Æner le g√©n√©rateur de fonctionnalit√©s sur les spectrogrammes est de d√©terminer leurs tailles.  De toute √©vidence, la pr√©cision de la classification sera la plus √©lev√©e, plus la p√©riode de temps que nous consid√©rerons sera grande, mais plus les signes ¬´moyens¬ª se r√©v√©leront.  Par cons√©quent, il est raisonnable d'utiliser une telle longueur de signal afin que 1 √† 3 phon√®mes (syllabes) y tombent - une demi-seconde semble appropri√©e. <br><br>  Pour la formation, nous prenons le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">jeu de</a> donn√©es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VoxCeleb2</a> , o√π pour chacun des 6300 haut-parleurs il y a plusieurs enregistrements audio s√©par√©s de plusieurs minutes chacun (r√©alis√©s dans des conditions diff√©rentes).  Nous utilisons une partie des fichiers audio pour la formation et le reste pour la validation, s√©lectionnez l'architecture du r√©seau de convolution, ajoutez-y Triplet Loss et apprenez. <br><br>  Les r√©sultats ont √©t√© tr√®s sympas.  En pr√®s de 2 semaines d'entra√Ænement √† 1080Ti (oui, depuis si longtemps), la pr√©cision de classification a atteint 55%.  Il semblerait que ce ne soit pas beaucoup, mais la pr√©cision du top-5 est de 78%, et si nous consid√©rons uniquement la moiti√© la plus forte des fragments, qui sont principalement des voyelles accentu√©es, alors la pr√©cision du top-5 augmentera √† 91%.  Nous pouvons dire que nous pouvons identifier une personne par l'une de ses phrases avec une pr√©cision d√©cente.  Mais cela n'a pas d'importance. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vz/el/21/vzel21arcsvyrco_kg_95usxziy.jpeg" alt="image"></div><br>  <i>Meme 3.</i> <br><br>  Apr√®s tout, tout a √©t√© lanc√© pour les fonctionnalit√©s qui peuvent √™tre obtenues pour sortir de l'avant-derni√®re avant de classer la couche de r√©seau neuronal.  Nous les avons test√©s sur nos t√¢ches, et partout les r√©sultats √©taient meilleurs que l'utilisation d'approches classiques pour calculer les attributs.  Par exemple, dans le probl√®me de la reconnaissance des √©motions, l'utilisation de vecteurs d nous a permis de contourner l'√©tat de l'art de 4%, et l'article correspondant a √©t√© accept√© lors de la conf√©rence FICC 2019. Cependant, la reconnaissance des √©motions est une histoire compl√®tement diff√©rente, dont nous parlerons plus tard. <br><br>  Publi√© par <b>Gregory Sterling</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">sterling239</a> , expert en apprentissage profond, Neurodata Lab. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr422635/">https://habr.com/ru/post/fr422635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr422625/index.html">Nous avons parl√© avec Troy Miles - le programmeur de "Neuromancer"</a></li>
<li><a href="../fr422627/index.html">Recherche sur le march√© du travail MongoDB et IT</a></li>
<li><a href="../fr422629/index.html">Arr√™tez de nourrir les b√ªcherons! Donnez plus de modificateurs! Champs finaux statiques paresseux. Projet d'esquisse d'objet</a></li>
<li><a href="../fr422631/index.html">Terminaux QIWI. Comment tirer le meilleur parti des technologies simples</a></li>
<li><a href="../fr422633/index.html">Comment nous avons automatis√© la surveillance du travail des employ√©s du r√©seau f√©d√©ral de stations-service</a></li>
<li><a href="../fr422637/index.html">Cadeau de geek: Protection Auto-Alkash</a></li>
<li><a href="../fr422641/index.html">Nuit polaire, pompage d'eau et coffre-fort intelligent: 5 projets √©tudiants dans le domaine de l'IoT</a></li>
<li><a href="../fr422643/index.html">Nouveaux appareils avec IFA 2018</a></li>
<li><a href="../fr422645/index.html">Quelle est l'importance de 196 884 = 196 883 + 1? Comment l'expliquer sur les doigts?</a></li>
<li><a href="../fr422649/index.html">VR multijoueur: comment l'impl√©menter?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
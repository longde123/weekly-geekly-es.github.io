<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßùüèæ ‚òÑÔ∏è üë©üèº‚Äçü§ù‚Äçüë®üèæ Keras Bewertung f√ºr TensorFlow üöí ‚è≤Ô∏è üà∫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="√úbersetzung des √úbersichtsleitfadens von Tensorflow.org. In diesem Handbuch erhalten Sie die Grundlagen f√ºr den Einstieg in Keras. Das Lesen dauert 10...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Keras Bewertung f√ºr TensorFlow</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482126/"><img src="https://habrastorage.org/webt/wz/o5/gm/wzo5gmjyybfdr1ea_lwtrhsjzvw.jpeg"><br><br>  √úbersetzung des √úbersichtsleitfadens von Tensorflow.org.  In diesem Handbuch erhalten Sie die Grundlagen f√ºr den Einstieg in Keras.  Das Lesen dauert 10 Minuten. <br><a name="habracut"></a><br><h2>  Import tf.keras </h2><br>  <code>tf.keras</code> ist eine Implementierung der TensorFlow Keras API-Spezifikation.  Dies ist eine High-Level-API zum <code>tf.data</code> und Trainieren von Modellen, die erstklassige Unterst√ºtzung f√ºr TensorFlow-spezifische Funktionen wie <i>eifrige Ausf√ºhrung</i> , <code>tf.data</code> Pipelines und <i>Estimators umfasst</i> .  <code>tf.keras</code> die Verwendung von TensorFlow ohne Einbu√üen bei Flexibilit√§t und Leistung. <br><br>  Importieren Sie zun√§chst <code>tf.keras</code> als Teil Ihres TensorFlow-Setups: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras</code> </pre> <br>  <code>tf.keras</code> kann jeden Keras-kompatiblen Code ausf√ºhren. <code>tf.keras</code> jedoch <code>tf.keras</code> : <br><br><ul><li>  Die Version von <code>tf.keras</code> in der neuesten TensorFlow-Version unterscheidet sich m√∂glicherweise von der neuesten Version von <code>keras</code> in PyPI.  Schauen Sie sich <code>tf.keras.__version__</code> . </li><li>  Wenn Sie Modellgewichte speichern, f√ºhrt <code>tf.keras</code> dies standardm√§√üig im Pr√ºfpunktformat aus.  <code>save_format='h5'</code> Parameter <code>save_format='h5'</code> , um HDF5 zu verwenden (oder f√ºgen Sie dem <code>.h5</code> Erweiterung <code>.h5</code> ). </li></ul><br><h2>  Erstellen Sie ein einfaches Modell </h2><br><h3>  Sequenzielles Modell </h3><br>  In Keras sammeln Sie <i>Layer</i> zum Erstellen von <i>Modellen</i> .  Ein Modell ist (normalerweise) ein Layerdiagramm.  Der gebr√§uchlichste Modelltyp ist der Ebenenstapel: <code>tf.keras.Sequential</code> model. <br><br>  Wir konstruieren ein einfaches, vollst√§ndig verbundenes Netzwerk (d. H. Ein mehrschichtiges Perzeptron): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers model = tf.keras.Sequential() <span class="hljs-comment"><span class="hljs-comment">#       64 : model.add(layers.Dense(64, activation='relu')) #   : model.add(layers.Dense(64, activation='relu')) #   softmax  10 : model.add(layers.Dense(10, activation='softmax'))</span></span></code> </pre> <br><h3>  Ebenen anpassen </h3><br>  Viele verschiedene <code>tf.keras.layers</code> Layer sind <code>tf.keras.layers</code> .  Die meisten von ihnen verwenden einen gemeinsamen Argumentkonstruktor: <br><br><ul><li>  <code>activation</code> : Legt die Aktivierungsfunktion f√ºr die Ebene fest.  Dieser Parameter gibt den Namen der eingebauten Funktion oder des aufgerufenen Objekts an.  Der Parameter hat keinen Standardwert. </li><li>  <code>kernel_initializer</code> und <code>bias_initializer</code> : Initialisierungsschemata, die Layer-Gewichte erzeugen (Core und Shift).  Dieser Parameter kann der Name oder das aufgerufene Objekt sein.  Der Standardinitialisierer ist <code>"Glorot uniform"</code> . </li><li>  <code>kernel_regularizer</code> und <code>bias_regularizer</code> : Regularisierungsschemata, die zu Layer-Gewichten (Core und Shift) hinzugef√ºgt wurden, z. B. L1- oder L2-Regularisierung.  Standardm√§√üig ist die Regularisierung nicht festgelegt. </li></ul><br>  Die folgenden Beispiele f√ºr Instanzen der Ebenen `tf.keras.layers.Dense` verwenden Konstruktorargumente: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    : layers.Dense(64, activation='sigmoid') # : layers.Dense(64, activation=tf.keras.activations.sigmoid) #     L1   0.01    : layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01)) #     L2   0.01    : layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01)) #        : layers.Dense(64, kernel_initializer='orthogonal') #        2.0: layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))</span></span></code> </pre> <br><h2>  Schulung und Bewertung </h2><br><h3>  Trainingsaufbau </h3><br>  Konfigurieren Sie nach dem <code>compile</code> des Modells den Lernprozess, indem Sie die <code>compile</code> aufrufen: <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ <span class="hljs-comment"><span class="hljs-comment">#     64   : layers.Dense(64, activation='relu', input_shape=(32,)), #  : layers.Dense(64, activation='relu'), #   softmax  10 : layers.Dense(10, activation='softmax')]) model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss='categorical_crossentropy', metrics=['accuracy'])</span></span></code> </pre> <br>  <code>tf.keras.Model.compile</code> akzeptiert drei wichtige Argumente: <br><br><ul><li>  <code>optimizer</code> : Dieses Objekt definiert den Trainingsablauf.  <code>tf.keras.optimizers</code> Optimiererinstanzen aus dem Modul <code>tf.keras.optimizers</code> , z. B. <code>tf.keras.optimizers.Adam</code> oder <code>tf.keras.optimizers.SGD</code> .  Wenn Sie nur die Standardoptionen verwenden m√∂chten, k√∂nnen Sie auch Optimierer mit Schl√ºsselw√∂rtern wie <code>'adam'</code> oder <code>'sgd'</code> . </li><li>  <code>loss</code> : Dies ist eine Funktion, die im Lernprozess minimiert wird.  Zu den gebr√§uchlichen Varianten geh√∂ren der Standardfehler ( <code>mse</code> ), <code>categorical_crossentropy</code> und <code>binary_crossentropy</code> .  Verlustfunktionen werden durch den Namen oder die √úbergabe des aufgerufenen Objekts aus dem Modul <code>tf.keras.losses</code> . </li><li>  <code>metrics</code> : Dient zum √úberwachen des Trainings.  Dies sind Zeichenfolgenamen oder aufgerufene Objekte aus dem Modul <code>tf.keras.metrics</code> . </li><li>  <code>run_eagerly=True</code> Sie au√üerdem sicher, dass Sie den Parameter <code>run_eagerly=True</code> an den Compiler √ºbergeben, um sicherzustellen, dass das Modell <code>run_eagerly=True</code> trainiert und ausgewertet wird </li></ul><br>  Als N√§chstes sehen wir einige Beispiele f√ºr die Modellkonfiguration f√ºr das Training: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       . model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss='mse', # mean squared error metrics=['mae']) # mean absolute error #     . model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])</span></span></code> </pre> <br><h3>  Aus NumPy-Daten lernen </h3><br>  Verwenden Sie f√ºr kleinere Datens√§tze die Speicher-Arrays von NumPy, um das Modell zu trainieren und auszuwerten.  Das Modell wird auf Trainingsdaten mit der "Fit" -Methode "trainiert": <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np data = np.random.random((<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)) labels = np.random.random((<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) model.fit(data, labels, epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>)</code> </pre> <br>  <code>tf.keras.Model.fit</code> hat drei wichtige Argumente: <br><br><ul><li>  <code>epochs</code> : Lernen gliedert sich in * Epochen *.  Die √Ñra ist eine Iteration √ºber alle Eingabedaten (dies erfolgt in kleinen Stapeln). </li><li>  <code>batch_size</code> : Beim √úbertragen von NumPy-Daten zerlegt das Modell die Daten in kleinere Bl√∂cke (Batches) und iteriert w√§hrend des Trainings √ºber diese Bl√∂cke.  Diese Nummer gibt die Gr√∂√üe jedes Datenblocks an.  Beachten Sie, dass der letzte Block m√∂glicherweise kleiner ist, wenn die Gesamtzahl der Datens√§tze nicht durch die Stapelgr√∂√üe geteilt wird. </li><li>  <code>validation_data</code> : Beim Prototyping eines Modells m√∂chten Sie dessen Leistung anhand von Validierungsdaten auf einfache Weise verfolgen.  Durch √úbergeben eines Tupels von Eingabedaten und Bezeichnungen mit diesem Argument kann das Modell die Werte der Verlustfunktion und der Metriken im Ausgabemodus f√ºr die Daten anzeigen, die am Ende jeder √Ñra √ºbertragen werden. </li></ul><br>  Hier ist ein Beispiel mit <code>validation_data</code> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np data = np.random.random((<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)) labels = np.random.random((<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) val_data = np.random.random((<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)) val_labels = np.random.random((<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) model.fit(data, labels, epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, validation_data=(val_data, val_labels))</code> </pre> <br><h3>  Schulung mit tf.data-Datens√§tzen </h3><br>  Verwenden Sie die Datasets-API, um gro√üe Datenbanken oder Schulungen auf mehreren Ger√§ten zu skalieren.  √úbergeben Sie die Instanz von "tf.data.Dataset" an die <code>fit</code> Methode: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    : dataset = tf.data.Dataset.from_tensor_slices((data, labels)) dataset = dataset.batch(32) model.fit(dataset, epochs=10)</span></span></code> </pre> <br>  Da <code>Dataset</code> Daten in <code>batch_size</code> bereitstellt, ist f√ºr diesen Code das Argument <code>batch_size</code> nicht erforderlich. <br><br>  Datens√§tze k√∂nnen auch verwendet werden, um Folgendes zu √ºberpr√ºfen: <br><br><pre> <code class="python hljs">dataset = tf.data.Dataset.from_tensor_slices((data, labels)) dataset = dataset.batch(<span class="hljs-number"><span class="hljs-number">32</span></span>) val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels)) val_dataset = val_dataset.batch(<span class="hljs-number"><span class="hljs-number">32</span></span>) model.fit(dataset, epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>, validation_data=val_dataset)</code> </pre> <br><h3>  Einsch√§tzung und Vorhersage </h3><br>  Die <code>tf.keras.Model.predict</code> <code>tf.keras.Model.evaluate</code> und <code>tf.keras.Model.predict</code> k√∂nnen die <code>tf.data.Dataset</code> NumPy und <code>tf.data.Dataset</code> . <br><br>  So k√∂nnen Sie <i>die</i> Verluste im Ausgabemodus und die Messdaten f√ºr die bereitgestellten Daten <i>absch√§tzen</i> : <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   Numpy data = np.random.random((1000, 32)) labels = np.random.random((1000, 10)) model.evaluate(data, labels, batch_size=32) #   dataset = tf.data.Dataset.from_tensor_slices((data, labels)) dataset = dataset.batch(32) model.evaluate(dataset)</span></span></code> </pre> <br>  Und so <i>k√∂nnen Sie die</i> Ausgabe der letzten Ebene im Ausgabemodus f√ºr die bereitgestellten Daten in Form eines NumPy-Arrays <i>vorhersagen</i> : <br><br><h2>  Komplexe Modelle erstellen </h2><br><h3>  Die funktionale API </h3><br>  Das <code>tf.keras.Sequential</code> Modell ist ein einfacher Ebenenstapel, mit dem Sie sich kein beliebiges Modell vorstellen k√∂nnen.  Verwenden Sie die Keras-Funktions-API, um komplexe Modelltopologien zu erstellen, z. <br><br><ul><li>  Modelle mit mehreren Eing√§ngen </li><li>  Modelle mit mehreren Ausg√§ngen, </li><li>  Modelle mit gemeinsamen Ebenen (dieselbe Ebene wird mehrmals aufgerufen), </li><li>  Modelle mit inkonsistenten Datenstr√∂men (z. B. Restbeziehungen). </li></ul><br>  Das Erstellen eines Modells mit einer funktionalen API funktioniert wie folgt: <br><br><ol><li>  Die Ebeneninstanz ist aufrufbar und gibt einen Tensor zur√ºck. </li><li>  Eingabe- und Ausgabetensoren werden verwendet, um die Instanz von <code>tf.keras.Model</code> zu bestimmen </li><li>  Dieses Modell wird genau wie das 'Sequential'-Modell trainiert. </li></ol><br>  Im folgenden Beispiel wird mithilfe der funktionalen API ein einfaches, vollst√§ndig verbundenes Netzwerk erstellt: <br><br><pre> <code class="python hljs">inputs = tf.keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>,)) <span class="hljs-comment"><span class="hljs-comment">#    #        . x = layers.Dense(64, activation='relu')(inputs) x = layers.Dense(64, activation='relu')(x) predictions = layers.Dense(10, activation='softmax')(x)</span></span></code> </pre> <br>  Erstellen Sie mit diesen Ein- und Ausg√§ngen eine Instanz des Modells. <br><br><pre> <code class="python hljs">model = tf.keras.Model(inputs=inputs, outputs=predictions) <span class="hljs-comment"><span class="hljs-comment">#     . model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001), loss='categorical_crossentropy', metrics=['accuracy']) #   5  model.fit(data, labels, batch_size=32, epochs=5)</span></span></code> </pre> <br><h3>  Unterklassen von Modellen </h3><br>  Erstellen Sie ein vollst√§ndig anpassbares Modell, indem Sie die Unterklasse <code>tf.keras.Model</code> und Ihre eigene direkte Verteilung definieren.  Erstellen Sie Ebenen in der Methode <code>__init__</code> und legen Sie sie als Attribute der Klasseninstanz fest.  Definieren Sie die direkte Weitergabe in der <code>call</code> . <br><br>  Die Unterklassifizierung eines Modells ist besonders n√ºtzlich, wenn die Eager-Ausf√ºhrung aktiviert ist, da Sie die direkte Verteilung zwingend schreiben k√∂nnen. <br><br>  Hinweis: Wenn Ihr Modell <i>immer</i> zwingend ausgef√ºhrt werden soll, k√∂nnen Sie <code>dynamic=True</code> wenn Sie den <code>super</code> aufrufen. <br><blockquote>  Schl√ºsselpunkt: Verwenden Sie die richtige API, um zu arbeiten.  Die Unterklassifizierung eines Modells bietet zwar Flexibilit√§t, Sie m√ºssen jedoch daf√ºr mit einer h√∂heren Komplexit√§t und einem h√∂heren Potenzial f√ºr benutzerdefinierte Fehler bezahlen.  Wenn m√∂glich, w√§hlen Sie die funktionale API. </blockquote>  Das folgende Beispiel zeigt ein untergeordnetes tf.keras.Model-Modell mit benutzerdefinierter Direktverteilung, die nicht unbedingt erforderlich ist: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModel</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(tf.keras.Model)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, num_classes=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> super(MyModel, self).__init__(name=<span class="hljs-string"><span class="hljs-string">'my_model'</span></span>) self.num_classes = num_classes <span class="hljs-comment"><span class="hljs-comment">#    . self.dense_1 = layers.Dense(32, activation='relu') self.dense_2 = layers.Dense(num_classes, activation='sigmoid') def call(self, inputs): #     , #      ( `__init__`). x = self.dense_1(inputs) return self.dense_2(x)</span></span></code> </pre> <br>  Erstellen Sie eine Instanz der neuen Modellklasse: <br><br><pre> <code class="python hljs">model = MyModel(num_classes=<span class="hljs-number"><span class="hljs-number">10</span></span>) <span class="hljs-comment"><span class="hljs-comment">#     . model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001), loss='categorical_crossentropy', metrics=['accuracy']) #   5 . model.fit(data, labels, batch_size=32, epochs=5)</span></span></code> </pre> <br><h3>  Benutzerdefinierte Ebenen </h3><br>  Erstellen Sie eine benutzerdefinierte Ebene, indem Sie <code>tf.keras.layers.Layer</code> unterklassifizieren und die folgenden Methoden implementieren: <br><br><ul><li>  <code>__init__</code> : <code>__init__</code> optional die Sublayer an, die in dieser Ebene verwendet werden sollen. </li><li>  * <code>build</code> : Lagengewichte erstellen.  F√ºgen Sie Gewichte mit der Methode <code>add_weight</code> </li><li>  <code>call</code> : Direktverteilung definieren. </li><li>  Optional kann der Layer durch Implementieren der <code>get_config</code> Methode und der <code>from_config</code> Klassenmethode <code>from_config</code> . </li></ul><br>  Unten sehen Sie ein Beispiel f√ºr eine Benutzerebene, die die Matrix ( <code>matmul</code> ), die der Eingabe zugef√ºhrt wird, mit der <code>matmul</code> multipliziert: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyLayer</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, output_dim, **kwargs)</span></span></span><span class="hljs-function">:</span></span> self.output_dim = output_dim super(MyLayer, self).__init__(**kwargs) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_shape)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#       . self.kernel = self.add_weight(name='kernel', shape=(input_shape[1], self.output_dim), initializer='uniform', trainable=True) def call(self, inputs): return tf.matmul(inputs, self.kernel) def get_config(self): base_config = super(MyLayer, self).get_config() base_config['output_dim'] = self.output_dim return base_config @classmethod def from_config(cls, config): return cls(**config)</span></span></code> </pre><br>  Erstellen Sie ein Modell mit Ihrer benutzerdefinierten Ebene: <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ MyLayer(<span class="hljs-number"><span class="hljs-number">10</span></span>), layers.Activation(<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)]) <span class="hljs-comment"><span class="hljs-comment">#      model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001), loss='categorical_crossentropy', metrics=['accuracy']) #   5 . model.fit(data, labels, batch_size=32, epochs=5)</span></span></code> </pre> <br><h2>  Kolbeki </h2><br>  Kolbek ist ein Objekt, das auf das Modell √ºbertragen wird, um sein Verhalten w√§hrend des Trainings anzupassen und zu erweitern.  Sie k√∂nnen Ihren eigenen benutzerdefinierten R√ºckruf schreiben oder die integrierten <code>tf.keras.callbacks</code> die <code>tf.keras.callbacks</code> umfassen: <br><br>  <code>tf.keras.callbacks.ModelCheckpoint</code> : Speichern von Modell-Haltepunkten in regelm√§√üigen Abst√§nden. <br>  <code>tf.keras.callbacks.LearningRateScheduler</code> : <code>tf.keras.callbacks.LearningRateScheduler</code> dynamisch √§ndern. <br>  <code>tf.keras.callbacks.EarlyStopping</code> : <code>tf.keras.callbacks.EarlyStopping</code> Trainings, wenn sich das Ergebnis der Validierung nicht mehr verbessert. <br>  <code>tf.keras.callbacks.TensorBoard:</code> √úberwachen des Modellverhaltens mit <br>  Tensorboard <br><br>  Um <code>tf.keras.callbacks.Callback</code> , √ºbergeben Sie es an die Methode <code>fit</code> model: <br><br><pre> <code class="python hljs">callbacks = [ <span class="hljs-comment"><span class="hljs-comment">#    `val_loss`     2  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'), #   TensorBoard   `./logs` directory tf.keras.callbacks.TensorBoard(log_dir='./logs') ] model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks, validation_data=(val_data, val_labels))</span></span></code> </pre> <br><h2>  Speichern und Wiederherstellen </h2><br><h3>  Nur Gewichtswerte speichern </h3><br>  Speichern und Laden von Modellgewichten mit <code>tf.keras.Model.save_weights</code> : <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>,)), layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)]) model.compile(optimizer=tf.keras.optimizers.Adam(<span class="hljs-number"><span class="hljs-number">0.001</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     TensorFlow Checkpoint model.save_weights('./weights/my_model') #    #        . model.load_weights('./weights/my_model')</span></span></code> </pre> <br>  Standardm√§√üig werden Modellgewichte im TensorFlow-Pr√ºfpunktformat gespeichert.  Gewichte k√∂nnen auch im Keras HDF5-Format gespeichert werden (Standardwert f√ºr die universelle Keras-Implementierung): <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     HDF5 model.save_weights('my_model.h5', save_format='h5') #    model.load_weights('my_model.h5')</span></span></code> </pre> <br><h3>  Nur Modellkonfiguration speichern </h3><br>  Die Konfiguration des Modells kann gespeichert werden - dies serialisiert die Architektur des Modells ohne Gewichte.  Eine gespeicherte Konfiguration kann dasselbe Modell wiederherstellen und initialisieren, auch ohne Code, der das urspr√ºngliche Modell definiert.  Keras unterst√ºtzt die Serialisierungsformate JSON und YAML: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     JSON json_string = model.to_json() json_string</span></span></code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> json <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pprint pprint.pprint(json.loads(json_string))</code> </pre> <br>  Modell aus JSON wiederherstellen (neu initialisieren): <br><br><pre> <code class="python hljs">fresh_model = tf.keras.models.model_from_json(json_string)</code> </pre><br>  Um das Modell in YAML zu serialisieren, muss <i>vor dem Import von TensorFlow</i> `pyyaml` installiert werden: <br><br><pre> <code class="python hljs">yaml_string = model.to_yaml() print(yaml_string)</code> </pre> <br>  Wiederherstellen eines Modells aus YAML: <br><br><pre> <code class="python hljs">fresh_model = tf.keras.models.model_from_yaml(yaml_string)</code> </pre> <br><blockquote>  Hinweis: Modelle mit Unterklassen k√∂nnen nicht serialisiert werden, da ihre Architektur durch Python-Code im Hauptteil der Methode `call` definiert wird. </blockquote><br><h3>  Speichern des gesamten Modells in einer Datei </h3><br>  Das gesamte Modell kann in einer Datei gespeichert werden, die die Werte der Gewichte, die Konfiguration des Modells und sogar die Konfiguration des Optimierers enth√§lt.  Auf diese Weise k√∂nnen Sie einen Modell-Haltepunkt festlegen und sp√§ter von genau derselben Position aus weiter trainieren, auch ohne Zugriff auf den Quellcode. <br><br><pre> <code class="plaintext hljs">#    model = tf.keras.Sequential([ layers.Dense(10, activation='softmax', input_shape=(32,)), layers.Dense(10, activation='softmax') ]) model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) model.fit(data, labels, batch_size=32, epochs=5) #      HDF5 model.save('my_model.h5') #         . model = tf.keras.models.load_model('my_model.h5')</code> </pre> <br><h2>  Eifrige Ausf√ºhrung </h2><br>  Eager Execution ist eine zwingende Programmierumgebung, die Operationen sofort ausf√ºhrt.  Dies ist f√ºr Keras nicht erforderlich, wird jedoch von <code>tf.keras</code> und ist n√ºtzlich, um Ihr Programm und das Debuggen zu √ºberpr√ºfen. <br><br>  Alle Geb√§udemodelle der `tf.keras` API sind mit Eiferausf√ºhrung kompatibel.  Obwohl die sequentiellen und funktionalen APIs verwendet werden k√∂nnen, ist eine eifrige Ausf√ºhrung besonders n√ºtzlich, wenn Sie <i>ein Modell</i> in <i>Unterklassen unterteilen</i> und <i>benutzerdefinierte Layer</i> erstellen. Bei diesen APIs m√ºssen Sie die direkte Verteilung in Form von Code schreiben (anstelle der APIs, die Modelle durch Zusammenstellen vorhandener Layer erstellen). <br><br><h2>  Verteilung </h2><br><h3>  Mehrere GPUs </h3><br>  <code>tf.keras</code> Modelle k√∂nnen mit <code>tf.distribute.Strategy</code> auf mehreren GPUs <code>tf.distribute.Strategy</code> .  Diese API bietet verteiltes Lernen √ºber mehrere GPUs mit nur geringen oder keinen √Ñnderungen an vorhandenem Code. <br><br>  Derzeit ist <code>tf.distribute.MirroredStrategy</code> einzige unterst√ºtzte Verteilungsstrategie.  <code>MirroredStrategy</code> repliziert Diagramme mit <br>  Synchrones Lernen mit All-Reduce auf einer Maschine.  Um ` <code>distribute.Strategy</code> , verschachteln Sie die Installation, den Entwurf und die Kompilierung des Optimierers des Modells <code>.scope()</code> <code>Strategy</code> <code>.scope()</code> `und trainieren Sie dann das Modell. <br><br>  Im folgenden Beispiel wird <code>tf.keras.Model</code> mehrere GPUs auf demselben Computer verteilt. <br><br>  Zun√§chst definieren wir ein Modell im Bereich einer verteilten Strategie: <br><br><pre> <code class="python hljs">strategy = tf.distribute.MirroredStrategy() <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> strategy.scope(): model = tf.keras.Sequential() model.add(layers.Dense(<span class="hljs-number"><span class="hljs-number">16</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">10</span></span>,))) model.add(layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)) optimizer = tf.keras.optimizers.SGD(<span class="hljs-number"><span class="hljs-number">0.2</span></span>) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, optimizer=optimizer) model.summary()</code> </pre> <br>  Dann trainieren wir das Modell wie gewohnt an den Daten: <br><br><pre> <code class="python hljs">x = np.random.random((<span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) y = np.random.randint(<span class="hljs-number"><span class="hljs-number">2</span></span>, size=(<span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) x = tf.cast(x, tf.float32) dataset = tf.data.Dataset.from_tensor_slices((x, y)) dataset = dataset.shuffle(buffer_size=<span class="hljs-number"><span class="hljs-number">1024</span></span>).batch(<span class="hljs-number"><span class="hljs-number">32</span></span>) model.fit(dataset, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  <i>Nach der √úberpr√ºfung wird die √úbersetzung auch auf Tensorflow.org angezeigt.</i>  <i>Wenn Sie an der √úbersetzung der Dokumentation der Tensorflow.org-Website ins Russische teilnehmen m√∂chten, wenden Sie sich bitte an eine Person oder einen Kommentar.</i>  <i>Korrekturen oder Kommentare sind willkommen.</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de482126/">https://habr.com/ru/post/de482126/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de482104/index.html">Umgang mit den Gewohnheiten programmierter Menschen</a></li>
<li><a href="../de482106/index.html">Habr Freelance 2019: Ergebnisse des Jahres</a></li>
<li><a href="../de482108/index.html">Leise Intelligenz. Methode zur Identifizierung potenzieller WEB-Schwachstellen</a></li>
<li><a href="../de482110/index.html">Linux l√§uft auf meiner Visitenkarte</a></li>
<li><a href="../de482114/index.html">Senden Sie E-Mails mit asyncio und aiohttp aus einer Django-Anwendung</a></li>
<li><a href="../de482128/index.html">gReebok erkannt. Dermatovenerologe selbst</a></li>
<li><a href="../de482130/index.html">Umfangreiche Zuweisung von Rechten an Dom√§nenbenutzer aus verschiedenen Gesamtstrukturen</a></li>
<li><a href="../de482132/index.html">Tesla Cybertruck Kopie wurde in Moskau entdeckt. Dies ist eine ... russische LADA Samara</a></li>
<li><a href="../de482134/index.html">Vergleich der Hybriden oder was die Besitzer der rum√§nischen Meze-Kopfh√∂rer f√ºr 84 990 und 239 990 Rubel erwarten</a></li>
<li><a href="../de482136/index.html">Wie kann ein Monobrand-Projekt in die TOP-Liste aufgenommen werden, indem Aggregatoren und interne Dienste von Suchmaschinen besiegt werden?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
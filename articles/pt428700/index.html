<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèæ‚Äçü§ù‚Äçüë®üèø üëÜüèΩ üïπÔ∏è Como o aprendizado de m√°quina na YouDo entra em produ√ß√£o. Palestra em Yandex üïö üèûÔ∏è ü§ôüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Em grandes servi√ßos, resolver um problema usando o aprendizado de m√°quina significa fazer apenas parte do trabalho. A incorpora√ß√£o de modelos de ML n√£...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como o aprendizado de m√°quina na YouDo entra em produ√ß√£o. Palestra em Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/428700/">  Em grandes servi√ßos, resolver um problema usando o aprendizado de m√°quina significa fazer apenas parte do trabalho.  A incorpora√ß√£o de modelos de ML n√£o √© t√£o f√°cil e a cria√ß√£o de processos de CI / CD em torno deles √© ainda mais dif√≠cil.  Na confer√™ncia Yandex <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">‚ÄúData &amp; Science: the application program‚Äù,</a> Adam Eldarov <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">,</a> chefe de ci√™ncia de dados da YouDo, falou sobre como gerenciar o ciclo de vida dos modelos, configurar processos de reciclagem e reciclagem, desenvolver microsservi√ßos escal√°veis ‚Äã‚Äãe muito mais. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/k1Rp0A2NVdk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - Vamos come√ßar com a introdu√ß√£o.  H√° um cientista de dados, ele escreve algum c√≥digo no Jupyter Notebook, faz engenharia de recursos, valida√ß√£o cruzada, treina modelos de modelos.  A velocidade est√° crescendo. <a name="habracut"></a><br><br><img src="https://habrastorage.org/webt/fr/sg/9x/frsg9xiv8sslwj5gritig9jx4xc.jpeg"><br><br>  Mas, em algum momento, ele entende: para agregar valor √† empresa, ele deve anexar a solu√ß√£o em algum lugar da produ√ß√£o, a alguma produ√ß√£o m√≠tica, o que nos causa muitos problemas.  O laptop que vimos em produ√ß√£o na maioria dos casos n√£o pode ser enviado.  E surge a pergunta: como enviar esse c√≥digo dentro do laptop para um determinado servi√ßo.  Na maioria dos casos, voc√™ precisa escrever um servi√ßo que tenha uma API.  Ou eles se comunicam atrav√©s do PubSub, atrav√©s de filas. <br><br><img src="https://habrastorage.org/webt/lj/al/h0/ljalh0b3jiosapstldusxdueenk.jpeg"><br><br>  Quando fazemos recomenda√ß√µes, geralmente precisamos treinar modelos e trein√°-los novamente.  Esse processo deve ser monitorado.  Nesse caso, √© preciso sempre verificar com testes o pr√≥prio c√≥digo e os modelos, para que em um momento nosso modelo n√£o fique louco e nem sempre comece a prever zero.  Tamb√©m precisa ser verificado em usu√°rios reais atrav√©s de testes AB - o que fizemos melhor ou pelo menos n√£o pior. <br><br>  Como abordamos o c√≥digo?  N√≥s temos o GitLab.  Todo o nosso c√≥digo √© dividido em muitas pequenas bibliotecas que resolvem um problema espec√≠fico de dom√≠nio.  Ao mesmo tempo, √© um projeto GitLab separado, controle de vers√£o Git e o modelo de ramifica√ß√£o GitFlow.  Usamos coisas como ganchos de pr√©-confirma√ß√£o, para que voc√™ n√£o possa confirmar c√≥digos que n√£o atendam √†s nossas verifica√ß√µes de teste estat√≠stico.  E os pr√≥prios testes, testes de unidade.  Usamos a abordagem de teste baseada em propriedades para eles. <br><br><img src="https://habrastorage.org/webt/l8/bm/3y/l8bm3y6qju0gpmusipaz_1dvatk.jpeg"><br><br>  Geralmente, quando voc√™ escreve testes, quer dizer que possui uma fun√ß√£o de teste e os argumentos que cria com as m√£os, alguns exemplos e quais valores sua fun√ß√£o de teste retorna.  Isso √© inconveniente.  O c√≥digo √© inflado, muitos em princ√≠pio s√£o pregui√ßosos demais para escrev√™-lo.  Como resultado, temos um monte de c√≥digo descoberto por testes.  O teste baseado em propriedades implica que todos os seus argumentos t√™m uma certa distribui√ß√£o.  Vamos fazer a fase e, muitas vezes, provar todos os nossos argumentos dessas distribui√ß√µes, chamar a fun√ß√£o sob teste com esses argumentos e verificar se certas propriedades s√£o o resultado dessa fun√ß√£o.  Como resultado, temos muito menos c√≥digo e, ao mesmo tempo, existem muitos outros testes. <br><br><img src="https://habrastorage.org/webt/6i/x6/pc/6ix6pclinddxyed-lumlmodfbdk.jpeg"><br><br>  O que √© o GitFlow?  Este √© um modelo de ramifica√ß√£o, o que implica que voc√™ tem duas ramifica√ß√µes principais - develop e master, onde o c√≥digo de produ√ß√£o pronto est√° localizado, e todo o desenvolvimento √© realizado na branch de desenvolvimento, na qual todos os novos recursos s√£o extra√≠dos de brunches de recursos.  Ou seja, cada recurso √© um novo brunch de recursos, enquanto o brunch de recursos deve durar pouco e para sempre - tamb√©m coberto por altern√¢ncia de recursos.  Em seguida, fazemos um lan√ßamento, do dev lan√ßamos as altera√ß√µes para o master e colocamos a tag de vers√£o da nossa biblioteca ou servi√ßo. <br><br><img src="https://habrastorage.org/webt/ne/a7/5h/nea75hpkozbra0cmpe1q-iheh8q.jpeg"><br><br>  Estamos desenvolvendo, vendo algum recurso, enviando-o para o GitLab, criando uma solicita√ß√£o de mesclagem do brunch de recursos para as donzelas.  Os gatilhos funcionam, executam testes, se estiver tudo bem, podemos congel√°-lo.  Mas n√£o somos n√≥s que estamos segurando, mas algu√©m da equipe.  Ele revisa o c√≥digo e, assim, aumenta o fator de barramento.  Esta se√ß√£o de c√≥digo j√° √© conhecida por duas pessoas.  Como resultado, se algu√©m √© atropelado por um √¥nibus, algu√©m j√° sabe o que est√° fazendo. <br><br><img src="https://habrastorage.org/webt/vg/fn/69/vgfn69mplj3hogej0adwyqe4cxe.jpeg"><br><br>  A integra√ß√£o cont√≠nua para bibliotecas geralmente se parece com testes para altera√ß√µes.  E se o liberarmos, ele tamb√©m ser√° publicado no servidor PyPI privado do nosso pacote. <br><br><img src="https://habrastorage.org/webt/b5/cy/fr/b5cyfrfqzlecbvb53clsbhklvp4.jpeg"><br><br>  Al√©m disso, podemos colet√°-lo em gasodutos.  Para isso, usamos a biblioteca Luigi.  Ele trabalha com uma entidade como tarefa, que possui uma sa√≠da, na qual o artefato criado durante a execu√ß√£o da tarefa √© salvo.  H√° um par√¢metro de tarefa que parametriza a l√≥gica de neg√≥cios que ele executa, identifica a tarefa e sua sa√≠da.  Ao mesmo tempo, as tarefas sempre t√™m requisitos que outras tarefas apresentam.  Quando executamos algum tipo de tarefa, todas as suas depend√™ncias s√£o verificadas atrav√©s da verifica√ß√£o de suas sa√≠das.  Se a sa√≠da existir, nossa depend√™ncia n√£o ser√° iniciada.  Se o artefato estiver ausente em algum armazenamento, ele ser√° iniciado.  Isso forma um pipeline, um gr√°fico c√≠clico direcionado. <br><br><img src="https://habrastorage.org/webt/4k/xg/_j/4kxg_j0yykqghkej-ikbbo7y_oq.jpeg"><br><br>  Todos os par√¢metros identificam a l√≥gica de neg√≥cios.  Ao fazer isso, eles identificam o artefato.  √â sempre uma data com alguma granularidade, sensibilidade ou uma semana, dia, hora, tr√™s horas.  Se treinamos algum modelo, Luigi Taska sempre tem hiperpar√¢metros dessa tarefa, eles vazam para o artefato que estamos produzindo, os hiperpar√¢metros s√£o refletidos no nome do artefato.  Portanto, essencialmente vers√£o de todos os conjuntos de dados intermedi√°rios e artefatos finais, e eles nunca s√£o substitu√≠dos, sempre aumentam apenas o armazenamento, e o armazenamento √© HDFS e S3 privado, que v√™ artefatos finais de alguns pickles, modelos ou qualquer outra coisa .  E todo o c√≥digo do pipeline est√° no projeto de servi√ßo no reposit√≥rio ao qual se relaciona. <br><br><img src="https://habrastorage.org/webt/o6/a1/h_/o6a1h_rv7c9-vtggkki_vmbe7iq.jpeg"><br><br>  Ele precisa ser corrigido de alguma forma.  A pilha HashiCorp vem em socorro, usamos o Terraform para declarar a infraestrutura na forma de c√≥digo, o Vault para gerenciar segredos, todas as senhas, apar√™ncias no banco de dados.  O Consul √© um servi√ßo de descoberta distribu√≠do pelo armazenamento de valores-chave que voc√™ pode usar para configurar.  E tamb√©m o Consul faz verifica√ß√µes de sa√∫de de seus n√≥s e seus servi√ßos, verificando sua disponibilidade. <br><br>  E - Nomad.  √© um sistema de orquestra√ß√£o, distribuindo seus servi√ßos e algum tipo de trabalho em lotes. <br><br><img src="https://habrastorage.org/webt/cy/zb/rd/cyzbrd9uibdyssgdczrckszrpwk.jpeg"><br><br>  Como usamos isso?  H√° um pipeline Luigi, vamos empacot√°-lo no cont√™iner do Docker, colocar o bast√£o ou o trabalho em lotes peri√≥dico no Nomad.  Trabalho em lote - isso √© algo conclu√≠do e encerrado e, se tudo der certo - tudo est√° bem, podemos inici√°-lo manualmente novamente.  Mas se algo der errado, o Nomad tenta novamente at√© esgotar a tentativa ou n√£o termina com sucesso. <br><br>  Trabalho em lote peri√≥dico - √© exatamente o mesmo, funciona apenas em uma programa√ß√£o. <br><br>  H√° um problema.  Quando implantamos um cont√™iner em qualquer sistema de orquestra√ß√£o, precisamos indicar quanta mem√≥ria esse cont√™iner, CPU ou mem√≥ria precisa.  Se tivermos um pipeline que funcione por tr√™s horas, duas horas disso consumir√£o 10 GB de RAM, 1 hora - 70 GB.  Se excedermos o limite que lhe damos, o daemon do Docker chega e mata os Dockers e (nrzb.) [02:26:13] N√£o queremos ficar sem mem√≥ria constantemente, portanto, precisamos especificar todos os 70 GB, o pico de carga de mem√≥ria.  Mas aqui est√° o problema: todos os 70 GB por tr√™s horas ser√£o alocados e inacess√≠veis a qualquer outro trabalho. <br><br>  Portanto, seguimos o outro caminho.  Todo o nosso pipeline Luigi n√£o inicia nenhum tipo de l√≥gica de neg√≥cios, apenas lan√ßa um conjunto de dados no Nomad, o chamado trabalho parametrizado.  De fato, este √© um an√°logo das fun√ß√µes do Servidor (NRZB.) [02:26:39], AVS Lambda, quem sabe.  Quando criamos uma biblioteca, implantamos por meio do CI todo o nosso c√≥digo na forma de trabalhos parametrizados, ou seja, um cont√™iner com alguns par√¢metros.  Suponha, Lite JBM Classifier, que tenha um par√¢metro para o caminho para os dados de entrada para treinamento, hiperpar√¢metros dos modelos e o caminho para os artefatos de sa√≠da.  Tudo isso √© registrado no Nomad e, a partir do pipeline do Luigi, podemos puxar todos esses trabalhos do Nomad por meio da API e, ao mesmo tempo, o Luigi garante que n√£o execute a mesma tarefa muitas vezes. <br><br>  Suponha que tenhamos o mesmo processamento de texto.  Existem 10 modelos condicionais e n√£o queremos reiniciar o processamento de texto sempre.  Ele come√ßar√° apenas uma vez e, ao mesmo tempo, haver√° um resultado final sempre que for reutilizado.  E, ao mesmo tempo, tudo isso funciona de maneira distribu√≠da, podemos executar uma pesquisa de grade gigante em um grande aglomerado, apenas ter tempo para despejar o ferro. <br><br><img src="https://habrastorage.org/webt/ig/bg/fv/igbgfv9ciptp0thzljej2u1pa-a.jpeg"><br><br>  Temos um artefato, precisamos de alguma forma organizar isso na forma de um servi√ßo.  Os servi√ßos exp√µem uma API HTTP ou se comunicam atrav√©s de filas.  Neste exemplo, esta √© a API HTTP, o exemplo mais simples.  Ao mesmo tempo, a comunica√ß√£o com o servi√ßo ou nosso servi√ßo se comunica com outros servi√ßos por meio da API HTTP JSON, valida o esquema JSON.  O pr√≥prio servi√ßo sempre descreve um objeto JSON na documenta√ß√£o para sua API e o esquema desse objeto.  Mas nem todos os campos do objeto JSON s√£o sempre necess√°rios; portanto, os contratos orientados ao consumidor s√£o validados; esse esquema √© validado; a comunica√ß√£o ocorre por meio de disjuntor padr√£o para impedir que nosso sistema distribu√≠do falhe devido a falhas em cascata. <br><br>  Ao mesmo tempo, o servi√ßo deve definir uma verifica√ß√£o de integridade HTTP, para que o Consul possa entrar e verificar a disponibilidade desse servi√ßo.  Ao mesmo tempo, o Nomad pode fazer com que haja um servi√ßo para tr√™s verifica√ß√µes de hello seguidas, e pode reiniciar o servi√ßo para ajud√°-lo.  O servi√ßo grava todos os seus logs no formato JSON.  Usamos o driver de log JSON e a pilha Elastics, em cada momento o FileBit simplesmente pega todos os logs JSON, lan√ßa-os no cache de log, de onde eles chegam ao Elastic, podemos analisar o KBan.  Ao mesmo tempo, n√£o usamos logs para coleta de m√©tricas e constru√ß√£o de pain√©is, √© ineficiente, usamos o sistema de entrada do Prometheus para isso, temos um processo para criar modelos para cada servi√ßo de painel e podemos analisar m√©tricas t√©cnicas produzidas pelo servi√ßo. <br><br>  Al√©m disso, se algo der errado, chegam alertas, mas na maioria dos casos isso n√£o √© suficiente.  Sentry vem em nosso aux√≠lio, isso √© uma coisa para an√°lise de incidentes.  De fato, capturamos todos os logs de n√≠vel de erro pelo manipulador do Sentry e os enviamos para o Sentry.  E h√° um rastreamento detalhado, todas as informa√ß√µes sobre em que ambiente o servi√ßo estava, qual vers√£o, quais fun√ß√µes foram chamadas por quais argumentos e quais vari√°veis ‚Äã‚Äãnesse escopo estavam com quais valores.  Todas as configura√ß√µes, tudo isso √© vis√≠vel, e ajuda muito a entender rapidamente o que aconteceu e corrigir o erro. <br><br><img src="https://habrastorage.org/webt/yx/oj/rl/yxojrltjutx_s1_tll0fa9xajrc.jpeg"><br><br>  Como resultado, o servi√ßo se parece com isso.  Projeto GitLab separado, c√≥digo de pipeline, c√≥digo de teste, c√≥digo de servi√ßo em si, v√°rias configura√ß√µes diferentes, Nomad, configura√ß√µes de CI, documenta√ß√£o de API, ganchos de confirma√ß√£o e muito mais. <br><br><img src="https://habrastorage.org/webt/_b/8q/f_/_b8qf_bf1ninu3_2gafa6qmm9by.jpeg"><br><br>  CI, quando fazemos um release, fazemos da seguinte maneira: constru√≠mos um cont√™iner, executamos testes, lan√ßamos um cluster em um palco, executamos um contrato de teste para nosso servi√ßo l√°, conduzimos testes de estresse para garantir que nossa previs√£o n√£o seja muito lenta e mantenha a carga que pensamos .  Se tudo estiver correto, implantaremos esse servi√ßo na produ√ß√£o.  E existem duas maneiras: podemos implantar o pipeline, se o trabalho peri√≥dico em lote, ele trabalha em algum lugar em segundo plano e produz artefatos, ou com as canetas acionamos algum pipeline, ele treina algum modelo, depois entendemos que est√° tudo bem e implantar o servi√ßo. <br><br><img src="https://habrastorage.org/webt/ee/uo/uv/eeuouvuw2tpqohzhcwtz1x-qjje.jpeg"><br><br>  O que mais acontece neste caso?  Eu disse que no desenvolvimento de brunches de recursos existe um paradigma que alterna recursos.  De uma maneira boa, voc√™ precisa cobrir os recursos com algumas altern√¢ncias, apenas para reduzir um recurso na batalha se algo der errado.  Em seguida, podemos coletar todos os recursos nos trens de libera√ß√£o e, mesmo que os recursos n√£o estejam conclu√≠dos, podemos implant√°-los.  Apenas a altern√¢ncia de recursos ser√° desativada.  Como somos todos cientistas de dados, tamb√©m queremos fazer testes de AV.  Digamos que substitu√≠mos o LightGBM pelo CatBoost.  Queremos verificar isso, mas, ao mesmo tempo, o teste AV √© gerenciado com refer√™ncia a algum ID do usu√°rio.  A altern√¢ncia de recurso est√° vinculada ao ID do usu√°rio e, portanto, passa no teste AV.  Precisamos verificar essas m√©tricas aqui. <br><br>  Todos os servi√ßos s√£o implantados no Nomad.  Temos dois clusters de produ√ß√£o Nomad - um para trabalho em lote e outro para servi√ßos. <br><br><img src="https://habrastorage.org/webt/xc/ku/mm/xckummfxsskmztnet3fnzklweny.jpeg"><br><br>  Eles enviam todos os seus eventos de neg√≥cios para Kafka.  De l√°, podemos busc√°-los.  Em ess√™ncia, √© uma arquitetura de cordeiro.  Podemos assinar o HDFS com alguns servi√ßos, fazer an√°lises em tempo real e, ao mesmo tempo, todos utilizamos o ClickHouse e criamos pain√©is para analisar todos os eventos de neg√≥cios de nossos servi√ßos.  Podemos analisar testes AV, qualquer que seja. <br><br><img src="https://habrastorage.org/webt/e9/_z/g1/e9_zg1a4j-ycqi6c0ghuzmphd0c.jpeg"><br><br>  E se n√£o alteramos o c√≥digo, n√£o use as altern√¢ncias de recursos.  Come√ßamos a trabalhar com algumas canetas em algum oleoduto, ele nos ensinou um novo modelo.  Temos um novo caminho para isso.  Apenas mudamos o caminho do Nomad para o modelo na configura√ß√£o, lan√ßamos um novo servi√ßo e aqui o paradigma Canary Deployment vem em nosso aux√≠lio, est√° dispon√≠vel no Nomad a partir da caixa. <br><br>  Temos a vers√£o atual do servi√ßo em tr√™s inst√¢ncias.  Dizemos que queremos tr√™s can√°rios - mais tr√™s r√©plicas de novas vers√µes s√£o implantadas sem reduzir as antigas.  Como resultado, o tr√°fego come√ßa a se dividir em duas partes.  Parte do tr√°fego cai em novas vers√µes de servi√ßos.  Todos os servi√ßos enviam todos os eventos de neg√≥cios para Kafka.  Como resultado, podemos analisar m√©tricas em tempo real. <br><br>  Se estiver tudo bem, podemos dizer que est√° tudo bem.  Ao implantar, o Nomad continuar√°, desligue suavemente todas as vers√µes antigas e dimensione as novas. <br><br>  Esse modelo √© ruim, pois se precisarmos vincular o roteamento de vers√£o por alguma entidade, Item de Usu√°rio.  Esse esquema n√£o funciona, porque o tr√°fego √© equilibrado atrav√©s de round-robin.  Portanto, seguimos o caminho a seguir e cortamos o servi√ßo em duas partes. <br><br><img src="https://habrastorage.org/webt/mr/s4/hf/mrs4hf-bhaqlntomrhwjah_0qms.jpeg"><br><br>  Essa √© a camada Gateway e a camada Trabalhadores.  O cliente se comunica via HTTP com a camada Gateway, toda a l√≥gica de sele√ß√£o de vers√£o e balanceamento de tr√°fego est√° no Gateway.  Ao mesmo tempo, todas as tarefas Limitadas de E / S necess√°rias para concluir o predicado tamb√©m est√£o localizadas no Gateway.  Suponha que obtivemos um ID do usu√°rio no predicado na solicita√ß√£o, que precisamos enriquecer com algumas informa√ß√µes.  Devemos puxar outros microsservi√ßos e coletar todas as informa√ß√µes, recursos ou bases.  Como resultado, tudo isso acontece no gateway.  Ele se comunica com os trabalhadores que est√£o apenas no modelo e faz uma coisa - uma previs√£o.  Entrada e sa√≠da. <br><br>  Por√©m, como dividimos nosso servi√ßo em duas partes, a sobrecarga apareceu devido a uma chamada de rede remota.  Como nivel√°-lo?  A estrutura JRPC do Google, a RPC do Google, que roda em cima do HTTP2, vem em socorro.  Voc√™ pode usar multiplexa√ß√£o e compacta√ß√£o.  JPRC usa protobuff.  Este √© um protocolo bin√°rio fortemente tipado que possui serializa√ß√£o e desserializa√ß√£o r√°pidas. <br><br>  Como resultado, tamb√©m temos a capacidade de escalar independentemente o Gateway e o trabalhador.  Digamos que n√£o possamos manter uma certa quantidade de conex√µes HTTP abertas.  Ok, dimensionando o Gateway.  Nossa previs√£o √© muito lenta, n√£o temos tempo para manter a carga - ok, dimensionamos trabalhadores.  Essa abordagem se encaixa muito bem com bandidos com v√°rios bra√ßos.  No Gateway, como toda a l√≥gica do balanceamento de tr√°fego √© implementada, ele pode acessar microsservi√ßos externos e obter todas as estat√≠sticas de cada vers√£o, al√©m de tomar decis√µes sobre como equilibrar o tr√°fego.  Digamos usando o Thompson Sampling. <br><br><img src="https://habrastorage.org/webt/wh/nf/3e/whnf3envxyd5biwjhjftw4yjlsu.jpeg"><br><br>  Tudo bem, os modelos foram de alguma forma treinados, n√≥s os registramos na configura√ß√£o do Nomad.  Mas e se houver um modelo de recomenda√ß√µes que j√° tenha tempo para se tornar obsoleto durante o treinamento e precisarmos trein√°-las constantemente?  Tudo √© feito da mesma maneira: por meio de trabalhos em lotes peri√≥dicos, algum artefato √© produzido - digamos, a cada tr√™s horas.  Ao mesmo tempo, no final de seu trabalho, o pipeline define o caminho para o novo modelo no Consul.  Este √© o armazenamento de valor-chave, usado para configura√ß√£o.  O Nomad pode configurar as configura√ß√µes.  Exista uma vari√°vel de ambiente com base nos valores do Consul de armazenamento de valores-chave.  Ele monitora as altera√ß√µes e, assim que um novo caminho aparece, decide que dois caminhos podem ser seguidos.  Ele baixa o artefato por meio de um novo link, coloca o cont√™iner de servi√ßo no Docker usando volume e reinicializa - e faz tudo isso para que n√£o haja tempo de inatividade, ou seja, lentamente, individualmente.  Ou ele renderiza uma nova configura√ß√£o e relata o servi√ßo para ele.  Ou o pr√≥prio servi√ßo o detecta - e dentro de si pode, independentemente, atualizar ao vivo sua modelka.  Isso √© tudo, obrigado. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt428700/">https://habr.com/ru/post/pt428700/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt428688/index.html">Configurando o ambiente de trabalho no Docker para o aplicativo yii-framework</a></li>
<li><a href="../pt428690/index.html">Como ensinar sua namorada a programar se voc√™ n√£o √© professora, mas ela acredita em voc√™</a></li>
<li><a href="../pt428694/index.html">A hist√≥ria de um √∫nico jogo ou estrat√©gia 4x que come√ßou h√° 20 anos e ainda est√° vivo</a></li>
<li><a href="../pt428696/index.html">Coment√°rios do canal Telegram</a></li>
<li><a href="../pt428698/index.html">The Elusive Space Pirate: esconda-se na geladeira dos policiais, derrote a guerra dos dr√≥ides e cuspa nos olhos de Sauron</a></li>
<li><a href="../pt428702/index.html">Ecos de magia em guarda das ci√™ncias exatas</a></li>
<li><a href="../pt428704/index.html">Prologue Workouts</a></li>
<li><a href="../pt428706/index.html">Crypt Bugs</a></li>
<li><a href="../pt428708/index.html">Nata√ß√£o f√°cil com Kubernetes (banda desenhada)</a></li>
<li><a href="../pt428710/index.html">Usando e restaurando baterias de chumbo minha experi√™ncia</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
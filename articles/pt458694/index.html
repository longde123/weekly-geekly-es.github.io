<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîá üëáüèº üèåÔ∏è O Python GIL est√° realmente morto? üë©üèø‚Äçüåæ ‚ò†Ô∏è üßìüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√° pessoal! Na pr√≥xima segunda-feira, as aulas come√ßar√£o no novo grupo do curso Python Developer , o que significa que temos tempo para publicar outr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>O Python GIL est√° realmente morto?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/458694/">  Ol√° pessoal!  Na pr√≥xima segunda-feira, as aulas come√ßar√£o no novo grupo do curso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Python Developer</a> , o que significa que temos tempo para publicar outro material interessante, o que faremos agora.  Boa leitura. <br><br><img src="https://habrastorage.org/webt/jb/cq/wj/jbcqwjrmctxos6x_uzhptngfd9y.png"><br><br>  Em 2003, a Intel lan√ßou o novo processador Pentium 4 "HT".  Este processador com overclock para 3GHz e suportou a tecnologia hyper-threading. <a name="habracut"></a><br><br><img src="https://habrastorage.org/webt/9d/z1/es/9dz1esccmgms80liftaeolcqiui.jpeg"><br><br>  Nos anos seguintes, Intel e AMD lutaram para alcan√ßar o melhor desempenho de desktop, aumentando a velocidade do barramento, o tamanho do cache L2 e reduzindo o tamanho da matriz para minimizar a lat√™ncia.  Em 2004, o modelo HT com frequ√™ncia de 3 GHz foi substitu√≠do pelo modelo 580 Prescott com overclock para 4 GHz. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/AmwzUrL3vMc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Parecia que, para avan√ßar, era apenas necess√°rio aumentar a frequ√™ncia do rel√≥gio; no entanto, os novos processadores sofriam de alto consumo de energia e dissipa√ß√£o de calor. <br><br>  Seu processador de mesa oferece 4 GHz hoje?  √â improv√°vel, uma vez que o caminho para melhorar o desempenho acabou por aumentar a velocidade do barramento e aumentar o n√∫mero de n√∫cleos.  Em 2006, o Intel Core 2 substituiu o Pentium 4 e teve uma velocidade de clock muito menor. <br><br>  Al√©m de liberar processadores com v√°rios n√∫cleos para um amplo p√∫blico de usu√°rios, outra coisa aconteceu em 2006.  Python 2.5 finalmente viu a luz!  Ele j√° veio com uma vers√£o beta da palavra-chave with, que todos voc√™s conhecem e adoram. <br><br>  O Python 2.5 teve uma grande limita√ß√£o no uso do Intel Core 2 ou AMD Athlon X2. <br>  Foi um GIL. <br><br><h2>  O que √© um GIL? </h2><br>  GIL (Global Interpreter Lock) √© um valor booleano no interpretador Python protegido por um mutex.  O bloqueio √© usado no loop de c√°lculo principal do bytecode do CPython para determinar qual encadeamento est√° atualmente executando instru√ß√µes. <br><br>  O CPython suporta o uso de v√°rios threads em um √∫nico int√©rprete, mas os threads devem solicitar acesso ao GIL para executar opera√ß√µes de baixo n√≠vel.  Por sua vez, isso significa que os desenvolvedores do Python podem usar c√≥digo ass√≠ncrono, multithreading e n√£o precisam mais se preocupar em bloquear nenhuma vari√°vel ou falha no n√≠vel do processador durante conflitos. <br><br>  O GIL simplifica a programa√ß√£o Python multithread. <br><br><img src="https://habrastorage.org/webt/lg/yz/3h/lgyz3hoq07fkumzp4axuuiqxplk.gif"><br><br>  O GIL tamb√©m nos diz que, embora o CPython possa ser multiencadeado, apenas um encadeamento por vez pode ser executado.  Isso significa que seu processador quad-core faz algo assim (com exce√ß√£o da tela azul, espero). <br><br>  A vers√£o atual do GIL <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">foi escrita em 2009</a> para oferecer suporte a fun√ß√µes ass√≠ncronas e permaneceu inalterada, mesmo ap√≥s v√°rias tentativas de remov√™-lo em princ√≠pio ou alterar os requisitos para ele. <br><br>  Qualquer sugest√£o para remover o GIL foi justificada pelo fato de que o bloqueio global do int√©rprete n√£o deve prejudicar o desempenho do c√≥digo de thread √∫nico.  Qualquer pessoa que tentou ativar o hyperthreading em 2003 entender√° o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">que estou falando</a> . <br><br><h2>  Abandono de Gil no CPython </h2><br>  Se voc√™ realmente deseja paralelizar o c√≥digo no CPython, precisar√° usar v√°rios processos. <br><br>  No CPython 2.6, o m√≥dulo de <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">multiprocessamento</a></i> foi adicionado √† biblioteca padr√£o.  O multiprocessamento mascara a gera√ß√£o de processos no CPython (cada processo com seu pr√≥prio GIL). <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> multiprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Process <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">f</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'hello'</span></span>, name <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: p = Process(target=f, args=(<span class="hljs-string"><span class="hljs-string">'bob'</span></span>,)) p.start() p.join()</code> </pre> <br><br>  Os processos s√£o criados, os comandos s√£o enviados a eles usando m√≥dulos compilados e fun√ß√µes Python e, em seguida, s√£o reunidos novamente ao processo principal. <br><br>  O multiprocessamento tamb√©m suporta o uso de vari√°veis ‚Äã‚Äãatrav√©s de uma fila ou canal.  Ela tem um objeto de bloqueio, que √© usado para bloquear objetos no processo principal e gravar de outros processos. <br><br>  O multiprocessamento tem uma grande desvantagem.  Ele carrega uma carga computacional significativa, o que afeta o tempo de processamento e o uso de mem√≥ria.  O tempo de inicializa√ß√£o do CPython, mesmo sem site, √© de 100 a 200 ms (consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://hackernoon.com/which-is-the-fastest-version-of-python-2ae7c61a6b2b</a> para saber mais). <br><br>  Como resultado, voc√™ pode ter um c√≥digo paralelo no CPython, mas ainda precisa planejar cuidadosamente o trabalho de processos de longa execu√ß√£o que compartilham v√°rios objetos. <br><br>  Outra alternativa pode ser usar um pacote de terceiros como o Twisted. <br><br><h2>  PEP554 e a morte de GIL? </h2><br>  Ent√£o, deixe-me lembr√°-lo de que o multithreading no CPython √© simples, mas na realidade n√£o √© paralelismo, mas o multiprocessamento √© paralelo, mas implica uma sobrecarga significativa. <br><br>  <i>E se houver uma maneira melhor?</i> <br>  A chave para ignorar o GIL est√° no nome, o bloqueio global do int√©rprete faz parte do estado global do int√©rprete.  Os processos CPython podem ter v√°rios int√©rpretes e, portanto, v√°rios bloqueios, no entanto, essa fun√ß√£o raramente √© usada, pois o acesso a ele √© apenas por meio da C-API. <br><br>  Um dos recursos do CPython 3.8 √© o PEP554, uma implementa√ß√£o de sub-int√©rpretes e APIs com um novo m√≥dulo de <code>interpreters</code> na biblioteca padr√£o. <br><br>  Isso permite criar v√°rios int√©rpretes a partir do Python em um √∫nico processo.  Outra inova√ß√£o do Python 3.8 √© que todos os int√©rpretes ter√£o seu pr√≥prio GIL. <br><br><img src="https://habrastorage.org/webt/bq/nc/m2/bqncm29jhm-ytakgrlkasbfe_6y.png"><br><br>  Como o estado do int√©rprete cont√©m uma regi√£o alocada na mem√≥ria, uma cole√ß√£o de todos os ponteiros para objetos Python (local e global), os subinterpretadores no PEP554 n√£o podem acessar as vari√°veis ‚Äã‚Äãglobais de outros int√©rpretes. <br><br>  Como o multiprocessamento, os int√©rpretes que compartilham objetos consistem em serializ√°-los e usar o formul√°rio IPC (rede, disco ou mem√≥ria compartilhada).  Existem v√°rias maneiras de serializar objetos no Python, por exemplo, o m√≥dulo <code>marshal</code> , o m√≥dulo <code>pickle</code> ou m√©todos mais padronizados, como <code>json</code> ou <code>simplexml</code> .  Cada um deles tem seus pr√≥s e contras, e todos oferecem uma carga de computa√ß√£o. <br><br>  Seria melhor ter um espa√ßo de mem√≥ria comum que possa ser alterado e controlado por um processo espec√≠fico.  Assim, os objetos podem ser enviados pelo int√©rprete principal e recebidos por outro int√©rprete.  Este ser√° o espa√ßo de mem√≥ria gerenciado para procurar ponteiros PyObject, que todo int√©rprete pode acessar, enquanto o processo principal gerenciar√° os bloqueios. <br><br><img src="https://habrastorage.org/webt/be/ww/d8/bewwd8ju-3akmyhs7ujq7xmyliy.png"><br><br>  Uma API para isso ainda est√° sendo desenvolvida, mas provavelmente ser√° algo como isto: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> _xxsubinterpreters <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> interpreters <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> threading <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> textwrap <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tw <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> marshal <span class="hljs-comment"><span class="hljs-comment"># Create a sub-interpreter interpid = interpreters.create() # If you had a function that generated some data arry = list(range(0,100)) # Create a channel channel_id = interpreters.channel_create() # Pre-populate the interpreter with a module interpreters.run_string(interpid, "import marshal; import _xxsubinterpreters as interpreters") # Define a def run(interpid, channel_id): interpreters.run_string(interpid, tw.dedent(""" arry_raw = interpreters.channel_recv(channel_id) arry = marshal.loads(arry_raw) result = [1,2,3,4,5] # where you would do some calculating result_raw = marshal.dumps(result) interpreters.channel_send(channel_id, result_raw) """), shared=dict( channel_id=channel_id ), ) inp = marshal.dumps(arry) interpreters.channel_send(channel_id, inp) # Run inside a thread t = threading.Thread(target=run, args=(interpid, channel_id)) t.start() # Sub interpreter will process. Feel free to do anything else now. output = interpreters.channel_recv(channel_id) interpreters.channel_release(channel_id) output_arry = marshal.loads(output) print(output_arry)</span></span></code> </pre> <br><br>  Este exemplo usa NumPy.  A matriz numpy √© enviada pelo canal, √© serializada usando o m√≥dulo <code>marshal</code> , em seguida, o subinterpretador processa os dados (em um GIL separado); portanto, pode haver um problema de paralelismo associado √† CPU, ideal para subinterpretadores. <br><br><h4>  <b>Parece ineficiente</b> </h4><br>  O m√≥dulo <code>marshal</code> funciona muito r√°pido, mas n√£o t√£o r√°pido quanto compartilhar objetos diretamente da mem√≥ria. <br><br>  O PEP574 apresenta um novo protocolo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pickle (v5)</a> que suporta a capacidade de processar buffers de mem√≥ria separadamente do restante do fluxo de pickle.  Para objetos de dados grandes, a serializa√ß√£o de todos de uma s√≥ vez e a desserializa√ß√£o de um subinterpretador adicionar√° muita sobrecarga. <br><br>  A nova API pode ser implementada (puramente hipoteticamente) da seguinte maneira: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> _xxsubinterpreters <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> interpreters <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> threading <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> textwrap <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tw <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pickle <span class="hljs-comment"><span class="hljs-comment"># Create a sub-interpreter interpid = interpreters.create() # If you had a function that generated a numpy array arry = [5,4,3,2,1] # Create a channel channel_id = interpreters.channel_create() # Pre-populate the interpreter with a module interpreters.run_string(interpid, "import pickle; import _xxsubinterpreters as interpreters") buffers=[] # Define a def run(interpid, channel_id): interpreters.run_string(interpid, tw.dedent(""" arry_raw = interpreters.channel_recv(channel_id) arry = pickle.loads(arry_raw) print(f"Got: {arry}") result = arry[::-1] result_raw = pickle.dumps(result, protocol=5) interpreters.channel_send(channel_id, result_raw) """), shared=dict( channel_id=channel_id, ), ) input = pickle.dumps(arry, protocol=5, buffer_callback=buffers.append) interpreters.channel_send(channel_id, input) # Run inside a thread t = threading.Thread(target=run, args=(interpid, channel_id)) t.start() # Sub interpreter will process. Feel free to do anything else now. output = interpreters.channel_recv(channel_id) interpreters.channel_release(channel_id) output_arry = pickle.loads(output) print(f"Got back: {output_arry}")</span></span></code> </pre> <br><h4>  <b>Parece padronizado</b> </h4><br>  Em ess√™ncia, este exemplo √© baseado no uso da API de subinterpretadores de baixo n√≠vel.  Se voc√™ n√£o usou a biblioteca de <code>multiprocessing</code> , alguns problemas lhe parecer√£o familiares.  N√£o √© t√£o simples quanto o processamento de fluxo, voc√™ n√£o pode simplesmente, digamos, executar esta fun√ß√£o com uma lista de dados de entrada em int√©rpretes separados (por enquanto). <br><br>  Assim que esse PEP se fundir com outros, acho que veremos v√°rias novas APIs no PyPi. <br><br><h3>  Quanta sobrecarga o subinterpretador possui? </h3><br>  <b>Resposta curta:</b> mais que um fluxo, menos que um processo. <br>  <b>Resposta longa: o</b> int√©rprete tem seu pr√≥prio estado, portanto, ser√° necess√°rio clonar e inicializar o seguinte, apesar do PEP554 simplificar a cria√ß√£o de subinterpretadores: <br><br><ul><li>  M√≥dulos no <code>importlib</code> <code>__main__</code> e <code>importlib</code> ; </li><li>  O conte√∫do do dicion√°rio <code>sys</code> ; </li><li>  Fun√ß√µes <code>print()</code> ( <code>print()</code> , <code>assert</code> , etc.); </li><li>  C√≥rregos; </li><li>  Configura√ß√£o do kernel. </li></ul><br><br>  A configura√ß√£o do kernel pode ser facilmente clonada da mem√≥ria, mas a importa√ß√£o de m√≥dulos n√£o √© t√£o simples.  A importa√ß√£o de m√≥dulos no Python √© lenta, portanto, se criar um subinterpretador significa importar m√≥dulos para um espa√ßo de nome diferente a cada vez, os benef√≠cios s√£o reduzidos. <br><br><h3>  E o ass√≠ncio? </h3><br>  A implementa√ß√£o existente do <code>asyncio</code> eventos <code>asyncio</code> na biblioteca padr√£o cria quadros de pilha para avalia√ß√£o e tamb√©m <code>asyncio</code> estado no int√©rprete principal (e, portanto, compartilha o GIL). <br><br>  Ap√≥s combinar o PEP554, provavelmente j√° no Python 3.9, uma implementa√ß√£o alternativa do loop de eventos pode ser usada (embora ningu√©m tenha feito isso ainda), que executa m√©todos ass√≠ncronos em subinterpretadores em paralelo. <br><br><h3>  Parece legal, me envolva tamb√©m! </h3><br>  Bem, na verdade n√£o. <br>  Como o CPython est√° em execu√ß√£o no mesmo int√©rprete h√° tanto tempo, muitas partes da base de c√≥digo usam "Runtime State" em vez de "Interpreter State", portanto, se o PEP554 fosse introduzido agora, ainda haveria muitos problemas. <br><br>  Por exemplo, o estado do coletor de lixo (nas vers√µes 3.7 &lt;) pertence ao tempo de execu√ß√£o. <br><br>  Nas mudan√ßas durante os sprints do PyCon, o estado do coletor de lixo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">come√ßou a passar</a> para o int√©rprete, de modo que cada subinterpretador tivesse seu pr√≥prio coletor de lixo (como deveria ser). <br><br>  Outro problema √© que existem algumas vari√°veis ‚Äã‚Äã"globais" que permaneceram na base de c√≥digo do CPython junto com muitas extens√µes em C. Portanto, quando as pessoas come√ßaram a paralelizar seu c√≥digo de repente, vimos alguns problemas. <br><br>  Outro problema √© que os descritores de arquivo pertencem ao processo, portanto, se voc√™ tiver um arquivo aberto para grava√ß√£o em um int√©rprete, o subinterpretador n√£o poder√° acessar esse arquivo (sem altera√ß√µes adicionais no CPython). <br><br>  Em resumo, ainda existem muitos problemas que precisam ser resolvidos. <br><br><h2>  Conclus√£o: O GIL √© mais verdadeiro? </h2><br>  O GIL continuar√° sendo usado para aplicativos de thread √∫nico.  Portanto, mesmo ao seguir o PEP554, seu c√≥digo de thread √∫nico repentinamente n√£o ficar√° paralelo. <br>  Se voc√™ deseja escrever c√≥digo paralelo no Python 3.8, voc√™ ter√° problemas de paraleliza√ß√£o associados ao processador, mas este tamb√©m √© um ticket para o futuro! <br><br><h2>  Quando? </h2><br>  O Pickle v5 e o compartilhamento de mem√≥ria para multiprocessamento provavelmente estar√£o no Python 3.8 (outubro de 2019), e os sub-int√©rpretes aparecer√£o entre as vers√µes 3.8 e 3.9. <br>  Se voc√™ deseja brincar com os exemplos apresentados, criei um ramo separado com todo o c√≥digo necess√°rio: <a href="">https://github.com/tonybaloney/cpython/tree/subinterpreters.</a> <br><br>  O que voc√™ acha disso?  Escreva seus coment√°rios e at√© o curso. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt458694/">https://habr.com/ru/post/pt458694/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt458684/index.html">ICANN remove o limite de pre√ßo para o dom√≠nio .org - por que a comunidade de TI √© contra e o que acontecer√° a seguir</a></li>
<li><a href="../pt458686/index.html">@Pythonetc junho de 2019</a></li>
<li><a href="../pt458688/index.html">Dicas e truques do meu canal de telegrama @pythonetc, junho de 2019</a></li>
<li><a href="../pt458690/index.html">Automatize-o! Como aprimoramos os testes de integra√ß√£o</a></li>
<li><a href="../pt458692/index.html">M√¥nada ‚ÄúTalvez‚Äù atrav√©s de ass√≠ncrono / espera em C # (sem tarefas!)</a></li>
<li><a href="../pt458696/index.html">Texturiza√ß√£o ou o que voc√™ precisa saber para se tornar um Artista de Superf√≠cie. Parte 3. PBR e materiais</a></li>
<li><a href="../pt458698/index.html">O caminho da paz e o caminho da guerra em projetos de TI</a></li>
<li><a href="../pt458702/index.html">C√£es de tren√≥: o que voc√™ precisa saber sobre eles e como eles foram trazidos</a></li>
<li><a href="../pt458704/index.html">Implementa√ß√£o de um sistema DLP no exemplo do varejo</a></li>
<li><a href="../pt458706/index.html">Os Gopniks est√£o agora em mercados estrangeiros, ou "Por que √© t√£o dif√≠cil encontrar um programador normal?"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
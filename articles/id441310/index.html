<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👏 🌬️ 🤚🏻 Pengalaman dalam membangun infrastruktur pada arsitektur layanan mikro 📎 🍂 🍷</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Selama setahun terakhir, ada begitu banyak publikasi tentang layanan mikro sehingga akan membuang waktu untuk mengatakan apa itu dan mengapa, sehingga...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pengalaman dalam membangun infrastruktur pada arsitektur layanan mikro</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441310/"><p><img src="https://habrastorage.org/webt/vn/kb/qn/vnkbqnbwlqbmim3tn1ipiy_rhri.jpeg"></p><br><p>  Selama setahun terakhir, ada begitu banyak publikasi tentang layanan mikro sehingga akan membuang waktu untuk mengatakan apa itu dan mengapa, sehingga sisa diskusi akan fokus pada pertanyaan tentang bagaimana menerapkan arsitektur ini dan mengapa itu dihadapi persis dan masalah apa yang dihadapi. </p><br><p>  Kami memiliki masalah besar di bank kecil: 3 monolit python dihubungkan oleh sejumlah besar interaksi RPC sinkron dengan volume besar warisan.  Untuk setidaknya sebagian menyelesaikan semua masalah yang muncul dalam kasus ini, diputuskan untuk beralih ke arsitektur layanan-mikro.  Tetapi sebelum memutuskan langkah seperti itu, Anda perlu menjawab 3 pertanyaan utama: </p><br><ul><li>  Bagaimana memecah monolit menjadi layanan-layanan mikro dan kriteria apa yang harus diikuti. </li><li>  Bagaimana layanan microser berinteraksi? </li><li>  Bagaimana cara memonitor? </li></ul><br><p>  Sebenarnya jawaban singkat untuk pertanyaan ini akan dikhususkan untuk artikel ini. </p><a name="habracut"></a><br><h2 id="kak-razbit-monolit-na-mikroservisy-i-kakimi-kriteriyami-sleduet-pri-etom-rukovodstvovatsya">  Bagaimana memecah monolit menjadi layanan-layanan mikro dan kriteria apa yang harus diikuti. </h2><br><p>  Pertanyaan yang tampaknya sederhana ini akhirnya menentukan seluruh arsitektur masa depan. </p><br><p>  Kami adalah bank, sehingga seluruh sistem berputar di sekitar operasi dengan keuangan dan berbagai hal tambahan.  Tentu saja mungkin untuk mentransfer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">transaksi ACID keuangan ke sistem terdistribusi dengan sagas</a> , tetapi dalam kasus umum itu sangat sulit.  Jadi kami mengembangkan aturan berikut: </p><br><ul><li>  Mematuhi S dari SOLID untuk layanan microser </li><li>  Transaksi harus sepenuhnya dilakukan dalam microservice - tidak ada transaksi terdistribusi pada kerusakan database </li><li>  Agar berfungsi, layanan mikro dalam membutuhkan informasi dari basis datanya sendiri atau dari permintaan </li><li>  Cobalah untuk memastikan kebersihan (dalam arti bahasa fungsional) untuk layanan microser </li></ul><br><p>  Secara alami, pada saat yang sama tidak mungkin untuk sepenuhnya memuaskan mereka, tetapi bahkan implementasi parsial sangat menyederhanakan pengembangan. </p><br><h2 id="kakim-obrazom-mikroservisy-budut-vzaimodeystvovat">  Bagaimana layanan microser berinteraksi? </h2><br><p>  Ada banyak opsi, tetapi pada akhirnya, semuanya dapat diabstraksi dengan sederhana "pesan pertukaran layanan microser," tetapi jika Anda menerapkan protokol sinkron (misalnya, RPC melalui REST), maka sebagian besar kerugian dari monolith akan tetap ada, tetapi keuntungan dari layanan microser hampir tidak akan muncul.  Jadi solusi yang jelas adalah mengambil broker pesan dan memulai.  Memilih antara RabbitMQ dan Kafka menentukan yang terakhir, dan inilah alasannya: </p><br><ul><li>  Kafka lebih sederhana dan menyediakan model pesan tunggal - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Terbitkan - berlangganan</a> </li><li>  Relatif mudah untuk mendapatkan data dari Kafka untuk kedua kalinya.  Ini sangat nyaman untuk debugging atau memperbaiki bug selama pemrosesan yang salah, serta untuk pemantauan dan pencatatan. </li><li>  Cara yang jelas dan sederhana untuk meningkatkan skala layanan: menambahkan partisi ke topik, meluncurkan lebih banyak pelanggan - sisanya akan dilakukan oleh kafka. </li></ul><br><p>  Selain itu saya ingin menarik perhatian pada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">perbandingan yang sangat berkualitas tinggi dan terperinci</a> . </p><br><p>  Antrian di kafka + asynchrony memungkinkan kita untuk: </p><br><ul><li>  Matikan semua microservice untuk pembaruan secara singkat tanpa konsekuensi nyata untuk sisanya </li><li>  Matikan semua layanan untuk waktu yang lama dan tidak repot dengan pemulihan data.  Sebagai contoh, microservice fiskalisasi baru-baru ini jatuh.  Itu diperbaiki setelah 2 jam, dia mengambil akun mentah dari Kafka dan memproses semuanya.  Itu tidak perlu, seperti sebelumnya, untuk mengembalikan apa yang seharusnya terjadi di sana dan secara manual melakukan log HTTP dan tabel terpisah dalam database. </li><li>  Jalankan versi uji layanan pada data saat ini dari penjualan dan bandingkan hasil pemrosesan mereka dengan versi layanan pada penjualan. </li></ul><br><p>  Sebagai sistem serialisasi data, kami memilih AVRO, mengapa - dijelaskan dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel terpisah</a> . </p><br><p>  Tetapi terlepas dari metode serialisasi yang dipilih, penting untuk memahami bagaimana protokol akan diperbarui.  Meskipun AVRO mendukung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Resolusi Skema,</a> kami tidak menggunakan ini dan memutuskan secara administratif: </p><br><ul><li>  Data dalam topik ditulis dan dibaca hanya melalui AVRO, nama topik sesuai dengan nama skema (dan Confluent memiliki <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pendekatan yang berbeda</a> - mereka menulis skema ID AVRO dari registri dalam byte pesan yang tinggi, sehingga mereka dapat memiliki berbagai jenis pesan dalam satu topik </li><li>  Jika Anda perlu menambah atau mengubah data, skema baru dibuat dengan topik baru di kafka, setelah itu semua produsen beralih ke topik baru, dan diikuti oleh pelanggan </li></ul><br><p>  Kami menyimpan sendiri sirkuit AVRO dalam submit git dan terhubung ke semua proyek kafka.  Mereka memutuskan untuk tidak menerapkan daftar skema yang terpusat. </p><br><p>  PS: Kolega <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">membuat opsi opensource tetapi hanya dengan skema JSON bukan AVRO</a> . </p><br><h3 id="nekotorye-tonkosti">  Beberapa kehalusan </h3><br><h4 id="kazhdyy-podpischik-poluchaet-vse-soobscheniya-iz-topika">  Setiap pelanggan menerima semua pesan dari topik </h4><br><p>  Ini adalah kekhususan model interaksi Terbitkan - berlangganan - saat berlangganan suatu topik, pelanggan akan menerima semuanya.  Akibatnya, jika layanan hanya membutuhkan beberapa pesan, ia harus menyaringnya.  Jika ini menjadi masalah, dimungkinkan untuk membuat router layanan terpisah yang akan menjabarkan pesan dalam beberapa topik yang berbeda, sehingga mengimplementasikan bagian dari fungsi RabbitMQ yang tidak ada dalam kafka.  Sekarang kami memiliki satu pelanggan pada python dalam satu proses thread sekitar 7-5 ribu pesan per detik, tetapi jika Anda menjalankan dari melalui PyPy, maka kecepatannya tumbuh menjadi 11-15 ribu / detik. </p><br><h4 id="ogranichenie-vremeni-zhizni-ukazatelya-v-topike">  Batasi masa pakai pointer dalam suatu topik </h4><br><p>  Dalam pengaturan kafka ada parameter yang membatasi waktu kafka "mengingat" di mana pembaca berhenti - defaultnya adalah 2 hari.  Akan menyenangkan untuk menaikkannya menjadi seminggu, sehingga jika masalah muncul pada hari libur dan 2 hari tidak terselesaikan, maka ini tidak akan menyebabkan hilangnya posisi dalam topik. </p><br><h4 id="ogranichenie-vremeni-na-podtverzhdenie-chteniya">  Baca Batas Waktu Konfirmasi </h4><br><p>  Jika pembaca Kafka tidak mengkonfirmasi pembacaan dalam 30 detik (parameter yang dapat dikonfigurasi), maka broker percaya bahwa ada kesalahan dan terjadi kesalahan ketika mencoba mengkonfirmasi pembacaan.  Untuk menghindari hal ini, saat memproses pesan untuk waktu yang lama, kami mengirim konfirmasi baca tanpa memindahkan pointer. </p><br><h4 id="graf-svyazey-poluchaetsya-trudnym-dlya-vospriyatiya">  Grafik koneksi sulit dipahami. </h4><br><p>  Jika Anda benar-benar menggambar semua hubungan dalam graphviz, maka ada landak dari kiamat tradisional untuk layanan microser dengan puluhan koneksi dalam satu node.  Setidaknya agar entah bagaimana membuatnya (grafik koneksi) dapat dibaca, kami menyetujui notasi berikut: microservices - oval, topik kafka - persegi panjang.  Jadi, pada satu grafik, dimungkinkan untuk menampilkan fakta interaksi dan tipenya.  Namun, sayangnya, ini tidak menjadi jauh lebih baik.  Jadi pertanyaan ini masih terbuka. </p><br><p><img src="https://habrastorage.org/webt/fy/lw/qf/fylwqfrc5nspiw_ci170mvntzku.png"></p><br><h2 id="kak-osuschestvlyat-monitoring">  Bagaimana cara memonitor? </h2><br><p>  Bahkan sebagai bagian dari monolith, kami memiliki log dalam file dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Sentry.</a> Tetapi ketika kami beralih ke interaksi melalui Kafka dan disebarkan ke k8, log dipindahkan ke ElasticSearch dan, oleh karena itu, kami pertama-tama memantau membaca log pelanggan di Elastic.  Tanpa log - tidak ada pekerjaan. <br>  Setelah itu, mereka mulai menggunakan Prometheus dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pengekspor kafka</a> sedikit mengubah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dasbornya</a> : <a href="">https://github.com/kkirsanov/articles/blob/master/2019-habr-kafka/dashboard.json</a> </p><br><p>  Hasilnya, kami mendapatkan gambar-gambar ini: <br><img src="https://habrastorage.org/webt/lg/bg/k5/lgbgk5zs7fzl_3hrhork-ybejjw.png"><br>  Anda dapat melihat layanan mana yang berhenti memproses pesan mana. </p><br><p>  Selain itu, semua pesan dari topik utama (transaksi pembayaran, pemberitahuan dari mitra, dll.) Disalin ke InfluxDB, yang diatur dalam grafana yang sama.  Jadi, kita tidak hanya bisa merekam fakta lewat pesan, tetapi juga membuat berbagai sampel sesuai konten.  Jadi, jawaban untuk pertanyaan seperti "berapa waktu tunda rata-rata untuk respons dari layanan" atau "Apakah arus transaksi sangat berbeda hari ini dari kemarin di toko ini" selalu ada. </p><br><p>  Juga, untuk menyederhanakan analisis insiden, kami menggunakan pendekatan berikut: setiap layanan, saat memproses pesan, menambahkannya dengan informasi meta yang berisi UUID yang dikeluarkan ketika sistem menampilkan serangkaian catatan jenis: </p><br><ul><li>  nama layanan </li><li>  UUID dari proses pemrosesan dalam microservice ini </li><li>  proses mulai cap waktu </li><li>  waktu proses </li><li>  set tag </li></ul><br><p>  Akibatnya, saat pesan melewati grafik komputasi, pesan diperkaya dengan informasi tentang jalur yang ditempuh pada grafik.  Ternyata analog zipkin / opentracing untuk MQ, yang memungkinkan menerima pesan untuk dengan mudah mengembalikan jalurnya pada grafik.  Ini mendapatkan nilai khusus dalam kasus-kasus ketika siklus muncul pada grafik.  Ingat contoh layanan kecil, bagian pembayarannya hanya 0,0001%. Dengan menganalisis meta-informasi dalam pesan, ia dapat menentukan apakah mereka adalah pemrakarsa pembayaran, tanpa menghubungi database untuk verifikasi. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id441310/">https://habr.com/ru/post/id441310/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id441296/index.html">OpenStreetMap Part Medium: Visualisasi Data Tersembunyi</a></li>
<li><a href="../id441298/index.html">Cisco Live EMEA 2019: mengubah sepeda IT lama menjadi BMW di awan</a></li>
<li><a href="../id441300/index.html">Anakronisme, krisis, struktur organisasi yang buruk: tiga rasa sakit dari kepemimpinan tim dalam suatu perusahaan</a></li>
<li><a href="../id441302/index.html">AMA dengan Habr (Sambungan langsung dengan TM, v 6.0)</a></li>
<li><a href="../id441306/index.html">Cara mendapatkan penawaran di Moskow dalam 1 hari untuk insinyur QA (dan biayanya mahal untuk tinggal di sini)</a></li>
<li><a href="../id441312/index.html">Dunia kebisingan Perlin yang kabur</a></li>
<li><a href="../id441314/index.html">PyCon Russia 2019: jawaban atas pertanyaan kunci</a></li>
<li><a href="../id441316/index.html">Memilih earbud nirkabel sejati: 6 bulan kemudian ...</a></li>
<li><a href="../id441318/index.html">Ekstensi Kode Visual Studio Populer</a></li>
<li><a href="../id441320/index.html">Menjinakkan dukungan teknis Anda</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
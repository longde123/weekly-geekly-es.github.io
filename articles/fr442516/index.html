<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🍚 👨🏾‍🤝‍👨🏼 📅 Pandas Guide to Big Data Analysis 👨🏿‍🚀 🤙🏽 🤸🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Lorsque vous utilisez la bibliothèque pandas pour analyser de petits ensembles de données, dont la taille ne dépasse pas 100 mégaoctets, les performan...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pandas Guide to Big Data Analysis</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/442516/"> Lorsque vous utilisez la bibliothèque pandas pour analyser de petits ensembles de données, dont la taille ne dépasse pas 100 mégaoctets, les performances deviennent rarement un problème.  Mais en ce qui concerne l'étude des ensembles de données, dont la taille peut atteindre plusieurs gigaoctets, les problèmes de performances peuvent entraîner une augmentation significative de la durée de l'analyse des données et peuvent même entraîner l'impossibilité d'effectuer une analyse en raison d'un manque de mémoire. <br><br>  Alors que des outils comme Spark peuvent traiter efficacement des ensembles de données volumineux (de centaines de gigaoctets à plusieurs téraoctets), afin d'utiliser pleinement leurs capacités, vous avez généralement besoin d'un matériel assez puissant et coûteux.  Et, par rapport aux pandas, ils ne diffèrent pas par de riches ensembles d'outils pour le nettoyage, la recherche et l'analyse des données de haute qualité.  Pour les ensembles de données de taille moyenne, il est préférable d'essayer d'utiliser les pandas plus efficacement, plutôt que de passer à d'autres outils. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/gd/jg/60/gdjg60abxgti2otxocpd0ct2uci.jpeg"></a> <br><br>  Dans l'article, dont nous publions la traduction aujourd'hui, nous parlerons des particularités du travail avec la mémoire lors de l'utilisation de pandas, et comment réduire simplement la consommation de mémoire de près de 90% en sélectionnant simplement les types de données appropriés stockés dans les colonnes des structures de données de table du <code>DataFrame</code> . <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Travailler avec des données sur des jeux de baseball</font> </h2><br>  Nous travaillerons avec des données sur les matchs de baseball de la Major League collectées sur 130 ans et extraites de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Retrosheet</a> . <br><br>  Initialement, ces données étaient présentées sous la forme de 127 fichiers CSV, mais nous les avons combinées en un seul ensemble de données à l'aide de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">csvkit</a> et ajouté, comme première ligne du tableau résultant, une ligne avec les noms des colonnes.  Si vous le souhaitez, vous pouvez télécharger <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">notre version de</a> ces données et l'expérimenter en lisant l'article. <br><br>  Commençons par importer un jeu de données et jetons un œil à ses cinq premières lignes.  Vous pouvez les trouver dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce</a> tableau, sur le <code>   </code> feuille de <code>   </code> . <br><br><pre> <code class="plaintext hljs">import pandas as pd gl = pd.read_csv('game_logs.csv') gl.head()</code> </pre> <br>  Vous trouverez ci-dessous des informations sur les colonnes les plus importantes du tableau contenant ces données.  Si vous souhaitez lire les explications de toutes les colonnes, vous trouverez ici un dictionnaire de données pour l'ensemble des données. <br><br><ul><li>  <code>date</code> - Date de la partie. </li><li>  <code>v_name</code> - Le nom de l'équipe invitée. </li><li>  <code>v_league</code> - Ligue de l'équipe visiteuse. </li><li>  <code>h_name</code> - Le nom de l'équipe locale. </li><li>  <code>h_league</code> - La ligue de l'équipe à domicile. </li><li>  <code>v_score</code> - Points de l'équipe à l'extérieur. </li><li>  <code>h_score</code> - Points de l'équipe à domicile. </li><li>  <code>v_line_score</code> - Un résumé des points de l'équipe invitée, par exemple - <code>010000(10)00</code> . </li><li>  <code>h_line_score</code> - Un résumé des points de l'équipe à domicile, par exemple - <code>010000(10)0X</code> . </li><li>  <code>park_id</code> - L'identifiant du champ sur lequel le jeu a été joué. </li><li>  <code>attendance</code> - Le nombre de téléspectateurs. </li></ul><br>  Afin de trouver des informations générales sur l'objet <code>DataFrame</code> , vous pouvez utiliser la méthode <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DataFrame.info ()</a> .  Grâce à cette méthode, vous pouvez en apprendre davantage sur la taille d'un objet, sur les types de données et sur l'utilisation de la mémoire. <br><br>  Par défaut, les pandas, pour gagner du temps, <code>DataFrame</code> informations approximatives sur l'utilisation de la mémoire d'un <code>DataFrame</code> .  Nous souhaitons des informations précises, nous allons donc définir le paramètre <code>memory_usage</code> sur <code>'deep'</code> . <br><br><pre> <code class="plaintext hljs">gl.info(memory_usage='deep')</code> </pre> <br>  Voici les informations que nous avons réussi à obtenir: <br><br><pre> <code class="plaintext hljs">&lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 171907 entries, 0 to 171906 Columns: 161 entries, date to acquisition_info dtypes: float64(77), int64(6), object(78) memory usage: 861.6 MB</code> </pre> <br>  Il s'est avéré que nous avons 171 907 lignes et 161 colonnes.  La bibliothèque pandas a détecté automatiquement les types de données.  Il y a 83 colonnes avec des données numériques et 78 colonnes avec des objets.  Les colonnes d'objets sont utilisées pour stocker des données de chaîne et dans les cas où la colonne contient des données de différents types. <br><br>  Maintenant, afin de mieux comprendre comment vous pouvez optimiser l'utilisation de la mémoire avec ce <code>DataFrame</code> , parlons de la façon dont les pandas stockent les données en mémoire. <br><br><h2>  <font color="#3AC1EF">Vue interne d'un DataFrame</font> </h2><br>  À l'intérieur des pandas, les colonnes de données sont regroupées en blocs avec des valeurs du même type.  Voici un exemple de la façon dont les 12 premières colonnes d'un <code>DataFrame</code> sont stockées dans des pandas. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d35/c70/c63/d35c70c635289a5cecc520c58e662e9a.png"></div><br>  <i><font color="#999999">Représentation interne de différents types de données dans les pandas</font></i> <br><br>  Vous pouvez remarquer que les blocs ne stockent pas les informations de nom de colonne.  Cela est dû au fait que les blocs sont optimisés pour stocker les valeurs disponibles dans les cellules du tableau de l'objet <code>DataFrame</code> .  La classe <code>BlockManager</code> est chargée de stocker des informations sur la correspondance entre les index de ligne et de colonne de l'ensemble de données et ce qui est stocké dans des blocs du même type de données.  Il joue le rôle d'une API qui donne accès aux données de base.  Lorsque nous lisons, <code>DataFrame</code> valeurs, la classe <code>DataFrame</code> interagit avec la classe <code>BlockManager</code> pour convertir nos requêtes en appels de fonction et de méthode. <br><br>  Chaque type de données a une classe spécialisée dans le module <code>pandas.core.internals</code> .  Par exemple, pandas utilise la classe <code>ObjectBlock</code> pour représenter des blocs contenant des colonnes de chaînes et la classe <code>FloatBlock</code> pour représenter des blocs contenant des colonnes contenant <code>FloatBlock</code> nombres à virgule flottante.  Pour les blocs représentant des valeurs numériques qui ressemblent à des entiers ou à des nombres à virgule flottante, pandas combine les colonnes et les stocke en tant que <code>ndarray</code> données <code>ndarray</code> la bibliothèque NumPy.  Cette structure de données est basée sur le tableau C, les valeurs sont stockées dans un bloc de mémoire continu.  Grâce à ce schéma de stockage des données, l'accès aux fragments de données est très rapide. <br><br>  Étant donné que les données de différents types sont stockées séparément, nous examinons l'utilisation de la mémoire de différents types de données.  Commençons par l'utilisation moyenne de la mémoire pour différents types de données. <br><br><pre> <code class="plaintext hljs">for dtype in ['float','int','object']:   selected_dtype = gl.select_dtypes(include=[dtype])   mean_usage_b = selected_dtype.memory_usage(deep=True).mean()   mean_usage_mb = mean_usage_b / 1024 ** 2   print("Average memory usage for {} columns: {:03.2f} MB".format(dtype,mean_usage_mb))</code> </pre> <br>  En conséquence, il s'avère que les indicateurs moyens d'utilisation de la mémoire pour des données de différents types ressemblent à ceci: <br><br><pre> <code class="plaintext hljs">Average memory usage for float columns: 1.29 MB Average memory usage for int columns: 1.12 MB Average memory usage for object columns: 9.53 MB</code> </pre> <br>  Ces informations nous font comprendre que la majeure partie de la mémoire est consacrée à 78 colonnes stockant des valeurs d'objet.  Nous en parlerons plus tard, mais réfléchissons maintenant à l'amélioration de l'utilisation de la mémoire avec des colonnes qui stockent des données numériques. <br><br><h2>  <font color="#3AC1EF">Sous-types</font> </h2><br>  Comme nous l'avons déjà dit, les pandas représentent des valeurs numériques sous <code>ndarray</code> structures de données <code>ndarray</code> NumPy et les stockent dans des blocs de mémoire contigus.  Ce modèle de stockage de données vous permet d'économiser de la mémoire et d'accéder rapidement aux valeurs.  Étant donné que les pandas représentent chaque valeur du même type en utilisant le même nombre d'octets et <code>ndarray</code> structures <code>ndarray</code> stockent des informations sur le nombre de valeurs, les pandas peuvent <code>ndarray</code> rapidement et avec précision la quantité de mémoire consommée par les colonnes stockant des valeurs numériques. <br><br>  De nombreux types de données dans les pandas ont de nombreux sous-types qui peuvent utiliser moins d'octets pour représenter chaque valeur.  Par exemple, le type <code>float</code> a les sous-types <code>float16</code> , <code>float32</code> et <code>float64</code> .  Le nombre dans le nom du type indique le nombre de bits que le sous-type utilise pour représenter les valeurs.  Par exemple, dans les sous-types juste énumérés, 2, 4, 8 et 16 octets sont utilisés respectivement pour le stockage des données.  Le tableau suivant montre les sous-types des types de données les plus couramment utilisés chez les pandas. <br><table><tbody><tr><td>  <sup>Utilisation de la mémoire, octets</sup> <sup><br></sup> </td><td>  <sup>Numéro à virgule flottante</sup> <sup><br></sup> </td><td>  <sup>Entier</sup> <sup><br></sup> </td><td>  <sup>Entier non signé</sup> <sup><br></sup> </td><td>  <sup>Date et heure</sup> <sup><br></sup> </td><td>  <sup>Valeur booléenne</sup> <sup><br></sup> </td><td width="75">  <sup>Objet</sup> <sup><br></sup> </td></tr><tr><td>  <sup>1</sup> <sup><br></sup> </td><td></td><td>  <sup>int8</sup> <sup><br></sup> </td><td>  <sup>uint8</sup> <sup><br></sup> </td><td></td><td>  <sup>bool</sup> <sup><br></sup> </td><td></td></tr><tr><td>  <sup>2</sup> <sup><br></sup> </td><td>  <sup>float16</sup> <sup><br></sup> </td><td>  <sup>int16</sup> <sup><br></sup> </td><td>  <sup>uint16</sup> <sup><br></sup> </td><td></td><td></td><td></td></tr><tr><td>  <sup>4</sup> <sup><br></sup> </td><td>  <sup>float32</sup> <sup><br></sup> </td><td>  <sup>int32</sup> <sup><br></sup> </td><td>  <sup>uint32</sup> <sup><br></sup> </td><td></td><td></td><td></td></tr><tr><td>  <sup>8</sup> <sup><br></sup> </td><td>  <sup>float64</sup> <sup><br></sup> </td><td>  <sup>int64</sup> <sup><br></sup> </td><td>  <sup>uint64</sup> <sup><br></sup> </td><td>  <sup>datetime64</sup> <sup><br></sup> </td><td></td><td></td></tr><tr><td>  <sup>Capacité de mémoire variable</sup> <sup><br></sup> </td><td></td><td></td><td></td><td></td><td></td><td>  <sup>objet</sup> <sup><br></sup> </td></tr></tbody></table><br>  Une valeur de type <code>int8</code> utilise 1 octet (8 bits) pour stocker un nombre et peut représenter 256 valeurs binaires (puissance de 2 à 8).  Cela signifie que ce sous-type peut être utilisé pour stocker des valeurs dans la plage de -128 à 127 (dont 0). <br><br>  Pour vérifier les valeurs minimales et maximales appropriées pour le stockage à l'aide de chaque sous-type entier, vous pouvez utiliser la méthode <code>numpy.iinfo()</code> .  Prenons un exemple: <br><br><pre> <code class="plaintext hljs">import numpy as np int_types = ["uint8", "int8", "int16"] for it in int_types:   print(np.iinfo(it))</code> </pre> <br>  En exécutant ce code, nous obtenons les données suivantes: <br><br><pre> <code class="plaintext hljs">Machine parameters for uint8 --------------------------------------------------------------- min = 0 max = 255 --------------------------------------------------------------- Machine parameters for int8 --------------------------------------------------------------- min = -128 max = 127 --------------------------------------------------------------- Machine parameters for int16 --------------------------------------------------------------- min = -32768 max = 32767 ---------------------------------------------------------------</code> </pre> <br>  Ici, vous pouvez faire attention à la différence entre les types <code>uint</code> (entier non signé) et <code>int</code> (entier signé).  Les deux types ont la même capacité, mais lorsqu'ils stockent uniquement des valeurs positives dans des colonnes, les types non signés permettent une utilisation plus efficace de la mémoire. <br><br><h2>  <font color="#3AC1EF">Optimisation du stockage des données numériques à l'aide de sous-types</font> </h2><br>  La fonction <code>pd.to_numeric()</code> peut être utilisée pour convertir des types numériques.  Pour sélectionner des colonnes entières, nous utilisons la méthode <code>DataFrame.select_dtypes()</code> , puis nous les optimisons et comparons l'utilisation de la mémoire avant et après l'optimisation. <br><br><pre> <code class="plaintext hljs">#     ,   , #   ,      . def mem_usage(pandas_obj):   if isinstance(pandas_obj,pd.DataFrame):       usage_b = pandas_obj.memory_usage(deep=True).sum()   else: #     ,     DataFrame,   Series       usage_b = pandas_obj.memory_usage(deep=True)   usage_mb = usage_b / 1024 ** 2 #       return "{:03.2f} MB".format(usage_mb) gl_int = gl.select_dtypes(include=['int']) converted_int = gl_int.apply(pd.to_numeric,downcast='unsigned') print(mem_usage(gl_int)) print(mem_usage(converted_int)) compare_ints = pd.concat([gl_int.dtypes,converted_int.dtypes],axis=1) compare_ints.columns = ['before','after'] compare_ints.apply(pd.Series.value_counts)</code> </pre> <br>  Voici le résultat d'une étude de la consommation de mémoire: <br><br> <code>7.87 MB <br> 1.48 MB</code> <br> <table><tbody><tr><td></td><td>  À <br></td><td>  Après <br></td></tr><tr><td>  uint8 <br></td><td>  NaN <br></td><td>  5,0 <br></td></tr><tr><td>  uint32 <br></td><td>  NaN <br></td><td>  1.0 <br></td></tr><tr><td>  int64 <br></td><td>  6.0 <br></td><td>  NaN <br></td></tr></tbody></table><br>  En conséquence, vous pouvez constater une baisse de l'utilisation de la mémoire de 7,9 à 1,5 mégaoctets, c'est-à-dire que nous avons réduit la consommation de mémoire de plus de 80%.  L'impact global de cette optimisation sur le <code>DataFrame</code> origine, cependant, n'est pas particulièrement fort car il a très peu de colonnes entières. <br><br>  Faisons de même avec les colonnes contenant des nombres à virgule flottante. <br><br><pre> <code class="plaintext hljs">gl_float = gl.select_dtypes(include=['float']) converted_float = gl_float.apply(pd.to_numeric,downcast='float') print(mem_usage(gl_float)) print(mem_usage(converted_float)) compare_floats = pd.concat([gl_float.dtypes,converted_float.dtypes],axis=1) compare_floats.columns = ['before','after'] compare_floats.apply(pd.Series.value_counts)</code> </pre> <br>  Le résultat est le suivant: <br><br> <code>100.99 MB <br> 50.49 MB</code> <br> <table><tbody><tr><td></td><td>  À <br></td><td>  Après <br></td></tr><tr><td>  float32 <br></td><td>  NaN <br></td><td>  77,0 <br></td></tr><tr><td>  float64 <br></td><td>  77,0 <br></td><td>  NaN <br></td></tr></tbody></table><br>  Par conséquent, toutes les colonnes qui stockaient des nombres à virgule flottante avec le type de données <code>float64</code> stockent désormais des nombres de type <code>float32</code> , ce qui nous a permis de réduire de 50% l'utilisation de la mémoire. <br><br>  Créez une copie du <code>DataFrame</code> origine, utilisez ces colonnes numériques optimisées au lieu de celles qui y étaient initialement présentes et examinez l'utilisation globale de la mémoire après l'optimisation. <br><br><pre> <code class="plaintext hljs">optimized_gl = gl.copy() optimized_gl[converted_int.columns] = converted_int optimized_gl[converted_float.columns] = converted_float print(mem_usage(gl)) print(mem_usage(optimized_gl))</code> </pre> <br>  Voici ce que nous avons obtenu: <br><br> <code>861.57 MB <br> 804.69 MB</code> <br> <br>  Bien que nous ayons considérablement réduit la consommation de mémoire par les colonnes stockant des données numériques, en général, sur l'ensemble du <code>DataFrame</code> , la consommation de mémoire n'a diminué que de 7%.  L'optimisation du stockage des types d'objets peut devenir une source d'amélioration beaucoup plus sérieuse d'une situation. <br><br>  Avant de procéder à cette optimisation, nous allons examiner de plus près comment les chaînes sont stockées dans les pandas et comparer cela avec la façon dont les nombres sont stockés ici. <br><br><h2>  <font color="#3AC1EF">Comparaison des mécanismes de stockage des nombres et des chaînes</font> </h2><br>  Le type d' <code>object</code> représente des valeurs à l'aide d'objets chaîne Python.  Cela est dû en partie au fait que NumPy ne prend pas en charge la représentation des valeurs de chaîne manquantes.  Étant donné que Python est un langage interprété de haut niveau, il ne fournit pas au programmeur d'outils pour affiner la façon dont les données sont stockées en mémoire. <br><br>  Cette limitation conduit au fait que les chaînes ne sont pas stockées dans des fragments de mémoire contigus; leur représentation en mémoire est fragmentée.  Cela entraîne une augmentation de la consommation de mémoire et un ralentissement de la vitesse de travail avec les valeurs de chaîne.  Chaque élément de la colonne stockant le type de données d'objet est en fait un pointeur qui contient «l'adresse» à laquelle la valeur réelle est située en mémoire. <br><br>  Ce qui suit est un diagramme basé sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce</a> matériel qui compare le stockage de données numériques en utilisant les types de données NumPy et le stockage de chaînes en utilisant les types de données intégrés de Python. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d80/66f/54b/d8066f54b091531c120b94c90f698236.png"></div><br>  <i><font color="#999999">Stockage de données numériques et de chaînes</font></i> <br><br>  Ici, vous vous souvenez que dans l'un des tableaux ci-dessus, il a été montré qu'une quantité variable de mémoire est utilisée pour stocker des données de types d'objets.  Bien que chaque pointeur occupe 1 octet de mémoire, chaque valeur de chaîne particulière occupe la même quantité de mémoire qui serait utilisée pour stocker une seule chaîne en Python.  Afin de confirmer cela, nous utiliserons la méthode <code>sys.getsizeof()</code> .  Tout d'abord, jetez un œil aux lignes individuelles, puis à l'objet pandas de <code>Series</code> qui stocke les données de chaîne. <br><br>  Donc, nous examinons d'abord les lignes habituelles: <br><br><pre> <code class="plaintext hljs">from sys import getsizeof s1 = 'working out' s2 = 'memory usage for' s3 = 'strings in python is fun!' s4 = 'strings in python is fun!' for s in [s1, s2, s3, s4]:   print(getsizeof(s))</code> </pre> <br>  Ici, les données d'utilisation de la mémoire ressemblent à ceci: <br><br> <code>60 <br> 65 <br> 74 <br> 74</code> <br> <br>  Voyons maintenant à quoi ressemble l'utilisation de chaînes dans l'objet <code>Series</code> : <br><br><pre> <code class="plaintext hljs">obj_series = pd.Series(['working out',                         'memory usage for',                         'strings in python is fun!',                         'strings in python is fun!']) obj_series.apply(getsizeof)</code> </pre> <br>  Ici, nous obtenons ce qui suit: <br><br><pre> <code class="plaintext hljs">0    60 1    65 2    74 3    74 dtype: int64</code> </pre> <br>  Ici, vous pouvez voir que les tailles des lignes stockées dans les objets pandas <code>Series</code> sont similaires à leurs tailles lorsque vous travaillez avec eux en Python et lorsque vous les représentez en tant qu'entités distinctes. <br><br><h2>  <font color="#3AC1EF">Optimisation du stockage des données de type objet à l'aide de variables catégorielles</font> </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Les variables catégorielles sont</a> apparues dans la version 0.15 de pandas.  Le type correspondant, <code>category</code> , utilise des valeurs entières dans ses mécanismes internes, au lieu des valeurs d'origine stockées dans les colonnes du tableau.  Pandas utilise un dictionnaire séparé qui définit la correspondance des valeurs entières et initiales.  Cette approche est utile lorsque les colonnes contiennent des valeurs d'un ensemble limité.  Lorsque les données stockées dans une colonne sont converties en type de <code>category</code> , pandas utilise le sous-type <code>int</code> , qui permet l'utilisation la plus efficace de la mémoire et est capable de représenter toutes les valeurs uniques trouvées dans la colonne. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1f5/48d/59c/1f548d59c9b41fd906d038c19d3a2da2.png"></div><br>  <i><font color="#999999">Données source et données catégorielles utilisant le sous-type int8</font></i> <br><br>  Afin de comprendre exactement où nous pouvons utiliser des données catégorielles pour réduire la consommation de mémoire, nous trouvons le nombre de valeurs uniques dans les colonnes qui stockent les valeurs des types d'objets: <br><br><pre> <code class="plaintext hljs">gl_obj = gl.select_dtypes(include=['object']).copy() gl_obj.describe()</code> </pre> <br>  Vous pouvez trouver ce que nous avons dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce</a> tableau, sur la feuille <code>    </code> . <br><br>  Par exemple, dans la colonne <code>day_of_week</code> , qui est le jour de la semaine où le jeu a été joué, il y a 171907 valeurs.  Parmi eux, seuls 7 sont uniques.  Dans l'ensemble, un seul coup d'œil sur ce rapport suffit pour comprendre que plusieurs valeurs uniques sont utilisées dans de nombreuses colonnes pour représenter les données d'environ 172 000 jeux. <br><br>  Avant de procéder à l'optimisation à grande échelle, sélectionnons une colonne qui stocke les données d'objet, au moins <code>day_of_week</code> , et voyons ce qui se passe à l'intérieur du programme lorsqu'il est converti en un type catégorique. <br><br>  Comme déjà mentionné, cette colonne ne contient que 7 valeurs uniques.  Pour le convertir en un type catégoriel, nous utilisons la méthode <code>.astype()</code> . <br><br><pre> <code class="plaintext hljs">dow = gl_obj.day_of_week print(dow.head()) dow_cat = dow.astype('category') print(dow_cat.head())</code> </pre> <br>  Voici ce que nous avons obtenu: <br><br><pre> <code class="plaintext hljs">0    Thu 1    Fri 2    Sat 3    Mon 4    Tue Name: day_of_week, dtype: object 0    Thu 1    Fri 2    Sat 3    Mon 4    Tue Name: day_of_week, dtype: category Categories (7, object): [Fri, Mon, Sat, Sun, Thu, Tue, Wed]</code> </pre> <br>  Comme vous pouvez le voir, bien que le type de la colonne ait changé, les données qui y sont stockées ont la même apparence qu'auparavant.  Voyons maintenant ce qui se passe à l'intérieur du programme. <br><br>  Dans le code suivant, nous utilisons l'attribut <code>Series.cat.codes</code> pour déterminer les valeurs entières que le type de <code>category</code> utilise pour représenter chaque jour de la semaine: <br><br><pre> <code class="plaintext hljs">dow_cat.head().cat.codes</code> </pre> <br>  Nous réussissons à découvrir ce qui suit: <br><br><pre> <code class="plaintext hljs">0    4 1    0 2    2 3    1 4    5 dtype: int8</code> </pre> <br>  Ici, vous pouvez voir que chaque valeur unique se voit attribuer une valeur entière et que la colonne est désormais de type <code>int8</code> .  Il n'y a pas de valeurs manquantes, mais si c'était le cas, -1 serait utilisé pour indiquer ces valeurs. <br><br>  Comparons maintenant la consommation de mémoire avant et après la conversion de la colonne <code>day_of_week</code> en type de <code>category</code> . <br><br><pre> <code class="plaintext hljs">print(mem_usage(dow)) print(mem_usage(dow_cat))</code> </pre> <br>  Voici le résultat: <br><br> <code>9.84 MB <br> 0.16 MB</code> <br> <br>  Comme vous pouvez le voir, au début, 9,84 mégaoctets de mémoire ont été consommés, et après optimisation, seulement 0,16 mégaoctets, ce qui signifie une amélioration de 98% de cet indicateur.  Veuillez noter que l'utilisation de cette colonne illustre probablement l'un des scénarios d'optimisation les plus rentables lorsque seules 7 valeurs uniques sont utilisées dans une colonne contenant environ 172 000 éléments. <br><br>  Bien que l'idée de convertir toutes les colonnes en ce type de données semble intéressante, avant de le faire, considérez les effets secondaires négatifs d'une telle conversion.  Ainsi, le plus grave inconvénient de cette transformation est l'impossibilité d'effectuer des opérations arithmétiques sur des données catégorielles.  Cela s'applique également aux opérations arithmétiques ordinaires et à l'utilisation de méthodes telles que <code>Series.min()</code> et <code>Series.max()</code> sans d'abord convertir les données en un type de nombre réel. <br><br>  Nous devons limiter l'utilisation du type de <code>category</code> à principalement des colonnes qui stockent des données de type <code>object</code> , dans lesquelles moins de 50% des valeurs sont uniques.  Si toutes les valeurs d'une colonne sont uniques, l'utilisation du type de <code>category</code> augmentera le niveau d'utilisation de la mémoire.  Cela est dû au fait qu'en mémoire, vous devez stocker, en plus des codes de catégorie numériques, les valeurs de chaîne d'origine.  Les détails sur les restrictions de type de <code>category</code> peuvent être trouvés dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation des</a> pandas. <br><br>  Créons une boucle qui itère sur toutes les colonnes stockant des données d' <code>object</code> type, découvre si le nombre de valeurs uniques dans les colonnes dépasse 50% et, si tel est le cas, les convertit en <code>category</code> type. <br><br><pre> <code class="plaintext hljs">converted_obj = pd.DataFrame() for col in gl_obj.columns:   num_unique_values = len(gl_obj[col].unique())   num_total_values = len(gl_obj[col])   if num_unique_values / num_total_values &lt; 0.5:       converted_obj.loc[:,col] = gl_obj[col].astype('category')   else:       converted_obj.loc[:,col] = gl_obj[col]</code> </pre> <br>  Comparez maintenant ce qui s'est passé après l'optimisation avec ce qui s'est passé avant: <br><br><pre> <code class="plaintext hljs">print(mem_usage(gl_obj)) print(mem_usage(converted_obj)) compare_obj = pd.concat([gl_obj.dtypes,converted_obj.dtypes],axis=1) compare_obj.columns = ['before','after'] compare_obj.apply(pd.Series.value_counts)</code> </pre> <br>  Nous obtenons ce qui suit: <br><br> <code>752.72 MB <br> 51.67 MB</code> <br> <table><tbody><tr><td></td><td>  À <br></td><td>  Après <br></td></tr><tr><td>  objet <br></td><td>  78,0 <br></td><td>  NaN <br></td></tr><tr><td>  catégorie <br></td><td>  NaN <br></td><td>  78,0 <br></td></tr></tbody></table><br>           <code>category</code> ,     ,          , ,      ,     ,    ,  ,     . <br><br>  ,  ,     ,    <code>object</code> ,   752   52 ,    93%.     ,          .  ,       ,   ,  ,     891 . <br><br><pre> <code class="plaintext hljs">optimized_gl[converted_obj.columns] = converted_obj mem_usage(optimized_gl)</code> </pre> <br>     : <br><br> <code>'103.64 MB'</code> <br> <br>  .     - .    ,       <code>datetime</code> , ,  ,        . <br><br><pre> <code class="plaintext hljs">date = optimized_gl.date print(mem_usage(date)) date.head()</code> </pre> <br>       : <br><br> <code>0.66 MB</code> <br> <br>    : <br><br><pre> <code class="plaintext hljs">0    18710504 1    18710505 2    18710506 3    18710508 4    18710509 Name: date, dtype: uint32</code> </pre> <br>  ,               <code>uint32</code> . -       <code>datetime</code>     ,         64 .       <code>datetime</code> ,  ,  ,          . <br><br>      <code>to_datetime()</code> ,  <code>format</code>    ,      <code>YYYY-MM-DD</code> . <br><br><pre> <code class="plaintext hljs">optimized_gl['date'] = pd.to_datetime(date,format='%Y%m%d') print(mem_usage(optimized_gl)) optimized_gl.date.head()</code> </pre> <br>    : <br><br> <code>104.29 MB</code> <br> <br>    : <br><br><pre> <code class="plaintext hljs">0   1871-05-04 1   1871-05-05 2   1871-05-06 3   1871-05-08 4   1871-05-09 Name: date, dtype: datetime64[ns]</code> </pre> <br><h2> <font color="#3AC1EF">    </font> </h2><br>            <code>DataFrame</code> .        , , ,   ,  ,  ,  ,  .       ,        .    ,     ,     ,     .        ,        ,      <code>DataFrame</code> ,   . <br><br>  ,             .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pandas.read_csv()</a>   ,   . ,  <code>dtype</code>  ,   ,   ,   ,     —  NumPy. <br><br>      ,          ,   .         ,      . <br><br><pre> <code class="plaintext hljs">dtypes = optimized_gl.drop('date',axis=1).dtypes dtypes_col = dtypes.index dtypes_type = [i.name for i in dtypes.values] column_types = dict(zip(dtypes_col, dtypes_type)) #    161 ,  #  10  /   #     preview = first2pairs = {key:value for key,value in list(column_types.items())[:10]} import pprint pp = pp = pprint.PrettyPrinter(indent=4) pp.pprint(preview)     : {   'acquisition_info': 'category',   'h_caught_stealing': 'float32',   'h_player_1_name': 'category',   'h_player_9_name': 'category',   'v_assists': 'float32',   'v_first_catcher_interference': 'float32',   'v_grounded_into_double': 'float32',   'v_player_1_id': 'category',   'v_player_3_id': 'category',   'v_player_5_id': 'category'}</code> </pre> <br>          ,      ,    . <br><br>    - : <br><br><pre> <code class="plaintext hljs">read_and_optimized = pd.read_csv('game_logs.csv',dtype=column_types,parse_dates=['date'],infer_datetime_format=True) print(mem_usage(read_and_optimized)) read_and_optimized.head()</code> </pre> <br>       : <br><br> <code>104.28 MB</code> <br> <br>    ,     <code>   </code>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> . <br><br>  ,    <code>   </code>  <code>   </code> ,     ,  ,       .      pandas       861.6   104.28 ,     88% . <br><br><h2> <font color="#3AC1EF">  </font> </h2><br> ,  ,    ,     .     . <br><br><pre> <code class="plaintext hljs">optimized_gl['year'] = optimized_gl.date.dt.year games_per_day = optimized_gl.pivot_table(index='year',columns='day_of_week',values='date',aggfunc=len) games_per_day = games_per_day.divide(games_per_day.sum(axis=1),axis=0) ax = games_per_day.plot(kind='area',stacked='true') ax.legend(loc='upper right') ax.set_ylim(0,1) plt.show()</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3b2/699/6a2/3b26996a26b73e9a3ce87f3ff22dcf34.png"></div><br> <i><font color="#999999">,    </font></i> <br><br>  ,  1920-      ,  ,    50 ,        . <br><br>  ,  ,    ,      50 ,   . <br><br>    ,      . <br><br><pre> <code class="plaintext hljs">game_lengths = optimized_gl.pivot_table(index='year', values='length_minutes') game_lengths.reset_index().plot.scatter('year','length_minutes') plt.show()</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a6d/6db/5d2/a6d6db5d2e6bdb7330ac8a0ff2a6febd.png"></div><br> <i><font color="#999999"> </font></i> <br><br>   ,   1940-         . <br><br><h2>  <font color="#3AC1EF">Résumé</font> </h2><br>            pandas,         ,     <code>DataFrame</code> ,   90%.       : <br><br><ul><li>       ,   ,   ,    , . </li><li>        . </li></ul><br>  ,            , ,         ,    ,  ,       pandas,    ,    . <br><br>  <b>Chers lecteurs!</b>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">eugene_bb</a> .    -  ,    —    . <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr442516/">https://habr.com/ru/post/fr442516/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr442504/index.html">Proxy PHP Xdebug: lorsque les fonctionnalités standard de Xdebug ne suffisent pas</a></li>
<li><a href="../fr442506/index.html">La Russie est-elle punie pour commerce illégal de données personnelles?</a></li>
<li><a href="../fr442508/index.html">Comment udalenka accélère l'innovation sur GitLab</a></li>
<li><a href="../fr442512/index.html">Personnalisation de Django ORM sur l'exemple de ZomboDB</a></li>
<li><a href="../fr442514/index.html">Systèmes distribués. Modèles de conception. Critique de livre</a></li>
<li><a href="../fr442518/index.html">Top 10 des techniques de piratage Web 2018</a></li>
<li><a href="../fr442520/index.html">Affaire. Économie de 300 000 p. par mois sur la publicité contextuelle</a></li>
<li><a href="../fr442522/index.html">Intuitive RL (Reinforcement Learning): Introduction à Advantage-Actor-Critic (A2C)</a></li>
<li><a href="../fr442524/index.html">Comment accroître la sécurité des systèmes d'identification personnelle et de contrôle d'accès</a></li>
<li><a href="../fr442526/index.html">L'histoire des cassettes soviétiques (deuxième partie): le boom des Walkmen, un gadget pour le KGB et des magnétophones</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
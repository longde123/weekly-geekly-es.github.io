<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üò∑ üöë üë∑üèº Kaggle Home Credit Default Risk-Wettbewerb - Datenanalyse und einfache Vorhersagemodelle üöΩ üêê üõ§Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Auf dem Datenfestival 2 in Minsk bemerkte Vladimir Iglovikov, Bildverarbeitungsingenieur bei Lyft, dass der beste Weg, Data Science zu lernen, darin b...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kaggle Home Credit Default Risk-Wettbewerb - Datenanalyse und einfache Vorhersagemodelle</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414613/">  Auf dem Datenfestival 2 in Minsk bemerkte Vladimir Iglovikov, Bildverarbeitungsingenieur bei Lyft, dass der beste Weg, Data Science zu lernen, darin besteht, an Wettbewerben teilzunehmen, L√∂sungen anderer zu entwickeln, diese zu kombinieren, Ergebnisse zu erzielen und Ihre Arbeit zu zeigen.  Im Rahmen dieses Paradigmas habe ich mich entschlossen, den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wettbewerb zur</a> Bewertung des Kreditrisikos f√ºr Privatkredite genauer zu betrachten und (Anf√§ngern, Wissenschaftlern und vor allem mir selbst) zu erkl√§ren, wie solche Datens√§tze richtig analysiert und Modelle f√ºr sie erstellt werden k√∂nnen. <br><br><img src="https://habrastorage.org/webt/iv/ji/-t/ivji-tusvam8d05dqef8wjbmbye.png"><br><a name="habracut"></a><br>  (Bild <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von hier</a> ) <br><br><img src="https://habrastorage.org/webt/xc/er/pe/xcerpefrjvrblmubhxyeljevcie.png" width="250" align="right">  Die Home Credit Group ist eine Gruppe von Banken und Nichtbanken-Kreditorganisationen, die in 11 L√§ndern t√§tig sind (einschlie√ülich Russland als Home Credit and Finance Bank LLC).  Ziel des Wettbewerbs ist es, eine Methode zur Bewertung der Kreditw√ºrdigkeit von Kreditnehmern zu erstellen, die keine Bonit√§tshistorie haben.  Was ziemlich edel aussieht - Kreditnehmer dieser Kategorie k√∂nnen oft keinen Kredit von der Bank erhalten und sind gezwungen, sich an Betr√ºger und Mikrokredite zu wenden.  Es ist interessant, dass der Kunde keine Anforderungen an die Transparenz und Interpretierbarkeit des Modells stellt (wie dies normalerweise bei Banken der Fall ist). Sie k√∂nnen alles verwenden, auch ein neuronales Netzwerk. <br><br>  Die Trainingsstichprobe besteht aus mehr als 300.000 Datens√§tzen, es gibt ziemlich viele Anzeichen - 122, darunter viele kategoriale (nicht numerische).  Schilder beschreiben den Kreditnehmer ausreichend detailliert bis hin zu dem Material, aus dem die W√§nde seines Hauses bestehen.  Ein Teil der Daten ist in 6 zus√§tzlichen Tabellen enthalten (Daten zum Kreditb√ºro, zum Kreditkartenguthaben und zu fr√ºheren Darlehen). Diese Daten m√ºssen auch irgendwie verarbeitet und in die Hauptdaten geladen werden. <br><br>  Der Wettbewerb sieht aus wie eine Standardklassifizierungsaufgabe (1 im Feld ZIEL bedeutet Schwierigkeiten bei der Zahlung, 0 bedeutet keine Schwierigkeiten).  Es sollte jedoch nicht 0/1 vorhergesagt werden, sondern die Wahrscheinlichkeit von Problemen (die im √úbrigen leicht mit den Wahrscheinlichkeitsvorhersagemethoden predict_proba aller komplexen Modelle gel√∂st werden k√∂nnen). <br><br>  Auf den ersten Blick ist der Datensatz ein Standard f√ºr maschinelles Lernen. Die Organisatoren haben einen hohen Preis von 70.000 US-Dollar angeboten. Infolgedessen nehmen heute mehr als 2.600 Teams am Wettbewerb teil, und der Kampf findet in Tausendstel Prozent statt.  Andererseits bedeutet eine solche Popularit√§t, dass der Datensatz auf und ab untersucht wurde und viele Kernel mit guter EDA (Exploratory Data Analisys - Forschung und Analyse von Daten im Netzwerk, einschlie√ülich grafischer Daten), Feature Engineering (Arbeiten mit Attributen) erstellt wurden. und mit interessanten Modellen.  (Der Kernel ist ein Beispiel f√ºr die Arbeit mit einem Datensatz, den jeder anlegen kann, um anderen K√§mpfern seine Arbeit zu zeigen.) <br><br>  Kernel verdienen Aufmerksamkeit: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">EDA mit einer detaillierten Beschreibung f√ºr Anf√§nger und einfache Modelle</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deep EDA mit Plotly Package + Bureau Data Upload</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sch√∂ne EDA mit Seaborn-Paket</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Vergleichende Analyse von Problem- und Ausfallkreditnehmern</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">15-zeiliges LightGBM auf drei Schildern mit einer Endgeschwindigkeit von 0,714</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Analyse der Zeichen nach Kreditauskunfteien</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verarbeitung hinzuf√ºgen.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tabellen + LightGBM</a> </li></ul><br>  Um mit Daten zu arbeiten, wird normalerweise der folgende Plan empfohlen, dem wir folgen werden. <br><br><ol><li>  Das Problem verstehen und sich mit den Daten vertraut machen </li><li>  Datenbereinigung und Formatierung </li><li>  EDA </li><li>  Basismodell </li><li>  Modellverbesserung </li><li>  Modellinterpretation </li></ol><br>  In diesem Fall m√ºssen Sie ber√ºcksichtigen, dass die Daten sehr umfangreich sind und nicht sofort √ºberlastet werden k√∂nnen. Es ist sinnvoll, schrittweise zu handeln. <br><br>  Beginnen wir mit dem Importieren der Bibliotheken, die wir f√ºr die Analyse ben√∂tigen, um mit Daten in Form von Tabellen zu arbeiten, Diagramme zu erstellen und mit Matrizen zu arbeiten. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns %matplotlib inline</code> </pre> <br>  Laden Sie die Daten herunter.  Mal sehen, was wir alle haben.  Dieser Speicherort im Verzeichnis "../input/" ist √ºbrigens mit der Anforderung verbunden, Ihre Kernel auf Kaggle zu platzieren. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os PATH=<span class="hljs-string"><span class="hljs-string">"../input/"</span></span> print(os.listdir(PATH))</code> </pre> <br> <code>['application_test.csv', 'application_train.csv', 'bureau.csv', 'bureau_balance.csv', 'credit_card_balance.csv', 'HomeCredit_columns_description.csv', 'installments_payments.csv', 'POS_CASH_balance.csv', 'previous_application.csv']</code> <br> <br>  Es gibt 8 Tabellen mit Daten (ohne die Tabelle HomeCredit_columns_description.csv, die eine Beschreibung der Felder enth√§lt), die wie folgt miteinander verbunden sind: <br><br><img src="https://habrastorage.org/webt/vn/yr/84/vnyr84vhzozgnfinu2to2tyhlp8.png"><br><br>  application_train / application_test: Stammdaten, der Kreditnehmer wird durch das Feld SK_ID_CURR identifiziert <br>  B√ºro: Daten zu fr√ºheren Darlehen anderer Kreditinstitute von einem Kreditb√ºro <br>  office_balance: Monatliche Daten zu fr√ºheren B√ºrodarlehen.  Jede Zeile ist der Monat, in dem das Darlehen verwendet wird <br>  vorherige_Anwendung: Fr√ºhere Antr√§ge auf Darlehen in Home Credit haben jeweils ein eindeutiges Feld SK_ID_PREV <br>  POS_CASH_BALANCE: Monatliche Daten zu Krediten in Home Credit mit der Ausgabe von Bargeld und Krediten f√ºr den Kauf von Waren <br>  credit_card_balance: Monatliche Kreditkartenguthaben in Home Credit <br>  Ratenzahlung_Zahlung: Zahlungsverlauf fr√ºherer Kredite bei Home Credit. <br><br>  Konzentrieren wir uns zun√§chst auf die Hauptdatenquelle und sehen, welche Informationen daraus extrahiert werden k√∂nnen und welche Modelle erstellt werden sollen.  Laden Sie die Basisdaten herunter. <br><br><ul><li>  app_train = pd.read_csv (PATH + 'application_train.csv',) </li><li>  app_test = pd.read_csv (PATH + 'application_test.csv',) </li><li>  print ("Trainingssatzformat:", app_train.shape) </li><li>  print ("Testbeispielformat:", app_test.shape) </li><li>  Trainingsbeispielformat: (307511, 122) </li><li>  Testmusterformat: (48744, 121) </li></ul><br>  Insgesamt haben wir 307.000 Datens√§tze und 122 Zeichen in der Trainingsstichprobe und 49.000 Datens√§tze und 121 Zeichen im Test.  Die Diskrepanz ist offensichtlich auf die Tatsache zur√ºckzuf√ºhren, dass die Testprobe kein Zielattribut TARGET enth√§lt, und wir werden es vorhersagen. <br><br>  Schauen wir uns die Daten genauer an <br><br><pre> <code class="python hljs">pd.set_option(<span class="hljs-string"><span class="hljs-string">'display.max_columns'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) <span class="hljs-comment"><span class="hljs-comment">#  pandas     app_train.head()</span></span></code> </pre> <br><br><img src="https://habrastorage.org/webt/xo/yc/rg/xoycrgiodfhonfrjbt50ncthrls.png"><br>  (erste 8 Spalten gezeigt) <br><br>  Es ist ziemlich schwierig, Daten in diesem Format anzusehen.  Schauen wir uns die Liste der Spalten an: <br><br> <code>app_train.info(max_cols=122) <br> &lt;class 'pandas.core.frame.DataFrame'&gt; <br> RangeIndex: 307511 entries, 0 to 307510 <br> Data columns (total 122 columns): <br> SK_ID_CURR 307511 non-null int64 <br> TARGET 307511 non-null int64 <br> NAME_CONTRACT_TYPE 307511 non-null object <br> CODE_GENDER 307511 non-null object <br> FLAG_OWN_CAR 307511 non-null object <br> FLAG_OWN_REALTY 307511 non-null object <br> CNT_CHILDREN 307511 non-null int64 <br> AMT_INCOME_TOTAL 307511 non-null float64 <br> AMT_CREDIT 307511 non-null float64 <br> AMT_ANNUITY 307499 non-null float64 <br> AMT_GOODS_PRICE 307233 non-null float64 <br> NAME_TYPE_SUITE 306219 non-null object <br> NAME_INCOME_TYPE 307511 non-null object <br> NAME_EDUCATION_TYPE 307511 non-null object <br> NAME_FAMILY_STATUS 307511 non-null object <br> NAME_HOUSING_TYPE 307511 non-null object <br> REGION_POPULATION_RELATIVE 307511 non-null float64 <br> DAYS_BIRTH 307511 non-null int64 <br> DAYS_EMPLOYED 307511 non-null int64 <br> DAYS_REGISTRATION 307511 non-null float64 <br> DAYS_ID_PUBLISH 307511 non-null int64 <br> OWN_CAR_AGE 104582 non-null float64 <br> FLAG_MOBIL 307511 non-null int64 <br> FLAG_EMP_PHONE 307511 non-null int64 <br> FLAG_WORK_PHONE 307511 non-null int64 <br> FLAG_CONT_MOBILE 307511 non-null int64 <br> FLAG_PHONE 307511 non-null int64 <br> FLAG_EMAIL 307511 non-null int64 <br> OCCUPATION_TYPE 211120 non-null object <br> CNT_FAM_MEMBERS 307509 non-null float64 <br> REGION_RATING_CLIENT 307511 non-null int64 <br> REGION_RATING_CLIENT_W_CITY 307511 non-null int64 <br> WEEKDAY_APPR_PROCESS_START 307511 non-null object <br> HOUR_APPR_PROCESS_START 307511 non-null int64 <br> REG_REGION_NOT_LIVE_REGION 307511 non-null int64 <br> REG_REGION_NOT_WORK_REGION 307511 non-null int64 <br> LIVE_REGION_NOT_WORK_REGION 307511 non-null int64 <br> REG_CITY_NOT_LIVE_CITY 307511 non-null int64 <br> REG_CITY_NOT_WORK_CITY 307511 non-null int64 <br> LIVE_CITY_NOT_WORK_CITY 307511 non-null int64 <br> ORGANIZATION_TYPE 307511 non-null object <br> EXT_SOURCE_1 134133 non-null float64 <br> EXT_SOURCE_2 306851 non-null float64 <br> EXT_SOURCE_3 246546 non-null float64 <br> APARTMENTS_AVG 151450 non-null float64 <br> BASEMENTAREA_AVG 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_AVG 157504 non-null float64 <br> YEARS_BUILD_AVG 103023 non-null float64 <br> COMMONAREA_AVG 92646 non-null float64 <br> ELEVATORS_AVG 143620 non-null float64 <br> ENTRANCES_AVG 152683 non-null float64 <br> FLOORSMAX_AVG 154491 non-null float64 <br> FLOORSMIN_AVG 98869 non-null float64 <br> LANDAREA_AVG 124921 non-null float64 <br> LIVINGAPARTMENTS_AVG 97312 non-null float64 <br> LIVINGAREA_AVG 153161 non-null float64 <br> NONLIVINGAPARTMENTS_AVG 93997 non-null float64 <br> NONLIVINGAREA_AVG 137829 non-null float64 <br> APARTMENTS_MODE 151450 non-null float64 <br> BASEMENTAREA_MODE 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_MODE 157504 non-null float64 <br> YEARS_BUILD_MODE 103023 non-null float64 <br> COMMONAREA_MODE 92646 non-null float64 <br> ELEVATORS_MODE 143620 non-null float64 <br> ENTRANCES_MODE 152683 non-null float64 <br> FLOORSMAX_MODE 154491 non-null float64 <br> FLOORSMIN_MODE 98869 non-null float64 <br> LANDAREA_MODE 124921 non-null float64 <br> LIVINGAPARTMENTS_MODE 97312 non-null float64 <br> LIVINGAREA_MODE 153161 non-null float64 <br> NONLIVINGAPARTMENTS_MODE 93997 non-null float64 <br> NONLIVINGAREA_MODE 137829 non-null float64 <br> APARTMENTS_MEDI 151450 non-null float64 <br> BASEMENTAREA_MEDI 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_MEDI 157504 non-null float64 <br> YEARS_BUILD_MEDI 103023 non-null float64 <br> COMMONAREA_MEDI 92646 non-null float64 <br> ELEVATORS_MEDI 143620 non-null float64 <br> ENTRANCES_MEDI 152683 non-null float64 <br> FLOORSMAX_MEDI 154491 non-null float64 <br> FLOORSMIN_MEDI 98869 non-null float64 <br> LANDAREA_MEDI 124921 non-null float64 <br> LIVINGAPARTMENTS_MEDI 97312 non-null float64 <br> LIVINGAREA_MEDI 153161 non-null float64 <br> NONLIVINGAPARTMENTS_MEDI 93997 non-null float64 <br> NONLIVINGAREA_MEDI 137829 non-null float64 <br> FONDKAPREMONT_MODE 97216 non-null object <br> HOUSETYPE_MODE 153214 non-null object <br> TOTALAREA_MODE 159080 non-null float64 <br> WALLSMATERIAL_MODE 151170 non-null object <br> EMERGENCYSTATE_MODE 161756 non-null object <br> OBS_30_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DEF_30_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> OBS_60_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DEF_60_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DAYS_LAST_PHONE_CHANGE 307510 non-null float64 <br> FLAG_DOCUMENT_2 307511 non-null int64 <br> FLAG_DOCUMENT_3 307511 non-null int64 <br> FLAG_DOCUMENT_4 307511 non-null int64 <br> FLAG_DOCUMENT_5 307511 non-null int64 <br> FLAG_DOCUMENT_6 307511 non-null int64 <br> FLAG_DOCUMENT_7 307511 non-null int64 <br> FLAG_DOCUMENT_8 307511 non-null int64 <br> FLAG_DOCUMENT_9 307511 non-null int64 <br> FLAG_DOCUMENT_10 307511 non-null int64 <br> FLAG_DOCUMENT_11 307511 non-null int64 <br> FLAG_DOCUMENT_12 307511 non-null int64 <br> FLAG_DOCUMENT_13 307511 non-null int64 <br> FLAG_DOCUMENT_14 307511 non-null int64 <br> FLAG_DOCUMENT_15 307511 non-null int64 <br> FLAG_DOCUMENT_16 307511 non-null int64 <br> FLAG_DOCUMENT_17 307511 non-null int64 <br> FLAG_DOCUMENT_18 307511 non-null int64 <br> FLAG_DOCUMENT_19 307511 non-null int64 <br> FLAG_DOCUMENT_20 307511 non-null int64 <br> FLAG_DOCUMENT_21 307511 non-null int64 <br> AMT_REQ_CREDIT_BUREAU_HOUR 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_DAY 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_WEEK 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_MON 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_QRT 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_YEAR 265992 non-null float64 <br> dtypes: float64(65), int64(41), object(16) <br> memory usage: 286.2+ MB</code> <br> <br>  Rufen Sie detaillierte Anmerkungen nach Feld in der Datei HomeCredit_columns_description auf.  Wie Sie aus den Informationen ersehen k√∂nnen, ist ein Teil der Daten unvollst√§ndig und ein Teil kategorisch. Sie werden als Objekt angezeigt.  Die meisten Modelle arbeiten nicht mit solchen Daten, wir m√ºssen etwas damit anfangen.  In diesem Zusammenhang kann die erste Analyse als abgeschlossen betrachtet werden, wir werden direkt zu EDA gehen <br><br><h2>  Explorative Datenanalyse oder prim√§res Data Mining </h2><br>  Im EDA-Prozess z√§hlen wir die grundlegenden Statistiken und zeichnen Diagramme, um Trends, Anomalien, Muster und Beziehungen innerhalb der Daten zu finden.  Ziel von EDA ist es herauszufinden, was die Daten aussagen k√∂nnen.  In der Regel geht die Analyse von oben nach unten - von einem allgemeinen √úberblick bis zur Untersuchung einzelner Zonen, die Aufmerksamkeit erregen und von Interesse sein k√∂nnen.  Anschlie√üend k√∂nnen diese Erkenntnisse bei der Konstruktion des Modells, der Auswahl der Merkmale f√ºr das Modell und seiner Interpretation verwendet werden. <br><br><h3>  Verteilung der Zielvariablen </h3><br><pre> <code class="python hljs">app_train.TARGET.value_counts()</code> </pre> <br> <code>0 282686 <br> 1 24825 <br> Name: TARGET, dtype: int64</code> <br> <br><pre> <code class="python hljs">plt.style.use(<span class="hljs-string"><span class="hljs-string">'fivethirtyeight'</span></span>) plt.rcParams[<span class="hljs-string"><span class="hljs-string">"figure.figsize"</span></span>] = [<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>]‚Äã plt.hist(app_train.TARGET) plt.show()</code> </pre> <br><img src="https://habrastorage.org/webt/xm/rd/ch/xmrdchcab8eqbwt2p1pie4jmaeu.png"><br><br>  Ich m√∂chte Sie daran erinnern, dass 1 Probleme jeglicher Art mit einer R√ºckgabe bedeutet, 0 bedeutet keine Probleme.  Wie Sie sehen, haben haupts√§chlich Kreditnehmer keine Probleme mit der R√ºckzahlung, der Anteil der Problematik liegt bei etwa 8%.  Dies bedeutet, dass die Klassen nicht ausgeglichen sind und dies m√∂glicherweise beim Erstellen des Modells ber√ºcksichtigt werden muss. <br><br><h3>  Fehlende Datenrecherche </h3><br>  Wir haben gesehen, dass der Mangel an Daten ziemlich gro√ü ist.  Mal sehen, wo und was fehlt. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      def missing_values_table(df): #   mis_val = df.isnull().sum() #    mis_val_percent = 100 * df.isnull().sum() / len(df) #    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1) #   mis_val_table_ren_columns = mis_val_table.rename( columns = {0 : 'Missing Values', 1 : '% of Total Values'}) #    mis_val_table_ren_columns = mis_val_table_ren_columns[ mis_val_table_ren_columns.iloc[:,1] != 0].sort_values( '% of Total Values', ascending=False).round(1) #  print ("   " + str(df.shape[1]) + " .\n" " " + str(mis_val_table_ren_columns.shape[0]) + "    .") #     return mis_val_table_ren_columns missing_values = missing_values_table(app_train) missing_values.head(10)</span></span></code> </pre> <br><br> <code>   122 . <br>  67    .</code> <br> <img src="https://habrastorage.org/webt/oa/jm/tp/oajmtpuvkymt4asczwqmhqziria.png"><br><br>  Im Grafikformat: <br><br><pre> <code class="python hljs">plt.style.use(<span class="hljs-string"><span class="hljs-string">'seaborn-talk'</span></span>)‚Äã fig = plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">18</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>)) miss_train = pd.DataFrame((app_train.isnull().sum())*<span class="hljs-number"><span class="hljs-number">100</span></span>/app_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]).reset_index() miss_test = pd.DataFrame((app_test.isnull().sum())*<span class="hljs-number"><span class="hljs-number">100</span></span>/app_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]).reset_index() miss_train[<span class="hljs-string"><span class="hljs-string">"type"</span></span>] = <span class="hljs-string"><span class="hljs-string">""</span></span> miss_test[<span class="hljs-string"><span class="hljs-string">"type"</span></span>] = <span class="hljs-string"><span class="hljs-string">""</span></span> missing = pd.concat([miss_train,miss_test],axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) ax = sns.pointplot(<span class="hljs-string"><span class="hljs-string">"index"</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,data=missing,hue=<span class="hljs-string"><span class="hljs-string">"type"</span></span>) plt.xticks(rotation =<span class="hljs-number"><span class="hljs-number">90</span></span>,fontsize =<span class="hljs-number"><span class="hljs-number">7</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">"    "</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">"  %"</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">""</span></span>)</code> </pre> <br><br><img src="https://habrastorage.org/webt/iv/fc/ib/ivfcibv85aaktlxybl8bps2vurw.png"><br><br>  Es gibt viele Antworten auf die Frage, was mit all dem zu tun ist.  Sie k√∂nnen es mit Nullen f√ºllen, Sie k√∂nnen Medianwerte verwenden, Sie k√∂nnen nur Zeilen ohne die erforderlichen Informationen l√∂schen.  Es h√§ngt alles von dem Modell ab, das wir verwenden m√∂chten, da einige von ihnen perfekt mit fehlenden Werten umgehen.  W√§hrend wir uns an diese Tatsache erinnern und alles so lassen, wie es ist. <br><br><h3>  Spaltentypen und kategoriale Codierung </h3><br>  Wie wir uns erinnern.  Ein Teil der Spalten ist vom Typ Objekt, dh er hat keinen numerischen Wert, spiegelt jedoch eine Kategorie wider.  Schauen wir uns diese Spalten genauer an. <br><br><pre> <code class="python hljs">app_train.dtypes.value_counts()</code> </pre> <br> <code>float64 65 <br> int64 41 <br> object 16 <br> dtype: int64</code> <br> <br><pre> <code class="python hljs">app_train.select_dtypes(include=[object]).apply(pd.Series.nunique, axis = <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br> <code>NAME_CONTRACT_TYPE 2 <br> CODE_GENDER 3 <br> FLAG_OWN_CAR 2 <br> FLAG_OWN_REALTY 2 <br> NAME_TYPE_SUITE 7 <br> NAME_INCOME_TYPE 8 <br> NAME_EDUCATION_TYPE 5 <br> NAME_FAMILY_STATUS 6 <br> NAME_HOUSING_TYPE 6 <br> OCCUPATION_TYPE 18 <br> WEEKDAY_APPR_PROCESS_START 7 <br> ORGANIZATION_TYPE 58 <br> FONDKAPREMONT_MODE 4 <br> HOUSETYPE_MODE 3 <br> WALLSMATERIAL_MODE 7 <br> EMERGENCYSTATE_MODE 2 <br> dtype: int64</code> <br> <br>  Wir haben 16 Spalten mit jeweils 2 bis 58 verschiedenen Wertoptionen.  Im Allgemeinen k√∂nnen Modelle f√ºr maschinelles Lernen mit solchen Spalten nichts anfangen (mit Ausnahme einiger, wie z. B. LightGBM oder CatBoost).  Da wir verschiedene Modelle im Datensatz ausprobieren m√∂chten, muss hiermit etwas unternommen werden.  Grunds√§tzlich gibt es zwei Ans√§tze: <br><br><ul><li>  Beschriftungscodierung - Kategorien werden mit den Ziffern 0, 1, 2 usw. versehen und in dieselbe Spalte geschrieben </li><li>  One-Hot-Codierung - Eine Spalte wird entsprechend der Anzahl der Optionen in mehrere zerlegt. Diese Spalten geben an, welche Option dieser Datensatz hat. </li></ul><br>  Unter den popul√§ren ist es erw√§hnenswert, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mittlere</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zielcodierung</a> (danke f√ºr die Klarstellung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">roryorangepants</a> ). <br><br>  Bei der Etikettencodierung gibt es ein kleines Problem: Sie weist numerische Werte zu, die nichts mit der Realit√§t zu tun haben.  Wenn es sich beispielsweise um einen numerischen Wert handelt, ist das Einkommen des Kreditnehmers von 100.000 definitiv h√∂her und besser als das Einkommen von 20.000. Man kann jedoch sagen, dass beispielsweise eine Stadt besser ist als eine andere, weil einer der Wert 100 und die andere 200 zugewiesen wird ? <br><br>  One-Hot-Codierung ist dagegen sicherer, kann jedoch "zus√§tzliche" Spalten erzeugen.  Wenn wir beispielsweise dasselbe Geschlecht mit One-Hot codieren, erhalten wir zwei Spalten, "m√§nnliches Geschlecht" und "weibliches Geschlecht", obwohl eine ausreichen w√ºrde, "ist es m√§nnlich". <br><br>  F√ºr einen guten Datensatz w√§re es notwendig, Zeichen mit geringer Variabilit√§t mithilfe der Etikettencodierung und allem anderen zu codieren - One-Hot, aber der Einfachheit halber codieren wir alles gem√§√ü One-Hot.  Dies hat praktisch keinen Einfluss auf die Berechnungsgeschwindigkeit und das Ergebnis.  Der Pandas-Kodierungsprozess selbst ist sehr einfach. <br><br><pre> <code class="python hljs">app_train = pd.get_dummies(app_train) app_test = pd.get_dummies(app_test)‚Äã print(<span class="hljs-string"><span class="hljs-string">'Training Features shape: '</span></span>, app_train.shape) print(<span class="hljs-string"><span class="hljs-string">'Testing Features shape: '</span></span>, app_test.shape)</code> </pre> <br> <code>Training Features shape: (307511, 246) <br> Testing Features shape: (48744, 242)</code> <br> <br>  Da die Anzahl der Optionen in den Auswahlspalten nicht gleich ist, stimmt die Anzahl der Spalten jetzt nicht √ºberein.  Ausrichtung ist erforderlich - Sie m√ºssen Spalten aus dem Trainingssatz entfernen, die nicht im Testsatz enthalten sind.  Damit ist die Ausrichtungsmethode erforderlich. Sie m√ºssen Achse = 1 angeben (f√ºr Spalten). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># ,           . train_labels = app_train['TARGET']‚Äã #  -   .     app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)‚Äã print('  : ', app_train.shape) print('  : ', app_test.shape)‚Äã # Add target back in to the data app_train['TARGET'] = train_labels</span></span></code> </pre> <br> <code>  : (307511, 242) <br>   : (48744, 242)</code> <br> <br><h3>  Datenkorrelation </h3><br>  Ein guter Weg, um die Daten zu verstehen, besteht darin, die Pearson-Korrelationskoeffizienten f√ºr die Daten relativ zum Zielattribut zu berechnen.  Dies ist nicht die beste Methode, um die Relevanz von Features zu zeigen, aber sie ist einfach und erm√∂glicht es Ihnen, sich ein Bild von den Daten zu machen.  Die Koeffizienten k√∂nnen wie folgt interpretiert werden: <br><br><ul><li>  00-.19 "sehr schwach" </li><li>  20-.39 "schwach" </li><li>  40-.59 "Durchschnitt" </li><li>  60-79 stark </li><li>  80-1.0 "sehr stark" </li></ul><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    correlations = app_train.corr()['TARGET'].sort_values()‚Äã #  print('  : \n', correlations.tail(15)) print('\n  : \n', correlations.head(15))</span></span></code> </pre> <br> <code>  : <br> DAYS_REGISTRATION 0.041975 <br> OCCUPATION_TYPE_Laborers 0.043019 <br> FLAG_DOCUMENT_3 0.044346 <br> REG_CITY_NOT_LIVE_CITY 0.044395 <br> FLAG_EMP_PHONE 0.045982 <br> NAME_EDUCATION_TYPE_Secondary / secondary special 0.049824 <br> REG_CITY_NOT_WORK_CITY 0.050994 <br> DAYS_ID_PUBLISH 0.051457 <br> CODE_GENDER_M 0.054713 <br> DAYS_LAST_PHONE_CHANGE 0.055218 <br> NAME_INCOME_TYPE_Working 0.057481 <br> REGION_RATING_CLIENT 0.058899 <br> REGION_RATING_CLIENT_W_CITY 0.060893 <br> DAYS_BIRTH 0.078239 <br> TARGET 1.000000 <br> Name: TARGET, dtype: float64 <br> <br>   : <br> EXT_SOURCE_3 -0.178919 <br> EXT_SOURCE_2 -0.160472 <br> EXT_SOURCE_1 -0.155317 <br> NAME_EDUCATION_TYPE_Higher education -0.056593 <br> CODE_GENDER_F -0.054704 <br> NAME_INCOME_TYPE_Pensioner -0.046209 <br> ORGANIZATION_TYPE_XNA -0.045987 <br> DAYS_EMPLOYED -0.044932 <br> FLOORSMAX_AVG -0.044003 <br> FLOORSMAX_MEDI -0.043768 <br> FLOORSMAX_MODE -0.043226 <br> EMERGENCYSTATE_MODE_No -0.042201 <br> HOUSETYPE_MODE_block of flats -0.040594 <br> AMT_GOODS_PRICE -0.039645 <br> REGION_POPULATION_RELATIVE -0.037227 <br> Name: TARGET, dtype: float64</code> <br> <br>  Somit korrelieren alle Daten schwach mit dem Ziel (mit Ausnahme des Ziels selbst, das nat√ºrlich gleich sich selbst ist).  Das Alter und einige ‚Äûexterne Datenquellen‚Äú unterscheiden sich jedoch von den Daten.  Dies sind wahrscheinlich einige zus√§tzliche Daten von anderen Kreditorganisationen.  Es ist lustig, dass, obwohl das Ziel bei einer Kreditentscheidung als Unabh√§ngigkeit von solchen Daten erkl√§rt wird, wir uns in erster Linie auf diese st√ºtzen werden. <br><br><h3>  Alter </h3><br>  Es ist klar, dass je √§lter der Kunde ist, desto h√∂her ist die Wahrscheinlichkeit einer R√ºckkehr (nat√ºrlich bis zu einem bestimmten Limit).  Aus irgendeinem Grund wird das Alter jedoch in negativen Tagen vor der Ausgabe eines Kredits angegeben, weshalb es positiv mit der Nichtr√ºckzahlung korreliert (was etwas seltsam aussieht).  Wir bringen es auf einen positiven Wert und betrachten die Korrelation. <br><br><pre> <code class="python hljs">app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>] = abs(app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>]) app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>].corr(app_train[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>])</code> </pre> <br> <code>-0.078239308309827088</code> <br> <br>  Schauen wir uns die Variable genauer an.  Beginnen wir mit dem Histogramm. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     ,  25  plt.hist(app_train['DAYS_BIRTH'] / 365, edgecolor = 'k', bins = 25) plt.title('Age of Client'); plt.xlabel('Age (years)'); plt.ylabel('Count');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/v2/zq/1q/v2zq1qolo8rc5wx0tyao4ucygxc.png"><br><br>  Das Verteilungshistogramm selbst kann ein wenig n√ºtzlich sein, au√üer dass wir keine speziellen Ausrei√üer sehen und alles mehr oder weniger glaubw√ºrdig aussieht.  Um die Auswirkung des Einflusses des Alters auf das Ergebnis zu zeigen, k√∂nnen wir ein Diagramm der Kerndichtesch√§tzung (KDE) erstellen - die Verteilung der Kerndichte, die in den Farben des Zielattributs dargestellt ist.  Es zeigt die Verteilung einer Variablen und kann als gegl√§ttetes Histogramm interpretiert werden (berechnet als Gau√üscher Kern f√ºr jeden Punkt, der dann gemittelt wird, um ihn zu gl√§tten). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365, label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365, label = 'target == 1')‚Äã #  plt.xlabel('Age (years)'); plt.ylabel('Density'); plt.title('Distribution of Ages');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/st/xs/e1/stxse1wipiaqcf0a7trlm0lwz0g.png"><br><br>  Wie zu sehen ist, ist der Anteil der Ausf√§lle bei jungen Menschen h√∂her und nimmt mit zunehmendem Alter ab.  Dies ist kein Grund, jungen Menschen immer Kredite zu verweigern. Eine solche ‚ÄûEmpfehlung‚Äú f√ºhrt nur zu Einkommens- und Marktverlusten f√ºr die Bank.  Dies ist eine Gelegenheit, √ºber eine gr√ºndlichere √úberwachung solcher Kredite, eine Bewertung und m√∂glicherweise sogar eine Art finanzielle Bildung f√ºr junge Kreditnehmer nachzudenken. <br><br><h3>  Externe Quellen </h3><br>  Schauen wir uns die ‚Äûexternen Datenquellen‚Äú EXT_SOURCE und ihre Korrelation genauer an. <br><br><pre> <code class="python hljs">ext_data = app_train[[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_1'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_2'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_3'</span></span>, <span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>]] ext_data_corrs = ext_data.corr() ext_data_corrs</code> </pre> <br><img src="https://habrastorage.org/webt/5k/ba/fe/5kbafej-y0vvcexlt6iebcjvjbs.png"><br><br>  Es ist auch bequem, die Korrelation mithilfe der Heatmap anzuzeigen <br><br><pre> <code class="python hljs">sns.heatmap(ext_data_corrs, cmap = plt.cm.RdYlBu_r, vmin = <span class="hljs-number"><span class="hljs-number">-0.25</span></span>, annot = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, vmax = <span class="hljs-number"><span class="hljs-number">0.6</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'Correlation Heatmap'</span></span>);</code> </pre> <br><img src="https://habrastorage.org/webt/e6/wj/vw/e6wjvwnetgs2y-i65_4okda-6t8.png"><br><br>  Wie Sie sehen k√∂nnen, zeigen alle Quellen eine negative Korrelation mit dem Ziel.  Schauen wir uns die Verteilung von KDE f√ºr jede Quelle an. <br><br><pre> <code class="python hljs">plt.figure(figsize = (<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment">#    for i, source in enumerate(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']): #  plt.subplot(3, 1, i + 1) #    sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, source], label = 'target == 0') #    sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, source], label = 'target == 1') #  plt.title('Distribution of %s by Target Value' % source) plt.xlabel('%s' % source); plt.ylabel('Density'); plt.tight_layout(h_pad = 2.5)</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/lf/ig/xm/lfigxmxlck1s4w2uyygfudghajm.png"><br><br>  Das Bild √§hnelt der Verteilung nach Alter - mit einem Anstieg des Indikators steigt die Wahrscheinlichkeit einer Kreditrendite.  Die dritte Quelle ist in dieser Hinsicht die m√§chtigste.  Obwohl die Korrelation mit der Zielvariablen in absoluten Zahlen immer noch in der Kategorie ‚Äûsehr niedrig‚Äú liegt, werden externe Datenquellen und das Alter f√ºr die Erstellung des Modells von h√∂chster Bedeutung sein. <br><br><h3>  Paar Zeitplan </h3><br>  Um die Beziehung dieser Variablen besser zu verstehen, k√∂nnen Sie ein Paardiagramm erstellen. Darin sehen Sie die Beziehung jedes Paares und ein Histogramm der Verteilung entlang der Diagonale.  Oberhalb der Diagonale k√∂nnen Sie das Streudiagramm und darunter - 2d KDE anzeigen. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       age_data = app_train[['TARGET', 'DAYS_BIRTH']] age_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / 365‚Äã #     plot_data = ext_data.drop(labels = ['DAYS_BIRTH'], axis=1).copy()‚Äã #   plot_data['YEARS_BIRTH'] = age_data['YEARS_BIRTH']‚Äã #         100 .  plot_data = plot_data.dropna().loc[:100000, :]‚Äã #     def corr_func(x, y, **kwargs): r = np.corrcoef(x, y)[0][1] ax = plt.gca() ax.annotate("r = {:.2f}".format(r), xy=(.2, .8), xycoords=ax.transAxes, size = 20)‚Äã #   pairgrid object grid = sns.PairGrid(data = plot_data, size = 3, diag_sharey=False, hue = 'TARGET', vars = [x for x in list(plot_data.columns) if x != 'TARGET'])‚Äã #  -  grid.map_upper(plt.scatter, alpha = 0.2)‚Äã #  -  grid.map_diag(sns.kdeplot)‚Äã #  -   grid.map_lower(sns.kdeplot, cmap = plt.cm.OrRd_r);‚Äã plt.suptitle('Ext Source and Age Features Pairs Plot', size = 32, y = 1.05);</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/wu/bm/ut/wubmutz04p4kwsmmk34gbuoq71g.png"><br><br>  R√ºckzahlbare Kredite werden in blau angezeigt, nicht r√ºckzahlbar in rot.  All dies zu interpretieren ist ziemlich schwierig, aber ein guter Druck auf einem T-Shirt oder einem Bild in einem Museum f√ºr moderne Kunst kann aus diesem Bild hervorgehen. <br><br><h3>  Untersuchung anderer Anzeichen </h3><br>  Lassen Sie uns andere Merkmale und ihre Abh√§ngigkeit von der Zielvariablen genauer betrachten.  Da es viele kategoriale gibt (und wir haben es bereits geschafft, sie zu kodieren), ben√∂tigen wir wieder die Anfangsdaten.  Nennen wir sie etwas anders, um Verwirrung zu vermeiden <br><br><pre> <code class="python hljs">application_train = pd.read_csv(PATH+<span class="hljs-string"><span class="hljs-string">"application_train.csv"</span></span>) application_test = pd.read_csv(PATH+<span class="hljs-string"><span class="hljs-string">"application_test.csv"</span></span>)</code> </pre> <br>  Wir werden auch einige Funktionen ben√∂tigen, um die Verteilungen und ihren Einfluss auf die Zielvariable sch√∂n darzustellen.  Vielen Dank <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">an</a> sie f√ºr den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Autor</a> dieses <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kernels</a> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_stats</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(feature,label_rotation=False,horizontal_layout=True)</span></span></span><span class="hljs-function">:</span></span> temp = application_train[feature].value_counts() df1 = pd.DataFrame({feature: temp.index,<span class="hljs-string"><span class="hljs-string">' '</span></span>: temp.values})‚Äã <span class="hljs-comment"><span class="hljs-comment">#   target=1   cat_perc = application_train[[feature, 'TARGET']].groupby([feature],as_index=False).mean() cat_perc.sort_values(by='TARGET', ascending=False, inplace=True) if(horizontal_layout): fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6)) else: fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12,14)) sns.set_color_codes("pastel") s = sns.barplot(ax=ax1, x = feature, y=" ",data=df1) if(label_rotation): s.set_xticklabels(s.get_xticklabels(),rotation=90) s = sns.barplot(ax=ax2, x = feature, y='TARGET', order=cat_perc[feature], data=cat_perc) if(label_rotation): s.set_xticklabels(s.get_xticklabels(),rotation=90) plt.ylabel(' ', fontsize=10) plt.tick_params(axis='both', which='major', labelsize=10)‚Äã plt.show();</span></span></code> </pre> <br>  Wir werden also die Hauptzeichen der Kunden ber√ºcksichtigen <br><br><h3>  Art des Darlehens </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_TYPE'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/gf/xr/hd/gfxrhdfhqe7zyvlvwjmtgg-opam.png"><br><br>  Interessanterweise machen revolvierende Kredite (wahrscheinlich √úberziehungskredite oder √§hnliches) weniger als 10% der Gesamtzahl der Kredite aus.  Gleichzeitig ist der Prozentsatz der Nichtrendite unter ihnen viel h√∂her.  Ein guter Grund, die Arbeitsweise dieser Kredite zu √ºberarbeiten und sie vielleicht sogar aufzugeben. <br><br><h3>  Geschlecht des Kunden </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CODE_GENDER'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/fj/vu/eu/fjvueuchpemqvpmijfzsslyiy5m.png"><br><br>  Es gibt fast doppelt so viele weibliche Klienten wie M√§nner, wobei M√§nner ein viel h√∂heres Risiko aufweisen. <br><br><h3>  Auto- und Eigentum </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'FLAG_OWN_CAR'</span></span>) plot_stats(<span class="hljs-string"><span class="hljs-string">'FLAG_OWN_REALTY'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/l4/iv/u4/l4ivu4-yhdkdma8yjrnhj07evdq.png"><br><img src="https://habrastorage.org/webt/fg/qn/2-/fgqn2-3qqhjvkbovec9zm_qkfgo.png"><br><br>  Kunden mit dem Auto sind halb so viel wie "pferdelos".  Das Risiko ist fast gleich, Kunden mit der Maschine zahlen etwas besser. <br><br>  Bei Immobilien ist das Gegenteil der Fall - es gibt halb so wenige Kunden ohne diese.  Das Risiko f√ºr Immobilienbesitzer ist ebenfalls etwas geringer. <br><br><h3>  Familienstand </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_FAMILY_STATUS'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/7u/qt/t1/7uqtt10kghqs01w-_y_1e6vx2jw.png"><br><br>  W√§hrend die meisten Klienten verheiratet sind, sind Zivil- und Alleinklienten die riskantesten.  Witwer weisen ein minimales Risiko auf. <br><br><h3>  Anzahl der Kinder </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CNT_CHILDREN'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/5s/ux/o8/5suxo8vh8yl68pnxqf4vm7c-ixa.png"><br><br>  Die meisten Kunden sind kinderlos.  Gleichzeitig weisen Kunden mit 9 und 11 Kindern eine vollst√§ndige Nichtr√ºckerstattung auf <br><br><pre> <code class="python hljs">application_train.CNT_CHILDREN.value_counts()</code> </pre> <br> <code>0 215371 <br> 1 61119 <br> 2 26749 <br> 3 3717 <br> 4 429 <br> 5 84 <br> 6 21 <br> 7 7 <br> 14 3 <br> 19 2 <br> 12 2 <br> 10 2 <br> 9 2 <br> 8 2 <br> 11 1 <br> Name: CNT_CHILDREN, dtype: int64</code> <br> <br>  Wie die Berechnung der Werte zeigt, sind diese Daten statistisch nicht signifikant - nur 1-2 Kunden beider Kategorien.  Alle drei gingen jedoch in Verzug, ebenso wie die H√§lfte der Kunden mit 6 Kindern. <br><br><h3>  Anzahl der Familienmitglieder </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CNT_FAM_MEMBERS'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/bw/tg/sc/bwtgsctk9vk_y8tcx9bv9fraogu.png"><br><br>  Die Situation ist √§hnlich - je weniger M√ºnder, desto h√∂her die Rendite. <br><br><h3>  Art des Einkommens </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_INCOME_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/ow/la/kf/owlakfzs7cqh74msyjw9ngeq8h4.png"><br><br>  Alleinerziehende M√ºtter und Arbeitslose werden wahrscheinlich in der Antragsphase abgeschnitten - es gibt zu wenige von ihnen in der Stichprobe.  Aber die Probleme zeigen sich stabil. <br><br><h3>  Art der Aktivit√§t </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'OCCUPATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/pw/m4/eu/pwm4eui3y46rrd0380w5jnkqiug.png"><br><br><pre> <code class="python hljs">application_train.OCCUPATION_TYPE.value_counts()</code> </pre> <br> <code>Laborers 55186 <br> Sales staff 32102 <br> Core staff 27570 <br> Managers 21371 <br> Drivers 18603 <br> High skill tech staff 11380 <br> Accountants 9813 <br> Medicine staff 8537 <br> Security staff 6721 <br> Cooking staff 5946 <br> Cleaning staff 4653 <br> Private service staff 2652 <br> Low-skill Laborers 2093 <br> Waiters/barmen staff 1348 <br> Secretaries 1305 <br> Realty agents 751 <br> HR staff 563 <br> IT staff 526 <br> Name: OCCUPATION_TYPE, dtype: int64</code> <br> <br>  Es ist f√ºr Fahrer und Sicherheitsbeamte von Interesse, die zahlreich sind und h√§ufiger Probleme haben als andere Kategorien. <br><br><h3>  Bildung </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_EDUCATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/dh/g9/-t/dhg9-t4wl5oaaultg0m4ujq4ky0.png"><br><br>  Je h√∂her die Ausbildung, desto besser ist nat√ºrlich die Wiederholung. <br><br><h3>  Art der Organisation - Arbeitgeber </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'ORGANIZATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/nm/eq/p-/nmeqp-rvrmowwpqhkjzvygeah20.png"><br><br>  Der h√∂chste Prozentsatz der Nichtr√ºckgabe wird bei Transport: Typ 3 (16%), Branche: Typ 13 (13,5%), Branche: Typ 8 (12,5%) und Restaurant (bis zu 12%) beobachtet. <br><br><h3>  Kreditvergabe </h3><br>  Ber√ºcksichtigen Sie die Verteilung der Kreditbetr√§ge und ihre Auswirkungen auf die R√ºckzahlung <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>)) plt.title(<span class="hljs-string"><span class="hljs-string">" AMT_CREDIT"</span></span>) ax = sns.distplot(app_train[<span class="hljs-string"><span class="hljs-string">"AMT_CREDIT"</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/x1/8k/qg/x18kqghr1tue4io96l_keuqcr94.png"><br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'AMT_CREDIT'], label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'AMT_CREDIT'], label = 'target == 1')‚Äã #  plt.xlabel(' '); plt.ylabel(''); plt.title(' ');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/_3/fu/cj/_3fucjn19lmxvjjaamrrlwumh5m.png"><br><br>  Wie das Dichtediagramm zeigt, werden robuste Mengen h√§ufiger zur√ºckgegeben <br><br><h3>  Dichteverteilung </h3><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>)) plt.title(<span class="hljs-string"><span class="hljs-string">" REGION_POPULATION_RELATIVE"</span></span>) ax = sns.distplot(app_train[<span class="hljs-string"><span class="hljs-string">"REGION_POPULATION_RELATIVE"</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/26/3h/os/263hoss0mbvvq2p0ewagrw5v-sm.png"><br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'REGION_POPULATION_RELATIVE'], label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'REGION_POPULATION_RELATIVE'], label = 'target == 1')‚Äã #  plt.xlabel(''); plt.ylabel(' '); plt.title(' ');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/fs/ez/82/fsez82q5fbqdkiqizkxjralpm-8.png"><br><br>  Kunden aus bev√∂lkerungsreicheren Regionen zahlen Kredite tendenziell besser. <br><br>  So erhielten wir eine Vorstellung von den Hauptmerkmalen des Datensatzes und deren Einfluss auf das Ergebnis.  Wir werden nichts spezielles mit den in diesem Artikel aufgef√ºhrten tun, aber sie k√∂nnen sich in zuk√ºnftigen Arbeiten als sehr wichtig herausstellen. <br><br><h2>  Feature Engineering - Feature-Konvertierung </h2><br>  Wettbewerbe auf Kaggle werden durch Transformation von Zeichen gewonnen - derjenige, der aus den Daten die n√ºtzlichsten Zeichen erstellen kann, gewinnt.  Zumindest f√ºr strukturierte Daten sind Gewinnmodelle jetzt grunds√§tzlich verschiedene Optionen zur Erh√∂hung des Gradienten.  In den meisten F√§llen ist es effizienter, Zeit mit der Konvertierung von Attributen zu verbringen, als Hyperparameter einzurichten oder Modelle auszuw√§hlen.  Ein Modell kann immer noch nur aus den Daten lernen, die an es √ºbertragen wurden.  Die Hauptverantwortung f√ºr das Datum des Wissenschaftlers liegt darin, sicherzustellen, dass die Daten f√ºr die Aufgabe relevant sind. <br><br>  Der Prozess der Transformation von Merkmalen kann die Erstellung neuer verf√ºgbarer Daten, die Auswahl der wichtigsten verf√ºgbaren Daten usw. umfassen.  Wir werden diesmal Polynomzeichen versuchen. <br><br><h3>  Polynomzeichen </h3><br>  Die Polynommethode zum Erstellen von Features besteht darin, dass wir einfach Features erstellen, die dem Grad der verf√ºgbaren Features und ihren Produkten entsprechen.  In einigen F√§llen k√∂nnen solche konstruierten Merkmale eine st√§rkere Korrelation mit der Zielvariablen aufweisen als ihre ‚ÄûEltern‚Äú.  Obwohl solche Methoden h√§ufig in statistischen Modellen verwendet werden, sind sie beim maschinellen Lernen viel seltener.  Allerdings.  Nichts hindert uns daran, sie auszuprobieren, zumal Scikit-Learn eine Klasse speziell f√ºr diese Zwecke hat - PolynomialFeatures -, die Polynom-Features und ihre Produkte erstellt. Sie m√ºssen nur die urspr√ºnglichen Features selbst und den maximalen Grad angeben, in dem sie erh√∂ht werden m√ºssen.  Wir verwenden die st√§rksten Effekte auf das Ergebnis von 4 Attributen und Grad 3, um das Modell nicht zu komplizieren und eine √úberanpassung zu vermeiden (√úbertraining des Modells - seine √ºberm√§√üige Anpassung an das Trainingsmuster). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       poly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']] poly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]‚Äã #    from sklearn.preprocessing import Imputer imputer = Imputer(strategy = 'median')‚Äã poly_target = poly_features['TARGET']‚Äã poly_features = poly_features.drop('TARGET', axis=1)‚Äã poly_features = imputer.fit_transform(poly_features) poly_features_test = imputer.transform(poly_features_test) from sklearn.preprocessing import PolynomialFeatures #     3 poly_transformer = PolynomialFeatures(degree = 3) #    poly_transformer.fit(poly_features) #   poly_features = poly_transformer.transform(poly_features) poly_features_test = poly_transformer.transform(poly_features_test) print('  : ', poly_features.shape)</span></span></code> </pre> <br> <code>  : (307511, 35) <br>        get_feature_names</code> <br> <br><pre> <code class="python hljs">poly_transformer.get_feature_names(input_features = [<span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_1'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_2'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_3'</span></span>, <span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>])[:<span class="hljs-number"><span class="hljs-number">15</span></span>]</code> </pre> <br> <code>['1', <br> 'EXT_SOURCE_1', <br> 'EXT_SOURCE_2', <br> 'EXT_SOURCE_3', <br> 'DAYS_BIRTH', <br> 'EXT_SOURCE_1^2', <br> 'EXT_SOURCE_1 EXT_SOURCE_2', <br> 'EXT_SOURCE_1 EXT_SOURCE_3', <br> 'EXT_SOURCE_1 DAYS_BIRTH', <br> 'EXT_SOURCE_2^2', <br> 'EXT_SOURCE_2 EXT_SOURCE_3', <br> 'EXT_SOURCE_2 DAYS_BIRTH', <br> 'EXT_SOURCE_3^2', <br> 'EXT_SOURCE_3 DAYS_BIRTH', <br> 'DAYS_BIRTH^2']</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Insgesamt 35 Polynom- und Ableitungsmerkmale. </font><font style="vertical-align: inherit;">√úberpr√ºfen Sie ihre Korrelation mit dem Ziel.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     poly_features = pd.DataFrame(poly_features, columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']))‚Äã #   poly_features['TARGET'] = poly_target‚Äã #   poly_corrs = poly_features.corr()['TARGET'].sort_values()‚Äã #      print(poly_corrs.head(10)) print(poly_corrs.tail(5))</span></span></code> </pre> <br> <code>EXT_SOURCE_2 EXT_SOURCE_3 -0.193939 <br> EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3 -0.189605 <br> EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH -0.181283 <br> EXT_SOURCE_2^2 EXT_SOURCE_3 -0.176428 <br> EXT_SOURCE_2 EXT_SOURCE_3^2 -0.172282 <br> EXT_SOURCE_1 EXT_SOURCE_2 -0.166625 <br> EXT_SOURCE_1 EXT_SOURCE_3 -0.164065 <br> EXT_SOURCE_2 -0.160295 <br> EXT_SOURCE_2 DAYS_BIRTH -0.156873 <br> EXT_SOURCE_1 EXT_SOURCE_2^2 -0.156867 <br> Name: TARGET, dtype: float64 <br> DAYS_BIRTH -0.078239 <br> DAYS_BIRTH^2 -0.076672 <br> DAYS_BIRTH^3 -0.074273 <br> TARGET 1.000000 <br> 1 NaN <br> Name: TARGET, dtype: float64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Einige Zeichen zeigen also eine h√∂here Korrelation als das Original. </font><font style="vertical-align: inherit;">Es ist sinnvoll, mit und ohne sie zu lernen (wie viel mehr beim maschinellen Lernen kann dies experimentell bestimmt werden). </font><font style="vertical-align: inherit;">Erstellen Sie dazu eine Kopie der Datenrahmen und f√ºgen Sie dort neue Funktionen hinzu.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      poly_features_test = pd.DataFrame(poly_features_test, columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']))‚Äã #    poly_features['SK_ID_CURR'] = app_train['SK_ID_CURR'] app_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')‚Äã #    poly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR'] app_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')‚Äã #   app_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)‚Äã #   print('    : ', app_train_poly.shape) print('    : ', app_test_poly.shape)</span></span></code> </pre> <br> <code>    : (307511, 277) <br>     : (48744, 277)</code> <br> <br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modelltraining </font></font></h2><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Grundstufe </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In den Berechnungen m√ºssen Sie von einer grundlegenden Ebene des Modells ausgehen, unter die es nicht mehr m√∂glich ist, zu fallen. </font><font style="vertical-align: inherit;">In unserem Fall k√∂nnte dies f√ºr alle Testkunden 0,5 sein - dies zeigt, dass wir √ºberhaupt keine Ahnung haben, ob der Kunde das Darlehen zur√ºckzahlen wird oder nicht. </font><font style="vertical-align: inherit;">In unserem Fall wurden bereits Vorarbeiten durchgef√ºhrt und komplexere Modelle k√∂nnen verwendet werden.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Logistische Regression </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">logistische Regression</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> zu berechnen </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">, m√ºssen</font></a><font style="vertical-align: inherit;"> wir Tabellen mit codierten kategorialen Merkmalen erstellen, die fehlenden Daten ausf√ºllen und normalisieren (auf Werte von 0 bis 1 bringen). </font><font style="vertical-align: inherit;">All dies f√ºhrt den folgenden Code aus:</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MinMaxScaler, Imputer‚Äã <span class="hljs-comment"><span class="hljs-comment">#      if 'TARGET' in app_train: train = app_train.drop(labels = ['TARGET'], axis=1) else: train = app_train.copy() features = list(train.columns)‚Äã #    test = app_test.copy()‚Äã #     imputer = Imputer(strategy = 'median')‚Äã #  scaler = MinMaxScaler(feature_range = (0, 1))‚Äã #    imputer.fit(train)‚Äã #      train = imputer.transform(train) test = imputer.transform(app_test)‚Äã #      scaler.fit(train) train = scaler.transform(train) test = scaler.transform(test)‚Äã print('  : ', train.shape) print('  : ', test.shape)</span></span></code> </pre> <br> <code>  : (307511, 242) <br>   : (48744, 242)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir verwenden die logistische Regression von Scikit-Learn als erstes Modell. </font><font style="vertical-align: inherit;">Nehmen wir das Entlaubungsmodell mit einer Korrektur - wir senken den Regularisierungsparameter C, um eine √úberanpassung zu vermeiden. </font><font style="vertical-align: inherit;">Die Syntax ist normal - wir erstellen ein Modell, trainieren es und prognostizieren die Wahrscheinlichkeit mit Predict_Proba (wir brauchen Wahrscheinlichkeit, nicht 0/1).</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LogisticRegression‚Äã <span class="hljs-comment"><span class="hljs-comment">#   log_reg = LogisticRegression(C = 0.0001)‚Äã #   log_reg.fit(train, train_labels) LogisticRegression(C=0.0001, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='liblinear', tol=0.0001, verbose=0, warm_start=False)      .  prdict_proba     mx 2,  m -  ,   -  0,  -  1.    ( ). log_reg_pred = log_reg.predict_proba(test)[:, 1]</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jetzt k√∂nnen Sie eine Datei zum Hochladen auf Kaggle erstellen. </font><font style="vertical-align: inherit;">Erstellen Sie einen Datenrahmen aus der Kunden-ID und der Wahrscheinlichkeit einer Nichtr√ºckgabe und laden Sie ihn hoch.</font></font><br><br><pre> <code class="python hljs">submit = app_test[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]] submit[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>] = log_reg_pred‚Äã submit.head()</code> </pre> <br> <code>SK_ID_CURR TARGET <br> 0 100001 0.087954 <br> 1 100005 0.163151 <br> 2 100013 0.109923 <br> 3 100028 0.077124 <br> 4 100038 0.151694</code> <br> <br><pre> <code class="python hljs">submit.to_csv(<span class="hljs-string"><span class="hljs-string">'log_reg_baseline.csv'</span></span>, index = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Ergebnis unserer titanischen Arbeit: 0,673, mit dem besten Ergebnis f√ºr heute ist 0,802.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Verbessertes Modell - Zuf√§lliger Wald </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Logreg zeigt sich nicht sehr gut. Versuchen wir, ein verbessertes Modell zu verwenden - einen zuf√§lligen Wald. </font><font style="vertical-align: inherit;">Dies ist ein viel leistungsf√§higeres Modell, das Hunderte von B√§umen bauen und ein viel genaueres Ergebnis erzielen kann. </font><font style="vertical-align: inherit;">Wir benutzen 100 B√§ume. </font><font style="vertical-align: inherit;">Das Schema der Arbeit mit dem Modell ist das gleiche, v√∂llig standardm√§√üige - Laden des Klassifikators, Training. </font><font style="vertical-align: inherit;">Vorhersage.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier‚Äã <span class="hljs-comment"><span class="hljs-comment">#   random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50)‚Äã #     random_forest.fit(train, train_labels)‚Äã #     predictions = random_forest.predict_proba(test)[:, 1]‚Äã #     submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #  submit.to_csv('random_forest_baseline.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das zuf√§llige Waldergebnis ist etwas besser - 0,683</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Trainingsmodell mit Polynommerkmalen </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jetzt haben wir ein Modell. </font><font style="vertical-align: inherit;">Das macht zumindest etwas - es ist Zeit, unsere Polynomzeichen zu testen. </font><font style="vertical-align: inherit;">Machen wir dasselbe mit ihnen und vergleichen wir das Ergebnis.</font></font><br><br><pre> <code class="python hljs">poly_features_names = list(app_train_poly.columns)‚Äã <span class="hljs-comment"><span class="hljs-comment">#         imputer = Imputer(strategy = 'median')‚Äã poly_features = imputer.fit_transform(app_train_poly) poly_features_test = imputer.transform(app_test_poly)‚Äã #  scaler = MinMaxScaler(feature_range = (0, 1))‚Äã poly_features = scaler.fit_transform(poly_features) poly_features_test = scaler.transform(poly_features_test)‚Äã random_forest_poly = RandomForestClassifier(n_estimators = 100, random_state = 50) #     random_forest_poly.fit(poly_features, train_labels)‚Äã #  predictions = random_forest_poly.predict_proba(poly_features_test)[:, 1]‚Äã #    submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #   submit.to_csv('random_forest_baseline_engineered.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Ergebnis eines zuf√§lligen Waldes mit Polynommerkmalen ist schlechter geworden - 0,633. </font><font style="vertical-align: inherit;">Was die Notwendigkeit ihrer Verwendung stark in Frage stellt.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Gradientenverst√§rkung </font></font></h3><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a> ‚Äî ¬´ ¬ª   .     ¬´¬ª .       . <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LGBMClassifier‚Äã clf = LGBMClassifier() clf.fit(train, train_labels)‚Äã predictions = clf.predict_proba(test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]‚Äã <span class="hljs-comment"><span class="hljs-comment">#    submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #   submit.to_csv('lightgbm_baseline.csv', index = False)</span></span></code> </pre> <br><br> <b> LightGBM ‚Äî 0,735,       </b> <br><br><h3>   ‚Äî   </h3><br>      ‚Äî     (      ).      ,    ,           . <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      def show_feature_importances(model, features): plt.figure(figsize = (12, 8)) #          results = pd.DataFrame({'feature': features, 'importance': model.feature_importances_}) results = results.sort_values('importance', ascending = False) #  print(results.head(10)) print('\n     0.01 = ', np.sum(results['importance'] &gt; 0.01)) #  results.head(20).plot(x = 'feature', y = 'importance', kind = 'barh', color = 'red', edgecolor = 'k', title = 'Feature Importances'); return results #         feature_importances = show_feature_importances(clf, features)</span></span></code> </pre> <br>‚Äã <code>feature importance <br> 28 EXT_SOURCE_1 310 <br> 30 EXT_SOURCE_3 282 <br> 29 EXT_SOURCE_2 271 <br> 7 DAYS_BIRTH 192 <br> 3 AMT_CREDIT 161 <br> 4 AMT_ANNUITY 142 <br> 5 AMT_GOODS_PRICE 129 <br> 8 DAYS_EMPLOYED 127 <br> 10 DAYS_ID_PUBLISH 102 <br> 9 DAYS_REGISTRATION 69 <br> <br>     0.01 = 158</code> <br> <br><img src="https://habrastorage.org/webt/uc/pi/ox/ucpiox1dno_vps4lsuk0lmxk7si.png"><br><br>    ,        4 .   ‚Äî      ,      ,      <br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Hinzuf√ºgen von Daten aus anderen Tabellen </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jetzt werden wir sorgf√§ltig √ºber zus√§tzliche Tabellen nachdenken und dar√ºber, was damit gemacht werden kann. </font><font style="vertical-align: inherit;">Beginnen Sie sofort mit der Vorbereitung der Tische f√ºr das weitere Training. </font><font style="vertical-align: inherit;">L√∂schen Sie jedoch zuerst die umfangreichen Tabellen der Vergangenheit aus dem Speicher, l√∂schen Sie den Speicher mit dem Garbage Collector und importieren Sie die f√ºr die weitere Analyse erforderlichen Bibliotheken.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gc‚Äã <span class="hljs-comment"><span class="hljs-comment">#del app_train, app_test, train_labels, application_train, application_test, poly_features, poly_features_test‚Äã gc.collect() import pandas as pd import numpy as np‚Äã from sklearn.preprocessing import MinMaxScaler, LabelEncoder from sklearn.model_selection import train_test_split, KFold from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix from sklearn.feature_selection import VarianceThreshold‚Äã from lightgbm import LGBMClassifier</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Importieren Sie Daten und entfernen Sie sofort die Zielspalte in einer separaten Spalte </font></font><br><br><pre> <code class="python hljs">data = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/application_train.csv'</span></span>) test = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/application_test.csv'</span></span>) prev = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/previous_application.csv'</span></span>) buro = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/bureau.csv'</span></span>) buro_balance = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/bureau_balance.csv'</span></span>) credit_card = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/credit_card_balance.csv'</span></span>) POS_CASH = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/POS_CASH_balance.csv'</span></span>) payments = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/installments_payments.csv'</span></span>)‚Äã <span class="hljs-comment"><span class="hljs-comment">#Separate target variable y = data['TARGET'] del data['TARGET']</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Codieren Sie sofort kategoriale Features. </font><font style="vertical-align: inherit;">Wir haben dies bereits zuvor getan und die Trainings- und Testmuster separat codiert und dann die Daten ausgerichtet. </font><font style="vertical-align: inherit;">Versuchen wir einen etwas anderen Ansatz - wir werden alle diese kategorialen Zeichen finden, die Datenrahmen kombinieren, aus der Liste der gefundenen kodieren und dann die Stichproben erneut in Trainings- und Testmuster unterteilen.</font></font><br><br><pre> <code class="python hljs">categorical_features = [col <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> data[col].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>]‚Äã one_hot_df = pd.concat([data,test]) one_hot_df = pd.get_dummies(one_hot_df, columns=categorical_features)‚Äã data = one_hot_df.iloc[:data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>],:] test = one_hot_df.iloc[data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]:,]‚Äã <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, data.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, test.shape)</code> </pre> <br> <code>   (307511, 245) <br>    (48744, 245)</code> <br> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kreditb√ºrodaten zum monatlichen Kreditsaldo. </font></font></h3><br><pre> <code class="python hljs">buro_balance.head()</code> </pre> <br><img src="https://habrastorage.org/webt/pa/im/0s/paim0sea2cdjnvm7lok--vi8oke.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MONTHS_BALANCE - Die Anzahl der Monate vor dem Datum der Beantragung eines Darlehens. </font><font style="vertical-align: inherit;">Schauen Sie sich die "Status" genauer an.</font></font><br><br><pre> <code class="python hljs">buro_balance.STATUS.value_counts()</code> </pre> <br> <code>C 13646993 <br> 0 7499507 <br> X 5810482 <br> 1 242347 <br> 5 62406 <br> 2 23419 <br> 3 8924 <br> 4 5847 <br> Name: STATUS, dtype: int64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Status bedeuten Folgendes: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - geschlossen, </font><font style="vertical-align: inherit;">dh </font><font style="vertical-align: inherit;">zur√ºckgezahltes Darlehen. </font><font style="vertical-align: inherit;">X ist ein unbekannter Status. </font><font style="vertical-align: inherit;">0 - aktuelles Darlehen, keine Kriminalit√§t. </font><font style="vertical-align: inherit;">1 - Verz√∂gerung von 1-30 Tagen, 2 - Verz√∂gerung von 31-60 Tagen usw. bis Status 5 - Das Darlehen wird an einen Dritten verkauft oder abgeschrieben. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier k√∂nnen beispielsweise folgende Zeichen unterschieden werden: buro_grouped_size - die Anzahl der Eintr√§ge in der Datenbank buro_grouped_max - der maximale Kreditsaldo buro_grouped_min - der minimale Kreditsaldo </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Und all diese Kreditstatus k√∂nnen codiert werden (wir verwenden die Unstack-Methode und h√§ngen die empfangenen Daten seitdem an die Buro-Tabelle an SK_ID_BUREAU ist hier und da gleich.</font></font><br><br><pre> <code class="python hljs">buro_grouped_size = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].size() buro_grouped_max = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].max() buro_grouped_min = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].min()‚Äã buro_counts = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'STATUS'</span></span>].value_counts(normalize = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) buro_counts_unstacked = buro_counts.unstack(<span class="hljs-string"><span class="hljs-string">'STATUS'</span></span>) buro_counts_unstacked.columns = [<span class="hljs-string"><span class="hljs-string">'STATUS_0'</span></span>, <span class="hljs-string"><span class="hljs-string">'STATUS_1'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_2'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_3'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_4'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_5'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_C'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_X'</span></span>,] buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_COUNT'</span></span>] = buro_grouped_size buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_MIN'</span></span>] = buro_grouped_min buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_MAX'</span></span>] = buro_grouped_max‚Äã buro = buro.join(buro_counts_unstacked, how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> buro_balance gc.collect()</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Allgemeine Informationen zu Kreditauskunfteien </font></font></h3><br><pre> <code class="python hljs">buro.head()</code> </pre> <br><img src="https://habrastorage.org/webt/00/7q/dz/007qdzakfbvd5qiizsxqwxvoari.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Die ersten 7 Spalten werden angezeigt.) Es gibt eine </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ganze Reihe von Daten, die Sie im Allgemeinen einfach mit One-Hot-Encoding codieren k√∂nnen, gruppieren nach SK_ID_CURR, durchschnittlich und auf die gleiche Weise f√ºr den Beitritt zur Haupttabelle vorbereiten</font></font><br><br><pre> <code class="python hljs">buro_cat_features = [bcol <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> bcol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> buro.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> buro[bcol].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>] buro = pd.get_dummies(buro, columns=buro_cat_features) avg_buro = buro.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() avg_buro[<span class="hljs-string"><span class="hljs-string">'buro_count'</span></span>] = buro[[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>, <span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).count()[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_buro[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> buro gc.collect()</code> </pre> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Daten zu fr√ºheren Anwendungen </font></font></h3><br><pre> <code class="python hljs">prev.head()</code> </pre> <br><img src="https://habrastorage.org/webt/nx/sv/z-/nxsvz-simhdingy0zqgnwg9xxpi.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> In √§hnlicher Weise codieren wir kategoriale Merkmale, mitteln und kombinieren sie √ºber die aktuelle ID. </font></font><br><br><pre> <code class="python hljs">prev_cat_features = [pcol <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> pcol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> prev.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> prev[pcol].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>] prev = pd.get_dummies(prev, columns=prev_cat_features) avg_prev = prev.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() cnt_prev = prev[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).count() avg_prev[<span class="hljs-string"><span class="hljs-string">'nb_app'</span></span>] = cnt_prev[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_prev[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> prev gc.collect()</code> </pre> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kreditkartenguthaben </font></font></h3><br><pre> <code class="python hljs">POS_CASH.head()</code> </pre> <br><img src="https://habrastorage.org/webt/aq/25/er/aq25erq2wzuknck85ina4twk2g8.png"><br><br><pre> <code class="python hljs">POS_CASH.NAME_CONTRACT_STATUS.value_counts()</code> </pre> <br> <code>Active 9151119 <br> Completed 744883 <br> Signed 87260 <br> Demand 7065 <br> Returned to the store 5461 <br> Approved 4917 <br> Amortized debt 636 <br> Canceled 15 <br> XNA 2 <br> Name: NAME_CONTRACT_STATUS, dtype: int64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wir codieren kategoriale Merkmale und bereiten eine Tabelle zum Kombinieren vor </font></font><br><br><pre> <code class="python hljs">le = LabelEncoder() POS_CASH[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] = le.fit_transform(POS_CASH[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>].astype(str)) nunique_status = POS_CASH[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).nunique() nunique_status2 = POS_CASH[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() POS_CASH[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS'</span></span>] = nunique_status[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] POS_CASH[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS2'</span></span>] = nunique_status2[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] POS_CASH.drop([<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kartendaten </font></font></h3><br><pre> <code class="python hljs">credit_card.head()</code> </pre> <br><img src="https://habrastorage.org/webt/q5/wj/pj/q5wjpj8s-vak-svacdtlhqrwlus.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(erste 7 Spalten) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Ñhnliche Arbeit</font></font><br><br><pre> <code class="python hljs">credit_card[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] = le.fit_transform(credit_card[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>].astype(str)) nunique_status = credit_card[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).nunique() nunique_status2 = credit_card[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() credit_card[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS'</span></span>] = nunique_status[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] credit_card[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS2'</span></span>] = nunique_status2[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] credit_card.drop([<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Zahlungsdaten </font></font></h3><br><pre> <code class="python hljs">payments.head()</code> </pre> <br><img src="https://habrastorage.org/webt/ay/fy/3y/ayfy3yp5tzdxsffurkrgjd4udwu.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Die ersten 7 Spalten werden angezeigt.) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erstellen wir drei Tabellen - mit Durchschnitts-, Minimal- und Maximalwerten aus dieser Tabelle.</font></font><br><br><pre> <code class="python hljs">avg_payments = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() avg_payments2 = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() avg_payments3 = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).min() <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_payments[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> payments gc.collect()</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tabellenverkn√ºpfung </font></font></h3><br><pre> <code class="python hljs">data = data.merge(right=avg_prev.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_prev.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_buro.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_buro.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(POS_CASH.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(POS_CASH.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(credit_card.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(credit_card.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments2.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments2.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments3.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments3.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_prev, avg_buro, POS_CASH, credit_card, avg_payments, avg_payments2, avg_payments3 gc.collect() <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, data.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, test.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, y.shape)</code> </pre> <br> <code>   (307511, 504) <br>    (48744, 504) <br>    (307511,)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Und tats√§chlich werden wir diesen doppelten Tisch mit einem Gradienten-Boost treffen! </font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LGBMClassifier‚Äã clf2 = LGBMClassifier() clf2.fit(data, y)‚Äã predictions = clf2.predict_proba(test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]‚Äã <span class="hljs-comment"><span class="hljs-comment">#    submission = test[['SK_ID_CURR']] submission['TARGET'] = predictions‚Äã #   submission.to_csv('lightgbm_full.csv', index = False)</span></span></code> </pre> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">das Ergebnis ist 0,770. </font></font></b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OK, zum Schluss versuchen wir eine komplexere Technik mit Falten in Falten, Kreuzvalidierung und Auswahl der besten Iteration.</font></font><br><br><pre> <code class="python hljs">folds = KFold(n_splits=<span class="hljs-number"><span class="hljs-number">5</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">546789</span></span>) oof_preds = np.zeros(data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) sub_preds = np.zeros(test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>])‚Äã feature_importance_df = pd.DataFrame()‚Äã feats = [f <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> [<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]]‚Äã <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n_fold, (trn_idx, val_idx) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(folds.split(data)): trn_x, trn_y = data[feats].iloc[trn_idx], y.iloc[trn_idx] val_x, val_y = data[feats].iloc[val_idx], y.iloc[val_idx] clf = LGBMClassifier( n_estimators=<span class="hljs-number"><span class="hljs-number">10000</span></span>, learning_rate=<span class="hljs-number"><span class="hljs-number">0.03</span></span>, num_leaves=<span class="hljs-number"><span class="hljs-number">34</span></span>, colsample_bytree=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, subsample=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, max_depth=<span class="hljs-number"><span class="hljs-number">8</span></span>, reg_alpha=<span class="hljs-number"><span class="hljs-number">.1</span></span>, reg_lambda=<span class="hljs-number"><span class="hljs-number">.1</span></span>, min_split_gain=<span class="hljs-number"><span class="hljs-number">.01</span></span>, min_child_weight=<span class="hljs-number"><span class="hljs-number">375</span></span>, silent=<span class="hljs-number"><span class="hljs-number">-1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">-1</span></span>, ) clf.fit(trn_x, trn_y, eval_set= [(trn_x, trn_y), (val_x, val_y)], eval_metric=<span class="hljs-string"><span class="hljs-string">'auc'</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">100</span></span>, early_stopping_rounds=<span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-comment"><span class="hljs-comment">#30 ) oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1] sub_preds += clf.predict_proba(test[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits fold_importance_df = pd.DataFrame() fold_importance_df["feature"] = feats fold_importance_df["importance"] = clf.feature_importances_ fold_importance_df["fold"] = n_fold + 1 feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0) print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx]))) del clf, trn_x, trn_y, val_x, val_y gc.collect()‚Äã print('Full AUC score %.6f' % roc_auc_score(y, oof_preds))‚Äã test['TARGET'] = sub_preds‚Äã test[['SK_ID_CURR', 'TARGET']].to_csv('submission_cross.csv', index=False)</span></span></code> </pre> <br> <code>Full AUC score 0.785845</code> <br> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Letzter Treffer bei Kaggle 0.783</font></font></b> <br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wohin als n√§chstes gehen </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Arbeiten Sie auf jeden Fall weiter mit Schildern. Durchsuchen Sie die Daten, w√§hlen Sie einige der Zeichen aus, kombinieren Sie sie und h√§ngen Sie zus√§tzliche Tabellen auf andere Weise an. Sie k√∂nnen mit Hyperparametern Mogheli experimentieren - viele Richtungen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich hoffe, diese kleine Zusammenstellung hat Ihnen moderne Methoden zur Erforschung von Daten und zur Erstellung von Vorhersagemodellen gezeigt. Lerne Daten, nimm an Wettbewerben teil, sei cool! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Und wieder Links zu den Kerneln, die mir bei der Vorbereitung dieses Artikels geholfen haben. Der Artikel wird auch in Form eines </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Laptops auf Github</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ver√∂ffentlicht. Sie k√∂nnen ihn herunterladen, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">datieren</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und ausf√ºhren und experimentieren. </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Will Koehrsen. Beginnen Sie hier: Eine sanfte Einf√ºhrung </font></font></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sban. HomeCreditRisk: Umfangreiche EDA + Baseline [0.772]</font></font></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gabriel Preda. Home Credit Default Risk Extensive EDA</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pavan Raj. Loan repayers v/s Loan defaulters ‚Äî HOME CREDIT</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lem Lordje Ko. 15 lines: Just EXT_SOURCE_x</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Shanth. HOME CREDIT ‚Äî BUREAU DATA ‚Äî FEATURE ENGINEERING</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dmitriy Kisil. Good_fun_with_LigthGBM</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de414613/">https://habr.com/ru/post/de414613/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de414593/index.html">Vergleich von C # und JavaScript. Die Grundlagen</a></li>
<li><a href="../de414597/index.html">Fragen Sie Ethan: Wie nahe k√∂nnen au√üerirdische Zivilisationen zusammenkommen?</a></li>
<li><a href="../de414605/index.html">Mini-Imperien</a></li>
<li><a href="../de414609/index.html">Kann 2018 PWA (Progressive Web Apps) ein w√ºrdiger Wettbewerb f√ºr native Anwendungen sein?</a></li>
<li><a href="../de414611/index.html">Meine Geschichte, eine Motivationsanwendung (iOS und Android) f√ºr eine Tochter mit einer Tochter in Unity und C # zu erstellen</a></li>
<li><a href="../de414615/index.html">Vergessen Sie die DSGVO: Die EU-Urheberrechtsreform k√∂nnte das Web komplett ver√§ndern</a></li>
<li><a href="../de414617/index.html">Ressourceneffizienz berechnen</a></li>
<li><a href="../de414619/index.html">Red Hogwarts. Serie 8. Segel</a></li>
<li><a href="../de414621/index.html">Das Robotersystem beschleunigt die Blutentnahme und -untersuchung</a></li>
<li><a href="../de414625/index.html">Data Center World: Lohnt sich die Fahrt?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
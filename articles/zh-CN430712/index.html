<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🥢 🌽 📭 NeurIPS：如何征服最佳ML会议 👨‍🚀 🚓 🌀</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="NeurIPS –是目前被认为是机器学习领域最重要的会议。 今天，我将向您介绍我参加NeurIPS竞赛的经验：如何与世界上最好的学者竞争，获得奖品并发表文章。 


 会议的实质是什么？ 


 NeurIPS支持在各种科学学科中引入机器学习方法。 每年推出约10 条曲目 ，以解决学术界紧迫的问题。...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NeurIPS：如何征服最佳ML会议</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/430712/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">NeurIPS</a> –是目前被认为是机器学习领域最重要的会议。 今天，我将向您介绍我参加NeurIPS竞赛的经验：如何与世界上最好的学者竞争，获得奖品并发表文章。 </p><br><img src="https://habrastorage.org/webt/hb/kq/-v/hbkq-vnd_xgxhvcixlo-u8b_pmk.jpeg"><a name="habracut"></a><br><hr><br><h1 id="v-chem-sut-konferencii"> 会议的实质是什么？ </h1><br><p>  NeurIPS支持在各种科学学科中引入机器学习方法。 每年推出约10 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">条曲目</a> ，以解决学术界紧迫的问题。 根据比赛的结果，优胜者在会议上发表报告，新进展和算法。 最重要的是，我对强化学习（强化学习或RL）充满热情，这就是为什么我第二年参加了针对NeurIPS的RL竞赛的原因。 </p><br><h1 id="pochemu-neurips"> 为什么选择NeurIPS </h1><br><img src="https://habrastorage.org/webt/ei/c2/us/eic2usvfs-brxmsjczvkvygpfwq.png"><br><br>  NeurIPS主要专注于科学，而不是金钱。 通过参加比赛，您正在做一些非常重要的事情，处理紧迫的问题。 <br><p> 其次，这次会议是全球性的活动，来自不同国家的科学家聚集在一个地方，每个地方您都可以交谈。 </p><br><p> 此外，整个会议都充满了最新的科学成就和最新成果，对于数据科学领域的人们来说，了解和监控它们至关重要。 </p><br><h1 id="kak-nachat"> 如何开始？ </h1><br><p> 开始参加此类比赛非常简单。 如果您对DL的了解如此之<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">深</a> ，可以<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">培训ResNet</a> ，那就足够了：注册并开始。 总是有一个公共排行榜，您可以与其他参与者相比清醒地评估自己的水平。 如果不清楚的话–总是有闲暇/不和谐/烦恼等渠道讨论所有新出现的问题。 如果主题确实是“您的”，那么什么都不会阻止您获得珍贵的结果–在我参加的所有比赛中，都在比赛过程中研究并实施了所有方法和解决方案。 </p><br><h1 id="neurips-na-primere-konkretnogo-keysa-learning-to-run">  NeurIPS案例研究：学习跑步 </h1><br><img src="https://habrastorage.org/webt/hu/ws/d5/huwsd5weqocxiuqv3hugygmfqea.jpeg"><br><br><h3 id="problematika"> 发行 </h3><br><p> 一个人的步态是肌肉，骨骼，视觉器官和内耳相互作用的结果。 如果中枢神经系统受到破坏，则可能会发生某些运动障碍，包括步态障碍–失语症。 <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">斯坦福大学神经肌肉生物力学实验室的</a>研究人员决定将机器学习与治疗问题联系起来，以便能够在骨骼的虚拟模型上而不是在活人身上进行实验和测试。 </p><br><h3 id="postanovka-zadachi"> 问题陈述 </h3><br><p> 给参与者一个虚拟的人体骨​​骼（在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">OpenSim</a>仿真器中），该骨骼由假肢代替一只脚。 任务是教骨骼以给定速度沿特定方向移动。 在仿真过程中，方向和速度都可能改变。 </p><br><img src="https://habrastorage.org/webt/od/vj/np/odvjnpxb7xogj5h_5ll85iokhp0.jpeg"><br><br> 为了获得虚拟骨架控制模型，提出了使用强化学习的方法。 模拟器为我们提供了骨架S的状态（约400个数字的向量）。 必须预测需要执行什么动作A（腿部肌肉的激活力是19个数字的向量）。 在仿真过程中，骨架被授予R奖-作为一种常数减去对给定速度和方向的偏离的惩罚。 <br><div class="spoiler">  <b class="spoiler_title">关于强化训练</b> <div class="spoiler_text"><p> 强化学习（RL）是一个涉及决策理论和寻求最佳行为策略的领域。 </p><br><p> 回想一下他们的教学方式 <del> 猫 </del> 小狗的新花样。 重复一些动作，给人以表演技巧的机会，不要为失败而付出。 狗应该了解所有这一切，并找到一种行为策略（就RL而言是“策略”或“策略”），该策略可以使所接收的糖果数量最大化。 </p><br><p> 正式地，我们有一个代理商（狗），他受过与环境（人）互动历史的培训。 同时，评估代理人行为的环境为他提供了奖励（美味）-代理人的行为越好，奖励就越大。 因此，代理商的任务是找到一种政策，在与环境互动的整个过程中最大限度地提高回报。 </p><br><p> 进一步开发该主题时，基于规则的解决方案-软件1.0（由开发人员设置所有规则），有监督的学习-软件2.0（当系统使用可用示例进行自我学习并找到数据依赖项时），强化学习是系统本身的又一步学会研究，试验并在决策中找到所需的依赖性。 我们走的越远，我们越会尝试重复一个人的学习方式。 </p></div></div><br><h3 id="osobennosti-zadachi"> 任务功能 </h3><br><p> 作业看起来像是对具有连续动作空间（RL为连续动作空间）的任务进行强化学习的典型代表。 它与普通RL的不同之处在于，它不需要选择特定的动作（按操纵杆按钮），而是需要此动作来准确预测（并且存在无限多种可能性）。 </p><br><p> 解决方案的基本方法（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">深度确定性策略梯度</a> ）于2015年发明，长期以来，根据DL的标准，该地区继续积极地在机器人技术和实际RL应用程序中进行开发。 有一些需要改进的地方：健壮的方法（以免破坏真实的机器人），采样效率（以防止数月不从真实的机器人收集数据）和其他RL问题（探索与利用权衡等）。 在这场比赛中，他们没有给我们一个真正的机器人-只是一个仿真器，但是仿真器本身比开源软件（每个人都要检查其RL算法）慢2,000倍，因此将采样效率问题提高到一个新的水平。 </p><br><h3 id="etapy-sorevnovaniya"> 比赛阶段 </h3><br><p> 比赛本身分为三个阶段，在此阶段任务和条件有所变化。 </p><br><ul><li> 阶段1：骨骼学会了以每秒3米的速度笔直行走。 如果座席经过300个步骤，则认为该任务已完成。 </li><li> 第二阶段：速度和方向以固定的频率变化。 距离的长度增加到1000步。 </li><li> 第3阶段：最终解决方案必须打包在docker映像中并发送以进行验证。 总共可以制作10个包裹。 </li></ul><br><p> 主要的质量指标被认为是模拟的总回报，它显示了骨骼在整个距离上对指定方向和速度的粘附程度。 </p><br><p> 在第一阶段和第二阶段，每个参与者的进度都显示在排行榜上。 最终解决方案需要作为docker映像发送。 它规定了工作时间和资源的限制。 </p><br><div class="spoiler">  <b class="spoiler_title">Coolstory：公共排行榜和RL</b> <div class="spoiler_text"><p> 由于排行榜的可用性，没有人展示他们的最佳模式，以便在最后一轮比赛中给予“比平时多一点”的机会并使对手感到惊讶。 </p></div></div><br><h6 id="pochemu-tak-vazhny-docker-obrazy"> 为什么Docker映像如此重要 </h6><br><p> 去年，在第一轮评估决策时发生了一次小事件。 当时，检查是通过与平台的http交互进行的，并且发现了测试条件。 可以找出在哪些特定情况下对代理进行了评估，并仅在这些条件下对其进行了重新培训。 当然，这并没有解决真正的问题。 这就是为什么他们决定将提交系统转移到docker-images并在组织者的远程服务器上启动它的原因。  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">出于</a>相同的原因， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Dbrain</a>使用相同的系统精确计算比赛结果。 </p><br><h1 id="klyuchevye-momenty"> 重点 </h1><br><h3 id="komanda"> 团队 </h3><br><img src="https://habrastorage.org/webt/ty/ur/gp/tyurgpqbzb2zl2wimtzri0mnpwk.jpeg"><br><br> 对于整个企业的成功至关重要的第一件事就是团队。 无论您有多出色（以及您的爪子有多强大），参与团队都会大大增加成功的机会。 原因很简单-各种各样的意见和方法，重新检验假设，具有并行工作和进行更多实验的能力。 在解决您必须面对的新问题时，所有这些都非常重要。 <br><p> 理想情况下，您的知识和技能应处于同一水平，并且应相互补充。 因此，例如，今年我在PyTorch上建立了我们的团队，并且对实施分布式代理培训系统有了一些初步想法。 </p><br><p> 如何找到球队？ 首先，您可以加入<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ods</a>队伍并在那里寻找志趣相投的人。 其次，对于RL研究员，在电报<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">RL俱乐部中</a>有一个单独的聊天室。 第三，您可以从ShAD- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Practical RL</a>学习一门很棒的课程，然后一定会结识一些。 </p><br><p> 但是，值得记住“提交或不提交”的政策。 如果您要团结，首先要做出决定，提交，出现在排行榜上并显示您的水平。 实践证明，这样的团队更加平衡。 </p><br><h3 id="motivaciya"> 动机 </h3><br><p> 正如我已经写过的，如果主题是“您的”，那么没有什么可以阻止您。 这意味着该地区不仅会像您一样，还会激发您的灵感-燃烧它，想成为其中最好的。 <br> 我4年前遇到了RL，当时是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Berkeley 188x逝世时-AI简介</a> -但我仍然不停地想知道这方面的进展。 </p><br><h3 id="sistematichnost"> 系统的 </h3><br><p> 第三，但同样重要-您必须能够兑现承诺，每天都在竞争中投入资金，只是...解决问题。 每一天 天生的才能无法与做某事的能力相提并论。 为此，将需要动力。 为了获得成功，我建议阅读<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">DeepWork</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">AMA ternaus</a> 。 </p><br><h3 id="time-management"> 时间管理 </h3><br><p> 另一个极其重要的技能是能够分散力量并正确利用空闲时间的能力。 将全职工作和参加比赛相结合是一项艰巨的任务。 在这种情况下，最重要的是不要烧坏并承受整个负载。 为此，您需要适当地管理时间，清醒地评估自己的力量，并且不要忘记按时放松。 </p><br><h3 id="overwork"> 劳累过度 </h3><br><p> 在比赛的最后阶段，通常会出现这样一种情况，即实际上一周之内您需要做的不仅很多，而且很多。 为了获得最佳结果，您需要能够迫使自己坐下来，最后冲刺至梦prize以求的奖项。 </p><br><div class="spoiler">  <b class="spoiler_title">Coolstory：截止期限之后的截止期限</b> <div class="spoiler_text"><p> 因此，一般而言，您可能需要循环利用以利于竞争？ 答案很简单-截止日期转移。 在这样的比赛中，组织者通常无法预测所有事情，因此，最简单的方法是给参与者更多的时间。 今年比赛进行了3次：第一次是一个月，然后是一周，最后一刻（截止日期前24小时）又延长了2天。 而且，如果在前两次传输中您只需要正确地组织额外的时间，那么在最后两天中，您只需要耕作即可。 </p></div></div><br><h3 id="theory"> 理论 </h3><br><img src="https://habrastorage.org/webt/gf/rg/9q/gfrg9ql1ukvjmlbglwcizlfcpto.png"><br><p> 除其他事项外，请不要忘记理论-要了解该领域中正在发生的事情并能够注意到相关问题。 因此，例如，为了解决去年的问题，我们的团队摘录了以下文章： </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">通过深度强化学习进行持续控制</a>是有关具有连续动作空间的任务的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">深度强化学习</a>的基础文章。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">用于探索的参数空间噪声</a> -对代理权重添加噪声以更好地研究环境的研究。 根据经验-RL中最好的勘探技术之一。 </li></ul><br><p> 今年，又增加了一些： </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">强化学习的分布视角</a> -重新审视可能的奖励预测。 不是简单地预测平均值，而是计算未来奖励的分布。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">具有分位数回归的分布强化学习</a>是先前工作的延续，但具有分布的“量化”。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">分布式优先体验重播</a> -从深度强化学习的方向大规模开展工作。 关于如何正确组织实验的架构，以最大程度地利用可用资源并提高培训代理的速度。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">分布式分布确定性策略梯度</a> -前三篇文章的结合，用于具有连续操作空间的任务。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">解决Actor-Critic方法中的函数逼近误差</a> -出色的工作以提高RL代理的鲁棒性。 我建议阅读。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">数据有效的分层强化学习</a>是对分层强化学习（HRL）领域中前一篇文章的改进。 </li></ul><br><div class="spoiler">  <b class="spoiler_title">补充阅读</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">软角色批评：带有随机角色的非策略最大熵深度强化学习</a> -作者提出了一种基于非策略强化学习训练随机策略的方法。 多亏了这篇文章，即使在具有连续行动空间的任务中，也可以训练不确定性的政治家。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">分层强化学习的潜在空间策略</a>是HRL上一篇文章的延续，其中包含多层随机策略。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">多样性就是您所需要的：没有奖励功能的学习技能</a> -本文包含一种方法，可以学习许多随机的低级随机策略，而不会受到环境的任何奖励。 随后，当我们设置了奖励功能时，与奖励最相关的内容可以用来在最高级的层次上教授高级政治。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">作为概率推断的强化学习和控制：教程和复习</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">-Sergey Levine提出的</a>各种最大熵强化学习方法的概述。 </li></ul><br><p> 我还建议<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">OpenAI选择一些</a>有关强化学习<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">的文章</a>及其<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">针对Mendeley的版本</a> 。 并且，如果您对强化训练的主题感兴趣，请加入<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">RL俱乐部</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">RL论文</a> 。 </p></div></div><br><h3 id="practice"> 练习 </h3><br><img src="https://habrastorage.org/webt/xp/g7/it/xpg7itebqdpi3cwex33uzrzkidg.jpeg"><br><br> 仅仅了解理论是不够的-重要的是能够将所有这些方法付诸实践并建立正确的验证系统来评估决策。 例如，今年我们了解到，我们的经纪人在比赛结束前仅2天就无法很好地应对某些地区性案件。 因此，我们没有时间完全修正我们的模型，并且从字面上也没有获得令人垂涎的第二名的分数。 如果我们甚至在一周内发现了这一点-结果可能会更好。 <br><div class="spoiler">  <b class="spoiler_title">Coolstory：第三集</b> <div class="spoiler_text"><p> 该解决方案的最终评估是10次测试情节的平均奖励。 </p><br><img src="https://habrastorage.org/webt/jq/bj/yc/jqbjyctkjettuu2bqd19xcahssk.png"><br><p> 该图显示了测试我们的特工的结果：10个情节中有9个，我们的骨骼还不错（平均-9955.66），但是有一个情节...。没有给他第3集（奖励9870）。 正是这个错误导致最终速度下降到9947（-8分）。 </p></div></div><br><h3 id="udacha"> 祝你好运 </h3><br><p> 最后-不要忘了平庸的运气。 不要以为这是有争议的观点。 相反，一点点运气对自己不断的工作有很大的贡献：即使碰运气的可能性只有10％，尝试100次参加比赛的人比仅仅尝试1次并放弃这个想法的人成功得多。 </p><br><h1 id="tuda-i-obratno-reshenie-proshlogo-goda--trete-mestohttpswwwcrowdaiorgchallengesnips-2017-learning-to-runwinners"> 往返：去年的决定- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">第三名</a> </h1><br><img src="https://habrastorage.org/webt/mq/lx/i_/mqlxi_alc8pt0acnzwoi8twb8oo.jpeg"><br><br> 去年，我们的团队-Mikhail Pavlov和I-首次参加了NeurIPS竞赛，其主要动机只是参加了首届NeurIPS强化学习竞赛。 然后，我刚刚完成SHAD的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">实用RL</a>课程，并想测试所学技能。 结果，我们名列第三，仅输给了nnaisene（Schmidhuber）和来自中国的大学团队。 当时，我们的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">解决方案</a> “非常简单”，并且基于带有参数噪声的分布式DDPG（在ml.Training上<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">发布</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">演示</a> ）。 <br><h1 id="reshenie-etogo-goda--trete-mestohttpswwwcrowdaiorgchallengesnips-2018-ai-for-prosthetics-challengeleaderboards"> 今年的决定是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">第三名</a> </h1><br><img src="https://habrastorage.org/webt/gf/qq/to/gfqqtoneh51dn47m3f7oicyqixk.jpeg"><br><p> 今年发生了一些变化。 首先，我没有参加比赛的愿望，我想赢得比赛。 其次， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">团队</a>的组成也发生了变化：Alexey Grinchuk，Anton Pechenko和我。  Take and win-没用，但是我们再次获得了第三名。 <br> 我们的解决方案将在NeurIPS上正式提出，现在我们将只限于少数几个细节。 基于去年的决定以及今年的非政策强化学习的成功（上文），我们增加了一些我们自己的发展，我们将在NeurIPS上进行讨论，并获得了分布式全能合奏评论家，我们排名第三。 </p><br><p> 我们的所有最佳实践-分布式学习系统，算法等，将在NeurIPS之后发布并在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Catalyst.RL中</a>提供。 </p><br><div class="spoiler">  <b class="spoiler_title">Coolstory：大男孩-大枪</b> <div class="spoiler_text"><p> 我们的团队充满信心地在比赛中获得了第一名。 但是，大人物还有其他计划-比赛结束前2周有2位大型选手参加了比赛：FireWork（百度）和nnaisense（Schmidhuber）。 而且，如果我们对中文Google不能做任何事情，那么与Schmidhuber团队一起工作了很长时间，我们就设法诚实地争取了第二名，只损失了很少的利润。 在我看来，对恋人来说相当不错。 </p></div></div><br><h1 id="zachem-eto-vse"> 为什么这一切呢？ </h1><br><ul><li> 交流。 顶尖的研究人员来参加会议，您可以与他们实时聊天，而不会给出任何电子邮件通信。 </li><li> 出版刊物 如果解决方案获得了大奖，那么团队将被邀请参加会议（或可能不止一个），以提出其决定并发表文章。 </li><li> 工作机会和博士学位。 在这样的会议上发表论文和获得奖品会大大增加您在OpenAI，DeepMind，Google，Facebook，Microsoft等领先公司中获得职位的机会。 </li><li> 现实世界的价值。 进行NeurIPS是为了解决学术和现实世界中紧迫的问题。 您可以确定结果不会出现，但是确实有需求，并且将有助于改善世界。 </li><li> 驱动器 解决这样的竞赛……真有趣。 在比赛中，您可以想出很多新想法，尝试不同的方法-做到最好。 老实说，为了科学起见，您还能在什么时候以严肃的表情驾驶骨骼，玩游戏以及所有这些？ </li></ul><br><div class="spoiler">  <b class="spoiler_title">Coolstory：签证和RL</b> <div class="spoiler_text"><p> 我强烈不建议尝试训练要在模拟中运行的虚拟骨架，而是试图向美国人检查您要参加会议的解释。 只是去会议上讲话。 </p></div></div><br><h1 id="itogi"> 总结 </h1><br><p> 参加NeurIPS是一种很难被高估的经历。 不要担心备受关注的头条新闻-您只需要团结一致并开始做出决定。 </p><br><p> 然后转到<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Catalyst.RL</a> ，然后输入。 </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN430712/">https://habr.com/ru/post/zh-CN430712/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN430702/index.html">非常奇怪的训练</a></li>
<li><a href="../zh-CN430704/index.html">人工智能技术如何帮助Aviasales成长：七个例子</a></li>
<li><a href="../zh-CN430706/index.html">新进化论</a></li>
<li><a href="../zh-CN430708/index.html">井字游戏“无国界”</a></li>
<li><a href="../zh-CN430710/index.html">如果黑色星期五是明天并且您的服务器未准备好怎么办</a></li>
<li><a href="../zh-CN430714/index.html">VMware收购Heptio-对Kubernetes意味着什么</a></li>
<li><a href="../zh-CN430718/index.html">使用云视频监控对哪些对象有价值？</a></li>
<li><a href="../zh-CN430720/index.html">英特尔实感D435i：较小的更新和较短的历史题外话</a></li>
<li><a href="../zh-CN430722/index.html">PHP性能：规划，概要分析，优化</a></li>
<li><a href="../zh-CN430724/index.html">DEFCON 21. DNS会议可能对您的健康有害。 第一部分</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
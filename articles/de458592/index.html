<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®‚Äçüë¶ üèúÔ∏è üë®‚ÄçüöÄ Von der hohen Ceph-Latenz zum Kernel-Patch mit eBPF / BCC ‚õπüèø üàÅ üë®üèª‚Äçüè≠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Linux verf√ºgt √ºber eine gro√üe Anzahl von Kernel-Debugging-Tools und -Anwendungen. Die meisten von ihnen beeintr√§chtigen die Anwendungsleistung und k√∂n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Von der hohen Ceph-Latenz zum Kernel-Patch mit eBPF / BCC</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/458592/"><img src="https://habrastorage.org/webt/-8/ok/na/-8okna9qfyroicvgoz-zenv7-si.png" alt="Bild"><br><br>  Linux verf√ºgt √ºber eine gro√üe Anzahl von Kernel-Debugging-Tools und -Anwendungen.  Die meisten von ihnen beeintr√§chtigen die Anwendungsleistung und k√∂nnen nicht in der Produktion verwendet werden. <br><a name="habracut"></a><br>  Vor einigen Jahren wurde ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">weiteres Tool entwickelt</a> - eBPF.  Es erm√∂glicht die Verfolgung des Kernels und der Benutzeranwendungen mit geringem Overhead und ohne dass Programme neu erstellt und Module von Drittanbietern in den Kernel geladen werden m√ºssen. <br><br>  Jetzt gibt es viele Anwendungsdienstprogramme, die eBPF verwenden. In diesem Artikel erfahren Sie, wie Sie unser eigenes Profiling-Dienstprogramm basierend auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PythonBCC-</a> Bibliothek schreiben.  Der Artikel basiert auf realen Ereignissen.  Wir werden vom Auftreten des Problems bis zu seiner Korrektur gehen, um zu zeigen, wie vorhandene Dienstprogramme in bestimmten Situationen verwendet werden k√∂nnen. <br><br><h2>  Ceph ist langsam </h2><br>  Dem Ceph-Cluster wurde ein neuer Host hinzugef√ºgt.  Nach der Migration einiger Daten haben wir festgestellt, dass die Geschwindigkeit der Verarbeitung von Schreibanforderungen viel geringer ist als auf anderen Servern. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4c/_r/yv/4c_ryvapivstw8l-nr7dipfvh8e.png"></div><br>  Im Gegensatz zu anderen Plattformen wurden auf diesem Host bcache und der neue Linux 4.15-Kernel verwendet.  Hier wurde erstmals ein Host dieser Konfiguration verwendet.  Und zu dieser Zeit war klar, dass theoretisch alles die Wurzel des Problems sein k√∂nnte. <br><br><h3>  Untersuchung des Gastgebers </h3><br>  Lassen Sie uns zun√§chst sehen, was im ceph-osd-Prozess passiert.  Dazu verwenden wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Perf</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Flamescope</a> (mehr dazu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uw/gj/ox/uwgjoxekagdl-noj-wp_uy5g8q8.png"></div><br>  Das Bild zeigt, dass die Funktion <strong>fdatasync ()</strong> viel Zeit damit verbracht hat, eine Anforderung an die Funktion <strong>generic_make_request ()</strong> zu <strong>senden</strong> .  Dies bedeutet, dass die Ursache der Probleme h√∂chstwahrscheinlich irgendwo au√üerhalb des osd-Daemons selbst liegt.  Es kann sich entweder um einen Kernel oder um Festplatten handeln.  Die iostat-Ausgabe zeigte eine hohe Latenz bei der Verarbeitung von Anforderungen mit bcache-Festplatten. <br><br>  Bei der √úberpr√ºfung des Hosts haben wir festgestellt, dass der systemd-udevd-Daemon viel CPU-Zeit verbraucht - etwa 20% auf mehreren Kernen.  Dies ist ein seltsames Verhalten, daher m√ºssen Sie die Ursache herausfinden.  Da Systemd-udevd mit uevents arbeitet, haben wir uns entschlossen, sie √ºber den <strong>udevadm-Monitor zu betrachten</strong> .  Es stellt sich heraus, dass f√ºr jedes Blockger√§t im System eine gro√üe Anzahl von √Ñnderungsereignissen generiert wurde.  Dies ist ziemlich ungew√∂hnlich, daher m√ºssen Sie sehen, was all diese Ereignisse erzeugt. <br><br><h3>  Verwenden des BCC Toolkit </h3><br>  Wie wir bereits herausgefunden haben, verbringt der Kernel (und der Ceph-Daemon im Systemaufruf) viel Zeit in <strong>generic_make_request ()</strong> .  Versuchen wir, die Geschwindigkeit dieser Funktion zu messen.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BCC hat</a> bereits ein gro√üartiges Dienstprogramm - die <strong>Funclatency</strong> .  Wir werden den D√§mon anhand seiner PID mit einem Intervall zwischen den Informationsausgaben von 1 Sekunde verfolgen und das Ergebnis in Millisekunden ausgeben. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o7/zw/rl/o7zwrly0nejoo5r7zbezws3jxmo.png"></div><br>  Normalerweise ist diese Funktion schnell.  Sie sendet die Anforderung lediglich an die Ger√§tetreiberwarteschlange. <br><br>  <strong>Bcache</strong> ist ein komplexes Ger√§t, das tats√§chlich aus drei Festplatten besteht: <br><br><ul><li>  Sicherungsger√§t (zwischengespeicherte Festplatte), in diesem Fall eine langsame Festplatte; </li><li>  Caching-Ger√§t (Caching-Datentr√§ger), hier ist es ein Abschnitt des NVMe-Ger√§ts; </li><li>  bcache virtuelles Ger√§t, mit dem die Anwendung arbeitet. </li></ul><br>  Wir wissen, dass die Anforderungs√ºbertragung langsam ist, aber f√ºr welches dieser Ger√§te?  Wir werden uns etwas sp√§ter darum k√ºmmern. <br><br>  Wir wissen jetzt, dass Ereignisse wahrscheinlich Probleme verursachen.  Es ist nicht so einfach herauszufinden, was genau ihre Entstehung verursacht.  Angenommen, dies ist eine Art Software, die regelm√§√üig ausgef√ºhrt wird.  Lassen Sie uns sehen, welche <strong>Art</strong> von Software auf dem System mithilfe des <strong>execsnoop-</strong> Skripts aus denselben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BCC-Dienstprogrammen</a> gestartet wird.  F√ºhren Sie es aus und leiten Sie die Ausgabe in eine Datei. <br><br>  Zum Beispiel so: <br><br><pre><code class="bash hljs">/usr/share/bcc/tools/execsnoop | tee ./execdump</code> </pre> <br>  Wir werden hier nicht die vollst√§ndige Ausgabe von execsnoop geben, aber eine f√ºr uns interessante Zeile sah folgenderma√üen aus: <br><br><pre> <code class="bash hljs">sh 1764905 5802 0 sudo arcconf getconfig 1 AD | grep Temperature | awk -F <span class="hljs-string"><span class="hljs-string">'[:/]'</span></span> <span class="hljs-string"><span class="hljs-string">'{print $2}'</span></span> | sed <span class="hljs-string"><span class="hljs-string">'s/^ \([0-9]*\) C.*/\1/'</span></span></code> </pre><br>  Die dritte Spalte ist die PPID (√ºbergeordnete PID) des Prozesses.  Der Prozess mit PID 5802 erwies sich als einer der F√§den unseres √úberwachungssystems.  Bei der √úberpr√ºfung der Konfiguration des √úberwachungssystems wurden fehlerhafte Parameter gefunden.  Die Temperatur des HBA-Adapters wurde alle 30 Sekunden gemessen, was viel h√§ufiger als n√∂tig ist.  Nachdem wir das √úberpr√ºfungsintervall in ein l√§ngeres ge√§ndert haben, haben wir festgestellt, dass sich die Verz√∂gerung bei der Verarbeitung von Anforderungen auf diesem Host nicht mehr von den √ºbrigen Hosts abhebt. <br><br>  Es ist jedoch immer noch nicht klar, warum das bcache-Ger√§t so langsam war.  Wir haben eine Testplattform mit identischer Konfiguration vorbereitet und versucht, das Problem zu reproduzieren, indem wir fio auf bcache ausgef√ºhrt haben und regelm√§√üig den udevadm-Trigger gestartet haben, um Ereignisse zu generieren. <br><br><h3>  Schreiben von BCC-basierten Tools </h3><br>  Versuchen wir, ein einfaches Dienstprogramm zum Verfolgen und Anzeigen der langsamsten Aufrufe von <strong>generic_make_request ()</strong> zu <strong>schreiben</strong> .  Uns interessiert auch der Name des Laufwerks, f√ºr das diese Funktion aufgerufen wurde. <br><br>  Der Plan ist einfach: <br><br><ul><li>  Registrieren Sie <strong>kprobe</strong> bei <strong>generic_make_request ()</strong> : <br><ul><li>  Wir speichern den Datentr√§gernamen, auf den √ºber das Funktionsargument zugegriffen werden kann. </li><li>  Speichern Sie den Zeitstempel. </li></ul><br></li></ul><ul><li>  Registrieren Sie <strong>kretprobe</strong> , um von <strong>generic_make_request () zur√ºckzukehren</strong> : <br><ul><li>  Holen Sie sich den aktuellen Zeitstempel. </li><li>  Wir suchen nach dem gespeicherten Zeitstempel und vergleichen ihn mit dem aktuellen. </li><li>  Wenn das Ergebnis gr√∂√üer als das angegebene ist, suchen wir den gespeicherten Datentr√§gernamen und zeigen ihn auf dem Terminal an. </li></ul><br></li></ul>  <strong>Kprobes</strong> und <strong>Kretprobes</strong> verwenden einen Haltepunktmechanismus, um den Funktionscode im <strong>laufenden</strong> Betrieb zu √§ndern.  Sie k√∂nnen die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> und einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">guten</a> Artikel zu diesem Thema lesen.  Wenn Sie sich den Code verschiedener Dienstprogramme in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BCC</a> ansehen, werden Sie feststellen, dass sie eine identische Struktur haben.  In diesem Artikel werden wir also das Parsen von Skriptargumenten weglassen und zum BPF-Programm selbst √ºbergehen. <br><br>  Der eBPF-Text im Python-Skript sieht folgenderma√üen aus: <br><br><pre> <code class="python hljs">bpf_text = ‚Äú‚Äù‚Äù <span class="hljs-comment"><span class="hljs-comment"># Here will be the bpf program code ‚Äú‚Äù‚Äù</span></span></code> </pre><br>  Zum Austausch von Daten zwischen Funktionen verwenden eBPF-Programme <a href="">Hash-Tabellen</a> .  Wir werden es auch tun.  Als Schl√ºssel verwenden wir die PID des Prozesses und als Wert definieren wir die Struktur: <br><br><pre> <code class="python hljs">struct data_t { u64 pid; u64 ts; char comm[TASK_COMM_LEN]; u64 lat; char disk[DISK_NAME_LEN]; }; BPF_HASH(p, u64, struct data_t); BPF_PERF_OUTPUT(events);</code> </pre><br>  Hier registrieren wir eine Hash-Tabelle namens <em>p</em> mit einem Schl√ºssel vom Typ <em>u64</em> und einem Wert vom Typ <em>struct data_t</em> .  Die Tabelle wird im Rahmen unseres BPF-Programms verf√ºgbar sein.  Das Makro BPF_PERF_OUTPUT registriert eine andere Tabelle namens <em>Ereignisse</em> , mit der <a href="">Daten</a> in den Benutzerbereich √ºbertragen werden. <br><br>  Bei der Messung von Verz√∂gerungen zwischen einem Funktionsaufruf und dessen R√ºckgabe oder zwischen Aufrufen verschiedener Funktionen sollte ber√ºcksichtigt werden, dass die empfangenen Daten zum selben Kontext geh√∂ren m√ºssen.  Mit anderen Worten, Sie m√ºssen sich an den m√∂glichen parallelen Start von Funktionen erinnern.  Wir haben die M√∂glichkeit, die Verz√∂gerung zwischen dem Aufrufen einer Funktion im Kontext eines Prozesses und der R√ºckkehr von dieser Funktion im Kontext eines anderen Prozesses zu messen, aber dies ist h√∂chstwahrscheinlich nutzlos.  Ein gutes Beispiel hierf√ºr ist das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Biolatency-Dienstprogramm</a> , bei dem ein Zeiger auf eine <em>Strukturanforderung</em> , die eine einzelne Festplattenanforderung widerspiegelt, als Schl√ºssel in der Hash-Tabelle festgelegt wird. <br><br>  Als n√§chstes m√ºssen wir den Code schreiben, der ausgef√ºhrt wird, wenn die untersuchte Funktion aufgerufen wird: <br><br><pre> <code class="python hljs">void start(struct pt_regs *ctx, struct bio *bio) { u64 pid = bpf_get_current_pid_tgid(); struct data_t data = {}; u64 ts = bpf_ktime_get_ns(); data.pid = pid; data.ts = ts; bpf_probe_read_str(&amp;data.disk, sizeof(data.disk), (void*)bio-&gt;bi_disk-&gt;disk_name); p.update(&amp;pid, &amp;data); }</code> </pre><br>  Hier wird das zweite Argument der aufgerufenen Funktion <a href="">generic_make_request ()</a> als zweites Argument ersetzt.  Danach erhalten wir die PID des Prozesses, in dem wir arbeiten, und den aktuellen Zeitstempel in Nanosekunden.  All dies schreiben wir in die <em>neu zugewiesenen struct data_t data</em> .  Wir erhalten den Datentr√§gernamen aus der <strong>Biostruktur</strong> , die beim Aufruf von <strong>generic_make_request () √ºbergeben wird</strong> , und speichern ihn in derselben <em>Datenstruktur</em> .  Der letzte Schritt besteht darin, der zuvor erw√§hnten Hash-Tabelle einen Eintrag hinzuzuf√ºgen. <br><br>  Die folgende Funktion wird bei der R√ºckkehr von <strong>generic_make_request () aufgerufen</strong> : <br><br><pre> <code class="python hljs">void stop(struct pt_regs *ctx) { u64 pid = bpf_get_current_pid_tgid(); u64 ts = bpf_ktime_get_ns(); struct data_t* data = p.lookup(&amp;pid); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (data != <span class="hljs-number"><span class="hljs-number">0</span></span> &amp;&amp; data-&gt;ts &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { bpf_get_current_comm(&amp;data-&gt;comm, sizeof(data-&gt;comm)); data-&gt;lat = (ts - data-&gt;ts)/<span class="hljs-number"><span class="hljs-number">1000</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (data-&gt;lat &gt; MIN_US) { FACTOR data-&gt;pid &gt;&gt;= <span class="hljs-number"><span class="hljs-number">32</span></span>; events.perf_submit(ctx, data, sizeof(struct data_t)); } p.delete(&amp;pid); } }</code> </pre><br>  Diese Funktion √§hnelt der vorherigen: Wir erkennen die Prozess-PID und den Zeitstempel, weisen jedoch keinen Speicher f√ºr die neue Datenstruktur zu.  Stattdessen suchen wir in der Hash-Tabelle nach einer vorhandenen Struktur mit dem Schl√ºssel == aktuelle PID.  Wenn die Struktur gefunden wird, ermitteln wir den Namen des laufenden Prozesses und f√ºgen ihn hinzu. <br><br>  Die hier verwendete bin√§re Verschiebung wird ben√∂tigt, um die Thread-GID zu erhalten.  d.h.  Die PID des Hauptprozesses, der den Thread gestartet hat, in dessen Kontext wir arbeiten.  Die von uns <a href="">aufgerufene</a> Funktion <a href="">bpf_get_current_pid_tgid ()</a> gibt sowohl die GID des Threads als auch seine PID in einem 64-Bit-Wert zur√ºck. <br><br>  Bei der Ausgabe an das Terminal interessieren wir uns jetzt nicht mehr f√ºr den Stream, sondern f√ºr den Hauptprozess.  Nachdem wir die empfangene Verz√∂gerung mit einem bestimmten Schwellenwert verglichen haben, √ºbertragen wir unsere <em>Datenstruktur</em> √ºber die <em>Ereignistabelle</em> in den Benutzerbereich und l√∂schen dann den Datensatz aus <em>p</em> . <br><br>  In dem Python-Skript, das diesen Code l√§dt, m√ºssen wir MIN_US und FACTOR durch die Verz√∂gerungsschwellen und Zeiteinheiten ersetzen, die wir durch die Argumente weitergeben: <br><br><pre> <code class="python hljs">bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'MIN_US'</span></span>,str(min_usec)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> args.milliseconds: bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'FACTOR'</span></span>,<span class="hljs-string"><span class="hljs-string">'data-&gt;lat /= 1000;'</span></span>) label = <span class="hljs-string"><span class="hljs-string">"msec"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'FACTOR'</span></span>,<span class="hljs-string"><span class="hljs-string">''</span></span>) label = <span class="hljs-string"><span class="hljs-string">"usec"</span></span></code> </pre><br>  Jetzt m√ºssen wir das BPF-Programm √ºber das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BPF-Makro</a> vorbereiten und die Beispiele registrieren: <br><br><pre> <code class="python hljs">b = BPF(text=bpf_text) b.attach_kprobe(event=<span class="hljs-string"><span class="hljs-string">"generic_make_request"</span></span>,fn_name=<span class="hljs-string"><span class="hljs-string">"start"</span></span>) b.attach_kretprobe(event=<span class="hljs-string"><span class="hljs-string">"generic_make_request"</span></span>,fn_name=<span class="hljs-string"><span class="hljs-string">"stop"</span></span>)</code> </pre><br>  Wir m√ºssen auch <em>struct data_t</em> in unserem Skript definieren, sonst k√∂nnen wir nichts lesen: <br><br><pre> <code class="python hljs">TASK_COMM_LEN = <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-comment"><span class="hljs-comment"># linux/sched.h DISK_NAME_LEN = 32 # linux/genhd.h class Data(ct.Structure): _fields_ = [("pid", ct.c_ulonglong), ("ts", ct.c_ulonglong), ("comm", ct.c_char * TASK_COMM_LEN), ("lat", ct.c_ulonglong), ("disk",ct.c_char * DISK_NAME_LEN)]</span></span></code> </pre><br>  Der letzte Schritt ist die Datenausgabe an das Terminal: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">print_event</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cpu, data, size)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> start event = ct.cast(data, ct.POINTER(Data)).contents <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> start == <span class="hljs-number"><span class="hljs-number">0</span></span>: start = event.ts time_s = (float(event.ts - start)) / <span class="hljs-number"><span class="hljs-number">1000000000</span></span> print(<span class="hljs-string"><span class="hljs-string">"%-18.9f %-16s %-6d %-1s %s %s"</span></span> % (time_s, event.comm, event.pid, event.lat, label, event.disk)) b[<span class="hljs-string"><span class="hljs-string">"events"</span></span>].open_perf_buffer(print_event) <span class="hljs-comment"><span class="hljs-comment"># format output start = 0 while 1: try: b.perf_buffer_poll() except KeyboardInterrupt: exit()</span></span></code> </pre><br>  Das Skript selbst ist auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GItHub</a> verf√ºgbar.  Versuchen wir es auf einer Testplattform auszuf√ºhren, auf der fio in bcache geschrieben ist, und rufen Sie udevadm monitor auf: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/0q/wl/yo/0qwlyofk3ynh0ksh1rcqe_9kt6w.png"></div><br>  Endlich!  Jetzt sehen wir, dass das, was wie ein bremsendes Bcache-Ger√§t aussah, tats√§chlich ein <strong>Bremsaufruf</strong> von <strong>generic_make_request ()</strong> auf einem zwischengespeicherten Laufwerk ist. <br><br><h3>  Grabe dich in den Kernel </h3><br>  Was genau verlangsamt sich w√§hrend der √úbertragung der Anfrage?  Wir sehen, dass die Verz√∂gerung bereits vor dem Beginn der Abrechnung der Anforderung auftritt, d. H.  Die Ber√ºcksichtigung einer bestimmten Anforderung weiterer Statistiken (/ proc / diskstats oder iostat) hat noch nicht begonnen.  Dies kann leicht √ºberpr√ºft werden, indem iostat ausgef√ºhrt wird, w√§hrend das Problem reproduziert wird, oder das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BCC-Biolatency-Skript</a> , das auf dem Beginn und dem Ende der Abrechnung von Anforderungen basiert.  Keines dieser Dienstprogramme zeigt Probleme bei Abfragen an das zwischengespeicherte Laufwerk. <br><br>  Wenn wir uns die Funktion <strong>generic_make_request () ansehen</strong> , werden wir sehen, dass zwei weitere Funktionen aufgerufen werden, bevor die Anforderung <strong>aufgezeichnet wird</strong> .  Der erste, <strong>generic_make_request_checks ()</strong> , √ºberpr√ºft die Legitimit√§t einer Anforderung f√ºr Festplatteneinstellungen.  Das zweite ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_queue_enter ()</a> , das einen interessanten Aufruf von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wait_event_interruptible () hat</a> : <br><br><pre> <code class="python hljs">ret = wait_event_interruptible(q-&gt;mq_freeze_wq, (atomic_read(&amp;q-&gt;mq_freeze_depth) == <span class="hljs-number"><span class="hljs-number">0</span></span> &amp;&amp; (preempt || !blk_queue_preempt_only(q))) || blk_queue_dying(q));</code> </pre><br>  Darin wartet der Kernel auf das Auftauen der Warteschlange.  Wir messen die Verz√∂gerung <strong>blk_queue_enter ()</strong> : <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /usr/share/bcc/tools/funclatency blk_queue_enter -i 1 -m Tracing 1 functions for "blk_queue_enter"... Hit Ctrl-C to end. msecs : count distribution 0 -&gt; 1 : 341 |****************************************| msecs : count distribution 0 -&gt; 1 : 316 |****************************************| msecs : count distribution 0 -&gt; 1 : 255 |****************************************| 2 -&gt; 3 : 0 | | 4 -&gt; 7 : 0 | | 8 -&gt; 15 : 1 | |</span></span></code> </pre><br>  Es scheint, dass wir einer L√∂sung nahe sind.  Die Funktionen zum "Einfrieren / Auftauen" der Warteschlange sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_mq_freeze_queue</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_mq_unfreeze_queue</a> .  Sie werden verwendet, wenn die Einstellungen der Abfragewarteschlange ge√§ndert werden m√ºssen, die f√ºr die Abfragen in dieser Warteschlange m√∂glicherweise gef√§hrlich sind.  Wenn <strong>blk_mq_freeze_queue ()</strong> aufgerufen wird, erh√∂ht die Funktion <strong>blk_freeze_queue_start ()</strong> den <strong>Z√§hler q-&gt; mq_freeze_depth</strong> .  Danach wartet der Kernel auf das Leeren der Warteschlange in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_mq_freeze_queue_wait ()</a> . <br><br>  Die Wartezeit zum L√∂schen dieser Warteschlange entspricht der Festplattenlatenz, da der Kernel darauf wartet, dass alle Operationen in der Warteschlange abgeschlossen sind.  Sobald die Warteschlange leer ist, werden √Ñnderungen an den Einstellungen angewendet.  Dann wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_mq_unfreeze_queue ()</a> aufgerufen, <strong>wodurch</strong> der Z√§hler <strong>freeze_depth</strong> dekrementiert <strong>wird</strong> . <br><br>  Jetzt wissen wir genug, um die Situation zu korrigieren.  Der Befehl udevadm trigger f√ºhrt zur Anwendung von Einstellungen f√ºr das Blockger√§t.  Diese Einstellungen sind in den udev-Regeln beschrieben.  Wir k√∂nnen genau herausfinden, welche Einstellungen die Warteschlange "einfrieren", indem wir versuchen, sie √ºber sysfs zu √§ndern, oder indem wir uns den Kernel-Quellcode ansehen.  Wir k√∂nnen auch das BCC- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Trace-</a> Dienstprogramm ausprobieren, das den Kernel-Stack und die User-Space-Traces f√ºr das Terminal f√ºr jeden Aufruf von <strong>blk_freeze_queue anzeigt</strong> , zum Beispiel: <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /usr/share/bcc/tools/trace blk_freeze_queue -K -U PID TID COMM FUNC 3809642 3809642 systemd-udevd blk_freeze_queue blk_freeze_queue+0x1 [kernel] elevator_switch+0x29 [kernel] elv_iosched_store+0x197 [kernel] queue_attr_store+0x5c [kernel] sysfs_kf_write+0x3c [kernel] kernfs_fop_write+0x125 [kernel] __vfs_write+0x1b [kernel] vfs_write+0xb8 [kernel] sys_write+0x55 [kernel] do_syscall_64+0x73 [kernel] entry_SYSCALL_64_after_hwframe+0x3d [kernel] __write_nocancel+0x7 [libc-2.23.so] [unknown] 3809631 3809631 systemd-udevd blk_freeze_queue blk_freeze_queue+0x1 [kernel] queue_requests_store+0xb6 [kernel] queue_attr_store+0x5c [kernel] sysfs_kf_write+0x3c [kernel] kernfs_fop_write+0x125 [kernel] __vfs_write+0x1b [kernel] vfs_write+0xb8 [kernel] sys_write+0x55 [kernel] do_syscall_64+0x73 [kernel] entry_SYSCALL_64_after_hwframe+0x3d [kernel] __write_nocancel+0x7 [libc-2.23.so] [unknown]</span></span></code> </pre><br>  Udev-Regeln √§ndern sich ziemlich selten und normalerweise geschieht dies unter Kontrolle.  Wir sehen also, dass selbst die Verwendung bereits festgelegter Werte die Verz√∂gerung bei der √úbertragung der Anforderung von der Anwendung auf die Festplatte erh√∂ht.  Das Generieren von udev-Ereignissen, wenn keine √Ñnderungen an der Festplattenkonfiguration vorgenommen wurden (z. B. wenn das Ger√§t keine Verbindung herstellt / trennt), ist nat√ºrlich keine gute Vorgehensweise.  Wir k√∂nnen dem Kernel jedoch helfen, keine nutzlose Arbeit zu leisten und die Anforderungswarteschlange nicht einzufrieren, wenn dies nicht erforderlich ist.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Drei</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kleine</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Commits</a> korrigieren die Situation. <br><br><h2>  Fazit </h2><br>  eBPF ist ein sehr flexibles und leistungsstarkes Tool.  In dem Artikel haben wir einen praktischen Fall untersucht und einen kleinen Teil dessen gezeigt, was m√∂glich ist.  Wenn Sie an der Entwicklung von BCC-Dienstprogrammen interessiert sind, sollten Sie sich das <a href="">offizielle Tutorial</a> ansehen, in dem die Grundlagen gut beschrieben werden. <br><br>  Es gibt andere interessante Debugging- und Profiling-Tools, die auf eBPF basieren.  Eines davon ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bpftrace</a> , mit dem Sie leistungsstarke einzeilige und kleine Programme in einer awk-√§hnlichen Sprache schreiben k√∂nnen.  Ein anderer - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ebpf_exporter</a> - erm√∂glicht es Ihnen, hochaufl√∂sende Metriken auf niedriger Ebene direkt auf Ihrem Prometheus-Server zu sammeln und in Zukunft eine sch√∂ne Visualisierung und sogar Warnungen zu erhalten. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458592/">https://habr.com/ru/post/de458592/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458568/index.html">Wie haben wir die ersten 3D-Bilder der vielleicht √§ltesten christlichen Kirche in Russland bekommen?</a></li>
<li><a href="../de458572/index.html">Anatoly Slyusar: ‚ÄûDie Zeit des EU-Computers erm√∂glichte es uns, System- und angewandte Programmierer auszubilden.‚Äú</a></li>
<li><a href="../de458574/index.html">Wie man von einem Entwickler zu einem Teamleiter heranw√§chst und weiter damit lebt</a></li>
<li><a href="../de458582/index.html">Der Ingenieur von Amazon hat ein KI-Blockierungsger√§t entwickelt, das Katzen von der Stra√üe fernh√§lt</a></li>
<li><a href="../de458584/index.html">11. Juli, Group-IB-Webinar ‚ÄûMalware-Analyse f√ºr Anf√§nger: Grundlegende Ans√§tze‚Äú</a></li>
<li><a href="../de458594/index.html">Vergessen Sie nicht, die Wahrscheinlichkeit einer Antwort an den Client durch eine wiederholte Anforderung beim L7-Ausgleich zu erh√∂hen</a></li>
<li><a href="../de458596/index.html">Kleine Freude # 6: OpenAI Gym - Spiele spielen und Roboter steuern</a></li>
<li><a href="../de458600/index.html">Was sind Elektrofahrr√§der (Gruppenbewertung in zwei Teilen von f√ºnf Modellen zweier Hersteller), Teil 1</a></li>
<li><a href="../de458602/index.html">Wie wir die Great Chinese Firewall durchbohrt haben (Teil 1)</a></li>
<li><a href="../de458604/index.html">Warum sich die beiden gr√∂√üten Elektronikhersteller zu einem neuen GPU-Projekt zusammengeschlossen haben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
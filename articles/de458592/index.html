<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨‍👦 🏜️ 👨‍🚀 Von der hohen Ceph-Latenz zum Kernel-Patch mit eBPF / BCC ⛹🏿 🈁 👨🏻‍🏭</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Linux verfügt über eine große Anzahl von Kernel-Debugging-Tools und -Anwendungen. Die meisten von ihnen beeinträchtigen die Anwendungsleistung und kön...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Von der hohen Ceph-Latenz zum Kernel-Patch mit eBPF / BCC</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/458592/"><img src="https://habrastorage.org/webt/-8/ok/na/-8okna9qfyroicvgoz-zenv7-si.png" alt="Bild"><br><br>  Linux verfügt über eine große Anzahl von Kernel-Debugging-Tools und -Anwendungen.  Die meisten von ihnen beeinträchtigen die Anwendungsleistung und können nicht in der Produktion verwendet werden. <br><a name="habracut"></a><br>  Vor einigen Jahren wurde ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">weiteres Tool entwickelt</a> - eBPF.  Es ermöglicht die Verfolgung des Kernels und der Benutzeranwendungen mit geringem Overhead und ohne dass Programme neu erstellt und Module von Drittanbietern in den Kernel geladen werden müssen. <br><br>  Jetzt gibt es viele Anwendungsdienstprogramme, die eBPF verwenden. In diesem Artikel erfahren Sie, wie Sie unser eigenes Profiling-Dienstprogramm basierend auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PythonBCC-</a> Bibliothek schreiben.  Der Artikel basiert auf realen Ereignissen.  Wir werden vom Auftreten des Problems bis zu seiner Korrektur gehen, um zu zeigen, wie vorhandene Dienstprogramme in bestimmten Situationen verwendet werden können. <br><br><h2>  Ceph ist langsam </h2><br>  Dem Ceph-Cluster wurde ein neuer Host hinzugefügt.  Nach der Migration einiger Daten haben wir festgestellt, dass die Geschwindigkeit der Verarbeitung von Schreibanforderungen viel geringer ist als auf anderen Servern. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4c/_r/yv/4c_ryvapivstw8l-nr7dipfvh8e.png"></div><br>  Im Gegensatz zu anderen Plattformen wurden auf diesem Host bcache und der neue Linux 4.15-Kernel verwendet.  Hier wurde erstmals ein Host dieser Konfiguration verwendet.  Und zu dieser Zeit war klar, dass theoretisch alles die Wurzel des Problems sein könnte. <br><br><h3>  Untersuchung des Gastgebers </h3><br>  Lassen Sie uns zunächst sehen, was im ceph-osd-Prozess passiert.  Dazu verwenden wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Perf</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Flamescope</a> (mehr dazu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uw/gj/ox/uwgjoxekagdl-noj-wp_uy5g8q8.png"></div><br>  Das Bild zeigt, dass die Funktion <strong>fdatasync ()</strong> viel Zeit damit verbracht hat, eine Anforderung an die Funktion <strong>generic_make_request ()</strong> zu <strong>senden</strong> .  Dies bedeutet, dass die Ursache der Probleme höchstwahrscheinlich irgendwo außerhalb des osd-Daemons selbst liegt.  Es kann sich entweder um einen Kernel oder um Festplatten handeln.  Die iostat-Ausgabe zeigte eine hohe Latenz bei der Verarbeitung von Anforderungen mit bcache-Festplatten. <br><br>  Bei der Überprüfung des Hosts haben wir festgestellt, dass der systemd-udevd-Daemon viel CPU-Zeit verbraucht - etwa 20% auf mehreren Kernen.  Dies ist ein seltsames Verhalten, daher müssen Sie die Ursache herausfinden.  Da Systemd-udevd mit uevents arbeitet, haben wir uns entschlossen, sie über den <strong>udevadm-Monitor zu betrachten</strong> .  Es stellt sich heraus, dass für jedes Blockgerät im System eine große Anzahl von Änderungsereignissen generiert wurde.  Dies ist ziemlich ungewöhnlich, daher müssen Sie sehen, was all diese Ereignisse erzeugt. <br><br><h3>  Verwenden des BCC Toolkit </h3><br>  Wie wir bereits herausgefunden haben, verbringt der Kernel (und der Ceph-Daemon im Systemaufruf) viel Zeit in <strong>generic_make_request ()</strong> .  Versuchen wir, die Geschwindigkeit dieser Funktion zu messen.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BCC hat</a> bereits ein großartiges Dienstprogramm - die <strong>Funclatency</strong> .  Wir werden den Dämon anhand seiner PID mit einem Intervall zwischen den Informationsausgaben von 1 Sekunde verfolgen und das Ergebnis in Millisekunden ausgeben. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o7/zw/rl/o7zwrly0nejoo5r7zbezws3jxmo.png"></div><br>  Normalerweise ist diese Funktion schnell.  Sie sendet die Anforderung lediglich an die Gerätetreiberwarteschlange. <br><br>  <strong>Bcache</strong> ist ein komplexes Gerät, das tatsächlich aus drei Festplatten besteht: <br><br><ul><li>  Sicherungsgerät (zwischengespeicherte Festplatte), in diesem Fall eine langsame Festplatte; </li><li>  Caching-Gerät (Caching-Datenträger), hier ist es ein Abschnitt des NVMe-Geräts; </li><li>  bcache virtuelles Gerät, mit dem die Anwendung arbeitet. </li></ul><br>  Wir wissen, dass die Anforderungsübertragung langsam ist, aber für welches dieser Geräte?  Wir werden uns etwas später darum kümmern. <br><br>  Wir wissen jetzt, dass Ereignisse wahrscheinlich Probleme verursachen.  Es ist nicht so einfach herauszufinden, was genau ihre Entstehung verursacht.  Angenommen, dies ist eine Art Software, die regelmäßig ausgeführt wird.  Lassen Sie uns sehen, welche <strong>Art</strong> von Software auf dem System mithilfe des <strong>execsnoop-</strong> Skripts aus denselben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BCC-Dienstprogrammen</a> gestartet wird.  Führen Sie es aus und leiten Sie die Ausgabe in eine Datei. <br><br>  Zum Beispiel so: <br><br><pre><code class="bash hljs">/usr/share/bcc/tools/execsnoop | tee ./execdump</code> </pre> <br>  Wir werden hier nicht die vollständige Ausgabe von execsnoop geben, aber eine für uns interessante Zeile sah folgendermaßen aus: <br><br><pre> <code class="bash hljs">sh 1764905 5802 0 sudo arcconf getconfig 1 AD | grep Temperature | awk -F <span class="hljs-string"><span class="hljs-string">'[:/]'</span></span> <span class="hljs-string"><span class="hljs-string">'{print $2}'</span></span> | sed <span class="hljs-string"><span class="hljs-string">'s/^ \([0-9]*\) C.*/\1/'</span></span></code> </pre><br>  Die dritte Spalte ist die PPID (übergeordnete PID) des Prozesses.  Der Prozess mit PID 5802 erwies sich als einer der Fäden unseres Überwachungssystems.  Bei der Überprüfung der Konfiguration des Überwachungssystems wurden fehlerhafte Parameter gefunden.  Die Temperatur des HBA-Adapters wurde alle 30 Sekunden gemessen, was viel häufiger als nötig ist.  Nachdem wir das Überprüfungsintervall in ein längeres geändert haben, haben wir festgestellt, dass sich die Verzögerung bei der Verarbeitung von Anforderungen auf diesem Host nicht mehr von den übrigen Hosts abhebt. <br><br>  Es ist jedoch immer noch nicht klar, warum das bcache-Gerät so langsam war.  Wir haben eine Testplattform mit identischer Konfiguration vorbereitet und versucht, das Problem zu reproduzieren, indem wir fio auf bcache ausgeführt haben und regelmäßig den udevadm-Trigger gestartet haben, um Ereignisse zu generieren. <br><br><h3>  Schreiben von BCC-basierten Tools </h3><br>  Versuchen wir, ein einfaches Dienstprogramm zum Verfolgen und Anzeigen der langsamsten Aufrufe von <strong>generic_make_request ()</strong> zu <strong>schreiben</strong> .  Uns interessiert auch der Name des Laufwerks, für das diese Funktion aufgerufen wurde. <br><br>  Der Plan ist einfach: <br><br><ul><li>  Registrieren Sie <strong>kprobe</strong> bei <strong>generic_make_request ()</strong> : <br><ul><li>  Wir speichern den Datenträgernamen, auf den über das Funktionsargument zugegriffen werden kann. </li><li>  Speichern Sie den Zeitstempel. </li></ul><br></li></ul><ul><li>  Registrieren Sie <strong>kretprobe</strong> , um von <strong>generic_make_request () zurückzukehren</strong> : <br><ul><li>  Holen Sie sich den aktuellen Zeitstempel. </li><li>  Wir suchen nach dem gespeicherten Zeitstempel und vergleichen ihn mit dem aktuellen. </li><li>  Wenn das Ergebnis größer als das angegebene ist, suchen wir den gespeicherten Datenträgernamen und zeigen ihn auf dem Terminal an. </li></ul><br></li></ul>  <strong>Kprobes</strong> und <strong>Kretprobes</strong> verwenden einen Haltepunktmechanismus, um den Funktionscode im <strong>laufenden</strong> Betrieb zu ändern.  Sie können die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> und einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">guten</a> Artikel zu diesem Thema lesen.  Wenn Sie sich den Code verschiedener Dienstprogramme in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BCC</a> ansehen, werden Sie feststellen, dass sie eine identische Struktur haben.  In diesem Artikel werden wir also das Parsen von Skriptargumenten weglassen und zum BPF-Programm selbst übergehen. <br><br>  Der eBPF-Text im Python-Skript sieht folgendermaßen aus: <br><br><pre> <code class="python hljs">bpf_text = “”” <span class="hljs-comment"><span class="hljs-comment"># Here will be the bpf program code “””</span></span></code> </pre><br>  Zum Austausch von Daten zwischen Funktionen verwenden eBPF-Programme <a href="">Hash-Tabellen</a> .  Wir werden es auch tun.  Als Schlüssel verwenden wir die PID des Prozesses und als Wert definieren wir die Struktur: <br><br><pre> <code class="python hljs">struct data_t { u64 pid; u64 ts; char comm[TASK_COMM_LEN]; u64 lat; char disk[DISK_NAME_LEN]; }; BPF_HASH(p, u64, struct data_t); BPF_PERF_OUTPUT(events);</code> </pre><br>  Hier registrieren wir eine Hash-Tabelle namens <em>p</em> mit einem Schlüssel vom Typ <em>u64</em> und einem Wert vom Typ <em>struct data_t</em> .  Die Tabelle wird im Rahmen unseres BPF-Programms verfügbar sein.  Das Makro BPF_PERF_OUTPUT registriert eine andere Tabelle namens <em>Ereignisse</em> , mit der <a href="">Daten</a> in den Benutzerbereich übertragen werden. <br><br>  Bei der Messung von Verzögerungen zwischen einem Funktionsaufruf und dessen Rückgabe oder zwischen Aufrufen verschiedener Funktionen sollte berücksichtigt werden, dass die empfangenen Daten zum selben Kontext gehören müssen.  Mit anderen Worten, Sie müssen sich an den möglichen parallelen Start von Funktionen erinnern.  Wir haben die Möglichkeit, die Verzögerung zwischen dem Aufrufen einer Funktion im Kontext eines Prozesses und der Rückkehr von dieser Funktion im Kontext eines anderen Prozesses zu messen, aber dies ist höchstwahrscheinlich nutzlos.  Ein gutes Beispiel hierfür ist das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Biolatency-Dienstprogramm</a> , bei dem ein Zeiger auf eine <em>Strukturanforderung</em> , die eine einzelne Festplattenanforderung widerspiegelt, als Schlüssel in der Hash-Tabelle festgelegt wird. <br><br>  Als nächstes müssen wir den Code schreiben, der ausgeführt wird, wenn die untersuchte Funktion aufgerufen wird: <br><br><pre> <code class="python hljs">void start(struct pt_regs *ctx, struct bio *bio) { u64 pid = bpf_get_current_pid_tgid(); struct data_t data = {}; u64 ts = bpf_ktime_get_ns(); data.pid = pid; data.ts = ts; bpf_probe_read_str(&amp;data.disk, sizeof(data.disk), (void*)bio-&gt;bi_disk-&gt;disk_name); p.update(&amp;pid, &amp;data); }</code> </pre><br>  Hier wird das zweite Argument der aufgerufenen Funktion <a href="">generic_make_request ()</a> als zweites Argument ersetzt.  Danach erhalten wir die PID des Prozesses, in dem wir arbeiten, und den aktuellen Zeitstempel in Nanosekunden.  All dies schreiben wir in die <em>neu zugewiesenen struct data_t data</em> .  Wir erhalten den Datenträgernamen aus der <strong>Biostruktur</strong> , die beim Aufruf von <strong>generic_make_request () übergeben wird</strong> , und speichern ihn in derselben <em>Datenstruktur</em> .  Der letzte Schritt besteht darin, der zuvor erwähnten Hash-Tabelle einen Eintrag hinzuzufügen. <br><br>  Die folgende Funktion wird bei der Rückkehr von <strong>generic_make_request () aufgerufen</strong> : <br><br><pre> <code class="python hljs">void stop(struct pt_regs *ctx) { u64 pid = bpf_get_current_pid_tgid(); u64 ts = bpf_ktime_get_ns(); struct data_t* data = p.lookup(&amp;pid); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (data != <span class="hljs-number"><span class="hljs-number">0</span></span> &amp;&amp; data-&gt;ts &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { bpf_get_current_comm(&amp;data-&gt;comm, sizeof(data-&gt;comm)); data-&gt;lat = (ts - data-&gt;ts)/<span class="hljs-number"><span class="hljs-number">1000</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (data-&gt;lat &gt; MIN_US) { FACTOR data-&gt;pid &gt;&gt;= <span class="hljs-number"><span class="hljs-number">32</span></span>; events.perf_submit(ctx, data, sizeof(struct data_t)); } p.delete(&amp;pid); } }</code> </pre><br>  Diese Funktion ähnelt der vorherigen: Wir erkennen die Prozess-PID und den Zeitstempel, weisen jedoch keinen Speicher für die neue Datenstruktur zu.  Stattdessen suchen wir in der Hash-Tabelle nach einer vorhandenen Struktur mit dem Schlüssel == aktuelle PID.  Wenn die Struktur gefunden wird, ermitteln wir den Namen des laufenden Prozesses und fügen ihn hinzu. <br><br>  Die hier verwendete binäre Verschiebung wird benötigt, um die Thread-GID zu erhalten.  d.h.  Die PID des Hauptprozesses, der den Thread gestartet hat, in dessen Kontext wir arbeiten.  Die von uns <a href="">aufgerufene</a> Funktion <a href="">bpf_get_current_pid_tgid ()</a> gibt sowohl die GID des Threads als auch seine PID in einem 64-Bit-Wert zurück. <br><br>  Bei der Ausgabe an das Terminal interessieren wir uns jetzt nicht mehr für den Stream, sondern für den Hauptprozess.  Nachdem wir die empfangene Verzögerung mit einem bestimmten Schwellenwert verglichen haben, übertragen wir unsere <em>Datenstruktur</em> über die <em>Ereignistabelle</em> in den Benutzerbereich und löschen dann den Datensatz aus <em>p</em> . <br><br>  In dem Python-Skript, das diesen Code lädt, müssen wir MIN_US und FACTOR durch die Verzögerungsschwellen und Zeiteinheiten ersetzen, die wir durch die Argumente weitergeben: <br><br><pre> <code class="python hljs">bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'MIN_US'</span></span>,str(min_usec)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> args.milliseconds: bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'FACTOR'</span></span>,<span class="hljs-string"><span class="hljs-string">'data-&gt;lat /= 1000;'</span></span>) label = <span class="hljs-string"><span class="hljs-string">"msec"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'FACTOR'</span></span>,<span class="hljs-string"><span class="hljs-string">''</span></span>) label = <span class="hljs-string"><span class="hljs-string">"usec"</span></span></code> </pre><br>  Jetzt müssen wir das BPF-Programm über das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BPF-Makro</a> vorbereiten und die Beispiele registrieren: <br><br><pre> <code class="python hljs">b = BPF(text=bpf_text) b.attach_kprobe(event=<span class="hljs-string"><span class="hljs-string">"generic_make_request"</span></span>,fn_name=<span class="hljs-string"><span class="hljs-string">"start"</span></span>) b.attach_kretprobe(event=<span class="hljs-string"><span class="hljs-string">"generic_make_request"</span></span>,fn_name=<span class="hljs-string"><span class="hljs-string">"stop"</span></span>)</code> </pre><br>  Wir müssen auch <em>struct data_t</em> in unserem Skript definieren, sonst können wir nichts lesen: <br><br><pre> <code class="python hljs">TASK_COMM_LEN = <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-comment"><span class="hljs-comment"># linux/sched.h DISK_NAME_LEN = 32 # linux/genhd.h class Data(ct.Structure): _fields_ = [("pid", ct.c_ulonglong), ("ts", ct.c_ulonglong), ("comm", ct.c_char * TASK_COMM_LEN), ("lat", ct.c_ulonglong), ("disk",ct.c_char * DISK_NAME_LEN)]</span></span></code> </pre><br>  Der letzte Schritt ist die Datenausgabe an das Terminal: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">print_event</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cpu, data, size)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> start event = ct.cast(data, ct.POINTER(Data)).contents <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> start == <span class="hljs-number"><span class="hljs-number">0</span></span>: start = event.ts time_s = (float(event.ts - start)) / <span class="hljs-number"><span class="hljs-number">1000000000</span></span> print(<span class="hljs-string"><span class="hljs-string">"%-18.9f %-16s %-6d %-1s %s %s"</span></span> % (time_s, event.comm, event.pid, event.lat, label, event.disk)) b[<span class="hljs-string"><span class="hljs-string">"events"</span></span>].open_perf_buffer(print_event) <span class="hljs-comment"><span class="hljs-comment"># format output start = 0 while 1: try: b.perf_buffer_poll() except KeyboardInterrupt: exit()</span></span></code> </pre><br>  Das Skript selbst ist auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GItHub</a> verfügbar.  Versuchen wir es auf einer Testplattform auszuführen, auf der fio in bcache geschrieben ist, und rufen Sie udevadm monitor auf: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/0q/wl/yo/0qwlyofk3ynh0ksh1rcqe_9kt6w.png"></div><br>  Endlich!  Jetzt sehen wir, dass das, was wie ein bremsendes Bcache-Gerät aussah, tatsächlich ein <strong>Bremsaufruf</strong> von <strong>generic_make_request ()</strong> auf einem zwischengespeicherten Laufwerk ist. <br><br><h3>  Grabe dich in den Kernel </h3><br>  Was genau verlangsamt sich während der Übertragung der Anfrage?  Wir sehen, dass die Verzögerung bereits vor dem Beginn der Abrechnung der Anforderung auftritt, d. H.  Die Berücksichtigung einer bestimmten Anforderung weiterer Statistiken (/ proc / diskstats oder iostat) hat noch nicht begonnen.  Dies kann leicht überprüft werden, indem iostat ausgeführt wird, während das Problem reproduziert wird, oder das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BCC-Biolatency-Skript</a> , das auf dem Beginn und dem Ende der Abrechnung von Anforderungen basiert.  Keines dieser Dienstprogramme zeigt Probleme bei Abfragen an das zwischengespeicherte Laufwerk. <br><br>  Wenn wir uns die Funktion <strong>generic_make_request () ansehen</strong> , werden wir sehen, dass zwei weitere Funktionen aufgerufen werden, bevor die Anforderung <strong>aufgezeichnet wird</strong> .  Der erste, <strong>generic_make_request_checks ()</strong> , überprüft die Legitimität einer Anforderung für Festplatteneinstellungen.  Das zweite ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_queue_enter ()</a> , das einen interessanten Aufruf von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wait_event_interruptible () hat</a> : <br><br><pre> <code class="python hljs">ret = wait_event_interruptible(q-&gt;mq_freeze_wq, (atomic_read(&amp;q-&gt;mq_freeze_depth) == <span class="hljs-number"><span class="hljs-number">0</span></span> &amp;&amp; (preempt || !blk_queue_preempt_only(q))) || blk_queue_dying(q));</code> </pre><br>  Darin wartet der Kernel auf das Auftauen der Warteschlange.  Wir messen die Verzögerung <strong>blk_queue_enter ()</strong> : <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /usr/share/bcc/tools/funclatency blk_queue_enter -i 1 -m Tracing 1 functions for "blk_queue_enter"... Hit Ctrl-C to end. msecs : count distribution 0 -&gt; 1 : 341 |****************************************| msecs : count distribution 0 -&gt; 1 : 316 |****************************************| msecs : count distribution 0 -&gt; 1 : 255 |****************************************| 2 -&gt; 3 : 0 | | 4 -&gt; 7 : 0 | | 8 -&gt; 15 : 1 | |</span></span></code> </pre><br>  Es scheint, dass wir einer Lösung nahe sind.  Die Funktionen zum "Einfrieren / Auftauen" der Warteschlange sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_mq_freeze_queue</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_mq_unfreeze_queue</a> .  Sie werden verwendet, wenn die Einstellungen der Abfragewarteschlange geändert werden müssen, die für die Abfragen in dieser Warteschlange möglicherweise gefährlich sind.  Wenn <strong>blk_mq_freeze_queue ()</strong> aufgerufen wird, erhöht die Funktion <strong>blk_freeze_queue_start ()</strong> den <strong>Zähler q-&gt; mq_freeze_depth</strong> .  Danach wartet der Kernel auf das Leeren der Warteschlange in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_mq_freeze_queue_wait ()</a> . <br><br>  Die Wartezeit zum Löschen dieser Warteschlange entspricht der Festplattenlatenz, da der Kernel darauf wartet, dass alle Operationen in der Warteschlange abgeschlossen sind.  Sobald die Warteschlange leer ist, werden Änderungen an den Einstellungen angewendet.  Dann wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">blk_mq_unfreeze_queue ()</a> aufgerufen, <strong>wodurch</strong> der Zähler <strong>freeze_depth</strong> dekrementiert <strong>wird</strong> . <br><br>  Jetzt wissen wir genug, um die Situation zu korrigieren.  Der Befehl udevadm trigger führt zur Anwendung von Einstellungen für das Blockgerät.  Diese Einstellungen sind in den udev-Regeln beschrieben.  Wir können genau herausfinden, welche Einstellungen die Warteschlange "einfrieren", indem wir versuchen, sie über sysfs zu ändern, oder indem wir uns den Kernel-Quellcode ansehen.  Wir können auch das BCC- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Trace-</a> Dienstprogramm ausprobieren, das den Kernel-Stack und die User-Space-Traces für das Terminal für jeden Aufruf von <strong>blk_freeze_queue anzeigt</strong> , zum Beispiel: <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /usr/share/bcc/tools/trace blk_freeze_queue -K -U PID TID COMM FUNC 3809642 3809642 systemd-udevd blk_freeze_queue blk_freeze_queue+0x1 [kernel] elevator_switch+0x29 [kernel] elv_iosched_store+0x197 [kernel] queue_attr_store+0x5c [kernel] sysfs_kf_write+0x3c [kernel] kernfs_fop_write+0x125 [kernel] __vfs_write+0x1b [kernel] vfs_write+0xb8 [kernel] sys_write+0x55 [kernel] do_syscall_64+0x73 [kernel] entry_SYSCALL_64_after_hwframe+0x3d [kernel] __write_nocancel+0x7 [libc-2.23.so] [unknown] 3809631 3809631 systemd-udevd blk_freeze_queue blk_freeze_queue+0x1 [kernel] queue_requests_store+0xb6 [kernel] queue_attr_store+0x5c [kernel] sysfs_kf_write+0x3c [kernel] kernfs_fop_write+0x125 [kernel] __vfs_write+0x1b [kernel] vfs_write+0xb8 [kernel] sys_write+0x55 [kernel] do_syscall_64+0x73 [kernel] entry_SYSCALL_64_after_hwframe+0x3d [kernel] __write_nocancel+0x7 [libc-2.23.so] [unknown]</span></span></code> </pre><br>  Udev-Regeln ändern sich ziemlich selten und normalerweise geschieht dies unter Kontrolle.  Wir sehen also, dass selbst die Verwendung bereits festgelegter Werte die Verzögerung bei der Übertragung der Anforderung von der Anwendung auf die Festplatte erhöht.  Das Generieren von udev-Ereignissen, wenn keine Änderungen an der Festplattenkonfiguration vorgenommen wurden (z. B. wenn das Gerät keine Verbindung herstellt / trennt), ist natürlich keine gute Vorgehensweise.  Wir können dem Kernel jedoch helfen, keine nutzlose Arbeit zu leisten und die Anforderungswarteschlange nicht einzufrieren, wenn dies nicht erforderlich ist.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Drei</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kleine</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Commits</a> korrigieren die Situation. <br><br><h2>  Fazit </h2><br>  eBPF ist ein sehr flexibles und leistungsstarkes Tool.  In dem Artikel haben wir einen praktischen Fall untersucht und einen kleinen Teil dessen gezeigt, was möglich ist.  Wenn Sie an der Entwicklung von BCC-Dienstprogrammen interessiert sind, sollten Sie sich das <a href="">offizielle Tutorial</a> ansehen, in dem die Grundlagen gut beschrieben werden. <br><br>  Es gibt andere interessante Debugging- und Profiling-Tools, die auf eBPF basieren.  Eines davon ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bpftrace</a> , mit dem Sie leistungsstarke einzeilige und kleine Programme in einer awk-ähnlichen Sprache schreiben können.  Ein anderer - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ebpf_exporter</a> - ermöglicht es Ihnen, hochauflösende Metriken auf niedriger Ebene direkt auf Ihrem Prometheus-Server zu sammeln und in Zukunft eine schöne Visualisierung und sogar Warnungen zu erhalten. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458592/">https://habr.com/ru/post/de458592/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458568/index.html">Wie haben wir die ersten 3D-Bilder der vielleicht ältesten christlichen Kirche in Russland bekommen?</a></li>
<li><a href="../de458572/index.html">Anatoly Slyusar: „Die Zeit des EU-Computers ermöglichte es uns, System- und angewandte Programmierer auszubilden.“</a></li>
<li><a href="../de458574/index.html">Wie man von einem Entwickler zu einem Teamleiter heranwächst und weiter damit lebt</a></li>
<li><a href="../de458582/index.html">Der Ingenieur von Amazon hat ein KI-Blockierungsgerät entwickelt, das Katzen von der Straße fernhält</a></li>
<li><a href="../de458584/index.html">11. Juli, Group-IB-Webinar „Malware-Analyse für Anfänger: Grundlegende Ansätze“</a></li>
<li><a href="../de458594/index.html">Vergessen Sie nicht, die Wahrscheinlichkeit einer Antwort an den Client durch eine wiederholte Anforderung beim L7-Ausgleich zu erhöhen</a></li>
<li><a href="../de458596/index.html">Kleine Freude # 6: OpenAI Gym - Spiele spielen und Roboter steuern</a></li>
<li><a href="../de458600/index.html">Was sind Elektrofahrräder (Gruppenbewertung in zwei Teilen von fünf Modellen zweier Hersteller), Teil 1</a></li>
<li><a href="../de458602/index.html">Wie wir die Great Chinese Firewall durchbohrt haben (Teil 1)</a></li>
<li><a href="../de458604/index.html">Warum sich die beiden größten Elektronikhersteller zu einem neuen GPU-Projekt zusammengeschlossen haben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
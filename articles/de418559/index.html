<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üññüèæ ü§ûüèø üë£ NL2API: Erstellen von Schnittstellen in nat√ºrlicher Sprache f√ºr die Web-API üåó üöö üßõüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! In j√ºngerer Zeit haben wir kurz √ºber Natural Language Interfaces gesprochen. Nun, heute haben wir nicht kurz. Unter dem Ausschnitt finden ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NL2API: Erstellen von Schnittstellen in nat√ºrlicher Sprache f√ºr die Web-API</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/microsoft/blog/418559/">  Hallo Habr!  In j√ºngerer Zeit haben wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kurz</a> √ºber Natural Language Interfaces gesprochen.  Nun, heute haben wir nicht kurz.  Unter dem Ausschnitt finden Sie eine vollst√§ndige Geschichte zum Erstellen von NL2API f√ºr die Web-API.  Unsere Kollegen von Research haben einen einzigartigen Ansatz zur Erfassung von Trainingsdaten f√ºr das Framework ausprobiert.  Jetzt mitmachen! <br><br><img src="https://habrastorage.org/webt/ry/bd/kj/rybdkjnazdjarwxlrggugof4pja.jpeg"><a name="habracut"></a><br><br><h2>  Anmerkung </h2><br>  W√§hrend sich das Internet zu einer serviceorientierten Architektur entwickelt, werden Software-Schnittstellen (APIs) immer wichtiger, um den Zugriff auf Daten, Dienste und Ger√§te zu erm√∂glichen.  Wir arbeiten an der Erstellung einer Schnittstelle in nat√ºrlicher Sprache f√ºr die API (NL2API) mit Schwerpunkt auf Webdiensten.  NL2API-L√∂sungen bieten viele potenzielle Vorteile, beispielsweise die Vereinfachung der Integration von Webdiensten in virtuelle Assistenten. <br><br>  Wir bieten die erste umfassende Plattform (Framework), mit der Sie NL2API f√ºr eine bestimmte Web-API erstellen k√∂nnen.  Die Hauptaufgabe besteht darin, Daten f√ºr das Training zu sammeln, dh die Paare ‚ÄûNL-Befehl - API-Aufruf‚Äú, sodass NL2API die Semantik beider NL-Befehle untersuchen kann, die kein streng definiertes Format und formalisierte API-Aufrufe haben.  Wir bieten unseren eigenen einzigartigen Ansatz f√ºr die Erfassung von Trainingsdaten f√ºr NL2API mithilfe von Crowdsourcing - und ziehen viele Remote-Mitarbeiter an, um verschiedene NL-Teams zu generieren.  Wir optimieren den Crowdsourcing-Prozess selbst, um die Kosten zu senken. <br><br>  Insbesondere bieten wir ein grundlegend neues hierarchisches Wahrscheinlichkeitsmodell an, mit dessen Hilfe wir das Budget f√ºr Crowdsourcing verteilen k√∂nnen, haupts√§chlich zwischen API-Aufrufen, die f√ºr das Erlernen von NL2API von hohem Wert sind.  Wir wenden unser Framework auf echte APIs an und zeigen, dass Sie damit hochwertige Trainingsdaten zu minimalen Kosten erfassen und leistungsstarke NL2API von Grund auf neu erstellen k√∂nnen.  Wir zeigen auch, dass unser Crowdsourcing-Modell die Effizienz dieses Prozesses verbessert, dh die im Rahmen des Frameworks gesammelten Trainingsdaten bieten eine h√∂here NL2API-Leistung, die die Basislinie erheblich √ºbertrifft. <br><br><h2>  Einf√ºhrung </h2><br>  Anwendungsprogrammierschnittstellen (APIs) spielen sowohl in der virtuellen als auch in der physischen Welt dank der Entwicklung von Technologien wie serviceorientierter Architektur (SOA), Cloud Computing und Internet der Dinge (IoT) eine immer wichtigere Rolle.  Beispielsweise stellen in der Cloud gehostete Webdienste (Wetter, Sport, Finanzen usw.) √ºber die Web-API Daten und Dienste f√ºr Endbenutzer bereit, und IoT-Ger√§te erm√∂glichen anderen Netzwerkger√§ten, ihre Funktionen zu nutzen. <br><br><img src="https://habrastorage.org/webt/tc/kd/fb/tckdfbxc1i4zg4km413wnducl_4.png"><br>  <i>Abbildung 1. Die Paare "NL-Befehl (links) und API-Aufruf (rechts)" wurden zusammengestellt</i> <i><br></i>  <i>unser Framework und Vergleich mit IFTTT.</i>  <i>GET-Messages und GET-Events sind zwei Web-APIs zum Auffinden von E-Mails bzw. Kalenderereignissen.</i>  <i>API kann mit verschiedenen Parametern aufgerufen werden.</i>  <i>Wir konzentrieren uns auf vollst√§ndig parametrisierte API-Aufrufe, w√§hrend IFTTT auf APIs mit einfachen Parametern beschr√§nkt ist.</i> <br><br>  In der Regel werden APIs in einer Vielzahl von Software verwendet: Desktop-Anwendungen, Websites und mobile Anwendungen.  Sie dienen Benutzern auch √ºber eine grafische Benutzeroberfl√§che (GUI).  Die grafische Benutzeroberfl√§che hat einen gro√üen Beitrag zur Popularisierung von Computern geleistet, aber im Zuge der Weiterentwicklung der Computertechnologie werden ihre zahlreichen Einschr√§nkungen zunehmend deutlich.  Einerseits steigen die Anforderungen an die grafische Anzeige auf dem Bildschirm st√§ndig, wenn Ger√§te kleiner, mobiler und intelligenter werden, beispielsweise bei tragbaren Ger√§ten oder Ger√§ten, die an das Internet der Dinge angeschlossen sind. <br><br>  Andererseits m√ºssen sich Benutzer f√ºr verschiedene Dienste und Ger√§te an verschiedene spezialisierte GUIs anpassen.  Mit zunehmender Anzahl verf√ºgbarer Dienste und Ger√§te steigen auch die Kosten f√ºr Schulung und Benutzeranpassung.  Natural Language Interfaces (NLIs) wie die virtuellen Assistenten von Apple Siri und Microsoft Cortana, auch Conversational oder Conversational Interfaces (CUIs) genannt, weisen als ein einziges intelligentes Tool f√ºr eine Vielzahl von Serverdiensten und -ger√§ten ein erhebliches Potenzial auf. <br><br>  In diesem Artikel betrachten wir das Problem der Erstellung einer Schnittstelle in nat√ºrlicher Sprache f√ºr die API (NL2API).  Im Gegensatz zu virtuellen Assistenten handelt es sich hierbei jedoch nicht um Allzweck-NLIs. <br>  Wir entwickeln Ans√§tze zum Erstellen von NLIs f√ºr bestimmte Web-APIs, d. h. Webdienst-APIs wie den ESPN1-Multisportdienst.  Solche NL2APIs k√∂nnen das Skalierbarkeitsproblem von Allzweck-NLIs l√∂sen, indem sie eine verteilte Entwicklung erm√∂glichen.  Der Nutzen eines virtuellen Assistenten h√§ngt weitgehend von der Breite seiner Funktionen ab, dh von der Anzahl der unterst√ºtzten Dienste. <br><br>  Die Integration von Webdiensten in einen virtuellen Assistenten ist jedoch unglaublich m√ºhsam.  Wenn einzelne Webdienstanbieter eine kosteng√ºnstige M√∂glichkeit h√§tten, NLIs f√ºr ihre APIs zu erstellen, w√ºrden die Integrationskosten erheblich reduziert.  Ein virtueller Assistent m√ºsste nicht unterschiedliche Schnittstellen f√ºr unterschiedliche Webdienste verarbeiten.  Es w√ºrde f√ºr ihn ausreichen, einfach einzelne NL2APIs zu integrieren, die dank der nat√ºrlichen Sprache Einheitlichkeit erreichen.  Andererseits kann NL2API auch die Ermittlung von Webdiensten sowie Programmierempfehlungs- und -unterst√ºtzungssystemen f√ºr APIs vereinfachen, sodass Sie sich nicht mehr an die gro√üe Anzahl verf√ºgbarer Web-APIs und deren Syntax erinnern m√ºssen. <br><br>  <b>Beispiel 1.</b> In Abbildung 1 sind zwei Beispiele dargestellt. Die API kann mit verschiedenen Parametern aufgerufen werden.  Bei der E-Mail-Such-API k√∂nnen Benutzer E-Mails nach bestimmten Eigenschaften filtern oder nach E-Mails nach Schl√ºsselw√∂rtern suchen.  Die Hauptaufgabe von NL2API besteht darin, NL-Befehle den entsprechenden API-Aufrufen zuzuordnen. <br><br>  <b>Herausforderung.</b>  Die Erfassung von Trainingsdaten ist eine der wichtigsten Aufgaben im Zusammenhang mit der Erforschung der Entwicklung von NLI-Schnittstellen und ihrer praktischen Anwendung.  NLIs verwenden kontrollierte Trainingsdaten, die im Fall von NL2API aus Paaren von "NL-Befehl - API-Aufruf" bestehen, um die Semantik zu untersuchen und NL-Befehle eindeutig den entsprechenden formalisierten Darstellungen zuzuordnen.  Die nat√ºrliche Sprache ist sehr flexibel, sodass Benutzer den API-Aufruf auf syntaktisch unterschiedliche Weise beschreiben k√∂nnen, dh es findet eine Paraphrasierung statt. <br><br>  Betrachten Sie das zweite Beispiel in Abbildung 1. Benutzer k√∂nnen diese Frage wie folgt umformulieren: ‚ÄûWo findet das n√§chste Meeting statt?‚Äú Oder ‚ÄûSuchen Sie einen Ort f√ºr das n√§chste Meeting‚Äú.  Daher ist es √§u√üerst wichtig, ausreichende Trainingsdaten zu sammeln, damit das System solche Optionen weiter erkennt.  Bestehende NLIs halten sich bei der Datenerfassung normalerweise an das ‚Äûbestm√∂gliche‚Äú Prinzip.  Das n√§chste Analogon unserer Methode zum Vergleichen von NL-Befehlen mit API-Aufrufen verwendet beispielsweise das Konzept von IF-This-Then-That (IFTTT) - ‚ÄûWenn ja, dann‚Äú (Abbildung 1).  Trainingsdaten stammen direkt von der IFTTT-Website. <br><br>  Wenn die API jedoch nicht oder nicht vollst√§ndig unterst√ºtzt wird, kann die Situation nicht behoben werden.  Dar√ºber hinaus sind die auf diese Weise gesammelten Trainingsdaten nicht anwendbar, um erweiterte Befehle mit mehreren Parametern zu unterst√ºtzen.  Zum Beispiel haben wir anonymisierte Microsoft API-Anrufprotokolle analysiert, um nach E-Mails f√ºr den Monat zu suchen, und festgestellt, dass etwa 90% von ihnen zwei oder drei Parameter (ungef√§hr die gleiche Menge) verwenden, und diese Parameter sind sehr unterschiedlich.  Daher bem√ºhen wir uns, die API-Parametrisierung vollst√§ndig zu unterst√ºtzen und erweiterte NL-Befehle zu implementieren.  Das Problem der Bereitstellung eines aktiven und anpassbaren Prozesses zum Sammeln von Trainingsdaten f√ºr eine bestimmte API bleibt derzeit ungel√∂st. <br><br>  Die Probleme bei der Verwendung von NLI in Kombination mit anderen formalisierten Darstellungen wie relationalen Datenbanken, Wissensdatenbanken und Webtabellen wurden recht gut gel√∂st, w√§hrend der Entwicklung von NLI f√ºr Web-APIs fast keine Aufmerksamkeit geschenkt wurde.  Wir bieten die erste umfassende Plattform (Framework), mit der Sie NL2API f√ºr eine bestimmte Web-API von Grund auf neu erstellen k√∂nnen.  Bei der Implementierung der Web-API umfasst unser Framework drei Phasen: (1) Pr√§sentation.  Das urspr√ºngliche HTTP-Web-API-Format enth√§lt viele redundante und daher ablenkende Details aus Sicht des NLI. <br><br>  Wir empfehlen die Verwendung einer semantischen Zwischendarstellung f√ºr die Web-API, um das NLI nicht mit unn√∂tigen Informationen zu √ºberladen.  (2) Eine Reihe von Trainingsdaten.  Wir bieten einen neuen Ansatz, um kontrollierte Trainingsdaten basierend auf Crowdsourcing zu erhalten.  (3) NL2API.  Wir bieten auch zwei NL2API-Modelle an: ein sprachbasiertes Extraktionsmodell und ein wiederkehrendes neuronales Netzwerkmodell (Seq2Seq). <br><br>  Eines der wichtigsten technischen Ergebnisse dieser Arbeit ist ein grundlegend neuer Ansatz f√ºr die aktive Erfassung von Trainingsdaten f√ºr NL2API auf der Basis von Crowdsourcing. Wir verwenden Remote-F√ºhrungskr√§fte, um API-Aufrufe beim Vergleich mit NL-Befehlen mit Anmerkungen zu versehen.  Auf diese Weise k√∂nnen Sie drei Entwurfsziele erreichen, indem Sie Folgendes bereitstellen: (1) Anpassbarkeit.  Sie m√ºssen angeben k√∂nnen, welche Parameter f√ºr welche API verwendet werden sollen und wie viele Trainingsdaten erfasst werden sollen.  (2) Niedrige Kosten.  Die Dienstleistungen von Crowdsourcing-Mitarbeitern sind um eine Gr√∂√üenordnung billiger als die von spezialisierten Spezialisten, weshalb sie eingestellt werden sollten.  (3) Hohe Qualit√§t.  Die Qualit√§t der Trainingsdaten sollte nicht verringert werden. <br><br>  Bei der Gestaltung dieses Ansatzes treten zwei Hauptprobleme auf.  Erstens sind API-Aufrufe mit erweiterter Parametrisierung, wie in Abbildung 1 dargestellt, f√ºr den Durchschnittsbenutzer nicht nachvollziehbar. Daher m√ºssen Sie entscheiden, wie das Anmerkungsproblem formuliert werden soll, damit Crowdsourcing-Mitarbeiter problemlos damit umgehen k√∂nnen.  Wir beginnen mit der Entwicklung einer semantischen Zwischendarstellung f√ºr die Web-API (siehe Abschnitt 2.2), mit der wir nahtlos API-Aufrufe mit den erforderlichen Parametern generieren k√∂nnen. <br><br>  Dann √ºberlegen wir uns die Grammatik f√ºr die automatische Konvertierung jedes API-Aufrufs in einen kanonischen NL-Befehl, was ziemlich umst√§ndlich sein kann, aber f√ºr den durchschnittlichen Crowdsourcing-Mitarbeiter klar ist (siehe Abschnitt 3.1).  Die Darsteller m√ºssen das kanonische Team nur umformulieren, damit es nat√ºrlicher klingt.  Mit diesem Ansatz k√∂nnen Sie viele Fehler bei der Erfassung von Schulungsdaten vermeiden, da die Umformulierungsaufgabe f√ºr den durchschnittlichen Crowdsourcing-Mitarbeiter viel einfacher und verst√§ndlicher ist. <br><br>  Zweitens m√ºssen Sie verstehen, wie Sie nur diejenigen API-Aufrufe definieren und mit Anmerkungen versehen, die f√ºr das Erlernen von NL2API von echtem Wert sind.  Die ‚Äûkombinatorische Explosion‚Äú, die w√§hrend der Parametrierung auftritt, f√ºhrt dazu, dass die Anzahl der Aufrufe selbst f√ºr eine API sehr gro√ü sein kann.  Es ist nicht sinnvoll, alle Anrufe mit Anmerkungen zu versehen.  Wir bieten ein grundlegend neues hierarchisches Wahrscheinlichkeitsmodell f√ºr die Implementierung des Crowdsourcing-Prozesses an (siehe Abschnitt 3.2).  In Analogie zur Sprachmodellierung zum Abrufen von Informationen gehen wir davon aus, dass NL-Befehle basierend auf den entsprechenden API-Aufrufen generiert werden. Daher sollte das Sprachmodell f√ºr jeden API-Aufruf verwendet werden, um diesen ‚Äûgenerativen‚Äú Prozess zu registrieren. <br><br>  Unser Modell basiert auf der Zusammensetzung von API-Aufrufen oder formalisierten Darstellungen der semantischen Struktur als Ganzes.  Auf einer intuitiven Ebene k√∂nnen wir einen API-Aufruf erstellen, wenn er aus einfacheren Aufrufen besteht (z. B. "ungelesene E-Mails √ºber einen Kandidaten f√ºr einen naturwissenschaftlichen Abschluss" = "ungelesene E-Mails" + "E-Mails f√ºr einen Kandidaten f√ºr einen naturwissenschaftlichen Abschluss") Sprachmodell aus einfachen API-Aufrufen, auch ohne Annotation. Durch Annotieren einer kleinen Anzahl von API-Aufrufen k√∂nnen wir das Sprachmodell f√ºr alle anderen berechnen. <br><br>  Nat√ºrlich sind die berechneten Sprachmodelle alles andere als ideal, sonst h√§tten wir das Problem der Erstellung von NL2API bereits gel√∂st.  Eine solche Extrapolation des Sprachmodells auf nicht kommentierte API-Aufrufe gibt uns jedoch eine ganzheitliche Sicht auf den gesamten Bereich der API-Aufrufe sowie auf das Zusammenspiel der nat√ºrlichen Sprache und der API-Aufrufe, wodurch wir den Crowdsourcing-Prozess optimieren k√∂nnen.  In Abschnitt 3.3 beschreiben wir einen Algorithmus zum selektiven Kommentieren von API-Aufrufen, um die Unterscheidbarkeit von API-Aufrufen zu verbessern, dh um die Diskrepanz zwischen ihren Sprachmodellen zu maximieren. <br><br>  Wir wenden unser Framework auf zwei bereitgestellte APIs aus dem Microsoft Graph API2-Paket an.  Wir zeigen, dass qualitativ hochwertige Trainingsdaten zu minimalen Kosten gesammelt werden k√∂nnen, wenn der vorgeschlagene Ansatz verwendet wird3.  Wir zeigen auch, dass unser Ansatz das Crowdsourcing verbessert.  Zu √§hnlichen Kosten sammeln wir bessere Trainingsdaten, die die Basislinie deutlich √ºberschreiten.  Infolgedessen bieten unsere NL2API-L√∂sungen eine h√∂here Genauigkeit. <br><br>  Im Allgemeinen umfasst unser Hauptbeitrag drei Aspekte: <br><br><ul><li>  Wir waren eine der ersten, die sich mit den Problemen von NL2API befasst haben, und haben einen umfassenden Rahmen f√ºr die Erstellung von NL2API von Grund auf vorgeschlagen. </li><li>  Wir haben einen einzigartigen Ansatz f√ºr die Erfassung von Trainingsdaten mithilfe von Crowdsourcing und ein grundlegend neues hierarchisches Wahrscheinlichkeitsmodell vorgeschlagen, um diesen Prozess zu optimieren. </li><li>  Wir haben unser Framework auf echte Web-APIs angewendet und gezeigt, dass eine ausreichend effektive NL2API-L√∂sung von Grund auf neu erstellt werden kann. </li></ul><br><img src="https://habrastorage.org/webt/t4/fs/vl/t4fsvlxndjmziwbvzjh2rwqut2c.png"><br>  <i>Tabelle 1. OData-Abfrageparameter.</i> <br><br><h2>  Pr√§ambel </h2><br><h4>  RESTful API </h4><br>  In letzter Zeit werden Web-APIs, die dem REST-Architekturstil entsprechen, d. H. Der RESTful-API, aufgrund ihrer Einfachheit immer beliebter.  RESTful-APIs werden auch auf Smartphones und IoT-Ger√§ten verwendet.  Die Restful-APIs arbeiten mit Ressourcen, die √ºber URIs angesprochen werden, und bieten einer Vielzahl von Clients mithilfe einfacher HTTP-Befehle Zugriff auf diese Ressourcen: GET, PUT, POST usw. Wir werden haupts√§chlich mit der RESTful-API arbeiten, aber die grundlegenden Methoden k√∂nnen verwendet werden und andere APIs. <br><br>  Nehmen Sie beispielsweise das beliebte Open Data Protocol (OData) f√ºr die RESTful-API und zwei Web-APIs aus dem Microsoft Graph API-Paket (Abbildung 1), die jeweils zur Suche nach E-Mails und Benutzerkalenderereignissen verwendet werden.  Ressourcen in OData sind Entit√§ten, von denen jede einer Liste von Eigenschaften zugeordnet ist.  Beispielsweise verf√ºgt die Nachrichtenentit√§t - eine E-Mail - √ºber Eigenschaften wie Betreff (Betreff), von (von), isRead (Lesen), receiveDateTime (Datum und Uhrzeit des Empfangs) usw. <br><br>  Dar√ºber hinaus definiert OData eine Reihe von Abfrageparametern, mit denen Sie erweiterte Manipulationen an Ressourcen durchf√ºhren k√∂nnen.  Mit dem Parameter FILTER k√∂nnen Sie beispielsweise nach E-Mails eines bestimmten Absenders oder nach Briefen suchen, die an einem bestimmten Datum eingegangen sind.  Die Anforderungsparameter, die wir verwenden werden, sind in Tabelle 1 aufgef√ºhrt. Wir rufen jede Kombination des HTTP-Befehls und der Entit√§t (oder einer Gruppe von Entit√§ten) als API auf, z. B. GET-Nachrichten, um nach E-Mails zu suchen.  Jede parametrisierte Anforderung, z. B. FILTER (isRead = False), wird als Parameter bezeichnet, und ein API-Aufruf ist eine API mit einer Liste von Parametern. <br><br><h4>  NL2API </h4><br>  Die Hauptaufgabe von NLI besteht darin, eine Anweisung (einen Befehl in einer nat√ºrlichen Sprache) mit einer bestimmten formalisierten Darstellung zu vergleichen, z. B. logischen Formularen oder SPARQL-Abfragen f√ºr Wissensdatenbanken oder Web-APIs in unserem Fall.  Wenn es notwendig ist, sich auf die semantische Abbildung zu konzentrieren, ohne von irrelevanten Details abgelenkt zu werden, wird normalerweise eine semantische Zwischendarstellung verwendet, um nicht direkt mit dem Ziel zu arbeiten.  Beispielsweise wird die kombinatorische kategoriale Grammatik h√§ufig zum Erstellen von NLIs f√ºr Datenbanken und Wissensdatenbanken verwendet.  Ein √§hnlicher Ansatz zur Abstraktion ist auch f√ºr NL2API sehr wichtig.  Viele Details, einschlie√ülich URL-Konventionen, HTTP-Header und Antwortcodes, k√∂nnen die NL2API von der L√∂sung des Hauptproblems - der semantischen Zuordnung - "ablenken". <br><br>  Daher erstellen wir eine Zwischenansicht f√ºr RESTful-APIs (Abbildung 2) mit dem Namen API-Frame. Diese Ansicht spiegelt die Semantik des Frames wider.  Der API-Frame besteht aus f√ºnf Teilen.  HTTP-Verb (HTTP-Befehl) und Ressource sind die Grundelemente f√ºr eine RESTful-API.  Mit Return Type k√∂nnen Sie zusammengesetzte APIs erstellen, dh mehrere API-Aufrufe kombinieren, um eine komplexere Operation auszuf√ºhren.  Erforderliche Parameter werden am h√§ufigsten bei PUT- oder POST-Aufrufen in der API verwendet. Beispielsweise sind Adresse, Header und Nachrichtentext erforderliche Parameter f√ºr das Senden von E-Mails.  Optionale Parameter sind h√§ufig in GET-Aufrufen in der API vorhanden. Sie helfen dabei, die Informationsanforderung einzugrenzen. <br><br>  Wenn die erforderlichen Parameter fehlen, serialisieren wir den API-Frame, zum Beispiel: GET-messages {FILTER (isRead = False), SEARCH (‚ÄûPhD application‚Äú), COUNT ()}.  Ein API-Frame kann deterministisch sein und in einen echten API-Aufruf konvertiert werden.  W√§hrend des Konvertierungsprozesses werden die erforderlichen Kontextdaten hinzugef√ºgt, einschlie√ülich Benutzer-ID, Ort, Datum und Uhrzeit.  Im zweiten Beispiel (Abbildung 1) wird der Now-Wert im Parameter FILTER durch das Datum und die Uhrzeit der Ausf√ºhrung des entsprechenden Befehls w√§hrend der Konvertierung des API-Frames in einen echten API-Aufruf ersetzt.  Ferner werden die Konzepte eines API-Rahmens und eines API-Aufrufs austauschbar verwendet. <br><br><img src="https://habrastorage.org/webt/zq/ya/1s/zqya1s2fappwxv0soevosjshp6o.png"><br>  <i>Abbildung 2. Der API-Frame.</i>  <i>Oben: Team in nat√ºrlicher Sprache.</i>  <i>In der Mitte: Frame API.</i>  <i>Unten: API-Aufruf.</i> <br><br><img src="https://habrastorage.org/webt/d1/4j/br/d14jbrsdzhethdl8tpvjlf0v7bq.png"><br> <i> 3.  .</i> <br><br><h2>    </h2><br>                NL2API   .     API        ,     ( 3.1),          ( 3).     API,       ( 3.2),      ( 3.3). <br><br><img src="https://habrastorage.org/webt/-m/hx/zh/-mhxzhnfom3w3n8cck-nkazfwiu.png"><br> <i> 4.   . :   . :  .</i> <br><br><h4>  API    </h4><br>    API     API.   ,       ,        API,   API  .      ,  Boolean,     (True/False). <br><br>      ,  Datetime,     ,  today  this_week  receivedDateTime.  ,        API           (,    )    API    API. <br><br>     ,        API .        . ,     TOP,         ORDERBY.  ,   Boolean,  isRead,  ORDERBY   .    ¬´ ¬ª         API   API. <br><br>      API.       API   .     API     API  ( 4).            ( HTTP, ,    ). ,   ‚ü®sender ‚Üí NP[from]‚ü© ,     from  ¬´sender¬ª,    ‚Äî   (NP),     . <br><br>       (V),   (VP),  (JJ), - (CP),   ,       (NP/NP),    (PP/NP),  (S)  . . <br><br>  ,       API     ,           RESTful API    OData ‚Äî ¬´ ¬ª    . 17     4     API,     ( 5). <br><br>   ,          API.     ‚ü®t1, t2, ..., tn ‚Üí c[z]‚ü©,  <img src="https://habrastorage.org/webt/h5/rj/n2/h5rjn28vmc1twejoa5459flx0gm.png">    , z    API,  cz ‚Äî   .     4.   API    ,     S,     G4,     API   . C    ,          ,               - ¬´that is not read¬ª. <br><br>  ,      . ,  VP[x = False]     B2,   B4,       x.  x     VP,   B2 (, x is hasAttachments ‚Üí ¬´do not have attachment¬ª);    JJ,    B4 (, x is isRead ‚Üí ¬´is not read¬ª).       (¬´do not read¬ª or ¬´is not have attachment¬ª)       . <br><br><h4>   </h4><br>  Mit dem oben beschriebenen Ansatz k√∂nnen wir eine gro√üe Anzahl von API-Aufrufen generieren, aber das Annotieren aller Aufrufe mithilfe von Crowdsourcing ist wirtschaftlich nicht machbar.  Daher schlagen wir ein hierarchisches Wahrscheinlichkeitsmodell f√ºr Crowdsourcing vor, mit dessen Hilfe Sie entscheiden k√∂nnen, welche API-Aufrufe mit Anmerkungen versehen werden sollen.  Soweit wir wissen, ist dies das erste probabilistische Modell f√ºr die Verwendung von Crowdsourcing zur Erstellung von NLI-Schnittstellen, mit dem wir die einzigartige und faszinierende Aufgabe der Modellierung der Interaktion zwischen Darstellungen nat√ºrlicher Sprache und formalisierten semantischen Strukturdarstellungen l√∂sen k√∂nnen.  Formalisierte Darstellungen der semantischen Struktur im Allgemeinen und API-Aufrufe im Besonderen sind kompositorischer Natur.  Zum Beispiel besteht z12 = GET-Nachrichten {COUNT (), FILTER (isRead = False)} aus z1 = GET-Nachrichten {FILTER (isRead = False)} und z2 = GET-Nachrichten {COUNT ()} (diese Beispiele sind detaillierter weiter diskutieren). <br><br><img src="https://habrastorage.org/webt/fa/w0/eh/faw0ehohhnasifwgtragzrqwg3o.png"><br>  <i>Abbildung 5. Das semantische Netzwerk.</i>  <i>Die i-te Schicht besteht aus API-Aufrufen mit i-Parametern.</i>  <i>Rippen sind Kompositionen.</i>  <i>Die Wahrscheinlichkeitsverteilungen an den Eckpunkten charakterisieren die entsprechenden Sprachmodelle.</i> <br><br>  Eines der wichtigsten Ergebnisse unserer Studie war die Best√§tigung, dass eine solche Zusammensetzung zur Modellierung des Crowdsourcing-Prozesses verwendet werden kann. <br><br>  Zun√§chst definieren wir die Zusammensetzung basierend auf einer Reihe von API-Aufrufparametern. <br><br>  <b>Definition 3.1 (Zusammensetzung).</b>  Nehmen Sie eine API und eine Reihe von API-Aufrufen <br><img src="https://habrastorage.org/webt/jp/nd/rx/jpndrxembixwz20-sym5vtxyhaq.png">  Wenn wir r (z) als einen Satz von Parametern f√ºr z definieren, dann <img src="https://habrastorage.org/webt/zq/ih/u5/zqihu5tkga6iigokecjod-cg5um.png">  ist eine Komposition <img src="https://habrastorage.org/webt/_a/1x/jv/_a1xjvs9yduvatefhmfdk6xumq8.png">  genau dann, wenn <img src="https://habrastorage.org/webt/0e/oy/hw/0eoyhwaahe8xlrbplt1nqajeego.png">  ist ein Teil <img src="https://habrastorage.org/webt/np/q5/sy/npq5syhh47uv3yvyba_t1_4tqc0.png"><br><br>  Basierend auf den Zusammensetzungsbeziehungen von API-Aufrufen k√∂nnen Sie alle API-Aufrufe in einer einzigen hierarchischen Struktur organisieren.  API-Aufrufe mit der gleichen Anzahl von Parametern werden als Eckpunkte einer Ebene dargestellt, und Kompositionen werden als dargestellt <br>  gerichtete Rippen zwischen den Schichten.  Wir nennen diese Struktur ein sematisches Netzwerk (oder SeMesh). <br><br>  In Analogie zu dem Ansatz, der auf der Sprachmodellierung beim Abrufen von Informationen basiert, nehmen wir an, dass Anweisungen, die einem API-z-Aufruf entsprechen, unter Verwendung eines stochastischen Prozesses generiert werden, der durch ein Sprachmodell gekennzeichnet ist <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  .  Zur Vereinfachung konzentrieren wir uns daher auf die Wahrscheinlichkeiten von W√∂rtern <img src="https://habrastorage.org/webt/on/eh/p5/onehp5mxamc9ehgpsl1u4pbkfr4.png">  wo <img src="https://habrastorage.org/webt/a-/v8/rh/a-v8rh1ddeh_ai-eawq8udhqe80.png">  bezeichnet ein W√∂rterbuch. <br><br>  Aus Gr√ºnden, die etwas sp√§ter deutlich werden, empfehlen wir anstelle des Standard-Sprach-Unigramm-Modells die Verwendung einer Reihe von Bernoulli-Verteilungen (Bag of Bernoulli, BoB).  Jede Bernoulli-Verteilung entspricht einer Zufallsvariablen W, die bestimmt, ob das Wort w in dem auf der Grundlage von z erzeugten Satz erscheint, und die BoB-Verteilung ist eine Menge von Bernoulli-Verteilungen f√ºr alle W√∂rter <img src="https://habrastorage.org/webt/k0/gw/fj/k0gwfjeikxqircdxhndamv6xbba.png">  .  Wir werden verwenden <img src="https://habrastorage.org/webt/j1/vn/qm/j1vnqmhyhigxbdpj7s5irirmxae.png">  als Kurznotation f√ºr <img src="https://habrastorage.org/webt/ub/xi/rx/ubxirxha2um6wer3obznfezis7w.png">  . <br><br>  Angenommen, wir haben eine (Mehrfach-) Menge von Anweisungen gebildet <img src="https://habrastorage.org/webt/m5/nb/sr/m5nbsrzyyxpfpzc6isj_qrjjxbs.png">  f√ºr z, <br>  Mit der Maximum Likelihood Estimation (MLE) f√ºr die BoB-Verteilung k√∂nnen Sie Anweisungen ausw√§hlen, die w enthalten: <br><br><img src="https://habrastorage.org/webt/ix/gv/2q/ixgv2qua9ifqtxbp1mi3hf58izc.png"><br><br>  <b>Beispiel 2.</b> In Bezug auf den obigen API-Aufruf z1 nehmen wir an, wir haben zwei Anweisungen: u1 = "ungelesene E-Mails finden" und u2 = "nicht gelesene E-Mails", dann u = {u1, u2}.  pb ("E-Mails" | z) = 1.0, da "E-Mails" in beiden Anweisungen vorhanden sind.  In √§hnlicher Weise ist pb ("ungelesen" | z) = 0,5 und pb ("Treffen" | z) = 0,0. <br><br>  Im semantischen Netzwerk gibt es drei grundlegende Operationen auf der Scheitelpunktebene: <br>  Anmerkung, Layout und Interpolation. <br><br>  <b>ANNOTATE</b> (zu kommentieren) bedeutet, Aussagen zu sammeln <img src="https://habrastorage.org/webt/m5/nb/sr/m5nbsrzyyxpfpzc6isj_qrjjxbs.png">  den kanonischen Befehl des Scheitelpunkts z mithilfe von Crowdsourcing zu paraphrasieren und die empirische Verteilung zu bewerten <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  Maximum-Likelihood-Methode. <br><br>  <b>COMPOSE</b> (compose) versucht, ein auf Kompositionen basierendes Sprachmodell abzuleiten, um die erwartete Verteilung zu berechnen <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  .  Wie wir experimentell zeigen, <img src="https://habrastorage.org/webt/zq/ih/u5/zqihu5tkga6iigokecjod-cg5um.png">  Ist eine Komposition f√ºr z.  Wenn wir von der Annahme ausgehen, dass die entsprechenden Aussagen durch denselben kompositorischen Zusammenhang gekennzeichnet sind, dann <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  sollte angelegt werden <img src="https://habrastorage.org/webt/xe/zj/vd/xezjvdelmyapzpsz-c-ubbyrowq.png">  :: <br><br><img src="https://habrastorage.org/webt/1j/kw/gy/1jkwgy2cjdyy2tkd9fd94_vdtf0.png"><br><br>  wobei f eine kompositorische Funktion ist.  F√ºr die BoB-Verteilung sieht die Kompositionsfunktion folgenderma√üen aus: <br><br><img src="https://habrastorage.org/webt/-j/yo/yc/-jyoycveazjjahzb2va3w26sfv0.png"><br><br>  Mit anderen Worten, wenn ui eine Aussage zi ist, ist u eine Aussage <img src="https://habrastorage.org/webt/lr/ls/g_/lrlsg_9r0ga50mjkj47anmczlga.png">  kompositorisch bildet u, dann geh√∂rt das Wort w nicht zu u.  Genau dann, wenn es keiner Benutzeroberfl√§che geh√∂rt.  Wenn z viele Zusammensetzungen hat, wird Œ∏e x separat berechnet und dann gemittelt.  Das Standard-Sprach-Unigramm-Modell f√ºhrt nicht zu einer nat√ºrlichen Kompositionsfunktion.  Bei der Normalisierung der Wortwahrscheinlichkeiten wird die L√§nge der S√§tze ber√ºcksichtigt, was wiederum die Komplexit√§t der API-Aufrufe ber√ºcksichtigt und die Zerlegung in Gleichung (2) verletzt.  Deshalb bieten wir den BoB-Vertrieb an. <br><br>  <b>Beispiel 3.</b> Angenommen, wir haben eine Annotation f√ºr die zuvor erw√§hnten API-Aufrufe z1 und z2 erstellt, von denen jede zwei Anweisungen enth√§lt: <img src="https://habrastorage.org/webt/zy/pr/yx/zypryx-8unafep9q1_lu2bnwewi.png">  = {"Ungelesene E-Mails suchen", "E-Mails, die nicht gelesen werden"} und <img src="https://habrastorage.org/webt/7n/4a/74/7n4a746gi-pf2_nf0ocy0dohdqm.png">  = {"Wie viele E-Mails habe ich?", "Anzahl der E-Mails ermitteln"}.  Wir haben Sprachmodelle bewertet <img src="https://habrastorage.org/webt/7a/uj/od/7aujod7s9qek21mw3zemkcgaake.png">  und <img src="https://habrastorage.org/webt/vp/so/fn/vpsofnkfxhjn38dfcjpm6bqzzio.png">  .  Die Kompositionsoperation versucht zu bewerten <img src="https://habrastorage.org/webt/qt/tm/ud/qttmudo6ekcwmdeptxfjigmmcck.png">  ohne zu fragen <img src="https://habrastorage.org/webt/hx/6c/sn/hx6csng8_0l_yqxgvteefbapkm0.png">  .  Zum Beispiel ist f√ºr das Wort "E-Mails" pb ("E-Mails" | z1) = 1,0 und pb ("E-Mails" | z2) = 1,0, so dass aus Gleichung (3) folgt, dass pb ("E-Mails" | z12) = 1.0, das hei√üt, wir glauben, dass dieses Wort in jeder Aussage von z12 enthalten sein wird.  In √§hnlicher Weise ist pb ("find" | z1) = 0,5 und pb ("find" | z2) = 0,5, so dass pb ("find" | z12) = 0,75 ist.  Ein Wort hat eine gute Chance, aus einem beliebigen z1 oder z2 generiert zu werden, daher sollte seine Wahrscheinlichkeit f√ºr z12 h√∂her sein. <br><br>  Nat√ºrlich werden Aussagen nicht immer kompositorisch kombiniert.  Beispielsweise k√∂nnen mehrere Elemente in einer formalisierten Darstellung einer semantischen Struktur in einem einzigen Wort oder einer Phrase in einer nat√ºrlichen Sprache vermittelt werden. Dieses Ph√§nomen wird als sublexische Kompositionalit√§t bezeichnet.  Ein solches Beispiel ist in Abbildung 3 dargestellt, in der die drei Parameter TOP (1), FILTER (Start&gt; jetzt) ‚Äã‚Äãund ORDERBY (Start, aufsteigend) durch das einzelne Wort ‚Äûnext‚Äú dargestellt werden.  Es ist jedoch unm√∂glich, solche Informationen zu erhalten, ohne den API-Aufruf mit Anmerkungen zu versehen, sodass das Problem selbst dem Problem von H√ºhnchen und Eiern √§hnelt.  In Ermangelung solcher Informationen ist es vern√ºnftig, die Standardannahme einzuhalten, dass Anweisungen durch dieselbe Zusammensetzungsbeziehung wie API-Aufrufe gekennzeichnet sind. <br><br>  Dies ist eine plausible Annahme.  Es ist erw√§hnenswert, dass diese Annahme nur zur Modellierung des Crowdsourcing-Prozesses mit dem Ziel der Datenerfassung verwendet wird.  In der Testphase entsprechen die Aussagen realer Benutzer m√∂glicherweise nicht dieser Annahme.  Die Schnittstelle in nat√ºrlicher Sprache wird in der Lage sein, solche nicht kompositorischen Situationen zu bew√§ltigen, wenn sie durch die gesammelten Trainingsdaten abgedeckt sind. <br><br>  <b>INTERPOLATE</b> (Interpolation) kombiniert alle verf√ºgbaren Informationen √ºber z, dh kommentierte √Ñu√üerungen z und Informationen, die aus den Kompositionen erhalten wurden, und erh√§lt eine genauere Sch√§tzung <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  durch Interpolation <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  und <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  . <br><br><img src="https://habrastorage.org/webt/s4/qk/00/s4qk00v3xupp-nglc-ge-mmgwxa.png"><br><br>  Der Balance-Parameter Œ± steuert die Kompromisse zwischen Anmerkungen <br>  Stromspitzen, die genau, aber ausreichend sind, und Informationen, die aus Zusammensetzungen erhalten werden, die auf der Annahme der Zusammensetzung beruhen, sind m√∂glicherweise nicht so genau, bieten jedoch eine breitere Abdeckung.  In gewissem Sinne <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  dient dem gleichen Zweck wie Anti-Aliasing in der Sprachmodellierung, das eine bessere Sch√§tzung der Wahrscheinlichkeitsverteilung mit unzureichenden Daten (Anmerkungen) erm√∂glicht.  Mehr als <img src="https://habrastorage.org/webt/xt/ml/w5/xtmlw5p16zioqn1amioucvjhe5o.png">  je mehr Gewicht in <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  .  F√ºr einen Wurzelscheitelpunkt, der keine Zusammensetzung hat, <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  = <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  .  F√ºr ein nicht kommentiertes Top <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  = <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  . <br><br>  Als n√§chstes beschreiben wir den semantischen Netzwerkaktualisierungsalgorithmus, d. H. Berechnungen <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  f√ºr alle z (Algorithmus 1), auch wenn nur ein kleiner Teil der Eckpunkte mit Anmerkungen versehen wurde.  Wir gehen davon aus, dass der Wert <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  Bereits f√ºr alle kommentierten Websites aktualisiert.  Wir gehen von oben nach unten und berechnen nacheinander <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  und <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  f√ºr jeden Scheitelpunkt z.  Zun√§chst m√ºssen Sie die oberen Ebenen aktualisieren, damit Sie die erwartete Verteilung der Scheitelpunkte der unteren Ebene berechnen k√∂nnen.  Wir haben alle Wurzelscheitelpunkte mit Anmerkungen versehen, damit wir berechnen k√∂nnen <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  f√ºr alle Eckpunkte. <br><br>  <i>Algorithmus 1. Aktualisieren Sie die Knotenverteilungen des semantischen Netzes</i> <br><br><img src="https://habrastorage.org/webt/wd/ja/xx/wdjaxx4oqk_1rqniul9rnbc-fno.png"><br><br><h4>  3.3 Crowdsourcing-Optimierung </h4><br>  Das semantische Netzwerk bildet eine ganzheitliche Ansicht des gesamten Raums von API-Aufrufen sowie der Interaktion von Anweisungen und Aufrufen.  Basierend auf dieser Ansicht k√∂nnen wir nur eine Teilmenge hochwertiger API-Aufrufe selektiv mit Anmerkungen versehen.  In diesem Abschnitt beschreiben wir unsere Differenzverteilungsstrategie zur Optimierung des Crowdsourcing. <br><br>  Stellen Sie sich ein semantisches Netzwerk mit vielen Eckpunkten Z vor. Unsere Aufgabe besteht darin, eine Teilmenge von Eckpunkten innerhalb des iterativen Prozesses zu bestimmen <img src="https://habrastorage.org/webt/ti/9x/ac/ti9xacqha0b1hbtkyeejh30f3sk.png">  von Crowdsourcing-Mitarbeitern kommentiert werden.  Die zuvor mit Anmerkungen versehenen Scheitelpunkte werden als Statusstatus bezeichnet. <br>  dann m√ºssen wir politische Richtlinien finden <img src="https://habrastorage.org/webt/9i/oc/9m/9ioc9mao9yuvhq7uhkiemeqet4g.png">  um jeden nicht kommentierten Scheitelpunkt basierend auf dem aktuellen Status zu bewerten. <br><br>  Bevor wir uns mit der Diskussion von Ans√§tzen zur Berechnung effektiver Richtlinien befassen, nehmen wir an, dass wir bereits einen haben, und geben eine allgemeine Beschreibung unseres Crowdsourcing-Algorithmus (Algorithmus 2), um die zugeh√∂rigen Methoden zu beschreiben.  Insbesondere kommentieren wir zuerst alle Wurzelscheitelpunkte, um die Verteilung f√ºr alle Scheitelpunkte in Z (Zeile 3) zu bewerten.  Bei jeder Iteration aktualisieren wir die Scheitelpunktverteilung (Zeile 5), berechnen <br>  W√§hlen Sie eine Richtlinie aus, die auf dem aktuellen Status des semantischen Netzwerks basiert (Zeile 6), w√§hlen Sie den nicht kommentierten Scheitelpunkt mit der maximalen Bewertung aus (Zeile 7) und kommentieren Sie den Scheitelpunkt und das Ergebnis im neuen Status (Zeile 8).  In der Praxis k√∂nnen Sie im Rahmen einer Iteration mehrere Scheitelpunkte mit Anmerkungen versehen, um die Effizienz zu steigern. <br><br><img src="https://habrastorage.org/webt/va/tz/hs/vatzhsjcogvaktg8wh4h0a8al70.png"><br>  <i>Abbildung 6. Differentialverteilung.</i>  <i>z12 und z23 repr√§sentieren das untersuchte Eckpunktpaar.</i>  <i>w ist eine Sch√§tzung, die auf der Grundlage von d (z12, z23) berechnet wird und sich iterativ von unten nach oben ausbreitet und in jeder Iteration verdoppelt wird.</i>  <i>Die Sch√§tzung f√ºr den Scheitelpunkt ist die absolute Differenz seiner Sch√§tzungen von z12 und z23 (daher differenziell).</i>  <i>z2 erh√§lt eine Punktzahl von 0, da es die gemeinsame √ºbergeordnete Entit√§t f√ºr z12 und z23 ist.</i>  <i>Anmerkungen sind in diesem Fall von geringem Nutzen, um die Unterscheidbarkeit von z12 und z23 sicherzustellen.</i> <br><br>  Im weitesten Sinne k√∂nnen die Aufgaben, die wir l√∂sen, auf das Problem des aktiven Lernens zur√ºckgef√ºhrt werden. Wir haben uns zum Ziel gesetzt, eine Teilmenge von Beispielen f√ºr Anmerkungen zu identifizieren, um ein Trainingsset zu erhalten, das die Lernergebnisse verbessern kann.  Einige wesentliche Unterschiede erlauben jedoch nicht die direkte Anwendung klassischer aktiver Lehrmethoden, wie z. B. ‚ÄûStichprobenunsicherheit‚Äú.  W√§hrend des aktiven Lernens versucht der Sch√ºler, in unserem Fall die NLI-Schnittstelle, normalerweise, die Zuordnung f: X ‚Üí Y zu untersuchen, wobei X die Eingangsraumprobe ist, die aus einem kleinen Satz markierter und einer gro√üen Anzahl nicht markierter Proben besteht, und Y normalerweise ein Satz Markierungen Klasse. <br><br>  Der Student bewertet den informativen Wert unbeschrifteter Beispiele und w√§hlt den informativsten aus, um von Crowdsourcing-Mitarbeitern eine Y-Note zu erhalten.  Im Rahmen des Problems, das wir l√∂sen, wird das Annotationsproblem jedoch anders gestellt.  Wir m√ºssen eine Instanz aus Y, einem gro√üen API-Aufrufraum, ausw√§hlen und Crowdsourcing-Mitarbeiter bitten, sie zu kennzeichnen, indem sie Muster in X, dem Satzraum, angeben.  Dar√ºber hinaus sind wir nicht an einen bestimmten Auszubildenden gebunden.  Daher schlagen wir eine neue L√∂sung f√ºr das vorliegende Problem vor.  Wir lassen uns von zahlreichen Quellen zum aktiven Lernen inspirieren. <br><br>  Zun√§chst bestimmen wir das Ziel, anhand dessen der Informationsgehalt der Knoten ausgewertet wird.  Nat√ºrlich m√∂chten wir, dass verschiedene API-Aufrufe unterscheidbar sind.  Im semantischen Netzwerk bedeutet dies, dass die Verteilung <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  Unterschiedliche Peaks weisen offensichtliche Unterschiede auf.  Zun√§chst pr√§sentieren wir jede Distribution <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  wie ein n-dimensionaler Vektor <img src="https://habrastorage.org/webt/nv/ky/pn/nvkypndwq-7j6xnikrteas3oiq4.png">  wobei n = | <img src="https://habrastorage.org/webt/a-/v8/rh/a-v8rh1ddeh_ai-eawq8udhqe80.png">  |  - die Gr√∂√üe des W√∂rterbuchs.  Mit einer bestimmten Metrik des Vektorabstands d (in unseren Experimenten verwenden wir den Abstand zwischen den Vektoren pL1) meinen wir <img src="https://habrastorage.org/webt/jc/z9/de/jcz9demx4drw0fsgz1niisgavd0.png">  Das hei√üt, der Abstand zwischen zwei Eckpunkten ist gleich dem Abstand zwischen ihren Verteilungen. <br><br>  Das offensichtliche Ziel besteht darin, den Gesamtabstand zwischen allen Scheitelpunktpaaren zu maximieren.  Die Optimierung aller paarweisen Abst√§nde kann jedoch f√ºr Berechnungen zu kompliziert sein, und selbst dies ist nicht erforderlich.  Ein Paar entfernter Spitzen weist bereits gen√ºgend Unterschiede auf, sodass eine weitere Erh√∂hung der Entfernung keinen Sinn ergibt.  Stattdessen k√∂nnen wir uns auf die Eckpunktpaare konzentrieren, die am meisten Verwirrung stiften, dh der Abstand zwischen ihnen ist am geringsten. <br><br><img src="https://habrastorage.org/webt/of/tp/sl/oftpslo2cmmijyxtccepbyqsmsc.png"><br><br>  wo <img src="https://habrastorage.org/webt/1g/-h/nh/1g-hnhpklydkghmo4z7pq7ujouu.png">  zeigt auf die ersten K Eckpunktpaare, wenn wir alle Knotenpaare nach Entfernung in aufsteigender Reihenfolge ordnen. <br><br>  <i>Algorithmus 2. Kommentieren Sie ein semantisches Netz iterativ mit einer Richtlinie</i> <br><br><img src="https://habrastorage.org/webt/5p/j2/2r/5pj22rp_c5npknusixp4k4ulfli.png"><br><br>  <i>Algorithmus 3. Berechnen Sie die Richtlinie basierend auf der differentiellen Ausbreitung</i> <br><br><img src="https://habrastorage.org/webt/s5/ee/zb/s5eezb7ls03ly9nfndyotsqhlva.png"><br><br>  <i>Algorithmus 4. Propagieren Sie eine Punktzahl rekursiv von einem Quellknoten auf alle √ºbergeordneten Knoten</i> <br><br><img src="https://habrastorage.org/webt/m9/ge/vt/m9gevt8-vlgwxxulaxyfxkovdmk.png"><br><br>  Scheitelpunkte mit h√∂herem Informationsgehalt nach der Annotation erh√∂hen m√∂glicherweise den Wert von Œò.  Zur Quantifizierung in diesem Fall schlagen wir die Verwendung einer Differenzverteilungsstrategie vor.  Wenn der Abstand zwischen einem Scheitelpunktpaar klein ist, untersuchen wir alle √ºbergeordneten Scheitelpunkte: Wenn der √ºbergeordnete Scheitelpunkt f√ºr ein Scheitelpunktpaar gleich ist, sollte er eine niedrige Bewertung erhalten, da Anmerkungen f√ºr beide Scheitelpunkte zu √§hnlichen √Ñnderungen f√ºhren. <br><br>  Andernfalls muss der Scheitelpunkt hoch bewertet werden. Je n√§her das Scheitelpunktpaar ist, desto h√∂her ist die Bewertung.  Wenn beispielsweise der Abstand zwischen den Scheitelpunkten von "ungelesenen E-Mails zur Promotion" und "Wie viele E-Mails zur Promotion" gering ist, ist das Kommentieren des √ºbergeordneten Scheitelpunkts "E-Mails zur Promotion" unter dem Gesichtspunkt der Unterscheidung dieser Scheitelpunkte nicht sehr sinnvoll.  Es ist ratsamer, √ºbergeordnete Knoten mit Anmerkungen zu versehen, die ihnen nicht gemeinsam sind: "ungelesene E-Mails" und "wie viele E-Mails". <br><br>  Ein Beispiel f√ºr eine solche Situation ist in Abbildung 6 dargestellt. Der Algorithmus ist Algorithmus 3. Als Sch√§tzung nehmen wir den Kehrwert der durch eine Konstante begrenzten Knotenentfernung (Linie 6), sodass die n√§chsten Eckpunktpaare den gr√∂√üten Einfluss haben.  Wenn Sie mit einem Scheitelpunktpaar arbeiten, weisen wir allen √ºbergeordneten Scheitelpunkten gleichzeitig eine Bewertung jedes Scheitelpunkts zu (Zeile 9, 10 und Algorithmus 4).  Eine Sch√§tzung eines nicht kommentierten Scheitelpunkts ist die absolute Differenz der Sch√§tzungen des entsprechenden Scheitelpunktpaars mit Summation √ºber alle Scheitelpunktpaare (Zeile 12). <br><br><h2>  Schnittstelle in nat√ºrlicher Sprache </h2><br>  Um den vorgeschlagenen Rahmen zu bewerten, m√ºssen die NL2API-Modelle anhand der gesammelten Daten trainiert werden.  Derzeit ist das fertige NL2API-Modell nicht verf√ºgbar. Wir passen jedoch zwei getestete NLI-Modelle aus anderen Bereichen an, um sie auf die API anzuwenden. <br><br><h4>  Sprachmodell-Extraktionsmodell </h4><br>  Basierend auf den j√ºngsten Entwicklungen auf dem Gebiet des NLI f√ºr Wissensdatenbanken k√∂nnen wir die Schaffung von NL2API im Kontext des Problems der Informationsextraktion in Betracht ziehen, um das auf dem Sprachmodell (LM) basierende Extraktionsmodell an unsere Bedingungen anzupassen. <br><br>  Um u zu sagen, m√ºssen Sie einen API z-Aufruf im semantischen Netzwerk finden, der am besten zu u passt.  Zuerst transformieren wir die Verteilung von BoB <img src="https://habrastorage.org/webt/rq/qs/9-/rqqs9-qn12-qsdd7mahxx5tg-si.png">  jeder Aufruf der API z an das Sprach-Unigramm-Modell: <br><br><img src="https://habrastorage.org/webt/lr/4f/pt/lr4fptel7voyxz2pelzjinbyu14.png"><br><br>  wo wir additive Gl√§ttung verwenden und 0 ‚â§ Œ≤ ‚â§ 1 der Gl√§ttungsparameter ist.  H√∂herer Wert <img src="https://habrastorage.org/webt/rh/1e/wc/rh1ewczas_fvleaxd5za0qvury0.png">  Je gr√∂√üer das Gewicht der W√∂rter ist, die noch nicht analysiert wurden.  API-Aufrufe k√∂nnen nach ihrer logarithmischen Wahrscheinlichkeit eingestuft werden: <br><br><img src="https://habrastorage.org/webt/3c/sf/fu/3csffus3jr7h6kpxq6czdyvhdtm.png"><br><br>  (vorbehaltlich einer einheitlichen a priori Wahrscheinlichkeitsverteilung) <br><br><img src="https://habrastorage.org/webt/0s/xu/y-/0sxuy-xon3k12zlsbn2f41wzyco.png"><br><br>  Der API-Aufruf mit der h√∂chsten Bewertung wird als Simulationsergebnis verwendet. <br><br><h4>  Seq2Seq-Umformulierungsmodul </h4><br>  Neuronale Netze werden als Modelle f√ºr NLI immer weiter verbreitet, w√§hrend das Seq2Seq-Modell f√ºr diesen Zweck besser ist als die anderen, da Sie auf nat√ºrliche Weise Eingabe- und Ausgabesequenzen variabler L√§nge verarbeiten k√∂nnen.  Wir passen dieses Modell f√ºr NL2API an. <br><br>  F√ºr die Eingabesequenz e <img src="https://habrastorage.org/webt/sl/zv/2w/slzv2wvhssrsrt-2cehxkcosmr0.png">  Das Modell sch√§tzt die bedingte Wahrscheinlichkeitsverteilung p (y | x) f√ºr alle m√∂glichen Ausgabesequenzen <img src="https://habrastorage.org/webt/zz/ar/74/zzar74ttz1utynmp2qpkuprrhwc.png">  .  Die L√§ngen T und T 'k√∂nnen variieren und einen beliebigen Wert annehmen.  In NL2API ist x die Ausgabeanweisung.  y kann ein serialisierter API-Aufruf oder sein kanonischer Befehl sein.  Wir werden kanonische Befehle als Zielausgabesequenzen verwenden, was unser Problem tats√§chlich in ein Umformulierungsproblem verwandelt. <br><br>  Ein Encoder, der als wiederkehrendes neuronales Netzwerk (RNN) mit gesteuerten Wiederholungseinheiten (GRU) implementiert ist, repr√§sentiert zuerst x als einen Vektor fester Gr√∂√üe. <br><br><img src="https://habrastorage.org/webt/_l/vv/ht/_lvvhtq3g73uajiwibi7r5xzspc.png"><br><br>  Dabei ist RN N eine kurze Darstellung zum Anwenden von GRU auf die gesamte Eingabesequenz, Marker f√ºr Marker, gefolgt von der Ausgabe des letzten verborgenen Zustands. <br><br>  Der Decodierer, der auch ein RNN mit GRU ist, nimmt h0 als Anfangszustand und verarbeitet die Ausgangssequenz y Marker f√ºr Marker, um eine Sequenz von Zust√§nden zu erzeugen. <br><br><img src="https://habrastorage.org/webt/eo/lg/9l/eolg9ljwlyskjfurunypvlmswaa.png"><br><br>  Die Ausgabeschicht nimmt jeden Decoderzustand als Eingabewert und generiert eine W√∂rterbuchverteilung <img src="https://habrastorage.org/webt/a-/v8/rh/a-v8rh1ddeh_ai-eawq8udhqe80.png">  als Ausgabewert.  Wir verwenden nur die affine Transformation, gefolgt von der Multi-Variablen-Logistikfunktion softmax: <br><br><img src="https://habrastorage.org/webt/qr/ty/c9/qrtyc9lsayvqiczswbr-837_pba.png"><br><br>  Die endg√ºltige bedingte Wahrscheinlichkeit, mit der wir bewerten k√∂nnen, wie gut der kanonische Befehl y die Eingabeanweisung x umformuliert, ist <img src="https://habrastorage.org/webt/l5/yt/wn/l5ytwnga_iegxtspqogvabwe5g0.png"><img src="https://habrastorage.org/webt/ul/7k/ny/ul7knyk1imjwc0p_hrjisfmy8-e.png">  .  API-Aufrufe werden dann nach der bedingten Wahrscheinlichkeit ihres kanonischen Befehls eingestuft.  Wir empfehlen Ihnen, sich mit der Quelle vertraut zu machen, in der der Modelllernprozess ausf√ºhrlicher beschrieben wird. <br><br><h2>  Experimente </h2><br>  Experimentell untersuchen wir die folgenden Forschungsthemen: [PI1]: K√∂nnen wir den vorgeschlagenen Rahmen verwenden, um qualitativ hochwertige Trainingsdaten zu einem angemessenen Preis zu sammeln?  [PI2]: Bietet das semantische Netzwerk eine genauere Bewertung von Sprachmodellen als die Bewertung der maximalen Wahrscheinlichkeit?  [PI3]: Verbessert eine differenzierte Vertriebsstrategie die Crowdsourcing-Effizienz? <br><br><h4>  Crowdsourcing </h4><br>       -API  Microsoft ‚Äî GET-Events  GET-Messages ‚Äî              .       API,    API ( 3.1)      .   API    2.      ,  Amazon Mechanical Turk.    ,     API    . <br><br>             .   API  10 ,       10 .    201 ,        .          44 ,     82       ,    8,2 , ,   ,  .    ,    400    ,     17,4 %. <br><br>         (,     ORDERBY  a COUNT parameter)     (,    ,        ).       .            NLI.  ,  ,    [1] .           . <br><br>  ,      ,         ,   ,  API    (. 3).   API       .        ,    .     61  API  157   GET-Messages,   77  API  190   GET-Events.        ,  ,    API (,    )     , ,     . <br><br><img src="https://habrastorage.org/webt/dc/yk/nv/dcyknvmod2su0cutkru02tpklti.png"><br> <i> 2.   API.</i> <br><br><img src="https://habrastorage.org/webt/x9/dm/_b/x9dm_bbbgyua7xe0cl1fzjloc5o.png"><br> <i> 3.   :  ().</i> <br><br><h4>   </h4><br>       ,     ,      .    ,   Œ± = 0,3,    LM Œ≤ = 0,001.    K,    ,  100 000.    , ,      Seq2Seq ‚Äî 500.           (  ). <br><br>                  NLI,     .          . <br><br><h4>    </h4><br>  .         ,  ,            .         LM:   ,   .     ,     . ROOT ‚Äî   . TOP2 = ROOT +    2;  TOP3 = TOP2 +    3.            . <br><br>     4.      LM      (MLE)    ,     <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">    ,      . ,    ,      ,  MLE       . <br><br>    MLE,      <img src="https://habrastorage.org/webt/rz/hi/nv/rzhinvau9uyozj1iphz8idarw9m.png">   ,  <img src="https://habrastorage.org/webt/1d/h2/o8/1dh2o8om1hinyzi3r41ipp4pd3e.png"> -    ,    .     API    .    16   API (ROOT)   LM  SeMesh        Seq2Seq       API (TOP2)    ,   500   API (TOP3). <br><br>    ,   ,     ,  ,     ( 3.2)   .  ,    GET-Events    ,   GET-Messages.   ,  GET-Events  <br>  ,    ,        ,         . <br><br><img src="https://habrastorage.org/webt/pb/ym/e4/pbyme4xdpxcqabwlawu_bmkefkg.png"><br> <i> 4.    .        LM,       Seq2Seq,      .  ,        .</i> <br><br>  LM +  ,      ,       <img src="https://habrastorage.org/webt/1d/h2/o8/1dh2o8om1hinyzi3r41ipp4pd3e.png">     Œ∏em with <img src="https://habrastorage.org/webt/rz/hi/nv/rzhinvau9uyozj1iphz8idarw9m.png">  .    <img src="https://habrastorage.org/webt/1d/h2/o8/1dh2o8om1hinyzi3r41ipp4pd3e.png">  und <img src="https://habrastorage.org/webt/rz/hi/nv/rzhinvau9uyozj1iphz8idarw9m.png"> ,    ,    ROOT,          <img src="https://habrastorage.org/webt/1d/h2/o8/1dh2o8om1hinyzi3r41ipp4pd3e.png">  und <img src="https://habrastorage.org/webt/rz/hi/nv/rzhinvau9uyozj1iphz8idarw9m.png">  .    ,        ,    .             MLE.  ,  ,    [2] . <br><br>        0,45  0,6:    ,           NLI   .    ,            API.        API (.   7)     ,    RNN   ,     .       . <br><br>  .        :   |u |    Œ±.   -     LM ( 7).    ,  |u | &lt; 10,         10  .     GET-Events,  GET-Messages  . <br><br> ,         ,   ,    . ,    ,    .   ,       Œ±,        ([0.1, 0.7]).   Œ±      ,   ,      . <br><br><h4>   </h4><br>            (DP)   .       API  .       50  API,    ,    NL2API      . <br><br> ,     .     LM,      .             .           ,       ( 5.1),          API   . <br><br><img src="https://habrastorage.org/webt/lg/xz/z9/lgxzz9zznpwnk0c4vdqfnfaurrg.png"><br>  7.  . <br><br><img src="https://habrastorage.org/webt/ak/5p/da/ak5pda8vlogeadhfjphy-t33dcg.png"><br>  8.    . : GET-Events. : GET-Messages <br><br>       breadth first (BF),          .    .     .  API    ,       API  . <br><br>      8.    NL2API   API  DP      .     300    API,    Seq2Seq, DP      7 %   API.       ,  .  ,  DP    API,      NL2API.  ,  ,    [3] . <br><br><h2>    </h2><br> - .   -  (NLI)     .  NLI    . ,   ,       .                . <br><br>      NLI    ,    -,    API   .  NL2API     :      API ,   - ,   .      .      API    REST           . <br><br> <b>    NLI.</b>        NLI    ¬´  ¬ª. ,         Google Suggest API,        API   IFTTT.         NLI,       .        ,   . <br><br>          NLI,                  .        NLI   ,          .           ,           ,        . <br><br>                  API  .         ,          -API.                  . <br><br> <b>   -API.</b>     ,   -API. ,   -API      API,         -API   .  NL2API     , ,          API. <br><br><h2>      </h2><br>     -   -API (NL2API)       NL2API  .                NL2API   .       : (1)  .            , , ? (2)  . <br><br>      ? (3)  NL2API. ,               API. (4)  API.         API? (5)    :    NL2API        ? </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de418559/">https://habr.com/ru/post/de418559/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de418547/index.html">Asynchrone Programmierung mit Beispielen: Rekonstruktion der Methoden java.util.concurrent.CompletableFuture</a></li>
<li><a href="../de418549/index.html">Erstellen eines Bots zur Teilnahme am AI Mini Cup 2018 basierend auf einem wiederkehrenden neuronalen Netzwerk (Teil 3)</a></li>
<li><a href="../de418551/index.html">Wie viel sollte ein Programmierer in Mathe wissen?</a></li>
<li><a href="../de418553/index.html">Kotlin + Reagieren gegen Javasript + Reagieren</a></li>
<li><a href="../de418557/index.html">Berechnung von Wellenprozessen in einer Hydraulikleitung nach der Methode der Eigenschaften</a></li>
<li><a href="../de418561/index.html">Zustandsautomaten im Dienst von MVP. Yandex Vortrag</a></li>
<li><a href="../de418563/index.html">Die Zusammenfassung interessanter Materialien f√ºr den mobilen Entwickler # 263 (23. Juli - 29. Juli)</a></li>
<li><a href="../de418565/index.html">Auf dem Weg zu einer 100% igen Codeabdeckung mit Tests in Go am Beispiel von SQL-Dumper</a></li>
<li><a href="../de418567/index.html">Dell wird aufh√∂ren, ein privates Unternehmen zu sein, und zum ersten Mal seit 5 Jahren Aktien an die B√∂rse bringen</a></li>
<li><a href="../de418569/index.html">Neue Satelliten - neue Fehler: Der Satelliten-Infrarotsensor GOES-17 k√ºhlt nicht gut ab</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
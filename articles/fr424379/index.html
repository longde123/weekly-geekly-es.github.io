<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö± üçª üõÅ Reconnaissance des √©colabels √† l'aide d'Azure Custom Vision √† partir d'une application mobile üé∑ ‚úåüèª üöΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans cet article, je veux parler de l'utilisation du service Custom Vision pour reconna√Ætre les photos d'√©tiquettes √©cologiques √† partir d'une applica...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Reconnaissance des √©colabels √† l'aide d'Azure Custom Vision √† partir d'une application mobile</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/424379/"><p>  Dans cet article, je veux parler de l'utilisation du service Custom Vision pour reconna√Ætre les photos d'√©tiquettes √©cologiques √† partir d'une application mobile. </p><br><p>  CustomVision fait partie des services cognitifs bas√©s sur le cloud d'Azure. <br>  √Ä propos des technologies qui devaient √™tre √©tudi√©es, comment travailler avec CustomVision, ce qu'elle est et ce qu'elle permet d'atteindre - plus loin. </p><br><p><img src="https://habrastorage.org/webt/bc/7h/ox/bc7hoxzxf64einuj6yh30ftnuk8.png"></p><a name="habracut"></a><br><p>  La reconnaissance des √©colabels est apparue il y a trois ans lorsque ma femme et moi avons commenc√© √† discuter d'une application mobile que son organisation (une ONG dans le domaine de l'√©cologie) souhaitait r√©aliser pour diffuser des informations sur les √©colabels. </p><br><h3 id="chto-takoe-ekomarkirovka">  Qu'est-ce que l'√©co-√©tiquetage? </h3><br><p>  L'√©co-√©tiquetage est un certificat et un logo correspondant √©mis par des organismes de certification qui v√©rifient la conformit√© des produits ou services du fabricant-fournisseur avec certains crit√®res li√©s au cycle de vie du produit-service et ax√©s sur son respect de l'environnement.  Apr√®s la certification, le fabricant peut apposer le label √©cologique sur ses produits. </p><br><p>  En outre, l'√©co-√©tiquetage peut √™tre attribu√© au marquage plastique par sa composition pour simplifier le dimensionnement et le traitement et d'autres signes similaires. </p><br><p>  Par exemple, voici un signe: </p><br><p><img src="https://habrastorage.org/webt/_q/b6/od/_qb6odkao8hmg469ujzuqsjyjoc.png"></p><br><h3 id="process-vybora-tehnologii-raspoznavaniya">  Processus de s√©lection des technologies de reconnaissance </h3><br><p>  Les deux principales caract√©ristiques de l'application √©taient de rechercher des magasins avec des produits respectueux de l'environnement et de reconna√Ætre les √©colabels.  Si technologiquement tout est relativement simple avec la recherche de magasins, alors avec la reconnaissance ce n'est pas tr√®s simple.  Le mot est √† la mode, mais comment le rendre n'√©tait pas clair.  Et j'ai commenc√© √† √©tudier la question. </p><br><p>  Les logos de marquage sont normalis√©s et sont des objets id√©aux pour la reconnaissance - il a point√© le t√©l√©phone vers l'image sur l'emballage des marchandises, a pris une photo et l'application indique quel type de signe cela signifie et s'il faut lui faire confiance. </p><br><p>  J'ai commenc√© √† r√©fl√©chir √† la fa√ßon de faire la reconnaissance et d'analyser diff√©rentes options - j'ai essay√© OpenCV avec ses algorithmes de reconnaissance (cascades Haar, SWIFT, correspondance de mod√®les, etc.) mais la qualit√© de la reconnaissance n'√©tait pas tr√®s bonne - pas plus de 70% avec un ensemble de formation de plusieurs dizaines d'images . </p><br><p>  Quelque part, j'ai peut-√™tre mal compris quelque chose et fait quelque chose de mal, mais nous avons √©galement demand√© √† un autre ami d'enqu√™ter sur ce sujet et il a √©galement d√©clar√© que 70% des cascades de Haar √©taient le maximum sur un tel ensemble de donn√©es. </p><br><p>  Parall√®lement √† cela, des documents sur divers cadres de r√©seaux de neurones et l'utilisation r√©ussie de r√©seaux de neurones pour r√©soudre de tels probl√®mes ont commenc√© √† appara√Ætre de plus en plus souvent.  Mais partout, des tailles terrifiantes de jeux de donn√©es ont flash√© (des centaines ou des milliers d'images pour chaque classe), qui ne me sont pas familiers avec Python, TensorFlow, la n√©cessit√© de mon backend - tout cela √©tait un peu effrayant. </p><br><p>  En tant que d√©veloppeur .NET, j'ai regard√© Accord.NET mais je n'ai pas non plus trouv√© rapidement quelque chose qui conviendrait tout de suite. </p><br><p>  A cette √©poque, nous √©tions occup√©s √† finaliser la demande et √† la lancer dans le prod, et j'ai report√© la proc√©dure avec reconnaissance. </p><br><p>  Il y a environ un an, je suis tomb√© sur un article d√©crivant l'aper√ßu pr√©coce de Microsoft Custom Vision, un service de classification d'images cloud.  Je l'ai test√© sur 3 caract√®res et je l'ai aim√© - un portail compr√©hensible o√π vous pouvez former et tester le classificateur sans connaissances techniques, former un ensemble de 100 images en 10-20 secondes, la qualit√© de la classification est sup√©rieure √† 90% m√™me sur 30 images de chaque personnage - ce qui est n√©cessaire. </p><br><p>  J'ai partag√© la d√©couverte avec ma femme et nous avons commenc√© √† cr√©er une version internationale moins fonctionnelle de l'application, qui ne contient pas d'informations sur les produits et les magasins, mais qui est capable de reconna√Ætre les √©colabels. </p><br><p>  Passons aux d√©tails techniques d'une application de reconnaissance en cours d'ex√©cution. </p><br><h3 id="custom-vision">  Vision personnalis√©e </h3><br><p>  CV fait partie des services cognitifs dans Azure.  Maintenant, il peut √™tre officiellement publi√© et il paiera avec un abonnement Azure, bien qu'il soit toujours r√©pertori√© dans Aper√ßu. </p><br><p>  En cons√©quence, comme tout autre produit Azure, CognitiveServices sont affich√©s et g√©r√©s sur le portail Azure. </p><br><p>  CV fournit deux API REST, une pour la formation et une pour la pr√©diction.  Je d√©crirai plus en d√©tail l'interaction avec Prediction </p><br><p>  En plus du portail Azure et de l'API, les utilisateurs de CV ont acc√®s au portail customvision.ai, o√π il est tr√®s facile et clair de t√©l√©charger des images, de placer des marques dessus, vous pouvez voir des images et des r√©sultats de reconnaissance qui sont pass√©s par l'API. </p><br><p>  Le portail et l'API customvision.ai peuvent √™tre d√©marr√©s pour √™tre utilis√©s sans aucune liaison avec Azure - √† des fins de test, un projet est cr√©√© m√™me sans abonnement Azure.  Mais si vous souhaitez cr√©er un projet de production √† partir de votre projet de test √† l'avenir, il est pr√©f√©rable de le faire imm√©diatement, sinon nous devions copier manuellement les images du projet de test et le re-marquer en production. </p><br><p>  Pour cr√©er un projet dans Azure, vous devez vous y inscrire et cr√©er un abonnement.  C'est relativement facile, les probl√®mes ne peuvent √™tre que lors de la saisie et de la validation des donn√©es d'une carte de cr√©dit - cela arrive parfois. </p><br><p>  Apr√®s l'enregistrement, vous devez cr√©er une instance ComputerVision via le portail Azure </p><br><p><img src="https://habrastorage.org/webt/jk/cf/vv/jkcfvvmhkp80zpptg1lpfinwxzi.png"></p><br><p>  Apr√®s avoir cr√©√© des ressources dans Azure, elles seront disponibles dans customvision.ai </p><br><p>  Sur le portail customvision.ai, vous pouvez t√©l√©charger des images et les √©tiqueter - il peut y avoir plusieurs balises sur une m√™me image, mais sans mettre en √©vidence les zones.  Autrement dit, l'image appartient √† plusieurs classes, mais √† ce stade du d√©veloppement du service, il est impossible de s√©lectionner un fragment sp√©cifique dans l'image et de l'attribuer √† la classe. </p><br><p>  Apr√®s le marquage, vous devez commencer la formation en appuyant sur le bouton Train - la formation d'un mod√®le de 70 balises et de 3 000 images dure environ 30 secondes. </p><br><p>  Les r√©sultats de la formation sont stock√©s dans l'entit√© It√©ration.  En fait, Iteration impl√©mente la gestion des versions. </p><br><p>  Chaque it√©ration peut √™tre utilis√©e ind√©pendamment - c'est-√†-dire que vous pouvez cr√©er une it√©ration, tester le r√©sultat et le supprimer s'il ne correspond pas ou ne se traduit pas par d√©faut et remplacer l'it√©ration par d√©faut actuelle, puis toute la reconnaissance des applications viendra au mod√®le √† partir de cette it√©ration. </p><br><p>  La qualit√© du mod√®le est affich√©e sous forme de pr√©cision et de rappel (plus de d√©tails <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ) √† la fois pour toutes les classes √† la fois et s√©par√©ment. </p><br><p><img src="https://habrastorage.org/webt/j-/es/_m/j-es_mwi8onzwum9uc2a9k2p4y0.png"></p><br><p>  Voici √† quoi ressemble un projet avec des images d√©j√† t√©l√©charg√©es et pass√©es par la formation. </p><br><p><img src="https://habrastorage.org/webt/os/iq/pi/osiqpinmfbcxb8-zp8bunbr7lni.png"></p><br><p>  Sur le portail, vous pouvez ex√©cuter la reconnaissance d'image √† partir d'un disque ou d'une URL √† l'aide du test rapide et tester la reconnaissance par une seule image. </p><br><p>  Sur l'onglet Pr√©dictions, vous pouvez voir les r√©sultats de toutes les derni√®res reconnaissances - les pourcentages de marquage sont affich√©s directement dans l'image. </p><br><p><img src="https://habrastorage.org/webt/zy/-f/-k/zy-f-kqcj7v4npxr4adnakn0724.png"></p><br><p>  La possibilit√© de voir tous les r√©sultats de la reconnaissance et de les ajouter √† l'ensemble de formation en quelques clics de souris aide vraiment - tout le monde peut le faire sans aucune connaissance de l'IA ou de la programmation. </p><br><h3 id="ispolzovanie-api">  Utilisation de l'API </h3><br><p>  Custom Vision Service dispose d'une API REST tr√®s simple et intuitive pour la formation et la reconnaissance. </p><br><p>  Notre application utilise uniquement l'API de reconnaissance et je parlerai de son utilisation </p><br><p>  URL pour une reconnaissance de ce type: </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://southcentralus.api.cognitive.microsoft.com/customvision/v2.0/Prediction/{Your</a> GUID de votre projet} / image </p><br><p>  o√π <br>  <strong>southcentralus **</strong> - le nom de la r√©gion Azure o√π se trouve le service.  Jusqu'√† pr√©sent, le service n'est disponible que dans la r√©gion centre-sud des √âtats-Unis.  Cela ne signifie pas que vous pouvez l'utiliser uniquement l√†-bas!  Il vit l√†-bas - vous pouvez l'utiliser partout o√π il y a Internet. <br>  <strong>{GUID de votre projet} **</strong> - identifiant de votre projet.  Vous pouvez le voir sur le portail customvision.ai </p><br><p>  Pour la reconnaissance, il est n√©cessaire d'envoyer l'image via POST.  Vous pouvez √©galement envoyer une URL d'image accessible au public et le service la t√©l√©chargera vous-m√™me. </p><br><p>  De plus, vous devez ajouter l'en-t√™te ¬´Prediction-Key¬ª aux en-t√™tes vers lesquels vous pouvez transf√©rer l'une des cl√©s d'acc√®s qui seront √©mises lors de l'inscription - elles sont disponibles √† la fois sur le portail customvision.ai et sur le portail Azure. </p><br><p>  Le r√©sultat contient le champ suivant: </p><br><pre><code class="hljs powershell"><span class="hljs-string"><span class="hljs-string">"Predictions"</span></span>:[ {<span class="hljs-string"><span class="hljs-string">"TagId"</span></span>:<span class="hljs-string"><span class="hljs-string">"35ac2ad0-e3ef-4e60-b81f-052a1057a1ca"</span></span>,<span class="hljs-string"><span class="hljs-string">"Tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"dog"</span></span>,<span class="hljs-string"><span class="hljs-string">"Probability"</span></span>:<span class="hljs-number"><span class="hljs-number">0.102716163</span></span>}, {<span class="hljs-string"><span class="hljs-string">"TagId"</span></span>:<span class="hljs-string"><span class="hljs-string">"28e1a872-3776-434c-8cf0-b612dd1a953c"</span></span>,<span class="hljs-string"><span class="hljs-string">"Tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"cat"</span></span>,<span class="hljs-string"><span class="hljs-string">"Probability"</span></span>:<span class="hljs-number"><span class="hljs-number">0.02037274</span></span>} ]</code> </pre> <br><p>  O√π Probabilit√© indique la probabilit√© que l'image appartient √† la balise sp√©cifi√©e (classe). </p><br><p>  En C #, √ßa ressemble √† √ßa </p><br><pre> <code class="cs hljs"> <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> client = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> HttpClient(); client.DefaultRequestHeaders.Add(<span class="hljs-string"><span class="hljs-string">"Prediction-Key"</span></span>, <span class="hljs-string"><span class="hljs-string">"{Acess key}"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> url = <span class="hljs-string"><span class="hljs-string">"https://southcentralus.api.cognitive.microsoft.com/customvision/v2.0/Prediction/{Your project GUID}/image"</span></span>; HttpResponseMessage response; List&lt;RecognitionResult&gt; recognitions = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> List&lt;RecognitionResult&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> content = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ByteArrayContent(imageBytes)) { content.Headers.ContentType = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> MediaTypeHeaderValue (<span class="hljs-string"><span class="hljs-string">"application/octet-stream"</span></span>); response = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> client.PostAsync(url, content); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (response.IsSuccessStatusCode) { <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> strRes = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> response.Content.ReadAsStringAsync(); <span class="hljs-keyword"><span class="hljs-keyword">dynamic</span></span> res = (<span class="hljs-keyword"><span class="hljs-keyword">dynamic</span></span>) JsonConvert.DeserializeObject(strRes); <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> pr <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> res.predictions) { recognitions.Add( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> RecognitionResult() { Tag = pr.tagName, RecognPercent = pr.probability }); } } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { Debug.WriteLine( <span class="hljs-string"><span class="hljs-string">"Non successful response. "</span></span> + response.ToString()); } }</code> </pre> <br><p>  Comme vous pouvez le voir - absolument rien de compliqu√©.  Toute la magie op√®re du c√¥t√© du service. </p><br><h3 id="prilozhenie-i-nekotorye-podobrannye-parametry">  L'application et certains param√®tres s√©lectionn√©s. </h3><br><p>  L'application est assez simple et se compose d'une liste d'√©colabels, d'informations sur ce que sont les √©colabels, comment ils sont subdivis√©s et le scanner lui-m√™me. </p><br><p>  La partie principale est √©crite dans Xamarin.Forms, mais la fen√™tre du scanner fonctionne avec la cam√©ra et cela devait √™tre fait en tant que rendus et impl√©ment√© pour chaque plate-forme s√©par√©ment </p><br><p>  Le niveau lorsque l'application d√©cide que l'√©colabel est reconnu exactement&gt; = 90%, tandis que presque toutes les images sont reconnues si elles sont plus ou moins de qualit√© acceptable et qu'il n'y a pas d'autres signes sur l'image. <br>  Ce nombre a √©t√© d√©riv√© empiriquement - nous avons commenc√© avec 80, mais nous avons r√©alis√© que 90 r√©duisaient les faux positifs.  Et il y en a beaucoup - de nombreux marquages ‚Äã‚Äãsont similaires et contiennent des √©l√©ments similaires et le jeu de couleurs passe au vert. </p><br><p>  Par exemple, ce n'est pas l'image de la plus haute qualit√© reconnue correctement avec une pr√©cision de 91% </p><br><p><img src="https://habrastorage.org/webt/uc/ru/cp/ucrucpzt4yiudf1ooaco4t7aska.jpeg"></p><br><p>  B en m√™me temps, cette classe a √©t√© form√©e sur 45 images. </p><br><p>  J'esp√®re que l'article a √©t√© utile et permettra aux lecteurs int√©ress√©s de jeter un ≈ìil aux nouveaux outils AI et ML. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr424379/">https://habr.com/ru/post/fr424379/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr424369/index.html">Mon fichier pr√©f√©r√© dans la base de code Chromium</a></li>
<li><a href="../fr424371/index.html">D√©ployer vCloud Extender</a></li>
<li><a href="../fr424373/index.html">O√π travailler en informatique, num√©ro 1: Voximplant</a></li>
<li><a href="../fr424375/index.html">Examen de la moulureuse sous vide Mayku FormBox: laissez les pi√®ces se propager</a></li>
<li><a href="../fr424377/index.html">Playme TIO Review: DVR √† montage magn√©tique haut de gamme</a></li>
<li><a href="../fr424381/index.html">H√©bergement de serveurs de jeux dans un centre de donn√©es professionnel</a></li>
<li><a href="../fr424383/index.html">Un guide complet pour bien utiliser l'animation dans UX</a></li>
<li><a href="../fr424385/index.html">DJI GO 4 Ultimate Guide: param√®tres de l'√©cran d'accueil et de l'appareil photo</a></li>
<li><a href="../fr424387/index.html">Nous vous invitons √† la r√©union GO.PITER</a></li>
<li><a href="../fr424389/index.html">Nouvelle science du regard au coin de la rue</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
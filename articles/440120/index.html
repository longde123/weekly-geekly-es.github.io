<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üñºÔ∏è üßòüèæ ‚õ¥Ô∏è Inteligencia artificial versus mentiras y enga√±os üëÇüèΩ üóùÔ∏è üò∫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En todas las tareas de ense√±anza de la inteligencia artificial, hay un fen√≥meno desagradable: los errores en el marcado de la secuencia de entrenamien...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Inteligencia artificial versus mentiras y enga√±os</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440120/">  En todas las tareas de ense√±anza de la inteligencia artificial, hay un fen√≥meno desagradable: los errores en el marcado de la secuencia de entrenamiento.  Estos errores son inevitables, ya que todo el marcado se realiza manualmente, porque si hay una manera de marcar datos reales mediante programaci√≥n, ¬øpor qu√© necesitamos a alguien m√°s que les ense√±e a marcar y gastar tiempo y dinero en crear un dise√±o absolutamente innecesario! <br><br>  La tarea de encontrar y eliminar m√°scaras falsas en una secuencia de entrenamiento grande es bastante complicada.  Puede verlos todos manualmente, pero esto no lo salvar√° de errores repetidos.  Pero si observa de cerca las herramientas para estudiar las redes neuronales propuestas en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">publicaciones anteriores</a> , resulta que hay una manera simple y efectiva de detectar y extraer todos los artefactos de la secuencia de entrenamiento. <br><br>  Y en esta publicaci√≥n hay un ejemplo concreto, es obvio que uno simple, en elipses y pol√≠gonos, para una red en U ordinaria, es nuevamente un lego en la caja de arena, pero es inusualmente concreto, √∫til y efectivo.  Mostraremos c√≥mo un m√©todo simple identifica y encuentra casi todos los artefactos, todas las mentiras de la secuencia de entrenamiento. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9r/r1/h7/9rr1h7wzzm_tnixujjpx1ow3rge.png" width="300"></div><br>  ¬°Entonces comencemos! <br><a name="habracut"></a><br>  Como antes, estudiaremos la secuencia de pares de im√°genes / m√°scaras.  En la imagen en diferentes trimestres, elegidos al azar, colocaremos una elipse de un tama√±o aleatorio y un cuadr√°ngulo de un tama√±o arbitrario, y ambos colores en el mismo color, tambi√©n seleccionados al azar de dos de ellos.  En el segundo color restante, coloreamos el fondo.  Las dimensiones de la elipse y el cuadr√°ngulo son, por supuesto, limitadas. <br><br>  Pero en este caso, haremos cambios en el programa de generaci√≥n de pares y prepararemos, junto con una m√°scara completamente correcta, una incorrecta, envenenada por una mentira: en aproximadamente el uno por ciento de los casos, reemplaza el cuadril√°tero con una elipse en la m√°scara, es decir.  El verdadero objeto para la segmentaci√≥n se denota con falsas m√°scaras como una elipse, no un cuadril√°tero. <br><br>  <b>Ejemplos aleatorios 10</b> <br><br><img src="https://habrastorage.org/webt/ff/7n/fo/ff7nfoxyodiogbucb6oqivjsm5e.png"><br><br>  <b>Ejemplos de 10 aleatorios, pero de marcado err√≥neo.</b>  <b>La m√°scara superior es verdadera, la inferior es falsa y los n√∫meros en la secuencia de entrenamiento se muestran en las im√°genes.</b> <br><br><img src="https://habrastorage.org/webt/sa/ww/wx/sawwwxtlmqvixgrab-sv3btbfdm.png"><br><br>  para la segmentaci√≥n, tomamos los mismos programas de c√°lculo de m√©trica y p√©rdida y la misma U-net simple, pero no usaremos Dropout. <br><br><div class="spoiler">  <b class="spoiler_title">Bibliotecas</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> matplotlib.colors <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> NoNorm %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-comment"><span class="hljs-comment">#from joblib import Parallel, delayed from skimage.draw import ellipse, polygon from keras import Model from keras.optimizers import Adam from keras.layers import Input,Conv2D,Conv2DTranspose,MaxPooling2D,concatenate from keras.layers import BatchNormalization,Activation,Add,Dropout from keras.losses import binary_crossentropy from keras import backend as K from keras.models import load_model import tensorflow as tf import keras as keras w_size = 128 train_num = 10000 radius_min = 10 radius_max = 30</span></span></code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Funciones m√©tricas y de p√©rdida</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_coef</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> y_true_f = K.flatten(y_true) y_pred = K.cast(y_pred, <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) y_pred_f = K.cast(K.greater(K.flatten(y_pred), <span class="hljs-number"><span class="hljs-number">0.5</span></span>), <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) intersection = y_true_f * y_pred_f score = <span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smooth = <span class="hljs-number"><span class="hljs-number">1.</span></span> y_true_f = K.flatten(y_true) y_pred_f = K.flatten(y_pred) intersection = y_true_f * y_pred_f score = (<span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bce_dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_iou_vector</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(A, B)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Numpy version batch_size = A.shape[0] metric = 0.0 for batch in range(batch_size): t, p = A[batch], B[batch] true = np.sum(t) pred = np.sum(p) # deal with empty mask first if true == 0: metric += (pred == 0) continue # non empty mask case. Union is never empty # hence it is safe to divide by its number of pixels intersection = np.sum(t * p) union = true + pred - intersection iou = intersection / union # iou metrric is a stepwise approximation of the real iou over 0.5 iou = np.floor(max(0, (iou - 0.45)*20)) / 10 metric += iou # teake the average over all images in batch metric /= batch_size return metric def my_iou_metric(label, pred): # Tensorflow version return tf.py_func(get_iou_vector, [label, pred &gt; 0.5], tf.float64) from keras.utils.generic_utils import get_custom_objects get_custom_objects().update({'bce_dice_loss': bce_dice_loss }) get_custom_objects().update({'dice_loss': dice_loss }) get_custom_objects().update({'dice_coef': dice_coef }) get_custom_objects().update({'my_iou_metric': my_iou_metric })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Red U normal</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(input_layer, start_neurons)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># 128 -&gt; 64 conv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(input_layer) conv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(conv1) pool1 = Conv2D(start_neurons * 1, (2, 2), strides=(2, 2), activation="relu", padding="same")(conv1) # pool1 = Dropout(0.25)(pool1) # 64 -&gt; 32 conv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(pool1) conv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(conv2) pool2 = Conv2D(start_neurons * 1, (2, 2), strides=(2, 2), activation="relu", padding="same")(conv2) # pool2 = Dropout(0.5)(pool2) # 32 -&gt; 16 conv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(pool2) conv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(conv3) pool3 = Conv2D(start_neurons * 1, (2, 2), strides=(2, 2), activation="relu", padding="same")(conv3) # pool3 = Dropout(0.5)(pool3) # 16 -&gt; 8 conv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(pool3) conv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(conv4) pool4 = Conv2D(start_neurons * 1, (2, 2), strides=(2, 2), activation="relu", padding="same")(conv4) # pool4 = Dropout(0.5)(pool4) # Middle convm = Conv2D(start_neurons * 16, (3, 3), activation="relu", padding="same")(pool4) convm = Conv2D(start_neurons * 16, (3, 3) , activation="relu", padding="same")(convm) # 8 -&gt; 16 deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding="same")(convm) uconv4 = concatenate([deconv4, conv4]) # uconv4 = Dropout(0.5)(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3) , activation="relu", padding="same")(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3) , activation="relu", padding="same")(uconv4) # 16 -&gt; 32 deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding="same")(uconv4) uconv3 = concatenate([deconv3, conv3]) # uconv3 = Dropout(0.5)(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3) , activation="relu", padding="same")(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3) , activation="relu", padding="same")(uconv3) # 32 -&gt; 64 deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding="same")(uconv3) uconv2 = concatenate([deconv2, conv2]) # uconv2 = Dropout(0.5)(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3) , activation="relu", padding="same")(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3) , activation="relu", padding="same")(uconv2) # 64 -&gt; 128 deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding="same")(uconv2) uconv1 = concatenate([deconv1, conv1]) # uconv1 = Dropout(0.5)(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3) , activation="relu", padding="same")(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3) , activation="relu", padding="same")(uconv1) # uncov1 = Dropout(0.5)(uconv1) output_layer = Conv2D(1, (1,1), padding="same", activation="sigmoid")(uconv1) return output_layer input_layer = Input((w_size, w_size, 1)) output_layer = build_model(input_layer, 27) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=1e-4), metrics=[my_iou_metric]) model.summary()</span></span></code> </pre> <br></div></div><br>  El programa para generar im√°genes y m√°scaras: verdadero y falso.  La primera capa de la imagen se coloca en la matriz, la segunda es la m√°scara verdadera y la tercera capa es la m√°scara falsa. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair_f</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(idx)</span></span></span><span class="hljs-function">:</span></span> img_l = np.ones((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>)*<span class="hljs-number"><span class="hljs-number">0.45</span></span> img_h = np.ones((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>)*<span class="hljs-number"><span class="hljs-number">0.55</span></span> img = np.zeros((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>) i0_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) i1_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> i0_qua == i1_qua: i1_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) _qua = np.int(w_size/<span class="hljs-number"><span class="hljs-number">4</span></span>) qua = np.array([[_qua,_qua],[_qua,_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>],[_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>,_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>],[_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>,_qua]]) p = np.random.sample() - <span class="hljs-number"><span class="hljs-number">0.5</span></span> r = qua[i0_qua,<span class="hljs-number"><span class="hljs-number">0</span></span>] c = qua[i0_qua,<span class="hljs-number"><span class="hljs-number">1</span></span>] r_radius = np.random.sample()*(radius_max-radius_min) + radius_min c_radius = np.random.sample()*(radius_max-radius_min) + radius_min rot = np.random.sample()*<span class="hljs-number"><span class="hljs-number">360</span></span> rr, cc = ellipse( r, c, r_radius, c_radius, rotation=np.deg2rad(rot), shape=img_l.shape ) p0 = np.rint(np.random.sample()*(radius_max-radius_min) + radius_min) p1 = qua[i1_qua,<span class="hljs-number"><span class="hljs-number">0</span></span>] - (radius_max-radius_min) p2 = qua[i1_qua,<span class="hljs-number"><span class="hljs-number">1</span></span>] - (radius_max-radius_min) p3 = np.rint(np.random.sample()*radius_min) p4 = np.rint(np.random.sample()*radius_min) p5 = np.rint(np.random.sample()*radius_min) p6 = np.rint(np.random.sample()*radius_min) p7 = np.rint(np.random.sample()*radius_min) p8 = np.rint(np.random.sample()*radius_min) poly = np.array(( (p1, p2), (p1+p3, p2+p4+p0), (p1+p5+p0, p2+p6+p0), (p1+p7+p0, p2+p8), (p1, p2), )) rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h[rr_p, cc_p] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l[rr_p, cc_p] img[:,:,<span class="hljs-number"><span class="hljs-number">1</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> img[:,:,<span class="hljs-number"><span class="hljs-number">1</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> img[rr_p, cc_p,<span class="hljs-number"><span class="hljs-number">1</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> img[:,:,<span class="hljs-number"><span class="hljs-number">2</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> p_f = np.random.sample()*<span class="hljs-number"><span class="hljs-number">1000.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p_f &gt; <span class="hljs-number"><span class="hljs-number">10</span></span>: img[rr_p, cc_p,<span class="hljs-number"><span class="hljs-number">2</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: img[rr, cc,<span class="hljs-number"><span class="hljs-number">2</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> i_false[idx] = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> img</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Programa de c√°lculo de hoja de trucos</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_sh</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(f_imgs, f_msks, val_len)</span></span></span><span class="hljs-function">:</span></span> precision = <span class="hljs-number"><span class="hljs-number">0.85</span></span> batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> t = tqdm() t_batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> raw_len = val_len id_train = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-comment"><span class="hljs-comment">#id_select = 1 v_false = np.zeros((train_num), dtype='float') while True: if id_train == 1: fit = model.fit(f_imgs[m2_select&gt;0], f_msks[m2_select&gt;0], batch_size=batch_size, epochs=1, verbose=0 ) current_accu = fit.history['my_iou_metric'][0] current_loss = fit.history['loss'][0] if current_accu &gt; precision: id_train = 0 else: t_pred = model.predict( f_imgs[raw_len: min(raw_len+t_batch_size,f_imgs.shape[0])], batch_size=batch_size ) for kk in range(t_pred.shape[0]): val_iou = get_iou_vector( f_msks[raw_len+kk].reshape(1,w_size,w_size,1), t_pred[kk].reshape(1,w_size,w_size,1) &gt; 0.5) v_false[raw_len+kk] = val_iou if val_iou &lt; precision*0.95: new_img_test = 1 m2_select[raw_len+kk] = 1 val_len += 1 break raw_len += (kk+1) id_train = 1 t.set_description("Accuracy {0:6.4f} loss {1:6.4f} selected img {2:5d} tested img {3:5d} ". format(current_accu, current_loss, val_len, raw_len)) t.update(1) if raw_len &gt;= train_num: break t.close() return v_false</span></span></code> </pre><br></div></div><br>  El principal programa de c√°lculos.  Hicimos peque√±os cambios en el mismo programa de la publicaci√≥n anterior y algunas variables requieren explicaci√≥n y comentarios. <br><br><pre> <code class="python hljs">i_false = np.zeros((train_num), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>)</code> </pre> <br>  Hay una m√°scara de falso indicador.  Si es 1, la m√°scara de F_msks no coincide con la m√°scara de f_msks.  Este es un indicador de lo que realmente estamos buscando: m√°scaras falsas. <br><br><pre> <code class="python hljs">m2_select = np.zeros((train_num), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>)</code> </pre> <br>  Indicador de que esta imagen est√° seleccionada en la hoja de trucos. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> val_len = batch_size + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-comment"><span class="hljs-comment"># i_false - false mask marked as 1 i_false = np.zeros((train_num), dtype='int') # t_imgs, t_msks -test images and masks _txy = [next_pair_f(idx) for idx in range(train_num)] t_imgs = np.array(_txy)[:,:,:,:1].reshape(-1,w_size ,w_size ,1) t_msks = np.array(_txy)[:,:,:,1].reshape(-1,w_size ,w_size ,1) # m2_select - initial 51 pair m2_select = np.zeros((train_num), dtype='int') for k in range(val_len): m2_select[k] = 1 # i_false - false mask marked as 1 i_false = np.zeros((train_num), dtype='int') _txy = [next_pair_f(idx) for idx in range(train_num)] f_imgs = np.array(_txy)[:,:,:,:1].reshape(-1,w_size ,w_size ,1) f_msks = np.array(_txy)[:,:,:,1].reshape(-1,w_size ,w_size ,1) # F_msks - mask array with ~1% false mask F_msks = np.array(_txy)[:,:,:,2].reshape(-1,w_size ,w_size ,1) fig, axes = plt.subplots(2, 10, figsize=(20, 5)) for k in range(10): kk = np.random.randint(train_num) axes[0,k].set_axis_off() axes[0,k].imshow(f_imgs[kk].squeeze(), cmap="gray", norm=NoNorm()) axes[1,k].set_axis_off() axes[1,k].imshow(f_msks[kk].squeeze(), cmap="gray", norm=NoNorm()) plt.show(block=True) false_num = np.arange(train_num)[i_false&gt;0] fig, axes = plt.subplots(3, 10, figsize=(20, 7)) for k in range(10): kk = np.random.randint(false_num.shape[0]) axes[0,k].set_axis_off() axes[0,k].set_title(false_num[kk]) axes[0,k].imshow(f_imgs[false_num[kk]].squeeze(), cmap="gray", norm=NoNorm()) axes[1,k].set_axis_off() axes[1,k].imshow(f_msks[false_num[kk]].squeeze(), cmap="gray", norm=NoNorm()) axes[2,k].set_axis_off() axes[2,k].imshow(F_msks[false_num[kk]].squeeze(), cmap="gray", norm=NoNorm()) plt.show(block=True)</span></span></code> </pre><br>  Construimos secuencias de pares de im√°genes / m√°scaras para entrenamiento y otra secuencia para pruebas.  Es decir  Verificaremos una nueva secuencia independiente de 10,000 pares.  Mostramos y verificamos visualmente selectivamente im√°genes aleatorias con m√°scaras verdaderas y falsas.  Se muestran las im√°genes de arriba. <br><br>  En este caso particular, se obtuvieron 93 m√°scaras falsas, en las que una elipse, en lugar de un cuadril√°tero, se marc√≥ como verdadero positivo. <br><br>  Comenzamos a entrenar en el conjunto correcto, usamos f_msks como m√°scara <br><br><pre> <code class="python hljs">input_layer = Input((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>)) output_layer = build_model(input_layer, <span class="hljs-number"><span class="hljs-number">25</span></span>) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>), metrics=[my_iou_metric]) v_false = make_sh(f_imgs, f_msks, val_len) t_pred = model.predict(t_imgs,batch_size=batch_size) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (get_iou_vector(t_msks,t_pred.reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>)))</code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9807 loss 0.0092 selected img 404 tested img 10000 : : 1801it [08:13, 3.65it/s] 0.9895299999999841</code> </pre> <br>  La hoja de trucos result√≥ en solo 404 im√°genes y obtuvo una precisi√≥n aceptable en una secuencia de prueba independiente. <br><br>  Ahora recompilamos la red y entrenamos en la misma secuencia de entrenamiento, pero como m√°scaras alimentamos F_msks con 1% de m√°scaras falsas a la entrada <br><br><pre> <code class="python hljs">input_layer = Input((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>)) output_layer = build_model(input_layer, <span class="hljs-number"><span class="hljs-number">25</span></span>) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>), metrics=[my_iou_metric]) v_false = make_sh(f_imgs, F_msks, val_len) t_pred = model.predict(t_imgs,batch_size=batch_size) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (get_iou_vector(t_msks,t_pred.reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>)))</code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9821 loss 0.0324 selected img 727 tested img 10000 : : 1679it [25:44, 1.09it/s] 0.9524099999999959</code> </pre> <br>  Obtuvimos una hoja de trucos de 727 im√°genes, que es significativamente mayor y la precisi√≥n de las predicciones de prueba, la misma que en la secuencia de prueba anterior, disminuy√≥ de 0.98953 a 0.9525.  Agregamos mentiras a la secuencia de entrenamiento en menos del 1%, solo 93 de cada 10,000 m√°scaras eran falsas, pero el resultado empeor√≥ en un 3.7%.  Y esto no es solo una mentira, ¬°es una verdadera astucia!  Y la hoja de trucos aument√≥ de solo 404 a ya 727 im√°genes. <br><br>  Calmante y agradable solo una cosa <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (len(set(np.arange(train_num)[m2_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>]).intersection(set(np.arange(train_num)[i_false&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>])))) <span class="hljs-number"><span class="hljs-number">93</span></span></code> </pre> <br>  Perm√≠tanme explicar esta larga f√≥rmula, tomamos la intersecci√≥n del conjunto de im√°genes seleccionadas en la hoja de trucos con el conjunto de im√°genes falsas y vemos que el algoritmo seleccion√≥ las 93 im√°genes falsas en la hoja de trucos. <br><br>  La tarea se simplifica significativamente, no son 10.000 im√°genes para mirar manualmente, solo son 727 y todas las mentiras se concentran aqu√≠. <br><br>  Pero hay una forma a√∫n m√°s interesante y √∫til.  Cuando elaboramos la hoja de trucos, incluimos solo aquellos pares de imagen / m√°scara cuya predicci√≥n es menor que el umbral, y en nuestro caso particular, guardamos el valor de la precisi√≥n de la predicci√≥n en la matriz <b>v_false</b> .  Veamos pares de la secuencia de entrenamiento que tienen un valor de predicci√≥n muy peque√±o, por ejemplo, menos de 0.1 y veamos cu√°ntas mentiras hay <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (len(set(np.arange(train_num)[v_false&lt;<span class="hljs-number"><span class="hljs-number">0.01</span></span>]).intersection(set(np.arange(train_num)[i_false&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>])))) <span class="hljs-number"><span class="hljs-number">89</span></span></code> </pre> <br><br>  Como puede ver, la parte principal de las m√°scaras falsas, 89 de 93, cay√≥ en estas m√°scaras. <br><pre> <code class="python hljs">np.arange(train_num)[v_false&lt;<span class="hljs-number"><span class="hljs-number">0.01</span></span>].shape (<span class="hljs-number"><span class="hljs-number">382</span></span>,)</code> </pre> <br>  Por lo tanto, si verificamos solo 382 m√°scaras manualmente, y esto es de 10,000 piezas, identificaremos y destruiremos la mayor√≠a de las m√°scaras falsas sin piedad. <br><br>  Si es posible ver im√°genes y m√°scaras durante la decisi√≥n de incluirlas en la hoja de trucos, a partir de un cierto paso, todas las m√°scaras falsas, todas las mentiras estar√°n determinadas por el nivel m√≠nimo de predicci√≥n de una red ligeramente entrenada, y las m√°scaras correctas tendr√°n una predicci√≥n mayor que este nivel . <br><br><h3>  Para resumir </h3><br>  Si en alg√∫n mundo imaginado la verdad es siempre cuadrangular, y la mentira ovalada y alguna entidad desconocida decidieron distorsionar la verdad y llamaron a algunos puntos suspensivos la verdad, y los cuadr√°ngulos son falsos, entonces, usando inteligencia artificial y la habilidad natural de hacer trampas, la Inquisici√≥n local encontrar√° r√°pida y f√°cilmente y erradica mentiras y enga√±os completa y completamente. <br><br>  PD La capacidad de detectar √≥valos, tri√°ngulos, pol√≠gonos simples es un requisito previo para crear cualquier IA que controle el autom√≥vil.  Si no sabe c√≥mo buscar √≥valos y tri√°ngulos, no encontrar√° todas las se√±ales de tr√°fico y su IA se ir√° en el autom√≥vil equivocado. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/440120/">https://habr.com/ru/post/440120/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../440110/index.html">Sum√©rgete en el ecosistema de c√≥digo abierto de Android</a></li>
<li><a href="../440112/index.html">C√≥mo cambiamos completamente las entrevistas</a></li>
<li><a href="../440114/index.html">Dise√±o de juego basado en decisiones</a></li>
<li><a href="../440116/index.html">Dagaz: Errores</a></li>
<li><a href="../440118/index.html">Mitos sobre Premier Field Engineer en Microsoft</a></li>
<li><a href="../440122/index.html">C√≥mo hacer una linterna solar con tus propias manos (parte 2)</a></li>
<li><a href="../440124/index.html">¬øPor qu√© los desarrolladores de redes neuronales ABBYY Mobile, un museo y Random Coffee?</a></li>
<li><a href="../440130/index.html">Vim para principiantes</a></li>
<li><a href="../440134/index.html">Migrar un sitio a est√°tica: motivaci√≥n, costo, trabajo</a></li>
<li><a href="../440138/index.html">Agregar autom√°ticamente espacio de servidor virtual</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
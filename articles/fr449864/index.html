<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧜 🙉 💇🏽 ResNet50. Mise en œuvre propre 👲🏾 🏇🏻 🛀🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour à tous. La bibliothèque du réseau neuronal est décrite dans mon dernier article . Ici, j'ai décidé de montrer comment vous pouvez utiliser le ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>ResNet50. Mise en œuvre propre</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/449864/">  Bonjour à tous.  La bibliothèque du réseau neuronal est décrite dans mon dernier <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> .  Ici, j'ai décidé de montrer comment vous pouvez utiliser le réseau formé de TF (Tensorflow) dans votre décision, et si cela en vaut la peine. <br><br>  Sous la coupe, une comparaison avec l'implémentation originale de TF, une application de démonstration pour reconnaître des images, enfin ... des conclusions.  Peu importe, s'il vous plaît. <br><a name="habracut"></a><br>  Vous pouvez découvrir comment fonctionne ResNet, par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Voici la structure du réseau en chiffres: <br><br><img src="https://habrastorage.org/webt/ye/ua/0q/yeua0qbp3fbsv7q2hek2-btfatu.png" width="600" height="400"><br><br>  Le code s'est avéré être pas plus simple et pas plus compliqué que python. <br><br><div class="spoiler">  <b class="spoiler_title">Code C ++ pour créer un réseau:</b> <div class="spoiler_text"><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> net = sn::Net(); net.addNode(<span class="hljs-string"><span class="hljs-string">"In"</span></span>, sn::Input(), <span class="hljs-string"><span class="hljs-string">"conv1"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"conv1"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, sn::batchNormType::beforeActive, sn::active::none, mode), <span class="hljs-string"><span class="hljs-string">"pool1_pad"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"pool1_pad"</span></span>, sn::Pooling(<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, sn::poolType::max, mode), <span class="hljs-string"><span class="hljs-string">"res2a_branch1 res2a_branch2a"</span></span>); convBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"res2a_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res2b_branch2a res2b_branchSum"</span></span>, mode); idntBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"res2b_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res2c_branch2a res2c_branchSum"</span></span>, mode); idntBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>}, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"res2c_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res3a_branch1 res3a_branch2a"</span></span>, mode); convBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">512</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"res3a_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res3b_branch2a res3b_branchSum"</span></span>, mode); idntBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">512</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"res3b_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res3c_branch2a res3c_branchSum"</span></span>, mode); idntBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">512</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"res3c_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res3d_branch2a res3d_branchSum"</span></span>, mode); idntBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">128</span></span>, <span class="hljs-number"><span class="hljs-number">512</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"res3d_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res4a_branch1 res4a_branch2a"</span></span>, mode); convBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">1024</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"res4a_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res4b_branch2a res4b_branchSum"</span></span>, mode); idntBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">1024</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"res4b_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res4c_branch2a res4c_branchSum"</span></span>, mode); idntBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">1024</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"res4c_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res4d_branch2a res4d_branchSum"</span></span>, mode); idntBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">1024</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"res4d_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res4e_branch2a res4e_branchSum"</span></span>, mode); idntBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">1024</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"res4e_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res4f_branch2a res4f_branchSum"</span></span>, mode); idntBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">1024</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"res4f_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res5a_branch1 res5a_branch2a"</span></span>, mode); convBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-number"><span class="hljs-number">2048</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"res5a_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res5b_branch2a res5b_branchSum"</span></span>, mode); idntBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-number"><span class="hljs-number">2048</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"res5b_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"res5c_branch2a res5c_branchSum"</span></span>, mode); idntBlock(net, <span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt;{ <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-number"><span class="hljs-number">2048</span></span> }, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"res5c_branch"</span></span>, <span class="hljs-string"><span class="hljs-string">"avg_pool"</span></span>, mode); net.addNode(<span class="hljs-string"><span class="hljs-string">"avg_pool"</span></span>, sn::Pooling(<span class="hljs-number"><span class="hljs-number">7</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>, sn::poolType::avg, mode), <span class="hljs-string"><span class="hljs-string">"fc1000"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"fc1000"</span></span>, sn::FullyConnected(<span class="hljs-number"><span class="hljs-number">1000</span></span>, sn::active::none, mode), <span class="hljs-string"><span class="hljs-string">"LS"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"LS"</span></span>, sn::LossFunction(sn::lossType::softMaxToCrossEntropy), <span class="hljs-string"><span class="hljs-string">"Output"</span></span>);</code> </pre> <br></div></div><br>  → Le code complet est disponible <a href="">ici</a> <br><br>  Vous pouvez le faire plus facilement, charger l'architecture du réseau et les poids à partir de fichiers, <br><br><div class="spoiler">  <b class="spoiler_title">comme ceci:</b> <div class="spoiler_text"><pre> <code class="cpp hljs"> <span class="hljs-built_in"><span class="hljs-built_in">string</span></span> archPath = <span class="hljs-string"><span class="hljs-string">"c:/cpp/other/skyNet/example/resnet50/resNet50Struct.json"</span></span>, weightPath = <span class="hljs-string"><span class="hljs-string">"c:/cpp/other/skyNet/example/resnet50/resNet50Weights.dat"</span></span>; <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::ifstream ifs; ifs.open(archPath, <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::ifstream::in); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!ifs.good()){ <span class="hljs-built_in"><span class="hljs-built_in">cout</span></span> &lt;&lt; <span class="hljs-string"><span class="hljs-string">"error open file : "</span></span> + archPath &lt;&lt; <span class="hljs-built_in"><span class="hljs-built_in">endl</span></span>; system(<span class="hljs-string"><span class="hljs-string">"pause"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">false</span></span>; } ifs.seekg(<span class="hljs-number"><span class="hljs-number">0</span></span>, ifs.end); <span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> length = ifs.tellg(); ifs.seekg(<span class="hljs-number"><span class="hljs-number">0</span></span>, ifs.beg); <span class="hljs-built_in"><span class="hljs-built_in">string</span></span> jnArch; jnArch.resize(length); ifs.read((<span class="hljs-keyword"><span class="hljs-keyword">char</span></span>*)jnArch.data(), length); <span class="hljs-comment"><span class="hljs-comment">// Create net sn::Net snet(jnArch, weightPath);</span></span></code> </pre><br></div></div><br>  Fait une demande d'intérêt.  Vous pouvez télécharger <a href="">ici</a> .  Le volume est important en raison des poids du réseau.  Les sources sont là, vous pouvez les utiliser comme exemple. <br><br>  L'application a été créée uniquement pour l'article, elle ne sera pas prise en charge, elle n'a donc pas été incluse dans le référentiel du projet. <br><br><img src="https://habrastorage.org/webt/wf/ie/c9/wfiec9viimwuvrlfucdlx6joyaa.gif" width="600" height="300"><br><br>  Maintenant, ce qui s'est passé par rapport à TF. <br><br>  Indications après une série de 100 images, en moyenne.  Machine: i5-2400, GF1050, Win7, MSVC12. <br><br>  Les valeurs des résultats de reconnaissance correspondent au troisième caractère. <br><br>  → <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Code de test</a> <br><div class="scrollable-table"><table><tbody><tr><th></th><th>  CPU: temps / img, ms </th><th>  GPU: temps / img, ms </th><th>  CPU: RAM, Mo </th><th>  GPU: RAM, Mo </th></tr><tr><td>  Skynet </td><td>  410 </td><td>  120 </td><td>  600 </td><td>  1200 </td></tr><tr><td>  Tensorflow </td><td>  250 </td><td>  25 </td><td>  400 </td><td>  1400 </td></tr></tbody></table></div><br><br>  En fait, tout est déplorable bien sûr. <br><br>  Pour le CPU, j'ai décidé de ne pas utiliser MKL-DNN, j'ai moi-même pensé à le finir: redistribué la mémoire pour une lecture séquentielle, chargé au maximum les registres vectoriels.  Peut-être était-il nécessaire de conduire à une multiplication matricielle et / ou à d'autres hacks.  Reposé ici, au début c'était pire, il serait plus correct d'utiliser tout de même MKL. <br><br>  Sur le GPU, du temps est consacré à la copie de la mémoire de / vers la mémoire de la carte vidéo et toutes les opérations ne sont pas effectuées sur le GPU. <br><br>  Quelles conclusions peut-on tirer de toute cette agitation: <br><br>  - non pas pour se montrer, mais pour utiliser des solutions éprouvées bien connues, elles leur sont déjà venues à l'esprit plus ou moins.  Il s'est assis sur mxnet lui-même une fois, et a travaillé dur avec l'usage indigène, plus sur celui ci-dessous; <br><br>  - N'essayez pas d'utiliser l'interface C native des frameworks ML.  Et utilisez-les dans le langage sur lequel les développeurs se sont concentrés, à savoir le python. <br><br>  Un moyen simple d'utiliser la fonctionnalité ML de votre langue est de faire un processus de service sur python et de lui envoyer des images sur le socket, vous obtenez une répartition des responsabilités et l'absence de code lourd. <br><br>  Peut-être tout.  L'article était court, mais les conclusions, je pense, sont précieuses et s'appliquent non seulement au BC. <br><br>  Je vous remercie <br><br>  PS: <br>  si quelqu'un a le désir et la force d'essayer de rattraper TF, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bienvenue</a> !) <br><br>  PS2: <br>  baissa les mains plus tôt.  Il a pris une pause fumée, l'a repris et tout a fonctionné. <br>  Pour le CPU, le casting vers la multiplication matricielle a aidé, comme je le pensais. <br>  Pour le GPU, j'ai sélectionné toutes les opérations dans une bibliothèque distincte, de sorte que sans copier sur le CPU et vice versa, le seul inconvénient de cette approche était que je devais réécrire (dupliquer) tous les opérateurs, bien que certaines choses coïncident, mais ne les lient pas. <br>  En général, voici comment maintenant: <br><div class="scrollable-table"><table><tbody><tr><th></th><th>  CPU: temps / img, ms </th><th>  GPU: temps / img, ms </th><th>  CPU: RAM, Mo </th><th>  GPU: RAM, Mo </th></tr><tr><td>  Skynet </td><td>  195 </td><td>  15 </td><td>  600 </td><td>  800 </td></tr><tr><td>  Tensorflow </td><td>  250 </td><td>  25 </td><td>  400 </td><td>  1400 </td></tr></tbody></table></div><br>  Autrement dit, au moins l'inférence s'est avérée encore plus rapide que sur TF. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le code de test</a> n'a pas changé. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr449864/">https://habr.com/ru/post/fr449864/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr449850/index.html">Top 7 des qualités d'un manager efficace</a></li>
<li><a href="../fr449854/index.html">Comment les plaintes reconfigurent votre cerveau de manière négative [et affectent la santé]</a></li>
<li><a href="../fr449858/index.html">Transmission sonore par modulation d'amplitude des ultrasons</a></li>
<li><a href="../fr449860/index.html">Cloud box office, mon humble expérience</a></li>
<li><a href="../fr449862/index.html">Le condensé de matériaux intéressants pour le développeur mobile # 296 (du 22 au 26 avril)</a></li>
<li><a href="../fr449866/index.html">Attaques potentielles contre HTTPS et comment se défendre contre elles</a></li>
<li><a href="../fr449868/index.html">Mécanisme de contrôle de version de base de données GIT (gestion de vidage MySQL)</a></li>
<li><a href="../fr449870/index.html">Generic JSONDecoder</a></li>
<li><a href="../fr449872/index.html">Principes de base de RxVMS: RxCommand et GetIt</a></li>
<li><a href="../fr449876/index.html">Innovation SSI-2001: l'histoire d'une des cartes son les plus rares pour le PC IBM (et sa réplique)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
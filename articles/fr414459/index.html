<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö§ ü¶í üëª D√©tecteurs et descripteurs de points singuliers FAST, BRIEF, ORB üßëüèø‚Äçü§ù‚Äçüßëüèø üéã ‚õ¥Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cet article se concentrera sur certains algorithmes de recherche et descriptions de points d'image sp√©cifiques. Ici, ce sujet a d√©j√† √©t√© soulev√© , et ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>D√©tecteurs et descripteurs de points singuliers FAST, BRIEF, ORB</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414459/">  Cet article se concentrera sur certains algorithmes de recherche et descriptions de points d'image sp√©cifiques.  Ici, ce sujet a d√©j√† √©t√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">soulev√©</a> , et plus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d'une fois</a> .  Je consid√©rerai que les d√©finitions de base sont d√©j√† famili√®res au lecteur, nous examinerons en d√©tail les algorithmes heuristiques FAST, FAST-9, FAST-ER, BRIEF, rBRIEF, ORB, et discuterons des id√©es √©tincelantes qui les sous-tendent.  En partie, ce sera une traduction gratuite de l'essence de plusieurs articles [1,2,3,4,5], il y aura un code pour ¬´essayer¬ª. <br><br><img src="https://pp.userapi.com/c846418/v846418322/73b6d/09CAYMQuFMs.jpg" alt="image"><br><a name="habracut"></a><br><h1>  Algorithme FAST </h1><br>  FAST, propos√© pour la premi√®re fois en 2005 dans [1], a √©t√© l'une des premi√®res m√©thodes heuristiques pour trouver des points singuliers, qui a gagn√© en popularit√© en raison de son efficacit√© de calcul.  Pour d√©cider s'il faut consid√©rer un point C donn√© comme sp√©cial ou non, cette m√©thode consid√®re la luminosit√© des pixels sur un cercle centr√© au point C et au rayon 3: <br><br><img src="https://pp.userapi.com/c848536/v848536622/5559/qPxNkhmqJSU.jpg" alt="image"><br><br>  En comparant la luminosit√© des pixels du cercle avec la luminosit√© du centre C, nous obtenons pour chacun trois r√©sultats possibles (plus clair, plus sombre, semble-t-il): <br><br><math> </math> $ inline $ \ begin {array} {l} {I_p}&gt; {I_C} + t \\ {I_p} &lt;{I_C} -t \\ {I_C} -t &lt;{I_p} &lt;{I_C} + t \ end {array} $ inline $ <br><br>  Ici I est la luminosit√© des pixels, t est un seuil de luminosit√© pr√©d√©termin√©. <br>  Un point est marqu√© comme sp√©cial s'il y a n = 12 pixels dans une rang√©e qui sont plus sombres, ou 12 pixels qui sont plus clairs que le centre. <br><br>  Comme la pratique l'a montr√©, en moyenne, pour prendre une d√©cision, il a fallu v√©rifier environ 9 points.  Afin d'acc√©l√©rer le processus, les auteurs ont sugg√©r√© de ne v√©rifier d'abord que quatre pixels avec des nombres: 1, 5, 9, 13. Si parmi eux, il y a 3 pixels plus clairs ou plus fonc√©s, une v√©rification compl√®te est effectu√©e sur 16 points, sinon, le point est imm√©diatement marqu√© comme " pas sp√©cial. "  Cela r√©duit consid√©rablement le temps de travail, pour prendre une d√©cision en moyenne, il suffit de sonder seulement environ 4 points d'un cercle. <br><br>  Un peu de code na√Øf se trouve <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> <br>  Param√®tres variables (d√©crits dans le code): rayon du cercle (prend les valeurs 1, 2, 3), param√®tre n (dans l'original, n = 12), param√®tre t.  Le code ouvre le fichier in.bmp, traite l'image, l'enregistre dans out.bmp.  Les images sont ordinaires en 24 bits. <br><br><h1>  Construire un arbre de d√©cision, Tree FAST, FAST-9 </h1><br>  En 2006, en [2], il a √©t√© possible de d√©velopper une id√©e originale en utilisant l'apprentissage automatique et les arbres de d√©cision. <br><br>  Le FAST d'origine pr√©sente les inconv√©nients suivants: <br><br><ul><li>  Plusieurs pixels adjacents peuvent √™tre marqu√©s comme des points sp√©ciaux.  Nous avons besoin d'une certaine mesure de la ¬´force¬ª d'une fonction.  L'une des premi√®res mesures propos√©es est la valeur maximale de t √† laquelle le point est toujours consid√©r√© comme sp√©cial. </li><li>  Un test rapide en 4 points n'est pas g√©n√©ralis√© pour n inf√©rieur √† 12. Ainsi, par exemple, visuellement, les meilleurs r√©sultats de la m√©thode sont obtenus avec n = 9, pas 12. </li><li>  J'aimerais aussi acc√©l√©rer l'algorithme! </li></ul><br>  Au lieu d'utiliser une cascade de deux tests de 4 et 16 points, il est propos√© de tout faire en un seul passage dans l'arbre de d√©cision.  De mani√®re similaire √† la m√©thode d'origine, nous comparerons la luminosit√© du point central avec les points du cercle, mais dans cet ordre pour prendre la d√©cision le plus rapidement possible.  Et il s'av√®re que vous pouvez prendre une d√©cision pour seulement ~ 2 (!!!) comparaisons en moyenne. <br><br>  Le sel est de savoir comment trouver le bon ordre pour comparer les points.  Trouvez en utilisant l'apprentissage automatique.  Supposons que quelqu'un ait not√© pour nous dans l'image beaucoup de points sp√©ciaux.  Nous les utiliserons comme un ensemble d'exemples de formation, et l'id√©e est de choisir <u>avec empressement</u> celui qui donnera le plus d'informations √† cette √©tape comme point suivant.  Par exemple, supposons qu'au d√©part, dans notre √©chantillon, il y avait 5 points singuliers et 5 points non singuliers.  Sous la forme d'une tablette comme celle-ci: <br><br><img src="https://pp.userapi.com/c848536/v848536622/5596/A83hqZFlbWY.jpg" alt="image"><br><br>  Maintenant, nous choisissons l'un des pixels p du cercle et pour tous les points singuliers, nous comparons le pixel central avec le pixel s√©lectionn√©.  Selon la luminosit√© du pixel s√©lectionn√© pr√®s de chaque point particulier, le tableau peut avoir le r√©sultat suivant: <br><br><img src="https://pp.userapi.com/c848536/v848536622/559d/A1CIWhE_LV8.jpg" alt="image"><br><br>  L'id√©e est de choisir un point p pour que les nombres dans les colonnes du tableau soient aussi diff√©rents que possible.  Et si maintenant, pour un nouveau point inconnu, nous obtenons le r√©sultat de comparaison ¬´Plus l√©ger¬ª, alors nous pouvons d√©j√† dire tout de suite que le point n'est ¬´pas sp√©cial¬ª (voir tableau).  Le processus se poursuit de mani√®re r√©cursive jusqu'√† ce que les points d'une seule des classes tombent dans chaque groupe apr√®s s'√™tre divis√©s en "plus sombres comme plus clairs".  Il s'av√®re un arbre de la forme suivante: <br><br><img src="https://pp.userapi.com/c848536/v848536622/55a4/W7idq5TQQZ4.jpg" alt="image"><br><br>  La valeur binaire est dans les feuilles de l'arbre (le rouge est sp√©cial, le vert n'est pas sp√©cial), et aux autres sommets de l'arbre est le num√©ro du point qui doit √™tre analys√©.  Plus pr√©cis√©ment, dans l'article d'origine, ils proposent de faire un choix du nombre de points en changeant l'entropie.  L'entropie de l'ensemble de points est calcul√©e: <br><br><p><math> </math> $$ afficher $$ H = \ gauche ({c + \ overline c} \ droite) {\ log _2} \ gauche ({c + \ overline c} \ droite) - c {\ log _2} c - \ overline c {\ log _2} \ overline c $$ display $$ </p><br><br>  c est le nombre de points singuliers, <math> </math> $ inline $ {\ bar c} $ inline $   Est le nombre de points non singuliers de l'ensemble <br><br>  Changement d'entropie apr√®s le point de traitement p: <br><br><p><math> </math> $$ afficher $$ \ Delta H = H - {H_ {fonc√©}} - {H_ {√©gal}} - {H_ {brillant}} $$ afficher $$ </p><br><br>  En cons√©quence, un point est s√©lectionn√© pour lequel le changement d'entropie sera maximum.  Le processus de division s'arr√™te lorsque l'entropie est nulle, ce qui signifie que tous les points sont soit singuliers, soit vice versa - tous ne sont pas sp√©ciaux.  Avec une impl√©mentation logicielle, apr√®s tout cela, l'arbre de d√©cision trouv√© est converti en un ensemble de constructions de type "if-else". <br><br>  La derni√®re √©tape de l'algorithme est l'op√©ration de suppression des non-maximums pour en obtenir un √† partir de plusieurs points adjacents.  Les d√©veloppeurs sugg√®rent d'utiliser la mesure d'origine bas√©e sur la somme des diff√©rences absolues entre le point central et les points du cercle sous cette forme: <br><br><p><math> </math> $$ affiche $$ V = \ max \ left ({\ sum \ limits_ {x \ in {S_ {bright}}} {\ left | {{I_x} - {I_p}} \ right | - t, \ sum \ limits_ {x \ in {S_ {dark}}} {\ left | {{I_p} - {I_x}} \ right | - t}}} \ right) $$ display $$ </p><br><br>  Ici <math> </math> $ inline $ {S_ {bright}} $ inline $   et <math> </math> $ inline $ {S_ {dark}} $ inline $   respectivement, les groupes de pixels sont plus clairs et plus sombres, t est la valeur seuil de luminosit√©, <math> </math> $ inline $ {I_p} $ inline $   - luminosit√© du pixel central, <math> </math> $ inline $ {{I_x}} $ inline $   - luminosit√© du pixel sur le cercle.  Vous pouvez essayer l'algorithme avec le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">code suivant</a> .  Le code est tir√© d'OpenCV et lib√©r√© de toutes les d√©pendances, il suffit de l'ex√©cuter. <br><br><h1>  Optimiser l'arbre de d√©cision - FAST-ER </h1><br>  FAST-ER [3] est un algorithme des m√™mes auteurs que le pr√©c√©dent, un d√©tecteur rapide est construit de mani√®re similaire, la s√©quence optimale de points est √©galement recherch√©e pour comparaison, un arbre de d√©cision est √©galement construit, mais en utilisant une m√©thode diff√©rente - la m√©thode d'optimisation. <br><br>  Nous comprenons d√©j√† qu'un d√©tecteur peut √™tre repr√©sent√© comme un arbre de d√©cision.  Si nous avions un crit√®re pour comparer les performances de diff√©rents arbres, nous pouvons maximiser ce crit√®re en triant diff√©rentes variantes d'arbres.  Et en tant que tel crit√®re, il est propos√© d'utiliser la ¬´r√©p√©tabilit√©¬ª. <br><br>  La r√©p√©tabilit√© montre √† quel point les points singuliers d'une sc√®ne sont d√©tect√©s sous diff√©rents angles.  Pour une paire d'images, un point est appel√© ¬´utile¬ª s'il se trouve sur une trame et peut th√©oriquement se trouver sur une autre, c'est-√†-dire  Ne bloquez pas les √©l√©ments de la sc√®ne.  Et le point est appel√© "r√©p√©t√©" (r√©p√©t√©), s'il se trouve √©galement dans la deuxi√®me image.  √âtant donn√© que l'optique de la cam√©ra n'est pas id√©ale, le point sur la deuxi√®me image peut ne pas √™tre dans le pixel calcul√©, mais quelque part √† proximit√© dans son voisinage.  Les d√©veloppeurs ont pris un quartier de 5 pixels.  Nous d√©finissons la r√©p√©tabilit√© comme le rapport du nombre de points r√©p√©t√©s au nombre de points utiles: <br><br><p><math> </math> $$ afficher $$ R = \ frac {{{N_ {r√©p√©t√©}}}} {{{N_ {utile}}}} $$ afficher $$ </p><br><br>  Pour trouver le meilleur d√©tecteur, une m√©thode de simulation de recuit est utilis√©e.  Il y a d√©j√† un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">excellent article</a> sur Habr√© √† son sujet.  En bref, l'essence de la m√©thode est la suivante: <br><br><ul><li>  Une solution initiale au probl√®me est s√©lectionn√©e (dans notre cas, il s'agit d'une sorte d'arbre de d√©tection). </li><li>  La r√©p√©tabilit√© est consid√©r√©e. </li><li>  L'arbre est modifi√© al√©atoirement. </li><li>  Si la version modifi√©e est meilleure par le crit√®re de r√©p√©tabilit√©, alors la modification est accept√©e, et si pire, elle peut √™tre accept√©e ou non, avec une certaine probabilit√©, qui d√©pend d'un nombre r√©el appel√© "temp√©rature".  √Ä mesure que le nombre d'it√©rations augmente, la temp√©rature tombe √† z√©ro. </li></ul><br>  De plus, la construction du d√©tecteur implique d√©sormais non plus 16 points du cercle, comme auparavant, mais 47, mais la signification ne change pas du tout: <br><br><img src="https://pp.userapi.com/c824411/v824411841/1607f1/5szVOBYHeck.jpg" alt="image"><br><br>  Selon la m√©thode de recuit simul√©, nous d√©finissons trois fonctions: <br><br>  ‚Ä¢ Fonction de co√ªt k.  Dans notre cas, nous utilisons la r√©p√©tabilit√© comme valeur.  Mais il y a un probl√®me.  Imaginez que tous les points de chacune des deux images soient d√©tect√©s comme singuliers.  Ensuite, il s'av√®re que la r√©p√©tabilit√© est de 100% - l'absurdit√©.  D'un autre c√¥t√©, m√™me si nous avons trouv√© un point particulier sur deux images, et ces points co√Øncident - la r√©p√©tabilit√© est √©galement de 100%, mais cela ne nous int√©resse pas non plus.  Et donc, les auteurs ont propos√© de l'utiliser comme crit√®re de qualit√©: <br><br><p><math> </math> $$ afficher $$ k = \ gauche ({1 + {{\ gauche ({\ frac {{{w_r}}} {R}} \ droite)} ^ 2}} \ droite) \ gauche ({1 + \ frac {1} {N} \ sum \ limits_ {i = 1} {{{\ left ({\ frac {{{d_i}}} {{{w_n}}}} right)} ^ 2}}} \ droite) \ gauche ({1 + {{\ gauche ({\ frac {s} {{{w_s}}}} droite)} ^ 2}} \ droite) $$ afficher $$ </p><br><br>  r est la r√©p√©tabilit√© <math> </math> $ inline $ {{d_i}} $ inline $   Est le nombre d'angles d√©tect√©s sur l'image i, N est le nombre d'images et s est la taille de l'arbre (nombre de sommets).  W sont des param√®tres de m√©thode personnalis√©s.] <br><br>  ‚Ä¢ Fonction du changement de temp√©rature dans le temps: <br><br><p><math> </math> $$ display $$ T \ left (I \ right) = \ beta \ exp \ left ({- \ frac {{\ alpha I}} {{{I _ {\ max}}}} \ right) $$ display $$ </p><br><br>  o√π <math> </math> $ inline $ \ alpha, \ beta $ inline $   Sont les coefficients, Imax est le nombre d'it√©rations. <br><br>  ‚Ä¢ Une fonction qui g√©n√®re une nouvelle solution.  L'algorithme apporte des modifications al√©atoires √† l'arbre.  Tout d'abord, s√©lectionnez un sommet.  Si le sommet s√©lectionn√© est une feuille d'un arbre, alors avec une probabilit√© √©gale nous faisons ce qui suit: <br><br><ol><li>  Remplacez le sommet par un sous-arbre al√©atoire de profondeur 1 </li><li>  Changer la classe de cette feuille (points singuliers-non singuliers) </li></ol><br>  S'il ne s'agit PAS d'une feuille: <br><br><ol><li>  Remplacez le num√©ro du point test√© par un nombre al√©atoire de 0 √† 47 </li><li>  Remplacer le sommet par une feuille avec une classe al√©atoire </li><li>  √âchangez deux sous-arbres de ce sommet </li></ol><br>  La probabilit√© P d'accepter le changement √† l'it√©ration I est: <br><math> </math> $ inline $ P = \ exp \ left ({\ frac {{k \ left ({i - 1} \ right) - k \ left (i \ right)}} {T}} \ right) $ inline $ <br>  k est la fonction de co√ªt, T est la temp√©rature, i est le num√©ro d'it√©ration. <br><br>  Ces modifications de l'arbre permettent √† la fois la croissance de l'arbre et sa r√©duction.  La m√©thode est al√©atoire, elle ne garantit pas que le meilleur arbre sera obtenu.  Ex√©cutez la m√©thode plusieurs fois, en choisissant la meilleure solution.  Dans l'article d'origine, par exemple, ils s'ex√©cutent 100 fois par 100 000 it√©rations chacun, ce qui prend 200 heures de temps processeur.  Comme le montrent les r√©sultats, le r√©sultat est meilleur que Tree FAST, en particulier dans les images bruyantes. <br><br><h1>  BREF descripteur </h1><br>  Une fois les points singuliers trouv√©s, leurs descripteurs sont calcul√©s, c'est-√†-dire  ensembles de caract√©ristiques caract√©risant le voisinage de chaque point singulier.  BRIEF [4] est un descripteur heuristique rapide, construit √† partir de 256 comparaisons binaires entre la luminosit√© des pixels dans une image <u>floue</u> .  Le test binaire entre les points x et y est d√©fini comme suit: <br><br><p><math> </math> $$ afficher $$ \ tau \ gauche ({P, x, y} \ droite): = \ left \ {{\ begin {array} {* {20} {c}} {1: p \ left (x \ droite) &lt;p \ gauche (y \ droite)} \\ {0: p \ gauche (x \ droite) \ ge p \ gauche (y \ droite)} \ end {array}} \ droite. $$ display $$ </p><br><br><img src="https://pp.userapi.com/c824411/v824411841/160801/dMWJxyV422c.jpg" alt="image"><br><br>  Dans l'article d'origine, plusieurs m√©thodes de choix des points pour les comparaisons binaires ont √©t√© envisag√©es.  Il s'est av√©r√© que l'un des meilleurs moyens √©tait de s√©lectionner au hasard des points en utilisant une distribution gaussienne autour d'un pixel central.  Cette s√©quence al√©atoire de points est s√©lectionn√©e une fois et ne change plus.  La taille du voisinage consid√©r√© du point est de 31x31 pixels et l'ouverture de flou est de 5. <br><br>  Le descripteur binaire r√©sultant r√©siste aux changements d'√©clairage, la distorsion de la perspective est rapidement calcul√© et compar√©, mais est tr√®s instable √† la rotation dans le plan de l'image. <br><br><h1>  ORB - rapide et efficace </h1><br>  Le d√©veloppement de toutes ces id√©es a √©t√© l'algorithme ORB (Oriented FAST and Rotated BRIEF) [5], dans lequel une tentative a √©t√© faite pour am√©liorer les performances BRIEF pendant la rotation de l'image.  Il est propos√© de calculer d'abord l'orientation du point singulier puis d'effectuer des comparaisons binaires conform√©ment √† cette orientation.  L'algorithme fonctionne comme ceci: <br><br>  1) Les points caract√©ristiques sont d√©tect√©s en utilisant l'arborescence FAST rapide dans l'image d'origine et dans plusieurs images de la pyramide des vignettes. <br><br>  2) Pour les points d√©tect√©s, la mesure de Harris est calcul√©e, les candidats avec une faible valeur de la mesure de Harris sont rejet√©s. <br><br>  3) L'angle d'orientation du point singulier est calcul√©.  Pour cela, les moments de luminosit√© pour le voisinage du point singulier sont d'abord calcul√©s: <br><br><math> </math> $ inline $ {m_ {pq}} = \ sum \ limits_ {x, y} {{x ^ p} {y ^ q} I \ left ({x, y} \ right)} $ inline $ <br>  x, y - coordonn√©es pixel, I - luminosit√©.  Et puis l'angle d'orientation du point singulier: <br><math> </math> $ inline $ \ theta = {\ rm {atan2}} \ left ({{m_ {01}}, {m_ {10}}} \ right) $ inline $ <br><br>  Tout cela, les auteurs ont appel√© ¬´l'orientation centro√Øde¬ª.  En cons√©quence, nous obtenons une certaine direction pour le voisinage du point singulier. <br><br>  4) Ayant l'angle d'orientation du point singulier, la s√©quence de points pour les comparaisons binaires dans le descripteur BRIEF tourne selon cet angle, par exemple: <br><br><img src="https://pp.userapi.com/c824411/v824411841/160813/y5R3uZYvsfQ.jpg" alt="image"><br><br>  Plus formellement, les nouvelles positions des points de test binaires sont calcul√©es comme suit: <br><br><p><math> </math> $$ afficher $$ \ gauche ({\ begin {array} {* {20} {c}} {{x_i} '} \\ {{y_i}'} \ end {array}} \ right) = R \ left (\ theta \ right) \ cdot \ left ({\ begin {array} {* {20} {c}} {{x_i}} \\ {{y_i}} \ end {array}} \ right) $$ display $$ </p><br><br>  5) Sur la base des points re√ßus, le descripteur binaire BRIEF est calcul√© <br><br>  Et ce n'est pas tout!  Il y a un autre d√©tail int√©ressant dans ORB qui n√©cessite une explication s√©par√©e.  Le fait est qu'au moment o√π nous ¬´tournons¬ª tous les points singuliers vers un angle nul, le choix al√©atoire des comparaisons binaires dans le descripteur cesse d'√™tre al√©atoire.  Cela conduit au fait que, d'une part, certaines comparaisons binaires s'av√®rent d√©pendantes les unes des autres, et d'autre part, leur moyenne n'est plus √©gale √† 0,5 (1 est plus clair, 0 est plus sombre lorsque le choix √©tait al√©atoire, puis la moyenne √©tait 0,5) et tout cela r√©duit consid√©rablement la capacit√© du descripteur √† distinguer les points singuliers entre eux. <br><br>  Solution - vous devez s√©lectionner les tests binaires ¬´corrects¬ª dans le processus d'apprentissage, cette id√©e souffle la m√™me saveur que la formation d'arbre pour l'algorithme FAST-9.  Supposons que nous ayons d√©j√† trouv√© un tas de points singuliers.  Consid√©rez toutes les options possibles pour les tests binaires.  Si le voisinage est 31 x 31 et que le test binaire est une paire de 5 x 5 sous-ensembles (en raison du flou), il existe de nombreuses options pour choisir N ‚Äã‚Äã= (31-5) ^ 2.  L'algorithme de recherche des "bons" tests est le suivant: <br><br><ol><li>  Nous calculons le r√©sultat de tous les tests pour tous les points singuliers </li><li>  Organiser l'ensemble des tests en fonction de leur distance √† la moyenne 0,5 </li><li>  Cr√©ez une liste qui contiendra les "bons" tests s√©lectionn√©s, appelons la liste R. </li><li>  Ajouter √† R le premier test de l'ensemble tri√© </li><li>  Nous prenons le test suivant et le comparons avec tous les tests de R. Si la corr√©lation est sup√©rieure au seuil, alors nous rejetons le nouveau test, sinon nous l'ajoutons. </li><li>  R√©p√©tez l'√©tape 5 jusqu'√† ce que nous tapions le nombre de tests requis. </li></ol><br>  Il s'av√®re que les tests sont s√©lectionn√©s pour que, d'une part, la valeur moyenne de ces tests soit aussi proche que possible de 0,5, d'autre part, de sorte que la corr√©lation entre les diff√©rents tests soit minimale.  Et c'est ce dont nous avons besoin.  Comparez comment c'√©tait et comment c'est devenu: <br><br><img src="https://pp.userapi.com/c824411/v824411841/160829/ozQhEUvtdBs.jpg" alt="image"><br><br>  Heureusement, l'algorithme ORB est impl√©ment√© dans la biblioth√®que OpenCV de la classe cv :: ORB.  J'utilise la version 2.4.13.  Le constructeur de classe accepte les param√®tres suivants: <br><br>  nfeatures - nombre maximum de points singuliers <br>  scaleFactor - multiplicateur pour la pyramide d'images, plus d'un.  La valeur 2 impl√©mente la pyramide classique. <br>  nlevels - le nombre de niveaux dans la pyramide d'images. <br>  edgeThreshold - le nombre de pixels √† la fronti√®re de l'image o√π les points singuliers ne sont pas d√©tect√©s. <br>  firstLevel - laissez z√©ro. <br>  WTA_K - le nombre de points requis pour un √©l√©ment du descripteur.  S'il est √©gal √† 2, la luminosit√© de deux pixels s√©lectionn√©s au hasard est compar√©e.  C'est ce qui est n√©cessaire. <br>  scoreType - si 0, alors harris est utilis√© comme mesure caract√©ristique, sinon - la mesure FAST (bas√©e sur la somme des modules des diff√©rences de luminosit√© aux points du cercle).  La mesure FAST est l√©g√®rement moins stable, mais plus rapide. <br>  patchSize - la taille du voisinage dans lequel des pixels al√©atoires sont s√©lectionn√©s pour la comparaison.  Le code recherche et compare les points singuliers dans deux images, "templ.bmp" et "img.bmp" <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre><code class="cpp hljs">cv::Mat img_object=cv::imread(<span class="hljs-string"><span class="hljs-string">"templ.bmp"</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>); <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;cv::KeyPoint&gt; keypoints_object, keypoints_scene; cv::Mat descriptors_object, descriptors_scene; cv::<span class="hljs-function"><span class="hljs-function">ORB </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">orb</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">500</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">4</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">31</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">31</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span></span>; <span class="hljs-comment"><span class="hljs-comment">//    orb.detect(img_object, keypoints_object); orb.compute(img_object, keypoints_object, descriptors_object); //    cv::Mat img = cv::imread("img.bmp", 1); cv::Mat img_scene = cv::Mat(img.size(), CV_8UC1); orb.detect(img, keypoints_scene); orb.compute(img, keypoints_scene, descriptors_scene); cv::imshow("desrs", descriptors_scene); cvWaitKey(); int test[10]; for (int q = 0; q&lt;10 ; q++) test[q]=descriptors_scene.data[q]; //-- matching descriptor vectors using FLANN matcher cv::BFMatcher matcher; std::vector&lt;cv::DMatch&gt; matches; cv::Mat img_matches; if(!descriptors_object.empty() &amp;&amp; !descriptors_scene.empty()) { matcher.match (descriptors_object, descriptors_scene, matches); double max_dist = 0; double min_dist = 100; // calculation of max and min idstance between keypoints for( int i = 0; i &lt; descriptors_object.rows; i++) { double dist = matches[i].distance; if( dist &lt; min_dist ) min_dist = dist; if( dist &gt; max_dist ) max_dist = dist; } //-- Draw only good matches (ie whose distance is less than 3*min_dist) std::vector&lt; cv::DMatch &gt;good_matches; for( int i = 0; i &lt; descriptors_object.rows; i++ ) if( matches[i].distance &lt; (max_dist/1.6) ) good_matches.push_back(matches[i]); cv::drawMatches(img_object, keypoints_object, img_scene, keypoints_scene, good_matches, img_matches, cv::Scalar::all(-1), cv::Scalar::all(-1), std::vector&lt;char&gt;(), cv::DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS); } cv::imshow("match result", img_matches ); cv::waitKey(); return 0;</span></span></code> </pre> <br></div></div><br>  Si quelqu'un a aid√© √† comprendre l'essence des algorithmes, ce n'est pas en vain.  √Ä tous Habr. <br><br>  R√©f√©rences: <br><br>  1. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Points de fusion et lignes pour un suivi haute performance</a> <br>  2. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apprentissage automatique pour la d√©tection des virages √† grande vitesse</a> <br>  3. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Plus rapide et meilleur: une approche d'apprentissage automatique pour la d√©tection des coins</a> <br>  4. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">BREF: Caract√©ristiques √©l√©mentaires ind√©pendantes robustes binaires</a> <br>  5. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ORB: une alternative efficace au SIFT ou au SURF</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr414459/">https://habr.com/ru/post/fr414459/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr414447/index.html">Des tr√©sors de tous les temps</a></li>
<li><a href="../fr414449/index.html">Comment se faire des amis de tous les op√©rateurs du stade et ne pas l'ensemencer avec des centaines d'antennes</a></li>
<li><a href="../fr414451/index.html">"Calendrier des testeurs" pour juin. Le testeur doit attraper le bug, lire Caner et organiser le d√©placement.</a></li>
<li><a href="../fr414453/index.html">Impl√©menter Path Finder pour les agents AI avec NavMesh</a></li>
<li><a href="../fr414455/index.html">Algorithme de g√©n√©ration de palette de couleurs</a></li>
<li><a href="../fr414463/index.html">L'IA elle-m√™me a appris √† construire un Rubik's Cube</a></li>
<li><a href="../fr414465/index.html">Meta Crush Saga: jeu de compilation</a></li>
<li><a href="../fr414467/index.html">Articles de la conf√©rence Minsk C ++ CoreHard Spring 2018</a></li>
<li><a href="../fr414469/index.html">Semaine de la s√©curit√© 22: Deux secondes de verrouillage intelligent</a></li>
<li><a href="../fr414471/index.html">11 cercles d'enfer pour ceux qui manquent d'exp√©rience dans un nouvel emploi</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
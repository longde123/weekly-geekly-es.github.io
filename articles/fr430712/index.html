<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë≤üèø üö∑ ü¶Ñ NeurIPS: Comment conqu√©rir la meilleure conf√©rence ML üë©üèø üéì ü¶è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="NeurIPS ‚Äì‚Äì une conf√©rence qui est actuellement consid√©r√©e comme l'√©v√©nement le plus important dans le monde de l'apprentissage automatique. Aujourd'hu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NeurIPS: Comment conqu√©rir la meilleure conf√©rence ML</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/430712/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">NeurIPS</a> ‚Äì‚Äì une conf√©rence qui est actuellement consid√©r√©e comme l'√©v√©nement le plus important dans le monde de l'apprentissage automatique.  Aujourd'hui, je vais vous parler de mon exp√©rience de participation aux concours NeurIPS: comment rivaliser avec les meilleurs universitaires du monde, remporter un prix et publier un article. </p><br><img src="https://habrastorage.org/webt/hb/kq/-v/hbkq-vnd_xgxhvcixlo-u8b_pmk.jpeg"><a name="habracut"></a><br><hr><br><h1 id="v-chem-sut-konferencii">  Quelle est l'essence de la conf√©rence? </h1><br><p>  NeurIPS soutient l'introduction de m√©thodes d'apprentissage automatique dans diverses disciplines scientifiques.  Une dizaine de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pistes sont</a> lanc√©es chaque ann√©e pour r√©soudre les probl√®mes pressants du monde acad√©mique.  Selon les r√©sultats du concours, les gagnants interviennent lors de la conf√©rence avec des rapports, de nouveaux d√©veloppements et des algorithmes.  Surtout, je suis passionn√© par l'apprentissage renforc√© (Reinforcement Learning ou RL), c'est pourquoi je participe √† des concours RL d√©di√©s √† NeurIPS pour la deuxi√®me ann√©e maintenant. </p><br><h1 id="pochemu-neurips">  Pourquoi NeurIPS </h1><br><img src="https://habrastorage.org/webt/ei/c2/us/eic2usvfs-brxmsjczvkvygpfwq.png"><br><br>  NeurIPS se concentre principalement sur la science, pas sur l'argent.  En participant √† des concours, vous faites quelque chose de vraiment important, en traitant des probl√®mes urgents. <br><p>  Deuxi√®mement, cette conf√©rence est un √©v√©nement mondial, des scientifiques de diff√©rents pays se r√©unissent en un seul endroit, avec chacun desquels vous pouvez parler. </p><br><p>  De plus, toute la conf√©rence est remplie des derni√®res r√©alisations scientifiques et des r√©sultats de pointe, il est extr√™mement important pour les personnes du domaine de la science des donn√©es de les conna√Ætre et de les surveiller. </p><br><h1 id="kak-nachat">  Comment commencer? </h1><br><p>  Commencer √† participer √† de telles comp√©titions est assez simple.  Si vous comprenez tellement DL que vous pouvez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">former ResNet</a> ‚Äì‚Äì cela suffit: inscrivez-vous et c'est parti.  Il y a toujours un classement public sur lequel vous pouvez √©valuer sobrement votre niveau par rapport aux autres participants.  Et si quelque chose n'est pas clair - il y a toujours des canaux dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">slack</a> / discord / gitter / etc pour discuter de toutes les questions √©mergentes.  Si le sujet est vraiment ¬´le v√¥tre¬ª, alors rien ne vous emp√™chera de recevoir le r√©sultat recherch√© ‚Äì‚Äì dans tous les concours auxquels j'ai particip√©, toutes les approches et solutions ont √©t√© √©tudi√©es et mises en ≈ìuvre tout au long du concours. </p><br><h1 id="neurips-na-primere-konkretnogo-keysa-learning-to-run">  √âtude de cas NeurIPS: apprendre √† courir </h1><br><img src="https://habrastorage.org/webt/hu/ws/d5/huwsd5weqocxiuqv3hugygmfqea.jpeg"><br><br><h3 id="problematika">  Probl√®me </h3><br><p>  La d√©marche d'une personne est le r√©sultat de l'interaction des muscles, des os, des organes de vision et de l'oreille interne.  En cas de perturbation du syst√®me nerveux central, certains troubles moteurs peuvent survenir, notamment des troubles de la marche ‚Äì‚Äì abasie. <br>  Des chercheurs du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Stanford Laboratory of Neuromuscular Biomechanics ont</a> d√©cid√© de connecter l'apprentissage automatique au probl√®me du traitement afin de pouvoir exp√©rimenter et tester leurs th√©ories sur un mod√®le virtuel du squelette, et non sur des personnes vivantes. </p><br><h3 id="postanovka-zadachi">  √ânonc√© du probl√®me </h3><br><p>  Les participants ont re√ßu un squelette humain virtuel (dans le simulateur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenSim</a> ), qui avait une proth√®se √† la place d'une jambe.  La t√¢che consistait √† apprendre au squelette √† se d√©placer dans une certaine direction √† une vitesse donn√©e.  Pendant la simulation, la direction et la vitesse peuvent changer. </p><br><img src="https://habrastorage.org/webt/od/vj/np/odvjnpxb7xogj5h_5ll85iokhp0.jpeg"><br><br>  Pour obtenir un mod√®le de contr√¥le de squelette virtuel, il a √©t√© propos√© d'utiliser l'apprentissage par renforcement.  Le simulateur nous a donn√© un √©tat du squelette S (un vecteur de ~ 400 nombres).  Il √©tait n√©cessaire de pr√©dire quelle action A devait √™tre effectu√©e (les forces d'activation des muscles des jambes sont un vecteur de 19 nombres).  Au cours de la simulation, le squelette a re√ßu un prix R - comme une sorte de constante moins une p√©nalit√© pour avoir d√©vi√© d'une vitesse et d'une direction donn√©es. <br><div class="spoiler">  <b class="spoiler_title">√Ä propos de la formation de renforcement</b> <div class="spoiler_text"><p>  L'apprentissage par renforcement (RL) est un domaine qui traite de la th√©orie de la d√©cision et de la recherche de politiques comportementales optimales. </p><br><p>  Rappelez-vous comment ils enseignent <del>  chat </del>  levrette de nouveaux trucs.  R√©p√©tez une action, donnez un d√©licieux pour effectuer un tour et ne donnez pas pour non-accomplissement.  Le chien doit comprendre tout cela et trouver une strat√©gie comportementale (¬´politique¬ª ou ¬´politique¬ª en termes de RL), qui maximise le nombre de bonbons re√ßus. </p><br><p>  Formellement, nous avons un agent (chien) qui est form√© sur l'histoire des interactions avec l'environnement (personne).  Dans le m√™me temps, l'environnement, √©valuant les actions de l'agent, lui fournit une r√©compense (d√©licieuse) - meilleur est le comportement de l'agent, meilleure est la r√©compense.  En cons√©quence, la t√¢che de l'agent est de trouver une politique qui maximise bien la r√©compense pour tout le temps d'interaction avec l'environnement. </p><br><p>  D√©velopper davantage ce sujet, des solutions bas√©es sur des r√®gles - logiciel 1.0, lorsque toutes les r√®gles ont √©t√© d√©finies par le d√©veloppeur, apprentissage supervis√© - le m√™me logiciel 2.0, lorsque le syst√®me apprend lui-m√™me √† l'aide des exemples disponibles et trouve des d√©pendances de donn√©es, l'apprentissage par renforcement est un peu plus loin lorsque le syst√®me lui-m√™me apprend √† rechercher, exp√©rimenter et trouver les d√©pendances requises dans ses d√©cisions.  Plus nous allons loin, mieux nous essayons de r√©p√©ter comment une personne apprend. </p></div></div><br><h3 id="osobennosti-zadachi">  Caract√©ristiques des t√¢ches </h3><br><p>  Le devoir ressemble √† un repr√©sentant typique de l'apprentissage renforc√© pour les t√¢ches avec un espace d'action continue (RL pour l'espace d'action continue).  Il diff√®re du RL ordinaire en ce qu'au lieu de choisir une action sp√©cifique (en appuyant sur le bouton du joystick), cette action est n√©cessaire pour pr√©dire avec pr√©cision (et il existe une infinit√© de possibilit√©s). </p><br><p>  L'approche de base de la solution ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deep Deterministic Policy Gradient</a> ) a √©t√© invent√©e en 2015, qui pendant longtemps selon les normes de DL, la r√©gion continue de d√©velopper activement des applications √† la robotique et aux applications RL du monde r√©el.  Il y a quelque chose √† am√©liorer: des approches robustes (pour ne pas casser un vrai robot), l'efficacit√© des √©chantillons (pour ne pas collecter des donn√©es de vrais robots pendant des mois) et d'autres probl√®mes de RL (exploration vs compromis d'exploitation, etc.).  Dans cette comp√©tition, ils ne nous ont pas donn√© un vrai robot - seulement une simulation, mais le simulateur lui-m√™me √©tait 2000 fois plus lent que les homologues Open Source (sur lesquels tout le monde v√©rifie leurs algorithmes RL), et a donc port√© le probl√®me de l'efficacit√© des √©chantillons √† un nouveau niveau. </p><br><h3 id="etapy-sorevnovaniya">  √âtapes de comp√©tition </h3><br><p>  Le concours lui-m√™me s'est d√©roul√© en trois √©tapes, au cours desquelles la t√¢che et les conditions ont quelque peu chang√©. </p><br><ul><li>  √âtape 1: le squelette a appris √† marcher droit √† une vitesse de 3 m√®tres par seconde.  La t√¢che √©tait consid√©r√©e comme termin√©e si l'agent avait effectu√© 300 √©tapes. </li><li>  √âtape 2: la vitesse et la direction ont chang√© avec une fr√©quence r√©guli√®re.  La longueur de la distance est pass√©e √† 1000 pas. </li><li>  √âtape 3: la solution finale devait √™tre emball√©e dans une image docker et envoy√©e pour v√©rification.  Au total, 10 colis ont pu √™tre r√©alis√©s. </li></ul><br><p>  La mesure de qualit√© principale a √©t√© consid√©r√©e comme la r√©compense totale de la simulation, qui a montr√© √† quel point le squelette adh√©rait √† une direction et une vitesse donn√©es sur toute la distance. </p><br><p>  Lors des 1√®re et 2√®me √©tapes, la progression de chaque participant a √©t√© affich√©e sur le classement.  La solution finale devait √™tre envoy√©e sous forme d'image docker.  Il pr√©voyait des restrictions sur les heures de travail et les ressources. </p><br><div class="spoiler">  <b class="spoiler_title">Coolstory: classement public et RL</b> <div class="spoiler_text"><p>  En raison de la disponibilit√© du classement, personne ne montre son meilleur mod√®le afin de donner ¬´un peu plus que d'habitude¬ª dans le tour final et surprendre ses rivaux. </p></div></div><br><h6 id="pochemu-tak-vazhny-docker-obrazy">  Pourquoi les images Docker sont si importantes </h6><br><p>  L'ann√©e derni√®re, un petit incident s'est produit lors de l'√©valuation des d√©cisions du tout premier tour.  √Ä ce moment-l√†, le ch√®que est pass√© par l'interaction http avec la plate-forme, et un visage des conditions de test a √©t√© trouv√©.  On peut savoir dans quelles situations particuli√®res l'agent a √©t√© √©valu√© et le recycler uniquement dans ces conditions.  Ce qui, bien s√ªr, n'a pas r√©solu le vrai probl√®me.  C'est pourquoi ils ont d√©cid√© de transf√©rer le syst√®me de soumissions √† docker-images et de le lancer sur les serveurs distants des organisateurs.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dbrain</a> utilise le m√™me syst√®me pour calculer le r√©sultat des comp√©titions pr√©cis√©ment pour les m√™mes raisons. </p><br><h1 id="klyuchevye-momenty">  Points cl√©s </h1><br><h3 id="komanda">  L'√©quipe </h3><br><img src="https://habrastorage.org/webt/ty/ur/gp/tyurgpqbzb2zl2wimtzri0mnpwk.jpeg"><br><br>  La premi√®re chose qui est importante pour le succ√®s de toute l'entreprise est l'√©quipe.  Peu importe √† quel point vous √™tes bon (et √† quel point vos pattes sont puissantes) - la participation √† l'√©quipe augmente consid√©rablement les chances de succ√®s.  La raison en est simple - une vari√©t√© d'opinions et d'approches, une nouvelle v√©rification des hypoth√®ses, la possibilit√© de parall√©liser le travail et de mener plus d'exp√©riences.  Tout cela est extr√™mement important lors de la r√©solution de nouveaux probl√®mes auxquels vous devez faire face. <br><p>  Id√©alement, vos connaissances et comp√©tences devraient √™tre au m√™me niveau et se compl√©ter.  Ainsi, par exemple, cette ann√©e, j'ai implant√© notre √©quipe sur PyTorch, et j'ai eu quelques id√©es initiales sur la mise en ≈ìuvre d'un syst√®me de formation d'agent distribu√©. </p><br><p>  Comment trouver une √©quipe?  Tout d'abord, vous pouvez rejoindre les rangs des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ods</a> et y rechercher des personnes partageant les m√™mes id√©es.  Deuxi√®mement, pour les boursiers RL, il existe une salle de discussion s√©par√©e dans un t√©l√©gramme - le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">club RL</a> .  Troisi√®mement, vous pouvez suivre un merveilleux cours de ShAD - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Practical RL</a> , apr√®s quoi vous obtiendrez s√ªrement quelques connaissances. </p><br><p>  Cependant, il convient de rappeler la politique de ¬´soumission - ou ne l'√©tait pas¬ª.  Si vous voulez vous unir, obtenez d'abord votre d√©cision, soumettez, apparaissez dans le classement et montrez votre niveau.  Comme le montre la pratique, ces √©quipes sont beaucoup plus √©quilibr√©es. </p><br><h3 id="motivaciya">  La motivation </h3><br><p>  Comme je l'ai d√©j√† √©crit, si le sujet est ¬´le v√¥tre¬ª, alors rien ne vous arr√™tera.  Cela signifie que la r√©gion ne vous aime pas seulement, mais vous inspire - vous la br√ªlez, vous voulez en devenir la meilleure. <br>  J'ai rencontr√© RL il y a 4 ans - lors du passage du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Berkeley 188x - Intro √† l'IA</a> - et je n'arr√™te pas de m'interroger sur les progr√®s dans ce domaine. </p><br><h3 id="sistematichnost">  Syst√©matique </h3><br><p>  Troisi√®mement, mais tout aussi important - vous devez √™tre capable de faire ce que vous avez promis, d'investir dans la comp√©tition tous les jours et juste ... de le r√©soudre.  Tous les jours.  Aucun talent inn√© ne peut √™tre compar√© √† la capacit√© de faire quelque chose, m√™me un peu, mais tous les jours.  C'est pour cela que la motivation est n√©cessaire.  Pour r√©ussir, je recommande de lire <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DeepWork</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AMA ternaus</a> . </p><br><h3 id="time-management">  Gestion du temps </h3><br><p>  Une autre comp√©tence extr√™mement importante est la capacit√© de r√©partir sa force et d‚Äôutiliser correctement le temps libre.  Combiner travail √† plein temps et participation √† des comp√©titions n'est pas une t√¢che ais√©e.  La chose la plus importante dans ces conditions est de ne pas br√ªler et de supporter toute la charge.  Pour ce faire, vous devez g√©rer correctement votre temps, √©valuer sobrement votre force et ne pas oublier de vous d√©tendre √† temps. </p><br><h3 id="overwork">  Surmenage </h3><br><p>  Au stade final de la comp√©tition, une situation se pr√©sente g√©n√©ralement o√π litt√©ralement en une semaine, vous devez faire non seulement beaucoup, mais TR√àS beaucoup.  Pour le meilleur r√©sultat, vous devez √™tre en mesure de vous forcer √† vous asseoir et √† faire le dernier bond vers le prix convoit√©. </p><br><div class="spoiler">  <b class="spoiler_title">Coolstory: d√©lai apr√®s d√©lai</b> <div class="spoiler_text"><p>  √Ä cause de quoi, en g√©n√©ral, vous pourriez avoir besoin de recycler au profit de la concurrence?  La r√©ponse est assez simple - transfert de date limite.  Lors de telles comp√©titions, les organisateurs ne peuvent souvent pas tout pr√©voir, car le moyen le plus simple est de donner plus de temps aux participants.  Cette ann√©e, le concours a √©t√© prolong√© 3 fois: d'abord pour un mois, puis pour une semaine et au tout dernier moment (24 heures avant la date limite) - pour encore 2 jours.  Et si au cours des deux premiers transferts, vous aviez juste besoin d'organiser correctement le temps suppl√©mentaire, alors au cours des deux derniers jours, vous n'aviez qu'√† labourer. </p></div></div><br><h3 id="theory">  Th√©orie </h3><br><img src="https://habrastorage.org/webt/gf/rg/9q/gfrg9ql1ukvjmlbglwcizlfcpto.png"><br><p>  Entre autres choses, n'oubliez pas la th√©orie - √™tre conscient de ce qui se passe sur le terrain et √™tre capable de noter ce qui est pertinent.  Ainsi, par exemple, pour r√©soudre l'an dernier, notre √©quipe est partie des articles suivants: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le contr√¥le continu avec l'apprentissage par renforcement profond</a> est un article de base sur l'apprentissage par renforcement profond pour les t√¢ches avec un espace d'action continue. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Param√®tre Space Noise for Exploration</a> - une √©tude sur l'ajout de bruit aux poids des agents pour une meilleure √©tude de l'environnement.  Par exp√©rience - l'une des meilleures techniques d'exploration en RL. </li></ul><br><p>  Cette ann√©e, quelques autres y ont √©t√© ajout√©s: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Une perspective distributionnelle sur l'apprentissage par renforcement</a> - Un nouveau regard sur les pr√©dictions d'une r√©compense possible.  Au lieu de simplement pr√©dire la moyenne, la distribution des r√©compenses futures est calcul√©e. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'apprentissage par renforcement de la distribution avec r√©gression quantile</a> est une continuation du travail pr√©c√©dent, mais avec la ¬´quantification¬ª de la distribution. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Reprise d'exp√©rience distribu√©e</a> - travaillez dans le sens d'un apprentissage par renforcement profond √† grande √©chelle.  Comment organiser correctement l'architecture de l'exp√©rience pour maximiser l'utilisation des ressources disponibles et augmenter la vitesse de formation des agents. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Gradients de politique d√©terministes distribu√©s distribu√©s</a> - une combinaison des trois articles pr√©c√©dents pour les t√¢ches avec un espace d'action continu. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Adressage des erreurs d'approximation des fonctions dans les m√©thodes des acteurs critiques</a> - excellent travail pour augmenter la robustesse des agents RL.  Je recommande de le lire. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'apprentissage par renforcement hi√©rarchique efficace des donn√©es</a> est le d√©veloppement d'un article pr√©c√©dent dans le domaine de l'apprentissage par renforcement hi√©rarchique (HRL). </li></ul><br><div class="spoiler">  <b class="spoiler_title">Lecture compl√©mentaire</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Soft Actor-Critic: Apprentissage par renforcement profond d'entropie maximale hors politique avec un acteur stochastique</a> - les auteurs ont propos√© une m√©thode pour former des politiques stochastiques avec un apprentissage par renforcement hors politique.  Gr√¢ce √† cet article, il est devenu possible de former des politiciens non d√©terministes m√™me dans des t√¢ches avec un espace d'action continu. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Politiques d'espace latent pour l'apprentissage de renforcement hi√©rarchique</a> est une continuation d'un article HRL pr√©c√©dent avec des politiques stochastiques √† plusieurs niveaux. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La diversit√© est tout ce dont vous avez besoin: apprendre des comp√©tences sans fonction de r√©compense</a> - cet article contient une approche avec l'apprentissage de nombreuses politiques stochastiques al√©atoires de bas niveau sans aucune r√©compense de l'environnement.  Par la suite, lorsque nous avons d√©fini la fonction de r√©compense, la plus corr√©l√©e avec le prix peut √™tre utilis√©e pour enseigner la politique de haut niveau. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apprentissage et contr√¥le du renforcement en tant qu'inf√©rence probabiliste: didacticiel et examen</a> - un aper√ßu de toutes sortes de m√©thodes d'apprentissage par renforcement d'entropie maximale de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sergey Levine</a> . </li></ul><br><p>  Je conseille √©galement <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenAI une s√©lection d'articles</a> sur l'apprentissage par renforcement et sa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">version pour mendeley</a> .  Et si vous √™tes int√©ress√© par le sujet de la formation de renforcement, rejoignez le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">club</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RL</a> et les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">papiers RL</a> . </p></div></div><br><h3 id="practice">  Pratique </h3><br><img src="https://habrastorage.org/webt/xp/g7/it/xpg7itebqdpi3cwex33uzrzkidg.jpeg"><br><br>  Conna√Ætre la th√©orie seule ne suffit pas - il est important de pouvoir mettre en pratique toutes ces approches et d'√©tablir le bon syst√®me de validation pour √©valuer les d√©cisions.  Par exemple, cette ann√©e, nous avons appris que notre agent g√®re mal certains cas r√©gionaux seulement 2 jours avant la fin de la comp√©tition.  Pour cette raison, nous n'avons pas eu le temps de r√©parer compl√®tement notre mod√®le et nous n'avons pas obtenu litt√©ralement quelques points pour la deuxi√®me place tant convoit√©e.  Si nous trouvions cela m√™me en une semaine - le r√©sultat pourrait √™tre meilleur. <br><div class="spoiler">  <b class="spoiler_title">Coolstory: √©pisode III</b> <div class="spoiler_text"><p>  La r√©compense moyenne pour 10 √©pisodes de test a servi d'√©valuation finale de la solution. </p><br><img src="https://habrastorage.org/webt/jq/bj/yc/jqbjyctkjettuu2bqd19xcahssk.png"><br><p>  Le graphique montre les r√©sultats des tests de notre agent: 9 √©pisodes sur 10, notre squelette s'est tr√®s bien pass√© (moyenne - 9955,66), mais un √©pisode .... L'√©pisode 3 ne lui a pas √©t√© donn√© (r√©compense 9870).  C'est cette erreur qui a conduit √† la chute de la vitesse finale √† 9947 (-8 points). </p></div></div><br><h3 id="udacha">  Bonne chance </h3><br><p>  Et enfin - n'oubliez pas la chance banale.  Ne pensez pas que c'est un point controvers√©.  Au contraire, un peu de chance contribue grandement au travail constant sur soi: m√™me si la probabilit√© de chance n'est que de 10%, une personne qui a tent√© de participer au concours 100 fois r√©ussira beaucoup plus que quelqu'un qui n'a essay√© qu'une seule fois et a abandonn√© l'id√©e. </p><br><h1 id="tuda-i-obratno-reshenie-proshlogo-goda--trete-mestohttpswwwcrowdaiorgchallengesnips-2017-learning-to-runwinners">  Aller-retour: d√©cision de l'ann√©e derni√®re - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">troisi√®me place</a> </h1><br><img src="https://habrastorage.org/webt/mq/lx/i_/mqlxi_alc8pt0acnzwoi8twb8oo.jpeg"><br><br>  L'ann√©e derni√®re, notre √©quipe - Mikhail Pavlov et moi - a particip√© pour la premi√®re fois aux comp√©titions NeurIPS et la principale motivation √©tait simplement de participer √† la premi√®re comp√©tition NeurIPS en apprentissage par renforcement.  Ensuite, je viens de terminer le cours <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pratique de RL</a> au SHAD et je voulais tester les comp√©tences acquises.  En cons√©quence, nous avons pris une honorable troisi√®me place, perdant seulement contre nnaisene (Schmidhuber) et l'√©quipe universitaire de Chine.  A l'√©poque, notre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">solution</a> √©tait ¬´assez simple¬ª et reposait sur le DDPG distribu√© avec bruit de param√®tre ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">publication</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pr√©sentation sur ml</a> . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Trainings</a> ). <br><h1 id="reshenie-etogo-goda--trete-mestohttpswwwcrowdaiorgchallengesnips-2018-ai-for-prosthetics-challengeleaderboards">  La d√©cision de cette ann√©e est la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">troisi√®me place</a> </h1><br><img src="https://habrastorage.org/webt/gf/qq/to/gfqqtoneh51dn47m3f7oicyqixk.jpeg"><br><p>  Il y a eu quelques changements cette ann√©e.  Premi√®rement, il n'y avait aucune envie de simplement participer √† ce concours, je voulais le gagner.  Deuxi√®mement, la composition de l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©quipe a</a> √©galement chang√©: Alexey Grinchuk, Anton Pechenko et moi.  Prendre et gagner - n'a pas fonctionn√©, mais nous avons de nouveau pris la 3e place. <br>  Notre solution sera officiellement pr√©sent√©e √† NeurIPS, et maintenant nous nous limiterons √† un petit nombre de d√©tails.  Sur la base de la d√©cision de l'ann√©e derni√®re et du succ√®s de l'apprentissage de renforcement hors politique de cette ann√©e (articles ci-dessus), nous avons ajout√© un certain nombre de nos propres d√©veloppements, dont nous parlerons √† NeurIPS, et avons obtenu le Critique d'ensemble quantique distribu√©, avec lequel nous avons pris la troisi√®me place. </p><br><p>  Toutes nos meilleures pratiques - un syst√®me d'apprentissage distribu√©, des algorithmes, etc. seront publi√©s et disponibles dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Catalyst.RL</a> apr√®s NeurIPS. </p><br><div class="spoiler">  <b class="spoiler_title">Coolstory: grands gar√ßons - gros canons</b> <div class="spoiler_text"><p>  Notre √©quipe est all√©e avec confiance √† la 1√®re place tout au long de la comp√©tition.  Cependant, les gros joueurs avaient d'autres plans - 2 grands joueurs sont entr√©s en comp√©tition 2 semaines avant la fin de la comp√©tition: FireWork (Baidu) et nnaisense (Schmidhuber).  Et si rien ne pouvait √™tre fait avec Google chinois, alors avec l'√©quipe Schmidhuber pendant un bon moment, nous avons pu nous battre honn√™tement pour la deuxi√®me place, ne perdant qu'avec une marge minimale.  Cela me semble assez bon pour les amoureux. </p></div></div><br><h1 id="zachem-eto-vse">  Pourquoi tout cela? </h1><br><ul><li>  La communication.  Les meilleurs chercheurs viennent √† la conf√©rence avec laquelle vous pouvez discuter en direct, qui ne donnera aucune correspondance par e-mail. </li><li>  Publication  Si la solution remporte le prix, l'√©quipe est invit√©e √† la conf√©rence (ou peut-√™tre plus d'une) pour pr√©senter sa d√©cision et publier l'article. </li><li>  Offre d'emploi et doctorat.  La publication et un prix dans une telle conf√©rence augmentent consid√©rablement vos chances d'obtenir une position dans des entreprises de premier plan telles que OpenAI, DeepMind, Google, Facebook, Microsoft. </li><li>  Valeur r√©elle.  NeurIPS est r√©alis√© pour r√©soudre les probl√®mes pressants du monde acad√©mique et r√©el.  Vous pouvez √™tre s√ªr que les r√©sultats n'iront pas √† la table, mais seront vraiment en demande et aideront √† am√©liorer le monde. </li><li>  Conduire  R√©soudre de tels concours ... juste int√©ressant.  Dans un concours, vous pouvez trouver beaucoup de nouvelles id√©es, tester diff√©rentes approches - juste pour √™tre le meilleur.  Et soyons honn√™tes, quand d'autre pouvez-vous conduire des squelettes, jouer √† des jeux et tout cela avec un regard s√©rieux et pour le bien de la science? </li></ul><br><div class="spoiler">  <b class="spoiler_title">Coolstory: visa et RL</b> <div class="spoiler_text"><p>  Je d√©conseille fortement d'essayer d'expliquer √† l'Am√©ricain de vous v√©rifier que vous allez √† la conf√©rence, car vous entra√Ænez des squelettes virtuels √† s'ex√©cuter dans des simulations.  Allez simplement √† la conf√©rence avec une conf√©rence. </p></div></div><br><h1 id="itogi">  R√©sum√© </h1><br><p>  Participer √† NeurIPS est une exp√©rience difficile √† surestimer.  N'ayez pas peur des gros titres - il vous suffit de vous ressaisir et de commencer √† d√©cider. </p><br><p>  Et allez sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Catalyst.RL</a> , alors quoi. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr430712/">https://habr.com/ru/post/fr430712/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr430702/index.html">Formation tr√®s √©trange</a></li>
<li><a href="../fr430704/index.html">Comment les technologies de l'intelligence artificielle aident les ventes d'avias √† se d√©velopper: sept exemples</a></li>
<li><a href="../fr430706/index.html">Nouvelle th√©orie de l'√©volution</a></li>
<li><a href="../fr430708/index.html">Tic Tac Toe ¬´Sans Fronti√®res¬ª</a></li>
<li><a href="../fr430710/index.html">Que faire si le Black Friday est demain et que vos serveurs ne sont pas pr√™ts</a></li>
<li><a href="../fr430714/index.html">VMware ach√®te Heptio - qu'est-ce que cela signifie pour Kubernetes</a></li>
<li><a href="../fr430718/index.html">Pour quels objets vaut-il la peine d'utiliser la vid√©osurveillance dans le cloud?</a></li>
<li><a href="../fr430720/index.html">Intel RealSense D435i: petite mise √† jour et courte digression historique</a></li>
<li><a href="../fr430722/index.html">Performances PHP: planification, profilage, optimisation</a></li>
<li><a href="../fr430724/index.html">DEFCON 21. La conf√©rence DNS peut √™tre dangereuse pour votre sant√©. Partie 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚ÄçüöÄ üïµüèª üïü Segmentierung von Satellitenbildern am Beispiel der Baumerkennung üö´ üõ¥ üéø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die automatische Erkennung von Satelliten- oder Luftbildern ist der vielversprechendste Weg, um Informationen √ºber die Position verschiedener Objekte ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Segmentierung von Satellitenbildern am Beispiel der Baumerkennung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/421277/"><img src="https://habrastorage.org/webt/29/oa/ku/29oakuyg7l3gw-gqre-xvdxr3s0.jpeg" alt="Bild"><br><br>  Die automatische Erkennung von Satelliten- oder Luftbildern ist der vielversprechendste Weg, um Informationen √ºber die Position verschiedener Objekte auf dem Boden zu erhalten.  Die Ablehnung der manuellen Bildsegmentierung ist besonders wichtig, wenn gro√üe Bereiche der Erdoberfl√§che in kurzer Zeit bearbeitet werden sollen. <br><br>  Vor kurzem hatte ich die M√∂glichkeit, theoretische F√§higkeiten anzuwenden und mich im Bereich des maschinellen Lernens in einem realen Bildsegmentierungsprojekt zu versuchen.  Ziel des Projekts ist die Erkennung von Waldbest√§nden, n√§mlich Baumkronen in hochaufl√∂senden Satellitenbildern.  Unter dem Schnitt werde ich meine Erfahrungen und Ergebnisse teilen. <br><a name="habracut"></a><br>  Wenn es um die Bildverarbeitung geht, kann die Segmentierung wie folgt definiert werden - dies ist das Vorhandensein charakteristischer Bereiche auf dem Bild, die in diesem Merkmalsraum gleicherma√üen beschrieben werden. <br><br>  Unterscheiden Sie zwischen Helligkeit, Kontur, Textur und semantischer Segmentierung. <br><br>  Semantische (oder semantische) Bildsegmentierung dient zum Hervorheben von Bereichen auf dem Bild, von denen jeder einem bestimmten Attribut entspricht.  Im Allgemeinen sind Probleme der semantischen Segmentierung schwer zu algorithmisieren, so dass Faltungs-Neuronale Netze, die gute Ergebnisse zeigen, derzeit h√§ufig f√ºr die Bildsegmentierung verwendet werden. <br><br><h3>  Erkl√§rung des Problems </h3><br>  Das Problem der bin√§ren Segmentierung wird gel√∂st - Farbbilder (hochaufl√∂sende Satellitenbilder) werden dem Eingang des neuronalen Netzwerks zugef√ºhrt, auf dem die Bereiche von Pixeln hervorgehoben werden m√ºssen, die zu denselben Klassenb√§umen geh√∂ren. <br><br><h3>  Ausgangsdaten </h3><br>  Zu meiner Verf√ºgung gab es eine Reihe von Satellitenbildkacheln mit einem rechteckigen Bereich, in den das Polygon passt.  Darin m√ºssen Sie nach B√§umen suchen.  Das Polygon oder Multipolygon wird als GeoJSON-Datei dargestellt.  In meinem Fall hatten die Kacheln ein PNG-Format mit einer Gr√∂√üe von 256 x 256 Pixel in Echtfarbe.  (leider ohne IR) Nummerierung der Kacheln in der Form /zoom/x/y.png. <br><br>  Es ist garantiert, dass alle Kacheln im Set aus Satellitenbildern stammen, die ungef√§hr zur gleichen Jahreszeit (Sp√§tfr√ºhling - Fr√ºhherbst, abh√§ngig vom Klima einer bestimmten Region) und an einem Tag in einem √§hnlichen Winkel zur Oberfl√§che aufgenommen wurden, an dem eine leichte Wolkendecke zul√§ssig war. <br><br><h3>  Datenaufbereitung </h3><br>  Da die Fl√§che des gew√ºnschten Polygons kleiner sein kann als diese rechteckige Fl√§che, m√ºssen zun√§chst die Kacheln ausgeschlossen werden, die √ºber die Grenzen des Polygons hinausgehen.  Zu diesem Zweck wurde ein einfaches Skript geschrieben, das die erforderlichen Kacheln aus dem GeoJSON-Dateipolygon ausw√§hlt.  Es funktioniert wie folgt.  Zun√§chst werden die Koordinaten aller Eckpunkte des Polygons in Kachelnummern <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">konvertiert</a> und einem Array hinzugef√ºgt.  Es gibt auch einen Versatz relativ zum Ursprung.  Zur visuellen Pr√ºfung wird ein Bild erzeugt, bei dem ein Pixel einer Kachel entspricht.  Das Polygon im Bild wird bereits unter Ber√ºcksichtigung des Versatzes mit PIL ausgef√ºllt.  Danach wird das Bild in ein Array √ºbertragen, aus dem die erforderlichen Kacheln ausgew√§hlt werden, die in das Polygon fallen. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image, ImageDraw <span class="hljs-comment"><span class="hljs-comment"># . . . #             . img = Image.new("L", (x, y), 0) draw = ImageDraw.Draw(img) #    .     . points ‚Äî  . draw.polygon(points, fill=255) img.show() mask = numpy.array(img) # . . .</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/-m/mk/ai/-mmkai6lmgfie8hnipom9rgjvxk.jpeg"><br>  <i>Visuelles Ergebnis der Konvertierung eines Polygons in eine Reihe von Kacheln</i> <br><br><h3>  Netzwerkmodell </h3><br>  Um die Probleme der Bildsegmentierung zu l√∂sen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gibt es</a> eine Reihe von Modellen f√ºr Faltungs-Neuronale Netze.  Ich habe mich f√ºr <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">U-Net entschieden</a> , das sich bei der Segmentierung von Bin√§rbildern bew√§hrt hat.  Die U-Net-Architektur besteht aus den sogenannten Kontraktions- und Expansionspfaden, die durch Probros in den entsprechenden Gr√∂√üenstufen verbunden sind. Sie reduzieren zuerst die Aufl√∂sung des Bildes und erh√∂hen es dann, indem sie es zuvor mit den Bilddaten kombinieren und andere Ebenen durchlaufen Faltung.  Somit wirkt das Netzwerk als eine Art Filter.  Das Komprimieren und Dekomprimieren von Bl√∂cken wird als Satz von Bl√∂cken einer bestimmten Dimension dargestellt.  Und jeder Block besteht aus grundlegenden Operationen: Faltung, ReLu und Max-Pooling.  Es gibt Implementierungen des U-Net-Modells f√ºr Keras, Tensorflow, Caffe und PyTorch.  Ich habe Keras benutzt. <br><br><h3>  Trainingsset erstellen </h3><br>  Um dieses Unet-Modell zu lernen, ben√∂tigen Sie Bilder.  Das erste, was mir in den Sinn kam, war die Idee, OpenStreetMap-Daten zu nehmen und darauf basierend Masken f√ºr das Training zu generieren.  Aber wie sich in meinem Fall herausstellte, l√§sst die Genauigkeit der Polygone, die ich ben√∂tige, zu w√ºnschen √ºbrig.  Ich brauchte auch die Anwesenheit einzelner B√§ume, die nicht immer kartiert sind.  Deshalb musste ich ein solches Unternehmen aufgeben.  Es ist jedoch erw√§hnenswert, dass dieser Ansatz f√ºr andere Objekte wie Stra√üen oder Geb√§ude <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">effektiv sein kann</a> . <br><br><img src="https://habrastorage.org/webt/rc/po/v0/rcpov0qaluuosozh7isz8z-ya1y.png"><br><br>  Da die Idee, automatisch ein Trainingsmuster basierend auf OSM-Daten zu generieren, aufgegeben werden musste, habe ich beschlossen, einen kleinen Bereich manuell zu markieren.  Zu diesem Zweck habe ich den JOSM-Editor verwendet, in dem ich verf√ºgbare Gel√§ndebilder als Substrat verwendet habe, das ich auf einem lokalen Server platziert habe.  Dann tauchte ein anderes Problem auf - ich fand keine Gelegenheit, die Anzeige des Kachelrasters mit normalen JOSM-Werkzeugen einzuschalten.  Aus diesem Grund haben einige einfache Zeilen in .htaccess auf demselben Server aus einem anderen Verzeichnis eine leere Kachel mit einem Pixelrand f√ºr jede Anforderung des Formulars grid_tile / z / x / y.png ausgegeben und JOSM eine solche spontane Ebene hinzugef√ºgt.  So ein Fahrrad. <br><br><img src="https://habrastorage.org/webt/xe/ir/za/xeirzah3mp-kqtbpp0vvayzxhyi.png"><br><br>  Zuerst habe ich ungef√§hr 30 Kacheln markiert.  Mit einem Grafiktablett und dem ‚ÄûSchnellzeichnungsmodus‚Äú in JOSM dauerte es nicht lange.  Ich habe verstanden, dass eine solche Menge f√ºr ein vollwertiges Training nicht ausreicht, aber ich habe mich entschlossen, damit zu beginnen.  Dar√ºber hinaus wird das Training mit so vielen Daten schnell genug sein. <br><br><h3>  Training und erstes Ergebnis </h3><br>  Das Netzwerk wurde f√ºr 15 Epochen ohne vorherige Datenerweiterung trainiert.  Die Grafik zeigt die Werte f√ºr Verluste und Genauigkeit der Testprobe: <br><br><img src="https://habrastorage.org/webt/ln/h-/pk/lnh-pkjwqz-eziqh4gafem781og.png"><br><br>  Das Ergebnis der Erkennung von Bildern, die sich weder im Training noch in der Testprobe befanden, erwies sich als recht vern√ºnftig: <br><br> <a href=""><img src="https://habrastorage.org/webt/ao/kr/ed/aokredzarfej2cczep8ir7facx4.png"></a> <br><br>  Nach einer gr√ºndlicheren Untersuchung der Ergebnisse wurden einige Probleme deutlich.  Viele Fehler befanden sich in den Schattenbereichen der Bilder - das Netzwerk fand entweder B√§ume im Schatten, wo sie nicht waren, oder genau das Gegenteil.  Dies wurde erwartet, da das Trainingsset nur wenige solcher Beispiele enthielt.  Ich hatte aber nicht erwartet, dass einige Teile der Wasseroberfl√§che und dunkle D√§cher des Metallprofils (vermutlich) als B√§ume erkannt w√ºrden.  Es gab auch Ungenauigkeiten bei Rasenfl√§chen.  Es wurde beschlossen, die Stichprobe zu verbessern, indem eine gr√∂√üere Anzahl von Bildern mit kontroversen Abschnitten hinzugef√ºgt wurde, sodass die Trainingsstichprobe fast verdoppelt wurde. <br><br><h3>  Datenerweiterung </h3><br>  Um die Datenmenge weiter zu erh√∂hen, habe ich beschlossen, das Bild in einem beliebigen Winkel zu drehen.  Zun√§chst habe ich das Standardmodul keras.preprocessing.image.ImageDataGenerator ausprobiert.  Wenn Sie unter Beibehaltung des Ma√üstabs drehen, verbleiben leere Bereiche an den Bildr√§ndern, deren F√ºllung durch den Parameter <i>fill_mode festgelegt</i> wird.  Sie k√∂nnen diese Bereiche einfach mit Farbe f√ºllen, indem Sie sie in <i>cval angeben</i> . Ich wollte jedoch eine vollst√§ndige Drehung, in der Hoffnung, dass die Auswahl vollst√§ndiger ist, und habe den Generator selbst implementiert.  Dadurch konnte die Gr√∂√üe um mehr als das Zehnfache erh√∂ht werden. <br><br><img src="https://habrastorage.org/webt/oa/i9/hr/oai9hrvaxhigjgwp5xatijyht5u.png"><br>  <i>fill_mode = am n√§chsten</i> <br><br>  Mein Datengenerator klebt vier benachbarte Kacheln in eine einzige Quellkachel mit einer Gr√∂√üe von 512 x 512 Pixel.  Der Drehwinkel wird zuf√§llig ausgew√§hlt, wobei ber√ºcksichtigt wird, dass die zul√§ssigen Intervalle von x und y f√ºr die Mitte der resultierenden Kachel berechnet werden, in der er nicht √ºber die urspr√ºngliche Kachel hinausgeht.  Die Koordinaten des Zentrums werden unter Ber√ºcksichtigung der zul√§ssigen Intervalle zuf√§llig ausgew√§hlt.  Nat√ºrlich gelten alle diese Transformationen f√ºr das Kachelmaskenpaar.  All dies wird f√ºr verschiedene Gruppen benachbarter Kacheln wiederholt.  Aus einer Gruppe k√∂nnen Sie mehr als ein Dutzend Kacheln mit verschiedenen Abschnitten des Gel√§ndes erhalten, die in verschiedenen Winkeln gedreht werden. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       # image ‚Äî  , center (x, y) ‚Äî   , a ‚Äî   , width  height ‚Äî   . shape = image.shape[:2] matrix = cv2.getRotationMatrix2D( center=center, angle=a, scale=1 ) image = cv2.warpAffine( src=image, M=matrix, dsize=shape ) x = int( center[0] - width/2 ) y = int( center[1] - height/2 ) image = image[ y:y+height, x:x+width ] # </span></span></code> </pre><br><img src="https://habrastorage.org/webt/zy/mo/po/zymopoykrdt5ezki8ojru1te-di.png"><br>  <i>Ein Beispiel f√ºr das Ergebnis des Generators</i> <br><br><h3>  Lernen mit mehr Daten </h3><br>  Infolgedessen betrug die Gr√∂√üe des Trainingsmusters 1881 Bilder, und ich erh√∂hte auch die Anzahl der Epochen auf 30: <br><br><img src="https://habrastorage.org/webt/yh/ja/k9/yhjak9qcoyqb1lr64hhbet9d8sc.png"><br><br>  Nach dem Training des Modells mit einem neuen Datenvolumen wurden keine Probleme mit der fehlerhaften Segmentierung von D√§chern und Wasser mehr festgestellt.  Es war √ºberhaupt nicht m√∂glich, Fehler im Schatten loszuwerden, aber sie wurden im Auge weniger, ebenso wie Fehler bei Rasenfl√§chen.  Es ist zu beachten, dass die √ºberwiegende Mehrheit der Fehler darin besteht, dass das Netzwerk B√§ume dort sieht, wo sie nicht sind, und nicht umgekehrt.  Die erreichte Genauigkeit kann verbessert werden, indem Satellitenbilder mit einer gro√üen Anzahl von Kan√§len verwendet und die Netzwerkarchitektur f√ºr eine bestimmte Aufgabe ge√§ndert werden. <br><br><img src="https://habrastorage.org/webt/er/i-/bk/eri-bkryiex4pidpmej4ybr_hyk.png"><br><br>  Im Allgemeinen war ich mit dem Ergebnis der geleisteten Arbeit zufrieden, und der geschulte Netzwerkprototyp wurde angewendet, um echte Probleme zu l√∂sen.  Zum Beispiel die Berechnung der Dichte von Waldbest√§nden in Moskau: <br><br> <a href=""><img src="https://habrastorage.org/webt/3_/7a/dr/3_7adrfwb3ouixjq35wtn2lim7c.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de421277/">https://habr.com/ru/post/de421277/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de421265/index.html">Monster nach den Ferien: AMD Threadripper 2990WX 32-Core und 2950X 16-Core (Teil 2)</a></li>
<li><a href="../de421267/index.html">Semipassive Computer-Netzteilk√ºhlung</a></li>
<li><a href="../de421269/index.html">Das am amerikanischen Flughafen installierte Gesichtserkennungssystem half, den Angreifer zu fangen</a></li>
<li><a href="../de421271/index.html">Eine Auswahl n√ºtzlicher Materialien zu Azure. Teil 2 - Kurse</a></li>
<li><a href="../de421275/index.html">Was ich nach dem Verkauf von zwei Startups in 12 Monaten verstanden habe</a></li>
<li><a href="../de421279/index.html">Zus√§tzliche Sicherheitssoftware f√ºr NAS</a></li>
<li><a href="../de421281/index.html">Antworten des technischen Supports von 3CX: Installieren Sie Ihr eigenes Logo auf dem Display des IP-Telefons</a></li>
<li><a href="../de421283/index.html">Das Buch √ºber "Paragraph" √ºber Habr√©. Kapitel Eins: Der Wachmann-Wissenschaftler</a></li>
<li><a href="../de421285/index.html">Optische Tracker: ASEF und MOSSE</a></li>
<li><a href="../de421287/index.html">Mondsteine ‚Äã‚Äãaus einem Solarofen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
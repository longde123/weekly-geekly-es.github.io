<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩‍🚀 🕵🏻 🕟 Segmentierung von Satellitenbildern am Beispiel der Baumerkennung 🚫 🛴 🎿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die automatische Erkennung von Satelliten- oder Luftbildern ist der vielversprechendste Weg, um Informationen über die Position verschiedener Objekte ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Segmentierung von Satellitenbildern am Beispiel der Baumerkennung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/421277/"><img src="https://habrastorage.org/webt/29/oa/ku/29oakuyg7l3gw-gqre-xvdxr3s0.jpeg" alt="Bild"><br><br>  Die automatische Erkennung von Satelliten- oder Luftbildern ist der vielversprechendste Weg, um Informationen über die Position verschiedener Objekte auf dem Boden zu erhalten.  Die Ablehnung der manuellen Bildsegmentierung ist besonders wichtig, wenn große Bereiche der Erdoberfläche in kurzer Zeit bearbeitet werden sollen. <br><br>  Vor kurzem hatte ich die Möglichkeit, theoretische Fähigkeiten anzuwenden und mich im Bereich des maschinellen Lernens in einem realen Bildsegmentierungsprojekt zu versuchen.  Ziel des Projekts ist die Erkennung von Waldbeständen, nämlich Baumkronen in hochauflösenden Satellitenbildern.  Unter dem Schnitt werde ich meine Erfahrungen und Ergebnisse teilen. <br><a name="habracut"></a><br>  Wenn es um die Bildverarbeitung geht, kann die Segmentierung wie folgt definiert werden - dies ist das Vorhandensein charakteristischer Bereiche auf dem Bild, die in diesem Merkmalsraum gleichermaßen beschrieben werden. <br><br>  Unterscheiden Sie zwischen Helligkeit, Kontur, Textur und semantischer Segmentierung. <br><br>  Semantische (oder semantische) Bildsegmentierung dient zum Hervorheben von Bereichen auf dem Bild, von denen jeder einem bestimmten Attribut entspricht.  Im Allgemeinen sind Probleme der semantischen Segmentierung schwer zu algorithmisieren, so dass Faltungs-Neuronale Netze, die gute Ergebnisse zeigen, derzeit häufig für die Bildsegmentierung verwendet werden. <br><br><h3>  Erklärung des Problems </h3><br>  Das Problem der binären Segmentierung wird gelöst - Farbbilder (hochauflösende Satellitenbilder) werden dem Eingang des neuronalen Netzwerks zugeführt, auf dem die Bereiche von Pixeln hervorgehoben werden müssen, die zu denselben Klassenbäumen gehören. <br><br><h3>  Ausgangsdaten </h3><br>  Zu meiner Verfügung gab es eine Reihe von Satellitenbildkacheln mit einem rechteckigen Bereich, in den das Polygon passt.  Darin müssen Sie nach Bäumen suchen.  Das Polygon oder Multipolygon wird als GeoJSON-Datei dargestellt.  In meinem Fall hatten die Kacheln ein PNG-Format mit einer Größe von 256 x 256 Pixel in Echtfarbe.  (leider ohne IR) Nummerierung der Kacheln in der Form /zoom/x/y.png. <br><br>  Es ist garantiert, dass alle Kacheln im Set aus Satellitenbildern stammen, die ungefähr zur gleichen Jahreszeit (Spätfrühling - Frühherbst, abhängig vom Klima einer bestimmten Region) und an einem Tag in einem ähnlichen Winkel zur Oberfläche aufgenommen wurden, an dem eine leichte Wolkendecke zulässig war. <br><br><h3>  Datenaufbereitung </h3><br>  Da die Fläche des gewünschten Polygons kleiner sein kann als diese rechteckige Fläche, müssen zunächst die Kacheln ausgeschlossen werden, die über die Grenzen des Polygons hinausgehen.  Zu diesem Zweck wurde ein einfaches Skript geschrieben, das die erforderlichen Kacheln aus dem GeoJSON-Dateipolygon auswählt.  Es funktioniert wie folgt.  Zunächst werden die Koordinaten aller Eckpunkte des Polygons in Kachelnummern <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">konvertiert</a> und einem Array hinzugefügt.  Es gibt auch einen Versatz relativ zum Ursprung.  Zur visuellen Prüfung wird ein Bild erzeugt, bei dem ein Pixel einer Kachel entspricht.  Das Polygon im Bild wird bereits unter Berücksichtigung des Versatzes mit PIL ausgefüllt.  Danach wird das Bild in ein Array übertragen, aus dem die erforderlichen Kacheln ausgewählt werden, die in das Polygon fallen. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image, ImageDraw <span class="hljs-comment"><span class="hljs-comment"># . . . #             . img = Image.new("L", (x, y), 0) draw = ImageDraw.Draw(img) #    .     . points —  . draw.polygon(points, fill=255) img.show() mask = numpy.array(img) # . . .</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/-m/mk/ai/-mmkai6lmgfie8hnipom9rgjvxk.jpeg"><br>  <i>Visuelles Ergebnis der Konvertierung eines Polygons in eine Reihe von Kacheln</i> <br><br><h3>  Netzwerkmodell </h3><br>  Um die Probleme der Bildsegmentierung zu lösen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gibt es</a> eine Reihe von Modellen für Faltungs-Neuronale Netze.  Ich habe mich für <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">U-Net entschieden</a> , das sich bei der Segmentierung von Binärbildern bewährt hat.  Die U-Net-Architektur besteht aus den sogenannten Kontraktions- und Expansionspfaden, die durch Probros in den entsprechenden Größenstufen verbunden sind. Sie reduzieren zuerst die Auflösung des Bildes und erhöhen es dann, indem sie es zuvor mit den Bilddaten kombinieren und andere Ebenen durchlaufen Faltung.  Somit wirkt das Netzwerk als eine Art Filter.  Das Komprimieren und Dekomprimieren von Blöcken wird als Satz von Blöcken einer bestimmten Dimension dargestellt.  Und jeder Block besteht aus grundlegenden Operationen: Faltung, ReLu und Max-Pooling.  Es gibt Implementierungen des U-Net-Modells für Keras, Tensorflow, Caffe und PyTorch.  Ich habe Keras benutzt. <br><br><h3>  Trainingsset erstellen </h3><br>  Um dieses Unet-Modell zu lernen, benötigen Sie Bilder.  Das erste, was mir in den Sinn kam, war die Idee, OpenStreetMap-Daten zu nehmen und darauf basierend Masken für das Training zu generieren.  Aber wie sich in meinem Fall herausstellte, lässt die Genauigkeit der Polygone, die ich benötige, zu wünschen übrig.  Ich brauchte auch die Anwesenheit einzelner Bäume, die nicht immer kartiert sind.  Deshalb musste ich ein solches Unternehmen aufgeben.  Es ist jedoch erwähnenswert, dass dieser Ansatz für andere Objekte wie Straßen oder Gebäude <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">effektiv sein kann</a> . <br><br><img src="https://habrastorage.org/webt/rc/po/v0/rcpov0qaluuosozh7isz8z-ya1y.png"><br><br>  Da die Idee, automatisch ein Trainingsmuster basierend auf OSM-Daten zu generieren, aufgegeben werden musste, habe ich beschlossen, einen kleinen Bereich manuell zu markieren.  Zu diesem Zweck habe ich den JOSM-Editor verwendet, in dem ich verfügbare Geländebilder als Substrat verwendet habe, das ich auf einem lokalen Server platziert habe.  Dann tauchte ein anderes Problem auf - ich fand keine Gelegenheit, die Anzeige des Kachelrasters mit normalen JOSM-Werkzeugen einzuschalten.  Aus diesem Grund haben einige einfache Zeilen in .htaccess auf demselben Server aus einem anderen Verzeichnis eine leere Kachel mit einem Pixelrand für jede Anforderung des Formulars grid_tile / z / x / y.png ausgegeben und JOSM eine solche spontane Ebene hinzugefügt.  So ein Fahrrad. <br><br><img src="https://habrastorage.org/webt/xe/ir/za/xeirzah3mp-kqtbpp0vvayzxhyi.png"><br><br>  Zuerst habe ich ungefähr 30 Kacheln markiert.  Mit einem Grafiktablett und dem „Schnellzeichnungsmodus“ in JOSM dauerte es nicht lange.  Ich habe verstanden, dass eine solche Menge für ein vollwertiges Training nicht ausreicht, aber ich habe mich entschlossen, damit zu beginnen.  Darüber hinaus wird das Training mit so vielen Daten schnell genug sein. <br><br><h3>  Training und erstes Ergebnis </h3><br>  Das Netzwerk wurde für 15 Epochen ohne vorherige Datenerweiterung trainiert.  Die Grafik zeigt die Werte für Verluste und Genauigkeit der Testprobe: <br><br><img src="https://habrastorage.org/webt/ln/h-/pk/lnh-pkjwqz-eziqh4gafem781og.png"><br><br>  Das Ergebnis der Erkennung von Bildern, die sich weder im Training noch in der Testprobe befanden, erwies sich als recht vernünftig: <br><br> <a href=""><img src="https://habrastorage.org/webt/ao/kr/ed/aokredzarfej2cczep8ir7facx4.png"></a> <br><br>  Nach einer gründlicheren Untersuchung der Ergebnisse wurden einige Probleme deutlich.  Viele Fehler befanden sich in den Schattenbereichen der Bilder - das Netzwerk fand entweder Bäume im Schatten, wo sie nicht waren, oder genau das Gegenteil.  Dies wurde erwartet, da das Trainingsset nur wenige solcher Beispiele enthielt.  Ich hatte aber nicht erwartet, dass einige Teile der Wasseroberfläche und dunkle Dächer des Metallprofils (vermutlich) als Bäume erkannt würden.  Es gab auch Ungenauigkeiten bei Rasenflächen.  Es wurde beschlossen, die Stichprobe zu verbessern, indem eine größere Anzahl von Bildern mit kontroversen Abschnitten hinzugefügt wurde, sodass die Trainingsstichprobe fast verdoppelt wurde. <br><br><h3>  Datenerweiterung </h3><br>  Um die Datenmenge weiter zu erhöhen, habe ich beschlossen, das Bild in einem beliebigen Winkel zu drehen.  Zunächst habe ich das Standardmodul keras.preprocessing.image.ImageDataGenerator ausprobiert.  Wenn Sie unter Beibehaltung des Maßstabs drehen, verbleiben leere Bereiche an den Bildrändern, deren Füllung durch den Parameter <i>fill_mode festgelegt</i> wird.  Sie können diese Bereiche einfach mit Farbe füllen, indem Sie sie in <i>cval angeben</i> . Ich wollte jedoch eine vollständige Drehung, in der Hoffnung, dass die Auswahl vollständiger ist, und habe den Generator selbst implementiert.  Dadurch konnte die Größe um mehr als das Zehnfache erhöht werden. <br><br><img src="https://habrastorage.org/webt/oa/i9/hr/oai9hrvaxhigjgwp5xatijyht5u.png"><br>  <i>fill_mode = am nächsten</i> <br><br>  Mein Datengenerator klebt vier benachbarte Kacheln in eine einzige Quellkachel mit einer Größe von 512 x 512 Pixel.  Der Drehwinkel wird zufällig ausgewählt, wobei berücksichtigt wird, dass die zulässigen Intervalle von x und y für die Mitte der resultierenden Kachel berechnet werden, in der er nicht über die ursprüngliche Kachel hinausgeht.  Die Koordinaten des Zentrums werden unter Berücksichtigung der zulässigen Intervalle zufällig ausgewählt.  Natürlich gelten alle diese Transformationen für das Kachelmaskenpaar.  All dies wird für verschiedene Gruppen benachbarter Kacheln wiederholt.  Aus einer Gruppe können Sie mehr als ein Dutzend Kacheln mit verschiedenen Abschnitten des Geländes erhalten, die in verschiedenen Winkeln gedreht werden. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       # image —  , center (x, y) —   , a —   , width  height —   . shape = image.shape[:2] matrix = cv2.getRotationMatrix2D( center=center, angle=a, scale=1 ) image = cv2.warpAffine( src=image, M=matrix, dsize=shape ) x = int( center[0] - width/2 ) y = int( center[1] - height/2 ) image = image[ y:y+height, x:x+width ] # </span></span></code> </pre><br><img src="https://habrastorage.org/webt/zy/mo/po/zymopoykrdt5ezki8ojru1te-di.png"><br>  <i>Ein Beispiel für das Ergebnis des Generators</i> <br><br><h3>  Lernen mit mehr Daten </h3><br>  Infolgedessen betrug die Größe des Trainingsmusters 1881 Bilder, und ich erhöhte auch die Anzahl der Epochen auf 30: <br><br><img src="https://habrastorage.org/webt/yh/ja/k9/yhjak9qcoyqb1lr64hhbet9d8sc.png"><br><br>  Nach dem Training des Modells mit einem neuen Datenvolumen wurden keine Probleme mit der fehlerhaften Segmentierung von Dächern und Wasser mehr festgestellt.  Es war überhaupt nicht möglich, Fehler im Schatten loszuwerden, aber sie wurden im Auge weniger, ebenso wie Fehler bei Rasenflächen.  Es ist zu beachten, dass die überwiegende Mehrheit der Fehler darin besteht, dass das Netzwerk Bäume dort sieht, wo sie nicht sind, und nicht umgekehrt.  Die erreichte Genauigkeit kann verbessert werden, indem Satellitenbilder mit einer großen Anzahl von Kanälen verwendet und die Netzwerkarchitektur für eine bestimmte Aufgabe geändert werden. <br><br><img src="https://habrastorage.org/webt/er/i-/bk/eri-bkryiex4pidpmej4ybr_hyk.png"><br><br>  Im Allgemeinen war ich mit dem Ergebnis der geleisteten Arbeit zufrieden, und der geschulte Netzwerkprototyp wurde angewendet, um echte Probleme zu lösen.  Zum Beispiel die Berechnung der Dichte von Waldbeständen in Moskau: <br><br> <a href=""><img src="https://habrastorage.org/webt/3_/7a/dr/3_7adrfwb3ouixjq35wtn2lim7c.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de421277/">https://habr.com/ru/post/de421277/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de421265/index.html">Monster nach den Ferien: AMD Threadripper 2990WX 32-Core und 2950X 16-Core (Teil 2)</a></li>
<li><a href="../de421267/index.html">Semipassive Computer-Netzteilkühlung</a></li>
<li><a href="../de421269/index.html">Das am amerikanischen Flughafen installierte Gesichtserkennungssystem half, den Angreifer zu fangen</a></li>
<li><a href="../de421271/index.html">Eine Auswahl nützlicher Materialien zu Azure. Teil 2 - Kurse</a></li>
<li><a href="../de421275/index.html">Was ich nach dem Verkauf von zwei Startups in 12 Monaten verstanden habe</a></li>
<li><a href="../de421279/index.html">Zusätzliche Sicherheitssoftware für NAS</a></li>
<li><a href="../de421281/index.html">Antworten des technischen Supports von 3CX: Installieren Sie Ihr eigenes Logo auf dem Display des IP-Telefons</a></li>
<li><a href="../de421283/index.html">Das Buch über "Paragraph" über Habré. Kapitel Eins: Der Wachmann-Wissenschaftler</a></li>
<li><a href="../de421285/index.html">Optische Tracker: ASEF und MOSSE</a></li>
<li><a href="../de421287/index.html">Mondsteine ​​aus einem Solarofen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
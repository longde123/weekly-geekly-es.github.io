<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§ûüèΩ üë©üèΩ‚Äçüöí üë®üèª‚Äçüè´ KI, praktischer Kurs. √úbersicht √ºber neuronale Netze zur Bildklassifizierung üé© ‚õ¥Ô∏è üîü</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dieser Artikel bietet einen zug√§nglichen theoretischen √úberblick √ºber Faltungs-Neuronale Netze (CNN) und erl√§utert deren Anwendung auf das Bildklassif...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>KI, praktischer Kurs. √úbersicht √ºber neuronale Netze zur Bildklassifizierung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/415811/">  Dieser Artikel bietet einen zug√§nglichen theoretischen √úberblick √ºber Faltungs-Neuronale Netze (CNN) und erl√§utert deren Anwendung auf das Bildklassifizierungsproblem. <br><br><img src="https://habrastorage.org/webt/_d/ve/hi/_dvehi4kbgauxndfn56s7-tmtku.jpeg"><br><a name="habracut"></a><br><h2>  <font color="#0071c5">Gemeinsamer Ansatz: Kein tiefes Lernen</font> </h2><br>  Der Begriff "Bildverarbeitung" bezieht sich auf eine breite Klasse von Aufgaben, f√ºr die die Eingabedaten Bilder sind, und die Ausgabe kann entweder Bilder oder S√§tze von zugeh√∂rigen charakteristischen Merkmalen sein.  Es gibt viele Optionen: Klassifizierung, Segmentierung, Annotation, Objekterkennung usw. In diesem Artikel untersuchen wir die Klassifizierung von Bildern, nicht nur, weil dies die einfachste Aufgabe ist, sondern auch, weil sie vielen anderen Aufgaben zugrunde liegt. <br><br>  Der allgemeine Ansatz zur Klassifizierung von Bildern besteht aus den folgenden zwei Schritten: <br><br><ol><li>  Erzeugung wesentlicher Merkmale des Bildes. </li><li>  Klassifizierung eines Bildes anhand seiner Attribute. </li></ol><br>  Die √ºbliche Abfolge von Vorg√§ngen verwendet einfache Modelle wie MultiLayer Perceptron (MLP), Support Vector Machine (SVM), die Methode der n√§chsten Nachbarn und die logistische Regression zus√§tzlich zu manuell erstellten Funktionen.  Attribute werden unter Verwendung verschiedener Transformationen (z. B. Graustufen- und Schwellenwerterkennung) und Deskriptoren erzeugt, z. B. Histogramm orientierter Gradienten ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HOG</a> ) oder skaleninvarianter Merkmalstransformationstransformationen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SIFT</a> ) und usw. <br><br>  Die Hauptbeschr√§nkung allgemein anerkannter Methoden besteht in der Teilnahme eines Experten, der einen Satz und eine Abfolge von Schritten zum Generieren von Merkmalen ausw√§hlt. <br><br>  Im Laufe der Zeit wurde festgestellt, dass die meisten Techniken zum Erzeugen von Merkmalen mithilfe von Kerneln (Filtern) verallgemeinert werden k√∂nnen - kleinen Matrizen (normalerweise 5 √ó 5 gro√ü), die Windungen der Originalbilder sind.  Die Faltung kann als ein sequentieller zweistufiger Prozess betrachtet werden: <br><br><ol><li> F√ºhren Sie denselben festen Kern √ºber das gesamte Quellbild. </li><li>  Berechnen Sie bei jedem Schritt das Skalarprodukt des Kernels und das Originalbild an der aktuellen Position des Kernels. </li></ol><br>  Das Ergebnis der Faltung des Bildes und des Kernels wird als Feature-Map bezeichnet. <br>  Eine mathematisch strengere Erkl√§rung findet sich im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">entsprechenden Kapitel des</a> k√ºrzlich ver√∂ffentlichten Buches Deep Learning von I. Goodfellow, I. Benjio und A. Courville. <br><br><img src="https://habrastorage.org/webt/kw/lm/rd/kwlmrdg1y8wsniz94riol_8fiie.png"><br>  <i>Der Prozess der Faltung des Kerns (dunkelgr√ºn) mit dem Originalbild (gr√ºn), wodurch eine Merkmalskarte erhalten wird (gelb).</i> <br><br>  Ein einfaches Beispiel f√ºr eine Transformation, die mit Filtern durchgef√ºhrt werden kann, ist das Verwischen eines Bildes.  Nehmen Sie einen Filter, der aus allen Einheiten besteht.  Es berechnet den vom Filter bestimmten Durchschnitt der Nachbarschaft.  In diesem Fall ist die Nachbarschaft ein quadratischer Abschnitt, aber sie kann kreuzf√∂rmig sein oder was auch immer.  Die Mittelung f√ºhrt zum Verlust von Informationen √ºber die genaue Position von Objekten, wodurch das gesamte Bild unscharf wird.  Eine √§hnliche intuitive Erkl√§rung kann f√ºr jeden manuell erstellten Filter gegeben werden. <br><br><img src="https://habrastorage.org/webt/5t/ud/g7/5tudg7ebng4ocb6jdc1-1alsqpo.png"><br>  <i>Das Ergebnis der Faltung des Bildes des Geb√§udes der Harvard University mit drei verschiedenen Kernen.</i> <br><br><h2>  <font color="#0071c5">Faltungsneurale Netze</font> </h2><br>  Der Faltungsansatz zur Bildklassifizierung weist eine Reihe wesentlicher Nachteile auf: <br><br><ul><li>  Ein mehrstufiger Prozess anstelle einer End-to-End-Sequenz. </li><li>  Filter sind ein gro√üartiges Verallgemeinerungswerkzeug, aber sie sind feste Matrizen.  Wie w√§hlt man Gewichte in Filtern? </li></ul><br>  Gl√ºcklicherweise wurden lernbare Filter erfunden, die das Grundprinzip von CNN darstellen.  Das Prinzip ist einfach: Wir werden die Filter trainieren, die auf die Beschreibung von Bildern angewendet werden, um ihre Aufgabe bestm√∂glich zu erf√ºllen. <br><br>  CNN hat keinen Erfinder, aber einer der ersten F√§lle ihrer Anwendung ist LeNet-5 * in der Arbeit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚Äû</a> Gradientenbasiertes Lernen f√ºr die Dokumentenerkennung‚Äú von I. LeCun und anderen Autoren. <br><br>  CNN t√∂tet zwei Fliegen mit einer Klappe: Es ist keine vorl√§ufige Definition von Filtern erforderlich, und der Lernprozess wird von Ende zu Ende.  Eine typische CNN-Architektur besteht aus folgenden Teilen: <br><br><ul><li>  Faltungsschichten </li><li>  Unterabtastungsebenen </li><li>  Dichte (vollst√§ndig verbundene) Schichten </li></ul><br>  Lassen Sie uns jeden Teil genauer betrachten. <br><br><h3>  <font color="#0071c5">Faltungsschichten</font> </h3><br>  Die Faltungsschicht ist das Hauptstrukturelement von CNN.  Die Faltungsschicht weist eine Reihe von Eigenschaften auf: <br>  <i>Lokale (sp√§rliche) Konnektivit√§t</i> .  In dichten Schichten ist jedes Neuron mit jedem Neuron der vorherigen Schicht verbunden (daher wurden sie als dicht bezeichnet).  In der Faltungsschicht ist jedes Neuron nur mit einem kleinen Teil der Neuronen der vorherigen Schicht verbunden. <br><br><img src="https://habrastorage.org/webt/nl/1a/6t/nl1a6t8bvbzna0rv_y3qjv_gsua.png"><br>  <i>Ein Beispiel f√ºr ein eindimensionales neuronales Netzwerk.</i>  <i>(links) Verbindung von Neuronen in einem typischen dichten Netzwerk, (rechts) Charakterisierung der lokalen Konnektivit√§t, die der Faltungsschicht innewohnt.</i>  <i>Bilder von I. Goodfellow und anderen von Deep Learning</i> <br><br>  <i>Die Gr√∂√üe des Bereichs, mit dem das Neuron verbunden</i> ist, wird als Gr√∂√üe des Filters bezeichnet (die L√§nge des Filters bei eindimensionalen Daten, z. B. Zeitreihen, oder die Breite / H√∂he bei zweidimensionalen Daten, z. B. Bildern).  In der Abbildung rechts betr√§gt die Filtergr√∂√üe 3. Die <i>Gewichte, mit denen die Verbindung hergestellt</i> wird, werden als Filter bezeichnet (ein Vektor bei eindimensionalen Daten und eine Matrix f√ºr zweidimensionale Daten).  <i>Der Schritt ist die Entfernung, um die sich der Filter √ºber die Daten bewegt</i> (in der Abbildung rechts ist der Schritt 1).  Die Idee der lokalen Konnektivit√§t ist nichts anderes als ein Kernel, der einen Schritt bewegt.  Jedes Neuron auf Faltungsebene repr√§sentiert und implementiert eine bestimmte Position des Kerns, der entlang des Originalbildes gleitet. <br><br><img src="https://habrastorage.org/webt/nu/we/gf/nuwegftvmoigtcdz2mlt0xwmm5g.png"><br>  <i>Zwei benachbarte eindimensionale Faltungsschichten</i> <br><br>  Eine weitere wichtige Eigenschaft ist die sogenannte <i>Suszeptibilit√§tszone</i> .  Es spiegelt die Anzahl der Positionen des urspr√ºnglichen Signals wider, die das aktuelle Neuron ‚Äûsehen‚Äú kann.  Beispielsweise ist die in der Figur gezeigte Suszeptibilit√§tszone der ersten Netzwerkschicht gleich der Gr√∂√üe von Filter 3, da jedes Neuron nur mit drei Neuronen des urspr√ºnglichen Signals verbunden ist.  Auf der zweiten Schicht betr√§gt die Suszeptibilit√§tszone jedoch bereits 5, da das Neuron der zweiten Schicht drei Neuronen der ersten Schicht aggregiert, von denen jede eine Suszeptibilit√§tszone 3 aufweist. Mit zunehmender Tiefe w√§chst die Suszeptibilit√§tszone linear. <br><br>  <i>Gemeinsame Parameter</i> .  Denken Sie daran, dass bei der klassischen Bildverarbeitung derselbe Kern √ºber das gesamte Bild glitt.  Die gleiche Idee gilt hier.  Wir legen nur die Gr√∂√üe des Filter der Gewichte f√ºr eine Schicht fest und wenden diese Gewichte auf alle Neuronen in der Schicht an.  Dies entspricht dem Verschieben desselben Kerns im gesamten Bild.  Es kann sich aber die Frage stellen: Wie k√∂nnen wir mit so wenigen Parametern etwas lernen? <br><br><img src="https://habrastorage.org/webt/ue/qo/gi/ueqogixaqstaotlmnlfnjfn3dtc.png"><br>  <i>Dunkle Pfeile stehen f√ºr die gleichen Gewichte.</i>  <i>(links) Regul√§rer MLP, bei dem jeder Gewichtungsfaktor ein separater Parameter ist. (rechts) Ein Beispiel f√ºr die Parametertrennung, bei der mehrere Gewichtungsfaktoren denselben Trainingsparameter angeben</i> <br><br>  <i>Raumstruktur</i> .  Die Antwort auf diese Frage ist einfach: Wir werden mehrere Filter in einer Schicht trainieren!  Sie sind parallel zueinander angeordnet und bilden so eine neue Dimension. <br><br>  Wir machen eine kurze Pause und erl√§utern die Idee am Beispiel eines zweidimensionalen RGB-Bildes von 227 √ó 227. Beachten Sie, dass es sich hier um ein dreikanaliges Eingabebild handelt, was im Wesentlichen bedeutet, dass wir drei Eingabebilder oder dreidimensionale Eingabedaten haben. <br><br><img src="https://habrastorage.org/webt/ol/9r/ty/ol9rtyiz5s9btzfnldhf6bo_0wi.png"><br>  <i>Die r√§umliche Struktur des Eingabebildes</i> <br><br>  Wir werden die Abmessungen der Kan√§le als Bildtiefe betrachten (beachten Sie, dass dies nicht der Tiefe der neuronalen Netze entspricht, die der Anzahl der Netzwerkschichten entspricht).  Die Frage ist, wie der Kernel f√ºr diesen Fall bestimmt wird. <br><br><img src="https://habrastorage.org/webt/l6/pt/be/l6ptberff4a-rbz81bq-uxa-10w.png"><br>  <i>Ein Beispiel f√ºr einen zweidimensionalen Kern, bei dem es sich im Wesentlichen um eine dreidimensionale Matrix mit einer zus√§tzlichen Tiefenmessung handelt.</i>  <i>Dieser Filter ergibt eine Faltung mit dem Bild;</i>  <i>Das hei√üt, es gleitet √ºber das Bild im Raum und berechnet skalare Produkte</i> <br><br>  Die Antwort ist einfach, aber immer noch nicht offensichtlich: Wir werden den Kernel auch dreidimensional machen.  Die ersten beiden Dimensionen bleiben gleich (Kernbreite und -h√∂he), und die dritte Dimension entspricht immer der Tiefe der Eingabedaten. <br><br><img src="https://habrastorage.org/webt/yu/e3/xz/yue3xziqupgpwtmqvtit8ik5hos.png"><br>  <i>Ein Beispiel f√ºr einen r√§umlichen Faltungsschritt.</i>  <i>Das Ergebnis des Skalarprodukts des Filters und eines kleinen Teils des Bildes 5 √ó 5 √ó 3 (d. H. 5 √ó 5 √ó 5 + 1 = 76, die Dimension des Skalarprodukts + Verschiebung) ist eine Zahl</i> <br><br>  In diesem Fall wird der gesamte 5 √ó 5 √ó 3-Abschnitt des Originalbilds in eine Zahl umgewandelt, und das dreidimensionale Bild selbst wird in <i>eine Merkmalskarte</i> ( <i>Aktivierungskarte</i> ) umgewandelt.  Eine Feature-Map ist eine Reihe von Neuronen, von denen jede ihre eigene Funktion berechnet, wobei zwei oben diskutierte Grundprinzipien ber√ºcksichtigt werden: <i>lokale Konnektivit√§t</i> (jedes Neuron ist nur einem kleinen Teil der Eingabedaten zugeordnet) und <i>Trennung von Parametern</i> (alle Neuronen verwenden denselben Filter).  Im Idealfall ist diese Feature-Map dieselbe wie die, die bereits im Beispiel eines allgemein akzeptierten Netzwerks angetroffen wurde. Sie speichert die Ergebnisse der Faltung des Eingabebilds und des Filters. <br><br><img src="https://habrastorage.org/webt/iw/4w/qr/iw4wqr77vslpfjqblrgtjlxyxkw.png"><br>  <i>Merkmalskarte als Ergebnis der Faltung des Kerns mit allen r√§umlichen Positionen</i> <br><br>  Beachten Sie, dass die Tiefe der Feature-Map 1 betr√§gt, da wir nur einen Filter verwendet haben.  Aber nichts hindert uns daran, mehr Filter zu verwenden.  Beispiel: 6. Alle interagieren mit denselben Eingabedaten und arbeiten unabh√§ngig voneinander.  Gehen wir noch einen Schritt weiter und kombinieren diese Funktionskarten.  Ihre r√§umlichen Abmessungen sind gleich, da die Abmessungen der Filter gleich sind.  Somit k√∂nnen die zusammen gesammelten Merkmalskarten als eine neue dreidimensionale Matrix betrachtet werden, deren Tiefenabmessung durch Merkmalskarten aus verschiedenen Kernen dargestellt wird.  In diesem Sinne sind die RGB-Kan√§le des Eingabebildes nichts anderes als die drei urspr√ºnglichen Feature-Maps. <br><br><img src="https://habrastorage.org/webt/c8/f1/23/c8f123tp1nnbklt5oimm4gkmwj4.png"><br>  <i>Die parallele Anwendung mehrerer Filter auf das Eingabebild und den daraus resultierenden Satz von Aktivierungskarten</i> <br><br>  Ein solches Verst√§ndnis der Feature-Maps und ihrer Kombination ist sehr wichtig, da wir, nachdem wir dies erkannt haben, die Netzwerkarchitektur erweitern und Faltungsschichten √ºbereinander installieren k√∂nnen, wodurch die Suszeptibilit√§tszone erh√∂ht und unser Klassifikator angereichert wird. <br><br><img src="https://habrastorage.org/webt/7_/3g/hp/7_3ghputtiaz-2l-hbbs7dagmvi.png"><br>  <i>√úbereinander installierte Faltungsschichten.</i>  <i>In jeder Schicht k√∂nnen die Gr√∂√üe der Filter und ihre Anzahl variieren</i> <br><br>  Jetzt verstehen wir, was ein Faltungsnetzwerk ist.  Das Hauptziel dieser Schichten ist das gleiche wie beim allgemein akzeptierten Ansatz - signifikante Zeichen des Bildes zu erkennen.  Und wenn diese Zeichen in der ersten Schicht sehr einfach sein k√∂nnen (das Vorhandensein vertikaler / horizontaler Linien), erh√∂ht die Tiefe des Netzwerks den Grad ihrer Abstraktion (das Vorhandensein eines Hundes / einer Katze / einer Person). <br><br><h3>  <font color="#0071c5">Unterabtastungsebenen</font> </h3><br>  Faltungsschichten sind der Hauptbaustein von CNN.  Aber es gibt noch einen anderen wichtigen und h√§ufig verwendeten Teil - dies sind Unterprobenschichten.  Bei der herk√∂mmlichen Bildverarbeitung gibt es kein direktes Analogon, aber eine Unterprobe kann als eine andere Art von Kernel betrachtet werden.  Was ist das <br><br><img src="https://habrastorage.org/webt/n4/fm/df/n4fmdf4o-i1pa7qs4w4oj7wmzgy.png"><br>  <i>Beispiele f√ºr Unterabtastung.</i>  <i>(links) Wie ein Teilmuster die r√§umlichen (aber nicht die Kanal!) Gr√∂√üen von Datenarrays √§ndert. (rechts) Ein grundlegendes Schema f√ºr die Funktionsweise eines Teilmusters</i> <br><br>  Eine Unterabtastung filtert einen Teil der Nachbarschaft jedes Pixels der Eingabedaten mit einer bestimmten Aggregationsfunktion, beispielsweise Maximum, Durchschnitt usw. Die Unterabtastung entspricht im Wesentlichen der Faltung, aber die Pixelkombinationsfunktion ist nicht auf das Skalarprodukt beschr√§nkt.  Ein weiterer wichtiger Unterschied besteht darin, dass die Unterabtastung nur in der r√§umlichen Dimension funktioniert.  Ein charakteristisches Merkmal der Unterabtastschicht ist, dass der <i>Abstand normalerweise gleich der Gr√∂√üe des Filters ist</i> (der typische Wert ist 2). <br><br>  Eine Teilstichprobe hat drei Hauptziele: <br><br><ul><li>  Verringerung der r√§umlichen Dimension oder Unterabtastung.  Dies geschieht, um die Anzahl der Parameter zu verringern. </li><li>  Das Wachstum der Suszeptibilit√§tszone.  Aufgrund der Teilprobenneuronen in den nachfolgenden Schichten werden mehr Schritte des Eingangssignals akkumuliert </li><li>  Translationale Invarianz zu kleinen Heterogenit√§ten in der Position der Muster im Eingangssignal.  Durch Berechnung der Aggregationsstatistik kleiner Nachbarschaften des Eingangssignals kann eine Teilstichprobe kleine r√§umliche Verschiebungen darin ignorieren. </li></ul><br><h3>  <font color="#0071c5">Dicke Schichten</font> </h3><br>  Faltungsebenen und Unterabtastebenen dienen demselben Zweck - sie erzeugen Bildattribute.  Der letzte Schritt besteht darin, das Eingabebild anhand der erkannten Merkmale zu klassifizieren.  Bei CNN tun dies dichte Schichten √ºber dem Netzwerk.  Dieser Teil des Netzwerks wird als <i>Klassifizierung bezeichnet</i> .  Es kann mehrere Ebenen mit vollst√§ndiger Konnektivit√§t √ºbereinander enthalten, endet jedoch normalerweise mit einer <i>Softmax-</i> Klassenebene, die durch eine logistische Aktivierungsfunktion mit mehreren Variablen aktiviert wird, bei der die Anzahl der Bl√∂cke der Anzahl der Klassen entspricht.  Am Ausgang dieser Schicht befindet sich die Wahrscheinlichkeitsverteilung nach Klasse f√ºr das Eingabeobjekt.  Jetzt kann das Bild klassifiziert werden, indem die wahrscheinlichste Klasse ausgew√§hlt wird. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de415811/">https://habr.com/ru/post/de415811/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de415795/index.html">Schreiben einer Snapchat-Benutzeroberfl√§che auf Swift</a></li>
<li><a href="../de415797/index.html">Regul√§re Ausdr√ºcke + logische Programmierung. Was ist das Ergebnis?</a></li>
<li><a href="../de415801/index.html">Google: Unsere "Telefon" -KI ist nicht gut genug, um gef√§hrlich zu sein</a></li>
<li><a href="../de415805/index.html">Modifikation des Doorhan GSM Barrier Moduls zur Internetsteuerung</a></li>
<li><a href="../de415809/index.html">Verwendung von Soja, Requirejs und Backbone-Js in Plugins f√ºr Atlassian Jira</a></li>
<li><a href="../de415813/index.html">Einige Hinweise zum aktuellen Status von Cloud Gaming</a></li>
<li><a href="../de415815/index.html">An der Spitze der Wissenschaft: eine Analyse der Artikel von arxiv.org</a></li>
<li><a href="../de415817/index.html">Wir √ºbertakten das Backup. Yandex Vortrag</a></li>
<li><a href="../de415819/index.html">Bericht des Club of Rome 2018, Kapitel 3.16: Globale Regierung</a></li>
<li><a href="../de415821/index.html">Der Weg, um ein "intelligentes" Haus mit einer m√∂glichst breiten elektrischen Steuerung zu organisieren</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
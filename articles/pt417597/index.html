<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôä üå•Ô∏è ü•Ñ Armazenamento confi√°vel com DRBD9 e Proxmox (parte 2: iSCSI + LVM) üò© üë©üèΩ‚Äçü§ù‚Äçüë®üèª üë®üèº‚Äçüî¨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Em um artigo anterior, examinei a possibilidade de criar um servidor NFS tolerante a falhas usando DRBD e Proxmox. Acabou muito bem, mas n√£o vamos des...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Armazenamento confi√°vel com DRBD9 e Proxmox (parte 2: iSCSI + LVM)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/417597/"><p><img src="https://habrastorage.org/getpro/habr/post_images/101/70c/524/10170c52443d67bd757a09ef22ba39e2.jpg" alt="imagem"></p><br><p>  Em um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo anterior,</a> examinei a possibilidade de criar um servidor NFS tolerante a falhas usando DRBD e Proxmox.  Acabou muito bem, mas n√£o vamos descansar sobre os louros e agora vamos tentar "espremer todos os sucos" do nosso armazenamento. </p><br><p> Neste artigo, mostrarei como criar um destino iSCSI tolerante a falhas dessa maneira, que usaremos o LVM para cortar em peda√ßos pequenos e us√°-lo em m√°quinas virtuais. </p><br><p>  √â essa abordagem que reduz a carga e aumenta a velocidade do acesso aos dados v√°rias vezes; isso √© especialmente ben√©fico quando o acesso competitivo aos dados n√£o √© necess√°rio, por exemplo, no caso em que voc√™ precisa organizar o armazenamento para m√°quinas virtuais. </p><a name="habracut"></a><br><h2 id="para-slov-o-drbd">  Algumas palavras sobre DRBD </h2><br><p>  DRBD √© uma solu√ß√£o bastante simples e madura, o c√≥digo da oitava vers√£o √© adotado como parte do kernel do Linux.  De fato, representa um espelho de rede RAID1.  A nona vers√£o introduziu suporte para quorum e replica√ß√£o com mais de dois n√≥s. </p><br><p>  De fato, ele permite combinar dispositivos de bloco em v√°rios n√≥s f√≠sicos em uma rede compartilhada comum. </p><br><p>  Usando o DRBD, voc√™ pode obter configura√ß√µes muito interessantes.  Hoje falaremos sobre iSCSI e LVM. </p><br><p>  Voc√™ pode aprender mais sobre isso lendo meu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo anterior</a> , onde descrevi essa solu√ß√£o em detalhes. </p><br><h2 id="para-slov-ob-iscsi">  Algumas palavras sobre o iSCSI </h2><br><p>  O iSCSI √© um protocolo de entrega de dispositivo de bloco em uma rede. </p><br><p>  Ao contr√°rio do NBD, ele suporta autoriza√ß√£o, elimina falhas de rede sem problemas e suporta muitas outras fun√ß√µes √∫teis e, o mais importante, mostra um desempenho muito bom. </p><br><p>  H√° um grande n√∫mero de implementa√ß√µes, algumas delas tamb√©m inclu√≠das no kernel e n√£o exigem dificuldades especiais para sua configura√ß√£o e conex√£o. </p><br><h2 id="para-slov-ob-lvm">  Algumas palavras sobre o LVM </h2><br><p>  Vale ressaltar que o LINBIT tem sua pr√≥pria solu√ß√£o para o Proxmox, ele deve funcionar imediatamente e permitir obter um resultado semelhante, mas neste artigo eu n√£o gostaria de focar apenas no Proxmox e descrever uma solu√ß√£o mais universal que seja adequada para Proxmox e qualquer outra coisa, neste exemplo, o proxmox √© usado apenas como um meio de orquestra√ß√£o de cont√™iner; na verdade, voc√™ pode substitu√≠-lo por outra solu√ß√£o, por exemplo, iniciar cont√™ineres com um destino no Kubernetes. </p><br><p>  Quanto ao Proxmox especificamente, ele funciona bem com LUN e LVM compartilhados, usando apenas seus pr√≥prios drivers padr√£o. </p><br><p>  As vantagens do LVM incluem o fato de que seu uso n√£o √© algo revolucion√°rio, novo e insuficiente, mas, pelo contr√°rio, mostra estabilidade a seco, o que geralmente √© exigido no armazenamento.  Vale ressaltar que o LVM √© usado ativamente em outros ambientes, por exemplo, no OpenNebula ou no Kubernetes, e √© bem suportado por l√°. </p><br><p>  Assim, voc√™ receber√° armazenamento universal que pode ser usado em sistemas diferentes (n√£o apenas no proxmox), usando apenas drivers prontos, sem necessidade especial de modific√°-lo com um arquivo. </p><br><p>  Infelizmente, ao escolher uma solu√ß√£o para armazenamento, voc√™ sempre precisa fazer alguns compromissos.  Portanto, aqui, esta solu√ß√£o n√£o oferece a mesma flexibilidade que, por exemplo, o Ceph. <br>  O tamanho do disco virtual √© limitado pelo tamanho do grupo LVM, e a √°rea marcada para um disco virtual espec√≠fico ser√° necessariamente realocada - isso melhora muito a velocidade do acesso aos dados, mas n√£o permite o Thin-Provisioning (quando o disco virtual ocupa menos espa√ßo do que realmente √©).  Vale ressaltar que o desempenho do LVM diminui bastante ao usar instant√¢neos e, portanto, a possibilidade de seu uso gratuito √© frequentemente eliminada. </p><br><p>  Sim, o LVM suporta pools Thin-Provision que n√£o t√™m essa desvantagem, mas infelizmente seu uso √© poss√≠vel apenas no contexto de um √∫nico n√≥ e n√£o h√° como compartilhar um pool Thin-Provision em v√°rios n√≥s em um cluster. </p><br><p>  Mas, apesar dessas defici√™ncias, devido √† sua simplicidade, o LVM ainda n√£o permite que os concorrentes o contornem e o empurram completamente para fora do campo de batalha. </p><br><p>  Com uma sobrecarga bastante pequena, o LVM ainda fornece uma solu√ß√£o muito r√°pida, est√°vel e bastante flex√≠vel. </p><br><h1 id="obschaya-shema">  Esquema geral </h1><br><ul><li>  N√≥s temos <strong>tr√™s n√≥s</strong> </li><li>  Cada n√≥ possui um <strong>dispositivo drbd</strong> distribu√≠do. </li><li>  Na parte superior do dispositivo drbd, um <strong>cont√™iner LXC</strong> com um destino iSCSI √© iniciado. </li><li>  O destino est√° conectado aos tr√™s n√≥s. </li><li>  Um <strong>grupo LVM</strong> foi criado no destino conectado. </li><li>  Se necess√°rio, o <strong>cont√™iner LXC</strong> pode ser movido para outro n√≥, junto com o <strong>destino iSCSI</strong> </li></ul><br><h1 id="nastroyka">  Personaliza√ß√£o </h1><br><p>  Descobrimos a id√©ia agora, vamos seguir para a implementa√ß√£o. </p><br><p>  Por padr√£o <strong>, a oitava vers√£o do drbd</strong> √© fornecida <strong>com o kernel Linux</strong> , infelizmente <strong>n√£o</strong> nos <strong>conv√©m</strong> e precisamos instalar a nona vers√£o do m√≥dulo. </p><br><p>  Conecte o reposit√≥rio LINBIT e instale tudo o que voc√™ precisa: </p><br><pre><code class="bash hljs">wget -O- https://packages.linbit.com/package-signing-pubkey.asc | apt-key add - <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://packages.linbit.com/proxmox/ proxmox-5 drbd-9.0"</span></span> \ &gt; /etc/apt/sources.list.d/linbit.list apt-get update &amp;&amp; apt-get -y install pve-headers drbd-dkms drbd-utils drbdtop</code> </pre> <br><ul><li>  <code>pve-headers</code> - <code>pve-headers</code> kernel necess√°rios para construir o m√≥dulo </li><li>  <code>drbd-dkms</code> - m√≥dulo do kernel no formato DKMS </li><li>  <code>drbd-utils</code> - utilit√°rios b√°sicos de gerenciamento DRBD </li><li>  <code>drbdtop</code> √© uma ferramenta interativa como top apenas para DRBD </li></ul><br><p>  Depois de instalar o <strong>m√≥dulo,</strong> verifique se est√° tudo bem com ele: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># modprobe drbd # cat /proc/drbd version: 9.0.14-1 (api:2/proto:86-113)</span></span></code> </pre> <br><p>  Se voc√™ vir a <strong>oitava vers√£o</strong> na sa√≠da do comando, algo deu errado e o m√≥dulo do kernel <strong>na √°rvore</strong> √© carregado.  Verifique o <code>dkms status</code> descobrir qual √© o motivo. </p><br><p>  Cada n√≥ que temos ter√° o mesmo <strong>dispositivo drbd</strong> rodando sobre parti√ß√µes regulares.  Primeiro, precisamos preparar esta se√ß√£o para o drbd em cada n√≥. </p><br><p>  Essa parti√ß√£o pode ser qualquer <strong>dispositivo de bloco</strong> , pode ser lvm, zvol, uma parti√ß√£o de disco ou o disco inteiro.  Neste artigo, usarei um disco nvme separado com uma parti√ß√£o sob drbd: <code>/dev/nvme1n1p1</code> </p><br><p>  Vale a pena notar que os nomes dos dispositivos tendem a mudar algumas vezes; portanto, √© melhor adotar imediatamente o h√°bito de usar o link simb√≥lico constante para o dispositivo. </p><br><p>  Voc√™ pode encontrar um link simb√≥lico para <code>/dev/nvme1n1p1</code> desta maneira: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># find /dev/disk/ -lname '*/nvme1n1p1' /dev/disk/by-partuuid/847b9713-8c00-48a1-8dff-f84c328b9da2 /dev/disk/by-path/pci-0000:0e:00.0-nvme-1-part1 /dev/disk/by-id/nvme-eui.0000000001000000e4d25c33da9f4d01-part1 /dev/disk/by-id/nvme-INTEL_SSDPEKKA010T7_BTPY703505FB1P0H-part1</span></span></code> </pre> <br><p>  Descrevemos nosso recurso nos tr√™s n√≥s: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># cat /etc/drbd.d/tgt1.res resource tgt1 { meta-disk internal; device /dev/drbd100; protocol C; net { after-sb-0pri discard-zero-changes; after-sb-1pri discard-secondary; after-sb-2pri disconnect; } on pve1 { address 192.168.2.11:7000; disk /dev/disk/by-partuuid/95e7eabb-436e-4585-94ea-961ceac936f7; node-id 0; } on pve2 { address 192.168.2.12:7000; disk /dev/disk/by-partuuid/aa7490c0-fe1a-4b1f-ba3f-0ddee07dfee3; node-id 1; } on pve3 { address 192.168.2.13:7000; disk /dev/disk/by-partuuid/847b9713-8c00-48a1-8dff-f84c328b9da2; node-id 2; } connection-mesh { hosts pve1 pve2 pve3; } }</span></span></code> </pre> <br><p>  √â aconselh√°vel usar uma <strong>rede separada</strong> para sincroniza√ß√£o drbd. </p><br><p>  Agora crie os metadados para drbd e execute-o: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># drbdadm create-md tgt1 initializing activity log initializing bitmap (320 KB) to all zero Writing meta data... New drbd meta data block successfully created. success # drbdadm up tgt1</span></span></code> </pre> <br><p>  Repita estas etapas nos tr√™s n√≥s e verifique o status: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># drbdadm status tgt1 role:Secondary disk:Inconsistent pve2 role:Secondary peer-disk:Inconsistent pve3 role:Secondary peer-disk:Inconsistent</span></span></code> </pre> <br><p>  Agora, nosso disco <strong>inconsistente est√°</strong> nos tr√™s n√≥s, isso ocorre porque o drbd n√£o sabe qual disco deve ser tomado como original.  Devemos marcar um deles como <strong>Prim√°rio</strong> para que seu estado seja sincronizado com os outros n√≥s: </p><br><pre> <code class="bash hljs">drbdadm primary --force tgt1 drbdadm secondary tgt1</code> </pre> <br><p>  Imediatamente ap√≥s isso, a <strong>sincroniza√ß√£o</strong> come√ßar√°: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># drbdadm status tgt1 role:Secondary disk:UpToDate pve2 role:Secondary replication:SyncSource peer-disk:Inconsistent done:26.66 pve3 role:Secondary replication:SyncSource peer-disk:Inconsistent done:14.20</span></span></code> </pre><br><p>  N√£o precisamos esperar que termine e podemos executar outras etapas em paralelo.  Eles podem ser executados em <strong>qualquer n√≥</strong> , independentemente do estado atual do disco local no DRBD.  Todas as solicita√ß√µes ser√£o redirecionadas automaticamente para o dispositivo com o estado <strong>UpToDate</strong> . </p><br><p>  N√£o se esque√ßa de ativar a <strong>execu√ß√£o autom√°tica do</strong> servi√ßo drbd nos n√≥s: </p><br><pre> <code class="hljs pgsql">systemctl <span class="hljs-keyword"><span class="hljs-keyword">enable</span></span> drbd.service</code> </pre> <br><h2 id="nastroyka-lxc-konteynera">  Configurando um Cont√™iner LXC </h2><br><p>  Vamos omitir a parte de configura√ß√£o do <strong>cluster Proxmox</strong> de tr√™s n√≥s, essa parte est√° bem descrita no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">wiki oficial</a> </p><br><p>  Como eu disse antes, nosso <strong>destino iSCSI</strong> funcionar√° em um <strong>cont√™iner LXC</strong> .  Manteremos o cont√™iner no dispositivo <code>/dev/drbd100</code> que acabamos de criar. </p><br><p>  Primeiro, precisamos criar um <strong>sistema de arquivos</strong> nele: </p><br><pre> <code class="hljs powershell">mkfs <span class="hljs-literal"><span class="hljs-literal">-t</span></span> ext4 <span class="hljs-literal"><span class="hljs-literal">-O</span></span> mmp <span class="hljs-literal"><span class="hljs-literal">-E</span></span> mmp_update_interval=<span class="hljs-number"><span class="hljs-number">5</span></span> /dev/drbd100</code> </pre> <br><p>  <strong>O Proxmox,</strong> por padr√£o, inclui <strong>prote√ß√£o multimount</strong> no n√≠vel do sistema de arquivos; em princ√≠pio, podemos fazer sem ele, porque  Por padr√£o, o DRBD possui sua pr√≥pria prote√ß√£o; ele simplesmente pro√≠be a segunda <strong>Prim√°ria</strong> do dispositivo, mas o cuidado n√£o nos prejudica. </p><br><p>  Agora baixe o modelo do Ubuntu: </p><br><pre> <code class="hljs pgsql"># wget http://download.proxmox.com/images/<span class="hljs-keyword"><span class="hljs-keyword">system</span></span>/ubuntu<span class="hljs-number"><span class="hljs-number">-16.04</span></span>-standard_16<span class="hljs-number"><span class="hljs-number">.04</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>_amd64.tar.gz -P /var/lib/vz/<span class="hljs-keyword"><span class="hljs-keyword">template</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/</code> </pre> <br><p>  E crie nosso cont√™iner a partir dele: </p><br><pre> <code class="hljs powershell">pct create <span class="hljs-number"><span class="hljs-number">101</span></span> local:vztmpl/ubuntu<span class="hljs-literal"><span class="hljs-literal">-16</span></span>.<span class="hljs-number"><span class="hljs-number">04</span></span><span class="hljs-literal"><span class="hljs-literal">-standard_16</span></span>.<span class="hljs-number"><span class="hljs-number">04</span></span><span class="hljs-literal"><span class="hljs-literal">-1_amd64</span></span>.tar.gz \ -<span class="hljs-literal"><span class="hljs-literal">-hostname</span></span>=tgt1 \ -<span class="hljs-literal"><span class="hljs-literal">-net0</span></span>=name=eth0,bridge=vmbr0,gw=<span class="hljs-number"><span class="hljs-number">192.168</span></span>.<span class="hljs-number"><span class="hljs-number">1.1</span></span>,ip=<span class="hljs-number"><span class="hljs-number">192.168</span></span>.<span class="hljs-number"><span class="hljs-number">1.11</span></span>/<span class="hljs-number"><span class="hljs-number">24</span></span> \ -<span class="hljs-literal"><span class="hljs-literal">-rootfs</span></span>=volume=/dev/drbd100,shared=<span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br><p>  Neste comando, indicamos que o <strong>sistema raiz do</strong> nosso cont√™iner estar√° no dispositivo <code>/dev/drbd100</code> e adicionamos o par√¢metro <code>shared=1</code> para permitir a <strong>migra√ß√£o do</strong> cont√™iner entre os n√≥s. </p><br><p>  Se algo der errado, voc√™ sempre poder√° corrigi-lo atrav√©s da interface <strong>Proxmox</strong> ou na <code>/etc/pve/lxc/101.conf</code> cont√™iner <code>/etc/pve/lxc/101.conf</code> </p><br><p>  O Proxmox ir√° descompactar o modelo e preparar <strong>o sistema raiz do</strong> cont√™iner para n√≥s.  Depois disso, podemos lan√ßar nosso cont√™iner: </p><br><pre> <code class="hljs pgsql">pct <span class="hljs-keyword"><span class="hljs-keyword">start</span></span> <span class="hljs-number"><span class="hljs-number">101</span></span></code> </pre> <br><h2 id="nastroyka-iscsi-targeta">  Configurando um destino iSCSI. </h2><br><p>  De todo o conjunto de <strong>destinos</strong> , eu escolhi o <strong>istgt</strong> , pois ele tem o melhor desempenho e trabalha no espa√ßo do usu√°rio. </p><br><p>  Agora vamos fazer login no nosso cont√™iner: </p><br><pre> <code class="hljs perl">pct <span class="hljs-keyword"><span class="hljs-keyword">exec</span></span> <span class="hljs-number"><span class="hljs-number">101</span></span> bash</code> </pre> <br><p>  Instale atualiza√ß√µes e <strong>istgt</strong> : </p><br><pre> <code class="hljs sql">apt-get <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> -y <span class="hljs-keyword"><span class="hljs-keyword">upgrade</span></span> apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> -y <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> istgt</code> </pre> <br><p>  Crie um arquivo que forneceremos pela rede: </p><br><pre> <code class="hljs powershell">mkdir <span class="hljs-literal"><span class="hljs-literal">-p</span></span> /<span class="hljs-keyword"><span class="hljs-keyword">data</span></span> fallocate <span class="hljs-literal"><span class="hljs-literal">-l</span></span> <span class="hljs-number"><span class="hljs-number">740</span></span>G /<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/target1.img</code> </pre> <br><p>  Agora precisamos escrever uma configura√ß√£o para <strong>istgt</strong> <code>/etc/istgt/istgt.conf</code> : </p><br><pre> <code class="hljs sql">[Global] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"Global section"</span></span> NodeBase <span class="hljs-string"><span class="hljs-string">"iqn.2018-07.org.example.tgt1"</span></span> PidFile /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/run/istgt.pid AuthFile /etc/istgt/auth.conf MediaDirectory /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/istgt LogFacility <span class="hljs-string"><span class="hljs-string">"local7"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Timeout</span></span> <span class="hljs-number"><span class="hljs-number">30</span></span> NopInInterval <span class="hljs-number"><span class="hljs-number">20</span></span> DiscoveryAuthMethod <span class="hljs-keyword"><span class="hljs-keyword">Auto</span></span> MaxSessions <span class="hljs-number"><span class="hljs-number">16</span></span> MaxConnections <span class="hljs-number"><span class="hljs-number">4</span></span> MaxR2T <span class="hljs-number"><span class="hljs-number">32</span></span> MaxOutstandingR2T <span class="hljs-number"><span class="hljs-number">16</span></span> DefaultTime2Wait <span class="hljs-number"><span class="hljs-number">2</span></span> DefaultTime2Retain <span class="hljs-number"><span class="hljs-number">60</span></span> FirstBurstLength <span class="hljs-number"><span class="hljs-number">262144</span></span> MaxBurstLength <span class="hljs-number"><span class="hljs-number">1048576</span></span> MaxRecvDataSegmentLength <span class="hljs-number"><span class="hljs-number">262144</span></span> InitialR2T Yes ImmediateData Yes DataPDUInOrder Yes DataSequenceInOrder Yes ErrorRecoveryLevel <span class="hljs-number"><span class="hljs-number">0</span></span> [UnitControl] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"Internal Logical Unit Controller"</span></span> AuthMethod CHAP Mutual AuthGroup AuthGroup10000 Portal UC1 <span class="hljs-number"><span class="hljs-number">127.0</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>:<span class="hljs-number"><span class="hljs-number">3261</span></span> Netmask <span class="hljs-number"><span class="hljs-number">127.0</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span> [PortalGroup1] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"SINGLE PORT TEST"</span></span> Portal DA1 <span class="hljs-number"><span class="hljs-number">192.168</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span><span class="hljs-number"><span class="hljs-number">.11</span></span>:<span class="hljs-number"><span class="hljs-number">3260</span></span> [InitiatorGroup1] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"Initiator Group1"</span></span> InitiatorName <span class="hljs-string"><span class="hljs-string">"ALL"</span></span> Netmask <span class="hljs-number"><span class="hljs-number">192.168</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>/<span class="hljs-number"><span class="hljs-number">24</span></span> [LogicalUnit1] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"Hard Disk Sample"</span></span> TargetName disk1 TargetAlias <span class="hljs-string"><span class="hljs-string">"Data Disk1"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Mapping</span></span> PortalGroup1 InitiatorGroup1 AuthMethod <span class="hljs-keyword"><span class="hljs-keyword">Auto</span></span> AuthGroup AuthGroup1 UseDigest <span class="hljs-keyword"><span class="hljs-keyword">Auto</span></span> UnitType Disk LUN0 <span class="hljs-keyword"><span class="hljs-keyword">Storage</span></span> /<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/target1.img <span class="hljs-keyword"><span class="hljs-keyword">Auto</span></span></code> </pre> <br><p>  Reinicie o istgt: </p><br><pre> <code class="hljs pgsql">systemctl <span class="hljs-keyword"><span class="hljs-keyword">restart</span></span> istgt</code> </pre> <br><p>  Isso completa a configura√ß√£o de destino </p><br><h2 id="nastroyka-ha">  Configura√ß√£o de HA </h2><br><p>  Agora podemos passar para a configura√ß√£o do <strong>gerenciador de alta disponibilidade</strong> .  Vamos criar um grupo HA separado para o nosso dispositivo: </p><br><pre> <code class="hljs powershell">ha<span class="hljs-literal"><span class="hljs-literal">-manager</span></span> groupadd tgt1 -<span class="hljs-literal"><span class="hljs-literal">-nodes</span></span> pve1,pve2,pve3 -<span class="hljs-literal"><span class="hljs-literal">-nofailback</span></span>=<span class="hljs-number"><span class="hljs-number">1</span></span> -<span class="hljs-literal"><span class="hljs-literal">-restricted</span></span>=<span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br><p>  Nosso <strong>recurso</strong> funcionar√° apenas nos n√≥s especificados para este grupo.  Adicione nosso cont√™iner a este grupo: </p><br><pre> <code class="hljs powershell">ha<span class="hljs-literal"><span class="hljs-literal">-manager</span></span> add ct:<span class="hljs-number"><span class="hljs-number">101</span></span> -<span class="hljs-literal"><span class="hljs-literal">-group</span></span>=tgt1 -<span class="hljs-literal"><span class="hljs-literal">-max_relocate</span></span>=<span class="hljs-number"><span class="hljs-number">3</span></span> -<span class="hljs-literal"><span class="hljs-literal">-max_restart</span></span>=<span class="hljs-number"><span class="hljs-number">3</span></span></code> </pre> <br><h2 id="rekomendacii-i-tyuning">  Recomenda√ß√µes e ajuste </h2><br><h5 id="drbd">  DRBD </h5><br><p>  Como observei acima, √© sempre aconselh√°vel usar uma rede separada para replica√ß√£o.  √â altamente recomend√°vel usar <strong>adaptadores de rede de 10 gigabit</strong> , caso contr√°rio, voc√™ ter√° velocidade de porta. <br>  Se a replica√ß√£o parecer lenta o suficiente, tente algumas das op√ß√µes para <strong>DRBD</strong> .  Aqui est√° a configura√ß√£o, que na minha opini√£o √© ideal para minha <strong>rede 10G</strong> : </p><br><pre> <code class="hljs swift"># cat /etc/drbd.d/global_common.conf global { usage-<span class="hljs-built_in"><span class="hljs-built_in">count</span></span> yes; udev-always-use-vnr; } common { handlers { } startup { } options { } disk { <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-fill-target 10M; <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-<span class="hljs-built_in"><span class="hljs-built_in">max</span></span>-rate 720M; <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-plan-ahead <span class="hljs-number"><span class="hljs-number">10</span></span>; <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-<span class="hljs-built_in"><span class="hljs-built_in">min</span></span>-rate 20M; } net { <span class="hljs-built_in"><span class="hljs-built_in">max</span></span>-buffers 36k; sndbuf-size 1024k; rcvbuf-size 2048k; } }</code> </pre> <br><p>  Voc√™ pode obter mais informa√ß√µes sobre cada par√¢metro na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o oficial do DRBD.</a> </p><br><h5 id="open-iscsi">  Abra o iSCSI </h5><br><p>  Como n√£o usamos caminhos m√∫ltiplos, no nosso caso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">, √© recomend√°vel</a> desativar as verifica√ß√µes peri√≥dicas de conex√£o nos clientes, al√©m de aumentar o tempo limite de espera para recupera√ß√£o da sess√£o no <code>/etc/iscsi/iscsid.conf</code> . </p><br><pre> <code class="hljs powershell">node.conn[<span class="hljs-number"><span class="hljs-number">0</span></span>].timeo.noop_out_interval = <span class="hljs-number"><span class="hljs-number">0</span></span> node.conn[<span class="hljs-number"><span class="hljs-number">0</span></span>].timeo.noop_out_timeout = <span class="hljs-number"><span class="hljs-number">0</span></span> node.session.timeo.replacement_timeout = <span class="hljs-number"><span class="hljs-number">86400</span></span></code> </pre> <br><h2 id="ispolzovanie">  Use </h2><br><h4 id="proxmox">  Proxmox </h4><br><p>  O <strong>destino iSCSI</strong> resultante pode ser conectado imediatamente ao Proxmox, sem esquecer de desmarcar <strong>Usar LUN diretamente</strong> . </p><br><p><img src="https://habrastorage.org/webt/uw/j3/pu/uwj3pusr-nf9bc7neisd5x-fcsg.png"></p><br><p>  Imediatamente depois disso, ser√° poss√≠vel criar LVM sobre ele, n√£o se esque√ßa de marcar a caixa <strong>compartilhada</strong> : </p><br><p><img src="https://habrastorage.org/webt/j1/ob/mw/j1obmwcwhz-e6krjix72pmiz118.png"></p><br><h4 id="drugie-sredy">  Outros ambientes </h4><br><p>  Se voc√™ planeja usar esta solu√ß√£o em um ambiente diferente, pode ser necess√°rio instalar uma extens√£o de cluster para o LVM no momento em que houver duas implementa√ß√µes.  <strong>CLVM</strong> e <strong>lvmlockd</strong> . </p><br><p>  A configura√ß√£o do <strong>CLVM</strong> n√£o <strong>√©</strong> trivial e requer um gerenciador de cluster em funcionamento. <br>  Onde, como segundo m√©todo, o <strong>lvmlockd</strong> ainda n√£o foi totalmente testado e est√° apenas come√ßando a aparecer em reposit√≥rios est√°veis. </p><br><p>  Eu recomendo a leitura de um excelente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><strong>artigo sobre bloqueio no LVM</strong></a> </p><br><p>  Ao usar o <strong>LVM</strong> com <strong>Proxmox, a</strong> adi√ß√£o de cluster <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">n√£o</a> √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">necess√°ria</a> , pois o gerenciamento de volume √© fornecido pelo pr√≥prio proxmox, que atualiza e monitora os metadados do LVM independentemente.  O mesmo se aplica ao <strong>OpenNebula</strong> , como a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o oficial</a> indica claramente. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt417597/">https://habr.com/ru/post/pt417597/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt417587/index.html">M√≠dia: ataques cibern√©ticos em larga escala aceleraram o crescimento da capitaliza√ß√£o de empresas do setor de seguran√ßa da informa√ß√£o</a></li>
<li><a href="../pt417589/index.html">Sete regras simples para tornar a Internet acess√≠vel a todos</a></li>
<li><a href="../pt417591/index.html">Como "aprender" ingl√™s em um ano sozinho ou um artigo para quem n√£o trabalhou com ingl√™s</a></li>
<li><a href="../pt417593/index.html">NewSQL = NoSQL + ACID</a></li>
<li><a href="../pt417595/index.html">Antiguidades: Palm OS, c√≥digo eficiente e fotos nojentas</a></li>
<li><a href="../pt417601/index.html">Escolha um servidor. O que procurar? Lista de verifica√ß√£o</a></li>
<li><a href="../pt417603/index.html">An√∫ncio de uma mitap m√≥vel: o que fazer quando o aplicativo se tornar grande?</a></li>
<li><a href="../pt417605/index.html">No√ß√µes b√°sicas de modelagem 3D para impress√£o 3D</a></li>
<li><a href="../pt417607/index.html">Os testes A / B n√£o funcionam. Verifique o que voc√™ est√° fazendo de errado</a></li>
<li><a href="../pt417609/index.html">Especializa√ß√£o em programa√ß√£o esportiva no cursor</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
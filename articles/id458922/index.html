<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐔 🎻 🚯 Cara pindah dari ESXi ke KVM / LXD dan tidak kehilangan akal 🧖🏿 😦 ☃️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Untuk waktu yang lama, perusahaan Maxnet Systems menggunakan versi gratis VMware - ESXi, dimulai dengan versi 5.0, sebagai hypervisor. Versi berbayar ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cara pindah dari ESXi ke KVM / LXD dan tidak kehilangan akal</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/458922/">  Untuk waktu yang lama, perusahaan Maxnet Systems menggunakan versi gratis VMware - ESXi, dimulai dengan versi 5.0, sebagai hypervisor.  Versi berbayar vSphere menakuti model lisensi, sementara versi gratis memiliki sejumlah kelemahan yang tidak tersedia dalam versi berbayar, tetapi Anda bisa tahan dengan mereka.  Tetapi ketika dalam versi baru ESXi antarmuka web baru menolak untuk bekerja dengan yang lama, dan pemantauan array RAID berhenti menunjukkan tanda-tanda kehidupan, perusahaan memutuskan untuk mencari solusi yang lebih universal dan terbuka.  Perusahaan telah memiliki pengalaman yang baik dan kesan yang baik tentang LXC - Linux Containers.  Oleh karena itu, menjadi jelas bahwa hypervisor mimpi akan menjadi hibrida dan menggabungkan KVM dan LXD untuk beban yang berbeda - kelanjutan evolusi LXC.  Mencari informasi tentang KVM, perusahaan dihadapkan dengan kesalahpahaman, penggaruk dan praktik berbahaya, tetapi tes dan waktu menempatkan semuanya pada tempatnya. <br><br><img src="https://habrastorage.org/webt/s-/vc/6s/s-vc6shq5cfia5bjjcuhixbgukq.jpeg"><br><br>  Tentang cara mengatasi perpindahan dari ESXi ke KVM dan tidak menggerakkan roda dengan menyapu, akan memberi tahu <strong>Lev Nikolaev</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" class="user_link">maniaque</a> ) - administrator dan pengembang sistem yang sarat muatan, pelatih teknologi informasi.  Mari kita bicara tentang Jaringan, repositori, wadah, KVM, LXD, LXC, penyediaan, dan mesin virtual yang nyaman. <br><a name="habracut"></a><br><h2>  Prolog </h2><br>  Kami akan segera mengidentifikasi pemikiran-pemikiran utama, dan kemudian kami akan menganalisisnya secara lebih rinci. <br><br>  <strong>Jaringan</strong>  Meskipun kecepatan antarmuka Anda tidak melebihi 1 Gb / s, jembatan sudah cukup untuk Anda.  Segera setelah Anda ingin memeras lebih banyak - itu akan membatasi Anda. <br><br>  <strong>Repositori.</strong>  Buat penyimpanan jaringan bersama.  Bahkan jika Anda tidak siap untuk menggunakan 10 Gbit / s di dalam jaringan, bahkan 1 Gbit / s akan memberi Anda 125 MB / s penyimpanan.  Untuk sejumlah beban, ini akan cukup dengan margin, dan migrasi mesin virtual akan menjadi masalah mendasar. <br><br>  <strong>Wadah atau KVM?</strong>  Pro, kontra, perangkap.  Jenis-jenis muatan apa yang paling baik ditempatkan dalam sebuah wadah dan mana yang paling baik disimpan dalam KVM? <br><br>  <strong>LXD atau LXC</strong> .  Apakah LXD LXC?  Atau versi lain?  Atau add-on?  Tentang apa semua ini?  Mari kita singkirkan mitos dan pahami perbedaan antara LXD dan LXC. <br><br>  <strong>Provisi yang mudah</strong> .  Mana yang lebih nyaman: ambil gambar yang sama atau instal sistem dari awal setiap kali?  Bagaimana cara melakukannya dengan cepat dan akurat setiap saat? <br><br>  <strong>Mesin virtual yang nyaman.</strong>  Akan ada cerita menyeramkan tentang bootloader, partisi, LVM. <br><br>  <strong>Lain-lain</strong> .  Banyak pertanyaan kecil: bagaimana cara menyeret mesin virtual dengan cepat dari ESXi ke KVM, bagaimana cara bermigrasi dengan baik, bagaimana cara virtualisasi disk dengan benar? <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/HqsxBkxGxqg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2>  Alasan untuk pindah </h2><br>  Dari mana kita mendapatkan ide gila untuk pindah dari ESXi ke KVM / LXD?  ESXi populer di kalangan bisnis kecil dan menengah.  Ini adalah hypervisor yang bagus dan murah.  Namun ada nuansa. <br><br>  Kami mulai dengan versi 5.0 - nyaman, semuanya berfungsi!  Versi 5.5 berikutnya adalah sama. <br><br>  Sejak versi 6.0 itu sudah lebih sulit.  Pada ESXi, antarmuka Web tidak langsung menjadi gratis, hanya dari versi 6.5, sebelum itu diperlukan utilitas untuk Windows.  Kami tahan dengan ini.  Siapa yang menjalankan OS X membeli Parallels dan menginstal utilitas ini.  Ini adalah rasa sakit yang terkenal. <br><br>  Pemantauan secara berkala terlintas.  Itu perlu untuk me-restart layanan manajemen di konsol server - kemudian CIM Heartbeat muncul lagi.  Kami bertahan, karena dia tidak selalu jatuh. <br><br>  Versi ESXi 6.5 - sampah, limbah, dan kekejaman.  Hypervisor mengerikan.  Dan inilah alasannya. <br><br><ul><li>  <strong>Angular jatuh dengan pengecualian di pintu masuk ke antarmuka Web.</strong>  Segera setelah Anda memasukkan nama pengguna dan kata sandi - segera pengecualian! </li><li>  <strong>Kemampuan untuk memonitor status array RAID dari jarak jauh tidak berfungsi</strong> karena nyaman bagi kami.  Dulu nyaman, tetapi dalam versi 6.5, semuanya buruk. </li><li>  <strong>Dukungan lemah untuk kartu jaringan modern dari Intel</strong> .  Kartu jaringan dari Intel dan ESXi menyebabkan rasa sakit.  Ada utas sakit di forum dukungan ESXi tentang ini.  VMware dan Intel bukan teman dan hubungan tidak akan membaik dalam waktu dekat.  Yang menyedihkan adalah bahwa bahkan pelanggan solusi berbayar mengalami masalah. </li><li>  <strong>Tidak ada migrasi dalam ESXi</strong> .  Kecuali migrasi dianggap sebagai jeda, salin, dan mulai prosedur.  Kami menghentikan mobil, menyalinnya dengan cepat, dan menyalakannya di tempat lain.  Tetapi tidak mungkin menyebutnya migrasi - masih ada yang sederhana. </li></ul><br>  Setelah melihat semua ini, kami mendapat ide gila untuk bergerak dengan ESXi 6.5. <br><br><h2>  Daftar keinginan </h2><br>  Sebagai permulaan, kami menulis daftar keinginan untuk masa depan ideal yang akan kami tuju. <br><br>  <strong>Manajemen dari bawah SSH</strong> , dan Web dan lebih opsional.  Antarmuka web bagus, tetapi dalam perjalanan bisnis dari iPhone, masuk ke antarmuka web ESXi dan melakukan sesuatu yang tidak nyaman dan sulit.  Oleh karena itu, satu-satunya cara untuk mengelola semuanya adalah SSH, tidak akan ada yang lain. <br><br>  <strong>Virtualisasi Windows.</strong>  Terkadang pelanggan meminta hal-hal aneh, dan misi kami adalah membantu mereka. <br><br>  <strong>Driver selalu segar dan kemampuan untuk mengkonfigurasi kartu jaringan</strong> .  Keinginan yang memadai, tetapi tidak direalisasi di bawah ESXi murni. <br><br>  <strong>Migrasi langsung, bukan pengelompokan</strong> .  Kami ingin kemampuan untuk menyeret mesin dari satu hypervisor ke yang lain tanpa merasakan penundaan, waktu henti atau ketidaknyamanan. <br><br>  Daftar keinginan sudah siap, maka pencarian yang sulit telah dimulai. <br><br><h2>  Pilihan tepung </h2><br>  Pasar berputar di sekitar KVM atau LXC dengan saus yang berbeda.  Terkadang sepertinya Kubernetes berada di suatu tempat di atas, di mana semuanya baik-baik saja, matahari dan surga, dan pada tingkat di bawah ini ada Morlock - KVM, Xen atau sesuatu seperti itu ... <br><br>  Misalnya, Proxmox VE adalah Debian, yang ditarik oleh kernel dari Ubuntu.  Ini terlihat aneh, tetapi apakah ini membuatnya diproduksi? <br><br>  Tetangga kita di lantai bawah adalah Alt Linux.  Mereka datang dengan solusi yang indah: mereka menggabungkan Proxmox VE sebagai satu paket.  Mereka hanya menempatkan paket dalam satu perintah.  Ini mudah, tetapi kami tidak memasukkan Alt Linux ke dalam produksi, jadi itu tidak cocok untuk kami. <br><br><h3>  Ambil KVM </h3><br>  Pada akhirnya, kami memilih KVM.  Mereka tidak mengambilnya, Xen, misalnya, karena komunitas - KVM memiliki lebih banyak.  Tampaknya kami akan selalu menemukan jawaban untuk pertanyaan kami.  Kami kemudian menemukan bahwa ukuran komunitas tidak memengaruhi kualitasnya. <br><br>  Awalnya, kami menghitung bahwa kami akan menggunakan mesin Bare Metal, menambahkan Ubuntu yang sedang kami tangani, dan menggulung KVM / LXD dari atas.  Kami mengandalkan kemampuan menjalankan kontainer.  Ubuntu adalah sistem yang terkenal dan tidak ada kejutan dalam hal memecahkan masalah boot / pemulihan bagi kami.  Kami tahu di mana harus menendang jika hypervisor tidak dimulai.  Semuanya jelas dan nyaman bagi kita. <br><br><h2>  Kursus Kecelakaan KVM </h2><br>  Jika Anda berasal dari dunia ESXi, maka Anda akan menemukan banyak hal menarik.  Pelajari tiga kata: QEMU, KVM, dan libvirt. <br><br>  <strong>QEMU</strong> menerjemahkan keinginan OS tervirtualisasi ke dalam tantangan proses reguler.  Bekerja sangat baik hampir di mana-mana, tetapi lambat.  QEMU sendiri adalah produk mandiri yang memvirtualisasi banyak perangkat lain. <br><br>  Lebih jauh di tempat kejadian datang sekelompok <strong>QEMU-KVM</strong> .  Ini adalah modul kernel Linux untuk QEMU.  Virtualisasi semua instruksi itu mahal, jadi kami memiliki modul kernel KVM yang <strong>hanya menerjemahkan beberapa instruksi</strong> .  Hasilnya, ini secara signifikan lebih cepat, karena hanya beberapa persen dari instruksi dari set umum yang diproses.  Ini semua biaya virtualisasi. <br><br>  Jika Anda hanya memiliki QEMU, memulai mesin virtual tanpa ikatan terlihat seperti ini: <br><br><pre><code class="plaintext hljs">$ qemu &lt; &gt;</code> </pre> <br>  Dalam parameter yang Anda gambarkan jaringan, blokir perangkat.  Semuanya indah, tetapi tidak nyaman.  Karena itu ada libvirt. <br><br>  <strong>Tujuan libvirt adalah menjadi alat tunggal untuk semua hypervisor</strong> .  Itu bisa bekerja dengan apa saja: dengan KVM, dengan LXD.  Tampaknya hanya mempelajari sintaksis libvirt, tetapi pada kenyataannya ia bekerja lebih buruk daripada secara teori. <br><br>  Ketiga kata inilah yang diperlukan untuk meningkatkan mesin virtual pertama di KVM.  Tapi sekali lagi, ada nuansa ... <br><br>  Libvirt memiliki konfigurasi tempat mesin virtual dan pengaturan lainnya disimpan.  Ini menyimpan konfigurasi dalam file xml - penuh gaya, modis dan langsung dari tahun 90-an.  Jika diinginkan, mereka dapat diedit dengan tangan, tetapi mengapa, jika ada perintah yang mudah.  Juga nyaman adalah bahwa perubahan file xml luar biasa berversi.  Kami menggunakan <strong>dllkeeper</strong> - versi direktori dll.  Ini sudah mungkin untuk menggunakan dllkeeper dan sudah saatnya. <br><br><h2>  Kursus Kecelakaan LXC </h2><br>  Ada banyak kesalahpahaman tentang LXC dan LXD. <br><br><blockquote>  LXC adalah kemampuan kernel modern untuk menggunakan ruang nama - untuk berpura-pura bahwa itu bukan inti yang semula. </blockquote><br>  Anda dapat membuat ruang nama ini sebanyak yang Anda suka untuk setiap wadah.  Secara formal, intinya adalah satu, tetapi berperilaku seperti banyak inti identik.  LXC memungkinkan Anda untuk menjalankan kontainer, tetapi hanya menyediakan alat dasar. <br><br>  Canonical, yang berada di belakang Ubuntu dan dengan agresif memindahkan wadah ke depan, telah merilis <strong>LXD, sebuah analog dari libvirt</strong> .  Ini adalah penjilidan yang membuatnya lebih mudah untuk menjalankan kontainer, tetapi di dalamnya masih LXC. <br><br><blockquote>  LXD adalah hypervisor kontainer yang didasarkan pada LXC. </blockquote><br>  Perusahaan berkuasa di LXD.  LXD menyimpan konfigurasi dalam basis datanya - di direktori <code>/var/lib/lxd</code> .  Di sana, LXD mengarahkan konfigurasi ke konfigurasi di SQlite.  Menyalinnya tidak masuk akal, tetapi Anda dapat menuliskan perintah yang Anda gunakan untuk membuat konfigurasi wadah. <br><br>  Tidak ada pembongkaran seperti itu, tetapi sebagian besar perubahan diotomatiskan oleh tim.  Ini adalah analog dari file Docker, hanya dengan kontrol manual. <br><br><h2>  Produksi </h2><br>  Apa yang kami hadapi ketika kami semua mulai beroperasi. <br><br><h3>  Jaringan </h3><br>  Berapa banyak sampah dan keributan di Internet tentang jaringan di KVM!  90% material mengatakan menggunakan jembatan. <br><br><blockquote>  Berhenti menggunakan jembatan! </blockquote><br>  Apa yang salah dengannya?  Akhir-akhir ini, saya merasa bahwa kegilaan terjadi dengan kontainer: letakkan Docker di atas Docker sehingga Anda dapat menjalankan Docker di Docker sambil menonton Docker.  Kebanyakan tidak mengerti apa yang dilakukan jembatan. <br><br>  Ini menempatkan pengontrol jaringan Anda dalam <strong>mode promiscuous</strong> dan menerima semua lalu lintas karena tidak tahu yang mana dan yang tidak.  Akibatnya, semua lalu lintas jembatan melewati tumpukan jaringan Linux yang luar biasa cepat, dan ada banyak penyalinan.  Pada akhirnya, semuanya lambat dan buruk.  Karena itu, jangan menggunakan jembatan dalam produksi. <br><br><h3>  SR-IOV </h3><br>  <strong>SR-IOV adalah kemampuan untuk melakukan virtualisasi dalam kartu jaringan</strong> .  Kartu jaringan itu sendiri dapat mengalokasikan sebagian dari dirinya untuk mesin virtual, yang memerlukan dukungan perangkat keras.  Inilah yang akan mencegah migrasi.  Bermigrasi mesin virtual di mana SR-IOV hilang sangat menyakitkan. <br><br>  SR-IOV harus digunakan jika didukung oleh semua hypervisor sebagai bagian dari migrasi.  Jika tidak, maka macvtap adalah untuk Anda. <br><br><h3>  macvtap </h3><br>  Ini untuk mereka yang kartu jaringannya tidak mendukung SR-IOV.  Ini adalah versi ringan dari jembatan: alamat MAC yang berbeda digantung pada satu kartu jaringan, dan <strong>pemfilteran unicast digunakan</strong> : kartu jaringan tidak menerima semuanya, tetapi secara ketat sesuai dengan daftar alamat MAC. <br><br>  Rincian lebih berdarah dapat ditemukan di pembicaraan hebat Toshiaki Makita <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">, Virtual Switching Technologies dan Linux Bridge</a> .  Dia penuh dengan rasa sakit dan penderitaan. <br><br><blockquote>  90% materi tentang cara membangun jaringan di KVM tidak berguna. </blockquote><br>  Jika seseorang mengatakan jembatan itu luar biasa, jangan bicara dengan orang itu lagi. <br><br>  Dengan macvtap, <strong>CPU menyimpan sekitar 30%</strong> karena lebih sedikit salinan.  Namun mode promiscuous memiliki nuansa tersendiri.  Anda tidak dapat terhubung ke antarmuka jaringan mesin tamu dari hypervisor itu sendiri - dari host.  Laporan Toshiaki merinci ini.  Namun singkatnya - itu tidak akan berhasil. <br><br>  Dari hypervisor sangat jarang SSH.  Lebih mudah untuk memulai konsol di sana, misalnya, konsol Win.  Dimungkinkan untuk "menonton" lalu lintas di antarmuka - Anda tidak dapat terhubung melalui TCP, tetapi lalu lintas pada hypervisor terlihat. <br><br><blockquote>  Jika kecepatan Anda di atas 1 Gigabit - pilih macvtap. </blockquote><br>  Pada kecepatan antarmuka hingga atau sekitar 1 Gigabit per detik, bridge juga dapat digunakan.  Tetapi jika Anda memiliki kartu jaringan 10 Gb dan ingin membuangnya entah bagaimana, maka hanya macvtap yang tersisa.  Tidak ada pilihan lain.  Kecuali SR-IOV. <br><br><h3>  systemd-networkd </h3><br>  <strong>Ini adalah cara terbaik untuk menyimpan konfigurasi jaringan pada hypervisor itu sendiri</strong> .  Dalam kasus kami, ini adalah Ubuntu, tetapi untuk sistem lain, systemd berfungsi. <br><br>  Kami dulu memiliki file <code>/etc/network/interfaces</code> tempat kita semua menyimpannya.  Satu file tidak nyaman untuk diedit setiap kali - systemd-networkd memungkinkan Anda untuk membagi konfigurasi menjadi hamburan file-file kecil.  Ini nyaman karena berfungsi dengan sistem versi apa pun: dikirim ke Git dan Anda tahu kapan dan perubahan apa yang terjadi. <br><br>  Ada kekurangan yang ditemukan oleh networker kami.  Ketika Anda perlu menambahkan VLAN baru di hypervisor, saya pergi dan mengkonfigurasi.  Lalu saya berkata: "systemctl restart systemd-networkd".  Pada saat ini, semuanya baik-baik saja dengan saya, tetapi jika sesi BGP dari mesin ini dinaikkan, mereka rusak.  Networker kami tidak menyetujui ini. <br><br>  Untuk hypervisor, tidak ada hal buruk yang terjadi.  Systemd-networkd tidak cocok untuk boarder perbatasan, server dengan BGP tinggi, dan untuk hypervisor - sangat baik. <br><br>  Systemd-networkd masih jauh dari final dan tidak akan pernah selesai.  Tapi ini lebih nyaman daripada mengedit satu file besar.  Alternatif untuk systemd-networkd di Ubuntu 18.04 adalah Netplan.  Ini adalah cara "keren" untuk mengkonfigurasi jaringan dan menginjak menyapu. <br><br><h3>  Perangkat jaringan </h3><br>  Setelah menginstal KVM dan LXD pada hypervisor, hal pertama yang Anda akan lihat adalah dua jembatan.  Satu membuat KVM untuk dirinya sendiri, dan yang kedua - LXD. <br><br><blockquote>  LXD dan KVM sedang mencoba untuk menyebarkan jaringan mereka. </blockquote><br>  Jika Anda masih membutuhkan jembatan - untuk mesin uji atau untuk bermain, bunuh jembatan, yang dinyalakan secara default dan buat jembatan Anda sendiri - yang Anda inginkan.  KVM atau LXD melakukannya dengan sangat - selipkan dnsmasq, dan kengerian dimulai. <br><br><h3>  Penyimpanan </h3><br><blockquote>  Tidak masalah implementasi mana yang Anda sukai - gunakan penyimpanan bersama. </blockquote><br>  Misalnya, iSCSI untuk mesin virtual.  Anda tidak akan menyingkirkan "titik kegagalan", tetapi Anda dapat <strong>menggabungkan penyimpanan pada satu titik</strong> .  Ini membuka peluang baru yang menarik. <br><br>  Untuk melakukan ini, Anda harus memiliki setidaknya 10 Gb / s antarmuka di dalam pusat data.  Tetapi bahkan jika Anda hanya memiliki 1 Gbit / s - jangan khawatir.  Ini sekitar 125 MB / s - cukup baik untuk hypervisor yang tidak memerlukan beban disk yang tinggi. <br><br>  KVM dapat melakukan migrasi dan menyeret penyimpanan.  Tetapi, misalnya, dalam mode beban kerja, mentransfer mesin virtual ke beberapa Terabyte adalah hal yang menyebalkan.  Untuk migrasi dengan penyimpanan umum, hanya RAM yang cukup, yang bersifat elementer.  Ini <strong>mengurangi waktu migrasi</strong> . <br><br><h3>  Pada akhirnya, LXD atau KVM? </h3><br>  Awalnya, kami mengasumsikan bahwa untuk semua mesin virtual di mana kernel cocok dengan sistem host, kami akan mengambil LXD.  Dan di mana kita perlu mengambil inti lain - ambil KVM. <br><br>  Pada kenyataannya, rencana itu tidak berjalan.  Untuk memahami alasannya, lihat lebih dekat pada LXD. <br><br><h3>  Lxd </h3><br>  Kelebihan utama adalah menghemat memori pada intinya.  Kernelnya sama dan ketika kami meluncurkan wadah baru, kernelnya sama.  Tentang ini, pro berakhir dan kontra dimulai. <br><br>  <strong>Blokir perangkat dengan rootfs harus dipasang.</strong>  Ini lebih sulit daripada kedengarannya. <br><br>  <strong>Sebenarnya tidak ada migrasi</strong> .  Itu, dan didasarkan pada criu instrumen suram indah, yang melihat rekan kami.  Saya bangga dengan mereka, tetapi dalam kasus-kasus sederhana criu tidak bekerja. <br><br>  <strong>zabbix-agent berperilaku aneh dalam sebuah wadah</strong> .  Jika Anda menjalankannya di dalam wadah, maka Anda akan melihat serangkaian data dari sistem host, dan bukan dari wadah.  Sejauh ini tidak ada yang bisa dilakukan. <br><br>  <strong>Ketika melihat daftar proses pada hypervisor, tidak mungkin untuk dengan cepat memahami wadah mana dari proses tertentu tumbuh</strong> .  Butuh waktu untuk mengetahui namespace apa yang ada, apa dan di mana.  Jika beban di suatu tempat melonjak lebih dari biasanya, maka dengan cepat tidak mengerti.  Ini adalah masalah utama - keterbatasan kemampuan respons.  Investigasi mini dilakukan untuk setiap kasus. <br><br><blockquote>  Satu-satunya plus LXD adalah menghemat memori inti dan mengurangi overhead. </blockquote><br>  Tapi Memori Bersama Kernel di KVM sudah menghemat memori. <br><br>  Sejauh ini saya tidak melihat alasan untuk memperkenalkan produksi serius dan LXD.  Meskipun upaya terbaik Canonical di bidang ini, produksi LXD membawa lebih banyak masalah daripada solusi.  Dalam waktu dekat situasinya tidak akan berubah. <br><br>  Tapi, tidak bisa dikatakan bahwa LXD itu jahat.  Dia baik, tetapi dalam kasus terbatas, yang akan saya bahas nanti. <br><br><h3>  Criu </h3><br>  Criu adalah utilitas suram. <br><br>  Buat wadah kosong, itu akan tiba dengan klien DHCP dan katakan: "Tangguhkan!"  Dapatkan kesalahan karena ada klien DHCP: "Horor, horor!  Dia membuka soket dengan tanda "mentah" - sungguh mimpi buruk! "  Lebih buruk dari itu. <br><br><blockquote>  Tayangan kontainer: tidak ada migrasi, Criu berfungsi setiap saat. </blockquote><br>  Saya “suka” rekomendasi dari tim LXD apa yang harus dilakukan dengan Criu sehingga tidak ada masalah: <br><br>  - <em>Ambil versi yang lebih segar dari repositori!</em> <br><br>  Dan bisakah saya entah bagaimana meletakkannya dari paket agar tidak lari ke repositori? <br><br><h3>  Kesimpulan </h3><br>  <strong>LXD luar biasa jika Anda ingin membuat infrastruktur CI / CD.</strong>  Kami mengambil LVM - Manajer Volume Logis, membuat snapshot darinya, dan memulai wadah di atasnya.  Semuanya bekerja dengan baik!  Dalam sedetik, wadah bersih baru dibuat, yang dikonfigurasi untuk pengujian dan rolling chef - kami secara aktif menggunakannya. <br><br>  <strong>LXD lemah untuk produksi serius</strong> .  Kami tidak dapat menemukan apa yang harus dilakukan dengan LXD dalam produksi jika tidak bekerja dengan baik. <br><br>  <strong>Pilih KVM dan hanya KVM!</strong> <br><br><h3>  Migrasi </h3><br>  Saya akan mengatakan ini secara singkat.  Bagi kami, migrasi ternyata menjadi dunia baru yang indah yang kami sukai.  Semuanya sederhana di sana - ada tim untuk migrasi dan dua opsi penting: <br><br><pre> <code class="plaintext hljs">virsh migrate &lt;vm&gt; qemu+ssh://&lt;hypervisor&gt;/system --undefinesource -persistent</code> </pre> <br>  Jika Anda mengetik "migrasi KVM" di Google dan membuka materi pertama, Anda akan melihat perintah untuk migrasi, tetapi tanpa dua kunci terakhir.  Anda tidak akan melihat disebutkan bahwa itu penting: "Eksekusi saja perintah ini!"  Jalankan perintah - dan itu benar-benar bermigrasi, tetapi hanya bagaimana caranya? <br><br>  Opsi migrasi penting. <br><br>  <strong>undefinesource - lepaskan mesin virtual dari hypervisor tempat kami bermigrasi.</strong>  Jika Anda me-reboot setelah migrasi seperti itu, maka hypervisor yang Anda tinggalkan akan memulai kembali mesin ini.  Anda akan terkejut, tetapi ini normal. <br><br>  <strong>Tanpa parameter kedua - persisten - hypervisor tempat Anda pindah sama sekali tidak menganggap ini sebagai migrasi permanen.</strong>  Setelah reboot, hypervisor tidak akan mengingat apa pun. <br><br><pre> <code class="plaintext hljs">- virsh dominfo &lt;vm&gt; | grep persistent</code> </pre> <br>  Tanpa parameter ini, mesin virtual adalah lingkaran di atas air.  Jika parameter pertama ditentukan tanpa parameter kedua, maka tebak apa yang akan terjadi. <br><br>  Ada banyak momen seperti itu dengan KVM. <br><br><ul><li>  Jaringan: mereka selalu memberi tahu Anda tentang jembatan - itu mimpi buruk!  Anda membaca dan berpikir - bagaimana bisa ?! </li><li>  Migrasi: mereka juga tidak akan mengatakan sesuatu yang masuk akal, sampai Anda memukul kepala Anda di dinding ini. </li></ul><br><h2>  Di mana untuk memulai? </h2><br>  Untuk memulai terlambat - saya sedang berbicara tentang sesuatu yang lain. <br><br><h3>  Provisioning: bagaimana cara menggunakannya </h3><br><blockquote>  Jika Anda puas dengan opsi instalasi standar, mekanisme yang dipra-prakan sangat bagus. </blockquote><br>  Di bawah ESXi, kami menggunakan virt-install.  Ini adalah cara biasa untuk menggunakan mesin virtual.  Lebih mudah karena Anda membuat file preseed di mana Anda menggambarkan gambar Debian / Ubuntu Anda.  Mulai mesin baru dengan mengumpankannya kit distribusi ISO dan file preseed.  Kemudian mobil itu berputar sendiri.  Anda terhubung ke sana melalui SSH, kaitkan ke koki, roll cookie - itu saja, buru-buru ke prod! <br><br>  Tetapi jika Anda memiliki cukup menginstal kebajikan, saya punya kabar buruk.  Ini berarti bahwa Anda belum mencapai tahap ketika Anda ingin melakukan sesuatu yang lain.  Kami berhasil dan menyadari bahwa menginstal kebajikan tidak cukup.  Kami sampai pada beberapa "gambar emas", yang kami kloning dan kemudian meluncurkan mesin virtual. <br><br><h3>  Dan bagaimana cara mengatur mesin virtual? </h3><br>  Mengapa kita sampai pada gambar ini, dan mengapa penyediaan itu penting?  Karena masih ada pemahaman yang lemah di masyarakat bahwa ada perbedaan besar antara mesin virtual dan mesin biasa. <br><br>  <strong>Mesin virtual tidak perlu proses boot yang rumit dan bootloader yang pintar</strong> .  Jauh lebih mudah untuk melampirkan disk mesin virtual ke mesin yang memiliki seperangkat alat lengkap daripada dalam mode pemulihan mencoba keluar di suatu tempat. <br><br>  <strong>Mesin virtual membutuhkan kesederhanaan suatu perangkat</strong> .  Mengapa saya perlu partisi pada disk virtual?  Mengapa orang mengambil disk virtual dan meletakkan partisi di sana, bukan LVM? <br><br>  <strong>Mesin virtual membutuhkan ekstensibilitas maksimum</strong> .  Biasanya mesin virtual tumbuh.  Ini adalah proses "keren" - meningkatkan partisi di MBR.  Anda menghapusnya, pada saat itu menghapus keringat dari dahi Anda dan berpikir: "Jangan menulis sekarang, hanya saja tidak menulis!"  - dan buat ulang dengan parameter baru. <br><br><h3>  LVM @ lilo </h3><br>  Hasilnya, kami datang ke LVM @ lilo.  Ini adalah bootloader yang memungkinkan Anda untuk mengonfigurasi dari satu file.  Jika untuk mengedit konfigurasi GRUB Anda sedang mengedit file khusus yang mengontrol mesin template dan membuat boot.cfg, lalu dengan Lilo - satu file, dan tidak lebih. <br><br>  LVM tanpa partisi menjadikan sistem sempurna dan mudah.  Masalahnya adalah bahwa GRUB tidak dapat hidup tanpa MBR atau GPT dan itu membeku.  Kami memberitahunya: "GRUB menetap di sini," tetapi dia tidak bisa, karena tidak ada partisi. <br><br>  LVM memungkinkan Anda untuk dengan cepat memperluas dan membuat cadangan.  Dialog standar: <br><br>  <em>- Guys, bagaimana Anda melakukan backup virtual?</em> <br><br>  <em>- ... kami mengambil perangkat blok dan menyalin.</em> <br><br>  <em>- Sudahkah Anda mencoba mengerahkan kembali?</em> <br><br>  <em>- Yah, tidak, semuanya bekerja untuk kita!</em> <br><br>  Anda dapat menjilat perangkat blok di mesin virtual kapan saja, tetapi jika ada sistem file, maka catatan apa pun di dalamnya memerlukan tiga gerakan - prosedur ini bukan atom. <br><br>  Jika Anda melakukan snapshot dari mesin virtual dari dalam, maka ia dapat berbicara dengan sistem file sehingga datang ke kondisi konsisten yang diinginkan.  Tapi ini tidak cocok untuk semuanya. <br><br><h2>  Bagaimana cara membuat wadah? </h2><br>  Untuk memulai dan membuat wadah, ada alat biasa dari template.  LXD menawarkan template Ubuntu 16.04 atau 18.04.  Tetapi jika Anda seorang pejuang tingkat lanjut dan tidak menginginkan templat biasa, tetapi rootf kustom Anda, yang dapat Anda sesuaikan sendiri, muncul pertanyaan: bagaimana membuat wadah dari awal di LXD? <br><br><h3>  Wadah dari awal </h3><br>  <strong>Mempersiapkan rootfs</strong> .  Debootstrap akan membantu dengan ini: kami menjelaskan paket mana yang dibutuhkan, mana yang tidak, dan instal. <br><br>  <strong>Jelaskan kepada LXD bahwa kami ingin membuat wadah dari rootfs tertentu</strong> .  Tapi pertama-tama, buat wadah kosong dengan perintah pendek: <br><br><pre> <code class="plaintext hljs">curl --unix-socket /var/lib/lxd/unix.socket -X POST -d '{"name": "my-container", "source": {"type": "none"}}' lxd/1.0/containers</code> </pre> <br>  Ia bahkan bisa otomatis. <br><br>  Seorang pembaca yang bijaksana akan mengatakan - di mana rootfs-wadah saya?  Di mana itu ditunjukkan di tempat apa?  Tapi saya tidak mengatakan itu saja! <br><br>  <strong>Kami memasang rootfs dari wadah di</strong> mana ia akan tinggal.  Kemudian kami mengindikasikan bahwa wadah rootfs akan tinggal di sini: <br><br><pre> <code class="plaintext hljs">lxc config set my-container raw.lxc "lxc.rootfs=/containers/my-container/rootfs"</code> </pre> <br>  Sekali lagi ini otomatis. <br><br><h3>  Kehidupan kontainer </h3><br>  <strong>Kontainer tidak memiliki kernel sendiri</strong> , jadi memuatnya lebih mudah <strong>:</strong> systemd, init, dan terbang! <br><br>  Jika Anda tidak menggunakan alat biasa untuk bekerja dengan LVM, maka dalam kebanyakan kasus, untuk memulai wadah, Anda harus memasang rootfs wadah di hypervisor. <br><br>  Saya terkadang menemukan artikel yang memberi tahu autof.  Jangan lakukan itu.  Systemd memiliki unit automount yang berfungsi, tetapi autof tidak.  Oleh karena itu, unit automount systemd dapat dan harus digunakan, tetapi autof tidak sepadan. <br><br><h2>  Kesimpulan </h2><br>  <strong>Kami menyukai KVM dengan migrasi</strong> .  Dengan LXD, ini belum seperti itu, meskipun untuk menguji dan membangun infrastruktur kami menggunakannya di mana tidak ada beban produksi. <br><br>  <strong>Kami menyukai kinerja KVM</strong> .  Lebih akrab untuk melihat di atas, melihat ada proses yang relevan dengan mesin virtual ini, dan memahami siapa dan apa yang kita lakukan.  Ini lebih baik daripada menggunakan satu set utilitas aneh dengan wadah untuk mencari tahu apa jenis ketukan bawah air yang ada. <br><br>  <strong>Kami senang dengan migrasi.</strong>  Ini sebagian besar disebabkan oleh penyimpanan bersama.  Jika kami bermigrasi dengan menyeret disk, kami tidak akan senang. <br><br><blockquote>  Jika Anda, seperti Leo, siap untuk berbicara tentang mengatasi kesulitan operasi, integrasi atau dukungan, maka sekarang adalah waktu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">untuk mengirimkan laporan</a> ke konferensi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">DevOpsConf</a> musim gugur.  Dan kami dalam komite program akan membantu mempersiapkan presentasi yang menginspirasi dan berguna yang sama dengan ini. <br><br>  Kami tidak menunggu batas waktu Panggilan untuk Makalah dan telah menerima beberapa laporan ke <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">program</a> konferensi.  Berlangganan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">buletin</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">saluran telegram</a> dan dapatkan berita terbaru tentang persiapan untuk DevOpsConf 2019 dan jangan lewatkan artikel dan video baru. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id458922/">https://habr.com/ru/post/id458922/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id458912/index.html">Bermigrasi ke Zimbra dengan imapsync</a></li>
<li><a href="../id458914/index.html">Apa (tidak) yang perlu Anda ketahui untuk membuat game di Unity</a></li>
<li><a href="../id458916/index.html">Di bawah kap React. Kami menulis implementasi kami dari awal</a></li>
<li><a href="../id458918/index.html">Apa yang bisa Anda pelajari dari desain gim kasual</a></li>
<li><a href="../id458920/index.html">Konferensi untuk penggemar DevOps</a></li>
<li><a href="../id458924/index.html">Kecelakaan membantu Anda belajar</a></li>
<li><a href="../id458926/index.html">Tragedi tidak datang sendiri</a></li>
<li><a href="../id458928/index.html">XLNet vs BERT</a></li>
<li><a href="../id458930/index.html">Bagaimana siswa dari Perm berhasil mencapai final kejuaraan penambangan data internasional, Piala Penambangan Data 2019</a></li>
<li><a href="../id458932/index.html">Yota - atau bagaimana Anda bisa mengetahui semuanya</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
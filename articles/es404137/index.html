<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ú¥Ô∏è ‚ò∏Ô∏è üì≤ Eliezer Yudkowsky, fil√≥sofo de inteligencia artificial, sobre singularidad, cerebro bayesiano y duendes en un gabinete üê® üßùüèæ ü§û</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eliezer Shlomo Yudkovsky es un especialista estadounidense en inteligencia artificial, que estudia los problemas de la singularidad tecnol√≥gica y abog...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Eliezer Yudkowsky, fil√≥sofo de inteligencia artificial, sobre singularidad, cerebro bayesiano y duendes en un gabinete</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/404137/"><img src="https://habrastorage.org/getpro/geektimes/post_images/152/af6/3ff/152af63ff689233ebebadde98fed2580.png" alt="imagen"><br><br>  <i>Eliezer Shlomo Yudkovsky es un especialista estadounidense en inteligencia artificial, que estudia los problemas de la singularidad tecnol√≥gica y aboga por la creaci√≥n de AI amigable.</i>  <i>En los c√≠rculos no acad√©micos, es mejor conocido como el autor de la ficci√≥n de fan√°ticos de Harry Potter y M√©todos de racionalidad bajo los auspicios de Less Wrong.</i> <br><br>  Siempre me sorprendieron las personas inteligentes que creen en cosas que me parecen absurdas.  Por ejemplo, el genetista y director de los Institutos Nacionales de Salud, Francis Collins, cree que Jes√∫s resucit√≥ de entre los muertos.  El te√≥rico de IA Eliezer Yudkowsky cree que los autos ... Pero mejor le dar√© la palabra yo mismo.  En 2008, lo entrevist√© en Bloggingheads.tv, pero no sali√≥ nada bueno porque decid√≠ que era un seguidor del gur√∫ de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la</a> singularidad de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ray Kurzweil</a> .  Pero Yudkovsky no sigui√≥ a nadie y nunca fue a la universidad.  Es un te√≥rico terco y original de la inteligencia, tanto humana como artificial.  Su trabajo (por ejemplo, un ensayo que me ayud√≥ a comprender, o me dio la ilusi√≥n de comprender, los teoremas de Bayes) exuda la arrogancia de los autodidactas, cuyos bordes afilados no fueron pulidos por una educaci√≥n formal, pero esto es parte de su encanto.  Incluso cuando te molesta, Yudkovsky es divertido, fresco, provocativo.  Para obtener detalles de su biograf√≠a, consulte su sitio web personal o el sitio web del Instituto para el Estudio de la Inteligencia de M√°quinas, en el que particip√≥.  Y lea esta entrevista con una bonificaci√≥n en forma de comentarios de su esposa Briena. <br><a name="habracut"></a><br>  <b>Horgan</b> : Cuando te preguntan en una fiesta qu√© haces, ¬øqu√© respondes? <br><br>  <b>Yudkovsky</b> : Depende del evento.  ‚ÄúSoy especialista en teor√≠a de la decisi√≥n‚Äù o ‚ÄúCofundador del Instituto para el Estudio de la Inteligencia de M√°quinas‚Äù o, si se trata de una fiesta de un tipo diferente, hablo de mis obras de arte. <br><br>  <b>X:</b> ¬øCu√°l es tu pel√≠cula de IA favorita y por qu√©? <br><br>  <b>Yu: La</b> IA en las pel√≠culas es terriblemente est√°ndar.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ex Machina se ha</a> acercado tanto a una excepci√≥n a esta regla como se puede esperar. <br><br>  <b>X:</b> ¬øLa utilidad de la universidad est√° sobrevalorada? <br><br>  <b>Yu:</b> Me sorprender√≠a si se subestimara su utilidad, dados los requisitos sociales para terminarlo.  Hasta donde s√©, no hay raz√≥n para no creer en los economistas que creen que la universidad se ha convertido en un "producto prestigioso" y que los intentos de aumentar los pr√©stamos estudiantiles simplemente han aumentado el costo de la universidad y la carga de la deuda estudiantil. <br><br>  <b>X:</b> ¬øPor qu√© escribes historias de ficci√≥n? <br><br>  <b>Yu:</b> Si reformulas los c√≥mics de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Wondermark</a> : "Al principio trat√© de no hacerlo, pero no funcion√≥". <br><br>  Adem√°s, la literatura seria transmite conocimiento, mientras que la ficci√≥n transmite experiencia.  Si quieres entender las pruebas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de la f√≥rmula de Bayes</a> , puedo usar diagramas.  Si quieres sentir c√≥mo es usar la l√≥gica de Bayes, necesito escribir una historia en la que el personaje lo haga. <br><br>  <b>X:</b> ¬øEres religioso en alg√∫n sentido? <br><br>  <b>Yu:</b> no.  Cuando comete un error, debe evitar la tentaci√≥n de salir en defensa, tratar de encontrar alg√∫n punto de vista desde el cual tenga al menos un poco de raz√≥n.  Es mucho m√°s sabio decir: "Oh", admitir que ni siquiera ten√≠a un poco de raz√≥n, tragarse una p√≠ldora amarga entera y continuar viviendo.  As√≠ es como la humanidad deber√≠a relacionarse con la religi√≥n. <br><br>  <b>X:</b> Si te convirtieras en el "Rey del mundo", ¬øcu√°l estar√≠a en la parte superior de tu lista de tareas pendientes? <br><br>  <b>Yu: Una</b> vez escrib√≠: ‚ÄúUna prueba para un libertario funciona as√≠: imagina que has ganado poder;  ¬øQu√© pensar√°s en primer lugar, sobre las leyes que aceptas o sobre las leyes que derogas?  No soy 100% libertario, porque no toda mi lista de deseos se expresa en la abolici√≥n de las leyes y la relajaci√≥n de las restricciones.  Pero me imagino c√≥mo tratar√≠a de hacer un mundo en el que una persona desempleada pudiera ofrecerle transporte al trabajo, obtener $ 5 por un viaje de 20 minutos, y no le suceder√≠a nada malo por esto.  No tendr√≠a que perder el seguro de desempleo, registrar un permiso comercial, perder el seguro m√©dico, someterse a una auditor√≠a, pedirle a un abogado que certifique que su trabajo cumple con las normas de la Administraci√≥n de Protecci√≥n Laboral, etc.  Simplemente habr√≠a agregado $ 5. <br><br>  Intentar√≠a volver a un estado en el que contratar a un empleado ser√≠a tan simple como en el a√±o 1900.  Quiz√°s ahora haya un sentido en ciertas medidas de seguridad, pero tratar√≠a de crear tal seguridad que no restrinja a una persona y no produzca documentos como resultado del simple regreso de una persona a la econom√≠a. <br><br>  Intentar√≠a hacer todo lo que los economistas inteligentes han estado gritando durante mucho tiempo, y que ning√∫n estado hace.  Reemplace los impuestos a la inversi√≥n y a la renta con impuestos al consumo y bienes inmuebles  Reemplace el salario m√≠nimo con impuestos de n√≥mina negativos.  Establezca una pol√≠tica para apuntar al PIB nominal para los bancos centrales y deje de apoyar estructuras "demasiado grandes para ir a la quiebra".  Exigir que, durante el litigio de patentes, la parte perdedora pague honorarios legales [ <i>siguiendo el llamado</i>  <i>Regla inglesa - en contraste con las leyes estadounidenses, seg√∫n las cuales cada una de las partes incumple sus propios costos - aprox.</i>  <i>perev.</i>  ] y devolver la duraci√≥n de los derechos de autor a 28 a√±os.  Eliminar obst√°culos para construir casas.  Copiar seguro de salud de Singapur.  Gobierno electr√≥nico en Estonia.  Reemplazar comit√©s y procesos complejos de toma de decisiones con individuos espec√≠ficos que toman decisiones documentadas p√∫blicamente y son responsables de esto.  Realice experimentos controlados con varias opciones para gestionar pa√≠ses y tenga en cuenta sus resultados.  Puedo ir a la lista por horas. <br><br>  Todo esto puede no importar en doscientos millones de a√±os.  Pero los activos nominales resultantes del auge econ√≥mico pueden hacer un buen trabajo mientras trato de averiguar qu√© haremos con la inteligencia artificial.  Lo obvio es el proyecto de Manhattan en alg√∫n lugar de la isla, con pagos basados ‚Äã‚Äãen la competencia entre los fondos de cobertura m√°s grandes, en los que las personas pueden explorar el problema de la inteligencia artificial generalizada sin publicar los resultados de su trabajo que autom√°ticamente traer√° el fin del mundo.  Y a menos que aceptemos que tengo habilidades m√°gicas o un modo fundamentalmente irreversible, no veo c√≥mo cualquier ley que aceptar√≠a retrasar√≠a el enfoque de la IA con bastante fuerza en un planeta donde las computadoras son ubicuas. <br><br>  Pero todo esto todav√≠a puede considerarse un experimento mental imposible y en la vida real la probabilidad de tal experimento es cero. <br><br>  <b>X:</b> ¬øQu√© tiene de bueno el teorema de Bayes? <br><br>  <b>Yu:</b> Bueno, por ejemplo, ella es muy profunda.  Por lo tanto, tal pregunta es dif√≠cil de responder brevemente. <br><br>  Podr√≠a responder que el teorema de Bayes puede llamarse la segunda ley de la termodin√°mica para la cognici√≥n.  Si concluye que la probabilidad de alguna suposici√≥n es del 99%, ya sea la presencia de leche en el supermercado o la causa antropog√©nica del calentamiento global, entonces tiene una combinaci√≥n de probabilidades a priori suficientemente buenas y evidencia bastante confiable.  Este no es un requisito reglamentario, es una ley.  As√≠ como un autom√≥vil no puede conducir sin disipar la entrop√≠a, no se puede obtener una buena imagen del mundo sin realizar un proceso en el que exista una estructura bayesiana en alg√∫n lugar del interior, incluso si las probabilidades no se utilizan directamente en el proceso. <br><br>  Personalmente, creo que lo principal que Bayes puede ofrecernos es la existencia de reglas, leyes de hierro que determinan si la forma de pensar funciona para marcar la realidad.  A los mormones se les dice que reconocen la verdad del Libro de Morm√≥n a trav√©s de una sensaci√≥n de ardor en el coraz√≥n.  Acepte conservadoramente la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">probabilidad a priori del</a> Libro de Morm√≥n como una en mil millones.  Luego, evaluamos la probabilidad de que el Libro de Morm√≥n no sea cierto, y alguien experiment√≥ una sensaci√≥n de ardor en el coraz√≥n despu√©s de que le dijeron que esto era de esperarse.  Si comprende la f√≥rmula de Bayes, nos daremos cuenta de inmediato de que la baja probabilidad de la prueba es inconmensurable con la baja probabilidad de la hip√≥tesis que est√°n tratando de probar con su ayuda.  Ni siquiera necesita encontrar n√∫meros espec√≠ficos para entender que no convergen, como descubri√≥ Philip Tetlock en su estudio de " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">superpredictores</a> ", a menudo conoc√≠an la f√≥rmula de Bayes, pero rara vez daban n√∫meros espec√≠ficos.  En cierto sentido, es m√°s dif√≠cil enga√±arte si entiendes que hay alg√∫n tipo de matem√°tica con la que puedes determinar con precisi√≥n la fuerza de la prueba y entender si es suficiente para superar la baja probabilidad de la hip√≥tesis.  No puedes inventar algo y creer en √©l, porque no funciona as√≠. <br><br>  <b>X:</b> ¬øTe impresiona la hip√≥tesis del cerebro bayesiano? <br><br>  <b>Yu:</b> Creo que algunas personas que discuten sobre este tema hablan de cosas diferentes.  Preguntar si el cerebro es un algoritmo bayesiano es como preguntar si el Honda Accord <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">funciona con un motor t√©rmico Carnot</a> .  Si una persona dice: "Cada autom√≥vil es un proceso termodin√°mico que requiere combustible y disipa el calor perdido", y otra persona escucha: "Si construye un diagrama de ciclo de Carnot y muestra su mec√°nica, debe aceptar que se ve como el interior de un Honda Accord "Entonces el acalorado debate es inevitable. <br><br>  Algunas personas estar√°n muy felices cuando abran el motor de combusti√≥n interna, encuentren los cilindros y digan: "¬°Estoy seguro de que convierten el calor en presi√≥n y ayudan a mover el autom√≥vil hacia adelante!"  Y tendr√°n raz√≥n, pero otras personas dir√°n: ‚ÄúTe est√°s enfocando en el √∫nico componente de un conjunto mucho m√°s grande de piezas de autom√≥viles.  El convertidor catal√≠tico tambi√©n es muy importante, y no est√° en sus diagramas de ciclo de Carnot.  Y a veces un aire acondicionado funciona para nosotros, funcionando exactamente lo contrario de c√≥mo funciona el motor t√©rmico seg√∫n sus palabras ". <br><br>  No creo que sea sorprendente si digo que las personas que te critican: "No est√°s familiarizado con los autos modernos;  necesita un conjunto completo de m√©todos diferentes para construir un motor, como velas y convertidores catal√≠ticos, y no solo sus procesos termodin√°micos ‚Äù, pierden un nivel clave de abstracci√≥n. <br><br>  Pero si desea saber si el cerebro puede considerarse literalmente bayesiano, y no un dispositivo que realiza un trabajo cognitivo, cuya naturaleza podemos entender usando m√©todos bayesianos, entonces puedo responder su pregunta: "No, por supuesto".  Puede haber varios "cilindros" bayesianos en este "motor", pero mucho parecer√° tan extra√±o como los cinturones de seguridad y el aire acondicionado.  Pero estas adiciones no cambiar√°n el hecho de que para identificar correctamente una manzana basada en evidencia sensorial, se necesita hacer algo que pueda interpretarse como resultado de la inducci√≥n que pueda comprender el concepto de una manzana y se actualice con base en la evidencia que distingue las manzanas de las que no son manzanas. <br><br>  <b>X:</b> ¬øEs posible ser demasiado racional? <br><br>  <b>Yu:</b> Puedes meterte en el llamado  "El valle de la mala racionalidad".  Si antes de eso fueron irracionales en varias cosas, equilibr√°ndose entre s√≠, entonces, si se vuelven racionales, pueden volverse peores que antes.  Cuanto m√°s te vuelvas racional, peor puedes ser si eliges la direcci√≥n incorrecta para aplicar tus habilidades. <br><br>  Pero no recomendar√≠a cuidar demasiado esa oportunidad.  En mi opini√≥n, las personas que hablan de lo ingeniosamente irracional que pueden ser son idiotas.  Es dif√≠cil encontrar una situaci√≥n de vida realista, no exagerada, en la que puedas decidir ser irracional, y el resultado de esto a√∫n es desconocido para ti.  En la vida real, es mejor decirse la verdad y no ser inteligente. <br><br>  Es posible que el representante ideal del pensamiento bayesiano sea incompatible con una vida interesante y entretenida.  Pero claramente este no es un problema tan grande como nuestra tendencia a la autodestrucci√≥n. <br><br>  <b>X:</b> ¬øC√≥mo difiere su punto de vista sobre la singularidad del de Kurzweil? <br><br>  <b>Yu:</b> <br>  ‚Ä¢ No creo que la ley de Moore pueda aplicarse a la IA.  La IA es un problema de software. <br>  ‚Ä¢ No creo que el primer intelecto sobrehumano aparezca de la fusi√≥n de m√°quinas con personas.  Han pasado cien a√±os desde la llegada de los autom√≥viles, y ahora estamos tratando de hacer un exoesqueleto para un caballo, y un autom√≥vil com√∫n a√∫n es m√°s r√°pido. <br>  ‚Ä¢ No creo que la primera IA fuerte se base en algoritmos de neurobiolog√≠a, as√≠ como los aviones no se basaron en p√°jaros. <br>  ‚Ä¢ No creo que la fusi√≥n de nano, info y biotecnolog√≠as sea posible, inevitable, bien definida o necesaria. <br>  ‚Ä¢ Creo que entre 1930 y 1970 hubo m√°s cambios que entre 1970 y 2010. <br>  ‚Ä¢ Creo que en los pa√≠ses desarrollados la productividad se estanca. <br>  ‚Ä¢ Creo que la extrapolaci√≥n de la ley de Moore al progreso tecnol√≥gico, que supuestamente predice todo lo que ser√° m√°s inteligente que los humanos despu√©s del advenimiento de la IA, es algo muy extra√±o.  Una IA m√°s inteligente arruina todos tus gr√°ficos. <br>  ‚Ä¢ Algunos analistas, como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Illka ‚Äã‚ÄãTuomi</a> , creen que la ley de Moore se rompi√≥ a principios de la d√©cada de 2000.  No estoy seguro de que pueda objetar. <br>  ‚Ä¢ El √∫nico umbral tecnol√≥gico que me interesa es donde la IA gana la capacidad de mejorar.  No tenemos un horario para llegar a este umbral, y no est√° claro cu√°l ser√° (aunque no debe exceder en gran medida el nivel de una persona, ya que una persona entiende la inform√°tica), por lo que su ofensiva no se puede predecir. <br>  ‚Ä¢ No creo que el resultado de dicho progreso sea bueno por defecto.  Creo que puede hacerse bien, pero ser√° necesario trabajarlo seriamente, y las figuras clave no est√°n interesadas en esto.  Decirle a la gente que estamos en una trayectoria natural hacia grandes y maravillosos momentos ser√° una mentira. <br>  ‚Ä¢ Creo que "singularidad" se ha convertido en una palabra maleta con demasiados significados y detalles incompatibles dentro, as√≠ que dej√© de usarla. <br><br>  <b>X:</b> ¬øEs probable que te conviertas en un cyborg ultrainteligente? <br><br>  <b>Yu:</b> La ley de conjunci√≥n de probabilidades dice que P (A&amp;B) &lt;= P (A).  La probabilidad de la ocurrencia simult√°nea de los eventos A y B es menor que la probabilidad de la ocurrencia de un evento A. En los experimentos en los que las personas creen que P (A&amp;B)&gt; P (A) para dos eventos A y B, aparece un " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">error de conjunci√≥n</a> ", por ejemplo, en 1982, expertos del Congreso Internacional de Predicciones asignaron una mayor probabilidad al evento "Rusia invade Polonia y se rompen las relaciones diplom√°ticas con la URSS" que la probabilidad de un evento separado "ruptura de las relaciones diplom√°ticas con la URSS", designado por otro grupo.  Del mismo modo, otro grupo asign√≥ una mayor probabilidad al evento "Un terremoto en California conduce a una inundaci√≥n que lleva a miles de v√≠ctimas" que otro, la probabilidad del evento "En alg√∫n lugar de Am√©rica del Norte hay una inundaci√≥n con miles de v√≠ctimas".  Aunque agregar detalles adicionales a la historia claramente lo hace menos probable, lo hace m√°s cre√≠ble.  Para m√≠, entendiendo este hecho, es como un " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">puente de burros</a> " para el futurismo serio: la diferencia entre el hecho de que sopesas cuidadosamente cada suposici√≥n individual y descubres si puedes apoyar esta aclaraci√≥n independientemente de todas las dem√°s y que simplemente compones una maravillosa y una historia vibrante <br><br>  Esto es todo lo que digo en el contexto de responder la pregunta: ‚Äú¬øPor qu√© agregas a esto un refinamiento como un cyborg?  No quiero ser un cyborg ".  Es necesario tejer cuidadosamente detalles adicionales a las declaraciones. <br><br>  <b>X:</b> ¬øTienes alguna posibilidad de inmortalidad? <br><br>  <b>Yu:</b> ¬øLiteralmente?  La inmortalidad literal es dif√≠cil de lograr.  Para vivir mucho m√°s que unos pocos billones de a√±os, debe reconsiderar el destino esperado de un universo en expansi√≥n.  Para vivir m√°s tiempo que los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">googolpleks</a> , es necesario que cometamos un error sobre los fundamentos de las leyes f√≠sicas, y no solo en los detalles. <br><br>  Incluso si parte del razonamiento inusual resulta ser cierto y nuestro Universo puede generar universos hijos, esto no nos dar√° la inmortalidad.  Para vivir muchos m√°s a√±os de Googleplex y no repetirlo, necesitar√° computadoras con m√°s elementos que Google, y esa m√°quina no encajar√° en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">esfera de Hubble</a> . <br><br>  Y googolpleks no es infinito.  Parafraseando a Martin Gardner, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el n√∫mero de Graham</a> sigue siendo bastante peque√±o, ya que la mayor√≠a de los n√∫meros finales son mucho m√°s grandes que √©l.  Si quieres quedarte impresionado, lee sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">las jerarqu√≠as de r√°pido crecimiento</a> , y el infinito a√∫n ser√° m√°s largo.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Solo teor√≠as antr√≥picas muy extra√±as y aterradoras te permitir√°n vivir lo suficiente como para ver una parada en la m√°quina de Turing m√°s antigua con cientos de estados. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sin embargo, no creo que desde un punto de vista emocional me gustar√≠a vivir lo suficiente como para ver que la cent√©sima cifra en el juego " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">busque a un trabajador castor</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">". De alguna manera puedo empatizar conmigo mismo, que ha vivido dentro de cien a√±os a partir de ahora. Ese futuro puedo empatizar conmigo mismo dentro de otros cien a√±os. Y tal vez en alg√∫n lugar de esta secuencia habr√° alguien que se enfrente a la perspectiva de dejar de existir, y puede estar muy triste por esto. Pero no estoy seguro de poder imaginar a esta persona. "Quiero vivir otro d√≠a. Ma√±ana tambi√©n querr√© vivir otro d√≠a. Por lo tanto, quiero vivir para siempre, demostrado por la inducci√≥n de enteros positivos n√∫meros ". Incluso mi deseo durante mucho tiempo . De la vida en el universo es f√≠sicamente posible - es una abstracci√≥n generada por la inducci√≥n no puede imaginar s√≠ a trav√©s de un bill√≥n de a√±os. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Describ√≠ la singularidad como una fantas√≠a escapista y pseudocient√≠fica, que nos distrae del cambio clim√°tico, las guerras, la desigualdad y otros problemas graves. ¬øPor qu√© me equivoco? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Porque est√°s tratando de predecir hechos emp√≠ricos a trav√©s del psicoan√°lisis. Nunca funcionar√° </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Supongamos que vivimos para ver el advenimiento de la IA que es lo suficientemente inteligente como para que haga el mismo trabajo de mejorar la IA que las personas. Puede ajustarse, programar, inventar nuevos algoritmos. Para mejorar ¬øQu√© suceder√° despu√©s: se volver√° m√°s inteligente, ver√° a√∫n m√°s oportunidades de mejora y alcanzar√° r√°pidamente un nivel muy alto? ¬øO no pasar√° nada especial?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Puede suceder que (A) la superaci√≥n personal en un determinado delta haga que la IA sea lo suficientemente inteligente como para que pueda mirar hacia atr√°s y encontrar una nueva mejora potencial en el tama√±o de k * delta, donde k&gt; 1, y esto se repetir√° muchas veces para conducir a una r√°pida superaci√≥n nivel de superinteligencia. Lo que </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Irving John Goode</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> llam√≥ la "explosi√≥n de inteligencia". O (B), k es menos que la unidad o todas estas mejoras son peque√±as y no conducen a la aparici√≥n de superinteligencia, o la superinteligencia es generalmente imposible y, en lugar de una explosi√≥n, habr√° un cero. ¬øQu√© es verdad, A o B? Si construyes una IA de cierto nivel e intenta hacerlo, algo suceder√° en el mundo real emp√≠rico, y este evento estar√° determinado por hechos relacionados con el panorama de los algoritmos y las mejoras alcanzables.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No se puede obtener informaci√≥n confiable sobre este evento a partir del psicoan√°lisis de personas. Es como tratar de arrancar un autom√≥vil sin combustible, eso es lo que nos dice el teorema de Bayes. Algunas personas siempre ser√°n escapistas, independientemente de los valores reales de las variables ocultas en inform√°tica, por lo que observar a algunos escapistas no se puede llamar prueba rigurosa. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Esta es una idea err√≥nea sobre la naturaleza de la racionalidad: que es racional creer que "los duendes en los armarios no existen" porque la fe en los duendes de un armario es est√∫pida, inmadura, obsoleta, y solo los idiotas creen en ella. El verdadero principio de la racionalidad es ir y revisar el armario. Entonces, en aquellos universos donde los duendes viven en armarios, creer√°s en los duendes, y en los universos donde los duendes no est√°n en los armarios, no creer√°s en ellos.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es dif√≠cil, pero en principio es posible tratar de mirar por la puerta entreabierta y preguntar: "¬øQu√© ser√≠a diferente en el Universo si no fuera posible obtener un buen ingreso de las inversiones cognitivas, es decir, una IA que intenta mejorar no terminar√≠a con una explosi√≥n, sino con un cero? ¬øQu√© otros hechos ser√≠an caracter√≠sticos de tal universo? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hay personas que afirman que la IA solo se puede elevar al nivel de una persona, ya que nosotros mismos somos personas y no podemos elevarla m√°s. Me parece que si nuestro universo es as√≠, entonces deber√≠amos observar una disminuci√≥n en los ingresos de las inversiones en hardware y software para ajedrez inform√°tico que excede el nivel de una persona, lo que en realidad no sucede. Adem√°s, la selecci√≥n natural no podr√≠a crear una persona en ese momento, y la madre de Einstein deber√≠a haber sido un f√≠sico incre√≠ble, etc.</font></font> etc. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hay personas que sostienen que cuanto m√°s complejo es el algoritmo, m√°s ajustes necesita y que nuestra inteligencia sirve como una especie de limitaci√≥n para este proceso. Pero esto no est√° de acuerdo con los registros antropol√≥gicos de la inteligencia humana; Las inversiones en ajuste cerebral y mutaciones proporcionan capacidades cognitivas mejoradas. Lo sabemos porque la gen√©tica nos dice que las mutaciones con una peque√±a respuesta estad√≠stica no se arreglan durante la evoluci√≥n. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y los hom√≠nidos no necesitaban un cerebro exponencialmente m√°s grande que los chimpanc√©s. Y la cabeza de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">John von Neumann</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> no </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">era</font></a><font style="vertical-align: inherit;"> exponencialmente m√°s grande que la cabeza de la persona promedio.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Desde un punto de vista puramente pr√°ctico, los axones humanos transmiten informaci√≥n a una velocidad de un mill√≥n de veces menos que la velocidad de la luz, e incluso desde el punto de vista de la disipaci√≥n de calor, cada operaci√≥n sin√°ptica consume un mill√≥n de veces m√°s que la disipaci√≥n t√©rmica m√≠nima de una operaci√≥n binaria irreversible a 300 Kelvin, y as√≠ sucesivamente. ¬øPor qu√© debemos suponer que el software del cerebro est√° m√°s cerca del √≥ptimo que el hierro? El privilegio de la inteligencia humana es que es el nivel m√°s peque√±o de inteligencia capaz de crear una computadora. Si fuera posible crear una computadora con un nivel inferior de inteligencia, lo discutir√≠amos en un nivel inferior.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pero este no es un argumento simple, y para una descripci√≥n detallada, env√≠o personas a uno de mis viejos trabajos, "La microeconom√≠a de la explosi√≥n de inteligencia", que, desafortunadamente, todav√≠a sirve como la mejor fuente de informaci√≥n. Pero son precisamente esas preguntas las que deben formularse para utilizar la evidencia disponible para discutir si veremos una explosi√≥n de IA en la que una cierta mejora en las capacidades cognitivas invertidas en la auto-optimizaci√≥n dar√° un aumento en exceso de esta mejora. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En cuanto a las oportunidades y sus precios: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">puede imaginar un mundo sin una explosi√≥n de inteligencia y sin superinteligencia. O un mundo donde los trucos que los expertos en aprendizaje autom√°tico utilizar√°n para controlar la s√∫per IA son adecuados para controlar a las personas y al r√©gimen sobrehumano. O un mundo donde funciona el </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">internalismo moral</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, as√≠ que todas las IA bastante avanzadas son buenas. En tales mundos, nadie necesita todo el trabajo y las preocupaciones del Instituto para la Investigaci√≥n del Aprendizaje Autom√°tico. Y se desperdiciaron varias mosquiteras, y era mejor entregarlas al fondo para combatir la malaria. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tambi√©n puede imaginar un mundo en el que lucha contra la malaria, lucha y mantiene las emisiones de carbono al nivel adecuado, o utiliza soluciones de geoingenier√≠a para neutralizar los errores ya cometidos. Y todo esto resulta in√∫til, ya que la civilizaci√≥n no puede resolver el problema de la moralidad de la IA, y todos los ni√±os salvados de la malaria con la ayuda de redes crecen solo para que las nanom√°quinas los maten en un sue√±o.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Creo que las personas que est√°n tratando de participar en una organizaci√≥n ben√©fica razonable estar√°n de acuerdo en que no nos gustar√≠a vivir en ninguno de estos mundos. La √∫nica pregunta es cu√°l es m√°s probable. El principio central de la racionalidad es no rechazar la creencia en los duendes, porque es est√∫pido y no prestigioso, y no creer en los duendes, porque es saludable y hermoso. El principio central de la racionalidad es qu√© signos observables y conclusiones l√≥gicas nos ayudar√°n a elegir uno de estos dos mundos.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Creo que el primer mundo es poco probable, y el segundo es probable. Entiendo que tratar de convencer a otros de esto es tratar de nadar contra el flujo de la fe en la normalidad eterna. Cree que solo nuestra civilizaci√≥n a corto plazo, que ha existido durante varias d√©cadas, y solo nuestra especie, que existe solo un momento en las escalas evolutivas y geol√≥gicas, tiene sentido y debe existir para siempre. Y aunque creo que el primer mundo es solo un sue√±o optimista, no creo que debamos ignorar el problema, del cual nos asustaremos en el futuro. La misi√≥n del Instituto es realizar investigaciones hoy, que, seg√∫n las personas que viven despu√©s de 30 a√±os, deber√≠an haber comenzado hace 30 a√±os. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬øTu esposa Brijena cree en la singularidad?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Brijena: Si alguien me preguntara si creo en una singularidad, levantar√≠a una ceja y les preguntar√≠a si creen en los camiones autom√°ticos. Esta es una pregunta extra√±a. No s√© cu√°l ser√° la primera flota de camiones autom√°ticos, ni cu√°nto tiempo les llevar√° reemplazar el sistema de transporte de carga existente. Y no creo que crea en camiones rob√≥ticos, predigo con confianza que el transporte no tripulado reemplazar√° el transporte moderno con la participaci√≥n de personas, porque vamos en esta direcci√≥n si no sucede nada realmente extra√±o. Por la misma raz√≥n, predigo con confianza una explosi√≥n de inteligencia. En otros significados de la palabra "singularidad" no estoy tan seguro. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Brijena dio su respuesta sin ver mis respuestas. Es solo que estamos bien el uno para el otro. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬øEs posible crear superinteligencia sin entender c√≥mo funciona el cerebro? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> En el mismo sentido, puedes hacer aviones sin entender c√≥mo vuela un p√°jaro. No es necesario ser un experto en aves, pero al mismo tiempo necesita muchos conocimientos para construir un avi√≥n, habiendo obtenido lo que, en principio, ya puede comprender cu√°n rudo se eleva o se repele un p√°jaro desde el aire. Por lo tanto, estoy escribiendo sobre la racionalidad humana: si vas lo suficientemente lejos en el tema de la inteligencia artificial, no puedes evitar pensar en algunas ideas sobre c√≥mo piensa la gente. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬øQu√© podr√≠a querer la superinteligencia? ¬øTendr√°n algo como deseo sexual? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Piense en un vasto espacio de posibilidades, en una esfera gigante multidimensional. Este es un espacio de tipos de mente, un conjunto de todos los algoritmos cognitivos posibles. Imagine que en alg√∫n lugar en la parte inferior de la esfera hay un peque√±o punto que denota a todas las personas que alguna vez han vivido. Este es un punto peque√±o, ya que todas las personas tienen aproximadamente el mismo cerebro, con corteza, cerebelo, t√°lamo, etc. Algunas personas no son como otras, por lo que puede ser un punto puntiagudo, pero los picos estar√°n en la misma escala que el punto en s√≠. Independientemente de su neuroat√≠picidad, no trabajar√° en otro algoritmo cortical.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Preguntar "qu√© quiere la superinteligencia" es la pregunta equivocada. Las superinteligencias no son una tribu extra√±a de personas que viven al otro lado del r√≠o y tienen costumbres ex√≥ticas. AI es simplemente el nombre de todo el espacio de posibilidades fuera de un peque√±o punto humano. Con el conocimiento suficiente, puede subir a este espacio de oportunidades y salir de all√≠ una IA que tiene deseos que pueden ser descritos en lenguaje humano por Lista de Deseos, pero no porque sea la Lista de Deseos natural de estos ex√≥ticos sobrehumanos, sino porque aisl√≥ una parte del espacio de los tipos de mente. .</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Con respecto a los deseos sexuales: si sabe exactamente lo que est√° haciendo, ha resuelto el problema principal de construir IA, queriendo de manera estable ciertas cosas mientras mejora, si ha resuelto el problema principal de dirigir las funciones utilitarias de AI a tareas que parecen enga√±osamente simples para una persona, y Un problema a√∫n m√°s complicado es la construcci√≥n de IA utilizando un cierto tipo de arquitectura, en la que importan cosas como los "deseos sexuales" y la "felicidad del sexo", entonces, tal vez, puedas hacer que la IA mire a las personas que est√°n modelando sean sus deseos, extraiga esa parte de ellos con respecto al deseo sexual y haga que la IA lo experimente. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por supuesto, tambi√©n puede, con buenos conocimientos de biolog√≠a org√°nica y aerodin√°mica, construir aviones que puedan aparearse con las aves.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pero no creo que los hermanos Wright deber√≠an haber hecho esas cosas al comienzo de sus actividades. Eso no tendr√≠a sentido. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parece m√°s razonable resolver el problema de penetrar en el espacio de las mentes y extraer de all√≠ una IA que no quiere desarmarnos en √°tomos de repuesto. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Quiero pensar que las criaturas extra-inteligentes profesar√°n la no violencia, porque entender√°n que la violencia es est√∫pida. ¬øSoy ingenuo? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> eso creo. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">David hume</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le dir√≠a que est√° cometiendo un error t√≠pico al aplicar el predicado de "estupidez" a los valores u operaciones oficiales de un individuo. Las acciones, elecciones, reglas pueden ser est√∫pidas si tienes alguna preferencia sobre el estado final del mundo. Si usted es una persona con meta-preferencias que no ha calculado completamente, es posible que tenga una plataforma en la que pueda confiar y llamar "est√∫pido" a algunas especulaciones sobre las preferencias de objetos. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maximizador de grapas [ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">experimento mental que demuestra c√≥mo la IA hecha sin intenci√≥n maliciosa puede da√±ar a la humanidad - aprox.</font></font></i>  <i>perev.</i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">] no comete un error computacional, al elegir aquellos casos de aquellos en los que se obtiene el n√∫mero m√°ximo de grapas. No est√° dentro de su plataforma de preferencias, eligiendo acciones err√≥neas, y no est√° dentro de su plataforma de meta-preferencias, eligiendo err√≥neamente preferencias. Calcula la respuesta a otra pregunta, y no a la que te haces, la pregunta "¬øQu√© debo hacer?" El maximizador de grapas simplemente realiza la acci√≥n que lleva a la mayor√≠a de las grapas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un escenario fatal es cuando la IA no te ama ni te odia, porque est√°s hecho de √°tomos que puedes usar para crear otra cosa. Teor√≠a de juegos y problemas de cooperaci√≥n en </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">el dilema del prisionero.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">no se manifiesten en todos los casos posibles. Por ejemplo, no aparecen cuando cierto sujeto es mucho m√°s fuerte que t√∫ que puede convertirte en √°tomos cuando quieres hacer clic en los botones "cooperar" o "cambiar". Y cuando pasamos este umbral, o has resuelto el problema de crear algo que no quiere hacerte da√±o, o ya has perdido. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬øLa superinteligencia </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">resolver√° el dif√≠cil problema de la conciencia</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> S√≠, y mirando hacia atr√°s, la respuesta nos parecer√° vergonzosamente simple. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬øLas superinteligencias tendr√°n libre albedr√≠o? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> S√≠, pero no tendr√°n la ilusi√≥n del libre albedr√≠o. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬øC√≥mo es tu utop√≠a? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dirigir√© a tus lectores a los m√≠os "</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Secuencias de la teor√≠a del entretenimiento</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> " </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">,</font></a><font style="vertical-align: inherit;"> ya que a√∫n no he logrado escribir una historia cuya acci√≥n se desarrolla en un mundo √≥ptimo entretenido y te√≥rico.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es404137/">https://habr.com/ru/post/es404137/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es404125/index.html">La cuenta regresiva se ha ido: quedan 7 d√≠as antes del Polybius ICO</a></li>
<li><a href="../es404127/index.html">El primer lanzamiento del Electron LV fue parcialmente exitoso</a></li>
<li><a href="../es404129/index.html">Happy Geeks Day (s√≠, √©l es hoy)</a></li>
<li><a href="../es404133/index.html">Para fines de este a√±o, Google planea mostrar en operaci√≥n una computadora cu√°ntica de 49 qubits</a></li>
<li><a href="../es404135/index.html">Google recopila y analiza las compras fuera de l√≠nea de los usuarios de Android Pay</a></li>
<li><a href="../es404139/index.html">Bitcoin en Rusia: impuestos (algunas preguntas simples)</a></li>
<li><a href="../es404141/index.html">Competencia desleal en proveedor</a></li>
<li><a href="../es404143/index.html">Pepitas diminutas: una revisi√≥n de los registradores rusos TrendVision Split and Tube</a></li>
<li><a href="../es404147/index.html">Sonido, solo eres "espacio": auriculares Campfire Audio Andromeda</a></li>
<li><a href="../es404149/index.html">Revisi√≥n de la nueva generaci√≥n de lectores impermeables PocketBook 641 Aqua 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
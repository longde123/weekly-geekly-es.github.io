<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßñüèΩ üë®üèª‚Äç‚öïÔ∏è üë¥üèΩ Concurrencia PostgreSQL: no esf√©rica, no caballo, no en el vac√≠o üö∂üèΩ üç¢ üê¥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Escalar un DBMS es un futuro que avanza continuamente. Los DBMS mejoran y escalan mejor en plataformas de hardware, mientras que las plataformas de ha...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Concurrencia PostgreSQL: no esf√©rica, no caballo, no en el vac√≠o</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/postgrespro/blog/423685/"><img src="https://habrastorage.org/webt/b0/s3/rq/b0s3rqkffufh7baruji0jc_vbgq.jpeg"><br><br>  Escalar un DBMS es un futuro que avanza continuamente.  Los DBMS mejoran y escalan mejor en plataformas de hardware, mientras que las plataformas de hardware aumentan la productividad, la cantidad de n√∫cleos y la memoria: Aquiles se est√° poniendo al d√≠a con la tortuga, pero a√∫n no lo ha hecho.  El problema de escalar DBMS est√° en pleno apogeo. <br><br>  Postgres Professional tuvo un problema con el escalado no solo te√≥ricamente, sino tambi√©n pr√°cticamente: con sus clientes.  Y m√°s de una vez.  Uno de esos casos ser√° discutido en este art√≠culo. <br><br>  PostgreSQL escala bien en sistemas NUMA si es una placa base √∫nica con m√∫ltiples procesadores y m√∫ltiples buses de datos.  Algunas optimizaciones se pueden leer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> .  Sin embargo, hay otra clase de sistemas, tienen varias placas base, el intercambio de datos entre ellas se realiza mediante interconexi√≥n, mientras que una instancia del sistema operativo est√° trabajando en ellas y para el usuario este dise√±o parece una sola m√°quina.  Y aunque formalmente tales sistemas tambi√©n pueden atribuirse a NUMA, en esencia est√°n m√°s cerca de las supercomputadoras, como  El acceso a la memoria local del nodo y el acceso a la memoria del nodo vecino difieren radicalmente.  La comunidad PostgreSQL cree que la √∫nica instancia de Postgres que se ejecuta en tales arquitecturas es una fuente de problemas, y a√∫n no existe un enfoque sistem√°tico para resolverlos. <br><a name="habracut"></a><br>  Esto se debe a que la arquitectura de software que usa memoria compartida est√° dise√±ada fundamentalmente por el hecho de que el tiempo de acceso de los diferentes procesos a su propia memoria remota es m√°s o menos comparable.  En el caso de que trabajemos con muchos nodos, la apuesta por la memoria compartida como un canal de comunicaci√≥n r√°pido deja de justificarse, porque debido a la latencia es mucho m√°s "barato" enviar una solicitud de una determinada acci√≥n al nodo (nodo) donde se encuentra datos interesantes que enviar estos datos en el bus.  Por lo tanto, para las supercomputadoras y, en general, los sistemas con muchos nodos, las soluciones de cl√∫ster son relevantes. <br><br>  Esto no significa que sea necesario poner fin a la combinaci√≥n de sistemas de m√∫ltiples nodos y la arquitectura t√≠pica de memoria compartida de Postgres.  Despu√©s de todo, si los procesos postgres pasan la mayor parte de su tiempo haciendo c√°lculos complejos localmente, entonces esta arquitectura ser√° incluso muy eficiente.  En nuestra situaci√≥n, el cliente ya hab√≠a comprado un poderoso servidor de m√∫ltiples nodos, y tuvimos que resolver los problemas de PostgreSQL en √©l. <br><br>  Pero los problemas eran graves: las solicitudes de escritura m√°s simples (cambiar varios valores de campo en un registro) se ejecutaron en un per√≠odo de varios minutos a una hora.  Como se confirm√≥ m√°s tarde, estos problemas se manifestaron en todo su esplendor precisamente por la gran cantidad de n√∫cleos y, en consecuencia, el paralelismo radical en la ejecuci√≥n de solicitudes con un intercambio relativamente lento entre nodos. <br><br>  Por lo tanto, el art√≠culo resultar√°, por as√≠ decirlo, con dos prop√≥sitos: <br><br><ul><li>  Comparta experiencia: qu√© hacer si en un sistema de m√∫ltiples nodos la base de datos se ralentiza en serio.  Por d√≥nde empezar, c√≥mo diagnosticar d√≥nde moverse. </li><li>  Describa c√≥mo se pueden resolver los problemas del propio DBMS PostgreSQL con un alto nivel de concurrencia.  Incluyendo c√≥mo el cambio en el algoritmo para tomar bloqueos afecta el rendimiento de PostgreSQL. </li></ul><br><h3>  Servidor y DB </h3><br>  El sistema constaba de 8 cuchillas con 2 enchufes en cada una.  En total, m√°s de 300 n√∫cleos (excluyendo hypertreading).  Un neum√°tico r√°pido (tecnolog√≠a patentada por el fabricante) conecta las cuchillas.  No es que sea una supercomputadora, pero para una instancia del DBMS, la configuraci√≥n es impresionante. <br>  La carga tambi√©n es bastante grande.  M√°s de 1 terabyte de datos.  Alrededor de 3000 transacciones por segundo.  M√°s de 1000 conexiones a postgres. <br><br>  Habiendo comenzado a lidiar con las expectativas de grabaci√≥n por hora, lo primero que hicimos fue escribir en el disco como causa de demoras.  Tan pronto como comenzaron los retrasos incomprensibles, las pruebas comenzaron a hacerse exclusivamente en <code>tmpfs</code> .  La imagen no ha cambiado.  El disco no tiene nada que ver con eso. <br><br><h3>  Primeros pasos con los diagn√≥sticos: vistas </h3><br>  Dado que los problemas surgieron probablemente debido a la alta competencia de los procesos que "tocan" los mismos objetos, lo primero que debe verificar son los bloqueos.  En PostgreSQL, hay una vista <code>pg.catalog.pg_locks</code> y <code>pg_stat_activity</code> para tal verificaci√≥n.  El segundo, ya en la versi√≥n 9.6, agreg√≥ informaci√≥n sobre lo que el proceso est√° esperando ( <i>Amit Kapila, Ildus Kurbangaliev</i> ) - <code>wait_event_type</code> .  Los valores posibles para este campo se describen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><br>  Pero primero, solo cuenta: <br><br><pre> <code class="sql hljs">postgres=<span class="hljs-comment"><span class="hljs-comment"># SELECT COUNT(*) FROM pg_locks; count ‚Äî---‚Äî 88453 (1 row) postgres=# SELECT COUNT(*) FROM pg_stat_activity; count ‚Äî---‚Äî 1826 (1 row) postgres=# SELECT COUNT(*) FROM pg_stat_activity WHERE state ='active'; count ‚Äî---‚Äî 1005</span></span></code> </pre> <br>  Estos son n√∫meros reales.  Alcanz√≥ hasta 200,000 cerraduras. <br>  Al mismo tiempo, tales bloqueos colgaban de la solicitud desafortunada: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">COUNT</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">mode</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">mode</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_locks <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> pid =<span class="hljs-number"><span class="hljs-number">580707</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">mode</span></span>; count | mode ‚Äî<span class="hljs-comment"><span class="hljs-comment">-----+---------------‚Äî 93 | AccessShareLock 1 | ExclusiveLock</span></span></code> </pre> <br>  Al leer el b√∫fer, el DBMS usa el bloqueo <code>share</code> , mientras escribe, <code>exclusive</code> .  Es decir, los bloqueos de escritura representaron menos del 1% de todas las solicitudes. <br>  En la vista <code>pg_locks</code> , los tipos de bloqueo no siempre se ven como se describe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en la documentaci√≥n del</a> usuario. <br><br>  Aqu√≠ est√° la placa del partido: <br><br><pre> <code class="plaintext hljs">AccessShareLock = LockTupleKeyShare RowShareLock = LockTupleShare ExclusiveLock = LockTupleNoKeyExclusive AccessExclusiveLock = LockTupleExclusive</code> </pre> <br>  La consulta SELECT mode FROM pg_locks mostr√≥ que CREATE INDEX (sin CONCURRENTLY) esperar√≠a 234 INSERTs y 390 INSERTs para el <code>buffer content lock</code> .  Una posible soluci√≥n es "ense√±ar" INSERTs de diferentes sesiones para cruzarse menos en buffers. <br><br><h3>  Es hora de usar perf </h3><br>  La utilidad <b><code>perf</code></b> recopila mucha informaci√≥n de diagn√≥stico.  En modo de <code>record</code> ... escribe estad√≠sticas de eventos del sistema en archivos (de manera predeterminada est√°n en <code>./perf_data</code> ), y en modo de <code>report</code> analiza los datos recopilados, por ejemplo, puede filtrar eventos que conciernen solo <code>postgres</code> o un <code>pid</code> dado: <br><br><pre> <code class="plaintext hljs">$ perf record -u postgres  $ perf record -p 76876  ,  $ perf report &gt; ./my_results</code> </pre> <br>  Como resultado, veremos algo como <br><br><img src="https://habrastorage.org/webt/rn/ta/rv/rntarvj2jticq7glciiqockk3-y.jpeg"><br><br>  C√≥mo usar <code>perf</code> para diagnosticar PostgreSQL se describe, por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> , as√≠ como en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">p√°gina de wiki</a> . <br><br>  En nuestro caso, incluso el modo m√°s simple proporcion√≥ informaci√≥n importante: <code>perf top</code> , que funciona, por supuesto, en el esp√≠ritu del sistema operativo <code>top</code> .  Con <code>perf top</code> vimos que la mayor√≠a de las veces el procesador pasa en los <code>PinBuffer()</code> centrales, as√≠ como en las <code>PinBuffer()</code> y <code>LWLockAttemptLock().</code>  . <br><br>  <code>PinBuffer()</code> es una funci√≥n que aumenta el contador de referencias al b√∫fer (mapeando una p√°gina de datos a la RAM), gracias a que los procesos de postgres saben qu√© b√∫feres se pueden forzar y cu√°les no. <br><br>  <code>LWLockAttemptLock()</code> - <code>LWLock</code> de captura de <code>LWLock</code> .  <code>LWLock</code> es un tipo de bloqueo con dos niveles de <code>shared</code> y <code>exclusive</code> , sin definir <code>deadlock</code> , los bloqueos se asignan previamente a la <code>shared memory</code> , los procesos de espera est√°n esperando en una cola. <br><br>  Estas funciones ya se han optimizado bastante en PostgreSQL 9.5 y 9.6.  Los spinlocks dentro de ellos fueron reemplazados por el uso directo de operaciones at√≥micas. <br><br><h3>  Gr√°ficos de llamas </h3><br>  Es imposible sin ellos: incluso si fueran in√∫tiles, todav√≠a valdr√≠a la pena contarlos: son inusualmente hermosos.  Pero son √∫tiles.  Aqu√≠ hay una ilustraci√≥n de <code>github</code> , no de nuestro caso (ni nosotros ni el cliente estamos listos para revelar detalles a√∫n). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/75b/909/e8d/75b909e8de5177a48fa7d73f53eff437.svg"><br><br>  Estas bellas im√°genes muestran muy claramente lo que toman los ciclos del procesador.  El mismo <code>perf</code> puede recopilar datos, pero el <code>flame graph</code> visualiza de manera inteligente los datos y construye √°rboles en funci√≥n de las pilas de llamadas recopiladas.  Puede leer m√°s sobre la creaci√≥n de perfiles con gr√°ficos de llama, por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> , y descargar todo lo que necesita <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><br>  En nuestro caso, una gran cantidad de <code>nestloop</code> era visible en los gr√°ficos de llamas.  Aparentemente, las uniones de una gran cantidad de tablas en numerosas solicitudes de lectura concurrentes causaron una gran cantidad de bloqueos de <code>access share</code> . <br><br>  Las estad√≠sticas recopiladas por <code>perf</code> muestran d√≥nde van los ciclos del procesador.  Y aunque vimos que la mayor parte del tiempo del procesador pasa por las cerraduras, no vimos qu√© conduce exactamente a expectativas tan largas de las cerraduras, ya que no vemos exactamente d√≥nde ocurren las expectativas de las cerraduras, porque  El tiempo de CPU no se pierde esperando. <br><br>  Para ver las expectativas en s√≠ mismas, puede crear una solicitud para la vista del sistema <code>pg_stat_activity</code> . <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> wait_event_type, wait_event, <span class="hljs-keyword"><span class="hljs-keyword">COUNT</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_stat_activity <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> wait_event_type, wait_event;</code> </pre> <br>  revel√≥ que: <br><br><pre> <code class="plaintext hljs">LWLockTranche | buffer_content | UPDATE ************* LWLockTranche | buffer_content | INSERT INTO ******** LWLockTranche | buffer_content | \r | | insert into B4_MUTEX | | values (nextval('hib | | returning ID Lock | relation | INSERT INTO B4_***** LWLockTranche | buffer_content | UPDATE ************* Lock | relation | INSERT INTO ******** LWLockTranche | buffer_mapping | INSERT INTO ******** LWLockTranche | buffer_content | \r</code> </pre> <br>  (los asteriscos aqu√≠ simplemente reemplazan los detalles de la solicitud que no revelamos). <br><br>  Puede ver los valores <code>buffer_content</code> (bloqueando el contenido de los buffers) y <code>buffer_mapping</code> (bloqueando los componentes de la placa hash <code>shared_buffers</code> ). <br><br><h3>  Para ayuda a gdb </h3><br>  Pero, ¬øpor qu√© hay tantas expectativas para este tipo de cerraduras?  Para obtener informaci√≥n m√°s detallada sobre las expectativas, tuve que usar el depurador <code>GDB</code> .  Con <code>GDB</code> podemos obtener una pila de llamadas de procesos espec√≠ficos.  Mediante la aplicaci√≥n de muestreo, es decir  Despu√©s de recopilar un cierto n√∫mero de pilas de llamadas aleatorias, puede hacerse una idea de qu√© pilas tienen las expectativas m√°s largas. <br><br>  Considere el proceso de compilaci√≥n de estad√≠sticas.  Consideraremos la recopilaci√≥n ‚Äúmanual‚Äù de estad√≠sticas, aunque en la vida real se utilizan scripts especiales que lo hacen autom√°ticamente. <br><br>  Primero, <code>gdb</code> necesita estar adjunto al proceso PostgreSQL.  Para hacer esto, encuentre el <code>pid</code> proceso <code>pid</code> servidor, digamos de <br><br><pre> <code class="plaintext hljs">$ ps aux | grep postgres</code> </pre> <br>  Digamos que encontramos: <br><br><pre> <code class="plaintext hljs">postgres 2025 0.0 0.1 172428 1240 pts/17  S   23  0:00 /usr/local/pgsql/bin/postgres -D /usr/local/pgsql/data</code> </pre> <br>  y ahora inserte el <code>pid</code> en el depurador: <br><br><pre> <code class="plaintext hljs">igor_le:~$gdb -p 2025</code> </pre> <br>  Una vez dentro del depurador, escribimos <code>bt</code> [es decir, <code>backtrace</code> ] o <code>where</code> .  Y obtenemos mucha informaci√≥n sobre este tipo: <br><br><pre> <code class="plaintext hljs">(gdb) bt #0 0x00007fbb65d01cd0 in __write_nocancel () from /lib64/libc.so.6 #1 0x00000000007c92f4 in write_pipe_chunks ( data=0x110e6e8 "2018‚Äê06‚Äê01 15:35:38 MSK [524647]: [392‚Äê1] db=bp,user=bp,app=[unknown],client=192.168.70.163 (http://192.168.70.163) LOG: relation 23554 new block 493: 248.389503\n2018‚Äê06‚Äê01 15:35:38 MSK [524647]: [393‚Äê1] db=bp,user=bp,app=["..., len=409, dest=dest@entry=1) at elog.c:3123 #2 0x00000000007cc07b in send_message_to_server_log (edata=0xc6ee60 &lt;errordata&gt;) at elog.c:3024 #3 EmitErrorReport () at elog.c:1479</code> </pre> <br>  Una vez recopiladas las estad√≠sticas, incluidas las pilas de llamadas de todos los procesos de postgres, recopiladas repetidamente en diferentes puntos en el tiempo, vimos que el <code>buffer partition lock</code> del <code>buffer partition lock</code> dentro del <code>relation extension lock</code> la <code>relation extension lock</code> dur√≥ 3706 segundos (aproximadamente una hora), es decir, se bloquea en un trozo de la tabla hash del b√∫fer manager, que era necesario suplantar el b√∫fer antiguo, para luego reemplazarlo por uno nuevo correspondiente a la parte extendida de la tabla.  Tambi√©n se not√≥ un cierto n√∫mero de bloqueos del <code>buffer content lock</code> del <code>buffer content lock</code> , lo que correspond√≠a a la expectativa de bloquear las p√°ginas del √≠ndice del <code>B-tree</code> para su inserci√≥n. <br><br><img src="https://habrastorage.org/webt/6c/y6/cw/6cy6cwmfye29jw84dkzoabjlgvg.jpeg"><br><br>  Al principio, llegaron dos explicaciones para un tiempo de espera tan monstruoso: <br><br><ul><li>  Alguien m√°s tom√≥ este <code>LWLock</code> y se atasc√≥.  Pero esto es poco probable.  Porque no ocurre nada complicado dentro del bloqueo de la partici√≥n del b√∫fer. </li><li>  Encontramos alg√∫n comportamiento patol√≥gico de <code>LWLock</code> .  Es decir, a pesar de que nadie tom√≥ la cerradura demasiado tiempo, su expectativa dur√≥ demasiado. </li></ul><br><h3>  Parches de diagn√≥stico y tratamiento de √°rboles </h3><br>  Al reducir el n√∫mero de conexiones simult√°neas, probablemente descargar√≠amos el flujo de solicitudes a las cerraduras.  Pero eso ser√≠a como rendirse.  En cambio, <i>Alexander Korotkov</i> , el arquitecto jefe de Postgres Professional (por supuesto, ayud√≥ a preparar este art√≠culo), propuso una serie de parches. <br><br>  En primer lugar, era necesario obtener una imagen m√°s detallada del desastre.  No importa cu√°n buenas sean las herramientas terminadas, los parches de diagn√≥stico de su propia fabricaci√≥n tambi√©n ser√°n √∫tiles. <br><br>  Se escribi√≥ un parche que agrega un registro detallado del tiempo dedicado a la <code>relation extension</code> , lo que est√° sucediendo dentro de la funci√≥n <code>RelationAddExtraBlocks()</code> . Entonces descubrimos qu√© tiempo pasa dentro de <code>RelationAddExtraBlocks().</code> <br><br>  Y en apoyo de √©l, se escribi√≥ otro parche informando en <code>pg_stat_activity</code> sobre lo que estamos haciendo ahora en <code>relation extension</code> .  Se hizo de esta manera: cuando la <code>relation</code> expande, <code>application_name</code> convierte en <code>RelationAddExtraBlocks</code> .  Este proceso ahora se analiza convenientemente con los m√°ximos detalles utilizando <code>gdb bt</code> y <code>perf</code> . <br><br>  En realidad, los parches m√©dicos (y no diagn√≥sticos) se escribieron dos.  El primer parche cambi√≥ el comportamiento de los bloqueos de la hoja del <code>B‚Äêtree</code> : antes, cuando se le ped√≠a que se insertara, la hoja se bloque√≥ como recurso <code>share</code> , y despu√©s de eso se volvi√≥ <code>exclusive</code> .  Ahora inmediatamente se vuelve <code>exclusive</code> .  Ahora este parche <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ya se ha confirmado</a> para <b>PostgreSQL 12</b> .  Afortunadamente, este a√±o <i>Alexander Korotkov</i> recibi√≥ el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">estado de un committer</a> : el segundo committer PostgreSQL en Rusia y el segundo en la compa√±√≠a. <br><br>  El valor <code>NUM_BUFFER_PARTITIONS</code> tambi√©n se aument√≥ de 128 a 512 para reducir la carga en los bloqueos de mapeo: la tabla hash del administrador de b√∫fer se dividi√≥ en partes m√°s peque√±as, con la esperanza de que la carga en cada parte espec√≠fica se redujera. <br><br>  Despu√©s de aplicar este parche, los bloqueos en el contenido de los b√∫feres desaparecieron, pero a pesar del aumento en <code>NUM_BUFFER_PARTITIONS</code> , el <code>buffer_mapping</code> permaneci√≥, es decir, le recordamos las piezas bloqueadas de la tabla hash del administrador de b√∫fer: <br><br><pre> <code class="plaintext hljs">locks_count | active_session | buffer_content | buffer_mapping ----‚Äê‚Äê‚Äê--‚Äê‚Äê‚Äê+‚Äê------‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê------‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê------‚Äê‚Äê‚Äê 12549 | 1218 | 0 | 15</code> </pre> <br>  E incluso eso no es mucho.  B - el √°rbol ya no es un cuello de botella.  La extensi√≥n del <code>heap-</code> lleg√≥ a primer plano. <br><br><h3>  Tratamiento de la conciencia </h3><br>  A continuaci√≥n, Alexander present√≥ la siguiente hip√≥tesis y soluci√≥n: <br><br>  Esperamos mucho tiempo en el <code>buffer parittion lock</code> del <code>buffer parittion lock</code> al <code>buffer parittion lock</code> b√∫fer.  Quiz√°s, en el mismo <code>buffer parittion lock</code> hay una p√°gina muy demandada, por ejemplo, la ra√≠z de alg√∫n <code>B‚Äêtree</code>  En este punto, hay un flujo continuo de solicitudes de <code>shared lock</code> de las solicitudes de lectura. <br><br>  La l√≠nea de espera en <code>LWLock</code> "no es justa".  Dado que <code>shared lock</code> se pueden tomar tantos como sea necesario a la vez, entonces si el <code>shared lock</code> ya <code>shared lock</code> , los <code>shared lock</code> posteriores pasan sin hacer cola.  Por lo tanto, si la secuencia de bloqueos compartidos es de suficiente intensidad para que no haya "ventanas" entre ellos, entonces esperar un <code>exclusive lock</code> casi al infinito. <br><br>  Para solucionar esto, puede intentar ofrecer un parche de comportamiento "caballeroso" de las cerraduras.  Despierta la conciencia de <code>shared locker</code> y honestamente hacen cola cuando ya hay un <code>exclusive lock</code> (curiosamente, los candados pesados, <code>hwlock</code> , no tienen problemas con la conciencia: siempre hacen cola honestamente) <br><br><pre> <code class="plaintext hljs">locks_count | active_session | buffer_content | buffer_mapping | reladdextra | inserts&gt;30sec ‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê-‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê--‚Äê-‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê-‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê------ 173985 | 1802 | 0 | 569 | 0 | 0</code> </pre> <br>  Todo esta bien!  No hay <code>insert</code> largas.  Aunque las cerraduras en las piezas de las placas hash permanecieron.  Pero qu√© hacer, estas son las propiedades de los neum√°ticos de nuestra peque√±a supercomputadora. <br><br>  Este parche tambi√©n se <a href="">ofreci√≥ a la comunidad</a> .  Pero no importa c√≥mo se desarrolle el destino de estos parches en la comunidad, nada les impide acceder a las pr√≥ximas versiones de <b>Postgres Pro Enterprise</b> , que est√°n dise√±adas espec√≠ficamente para clientes con sistemas muy cargados. <br><br><h3>  Moraleja </h3><br>  Los bloqueos <code>share</code> ligeros de alta moralidad (bloques <code>exclusive</code> se saltan la cola) han resuelto el problema de los retrasos por hora en un sistema de m√∫ltiples nodos.  La etiqueta hash <code>buffer manager</code> no funcion√≥ debido a un flujo de <code>share lock</code> demasiado, lo que no dejaba la posibilidad de que los bloqueos necesarios suplantaran los viejos b√∫feres y cargaran otros nuevos.  Los problemas con la extensi√≥n del b√∫fer para las tablas de la base de datos fueron solo una consecuencia de esto.  Antes de esto, era posible expandir el cuello de botella con acceso a la ra√≠z del <code>B-tree</code> <br><br>  PostgreSQL no fue dise√±ado para arquitecturas y supercomputadoras NUMA.  Adaptarse a tales arquitecturas de Postgres es un trabajo enorme que requerir√≠a (y posiblemente requerir√≠a) los esfuerzos coordinados de muchas personas e incluso empresas.  Pero las consecuencias desagradables de estos problemas arquitect√≥nicos pueden mitigarse.  Y tenemos que hacerlo: los tipos de carga que provocaron retrasos similares a los descritos son bastante t√≠picos, las se√±ales de socorro similares de otros lugares contin√∫an llegando a nosotros.  Problemas anteriores aparecieron antes: en sistemas con menos n√∫cleos, solo las consecuencias no fueron tan monstruosas y los s√≠ntomas se trataron con otros m√©todos y otros parches.  Ahora ha aparecido otro medicamento, no universal, pero claramente √∫til. <br><br>  Entonces, cuando PostgreSQL funciona con la memoria de todo el sistema como local, ning√∫n bus de alta velocidad entre nodos puede compararse con el tiempo de acceso a la memoria local.  Las tareas surgen debido a esto dif√≠cil, a menudo urgente, pero interesante.  Y la experiencia de resolverlos es √∫til no solo para los decisivos, sino tambi√©n para toda la comunidad. <br><br><img src="https://habrastorage.org/webt/od/n1/sf/odn1sf_id7l60ezlyo-padxymmi.jpeg"></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es423685/">https://habr.com/ru/post/es423685/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es423663/index.html">Escribimos un traductor simple en Lisp - III</a></li>
<li><a href="../es423667/index.html">La historia de los primeros videojuegos con microprocesador</a></li>
<li><a href="../es423677/index.html">Pilotos de Jetpack: Frankie West</a></li>
<li><a href="../es423679/index.html">Una tarea con un rascacielos y huevos, ¬øno el contenedor de Newton?</a></li>
<li><a href="../es423683/index.html">Basado en el sentido com√∫n: desarrollar DevOps desde cero</a></li>
<li><a href="../es423687/index.html">HyperX Pulsefire FPS Pro: m√°s r√°pido, m√°s malo y m√°s asequible</a></li>
<li><a href="../es423689/index.html">RTOS MAX - gratis? Planeamos abrir una licencia para uso comercial gratuito</a></li>
<li><a href="../es423693/index.html">Otra forma de usar Webpack 4 y separaci√≥n de c√≥digo</a></li>
<li><a href="../es423695/index.html">C√≥mo jubilarse antes de los 40 a√±os con un mill√≥n de d√≥lares en una cuenta bancaria</a></li>
<li><a href="../es423697/index.html">Presentaci√≥n de Spring Data JDBC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§ûüèΩ üë¶üèª üë®üèæ‚ÄçüöÄ Cerebras Systems introduziu um computador com o maior processador do mundo 22 √ó 22 cent√≠metros üë®‚Äçüöí üë®‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë® ‚ô•Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O diagrama do computador CS-1 mostra que a maioria √© dedicada √† alimenta√ß√£o e ao resfriamento do gigante Wafer Scale Engine (WSE) "processador em plac...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cerebras Systems introduziu um computador com o maior processador do mundo 22 √ó 22 cent√≠metros</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dcmiran/blog/476706/"><img src="https://habrastorage.org/getpro/habr/post_images/43e/87f/2b3/43e87f2b3b76001e51387e09935558ba.jpg"><br>  <i><font color="gray">O diagrama do computador CS-1 mostra que a maioria √© dedicada √† alimenta√ß√£o e ao resfriamento do gigante Wafer Scale Engine (WSE) "processador em placa".</font></i>  <i><font color="gray">Foto: Cerebras Systems</font></i> <br><br>  Em agosto de 2019, a Cerebras Systems e seu parceiro de fabrica√ß√£o TSMC anunciaram o <a href="https://habr.com/ru/news/t/464271/">maior chip da hist√≥ria da tecnologia de computadores</a> .  Com uma √°rea de 46.225 mm¬≤ e 1,2 trilh√£o de transistores, o chip Wafer Scale Engine (WSE) √© aproximadamente 56,7 vezes maior que o maior GPU (21,1 bilh√µes de transistores, 815 mm¬≤). <br><br>  Os c√©ticos disseram que desenvolver um processador n√£o √© a tarefa mais dif√≠cil.  Mas aqui est√° como ele funcionar√° em um computador real?  Qual √© a porcentagem de trabalho defeituoso?  Que energia e refrigera√ß√£o ser√£o necess√°rias?  Quanto custa essa m√°quina? <br><br>  Parece que os engenheiros da Cerebras Systems e TSMC foram capazes de resolver esses problemas.  Em 18 de novembro de 2019, na confer√™ncia <a href="https://sc19.supercomputing.org/">Supercomputing 2019</a> , eles lan√ßaram oficialmente o <a href="https://www.businesswire.com/news/home/20191119005046/en/Cerebras-Systems-Unveils-CS-1-Industry%25E2%2580%2599s-Fastest-Artificial">CS-1</a> , "o computador mais r√°pido do mundo para a computa√ß√£o no campo de aprendizado de m√°quina e intelig√™ncia artificial". <br><a name="habracut"></a><br>  As primeiras c√≥pias do CS-1 j√° foram enviadas aos clientes.  Um deles est√° instalado no Laborat√≥rio Nacional de Argonne, no Departamento de Energia dos EUA, aquele em que a montagem do supercomputador mais poderoso nos EUA a partir dos <a href="https://habr.com/ru/company/dcmiran/blog/476378/">m√≥dulos Aurora na nova arquitetura da GPU Intel</a> come√ßar√°.  Outro cliente foi o Laborat√≥rio Nacional Livermore. <br><br>  O processador com 400.000 n√∫cleos foi projetado para data centers para processamento de computa√ß√£o no campo de aprendizado de m√°quina e intelig√™ncia artificial.  A Cerebras alega que o computador treina sistemas de IA por ordens de magnitude com mais efici√™ncia do que os equipamentos existentes.  O desempenho CS-1 √© equivalente a "centenas de servidores baseados em GPU", consumindo centenas de quilowatts.  Ao mesmo tempo, ocupa apenas 15 unidades no rack do servidor e consome cerca de 17 kW. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cfc/5aa/1da/cfc5aa1da0e52944fc1b68e4fca15146.jpg"><br>  <i><font color="gray">Processador WSE.</font></i>  <i><font color="gray">Foto: Cerebras Systems</font></i> <br><br>  Andrew Feldman, CEO e co-fundador da Cerebras Systems, diz que o CS-1 √© "o computador de IA mais r√°pido do mundo".  Ele o comparou aos clusters de TPU do Google e observou que cada um deles "pega 10 racks e consome mais de 100 quilowatts para fornecer um ter√ßo do desempenho de uma √∫nica instala√ß√£o do CS-1". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/523/1d3/b60/5231d3b60c445d641bb654d29b8fec21.jpg"><br>  <i><font color="gray">Computador CS-1.</font></i>  <i><font color="gray">Foto: Cerebras Systems</font></i> <br><br>  O aprendizado de grandes redes neurais pode levar semanas em um computador padr√£o.  Instalar um CS-1 com um chip de processador de 400.000 n√∫cleos e 1,2 trilh√µes de transistores executa essa tarefa em minutos ou at√© segundos, <a href="https://spectrum.ieee.org/tech-talk/computing/hardware/cerebras-unveils-ai-supercomputer-argonne-national-lab-first-installation">escreve o</a> IEEE Spectrum.  No entanto, a Cerebras n√£o forneceu resultados reais para testar declara√ß√µes de alto desempenho, como os <a href="https://mlperf.org/training-results-0-6">testes MLPerf</a> .  Em vez disso, a empresa estabeleceu contatos diretamente com clientes em potencial - e permitiu treinar seus pr√≥prios modelos de redes neurais no CS-1. <br><br>  Essa abordagem n√£o √© incomum, dizem os analistas: "Todo mundo gerencia seus pr√≥prios modelos que eles desenvolveram para seus pr√≥prios neg√≥cios", disse <a href="http://www.moorinsightsstrategy.com/karl-freund-biography/">Karl Freund</a> , analista de intelig√™ncia artificial da Moor Insights &amp; Strategies.  "Esta √© a √∫nica coisa que importa para os clientes." <br><br>  Muitas empresas est√£o desenvolvendo chips especializados para IA, incluindo representantes tradicionais da ind√∫stria, como Intel, Qualcomm, al√©m de v√°rias startups nos EUA, Reino Unido e China.  O Google desenvolveu um chip especificamente para redes neurais - um processador tensorial ou TPU.  V√°rios outros fabricantes seguiram o exemplo.  Os sistemas de IA operam no modo multiencadeado e o gargalo est√° movendo dados entre os chips: "A conex√£o dos chips os torna mais lentos e exige muita energia", <a href="https://www.nytimes.com/2019/08/19/technology/artificial-intelligence-chip-cerebras.html">explica</a> Subramanian Iyer, professor da Universidade da Calif√≥rnia em Los Angeles, especializado em desenvolvendo chips para intelig√™ncia artificial.  Os fabricantes de equipamentos est√£o explorando muitas op√ß√µes diferentes.  Alguns est√£o tentando expandir conex√µes entre processos. <br><br>  Fundada h√° tr√™s anos, a startup Cerebras, que recebeu mais de US $ 200 milh√µes em financiamento de empreendimentos, prop√¥s uma nova abordagem.  A id√©ia √© salvar todos os dados em um chip gigante - e, assim, acelerar os c√°lculos. <br><br><img src="https://habrastorage.org/webt/up/k1/ej/upk1ejv8zsqxtj9nadanm8898zc.jpeg"><br><br>  Toda a placa de microcircuito √© dividida em 400.000 se√ß√µes menores (n√∫cleos), uma vez que algumas delas n√£o funcionam.  O chip foi projetado com a capacidade de rotear em torno de √°reas defeituosas.  N√∫cleos program√°veis ‚Äã‚ÄãO SLAC (N√∫cleos de √Ålgebra Linear Esparsa) √© otimizado para √°lgebra linear, ou seja, para c√°lculos no espa√ßo vetorial.  A empresa tamb√©m desenvolveu a tecnologia "colheita de escassez" para melhorar o desempenho da computa√ß√£o sob cargas de trabalho esparsas (contendo zeros), como aprendizado profundo.  Vetores e matrizes no espa√ßo vetorial geralmente cont√™m muitos elementos nulos (de 50% a 98%); portanto, nas GPUs tradicionais, a maior parte da computa√ß√£o √© desperdi√ßada.  Por outro lado, os n√∫cleos SLAC pr√©-filtram dados nulos. <br><br>  As comunica√ß√µes entre os n√∫cleos s√£o fornecidas pelo sistema Swarm com uma taxa de transfer√™ncia de 100 petabits por segundo.  Roteamento de hardware, lat√™ncia medida em nanossegundos. <br><br>  O custo de um computador n√£o √© chamado.  Especialistas independentes acreditam que o pre√ßo real depende da porcentagem de casamento.  Al√©m disso, o desempenho do chip e quantos n√∫cleos est√£o operacionais em amostras reais n√£o s√£o conhecidos com confiabilidade. <br><br><h1>  De software </h1><br>  A Cerebras anunciou alguns detalhes sobre a parte do software do sistema CS-1.  O software permite que os usu√°rios criem seus pr√≥prios modelos de aprendizado de m√°quina usando estruturas padr√£o como <a href="https://pytorch.org/">PyTorch</a> e <a href="https://www.tensorflow.org/">TensorFlow</a> .  O sistema distribui 400.000 n√∫cleos e 18 gigabytes de mem√≥ria SRAM no chip para as camadas da rede neural, para que todas as camadas concluam seu trabalho quase ao mesmo tempo que seus vizinhos (tarefa de otimiza√ß√£o).  Como resultado, as informa√ß√µes s√£o processadas por todas as camadas sem demora.  Com um subsistema de E / S de 12 portas e 100 Gigabit Ethernet, o CS-1 pode processar 1,2 terabits de dados por segundo. <br><br>  A convers√£o da rede neural de origem em uma representa√ß√£o execut√°vel otimizada (Representa√ß√£o Intermedi√°ria de √Ålgebra Linear da Cerebras, CLAIR) √© feita pelo Cerebras Graph Compiler (CGC).  O compilador aloca recursos de computa√ß√£o e mem√≥ria para cada parte do gr√°fico e os compara com a matriz de computa√ß√£o.  Em seguida, o caminho da comunica√ß√£o √© calculado de acordo com a estrutura interna da placa, exclusiva para cada rede. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/098/093/569/098093569a8dca7e8dea9e26fc63a81a.jpg"><br>  <i><font color="gray">Distribui√ß√£o de opera√ß√µes matem√°ticas de uma rede neural por n√∫cleos de processador.</font></i>  <i><font color="gray"><a href="https://fortune.com/2019/11/19/artificial-intelligence-cerebras-supercomputer/">Foto</a> : Cerebras</font></i> <br><br>  Devido ao enorme tamanho do WSE, todas as camadas em uma rede neural est√£o localizadas simultaneamente nela e funcionam em paralelo.  Essa abordagem √© exclusiva do WSE - nenhum outro dispositivo possui mem√≥ria interna suficiente para caber em todas as camadas de um chip ao mesmo tempo, diz Cerebras.  Essa arquitetura com a coloca√ß√£o de toda a rede neural em um chip oferece enormes vantagens devido ao seu alto rendimento e baixa lat√™ncia. <br><br>  O software pode executar a tarefa de otimiza√ß√£o para v√°rios computadores, permitindo que o cluster de computadores atue como uma grande m√°quina.  Um cluster de 32 computadores CS-1 mostra um aumento de aproximadamente 32 vezes no desempenho, o que indica uma escalabilidade muito boa.  Feldman diz que isso √© diferente dos clusters baseados em GPU: ‚ÄúHoje, quando voc√™ cria um cluster de GPUs, ele n√£o se comporta como uma grande m√°quina.  Voc√™ adquire muitos carros pequenos. ‚Äù <br><br>  O <a href="https://www.businesswire.com/news/home/20191119005046/en/Cerebras-Systems-Unveils-CS-1-Industry%25E2%2580%2599s-Fastest-Artificial">comunicado √† imprensa</a> dizia que o Laborat√≥rio Nacional de Argonne trabalha com a Cerebras h√° dois anos: "Ao implantar o CS-1, aumentamos drasticamente a velocidade do treinamento de redes neurais, o que nos permitiu aumentar a produtividade de nossa pesquisa e alcan√ßar um sucesso significativo". <br><br>  Uma das primeiras cargas do CS-1 ser√° uma <a href="https://arxiv.org/abs/1903.01998">simula√ß√£o de rede neural de uma colis√£o de buracos negros</a> e ondas gravitacionais, criadas como resultado dessa colis√£o.  A vers√£o anterior desta tarefa funcionou em 1024 de 4392 n√≥s do supercomputador <a href="https://www.alcf.anl.gov/theta">Theta</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt476706/">https://habr.com/ru/post/pt476706/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt476696/index.html">Como criar e implantar full-stack Reagir aplica√ß√£o</a></li>
<li><a href="../pt476698/index.html">Como a Apple mata as tecnologias da Web</a></li>
<li><a href="../pt476700/index.html">Mes na produ√ß√£o de radiadores de a√ßo</a></li>
<li><a href="../pt476702/index.html">Como uma pequena cidade do interior se transformou em um centro internacional de com√©rcio eletr√¥nico</a></li>
<li><a href="../pt476704/index.html">Como automatizar o layout de emails com o mesmo tipo de elementos: usamos objetos inteligentes</a></li>
<li><a href="../pt476708/index.html">Slurm Basic em Moscou. Terceiro dia A cole√ß√£o de contra-intelig√™ncia e o cluster, voando Pavel Selivanov e "Slurm Inspires!"</a></li>
<li><a href="../pt476710/index.html">Registro aberto: Mergulhe profundamente em TI na Mars</a></li>
<li><a href="../pt476712/index.html">Servi√ßo para reuni√µes aleat√≥rias com estranhos, mas n√£o namoro. Hist√≥ria aleat√≥ria de inicializa√ß√£o do Coffee</a></li>
<li><a href="../pt476714/index.html">Opera√ß√£o de aprendizado de m√°quina no Mail.ru Mail</a></li>
<li><a href="../pt476718/index.html">Hist√≥ria de uma r√°dio nacional: Mussolini da Rural Radio e Joseph Goebbels aquecem l√¢mpadas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
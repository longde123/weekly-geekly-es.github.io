<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëäüèΩ üç∫ ü§ó Ajustar o balanceamento de carga üëë üë®üèΩ‚Äçüé§ üéç</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este artigo se concentrar√° no balanceamento de carga em projetos da web. Muitos acreditam que a solu√ß√£o para esse problema na distribui√ß√£o de carga en...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ajustar o balanceamento de carga</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/423085/">  Este artigo se concentrar√° no balanceamento de carga em projetos da web.  Muitos acreditam que a solu√ß√£o para esse problema na distribui√ß√£o de carga entre servidores - quanto mais preciso, melhor.  Mas sabemos que isso n√£o √© inteiramente verdade.  <strong>A estabilidade do sistema √© muito mais importante do ponto de vista comercial</strong> . <br><br><img src="https://habrastorage.org/webt/6i/vb/-w/6ivb-w0bzdgl_oa-hkep6luitfi.png"><br><br>  O pequeno pico de 84 RPS de "quinhentos" √© de cinco mil erros que os usu√°rios reais receberam.  Isso √© muito e √© muito importante.  √â necess√°rio procurar por raz√µes, trabalhar com erros e tentar continuar a evitar tais situa√ß√µes. <br><br>  <strong>Nikolay Sivko</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">NikolaySivko</a> ) em seu relat√≥rio no RootConf 2018 falou sobre os aspectos sutis e ainda n√£o muito populares do balanceamento de carga: <br><br><ul><li>  quando repetir a solicita√ß√£o (tentativas); </li><li>  como selecionar valores para tempos limite; </li><li>  como n√£o matar os servidores subjacentes no momento do acidente / congestionamento; </li><li>  se s√£o necess√°rios exames de sa√∫de; </li><li>  como lidar com problemas de oscila√ß√£o. </li></ul><br>  Sob decodifica√ß√£o de gato deste relat√≥rio. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/2-j2ADWFkkE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br>  <strong>Sobre o palestrante:</strong> Nikolay Sivko, cofundador da okmeter.io.  Ele trabalhou como administrador de sistemas e l√≠der de um grupo de administradores.  Opera√ß√£o supervisionada em hh.ru.  Ele fundou o servi√ßo de monitoramento okmeter.io.  Como parte deste relat√≥rio, o monitoramento da experi√™ncia de desenvolvimento √© a principal fonte de casos. <br><br><h2>  Sobre o que vamos falar? <br></h2><br>  Este artigo ir√° falar sobre projetos da web.  Abaixo est√° um exemplo de produ√ß√£o ao vivo: o gr√°fico mostra solicita√ß√µes por segundo para um determinado servi√ßo da web. <br><br><img src="https://habrastorage.org/webt/oy/5c/qt/oy5cqtlz-halhw7y5ayuz6xl9lm.png"><br><br>  Quando falo sobre balanceamento, muitos o percebem como "precisamos distribuir a carga entre os servidores - quanto mais preciso, melhor". <br><br><img src="https://habrastorage.org/webt/pm/g2/sp/pmg2spartsnxrxcyhzi_4-ui64g.png"><br><br>  De fato, isso n√£o √© inteiramente verdade.  Esse problema √© relevante para um n√∫mero muito pequeno de empresas.  Mais frequentemente, os neg√≥cios est√£o preocupados com erros e estabilidade do sistema. <br><br><img src="https://habrastorage.org/webt/6i/vb/-w/6ivb-w0bzdgl_oa-hkep6luitfi.png"><br><br>  O pequeno pico no gr√°fico √© "quinhentos", que o servidor retornou em um minuto e parou.  Do ponto de vista de uma empresa, como uma loja on-line, esse pequeno pico a 84 RPS de "quinhentos" representa 5040 erros para usu√°rios reais.  Alguns n√£o encontraram algo no seu cat√°logo, outros n√£o puderam colocar as mercadorias na cesta.  E isso √© muito importante.  Embora esse pico n√£o pare√ßa muito grande no gr√°fico, <strong>√© muito em usu√°rios reais</strong> . <br><br>  Como regra, todos t√™m esses picos, e os administradores nem sempre respondem a eles.  Muitas vezes, quando uma empresa pergunta o que era, eles respondem: <br><br><ul><li>  "Esta √© uma pequena explos√£o!" </li><li>  "√â apenas um lan√ßamento rolando". </li><li>  "O servidor est√° morto, mas tudo j√° est√° em ordem." </li><li>  "Vasya trocou a rede de um dos back-ends." </li></ul><br>  Muitas vezes, as pessoas <strong>nem tentam entender as raz√µes</strong> pelas <strong>quais</strong> isso aconteceu e n√£o fazem nenhum p√≥s-trabalho para que isso n√£o aconte√ßa novamente. <br><br><h2>  Ajuste fino <br></h2><br>  Chamei o relat√≥rio de ‚ÄúAjuste fino‚Äù (Eng. Ajuste fino), porque pensei que nem todo mundo chegaria a essa tarefa, mas valeria a pena.  Por que eles n√£o chegam l√°? <br><br><ul><li>  <strong>Nem todo mundo chega nessa tarefa,</strong> porque quando tudo funciona, n√£o √© vis√≠vel.  Isso √© muito importante para problemas.  Fakapa n√£o acontece todos os dias, e um problema t√£o pequeno requer esfor√ßos muito s√©rios para resolv√™-lo. </li><li>  <strong>Voc√™ precisa pensar muito.</strong>  Muitas vezes, o administrador - a pessoa que ajusta a balan√ßa - n√£o √© capaz de resolver esse problema independentemente.  A seguir, veremos o porqu√™. </li><li>  <strong>Ele captura os n√≠veis subjacentes.</strong>  Essa tarefa est√° intimamente ligada ao desenvolvimento, com a ado√ß√£o de decis√µes que afetam seu produto e seus usu√°rios. </li></ul><br>  <strong>Afirmo que √© hora de executar esta tarefa por v√°rios motivos:</strong> <br><br><ul><li>  O mundo est√° mudando, se tornando mais din√¢mico, h√° muitos lan√ßamentos.  Eles dizem que agora √© correto liberar 100 vezes por dia, e o lan√ßamento √© o futuro fakap com uma probabilidade de 50 a 50 (assim como a probabilidade de encontrar um dinossauro) </li><li>  Do ponto de vista da tecnologia, tudo tamb√©m √© muito din√¢mico.  Kubernetes e outros orquestradores apareceram.  N√£o h√° boa implanta√ß√£o antiga, quando um back-end em algum IP √© desativado, uma atualiza√ß√£o √© rolada e o servi√ßo √© iniciado.  Agora, no processo de lan√ßamento no k8s, a lista de IP upstream est√° mudando completamente. </li><li>  Microsservi√ßos: agora todos se comunicam pela rede, o que significa que voc√™ precisa fazer isso de forma confi√°vel.  O equil√≠brio desempenha um papel importante. </li></ul><br><h2>  Suporte de teste <br></h2><br>  Vamos come√ßar com casos simples e √≥bvios.  Para maior clareza, usarei uma bancada de testes.  Este √© um aplicativo Golang que fornece o http-200 ou voc√™ pode altern√°-lo para o modo "give http-503". <br><br>  Iniciamos 3 inst√¢ncias: <br><br><ul><li>  127.0.0.1:20001 </li><li>  127.0.0.1:20002 </li><li>  127.0.0.1:20003 </li></ul><br>  Servimos 100rps via yandex.tank via nginx. <br><br>  Nginx pronto para uso: <br><br><pre><code class="plaintext hljs">upstream backends { server 127.0.0.1:20001; server 127.0.0.1:20002; server 127.0.0.1:20003; } server { listen 127.0.0.1:30000; location / { proxy_pass http://backends; } }</code> </pre> <br><h3>  Cen√°rio primitivo </h3><br>  Em algum momento, ative um dos back-end no modo 503 e obteremos exatamente um ter√ßo dos erros. <br><br><img src="https://habrastorage.org/webt/qp/m1/ro/qpm1rolcydmcpwpvule4pw97b-o.png"><br><br>  √â claro que nada funciona imediatamente: o nginx n√£o tenta novamente novamente se recebeu <strong>alguma resposta</strong> do servidor. <br><br><pre> <code class="plaintext hljs">Nginx default: proxy_next_upstream error timeout;</code> </pre><br>  De fato, isso √© bastante l√≥gico do lado dos desenvolvedores do nginx: o nginx n√£o tem o direito de decidir para voc√™ o que voc√™ deseja recuperar e o que n√£o. <br><br>  Portanto, precisamos de tentativas - tentativas e come√ßamos a falar sobre elas. <br><br><h2>  Tentativas <br></h2><br>  √â necess√°rio encontrar um compromisso entre: <br><br><ul><li>  A solicita√ß√£o do usu√°rio √© santa, se machuca, mas responde.  Queremos responder ao usu√°rio a todo custo, o usu√°rio √© o mais importante. </li><li>  Melhor responder com um erro do que sobrecarregar os servidores. </li><li>  Integridade dos dados (para solicita√ß√µes n√£o idempotentes), ou seja, √© imposs√≠vel repetir certos tipos de solicita√ß√µes. </li></ul><br>  <strong>A verdade, como sempre, est√° em algum lugar no meio -</strong> somos for√ßados a equilibrar entre esses tr√™s pontos.  Vamos tentar entender o que e como. <br><br>  Dividi as tentativas fracassadas em 3 categorias: <br><br>  1. <strong>Erro de transporte</strong> <br>  Para o transporte HTTP √© TCP e, como regra, aqui falamos sobre erros de configura√ß√£o de conex√£o e tempos limite de configura√ß√£o de conex√£o.  No meu relat√≥rio, mencionarei tr√™s balanceadores comuns (falaremos um pouco mais sobre o Enviado): <br><br><ul><li>  <strong>nginx</strong> : erros + tempo limite (proxy_connect_timeout); </li><li>  <strong>HAProxy</strong> : conex√£o de tempo limite; </li><li>  <strong>Enviado</strong> : falha na conex√£o + fluxo recusado. </li></ul><br>  O Nginx tem a oportunidade de dizer que uma tentativa com falha √© um erro de conex√£o e um tempo limite de conex√£o;  O HAProxy tem um tempo limite de conex√£o, o Envoy tamb√©m tem tudo padr√£o e normal. <br><br>  2. <strong>Solicitar tempo limite:</strong> <br>  Suponha que tenhamos enviado uma solicita√ß√£o ao servidor, conectada com √™xito a ele, mas a resposta n√£o chegue at√© n√≥s, esperamos por ela e entendemos que n√£o h√° sentido em esperar mais.  Isso √© chamado de tempo limite da solicita√ß√£o: <br><br><ul><li>  <strong>O Nginx</strong> possui: timeout (prox_send_timeout * + proxy_read_timeout *); </li><li>  <strong>O HAProxy possui</strong> <strong>OOPS :(</strong> - ele n√£o existe em princ√≠pio. Muitas pessoas n√£o sabem que o HAProxy, se tiver estabelecido uma conex√£o com sucesso, nunca tentar√° reenviar a solicita√ß√£o. </li><li>  <strong>O enviado</strong> pode fazer tudo: timeout ||  per_try_timeout. </li></ul><br>  3. <strong>status HTTP</strong> <br>  Todos os balanceadores, exceto o HAProxy, s√£o capazes de processar, mesmo assim o back-end respondeu, mas com algum tipo de c√≥digo incorreto. <br><br><ul><li>  <strong>nginx</strong> : http_ * </li><li>  <strong>HAProxy</strong> : <strong>OOPS :(</strong> </li><li>  <strong>Enviado</strong> : 5xx, erro de gateway (502, 503, 504), retriable-4xx (409) </li></ul><br><h3>  Timeouts <br></h3><br>  Agora, vamos falar detalhadamente sobre os intervalos, parece-me que vale a pena prestar aten√ß√£o nisso.  N√£o haver√° mais ci√™ncia de foguetes - essas informa√ß√µes s√£o simplesmente estruturadas sobre o que geralmente acontece e como elas se relacionam. <br><br><h4>  Tempo limite de conex√£o <br></h4><br>  O tempo limite de conex√£o √© o tempo para estabelecer uma conex√£o.  Essa √© uma caracter√≠stica da sua rede e servidor espec√≠fico e n√£o depende da solicita√ß√£o.  Geralmente, o valor padr√£o para o tempo limite da conex√£o √© definido como pequeno.  Em todos os proxies, o valor padr√£o √© grande o suficiente, e isso est√° errado - devem ser <strong>unidades, √†s vezes dezenas de milissegundos</strong> (se estamos falando de uma rede em um DC). <br><br>  Se voc√™ deseja identificar servidores problem√°ticos um pouco mais r√°pido que essas unidades - dezenas de milissegundos, voc√™ pode ajustar a carga no back-end, configurando um pequeno backlog para receber conex√µes TCP.  Nesse caso, quando o backlog do aplicativo estiver cheio, voc√™ poder√° solicitar ao Linux para redefini-lo para estourar o backlog.  Em seguida, voc√™ poder√° capturar o back-end sobrecarregado "ruim" um pouco antes do tempo limite da conex√£o: <br><br><pre> <code class="plaintext hljs">fail fast: listen backlog + net.ipv4.tcp_abort_on_overflow</code> </pre> <br><h4>  Tempo limite da solicita√ß√£o <br></h4><br>  O tempo limite da solicita√ß√£o n√£o √© uma caracter√≠stica da rede, mas uma <strong>caracter√≠stica de um grupo de solicita√ß√µes</strong> (manipulador).  Existem solicita√ß√µes diferentes - elas s√£o diferentes em gravidade, possuem uma l√≥gica completamente diferente, precisam acessar reposit√≥rios completamente diferentes. <br><br>  O Nginx em si <strong>n√£o tem um tempo limite para toda a solicita√ß√£o.</strong>  Ele tem: <br><br><ul><li>  proxy_send_timeout: tempo entre duas opera√ß√µes de grava√ß√£o bem-sucedidas write (); </li><li>  proxy_read_timeout: tempo entre duas leituras de leitura bem-sucedidas (). </li></ul><br>  Ou seja, se voc√™ tem um back-end lentamente, um byte de vezes, fornece algo em um tempo limite, tudo est√° bem.  Como tal, o nginx n√£o possui request_timeout.  Mas estamos falando sobre a montante.  Em nosso data center, eles s√£o controlados por n√≥s, portanto, assumindo que a rede n√£o possui loris lentos, ent√£o, em princ√≠pio, o read_timeout pode ser usado como request_timeout. <br><br>  O enviado tem tudo: timeout ||  per_try_timeout. <br><br><h4>  Selecionar tempo limite da solicita√ß√£o <br></h4><br>  Agora, o mais importante, na minha opini√£o, √© qual request_timeout colocar.  N√≥s procedemos de quanto √© permitido ao usu√°rio esperar - este √© um certo m√°ximo.  √â claro que o usu√°rio n√£o esperar√° mais de 10 s, portanto, √© necess√°rio responder a ele mais rapidamente. <br><br><ul><li>  Se quisermos lidar com a falha de um √∫nico servidor, o tempo limite deve ser menor que o tempo limite m√°ximo permitido: <strong>request_timeout &lt;max.</strong> </li><li>  Se voc√™ deseja ter <strong>2 tentativas garantidas de</strong> enviar uma solicita√ß√£o para dois back-end diferentes, o tempo limite para uma tentativa √© igual √† metade desse intervalo permitido: <strong>per_try_timeout = 0,5 * m√°x.</strong> </li><li>  H√° tamb√©m uma op√ß√£o intermedi√°ria - <strong>2 tentativas otimistas</strong> , caso o primeiro back-end tenha "diminu√≠do", mas o segundo responder√° rapidamente: <strong>per_try_timeout = k * max (onde k&gt; 0,5).</strong> </li></ul><br>  Existem abordagens diferentes, mas, em geral, a <strong>escolha de um tempo limite √© dif√≠cil</strong> .  Sempre haver√° casos de limite, por exemplo, o mesmo manipulador em 99% dos casos √© processado em 10 ms, mas h√° 1% dos casos quando esperamos 500 ms, e isso √© normal.  Isso ter√° que ser resolvido. <br><br>  Com esse 1%, algo precisa ser feito, porque todo o grupo de solicita√ß√µes deve, por exemplo, cumprir o SLA e caber em 100 ms.  Muitas vezes, nesses momentos, o aplicativo √© processado: <br><br><ul><li>  A pagina√ß√£o aparece nos locais em que √© imposs√≠vel retornar todos os dados em um tempo limite. </li><li>  Os administradores / relat√≥rios s√£o separados em um grupo separado de URLs para aumentar o tempo limite para eles e sim para diminuir as solicita√ß√µes do usu√°rio. </li><li>  Reparamos / otimizamos as solicita√ß√µes que n√£o se encaixam no nosso tempo limite. </li></ul><br>  Aqui, precisamos tomar uma decis√£o, o que n√£o √© muito simples do ponto de vista psicol√≥gico, de que, se n√£o tivermos tempo para responder ao usu√°rio no prazo estipulado, cometeremos um erro (√© como em um ditado chin√™s antigo: "Se a √©gua estiver morta, des√ßa!") <strong>.</strong> <br><br>  Depois disso, o processo de monitorar seu servi√ßo do ponto de vista do usu√°rio √© simplificado: <br><br><ul><li>  Se houver erros, tudo est√° ruim, ele precisa ser corrigido. </li><li>  Se n√£o houver erros, ajustamos o tempo de resposta correto, tudo est√° bem. </li></ul><br><h3>  Tentativas especulativas # nifig <br></h3><br>  Garantimos que escolher um valor de tempo limite √© bastante dif√≠cil.  Como voc√™ sabe, para simplificar algo, voc√™ precisa complicar algo :) <br><br>  <strong>Retray especulativo</strong> - uma solicita√ß√£o repetida para outro servidor, que √© iniciada por alguma condi√ß√£o, mas a primeira solicita√ß√£o n√£o √© interrompida.  Tomamos a resposta do servidor que respondeu mais rapidamente. <br><br>  Eu n√£o vi esse recurso nos balanceadores conhecidos por mim, mas h√° um excelente exemplo com o Cassandra (prote√ß√£o r√°pida de leitura): <br><br>  speculative_retry = N ms |  <strong>M percentil</strong> <br><br>  Dessa forma, voc√™ <strong>n√£o precisa atingir o tempo limite</strong> .  Voc√™ pode deix√°-lo em um n√≠vel aceit√°vel e, em qualquer caso, ter uma segunda tentativa de obter uma resposta √† solicita√ß√£o. <br><br>  Cassandra tem uma oportunidade interessante de definir um speculative_retry ou din√¢mico est√°tico; a segunda tentativa ser√° feita atrav√©s do percentil do tempo de resposta.  Cassandra acumula estat√≠sticas sobre os tempos de resposta de pedidos anteriores e adapta um valor de tempo limite espec√≠fico.  Isso funciona muito bem. <br><br>  Nessa abordagem, tudo depende do equil√≠brio entre confiabilidade e carga esp√∫ria, n√£o servidores. Voc√™ fornece confiabilidade, mas √†s vezes recebe solicita√ß√µes extras para o servidor.  Se voc√™ estava com pressa em algum lugar e enviou uma segunda solicita√ß√£o, mas a primeira ainda respondeu, o servidor recebeu um pouco mais de carga.  Em um √∫nico caso, esse √© um pequeno problema. <br><br><img src="https://habrastorage.org/webt/uv/7c/bs/uv7cbswancegyh5vc8t7mwvr8uy.png"><br><br>  A consist√™ncia do tempo limite √© outro aspecto importante.  Falaremos mais sobre o cancelamento da solicita√ß√£o, mas, em geral, se o tempo limite da solicita√ß√£o inteira do usu√°rio for de 100 ms, n√£o faz sentido definir o tempo limite da solicita√ß√£o no banco de dados por 1 s.  Existem sistemas que permitem fazer isso dinamicamente: servi√ßo a servi√ßo transfere o restante do tempo que voc√™ esperar√° por uma resposta para essa solicita√ß√£o.  √â complicado, mas se voc√™ precisar de repente, poder√° descobrir facilmente como faz√™-lo no mesmo enviado. <br><br>  O que mais voc√™ precisa saber sobre novas tentativas? <br><br><h3>  Ponto sem retorno (V1) <br></h3><br>  Aqui o V1 n√£o √© a vers√£o 1. Na avia√ß√£o, existe esse conceito - velocidade V1.  Essa √© a velocidade ap√≥s a qual √© imposs√≠vel desacelerar a acelera√ß√£o na pista.  √â necess√°rio decolar e tomar uma decis√£o sobre o que fazer a seguir. <br><br>  O mesmo ponto sem retorno est√° nos balanceadores de carga: <strong>quando voc√™ passa 1 byte da resposta ao seu cliente, nenhum erro pode ser corrigido</strong> .  Se o back-end morrer neste momento, nenhuma nova tentativa ajudar√°.  Voc√™ s√≥ pode reduzir a probabilidade de um cen√°rio desse tipo ser acionado, fazer um desligamento normal, ou seja, informar seu aplicativo: ‚ÄúVoc√™ n√£o aceita novas solicita√ß√µes agora, mas modifica as antigas!‚Äù, E s√≥ ent√£o a extingue. <br><br>  Se voc√™ controla o cliente, este √© um aplicativo m√≥vel ou Ajax complicado, ele pode tentar repetir a solicita√ß√£o e voc√™ pode sair dessa situa√ß√£o. <br><br><h3>  Ponto de n√£o retorno [Enviado] <br></h3><br>  O enviado teve um truque t√£o estranho.  Existe per_try_timeout - limita quanto cada tentativa de obter uma resposta a uma solicita√ß√£o pode demorar.  Se esse tempo limite funcionou, mas o back-end j√° come√ßou a responder ao cliente, tudo foi interrompido, o cliente recebeu um erro. <br><br>  Meu colega Pavel Trukhanov ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">tru_pablo</a> ) fez um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">patch</a> , que j√° est√° no master Envoy e estar√° em 1.7.  Agora ele funciona como deveria: se a resposta come√ßou a ser transmitida, apenas o tempo limite global funcionar√°. <br><br><h3>  Tentativas: necessidade de limitar <br></h3><br>  As novas tentativas s√£o boas, mas existem os chamados pedidos matadores: consultas pesadas que executam uma l√≥gica muito complexa acessam muito o banco de dados e geralmente n√£o se encaixam em per_try_timeout.  Se enviarmos novas tentativas repetidamente, matamos nossa base.  Porque <strong>na maioria dos servi√ßos de banco de dados (99,9%) n√£o h√° cancelamento de solicita√ß√£o</strong> . <br><br>  Solicitar cancelamento significa que o cliente desengatou; √© necess√°rio interromper todo o trabalho no momento.  A Golang est√° promovendo ativamente essa abordagem, mas infelizmente termina com um back-end, e muitos reposit√≥rios de banco de dados n√£o suportam isso. <br><br>  Portanto, as novas tentativas precisam ser limitadas, o que permite quase todos os balanceadores (deixamos de considerar o HAProxy a partir de agora). <br><br>  <strong>Nginx:</strong> <br><br><ul><li>  proxy_next_upstream_timeout (global) </li><li>  proxt_read_timeout ** como per_try_timeout </li><li>  proxy_next_upstream_tries </li></ul><br>  <strong>Enviado:</strong> <br><br><ul><li>  tempo limite (global) </li><li>  per_try_timeout </li><li>  num_retries </li></ul><br>  No Nginx, podemos dizer que estamos tentando fazer novas tentativas na janela X, ou seja, em um determinado intervalo de tempo, por exemplo, 500 ms, fazemos tantas tentativas quanto caber.  Ou h√° uma configura√ß√£o que limita o n√∫mero de amostras repetidas.  No <strong>Enviado</strong> , o mesmo √© quantidade ou tempo limite (global). <br><br><h4>  Tentativas: aplicar [nginx] <br></h4><br>  Considere um exemplo: definimos tentativas de repeti√ß√£o no nginx 2 - de acordo com o recebimento do HTTP 503, tentamos enviar uma solicita√ß√£o ao servidor novamente.  Em seguida, desligue os <strong>dois</strong> back-ends. <br><br><pre> <code class="plaintext hljs">upstream backends { server 127.0.0.1:20001; server 127.0.0.1:20002; server 127.0.0.1:20003; } server { listen 127.0.0.1:30000; proxy_next_upstream error timeout http_503; proxy_next_upstream_tries 2; location / { proxy_pass http://backends; } }</code> </pre><br>  Abaixo est√£o os gr√°ficos da nossa bancada de testes.  N√£o h√° erros no gr√°fico superior, porque s√£o muito poucos.  Se voc√™ deixar apenas erros, √© claro que eles s√£o. <br><br><img src="https://habrastorage.org/webt/3h/sx/aq/3hsxaq8qyifcoyq3mvcyzmxm_cc.png"><br><br><img src="https://habrastorage.org/webt/sc/f_/2w/scf_2wz9tctmouvrs9hpqtpmau0.png"><br><br>  <strong>O que aconteceu</strong> <br><br><ul><li>  proxy_next_upstream_tries = <strong>2.</strong> </li><li>  No caso em que voc√™ faz a primeira tentativa no servidor "inoperante" e a segunda - no outro "inoperante", voc√™ obt√©m o HTTP-503 no caso de <strong>ambas as</strong> tentativas nos servidores "inoperantes". </li><li>  Existem alguns erros, j√° que o nginx "pro√≠be" um servidor inv√°lido.  Ou seja, se no nginx alguns erros retornaram do back-end, ele para de fazer as seguintes tentativas de enviar uma solicita√ß√£o a ele.  Isso √© governado pela vari√°vel <strong>fail_timeout.</strong> </li></ul><br>  Mas h√° erros, e isso n√£o nos conv√©m. <br><br>  <strong>O que fazer sobre isso?</strong> <br><br>  Podemos aumentar o n√∫mero de novas tentativas (mas depois retornar ao problema de "solicita√ß√µes assassinas") ou reduzir a probabilidade de uma solicita√ß√£o chegar a back-ends "mortos".  Isso pode ser feito com <strong>verifica√ß√µes de sa√∫de.</strong> <br><br><h2>  Verifica√ß√µes de integridade <br></h2><br>  Sugiro considerar as verifica√ß√µes de integridade como uma otimiza√ß√£o do processo de escolha de um servidor "ativo".  <strong>Isso n√£o oferece nenhuma garantia.</strong>  Consequentemente, durante a execu√ß√£o de uma solicita√ß√£o do usu√°rio, √© mais prov√°vel que consigamos acessar apenas servidores "ativos".  O balanceador acessa regularmente um URL espec√≠fico, o servidor responde: "Estou vivo e pronto". <br><br><h4>  Verifica√ß√µes de integridade: em termos de back-end <br></h4><br>  Do ponto de vista de back-end, voc√™ pode fazer coisas interessantes: <br><br><ul><li>  Verifique a prontid√£o para a opera√ß√£o de todos os subsistemas subjacentes dos quais a opera√ß√£o de back-end depende: o n√∫mero necess√°rio de conex√µes com o banco de dados √© estabelecido, o pool tem conex√µes livres, etc., etc. </li><li>  Voc√™ pode suspender sua pr√≥pria l√≥gica no URL de verifica√ß√µes de integridade se o balanceador usado n√£o for muito inteligente (por exemplo, voc√™ usa o Balanceador de Carga do host).  O servidor pode se lembrar de que "no √∫ltimo minuto, cometi tantos erros - provavelmente sou um servidor" errado "e, nos pr√≥ximos 2 minutos, responderei com" quinhentos "√†s verifica√ß√µes de integridade.  Ent√£o eu vou me banir! "  √Äs vezes, isso ajuda muito quando voc√™ tem um balanceador de carga n√£o controlado. </li><li>  Normalmente, o intervalo de verifica√ß√£o √© de cerca de um segundo e voc√™ precisa do manipulador de verifica√ß√£o de integridade para n√£o matar o servidor.  Deve ser leve. </li></ul><br><h4>  Verifica√ß√µes de integridade: implementa√ß√µes <br></h4><br>  Como regra, tudo aqui √© o mesmo para todos: <br><br><ul><li>  Solicita√ß√£o; </li><li>  Tempo limite nele; </li><li>  Intervalo atrav√©s do qual fazemos verifica√ß√µes.  Os proxies enganados t√™m <strong>jitter</strong> , ou seja, alguma randomiza√ß√£o, para que todas as verifica√ß√µes de integridade n√£o cheguem ao back-end de uma vez e n√£o o matem. </li><li>  <strong>Limite n√£o √≠ntegro</strong> - o limite de quantas verifica√ß√µes de integridade com falha devem passar para que o servi√ßo o marque como N√£o √≠ntegro. </li><li>  <strong>Limite saud√°vel</strong> - pelo contr√°rio, quantas tentativas bem-sucedidas devem passar para que o servidor retorne √† opera√ß√£o. </li><li>  L√≥gica adicional.  Voc√™ pode analisar Verificar status + corpo, etc. </li></ul><br>  O Nginx implementa as fun√ß√µes de verifica√ß√£o de integridade apenas na vers√£o paga do nginx +. <br><br>  Percebo um recurso do <strong>Envoy</strong> , ele tem um <strong>modo de p√¢nico de</strong> verifica√ß√£o de sa√∫de <strong>.</strong>  Quando banimos, como "n√£o saud√°veis", mais de N% dos hosts (digamos 70%), ele acredita que todos os nossos exames de sa√∫de est√£o mentindo e que todos os hosts est√£o realmente vivos.  Em um caso muito ruim, isso ajudar√° voc√™ a n√£o se deparar com uma situa√ß√£o em que voc√™ mesmo matou a perna e baniu todos os servidores.  Esta √© uma maneira de estar seguro novamente. <br><br><h2>  Juntando tudo <br></h2><br>  Normalmente, para verifica√ß√µes de integridade definidas: <br><br><ul><li>  Ou nginx +; </li><li>  Ou nginx + outra coisa :) </li></ul><br>  Em nosso pa√≠s, h√° uma tend√™ncia de definir nginx + HAProxy, porque a vers√£o gratuita do nginx n√£o possui verifica√ß√µes de sa√∫de e, at√© a vers√£o 1.11.5, n√£o havia limite no n√∫mero de conex√µes com o back-end.  Mas essa op√ß√£o √© ruim porque o HAProxy n√£o sabe se aposentar depois de estabelecer uma conex√£o.  Muitas pessoas pensam que, se o HAProxy retornar um erro nas tentativas nginx e nginx, tudo ficar√° bem.  Na verdade n√£o.  Voc√™ pode acessar outro HAProxy e o mesmo back-end, porque os pools de back-end s√£o os mesmos.  Ent√£o, voc√™ introduz mais um n√≠vel de abstra√ß√£o para si mesmo, o que reduz a precis√£o do seu equil√≠brio e, consequentemente, a disponibilidade do servi√ßo. <br><br>  Temos o nginx + Envoy, mas se voc√™ ficar confuso, poder√° limitar-se apenas ao Envoy. <br><br><h2>  Que tipo de enviado? <br></h2><br>  O Envoy √© um balanceador de carga para jovens da moda, originalmente desenvolvido em Lyft, escrito em C ++.  <strong>Fora da caixa, ele pode fazer um monte de p√£es no nosso t√≥pico hoje.</strong>  Voc√™ provavelmente o viu como uma malha de servi√ßo para o Kubernetes.  Como regra, o Envoy atua como um plano de dados, ou seja, equilibra diretamente o tr√°fego, e tamb√©m existe um plano de controle que fornece informa√ß√µes sobre o que voc√™ precisa para distribuir a carga (descoberta de servi√ßo etc.). <br><br>  Vou lhe dizer algumas palavras sobre os p√£es dele. <br><br>  Para aumentar a probabilidade de uma resposta de nova tentativa bem-sucedida na pr√≥xima vez que tentar, voc√™ pode dormir um pouco e esperar que os back-end voltem ao normal.  Dessa forma, lidaremos com pequenos problemas no banco de dados.  O enviado tem um <strong>backoff para tentativas</strong> - pausa entre tentativas.  Al√©m disso, o intervalo de atraso entre as tentativas aumenta exponencialmente.  A primeira tentativa ocorre ap√≥s 0-24 ms, a segunda ap√≥s 0-74 ms e, para cada tentativa subseq√ºente, o intervalo aumenta e o atraso espec√≠fico √© selecionado aleatoriamente nesse intervalo. <br><br>  A segunda abordagem n√£o √© espec√≠fica do enviado, mas um padr√£o chamado de <strong>quebra de circuito</strong> (lit. disjuntor ou fus√≠vel).  Quando nosso back-end diminui, na verdade tentamos termin√°-lo sempre.  Isso ocorre porque os usu√°rios em qualquer situa√ß√£o incompreens√≠vel clicam na p√°gina de atualiza√ß√£o, enviando cada vez mais solicita√ß√µes.  Seus balanceadores ficam nervosos, enviam novas tentativas, o n√∫mero de solicita√ß√µes aumenta - a carga est√° aumentando e, nessa situa√ß√£o, seria bom n√£o enviar solicita√ß√µes. <br><br>  O disjuntor apenas permite determinar que estamos nesse estado, disparar rapidamente o erro e dar aos back-ends "recuperar o f√¥lego". <br><br><img src="https://habrastorage.org/webt/xb/mm/i8/xbmmi88cqacoqvkzdmujynq6da0.gif"><br>  <em>Disjuntor (hystrix como libs),</em> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><em>original</em></a> <em>no blog do ebay.</em> <br><br>  Acima est√° o circuito do disjuntor Hystrix.  Hystrix √© a biblioteca Java da Netflix projetada para implementar padr√µes de toler√¢ncia a falhas. <br><br><ul><li>  O "fus√≠vel" pode estar no estado "fechado" quando todas as solicita√ß√µes s√£o enviadas para o back-end e n√£o h√° erros. </li><li>  Quando um certo limite de falha √© acionado, ou seja, alguns erros ocorreram, o disjuntor entra no estado "Aberto".  Ele retorna rapidamente um erro ao cliente e as solicita√ß√µes n√£o chegam ao back-end. </li><li>  Uma vez em um determinado per√≠odo de tempo, ainda uma pequena parte das solicita√ß√µes √© enviada ao back-end.  Se um erro for acionado, o estado permanecer√° "Aberto".  Se tudo come√ßar a funcionar bem e responder, o "fus√≠vel" ser√° fechado e o trabalho continuar√°. </li></ul><br>  No Enviado, como tal, isso n√£o √© tudo.  Existem limites de n√≠vel superior no fato de que n√£o pode haver mais de N solicita√ß√µes para um grupo upstream espec√≠fico.  Se houver mais, algo est√° errado aqui - retornamos um erro.  N√£o pode haver mais N tentativas ativas (ou seja, tentativas que est√£o acontecendo no momento). <br><br>  Voc√™ n√£o teve tentativas, algo explodiu - envie tentativas.  O enviado entende que mais de N √© anormal e todas as solicita√ß√µes devem ser disparadas com erro. <br><br>  <strong>Quebra de circuitos [Enviado]</strong> <br><br><ul><li>  M√°ximo de conex√µes de cluster (grupo upstream) </li><li>  Solicita√ß√µes pendentes m√°ximas do cluster </li><li>  Solicita√ß√µes m√°ximas de cluster </li><li>  M√°ximo de tentativas ativas do cluster </li></ul><br>  Essa coisa simples funciona bem, √© configur√°vel, voc√™ n√£o precisa criar par√¢metros especiais e as configura√ß√µes padr√£o s√£o muito boas. <br><br><h4>  Disjuntor: nossa experi√™ncia <br></h4><br>  Costum√°vamos ter um coletor de m√©tricas HTTP, ou seja, agentes instalados nos servidores de nossos clientes enviavam m√©tricas para nossa nuvem via HTTP.  Se houver algum problema na infraestrutura, o agente gravar√° as m√©tricas no disco e tentar√° envi√°-las para n√≥s. <br><br>  E os agentes constantemente fazem tentativas de enviar dados para n√≥s, eles n√£o ficam chateados porque, de alguma forma, respondemos incorretamente e n√£o sa√≠mos. <br><br>         (       ,      )  ,     ,           . <br><br>            nginx limit req.    ,    , , 200 RPS.       ,   ,          ,   limit req. <br><br>           TCP     HTTP (  nginx limit req).            .      limit req . <br><br>     ,      ,  .   <strong> </strong>  Circuit breaker,  ,     N  ,   ,   - ,   ,  .   ,    ,      spool  . <br><br>  <strong></strong>   Circuit breaker       + request cancellation ( ).  ,    N   Cassandra, N   Elastic,  ,    ‚Äî   ,         .      ‚Äî ,   . <br><br><img src="https://habrastorage.org/webt/jo/l2/jk/jol2jk44vlcmz3twgvr0jgtpbii.png"><br><br><img src="https://habrastorage.org/webt/1a/7b/x4/1a7bx4yq20uehqoagd4tutqxgmw.png"><br><br>    ,         (:  ‚Äî  ¬´¬ª,  ‚Äî ¬´¬ª). ,      800 RPS    20-30.     ¬´¬ª, ,    . <br><br><h2>    <br></h2><br>    ‚Äî  ,  . <br><br>         ,   ,        ‚Äî      .    . <br><br>  ,       , ,      ,   Health checks ‚Äî HTTP 200. <br><br>    . <br><br><img src="https://habrastorage.org/webt/yu/cy/9s/yucy9sofdr-z7brvjedmnxt4_gc.png"><br><br>     Load Balancer, 3 ,         Cassandra.      Cassandra,   Cassandra   ,    Cassandra     data noda. <br><br>   ‚Äî    : <strong>kernel: NETDEV WATCHDOG: eth0 (ixgbe): transmit queue 3 timed out.</strong> <br><br>   :     (    ),    64     . , 1/64   .     reboot,    . <br><br> ,  ,    ,      .  , ,        ,            .   ,    ,   .     ,   . <br><br> <strong>Cassandra: coordinator -&gt; nodes</strong> <br><br>  Cassandra,      (speculative retries),      .    latency  99 ,         . <br><br> <strong>App -&gt; cassandra coordinator</strong> <br><br>     .     Cassandra      ¬´¬ª ,    ,  ,  latency  .. <br><br>      gocql ‚Äî   cassandra client.       .   HostSelectionPolicy,       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">bitly/go-hostpool</a> .    Epsilon greedy  ,       . <br><br>     ,    <strong>Epsilon-greedy</strong> . <br><br>      (multi-armed bandit):       ,     ,     N     . <br><br>    : <br><br><ol><li>  ¬´ <strong>explore¬ª</strong> ‚Äî   : 10    ,  ,   . <br></li><li>  ¬´ <strong>exploit¬ª</strong> ‚Äî      . <br></li></ol><br> ,    (10 ‚Äî 30%)   <strong>round</strong> - <strong>robin</strong>    ,  ,  ,  .  70 ‚Äî 90%        . <br><br> Host-pool          .         .        (    ‚Äî ,    ,  ).      .      ,     , ,       . <br><br><h2>   </h2><br>   ¬´¬ª ()   ‚ÄîCassandra  Cassandra coordinator-data.     (nginx, Envoy ‚Äî  )    ¬´¬ª Application,     Cassandra  ,       ,      . <br><br>  Envoy    <strong>Outlier detection</strong> : <br><br><ul><li> Consecutive http-5xx. </li><li> Consecutive gateway errors (502,503,504). </li><li> Success rate. </li></ul><br>   ¬´¬ª  ,    -  ,   .   ,    .        ‚Äî    ,   ,     .  ,    ,          . <br><br>   ,       ¬´¬ª,   max_ejection_percent.    ,      outlier,     .  ,    70%  ‚Äî  ,   ‚Äî , ! <br><br>      ,       ‚Äî ! <br><br><h2>  <br></h2><br> ,     ,      .  ,       latency    , : <br><br><ul><li>  ,        .. </li><li>    ,      -,       . </li></ul><br> ,  <strong>    </strong> ,   .  ,      ,     ,         ‚Äî  ,    . <br><br> <strong>      </strong> .  99%     nginx/ <s>HAProxy</s> /Envoy.   proxy ,           ¬´¬ª. <br><br> <strong>    proxy</strong> (   HAProxy:)), <strong>  ,    .</strong> <br><br><blockquote>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">DevOpsConf Russia</a>      Kubernetes         .          <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> . <br><br>    ,       ‚Äî <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>      DevOps. <br><br>    ,   ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">YouTube-</a> ‚Äî              . <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt423085/">https://habr.com/ru/post/pt423085/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt423073/index.html">Sistema de arquivos interplanet√°rio - hash (identidade) trivial, bloco DAG e buffers de protocolo</a></li>
<li><a href="../pt423075/index.html">Por que os CFOs est√£o t√£o ansiosos para converter os gastos de capital em TI em opera√ß√µes</a></li>
<li><a href="../pt423077/index.html">Guia do montador X86 para iniciantes</a></li>
<li><a href="../pt423079/index.html">Pontos-chave de uma entrevista com Elon Musk em Joe Rogan</a></li>
<li><a href="../pt423083/index.html">Como me tornei desenvolvedor na ABBYY</a></li>
<li><a href="../pt423087/index.html">N√£o me empurre nos olhos</a></li>
<li><a href="../pt423089/index.html">Programadores na MBLT DEV 2018</a></li>
<li><a href="../pt423091/index.html">Flutter para desenvolvedores do Android. Como criar uma interface do usu√°rio para uma atividade usando o Flutter</a></li>
<li><a href="../pt423093/index.html">Aumentamos a aleatoriedade do fato de que [provavelmente] [quase] por acidente</a></li>
<li><a href="../pt423095/index.html">Novidades da apresenta√ß√£o da Apple</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
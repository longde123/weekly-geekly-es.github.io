<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë∂üèº ‚¨ÜÔ∏è üëâüèΩ Abonnieren Sie Kafka √ºber HTTP oder vereinfachen Sie Ihre Web-Hooks üë©üèΩ‚Äçüî¨ üç£ üòç</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Es gibt viele M√∂glichkeiten, Nachrichten von Pub-Sub-Systemen zu verarbeiten: Verwenden eines separaten Dienstes, Isolieren eines isolierten Prozesses...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Abonnieren Sie Kafka √ºber HTTP oder vereinfachen Sie Ihre Web-Hooks</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/435346/">  Es gibt viele M√∂glichkeiten, Nachrichten von Pub-Sub-Systemen zu verarbeiten: Verwenden eines separaten Dienstes, Isolieren eines isolierten Prozesses, Orchestrieren eines Pools von Prozessen / Threads, komplexer IPC, Poll-over-Http und viele andere.  Heute m√∂chte ich √ºber die Verwendung von Pub-Sub √ºber HTTP und √ºber meinen speziell daf√ºr geschriebenen Dienst sprechen. <br><br>  Die Verwendung eines vorgefertigten HTTP-Dienst-Backends ist in einigen F√§llen eine ideale L√∂sung f√ºr die Verarbeitung einer Nachrichtenwarteschlange: <br><br><ol><li>  Aus der Box balancieren.  Normalerweise befindet sich das Backend bereits hinter dem Balancer und verf√ºgt √ºber eine einladbare Infrastruktur, die die Arbeit mit Nachrichten erheblich vereinfacht. </li><li>  Verwenden eines regul√§ren REST-Controllers (eine beliebige HTTP-Ressource).  Durch das Konsumieren von HTTP-Nachrichten werden die Kosten f√ºr die Implementierung von Computern f√ºr verschiedene Sprachen minimiert, wenn das Backend gemischt ist. </li><li>  Vereinfachung der Verwendung von Web-Hooks anderer Dienste.  Jetzt unterst√ºtzt fast jeder Dienst (Jira, Gitlab, Mattermost, Slack ...) irgendwie Web-Hooks f√ºr die Interaktion mit der Au√üenwelt.  Sie k√∂nnen das Leben erleichtern, wenn Sie der Warteschlange beibringen, die Funktionen eines HTTP-Dispatchers auszuf√ºhren. </li></ol><br>  Dieser Ansatz hat auch Nachteile: <br><br><ol><li>  Sie k√∂nnen die Leichtigkeit der L√∂sung vergessen.  HTTP ist ein umfangreiches Protokoll, und die Verwendung von Frameworks auf der Seite des Verbrauchers erh√∂ht sofort die Latenz und die Last. </li><li>  Wir verlieren die St√§rken des Poll-Ansatzes und bekommen die Schw√§chen von Push. </li><li>  Das Verarbeiten von Nachrichten durch dieselben Dienstinstanzen, die Clients verarbeiten, kann die Reaktionsf√§higkeit beeintr√§chtigen.  Dies ist nicht signifikant, da es mit Ausgleich und Isolation behandelt wird. </li></ol><br>  Ich habe die Idee als Queue-Over-Http-Dienst implementiert, auf den sp√§ter noch eingegangen wird.  Das Projekt wird in Kotlin mit Spring Boot 2.1 geschrieben.  Als Broker ist derzeit nur Apache Kafka verf√ºgbar. <br><a name="habracut"></a><br>  <i>Weiter im Artikel wird angenommen, dass der Leser mit Kafka vertraut ist und die Commits (Commit) und Offsets (Offset) von Nachrichten, die Prinzipien von Gruppen (Gruppe) und Konsumenten (Konsumenten) kennt und auch versteht, wie sich Partition (Partition) vom Thema (Thema) unterscheidet. .</i>  <i>Wenn es L√ºcken gibt, empfehle ich Ihnen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesen</a> Abschnitt der Kafka-Dokumentation zu lesen, bevor Sie fortfahren.</i> <br><br><h1>  Inhalt </h1><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">R√ºckblick</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Commits</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fehlerbehandlung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nachrichten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Leistung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Demonstration</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fazit</a> </li></ul><br><a name="overview"></a><h1>  R√ºckblick </h1><br>  Queue-Over-Http ist ein Dienst, der als Vermittler zwischen einem Nachrichtenbroker und dem endg√ºltigen HTTP-Konsumenten fungiert (der Dienst erleichtert die Implementierung der Unterst√ºtzung f√ºr das Senden von Nachrichten an Verbraucher auf andere Weise, z. B. auf verschiedene * RPCs).  Derzeit ist nur das Abonnieren, Abbestellen und Anzeigen der Verbraucherliste verf√ºgbar. Das Senden von Nachrichten an den Broker (Produzieren) √ºber HTTP wurde noch nicht implementiert, da die Reihenfolge der Nachrichten ohne besondere Unterst√ºtzung des Herstellers nicht garantiert werden kann. <br><br>  Die Schl√ºsselfigur des Dienstes ist der Verbraucher, der bestimmte Partitionen oder nur Themen abonnieren kann (das Themenmuster wird unterst√ºtzt).  Im ersten Fall ist die automatische Balance von Partitionen deaktiviert.  Nach dem Abonnieren empf√§ngt die angegebene HTTP-Ressource Nachrichten von den zugewiesenen Kafka-Partitionen.  Architektonisch ist jeder Abonnent einem nativen Kafka Java-Client zugeordnet. <br><br><div class="spoiler">  <b class="spoiler_title">unterhaltsame Geschichte √ºber KafkaConsumer</b> <div class="spoiler_text">  Kafka hat einen wunderbaren Java-Client, der viel kann.  Ich verwende es im Warteschlangenadapter, um Nachrichten vom Broker zu empfangen und sie dann an die lokalen Servicewarteschlangen zu senden.  Erw√§hnenswert ist, dass der Client ausschlie√ülich im Kontext eines einzelnen Threads arbeitet. <br><br>  Die Idee des Adapters ist einfach.  Wir beginnen in einem Thread und schreiben den einfachsten Scheduler f√ºr native Clients, wobei wir uns auf die Reduzierung der Latenz konzentrieren.  Das hei√üt, wir schreiben etwas √Ñhnliches: <br><br><pre><code class="kotlin hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (!Thread.interrupted()) { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> hasWork = <span class="hljs-literal"><span class="hljs-literal">false</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (consumer <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> kafkaConsumers) { <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> queueGroup = consumers[consumer] ?: <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span> invalidateSubscription(consumer, queueGroup) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> records = consumer.poll(Duration.ZERO) <span class="hljs-comment"><span class="hljs-comment">/*      */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!records.isEmpty) { hasWork = <span class="hljs-literal"><span class="hljs-literal">true</span></span> } } <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> committed = doCommit() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!hasWork &amp;&amp; committed == <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// ,    Thread.sleep(1) } }</span></span></code> </pre> <br>  Es scheint, dass alles wunderbar ist, die Latenz ist selbst bei Dutzenden von Verbrauchern minimal.  In der Praxis stellte sich heraus, dass <code>KafkaConsumer</code> auf diese Betriebsart <code>KafkaConsumer</code> und in der Leerlaufzeit eine Zuordnungsrate von ca. 1,5 MB / s ergibt.  Bei 100 Kurieren erreicht die Zuweisungsrate 150 MB / s und l√§sst GC h√§ufig an die Anwendung denken.  Nat√ºrlich ist all dieser M√ºll in der jungen Gegend, GC ist durchaus in der Lage, damit umzugehen, aber die L√∂sung ist immer noch nicht perfekt. <br><br>  <code>KafkaConsumer</code> m√ºssen Sie den f√ºr <code>KafkaConsumer</code> typischen Weg <code>KafkaConsumer</code> und jetzt platziere ich jeden Abonnenten in meinem Stream.  Dies bedeutet einen Overhead f√ºr Speicher und Zeitplanung, aber es gibt keinen anderen Weg. <br><br>  Ich schreibe den Code von oben um, entferne die innere Schleife und √§ndere <code>Duration.ZERO</code> in <code>Duration.ofMillis(100)</code> .  Es stellt sich heraus, dass die Zuweisungsrate auf akzeptable 80-150 KB / s pro Verbraucher f√§llt.  Eine Abfrage mit einer Zeit√ºberschreitung von 100 ms verz√∂gert jedoch die gesamte Warteschlange der Festschreibungen auf dieselben 100 ms, und dies ist h√§ufig inakzeptabel. <br><br>  Bei der Suche nach L√∂sungen f√ºr das Problem erinnere <code>KafkaConsumer::wakeup</code> mich an <code>KafkaConsumer::wakeup</code> , das eine <code>WakeupException</code> und alle Blockierungsvorg√§nge f√ºr den Verbraucher unterbricht.  Mit dieser Methode ist der Weg zu einer geringen Latenz einfach: Wenn eine neue Anforderung f√ºr das Festschreiben eintrifft, stellen wir sie in die Warteschlange und rufen auf dem nativen Konsumenten <code>wakeup</code> .  Fangen <code>WakeupException</code> im Arbeitszyklus <code>WakeupException</code> und <code>WakeupException</code> Sie fest, was sich angesammelt hat.  F√ºr die √úbertragung der Kontrolle mit Hilfe von Ausnahmen m√ºssen Sie diese sofort in Ihre H√§nde geben, aber da sonst nichts ... <br><br>  Es stellt sich heraus, dass diese Option <code>WakeupException</code> perfekt ist, da jede Operation auf dem nativen Verbraucher jetzt eine <code>WakeupException</code> , einschlie√ülich des Commits selbst.  <code>wakeup</code> diese Situation verarbeiten, wird der Code mit einem Flag <code>wakeup</code> , das das <code>wakeup</code> erm√∂glicht. <br><br>  Ich komme zu dem Schluss, dass es sch√∂n w√§re, die <code>KafkaConsumer::poll</code> Methode so zu √§ndern, dass sie gem√§√ü einem zus√§tzlichen Flag normal unterbrochen werden kann.  Infolgedessen wurde <a href="https://github.com/viirtus/queue-over-">Frankenstein</a> aus der Reflexion geboren, die genau die urspr√ºngliche Abfragemethode kopiert und einen Ausgang aus der Schleife durch die Flagge hinzuf√ºgt.  Dieses Flag wird durch eine separate InterruptPoll-Methode gesetzt, die dar√ºber hinaus Wakeup auf dem Client-Selektor aufruft, um die Thread-Sperre f√ºr E / A-Operationen aufzuheben. <br><br>  Nachdem ich den Client auf diese Weise implementiert habe, erhalte ich die Reaktionsgeschwindigkeit ab dem Moment, in dem eine Anforderung f√ºr ein Commit bei der Verarbeitung eingeht, bis zu 100 Mikrosekunden und eine hervorragende Latenz f√ºr das Abrufen von Nachrichten von einem Broker, was in Ordnung ist. <br></div></div><br>  Jede Partition wird durch eine separate lokale Warteschlange dargestellt, in die der Adapter Nachrichten vom Broker schreibt.  Der Worker nimmt Nachrichten von ihm und sendet sie zur Ausf√ºhrung, dh zum Senden √ºber HTTP. <br><br>  Der Dienst unterst√ºtzt die Stapelnachrichtenverarbeitung, um den Durchsatz zu erh√∂hen.  Beim Abonnieren k√∂nnen Sie den <code>concurrencyFactor</code> jedes Thema angeben (gilt f√ºr jede zugewiesene Partition unabh√§ngig).  <code>concurrencyFactor=1000</code> bedeutet beispielsweise, dass 1000 Nachrichten in Form von HTTP-Anforderungen gleichzeitig an den Verbraucher gesendet werden k√∂nnen.  Sobald alle Nachrichten aus dem Paket vom Verbraucher eindeutig ausgearbeitet wurden, entscheidet der Dienst √ºber das n√§chste Festschreiben des Offsets der letzten Nachricht in Kafka.  Daher ist der zweite Wert von <code>concurrencyFactor</code> die maximale Anzahl von Nachrichten, die vom Verbraucher im Falle eines Kafka- oder Queue-Over-Http-Absturzes verarbeitet werden. <br><br>  Um Verz√∂gerungen zu <code>loadFactor = concurrencyFactor * 2</code> , verf√ºgt die Warteschlange √ºber <code>loadFactor = concurrencyFactor * 2</code> , <code>loadFactor = concurrencyFactor * 2</code> Sie doppelt so viele Nachrichten vom Broker lesen k√∂nnen, wie gesendet werden k√∂nnen.  Da die automatische Festschreibung auf dem nativen Client deaktiviert ist, verst√∂√üt ein solches Schema nicht gegen die Mindestgarantien. <br>  Ein hoher <code>concurrencyFactor</code> Wert erh√∂ht den Durchsatz der Warteschlange, indem die Anzahl der Commits verringert wird, die im schlimmsten Fall bis zu 10 ms dauern.  Gleichzeitig steigt die Belastung des Verbrauchers. <br><br>  Die Reihenfolge des Sendens von Nachrichten innerhalb des Bundles ist nicht garantiert, kann jedoch durch Setzen von <code>concurrencyFactor=1</code> . <br><br><a name="commits"></a><h1>  Commits </h1><br>  Commits sind ein wichtiger Bestandteil des Service.  Wenn das n√§chste Datenpaket bereit ist, wird der Offset der letzten Nachricht aus dem Paket sofort an Kafka festgeschrieben, und erst nach einem erfolgreichen Festschreiben wird das n√§chste Paket f√ºr die Verarbeitung verf√ºgbar.  Oft reicht dies nicht aus und ein automatisches Festschreiben ist erforderlich.  Zu diesem <code>autoCommitPeriodMs</code> gibt es den Parameter <code>autoCommitPeriodMs</code> , der mit der klassischen Autocommit-Periode f√ºr native Clients, die die zuletzt von der Partition gelesene Nachricht <code>autoCommitPeriodMs</code> , wenig gemein hat.  Stellen Sie sich <code>concurrencyFactor=10</code> .  Der Dienst hat alle 10 Nachrichten gesendet und wartet darauf, dass jede von ihnen bereit ist.  Die Verarbeitung von Nachricht 3 ist zuerst abgeschlossen, dann von Nachricht 1 und dann von Nachricht 10. Zu diesem Zeitpunkt ist es Zeit f√ºr die automatische Festschreibung.  Es ist wichtig, die Semantik von mindestens einmal nicht zu verletzen.  Daher k√∂nnen Sie nur die erste Nachricht festschreiben, dh Offset 2, da zu diesem Zeitpunkt nur die Nachricht erfolgreich verarbeitet wurde.  Bis zur n√§chsten automatischen Festschreibung werden die Nachrichten 2, 5, 6, 4 und 8 verarbeitet. Jetzt m√ºssen Sie nur noch den Offset 7 festschreiben und so weiter.  Autocommit hat fast keinen Einfluss auf den Durchsatz. <br><br><a name="errors"></a><h1>  Fehlerbehandlung </h1><br>  Im normalen Betriebsmodus sendet der Dienst einmal eine Nachricht an den Supervisor.  Wenn aus irgendeinem Grund ein 4xx- oder 5xx-Fehler verursacht wurde, sendet der Dienst die Nachricht erneut und wartet auf die erfolgreiche Verarbeitung.  Die Zeit zwischen den Versuchen kann als separater Parameter konfiguriert werden. <br><br>  Es ist auch m√∂glich, die Anzahl der Versuche festzulegen, nach denen die Nachricht als verarbeitet markiert wird, wodurch Neu√ºbertragungen unabh√§ngig vom Status der Antwort gestoppt werden.  Ich rate nicht, dies f√ºr sensible Daten zu verwenden. Versagenssituationen von Verbrauchern sollten immer manuell angepasst werden.  Sticky-Nachrichten k√∂nnen durch Serviceprotokolle und die √úberwachung des Status der Antwort des Verbrauchers √ºberwacht werden. <br><br><div class="spoiler">  <b class="spoiler_title">√ºber das Festhalten</b> <div class="spoiler_text">  Normalerweise sendet der HTTP-Server, der 4xx oder 5xx den Status der Antwort gibt, auch den Header <code>Connection: close</code> .  Eine auf diese Weise geschlossene TCP-Verbindung bleibt im Status <code>TIME_WAITED</code> , bis sie nach einiger Zeit vom Betriebssystem gel√∂scht wird.  Das Problem ist, dass solche Verbindungen einen gesamten Port belegen, der erst freigegeben werden kann.  Dies kann dazu f√ºhren, dass auf dem Computer keine freien Ports zum Herstellen einer TCP-Verbindung vorhanden sind und der Dienst bei jedem Senden mit Ausnahmen in den Protokollen ausgel√∂st wird.  In der Praxis enden die Ports unter Windows 10 nach 10 bis 20 000 fehlerhaften Nachrichten innerhalb von 1 bis 2 Minuten.  Im Standardmodus ist dies kein Problem. <br></div></div><br><a name="messages"></a><h1>  Nachrichten </h1><br>  Jede vom Broker extrahierte Nachricht wird √ºber HTTP an den Berater an die im Abonnement angegebene Ressource gesendet.  Standardm√§√üig wird eine Nachricht durch eine POST-Anforderung im Hauptteil gesendet.  Dieses Verhalten kann durch Angabe einer anderen Methode ge√§ndert werden.  Wenn die Methode das Senden von Daten im Hauptteil nicht unterst√ºtzt, k√∂nnen Sie den Namen des Zeichenfolgenparameters angeben, in dem die Nachricht gesendet wird.  Dar√ºber hinaus k√∂nnen Sie beim Abonnieren zus√§tzliche Header angeben, die jeder Nachricht hinzugef√ºgt werden. Dies ist praktisch f√ºr die grundlegende Autorisierung mithilfe von Token.  Zu jeder Nachricht werden Header mit der Kennung des Verbrauchers, des Themas und der Partition, von der die Nachricht gelesen wurde, der Nachrichtennummer, ggf. des Partitionsschl√ºssels sowie dem Namen des Brokers hinzugef√ºgt. <br><br><a name="performance"></a><h1>  Leistung </h1><br>  Um die Leistung zu bewerten, verwendete ich einen PC (Windows 10, OpenJDK-11 (G1 ohne Optimierung), i7-6700K, 16 GB), auf dem der Dienst ausgef√ºhrt wird, und einen Laptop (Windows 10, i5-8250U, 8 GB), auf dem der Nachrichtenproduzent HTTP arbeitet Resource Consumer und Kafka mit Standardeinstellungen.  Der PC ist √ºber eine 1-Gbit / s-Kabelverbindung mit dem Router verbunden, der Laptop √ºber 802.11ac.  Der Produzent schreibt alle 110 ms alle 100 ms f√ºr 110 Byte Nachrichten aus verschiedenen Gruppen zu den festgelegten Themen, f√ºr die die Follower abonniert sind ( <code>concurrencyFactor=500</code> , Auto-Commit ist deaktiviert).  Der Stand ist alles andere als ideal, aber Sie k√∂nnen sich ein Bild machen. <br><br>  Ein wichtiger Messparameter ist die Auswirkung des Dienstes auf die Latenz. <br><br>  Lassen Sie: <br>  - t <sub>q</sub> - Zeitstempel des Dienstes, der Nachrichten vom nativen Client empf√§ngt <br>  - d <sub>t0</sub> ist die Zeit zwischen t <sub>q</sub> und der Zeit, zu der die Nachricht von der lokalen Warteschlange an den Pool von F√ºhrungskr√§ften gesendet wurde <br>  - d <sub>t</sub> ist die Zeit zwischen t <sub>q</sub> und dem Zeitpunkt, zu dem die HTTP-Anforderung gesendet wurde.  <sub>Dies</sub> ist der Einfluss des Dienstes auf die Latenz der Nachricht. <br><br>  W√§hrend der Messungen wurden folgende Ergebnisse erhalten (C - Verbraucher, T - Themen, M - Nachrichten): <br><br><img src="https://habrastorage.org/webt/p4/r7/pq/p4r7pqavkke1d3glzc7u8o6a5gu.png"><br><br>  In der Standardbetriebsart hat der Dienst selbst fast keinen Einfluss auf die Latenz, und der Speicherverbrauch ist minimal.  Die Maximalwerte von d <sub>t</sub> (ca. 60 ms) sind nicht speziell angegeben, da sie vom Betrieb des GC und nicht vom Dienst selbst abh√§ngen.  Eine spezielle Abstimmung des GC oder das Ersetzen von G1 durch Shenandoah kann dazu beitragen, die Verteilung der Maximalwerte auszugleichen. <br><br>  Alles √§ndert sich dramatisch, wenn der Verbraucher den Nachrichtenfluss aus der Warteschlange nicht bew√§ltigt und der Dienst den Drosselungsmodus aktiviert.  In diesem Modus steigt der Speicherverbrauch, da die Antwortzeit auf Anforderungen erheblich zunimmt, wodurch eine rechtzeitige Bereinigung der Ressourcen verhindert wird.  Die Auswirkung auf die Latenz bleibt hier auf dem Niveau der vorherigen Ergebnisse, und hohe dt-Werte werden durch das Vorladen von Nachrichten in der lokalen Warteschlange verursacht. <br><br>  Leider ist es nicht m√∂glich, bei einer h√∂heren Last zu testen, da sich der Laptop bereits bei 1300 RPS verbiegt.  Wenn jemand bei der Organisation von Messungen bei hohen Lasten helfen kann, stelle ich gerne eine Baugruppe f√ºr Tests zur Verf√ºgung. <br><br><a name="demo"></a><h1>  Demonstration </h1><br>  Fahren wir nun mit der Demonstration fort.  Daf√ºr brauchen wir: <br><br><ul><li>  Kafka Broker, bereit zu gehen.  Ich werde die am 192.168.99.100:9092 von Bitnami erhobene Instanz √ºbernehmen. </li><li>  Eine HTTP-Ressource, die Nachrichten empf√§ngt.  Aus Gr√ºnden der Klarheit habe ich Slack Web-Hooks abgenommen. </li></ul><br>  Zun√§chst m√ºssen Sie den Queue-Over-Http-Dienst selbst aufrufen.  Erstellen Sie dazu die folgenden Inhalte in einem leeren Verzeichnis <code>application.yml</code> : <br><br><pre> <code class="plaintext hljs">spring: profiles: default logging: level: com: viirrtus: queueOverHttp: DEBUG app: persistence: file: storageDirectory: "persist" brokers: - name: "Kafka" origin: "kafka" config: bootstrap.servers: "192.168.99.100:9092"</code> </pre><br>  Hier geben wir dem Dienst die Verbindungsparameter eines bestimmten Brokers sowie den Speicherort f√ºr Abonnenten an, damit diese zwischen den Starts nicht verloren gehen.  In `app.brokers []. Config` k√∂nnen Sie alle Verbindungsparameter angeben, die vom nativen Kafka-Client unterst√ºtzt werden. Eine vollst√§ndige Liste finden Sie <a href="">hier</a> . <br><br>  Da die Konfigurationsdatei von Spring verarbeitet wird, k√∂nnen Sie dort viele interessante Dinge schreiben.  Konfigurieren Sie auch die Protokollierung. <br><br>  F√ºhren Sie nun den Dienst selbst aus.  Wir verwenden den einfachsten Weg - <code>docker-compose.yml</code> : <br><br><pre> <code class="plaintext hljs">version: "2" services: app: image: viirrtus/queue-over-http:0.1.3 restart: unless-stopped command: --debug ports: - "8080:8080" volumes: - ./application.yml:/application.yml - ./persist:/persist</code> </pre><br>  <i>Wenn diese Option nicht zu Ihnen passt, k√∂nnen Sie den Dienst aus der Quelle kompilieren.</i>  <i>Montageanleitung im Readme-Projekt, auf die am Ende des Artikels verwiesen wird.</i> <br><br>  Der n√§chste Schritt ist die Registrierung des ersten Teilnehmers.  Dazu m√ºssen Sie eine HTTP-Anforderung an den Dienst mit einer Beschreibung des Verbrauchers ausf√ºhren: <br><br><pre> <code class="plaintext hljs">POST localhost:8080/broker/subscription Content-Type: application/json { "id": "my-first-consumer", "group": { "id": "consumers" }, "broker": "Kafka", "topics": [ { "name": "slack.test", "config": { "concurrencyFactor": 10, "autoCommitPeriodMs": 100 } } ], "subscriptionMethod": { "type": "http", "delayOnErrorMs": 1000, "retryBeforeCommit": 10, "uri": "&lt;slack-wh-uri&gt;", "additionalHeaders": { "Content-Type": "application/json" } } }</code> </pre><br>  Wenn alles gut gegangen ist, wird die Antwort fast der gleiche gesendete Inhalt sein. <br><br>  Lassen Sie uns jeden Parameter durchgehen: <br><br><ul><li>  <code>Consumer.id</code> - ID unseres Abonnenten </li><li>  <code>Consumer.group.id</code> - Gruppenkennung </li><li>  <code>Consumer.broker</code> - Geben Sie an, welchen der Service Broker Sie abonnieren m√ºssen </li><li>  <code>Consumer.topics[0].name</code> - Der Name des Themas, von dem wir Nachrichten empfangen m√∂chten </li><li> <code>Consumer.topics[0].config. concurrencyFactor</code>  <code>Consumer.topics[0].config. concurrencyFactor</code> - maximale Anzahl gleichzeitig gesendeter Nachrichten </li><li> <code>Consumer.topics[0].config. autoCommitPeriodMs</code>  <code>Consumer.topics[0].config. autoCommitPeriodMs</code> - erzwungene <code>Consumer.topics[0].config. autoCommitPeriodMs</code> f√ºr fertige Nachrichten </li><li>  <code>Consumer.subscriptionMethod.type</code> - Abonnementtyp.  Derzeit ist nur HTTP verf√ºgbar. </li><li>  <code>Consumer.subscriptionMethod.delayOnErrorMs</code> - Zeit vor dem erneuten Senden einer Nachricht, die mit einem Fehler endete </li><li>  <code>Consumer.subscriptionMethod.retryBeforeCommit</code> - Die Anzahl der Versuche, die Fehlermeldung erneut zu senden.  Wenn 0 - wird die Nachricht bis zur erfolgreichen Verarbeitung gedreht.  In unserem Fall ist die Garantie der vollst√§ndigen Lieferung nicht so wichtig wie die Konstanz des Flusses. </li><li>  <code>Consumer.subscriptionMethod.uri</code> - die Ressource, an die Nachrichten gesendet werden </li><li>  <code>Consumer.subscriptionMethod.additionalHeader</code> - zus√§tzliche Header, die mit jeder Nachricht gesendet werden.  Beachten Sie, dass sich im Text jeder Nachricht JSON befindet, damit Slack die Anforderung korrekt interpretieren kann. </li></ul><br>  <i>In dieser Anforderung wird die HTTP-Methode weggelassen, da die Standardeinstellung POST, Slack in Ordnung ist.</i> <br><br>  Ab diesem Moment √ºberwacht der Dienst die zugewiesenen Partitionen des Themas slack.test auf neue Nachrichten. <br><br>  Um Nachrichten zum Thema zu schreiben, verwende ich die in Kafka integrierten Dienstprogramme, die sich in <code>/opt/bitnami/kafka/bin</code> gestarteten Kafka-Images befinden (die Position der Dienstprogramme in anderen Kafka-Instanzen kann unterschiedlich sein): <br><br><pre> <code class="plaintext hljs">kafka-console-producer.sh --broker-list localhost:9092 --topic slack.test &gt; {‚Äútext‚Äù: ‚ÄúHello!‚Äù}</code> </pre><br>  Gleichzeitig benachrichtigt Sie Slack √ºber eine neue Nachricht: <br><br><img src="https://habrastorage.org/webt/kl/eh/z7/klehz7ev6x1y2eaqpf_ylpnjic4.png"><br><br>  <i>Um einen Verbraucher abzumelden, reicht es aus, eine POST-Anfrage an "Broker / Abbestellen" mit demselben Inhalt wie w√§hrend des Abonnements zu stellen.</i> <br><br><a name="the-end"></a><h1>  Fazit </h1><br>  Derzeit ist nur die Grundfunktionalit√§t implementiert.  Dar√ºber hinaus ist geplant, die Stapelverarbeitung zu verbessern, eine einmalige Semantik zu implementieren, die M√∂glichkeit zum Senden von Nachrichten an den Broker √ºber HTTP hinzuzuf√ºgen und vor allem Unterst√ºtzung f√ºr andere beliebte Pub-Sub-Programme hinzuzuf√ºgen. <br><br>  Der Queue-Over-Http-Dienst befindet sich derzeit in der aktiven Entwicklung.  Version 0.1.3 ist stabil genug zum Testen auf Entwicklungs- und B√ºhnenst√§ndern.  Die Leistung wurde unter Windows 10, Debian 9 und Ubuntu 18.04 getestet.  Sie k√∂nnen prod auf eigenes Risiko verwenden.  Wenn Sie bei der Entwicklung helfen oder Feedback zum Service geben m√∂chten, hei√üen wir Sie beim <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://github.com/viirtus/queue-over-">Github-</a> Projekt willkommen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de435346/">https://habr.com/ru/post/de435346/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de435334/index.html">Reaktion auf kalte Briefe</a></li>
<li><a href="../de435336/index.html">Etwas gefunden: Papiere mit Elasticsearch Moskau-Treffen bei OZON</a></li>
<li><a href="../de435338/index.html">Wir schaffen ein System zur elektronischen Zeitmessung von Rennen</a></li>
<li><a href="../de435340/index.html">Der Forscher ver√∂ffentlicht ein Beispiel f√ºr einen Wurm-Arbeitscode f√ºr Facebook</a></li>
<li><a href="../de435344/index.html">Amazon hat Showroom eingef√ºhrt oder warum wir bald alle M√∂bel online kaufen werden</a></li>
<li><a href="../de435348/index.html">Simple MCerver - eine kleine Shell f√ºr den Minecraft-Server</a></li>
<li><a href="../de435352/index.html">DEFCON-Konferenz 18. Praktische Spionage mit einem Mobiltelefon. Teil 2</a></li>
<li><a href="../de435354/index.html">DEFCON-Konferenz 18. Praktische Spionage mit einem Mobiltelefon. Teil 1</a></li>
<li><a href="../de435358/index.html">Antiquit√§ten: Minidisk im Zeitalter des iPod</a></li>
<li><a href="../de435360/index.html">Snippets vs Clover - Schlie√üe das beliebteste Echtzeit-Quiz ab</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
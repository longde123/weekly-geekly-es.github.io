<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏉 🚟 💷 Spark Streaming和Kafka的集成 🔴 🐕 👩🏼‍💻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="大家好！ 我们提醒您，不久前我们出版了一本有关Spark的书 ，而现在一本有关Kafka的书正在接受最新的校对。 


 我们希望这些书能够取得成功，足以继续该主题-例如，有关Spark Streaming的文献的翻译和出版。 我们今天想为您提供有关将该技术与Kafka集成的翻译。 

 1.理由 ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Spark Streaming和Kafka的集成</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/417123/"> 大家好！ 我们提醒您，不久前我们出版了一<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">本有关Spark</a>的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">书</a> ，而现在一<a href="">本有关Kafka</a>的<a href="">书</a>正在接受最新的校对。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/it/cf/nj/itcfnjaffoo8apwikyd7_yfym5s.jpeg"></div><br> 我们希望这些书能够取得成功，足以继续该主题-例如，有关Spark Streaming的文献的翻译和出版。 我们今天想为您提供有关将该技术与Kafka集成的翻译。 <br><a name="habracut"></a><br>  <b>1.理由</b> <br><br>  Apache Kafka + Spark Streaming是创建实时应用程序的最佳组合之一。 在本文中，我们将详细讨论这种集成的细节。 此外，我们将以Spark Streaming-Kafka为例。 然后，我们讨论“接收方方法”以及Kafka和Spark Streaming直接集成的选项。 因此，让我们开始集成Kafka和Spark Streaming。 <br><br><img src="https://habrastorage.org/webt/8x/jl/cp/8xjlcpzhwdwi4w2g87iifbquvr0.jpeg"><br><br>  <b>2. Kafka和Spark Streaming的集成</b> <br><br> 在集成Apache Kafka和Spark Streaming时，有两种可能的方法来配置Spark Streaming以从Kafka接收数据-即 整合Kafka和Spark Streaming的两种方法。 首先，您可以使用收件人和高级Kafka API。 第二种（较新的）方法是没有收件人的工作。 两种方法都有不同的编程模型，例如在性能和语义保证方面有所不同。 <br><br><img src="https://habrastorage.org/webt/91/mn/sk/91mnsklu_81q0nx9aadnjgya4fc.png"><br><br> 让我们更详细地考虑这些方法。 <br><br>  <i><b>一个</b></i>  <i><b>基于收件人的方法</b></i> <br><br> 在这种情况下，数据的接收是由收件人提供的。 因此，使用Kafka提供的高级消费API，我们实现了收件人。 此外，接收到的数据存储在Spark Artists中。 然后，在Kafka-Spark Streaming中启动作业，在其中处理数据。 <br><br> 但是，使用这种方法时，在发生故障（使用默认配置）的情况下仍然存在数据丢失的风险。 因此，有必要在Kafka-Spark Streaming中另外包含一个预写日志，以消除数据丢失。 因此，从Kafka接收的所有数据都同步存储在分布式文件系统中的预写日志中。 因此，即使在系统出现故障后，也可以还原所有数据。 <br><br> 接下来，我们将研究如何在具有Kafka-Spark Streaming的应用程序中对收件人使用这种方法。 <br><br>  <i>我</i>  <i>装订</i> <br><br> 现在，我们将流应用程序与以下针对Scala / Java应用程序的工件相连，我们将使用SBT / Maven的项目定义。 <br><br><pre><code class="java hljs">groupId = org.apache.spark artifactId = spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span> version = <span class="hljs-number"><span class="hljs-number">2.2</span></span>.0</code> </pre> <br> 但是，在部署我们的应用程序时，我们将不得不添加上述库及其依赖项，Python应用程序将需要此库。 <br><br>  <i>ii。</i>  <i>程式设计</i> <br><br> 接下来，通过将<code>KafkaUtils</code>导入到流应用程序代码中来创建<code>DStream</code>输入流： <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.streaming.kafka._ val kafkaStream = KafkaUtils.createStream(streamingContext, [ZK quorum], [consumer group id], [per-topic number of Kafka partitions to consume])</code> </pre> <br> 此外，使用createStream选项，可以指定键类和值类，以及用于解码的相应类。 <br><br>  <i>iii。</i>  <i>部署方式</i> <br><br> 与任何Spark应用程序一样，spark-submit命令用于启动。 但是，细节在Scala / Java应用程序和Python应用程序中略有不同。 <br><br> 此外，使用<code>–packages</code>您可以将<code>spark-streaming-Kafka-0-8_2.11</code>及其依赖项直接添加到<code>spark-submit</code> ，这对于无法使用SBT / Maven管理项目的Python应用程序很有用。 <br><br><pre> <code class="java hljs">./bin/spark-submit --packages org.apache.spark:spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span>:<span class="hljs-number"><span class="hljs-number">2.2</span></span>.0 ...</code> </pre> <br> 您还可以从Maven存储库下载Maven工件<code>spark-streaming-Kafka-0-8-assembly</code>的JAR存档。 然后将其添加到带有<code>jars</code> <code>spark-submit</code> 。 <br><br>  <i>b。</i>  <i>直接方式（无收件人）</i> <br><br> 在使用接收者的方法之后，开发了一种较新的方法-“直接”方法。 它提供可靠的端到端保修。 在这种情况下，我们会定期向Kafka询问每个主题/部分的偏移量偏移量，而不安排通过接收者传送数据。 另外，确定读取的片段的大小，这对于正确处理每个分组是必需的。 最后，一个简单的消耗性API用于从具有指定偏移量的Kafka数据读取范围，尤其是在启动数据处理作业时。 整个过程就像从文件系统读取文件。 <br><br> 注意：此功能出现在Scala和Java API的Spark 1.3中，以及Python API的Spark 1.4中。 <br><br> 现在让我们讨论如何在我们的流应用程序中应用这种方法。 <br> 消费者API在以下链接中有更详细的描述： <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Apache Kafka使用者|</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">卡夫卡消费者的例子</a> <br><br> 我 装订 <br><br> 是的，仅Scala / Java应用程序支持此方法。 使用以下工件，构建SBT / Maven项目。 <br><br><pre> <code class="java hljs">groupId = org.apache.spark artifactId = spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span> version = <span class="hljs-number"><span class="hljs-number">2.2</span></span>.0</code> </pre> <br>  <i>ii。</i>  <i>程式设计</i> <br><br> 接下来，导入KafkaUtils并在流应用程序代码中创建一个输入<code>DStream</code> ： <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.streaming.kafka._ val directKafkaStream = KafkaUtils.createDirectStream[ [key <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">value</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">key</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">decoder</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">value</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">decoder</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">] ]( </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">streamingContext</span></span></span><span class="hljs-class">, [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">map</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">of</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Kafka</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">parameters</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">set</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">of</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">topics</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">to</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">consume</span></span></span><span class="hljs-class">])</span></span></code> </pre> <br> 在Kafka参数中，您将需要指定<code>metadata.broker.list</code>或<code>bootstrap.servers</code> 。 因此，默认情况下，我们将使用从Kafka的每个部分中的最后一个偏移量开始的数据。 但是，如果要从最小的片段开始读取，则需要在Kafka参数中设置配置选项<code>auto.offset.reset</code> 。 <br><br> 此外，使用选项<code>KafkaUtils.createDirectStream</code> ，您可以从任意偏移量开始读取。 然后，我们将执行以下操作，这将使我们能够访问每个包中消耗的Kafka片段。 <br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//      ,        var offsetRanges = Array.empty[OffsetRange] directKafkaStream.transform { rdd =&gt; offsetRanges = rdd.asInstanceOf[HasOffsetRanges].offsetRanges rdd }.map { ... }.foreachRDD { rdd =&gt; for (o &lt;- offsetRanges) { println(s"${o.topic} ${o.partition} ${o.fromOffset} ${o.untilOffset}") } ... }</span></span></code> </pre> <br> 如果我们要使用特殊工具在Zookeeper的基础上组织对Kafka的监视，可以在其帮助下自行更新Zookeeper。 <br><br>  <i>iii。</i>  <i>部署方式</i> <br><br> 在这种情况下，部署过程与接收方的变体中的部署过程类似。 <br><br>  <b>3.直接方法的好处</b> <br><br> 由于以下原因，将Spark Streaming与Kafka集成的第二种方法优于第一种： <br><br>  <b><i>一个</i></b>  <b><i>简化并发</i></b> <br><br> 在这种情况下，您无需创建许多Kafka输入流并将其组合。 但是，Kafka-Spark Streaming将创建与将要使用的Kafka分段一样多的RDD分段。 所有这些Kafka数据都将并行读取。 因此，可以说我们将在Kafka和RDD段之间建立一一对应的关系，这样的模型更易于理解且易于配置。 <br><br>  <i><b>b。</b></i>  <i><b>实效</b></i> <br><br> 为了完全消除第一种方法期间的数据丢失，需要将信息存储在主要记录的日志中，然后再进行复制。 实际上，这是低效的，因为数据被复制了两次：第一次是由Kafka本身复制，第二次是通过预写日志复制。 在第二种方法中，由于没有接收者，因此消除了此问题，因此不需要引导写日记帐。 如果我们在Kafka中有足够长的数据存储空间，则可以直接从Kafka恢复消息。 <br><br>  <b><i>s</i></b>  <b><i>一次精确语义</i></b> <br><br> 基本上，我们在第一种方法中使用了高级Kafka API将消耗的读取片段存储在Zookeeper中。 但是，这是使用来自Kafka的数据的习惯。 尽管可以可靠地消除数据丢失，但是在某些故障中，个别记录可能会被消耗两次。 重点是Kafka-Spark Streaming中可靠的数据传输机制与Zookeeper中发生的片段读取之间的不一致。 因此，在第二种方法中，我们使用简单的Kafka API，它不需要求助于Zookeeper。 在这里，在Kafka-Spark Streaming中跟踪读取的片段，为此，使用了控制点。 在这种情况下，Spark Streaming和Zookeeper / Kafka之间的不一致将被消除。 <br><br> 因此，即使发生故障，Spark Streaming也仅严格接收一次每个记录。 在这里，我们需要确保将数据存储在外部存储中的输出操作是幂等的或原子事务，在其中存储结果和偏移量。 这就是在我们的结果推导中实现一次精确语义的方式。 <br><br> 虽然有一个缺点：Zookeeper中的偏移量不会更新。 因此，基于Zookeeper的Kafka监视工具不允许您跟踪进度。 <br> 但是，如果处理是以这种方式安排的，我们仍然可以引用偏移量-我们转向每个程序包并自行更新Zookeeper。 <br><br> 这就是我们想要讨论的有关集成Apache Kafka和Spark Streaming的全部内容。 希望您喜欢。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN417123/">https://habr.com/ru/post/zh-CN417123/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN417111/index.html">在线会议：流媒体vs网络研讨会</a></li>
<li><a href="../zh-CN417113/index.html">俄罗斯的3D意大利打印机：Raise3D N1 Dual-建模和原型制作</a></li>
<li><a href="../zh-CN417115/index.html">要埋葬或燃烧Flutter.io？</a></li>
<li><a href="../zh-CN417117/index.html">GameCube游戏中NES模拟器的逆向工程</a></li>
<li><a href="../zh-CN417119/index.html">Vue.js中的分页</a></li>
<li><a href="../zh-CN417125/index.html">RTC Meetup .Net：邀请参加第一次会议</a></li>
<li><a href="../zh-CN417127/index.html">特斯拉签署协议在中国建造Gigafactory 3</a></li>
<li><a href="../zh-CN417129/index.html">心灵的宇宙</a></li>
<li><a href="../zh-CN417131/index.html">现在如何在MongoDB中感受交易</a></li>
<li><a href="../zh-CN417135/index.html">Unity3D：如何找出场景中某个点的覆盖程度？</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
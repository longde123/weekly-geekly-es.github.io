<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëá üå≤ üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Crie uma solu√ß√£o de failover baseada na arquitetura Oracle RAC e AccelStor Shared-Nothing üë©üèø‚Äç‚öñÔ∏è üö≤ üò∏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Um n√∫mero consider√°vel de aplicativos corporativos e sistemas de virtualiza√ß√£o possui seus pr√≥prios mecanismos para criar solu√ß√µes tolerantes a falhas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Crie uma solu√ß√£o de failover baseada na arquitetura Oracle RAC e AccelStor Shared-Nothing</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/accelstor/blog/448538/"><p>  Um n√∫mero consider√°vel de aplicativos corporativos e sistemas de virtualiza√ß√£o possui seus pr√≥prios mecanismos para criar solu√ß√µes tolerantes a falhas.  Em particular, o Oracle RAC (Oracle Real Application Cluster) √© um cluster de dois ou mais servidores de banco de dados Oracle trabalhando juntos para equilibrar a carga e fornecer toler√¢ncia a falhas no n√≠vel do servidor / aplicativo.  Para trabalhar neste modo, √© necess√°rio um armazenamento comum, cuja fun√ß√£o √© geralmente armazenamento. </p><br><p>  Como j√° discutimos em um de nossos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigos</a> , o sistema de armazenamento, apesar da presen√ßa de componentes duplicados (incluindo controladores), ainda possui pontos de falha - principalmente na forma de um √∫nico conjunto de dados.  Portanto, para criar uma solu√ß√£o Oracle com maiores requisitos de confiabilidade, o esquema "N servidores - um armazenamento" deve ser complicado. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/l3/lh/1t/l3lh1tmhqobqcqow6yxo-g3j8lc.png"></div><br><a name="habracut"></a><br><p>  Primeiro, √© claro, voc√™ precisa decidir contra quais riscos estamos tentando garantir.  Neste artigo, n√£o consideraremos a prote√ß√£o contra amea√ßas como a chegada de um meteorito.  Portanto, a cria√ß√£o de uma solu√ß√£o de recupera√ß√£o de desastre geograficamente dispersa continuar√° sendo um t√≥pico para um dos seguintes artigos.  Aqui, examinamos a chamada solu√ß√£o de recupera√ß√£o de desastre entre rack, quando a prote√ß√£o √© criada no n√≠vel dos gabinetes de servidor.  Os pr√≥prios arm√°rios podem estar localizados na mesma sala ou em diferentes, mas geralmente dentro do mesmo pr√©dio. </p><br><p>  Esses gabinetes devem conter todo o conjunto de equipamentos e software necess√°rios para garantir a opera√ß√£o dos bancos de dados Oracle, independentemente do estado do ‚Äúvizinho‚Äù.  Em outras palavras, usando a solu√ß√£o de recupera√ß√£o de desastre Cross-Rack, eliminamos os riscos de falha: </p><br><ul><li>  Servidores de Aplicativos Oracle </li><li>  Sistemas de armazenamento </li><li>  Sistemas de comuta√ß√£o </li><li>  Falha completa de todos os equipamentos no gabinete: <br><ul><li>  Falha de energia </li><li>  Falha no sistema de refrigera√ß√£o </li><li>  Fatores externos (homem, natureza, etc.) </li></ul></li></ul><br><p>  A duplica√ß√£o de servidores Oracle implica o pr√≥prio princ√≠pio do Oracle RAC e √© implementada atrav√©s do aplicativo.  A duplica√ß√£o de ferramentas de comuta√ß√£o tamb√©m n√£o √© um problema.  Mas a duplica√ß√£o do sistema de armazenamento n√£o √© t√£o simples. </p><br><p>  A op√ß√£o mais f√°cil √© replicar dados do armazenamento prim√°rio para o backup.  S√≠ncrono ou ass√≠ncrono, dependendo dos recursos de armazenamento.  A replica√ß√£o ass√≠ncrona levanta imediatamente a quest√£o de garantir a consist√™ncia dos dados com o Oracle.  Por√©m, mesmo se houver integra√ß√£o de software com o aplicativo, em qualquer caso, em caso de acidente no sistema de armazenamento principal, ser√° necess√°ria uma interven√ß√£o manual dos administradores para alternar o cluster para o armazenamento de backup. </p><br><p>  Uma op√ß√£o mais complexa s√£o os ‚Äúvirtualizadores‚Äù de software e / ou hardware de sistemas de armazenamento, que eliminam problemas com consist√™ncia e interven√ß√£o manual.  Mas a complexidade da implanta√ß√£o e administra√ß√£o subsequente, bem como o custo muito indecente de tais solu√ß√µes, assusta muitos. </p><br><p>  Apenas para cen√°rios como recupera√ß√£o de desastre entre bastidores, o array All Flash AccelStor NeoSapphire ‚Ñ¢ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">H710</a> usando a arquitetura Shared-Nothing √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">perfeito</a> .  Este modelo √© um sistema de armazenamento duplo usando sua pr√≥pria tecnologia FlexiRemap¬Æ para trabalhar com pen drives.  Gra√ßas ao <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">FlexiRemap¬Æ</a> NeoSapphire ‚Ñ¢ H710, ele pode fornecer at√© 600K de grava√ß√£o aleat√≥ria IOPS @ 4K e 1M + IOPS @ 4K de leitura aleat√≥ria, o que √© inating√≠vel com o armazenamento cl√°ssico baseado em RAID. </p><br><p>  Mas a principal caracter√≠stica do NeoSapphire ‚Ñ¢ H710 √© a execu√ß√£o de dois n√≥s como gabinetes separados, cada um com sua pr√≥pria c√≥pia dos dados.  A sincroniza√ß√£o do n√≥ √© realizada atrav√©s da interface externa do InfiniBand.  Gra√ßas a essa arquitetura, os n√≥s podem se espalhar por diferentes locais, por dist√¢ncias de at√© 100m, fornecendo a solu√ß√£o de recupera√ß√£o de desastre Cross-Rack.  Ambos os n√≥s funcionam completamente no modo s√≠ncrono.  Do lado do host, o H710 parece um armazenamento comum de controlador duplo.  Portanto, nenhuma op√ß√£o adicional de software e hardware e configura√ß√µes particularmente complexas precisam ser executadas. </p><br><p>  Se voc√™ comparar todas as solu√ß√µes de recupera√ß√£o de desastre Cross-Rack descritas acima, a vers√£o AccelStor se destacar√° das demais: </p><br><table><tbody><tr><th></th><th>  Arquitetura compartilhada do AccelStor NeoSapphire ‚Ñ¢ Nothing </th><th>  Virtualizador de armazenamento de software ou hardware </th><th>  Solu√ß√£o de replica√ß√£o </th></tr><tr><td colspan="4">  <b>Disponibilidade</b> </td></tr><tr><td>  Falha no servidor </td><td>  <b>Sem tempo de inatividade</b> </td><td>  <b>Sem tempo de inatividade</b> </td><td>  <b>Sem tempo de inatividade</b> </td></tr><tr><td>  Falha no interruptor </td><td>  <b>Sem tempo de inatividade</b> </td><td>  <b>Sem tempo de inatividade</b> </td><td>  <b>Sem tempo de inatividade</b> </td></tr><tr><td>  Falha no armazenamento </td><td>  <b>Sem tempo de inatividade</b> </td><td>  <b>Sem tempo de inatividade</b> </td><td>  <font color="green"><b>Tempo de inatividade</b></font> </td></tr><tr><td>  Falha de todo o gabinete </td><td>  <b>Sem tempo de inatividade</b> </td><td>  <b>Sem tempo de inatividade</b> </td><td>  <font color="green"><b>Tempo de inatividade</b></font> </td></tr><tr><td colspan="4">  <b>Custo e complexidade</b> </td></tr><tr><td>  Custo da solu√ß√£o </td><td>  Baixo * </td><td>  <font color="green">Alta</font> </td><td>  <font color="green">Alta</font> </td></tr><tr><td>  Dificuldade de implanta√ß√£o </td><td>  Baixo </td><td>  <font color="green">Alta</font> </td><td>  <font color="green">Alta</font> </td></tr></tbody></table><br><p>  <i>* O AccelStor NeoSapphire ‚Ñ¢ ainda √© um array All Flash, que por defini√ß√£o n√£o custa ‚Äú3 copeques‚Äù, especialmente porque possui uma reserva de capacidade dupla.</i>  <i>No entanto, comparando o custo total da solu√ß√£o com base em solu√ß√µes similares de outros fornecedores, o custo pode ser considerado baixo.</i> </p><br><p>  A topologia para conectar servidores de aplicativos e todos os n√≥s da matriz Flash ter√° a seguinte apar√™ncia: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/5i/gb/cw/5igbcwdvm92bpabsylae4iysdra.png"></div><br><p>  Ao planejar a topologia, tamb√©m √© altamente recomend√°vel que voc√™ duplique os comutadores de gerenciamento e as interconex√µes do servidor. </p><br><p>  A seguir, falaremos sobre a conex√£o via Fibre Channel.  No caso de usar o iSCSI, tudo ser√° o mesmo, ajustado para os tipos de comutadores usados ‚Äã‚Äãe configura√ß√µes de matriz ligeiramente diferentes. </p><br><h3>  Trabalho preparat√≥rio na matriz </h3><br><div class="spoiler">  <b class="spoiler_title">Hardware e software usados</b> <div class="spoiler_text"><p>  <b>Especifica√ß√µes de servidor e switch</b> </p><br><table><tbody><tr><th>  Componentes </th><th>  Descri√ß√£o do produto </th></tr><tr><td>  Servidores Oracle Database 11g </td><td>  Dois </td></tr><tr><td>  Sistema operacional do servidor </td><td>  Oracle Linux </td></tr><tr><td>  Vers√£o do banco de dados Oracle </td><td>  11g (RAC) </td></tr><tr><td>  Processadores por servidor </td><td>  Dois CPU Intel¬Æ Xeon¬Æ de 16 n√∫cleos E5-2667 v2 a 3.30GHz </td></tr><tr><td>  Mem√≥ria f√≠sica por servidor </td><td>  128GB </td></tr><tr><td>  Rede FC </td><td>  FC de 16 Gb / s com caminhos m√∫ltiplos </td></tr><tr><td>  FC HBA </td><td>  Emulex Lpe-16002B </td></tr><tr><td>  Portas p√∫blicas de 1 GbE dedicadas para gerenciamento de cluster </td><td>  Adaptador ethernet Intel rj45 </td></tr><tr><td>  Chave FC de 16 Gb / s </td><td>  Brocade 6505 </td></tr><tr><td>  Portas privadas de 10GbE dedicadas para sincroniza√ß√£o de dados </td><td>  Intel X520 </td></tr></tbody></table><br><p>  <b>Especifica√ß√£o do AccelStor NeoSapphhire ‚Ñ¢ All Flash Array</b> </p><br><table><tbody><tr><th>  Componentes </th><th>  Descri√ß√£o do produto </th></tr><tr><td>  Sistema de armazenamento </td><td>  Modelo de alta disponibilidade NeoSapphire ‚Ñ¢: H710 </td></tr><tr><td>  Vers√£o da imagem </td><td>  4.0.1 </td></tr><tr><td>  N√∫mero total de unidades </td><td>  48. </td></tr><tr><td>  Tamanho da unidade </td><td>  1,92TB </td></tr><tr><td>  Tipo de unidade </td><td>  SSD </td></tr><tr><td>  Portas de destino FC </td><td>  Portas 16x 16Gb (8 por n√≥) </td></tr><tr><td>  Portas de gerenciamento </td><td>  O cabo Ethernet de 1 GbE se conecta aos hosts atrav√©s de um comutador Ethernet </td></tr><tr><td>  Porta de pulsa√ß√£o </td><td>  O cabo Ethernet 1GbE que conecta entre dois n√≥s de armazenamento </td></tr><tr><td>  Porta de sincroniza√ß√£o de dados </td><td>  Cabo InfiniBand de 56Gb / s </td></tr></tbody></table><br></div></div><br><p>  Antes de come√ßar a usar uma matriz, voc√™ deve inicializ√°-la.  Por padr√£o, o endere√ßo de controle dos dois n√≥s √© o mesmo (192.168.1.1).  Voc√™ precisa se conectar a eles um de cada vez, definir novos endere√ßos de gerenciamento (j√° diferentes) e configurar a sincroniza√ß√£o de hor√°rio, ap√≥s o qual as portas de gerenciamento podem ser conectadas a uma √∫nica rede.  Depois disso, os n√≥s s√£o combinados em um par de HA atribuindo sub-redes √†s conex√µes de Interlink. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/c3/kw/sp/c3kwspwqm38yl7ennakzykubswq.jpeg"></div><br><p>  Ap√≥s a conclus√£o da inicializa√ß√£o, voc√™ pode controlar a matriz a partir de qualquer n√≥. </p><br><p>  Em seguida, crie os volumes necess√°rios e publique-os para servidores de aplicativos. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/6h/4s/gf/6h4sgfinagrbbngoououu-lg1au.png"></div><br><p>  √â altamente recomend√°vel que voc√™ crie v√°rios volumes para o Oracle ASM, pois isso aumentar√° o n√∫mero de destinos para os servidores, o que acabar√° por melhorar o desempenho geral (mais sobre filas em outro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo</a> ). </p><br><div class="spoiler">  <b class="spoiler_title">Configura√ß√£o de teste</b> <div class="spoiler_text"><table><tbody><tr><th>  Nome do volume de armazenamento </th><th>  Tamanho do volume </th></tr><tr><td>  Data01 </td><td>  200GB </td></tr><tr><td>  Data02 </td><td>  200GB </td></tr><tr><td>  Data03 </td><td>  200GB </td></tr><tr><td>  Data04 </td><td>  200GB </td></tr><tr><td>  Data05 </td><td>  200GB </td></tr><tr><td>  Data06 </td><td>  200GB </td></tr><tr><td>  Data07 </td><td>  200GB </td></tr><tr><td>  Data08 </td><td>  200GB </td></tr><tr><td>  Data09 </td><td>  200GB </td></tr><tr><td>  Dados10 </td><td>  200GB </td></tr><tr><td>  Grid01 </td><td>  1GB </td></tr><tr><td>  Grid02 </td><td>  1GB </td></tr><tr><td>  Grade03 </td><td>  1GB </td></tr><tr><td>  Grade04 </td><td>  1GB </td></tr><tr><td>  Grade05 </td><td>  1GB </td></tr><tr><td>  Grid06 </td><td>  1GB </td></tr><tr><td>  Redo01 </td><td>  100GB </td></tr><tr><td>  Redo02 </td><td>  100GB </td></tr><tr><td>  Redo03 </td><td>  100GB </td></tr><tr><td>  Redo04 </td><td>  100GB </td></tr><tr><td>  Redo05 </td><td>  100GB </td></tr><tr><td>  Redo06 </td><td>  100GB </td></tr><tr><td>  Redo07 </td><td>  100GB </td></tr><tr><td>  Redo08 </td><td>  100GB </td></tr><tr><td>  Redo09 </td><td>  100GB </td></tr><tr><td>  Redo10 </td><td>  100GB </td></tr></tbody></table><br></div></div><br><h3>  Algumas explica√ß√µes sobre os modos de opera√ß√£o do array e os processos que ocorrem em situa√ß√µes de emerg√™ncia </h3><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/5m/_k/uu/5m_kuurlb-2fy52d8p1tzufcyic.png"></div><br><p>  Cada conjunto de dados do n√≥ possui um par√¢metro "n√∫mero da vers√£o".  Ap√≥s a inicializa√ß√£o, √© igual e igual a 1. Se, por algum motivo, o n√∫mero da vers√£o for diferente, sempre haver√° sincroniza√ß√£o dos dados da vers√£o mais antiga para a mais recente, ap√≥s o qual o n√∫mero ser√° alinhado para a vers√£o mais nova, ou seja,  isso significa que as c√≥pias s√£o id√™nticas.  Raz√µes pelas quais as vers√µes podem variar: </p><br><ul><li>  Reinicializa√ß√£o agendada de um dos n√≥s </li><li>  Um acidente em um dos n√≥s devido a um desligamento repentino (energia, superaquecimento, etc.). </li><li>  Conex√£o quebrada do InfiniBand com incapacidade de sincronizar </li><li>  Falha em um dos n√≥s devido √† corrup√ß√£o de dados.  Isso j√° exigir√° a cria√ß√£o de um novo grupo de alta disponibilidade e a sincroniza√ß√£o completa do conjunto de dados. </li></ul><br><p>  De qualquer forma, o n√≥ que permanece on-line aumenta seu n√∫mero de vers√£o em um, para que, ap√≥s reconectar-se ao par, sincronize seu conjunto de dados. </p><br><p>  Se a conex√£o for perdida atrav√©s do link Ethernet, o Heartbeat alternar√° temporariamente para o InfiniBand e retornar√° dentro de 10 segundos quando for restaurado. </p><br><h3>  Configura√ß√£o do host </h3><br><p>  Para garantir a toler√¢ncia a falhas e aumentar o desempenho, voc√™ deve habilitar o suporte MPIO para a matriz.  Para fazer isso, adicione linhas ao arquivo /etc/multipath.conf e recarregue o servi√ßo de caminhos m√∫ltiplos </p><br><div class="spoiler">  <b class="spoiler_title">Texto oculto</b> <div class="spoiler_text">  dispositivos { <br>  dispositivo { <br>  fornecedor "AStor" <br>  path_grouping_policy "group_by_prio" <br>  path_selector "comprimento da fila 0" <br>  path_checker "tur" <br>  apresenta "0" <br>  hardware_handler "0" <br>  prio "const" <br>  failback imediato <br>  fast_io_fail_tmo 5 <br>  dev_loss_tmo 60 <br>  user_friendly_names yes <br>  detect_prio sim <br>  rr_min_io_rq 1 <br>  no_path_retry 0 <br>  } <br>  } <br><br></div></div><br><p>  Al√©m disso, para que o ASM funcione com o MPIO atrav√©s do ASMLib, voc√™ precisa modificar o arquivo / etc / sysconfig / oracleasm e, em seguida, executar os esc√¢ndiscos /etc/init.d/oracleasm </p><br><div class="spoiler">  <b class="spoiler_title">Texto oculto</b> <div class="spoiler_text"><p>  # ORACLEASM_SCANORDER: Correspond√™ncia de padr√µes para solicitar a verifica√ß√£o de disco <br>  ORACLEASM_SCANORDER = "dm" </p><br><br><p>  # ORACLEASM_SCANEXCLUDE: padr√µes correspondentes para excluir discos da verifica√ß√£o <br>  ORACLEASM_SCANEXCLUDE = "sd" </p><br><p></p><h4>  Nota </h4><br><p>  <i>Se voc√™ n√£o quiser usar o ASMLib, poder√° usar as regras UDEV, que s√£o a base para o ASMLib.</i> </p><br><p>  <i>A partir da vers√£o 12.1.0.2 Oracle Database, a op√ß√£o est√° dispon√≠vel para instala√ß√£o como parte do software ASMFD.</i> </p><br></div></div><br><p>  Certifique-se de que os discos criados para o Oracle ASM estejam alinhados com o tamanho do bloco com o qual a matriz est√° trabalhando fisicamente (4K).  Caso contr√°rio, poder√£o ocorrer problemas de desempenho.  Portanto, voc√™ deve criar volumes com os par√¢metros apropriados: </p><br><p>  <i>parted / dev / mapper / nome do dispositivo mklabel gpt mkpart prim√°rio 2048s verifica√ß√£o 100% alinhada ideal 1</i> </p><br><h3>  Distribui√ß√£o de bancos de dados em volumes criados para nossa configura√ß√£o de teste </h3><br><table><tbody><tr><th>  Nome do volume de armazenamento </th><th>  Tamanho do volume </th><th>  Mapeamento de LUNs de volume </th><th>  Detalhe do dispositivo de volume ASM </th><th>  Tamanho da unidade de aloca√ß√£o </th></tr><tr><td>  Data01 </td><td>  200GB </td><td rowspan="26">  Mapeie todos os volumes de armazenamento para o sistema de armazenamento todas as portas de dados </td><td rowspan="10">  Redund√¢ncia: normal <br>  Nome: DGDATA <br>  Objetivo: arquivos de dados <br></td><td rowspan="10">  4MB </td></tr><tr><td>  Data02 </td><td>  200GB </td></tr><tr><td>  Data03 </td><td>  200GB </td></tr><tr><td>  Data04 </td><td>  200GB </td></tr><tr><td>  Data05 </td><td>  200GB </td></tr><tr><td>  Data06 </td><td>  200GB </td></tr><tr><td>  Data07 </td><td>  200GB </td></tr><tr><td>  Data08 </td><td>  200GB </td></tr><tr><td>  Data09 </td><td>  200GB </td></tr><tr><td>  Dados10 </td><td>  200GB </td></tr><tr><td>  <font color="#248dee">Grid01</font> </td><td>  <font color="#248dee">1GB</font> </td><td rowspan="3">  <font color="#248dee">Redund√¢ncia: normal</font> <font color="#248dee"><br></font>  <font color="#248dee">Nome: DGGRID1</font> <font color="#248dee"><br></font>  <font color="#248dee">Objetivo: Grade: CRS e vota√ß√£o</font> <br></td><td rowspan="3">  <font color="#248dee">4MB</font> </td></tr><tr><td>  <font color="#248dee">Grid02</font> </td><td>  <font color="#248dee">1GB</font> </td></tr><tr><td>  <font color="#248dee">Grade03</font> </td><td>  <font color="#248dee">1GB</font> </td></tr><tr><td>  Grade04 </td><td>  1GB </td><td rowspan="3">  Redund√¢ncia: normal <br>  Nome: DGGRID2 <br>  Objetivo: Grade: CRS e vota√ß√£o <br></td><td rowspan="3">  4MB </td></tr><tr><td>  Grade05 </td><td>  1GB </td></tr><tr><td>  Grid06 </td><td>  1GB </td></tr><tr><td>  <font color="#248dee">Redo01</font> </td><td>  <font color="#248dee">100GB</font> </td><td rowspan="5">  <font color="#248dee">Redund√¢ncia: normal</font> <font color="#248dee"><br></font>  <font color="#248dee">Nome: DGREDO1</font> <font color="#248dee"><br></font>  <font color="#248dee">Objetivo: Refazer o log do encadeamento 1</font> <font color="#248dee"><br></font> <br></td><td rowspan="5">  <font color="#248dee">4MB</font> </td></tr><tr><td>  <font color="#248dee">Redo02</font> </td><td>  <font color="#248dee">100GB</font> </td></tr><tr><td>  <font color="#248dee">Redo03</font> </td><td>  <font color="#248dee">100GB</font> </td></tr><tr><td>  <font color="#248dee">Redo04</font> </td><td>  <font color="#248dee">100GB</font> </td></tr><tr><td>  <font color="#248dee">Redo05</font> </td><td>  <font color="#248dee">100GB</font> </td></tr><tr><td>  Redo06 </td><td>  100GB </td><td rowspan="5">  Redund√¢ncia: normal <br>  Nome: DGREDO2 <br>  Objetivo: Refazer o log do encadeamento 2 <br><br></td><td rowspan="5">  4MB </td></tr><tr><td>  Redo07 </td><td>  100GB </td></tr><tr><td>  Redo08 </td><td>  100GB </td></tr><tr><td>  Redo09 </td><td>  100GB </td></tr><tr><td>  Redo10 </td><td>  100GB </td></tr></tbody></table><br><div class="spoiler">  <b class="spoiler_title">Configura√ß√µes do banco de dados</b> <div class="spoiler_text"><ul><li>  Tamanho do bloco = 8K </li><li>  Espa√ßo de troca = 16 GB </li><li>  Desativar AMM (Gerenciamento autom√°tico de mem√≥ria) </li><li>  Desativar p√°ginas enormes transparentes </li></ul><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Outras configura√ß√µes</b> <div class="spoiler_text"><p>  <u># vi /etc/sysctl.conf</u> <br>  ‚úì fs.aio-max-nr = 1048576 <br>  ‚úì fs.file-max = 6815744 <br>  ‚úì kernel.shmmax 103079215104 <br>  ‚úì kernel.shmall 31457280 <br>  ‚úì kernel.shmmn 4096 <br>  ‚úì kernel.sem = 250 32000 100 128 <br>  ‚úì net.ipv4.ip_local_port_range = 9000 65500 <br>  ‚úì net.core.rmem_default = 262144 <br>  ‚úì net.core.rmem_max = 4194304 <br>  ‚úì net.core.wmem_default = 262144 <br>  ‚úì net.core.wmem_max = 1048586 <br>  ‚úì vm.swappiness = 10 <br>  ‚úì vm.min_free_kbytes = 524288 # n√£o defina isso se voc√™ estiver usando o Linux x86 <br>  ‚úì vm.vfs_cache_pressure = 200 <br>  ‚úì vm.nr_hugepages = 57000 </p><br><br><p>  <u># vi /etc/security/limits.conf</u> <br>  ‚úì grade nproc macio 2047 <br>  ‚úì grade r√≠gida nproc 16384 <br>  ‚úì nofile macio da grade 1024 <br>  ‚úì nofile r√≠gido da grade 65536 <br>  ‚úì pilha macia de grade 10240 <br>  ‚úì pilha de disco r√≠gido 32768 <br>  ‚úì oracle soft nproc 2047 <br>  ‚úì oracle hard nproc 16384 <br>  ‚úì Oracle nofile macio 1024 <br>  ‚úì oracle hard nofile 65536 <br>  ‚úì pilha macia oracle 10240 <br>  ‚úì oracle hard stack 32768 <br>  ‚úì memlock suave 120795954 <br>  ‚úì bloqueio de mem√≥ria 120795954 <br></p><br><p>  <u>sqlplus ‚Äú/ as sysdba‚Äù</u> <br>  alterar processos do conjunto do sistema = 2000 scope = spfile; <br>  alterar o conjunto do sistema open_cursors = 2000 scope = spfile; <br>  alterar o conjunto do sistema session_cached_cursors = 300 scope = spfile; <br>  alterar conjunto de sistemas db_files = 8192 scope = spfile; <br></p><br><br></div></div><br><h3>  Teste de toler√¢ncia a falhas </h3><br><p>  Para fins de demonstra√ß√£o, o HammerDB foi usado para emular a carga OLTP.  Configura√ß√£o do HammerDB: </p><br><table><tbody><tr><td>  <b>N√∫mero de armaz√©ns</b> </td><td>  256 </td></tr><tr><td>  Total de transa√ß√µes por usu√°rio </td><td>  1000000000000 </td></tr><tr><td>  Usu√°rios virtuais </td><td>  256 </td></tr></tbody></table><br><p>  Como resultado, foi obtido o indicador de 2,1M TPM, que est√° longe do limite de desempenho do array <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">H710</a> , mas √© o "teto" para a atual configura√ß√£o de hardware dos servidores (principalmente devido aos processadores) e seu n√∫mero.  O objetivo deste teste ainda √© demonstrar a toler√¢ncia a falhas da solu√ß√£o como um todo e n√£o atingir o desempenho m√°ximo.  Portanto, simplesmente construiremos esse valor. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/3o/ds/id/3odsid2wr0ynssl4zuu8idq8dfq.png"></div><br><h3>  Teste de falha de um dos n√≥s </h3><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/ar/tf/og/artfogfilgwzy2vtxlsyvkp98vu.png"></div><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/zk/iv/xt/zkivxtazysrew4hhzjan-vujnma.png"></div><br><p>  Os hosts perderam alguns dos caminhos para a loja, continuando a trabalhar pelos demais com o segundo n√≥.  O desempenho caiu por alguns segundos devido √† reestrutura√ß√£o dos caminhos e depois voltou ao normal.  Nenhuma interrup√ß√£o de servi√ßo ocorreu. </p><br><h3>  Teste de falha do gabinete com todos os equipamentos </h3><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/mq/my/2b/mqmy2bzrge24zhnj217spj2rts4.png"></div><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/eq/nh/-8/eqnh-8pwbhyzqgdleh1tsiafkr0.png"></div><br><p>  Nesse caso, o desempenho tamb√©m caiu por alguns segundos devido √† reestrutura√ß√£o dos caminhos e retornou √† metade do valor do indicador original.  O resultado foi dividido pela metade do original devido √† exclus√£o da opera√ß√£o de um servidor de aplicativos.  A interrup√ß√£o do servi√ßo tamb√©m n√£o aconteceu. </p><br><blockquote>  Se voc√™ precisar implementar uma solu√ß√£o de recupera√ß√£o de desastre entre rack e tolerante a falhas para Oracle a um custo razo√°vel e com pouco esfor√ßo de implanta√ß√£o / administra√ß√£o, trabalhar em conjunto com a arquitetura Oracle RAC e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AccelStor Shared-Nothing</a> seria uma das melhores op√ß√µes.  Em vez do Oracle RAC, pode haver qualquer outro software que forne√ßa cluster, o mesmo DBMS ou sistemas de virtualiza√ß√£o, por exemplo.  O princ√≠pio de construir a solu√ß√£o permanecer√° o mesmo.  E a pontua√ß√£o final √© zero para RTO e RPO. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt448538/">https://habr.com/ru/post/pt448538/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt448528/index.html">Servi√ßo Wireguard VPN gratuito na AWS</a></li>
<li><a href="../pt448530/index.html">Como o Megafone dormiu em assinaturas m√≥veis</a></li>
<li><a href="../pt448532/index.html">Centro de Dados Espaciais. Resumindo o experimento</a></li>
<li><a href="../pt448534/index.html">Por que precisamos de comutadores industriais com EMC aprimorado?</a></li>
<li><a href="../pt448536/index.html">Transpar√™ncia - Panac√©ia dos Butcherts</a></li>
<li><a href="../pt448540/index.html">VMware NSX para o menor. Parte 5. Configurando o Balanceador de Carga</a></li>
<li><a href="../pt448546/index.html">Tamanhos autom√°ticos de cabe√ßalho e rodap√© do UITableView com AutoLayout</a></li>
<li><a href="../pt448548/index.html">Constru√ß√£o na arte: de Brueghel a Vasya Lozhkin</a></li>
<li><a href="../pt448550/index.html">Inaugura√ß√£o do Concurso de Reportagens no #PAYMENTSECURITY 2019</a></li>
<li><a href="../pt448552/index.html">ProLiant Series 100 - O irm√£o mais novo perdido</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
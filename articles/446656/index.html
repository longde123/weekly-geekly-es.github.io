<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöÄ ‚ô†Ô∏è ü•ö Codificaci√≥n de voz de 1600 bits / s con codificador de voz neural LPCNet ‚õîÔ∏è üë®üèª‚Äçüé® üëèüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Esta es una continuaci√≥n del primer art√≠culo sobre LPCNet . En la primera demostraci√≥n, presentamos una arquitectura que combina el procesamiento de s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Codificaci√≥n de voz de 1600 bits / s con codificador de voz neural LPCNet</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/446656/"><img src="https://habrastorage.org/getpro/habr/post_images/6ba/d56/c2e/6bad56c2eecd2e1aad4190ba40d1be74.jpg"><br><br>  Esta es una continuaci√≥n del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">primer art√≠culo sobre LPCNet</a> .  En la primera demostraci√≥n, presentamos una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arquitectura</a> que combina el procesamiento de se√±ales y el aprendizaje profundo para mejorar la efectividad de la s√≠ntesis del habla neural.  Esta vez convertiremos LPCNet en un c√≥dec de voz neural con una tasa de bits muy baja (vea el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo cient√≠fico</a> ).  Se puede utilizar en equipos actuales e incluso en tel√©fonos. <br><br>  Por primera vez, un vocoder neuronal funciona en tiempo real en el n√∫cleo de un procesador del tel√©fono y no en una GPU de alta velocidad.  La tasa de bits final de 1600 bps es aproximadamente diez veces menor que la de los c√≥decs de banda ancha ordinarios.  La calidad es mucho mejor que los vocoders existentes con una tasa de bits muy baja y comparable a los c√≥decs m√°s tradicionales que usan una tasa de bits m√°s alta. <br><a name="habracut"></a><br><h3>  Encoders y Vocoders de forma de onda </h3><br>  Hay dos grandes tipos de c√≥decs de voz: codificadores de forma de onda y codificadores de voz.  Los codificadores de forma de onda incluyen Opus, AMR / AMR-WB y todos los c√≥decs que se pueden usar para m√∫sica.  Intentan proporcionar una forma de onda decodificada lo m√°s cercana posible al original, generalmente teniendo en cuenta algunas caracter√≠sticas perceptivas.  Los vocoders, por otro lado, son en realidad sintetizadores.  El codificador extrae informaci√≥n sobre el tono y la forma de la ruta de voz, pasa esta informaci√≥n al decodificador y vuelve a sintetizar la voz.  Es casi como el reconocimiento de voz seguido de la lectura de texto en un sintetizador de voz, excepto que el codificador de texto es mucho m√°s simple / r√°pido que el reconocimiento de voz (y transmite un poco m√°s de informaci√≥n). <br><br>  Los vocodificadores han existido desde los a√±os 70, pero dado que sus decodificadores realizan s√≠ntesis de voz, no pueden ser mucho mejores que los sistemas convencionales de s√≠ntesis de voz, que hasta hace poco sonaban simplemente horribles.  Esta es la raz√≥n por la cual los vocoders se usaban t√≠picamente a velocidades inferiores a 3 kB / s.  Adem√°s, los codificadores de forma de onda simplemente proporcionan la mejor calidad.  Esto continu√≥ hasta hace poco, cuando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aparecieron los</a> sistemas de s√≠ntesis del habla neural como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">WaveNet</a> .  De repente, la s√≠ntesis comenz√≥ a sonar mucho mejor y, por supuesto, hab√≠a personas que quer√≠an <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hacer un vocoder de WaveNet</a> . <br><br><h3>  Descripci√≥n general de LPCNet </h3><br>  WaveNet produce voz de muy alta calidad, pero requiere cientos de gigaflops de potencia inform√°tica.  LPCNet redujo significativamente la complejidad computacional.  El vocoder se basa en WaveRNN, que mejora WaveNet utilizando una red neuronal recurrente (RNN) y matrices dispersas.  LPCNet mejora a√∫n m√°s WaveRNN con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">predicci√≥n lineal</a> (LPC), que funcion√≥ bien en vocoders m√°s antiguos.  Predice una muestra a partir de una combinaci√≥n lineal de muestras anteriores y, lo m√°s importante, la hace muchas veces m√°s r√°pida que una red neuronal.  Por supuesto, no es universal (de lo contrario, los vocoders de los a√±os 70 sonar√≠an genial), pero puede reducir seriamente la carga en la red neuronal.  Esto le permite utilizar una red m√°s peque√±a que WaveRNN sin sacrificar la calidad. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/652/8fc/7df/6528fc7df88256e797551173b11f5e1d.png"></div><br>  <i><font color="gray">Echemos un vistazo m√°s de cerca a LPCNet.</font></i>  <i><font color="gray">La parte amarilla de la izquierda se calcula una vez por cuadro, y su salida se usa para la frecuencia de muestreo de la red a la derecha (azul).</font></i>  <i><font color="gray">La unidad de computaci√≥n predice una muestra en el tiempo t en base a muestras anteriores y coeficientes de predicci√≥n lineal.</font></i> <br><br><h1>  Caracter√≠sticas de compresi√≥n </h1><br>  LPCNet sintetiza voz a partir de vectores de 20 caracteres por trama durante 10 ms.  De estos, 18 signos son coeficientes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cepstrales que</a> representan la forma del espectro.  Los dos restantes describen la altura: un par√°metro para el per√≠odo de tono (per√≠odo de tono) y el otro para la <i>fuerza</i> (cu√°nto se correlaciona la se√±al consigo mismo, si introduce un retraso por el tono).  Si almacena los par√°metros en forma de valores de coma flotante, toda esta informaci√≥n ocupar√° hasta 64 kbit / s durante el almacenamiento o la transmisi√≥n.  Esto es demasiado, porque incluso el c√≥dec Opus proporciona una codificaci√≥n de voz de muy alta calidad a solo 16 kbit / s (para 16 kHz mono).  Obviamente, debe aplicar una fuerte compresi√≥n aqu√≠. <br><br><h3>  Altura </h3><br>  Todos los c√≥decs dependen en gran medida del tono, pero a diferencia de los codificadores de forma de onda, donde el tono "justo" ayuda a reducir la redundancia, los codificadores de voz no tienen respaldo.  Si elige la altura incorrecta, comenzar√°n a generar un discurso que suena mal (o incluso ilegible).  Sin entrar en detalles (ver el art√≠culo cient√≠fico), el codificador LPCNet est√° luchando para no cometer un error de altura.  La b√∫squeda comienza con una b√∫squeda de <i>correlaciones de</i> tiempo en una se√±al de voz.  Vea a continuaci√≥n c√≥mo funciona una b√∫squeda t√≠pica. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3e4/024/a6a/3e4024a6aac9fcd8cd1fb8eb750918e6.gif"><br>  <i><font color="gray">El tono es el per√≠odo durante el cual se repite el tono.</font></i>  <i><font color="gray">La animaci√≥n busca el paso que corresponde a la correlaci√≥n m√°xima entre la se√±al x (n) y su copia x (nT) con un retraso.</font></i>  <i><font color="gray">El valor T con correlaci√≥n m√°xima es un paso de altura</font></i> <br><br>  Esta informaci√≥n debe codificarse con el menor n√∫mero de bits posible sin degradar demasiado el resultado.  Dado que percibimos la frecuencia por naturaleza en una escala logar√≠tmica (por ejemplo, cada octava musical dobla la frecuencia anterior), tiene sentido en la codificaci√≥n logar√≠tmica.  La altura de la se√±al de voz en la mayor√≠a de las personas (no estamos tratando de cubrir la soprano aqu√≠) est√° entre 62.5 y 500 Hz.  Con siete bits (128 valores posibles) obtenemos una resoluci√≥n de aproximadamente un cuarto de tono (la diferencia entre y antes y re es un tono). <br><br>  Entonces, ¬øcon la altura terminada?  Bueno, no tan r√°pido.  La gente no habla como robots de las pel√≠culas de los a√±os sesenta.  El tono de voz puede variar incluso dentro de un paquete de 40 milisegundos.  Debe tener esto en cuenta, dejando los bits para el par√°metro para cambiar la altura: 3 bits para codificar la diferencia de hasta 2.5 semitonos entre el comienzo y el final del paquete.  Finalmente, debe codificar la correlaci√≥n de los pasos de tono, distinguiendo entre vocales y consonantes (por ejemplo, syf).  Dos bits son suficientes para la correlaci√≥n. <br><br><h3>  Cepstrum </h3><br>  Si bien el tono contiene las caracter√≠sticas externas del habla (prosodia, emoci√≥n, acento, ...), la respuesta espectral determina <i>lo que</i> se dijo (excepto los idiomas tonales como el chino, donde el tono es importante para el significado).  Las cuerdas vocales producen aproximadamente el mismo sonido para cualquier vocal, pero la forma del tracto vocal determina qu√© sonido se hablar√°.  La ruta de voz act√∫a como un filtro, y la tarea del codificador es evaluar este filtro y pasarlo al decodificador.  Esto se puede hacer de manera efectiva si convierte el espectro a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cepstrum</a> (s√≠, este es un "espectro" con un orden de letras cambiado, estos son los tipos divertidos en el procesamiento de se√±ales digitales). <br><br>  Para una se√±al de entrada a 16 kHz, el cepstrum representa b√°sicamente un vector de 18 n√∫meros cada 10 ms, que debe comprimirse lo m√°s posible.  Dado que tenemos cuatro de esos vectores en un paquete de 40 ms y generalmente son similares entre s√≠, queremos eliminar la redundancia tanto como sea posible.  Esto se puede hacer usando vectores vecinos como predictores y transmitiendo solo la diferencia entre la predicci√≥n y el valor real.  Al mismo tiempo, no queremos depender demasiado de los paquetes anteriores si uno de ellos desaparece.  Parece que el problema ya se ha resuelto ... <br><br>  <font color="brown"><i>Si solo tienes un martillo, todo parece un clavo: Abraham Maslow.</i></font> <br><br>  Si <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">trabaj√≥</a> mucho <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">con los c√≥decs de video</a> , entonces probablemente se encontr√≥ con el concepto de B-frames.  A diferencia de los c√≥decs de video, que dividen un cuadro en muchos paquetes, nosotros, por el contrario, tenemos muchos cuadros en un paquete.  Comenzamos codificando el <i>cuadro clave</i> , es decir, el vector independiente y el <b>final del</b> paquete.  Este vector se codifica sin predicci√≥n, ocupando 37 bits: 7 para energ√≠a total (primer coeficiente cepstral) y 30 bits para otros par√°metros que usan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cuantificaci√≥n vectorial</a> (VQ).  Luego vienen los marcos B (jer√°rquicos).  De las dos palabras clave (una del paquete actual y otra del anterior), se predice un cepstrum entre ellas.  Como predictor para codificar la diferencia entre el valor real y la predicci√≥n, puede elegir entre dos cuadros clave o su valor promedio.  Usamos VQ nuevamente y codificamos este vector usando un total de 13 bits, incluida la elecci√≥n del predictor.  Ahora solo nos quedan dos vectores y muy pocos bits.  Use los √∫ltimos 3 bits para simplemente seleccionar el predictor para los vectores restantes.  Por supuesto, todo esto es mucho m√°s f√°cil de entender en la figura: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/530/395/c02/530395c02aba2079c8e82e79f98071f4.png"></div><br>  <i><font color="gray">Predicci√≥n y cuantificaci√≥n de cepstrum para el paquete k.</font></i>  <i><font color="gray">Los vectores verdes se cuantifican de forma independiente, los vectores azules se predicen y los vectores rojos usan predicci√≥n sin cuantificaci√≥n residual.</font></i>  <i><font color="gray">La predicci√≥n se muestra con flechas.</font></i> <br><br><h3>  Poniendo todo junto </h3><br>  Sumando todo lo anterior, obtenemos 64 bits por paquete de 40 milisegundos o 1600 bits por segundo.  Si desea calcular la relaci√≥n de compresi√≥n, la voz de banda ancha sin comprimir es de 256 kbps (16 kHz a 16 bits por muestra), lo que significa una relaci√≥n de compresi√≥n de 160 veces.  Por supuesto, siempre puedes jugar con cuantificadores y obtener una tasa de bits m√°s baja o m√°s alta (con un efecto correspondiente en la calidad), pero debes comenzar en alguna parte.  Aqu√≠ hay una tabla con el dise√±o donde van estos bits. <br><br><table><tbody><tr><td align="center" colspan="2">  <b>Asignaci√≥n de bits</b> </td></tr><tr><td>  Par√°metro </td><td>  Poco </td></tr><tr><td>  Pitch pitch </td><td>  6 6 </td></tr><tr><td>  Modulaci√≥n de altura </td><td>  3 </td></tr><tr><td>  Correlaci√≥n de altitud </td><td>  2 </td></tr><tr><td>  Energ√≠a </td><td>  7 7 </td></tr><tr><td>  Cepstrum VQ independiente (40 ms) </td><td>  30 </td></tr><tr><td>  Cepstrum VQ previsto (20 ms) </td><td>  13 </td></tr><tr><td>  Interpolaci√≥n de cepstrum (10 ms) </td><td>  3 </td></tr><tr><td>  Total </td><td>  64 </td></tr></tbody></table><br>  A 64 bits por paquete 40 ms, a 25 paquetes por segundo, se obtienen 1600 bps. <br><br><h1>  Implementaci√≥n </h1><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El c√≥digo fuente LPCNet</a> est√° disponible bajo la licencia BSD.  Incluye una biblioteca que simplifica el uso del c√≥dec.  Tenga en cuenta que el desarrollo no ha finalizado: tanto el formato como la API est√°n <b>obligados a</b> cambiar.  El repositorio tambi√©n tiene una aplicaci√≥n de demostraci√≥n <code>lpcnet_demo</code> en la que es f√°cil probar el c√≥dec desde la l√≠nea de comandos.  Consulte el archivo README.md para obtener instrucciones completas. <br><br>  Quien quiera profundizar, hay una opci√≥n para entrenar nuevos modelos y / o usar LPCNet como un bloque de construcci√≥n para otras aplicaciones, como la s√≠ntesis de voz (LPCNet es solo un componente del sintetizador, no realiza s√≠ntesis por s√≠ mismo). <br><br><h3>  Rendimiento </h3><br>  La s√≠ntesis del habla neural requiere muchos recursos.  En la conferencia ICASSP del a√±o pasado, Bastian Klein y sus colegas de Google / DeepMind presentaron <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un c√≥dec de 2400 bps basado en WaveNet</a> , recibiendo un flujo de bits del c√≥dec2.  Aunque suena incre√≠ble, la complejidad computacional de cientos de gigaflops significa que no se puede iniciar en tiempo real sin una GPU costosa y un esfuerzo serio. <br><br>  Por el contrario, nuestro c√≥dec de 1600 bit / s produce solo 3 gigaflops y est√° dise√±ado para funcionar en tiempo real en equipos mucho m√°s asequibles.  De hecho, se puede usar hoy en aplicaciones reales.  La optimizaci√≥n requer√≠a escribir algo de c√≥digo para los conjuntos de instrucciones AVX2 / FMA y Neon (solo c√≥digo incrustado, sin ensamblador).  Gracias a esto, ahora podemos codificar (y especialmente decodificar) el habla en tiempo real no solo en una PC, sino tambi√©n en tel√©fonos m√°s o menos modernos.  A continuaci√≥n se muestra el rendimiento en procesadores x86 y ARM. <br><br><table><tbody><tr><td colspan="4" align="center">  Rendimiento </td></tr><tr><td>  CPU </td><td>  Frecuencia </td><td>  % de un n√∫cleo </td><td>  A tiempo real </td></tr><tr><td>  AMD 2990WX (Threadripper) </td><td>  3.0 GHz * </td><td>  14% </td><td>  7.0x </td></tr><tr><td>  Intel Xeon E5-2640 v4 (Broadwell) </td><td>  2,4 GHz * </td><td>  20% </td><td>  5.0x </td></tr><tr><td>  Snapdragon 855 (Cortex-A76 en <b>Galaxy S10</b> ) </td><td>  2,82 GHz </td><td>  31% </td><td>  3.2x </td></tr><tr><td>  Snapdragon 845 (Cortex-A75 en <b>Pixel 3</b> ) </td><td>  2.5 GHz </td><td>  68% </td><td>  1.47x </td></tr><tr><td>  AMD A1100 (Cortex-A57) </td><td>  1.7 GHz </td><td>  102% </td><td>  0.98x </td></tr><tr><td>  BCM2837 (Cortex-A53 en Raspberry Pi 3) </td><td>  1,2 GHz </td><td>  310% </td><td>  0.32x </td></tr><tr><td>  * modo turbo </td><td></td><td></td><td></td></tr></tbody></table><br><br>  Los n√∫meros son bastante interesantes.  Aunque solo se muestran Broadwell y Threadripper, en la plataforma x86, los procesadores Haswell y Skylake tienen un rendimiento similar (teniendo en cuenta la frecuencia del reloj).  Sin embargo, los procesadores ARM son notablemente diferentes entre s√≠.  Incluso teniendo en cuenta la diferencia en la frecuencia, A76 es de cinco a seis veces m√°s r√°pido que A53: es bastante esperado, ya que A53 se utiliza principalmente para la eficiencia energ√©tica (por ejemplo, en sistemas big.LITTLE).  Sin embargo, LPCNet puede funcionar en tiempo real en un tel√©fono moderno, utilizando solo un n√∫cleo.  Aunque ser√≠a bueno ejecutarlo en tiempo real en el Raspberry Pi 3. Ahora esto est√° lejos, pero nada es imposible. <br><br>  En x86, el motivo de la limitaci√≥n de rendimiento es cinco veces el m√°ximo te√≥rico.  Como sabe, las operaciones de multiplicaci√≥n de matriz-vector son menos eficientes que las operaciones de matriz-matriz porque hay m√°s descargas por operaci√≥n, espec√≠ficamente, una descarga de matriz para cada operaci√≥n de FMA.  Por un lado, el rendimiento est√° relacionado con el cach√© L2, que proporciona solo 16 bits por ciclo.  Por otro lado, Intel afirma que L2 puede dar hasta 32 bits por ciclo en Broadwell y 64 bits por ciclo en Skylake. <br><br><h1>  Resultados </h1><br>  Realizamos pruebas de audio al estilo MUSHRA para comparar la calidad de la codificaci√≥n.  Condiciones de prueba: <br><br><ul><li>  <b>Muestra</b> : original (si obtiene un mejor resultado que el original, claramente hay algo mal con su prueba) <br></li><li>  <b>1600 bps LPCNet</b> : nuestra demostraci√≥n <br></li><li>  <b>LPNet sin comprimir</b> : "LPNet con 122 unidades equivalentes" del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">primer art√≠culo</a> <br></li><li>  <b>Opus 9000 bps de banda ancha</b> : velocidad de bits m√°s baja a la que Opus 1.3 codifica audio de banda ancha <br></li><li>  <b>MELP a 2400 bps</b> : un <b>codificador de</b> voz conocido con una baja velocidad de bits (similar en calidad al c√≥dec2) <br></li><li>  <b>Speex 4000 bps</b> : este vocoder de banda ancha nunca debe usarse, pero es una buena referencia para el fondo </li></ul><br>  En la primera prueba (conjunto 1), tenemos ocho fragmentos de declaraciones de dos hombres y dos mujeres.  Los archivos del primer conjunto pertenecen a la misma base de datos (es decir, las mismas condiciones de grabaci√≥n) que se us√≥ para el entrenamiento, pero estas personas espec√≠ficas fueron excluidas del conjunto de entrenamiento.  En la segunda prueba (conjunto 2), utilizamos algunos archivos de la prueba Opus (sin comprimir), grabando sonido en diferentes condiciones, para asegurarnos de que LPCNet vaya a alguna generalizaci√≥n.  En ambas pruebas, 100 participantes cada una, por lo que los errores son bastante peque√±os.  Vea los resultados a continuaci√≥n. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/dc6/e7d/cc5/dc6e7dcc5b08735cb492ad07bf7894af.svg"></div><br>  <i><font color="gray">Calidad subjetiva (MUSHRA) en dos pruebas</font></i> <br><br>  En general, LPCNet a 1600 bps se ve bien, mucho mejor que MELP a 2400 bps, y no muy por detr√°s de Opus a 9000 bps.  Al mismo tiempo, LPCNet sin comprimir es ligeramente mejor en calidad que Opus a 9000 bps.  Esto significa que es posible proporcionar una mejor calidad que Opus a velocidades de bits en el rango de 2000-6000 bps. <br><br><h3>  Escuchate a ti mismo </h3><br>  Aqu√≠ hay ejemplos de la prueba de audio: <br><br>  Mujer (set 1) <br><br><ul><li>  <a href="">Muestra</a> </li><li>  <a href="">LPCNet 1600 bps</a> </li><li>  <a href="">LPNet sin comprimir</a> </li><li>  <a href="">Opus 9000 bps</a> </li><li>  <a href="">MELP 2400 bps</a> </li><li>  <a href="">Speex 4000 bps</a> </li></ul><br>  Hombre (set 1) <br><br><ul><li>  <a href="">Muestra</a> </li><li>  <a href="">LPCNet 1600 bps</a> </li><li>  <a href="">LPNet sin comprimir</a> </li><li>  <a href="">Opus 9000 bps</a> </li><li>  <a href="">MELP 2400 bps</a> </li><li>  <a href="">Speex 4000 bps</a> </li></ul><br>  Mixto (set 2) <br><br><ul><li>  <a href="">Muestra</a> </li><li>  <a href="">LPCNet 1600 bps</a> </li><li>  <a href="">LPNet sin comprimir</a> </li><li>  <a href="">Opus 9000 bps</a> </li><li>  <a href="">MELP 2400 bps</a> </li><li>  <a href="">Speex 4000 bps</a> </li></ul><br><br><h1>  ¬øD√≥nde se puede usar esto? </h1><br>  Creemos que esta es una tecnolog√≠a genial en s√≠ misma, pero tambi√©n tiene aplicaciones pr√°cticas.  Aqu√≠ hay algunas opciones. <br><br><h3>  VoIP en pa√≠ses mal conectados </h3><br>  No todos siempre tienen una conexi√≥n de alta velocidad.  En algunos pa√≠ses, la comunicaci√≥n es muy lenta y poco confiable.  Un c√≥dec de voz de 1600 bits funciona normalmente en tales condiciones, incluso transmitiendo paquetes varias veces para mayor confiabilidad.  Por supuesto, debido a la sobrecarga de los encabezados de paquetes (40 bytes para IP + UDP + RTP), es mejor hacer paquetes m√°s grandes: 40, 80 o 120 ms. <br><br><h3>  Radioaficionado / HF </h3><br>  Durante diez a√±os, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">David Rowe</a> ha estado trabajando en la codificaci√≥n de voz para las comunicaciones de radio.  Desarroll√≥ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Codec2</a> , que transmite voz a velocidades de 700 a 3200 bps.  Durante el a√±o pasado, David y yo discutimos c√≥mo mejorar Codec2 usando s√≠ntesis neuronal, y ahora finalmente lo hacemos.  En su blog, David <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">escribi√≥</a> sobre su propia implementaci√≥n del c√≥dec basado en LPCNet para la integraci√≥n con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">FreeDV</a> . <br><br><h3>  Mayor confiabilidad en la p√©rdida de paquetes </h3><br>  La capacidad de codificar un flujo de bits de calidad decente en un peque√±o n√∫mero de bits es √∫til para proporcionar redundancia en un canal poco confiable.  Opus tiene un mecanismo de correcci√≥n de errores hacia adelante (FEC) conocido como LBRR, que codifica una trama anterior con una tasa de bits m√°s baja y la env√≠a en la trama actual.  Funciona bien, pero agrega una sobrecarga significativa.  La duplicaci√≥n de flujo de 1600 bit / s es mucho m√°s eficiente. <br><br><h1>  Planes </h1><br>  Hay muchas m√°s posibilidades para usar LPCNet.  Por ejemplo, mejorar los c√≥decs existentes (el mismo Opus).  Al igual que en otros c√≥decs, la calidad de Opus se degrada r√°pidamente a velocidades de bits muy bajas (por debajo de 8000 bps), porque el c√≥dec de forma de onda no tiene suficientes bits para coincidir con el original.  Pero la informaci√≥n de predicci√≥n lineal transmitida es suficiente para que LPCNet sintetice un discurso de sonido decente, mejor que Opus puede hacer a esta velocidad de bits.  Adem√°s, el resto de la informaci√≥n transmitida por Opus (pron√≥stico residual) ayuda a LPCNet a sintetizar un resultado a√∫n mejor.  En cierto sentido, LPCNet se puede usar como un elegante filtro posterior para mejorar la calidad de Opus (o cualquier otro c√≥dec) sin cambiar el flujo de bits (es decir, manteniendo la compatibilidad total). <br><br><h1>  Recursos Adicionales </h1><br><ol><li>  J.-M. Valin, J. Skoglund, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">vocoder neural de banda ancha de 1.6 Kbps usando LPCNet</a> , <i>enviado a Interspeech 2019</i> , arXiv: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1903.12087</a> . </li><li>  J.-M. Valin, J. Skoglund, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LPCNet: S√≠ntesis avanzada del habla neural a trav√©s de la predicci√≥n lineal</a> , <i>Proc.</i>  <i>ICASSP, 2019</i> , arXiv: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1810.11846</a> . </li><li>  A. van den Oord, S. Dileman, H. Zen, K. Simonyan, O. Vinyals, A. Graves, N. Kalkhbrenner, E. Senor, K. Kavukuglu, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">WaveNet: modelo generativo para sonido no procesado</a> , 2016. </li><li>  N. Karlhbrenner, E. Elsen, C. Simonyan, S. Nouri, N. Casagrande, E. Lockhart, F. Stimberg, A. van den Oord, S. Dileman, K. Kavukuglu, S√≠ntesis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">efectiva del sonido neural</a> , 2018. </li><li>  V.B.Klein, F.S.K. Lim, A.Lyubs, J.Skoglund, F. Stimberg, K. Wang, T.S. Walters, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">codificaci√≥n de voz de baja tasa de bits basada en Wavenet</a> , 2018 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El c√≥digo fuente de</a> LPCNet. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥dec para FreeDV basado en LPCNet de</a> David Rowe. </li><li>  √önase a la discusi√≥n sobre desarrollo en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">#opus en irc.freenode.net</a> (‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">interfaz web</a> ) </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/446656/">https://habr.com/ru/post/446656/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../446640/index.html">20 proyectos, 20 idiomas, fecha l√≠mite ayer. Parte 2</a></li>
<li><a href="../446642/index.html">Lista de verificaci√≥n para crear y publicar aplicaciones web</a></li>
<li><a href="../446644/index.html">C√≥mo ejecutar SMM en 2019: 17 diagramas de Neil Patel</a></li>
<li><a href="../446648/index.html">Desarrollo de operadores de Kubernetes con Operator Framework</a></li>
<li><a href="../446654/index.html">C√≥mo guardamos la revisi√≥n del c√≥digo</a></li>
<li><a href="../446658/index.html">Entrevista con Andrei Stankevich sobre programaci√≥n deportiva.</a></li>
<li><a href="../446660/index.html">IA, estudiante y gran premio: c√≥mo hacer aprendizaje autom√°tico en octavo grado</a></li>
<li><a href="../446662/index.html">Transacciones y mecanismos para su control.</a></li>
<li><a href="../446664/index.html">¬°SAP Forum 2019 est√° a solo 2 semanas! ¬øQu√© habr√° all√≠?</a></li>
<li><a href="../446666/index.html">Exprime al m√°ximo las calculadoras gr√°ficas: juegos en la TI-83</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩‍🌾 👽 🌊 Wie wir Nginx skaliert und die Welt gerettet haben 54 Jahre jeden Tag warten 👩🏿‍🤝‍👨🏾 💰 💇🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="„Das @ Cloudflare-Team hat gerade Änderungen vorgenommen, die unsere Netzwerkleistung erheblich verbessert haben, insbesondere bei den langsamsten Anf...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie wir Nginx skaliert und die Welt gerettet haben 54 Jahre jeden Tag warten</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/419023/"> <i>„Das @ Cloudflare-Team hat gerade Änderungen vorgenommen, die unsere Netzwerkleistung erheblich verbessert haben, insbesondere bei den langsamsten Anforderungen.</i>  <i>Wie viel schneller?</i>  <i>Wir schätzen, dass wir dem Internet etwa 54 Jahre Zeit <b>pro Tag</b> sparen, die sonst damit verbracht worden wären, auf das Laden der Websites zu warten</i> . <i>“</i>  - Matthew Prince <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tweet</a> , 28. Juni 2018 <br><br>  10 Millionen Websites, Anwendungen und APIs verwenden Cloudflare, um das Herunterladen von Inhalten für Benutzer zu beschleunigen.  In der Spitze verarbeiten wir mehr als 10 Millionen Anfragen pro Sekunde in 151 Rechenzentren.  Im Laufe der Jahre haben wir viele Änderungen an unserer Version von Nginx vorgenommen, um mit dem Wachstum fertig zu werden.  In diesem Artikel geht es um eine dieser Änderungen. <br><a name="habracut"></a><br><h1>  Wie Nginx funktioniert </h1><br>  Nginx ist eines der Programme, das Ereignisverarbeitungsschleifen verwendet, um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das C10K-Problem</a> zu lösen.  Jedes Mal, wenn ein Netzwerkereignis eintrifft (eine neue Verbindung, Anforderung oder Benachrichtigung zum Senden einer größeren Datenmenge usw.), wird Nginx aktiviert, verarbeitet das Ereignis und kehrt dann zu einem anderen Job zurück (dies kann andere Ereignisse verarbeiten).  Wenn ein Ereignis eintrifft, sind die Daten dafür bereit, sodass Sie viele gleichzeitige Anforderungen ohne Ausfallzeiten effizient verarbeiten können. <br><br><pre><code class="hljs pgsql">num_events = epoll_wait(epfd, <span class="hljs-comment"><span class="hljs-comment">/*returned=*/</span></span>events, events_len, <span class="hljs-comment"><span class="hljs-comment">/*timeout=*/</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>); // events <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> list <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> active events // handle event[<span class="hljs-number"><span class="hljs-number">0</span></span>]: incoming request <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://example.com/ // handle event[<span class="hljs-number"><span class="hljs-number">1</span></span>]: send <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> response <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://cloudflare.com/</code> </pre> <br>  So könnte beispielsweise ein Code aussehen, um Daten aus einem Dateideskriptor zu lesen: <br><br><pre> <code class="hljs pgsql">// we got a <span class="hljs-keyword"><span class="hljs-keyword">read</span></span> event <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> fd <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (buf_len &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { ssize_t n = <span class="hljs-keyword"><span class="hljs-keyword">read</span></span>(fd, buf, buf_len); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (n &lt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (errno == EWOULDBLOCK || errno == EAGAIN) { // try later <span class="hljs-keyword"><span class="hljs-keyword">when</span></span> we <span class="hljs-keyword"><span class="hljs-keyword">get</span></span> a <span class="hljs-keyword"><span class="hljs-keyword">read</span></span> event again } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (errno == EINTR) { <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> total; } buf_len -= n; buf += n; total += n; }</code> </pre> <br>  Wenn fd ein Netzwerk-Socket ist, werden bereits empfangene Bytes zurückgegeben.  Der letzte Aufruf gibt <code>EWOULDBLOCK</code> .  Dies bedeutet, dass der lokale Lesepuffer beendet wurde und Sie nicht mehr von diesem Socket lesen sollten, bis Daten angezeigt werden. <br><br><h1>  Die Festplatten-E / A unterscheidet sich vom Netzwerk </h1><br>  Wenn fd unter Linux eine reguläre Datei ist, werden <code>EWOULDBLOCK</code> und <code>EAGAIN</code> nie <code>EWOULDBLOCK</code> und der <code>EAGAIN</code> wartet immer darauf, den gesamten Puffer zu lesen, selbst wenn die Datei mit <code>O_NONBLOCK</code> geöffnet <code>O_NONBLOCK</code> .  Wie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offenen (2)</a> Handbuch geschrieben: <br><br><blockquote>  Bitte beachten Sie, dass dieses Flag nicht für reguläre Dateien und Blockgeräte gültig ist. </blockquote><br>  Mit anderen Worten, der obige Code ist im Wesentlichen auf Folgendes reduziert: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">read</span></span>(fd, buf, buf_len) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> buf_len; }</code> </pre> <br>  Wenn der Handler von der Festplatte lesen muss, blockiert er die Ereignisschleife, bis der Lesevorgang abgeschlossen ist, und nachfolgende Ereignishandler warten. <br><br>  Dies ist für die meisten Aufgaben normal, da das Lesen von einer Festplatte normalerweise recht schnell und viel vorhersehbarer ist als das Warten auf ein Paket aus dem Netzwerk.  Besonders jetzt, wo jeder eine SSD hat und alle unsere Caches auf SSDs sind.  Bei modernen SSDs eine sehr kleine Verzögerung, normalerweise in zehn Mikrosekunden.  Darüber hinaus können Sie Nginx mit mehreren Workflows ausführen, sodass ein langsamer Ereignishandler Anforderungen in anderen Prozessen nicht blockiert.  Meistens können Sie sich auf Nginx verlassen, um Anfragen schnell und effizient zu bearbeiten. <br><br><h1>  SSD-Leistung: nicht immer wie versprochen </h1><br>  Wie Sie vielleicht vermutet haben, sind diese rosigen Annahmen nicht immer wahr.  Wenn jeder Messwert immer 50 μs dauert, dauert das Lesen von 0,19 MB in Blöcken von 4 KB (und wir lesen in noch größeren Blöcken) nur 2 ms.  Tests haben jedoch gezeigt, dass die Zeit bis zum ersten Byte manchmal viel schlechter ist, insbesondere im 99. und 999. Perzentil.  Mit anderen Worten, das langsamste Auslesen von 100 (oder 1000) Messwerten dauert oft viel länger. <br><br>  Solid-State-Laufwerke sind sehr schnell, aber für ihre Komplexität bekannt.  Sie haben Computer in dieser Warteschlange und ordnen E / A neu an. Außerdem führen sie verschiedene Hintergrundaufgaben aus, z. B. Speicherbereinigung und Defragmentierung.  Von Zeit zu Zeit verlangsamen sich Anfragen merklich.  Mein Kollege <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ivan Bobrov</a> hat mehrere E / A-Benchmarks gestartet und Leseverzögerungen von bis zu 1 Sekunde registriert.  Darüber hinaus weisen einige unserer SSDs mehr solche Leistungsspitzen auf als andere.  In Zukunft werden wir diesen Indikator beim Kauf einer SSD berücksichtigen, aber jetzt müssen wir eine Lösung für vorhandene Geräte entwickeln. <br><br><h1>  Gleichmäßige Lastverteilung mit <code>SO_REUSEPORT</code> </h1><br>  Es ist schwierig, eine langsame Antwort pro 1000 Anfragen zu vermeiden, aber wir wollen wirklich nicht, dass die verbleibenden 1000 Anfragen für eine ganze Sekunde blockiert werden.  Konzeptionell kann Nginx viele Anforderungen parallel verarbeiten, startet jedoch jeweils nur einen Ereignishandler.  Also habe ich eine spezielle Metrik hinzugefügt: <br><br><pre> <code class="hljs pgsql">gettimeofday(&amp;<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>); num_events = epoll_wait(epfd, <span class="hljs-comment"><span class="hljs-comment">/*returned=*/</span></span>events, events_len, <span class="hljs-comment"><span class="hljs-comment">/*timeout=*/</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>); // events <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> list <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> active events // handle event[<span class="hljs-number"><span class="hljs-number">0</span></span>]: incoming request <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://example.com/ gettimeofday(&amp;event_start_handle, <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>); // handle event[<span class="hljs-number"><span class="hljs-number">1</span></span>]: send <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> response <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://cloudflare.com/ timersub(&amp;event_start_handle, &amp;<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>, &amp;event_loop_blocked);</code> </pre> <br>  Das 99. Perzentil (p99) <code>event_loop_blocked</code> 50% unseres TTFB überschritten.  Mit anderen Worten, die Hälfte der Zeit bei der Bearbeitung einer Anforderung ist das Ergebnis der Blockierung des Ereignisverarbeitungszyklus durch andere Anforderungen.  <code>event_loop_blocked</code> misst nur die Hälfte der Sperre (da ausstehende Aufrufe von <code>epoll_wait()</code> nicht gemessen werden), sodass das tatsächliche Verhältnis der blockierten Zeit viel höher ist. <br><br>  Auf jedem unserer Computer wird Nginx mit 15 Workflows ausgeführt, d. H. Eine langsame E / A blockiert nicht mehr als 6% der Anforderungen.  Die Ereignisse sind jedoch nicht gleichmäßig verteilt: Der Hauptmitarbeiter erhält 11% der Anfragen. <br><br>  <code>SO_REUSEPORT</code> kann das Problem der ungleichmäßigen Verteilung lösen.  Marek Maikovsky hat zuvor über den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nachteil</a> dieses Ansatzes im Zusammenhang mit anderen Nginx-Instanzen geschrieben, aber hier können Sie ihn größtenteils ignorieren: Upstream-Cache-Verbindungen sind dauerhaft, sodass Sie eine leichte Erhöhung der Verzögerung beim Öffnen der Verbindung vernachlässigen können.  Diese Konfigurationsänderung allein mit der Aktivierung von <code>SO_REUSEPORT</code> verbesserte den Peak p99 um 33%. <br><br><h1>  Read () in einen Thread-Pool verschieben: keine Silberkugel </h1><br>  Die Lösung besteht darin, read () nicht zu blockieren.  Eigentlich ist diese Funktion <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in normalem Nginx implementiert</a> !  Bei Verwendung der folgenden Konfiguration werden read () und write () im Thread-Pool ausgeführt und blockieren die Ereignisschleife nicht: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">aio</span></span> threads; <span class="hljs-attribute"><span class="hljs-attribute">aio_write</span></span> <span class="hljs-literal"><span class="hljs-literal">on</span></span>;</code> </pre> <br>  Wir haben diese Konfiguration jedoch getestet und anstatt die Antwortzeit um das 33-fache zu verbessern, haben wir nur eine kleine Änderung von p99 festgestellt. Der Unterschied liegt innerhalb der Fehlergrenze.  Das Ergebnis war sehr entmutigend, daher haben wir diese Option vorübergehend verschoben. <br><br>  Es gibt mehrere Gründe, warum wir keine signifikanten Verbesserungen hatten, wie die Nginx-Entwickler.  Im Test verwendeten sie 200 gleichzeitige Verbindungen, um Dateien mit 4 MB an die Festplatte anzufordern.  Winchester haben eine viel höhere E / A-Latenz, sodass die Optimierung einen größeren Effekt hat. <br><br>  Darüber hinaus sind wir hauptsächlich besorgt über die Leistung von p99 (und p999).  Die Optimierung der durchschnittlichen Verzögerung löst nicht unbedingt das Problem der Spitzenemission. <br><br>  Schließlich sind in unserer Umgebung typische Dateigrößen viel kleiner.  90% unserer Cache-Treffer sind weniger als 60 KB groß.  Je kleiner die Dateien sind, desto weniger Fälle von Blockierung (normalerweise lesen wir die gesamte Datei in zwei Lesevorgängen). <br><br>  Schauen wir uns die Festplatten-E / A an, wenn sie im Cache angezeigt werden: <br><br><pre> <code class="hljs ruby">/<span class="hljs-regexp"><span class="hljs-regexp">/     https:/</span></span><span class="hljs-regexp"><span class="hljs-regexp">/example.com    0xCAFEBEEF fd = open("/cache</span></span><span class="hljs-regexp"><span class="hljs-regexp">/prefix/dir</span></span><span class="hljs-regexp"><span class="hljs-regexp">/EF/</span></span>BE/CAFEBEEF<span class="hljs-string"><span class="hljs-string">", O_RDONLY); //    32    //    ,  "</span></span>aio threads<span class="hljs-string"><span class="hljs-string">"  read(fd, buf, 32*1024);</span></span></code> </pre> <br>  32K werden nicht immer gelesen.  Wenn die Header klein sind, müssen Sie nur 4 KB lesen (wir verwenden E / A nicht direkt, daher rundet der Kernel auf 4 KB).  <code>open()</code> scheint harmlos zu sein, benötigt aber tatsächlich Ressourcen.  Der Kernel sollte mindestens prüfen, ob die Datei vorhanden ist und ob der aufrufende Prozess die Berechtigung zum Öffnen hat.  Er muss den Inode für <code>/cache/prefix/dir/EF/BE/CAFEBEEF</code> , und dafür muss er in <code>/cache/prefix/dir/EF/BE/</code> nach <code>CAFEBEEF</code> suchen.  Kurz gesagt, im schlimmsten Fall führt der Kernel diese Suche durch: <br><br><pre> <code class="hljs pgsql">/<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span> /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF/BE /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF/BE/CAFEBEEF</code> </pre> <br>  Dies sind 6 separate Lesevorgänge, die <code>open()</code> erzeugt, verglichen mit 1 <code>read()</code> !  Glücklicherweise fällt die Suche in den meisten Fällen in den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dentry-Cache</a> und erreicht die SSD nicht.  Es ist jedoch klar, dass die Verarbeitung von <code>read()</code> in einem Thread-Pool nur die Hälfte des Bildes ausmacht. <br><br><h1>  Schlussakkord: nicht blockierendes open () in Thread-Pools </h1><br>  Daher haben wir eine Änderung an Nginx vorgenommen, sodass <code>open()</code> hauptsächlich im Thread-Pool ausgeführt wird und die Ereignisschleife nicht blockiert.  Und hier ist das Ergebnis von nicht blockierendem open () und read () gleichzeitig: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d70/b1a/84b/d70b1a84b46934921ffd5a1fd7e7182a.png"><br><br>  Am 26. Juni haben wir Änderungen an den 5 am stärksten frequentierten Rechenzentren und am nächsten Tag an allen anderen 146 Rechenzentren auf der ganzen Welt vorgenommen.  Der Gesamtpeak p99 TTFB nahm um das 6-fache ab.  Wenn wir die Zeit von 8 Millionen Anfragen pro Sekunde zusammenfassen, sparen wir dem Internet 54 Tage Wartezeit pro Tag. <br><br>  Unsere Veranstaltungsreihe hat die Schlösser noch nicht vollständig beseitigt.  Insbesondere tritt das Blockieren immer noch beim ersten <code>open(O_CREAT)</code> der Datei (sowohl <code>open(O_CREAT)</code> als auch beim <code>rename()</code> ) oder beim Aktualisieren der <code>open(O_CREAT)</code> .  Solche Fälle sind jedoch im Vergleich zu Cache-Zugriffen selten.  In Zukunft werden wir die Möglichkeit in Betracht ziehen, diese Elemente außerhalb der Ereignisverarbeitungsschleife zu verschieben, um den Verzögerungsfaktor p99 weiter zu verbessern. <br><br><h1>  Fazit </h1><br>  Nginx ist eine leistungsstarke Plattform, aber die Skalierung extrem hoher Linux-E / A-Lasten kann eine entmutigende Aufgabe sein.  Standard Nginx entlädt das Lesen in separaten Threads, aber auf unserer Skala müssen wir oft noch einen Schritt weiter gehen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de419023/">https://habr.com/ru/post/de419023/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de419011/index.html">Jinja2 in der C ++ - Welt, Teil zwei. Rendern</a></li>
<li><a href="../de419013/index.html">Trichterbasierte Zuordnung für SaaS-B2B-Unternehmen - da wir den Wert aller Marketingbemühungen berücksichtigt haben</a></li>
<li><a href="../de419017/index.html">Was ist neu in ConstraintLayout 1.1?</a></li>
<li><a href="../de419019/index.html">AlterEgo: Ein Gerät, das (einige) Gedanken lesen kann</a></li>
<li><a href="../de419021/index.html">Die wichtigsten Druckarten und ihre Funktionen</a></li>
<li><a href="../de419025/index.html">@ Pythonetc-Zusammenstellung, Juli 2018</a></li>
<li><a href="../de419027/index.html">Informationssicherheit bei bargeldlosen Bankzahlungen. Teil 6 - Analyse der Bankenkriminalität</a></li>
<li><a href="../de419029/index.html">Fortnite ist zu einem sozialen Phänomen geworden. Eltern stellen zunehmend Trainer für ihre Kinder ein und spielen mit ihnen</a></li>
<li><a href="../de419033/index.html">Ein kleiner Hinweis zum Thema Ausführen von vue.js im kubernetes-Cluster</a></li>
<li><a href="../de419035/index.html">Buch „Head First Agile. Flexibles Projektmanagement “</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
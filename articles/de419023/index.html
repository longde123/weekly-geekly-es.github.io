<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüåæ üëΩ üåä Wie wir Nginx skaliert und die Welt gerettet haben 54 Jahre jeden Tag warten üë©üèø‚Äçü§ù‚Äçüë®üèæ üí∞ üíáüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="‚ÄûDas @ Cloudflare-Team hat gerade √Ñnderungen vorgenommen, die unsere Netzwerkleistung erheblich verbessert haben, insbesondere bei den langsamsten Anf...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie wir Nginx skaliert und die Welt gerettet haben 54 Jahre jeden Tag warten</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/419023/"> <i>‚ÄûDas @ Cloudflare-Team hat gerade √Ñnderungen vorgenommen, die unsere Netzwerkleistung erheblich verbessert haben, insbesondere bei den langsamsten Anforderungen.</i>  <i>Wie viel schneller?</i>  <i>Wir sch√§tzen, dass wir dem Internet etwa 54 Jahre Zeit <b>pro Tag</b> sparen, die sonst damit verbracht worden w√§ren, auf das Laden der Websites zu warten</i> . <i>‚Äú</i>  - Matthew Prince <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tweet</a> , 28. Juni 2018 <br><br>  10 Millionen Websites, Anwendungen und APIs verwenden Cloudflare, um das Herunterladen von Inhalten f√ºr Benutzer zu beschleunigen.  In der Spitze verarbeiten wir mehr als 10 Millionen Anfragen pro Sekunde in 151 Rechenzentren.  Im Laufe der Jahre haben wir viele √Ñnderungen an unserer Version von Nginx vorgenommen, um mit dem Wachstum fertig zu werden.  In diesem Artikel geht es um eine dieser √Ñnderungen. <br><a name="habracut"></a><br><h1>  Wie Nginx funktioniert </h1><br>  Nginx ist eines der Programme, das Ereignisverarbeitungsschleifen verwendet, um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das C10K-Problem</a> zu l√∂sen.  Jedes Mal, wenn ein Netzwerkereignis eintrifft (eine neue Verbindung, Anforderung oder Benachrichtigung zum Senden einer gr√∂√üeren Datenmenge usw.), wird Nginx aktiviert, verarbeitet das Ereignis und kehrt dann zu einem anderen Job zur√ºck (dies kann andere Ereignisse verarbeiten).  Wenn ein Ereignis eintrifft, sind die Daten daf√ºr bereit, sodass Sie viele gleichzeitige Anforderungen ohne Ausfallzeiten effizient verarbeiten k√∂nnen. <br><br><pre><code class="hljs pgsql">num_events = epoll_wait(epfd, <span class="hljs-comment"><span class="hljs-comment">/*returned=*/</span></span>events, events_len, <span class="hljs-comment"><span class="hljs-comment">/*timeout=*/</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>); // events <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> list <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> active events // handle event[<span class="hljs-number"><span class="hljs-number">0</span></span>]: incoming request <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://example.com/ // handle event[<span class="hljs-number"><span class="hljs-number">1</span></span>]: send <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> response <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://cloudflare.com/</code> </pre> <br>  So k√∂nnte beispielsweise ein Code aussehen, um Daten aus einem Dateideskriptor zu lesen: <br><br><pre> <code class="hljs pgsql">// we got a <span class="hljs-keyword"><span class="hljs-keyword">read</span></span> event <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> fd <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (buf_len &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { ssize_t n = <span class="hljs-keyword"><span class="hljs-keyword">read</span></span>(fd, buf, buf_len); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (n &lt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (errno == EWOULDBLOCK || errno == EAGAIN) { // try later <span class="hljs-keyword"><span class="hljs-keyword">when</span></span> we <span class="hljs-keyword"><span class="hljs-keyword">get</span></span> a <span class="hljs-keyword"><span class="hljs-keyword">read</span></span> event again } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (errno == EINTR) { <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> total; } buf_len -= n; buf += n; total += n; }</code> </pre> <br>  Wenn fd ein Netzwerk-Socket ist, werden bereits empfangene Bytes zur√ºckgegeben.  Der letzte Aufruf gibt <code>EWOULDBLOCK</code> .  Dies bedeutet, dass der lokale Lesepuffer beendet wurde und Sie nicht mehr von diesem Socket lesen sollten, bis Daten angezeigt werden. <br><br><h1>  Die Festplatten-E / A unterscheidet sich vom Netzwerk </h1><br>  Wenn fd unter Linux eine regul√§re Datei ist, werden <code>EWOULDBLOCK</code> und <code>EAGAIN</code> nie <code>EWOULDBLOCK</code> und der <code>EAGAIN</code> wartet immer darauf, den gesamten Puffer zu lesen, selbst wenn die Datei mit <code>O_NONBLOCK</code> ge√∂ffnet <code>O_NONBLOCK</code> .  Wie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offenen (2)</a> Handbuch geschrieben: <br><br><blockquote>  Bitte beachten Sie, dass dieses Flag nicht f√ºr regul√§re Dateien und Blockger√§te g√ºltig ist. </blockquote><br>  Mit anderen Worten, der obige Code ist im Wesentlichen auf Folgendes reduziert: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">read</span></span>(fd, buf, buf_len) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> buf_len; }</code> </pre> <br>  Wenn der Handler von der Festplatte lesen muss, blockiert er die Ereignisschleife, bis der Lesevorgang abgeschlossen ist, und nachfolgende Ereignishandler warten. <br><br>  Dies ist f√ºr die meisten Aufgaben normal, da das Lesen von einer Festplatte normalerweise recht schnell und viel vorhersehbarer ist als das Warten auf ein Paket aus dem Netzwerk.  Besonders jetzt, wo jeder eine SSD hat und alle unsere Caches auf SSDs sind.  Bei modernen SSDs eine sehr kleine Verz√∂gerung, normalerweise in zehn Mikrosekunden.  Dar√ºber hinaus k√∂nnen Sie Nginx mit mehreren Workflows ausf√ºhren, sodass ein langsamer Ereignishandler Anforderungen in anderen Prozessen nicht blockiert.  Meistens k√∂nnen Sie sich auf Nginx verlassen, um Anfragen schnell und effizient zu bearbeiten. <br><br><h1>  SSD-Leistung: nicht immer wie versprochen </h1><br>  Wie Sie vielleicht vermutet haben, sind diese rosigen Annahmen nicht immer wahr.  Wenn jeder Messwert immer 50 Œºs dauert, dauert das Lesen von 0,19 MB in Bl√∂cken von 4 KB (und wir lesen in noch gr√∂√üeren Bl√∂cken) nur 2 ms.  Tests haben jedoch gezeigt, dass die Zeit bis zum ersten Byte manchmal viel schlechter ist, insbesondere im 99. und 999. Perzentil.  Mit anderen Worten, das langsamste Auslesen von 100 (oder 1000) Messwerten dauert oft viel l√§nger. <br><br>  Solid-State-Laufwerke sind sehr schnell, aber f√ºr ihre Komplexit√§t bekannt.  Sie haben Computer in dieser Warteschlange und ordnen E / A neu an. Au√üerdem f√ºhren sie verschiedene Hintergrundaufgaben aus, z. B. Speicherbereinigung und Defragmentierung.  Von Zeit zu Zeit verlangsamen sich Anfragen merklich.  Mein Kollege <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ivan Bobrov</a> hat mehrere E / A-Benchmarks gestartet und Leseverz√∂gerungen von bis zu 1 Sekunde registriert.  Dar√ºber hinaus weisen einige unserer SSDs mehr solche Leistungsspitzen auf als andere.  In Zukunft werden wir diesen Indikator beim Kauf einer SSD ber√ºcksichtigen, aber jetzt m√ºssen wir eine L√∂sung f√ºr vorhandene Ger√§te entwickeln. <br><br><h1>  Gleichm√§√üige Lastverteilung mit <code>SO_REUSEPORT</code> </h1><br>  Es ist schwierig, eine langsame Antwort pro 1000 Anfragen zu vermeiden, aber wir wollen wirklich nicht, dass die verbleibenden 1000 Anfragen f√ºr eine ganze Sekunde blockiert werden.  Konzeptionell kann Nginx viele Anforderungen parallel verarbeiten, startet jedoch jeweils nur einen Ereignishandler.  Also habe ich eine spezielle Metrik hinzugef√ºgt: <br><br><pre> <code class="hljs pgsql">gettimeofday(&amp;<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>); num_events = epoll_wait(epfd, <span class="hljs-comment"><span class="hljs-comment">/*returned=*/</span></span>events, events_len, <span class="hljs-comment"><span class="hljs-comment">/*timeout=*/</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>); // events <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> list <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> active events // handle event[<span class="hljs-number"><span class="hljs-number">0</span></span>]: incoming request <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://example.com/ gettimeofday(&amp;event_start_handle, <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>); // handle event[<span class="hljs-number"><span class="hljs-number">1</span></span>]: send <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> response <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://cloudflare.com/ timersub(&amp;event_start_handle, &amp;<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>, &amp;event_loop_blocked);</code> </pre> <br>  Das 99. Perzentil (p99) <code>event_loop_blocked</code> 50% unseres TTFB √ºberschritten.  Mit anderen Worten, die H√§lfte der Zeit bei der Bearbeitung einer Anforderung ist das Ergebnis der Blockierung des Ereignisverarbeitungszyklus durch andere Anforderungen.  <code>event_loop_blocked</code> misst nur die H√§lfte der Sperre (da ausstehende Aufrufe von <code>epoll_wait()</code> nicht gemessen werden), sodass das tats√§chliche Verh√§ltnis der blockierten Zeit viel h√∂her ist. <br><br>  Auf jedem unserer Computer wird Nginx mit 15 Workflows ausgef√ºhrt, d. H. Eine langsame E / A blockiert nicht mehr als 6% der Anforderungen.  Die Ereignisse sind jedoch nicht gleichm√§√üig verteilt: Der Hauptmitarbeiter erh√§lt 11% der Anfragen. <br><br>  <code>SO_REUSEPORT</code> kann das Problem der ungleichm√§√üigen Verteilung l√∂sen.  Marek Maikovsky hat zuvor √ºber den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nachteil</a> dieses Ansatzes im Zusammenhang mit anderen Nginx-Instanzen geschrieben, aber hier k√∂nnen Sie ihn gr√∂√ütenteils ignorieren: Upstream-Cache-Verbindungen sind dauerhaft, sodass Sie eine leichte Erh√∂hung der Verz√∂gerung beim √ñffnen der Verbindung vernachl√§ssigen k√∂nnen.  Diese Konfigurations√§nderung allein mit der Aktivierung von <code>SO_REUSEPORT</code> verbesserte den Peak p99 um 33%. <br><br><h1>  Read () in einen Thread-Pool verschieben: keine Silberkugel </h1><br>  Die L√∂sung besteht darin, read () nicht zu blockieren.  Eigentlich ist diese Funktion <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in normalem Nginx implementiert</a> !  Bei Verwendung der folgenden Konfiguration werden read () und write () im Thread-Pool ausgef√ºhrt und blockieren die Ereignisschleife nicht: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">aio</span></span> threads; <span class="hljs-attribute"><span class="hljs-attribute">aio_write</span></span> <span class="hljs-literal"><span class="hljs-literal">on</span></span>;</code> </pre> <br>  Wir haben diese Konfiguration jedoch getestet und anstatt die Antwortzeit um das 33-fache zu verbessern, haben wir nur eine kleine √Ñnderung von p99 festgestellt. Der Unterschied liegt innerhalb der Fehlergrenze.  Das Ergebnis war sehr entmutigend, daher haben wir diese Option vor√ºbergehend verschoben. <br><br>  Es gibt mehrere Gr√ºnde, warum wir keine signifikanten Verbesserungen hatten, wie die Nginx-Entwickler.  Im Test verwendeten sie 200 gleichzeitige Verbindungen, um Dateien mit 4 MB an die Festplatte anzufordern.  Winchester haben eine viel h√∂here E / A-Latenz, sodass die Optimierung einen gr√∂√üeren Effekt hat. <br><br>  Dar√ºber hinaus sind wir haupts√§chlich besorgt √ºber die Leistung von p99 (und p999).  Die Optimierung der durchschnittlichen Verz√∂gerung l√∂st nicht unbedingt das Problem der Spitzenemission. <br><br>  Schlie√ülich sind in unserer Umgebung typische Dateigr√∂√üen viel kleiner.  90% unserer Cache-Treffer sind weniger als 60 KB gro√ü.  Je kleiner die Dateien sind, desto weniger F√§lle von Blockierung (normalerweise lesen wir die gesamte Datei in zwei Lesevorg√§ngen). <br><br>  Schauen wir uns die Festplatten-E / A an, wenn sie im Cache angezeigt werden: <br><br><pre> <code class="hljs ruby">/<span class="hljs-regexp"><span class="hljs-regexp">/     https:/</span></span><span class="hljs-regexp"><span class="hljs-regexp">/example.com    0xCAFEBEEF fd = open("/cache</span></span><span class="hljs-regexp"><span class="hljs-regexp">/prefix/dir</span></span><span class="hljs-regexp"><span class="hljs-regexp">/EF/</span></span>BE/CAFEBEEF<span class="hljs-string"><span class="hljs-string">", O_RDONLY); //    32    //    ,  "</span></span>aio threads<span class="hljs-string"><span class="hljs-string">"  read(fd, buf, 32*1024);</span></span></code> </pre> <br>  32K werden nicht immer gelesen.  Wenn die Header klein sind, m√ºssen Sie nur 4 KB lesen (wir verwenden E / A nicht direkt, daher rundet der Kernel auf 4 KB).  <code>open()</code> scheint harmlos zu sein, ben√∂tigt aber tats√§chlich Ressourcen.  Der Kernel sollte mindestens pr√ºfen, ob die Datei vorhanden ist und ob der aufrufende Prozess die Berechtigung zum √ñffnen hat.  Er muss den Inode f√ºr <code>/cache/prefix/dir/EF/BE/CAFEBEEF</code> , und daf√ºr muss er in <code>/cache/prefix/dir/EF/BE/</code> nach <code>CAFEBEEF</code> suchen.  Kurz gesagt, im schlimmsten Fall f√ºhrt der Kernel diese Suche durch: <br><br><pre> <code class="hljs pgsql">/<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span> /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF/BE /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF/BE/CAFEBEEF</code> </pre> <br>  Dies sind 6 separate Lesevorg√§nge, die <code>open()</code> erzeugt, verglichen mit 1 <code>read()</code> !  Gl√ºcklicherweise f√§llt die Suche in den meisten F√§llen in den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dentry-Cache</a> und erreicht die SSD nicht.  Es ist jedoch klar, dass die Verarbeitung von <code>read()</code> in einem Thread-Pool nur die H√§lfte des Bildes ausmacht. <br><br><h1>  Schlussakkord: nicht blockierendes open () in Thread-Pools </h1><br>  Daher haben wir eine √Ñnderung an Nginx vorgenommen, sodass <code>open()</code> haupts√§chlich im Thread-Pool ausgef√ºhrt wird und die Ereignisschleife nicht blockiert.  Und hier ist das Ergebnis von nicht blockierendem open () und read () gleichzeitig: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d70/b1a/84b/d70b1a84b46934921ffd5a1fd7e7182a.png"><br><br>  Am 26. Juni haben wir √Ñnderungen an den 5 am st√§rksten frequentierten Rechenzentren und am n√§chsten Tag an allen anderen 146 Rechenzentren auf der ganzen Welt vorgenommen.  Der Gesamtpeak p99 TTFB nahm um das 6-fache ab.  Wenn wir die Zeit von 8 Millionen Anfragen pro Sekunde zusammenfassen, sparen wir dem Internet 54 Tage Wartezeit pro Tag. <br><br>  Unsere Veranstaltungsreihe hat die Schl√∂sser noch nicht vollst√§ndig beseitigt.  Insbesondere tritt das Blockieren immer noch beim ersten <code>open(O_CREAT)</code> der Datei (sowohl <code>open(O_CREAT)</code> als auch beim <code>rename()</code> ) oder beim Aktualisieren der <code>open(O_CREAT)</code> .  Solche F√§lle sind jedoch im Vergleich zu Cache-Zugriffen selten.  In Zukunft werden wir die M√∂glichkeit in Betracht ziehen, diese Elemente au√üerhalb der Ereignisverarbeitungsschleife zu verschieben, um den Verz√∂gerungsfaktor p99 weiter zu verbessern. <br><br><h1>  Fazit </h1><br>  Nginx ist eine leistungsstarke Plattform, aber die Skalierung extrem hoher Linux-E / A-Lasten kann eine entmutigende Aufgabe sein.  Standard Nginx entl√§dt das Lesen in separaten Threads, aber auf unserer Skala m√ºssen wir oft noch einen Schritt weiter gehen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de419023/">https://habr.com/ru/post/de419023/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de419011/index.html">Jinja2 in der C ++ - Welt, Teil zwei. Rendern</a></li>
<li><a href="../de419013/index.html">Trichterbasierte Zuordnung f√ºr SaaS-B2B-Unternehmen - da wir den Wert aller Marketingbem√ºhungen ber√ºcksichtigt haben</a></li>
<li><a href="../de419017/index.html">Was ist neu in ConstraintLayout 1.1?</a></li>
<li><a href="../de419019/index.html">AlterEgo: Ein Ger√§t, das (einige) Gedanken lesen kann</a></li>
<li><a href="../de419021/index.html">Die wichtigsten Druckarten und ihre Funktionen</a></li>
<li><a href="../de419025/index.html">@ Pythonetc-Zusammenstellung, Juli 2018</a></li>
<li><a href="../de419027/index.html">Informationssicherheit bei bargeldlosen Bankzahlungen. Teil 6 - Analyse der Bankenkriminalit√§t</a></li>
<li><a href="../de419029/index.html">Fortnite ist zu einem sozialen Ph√§nomen geworden. Eltern stellen zunehmend Trainer f√ºr ihre Kinder ein und spielen mit ihnen</a></li>
<li><a href="../de419033/index.html">Ein kleiner Hinweis zum Thema Ausf√ºhren von vue.js im kubernetes-Cluster</a></li>
<li><a href="../de419035/index.html">Buch ‚ÄûHead First Agile. Flexibles Projektmanagement ‚Äú</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
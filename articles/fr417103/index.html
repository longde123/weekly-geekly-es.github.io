<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙌🏻 👨🏽 👨🏿‍🎓 Spark SQL. Un peu sur l'optimiseur de requêtes 👩🏾‍🤝‍👨🏻 💾 🗓️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour à tous. En guise d'introduction, je veux vous dire comment je suis arrivé à une telle vie. 



 Avant de rencontrer Big Data et Spark, en part...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Spark SQL. Un peu sur l'optimiseur de requêtes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/neoflex/blog/417103/"><p>  Bonjour à tous.  En guise d'introduction, je veux vous dire comment je suis arrivé à une telle vie. <br></p><br><p>  Avant de rencontrer Big Data et Spark, en particulier, j'avais beaucoup et souvent à optimiser les requêtes SQL, d'abord pour MSSQL, puis pour Oracle, et maintenant je suis tombé sur SparkSQL. <br></p><br><p>  Et s'il existe déjà de nombreux bons livres pour le SGBD qui décrivent la méthodologie et les «stylos» que vous pouvez tourner pour obtenir le plan de requête optimal, alors je n'ai pas vu de tels livres pour Spark.  Je suis tombé sur plus d'articles et d'ensembles de pratiques, plus liés à l'utilisation de l'API RDD / Dataset qu'à du SQL pur.  Pour moi, l'un des ouvrages de référence sur l'optimisation SQL est le livre de J. Lewis, Oracle.  Bases de l'optimisation des coûts. "  J'ai cherché quelque chose de similaire en profondeur d'étude.  Pourquoi l'objet de la recherche était-il spécifiquement SparkSQL, et non l'API sous-jacente?  L'intérêt a ensuite été provoqué par les caractéristiques du projet sur lequel je travaille. <br></p><br><img src="https://habrastorage.org/webt/po/1f/un/po1fun6vgbktou6lykepwmrncci.jpeg"><br><a name="habracut"></a><br><p>  Pour l'un de nos clients, notre société développe un entrepôt de données, dont une couche détaillée et une partie des vitrines sont dans le cluster Hadoop, et les vitrines finales sont dans Oracle.  Ce projet implique une couche de conversion de données étendue, qui est implémentée sur Spark.  Pour accélérer le développement et la connectivité des développeurs ETL qui ne connaissent pas les subtilités des technologies Big Data, mais qui connaissent les outils SQL et ETL, un outil a été développé qui rappelle idéologiquement d'autres outils ETL, par exemple Informatica, et vous permet de concevoir visuellement des processus ETL avec la génération suivante code pour Spark.  En raison de la complexité des algorithmes et du grand nombre de transformations, les développeurs utilisent principalement des requêtes SparkSQL. <br></p><br><p> Et c'est là que commence l'histoire, car j'ai dû répondre à un grand nombre de questions du formulaire «Pourquoi la demande ne fonctionne-t-elle pas / fonctionne-t-elle lentement / fonctionne-t-elle différemment d'Oracle?».  Celui-ci s'est avéré être la partie la plus intéressante pour moi: "Pourquoi ça marche lentement?".  De plus, contrairement au SGBD avec lequel j'ai travaillé auparavant, vous pouvez entrer dans le code source et obtenir la réponse à vos questions. <br></p><cut text="    "></cut><br><h2>  Limitations et hypothèses </h2><br><p>  Spark 2.3.0 est utilisé pour exécuter des exemples et analyser le code source. <br>  Il est supposé que le lecteur connaît l'architecture Spark et les principes généraux de l'optimiseur de requêtes pour l'un des SGBD.  Au minimum, l'expression «plan de requête» ne devrait certainement pas être surprenante. <br></p><br><p>  De plus, cet article essaie de ne pas devenir une traduction du code de l'optimiseur Spark en russe, donc pour les choses très intéressantes du point de vue de l'optimiseur, mais qui peuvent être lues dans le code source, elles seront simplement brièvement mentionnées ici avec des liens vers les classes correspondantes. <br></p><br><h2>  Passez à l'étude </h2><br><p>  Commençons par une petite requête pour explorer les étapes de base à travers lesquelles elle passe de l'analyse à l'exécution. <br></p><br><pre><code class="scala hljs">scala&gt; spark.read.orc(<span class="hljs-string"><span class="hljs-string">"/user/test/balance"</span></span>).createOrReplaceTempView(<span class="hljs-string"><span class="hljs-string">"bal"</span></span>) scala&gt; spark.read.orc(<span class="hljs-string"><span class="hljs-string">"/user/test/customer"</span></span>).createOrReplaceTempView(<span class="hljs-string"><span class="hljs-string">"cust"</span></span>) scala&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> df = spark.sql(<span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">" | select bal.account_rk, cust.full_name | from bal | join cust | on bal.party_rk = cust.party_rk | and bal.actual_date = cust.actual_date | where bal.actual_date = cast('2017-12-31' as date) | "</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>) df: org.apache.spark.sql.<span class="hljs-type"><span class="hljs-type">DataFrame</span></span> = [account_rk: decimal(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), full_name: string] scala&gt; df.explain(<span class="hljs-literal"><span class="hljs-literal">true</span></span>)</code> </pre> <br><p>  Le module principal chargé d'analyser SQL et d'optimiser le plan d'exécution des requêtes est Spark Catalyst. <br></p><br><p>  La sortie développée dans la description du plan de demande (df.explain (true)) vous permet de suivre toutes les étapes de la demande: <br></p><br><ul><li>  Plan logique analysé - obtenez après l'analyse SQL.  À ce stade, seule l'exactitude syntaxique de la demande est vérifiée. </li></ul><br><pre> <code class="hljs rust">== Parsed Logical Plan == <span class="hljs-symbol"><span class="hljs-symbol">'Project</span></span> [<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.account_rk, <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.full_name] +- <span class="hljs-symbol"><span class="hljs-symbol">'Filter</span></span> (<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.actual_date = cast(<span class="hljs-number"><span class="hljs-number">2017</span></span>-<span class="hljs-number"><span class="hljs-number">12</span></span>-<span class="hljs-number"><span class="hljs-number">31</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> date)) +- <span class="hljs-symbol"><span class="hljs-symbol">'Join</span></span> Inner, ((<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.party_rk = <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.party_rk) &amp;&amp; (<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.actual_date = <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.actual_date)) :- <span class="hljs-symbol"><span class="hljs-symbol">'UnresolvedRelation</span></span> `bal` +- <span class="hljs-symbol"><span class="hljs-symbol">'UnresolvedRelation</span></span> `cust`</code> </pre><br><ul><li>  Plan logique analysé - à ce stade, des informations sur la structure des entités utilisées sont ajoutées, la correspondance de la structure et les attributs demandés sont vérifiés. </li></ul><br><pre> <code class="hljs delphi">== Analyzed Logical Plan == account_rk: decimal(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), full_name: <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Filter (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = cast(<span class="hljs-number"><span class="hljs-number">2017</span></span>-<span class="hljs-number"><span class="hljs-number">12</span></span>-<span class="hljs-number"><span class="hljs-number">31</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> date)) +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- SubqueryAlias bal : +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#0</span></span>,ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- SubqueryAlias cust +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#56</span></span>,PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><ul><li>  Le plan logique optimisé est le plus intéressant pour nous.  À ce stade, l'arbre de requête résultant est converti en fonction des règles d'optimisation disponibles. </li></ul><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span>)) : +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#0</span></span>,ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>)) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#56</span></span>,PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><ul><li>  Plan physique - les caractéristiques de l'accès aux données sources commencent à être prises en compte, y compris les optimisations pour filtrer les partitions et les données afin de minimiser l'ensemble de données résultant.  La stratégie d'exécution de jointure est sélectionnée (pour plus de détails sur les options disponibles, voir ci-dessous). </li></ul><br><pre> <code class="hljs pgsql">== Physical Plan == *(<span class="hljs-number"><span class="hljs-number">2</span></span>) Project [account_rk#<span class="hljs-number"><span class="hljs-number">1</span></span>, full_name#<span class="hljs-number"><span class="hljs-number">59</span></span>] +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) BroadcastHashJoin [party_rk#<span class="hljs-number"><span class="hljs-number">18</span></span>, actual_date#<span class="hljs-number"><span class="hljs-number">27</span></span>], [party_rk#<span class="hljs-number"><span class="hljs-number">57</span></span>, actual_date#<span class="hljs-number"><span class="hljs-number">88</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">Inner</span></span>, BuildRight :- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) Project [ACCOUNT_RK#<span class="hljs-number"><span class="hljs-number">1</span></span>, PARTY_RK#<span class="hljs-number"><span class="hljs-number">18</span></span>, ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>] : +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> isnotnull(party_rk#<span class="hljs-number"><span class="hljs-number">18</span></span>) : +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) FileScan orc [ACCOUNT_RK#<span class="hljs-number"><span class="hljs-number">1</span></span>,PARTY_RK#<span class="hljs-number"><span class="hljs-number">18</span></span>,ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>] Batched: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">Format</span></span>: ORC, <span class="hljs-keyword"><span class="hljs-keyword">Location</span></span>: InMemoryFileIndex[hdfs://<span class="hljs-keyword"><span class="hljs-keyword">cluster</span></span>:<span class="hljs-number"><span class="hljs-number">8020</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>/test/balance], PartitionCount: <span class="hljs-number"><span class="hljs-number">1</span></span>, PartitionFilters: [isnotnull(ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>), (ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)], PushedFilters: [IsNotNull(PARTY_RK)], ReadSchema: struct&lt;ACCOUNT_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>),PARTY_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>)&gt; +- BroadcastExchange HashedRelationBroadcastMode(List(<span class="hljs-keyword"><span class="hljs-keyword">input</span></span>[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">input</span></span>[<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-type"><span class="hljs-type">date</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>])) +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) Project [PARTY_RK#<span class="hljs-number"><span class="hljs-number">57</span></span>, FULL_NAME#<span class="hljs-number"><span class="hljs-number">59</span></span>, ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>] +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> isnotnull(party_rk#<span class="hljs-number"><span class="hljs-number">57</span></span>) +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) FileScan orc [PARTY_RK#<span class="hljs-number"><span class="hljs-number">57</span></span>,FULL_NAME#<span class="hljs-number"><span class="hljs-number">59</span></span>,ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>] Batched: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">Format</span></span>: ORC, <span class="hljs-keyword"><span class="hljs-keyword">Location</span></span>: InMemoryFileIndex[hdfs://<span class="hljs-keyword"><span class="hljs-keyword">cluster</span></span>:<span class="hljs-number"><span class="hljs-number">8020</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>/test/customer], PartitionCount: <span class="hljs-number"><span class="hljs-number">1</span></span>, PartitionFilters: [isnotnull(ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>), (ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)], PushedFilters: [IsNotNull(PARTY_RK)], ReadSchema: struct&lt;PARTY_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>),FULL_NAME:string&gt;</code> </pre><br><p>  Les étapes suivantes d'optimisation et d'exécution (par exemple, WholeStageCodegen) dépassent le cadre de cet article, mais sont décrites en détail (ainsi que les étapes décrites ci-dessus) dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mastering Spark Sql</a> . <br></p><br><p>  La lecture du plan d'exécution des requêtes se produit généralement «de l'intérieur» et «de bas en haut», c'est-à-dire que les parties les plus imbriquées sont exécutées en premier et progressent progressivement vers la projection finale située tout en haut. <br></p><br><h2>  Types d'optimiseurs de requête </h2><br><p>  On peut distinguer deux types d'optimiseurs de requête: </p><br><ul><li>  Optimiseurs basés sur des règles (RBO). </li><li>  Optimiseurs basés sur une estimation du coût d'exécution des requêtes (Optimiseur basé sur les coûts, CBO). </li></ul><br><p>  Les premiers se concentrent sur l'utilisation d'un ensemble de règles fixes, par exemple, l'application de conditions de filtrage d'où aux stades antérieurs, si possible, le calcul des constantes, etc. <br></p><br><p>  Pour évaluer la qualité du plan résultant, l'optimiseur CBO utilise une fonction de coût, qui dépend généralement de la quantité de données traitées, du nombre de lignes qui tombent sous les filtres et du coût d'exécution de certaines opérations. <br></p><br><p>  Pour en savoir plus sur la spécification de conception CBO pour Apache Spark, veuillez suivre les liens: la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">spécification</a> et la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tâche JIRA principale pour l'implémentation</a> . <br></p><br><p>  Le point de départ pour explorer la gamme complète des optimisations existantes est le code Optimizer.scala. <br></p><br><p>  Voici un court extrait d'une longue liste d'optimisations disponibles: <br></p><br><pre> <code class="hljs perl">def batches: Se<span class="hljs-string"><span class="hljs-string">q[Batch]</span></span> = { val operatorOptimizationRuleSet = Se<span class="hljs-string"><span class="hljs-string">q( // Operator push down PushProjectionThroughUnion, ReorderJoin, EliminateOuterJoin, PushPredicateThroughJoin, PushDownPredicate, LimitPushDown, ColumnPruning, InferFiltersFromConstraints, // Operator combine CollapseRepartition, CollapseProject, CollapseWindow, CombineFilters, CombineLimits, CombineUnions, // Constant folding and strength reduction NullPropagation, ConstantPropagation, ........</span></span></code> </pre><br><p>  Il convient de noter que la liste de ces optimisations comprend à la fois des optimisations basées sur des règles et des optimisations basées sur des estimations de coût de requête, qui seront discutées ci-dessous. <br></p><br><p>  Une caractéristique de CBO est que pour un fonctionnement correct, il doit connaître et stocker des informations sur les statistiques des données utilisées dans la requête - le nombre d'enregistrements, la taille des enregistrements, les histogrammes de distribution des données dans les colonnes du tableau. <br></p><br><p>  Pour collecter des statistiques, un ensemble de commandes SQL ANALYZE TABLE ... COMPUTE STATISTICS est utilisé, en outre, un ensemble de tables est nécessaire pour stocker des informations, l'API est fournie via ExternalCatalog, plus précisément via HiveExternalCatalog. <br></p><br><p>  Puisque CBO est actuellement désactivé par défaut, l'accent sera mis sur la recherche de l'optimisation et des nuances disponibles de RBO. <br></p><br><h2>  Types et choix de stratégie de jointure </h2><br><p>  Au stade de la formation du plan physique d'exécution de la demande, la stratégie de jointure est sélectionnée.  Les options suivantes sont actuellement disponibles dans Spark (vous pouvez commencer à apprendre le code à partir du code dans SparkStrategies.scala). <br></p><br><h3>  Rejoindre le hachage de diffusion </h3><br><p>  La meilleure option est si l'une des parties de jointure est suffisamment petite (le critère de suffisance est défini par le paramètre spark.sql.autoBroadcastJoinThreshold dans SQLConf).  Dans ce cas, ce côté est entièrement copié vers tous les exécuteurs, où il existe une jointure de hachage avec la table principale.  En plus de la taille, il convient de noter que dans le cas d'une jointure externe, seul le côté externe peut être copié.Par conséquent, si possible, en tant que table principale dans le cas d'une jointure externe, vous devez utiliser la table avec la plus grande quantité de données. <br></p><br><pre> <code class="hljs pgsql">  ,    ,     <span class="hljs-keyword"><span class="hljs-keyword">SQL</span></span>      Oracle,   <span class="hljs-comment"><span class="hljs-comment">/*+ broadcast(t1, t2) */</span></span></code> </pre><br><h3>  Trier la jointure de fusion </h3><br><p>  Avec <em>spark.sql.join.preferSortMergeJoin</em> activé par défaut, cette méthode est appliquée par défaut si les clés de jointure peuvent être triées. <br>  Parmi les fonctionnalités, on peut noter que, contrairement à la méthode précédente, l'optimisation de la génération de code pour effectuer l'opération n'est disponible que pour la jointure interne. <br></p><br><h3>  Shuffle hash join </h3><br><p>  Si les clés ne peuvent pas être triées ou si l'option de sélection de jointure de fusion par défaut est désactivée, Catalyst essaie d'appliquer une jointure de hachage aléatoire.  Outre la vérification des paramètres, il est également vérifié que Spark a suffisamment de mémoire pour créer une carte de hachage locale pour une partition (le nombre total de partitions est défini en définissant <em>spark.sql.shuffle.partitions</em> ) </p><br><h3>  BroadcastNestedLoopJoin et CartésienProduit </h3><br><p>  Dans le cas où il n'y a pas de possibilité de comparaison directe par clé (par exemple, une condition comme) ou il n'y a pas de clés pour joindre des tables, selon la taille des tables, ce type ou CartesianProduct est sélectionné. <br></p><br><h3>  L'ordre de spécification des tables dans join'ah </h3><br><p>  Dans tous les cas, la jointure nécessite de mélanger les tables par clé.  Par conséquent, pour le moment, l'ordre de spécification des tables, en particulier dans le cas de l'exécution de plusieurs jointures consécutives, est important (si vous êtes un alésage, alors si CBO n'est pas activé et le paramètre JOIN_REORDER_ENABLED n'est pas activé). <br></p><br><p>  Si possible, l'ordre de jointure des tables doit minimiser le nombre d'opérations de mélange pour les grandes tables, pour lesquelles les jointures sur la même clé doivent être séquentielles.  N'oubliez pas non plus de minimiser les données pour la jointure, pour activer Broadcast Hash Join. <br></p><br><h2>  Application transitive des conditions de filtrage </h2><br><p>  Considérez la requête suivante: <br></p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> bal.account_rk, cust.full_name <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> balance bal <span class="hljs-keyword"><span class="hljs-keyword">join</span></span> customer cust <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> bal.party_rk = cust.party_rk <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> bal.actual_date = cust.actual_date <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> bal.actual_date = <span class="hljs-keyword"><span class="hljs-keyword">cast</span></span>(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-built_in"><span class="hljs-built_in">date</span></span>)</code> </pre><br><p>  Ici, nous connectons deux tables qui sont partitionnées de la même manière, selon le champ actual_date et appliquons un filtre explicite uniquement à la partition en fonction de la table de solde. <br></p><br><p>  Comme le montre le plan de requête optimisé, le filtre par date est également appliqué au client, et au moment de la lecture des données du disque, il est déterminé qu’une seule partition est nécessaire. <br></p><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span>)) : +- Relation[,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Filter (((actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>) &amp;&amp; isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>)) +- Relation[,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><p>  Mais il vous suffit de remplacer la jointure interne par la gauche externe dans la requête, car le prédicat push pour la table client tombe immédiatement et une analyse complète se produit, ce qui est un effet indésirable. <br></p><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join LeftOuter, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter (isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) : +- Relation[,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Relation[,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><h2>  Conversion de type </h2><br><p>  Prenons un exemple simple de sélection à partir d'une table avec filtrage par type de client, dans le schéma le type du champ party_type est string. <br></p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> party_rk, full_name <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> cust <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> actual_date = cast(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-type"><span class="hljs-type">date</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> party_type = <span class="hljs-number"><span class="hljs-number">101</span></span> <span class="hljs-comment"><span class="hljs-comment">--   -- and party_type = '101' --    </span></span></code> </pre><br><p>  Et comparez les deux plans résultants, le premier - lorsque nous nous référons au type incorrect (il y aura une conversion implicite en int), le second - lorsque le type correspond au schéma. <br></p><br><pre> <code class="hljs powershell">PushedFilters: [<span class="hljs-type"><span class="hljs-type">IsNotNull</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>)] //            . PushedFilters: [<span class="hljs-type"><span class="hljs-type">IsNotNull</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>), <span class="hljs-type"><span class="hljs-type">EqualTo</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>,<span class="hljs-number"><span class="hljs-number">101</span></span>)] //             .</code> </pre><br><p>  Un problème similaire est observé dans le cas de la comparaison de dates avec une chaîne, il y aura un filtre pour comparer les chaînes.  Un exemple: <br></p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">where</span></span> OPER_DATE = <span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> (isnotnull(oper_date#<span class="hljs-number"><span class="hljs-number">0</span></span>) &amp;&amp; (cast(oper_date#<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> string) = <span class="hljs-number"><span class="hljs-number">2017</span></span><span class="hljs-number"><span class="hljs-number">-12</span></span><span class="hljs-number"><span class="hljs-number">-31</span></span>) PushedFilters: [IsNotNull(OPER_DATE)] <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> OPER_DATE = cast(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-type"><span class="hljs-type">date</span></span>) PushedFilters: [IsNotNull(OPER_DATE), EqualTo(OPER_DATE,<span class="hljs-number"><span class="hljs-number">2017</span></span><span class="hljs-number"><span class="hljs-number">-12</span></span><span class="hljs-number"><span class="hljs-number">-31</span></span>)]</code> </pre><br><p>  Dans le cas où une conversion de type implicite est possible, par exemple, int -&gt; décimal, l'optimiseur le fait de lui-même. <br></p><br><h2>  Recherche complémentaire </h2><br><p>  De nombreuses informations intéressantes sur les «boutons» pouvant être utilisés pour affiner Catalyst, ainsi que sur les possibilités (présentes et futures) de l'optimiseur, peuvent être obtenues à partir de SQLConf.scala. <br></p><br><p>  En particulier, comme vous pouvez le voir par défaut, l'optimiseur de coût est toujours désactivé pour le moment. <br></p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">CBO_ENABLED</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.enabled"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"Enables CBO for estimation of plan statistics when set true."</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><p>  Ainsi que ses optimisations dépendantes associées à la réorganisation de join'ov. <br></p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">JOIN_REORDER_ENABLED</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.joinReorder.enabled"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"Enables join reorder in CBO."</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><p>  ou </p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">STARSCHEMA_DETECTION</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.starSchemaDetection"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"When true, it enables join reordering based on star schema detection. "</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><h2>  Bref résumé </h2><br><p>  Seule une petite partie des optimisations existantes a été touchée, des expériences d'optimisation des coûts, qui peuvent donner beaucoup plus de place à la conversion des requêtes, sont à venir.  De plus, une autre question intéressante est la comparaison d'un ensemble d'optimisations lors de la lecture de fichiers de Parquet et Orc, à en juger par la jira du projet, il s'agit de parité, mais est-ce vraiment le cas? <br></p><br><p>  De plus: </p><br><ul><li>  L'analyse et l'optimisation des demandes sont intéressantes et passionnantes, surtout compte tenu de la disponibilité des codes sources. </li><li>  L'inclusion de CBO offrira des possibilités d'optimisation et de recherche supplémentaires. </li><li>  Il est nécessaire de contrôler l'applicabilité des règles de base qui vous permettent de filtrer autant de données «supplémentaires» que possible, le plus tôt possible. </li><li>  Rejoindre est un mal nécessaire, mais si possible, il vaut la peine de les minimiser et de garder une trace de l'implémentation utilisée sous le capot. </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr417103/">https://habr.com/ru/post/fr417103/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr417091/index.html">Créez un shader d'eau de dessin animé pour le Web. 3e partie</a></li>
<li><a href="../fr417093/index.html">Interrupteurs tactiles avec Modbus: pourquoi sont-ils nécessaires et comment les appliquer dans un appartement intelligent</a></li>
<li><a href="../fr417097/index.html">Métaprogrammation JavaScript</a></li>
<li><a href="../fr417099/index.html">Comment ai-je écrit la bibliothèque C ++ 11 standard ou pourquoi boost est si effrayant. Chapitre 2</a></li>
<li><a href="../fr417101/index.html">Définition de prêt - ce que nous avons oublié de dire</a></li>
<li><a href="../fr417105/index.html">Impression sur une imprimante 3D. Expériences secrètes de 3Dtool</a></li>
<li><a href="../fr417107/index.html">Créateur du jeu en mode True: découvrez () la programmation gamedev, les problèmes VR et les simulations ML</a></li>
<li><a href="../fr417109/index.html">Richard Hamming: Chapitre 10. Théorie du codage - I</a></li>
<li><a href="../fr417111/index.html">Conférences en ligne: streaming vs webinaire</a></li>
<li><a href="../fr417113/index.html">Imprimante 3D italienne en Russie: Raise3D N1 Dual - modélisation et prototypage</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
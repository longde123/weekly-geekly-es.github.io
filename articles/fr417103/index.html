<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôåüèª üë®üèΩ üë®üèø‚Äçüéì Spark SQL. Un peu sur l'optimiseur de requ√™tes üë©üèæ‚Äçü§ù‚Äçüë®üèª üíæ üóìÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour √† tous. En guise d'introduction, je veux vous dire comment je suis arriv√© √† une telle vie. 



 Avant de rencontrer Big Data et Spark, en part...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Spark SQL. Un peu sur l'optimiseur de requ√™tes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/neoflex/blog/417103/"><p>  Bonjour √† tous.  En guise d'introduction, je veux vous dire comment je suis arriv√© √† une telle vie. <br></p><br><p>  Avant de rencontrer Big Data et Spark, en particulier, j'avais beaucoup et souvent √† optimiser les requ√™tes SQL, d'abord pour MSSQL, puis pour Oracle, et maintenant je suis tomb√© sur SparkSQL. <br></p><br><p>  Et s'il existe d√©j√† de nombreux bons livres pour le SGBD qui d√©crivent la m√©thodologie et les ¬´stylos¬ª que vous pouvez tourner pour obtenir le plan de requ√™te optimal, alors je n'ai pas vu de tels livres pour Spark.  Je suis tomb√© sur plus d'articles et d'ensembles de pratiques, plus li√©s √† l'utilisation de l'API RDD / Dataset qu'√† du SQL pur.  Pour moi, l'un des ouvrages de r√©f√©rence sur l'optimisation SQL est le livre de J. Lewis, Oracle.  Bases de l'optimisation des co√ªts. "  J'ai cherch√© quelque chose de similaire en profondeur d'√©tude.  Pourquoi l'objet de la recherche √©tait-il sp√©cifiquement SparkSQL, et non l'API sous-jacente?  L'int√©r√™t a ensuite √©t√© provoqu√© par les caract√©ristiques du projet sur lequel je travaille. <br></p><br><img src="https://habrastorage.org/webt/po/1f/un/po1fun6vgbktou6lykepwmrncci.jpeg"><br><a name="habracut"></a><br><p>  Pour l'un de nos clients, notre soci√©t√© d√©veloppe un entrep√¥t de donn√©es, dont une couche d√©taill√©e et une partie des vitrines sont dans le cluster Hadoop, et les vitrines finales sont dans Oracle.  Ce projet implique une couche de conversion de donn√©es √©tendue, qui est impl√©ment√©e sur Spark.  Pour acc√©l√©rer le d√©veloppement et la connectivit√© des d√©veloppeurs ETL qui ne connaissent pas les subtilit√©s des technologies Big Data, mais qui connaissent les outils SQL et ETL, un outil a √©t√© d√©velopp√© qui rappelle id√©ologiquement d'autres outils ETL, par exemple Informatica, et vous permet de concevoir visuellement des processus ETL avec la g√©n√©ration suivante code pour Spark.  En raison de la complexit√© des algorithmes et du grand nombre de transformations, les d√©veloppeurs utilisent principalement des requ√™tes SparkSQL. <br></p><br><p> Et c'est l√† que commence l'histoire, car j'ai d√ª r√©pondre √† un grand nombre de questions du formulaire ¬´Pourquoi la demande ne fonctionne-t-elle pas / fonctionne-t-elle lentement / fonctionne-t-elle diff√©remment d'Oracle?¬ª.  Celui-ci s'est av√©r√© √™tre la partie la plus int√©ressante pour moi: "Pourquoi √ßa marche lentement?".  De plus, contrairement au SGBD avec lequel j'ai travaill√© auparavant, vous pouvez entrer dans le code source et obtenir la r√©ponse √† vos questions. <br></p><cut text="    "></cut><br><h2>  Limitations et hypoth√®ses </h2><br><p>  Spark 2.3.0 est utilis√© pour ex√©cuter des exemples et analyser le code source. <br>  Il est suppos√© que le lecteur conna√Æt l'architecture Spark et les principes g√©n√©raux de l'optimiseur de requ√™tes pour l'un des SGBD.  Au minimum, l'expression ¬´plan de requ√™te¬ª ne devrait certainement pas √™tre surprenante. <br></p><br><p>  De plus, cet article essaie de ne pas devenir une traduction du code de l'optimiseur Spark en russe, donc pour les choses tr√®s int√©ressantes du point de vue de l'optimiseur, mais qui peuvent √™tre lues dans le code source, elles seront simplement bri√®vement mentionn√©es ici avec des liens vers les classes correspondantes. <br></p><br><h2>  Passez √† l'√©tude </h2><br><p>  Commen√ßons par une petite requ√™te pour explorer les √©tapes de base √† travers lesquelles elle passe de l'analyse √† l'ex√©cution. <br></p><br><pre><code class="scala hljs">scala&gt; spark.read.orc(<span class="hljs-string"><span class="hljs-string">"/user/test/balance"</span></span>).createOrReplaceTempView(<span class="hljs-string"><span class="hljs-string">"bal"</span></span>) scala&gt; spark.read.orc(<span class="hljs-string"><span class="hljs-string">"/user/test/customer"</span></span>).createOrReplaceTempView(<span class="hljs-string"><span class="hljs-string">"cust"</span></span>) scala&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> df = spark.sql(<span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">" | select bal.account_rk, cust.full_name | from bal | join cust | on bal.party_rk = cust.party_rk | and bal.actual_date = cust.actual_date | where bal.actual_date = cast('2017-12-31' as date) | "</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>) df: org.apache.spark.sql.<span class="hljs-type"><span class="hljs-type">DataFrame</span></span> = [account_rk: decimal(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), full_name: string] scala&gt; df.explain(<span class="hljs-literal"><span class="hljs-literal">true</span></span>)</code> </pre> <br><p>  Le module principal charg√© d'analyser SQL et d'optimiser le plan d'ex√©cution des requ√™tes est Spark Catalyst. <br></p><br><p>  La sortie d√©velopp√©e dans la description du plan de demande (df.explain (true)) vous permet de suivre toutes les √©tapes de la demande: <br></p><br><ul><li>  Plan logique analys√© - obtenez apr√®s l'analyse SQL.  √Ä ce stade, seule l'exactitude syntaxique de la demande est v√©rifi√©e. </li></ul><br><pre> <code class="hljs rust">== Parsed Logical Plan == <span class="hljs-symbol"><span class="hljs-symbol">'Project</span></span> [<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.account_rk, <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.full_name] +- <span class="hljs-symbol"><span class="hljs-symbol">'Filter</span></span> (<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.actual_date = cast(<span class="hljs-number"><span class="hljs-number">2017</span></span>-<span class="hljs-number"><span class="hljs-number">12</span></span>-<span class="hljs-number"><span class="hljs-number">31</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> date)) +- <span class="hljs-symbol"><span class="hljs-symbol">'Join</span></span> Inner, ((<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.party_rk = <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.party_rk) &amp;&amp; (<span class="hljs-symbol"><span class="hljs-symbol">'bal</span></span>.actual_date = <span class="hljs-symbol"><span class="hljs-symbol">'cust</span></span>.actual_date)) :- <span class="hljs-symbol"><span class="hljs-symbol">'UnresolvedRelation</span></span> `bal` +- <span class="hljs-symbol"><span class="hljs-symbol">'UnresolvedRelation</span></span> `cust`</code> </pre><br><ul><li>  Plan logique analys√© - √† ce stade, des informations sur la structure des entit√©s utilis√©es sont ajout√©es, la correspondance de la structure et les attributs demand√©s sont v√©rifi√©s. </li></ul><br><pre> <code class="hljs delphi">== Analyzed Logical Plan == account_rk: decimal(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), full_name: <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Filter (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = cast(<span class="hljs-number"><span class="hljs-number">2017</span></span>-<span class="hljs-number"><span class="hljs-number">12</span></span>-<span class="hljs-number"><span class="hljs-number">31</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> date)) +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- SubqueryAlias bal : +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#0</span></span>,ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- SubqueryAlias cust +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#56</span></span>,PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><ul><li>  Le plan logique optimis√© est le plus int√©ressant pour nous.  √Ä ce stade, l'arbre de requ√™te r√©sultant est converti en fonction des r√®gles d'optimisation disponibles. </li></ul><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span>)) : +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#0</span></span>,ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>)) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) +- Relation[ACTUAL_END_DATE<span class="hljs-string"><span class="hljs-string">#56</span></span>,PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><ul><li>  Plan physique - les caract√©ristiques de l'acc√®s aux donn√©es sources commencent √† √™tre prises en compte, y compris les optimisations pour filtrer les partitions et les donn√©es afin de minimiser l'ensemble de donn√©es r√©sultant.  La strat√©gie d'ex√©cution de jointure est s√©lectionn√©e (pour plus de d√©tails sur les options disponibles, voir ci-dessous). </li></ul><br><pre> <code class="hljs pgsql">== Physical Plan == *(<span class="hljs-number"><span class="hljs-number">2</span></span>) Project [account_rk#<span class="hljs-number"><span class="hljs-number">1</span></span>, full_name#<span class="hljs-number"><span class="hljs-number">59</span></span>] +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) BroadcastHashJoin [party_rk#<span class="hljs-number"><span class="hljs-number">18</span></span>, actual_date#<span class="hljs-number"><span class="hljs-number">27</span></span>], [party_rk#<span class="hljs-number"><span class="hljs-number">57</span></span>, actual_date#<span class="hljs-number"><span class="hljs-number">88</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">Inner</span></span>, BuildRight :- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) Project [ACCOUNT_RK#<span class="hljs-number"><span class="hljs-number">1</span></span>, PARTY_RK#<span class="hljs-number"><span class="hljs-number">18</span></span>, ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>] : +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> isnotnull(party_rk#<span class="hljs-number"><span class="hljs-number">18</span></span>) : +- *(<span class="hljs-number"><span class="hljs-number">2</span></span>) FileScan orc [ACCOUNT_RK#<span class="hljs-number"><span class="hljs-number">1</span></span>,PARTY_RK#<span class="hljs-number"><span class="hljs-number">18</span></span>,ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>] Batched: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">Format</span></span>: ORC, <span class="hljs-keyword"><span class="hljs-keyword">Location</span></span>: InMemoryFileIndex[hdfs://<span class="hljs-keyword"><span class="hljs-keyword">cluster</span></span>:<span class="hljs-number"><span class="hljs-number">8020</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>/test/balance], PartitionCount: <span class="hljs-number"><span class="hljs-number">1</span></span>, PartitionFilters: [isnotnull(ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span>), (ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)], PushedFilters: [IsNotNull(PARTY_RK)], ReadSchema: struct&lt;ACCOUNT_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>),PARTY_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>)&gt; +- BroadcastExchange HashedRelationBroadcastMode(List(<span class="hljs-keyword"><span class="hljs-keyword">input</span></span>[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">input</span></span>[<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-type"><span class="hljs-type">date</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>])) +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) Project [PARTY_RK#<span class="hljs-number"><span class="hljs-number">57</span></span>, FULL_NAME#<span class="hljs-number"><span class="hljs-number">59</span></span>, ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>] +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> isnotnull(party_rk#<span class="hljs-number"><span class="hljs-number">57</span></span>) +- *(<span class="hljs-number"><span class="hljs-number">1</span></span>) FileScan orc [PARTY_RK#<span class="hljs-number"><span class="hljs-number">57</span></span>,FULL_NAME#<span class="hljs-number"><span class="hljs-number">59</span></span>,ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>] Batched: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">Format</span></span>: ORC, <span class="hljs-keyword"><span class="hljs-keyword">Location</span></span>: InMemoryFileIndex[hdfs://<span class="hljs-keyword"><span class="hljs-keyword">cluster</span></span>:<span class="hljs-number"><span class="hljs-number">8020</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>/test/customer], PartitionCount: <span class="hljs-number"><span class="hljs-number">1</span></span>, PartitionFilters: [isnotnull(ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span>), (ACTUAL_DATE#<span class="hljs-number"><span class="hljs-number">88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)], PushedFilters: [IsNotNull(PARTY_RK)], ReadSchema: struct&lt;PARTY_RK:<span class="hljs-type"><span class="hljs-type">decimal</span></span>(<span class="hljs-number"><span class="hljs-number">38</span></span>,<span class="hljs-number"><span class="hljs-number">18</span></span>),FULL_NAME:string&gt;</code> </pre><br><p>  Les √©tapes suivantes d'optimisation et d'ex√©cution (par exemple, WholeStageCodegen) d√©passent le cadre de cet article, mais sont d√©crites en d√©tail (ainsi que les √©tapes d√©crites ci-dessus) dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mastering Spark Sql</a> . <br></p><br><p>  La lecture du plan d'ex√©cution des requ√™tes se produit g√©n√©ralement ¬´de l'int√©rieur¬ª et ¬´de bas en haut¬ª, c'est-√†-dire que les parties les plus imbriqu√©es sont ex√©cut√©es en premier et progressent progressivement vers la projection finale situ√©e tout en haut. <br></p><br><h2>  Types d'optimiseurs de requ√™te </h2><br><p>  On peut distinguer deux types d'optimiseurs de requ√™te: </p><br><ul><li>  Optimiseurs bas√©s sur des r√®gles (RBO). </li><li>  Optimiseurs bas√©s sur une estimation du co√ªt d'ex√©cution des requ√™tes (Optimiseur bas√© sur les co√ªts, CBO). </li></ul><br><p>  Les premiers se concentrent sur l'utilisation d'un ensemble de r√®gles fixes, par exemple, l'application de conditions de filtrage d'o√π aux stades ant√©rieurs, si possible, le calcul des constantes, etc. <br></p><br><p>  Pour √©valuer la qualit√© du plan r√©sultant, l'optimiseur CBO utilise une fonction de co√ªt, qui d√©pend g√©n√©ralement de la quantit√© de donn√©es trait√©es, du nombre de lignes qui tombent sous les filtres et du co√ªt d'ex√©cution de certaines op√©rations. <br></p><br><p>  Pour en savoir plus sur la sp√©cification de conception CBO pour Apache Spark, veuillez suivre les liens: la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sp√©cification</a> et la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">t√¢che JIRA principale pour l'impl√©mentation</a> . <br></p><br><p>  Le point de d√©part pour explorer la gamme compl√®te des optimisations existantes est le code Optimizer.scala. <br></p><br><p>  Voici un court extrait d'une longue liste d'optimisations disponibles: <br></p><br><pre> <code class="hljs perl">def batches: Se<span class="hljs-string"><span class="hljs-string">q[Batch]</span></span> = { val operatorOptimizationRuleSet = Se<span class="hljs-string"><span class="hljs-string">q( // Operator push down PushProjectionThroughUnion, ReorderJoin, EliminateOuterJoin, PushPredicateThroughJoin, PushDownPredicate, LimitPushDown, ColumnPruning, InferFiltersFromConstraints, // Operator combine CollapseRepartition, CollapseProject, CollapseWindow, CombineFilters, CombineLimits, CombineUnions, // Constant folding and strength reduction NullPropagation, ConstantPropagation, ........</span></span></code> </pre><br><p>  Il convient de noter que la liste de ces optimisations comprend √† la fois des optimisations bas√©es sur des r√®gles et des optimisations bas√©es sur des estimations de co√ªt de requ√™te, qui seront discut√©es ci-dessous. <br></p><br><p>  Une caract√©ristique de CBO est que pour un fonctionnement correct, il doit conna√Ætre et stocker des informations sur les statistiques des donn√©es utilis√©es dans la requ√™te - le nombre d'enregistrements, la taille des enregistrements, les histogrammes de distribution des donn√©es dans les colonnes du tableau. <br></p><br><p>  Pour collecter des statistiques, un ensemble de commandes SQL ANALYZE TABLE ... COMPUTE STATISTICS est utilis√©, en outre, un ensemble de tables est n√©cessaire pour stocker des informations, l'API est fournie via ExternalCatalog, plus pr√©cis√©ment via HiveExternalCatalog. <br></p><br><p>  Puisque CBO est actuellement d√©sactiv√© par d√©faut, l'accent sera mis sur la recherche de l'optimisation et des nuances disponibles de RBO. <br></p><br><h2>  Types et choix de strat√©gie de jointure </h2><br><p>  Au stade de la formation du plan physique d'ex√©cution de la demande, la strat√©gie de jointure est s√©lectionn√©e.  Les options suivantes sont actuellement disponibles dans Spark (vous pouvez commencer √† apprendre le code √† partir du code dans SparkStrategies.scala). <br></p><br><h3>  Rejoindre le hachage de diffusion </h3><br><p>  La meilleure option est si l'une des parties de jointure est suffisamment petite (le crit√®re de suffisance est d√©fini par le param√®tre spark.sql.autoBroadcastJoinThreshold dans SQLConf).  Dans ce cas, ce c√¥t√© est enti√®rement copi√© vers tous les ex√©cuteurs, o√π il existe une jointure de hachage avec la table principale.  En plus de la taille, il convient de noter que dans le cas d'une jointure externe, seul le c√¥t√© externe peut √™tre copi√©.Par cons√©quent, si possible, en tant que table principale dans le cas d'une jointure externe, vous devez utiliser la table avec la plus grande quantit√© de donn√©es. <br></p><br><pre> <code class="hljs pgsql">  ,    ,     <span class="hljs-keyword"><span class="hljs-keyword">SQL</span></span>      Oracle,   <span class="hljs-comment"><span class="hljs-comment">/*+ broadcast(t1, t2) */</span></span></code> </pre><br><h3>  Trier la jointure de fusion </h3><br><p>  Avec <em>spark.sql.join.preferSortMergeJoin</em> activ√© par d√©faut, cette m√©thode est appliqu√©e par d√©faut si les cl√©s de jointure peuvent √™tre tri√©es. <br>  Parmi les fonctionnalit√©s, on peut noter que, contrairement √† la m√©thode pr√©c√©dente, l'optimisation de la g√©n√©ration de code pour effectuer l'op√©ration n'est disponible que pour la jointure interne. <br></p><br><h3>  Shuffle hash join </h3><br><p>  Si les cl√©s ne peuvent pas √™tre tri√©es ou si l'option de s√©lection de jointure de fusion par d√©faut est d√©sactiv√©e, Catalyst essaie d'appliquer une jointure de hachage al√©atoire.  Outre la v√©rification des param√®tres, il est √©galement v√©rifi√© que Spark a suffisamment de m√©moire pour cr√©er une carte de hachage locale pour une partition (le nombre total de partitions est d√©fini en d√©finissant <em>spark.sql.shuffle.partitions</em> ) </p><br><h3>  BroadcastNestedLoopJoin et Cart√©sienProduit </h3><br><p>  Dans le cas o√π il n'y a pas de possibilit√© de comparaison directe par cl√© (par exemple, une condition comme) ou il n'y a pas de cl√©s pour joindre des tables, selon la taille des tables, ce type ou CartesianProduct est s√©lectionn√©. <br></p><br><h3>  L'ordre de sp√©cification des tables dans join'ah </h3><br><p>  Dans tous les cas, la jointure n√©cessite de m√©langer les tables par cl√©.  Par cons√©quent, pour le moment, l'ordre de sp√©cification des tables, en particulier dans le cas de l'ex√©cution de plusieurs jointures cons√©cutives, est important (si vous √™tes un al√©sage, alors si CBO n'est pas activ√© et le param√®tre JOIN_REORDER_ENABLED n'est pas activ√©). <br></p><br><p>  Si possible, l'ordre de jointure des tables doit minimiser le nombre d'op√©rations de m√©lange pour les grandes tables, pour lesquelles les jointures sur la m√™me cl√© doivent √™tre s√©quentielles.  N'oubliez pas non plus de minimiser les donn√©es pour la jointure, pour activer Broadcast Hash Join. <br></p><br><h2>  Application transitive des conditions de filtrage </h2><br><p>  Consid√©rez la requ√™te suivante: <br></p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> bal.account_rk, cust.full_name <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> balance bal <span class="hljs-keyword"><span class="hljs-keyword">join</span></span> customer cust <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> bal.party_rk = cust.party_rk <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> bal.actual_date = cust.actual_date <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> bal.actual_date = <span class="hljs-keyword"><span class="hljs-keyword">cast</span></span>(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-built_in"><span class="hljs-built_in">date</span></span>)</code> </pre><br><p>  Ici, nous connectons deux tables qui sont partitionn√©es de la m√™me mani√®re, selon le champ actual_date et appliquons un filtre explicite uniquement √† la partition en fonction de la table de solde. <br></p><br><p>  Comme le montre le plan de requ√™te optimis√©, le filtre par date est √©galement appliqu√© au client, et au moment de la lecture des donn√©es du disque, il est d√©termin√© qu‚Äôune seule partition est n√©cessaire. <br></p><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join Inner, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter ((isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span>)) : +- Relation[,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Filter (((actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>) &amp;&amp; isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) &amp;&amp; isnotnull(party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>)) +- Relation[,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><p>  Mais il vous suffit de remplacer la jointure interne par la gauche externe dans la requ√™te, car le pr√©dicat push pour la table client tombe imm√©diatement et une analyse compl√®te se produit, ce qui est un effet ind√©sirable. <br></p><br><pre> <code class="hljs delphi">== Optimized Logical Plan == Project [account_rk<span class="hljs-string"><span class="hljs-string">#1</span></span>, full_name<span class="hljs-string"><span class="hljs-string">#59</span></span>] +- Join LeftOuter, ((party_rk<span class="hljs-string"><span class="hljs-string">#18</span></span> = party_rk<span class="hljs-string"><span class="hljs-string">#57</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = actual_date<span class="hljs-string"><span class="hljs-string">#88</span></span>)) :- Project [ACCOUNT_RK<span class="hljs-string"><span class="hljs-string">#1</span></span>, PARTY_RK<span class="hljs-string"><span class="hljs-string">#18</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#27</span></span>] : +- Filter (isnotnull(actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span>) &amp;&amp; (actual_date<span class="hljs-string"><span class="hljs-string">#27</span></span> = <span class="hljs-number"><span class="hljs-number">17531</span></span>)) : +- Relation[,... <span class="hljs-number"><span class="hljs-number">4</span></span> more fields] orc +- Project [PARTY_RK<span class="hljs-string"><span class="hljs-string">#57</span></span>, FULL_NAME<span class="hljs-string"><span class="hljs-string">#59</span></span>, ACTUAL_DATE<span class="hljs-string"><span class="hljs-string">#88</span></span>] +- Relation[,... <span class="hljs-number"><span class="hljs-number">9</span></span> more fields] orc</code> </pre><br><h2>  Conversion de type </h2><br><p>  Prenons un exemple simple de s√©lection √† partir d'une table avec filtrage par type de client, dans le sch√©ma le type du champ party_type est string. <br></p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">select</span></span> party_rk, full_name <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> cust <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> actual_date = cast(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-type"><span class="hljs-type">date</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> party_type = <span class="hljs-number"><span class="hljs-number">101</span></span> <span class="hljs-comment"><span class="hljs-comment">--   -- and party_type = '101' --    </span></span></code> </pre><br><p>  Et comparez les deux plans r√©sultants, le premier - lorsque nous nous r√©f√©rons au type incorrect (il y aura une conversion implicite en int), le second - lorsque le type correspond au sch√©ma. <br></p><br><pre> <code class="hljs powershell">PushedFilters: [<span class="hljs-type"><span class="hljs-type">IsNotNull</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>)] //            . PushedFilters: [<span class="hljs-type"><span class="hljs-type">IsNotNull</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>), <span class="hljs-type"><span class="hljs-type">EqualTo</span></span>(<span class="hljs-type"><span class="hljs-type">PARTY_TYPE</span></span>,<span class="hljs-number"><span class="hljs-number">101</span></span>)] //             .</code> </pre><br><p>  Un probl√®me similaire est observ√© dans le cas de la comparaison de dates avec une cha√Æne, il y aura un filtre pour comparer les cha√Ænes.  Un exemple: <br></p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">where</span></span> OPER_DATE = <span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Filter</span></span> (isnotnull(oper_date#<span class="hljs-number"><span class="hljs-number">0</span></span>) &amp;&amp; (cast(oper_date#<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> string) = <span class="hljs-number"><span class="hljs-number">2017</span></span><span class="hljs-number"><span class="hljs-number">-12</span></span><span class="hljs-number"><span class="hljs-number">-31</span></span>) PushedFilters: [IsNotNull(OPER_DATE)] <span class="hljs-keyword"><span class="hljs-keyword">where</span></span> OPER_DATE = cast(<span class="hljs-string"><span class="hljs-string">'2017-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-type"><span class="hljs-type">date</span></span>) PushedFilters: [IsNotNull(OPER_DATE), EqualTo(OPER_DATE,<span class="hljs-number"><span class="hljs-number">2017</span></span><span class="hljs-number"><span class="hljs-number">-12</span></span><span class="hljs-number"><span class="hljs-number">-31</span></span>)]</code> </pre><br><p>  Dans le cas o√π une conversion de type implicite est possible, par exemple, int -&gt; d√©cimal, l'optimiseur le fait de lui-m√™me. <br></p><br><h2>  Recherche compl√©mentaire </h2><br><p>  De nombreuses informations int√©ressantes sur les ¬´boutons¬ª pouvant √™tre utilis√©s pour affiner Catalyst, ainsi que sur les possibilit√©s (pr√©sentes et futures) de l'optimiseur, peuvent √™tre obtenues √† partir de SQLConf.scala. <br></p><br><p>  En particulier, comme vous pouvez le voir par d√©faut, l'optimiseur de co√ªt est toujours d√©sactiv√© pour le moment. <br></p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">CBO_ENABLED</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.enabled"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"Enables CBO for estimation of plan statistics when set true."</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><p>  Ainsi que ses optimisations d√©pendantes associ√©es √† la r√©organisation de join'ov. <br></p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">JOIN_REORDER_ENABLED</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.joinReorder.enabled"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"Enables join reorder in CBO."</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><p>  ou </p><br><pre> <code class="hljs scala"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">STARSCHEMA_DETECTION</span></span> = buildConf(<span class="hljs-string"><span class="hljs-string">"spark.sql.cbo.starSchemaDetection"</span></span>) .doc(<span class="hljs-string"><span class="hljs-string">"When true, it enables join reordering based on star schema detection. "</span></span>) .booleanConf .createWithDefault(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)</code> </pre><br><h2>  Bref r√©sum√© </h2><br><p>  Seule une petite partie des optimisations existantes a √©t√© touch√©e, des exp√©riences d'optimisation des co√ªts, qui peuvent donner beaucoup plus de place √† la conversion des requ√™tes, sont √† venir.  De plus, une autre question int√©ressante est la comparaison d'un ensemble d'optimisations lors de la lecture de fichiers de Parquet et Orc, √† en juger par la jira du projet, il s'agit de parit√©, mais est-ce vraiment le cas? <br></p><br><p>  De plus: </p><br><ul><li>  L'analyse et l'optimisation des demandes sont int√©ressantes et passionnantes, surtout compte tenu de la disponibilit√© des codes sources. </li><li>  L'inclusion de CBO offrira des possibilit√©s d'optimisation et de recherche suppl√©mentaires. </li><li>  Il est n√©cessaire de contr√¥ler l'applicabilit√© des r√®gles de base qui vous permettent de filtrer autant de donn√©es ¬´suppl√©mentaires¬ª que possible, le plus t√¥t possible. </li><li>  Rejoindre est un mal n√©cessaire, mais si possible, il vaut la peine de les minimiser et de garder une trace de l'impl√©mentation utilis√©e sous le capot. </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr417103/">https://habr.com/ru/post/fr417103/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr417091/index.html">Cr√©ez un shader d'eau de dessin anim√© pour le Web. 3e partie</a></li>
<li><a href="../fr417093/index.html">Interrupteurs tactiles avec Modbus: pourquoi sont-ils n√©cessaires et comment les appliquer dans un appartement intelligent</a></li>
<li><a href="../fr417097/index.html">M√©taprogrammation JavaScript</a></li>
<li><a href="../fr417099/index.html">Comment ai-je √©crit la biblioth√®que C ++ 11 standard ou pourquoi boost est si effrayant. Chapitre 2</a></li>
<li><a href="../fr417101/index.html">D√©finition de pr√™t - ce que nous avons oubli√© de dire</a></li>
<li><a href="../fr417105/index.html">Impression sur une imprimante 3D. Exp√©riences secr√®tes de 3Dtool</a></li>
<li><a href="../fr417107/index.html">Cr√©ateur du jeu en mode True: d√©couvrez () la programmation gamedev, les probl√®mes VR et les simulations ML</a></li>
<li><a href="../fr417109/index.html">Richard Hamming: Chapitre 10. Th√©orie du codage - I</a></li>
<li><a href="../fr417111/index.html">Conf√©rences en ligne: streaming vs webinaire</a></li>
<li><a href="../fr417113/index.html">Imprimante 3D italienne en Russie: Raise3D N1 Dual - mod√©lisation et prototypage</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
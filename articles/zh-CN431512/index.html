<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💅🏿 👍 🙇🏿 对简单的U-net（用于分段的经典卷积网络）的属性进行的小规模研究 🔥 🌘 💆🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="这篇文章是关于对海上寻找船只比赛的材料的分析和研究而写的。 



 让我们尝试了解网络寻找的方式和内容以及发现的内容。 本文只是出于好奇和闲置兴趣的结果，在实践中一无所获，对于实际任务，没有任何内容可供复制粘贴。 但是结果并不是完全预期的。 互联网上充斥着对网络操作的描述，作者在其中详细介绍了图像...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>对简单的U-net（用于分段的经典卷积网络）的属性进行的小规模研究</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/431512/"> 这篇文章是关于对海上寻找船只比赛的材料的分析和研究而写的。 <br><br><img src="https://habrastorage.org/webt/mu/kx/gb/mukxgbd0ziyg5hpxyf_ijb06yz0.png" alt="图片"><br><br> 让我们尝试了解网络寻找的方式和内容以及发现的内容。 本文只是出于好奇和闲置兴趣的结果，在实践中一无所获，对于实际任务，没有任何内容可供复制粘贴。 但是结果并不是完全预期的。 互联网上充斥着对网络操作的描述，作者在其中详细介绍了图像，并生动描述了网络如何确定原始元素（角度，圆，胡须，尾巴等），然后对其进行搜索以进行分段/分类。 使用来自其他大型和广域网络的权重，可以赢得很多比赛。 理解并了解网络是如何构建的以及什么构建了哪些原语是很有趣的。 <br><a name="habracut"></a><br> 我们将进行一次小型研究，并考虑各种选项-列出作者的推理和代码，您可以自己检查/补充/更改所有内容。 <br><br>  kaggle海洋搜索比赛最近结束了。 空中客车公司建议分析有船和无船的海洋卫星图像。 在总共192555张图片中，768x768x3 –如果是uint8，则为340 720 680 960字节；如果是float32，则为四倍（通过float32比float64更快，内存访问较少）；在15606张图片上，您需要找到船。 像往常一样，所有重要的地方都由参与ODS（ods.ai）的人员接替，这是自然而有希望的，我希望我们能够尽快学习思路和获胜者和获奖者的守则。 <br><br> 我们将考虑一个类似的问题，但要对其进行显着简化-取海np.random.sample（）* 0.5，我们不需要波浪，风，海滩和其他隐藏的图案和面孔。 让我们使海洋图像在0.0到0.5的RGB范围内真正随机。 我们将为船只涂上相同的颜色，并将它们与海区分开，将它们放置在0.5到1.0的范围内，并且它们的形状都相同-椭圆的大小和方向不同。 <br><br><img src="https://habrastorage.org/webt/yb/3w/gt/yb3wgteawunrk3urgpsxpnxugm4.png" alt="图片"><br><br> 使用非常通用的网络版本（您可以使用自己喜欢的网络），我们将使用它进行所有实验。 <br><br> 接下来，我们将更改图片的参数，创建干扰并建立假设-因此，我们重点介绍了网络查找椭圆的主要特征。 也许读者会得出结论并反驳作者。 <br><br><div class="spoiler">  <b class="spoiler_title">我们加载库，确定图片数组的大小</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm_notebook, tqdm <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> skimage.draw <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ellipse, polygon <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> EarlyStopping, ModelCheckpoint, ReduceLROnPlateau <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> load_model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.losses <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> binary_crossentropy <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm_notebook w_size = <span class="hljs-number"><span class="hljs-number">256</span></span> train_num = <span class="hljs-number"><span class="hljs-number">8192</span></span> train_x = np.zeros((train_num, w_size, w_size,<span class="hljs-number"><span class="hljs-number">3</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) train_y = np.zeros((train_num, w_size, w_size,<span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) img_l = np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>))*<span class="hljs-number"><span class="hljs-number">0.5</span></span> img_h = np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>))*<span class="hljs-number"><span class="hljs-number">0.5</span></span> + <span class="hljs-number"><span class="hljs-number">0.5</span></span> radius_min = <span class="hljs-number"><span class="hljs-number">10</span></span> radius_max = <span class="hljs-number"><span class="hljs-number">30</span></span></code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">确定损失和准确性函数</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_coef</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> y_true_f = K.flatten(y_true) y_pred = K.cast(y_pred, <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) y_pred_f = K.cast(K.greater(K.flatten(y_pred), <span class="hljs-number"><span class="hljs-number">0.5</span></span>), <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) intersection = y_true_f * y_pred_f score = <span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smooth = <span class="hljs-number"><span class="hljs-number">1.</span></span> y_true_f = K.flatten(y_true) y_pred_f = K.flatten(y_pred) intersection = y_true_f * y_pred_f score = (<span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bce_dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_iou_vector</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(A, B)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Numpy version batch_size = A.shape[0] metric = 0.0 for batch in range(batch_size): t, p = A[batch], B[batch] true = np.sum(t) pred = np.sum(p) # deal with empty mask first if true == 0: metric += (pred == 0) continue # non empty mask case. Union is never empty # hence it is safe to divide by its number of pixels intersection = np.sum(t * p) union = true + pred - intersection iou = intersection / union # iou metrric is a stepwise approximation of the real iou over 0.5 iou = np.floor(max(0, (iou - 0.45)*20)) / 10 metric += iou # teake the average over all images in batch metric /= batch_size return metric def my_iou_metric(label, pred): # Tensorflow version return tf.py_func(get_iou_vector, [label, pred &gt; 0.5], tf.float64) from keras.utils.generic_utils import get_custom_objects get_custom_objects().update({'bce_dice_loss': bce_dice_loss }) get_custom_objects().update({'dice_loss': dice_loss }) get_custom_objects().update({'dice_coef': dice_coef }) get_custom_objects().update({'my_iou_metric': my_iou_metric })</span></span></code> </pre><br></div></div><br> 我们在图像分割中使用经典指标，有很多文章，有关所选指标的带有注释的文本和代码，在同一kaggle上，有很多带有注释和解释的选项。 我们将预测像素的遮罩-这是“海”或“船”，并评估预测的真实性或虚假性。 即 以下四个选项是可能的-我们正确地预测像素是“海”，正确地预测像素是“船”，或者在预测“海”或“船”时出错。 因此，对于所有图片和所有像素，我们估计所有四个选项的数量并计算结果-这将是网络的结果。 错误的预测越少越准确，结果越准确，网络越好。 <br><br> 为了进行研究，让我们采用经过精心研究的u-net，它是用于图像分割的出色网络。 该网络在此类比赛中非常普遍，并且存在许多描述，应用程序的精妙之处等。 选择了经典U-net的变体，当然，可以对其进行升级，添加剩余块等。 但是“您不能拥抱巨大的事物”并立即进行所有实验和测试。  U-net对图片执行非常简单的操作-它通过逐步进行变换来减小图片的大小，然后尝试从压缩图像中恢复遮罩。 即 在本例中，图片的尺寸被设为32x32，然后我们尝试使用之前所有压缩中的数据来还原蒙版。 <br><br> 在图中，U-net方案来自原始文章，但我们对其进行了一些重编，但本质仍然相同-我们压缩图像→扩展为蒙版。 <br><br><img src="https://habrastorage.org/webt/un/ay/gn/unaygnyzsdhk_2dbk4qq2-2m340.png" alt="图片"><br><br><div class="spoiler">  <b class="spoiler_title">只是U网</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(input_layer, start_neurons)</span></span></span><span class="hljs-function">:</span></span> conv1 = Conv2D(start_neurons*<span class="hljs-number"><span class="hljs-number">1</span></span>,(<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>),activation=<span class="hljs-string"><span class="hljs-string">"relu"</span></span>, padding=<span class="hljs-string"><span class="hljs-string">"same"</span></span>)(input_layer) conv1 = Conv2D(start_neurons*<span class="hljs-number"><span class="hljs-number">1</span></span>,(<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>),activation=<span class="hljs-string"><span class="hljs-string">"relu"</span></span>, padding=<span class="hljs-string"><span class="hljs-string">"same"</span></span>)(conv1) pool1 = MaxPooling2D((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))(conv1) pool1 = Dropout(<span class="hljs-number"><span class="hljs-number">0.25</span></span>)(pool1) conv2 = Conv2D(start_neurons*<span class="hljs-number"><span class="hljs-number">2</span></span>,(<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>),activation=<span class="hljs-string"><span class="hljs-string">"relu"</span></span>, padding=<span class="hljs-string"><span class="hljs-string">"same"</span></span>)(pool1) conv2 = Conv2D(start_neurons*<span class="hljs-number"><span class="hljs-number">2</span></span>,(<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>),activation=<span class="hljs-string"><span class="hljs-string">"relu"</span></span>, padding=<span class="hljs-string"><span class="hljs-string">"same"</span></span>)(conv2) pool2 = MaxPooling2D((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))(conv2) pool2 = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(pool2) conv3 = Conv2D(start_neurons*<span class="hljs-number"><span class="hljs-number">4</span></span>,(<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>),activation=<span class="hljs-string"><span class="hljs-string">"relu"</span></span>, padding=<span class="hljs-string"><span class="hljs-string">"same"</span></span>)(pool2) conv3 = Conv2D(start_neurons*<span class="hljs-number"><span class="hljs-number">4</span></span>,(<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>),activation=<span class="hljs-string"><span class="hljs-string">"relu"</span></span>, padding=<span class="hljs-string"><span class="hljs-string">"same"</span></span>)(conv3) pool3 = MaxPooling2D((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))(conv3) pool3 = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(pool3) conv4 = Conv2D(start_neurons*<span class="hljs-number"><span class="hljs-number">8</span></span>,(<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>),activation=<span class="hljs-string"><span class="hljs-string">"relu"</span></span>, padding=<span class="hljs-string"><span class="hljs-string">"same"</span></span>)(pool3) conv4 = Conv2D(start_neurons*<span class="hljs-number"><span class="hljs-number">8</span></span>,(<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>),activation=<span class="hljs-string"><span class="hljs-string">"relu"</span></span>, padding=<span class="hljs-string"><span class="hljs-string">"same"</span></span>)(conv4) pool4 = MaxPooling2D((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))(conv4) pool4 = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(pool4) <span class="hljs-comment"><span class="hljs-comment"># Middle convm = Conv2D(start_neurons*16,(3,3),activation="relu", padding="same")(pool4) convm = Conv2D(start_neurons*16,(3,3),activation="relu", padding="same")(convm) deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding="same")(convm) uconv4 = concatenate([deconv4, conv4]) uconv4 = Dropout(0.5)(uconv4) uconv4 = Conv2D(start_neurons*8,(3,3),activation="relu", padding="same")(uconv4) uconv4 = Conv2D(start_neurons*8,(3,3),activation="relu", padding="same")(uconv4) deconv3 = Conv2DTranspose(start_neurons*4,(3,3),strides=(2, 2), padding="same")(uconv4) uconv3 = concatenate([deconv3, conv3]) uconv3 = Dropout(0.5)(uconv3) uconv3 = Conv2D(start_neurons*4,(3,3),activation="relu", padding="same")(uconv3) uconv3 = Conv2D(start_neurons*4,(3,3),activation="relu", padding="same")(uconv3) deconv2 = Conv2DTranspose(start_neurons*2,(3,3),strides=(2, 2), padding="same")(uconv3) uconv2 = concatenate([deconv2, conv2]) uconv2 = Dropout(0.5)(uconv2) uconv2 = Conv2D(start_neurons*2,(3,3),activation="relu", padding="same")(uconv2) uconv2 = Conv2D(start_neurons*2,(3,3),activation="relu", padding="same")(uconv2) deconv1 = Conv2DTranspose(start_neurons*1,(3,3),strides=(2, 2), padding="same")(uconv2) uconv1 = concatenate([deconv1, conv1]) uconv1 = Dropout(0.5)(uconv1) uconv1 = Conv2D(start_neurons*1,(3,3),activation="relu", padding="same")(uconv1) uconv1 = Conv2D(start_neurons*1,(3,3),activation="relu", padding="same")(uconv1) uncov1 = Dropout(0.5)(uconv1) output_layer = Conv2D(1,(1,1), padding="same", activation="sigmoid")(uconv1) return output_layer</span></span></code> </pre><br></div></div><br><h3> 第一个实验。 最简单的 </h3><br> 为了简化起见，我们选择了第一个实验版本-海洋更浅，船舶更暗。 一切都非常简单明了，我们假设网络将毫无问题地以任何精度找到船只/椭圆。  next_pair函数生成一对图片/遮罩，其中随机选择位置，大小，旋转角度。 此外，将对此功能进行所有更改-更改颜色，形状，干涉等。 但是，现在最简单的选择是，我们在浅色背景上测试暗船的假设。 <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> p = np.random.sample() - <span class="hljs-number"><span class="hljs-number">0.5</span></span> <span class="hljs-comment"><span class="hljs-comment">#    # r,c -    r = np.random.sample()*(w_size-2*radius_max) + radius_max c = np.random.sample()*(w_size-2*radius_max) + radius_max #      r_radius = np.random.sample()*(radius_max-radius_min) + radius_min c_radius = np.random.sample()*(radius_max-radius_min) + radius_min rot = np.random.sample()*360 #   rr, cc = ellipse( r, c, r_radius, c_radius, rotation=np.deg2rad(rot), shape=img_l.shape ) #     #   /    0.5  1.0 img = img_h.copy() #       0.0  0.5 img[rr, cc] = img_l[rr, cc] msk = np.zeros((w_size, w_size, 1), dtype='float32') msk[rr, cc] = 1. #     return img, msk</span></span></code> </pre><br> 我们生成了整个火车，看看发生了什么。 它看起来像海上的小船，仅此而已。 一切都清晰可见，清晰易懂。 该位置是随机的，每张图片中只有一个椭圆。 <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num): <span class="hljs-comment"><span class="hljs-comment">#   img train img, msk = next_pair() train_x[k] = img train_y[k] = msk fig, axes = plt.subplots(2, 10, figsize=(20, 5)) #    10   for k in range(10): axes[0,k].set_axis_off() axes[0,k].imshow(train_x[k]) axes[1,k].set_axis_off() axes[1,k].imshow(train_y[k].squeeze())</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/pf/cl/wa/pfclwaca6lntxzgsiplghwevvzk.png" alt="图片"><br><br> 毫无疑问，网络将成功学习并发现椭圆。 但是，让我们检验一下我们的假设，即该网络经过训练可以找到椭圆/船，并且同时具有很高的准确性。 <br><br><pre> <code class="python hljs">input_layer = Input((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>)) output_layer = build_model(input_layer, <span class="hljs-number"><span class="hljs-number">16</span></span>) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), metrics=[my_iou_metric]) model.save_weights(<span class="hljs-string"><span class="hljs-string">'./keras.weights'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: history = model.fit(train_x, train_y, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.1</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> history.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">0.75</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span></code> </pre> <br> <code>Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 55s 7ms/step - loss: 0.2272 - my_iou_metric: 0.7325 - val_loss: 0.0063 - val_my_iou_metric: 1.0000 <br> Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 53s 7ms/step - loss: 0.0090 - my_iou_metric: 1.0000 - val_loss: 0.0045 - val_my_iou_metric: 1.0000 <br></code> <br><br> 网络成功找到椭圆。 但这并不能完全证明她正在寻找关于人类的椭圆，因为椭圆区域是一个以椭圆方程为边界并填充有与背景不同的内容的区域，因此无法确定网络权重是否类似于二次椭圆方程的系数。 很明显，椭圆的亮度小于背景的亮度，并且没有秘密或谜语-我们假设我们只是检查了代码。 让我们修复明显的面孔，也使椭圆的背景和颜色随机。 <br><br><h3> 第二选择 </h3><br> 现在，相同的椭圆在同一条海洋上，但是海洋的颜色以及船的颜色是随机选择的。 如果海洋更黑，则船会更亮，反之亦然。 即 根据这组点的亮度，不可能确定它们是否在椭圆之外，即大海还是这些在椭圆内部。 再次，我们检验我们的假设，即网络将发现椭圆而不管颜色如何。 <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> p = np.random.sample() - <span class="hljs-number"><span class="hljs-number">0.5</span></span> <span class="hljs-comment"><span class="hljs-comment">#    / r = np.random.sample()*(w_size-2*radius_max) + radius_max c = np.random.sample()*(w_size-2*radius_max) + radius_max r_radius = np.random.sample()*(radius_max-radius_min) + radius_min c_radius = np.random.sample()*(radius_max-radius_min) + radius_min rot = np.random.sample()*360 rr, cc = ellipse( r, c, r_radius, c_radius, rotation=np.deg2rad(rot), shape=img_l.shape ) if p &gt; 0: #     img = img_l.copy() img[rr, cc] = img_h[rr, cc] else: #     img = img_h.copy() img[rr, cc] = img_l[rr, cc] msk = np.zeros((w_size, w_size, 1), dtype='float32') msk[rr, cc] = 1. return img, msk</span></span></code> </pre><br> 现在，通过像素及其周围环境，无法确定背景或椭圆形。 我们还生成图片和蒙版，并查看屏幕上的前10个。 <br><br><div class="spoiler">  <b class="spoiler_title">建筑面具</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num): img, msk = next_pair() train_x[k] = img train_y[k] = msk fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>): axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].imshow(train_x[k]) axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].imshow(train_y[k].squeeze())</code> </pre><br></div></div><br><br><img src="https://habrastorage.org/webt/fj/rz/vs/fjrzvsnrryaba58fxxb08mlmayu.png" alt="图片"><br><pre> <code class="python hljs">input_layer = Input((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>)) output_layer = build_model(input_layer, <span class="hljs-number"><span class="hljs-number">16</span></span>) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), metrics=[my_iou_metric]) model.load_weights(<span class="hljs-string"><span class="hljs-string">'./keras.weights'</span></span>, by_name=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: history = model.fit(train_x, train_y, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.1</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> history.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">0.75</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span></code> </pre> <br> <code>Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 56s 8ms/step - loss: 0.4652 - my_iou_metric: 0.5071 - val_loss: 0.0439 - val_my_iou_metric: 0.9005 <br> Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 55s 7ms/step - loss: 0.1418 - my_iou_metric: 0.8378 - val_loss: 0.0377 - val_my_iou_metric: 0.9206</code> <br> <br> 网络可以轻松应对并找到所有椭圆。 但是这里存在实现上的缺陷，而且一切都很明显-图片中两个区域中较小的一个是椭圆形，另一个背景。 也许这是一个错误的假设，但仍然可以解决，将另一个多边形添加到与椭圆颜色相同的图片上。 <br><br><h3> 第三选择 </h3><br> 在每张图片中，我们从两个选项中随机选择海洋的颜色，并添加一个椭圆和一个矩形，两者均与海洋的颜色不同。 原来是相同的“海洋”，也是涂漆的“船”，但是在同一张图片中，我们添加了与“船”相同颜色的矩形，并且具有随机选择的大小。 现在我们的假设更加复杂，在图片中有两个颜色相同的对象，但是我们假设网络仍将学习选择正确的对象。 <br><br><div class="spoiler">  <b class="spoiler_title">绘制椭圆和矩形的程序</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#        p = np.random.sample() - 0.5 r = np.random.sample()*(w_size-2*radius_max) + radius_max c = np.random.sample()*(w_size-2*radius_max) + radius_max r_radius = np.random.sample()*(radius_max-radius_min) + radius_min c_radius = np.random.sample()*(radius_max-radius_min) + radius_min rot = np.random.sample()*360 rr, cc = ellipse( r, c, r_radius, c_radius, rotation=np.deg2rad(rot), shape=img_l.shape ) p1 = np.rint(np.random.sample()*(w_size-2*radius_max) + radius_max) p2 = np.rint(np.random.sample()*(w_size-2*radius_max) + radius_max) p3 = np.rint(np.random.sample()*(2*radius_max - radius_min) + radius_min) p4 = np.rint(np.random.sample()*(2*radius_max - radius_min) + radius_min) #   /,    poly = np.array(( (p1, p2), (p1, p2+p4), (p1+p3, p2+p4), (p1+p3, p2), (p1, p2), )) rr_p, cc_p = polygon(poly[:, 0], poly[:, 1], img_l.shape) in_sc = list(set(rr) &amp; set(rr_p)) #   ,    #     #        if len(in_sc) &gt; 0: if np.mean(rr_p) &gt; np.mean(in_sc): poly += np.max(in_sc) - np.min(in_sc) else: poly -= np.max(in_sc) - np.min(in_sc) rr_p, cc_p = polygon(poly[:, 0], poly[:, 1], img_l.shape) if p &gt; 0: img = img_l.copy() img[rr, cc] = img_h[rr, cc] img[rr_p, cc_p] = img_h[rr_p, cc_p] else: img = img_h.copy() img[rr, cc] = img_l[rr, cc] img[rr_p, cc_p] = img_l[rr_p, cc_p] msk = np.zeros((w_size, w_size, 1), dtype='float32') msk[rr, cc] = 1. return img, msk</span></span></code> </pre><br></div></div><br> 和以前一样，我们计算图片和蒙版并查看前10对。 <br><br><div class="spoiler">  <b class="spoiler_title">建筑面具图片椭圆和矩形</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num): img, msk = next_pair() train_x[k] = img train_y[k] = msk fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>): axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].imshow(train_x[k]) axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].imshow(train_y[k].squeeze())</code> </pre><br></div></div><br><br><img src="https://habrastorage.org/webt/cg/p3/ak/cgp3ak3qbhsiecrrr2ge3mjxovc.png" alt="图片"><br><pre> <code class="python hljs">input_layer = Input((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>)) output_layer = build_model(input_layer, <span class="hljs-number"><span class="hljs-number">16</span></span>) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), metrics=[my_iou_metric]) model.load_weights(<span class="hljs-string"><span class="hljs-string">'./keras.weights'</span></span>, by_name=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: history = model.fit(train_x, train_y, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.1</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> history.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">0.75</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span></code> </pre><br> <code>Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 57s 8ms/step - loss: 0.7557 - my_iou_metric: 0.0937 - val_loss: 0.2510 - val_my_iou_metric: 0.4580 <br> Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 55s 7ms/step - loss: 0.0719 - my_iou_metric: 0.8507 - val_loss: 0.0183 - val_my_iou_metric: 0.9812</code> <br> <br> 不可能混淆网络的矩形，我们的假设得到了证实。 从实例和讨论来看，空客竞赛中的每个人都只有一艘船，几艘船都非常准确地在附近。 矩形的椭圆-即 即使多边形的颜色与椭圆相同，船还是来自岸上的房屋，网络也很明显。 这与颜色无关，因为椭圆和矩形均被随机地绘制。 <br><br><h3> 第四选择 </h3><br> 也许网络是用矩形来区分的-正确，使它们变形。 即 不论形状如何，网络都可以轻松找到两个封闭区域，并丢弃矩形区域。 这是作者的假设-我们将对其进行检查，为此我们将不添加矩形，而是添加任意形状的四边形多边形。 同样，我们的假设是网络将椭圆与相同颜色的任意四边形多边形区分开。 <br><br> 您当然可以进入网络的内部，然后查看各层并分析权重和班次的含义。 作者对网络的最终行为感兴趣；判断将基于工作的结果，尽管从内部看总是很有趣的。 <br><br><div class="spoiler">  <b class="spoiler_title">更改图像生成</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> p = np.random.sample() - <span class="hljs-number"><span class="hljs-number">0.5</span></span> r = np.random.sample()*(w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max c = np.random.sample()*(w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max r_radius = np.random.sample()*(radius_max-radius_min) + radius_min c_radius = np.random.sample()*(radius_max-radius_min) + radius_min rot = np.random.sample()*<span class="hljs-number"><span class="hljs-number">360</span></span> rr, cc = ellipse( r, c, r_radius, c_radius, rotation=np.deg2rad(rot), shape=img_l.shape ) p0 = np.rint(np.random.sample()*(radius_max-radius_min) + radius_min) p1 = np.rint(np.random.sample()*(w_size-radius_max)) p2 = np.rint(np.random.sample()*(w_size-radius_max)) p3 = np.rint(np.random.sample()*<span class="hljs-number"><span class="hljs-number">2.</span></span>*radius_min - radius_min) p4 = np.rint(np.random.sample()*<span class="hljs-number"><span class="hljs-number">2.</span></span>*radius_min - radius_min) p5 = np.rint(np.random.sample()*<span class="hljs-number"><span class="hljs-number">2.</span></span>*radius_min - radius_min) p6 = np.rint(np.random.sample()*<span class="hljs-number"><span class="hljs-number">2.</span></span>*radius_min - radius_min) p7 = np.rint(np.random.sample()*<span class="hljs-number"><span class="hljs-number">2.</span></span>*radius_min - radius_min) p8 = np.rint(np.random.sample()*<span class="hljs-number"><span class="hljs-number">2.</span></span>*radius_min - radius_min) poly = np.array(( (p1, p2), (p1+p3, p2+p4+p0), (p1+p5+p0, p2+p6+p0), (p1+p7+p0, p2+p8), (p1, p2), )) rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) in_sc = list(set(rr) &amp; set(rr_p)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(in_sc) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> np.mean(rr_p) &gt; np.mean(in_sc): poly += np.max(in_sc) - np.min(in_sc) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: poly -= np.max(in_sc) - np.min(in_sc) rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: img = img_l.copy() img[rr, cc] = img_h[rr, cc] img[rr_p, cc_p] = img_h[rr_p, cc_p] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: img = img_h.copy() img[rr, cc] = img_l[rr, cc] img[rr_p, cc_p] = img_l[rr_p, cc_p] msk = np.zeros((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) msk[rr, cc] = <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> img, msk</code> </pre><br></div></div><br> 我们计算图片和蒙版，并查看前10对。 <br><br><div class="spoiler">  <b class="spoiler_title">我们建立图片蒙版椭圆和多边形</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num): img, msk = next_pair() train_x[k] = img train_y[k] = msk fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>): axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].imshow(train_x[k]) axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].imshow(train_y[k].squeeze())</code> </pre><br></div></div><br><br><img src="https://habrastorage.org/webt/qc/hl/xu/qchlxu1uxvjmm5ooktztuw1ewbq.png" alt="图片"><br> 我们启动我们的网络。 让我提醒您，所有选项都相同。 <br><br><pre> <code class="python hljs">input_layer = Input((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>)) output_layer = build_model(input_layer, <span class="hljs-number"><span class="hljs-number">16</span></span>) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), metrics=[my_iou_metric]) model.load_weights(<span class="hljs-string"><span class="hljs-string">'./keras.weights'</span></span>, by_name=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: history = model.fit(train_x, train_y, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.1</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> history.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">0.75</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span></code> </pre><br> <code>Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 56s 8ms/step - loss: 0.6815 - my_iou_metric: 0.2168 - val_loss: 0.2078 - val_my_iou_metric: 0.4983 <br> Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 53s 7ms/step - loss: 0.1470 - my_iou_metric: 0.6396 - val_loss: 0.1046 - val_my_iou_metric: 0.7784 <br> Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 53s 7ms/step - loss: 0.0642 - my_iou_metric: 0.8586 - val_loss: 0.0403 - val_my_iou_metric: 0.9354 <br></code> <br> 假设得到证实，多边形和椭圆形很容易区分。 细心的读者会在这里注意到-当然，它们是不同的，这是胡说八道，任何正常的AI都可以区分第二阶曲线与第一阶曲线。 即 网络可以轻松地以二阶曲线的形式确定边界的存在。 我们不会争论，将椭圆形替换为七边形并进行检查。 <br><br><h3> 第五实验，最困难 </h3><br> 没有曲线，只有规则倾斜和旋转的七边形以及任意四边形多边形的光滑面。 我们将图像/遮罩生成器的更改引入功能中-仅投影正则七边形和相同颜色的任意四边形多边形。 <br><br><div class="spoiler">  <b class="spoiler_title">图像生成功能的最终修订版</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(_n = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">7</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> p = np.random.sample() - <span class="hljs-number"><span class="hljs-number">0.5</span></span> c_x = np.random.sample()*(w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max c_y = np.random.sample()*(w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max radius = np.random.sample()*(radius_max-radius_min) + radius_min d = np.random.sample()*<span class="hljs-number"><span class="hljs-number">0.5</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span> a_deg = np.random.sample()*<span class="hljs-number"><span class="hljs-number">360</span></span> a_rad = np.deg2rad(a_deg) poly = [] <span class="hljs-comment"><span class="hljs-comment">#    for k in range(_n): #     # _ _ -  poly.append(c_x+radius*math.sin(2.*k*math.pi/_n)) poly.append(c_y+radius*math.cos(2.*k*math.pi/_n)) # \  #    0.5  1.5  poly[-2] = (poly[-2]-c_x)/d +c_x poly[-1] = (poly[-1]-c_y) +c_y #     poly[-2] = ((poly[-2]-c_x)*math.cos(a_rad)\ - (poly[-1]-c_y)*math.sin(a_rad)) + c_x poly[-1] = ((poly[-2]-c_x)*math.sin(a_rad)\ + (poly[-1]-c_y)*math.cos(a_rad)) + c_y poly = np.rint(poly).reshape(-1,2) rr, cc = polygon(poly[:, 0], poly[:, 1], img_l.shape) p0 = np.rint(np.random.sample()*(radius_max-radius_min) + radius_min) p1 = np.rint(np.random.sample()*(w_size-radius_max)) p2 = np.rint(np.random.sample()*(w_size-radius_max)) p3 = np.rint(np.random.sample()*2.*radius_min - radius_min) p4 = np.rint(np.random.sample()*2.*radius_min - radius_min) p5 = np.rint(np.random.sample()*2.*radius_min - radius_min) p6 = np.rint(np.random.sample()*2.*radius_min - radius_min) p7 = np.rint(np.random.sample()*2.*radius_min - radius_min) p8 = np.rint(np.random.sample()*2.*radius_min - radius_min) poly = np.array(( (p1, p2), (p1+p3, p2+p4+p0), (p1+p5+p0, p2+p6+p0), (p1+p7+p0, p2+p8), (p1, p2), )) rr_p, cc_p = polygon(poly[:, 0], poly[:, 1], img_l.shape) in_sc = list(set(rr) &amp; set(rr_p)) if len(in_sc) &gt; 0: if np.mean(rr_p) &gt; np.mean(in_sc): poly += np.max(in_sc) - np.min(in_sc) else: poly -= np.max(in_sc) - np.min(in_sc) rr_p, cc_p = polygon(poly[:, 0], poly[:, 1], img_l.shape) if p &gt; 0: img = img_l.copy() img[rr, cc] = img_h[rr, cc] img[rr_p, cc_p] = img_h[rr_p, cc_p] else: img = img_h.copy() img[rr, cc] = img_l[rr, cc] img[rr_p, cc_p] = img_l[rr_p, cc_p] msk = np.zeros((w_size, w_size, 1), dtype='float32') msk[rr, cc] = 1. return img, msk</span></span></code> </pre><br></div></div><br> 和以前一样，我们构建数组并查看前10个。 <br><br><div class="spoiler">  <b class="spoiler_title">建筑面具</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num): img, msk = next_pair() train_x[k] = img train_y[k] = msk fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>): axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].imshow(train_x[k]) axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].imshow(train_y[k].squeeze())</code> </pre><br></div></div><br><img src="https://habrastorage.org/webt/ze/fs/lv/zefslv3lqpbtq2vuvk0usrvpua8.png" alt="图片"><br><pre> <code class="python hljs">input_layer = Input((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>)) output_layer = build_model(input_layer, <span class="hljs-number"><span class="hljs-number">16</span></span>) model = Model(input_layer, output_layer) model.compile(loss=dice_loss, optimizer=Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), metrics=[my_iou_metric]) model.load_weights(<span class="hljs-string"><span class="hljs-string">'./keras.weights'</span></span>, by_name=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: history = model.fit(train_x, train_y, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.1</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> history.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] &gt; <span class="hljs-number"><span class="hljs-number">0.75</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span></code> </pre><br> <code>Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 54s 7ms/step - loss: 0.5005 - my_iou_metric: 0.1296 - val_loss: 0.1692 - val_my_iou_metric: 0.3722 <br> Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 52s 7ms/step - loss: 0.1287 - my_iou_metric: 0.4522 - val_loss: 0.0449 - val_my_iou_metric: 0.6833 <br> Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 52s 7ms/step - loss: 0.0759 - my_iou_metric: 0.5985 - val_loss: 0.0397 - val_my_iou_metric: 0.7215 <br> Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 52s 7ms/step - loss: 0.0455 - my_iou_metric: 0.6936 - val_loss: 0.0297 - val_my_iou_metric: 0.7304 <br> Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 52s 7ms/step - loss: 0.0432 - my_iou_metric: 0.7053 - val_loss: 0.0215 - val_my_iou_metric: 0.7846 <br> Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 53s 7ms/step - loss: 0.0327 - my_iou_metric: 0.7417 - val_loss: 0.0171 - val_my_iou_metric: 0.7970 <br> Train on 7372 samples, validate on 820 samples <br> Epoch 1/1 <br> 7372/7372 [==============================] - 52s 7ms/step - loss: 0.0265 - my_iou_metric: 0.7679 - val_loss: 0.0138 - val_my_iou_metric: 0.8280</code> <br> <br><h3> 总结 </h3><br> 如您所见，网络在测试集上区分出正七边形和任意四边形多边形的投影，精度为0.828。 网络训练被0.75的任意值停止，最有可能的准确性应该要好得多。 如果我们从网络找到原语并且它们的组合确定对象这一论点出发，那么在我们的情况下，有两个区域与背景的平均值不同，在人类的理解中就没有原语了。 没有明显的单色线，也没有角，只有边界非常相似的区域。 即使您构建线，图片中的两个对象都是从相同的基元构建的。 <br><br> 鉴赏家的问题-该网络被视为是“船”与“干扰”区分开的标志？ 显然，这不是船只边界的颜色或形状。 当然，我们可以继续研究“海” /“船”的这种抽象构造，我们不是科学院，只能出于好奇而进行研究。 我们可以将七边形更改为八边形，或以规则的五角和六角填充图片，看看它们的网络是否可区分。 我将其留给读者-尽管我也想知道网络是否可以计算多边形的角点数量，并且为了进行测试，在图片中不排列规则的多边形，而是排列它们的随​​机投影。 <br><br> 这种船还有其他同样有趣的特性，这种实验的用处在于我们自己设置了研究集合的所有概率特征，而经过精心研究的网络的意外行为将增加知识并带来收益。 <br><br> 随机选择背景，随机选择颜色，随机选择船/椭圆位置。 图片中没有线条，存在具有不同特征的区域，但是没有单色线条！ 在这种情况下，当然会有简化，并且任务可能会更加复杂-例如，选择0.0 ... 0.9和0.1 ... 1.0之类的颜色-但对于网络而言则没有区别。 网络可以发现与人们清楚看到和发现的模式不同的模式。 <br><br> 如果其中一位读者感兴趣，则可以继续在网络上进行研究和挑选，如果无法解决或不清楚的事物，或者出现了新的好想法并给它留下深刻的印象，那么您可以随时与我们分享或询问大师（也包括大师）并在ODS社区寻求合格的帮助。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN431512/">https://habr.com/ru/post/zh-CN431512/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN431502/index.html">iOS开发人员Kolesa Mobile 3.0会议。 影片报告</a></li>
<li><a href="../zh-CN431504/index.html">网络钓鱼-作品。 iPhone XS盗窃纪事，然后是iCloud数据盗窃</a></li>
<li><a href="../zh-CN431506/index.html">LLDB中的Xcode和高级调试：第1部分</a></li>
<li><a href="../zh-CN431508/index.html">春季高效的交易管理</a></li>
<li><a href="../zh-CN431510/index.html">如何从轮廓中收集信息。</a></li>
<li><a href="../zh-CN431514/index.html">面试官面试</a></li>
<li><a href="../zh-CN431516/index.html">财务顾问生活中的一天</a></li>
<li><a href="../zh-CN431518/index.html">Microsoft Connect（）; 莫斯科聚会</a></li>
<li><a href="../zh-CN431520/index.html">使用RFM方法预测用户流失</a></li>
<li><a href="../zh-CN431524/index.html">Java中的序列化。 没那么简单</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
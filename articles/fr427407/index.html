<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèΩ‚Äçüéì ‚ö°Ô∏è üò† M√©ta-clustering avec minimisation des erreurs, et pourquoi je pense que le cerveau fonctionne de cette fa√ßon üï° üë©üèΩ‚Äçüöí üëµüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour √† tous! Je veux partager avec vous mon id√©e du machine learning. 

 Les grandes avanc√©es de l'apprentissage automatique sont impressionnantes....">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>M√©ta-clustering avec minimisation des erreurs, et pourquoi je pense que le cerveau fonctionne de cette fa√ßon</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/427407/">  Bonjour √† tous!  Je veux partager avec vous mon id√©e du machine learning. <br><br>  Les grandes avanc√©es de l'apprentissage automatique sont impressionnantes.  Les r√©seaux convolutionnels et les LSTM sont cool.  Mais presque toutes les technologies modernes sont bas√©es sur la propagation inverse de l'erreur.  Sur la base de cette m√©thode, il est peu probable de pouvoir construire une machine √† penser.  Les r√©seaux de neurones sont constitu√©s de quelque chose comme un cerveau gel√©, form√© une fois pour toutes, incapable de <strike>changer la</strike> pens√©e. <br><br>  J'ai pens√©, pourquoi ne pas essayer de cr√©er quelque chose comme un cerveau vivant.  Une sorte de r√©ing√©nierie.  √âtant donn√© que chez tous les animaux, malgr√© les diff√©rences d'intelligence, le cerveau est compos√© approximativement des m√™mes neurones, un principe de base devrait √™tre au c≈ìur de son travail. <br><a name="habracut"></a><br><h2>  Ce que je ne sais pas sur les neurones </h2><br>  Il y a plusieurs questions auxquelles je n'ai pas trouv√© de r√©ponses sans ambigu√Øt√© dans la litt√©rature populaire; <br><br><ul><li>  De toute √©vidence, un neurone r√©pond en quelque sorte aux neurotransmetteurs, mais comment exactement?  L'hypoth√®se simple selon laquelle plus le neurotransmetteur est grand, plus les adh√©rences sont fr√©quentes ne r√©siste √©videmment pas √† la critique.  S'il en √©tait ainsi, le d√©clenchement d'un neurone d√©clencherait le d√©clenchement de plusieurs voisins, ceux du suivant, et en peu de temps cette avalanche capturerait tout le cerveau.  Mais en r√©alit√©, cela ne se produit pas, en m√™me temps, seule une petite partie des neurones fonctionne dans le cerveau.  Pourquoi? </li><li>  Les neurones sont √©videmment des unit√©s de m√©moire, mais comment stockent-ils les informations?  La partie centrale du neurone n'a rien de sp√©cial: le noyau des mitochondries et similaires.  Axon ne peut pas influencer le pic, car les informations ne vont que dans une seule direction, depuis le noyau.  Donc, la seule chose qui reste, ce sont les dendrites.  Mais comment les informations y sont-elles stock√©es?  Sous forme analogique ou num√©rique? </li><li>  De toute √©vidence, les neurones apprennent en quelque sorte.  Mais comment exactement?  Supposons que les dendrites poussent dans des endroits o√π il y avait beaucoup de neurotransmetteurs juste avant le pic.  Mais si c'est le cas, le neurone d√©clench√© se d√©veloppera un peu et la prochaine fois qu'un neurotransmetteur appara√Ætra, ce sera le plus √©pais parmi les voisins, il absorbera la plupart du neurotransmetteur et fonctionnera √† nouveau.  Et encore un peu grandir.  Et ainsi de suite √† l'infini, jusqu'√† ce qu'il √©trangle tous ses voisins?  Quelque chose ne va pas ici? </li><li>  Si un neurone se d√©veloppe, les voisins devraient diminuer, la t√™te n'est pas en caoutchouc.  Quelque chose devrait faire s√©cher le neurone.  Quoi? </li></ul><br><h2>  Cluster juste </h2><br>  La r√©ponse plausible √† toutes ces questions me semble que le cerveau fonctionne comme beaucoup de clusters simples.  Est-il possible d'ex√©cuter un tel algorithme sur un groupe de neurones?  Par exemple, la m√©thode K-means.  Il suffit juste de le simplifier un peu.  Dans l'algorithme classique, les centres sont calcul√©s de mani√®re it√©rative comme la moyenne de tous les exemples consid√©r√©s, mais nous d√©placerons le centre imm√©diatement apr√®s chaque exemple. <br><br>  Voyons ce dont nous avons besoin pour impl√©menter l'algorithme de clustering. <br><br><ul><li>  Les centres de clusters, bien s√ªr, sont les dendrites des neurones de notre groupe.  Mais comment retenir les informations?  Supposons que la cellule unitaire pour stocker des informations dans la dendrite soit le volume de la branche dendrite dans la r√©gion de synapse.  Plus la branche est √©paisse, respectivement, son volume est plus grand, plus la valeur est enregistr√©e.  Ainsi, chaque dendrite peut m√©moriser plusieurs quantit√©s analogiques. </li><li>  Comparateurs pour calculer la proximit√© d'un exemple.  C'est plus compliqu√©.  Supposons qu'apr√®s la soumission des donn√©es (les axones ont √©ject√© un neurotransmetteur), chaque neurone fonctionnera plus vite, plus les donn√©es stock√©es (le centre du cluster) seront similaires √† l'exemple donn√© (le nombre de neurotransmetteurs).  Veuillez noter que le taux de r√©ponse d'un neurone n'est pas affect√© par la quantit√© absolue de neurotransmetteur, mais plut√¥t par la proximit√© de la quantit√© de neurotransmetteur avec la valeur stock√©e dans les dendrites.  Supposons que si le neurotransmetteur est petit, alors la dendrite ne donne pas l'ordre de piquer.  Rien ne se passe et s'il y a beaucoup de neurotransmetteur, le pic de la branche dendritique se produit plus t√¥t que dans les autres branches dendritiques et n'atteint pas le noyau.  Mais si le neurotransmetteur est juste, alors toutes les branches dendritiques donneront un mini-pic √† peu pr√®s au m√™me moment, et cette onde se transformera en pic d'un neurone qui ira le long de l'axone. </li><li>  Un comparateur √† entr√©es multiples vous permet de comparer les r√©sultats et de choisir le meilleur.  Supposons que les neurones voisins ont un effet inhibiteur sur tous leurs voisins.  Ainsi, dans un certain groupe de neurones, un seul peut √™tre actif √† tout moment.  Celui qui a fonctionn√© en premier.  √âtant donn√© que les neurones du groupe sont proches, ils ont le m√™me acc√®s √† tous les axones venant de ce groupe.  Ainsi, le neurone dans lequel les informations stock√©es sont les plus proches de l'exemple en question fonctionnera dans le groupe. </li><li>  Le m√©canisme de d√©placement du centre vers l'exemple.  Eh bien, tout est simple.  Apr√®s la pointe du neurone, toutes les dendrites de ce neurone changent de volume.  L√† o√π la concentration du neurotransmetteur √©tait trop √©lev√©e, les branches se d√©veloppent.  L√† o√π elle √©tait insuffisante, les rameaux sont r√©duits.  L√† o√π la concentration est juste, le volume ne change pas.  Les volumes de brindilles varient un peu.  Mais tout de suite.  Le prochain pic est le prochain changement. </li></ul><br>  V√©rifions l'algorithme r√©sultant dans la pratique.  J'ai esquiss√© quelques lignes en Python.  Voici ce qui se passe avec deux dimensions de nombres al√©atoires: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2a4/5b2/a12/2a45b2a122a9536cf95e3768af65d4f2.gif"></div><br>  Et voici MNIST: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ceb/6a5/61a/ceb6a561a711c640904a74d1443fa706.gif"></div><br>  √Ä premi√®re vue, il semble que tout ce qui pr√©c√®de n'a rien chang√©.  Eh bien, nous avions des donn√©es √† l'entr√©e, nous les avons transform√©es d'une mani√®re ou d'une autre, nous avons obtenu d'autres donn√©es. <br><br>  Mais il y a vraiment une diff√©rence.  Si avant la conversion, nous avions un tas de param√®tres analogiques, alors apr√®s la conversion, nous n'avons qu'un seul param√®tre, en m√™me temps cod√© par un code unitaire.  Chaque neurone du groupe peut √™tre associ√© √† une action sp√©cifique. <br><br>  Permettez-moi de donner un exemple: supposons qu'il n'y ait que deux neurones dans un groupe de clustering.  Appelez-les ¬´TASTY¬ª et ¬´SCARY¬ª.  Afin de permettre au cerveau de prendre une d√©cision, il suffit de connecter le neurone ¬´EAT¬ª au premier, et ¬´RUN¬ª au second.  Pour cela, nous avons besoin d'un enseignant.  Mais maintenant, ce n'est pas √ßa, enseigner avec un professeur est un sujet pour un autre article. <br><br>  Si vous augmentez le nombre de clusters, la pr√©cision augmentera progressivement.  Un cas extr√™me est le nombre de clusters √©gal au nombre d'exemples.  Mais il y a un probl√®me, le nombre de neurones dans le cerveau est limit√©.  Il faut constamment compromettre, soit la pr√©cision, soit la taille du cerveau. <br><br><h2>  Meta clustering </h2><br>  Supposons que nous ayons non pas un groupe de clustering, mais deux.  Dans ce cas, les m√™mes valeurs sont appliqu√©es aux entr√©es.  De toute √©vidence, vous obtenez le m√™me r√©sultat. <br><br>  Faisons une petite erreur al√©atoire.  Soit, parfois, chaque clusteriseur s√©lectionne non pas le centre le plus proche du cluster, mais lequel.  Ensuite, les valeurs commenceront √† diff√©rer, au fil du temps, la diff√©rence s'accumulera. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/844/742/6ce/8447426cea375229e23546b4be16ee1b.gif"></div><br>  Et maintenant, calculons l'erreur de chaque cluster.  L'erreur est la diff√©rence entre l'exemple d'entr√©e et le centre du cluster s√©lectionn√©.  Si un cluster a s√©lectionn√© la valeur la plus proche et l'autre al√©atoire, le second aura une erreur plus importante. <br><br>  Allez-y, ajoutez un masque √† l'entr√©e de chaque cluster.  Un masque est un ensemble de coefficients pour chaque entr√©e.  Pas z√©ro ou un, comme cela est couramment utilis√© dans les masques, mais un certain nombre r√©el de z√©ro √† un. <br><br>  Avant de donner un exemple √† l'entr√©e du cluster, nous multiplierons cet exemple par un masque.  Par exemple, si un masque est utilis√© pour une image, alors si pour un pixel le masque est √©gal √† un, c'est comme s'il √©tait compl√®tement transparent.  Et si le masque est nul, ce pixel est toujours noir.  Et si le masque est 1/2, alors le pixel est √† moiti√© assombri. <br><br>  Et maintenant l'action principale, nous allons r√©duire la valeur du masque proportionnellement √† l'erreur de clustering.  Autrement dit, si l'erreur est importante, alors nous diminuerons la valeur plus fortement, et si elle est nulle, nous ne la r√©duirons pas du tout. <br><br>  Afin que les valeurs des masques ne soient pas progressivement remises √† z√©ro, nous les normaliserons.  Autrement dit, la somme des valeurs de masque pour chaque param√®tre d'entr√©e est toujours √©gale √† un.  Si quelque chose est enlev√© dans un masque, il est ajout√© √† un autre. <br><br>  Essayons de voir ce qui se passe avec l'exemple du MNIST.  On voit que les masques divisent progressivement les pixels en deux parties. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/39c/204/a45/39c204a45731b8408b14cb9621cd91b0.gif"></div><br>  Les masques r√©sultants sont affich√©s sur le c√¥t√© droit de l'image.  √Ä la fin du processus, le clusteriseur sup√©rieur consid√®re le coin inf√©rieur droit et le clusteriseur inf√©rieur le reste des exemples.  Fait int√©ressant, si nous relan√ßons le processus, nous obtiendrons une autre s√©paration.  Mais en m√™me temps, les groupes de param√®tres sont obtenus non pas au hasard, mais de mani√®re √† r√©duire l'erreur de pr√©diction.  Les clusters semblent essayer chaque pixel pour leur masque, et en m√™me temps, le pixel prend le clusterizer auquel le pixel convient le mieux. <br><br>  Essayons d'entrer deux chiffres, non superpos√©s les uns aux autres, mais situ√©s c√¥te √† c√¥te, comme ceci (c'est un exemple, pas deux): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9ee/675/145/9ee6751458d904e22d9d286e704084eb.jpg" alt="image"></div><br>  Maintenant, nous voyons qu'√† chaque fois, la s√©paration se produit de la m√™me mani√®re.  Autrement dit, s'il existe un seul, clairement la meilleure option pour s√©parer les masques, il sera s√©lectionn√©. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/48b/55c/487/48b55c4877b5938ed22f5473bb4fb033.gif"></div><br>  Une seule chose sera al√©atoire, que le premier masque s√©lectionne le chiffre de gauche ou celui de droite. <br><br>  J'appelle les m√©ta-clusters de masques r√©sultants.  Et le processus de formation de masques par m√©ta-clustering.  Pourquoi meta?  Parce que le clustering n'est pas des exemples d'entr√©e, mais des entr√©es elles-m√™mes. <br><br>  Un exemple est plus compliqu√©.  Essayons de diviser 25 param√®tres en 5 m√©ta-clusters. <br><br>  Pour ce faire, nous prenons cinq groupes de cinq param√®tres cod√©s par un code unitaire. <br><br>  Autrement dit, dans chaque groupe, il y a une et une seule unit√© dans un endroit al√©atoire.  Il y a toujours cinq unit√©s dans chaque exemple servi. <br><br>  Dans les images ci-dessous, chaque colonne est un param√®tre d'entr√©e et chaque ligne est un masque de m√©ta-cluster.  Les grappes elles-m√™mes ne sont pas repr√©sent√©es. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/95e/a47/42b/95ea4742b10e16dac89d9a27dc02822a.gif"></div><br>  100 param√®tres et 10 m√©ta-clusters: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/55a/632/b55/55a632b5503d6b4c439c8905d1bdf46b.gif"></div><br>  √áa marche!  √Ä certains endroits, il ressemble m√™me l√©g√®rement √† une image d'une matrice du film du m√™me nom. <br><br>  L'utilisation du m√©ta-clustering peut r√©duire consid√©rablement le nombre de clusters. <br><br>  Par exemple, prenez dix groupes de dix param√®tres, chaque groupe a une unit√©. <br><br>  Si nous avons un clusteriseur (pas de m√©ta-clusters), alors nous avons besoin de 10 <sup>10</sup> = 10000000000 clusters pour obtenir une erreur nulle. <br><br>  Et si nous avons dix grappes, nous n'avons besoin que de 10 * 10 = 100 grappes.  Ceci est similaire au syst√®me de nombres d√©cimaux, vous n'avez pas besoin de trouver une notation pour tous les nombres possibles, vous pouvez le faire avec dix chiffres. <br><br>  Le m√©ta-clustering est tr√®s bien parall√©lis√©.  Les calculs les plus co√ªteux (en comparant l'exemple avec le centre du cluster) peuvent √™tre effectu√©s ind√©pendamment pour chaque cluster.  Veuillez noter, non pas pour le clustering, mais pour le cluster. <br><br><h2>  Comment √ßa marche dans le cerveau </h2><br>  Avant cela, je ne parlais que des dendrites, mais les neurones ont des axones.  Et ils √©tudient aussi.  Il est donc tr√®s probable que les axones soient les masques des m√©ta-grappes. <br><br>  Nous ajoutons une fonction suppl√©mentaire √† la description de l'op√©ration dendrite ci-dessus. <br><br>  Supposons que si un pic neuronal se produit, toutes les dendrites √©mettent d'une mani√®re ou d'une autre dans la synapse une sorte de substance qui montre la concentration du neurotransmetteur dans la dendrite.  Pas de l'axone √† la dendrite, mais en arri√®re.  La concentration de cette substance d√©pend de l'erreur de comparaison.  Supposons que plus l'erreur est petite, plus la quantit√© de substance √©mise est grande.  Eh bien, l'axone r√©agit √† la quantit√© de cette substance et se d√©veloppe.  Et si la substance est petite, ce qui signifie une grosse erreur, alors l'axone est progressivement r√©duit. <br><br>  Et si vous changez les axones d√®s la naissance m√™me du cerveau, au fil du temps, ils n'iront que vers les groupes de neurones o√π leurs adh√©rences √† ces axones sont n√©cessaires (ne conduisent pas √† de grosses erreurs). <br><br>  Exemple: souvenons-nous des visages humains.  Que chaque visage soit repr√©sent√© avec une image m√©gapixel.  Ensuite, pour chaque visage, vous avez besoin d'un neurone avec un million de dendrites, ce qui est irr√©aliste.  Maintenant, divisez tous les pixels en m√©ta-clusters, tels que les yeux, le nez, les oreilles, etc.  Seulement dix de ces m√©ta-grappes.  Soit dix grappes, dix options de nez, dix options d'oreille, etc. pour chaque m√©ta-grappe.  Maintenant, pour se souvenir du visage, un neurone avec dix dendrites suffit.  Cela r√©duit la m√©moire (et le volume du cerveau) de cinq ordres de grandeur. <br><br><h2>  Conclusion </h2><br>  Et maintenant, si nous supposons que le cerveau est constitu√© de m√©ta-clusters, nous pouvons essayer de consid√©rer de ce point de vue certains concepts inh√©rents au cerveau vivant: <br><br>  Les clusters doivent √™tre constamment form√©s, sinon les nouvelles donn√©es ne seront pas trait√©es correctement.  Pour former des grappes dans le cerveau, un √©chantillon √©quilibr√© est n√©cessaire.  Permettez-moi d'expliquer si l'hiver est maintenant, alors le cerveau n'apprendra que des exemples d'hiver, et les grappes r√©sultantes deviendront progressivement pertinentes uniquement pour l'hiver, et en √©t√©, tout sera mauvais pour ce cerveau.  Que faire √† ce sujet?  Il est n√©cessaire de soumettre p√©riodiquement √† tous les clusters non seulement de nouveaux, mais aussi d'anciens exemples importants (souvenirs d'hiver et d'√©t√©).  Et pour que ces sentiments n'interf√®rent pas avec les sentiments actuels, vous devez temporairement d√©sactiver les sens.  Chez les animaux, cela s'appelle un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√™ve</a> . <br><br>  Imaginez, le cerveau voit quelque chose de petit, GRIS, qui court.  Apr√®s m√©ta-clustering, nous avons trois neurones actifs dans trois m√©ta-clusters.  Et gr√¢ce √† la m√©moire, le cerveau sait que c'est d√©licieux.  Ensuite, le cerveau voit quelque chose de petit, BLEU qui court.  Mais le cerveau ne sait pas s'il est savoureux ou effrayant.  Il suffit de d√©sactiver temporairement le m√©ta-cluster o√π se trouvent les couleurs, et seul le petit qui s'ex√©cute restera.  Et le cerveau sait que c'est d√©licieux.  C'est ce qu'on appelle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">une analogie</a> . <br><br>  Supposons que le cerveau se souvienne de quelque chose, puis change le cluster de neurones actif dans un groupe en un autre, tandis que dans les m√©ta-clusters restants, il y a une vraie m√©moire.  Et maintenant, le cerveau a d√©j√† introduit quelque chose qui n'a jamais √©t√© vu auparavant.  Et c'est d√©j√† une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">imagination</a> . <br><br>  Merci de votre attention, le code est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr427407/">https://habr.com/ru/post/fr427407/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr427397/index.html">D√©veloppement d'un ensemble de donn√©es acoustiques pour la formation d'un r√©seau neuronal</a></li>
<li><a href="../fr427399/index.html">Utilisation de donn√©es lors de la cr√©ation d'une API bas√©e sur GraphQL</a></li>
<li><a href="../fr427401/index.html">Shaders de dissolution et exploration du monde</a></li>
<li><a href="../fr427403/index.html">API ReportingObserver: un regard sur le code des pages web sous un nouvel angle</a></li>
<li><a href="../fr427405/index.html">ES2018 - enfin promet m√©thode</a></li>
<li><a href="../fr427409/index.html">Le livre "The Brilliant Agile. Gestion de projet flexible avec Agile, Scrum et Kanban ¬ª</a></li>
<li><a href="../fr427413/index.html">Lutter pour les ressources, partie 4: grand</a></li>
<li><a href="../fr427415/index.html">Nous utilisons Node.js pour travailler avec des fichiers volumineux et des ensembles de donn√©es brutes.</a></li>
<li><a href="../fr427417/index.html">Avec de l'humour sur des disquettes de 8 pouces (dans les ann√©es 70, il n'y en avait que)</a></li>
<li><a href="../fr427419/index.html">Que faire lorsque le processeur n'a rien √† faire?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
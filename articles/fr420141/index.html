<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õÖÔ∏è üëµüèø üçü Depuis le SGBD MPP charg√© - Data Lake dynamique avec des outils d'analyse: partagez les d√©tails de la cr√©ation üöÅ üíÉüèΩ ‚¨áÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Toutes les organisations qui ont au moins quelque chose √† voir avec les donn√©es, t√¥t ou tard, sont confront√©es au probl√®me du stockage des bases de do...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Depuis le SGBD MPP charg√© - Data Lake dynamique avec des outils d'analyse: partagez les d√©tails de la cr√©ation</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/vtb/blog/420141/">  Toutes les organisations qui ont au moins quelque chose √† voir avec les donn√©es, t√¥t ou tard, sont confront√©es au probl√®me du stockage des bases de donn√©es relationnelles et non structur√©es.  Il n'est pas facile de trouver une approche pratique, efficace et peu co√ªteuse de ce probl√®me √† la fois.  Et pour vous assurer que les scientifiques des donn√©es peuvent travailler avec succ√®s avec des mod√®les d'apprentissage automatique.  Nous l'avons fait - et m√™me si j'ai d√ª le bricoler, le b√©n√©fice final a √©t√© encore plus que pr√©vu.  Nous discuterons de tous les d√©tails ci-dessous. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/755/bd0/32c/755bd032c95a1b46c4f412d65c5a7bf4.png"><br><a name="habracut"></a><br>  Au fil du temps, des quantit√©s incroyables de donn√©es d'entreprise s'accumulent dans n'importe quelle banque.  Un montant comparable n'est stock√© que dans les soci√©t√©s Internet et les t√©l√©communications.  Cela s'est produit en raison des exigences r√©glementaires √©lev√©es.  Ces donn√©es ne sont pas inutiles - les dirigeants des institutions financi√®res ont depuis longtemps compris comment en tirer profit. <br><br>  Nous avons tous commenc√© par la gestion et les rapports financiers.  Sur la base de ces donn√©es, nous avons appris √† prendre des d√©cisions commerciales.  Il √©tait souvent n√©cessaire d'obtenir des donn√©es de plusieurs syst√®mes d'information de la banque, pour lesquels nous avons cr√©√© des bases de donn√©es consolid√©es et des syst√®mes de reporting.  De cela s'est form√© progressivement ce qu'on appelle aujourd'hui un entrep√¥t de donn√©es.  Bient√¥t, sur la base de ce stockage, nos autres syst√®mes ont commenc√© √† fonctionner: <br><br><ul><li>  CRM analytique, permettant d'offrir au client des produits plus pratiques pour lui; <br></li><li>  des convoyeurs de pr√™t qui vous aident √† prendre une d√©cision rapide et pr√©cise sur un pr√™t; <br></li><li>  des syst√®mes de fid√©lit√© calculant des cashbacks ou des points bonus selon des m√©canismes de complexit√© variable. <br></li></ul><br>  Toutes ces t√¢ches sont r√©solues par des applications analytiques qui utilisent des mod√®les d'apprentissage automatique.  Plus les mod√®les d'informations peuvent prendre du r√©f√©rentiel, plus ils fonctionneront avec pr√©cision.  Leur besoin de donn√©es augmente de fa√ßon exponentielle. <br><br>  √Ä propos de cette situation, nous sommes arriv√©s il y a deux ou trois ans.  √Ä l'√©poque, nous disposions d'un stockage bas√© sur le SGBD MPP Teradata utilisant l'outil SAS Data Integration Studio ELT.  Nous avons construit ce magasin depuis 2011 en collaboration avec Glowbyte Consulting.  Plus de 15 grands syst√®mes bancaires y ont √©t√© int√©gr√©s, et en m√™me temps, suffisamment de donn√©es ont √©t√© accumul√©es pour la mise en ≈ìuvre et le d√©veloppement d'applications analytiques.  Soit dit en passant, juste √† ce moment-l√†, le volume de donn√©es dans les couches principales du magasin, en raison de nombreuses t√¢ches diff√©rentes, a commenc√© √† cro√Ætre de mani√®re non lin√©aire, et l'analyse client avanc√©e est devenue l'une des principales directions du d√©veloppement de la banque.  Oui, et nos scientifiques des donn√©es √©taient impatients de la soutenir.  En g√©n√©ral, pour construire la plateforme de recherche de donn√©es, les √©toiles se sont form√©es comme il se doit. <br><br><h2>  Planifier une solution </h2><br>  Ici, il faut expliquer: les logiciels industriels et les serveurs sont un plaisir cher m√™me pour une grande banque.  Toutes les organisations ne peuvent pas se permettre de stocker une grande quantit√© de donn√©es dans le SGBD MPP sup√©rieur.  Il faut toujours faire un choix entre prix et rapidit√©, fiabilit√© et volume. <br><br>  Pour tirer le meilleur parti des opportunit√©s disponibles, nous avons d√©cid√© de proc√©der comme suit: <br><br><ul><li> La charge ELT et la partie la plus demand√©e des donn√©es historiques du CD doivent √™tre laiss√©es sur le SGBD Teradata; <br></li><li>  exp√©diez l'histoire compl√®te √† Hadoop, ce qui vous permet de stocker des informations beaucoup moins cher. <br></li></ul><br>  √Ä cette √©poque, l'√©cosyst√®me Hadoop est devenu non seulement √† la mode, mais aussi suffisamment fiable et pratique pour une utilisation en entreprise.  Il fallait choisir un kit de distribution.  Vous pouvez cr√©er le v√¥tre ou utiliser Apache Hadoop ouvert.  Mais parmi les solutions d'entreprise bas√©es sur Hadoop, les distributions toutes faites d'autres fournisseurs - Cloudera et Hortonworks - ont fait leurs preuves.  Par cons√©quent, nous avons √©galement d√©cid√© d'utiliser une distribution pr√™te √† l'emploi. <br><br>  √âtant donn√© que notre t√¢che principale consistait toujours √† stocker des donn√©es volumineuses structur√©es, dans la pile Hadoop, nous √©tions int√©ress√©s par des solutions aussi proches que possible des SGBD SQL classiques.  Les dirigeants ici sont Impala et Hive.  Cloudera d√©veloppe et int√®gre les solutions Impala, Hortonworks - Hive. <br><br>  Pour une √©tude approfondie, nous avons organis√© des tests de charge pour les deux SGBD, en tenant compte de la charge de profil pour nous.  Je dois dire que les moteurs de traitement des donn√©es dans Impala et Hive sont sensiblement diff√©rents - Hive pr√©sente g√©n√©ralement plusieurs options diff√©rentes.  Cependant, le choix est tomb√© sur Impala - et, par cons√©quent, la distribution de Cloudera. <br><br><h2>  Ce que j'ai aim√© chez Impala </h2><br><ul><li>  <i>Grande vitesse d'ex√©cution des requ√™tes analytiques</i> gr√¢ce √† une approche alternative par rapport √† MapReduce.  Les r√©sultats interm√©diaires des calculs ne se replient pas dans HDFS, ce qui acc√©l√®re consid√©rablement le traitement des donn√©es. <br></li><li>  <i>Travail efficace avec stockage de donn√©es de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">parquet</a> dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Parquet</a> .</i>  Pour les t√¢ches analytiques, les tables dites larges avec de nombreuses colonnes sont souvent utilis√©es.  Toutes les colonnes sont rarement utilis√©es - la possibilit√© de lever √† partir de HDFS uniquement celles qui sont n√©cessaires au travail vous permet d'√©conomiser de la RAM et d'acc√©l√©rer consid√©rablement la demande. <br></li><li>  <i>Une solution √©l√©gante avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des filtres d'ex√©cution</a> qui incluent le filtrage de floraison.</i>  Hive et Impala sont tous deux limit√©s dans leur utilisation des index communs aux SGBD classiques en raison de la nature du syst√®me de stockage de fichiers HDFS.  Par cons√©quent, pour optimiser l'ex√©cution de la requ√™te SQL, le moteur de SGBD doit utiliser efficacement le partitionnement disponible m√™me s'il n'est pas explicitement sp√©cifi√© dans les conditions de la requ√™te.  En outre, il doit essayer de pr√©dire la quantit√© minimale de donn√©es de HDFS qui doit √™tre augment√©e pour garantir le traitement de toutes les lignes.  √Ä Impala, cela fonctionne tr√®s bien. <br></li><li>  <i>Impala <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">utilise LLVM</a></i> , un compilateur de machine virtuelle avec des instructions de type RISC, pour g√©n√©rer le code d'ex√©cution de requ√™te SQL optimal. <br></li><li>  <i>Les interfaces ODBC et JDBC sont prises en charge.</i>  Cela vous permet d'int√©grer les donn√©es Impala avec des outils et des applications analytiques presque pr√™ts √† l'emploi. <br></li><li>  <i>Il est possible d'utiliser Kudu</i> pour contourner certaines des limitations de HDFS et, en particulier, √©crire des constructions UPDATE et DELETE dans des requ√™tes SQL. <br></li></ul><br><h2>  Sqoop et le reste de l'architecture </h2><br>  L'outil le plus important suivant sur la pile Hadoop √©tait Sqoop pour nous.  Il vous permet de transf√©rer des donn√©es entre un SGBD relationnel (nous √©tions bien s√ªr int√©ress√©s par Teradata) et HDFS dans un cluster Hadoop sous diff√©rents formats, dont Parquet.  Lors des tests, Sqoop a montr√© une flexibilit√© et des performances √©lev√©es, nous avons donc d√©cid√© de l'utiliser - au lieu de d√©velopper nos propres outils pour capturer des donn√©es via ODBC / JDBC et les enregistrer sur HDFS. <br><br>  Pour les mod√®les de formation et les t√¢ches connexes de Data Science, qui sont plus pratiques √† ex√©cuter directement sur le cluster Hadoop, nous avons utilis√© Apache <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Spark</a> .  Dans son domaine, il est devenu une solution standard - et il y a une raison: <br><br><ul><li>  Biblioth√®ques d'apprentissage automatique Spark ML <br></li><li>  prise en charge de quatre langages de programmation (Scala, Java, Python, R); <br></li><li>  int√©gration avec des outils analytiques; <br></li><li>  le traitement des donn√©es en m√©moire donne d'excellentes performances. <br></li></ul><br>  Le serveur Oracle Big Data Appliance a √©t√© achet√© en tant que plate-forme mat√©rielle.  Nous avons commenc√© avec six n≈ìuds dans un circuit productif avec un processeur 2x24 c≈ìurs et 256 Go de m√©moire chacun.  La configuration actuelle contient 18 des m√™mes n≈ìuds avec une extension jusqu'√† 512 Go de m√©moire. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/58f/173/025/58f173025e987a85582e383fd5f4b3d9.png"><br><br>  Le diagramme montre l'architecture de niveau sup√©rieur de la plateforme de recherche de donn√©es et des syst√®mes associ√©s.  Le lien central est le cluster Hadoop bas√© sur la distribution Cloudera (CDH).  Il est utilis√© √† la fois pour recevoir avec Sqoop et pour stocker des donn√©es QCD en HDFS - au format parquet, permettant l'utilisation de codecs pour la compression, par exemple, Snappy.  Le cluster traite √©galement les donn√©es: Impala est utilis√© pour les transformations de type ELT, Spark - pour les t√¢ches de Data Science.  Sentry est utilis√© pour partager l'acc√®s aux donn√©es. <br><br>  Impala dispose d'interfaces pour presque tous les outils d'analyse d'entreprise modernes.  De plus, des outils arbitraires prenant en charge les interfaces ODBC / JDBC peuvent √™tre connect√©s en tant que clients.  Pour travailler avec SQL, nous consid√©rons Hue et TOAD for Hadoop comme les principaux clients. <br><br>  Un sous-syst√®me ETL compos√© d'outils SAS (Metadata Server, Data Integration Studio) et d'un framework ETL √©crit sur la base de scripts SAS et shell utilisant une base de donn√©es pour stocker les m√©tadonn√©es des processus ETL est utilis√© pour g√©rer tous les flux indiqu√©s par des fl√®ches sur le diagramme. .  Guid√© par les r√®gles sp√©cifi√©es dans les m√©tadonn√©es, le sous-syst√®me ETL lance des processus de traitement des donn√©es √† la fois sur QCD et sur la plateforme de recherche de donn√©es.  En cons√©quence, nous avons un syst√®me de bout en bout pour surveiller et g√©rer les flux de donn√©es quel que soit l'environnement utilis√© (Teradata, Impala, Spark, etc., si n√©cessaire). <br><br><h2>  √Ä travers le r√¢teau jusqu'aux √©toiles </h2><br>  Le d√©chargement de QCD semble √™tre simple.  En entr√©e et en sortie, SGBD relationnel, prenez et d√©bordez les donn√©es via Sqoop.  √Ä en juger par la description ci-dessus, tout s'est tr√®s bien pass√© avec nous, mais, bien s√ªr, cela n'a pas √©t√© sans aventures, et c'est peut-√™tre la partie la plus int√©ressante de tout le projet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c7/011/2fc/5c70112fc6dae573401cfd4a85733514.png"><br><br>  Avec notre volume, nous ne pouvions pas esp√©rer transf√©rer toutes les donn√©es enti√®rement tous les jours.  Par cons√©quent, √† partir de chaque installation de stockage, il √©tait n√©cessaire d'apprendre √† distinguer un incr√©ment fiable, ce qui n'est pas toujours facile lorsque les donn√©es des dates commerciales historiques peuvent changer dans le tableau.  Pour r√©soudre ce probl√®me, nous avons syst√©matis√© les objets en fonction des m√©thodes de chargement et de maintien de l'historique.  Ensuite, pour chaque type, le pr√©dicat correct pour Sqoop et la m√©thode de chargement dans le r√©cepteur ont √©t√© d√©termin√©s.  Et enfin, ils ont √©crit des instructions pour les d√©veloppeurs de nouveaux objets. <br><br>  Sqoop est un outil de tr√®s haute qualit√©, mais pas dans tous les cas et combinaisons de syst√®mes, il fonctionne de mani√®re absolument fiable.  Sur nos volumes, le connecteur vers Teradata n'a pas fonctionn√© de mani√®re optimale.  Nous avons profit√© du code open source de Sqoop et apport√© des modifications aux biblioth√®ques de connecteurs.  La stabilit√© de la connexion lors du d√©placement de donn√©es a augment√©. <br><br>  Pour une raison quelconque, lorsque Sqoop appelle Teradata, les pr√©dicats ne sont pas correctement convertis en conditions WHERE.  Pour cette raison, Sqoop essaie parfois de retirer une √©norme table et de la filtrer plus tard.  Nous n'avons pas r√©ussi √† patcher le connecteur ici, mais nous avons trouv√© un autre moyen: cr√©er de force une table temporaire avec un pr√©dicat impos√© pour chaque objet d√©charg√© et demander √† Sqoop de le remplir. <br><br>  Tous les MPP, et Teradata en particulier, ont une fonctionnalit√© li√©e au stockage de donn√©es parall√®le et √† l'ex√©cution des instructions.  Si cette fonctionnalit√© n'est pas prise en compte, il peut s'av√©rer que tout le travail sera pris en charge par un n≈ìud logique du cluster, ce qui rendra l'ex√©cution de la requ√™te beaucoup plus lente, une fois en 100-200.  Bien s√ªr, nous ne pouvions pas permettre cela, par cons√©quent, nous avons √©crit un moteur sp√©cial qui utilise les m√©tadonn√©es ETL des tables QCD et s√©lectionne le degr√© optimal de parall√©lisation des t√¢ches Sqoop. <br><br>  L'historicit√© du stockage est une question d√©licate, surtout si vous utilisez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SCD2</a> , alors <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">qu'Impala</a> ne prend pas en charge UPDATE et DELETE.  Bien s√ªr, nous voulons que les tableaux historiques de la plate-forme de recherche sur les donn√©es soient identiques √† ceux de Teradata.  Ceci peut √™tre r√©alis√© en combinant la r√©ception de l'incr√©ment via Sqoop, en mettant en √©vidence les cl√©s professionnelles mises √† jour et en supprimant les partitions dans Impala.  Pour que cette logique √©labor√©e n'ait pas √† √™tre √©crite par chaque d√©veloppeur, nous l'avons plac√©e dans une biblioth√®que sp√©ciale (sur notre ¬´chargeur¬ª d'argot ETL). <br><br>  Enfin - une question avec les types de donn√©es.  Impala est assez libre pour la conversion de type, nous avons donc rencontr√© des difficult√©s uniquement dans les types TIMESTAMP et CHAR / VARCHAR.  Pour la date-heure, nous avons d√©cid√© de stocker les donn√©es dans Impala au format texte (STRING) YYYY-MM-DD HH: MM: SS.  Cette approche, en fin de compte, permet d'utiliser les fonctions de transformation de la date et de l'heure.  Pour les donn√©es de cha√Æne d'une longueur donn√©e, il s'est av√©r√© que le stockage au format STRING dans Impala ne leur √©tait pas inf√©rieur, nous l'avons donc √©galement utilis√©. <br><br>  En r√®gle g√©n√©rale, pour organiser Data Lake, ils copient les donn√©es source dans des formats semi-structur√©s dans une zone d'√©tape sp√©ciale dans Hadoop, apr√®s quoi Hive ou Impala a configur√© un sch√©ma de d√©s√©rialisation pour ces donn√©es √† utiliser dans les requ√™tes SQL.  Nous avons fait de m√™me.  Il est important de noter que ce n'est pas tout et qu'il n'est pas toujours logique de le faire glisser dans l'entrep√¥t de donn√©es, car le d√©veloppement de processus de copie de fichiers et l'installation du sch√©ma sont beaucoup moins chers que le chargement d'attributs m√©tier dans le mod√®le QCD √† l'aide de processus ETL.  Quand on ne sait toujours pas combien, pour combien de temps et √† quelle fr√©quence les donn√©es sources sont n√©cessaires, Data Lake dans l'approche d√©crite est une solution simple et bon march√©.  Maintenant, nous t√©l√©chargeons r√©guli√®rement sur Data Lake principalement des sources qui g√©n√®rent des √©v√©nements utilisateur: donn√©es d'analyse d'application, journaux et sc√©narios de transition pour le num√©roteur automatique Avaya et le r√©pondeur, transactions par carte. <br><br><h2>  Bo√Æte √† outils d'analyste </h2><br>  Nous n'avons pas oubli√© un autre objectif de l'ensemble du projet: permettre aux analystes d'utiliser toute cette richesse.  Voici les principes de base qui nous ont guid√©s ici: <br><br><ul><li>  Commodit√© de l'outil dans l'utilisation et le support <br></li><li>  Applicabilit√© dans les t√¢ches de science des donn√©es <br></li><li>  La possibilit√© maximale d'utiliser les ressources informatiques du cluster Hadoop, plut√¥t que les serveurs d'applications ou l'ordinateur du chercheur <br></li></ul><br>  Et voici o√π nous nous sommes arr√™t√©s: <br><br><ul><li>  Python + Anaconda.  L'environnement utilis√© est iPython / Jupyter <br></li><li>  R + brillant.  Le chercheur travaille dans la version desktop ou web de R Studio, Shiny est utilis√© pour d√©velopper des applications web qui sont affin√©es par l'utilisation d'algorithmes d√©velopp√©s en R. <br></li><li>  Spark  Pour travailler avec des donn√©es, les interfaces pour Python (pyspark) et R sont utilis√©es, qui sont configur√©es dans les environnements de d√©veloppement sp√©cifi√©s dans les paragraphes pr√©c√©dents.  Les deux interfaces vous permettent d'utiliser la biblioth√®que Spark ML, ce qui permet de former des mod√®les ML sur le cluster Hadoop / Spark. <br></li><li>  Les donn√©es Impala sont accessibles via Hue, Spark et √† partir des environnements de d√©veloppement en utilisant l'interface ODBC standard et des biblioth√®ques sp√©ciales comme implyr <br></li></ul><br>  Actuellement, Data Lake contient environ 100 To de donn√©es provenant du stockage de d√©tail, plus environ 50 To provenant d'un certain nombre de sources OLTP.  Le lac est mis √† jour quotidiennement progressivement.  √Ä l'avenir, nous allons accro√Ætre la commodit√© pour les utilisateurs, introduire une charge ELT sur Impala, augmenter le nombre de sources t√©l√©charg√©es sur Data Lake et √©largir les possibilit√©s d'analyses avanc√©es. <br><br>  En conclusion, je voudrais donner quelques conseils g√©n√©raux √† des coll√®gues qui commencent tout juste leur parcours dans la cr√©ation de grands r√©f√©rentiels: <br><br><ul><li>  Utilisez les meilleures pratiques.  Si nous n'avions pas de sous-syst√®me ETL, de m√©tadonn√©es, de stockage versionn√© et d'une architecture compr√©hensible, nous n'aurions pas ma√Ætris√© cette t√¢che.  Les meilleures pratiques sont rentables, mais pas imm√©diatement. <br></li><li>  N'oubliez pas la quantit√© de donn√©es.  Le Big Data peut cr√©er des difficult√©s techniques dans des endroits tr√®s inattendus. <br></li><li>  Restez √† l'√©coute des nouvelles technologies.  De nouvelles solutions apparaissent souvent, toutes ne sont pas utiles, mais parfois de v√©ritables joyaux sont trouv√©s. <br></li><li>  Exp√©rimentez plus.  Ne vous fiez pas uniquement aux descriptions marketing des solutions - essayez-le vous-m√™me. <br></li></ul><br>  <i>Soit dit en passant, vous pouvez d√©couvrir comment nos analystes ont utilis√© le machine learning et les donn√©es bancaires pour g√©rer les risques de cr√©dit dans un article s√©par√©.</i> <i><br></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr420141/">https://habr.com/ru/post/fr420141/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr420129/index.html">Mod√®les de coroutine Asyncio: l'ext√©rieur attend</a></li>
<li><a href="../fr420131/index.html">M√©thode d'exploration de Bitcoin probabiliste</a></li>
<li><a href="../fr420133/index.html">Mod√©lisation des syst√®mes dynamiques: comment se d√©place la lune?</a></li>
<li><a href="../fr420135/index.html">C'est aussi Toshiba: des produits inattendus de la soci√©t√© japonaise</a></li>
<li><a href="../fr420139/index.html">Livre ¬´Site Reliability Engineering. Fiabilit√© et fiabilit√© comme dans Google ¬ª</a></li>
<li><a href="../fr420143/index.html">Performances de Kotlin sur Android</a></li>
<li><a href="../fr420145/index.html">Comment se passe la journ√©e de travail des membres du PC AppsConf</a></li>
<li><a href="../fr420147/index.html">OpenSource sur Clojure</a></li>
<li><a href="../fr420151/index.html">Plus simple qu'il n'y para√Æt. Chapitre 12</a></li>
<li><a href="../fr420153/index.html">Impression 3D de pi√®ces complexes en ABS et PLA avec beaucoup de support</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
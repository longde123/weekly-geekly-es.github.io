<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåó üåï üßúüèΩ Multithreading auf Node.js. Ereignisschleife üôáüèæ üôÜüèæ üôãüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Infa ist n√ºtzlich f√ºr JS-Entwickler, die die Grundlagen der Arbeit mit Node.js und Event Loop genau verstehen m√∂chten. Sie k√∂nnen den Programmablauf b...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Multithreading auf Node.js. Ereignisschleife</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/479062/"><p>  Infa ist n√ºtzlich f√ºr JS-Entwickler, die die Grundlagen der Arbeit mit Node.js und Event Loop genau verstehen m√∂chten.  Sie k√∂nnen den Programmablauf bewusst und flexibler steuern (Web-Server). </p><br><p>  Ich habe diesen Artikel auf der Grundlage meines letzten Berichts an Kollegen zusammengestellt. <br>  Am Ende des Artikels finden Sie n√ºtzliche Materialien f√ºr unabh√§ngige Studien. </p><br><h3 id="kak-ustroena-nodejs-vozmozhnosti-asinhrona">  Wie ist Node.js.  Asynchrone Funktionen </h3><br><p>  Sehen wir uns diesen Code an: Er demonstriert perfekt die Synchronisation der Codeausf√ºhrung in Node.js.  Irgendwo auf GitHub wird eine Anfrage gestellt, dann wird eine Datei gelesen und das Ergebnis in der Konsole angezeigt.  Was ergibt sich aus diesem Synchroncode? </p><br><p><img src="https://static.tildacdn.com/tild6636-3136-4462-b130-323161353738/1.png" alt="Bild"></p><a name="habracut"></a><br><p>  Angenommen, dies ist ein abstrakter Webserver, der Vorg√§nge auf einem Router ausf√ºhrt.  Wenn auf diesem Router eine eingehende Anfrage eingeht, stellen wir eine weitere Anfrage, lesen die Datei und drucken sie an die Konsole.  In der Zeit, die f√ºr das Anfordern und Lesen einer Datei aufgewendet wird, wird der Server blockiert, er kann keine anderen eingehenden Anforderungen verarbeiten und f√ºhrt keine anderen Vorg√§nge aus. </p><br><p>  Welche M√∂glichkeiten gibt es, um dieses Problem zu l√∂sen? </p><br><ol><li>  Multithreading </li><li>  Nicht blockierende E / A </li></ol><br><p>  F√ºr die erste Option (Multithreading) gibt es ein gutes Beispiel f√ºr den Webserver Apache vs Nginx. </p><br><p><img src="https://static.tildacdn.com/tild3135-6363-4633-b064-633962376236/2.png" alt="Bild"></p><br><p>  Bisher hat Apache f√ºr jede eingehende Anfrage einen Stream ausgel√∂st: Wie viele Anfragen gab es, die gleiche Anzahl von Threads.  Zu diesem Zeitpunkt hatte Nginx den Vorteil, nicht blockierende E / A zu verwenden.  Hier k√∂nnen Sie sehen, dass mit zunehmender Anzahl eingehender Anforderungen der von Apache belegte Speicherplatz zunimmt und auf der n√§chsten Folie die Anzahl der pro Sekunde verarbeiteten Anforderungen mit der Anzahl der Verbindungen f√ºr Nginx h√∂her ist. </p><br><p><img src="https://static.tildacdn.com/tild3661-3539-4965-a435-393731333863/3.png" alt="Bild"></p><br><p>  <strong>Es wird deutlich, dass nicht blockierende Ein- / Ausg√§nge effizienter sind.</strong> </p><br><p>  Dank moderner Betriebssysteme, die diesen Mechanismus bereitstellen - einen Ereignis-Demultiplexer - wird eine nicht blockierende Eingabe / Ausgabe erm√∂glicht. </p><br><p>  Ein Demultiplexer ist ein Mechanismus, der eine Anforderung von einer Anwendung empf√§ngt, registriert und ausf√ºhrt. </p><br><p><img src="https://static.tildacdn.com/tild3239-6537-4639-b262-303866363230/4.png" alt="Bild"></p><br><p>  Im oberen Teil des Diagramms ist zu sehen, dass wir eine Anwendung haben und Operationen darin ausgef√ºhrt werden (lass es eine Datei lesen).  Dazu wird eine Anfrage an den Event-Demultiplexer gestellt, hier wird eine Ressource gesendet (Link zur Datei), die gew√ºnschte Operation und der R√ºckruf.  Der Ereignisdemultiplexer registriert diese Anforderung und gibt die Steuerung direkt an die Anwendung zur√ºck - sie wird also nicht blockiert.  Anschlie√üend werden Operationen f√ºr die Datei ausgef√ºhrt. Anschlie√üend wird beim Lesen der Datei der R√ºckruf in der Ausf√ºhrungswarteschlange registriert.  Dann verarbeitet die Ereignisschleife nach und nach synchron jeden R√ºckruf aus dieser Warteschlange.  Und gibt dementsprechend das Ergebnis an die Anwendung zur√ºck.  Weiter wird (falls n√∂tig) alles nochmal gemacht. </p><br><p>  <strong>Dank dieser nicht blockierenden E / A kann Node.js also asynchron sein.</strong> <strong><br></strong> </p><br><p>  Ich werde klarstellen, dass in diesem Fall das Betriebssystem uns nicht blockierende Ein- / Ausgaben zur Verf√ºgung stellt.  Zur nicht blockierenden Eingabe / Ausgabe (im Allgemeinen zu Eingabe / Ausgabe-Operationen) schlie√üen wir Netzwerkanforderungen ein und arbeiten mit Dateien. </p><br><p>  Dies ist das allgemeine Konzept der nicht blockierenden E / A.  Als sich die Gelegenheit ergab, lie√ü sich Ryan Dahl, ein Entwickler von Node.js, von der Nginx-Erfahrung inspirieren, bei der nicht blockierende E / A verwendet wurden, und beschloss, eine Plattform speziell f√ºr Entwickler zu erstellen.  Das erste, was er tun musste, war, seine Plattform mit einem Event-Demultiplexer ‚Äûanzufreunden‚Äú.  Das Problem war, dass der Demultiplexer in jedem Betriebssystem anders implementiert war und er einen Wrapper schreiben musste, der sp√§ter als libuv bekannt wurde.  Dies ist eine in C geschriebene Bibliothek. Sie bietet eine einzige Schnittstelle f√ºr die Arbeit mit diesen Ereignisdemultiplexern. </p><br><h3 id="osobennosti-libuv-biblioteki">  Funktionen der Libuv-Bibliothek </h3><br><p><img src="https://static.tildacdn.com/tild3165-6435-4730-b264-616531326535/5.png" alt="Bild"></p><br><p>  Im Prinzip blockieren momentan unter Linux alle Operationen mit lokalen Dateien.  Das hei√üt, es scheint nicht blockierende Ein- / Ausgaben zu geben, aber genau bei der Arbeit mit lokalen Dateien blockiert der Vorgang immer noch.  Deshalb verwendet libuv intern Threads, um nicht blockierende E / A zu emulieren.  4 Threads steigen aus dem Kasten heraus, und hier m√ºssen wir die wichtigste Schlussfolgerung ziehen: Wenn wir 4 schwere Operationen an lokalen Dateien ausf√ºhren, werden wir dementsprechend unsere gesamte Anwendung blockieren (es ist unter Linux, andere Betriebssysteme nicht). </p><br><p><img src="https://static.tildacdn.com/tild3639-3865-4765-b565-636136653938/6.png" alt="Bild"></p><br><p>  Auf dieser Folie sehen wir die Architektur von Node.js.  F√ºr die Interaktion mit dem Betriebssystem wird die in C geschriebene libuv-Bibliothek verwendet.  Um JavaScript-Code in Maschinencode zu kompilieren, wird die Google V8-Engine verwendet. Au√üerdem gibt es eine Node.js-Core-Bibliothek, die Module f√ºr die Arbeit mit Netzwerkanforderungen, ein Dateisystem und ein Modul f√ºr die Protokollierung enth√§lt.  Da dies alles miteinander interagierte, werden Node.js Bindings geschrieben.  Diese 4 Komponenten bilden die Struktur von Node.js.  Der Event-Loop-Mechanismus selbst befindet sich in libuv. </p><br><h3 id="event-loop">  Ereignisschleife </h3><br><p><img src="https://static.tildacdn.com/tild6133-3435-4334-b037-623736653761/7.png" alt="Bild"></p><br><p>  Dies ist die einfachste Darstellung von Event Loop.  Es gibt eine bestimmte Warteschlange von Ereignissen, es gibt einen endlosen Zyklus von Ereignissen, die Operationen aus der Warteschlange synchron ausf√ºhren und sie weiter verteilen. </p><br><p>  <strong>Diese Folie zeigt, wie die Ereignisschleife direkt in Node.js aussieht.</strong> <br><img src="https://static.tildacdn.com/tild6535-3966-4634-a537-636236373930/9.png" alt="Bild"></p><br><p>  Dort ist die Implementierung interessanter und komplizierter.  Im Grunde ist eine Ereignisschleife eine Ereignisschleife und unendlich, solange etwas zu tun ist.  Die Ereignisschleife in Node.js ist in mehrere Phasen unterteilt.  (Die Phasen von Folie 8 m√ºssen mit dem Quellcode auf Folie 9 verglichen werden.) </p><br><p><img src="https://static.tildacdn.com/tild3639-6230-4232-b634-396363303036/10.png" alt="Bild"></p><br><h4 id="1-faza--taymery">  Phase 1 - Timer </h4><br><p>  Diese Phase wird direkt von Event Loop ausgef√ºhrt.  (Code-Snippet mit uv_update_time) - hier wird die Zeit, zu der die Event-Schleife zu arbeiten begann, einfach aktualisiert. </p><br><p>  uv_run_timers - Bei dieser Methode wird die n√§chste Timer-Aktion ausgef√ºhrt.  Es gibt einen bestimmten Stapel, genauer gesagt, eine Reihe von Timern. Dies ist im Wesentlichen dasselbe wie die Warteschlange, in der sich die Timer befinden.  Der Timer mit der k√ºrzesten Zeit wird verglichen mit der aktuellen Zeit der Ereignisschleife verwendet, und wenn es Zeit ist, diesen Timer auszuf√ºhren, wird sein R√ºckruf ausgef√ºhrt.  Es ist erw√§hnenswert, dass Node.js eine Implementierung von setTimeout hat und es setInterval gibt.  F√ºr libuv ist dies im Wesentlichen dasselbe, nur setInterval hat noch ein Wiederholungsflag. </p><br><p>  <strong>Wenn dieser Timer ein Wiederholungsflag hat, wird er dementsprechend erneut in die Ereigniswarteschlange gestellt und dann auf die gleiche Weise verarbeitet.</strong> </p><br><h3 id="2-faza--io-callbacki">  Phase 2 - E / A-R√ºckrufe </h3><br><p>  Hier m√ºssen wir zum Diagramm √ºber nicht blockierende Ein- / Ausg√§nge zur√ºckkehren. </p><br><p>  Wenn der Ereignisdemultiplexer eine Datei liest und den R√ºckruf in die Warteschlange stellt, entspricht dies nur der E / A-R√ºckrufstufe.  Hier werden Callbacks f√ºr nicht blockierende Ein- / Ausgaben durchgef√ºhrt, das sind genau die Funktionen, die nach einer Anforderung an eine Datenbank oder eine andere Ressource oder zum Lesen / Schreiben einer Datei verwendet werden.  Sie werden genau in dieser Phase durchgef√ºhrt. </p><br><p>  <strong>In Folie 9 startet die Ausf√ºhrung der E / A-R√ºckruffunktion Zeile 367: ran_pending = uv_run_pending (Schleife).</strong> <strong><br></strong> </p><br><h3 id="3-faza--ozhidanie-podgotovka">  3 Phasen - Warten, Vorbereiten </h3><br><p>  Dies sind interne Vorg√§nge f√ºr R√ºckrufe. Tats√§chlich k√∂nnen wir die Phase nicht nur indirekt beeinflussen.  Es gibt einen process.nextTick, dessen R√ºckruf m√∂glicherweise versehentlich in der Wartephase der Vorbereitung ausgef√ºhrt wird.  process.nextTick wird in der aktuellen Phase ausgef√ºhrt, d. h., process.nextTick kann in absolut jeder Phase ausgef√ºhrt werden.  Es gibt kein fertiges Tool, um den Code in der Phase "Warten, Vorbereiten" in Node.js auszuf√ºhren. </p><br><p>  Auf Folie 9 entsprechen die Zeilen 368, 369 dieser Phase: <br>  uv_run_idle (Schleife) - warte; <br>  uv_run_prepare (loop) - Vorbereitung. </p><br><h4 id="4-faza--opros">  4 Phasen - √úbersicht </h4><br><p>  Hier wird unser gesamter Code ausgef√ºhrt, den wir in JS schreiben.  Zun√§chst werden alle von uns gestellten Anforderungen hier abgerufen, und hier kann Node.js blockiert werden.  Wenn eine schwere Rechenoperation hier eintrifft, friert unsere Anwendung zu diesem Zeitpunkt m√∂glicherweise ein und wartet, bis diese Operation abgeschlossen ist. <br>  <strong>Auf Folie 9 befindet sich die Abfragefunktion in Zeile 370: uv_io_poll (Schleife, Zeit√ºberschreitung).</strong> </p><br><h4 id="5-faza--proverka">  5 Phasen - Check </h4><br><p>  In Node.js gibt es einen setImmediate-Timer, dessen R√ºckrufe in dieser Phase ausgef√ºhrt werden. <br>  <strong>Im Quellcode ist dies Zeile 371: uv_run_check (Schleife).</strong> </p><br><h4 id="6-faza-poslednyaya--callbacki-sobytiy-close">  6 phase (last) - R√ºckrufereignisse werden geschlossen </h4><br><p>  Beispielsweise muss ein Web-Socket die Verbindung trennen, in dieser Phase wird ein R√ºckruf dieses Ereignisses aufgerufen. </p><br><p>  <strong>Im Quellcode ist dies Zeile 372: uv_run_closing_handless (loop).</strong> </p><br><h3 id="i-v-itoge-event-loop-nodejs-vyglyadit-sleduyuschim-obrazom">  Und am Ende ist Event Loop Node.js wie folgt </h3><br><p><img src="https://static.tildacdn.com/tild6335-6631-4561-b732-376633616531/11.png" alt="Bild"></p><br><p>  Zuerst wird in der Zeitgeberwarteschlange der Zeitgeber ausgef√ºhrt, dessen Periode sich n√§hert. </p><br><p>  Dann werden I / O-Callbacks ausgef√ºhrt. </p><br><p>  Dann ist der Code die Basis, dann setImmediate und die Close-Ereignisse. </p><br><p>  Danach wiederholt sich alles im Kreis.  Um dies zu demonstrieren, √∂ffne ich den Code.  Wie wird es aufgef√ºhrt? </p><br><p><img src="https://static.tildacdn.com/tild6638-6163-4936-b032-633536393237/12.png" alt="Bild"></p><br><p>  Wir haben keine Timer in der Schlange, daher wird die Event-Schleife fortgesetzt.  Da es auch keine I / O-R√ºckrufe gibt, gehen wir sofort in die Polling-Phase.  Der gesamte Code, der sich hier befindet, wird anf√§nglich in der Abfragephase ausgef√ºhrt.  Deshalb drucken wir zuerst script_start, setInterval wird in die Timer-Warteschlange gestellt (nicht ausgef√ºhrt, nur platziert).  setTimeout wird ebenfalls in die Timer-Warteschlange gestellt, und dann werden die Versprechen ausgef√ºhrt: Zuerst Versprechen 1 und dann Versprechen 2. </p><br><p>  Im n√§chsten Tick (Event-Loop) kehren wir zur Timer-Stufe zur√ºck, hier in der Queue befinden sich bereits 2 Timer: setInterval und setTimeout.  Sie haben beide eine Verz√∂gerung von 0 bzw. sind zur Ausf√ºhrung bereit. </p><br><p>  SetInterval wird ausgef√ºhrt (Ausgabe an die Konsole), dann setTimeout 1. Es gibt keine nicht blockierenden E / A-R√ºckrufe, dann wird eine Abfragephase durchgef√ºhrt, Versprechen 3 und Versprechen 4 werden in der Konsole angezeigt. </p><br><p>  Als n√§chstes wird der setTimeout-Timer protokolliert.  Dies beendet den Tick, gehe zum n√§chsten Tick.  Es gibt wieder Timer, die Ausgabe an die Konsole lautet setInterval und setTimeout 2, dann werden Versprechen 5 und Versprechen 6 angezeigt. </p><br><p>  <strong>Wir haben Event Loop √ºberpr√ºft und k√∂nnen nun detaillierter auf Multithreading eingehen.</strong> </p><br><h3 id="mnogopotochnost--modul-worker_threads">  Threading - worker_threads-Modul </h3><br><p>  Threading ist in Node.js dank des Moduls worker_threads in Version 10.5 erschienen.  Und in der 10. Version wurde es ausschlie√ülich mit dem - experimental-worker-Schl√ºssel gestartet, und ab der 11. Version war es m√∂glich, ohne diesen zu starten. </p><br><p>  Node.js hat auch ein Cluster-Modul, aber es l√∂st keine Threads aus - es l√∂st mehrere weitere Prozesse aus.  Die Skalierbarkeit von Anwendungen ist das Hauptziel. </p><br><p><img src="https://static.tildacdn.com/tild3032-3166-4633-a462-316365303133/13.png" alt="Bild"></p><br><p>  Wie sieht ein Prozess aus: <br>  1 Node.js-Prozess, 1 Thread, 1 Ereignisschleife, 1 V8-Engine und libuv. </p><br><p>  Wenn wir X-Threads starten, sieht das so aus: <br>  1 Node.js-Prozess, X Threads, X Event Loops, X V8-Engines und X libuv. </p><br><h4 id="shematichno-eto-vyglyadit-sleduyuschim-obrazom">  Schematisch sieht es so aus </h4><br><p><img src="https://static.tildacdn.com/tild3439-3466-4132-a163-303062373338/14.png" alt="Bild"></p><br><h3 id="davayte-razberyom-primer">  Nehmen wir ein Beispiel. </h3><br><p><img src="https://static.tildacdn.com/tild3639-3061-4664-a231-393561643333/15.png" alt="Bild"></p><br><p>  Der einfachste Webserver unter Express.  Es gibt 2 Wege - / und / Fettoperation. </p><br><p>  Es gibt auch eine generateRandomArr () - Funktion.  Sie f√ºllt das Array mit zwei Millionen Datens√§tzen und sortiert es.  Starten wir den Server. </p><br><p>  Wir bitten um / Fettoperation.  Und in dem Moment, in dem die Sortierung des Arrays ausgef√ºhrt wird, senden wir eine weitere Anfrage an route /, aber um die Antwort zu erhalten, m√ºssen wir warten, bis das Array sortiert ist.  Dies ist eine klassische Single-Thread-Implementierung.  Jetzt verbinden wir das worker_threads-Modul. </p><br><p><img src="https://static.tildacdn.com/tild3765-6461-4664-b065-333430396433/16.png" alt="Bild"></p><br><p>  Wir stellen eine Anfrage an / fat-operation und dann - an /, worauf wir sofort die Antwort bekommen - Hallo Welt! </p><br><p>  F√ºr die Sortierung des Arrays haben wir einen separaten Thread mit einer eigenen Instanz von Event Loop ausgel√∂st, der die Ausf√ºhrung des Codes im Hauptthread nicht beeinflusst. </p><br><p>  Ein Thread wird "zerst√∂rt", wenn keine Operationen ausgef√ºhrt werden m√ºssen. </p><br><p>  Wir schauen uns den Quellcode an.  Wir registrieren den Arbeiter in Zeile 26 und leiten die Daten bei Bedarf an ihn weiter.  In diesem Fall sende ich nichts.  Und dann abonnieren wir Ereignisse: einen Fehler und eine Meldung.  Im Worker wird die Funktion aufgerufen, ein Array von zwei Millionen Datens√§tzen wird sortiert.  Sobald es sortiert ist, senden wir das Ergebnis √ºber post_message an den Hauptstream ok. </p><br><p><img src="https://static.tildacdn.com/tild3536-3636-4531-b064-663161303964/17.png" alt="Bild"></p><br><p>  Im Haupt-Thread fangen wir diese Nachricht ab und senden das Ergebnis zum Abschluss.  Der Worker und der Haupt-Thread haben einen gemeinsamen Speicher, sodass wir Zugriff auf globale Variablen des gesamten Prozesses haben.  Wenn wir Daten vom Hauptstream an den Worker √ºbertragen, erh√§lt der Worker nur eine Kopie. </p><br><p>  Wir k√∂nnen den Haupt- und den Worker-Stream in einer Datei beschreiben.  Das worker_threads-Modul bietet eine API, √ºber die wir bestimmen k√∂nnen, in welchem ‚Äã‚ÄãThread der Code gerade ausgef√ºhrt wird. </p><br><p><img src="https://static.tildacdn.com/tild3162-6264-4134-a363-663832656262/18.png" alt="Bild"></p><br><h4 id="dopolnitelnaya-informaciya">  Weitere Informationen </h4><br><p>  Ich teile Links zu n√ºtzlichen Ressourcen und einen Link zur Pr√§sentation von Ryan Dahl, als er den Event Loop pr√§sentierte (interessant zu sehen). </p><br><p>  Ereignisschleife </p><br><ol><li>  <a href="https://medium.com/devschacht/event-loop-timers-and-nexttick-18579cd122e0">√úbersetzung eines Artikels aus der Dokumentation von Node.js</a> </li><li>  <a href="https://blog.risingstack.com/node-js-at-scale-understanding-node-js-event-loop/">https://blog.risingstack.com/node-js-at-scale-understanding-node-js-event-loop/</a> </li><li>  <a href="https://habr.com/ru/post/336498/">https://habr.com/de/post/336498/</a> </li></ol><br><p>  Worker_threads </p><br><ol><li>  <a href="https://nodejs.org/api/worker_threads.html">https://nodejs.org/api/worker_threads.html#worker_threads_worker_workerdata</a> - API </li><li>  <a href="https://habr.com/ru/company/ruvds/blog/415659/">https://habr.com/ru/company/ruvds/blog/415659/</a> </li><li>  <a href="https://nodesource.com/blog/worker-threads-nodejs/">https://nodesource.com/blog/worker-threads-nodejs/</a> <a href="https://nodesource.com/blog/worker-threads-nodejs/"><br></a> </li><li>  <a href="https://www.slideshare.net/AartiParikh/original-slides-from-ryan-dahls-nodejs-intro-talk">Originalfolien aus Ryan Dahls Pr√§sentation (√ºber VPN)</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de479062/">https://habr.com/ru/post/de479062/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de479052/index.html">[Supercomputing 2019]. Multi-Cloud-Speicher als Anwendung f√ºr neue Kingston DC1000M-Laufwerke</a></li>
<li><a href="../de479054/index.html">Mobile Umfrage am Freitag</a></li>
<li><a href="../de479056/index.html">√úber das Leben reden? DREAM Team bei der Alexa Prize Socialbot Challenge 3</a></li>
<li><a href="../de479058/index.html">√úberwachung als Ereignisverwaltungsprozess</a></li>
<li><a href="../de479060/index.html">Warum QA eine gute Karriere f√ºr einen Programmierer ist</a></li>
<li><a href="../de479066/index.html">Tesla Cybertruck Industriedesigner: Warum ist er so gut und schlecht</a></li>
<li><a href="../de479068/index.html">Analyse von Vorf√§llen in Computersystemen und Netzwerken</a></li>
<li><a href="../de479070/index.html">Wie Nadia Nadezhda Mikhailovna wurde</a></li>
<li><a href="../de479072/index.html">Firefox-Browser - 15. Jahrestag: Aufstieg, Fall und Renaissance mit Schwerpunkt auf Datenschutz</a></li>
<li><a href="../de479074/index.html">Kommt die √Ñra der ARM-Server?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
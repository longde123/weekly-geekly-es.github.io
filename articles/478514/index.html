<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∞ üîí üßóüèª Usar datos cifrados para el aprendizaje autom√°tico sin descifrarlos üê≥ ‚ùáÔ∏è üòõ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Usar datos cifrados para el aprendizaje autom√°tico sin descifrarlos 
 Este art√≠culo trata sobre t√©cnicas criptogr√°ficas avanzadas. Esta es solo una de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Usar datos cifrados para el aprendizaje autom√°tico sin descifrarlos</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/478514/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/_p/ns/yf/_pnsyfz49v6t61j8whitl-q4qw0.jpeg"></div><br>  Usar datos cifrados para el aprendizaje autom√°tico sin descifrarlos <br>  Este art√≠culo trata sobre t√©cnicas criptogr√°ficas avanzadas.  Esta es solo una descripci√≥n general de la investigaci√≥n realizada por Julia Computing.  No use los ejemplos dados aqu√≠ en aplicaciones comerciales.  Siempre consulte con los cript√≥grafos antes de aplicar la criptograf√≠a. <br><br>  <a href="">Aqu√≠</a> puede descargar el paquete que implementa toda la magia, y <a href="">aqu√≠</a> est√° el c√≥digo que se discute en el art√≠culo. <br><a name="habracut"></a><br><h2>  Introduccion </h2><br>  Digamos que acaba de desarrollar un nuevo modelo de aprendizaje autom√°tico (por supuesto, usando <a href="">Flux.jl</a> ).  Y ahora desea comenzar a implementarlo para sus usuarios.  ¬øC√≥mo vas a hacer esto?  Probablemente la forma m√°s f√°cil es dar el modelo a los usuarios y dejar que se ejecute localmente en sus datos.  Pero este enfoque tiene desventajas: <br><br><ol><li>  Los modelos de aprendizaje autom√°tico son grandes, y las computadoras de los usuarios pueden no tener suficientes recursos inform√°ticos o de disco. </li><li>  Los modelos de aprendizaje autom√°tico a menudo se actualizan, y puede que no sea conveniente para usted enviar regularmente grandes cantidades de datos a trav√©s de la red. <br></li><li>  El desarrollo del modelo lleva mucho tiempo y requiere una gran cantidad de recursos inform√°ticos.  Y es posible que desee una compensaci√≥n por esto en forma de una tarifa por usar su modelo. </li></ol><br>  Luego, por lo general, recuerdan que el modelo se puede proporcionar en la nube a trav√©s de la API.  En los √∫ltimos a√±os, han aparecido muchos de estos servicios; cada gran plataforma en la nube ofrece servicios similares a los desarrolladores corporativos.  Pero los usuarios potenciales se enfrentan a un dilema obvio: ahora sus datos se procesan en un servidor remoto, que puede no ser confiable.  Esto tiene claras implicaciones √©ticas y legales que limitan el uso de dichos servicios.  En las industrias reguladas, especialmente los servicios de salud y financieros, a menudo no es posible enviar datos de pacientes y clientes a terceros para su procesamiento. <br><br>  ¬øAlguna otra opci√≥n? <br><br>  Resulta que hay!  Los descubrimientos recientes en criptograf√≠a permiten computar con datos <i>sin decodificarlos</i> .  Por ejemplo, un usuario env√≠a datos encriptados (por ejemplo, im√°genes) a la API en la nube, que lanza un modelo de aprendizaje autom√°tico, y luego env√≠a una respuesta encriptada.  En ning√∫n momento se descifran los datos, el proveedor de la nube no obtiene acceso a las im√°genes de origen y no puede descifrar el pron√≥stico calculado.  ¬øC√≥mo es esto posible?  Veamos el ejemplo de crear un servicio para el reconocimiento de escritura a mano en im√°genes encriptadas del conjunto de datos MNIST. <br><br><h2>  Acerca del cifrado homom√≥rfico </h2><br>  La capacidad de realizar c√°lculos con datos cifrados se conoce com√∫nmente como "computaci√≥n segura".  Esta es un √°rea grande para la investigaci√≥n, con numerosos enfoques de criptograf√≠a que dependen de todo tipo de escenarios de aplicaci√≥n.  Nos centraremos en una t√©cnica llamada "encriptaci√≥n homom√≥rfica".  En dicho sistema, las siguientes operaciones generalmente est√°n disponibles para nosotros: <br><br><ul><li><code>pub_key, eval_key, priv_key = keygen()</code> <br> </li><li> <code>encrypted = encrypt(pub_key, plaintext)</code> <br> </li><li> <code>decrypted = decrypt(priv_key, encrypted)</code> <br> </li><li> <code>encrypted‚Ä≤ = eval(eval_key, f, encrypted)</code> <br> </li></ul><br>  Las primeras tres operaciones son simples y familiares para todos los que ya han utilizado algoritmos de cifrado asim√©tricos (por ejemplo, si se conect√≥ a trav√©s de TLS).  Toda la magia sucede en la √∫ltima operaci√≥n.  Durante el cifrado, eval√∫a la funci√≥n <code>f</code> y devuelve otro valor cifrado calculado de acuerdo con el resultado de evaluar <code>f</code> en el valor cifrado.  Esta caracter√≠stica le dio a su enfoque su nombre.  La evaluaci√≥n est√° relacionada con la operaci√≥n de cifrado: <br><br><pre> <code class="julia hljs">f(decrypt(priv_key, encrypted)) == decrypt(priv_key, eval(eval_key, f, encrypted))</code> </pre> <br>  Del mismo modo, utilizando un valor cifrado, podemos evaluar homomorfismos arbitrarios <code>f</code> . <br><br>  Las funciones <code>f</code> admite <code>f</code> dependen de los esquemas criptogr√°ficos y las operaciones admitidas.  Si solo <code>f</code> admite una <code>f</code> (por ejemplo, <code>f = +</code> ), el circuito se llama "parcialmente homom√≥rfico".  Si <code>f</code> puede ser un conjunto completo de puertas de enlace, sobre la base de las cuales se pueden crear esquemas arbitrarios, entonces para un tama√±o limitado de un esquema esto se llama otro tipo de c√°lculo parcialmente homom√≥rfico - "algo homom√≥rfico", y para un tama√±o ilimitado - c√°lculo "completamente homom√≥rfico".  Puede convertir "de alguna manera" en un cifrado completamente homom√≥rfico utilizando la t√©cnica de arranque, pero esto est√° m√°s all√° del alcance de nuestro art√≠culo.  El cifrado totalmente homom√≥rfico es un descubrimiento relativamente reciente, el primer esquema de trabajo (aunque poco pr√°ctico) fue publicado por <a href="https://www.cs.cmu.edu/~odonnell/hits09/gentry-homomorphic-encryption.pdf">Craig Gentry en 2009</a> .  Hay una serie de esquemas completamente homom√≥rficos posteriores (y pr√°cticos).  Tambi√©n hay paquetes de software que implementan cualitativamente estos esquemas.  La mayor√≠a de las veces usan <a href="https://github.com/microsoft/SEAL">Microsoft SEAL</a> y <a href="https://palisade-crypto.org/">PALISADE</a> .  Adem√°s, recientemente abr√≠ el c√≥digo de implementaci√≥n para estos algoritmos de <a href="">Pure Julia</a> .  Para este art√≠culo, utilizaremos el cifrado CKKS implementado en √©l. <br><br><h2>  Descripci√≥n general de CKS </h2><br>  CKKS (por los nombres de los autores del <a href="https://eprint.iacr.org/2016/421.pdf">trabajo cient√≠fico</a> Cheon-Kim-Kim-Song, que propuso el algoritmo en 2016) es un esquema de cifrado homom√≥rfico que permite la evaluaci√≥n homom√≥rfica de las siguientes operaciones primitivas: <br><br><ul><li>  La adici√≥n por elementos de las longitudes de <code>n</code> vectores de n√∫meros complejos. <br></li><li>  Multiplicaci√≥n por elementos de las longitudes de <code>n</code> vectores complejos. <br></li><li>  Rotar elementos (en el contexto de un <code>circshift</code> ) en un vector. <br></li><li>  Emparejamiento integrado de elementos vectoriales. <br></li></ul><br>  El par√°metro <code>n</code> depende del nivel deseado de seguridad y precisi√≥n, y generalmente es bastante alto.  En nuestro ejemplo, ser√° igual a 4096 (un valor m√°s alto aumenta la seguridad, pero tambi√©n es m√°s dif√≠cil en los c√°lculos, se escala aproximadamente como <code>n log n</code> ). <br><br>  Adem√°s, los c√°lculos con CKKS son <i>ruidosos</i> .  Por lo tanto, los resultados son aproximados, y se debe tener cuidado de que los resultados se eval√∫en con suficiente precisi√≥n para no afectar la exactitud del resultado. <br><br>  Por otro lado, tales restricciones no son inusuales para los desarrolladores de paquetes de aprendizaje autom√°tico.  Los aceleradores especiales como la GPU tambi√©n suelen operar con vectores de n√∫meros.  Adem√°s, para muchos desarrolladores, los n√∫meros de coma flotante a veces parecen ruidosos debido a la influencia de algoritmos de selecci√≥n, subprocesos m√∫ltiples, etc.  Quiero enfatizar que la diferencia clave aqu√≠ es que los c√°lculos aritm√©ticos con n√∫meros de coma flotante son inicialmente deterministas, incluso si esto no es obvio debido a la complejidad de la implementaci√≥n, aunque las primitivas CKKS son realmente ruidosas.  Pero tal vez esto les permita a los usuarios comprender que el ruido no es tan aterrador como podr√≠a parecer. <br><br>  Ahora veamos c√≥mo puede realizar estas operaciones en Julia (nota: se seleccionan par√°metros muy inseguros, con estas operaciones solo ilustramos el uso de la biblioteca en REPL). <br><br><pre> <code class="julia hljs">julia&gt; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> ToyFHE <span class="hljs-comment"><span class="hljs-comment"># Let's play with 8 element vectors julia&gt; N = 8; # Choose some parameters - we'll talk about it later julia&gt; ‚Ñõ = NegacyclicRing(2N, (40, 40, 40)) ‚Ñ§‚ÇÅ‚ÇÉ‚ÇÇ‚Çâ‚ÇÇ‚ÇÇ‚Çá‚Çâ‚Çâ‚Çá‚ÇÖ‚ÇÜ‚Çà‚ÇÄ‚Çà‚ÇÅ‚ÇÑ‚ÇÖ‚Çá‚ÇÑ‚ÇÄ‚ÇÇ‚Çá‚ÇÄ‚ÇÅ‚ÇÇ‚ÇÄ‚Çá‚ÇÅ‚ÇÄ‚ÇÑ‚ÇÇ‚ÇÑ‚Çà‚ÇÇ‚ÇÖ‚Çá/(x¬π‚Å∂ + 1) # We'll use CKKS julia&gt; params = CKKSParams(‚Ñõ) CKKS parameters # We need to pick a scaling factor for a numbers - again we'll talk about that later julia&gt; Tscale = FixedRational{2^40} FixedRational{1099511627776,T} where T # Let's start with a plain Vector of zeros julia&gt; plain = CKKSEncoding{Tscale}(zero(‚Ñõ)) 8-element CKKSEncoding{FixedRational{1099511627776,T} where T} with indices 0:7: 0.0 + 0.0im 0.0 + 0.0im 0.0 + 0.0im 0.0 + 0.0im 0.0 + 0.0im 0.0 + 0.0im 0.0 + 0.0im 0.0 + 0.0im # Ok, we're ready to get started, but first we'll need some keys julia&gt; kp = keygen(params) CKKS key pair julia&gt; kp.priv CKKS private key julia&gt; kp.pub CKKS public key # Alright, let's encrypt some things: julia&gt; foreach(i-&gt;plain[i] = i+1, 0:7); plain 8-element CKKSEncoding{FixedRational{1099511627776,T} where T} with indices 0:7: 1.0 + 0.0im 2.0 + 0.0im 3.0 + 0.0im 4.0 + 0.0im 5.0 + 0.0im 6.0 + 0.0im 7.0 + 0.0im 8.0 + 0.0im julia&gt; c = encrypt(kp.pub, plain) CKKS ciphertext (length 2, encoding CKKSEncoding{FixedRational{1099511627776,T} where T}) # And decrypt it again julia&gt; decrypt(kp.priv, c) 8-element CKKSEncoding{FixedRational{1099511627776,T} where T} with indices 0:7: 0.9999999999995506 - 2.7335193113350057e-16im 1.9999999999989408 - 3.885780586188048e-16im 3.000000000000205 + 1.6772825551165524e-16im 4.000000000000538 - 3.885780586188048e-16im 4.999999999998865 + 8.382500573679615e-17im 6.000000000000185 + 4.996003610813204e-16im 7.000000000001043 - 2.0024593503998215e-16im 8.000000000000673 + 4.996003610813204e-16im # Note that we had some noise. Let's go through all the primitive operations we'll need: julia&gt; decrypt(kp.priv, c+c) 8-element CKKSEncoding{FixedRational{1099511627776,T} where T} with indices 0:7: 1.9999999999991012 - 5.467038622670011e-16im 3.9999999999978817 - 7.771561172376096e-16im 6.00000000000041 + 3.354565110233105e-16im 8.000000000001076 - 7.771561172376096e-16im 9.99999999999773 + 1.676500114735923e-16im 12.00000000000037 + 9.992007221626409e-16im 14.000000000002085 - 4.004918700799643e-16im 16.000000000001346 + 9.992007221626409e-16im julia&gt; csq = c*c CKKS ciphertext (length 3, encoding CKKSEncoding{FixedRational{1208925819614629174706176,T} where T}) julia&gt; decrypt(kp.priv, csq) 8-element CKKSEncoding{FixedRational{1208925819614629174706176,T} where T} with indices 0:7: 0.9999999999991012 - 2.350516767363621e-15im 3.9999999999957616 - 5.773159728050814e-15im 9.000000000001226 - 2.534464540987068e-15im 16.000000000004306 - 2.220446049250313e-15im 24.99999999998865 + 2.0903753311370056e-15im 36.00000000000222 + 4.884981308350689e-15im 49.000000000014595 + 1.0182491378134327e-15im 64.00000000001077 + 4.884981308350689e-15im</span></span></code> </pre> <br>  Tan simple!  Un lector atento podr√≠a notar que CSQ es ligeramente diferente del texto cifrado anterior.  En particular, el texto cifrado tiene "longitud 3" y la escala es mucho mayor.  Una explicaci√≥n de qu√© es esto y qu√© se necesita est√° m√°s all√° del alcance de este art√≠culo.  Baste decir que necesitamos bajar los valores antes de continuar con los c√°lculos, de lo contrario el "lugar" terminar√° en el texto cifrado.  Afortunadamente, podemos reducir cada uno de los dos valores aumentados: <br><br><pre> <code class="julia hljs"><span class="hljs-comment"><span class="hljs-comment"># To get back down to length 2, we need to `keyswitch` (aka # relinerarize), which requires an evaluation key. Generating # this requires the private key. In a real application we would # have generated this up front and sent it along with the encrypted # data, but since we have the private key, we can just do it now. julia&gt; ek = keygen(EvalMultKey, kp.priv) CKKS multiplication key julia&gt; csq_length2 = keyswitch(ek, csq) CKKS ciphertext (length 2, encoding CKKSEncoding{FixedRational{1208925819614629174706176,T} where T}) # Getting the scale back down is done using modswitching. julia&gt; csq_smaller = modswitch(csq_length2) CKKS ciphertext (length 2, encoding CKKSEncoding{FixedRational{1.099511626783e12,T} where T}) # And it still decrypts correctly (though note we've lost some precision) julia&gt; decrypt(kp.priv, csq_smaller) 8-element CKKSEncoding{FixedRational{1.099511626783e12,T} where T} with indices 0:7: 0.9999999999802469 - 5.005163520332181e-11im 3.9999999999957723 - 1.0468514951188039e-11im 8.999999999998249 - 4.7588542623100616e-12im 16.000000000023014 - 1.0413447889166631e-11im 24.999999999955193 - 6.187833723406491e-12im 36.000000000002345 + 1.860733715346631e-13im 49.00000000001647 - 1.442396043149794e-12im 63.999999999988695 - 1.0722489563648028e-10im</span></span></code> </pre> <br>  Adem√°s, la conmutaci√≥n de modulaci√≥n (abreviatura de conmutaci√≥n de m√≥dulo, conmutaci√≥n de m√≥dulo) reduce el tama√±o del m√≥dulo de texto cifrado, por lo que no podemos continuar haciendo esto indefinidamente (utilizamos un esquema de cifrado algo homom√≥rfico): <br><br><pre> <code class="julia hljs">julia&gt; ‚Ñõ <span class="hljs-comment"><span class="hljs-comment"># Remember the ring we initially created ‚Ñ§‚ÇÅ‚ÇÉ‚ÇÇ‚Çâ‚ÇÇ‚ÇÇ‚Çá‚Çâ‚Çâ‚Çá‚ÇÖ‚ÇÜ‚Çà‚ÇÄ‚Çà‚ÇÅ‚ÇÑ‚ÇÖ‚Çá‚ÇÑ‚ÇÄ‚ÇÇ‚Çá‚ÇÄ‚ÇÅ‚ÇÇ‚ÇÄ‚Çá‚ÇÅ‚ÇÄ‚ÇÑ‚ÇÇ‚ÇÑ‚Çà‚ÇÇ‚ÇÖ‚Çá/(x¬π‚Å∂ + 1) julia&gt; ToyFHE.ring(csq_smaller) # It shrunk! ‚Ñ§‚ÇÅ‚ÇÇ‚ÇÄ‚Çà‚Çâ‚ÇÇ‚ÇÖ‚Çà‚ÇÇ‚ÇÄ‚ÇÅ‚ÇÑ‚ÇÑ‚ÇÖ‚Çâ‚ÇÉ‚Çá‚Çá‚Çâ‚ÇÉ‚ÇÉ‚ÇÅ‚ÇÖ‚ÇÖ‚ÇÉ/(x¬π‚Å∂ + 1)&lt;/code&gt;     ‚Äî  (rotations).      keyswitch,       (evaluation key,     ): &lt;source lang="julia"&gt;julia&gt; gk = keygen(GaloisKey, kp.priv; steps=2) CKKS galois key (element 25) julia&gt; decrypt(circshift(c, gk)) decrypt(kp, circshift(c, gk)) 8-element CKKSEncoding{FixedRational{1099511627776,T} where T} with indices 0:7: 7.000000000001042 + 5.68459112632516e-16im 8.000000000000673 + 5.551115123125783e-17im 0.999999999999551 - 2.308655353580721e-16im 1.9999999999989408 + 2.7755575615628914e-16im 3.000000000000205 - 6.009767921608429e-16im 4.000000000000538 + 5.551115123125783e-17im 4.999999999998865 + 4.133860996136768e-17im 6.000000000000185 - 1.6653345369377348e-16im # And let's compare to doing the same on the plaintext julia&gt; circshift(plain, 2) 8-element OffsetArray(::Array{Complex{Float64},1}, 0:7) with eltype Complex{Float64} with indices 0:7: 7.0 + 0.0im 8.0 + 0.0im 1.0 + 0.0im 2.0 + 0.0im 3.0 + 0.0im 4.0 + 0.0im 5.0 + 0.0im 6.0 + 0.0im</span></span></code> </pre> <br>  Cubrimos los conceptos b√°sicos del uso de la biblioteca HE.  Pero antes de seguir usando estas primitivas para calcular los pron√≥sticos de la red neuronal, veamos el proceso de aprendizaje. <br><br><h2>  Modelo de aprendizaje autom√°tico </h2><br>  Si no est√° familiarizado con el aprendizaje autom√°tico o la biblioteca Flux.jl, le recomiendo una <a href="https://fluxml.ai/Flux.jl/stable/">revisi√≥n</a> r√°pida de la <a href="https://fluxml.ai/Flux.jl/stable/">documentaci√≥n de Flux.jl</a> o vea una <a href="https://juliaacademy.com/p/introduction-to-machine-learning">introducci√≥n</a> gratuita <a href="https://juliaacademy.com/p/introduction-to-machine-learning">al aprendizaje autom√°tico</a> , porque solo discutiremos los cambios en la aplicaci√≥n del modelo a los datos cifrados. <br><br>  Comencemos usando la red neuronal convolucional <a href="">del zool√≥gico Flux</a> .  Llevaremos a cabo el mismo ciclo de capacitaci√≥n, con preparaci√≥n de datos, etc., solo configuraremos un poco el modelo.  Aqu√≠ esta: <br><br><pre> <code class="julia hljs"><span class="hljs-keyword"><span class="hljs-keyword">function</span></span> reshape_and_vcat(x) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> y=reshape(x, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, size(x, <span class="hljs-number"><span class="hljs-number">4</span></span>)) vcat((y[:,i,:] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i=axes(y,<span class="hljs-number"><span class="hljs-number">2</span></span>))...) <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> model = Chain( <span class="hljs-comment"><span class="hljs-comment"># First convolution, operating upon a 28x28 image Conv((7, 7), 1=&gt;4, stride=(3,3), x-&gt;x.^2), reshape_and_vcat, Dense(256, 64, x-&gt;x.^2), Dense(64, 10), )</span></span></code> </pre><br>  Este es el mismo modelo que en el trabajo <a href="https://eprint.iacr.org/2018/1041.pdf">"Computaci√≥n y aplicaci√≥n de matriz de outsourcing seguro a redes neuronales"</a> , que utiliza el mismo esquema criptogr√°fico con dos diferencias: 1) en aras de la simplicidad, no ciframos el modelo en s√≠, y 2) despu√©s de cada capa tenemos Se usan vectores bayesianos (en Flux, esto se hace de manera predeterminada), no estoy seguro de qu√© era en el trabajo mencionado.  Quiz√°s, debido al segundo punto, la precisi√≥n en el conjunto de pruebas de nuestro modelo result√≥ ser ligeramente mayor (98.6% versus 98.1%), pero las diferencias hiperparam√©tricas tambi√©n podr√≠an ser la raz√≥n. <br><br>  Inusual (para aquellos que tienen experiencia en aprendizaje autom√°tico) es la activaci√≥n de funciones <code>x.^2</code> .  Muy a menudo en tales casos usan <code>tanh</code> , <code>relu</code> o algo m√°s imaginario.  Pero aunque estas funciones (especialmente <code>relu</code> ) se calculan f√°cilmente para valores de texto ordinarios, sin embargo, pueden requerir muchos recursos inform√°ticos para evaluarlas en forma cifrada (generalmente estimamos la aproximaci√≥n polin√≥mica).  Afortunadamente, en este caso <code>x.^2</code> funciona muy bien. <br><br>  El resto del ciclo de aprendizaje permaneci√≥ igual.  <code>softmax</code> del modelo para la <code>logitcrossentropy</code> funci√≥n de <code>logitcrossentropy</code> (puede dejarlo y evaluar softmax despu√©s del descifrado en el cliente).  El c√≥digo completo para entrenar el modelo se encuentra <a href="">en GitHub</a> , se ejecuta en unos minutos en cualquier tarjeta de video nueva. <br><br><h2>  Operaciones efectivas </h2><br>  Ahora sabemos qu√© operaciones debemos realizar: <br><br><ul><li>  Coagulaci√≥n <br></li><li>  Elemento cuadrado. <br></li><li>  Multiplicaci√≥n matricial. <br></li></ul><br>  Con la cuadratura todo es simple, ya lo hemos examinado anteriormente, por lo que consideraremos otras dos operaciones.  Suponemos que la longitud del paquete de datos es 64 (puede observar que los par√°metros del modelo y el tama√±o del paquete se eligen para aprovechar el vector de 4096 elementos que obtuvimos como resultado de una elecci√≥n realista de par√°metros). <br><br><h3>  Coagulaci√≥n </h3><br>  Recordemos c√≥mo funciona la coagulaci√≥n.  Tome una ventana (en nuestro caso 7x7) de la matriz de entrada original, y cada elemento de la ventana se multiplica por un elemento de m√°scara de convoluci√≥n.  Luego movemos la ventana a alg√∫n paso (en nuestro caso, el paso es 3, es decir, movemos 3 elementos) y repetimos el proceso (con la misma m√°scara de convoluci√≥n).  La animaci√≥n del proceso ( <a href="https://github.com/vdumoulin/conv_arithmetic">fuente</a> ) para la convoluci√≥n 3x3 con el paso <code>(2, 2)</code> muestra a continuaci√≥n (matriz azul - entrada, verde - salida): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/h5/a3/q3/h5a3q3ea0pljgdagz1wd-k2igdy.gif"></div><br>  Adem√°s, realizamos convoluci√≥n en cuatro "canales" diferentes (es decir, repetimos la convoluci√≥n 3 veces m√°s con diferentes m√°scaras). <br><br>  Ahora que sabemos qu√© hacer, queda por entender c√≥mo.  Somos afortunados de que la convoluci√≥n sea la primera operaci√≥n en nuestro modelo.  Como resultado, para ahorrar recursos, podemos preprocesar los datos en el cliente y luego encriptarlos (sin usar pesos).  Hagamos esto: <br><br><ul><li>  Primero, calculamos cada ventana de convoluci√≥n (es decir, una muestra de 7x7 de las im√°genes de origen), lo que nos da 64 matrices de 7x7 para cada imagen de entrada.  Tenga en cuenta que para una ventana de 7x7 en incrementos de 2, habr√° ventanas de convoluci√≥n de 8x8 para evaluar la imagen de entrada de 28x28. <br></li><li>  Recolectemos en un vector las mismas posiciones en cada ventana.  Es decir, para cada imagen tendremos un vector de 64 elementos, o un vector de elementos de 64x64 para un paquete de tama√±o 64 (un total de 49 matrices de 64x64). <br></li><li>  Lo encriptaremos. <br></li></ul><br>  Luego, la coagulaci√≥n simplemente se convierte en una multiplicaci√≥n escalar de toda la matriz con el elemento de m√°scara correspondiente.  Y resumiendo m√°s tarde los 49 elementos, obtenemos el resultado del plegado.  As√≠ es como se ver√≠a la implementaci√≥n de esta estrategia (en texto plano): <br><br><pre> <code class="julia hljs"><span class="hljs-keyword"><span class="hljs-keyword">function</span></span> public_preprocess(batch) ka = OffsetArray(<span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">7</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">7</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Create feature extracted matrix I = [[batch[i‚Ä≤*3 .+ (1:7), j‚Ä≤*3 .+ (1:7), 1, k] for i‚Ä≤=ka, j‚Ä≤=ka] for k = 1:64] # Reshape into the ciphertext I·µ¢‚±º = [[I[k][l...][i,j] for k=1:64, l=product(ka, ka)] for i=1:7, j=1:7] end I·µ¢‚±º = public_preprocess(batch) # Evaluate the convolution weights = model.layers[1].weight conv_weights = reverse(reverse(weights, dims=1), dims=2) conved = [sum(I·µ¢‚±º[i,j]*conv_weights[i,j,1,channel] for i=1:7, j=1:7) for channel = 1:4] conved = map(((x,b),)-&gt;x .+ b, zip(conved, model.layers[1].bias))</span></span></code> </pre> <br>  Este (m√≥dulo para cambiar la dimensi√≥n) (m√≥dulo: cambiar el orden de los tama√±os) da la misma respuesta que la operaci√≥n <code>model.layers[1](batch)</code> . <br><br>  A√±adir operaciones de cifrado: <br><br><pre> <code class="julia hljs">I·µ¢‚±º = public_preprocess(batch) C_I·µ¢‚±º = map(I·µ¢‚±º) <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> Iij plain = CKKSEncoding{Tscale}(zero(plaintext_space(ckks_params))) plain .= OffsetArray(vec(Iij), <span class="hljs-number"><span class="hljs-number">0</span></span>:(N√∑<span class="hljs-number"><span class="hljs-number">2</span></span>-<span class="hljs-number"><span class="hljs-number">1</span></span>)) encrypt(kp, plain) <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> weights = model.layers[<span class="hljs-number"><span class="hljs-number">1</span></span>].weight conv_weights = reverse(reverse(weights, dims=<span class="hljs-number"><span class="hljs-number">1</span></span>), dims=<span class="hljs-number"><span class="hljs-number">2</span></span>) conved3 = [sum(C_I·µ¢‚±º[i,j]*conv_weights[i,j,<span class="hljs-number"><span class="hljs-number">1</span></span>,channel] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i=<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">7</span></span>, j=<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">7</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> channel = <span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conved2 = map(((x,b),)-&gt;x .+ b, zip(conved3, model.layers[<span class="hljs-number"><span class="hljs-number">1</span></span>].bias)) conved1 = map(ToyFHE.modswitch, conved2)</code> </pre> <br>  Tenga en cuenta que no se requiere el interruptor de llave aqu√≠ porque los pesos son p√∫blicos.  Por lo tanto, no aumentamos la longitud del texto cifrado. <br><br><h3>  Multiplicaci√≥n de matrices </h3><br>  Pasando a la multiplicaci√≥n matricial, podemos usar la rotaci√≥n de elementos en el vector para cambiar el orden de los √≠ndices de multiplicaci√≥n.  Considere la colocaci√≥n en fila de elementos de matriz en un vector.  Si cambiamos el vector por un m√∫ltiplo del tama√±o de la fila, obtenemos el efecto de la rotaci√≥n de la columna, que es una primitiva suficiente para implementar la multiplicaci√≥n de matrices (al menos matrices cuadradas).  Probemos <br><br><pre> <code class="julia hljs"><span class="hljs-keyword"><span class="hljs-keyword">function</span></span> matmul_square_reordered(weights, x) sum(<span class="hljs-number"><span class="hljs-number">1</span></span>:size(weights, <span class="hljs-number"><span class="hljs-number">1</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> k <span class="hljs-comment"><span class="hljs-comment"># We rotate the columns of the LHS and take the diagonal weight_diag = diag(circshift(weights, (0,(k-1)))) # We rotate the rows of the RHS x_rotated = circshift(x, (k-1,0)) # We do an elementwise, broadcast multiply weight_diag .* x_rotated end end function matmul_reorderd(weights, x) sum(partition(1:256, 64)) do range matmul_square_reordered(weights[:, range], x[range, :]) end end fc1_weights = model.layers[3].W x = rand(Float64, 256, 64) @assert (fc1_weights*x) ‚âà matmul_reorderd(fc1_weights, x)</span></span></code> </pre> <br>  Por supuesto, para la multiplicaci√≥n matricial general, se requiere algo m√°s complicado, pero por ahora esto es suficiente. <br><br><h2>  Mejorando la t√©cnica </h2><br>  Ahora todos los componentes de nuestra t√©cnica funcionan.  Aqu√≠ est√° el c√≥digo completo (excepto para configurar las opciones de selecci√≥n y cosas similares): <br><br><pre> <code class="julia hljs">ek = keygen(EvalMultKey, kp.priv) gk = keygen(GaloisKey, kp.priv; steps=<span class="hljs-number"><span class="hljs-number">64</span></span>) I·µ¢‚±º = public_preprocess(batch) C_I·µ¢‚±º = map(I·µ¢‚±º) <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> Iij plain = CKKSEncoding{Tscale}(zero(plaintext_space(ckks_params))) plain .= OffsetArray(vec(Iij), <span class="hljs-number"><span class="hljs-number">0</span></span>:(N√∑<span class="hljs-number"><span class="hljs-number">2</span></span>-<span class="hljs-number"><span class="hljs-number">1</span></span>)) encrypt(kp, plain) <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> weights = model.layers[<span class="hljs-number"><span class="hljs-number">1</span></span>].weight conv_weights = reverse(reverse(weights, dims=<span class="hljs-number"><span class="hljs-number">1</span></span>), dims=<span class="hljs-number"><span class="hljs-number">2</span></span>) conved3 = [sum(C_I·µ¢‚±º[i,j]*conv_weights[i,j,<span class="hljs-number"><span class="hljs-number">1</span></span>,channel] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i=<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">7</span></span>, j=<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">7</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> channel = <span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conved2 = map(((x,b),)-&gt;x .+ b, zip(conved3, model.layers[<span class="hljs-number"><span class="hljs-number">1</span></span>].bias)) conved1 = map(ToyFHE.modswitch, conved2) Csqed1 = map(x-&gt;x*x, conved1) Csqed1 = map(x-&gt;keyswitch(ek, x), Csqed1) Csqed1 = map(ToyFHE.modswitch, Csqed1) <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> encrypted_matmul(gk, weights, x::ToyFHE.CipherText) result = repeat(diag(weights), inner=<span class="hljs-number"><span class="hljs-number">64</span></span>).*x rotated = x <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k = <span class="hljs-number"><span class="hljs-number">2</span></span>:<span class="hljs-number"><span class="hljs-number">64</span></span> rotated = ToyFHE.rotate(gk, rotated) result += repeat(diag(circshift(weights, (<span class="hljs-number"><span class="hljs-number">0</span></span>,(k-<span class="hljs-number"><span class="hljs-number">1</span></span>)))), inner=<span class="hljs-number"><span class="hljs-number">64</span></span>) .* rotated <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> result <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> fq1_weights = model.layers[<span class="hljs-number"><span class="hljs-number">3</span></span>].W Cfq1 = sum(enumerate(partition(<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>))) <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> (i,range) encrypted_matmul(gk, fq1_weights[:, range], Csqed1[i]) <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> Cfq1 = Cfq1 .+ OffsetArray(repeat(model.layers[<span class="hljs-number"><span class="hljs-number">3</span></span>].b, inner=<span class="hljs-number"><span class="hljs-number">64</span></span>), <span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">4095</span></span>) Cfq1 = modswitch(Cfq1) Csqed2 = Cfq1*Cfq1 Csqed2 = keyswitch(ek, Csqed2) Csqed2 = modswitch(Csqed2) <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> naive_rectangular_matmul(gk, weights, x) <span class="hljs-meta"><span class="hljs-meta">@assert</span></span> size(weights, <span class="hljs-number"><span class="hljs-number">1</span></span>) &lt; size(weights, <span class="hljs-number"><span class="hljs-number">2</span></span>) weights = vcat(weights, zeros(eltype(weights), size(weights, <span class="hljs-number"><span class="hljs-number">2</span></span>)-size(weights, <span class="hljs-number"><span class="hljs-number">1</span></span>), size(weights, <span class="hljs-number"><span class="hljs-number">2</span></span>))) encrypted_matmul(gk, weights, x) <span class="hljs-keyword"><span class="hljs-keyword">end</span></span> fq2_weights = model.layers[<span class="hljs-number"><span class="hljs-number">4</span></span>].W Cresult = naive_rectangular_matmul(gk, fq2_weights, Csqed2) Cresult = Cresult .+ OffsetArray(repeat(vcat(model.layers[<span class="hljs-number"><span class="hljs-number">4</span></span>].b, zeros(<span class="hljs-number"><span class="hljs-number">54</span></span>)), inner=<span class="hljs-number"><span class="hljs-number">64</span></span>), <span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">4095</span></span>)</code> </pre> <br>  No se ve muy bien, pero si hiciste todo esto, deber√≠as entender cada paso. <br>  Ahora pensemos en qu√© abstracciones podr√≠an simplificar nuestras vidas.  Estamos dejando el campo de la cartograf√≠a y el aprendizaje autom√°tico y avanzando hacia la arquitectura del lenguaje de programaci√≥n, as√≠ que aprovechemos el hecho de que Julia le permite usar y crear poderosas abstracciones.  Por ejemplo, puede encapsular todo el proceso de extracci√≥n de convoluciones en su tipo de matriz: <br><br><pre> <code class="julia hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> BlockArrays <span class="hljs-string"><span class="hljs-string">""" ExplodedConvArray{T, Dims, Storage} &lt;: AbstractArray{T, 4} Represents a an `nxmx1xb` array of images, but rearranged into a series of convolution windows. Evaluating a convolution compatible with `Dims` on this array is achievable through a sequence of scalar multiplications and sums on the underling storage. """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">struct</span></span> ExplodedConvArray{T, <span class="hljs-built_in"><span class="hljs-built_in">Dims</span></span>, Storage} &lt;: <span class="hljs-built_in"><span class="hljs-built_in">AbstractArray</span></span>{T, <span class="hljs-number"><span class="hljs-number">4</span></span>} <span class="hljs-comment"><span class="hljs-comment"># sx*sy matrix of b*(dx*dy) matrices of extracted elements # where (sx, sy) = kernel_size(Dims) # (dx, dy) = output_size(DenseConvDims(...)) cdims::Dims x::Matrix{Storage} function ExplodedConvArray{T, Dims, Storage}(cdims::Dims, storage::Matrix{Storage}) where {T, Dims, Storage} @assert all(==(size(storage[1])), size.(storage)) new{T, Dims, Storage}(cdims, storage) end end Base.size(ex::ExplodedConvArray) = (NNlib.input_size(ex.cdims)..., 1, size(ex.x[1], 1)) function ExplodedConvArray{T}(cdims, batch::AbstractArray{T, 4}) where {T} x, y = NNlib.output_size(cdims) kx, ky = NNlib.kernel_size(cdims) stridex, stridey = NNlib.stride(cdims) kax = OffsetArray(0:x-1, 0:x-1) kay = OffsetArray(0:x-1, 0:x-1) I = [[batch[i‚Ä≤*stridex .+ (1:kx), j‚Ä≤*stridey .+ (1:ky), 1, k] for i‚Ä≤=kax, j‚Ä≤=kay] for k = 1:size(batch, 4)] I·µ¢‚±º = [[I[k][l...][i,j] for k=1:size(batch, 4), l=product(kax, kay)] for (i,j) in product(1:kx, 1:ky)] ExplodedConvArray{T, typeof(cdims), eltype(I·µ¢‚±º)}(cdims, I·µ¢‚±º) end function NNlib.conv(x::ExplodedConvArray{&lt;:Any, Dims}, weights::AbstractArray{&lt;:Any, 4}, cdims::Dims) where {Dims&lt;:ConvDims} blocks = reshape([ Base.ReshapedArray(sum(xx[i,j]*weights[i,j,1,channel] for i=1:7, j=1:7), (NNlib.output_size(cdims)...,1,size(x, 4)), ()) for channel = 1:4 ],(1,1,4,1)) BlockArrays._BlockArray(blocks, BlockArrays.BlockSizes([8], [8], [1,1,1,1], [64])) end</span></span></code> </pre><br>  Aqu√≠ nuevamente utilizamos <code>BlockArrays</code> para representar una matriz de <code>8x8x4x64</code> como cuatro matrices de <code>8x8x1x64</code> como en el c√≥digo fuente.  Ahora la presentaci√≥n de la primera etapa se ha vuelto mucho m√°s bella, al menos con arreglos no cifrados: <br><br><pre> <code class="julia hljs">julia&gt; cdims = DenseConvDims(batch, model.layers[<span class="hljs-number"><span class="hljs-number">1</span></span>].weight; stride=(<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), padding=(<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>), dilation=(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>)) DenseConvDims: (<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) * (<span class="hljs-number"><span class="hljs-number">7</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>) -&gt; (<span class="hljs-number"><span class="hljs-number">8</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>), stride: (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) pad: (<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>), dil: (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), flip: <span class="hljs-literal"><span class="hljs-literal">false</span></span> julia&gt; a = ExplodedConvArray{eltype(batch)}(cdims, batch); julia&gt; model(a) <span class="hljs-number"><span class="hljs-number">10</span></span>√ó<span class="hljs-number"><span class="hljs-number">64</span></span> <span class="hljs-built_in"><span class="hljs-built_in">Array</span></span>{<span class="hljs-built_in"><span class="hljs-built_in">Float32</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>}: [snip]</code> </pre><br>  Ahora, ¬øc√≥mo conectamos esto con el cifrado?  Para hacer esto, necesitas: <br><br><ol><li>  Cifre la estructura ( <code>ExplodedConvArray</code> ) para que obtengamos el texto cifrado de cada campo.  Las operaciones con una estructura encriptada de este tipo verificar√°n lo que la funci√≥n har√≠a con la estructura original, y har√°n lo mismo homom√≥rficamente. <br></li><li>  Intercepte ciertas operaciones para realizarlas de manera diferente en un contexto cifrado. </li></ol><br>  Afortunadamente, Julia nos proporciona una abstracci√≥n para esto: un complemento de compilaci√≥n que utiliza el mecanismo <a href="">Cassette.jl</a> .  No le dir√© qu√© es y c√≥mo funciona, dir√© brevemente que puede determinar el contexto, por ejemplo, <code>Encrypted</code> , y luego define las reglas de c√≥mo deber√≠an funcionar las operaciones en este contexto.  Por ejemplo, puede escribir esto para el segundo requisito: <br><br><pre> <code class="julia hljs"><span class="hljs-comment"><span class="hljs-comment"># Define Matrix multiplication between an array and an encrypted block array function (*::Encrypted{typeof(*)})(a::Array{T, 2}, b::Encrypted{&lt;:BlockArray{T, 2}}) where {T} sum(a*b for (i,range) in enumerate(partition(1:size(a, 2), size(b.blocks[1], 1)))) end # Define Matrix multiplication between an array and an encrypted array function (*::Encrypted{typeof(*)})(a::Array{T, 2}, b::Encrypted{Array{T, 2}}) where {T} result = repeat(diag(a), inner=size(a, 1)).*x rotated = b for k = 2:size(a, 2) rotated = ToyFHE.rotate(GaloisKey(*), rotated) result += repeat(diag(circshift(a, (0,(k-1)))), inner=size(a, 1)) .* rotated end result end</span></span></code> </pre><br>  Como resultado, el usuario podr√° escribir todo lo anterior con una cantidad m√≠nima de trabajo manual: <br><br><pre> <code class="julia hljs">kp = keygen(ckks_params) ek = keygen(EvalMultKey, kp.priv) gk = keygen(GaloisKey, kp.priv; steps=<span class="hljs-number"><span class="hljs-number">64</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Create evaluation context ctx = Encrypted(ek, gk) # Do public preprocessing batch = ExplodedConvArray{eltype(batch)}(cdims, batch); # Run on encrypted data under the encryption context Cresult = ctx(model)(encrypt(kp.pub, batch)) # Decrypt the answer decrypt(kp, Cresult)</span></span></code> </pre> <br> ,     .   (   ‚Ñõ,   modswitch, keyswitch  ..)       ,      .  ,    ,    ,         ,        . <br><br><h2>  Conclusi√≥n </h2><br>          ‚Äî      .     Julia          .  RAMPARTS ( <a href="https://eprint.iacr.org/2019/988.pdf">paper</a> , <a href="https://www.youtube.com/watch%3Fv%3D_KLlMg6jKQg">JuliaCon talk</a> )       :  Julia-   -  PALISADE. Julia Computing    RAMPARTS    Verona, <a href="https://galois.com/news/15m-iarpa-hector-contract-privacy-preserving-technology/"> </a>     .             ,     .  .     ,   ,          . <br><br>        ,   <a href=""> ToyFHE</a> .   <a href="https://juliacomputing.github.io/ToyFHE.jl/dev/man/background/"></a> , ,   ,         . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/478514/">https://habr.com/ru/post/478514/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../478498/index.html">1. Fortinet Getting Started v 6.0. Introduccion</a></li>
<li><a href="../478500/index.html">¬øPor qu√© hay tan pocas conferencias en el verano?</a></li>
<li><a href="../478502/index.html">Tecnolog√≠a inteligente para todos</a></li>
<li><a href="../478504/index.html">C√≥mo se transforma el lugar de trabajo con la evoluci√≥n de la computadora port√°til</a></li>
<li><a href="../478510/index.html">Te invitamos a DINS QA NOCHE 12/12/19: crea una tuber√≠a de Jenkins y aprende c√≥mo paralelizar el lanzamiento de pruebas con su ayuda</a></li>
<li><a href="../478516/index.html">Caminos procesales en Houdini y Unity</a></li>
<li><a href="../478518/index.html">Experiencia implementando infraestructura de oficina en Zextras / Zimbra OSE</a></li>
<li><a href="../478522/index.html">Adm√≠telo, Watson, ¬øest√°s completamente desconcertado?</a></li>
<li><a href="../478526/index.html">Un mont√≥n de OpenVPN en Windows Server y Mikrotik con la migraci√≥n de estas cosas a Linux</a></li>
<li><a href="../478528/index.html">Mascota (una historia fant√°stica)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
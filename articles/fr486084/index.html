<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>âš™ï¸ ğŸ‘©â€â¤ï¸â€ğŸ‘¨ ğŸ‹ Remplacement de disques plus petits par des disques plus grands sous Linux ğŸ‘¸ğŸ» ğŸ® ğŸ‘©ğŸ»â€ğŸŒ¾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour Ã  tous. En prÃ©vision du dÃ©but d'un nouveau groupe de cours Administrateur Linux, nous publions du matÃ©riel utile rÃ©digÃ© par notre Ã©tudiant, ai...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Remplacement de disques plus petits par des disques plus grands sous Linux</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/486084/">  <i>Bonjour Ã  tous.</i>  <i>En prÃ©vision du dÃ©but d'un nouveau groupe de cours <a href="https://otus.pw/RDsq/">Administrateur Linux, nous</a> publions du matÃ©riel utile rÃ©digÃ© par notre Ã©tudiant, ainsi que par le mentor du cours, Roman Travin, spÃ©cialiste du support technique des produits d'entreprise REG.RU.</i> <br><br>  Dans cet article, nous considÃ©rerons 2 cas de remplacement de disques et de transfert d'informations vers de nouveaux disques d'un volume plus important avec une expansion supplÃ©mentaire de la baie et du systÃ¨me de fichiers.  Le premier cas concernera le remplacement de disques avec le mÃªme balisage MBR / MBR ou GPT / GPT, le deuxiÃ¨me cas concernera le remplacement de disques avec marquage MBR sur des disques d'une capacitÃ© supÃ©rieure Ã  2 To, sur lesquels un balisage GPT avec la partition de dÃ©marrage biologique sera requis.  Dans les deux cas, les disques vers lesquels nous transfÃ©rons les donnÃ©es sont dÃ©jÃ  installÃ©s sur le serveur.  Le systÃ¨me de fichiers utilisÃ© pour la partition racine est ext4. <br><br><hr><a name="habracut"></a><br><h3>  Cas 1: remplacement de disques plus petits par des disques plus grands (jusqu'Ã  2 To) </h3><br>  <b>TÃ¢che:</b> remplacer les disques actuels par des disques plus gros (jusqu'Ã  2 To) par transfert d'informations.  Dans ce cas, nous avons 2 disques SSD (RAID-1) de 240 Go avec le systÃ¨me installÃ© et 2 disques SATA de 1 To sur lesquels vous devez transfÃ©rer le systÃ¨me. <br><br>  Tenez compte de la disposition actuelle du disque. <br><br><pre><code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sda2 8:2 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 931,5G 0 disk sdd 8:48 0 931,5G 0 disk</span></span></code> </pre> <br>  VÃ©rifiez l'espace actuel du systÃ¨me de fichiers utilisÃ©. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># df -h      % C  devtmpfs 32G 0 32G 0% /dev tmpfs 32G 0 32G 0% /dev/shm tmpfs 32G 9,6M 32G 1% /run tmpfs 32G 0 32G 0% /sys/fs/cgroup /dev/mapper/vg0-root 204G 1,3G 192G 1% / /dev/md126 1007M 120M 837M 13% /boot tmpfs 6,3G 0 6,3G 0% /run/user/0</span></span></code> </pre> <br>  La taille du systÃ¨me de fichiers avant de remplacer les disques est de 204 Go, 2 baies logicielles md126 sont utilisÃ©es, qui est montÃ©e dans <code>/boot</code> et <code>md127</code> , qui est utilisÃ© comme <i>volume physique</i> pour le groupe VG <i>vg0</i> . <br><br><h4>  1. Suppression de partitions de disque des baies </h4><br>  VÃ©rifiez l'Ã©tat de la baie <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sda1[0] sdb1[1] 1047552 blocks super 1.2 [2/2] [UU] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sda2[0] sdb2[1] 233206784 blocks super 1.2 [2/2] [UU] bitmap: 0/2 pages [0KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br>  Le systÃ¨me utilise 2 tableaux: <code>md126</code> (point de montage <code>/boot</code> ) - se compose des <code>md127</code> <code>/dev/sda1</code> et <code>/dev/sdb1</code> , <code>md127</code> (LVM pour l' <i>Ã©change</i> et la racine du systÃ¨me de fichiers) - se compose de <code>/dev/sda2</code> et <code>/dev/sdb2</code> . <br><br>  Nous marquons les partitions du premier disque, qui sont utilisÃ©es dans chaque baie, comme mauvaises. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --fail /dev/sda1 mdadm /dev/md127 --fail /dev/sda2</code> </pre><br>  Nous supprimons des sections du bloc pÃ©riphÃ©rique / dev / sda des tableaux. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --remove /dev/sda1 mdadm /dev/md127 --remove /dev/sda2</code> </pre> <br>  AprÃ¨s avoir supprimÃ© le disque de la baie, les informations sur les pÃ©riphÃ©riques de bloc ressembleront Ã  ceci. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 931,5G 0 disk sdd 8:48 0 931,5G 0 disk</span></span></code> </pre> <br>  L'Ã©tat des baies aprÃ¨s la suppression des disques. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdb1[1] 1047552 blocks super 1.2 [2/1] [_U] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sdb2[1] 233206784 blocks super 1.2 [2/1] [_U] bitmap: 1/2 pages [4KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br><h4>  2. Copie de la table de partition sur un nouveau disque </h4><br>  Vous pouvez vÃ©rifier la table de partition utilisÃ©e sur le disque avec la commande suivante. <br><br><pre> <code class="bash hljs">fdisk -l /dev/sdb | grep <span class="hljs-string"><span class="hljs-string">'Disk label type'</span></span></code> </pre><br>  La sortie pour le MBR sera: <br><br><pre> <code class="bash hljs">Disk label <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>: dos</code> </pre> <br>  pour GPT: <br><br><pre> <code class="bash hljs">Disk label <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>: gpt</code> </pre> <br>  <b>Copier la table de balisage pour MBR:</b> <b><br></b> <br><pre> <code class="bash hljs">sfdisk -d /dev/sdb | sfdisk /dev/sdc</code> </pre> <br>  Dans cette commande, le <b>premier</b> est le lecteur Ã  <b>partir</b> <b>duquel le</b> balisage <b>est</b> copiÃ©, le <b>second est l'endroit oÃ¹</b> copier. <br><br><blockquote>  <b>ATTENTION</b> : Pour GPT, le lecteur <b>sur</b> lequel copier le balisage est le <b>premier Ã  Ãªtre</b> indiquÃ©, le lecteur <b>sur</b> lequel copier le balisage Ã  partir du <b>deuxiÃ¨me</b> lecteur.  Si vous mÃ©langez les disques, le balisage initialement sain sera Ã©crasÃ© et dÃ©truit. <br></blockquote><br>  <b>Copie de la table de balisage pour le GPT:</b> <b><br></b> <br><pre> <code class="bash hljs">sgdisk -R /dev/sd /dev/sdb</code> </pre> <br>  Ensuite, attribuez un UUID alÃ©atoire au disque (pour GPT). <br><br><pre> <code class="bash hljs">sgdisk -G /dev/sdc</code> </pre> <br>  Une fois la commande exÃ©cutÃ©e, les partitions doivent apparaÃ®tre sur le disque <code>/dev/sdc</code> . <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â””â”€sdc2 8:34 0 222,5G 0 part sdd 8:48 0 931,5G 0 disk</span></span></code> </pre> <br>  Si, aprÃ¨s l'action effectuÃ©e, les partitions du systÃ¨me sur le disque <code>/dev/sdc</code> ne sont pas dÃ©finies, nous exÃ©cutons la commande pour relire la table des partitions. <br><br><pre> <code class="bash hljs">sfdisk -R /dev/sdc</code> </pre> <br>  Si les disques actuels utilisent la table MBR et que les informations doivent Ãªtre transfÃ©rÃ©es vers des disques d'une capacitÃ© supÃ©rieure Ã  2 To, les nouveaux disques devront crÃ©er manuellement un balisage GPT Ã  l'aide de la section de dÃ©marrage biologique.  Ce cas sera examinÃ© dans la partie 2 de cet article. <br><br><h4>  3. Ajout de partitions du nouveau disque Ã  la baie </h4><br>  Ajoutez des partitions de disque aux tableaux correspondants. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --add /dev/sdc1 mdadm /dev/md127 --add /dev/sdc2</code> </pre> <br>  VÃ©rifiez que des sections ont Ã©tÃ© ajoutÃ©es. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk</span></span></code> </pre> <br>  AprÃ¨s cela, nous attendons la synchronisation des tableaux. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdc1[2] sdb1[1] 1047552 blocks super 1.2 [2/2] [UU] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sdc2[2] sdb2[1] 233206784 blocks super 1.2 [2/1] [_U] [==&gt;..................] recovery = 10.6% (24859136/233206784) finish=29.3min speed=118119K/sec bitmap: 2/2 pages [8KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br>  Vous pouvez surveiller en continu le processus de synchronisation Ã  l'aide de l'utilitaire de <code>watch</code> . <br><br><pre> <code class="bash hljs">watch -n 2 cat /proc/mdstat</code> </pre> <br>  L' <code>-n</code> spÃ©cifie Ã  quels intervalles en secondes la commande doit Ãªtre exÃ©cutÃ©e pour vÃ©rifier la progression. <br><br>  <b>RÃ©pÃ©tez les Ã©tapes 1 Ã  3 pour le lecteur de remplacement suivant.</b> <br><br>  Nous marquons les partitions du deuxiÃ¨me disque, qui sont utilisÃ©es dans chaque baie, comme mauvaises. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --fail /dev/sdb1 mdadm /dev/md127 --fail /dev/sdb2</code> </pre><br>  Nous supprimons des sections du bloc pÃ©riphÃ©rique <code>/dev/sdb</code> des tableaux. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --remove /dev/sdb1 mdadm /dev/md127 --remove /dev/sdb2</code> </pre> <br>  AprÃ¨s avoir supprimÃ© le disque de la baie, les informations sur les pÃ©riphÃ©riques de bloc ressembleront Ã  ceci. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk</span></span></code> </pre><br>  L'Ã©tat des baies aprÃ¨s la suppression des disques. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdc1[2] 1047552 blocks super 1.2 [2/1] [U_] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sdc2[2] 233206784 blocks super 1.2 [2/1] [U_] bitmap: 1/2 pages [4KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br>  Copiez la table de balisage MBR du lecteur <code>/dev/sd</code> vers le lecteur <code>/dev/sdd</code> . <br><br><pre> <code class="bash hljs">sfdisk -d /dev/sd | sfdisk /dev/sdd</code> </pre> <br>  Une fois la commande exÃ©cutÃ©e, les partitions doivent apparaÃ®tre sur le lecteur <code>/dev/sdd</code> . <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk â”œâ”€sdd1 8:49 0 1G 0 part â””â”€sdd2 8:50 0 222,5G 0 part</span></span></code> </pre> <br>  Ajoutez des partitions de disque aux tableaux. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --add /dev/sdd1 mdadm /dev/md127 --add /dev/sdd2</code> </pre> <br>  VÃ©rifiez que des sections ont Ã©tÃ© ajoutÃ©es. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk â”œâ”€sdd1 8:49 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdd2 8:50 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</span></span></code> </pre> <br>  AprÃ¨s cela, nous attendons la synchronisation des tableaux. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdd1[3] sdc1[2] 1047552 blocks super 1.2 [2/2] [UU] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sdd2[3] sdc2[2] 233206784 blocks super 1.2 [2/1] [U_] [&gt;....................] recovery = 0.5% (1200000/233206784) finish=35.4min speed=109090K/sec bitmap: 2/2 pages [8KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre><br><h4>  5. Installez GRUB sur de nouveaux disques </h4><br>  Pour CentOS: <br><br><pre> <code class="bash hljs">grub2-install /dev/sdX</code> </pre> <br>  Pour Debian / Ubuntu: <br><br><pre> <code class="bash hljs">grub-install /dev/sdX</code> </pre> <br>  oÃ¹ <code>X</code> est la lettre du pÃ©riphÃ©rique de bloc.  Dans ce cas, installez GRUB sur <code>/dev/sdc</code> et <code>/dev/sdd</code> . <br><br><h4>  6. Extension du systÃ¨me de fichiers (ext4) de la partition racine </h4><br>  931,5 Go sont disponibles sur les nouveaux <code>/dev/sdc</code> et <code>/dev/sdd</code> .  Ã‰tant donnÃ© que la table de partition est copiÃ©e Ã  partir de disques plus petits, 222,5 Go sont disponibles sur les <code>/dev/sdc2</code> et <code>/dev/sdd2</code> . <br><br><pre> <code class="bash hljs">sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk â”œâ”€sdd1 8:49 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdd2 8:50 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</code> </pre> <br>  Il faut: <br><br><ol><li>  Ã‰tendez la section 2 sur chaque lecteur, </li><li>  Ã‰tendez le tableau md127, </li><li>  DÃ©veloppez PV (volume physique), </li><li>  Ã‰tendre LV (volume logique) vg0-root, </li><li>  Ã‰tendez le systÃ¨me de fichiers. </li></ol><br>  Ã€ l'aide de l'utilitaire <i>parted,</i> dÃ©veloppez la <code>/dev/sdc2</code> Ã  la valeur maximale.  <code>parted /dev/sdc</code> commande <code>parted /dev/sdc</code> (1) et visualisons la table de partition actuelle avec la commande <code>p</code> (2). <br><br><img src="https://habrastorage.org/webt/ao/zx/xc/aozxxc_zhq42me4qblnij5bib4y.png"><br><br>  Comme vous pouvez le voir, la fin de la section 2 se termine avec 240 Go.  DÃ©veloppons la section avec la commande <code>resizepart</code> <code>2</code> , oÃ¹ 2 est le numÃ©ro de section (3).  Nous indiquons la valeur au format numÃ©rique, par exemple 1000 Go, ou nous utilisons l'indication du partage de disque - 100%.  Encore une fois, nous vÃ©rifions que la section a une nouvelle taille (4). <br><br>  RÃ©pÃ©tez les Ã©tapes ci-dessus pour le lecteur <code>/dev/sdd</code> .  AprÃ¨s avoir Ã©tendu les partitions, <code>/dev/sdc2</code> et <code>/dev/sdd2</code> devenus Ã©gaux Ã  930,5 Go. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 930,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk â”œâ”€sdd1 8:49 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdd2 8:50 0 930,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</span></span></code> </pre> <br>  AprÃ¨s cela, nous dÃ©veloppons le tableau <i>md127</i> au maximum. <br><br><pre> <code class="bash hljs">mdadm --grow /dev/md127 --size=max</code> </pre> <br>  VÃ©rifiez que le tableau s'est Ã©tendu.  Maintenant, sa taille est devenue 930,4 Go. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 931,5G 0 disk â”œâ”€sdc1 8:33 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc2 8:34 0 930,5G 0 part â””â”€md127 9:127 0 930,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 931,5G 0 disk â”œâ”€sdd1 8:49 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdd2 8:50 0 930,5G 0 part â””â”€md127 9:127 0 930,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</span></span></code> </pre> <br>  Nous effectuons l'expansion du <i>volume physique</i> .  Avant l'extension, vÃ©rifiez l'Ã©tat actuel de la PV. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># pvscan PV /dev/md127 VG vg0 lvm2 [222,40 GiB / 0 free] Total: 1 [222,40 GiB] / in use: 1 [222,40 GiB] / in no VG: 0 [0 ]</span></span></code> </pre><br>  Comme vous pouvez le voir, PV <code>/dev/md127</code> utilise <code>/dev/md127</code> Go d'espace. <br><br>  DÃ©veloppez PV avec la commande suivante. <br><br><pre> <code class="bash hljs">pvresize /dev/md127</code> </pre> <br>  VÃ©rifiez le rÃ©sultat de l'extension PV. <br><br>  [ <pre> <code class="bash hljs">root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># pvscan PV /dev/md127 VG vg0 lvm2 [930,38 GiB / 707,98 GiB free] Total: 1 [930,38 GiB] / in use: 1 [930,38 GiB] / in no VG: 0 [0 ]</span></span></code> </pre> <br>  Extension du <i>volume logique</i> .  Avant l'extension, vÃ©rifiez l'Ã©tat actuel de LV (1). <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lvscan ACTIVE '/dev/vg0/swap' [&lt;16,00 GiB] inherit ACTIVE '/dev/vg0/root' [&lt;206,41 GiB] inherit</span></span></code> </pre> <br>  LV <code>/dev/vg0/root</code> utilise 206,41 Go. <br><br>  Nous dÃ©veloppons LV avec la commande suivante (2). <br><br><pre> <code class="bash hljs">lvextend -l +100%FREE /dev/mapper/vg0-root</code> </pre> <br><br>  VÃ©rifiez l'action effectuÃ©e (3). <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lvscan ACTIVE '/dev/vg0/swap' [&lt;16,00 GiB] inherit ACTIVE '/dev/vg0/root' [&lt;914,39 GiB] inherit</span></span></code> </pre><br>  Comme vous pouvez le voir, aprÃ¨s l'extension LV, le volume d'espace disque occupÃ© est devenu 914,39 Go. <br><br><img src="https://habrastorage.org/webt/vd/6r/qh/vd6rqhe3wvbukzdfachz7xf4ehk.png"><br><br>  Le volume LV a augmentÃ© (4), mais le systÃ¨me de fichiers occupe toujours 204 Go (5). <br><br>  <i>1. Effectuez l'extension du systÃ¨me de fichiers.</i> <br><br><pre> <code class="bash hljs">resize2fs /dev/mapper/vg0-root</code> </pre> <br>  Nous vÃ©rifions aprÃ¨s la commande exÃ©cutÃ©e la taille du systÃ¨me de fichiers. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># df -h      % C  devtmpfs 32G 0 32G 0% /dev tmpfs 32G 0 32G 0% /dev/shm tmpfs 32G 9,5M 32G 1% /run tmpfs 32G 0 32G 0% /sys/fs/cgroup /dev/mapper/vg0-root 900G 1,3G 860G 1% / /dev/md126 1007M 120M 837M 13% /boot tmpfs 6,3G 0 6,3G 0% /run/user/0</span></span></code> </pre> <br>  La taille du systÃ¨me de fichiers racine passera Ã  900 Go.  AprÃ¨s avoir terminÃ© les Ã©tapes, vous pouvez retirer les anciens disques. <br><br><h3>  Cas 2: remplacement de disques plus petits par des disques plus grands (plus de 2 To) </h3><br>  <b>TÃ¢che:</b> remplacer les disques actuels par des disques plus gros (2 x 3 To) avec des informations d'enregistrement.  Dans ce cas, nous avons 2 disques SSD (RAID-1) de 240 Go avec le systÃ¨me installÃ© et 2 disques SATA de 3 To sur lesquels vous devez transfÃ©rer le systÃ¨me.  Les lecteurs actuels utilisent la table de partition MBR.  Ã‰tant donnÃ© que les nouveaux disques ont une capacitÃ© supÃ©rieure Ã  2 To, ils devront utiliser la table GPT, car MBR ne peut pas fonctionner avec des disques supÃ©rieurs Ã  2 To. <br><br>  Affichez la disposition actuelle du disque. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sda2 8:2 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 2,7T 0 disk sdd 8:48 0 2,7T 0 disk</span></span></code> </pre> <br>  VÃ©rifiez la table de partition utilisÃ©e sur le lecteur <code>/dev/sda</code> . <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># fdisk -l /dev/sda | grep 'Disk label type' Disk label type: dos</span></span></code> </pre> <br>  Le lecteur <code>/dev/sdb</code> utilise une table de partition similaire.  VÃ©rifiez l'espace disque utilisÃ© dans le systÃ¨me. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># df -h      % C  devtmpfs 16G 0 16G 0% /dev tmpfs 16G 0 16G 0% /dev/shm tmpfs 16G 9,5M 16G 1% /run tmpfs 16G 0 16G 0% /sys/fs/cgroup /dev/mapper/vg0-root 204G 1,3G 192G 1% / /dev/md126 1007M 120M 837M 13% /boot tmpfs 3,2G 0 3,2G 0% /run/user/0</span></span></code> </pre> <br>  Comme vous pouvez le voir, la racine du systÃ¨me de fichiers est de 204 Go.  VÃ©rifiez l'Ã©tat actuel du RAID logiciel. <br><br><h4>  1. Installer la table de partition GPT et le partitionnement de disque </h4><br>  VÃ©rifiez la disposition du disque par secteur. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># parted /dev/sda print : ATA KINGSTON SVP200S (scsi)  /dev/sda: 240GB   (./.): 512B/512B  : msdos Disk Flags:         1 1049kB 1076MB 1075MB primary , raid 2 1076MB 240GB 239GB primary raid</span></span></code> </pre><br>  Sur le nouveau disque de 3 To, nous devrons crÃ©er 3 partitions: <br><br><ol><li>  <code>bios_grub</code> pour la compatibilitÃ© GPT avec le BIOS, </li><li>  La partition pour la matrice RAID Ã  monter dans <code>/boot</code> . </li><li>  La partition de la matrice RAID sur laquelle seront la <i>racine</i> <i>LV</i> et le <i>swap LV</i> . </li></ol><br>  Installez l'utilitaire <i>parted avec la</i> commande <code>yum install -y parted</code> (pour CentOS), <code>apt install -y parted</code> (pour Debian / Ubuntu). <br><br>  En utilisant <i>parted,</i> exÃ©cutez les commandes suivantes pour partitionner le disque. <br><br>  <code>parted /dev/sdc</code> commande <code>parted /dev/sdc</code> au mode d'Ã©dition de la disposition du disque. <br><br>  CrÃ©ez une table de partition GPT. <br><br><pre> <code class="bash hljs">(parted) mktable gpt</code> </pre> <br>  CrÃ©ez une section <code>bios_grub</code> et dÃ©finissez un indicateur pour celle-ci. <br><br><pre> <code class="bash hljs">(parted) mkpart primary 1MiB 3MiB (parted) <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> 1 bios_grub on</code> </pre> <br>  CrÃ©ez une section 2 et dÃ©finissez un indicateur pour celle-ci.  La partition utilisera comme bloc pour la matrice RAID et la montera dans <code>/boot</code> . <br><br><pre> <code class="bash hljs">(parted) mkpart primary ext2 3MiB 1028MiB (parted) <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> 2 boot on</code> </pre> <br>  CrÃ©ez une section 3, qui sera Ã©galement utilisÃ©e comme bloc de tableau dans lequel se trouvera LVM. <br><br><pre> <code class="bash hljs">(parted) mkpart primary 1028MiB 100%</code> </pre> <br>  Dans ce cas, la dÃ©finition de l'indicateur n'est pas nÃ©cessaire, mais si nÃ©cessaire, il est possible de le dÃ©finir avec la commande suivante. <br><br><pre> <code class="bash hljs">(parted) <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> 3 raid on</code> </pre> <br>  VÃ©rifiez la table crÃ©Ã©e. <br><br><pre> <code class="bash hljs">(parted) p : ATA TOSHIBA DT01ACA3 (scsi)  /dev/sdc: 3001GB   (./.): 512B/4096B  : gpt Disk Flags:         1 1049kB 3146kB 2097kB primary bios_grub 2 3146kB 1077MB 1074MB primary  3 1077MB 3001GB 3000GB primary</code> </pre><br>  Attribuez au lecteur un nouveau GUID alÃ©atoire. <br><br><pre> <code class="bash hljs">sgdisk -G /dev/sdd</code> </pre><br><h4>  2. Suppression des partitions du premier disque des baies </h4><br>  VÃ©rifiez l'Ã©tat de la baie <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sda1[0] sdb1[1] 1047552 blocks super 1.2 [2/2] [UU] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sda2[0] sdb2[1] 233206784 blocks super 1.2 [2/2] [UU] bitmap: 0/2 pages [0KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br>  Le systÃ¨me utilise 2 tableaux: md126 (point de montage / dÃ©marrage) - se compose de <code>/dev/sda1</code> et <code>/dev/sdb1</code> , <code>md127</code> (LVM pour <code>swap</code> et la racine du systÃ¨me de fichiers) - se compose de <code>/dev/sda2</code> et <code>/dev/sdb2</code> . <br><br>  Nous marquons les partitions du premier disque, qui sont utilisÃ©es dans chaque baie, comme mauvaises. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --fail /dev/sda1 mdadm /dev/md127 --fail /dev/sda2</code> </pre> <br>  Nous supprimons des sections du bloc pÃ©riphÃ©rique <code>/dev/sda</code> des tableaux. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --remove /dev/sda1 mdadm /dev/md127 --remove /dev/sda2</code> </pre><br>  VÃ©rifiez l'Ã©tat de la baie aprÃ¨s avoir retirÃ© le disque. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdb1[1] 1047552 blocks super 1.2 [2/1] [_U] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sdb2[1] 233206784 blocks super 1.2 [2/1] [_U] bitmap: 2/2 pages [8KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre><br><h4>  3. Ajout de partitions du nouveau disque Ã  la baie </h4><br>  L'Ã©tape suivante consiste Ã  ajouter les partitions du nouveau disque aux baies pour la synchronisation.  Nous regardons l'Ã©tat actuel de la disposition du disque. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 2,7T 0 disk â”œâ”€sdc1 8:33 0 2M 0 part â”œâ”€sdc2 8:34 0 1G 0 part â””â”€sdc3 8:35 0 2,7T 0 part sdd 8:48 0 2,7T 0 disk</span></span></code> </pre> <br>  La <code>/dev/sdc1</code> est une partition <code>bios_grub</code> et n'est pas impliquÃ©e dans la crÃ©ation de tableaux.  <code>/dev/sdc2</code> utiliseront uniquement <code>/dev/sdc2</code> et <code>/dev/sdc3</code> .  Ajoutez ces sections aux tableaux correspondants. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --add /dev/sdc2 mdadm /dev/md127 --add /dev/sdc3</code> </pre> <br>  Ensuite, nous attendons la synchronisation du tableau. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdc2[2] sdb1[1] 1047552 blocks super 1.2 [2/2] [UU] bitmap: 0/1 pages [0KB], 65536KB chunk md127 : active raid1 sdc3[2] sdb2[1] 233206784 blocks super 1.2 [2/1] [_U] [&gt;....................] recovery = 0.2% (619904/233206784) finish=31.2min speed=123980K/sec bitmap: 2/2 pages [8KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br>  Partitionnement des disques aprÃ¨s l'ajout de partitions Ã  une baie. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdb2 8:18 0 222,5G 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdc 8:32 0 2,7T 0 disk â”œâ”€sdc1 8:33 0 2M 0 part â”œâ”€sdc2 8:34 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc3 8:35 0 2,7T 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 2,7T 0 disk</span></span></code> </pre> <br><h4>  4. Suppression de partitions du deuxiÃ¨me disque des baies </h4><br>  Nous marquons les partitions du deuxiÃ¨me disque, qui sont utilisÃ©es dans chaque baie, comme mauvaises. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --fail /dev/sdb1 mdadm /dev/md127 --fail /dev/sdb2</code> </pre><br>  Nous supprimons des sections du bloc pÃ©riphÃ©rique <code>/dev/sda</code> des tableaux. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --remove /dev/sdb1 mdadm /dev/md127 --remove /dev/sdb2</code> </pre><br><h4>  5. Copiez la table de balisage GPT et synchronisez le tableau </h4><br>  Pour copier la table de balisage GPT, nous utilisons l'utilitaire <code>sgdisk</code> , qui est inclus dans le package pour travailler avec les partitions de disque et la table GPT - <code>gdisk</code> . <br><br>  Installez <code>gdisk</code> pour CentOS: <br><br><pre> <code class="bash hljs">yum install -y gdisk</code> </pre> <br>  Installez <code>gdisk</code> pour Debian / Ubuntu: <br><br><pre> <code class="bash hljs">apt install -y gdisk</code> </pre> <br><blockquote>  <b>ATTENTION</b> : pour GPT, le disque <b>sur lequel le</b> balisage est copiÃ© est indiquÃ© en <b>premier</b> , le <b>deuxiÃ¨me</b> disque est le disque Ã  <b>partir duquel le</b> balisage <b>est</b> copiÃ©.  Si vous mÃ©langez les disques, le balisage initialement sain sera Ã©crasÃ© et dÃ©truit. <br></blockquote><br>  Copiez la table de balisage GPT. <br><br><pre> <code class="bash hljs">sgdisk -R /dev/sdd /dev/sdc</code> </pre> <br>  Partitionnement des disques aprÃ¨s le transfert d'une table vers le lecteur <code>/dev/sdd</code> . <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 2,7T 0 disk â”œâ”€sdc1 8:33 0 2M 0 part â”œâ”€sdc2 8:34 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc3 8:35 0 2,7T 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 2,7T 0 disk â”œâ”€sdd1 8:49 0 2M 0 part â”œâ”€sdd2 8:50 0 1G 0 part â””â”€sdd3 8:51 0 2,7T 0 part</span></span></code> </pre> <br>  Ensuite, nous ajoutons chacune des partitions participant aux matrices RAID logicielles. <br><br><pre> <code class="bash hljs">mdadm /dev/md126 --add /dev/sdd2 mdadm /dev/md127 --add /dev/sdd3</code> </pre> <br>  Nous attendons la synchronisation du tableau. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># cat /proc/mdstat Personalities : [raid1] md126 : active raid1 sdd2[3] sdc2[2] 1047552 blocks super 1.2 [2/2] [UU] bitmap: 1/1 pages [4KB], 65536KB chunk md127 : active raid1 sdd3[3] sdc3[2] 233206784 blocks super 1.2 [2/1] [U_] [&gt;....................] recovery = 0.0% (148224/233206784) finish=26.2min speed=148224K/sec bitmap: 2/2 pages [8KB], 65536KB chunk unused devices: &lt;none&gt;</span></span></code> </pre> <br>  AprÃ¨s avoir copiÃ© le balisage GPT sur un deuxiÃ¨me nouveau disque, le balisage ressemblera Ã  ceci. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk â”œâ”€sda1 8:1 0 1G 0 part â””â”€sda2 8:2 0 222,5G 0 part sdb 8:16 0 223,6G 0 disk â”œâ”€sdb1 8:17 0 1G 0 part â””â”€sdb2 8:18 0 222,5G 0 part sdc 8:32 0 2,7T 0 disk â”œâ”€sdc1 8:33 0 2M 0 part â”œâ”€sdc2 8:34 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdc3 8:35 0 2,7T 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 2,7T 0 disk â”œâ”€sdd1 8:49 0 2M 0 part â”œâ”€sdd2 8:50 0 1G 0 part â”‚ â””â”€md126 9:126 0 1023M 0 raid1 /boot â””â”€sdd3 8:51 0 2,7T 0 part â””â”€md127 9:127 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</span></span></code> </pre> <br>  Ensuite, installez GRUB sur les nouveaux disques. <br><br>  Installation pour CentOS: <br><br><pre> <code class="bash hljs">grub2-install /dev/sdX</code> </pre> <br>  Installation pour Debian / Ubuntu: <br><br><pre> <code class="bash hljs">grub-install /dev/sdX</code> </pre> <br>  oÃ¹ <code>X</code> est la lettre de lecteur, dans notre cas, les lecteurs <code>/dev/sdc</code> et <code>/dev/sdd</code> . <br><br>  Mise Ã  jour des informations sur la baie. <br><br>  Pour CentOS: <br><br><pre> <code class="bash hljs">mdadm --detail --scan --verbose &gt; /etc/mdadm.conf</code> </pre> <br>  Pour Debian / Ubuntu: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"DEVICE partitions"</span></span> &gt; /etc/mdadm/mdadm.conf mdadm --detail --scan --verbose | awk <span class="hljs-string"><span class="hljs-string">'/ARRAY/ {print}'</span></span> &gt;&gt; /etc/mdadm/mdadm.conf</code> </pre> <br>  Mise Ã  jour de l'image <code>initrd</code> : <br>  Pour CentOS: <br><br><pre> <code class="bash hljs">dracut -f -v --regenerate-all</code> </pre> <br>  Pour Debian / Ubuntu: <br><br><pre> <code class="bash hljs">update-initramfs -u -k all</code> </pre> <br>  Mise Ã  jour de la configuration GRUB. <br><br>  Pour CentOS: <br><br><pre> <code class="bash hljs">grub2-mkconfig -o /boot/grub2/grub.cfg</code> </pre><br>  Pour Debian / Ubuntu: <br><br><pre> <code class="bash hljs">update-grub</code> </pre> <br>  Une fois les Ã©tapes terminÃ©es, les anciens disques peuvent Ãªtre retirÃ©s. <br><br><h4>  6. Extension du systÃ¨me de fichiers (ext4) de la partition racine </h4><br>  Partitionner les disques avant d'Ã©tendre le systÃ¨me de fichiers aprÃ¨s avoir dÃ©placÃ© le systÃ¨me vers des disques 2 x 3 To (RAID-1). <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk sdb 8:16 0 223,6G 0 disk sdc 8:32 0 2,7T 0 disk â”œâ”€sdc1 8:33 0 2M 0 part â”œâ”€sdc2 8:34 0 1G 0 part â”‚ â””â”€md127 9:127 0 1023M 0 raid1 /boot â””â”€sdc3 8:35 0 2,7T 0 part â””â”€md126 9:126 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 2,7T 0 disk â”œâ”€sdd1 8:49 0 2M 0 part â”œâ”€sdd2 8:50 0 1G 0 part â”‚ â””â”€md127 9:127 0 1023M 0 raid1 /boot â””â”€sdd3 8:51 0 2,7T 0 part â””â”€md126 9:126 0 222,4G 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</span></span></code> </pre> <br>  Les <code>/dev/sdc3</code> et <code>/dev/sdd3</code> occupent <code>/dev/sdd3</code> 2,7 To.  Comme nous avons crÃ©Ã© un nouveau partitionnement des disques avec une table GPT, la taille des 3 partitions a Ã©tÃ© immÃ©diatement dÃ©finie sur l'espace disque maximal possible, dans ce cas, l'extension de la partition n'est pas nÃ©cessaire. <br><br>  Il faut: <br><br><ol><li>  Ã‰tendez le tableau md126, </li><li>  DÃ©veloppez PV (volume physique), </li><li>  Ã‰tendre LV (volume logique) vg0-root, </li><li>  Ã‰tendez le systÃ¨me de fichiers. </li></ol><br>  <i>1. <code>md126</code> tableau <code>md126</code> au maximum.</i> <br><br><pre> <code class="bash hljs">mdadm --grow /dev/md126 --size=max</code> </pre><br>  AprÃ¨s avoir Ã©tendu la matrice <code>md126</code> taille de l'espace occupÃ© est passÃ©e Ã  2,7 To. <br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 223,6G 0 disk sdb 8:16 0 223,6G 0 disk sdc 8:32 0 2,7T 0 disk â”œâ”€sdc1 8:33 0 2M 0 part â”œâ”€sdc2 8:34 0 1G 0 part â”‚ â””â”€md127 9:127 0 1023M 0 raid1 /boot â””â”€sdc3 8:35 0 2,7T 0 part â””â”€md126 9:126 0 2,7T 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP] sdd 8:48 0 2,7T 0 disk â”œâ”€sdd1 8:49 0 2M 0 part â”œâ”€sdd2 8:50 0 1G 0 part â”‚ â””â”€md127 9:127 0 1023M 0 raid1 /boot â””â”€sdd3 8:51 0 2,7T 0 part â””â”€md126 9:126 0 2,7T 0 raid1 â”œâ”€vg0-root 253:0 0 206,4G 0 lvm / â””â”€vg0-swap 253:1 0 16G 0 lvm [SWAP]</span></span></code> </pre><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Augmenter </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">le volume physique</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Avant expansion, nous vÃ©rifions la valeur actuelle de l'espace occupÃ© PV / </font></font><code>dev/md126</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># pvs PV VG Fmt Attr PSize PFree /dev/md126 vg0 lvm2 a-- 222,40g 0</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> DÃ©veloppez PV avec la commande suivante. </font></font><br><br><pre> <code class="bash hljs">pvresize /dev/md126</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> VÃ©rifiez l'action terminÃ©e. </font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># pvs PV VG Fmt Attr PSize PFree /dev/md126 vg0 lvm2 a-- &lt;2,73t 2,51t</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L' expansion </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classe volume logique vg0-racine</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AprÃ¨s avoir Ã©tendu PV, nous vÃ©rifions l'espace occupÃ© de VG.</font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># vgs VG #PV #LV #SN Attr VSize VFree vg0 1 2 0 wz--n- &lt;2,73t 2,51t</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> VÃ©rifiez l'espace occupÃ© par LV. </font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root vg0 -wi-ao---- &lt;206,41g swap vg0 -wi-ao---- &lt;16,00g</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le volume racine vg0 occupe 206,41 Go. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DÃ©veloppez LV Ã  l'espace disque maximal.</font></font><br><br><pre> <code class="bash hljs">lvextend -l +100%FREE /dev/mapper/vg0-root</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> VÃ©rification de l'espace BT aprÃ¨s expansion. </font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root vg0 -wi-ao---- 2,71t swap vg0 -wi-ao---- &lt;16,00g</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Extension du systÃ¨me de fichiers (ext4). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">VÃ©rifiez la taille actuelle du systÃ¨me de fichiers.</font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># df -h      % C  devtmpfs 16G 0 16G 0% /dev tmpfs 16G 0 16G 0% /dev/shm tmpfs 16G 9,6M 16G 1% /run tmpfs 16G 0 16G 0% /sys/fs/cgroup /dev/mapper/vg0-root 204G 1,4G 192G 1% / /dev/md127 1007M 141M 816M 15% /boot tmpfs 3,2G 0 3,2G 0% /run/user/0</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le volume / dev / mapper / vg0-root occupe 204 Go aprÃ¨s l'extension LV. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Extension du systÃ¨me de fichiers.</font></font><br><br><pre> <code class="bash hljs">resize2fs /dev/mapper/vg0-root</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> VÃ©rifiez la taille du systÃ¨me de fichiers aprÃ¨s son expansion. </font></font><br><br><pre> <code class="bash hljs">[root@localhost ~]<span class="hljs-comment"><span class="hljs-comment"># df -h      % C  devtmpfs 16G 0 16G 0% /dev tmpfs 16G 0 16G 0% /dev/shm tmpfs 16G 9,6M 16G 1% /run tmpfs 16G 0 16G 0% /sys/fs/cgroup /dev/mapper/vg0-root 2,7T 1,4G 2,6T 1% / /dev/md127 1007M 141M 816M 15% /boot tmpfs 3,2G 0 3,2G 0% /run/user/0</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> La taille du systÃ¨me de fichiers est augmentÃ©e de tout le volume du volume. </font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr486084/">https://habr.com/ru/post/fr486084/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr486062/index.html">Rendu simple sans copie de la vidÃ©o avec accÃ©lÃ©ration matÃ©rielle en QML</a></li>
<li><a href="../fr486064/index.html">CrÃ©ez un diaporama animÃ© en CSS pur.</a></li>
<li><a href="../fr486066/index.html">Dans la zone d'accÃ¨s. Trouvez la distance d'un point Ã  une zone et rÃ©duisez les demandes de gÃ©ocodage inversÃ©</a></li>
<li><a href="../fr486070/index.html">Les commutateurs ACL en dÃ©tail</a></li>
<li><a href="../fr486080/index.html">Permettez-moi de vous prÃ©senter: Veeam Availability Suite v10</a></li>
<li><a href="../fr486094/index.html">Un dÃ©mocrate se bat contre la Silicon Valley</a></li>
<li><a href="../fr486104/index.html">MVCC dans PostgreSQL-7. Autovacuum</a></li>
<li><a href="../fr486106/index.html">RÃ©troÃ©clairage adaptatif pour tÃ©lÃ©viseur Raspberry Pi - Ambilight Analog</a></li>
<li><a href="../fr486114/index.html">Des scientifiques de premier plan dans le domaine des neurosciences se rÃ©uniront lors du congrÃ¨s annuel du Neuronet Industry Union</a></li>
<li><a href="../fr486116/index.html">Tests de simplicitÃ© de Fermat et Miller-Rabin</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤛🏼 🆚 📒 Neuronale Netze. Wo geht das alles hin? 🏆 👨🏻‍🏭 👨🏾‍⚖️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Der Artikel besteht aus zwei Teilen: 


1. Eine kurze Beschreibung einiger Netzwerkarchitekturen zum Erkennen von Objekten in einem Bild und eine Bild...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Neuronale Netze. Wo geht das alles hin?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482794/"><p>  Der Artikel besteht aus zwei Teilen: </p><br><ol><li>  Eine kurze Beschreibung einiger Netzwerkarchitekturen zum Erkennen von Objekten in einem Bild und eine Bildsegmentierung mit den für mich verständlichsten Links zu Ressourcen.  Ich habe versucht, Video-Erklärungen zu wählen und am besten auf Russisch. </li><li>  Der zweite Teil ist ein Versuch, die Entwicklungsrichtung neuronaler Netzwerkarchitekturen zu verstehen.  Und darauf basierende Technologien. </li></ol><br><p><img src="https://habrastorage.org/webt/8a/ph/qb/8aphqb_xrv3ynavkgmuex1ib8qo.jpeg" alt="Das Verständnis neuronaler Netzwerkarchitekturen ist nicht einfach"></p><br><p>  Abbildung 1 - Das Verständnis der Architektur neuronaler Netze ist nicht einfach </p><br><p> Alles begann damit, dass er zwei Demoanwendungen zum Klassifizieren und Erkennen von Objekten auf einem Android-Handy erstellt hat: </p><br><ul><li>  <a href="https://github.com/foobar167/junkyard/tree/master/object_classifier">Backend-Demo</a> , wenn Daten auf dem Server verarbeitet und auf das Telefon übertragen werden.  Bildklassifizierung von drei Arten von Bären: Braun, Schwarz und Teddy. </li><li>  <a href="https://github.com/foobar167/android/tree/master/object_detection_demo">Front-End-Demo,</a> wenn Daten auf dem Telefon selbst verarbeitet werden.  Objekterkennung von drei Arten: Haselnüsse, Feigen und Datteln. </li></ul><a name="habracut"></a><br><p>  Es gibt einen Unterschied zwischen der Klassifizierung von Bildern, der Erkennung von Objekten in einem Bild und der <a href="https://medium.com/analytics-vidhya/image-classification-vs-object-detection-vs-image-segmentation-f36db85fe81">Segmentierung von Bildern</a> .  Es bestand daher die Notwendigkeit herauszufinden, welche neuronalen Netzwerkarchitekturen Objekte in Bildern erkennen und welche segmentiert werden können.  Ich habe die folgenden Beispiele für Architekturen mit den für mich verständlichsten Links zu Ressourcen gefunden: </p><br><ul><li>  Eine Reihe von Architekturen, die auf R-CNN basieren (Regionen mit <strong>C</strong> onvolution <strong>N</strong> etural <strong>N</strong> works): R-CNN, Schnelles R-CNN, <a href="https://medium.com/%40smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8">Schnelleres R-CNN</a> , <a href="https://youtu.be/0vt05rQqk_I">Maske R-CNN</a> .  Um ein Objekt in einem Bild mithilfe des RPN-Mechanismus (Region Proposal Network) zu erkennen, werden Begrenzungsrahmen zugewiesen.  Ursprünglich wurde der langsamere Selective Search-Mechanismus anstelle des RPN verwendet.  Dann werden die ausgewählten begrenzten Regionen dem Eingang eines normalen neuronalen Netzwerks zur Klassifizierung zugeführt.  In der Architektur von R-CNN gibt es explizite Aufzählungszyklen für begrenzte Regionen, insgesamt bis zu 2000 Läufe über das interne AlexNet-Netzwerk.  Aufgrund expliziter "for" -Schleifen wird die Bildverarbeitungsgeschwindigkeit verlangsamt.  Die Anzahl expliziter Zyklen, die durch das interne neuronale Netzwerk laufen, nimmt mit jeder neuen Version der Architektur ab, und Dutzende weiterer Änderungen werden durchgeführt, um die Geschwindigkeit zu erhöhen und die Aufgabe der Erkennung von Objekten durch Segmentierung von Objekten in der Maske R-CNN zu ersetzen. </li><li>  <a href="https://youtu.be/L0tzmv--CGY">YOLO</a> ist das erste neuronale Netzwerk, das Objekte in Echtzeit auf mobilen Geräten erkennt.  Besonderheit: Objekte in einem Durchgang unterscheiden (nur einmal schauen).  Das heißt, in der YOLO-Architektur gibt es keine expliziten "for" -Schleifen, weshalb das Netzwerk schnell ist.  Dies ist zum Beispiel eine Analogie: In NumPy gibt es keine expliziten "for" -Schleifen beim Arbeiten mit Matrizen, die in NumPy auf niedrigeren Architekturebenen durch die Programmiersprache C implementiert sind. YOLO verwendet ein Raster vordefinierter Fenster.  Um zu verhindern, dass dasselbe Objekt mehrmals erkannt wird, wird der Fensterüberlappungskoeffizient (IoU, Intersection over Union) verwendet.  Diese Architektur arbeitet in einem weiten Bereich und weist eine hohe <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25BE%25D0%25B1%25D0%25B0%25D1%2581%25D1%2582%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">Robustheit auf</a> : Das Modell kann in Fotografien trainiert werden, funktioniert aber gleichzeitig gut in gemalten Gemälden. </li><li>  <a href="https://youtu.be/P8e-G-Mhx4k">SSD</a> (Single Hot MultiBox Designer) - die erfolgreichsten „Hacks“ der YOLO-Architektur (z. B. nicht maximale Unterdrückung) werden verwendet und neue hinzugefügt, um das neuronale Netzwerk schneller und genauer zu machen.  Besonderheit: Unterscheiden von Objekten in einem Durchgang mithilfe eines bestimmten Fenstergitters (Standardfeld) auf der Bildpyramide.  Die Pyramide von Bildern wird während aufeinanderfolgender Faltungs- und Bündelungsoperationen in Faltungstensoren codiert (bei der Max-Pooling-Operation nimmt die räumliche Dimension ab).  Auf diese Weise werden sowohl große als auch kleine Objekte in einem einzigen Netzwerklauf ermittelt. </li><li>  MobileSSD ( <strong>Mobile</strong> NetV2 + <strong>SSD</strong> ) ist eine Kombination aus zwei neuronalen Netzwerkarchitekturen.  Das erste <a href="https://habr.com/ru/post/352804/">MobileNetV2-</a> Netzwerk ist schnell und erhöht die Erkennungsgenauigkeit.  MobileNetV2 wird anstelle von VGG-16 verwendet, das ursprünglich im Originalartikel verwendet wurde.  Das zweite SSD-Netzwerk bestimmt die Position von Objekten im Bild. </li><li>  <a href="https://youtu.be/ge_RT5wvHvY">SqueezeNet</a> ist ein sehr kleines, aber genaues neuronales Netzwerk.  An sich löst es nicht das Problem der Erkennung von Objekten.  Es kann jedoch mit einer Kombination verschiedener Architekturen verwendet werden.  Und auf mobilen Geräten verwendet werden.  Eine Besonderheit besteht darin, dass die Daten zunächst zu vier 1 × 1-Faltungsfiltern komprimiert und dann zu vier 1 × 1-Faltungsfiltern und vier 3 × 3-Faltungsfiltern erweitert werden.  Eine solche Iteration der Datenkomprimierungserweiterung wird als "Feuermodul" bezeichnet. </li><li>  <a href="https://youtu.be/b6jhopSMit8">DeepLab</a> (Semantische Bildsegmentierung mit Deep Convolutional Nets) - Segmentierung von Objekten im Bild.  Ein charakteristisches Merkmal der Architektur ist eine verdünnte Faltung, die die räumliche Auflösung beibehält.  Anschließend erfolgt die Nachbearbeitung der Ergebnisse mithilfe eines grafischen Wahrscheinlichkeitsmodells (Bedingtes Zufallsfeld), mit dem Sie geringes Rauschen in der Segmentierung entfernen und die Qualität des segmentierten Bildes verbessern können.  Hinter dem gewaltigen Namen "Graphical Probabilistic Model" verbirgt sich der übliche Gauß-Filter, der durch fünf Punkte angenähert wird. </li><li>  Ich habe versucht, das <a href="https://arxiv.org/abs/1711.06897">RefineDet-</a> Gerät (Single-Shot <strong>Refine</strong> ment Neural Network zur Objekterkennung) zu verstehen, aber ich habe sehr wenig verstanden. </li><li>  Ich habe mir auch angesehen, wie die Aufmerksamkeitstechnologie funktioniert: <a href="https://youtu.be/W2rWgXJBZhU">Video1</a> , <a href="https://youtu.be/iDulhoQ2pro">Video2</a> , <a href="https://youtu.be/H6Qiegq_36c">Video3</a> .  Ein charakteristisches Merkmal der "Aufmerksamkeit" -Architektur ist die automatische Zuweisung von Bereichen mit erhöhter Aufmerksamkeit zum Bild (ROI, Interessensregionen) unter Verwendung eines neuronalen Netzwerks, das als Aufmerksamkeitseinheit bezeichnet wird.  Bereiche mit erhöhter Aufmerksamkeit ähneln eingeschränkten Bereichen (Begrenzungsrahmen), sind jedoch im Gegensatz zu diesen nicht auf dem Bild fixiert und weisen möglicherweise unscharfe Ränder auf.  Anschließend werden aus den Bereichen mit erhöhter Aufmerksamkeit Merkmale (Features) unterschieden, die wiederkehrenden neuronalen Netzwerken mit <a href="https://youtu.be/5lUUrREboSk">LSDM-, GRU- oder Vanilla RNN-</a> Architekturen "zugeführt" werden.  Rekursive neuronale Netze können die Beziehung von Zeichen in einer Sequenz analysieren.  Rekursive neuronale Netze wurden ursprünglich verwendet, um Text in andere Sprachen zu übersetzen, und jetzt, um <a href="https://youtu.be/e-WB4lfg30M">Bilder in Text</a> und <a href="https://youtu.be/rAbhypxs1qQ">Text in Bilder</a> zu übersetzen. </li></ul><br><p>  Als ich diese Architekturen studierte, stellte <strong>ich fest, dass ich nichts verstand</strong> .  Und der Punkt ist nicht, dass mein neuronales Netzwerk Probleme mit dem Aufmerksamkeitsmechanismus hat.  Das Erstellen all dieser Architekturen sieht aus wie ein riesiger Hackathon, bei dem Autoren an Hacks teilnehmen.  Hack ist eine schnelle Lösung für eine schwierige Softwareaufgabe.  Das heißt, es gibt keine sichtbare und verständliche logische Verbindung zwischen all diesen Architekturen.  Alles, was sie verbindet, ist eine Reihe der erfolgreichsten Hacks, die sie voneinander ausleihen, sowie eine gemeinsame <a href="https://youtu.be/Ilg3gGewQ5U">Faltungsoperation mit Rückkopplung</a> (umgekehrte Ausbreitung von Fehlern, Backpropagation).  Kein <a href="https://habr.com/ru/post/272473/">systemisches Denken</a> !  Es ist nicht klar, was geändert und wie vorhandene Erfolge optimiert werden sollen. </p><br><p>  Aufgrund des Fehlens einer logischen Verbindung zwischen Hacks ist es äußerst schwierig, sich an sie zu erinnern und sie in die Praxis umzusetzen.  Das ist fragmentiertes Wissen.  Im besten Fall werden einige interessante und unerwartete Momente in Erinnerung gerufen, aber das meiste, was verstanden und unverständlich ist, verschwindet innerhalb weniger Tage aus dem Gedächtnis.  Es wird gut sein, wenn ich mich in einer Woche zumindest an den Namen der Architektur erinnere.  Aber es dauerte mehrere Stunden und sogar Tage, um Artikel zu lesen und Review-Videos anzuschauen! </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/ffc/1b0/019/ffc1b0019fe7a23e2923d9642485290a.png" alt="Neuronales Netzwerk Zoo"></p><br><p>  Abbildung 2 - <a href="https://www.asimovinstitute.org/neural-network-zoo/">Zoo neuronaler Netze</a> </p><br><p>  Die meisten Autoren von wissenschaftlichen Artikeln tun meiner Meinung nach alles, damit auch dieses fragmentierte Wissen vom Leser nicht verstanden wird.  Aber die Partizipien in Zehn-Zeilen-Sätzen mit Formeln, die "von der Decke" genommen wurden, sind ein Thema für einen separaten Artikel (Problem <a href="https://en.wikipedia.org/wiki/Publish_or_perish">veröffentlichen oder zugrunde gehen</a> ). </p><br><p>  Aus diesem Grund wurde es notwendig, Informationen in neuronalen Netzen zu systematisieren und damit die Qualität des Verstehens und des Erinnerns zu verbessern.  Daher war das Hauptthema der Analyse einzelner Technologien und Architekturen künstlicher neuronaler Netze die folgende Aufgabe: <strong>herauszufinden, wo sich all dies bewegt</strong> , und nicht das Gerät eines bestimmten neuronalen Netzes separat. </p><br><p>  Wohin geht das alles?  Die wichtigsten Ergebnisse: </p><br><ul><li>  Die Zahl der Startups im Bereich des maschinellen Lernens <a href="https://habr.com/ru/company/recognitor/blog/455676/">ist</a> in den letzten zwei Jahren stark zurückgegangen.  Möglicher Grund: "Neuronale Netze sind nicht mehr neu." </li><li>  Jeder kann ein funktionierendes neuronales Netzwerk erstellen, um ein einfaches Problem zu lösen.  Nehmen Sie dazu das fertige Modell aus dem „Modellzoo“ und trainieren Sie die letzte Schicht des neuronalen Netzwerks ( <a href="https://youtu.be/yofjFQddwHE">Transfer Learning</a> ) mit den fertigen Daten aus der <a href="https://toolbox.google.com/datasetsearch">Google Dataset Search</a> oder aus <a href="https://www.kaggle.com/datasets">25.000 Kaggle-Datensätzen</a> in der kostenlosen <a href="https://www.dataschool.io/cloud-services-for-jupyter-notebook/">Jupyter Notebook-Cloud</a> . </li><li>  Große Hersteller neuronaler Netze begannen, <strong>"Modellzoos"</strong> (model zoo) zu schaffen.  Mit ihnen können Sie schnell eine kommerzielle Anwendung erstellen: <a href="https://tfhub.dev/">TF Hub</a> für TensorFlow, <a href="https://github.com/open-mmlab/mmdetection">MMDetection</a> für PyTorch, <a href="https://github.com/facebookresearch/Detectron">Detectron</a> für Caffe2, <a href="https://github.com/wkentaro/chainer-modelzoo">chainer-modelzoo</a> für Chainer und <a href="https://modelzoo.co/">andere</a> . </li><li>  Neuronale Echtzeitnetze auf Mobilgeräten.  10 bis 50 Bilder pro Sekunde. </li><li>  Die Verwendung von neuronalen Netzen in Telefonen (TF Lite), in Browsern (TF.js) und in <a href="https://youtu.be/19ZNz2N79u4">Haushaltsgegenständen</a> (IoT, Internet und <strong>T</strong> hings).  Besonders in Telefonen, die bereits neuronale Netze auf Hardware-Ebene unterstützen (Neuroaccelerators). </li><li>  „Jedes Gerät, jede Kleidung und möglicherweise auch jedes Essen wird eine <strong>IP-v6-Adresse haben</strong> und miteinander kommunizieren“ - <a href="https://youtu.be/GG7H8Xa4m8I%3Ft%3D85">Sebastian Trun</a> . </li><li>  Die Zunahme der Veröffentlichungen zum maschinellen Lernen hat begonnen, <a href="http://data-mining.philippe-fournier-viger.com/too-many-machine-learning-papers">das Gesetz von Moore</a> (das sich alle zwei Jahre verdoppelt) seit 2015 zu <a href="http://data-mining.philippe-fournier-viger.com/too-many-machine-learning-papers">übertreffen</a> .  Offensichtlich werden neuronale Netze zur Artikelanalyse benötigt. </li><li>  Folgende Technologien werden immer beliebter: <br><ul><li>  <strong>PyTorch</strong> - Popularität wächst schnell und scheint TensorFlow zu überholen. </li><li>  Automatische Auswahl von <strong>AutoML-</strong> Hyperparametern - die Popularität wächst stetig. </li><li>  Allmähliche Abnahme der Genauigkeit und Erhöhung der Rechengeschwindigkeit: <a href="https://youtu.be/rln_kZbYaWc">Fuzzy-Logik</a> , <a href="https://youtu.be/MIPkK5ZAsms">Boosting-</a> Algorithmen, ungenaue (ungefähre) Berechnungen, Quantisierung (wenn die Gewichte eines neuronalen Netzwerks in ganze Zahlen und quantisiert werden), Neuro-Beschleuniger. </li><li>  Übersetzung von <a href="https://youtu.be/e-WB4lfg30M">Bild in Text</a> und <a href="https://youtu.be/rAbhypxs1qQ">Text in Bild</a> . </li><li>  Erstellen Sie <a href="https://youtu.be/OrHLacCDZVQ">dreidimensionale Objekte auf Video</a> , jetzt in Echtzeit. </li><li>  Die Hauptsache in DL sind viele Daten, aber das Sammeln und Markieren ist nicht einfach.  Daher entwickelt sich eine <a href="https://youtu.be/NcKTn4C91Yc">automatisierte Annotation</a> für neuronale Netze unter Verwendung neuronaler Netze. </li></ul></li><li>  Mit neuronalen Netzen wurde die Informatik plötzlich zu einer <strong>experimentellen Wissenschaft</strong> und es kam zu einer <a href="https://habr.com/ru/post/480348">Reproduzierbarkeitskrise</a> . </li><li>  IT-Geld und die Popularität neuronaler Netze entstanden gleichzeitig, als das Rechnen zum Marktwert wurde.  Die Wirtschaft von Gold und Devisen wird zum <strong>Goldwährungsrechner</strong> .  Siehe meinen Artikel über <a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D0%25BA%25D0%25BE%25D0%25BD%25D0%25BE%25D1%2584%25D0%25B8%25D0%25B7%25D0%25B8%25D0%25BA%25D0%25B0">Wirtschaftsphysik</a> und den Grund für die Entstehung von IT-Geld. </li></ul><br><p>  Allmählich erscheint eine neue <a href="https://habr.com/ru/post/481844">ML / DL-Programmiermethode</a> (Machine Learning &amp; Deep Learning), die auf der Darstellung des Programms als Sammlung trainierter neuronaler Netzwerkmodelle basiert. </p><br><p><img src="https://habrastorage.org/webt/tx/_a/vl/tx_avlc4bdfe6cfu5hy2bug3nby.png" alt="ML / DL als neue Programmiermethode"></p><br><p>  Abbildung 3 - ML / DL als neue Programmiermethode </p><br><p>  Die <strong>„Theorie der neuronalen Netze“</strong> , in deren Rahmen man systematisch denken und arbeiten kann, ist jedoch nicht aufgetaucht.  Was heute als "Theorie" bezeichnet wird, sind experimentelle heuristische Algorithmen. </p><br><p>  Links zu meinen und nicht nur Ressourcen: </p><br><ul><li>  Data Science Newsletter.  Meistens Bildverarbeitung.  Wer empfangen möchte, soll ihm eine E-Mail senden (foobar167 &lt;gaff-gaf&gt; gmail &lt;dot&gt; com).  Ich sende Links zu Artikeln und Videos, wenn sich Material ansammelt. </li><li>  Eine allgemeine <a href="">Liste der Kurse und Artikel</a> , an denen ich teilgenommen habe und teilnehmen möchte. </li><li>  <a href="">Kurse und Videos für Anfänger</a> , ab denen es sich lohnt, neuronale Netze zu studieren.  Dazu die Broschüre <a href="https://foobar167.github.io/page/vvedeniye-v-mashinnoye-obucheniye-i-iskusstvennyye-neyronnyye-seti.html">"Einführung in maschinelles Lernen und künstliche neuronale Netze".</a> </li><li>  <a href="">Nützliche Tools, bei</a> denen jeder etwas Interessantes für sich findet. </li><li>  Die <strong>Videokanäle zur Analyse von wissenschaftlichen Artikeln</strong> über Data Science haben sich als äußerst nützlich erwiesen.  Suchen, abonnieren und Links an Ihre Kollegen und mich senden.  Beispiele: <br><ul><li>  <a href="https://www.youtube.com/user/keeroyz">Zwei Minutenblätter</a> </li><li>  <a href="https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw">Henry AI Labs</a> </li><li>  <a href="https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew">Yannic Kilcher</a> </li><li>  <a href="https://www.youtube.com/channel/UC5_6ZD6s8klmMu9TXEB_1IA">CodeEmporium</a> </li><li>  <a href="https://www.dlology.com/">Chengwei Zhang</a> aka <a href="https://github.com/Tony607">Tony607 Blog</a> mit Schritt-für-Schritt-Anleitung und Open Source. </li></ul></li></ul><br><p>  Vielen Dank für Ihre Aufmerksamkeit! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de482794/">https://habr.com/ru/post/de482794/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de482780/index.html">Experimente mit neuronalen Netzen basierend auf seismischen Daten</a></li>
<li><a href="../de482784/index.html">Das geheime Leben eines Linux-Servers oder Fan-Brute-Force-Angriffs auf das SSH-Subsystem</a></li>
<li><a href="../de482786/index.html">Ungelöstes Rätsel</a></li>
<li><a href="../de482790/index.html">Vergessen Sie die homomorphe Verschlüsselung: Jetzt haben wir eine funktionale Verschlüsselung</a></li>
<li><a href="../de482792/index.html">ITER-Projekt im Jahr 2019</a></li>
<li><a href="../de482798/index.html">Sehen Sie den Wald hinter den Bäumen</a></li>
<li><a href="../de482800/index.html">Meine Suche nach dem physischen Bedienfeld eines Smart Homes</a></li>
<li><a href="../de482802/index.html">Remote-Einbindung von Mikrotik-Skripten aus Telegram 2.0</a></li>
<li><a href="../de482804/index.html">Java: Reduzieren Sie mehrzeilige Protokolle mithilfe von Spring and Logback oder Log4j2 in ein einzeiliges Protokoll</a></li>
<li><a href="../de482806/index.html">Die Propaganda des totalitären Regimes, des Antisemitismus und der Homophobie im Lehrbuch über die Programmierung von 2019? - Das ist möglich</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
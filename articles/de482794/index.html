<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§õüèº üÜö üìí Neuronale Netze. Wo geht das alles hin? üèÜ üë®üèª‚Äçüè≠ üë®üèæ‚Äç‚öñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Der Artikel besteht aus zwei Teilen: 


1. Eine kurze Beschreibung einiger Netzwerkarchitekturen zum Erkennen von Objekten in einem Bild und eine Bild...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Neuronale Netze. Wo geht das alles hin?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482794/"><p>  Der Artikel besteht aus zwei Teilen: </p><br><ol><li>  Eine kurze Beschreibung einiger Netzwerkarchitekturen zum Erkennen von Objekten in einem Bild und eine Bildsegmentierung mit den f√ºr mich verst√§ndlichsten Links zu Ressourcen.  Ich habe versucht, Video-Erkl√§rungen zu w√§hlen und am besten auf Russisch. </li><li>  Der zweite Teil ist ein Versuch, die Entwicklungsrichtung neuronaler Netzwerkarchitekturen zu verstehen.  Und darauf basierende Technologien. </li></ol><br><p><img src="https://habrastorage.org/webt/8a/ph/qb/8aphqb_xrv3ynavkgmuex1ib8qo.jpeg" alt="Das Verst√§ndnis neuronaler Netzwerkarchitekturen ist nicht einfach"></p><br><p>  Abbildung 1 - Das Verst√§ndnis der Architektur neuronaler Netze ist nicht einfach </p><br><p> Alles begann damit, dass er zwei Demoanwendungen zum Klassifizieren und Erkennen von Objekten auf einem Android-Handy erstellt hat: </p><br><ul><li>  <a href="https://github.com/foobar167/junkyard/tree/master/object_classifier">Backend-Demo</a> , wenn Daten auf dem Server verarbeitet und auf das Telefon √ºbertragen werden.  Bildklassifizierung von drei Arten von B√§ren: Braun, Schwarz und Teddy. </li><li>  <a href="https://github.com/foobar167/android/tree/master/object_detection_demo">Front-End-Demo,</a> wenn Daten auf dem Telefon selbst verarbeitet werden.  Objekterkennung von drei Arten: Haseln√ºsse, Feigen und Datteln. </li></ul><a name="habracut"></a><br><p>  Es gibt einen Unterschied zwischen der Klassifizierung von Bildern, der Erkennung von Objekten in einem Bild und der <a href="https://medium.com/analytics-vidhya/image-classification-vs-object-detection-vs-image-segmentation-f36db85fe81">Segmentierung von Bildern</a> .  Es bestand daher die Notwendigkeit herauszufinden, welche neuronalen Netzwerkarchitekturen Objekte in Bildern erkennen und welche segmentiert werden k√∂nnen.  Ich habe die folgenden Beispiele f√ºr Architekturen mit den f√ºr mich verst√§ndlichsten Links zu Ressourcen gefunden: </p><br><ul><li>  Eine Reihe von Architekturen, die auf R-CNN basieren (Regionen mit <strong>C</strong> onvolution <strong>N</strong> etural <strong>N</strong> works): R-CNN, Schnelles R-CNN, <a href="https://medium.com/%40smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8">Schnelleres R-CNN</a> , <a href="https://youtu.be/0vt05rQqk_I">Maske R-CNN</a> .  Um ein Objekt in einem Bild mithilfe des RPN-Mechanismus (Region Proposal Network) zu erkennen, werden Begrenzungsrahmen zugewiesen.  Urspr√ºnglich wurde der langsamere Selective Search-Mechanismus anstelle des RPN verwendet.  Dann werden die ausgew√§hlten begrenzten Regionen dem Eingang eines normalen neuronalen Netzwerks zur Klassifizierung zugef√ºhrt.  In der Architektur von R-CNN gibt es explizite Aufz√§hlungszyklen f√ºr begrenzte Regionen, insgesamt bis zu 2000 L√§ufe √ºber das interne AlexNet-Netzwerk.  Aufgrund expliziter "for" -Schleifen wird die Bildverarbeitungsgeschwindigkeit verlangsamt.  Die Anzahl expliziter Zyklen, die durch das interne neuronale Netzwerk laufen, nimmt mit jeder neuen Version der Architektur ab, und Dutzende weiterer √Ñnderungen werden durchgef√ºhrt, um die Geschwindigkeit zu erh√∂hen und die Aufgabe der Erkennung von Objekten durch Segmentierung von Objekten in der Maske R-CNN zu ersetzen. </li><li>  <a href="https://youtu.be/L0tzmv--CGY">YOLO</a> ist das erste neuronale Netzwerk, das Objekte in Echtzeit auf mobilen Ger√§ten erkennt.  Besonderheit: Objekte in einem Durchgang unterscheiden (nur einmal schauen).  Das hei√üt, in der YOLO-Architektur gibt es keine expliziten "for" -Schleifen, weshalb das Netzwerk schnell ist.  Dies ist zum Beispiel eine Analogie: In NumPy gibt es keine expliziten "for" -Schleifen beim Arbeiten mit Matrizen, die in NumPy auf niedrigeren Architekturebenen durch die Programmiersprache C implementiert sind. YOLO verwendet ein Raster vordefinierter Fenster.  Um zu verhindern, dass dasselbe Objekt mehrmals erkannt wird, wird der Fenster√ºberlappungskoeffizient (IoU, Intersection over Union) verwendet.  Diese Architektur arbeitet in einem weiten Bereich und weist eine hohe <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25BE%25D0%25B1%25D0%25B0%25D1%2581%25D1%2582%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">Robustheit auf</a> : Das Modell kann in Fotografien trainiert werden, funktioniert aber gleichzeitig gut in gemalten Gem√§lden. </li><li>  <a href="https://youtu.be/P8e-G-Mhx4k">SSD</a> (Single Hot MultiBox Designer) - die erfolgreichsten ‚ÄûHacks‚Äú der YOLO-Architektur (z. B. nicht maximale Unterdr√ºckung) werden verwendet und neue hinzugef√ºgt, um das neuronale Netzwerk schneller und genauer zu machen.  Besonderheit: Unterscheiden von Objekten in einem Durchgang mithilfe eines bestimmten Fenstergitters (Standardfeld) auf der Bildpyramide.  Die Pyramide von Bildern wird w√§hrend aufeinanderfolgender Faltungs- und B√ºndelungsoperationen in Faltungstensoren codiert (bei der Max-Pooling-Operation nimmt die r√§umliche Dimension ab).  Auf diese Weise werden sowohl gro√üe als auch kleine Objekte in einem einzigen Netzwerklauf ermittelt. </li><li>  MobileSSD ( <strong>Mobile</strong> NetV2 + <strong>SSD</strong> ) ist eine Kombination aus zwei neuronalen Netzwerkarchitekturen.  Das erste <a href="https://habr.com/ru/post/352804/">MobileNetV2-</a> Netzwerk ist schnell und erh√∂ht die Erkennungsgenauigkeit.  MobileNetV2 wird anstelle von VGG-16 verwendet, das urspr√ºnglich im Originalartikel verwendet wurde.  Das zweite SSD-Netzwerk bestimmt die Position von Objekten im Bild. </li><li>  <a href="https://youtu.be/ge_RT5wvHvY">SqueezeNet</a> ist ein sehr kleines, aber genaues neuronales Netzwerk.  An sich l√∂st es nicht das Problem der Erkennung von Objekten.  Es kann jedoch mit einer Kombination verschiedener Architekturen verwendet werden.  Und auf mobilen Ger√§ten verwendet werden.  Eine Besonderheit besteht darin, dass die Daten zun√§chst zu vier 1 √ó 1-Faltungsfiltern komprimiert und dann zu vier 1 √ó 1-Faltungsfiltern und vier 3 √ó 3-Faltungsfiltern erweitert werden.  Eine solche Iteration der Datenkomprimierungserweiterung wird als "Feuermodul" bezeichnet. </li><li>  <a href="https://youtu.be/b6jhopSMit8">DeepLab</a> (Semantische Bildsegmentierung mit Deep Convolutional Nets) - Segmentierung von Objekten im Bild.  Ein charakteristisches Merkmal der Architektur ist eine verd√ºnnte Faltung, die die r√§umliche Aufl√∂sung beibeh√§lt.  Anschlie√üend erfolgt die Nachbearbeitung der Ergebnisse mithilfe eines grafischen Wahrscheinlichkeitsmodells (Bedingtes Zufallsfeld), mit dem Sie geringes Rauschen in der Segmentierung entfernen und die Qualit√§t des segmentierten Bildes verbessern k√∂nnen.  Hinter dem gewaltigen Namen "Graphical Probabilistic Model" verbirgt sich der √ºbliche Gau√ü-Filter, der durch f√ºnf Punkte angen√§hert wird. </li><li>  Ich habe versucht, das <a href="https://arxiv.org/abs/1711.06897">RefineDet-</a> Ger√§t (Single-Shot <strong>Refine</strong> ment Neural Network zur Objekterkennung) zu verstehen, aber ich habe sehr wenig verstanden. </li><li>  Ich habe mir auch angesehen, wie die Aufmerksamkeitstechnologie funktioniert: <a href="https://youtu.be/W2rWgXJBZhU">Video1</a> , <a href="https://youtu.be/iDulhoQ2pro">Video2</a> , <a href="https://youtu.be/H6Qiegq_36c">Video3</a> .  Ein charakteristisches Merkmal der "Aufmerksamkeit" -Architektur ist die automatische Zuweisung von Bereichen mit erh√∂hter Aufmerksamkeit zum Bild (ROI, Interessensregionen) unter Verwendung eines neuronalen Netzwerks, das als Aufmerksamkeitseinheit bezeichnet wird.  Bereiche mit erh√∂hter Aufmerksamkeit √§hneln eingeschr√§nkten Bereichen (Begrenzungsrahmen), sind jedoch im Gegensatz zu diesen nicht auf dem Bild fixiert und weisen m√∂glicherweise unscharfe R√§nder auf.  Anschlie√üend werden aus den Bereichen mit erh√∂hter Aufmerksamkeit Merkmale (Features) unterschieden, die wiederkehrenden neuronalen Netzwerken mit <a href="https://youtu.be/5lUUrREboSk">LSDM-, GRU- oder Vanilla RNN-</a> Architekturen "zugef√ºhrt" werden.  Rekursive neuronale Netze k√∂nnen die Beziehung von Zeichen in einer Sequenz analysieren.  Rekursive neuronale Netze wurden urspr√ºnglich verwendet, um Text in andere Sprachen zu √ºbersetzen, und jetzt, um <a href="https://youtu.be/e-WB4lfg30M">Bilder in Text</a> und <a href="https://youtu.be/rAbhypxs1qQ">Text in Bilder</a> zu √ºbersetzen. </li></ul><br><p>  Als ich diese Architekturen studierte, stellte <strong>ich fest, dass ich nichts verstand</strong> .  Und der Punkt ist nicht, dass mein neuronales Netzwerk Probleme mit dem Aufmerksamkeitsmechanismus hat.  Das Erstellen all dieser Architekturen sieht aus wie ein riesiger Hackathon, bei dem Autoren an Hacks teilnehmen.  Hack ist eine schnelle L√∂sung f√ºr eine schwierige Softwareaufgabe.  Das hei√üt, es gibt keine sichtbare und verst√§ndliche logische Verbindung zwischen all diesen Architekturen.  Alles, was sie verbindet, ist eine Reihe der erfolgreichsten Hacks, die sie voneinander ausleihen, sowie eine gemeinsame <a href="https://youtu.be/Ilg3gGewQ5U">Faltungsoperation mit R√ºckkopplung</a> (umgekehrte Ausbreitung von Fehlern, Backpropagation).  Kein <a href="https://habr.com/ru/post/272473/">systemisches Denken</a> !  Es ist nicht klar, was ge√§ndert und wie vorhandene Erfolge optimiert werden sollen. </p><br><p>  Aufgrund des Fehlens einer logischen Verbindung zwischen Hacks ist es √§u√üerst schwierig, sich an sie zu erinnern und sie in die Praxis umzusetzen.  Das ist fragmentiertes Wissen.  Im besten Fall werden einige interessante und unerwartete Momente in Erinnerung gerufen, aber das meiste, was verstanden und unverst√§ndlich ist, verschwindet innerhalb weniger Tage aus dem Ged√§chtnis.  Es wird gut sein, wenn ich mich in einer Woche zumindest an den Namen der Architektur erinnere.  Aber es dauerte mehrere Stunden und sogar Tage, um Artikel zu lesen und Review-Videos anzuschauen! </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/ffc/1b0/019/ffc1b0019fe7a23e2923d9642485290a.png" alt="Neuronales Netzwerk Zoo"></p><br><p>  Abbildung 2 - <a href="https://www.asimovinstitute.org/neural-network-zoo/">Zoo neuronaler Netze</a> </p><br><p>  Die meisten Autoren von wissenschaftlichen Artikeln tun meiner Meinung nach alles, damit auch dieses fragmentierte Wissen vom Leser nicht verstanden wird.  Aber die Partizipien in Zehn-Zeilen-S√§tzen mit Formeln, die "von der Decke" genommen wurden, sind ein Thema f√ºr einen separaten Artikel (Problem <a href="https://en.wikipedia.org/wiki/Publish_or_perish">ver√∂ffentlichen oder zugrunde gehen</a> ). </p><br><p>  Aus diesem Grund wurde es notwendig, Informationen in neuronalen Netzen zu systematisieren und damit die Qualit√§t des Verstehens und des Erinnerns zu verbessern.  Daher war das Hauptthema der Analyse einzelner Technologien und Architekturen k√ºnstlicher neuronaler Netze die folgende Aufgabe: <strong>herauszufinden, wo sich all dies bewegt</strong> , und nicht das Ger√§t eines bestimmten neuronalen Netzes separat. </p><br><p>  Wohin geht das alles?  Die wichtigsten Ergebnisse: </p><br><ul><li>  Die Zahl der Startups im Bereich des maschinellen Lernens <a href="https://habr.com/ru/company/recognitor/blog/455676/">ist</a> in den letzten zwei Jahren stark zur√ºckgegangen.  M√∂glicher Grund: "Neuronale Netze sind nicht mehr neu." </li><li>  Jeder kann ein funktionierendes neuronales Netzwerk erstellen, um ein einfaches Problem zu l√∂sen.  Nehmen Sie dazu das fertige Modell aus dem ‚ÄûModellzoo‚Äú und trainieren Sie die letzte Schicht des neuronalen Netzwerks ( <a href="https://youtu.be/yofjFQddwHE">Transfer Learning</a> ) mit den fertigen Daten aus der <a href="https://toolbox.google.com/datasetsearch">Google Dataset Search</a> oder aus <a href="https://www.kaggle.com/datasets">25.000 Kaggle-Datens√§tzen</a> in der kostenlosen <a href="https://www.dataschool.io/cloud-services-for-jupyter-notebook/">Jupyter Notebook-Cloud</a> . </li><li>  Gro√üe Hersteller neuronaler Netze begannen, <strong>"Modellzoos"</strong> (model zoo) zu schaffen.  Mit ihnen k√∂nnen Sie schnell eine kommerzielle Anwendung erstellen: <a href="https://tfhub.dev/">TF Hub</a> f√ºr TensorFlow, <a href="https://github.com/open-mmlab/mmdetection">MMDetection</a> f√ºr PyTorch, <a href="https://github.com/facebookresearch/Detectron">Detectron</a> f√ºr Caffe2, <a href="https://github.com/wkentaro/chainer-modelzoo">chainer-modelzoo</a> f√ºr Chainer und <a href="https://modelzoo.co/">andere</a> . </li><li>  Neuronale Echtzeitnetze auf Mobilger√§ten.  10 bis 50 Bilder pro Sekunde. </li><li>  Die Verwendung von neuronalen Netzen in Telefonen (TF Lite), in Browsern (TF.js) und in <a href="https://youtu.be/19ZNz2N79u4">Haushaltsgegenst√§nden</a> (IoT, Internet und <strong>T</strong> hings).  Besonders in Telefonen, die bereits neuronale Netze auf Hardware-Ebene unterst√ºtzen (Neuroaccelerators). </li><li>  ‚ÄûJedes Ger√§t, jede Kleidung und m√∂glicherweise auch jedes Essen wird eine <strong>IP-v6-Adresse haben</strong> und miteinander kommunizieren‚Äú - <a href="https://youtu.be/GG7H8Xa4m8I%3Ft%3D85">Sebastian Trun</a> . </li><li>  Die Zunahme der Ver√∂ffentlichungen zum maschinellen Lernen hat begonnen, <a href="http://data-mining.philippe-fournier-viger.com/too-many-machine-learning-papers">das Gesetz von Moore</a> (das sich alle zwei Jahre verdoppelt) seit 2015 zu <a href="http://data-mining.philippe-fournier-viger.com/too-many-machine-learning-papers">√ºbertreffen</a> .  Offensichtlich werden neuronale Netze zur Artikelanalyse ben√∂tigt. </li><li>  Folgende Technologien werden immer beliebter: <br><ul><li>  <strong>PyTorch</strong> - Popularit√§t w√§chst schnell und scheint TensorFlow zu √ºberholen. </li><li>  Automatische Auswahl von <strong>AutoML-</strong> Hyperparametern - die Popularit√§t w√§chst stetig. </li><li>  Allm√§hliche Abnahme der Genauigkeit und Erh√∂hung der Rechengeschwindigkeit: <a href="https://youtu.be/rln_kZbYaWc">Fuzzy-Logik</a> , <a href="https://youtu.be/MIPkK5ZAsms">Boosting-</a> Algorithmen, ungenaue (ungef√§hre) Berechnungen, Quantisierung (wenn die Gewichte eines neuronalen Netzwerks in ganze Zahlen und quantisiert werden), Neuro-Beschleuniger. </li><li>  √úbersetzung von <a href="https://youtu.be/e-WB4lfg30M">Bild in Text</a> und <a href="https://youtu.be/rAbhypxs1qQ">Text in Bild</a> . </li><li>  Erstellen Sie <a href="https://youtu.be/OrHLacCDZVQ">dreidimensionale Objekte auf Video</a> , jetzt in Echtzeit. </li><li>  Die Hauptsache in DL sind viele Daten, aber das Sammeln und Markieren ist nicht einfach.  Daher entwickelt sich eine <a href="https://youtu.be/NcKTn4C91Yc">automatisierte Annotation</a> f√ºr neuronale Netze unter Verwendung neuronaler Netze. </li></ul></li><li>  Mit neuronalen Netzen wurde die Informatik pl√∂tzlich zu einer <strong>experimentellen Wissenschaft</strong> und es kam zu einer <a href="https://habr.com/ru/post/480348">Reproduzierbarkeitskrise</a> . </li><li>  IT-Geld und die Popularit√§t neuronaler Netze entstanden gleichzeitig, als das Rechnen zum Marktwert wurde.  Die Wirtschaft von Gold und Devisen wird zum <strong>Goldw√§hrungsrechner</strong> .  Siehe meinen Artikel √ºber <a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D0%25BA%25D0%25BE%25D0%25BD%25D0%25BE%25D1%2584%25D0%25B8%25D0%25B7%25D0%25B8%25D0%25BA%25D0%25B0">Wirtschaftsphysik</a> und den Grund f√ºr die Entstehung von IT-Geld. </li></ul><br><p>  Allm√§hlich erscheint eine neue <a href="https://habr.com/ru/post/481844">ML / DL-Programmiermethode</a> (Machine Learning &amp; Deep Learning), die auf der Darstellung des Programms als Sammlung trainierter neuronaler Netzwerkmodelle basiert. </p><br><p><img src="https://habrastorage.org/webt/tx/_a/vl/tx_avlc4bdfe6cfu5hy2bug3nby.png" alt="ML / DL als neue Programmiermethode"></p><br><p>  Abbildung 3 - ML / DL als neue Programmiermethode </p><br><p>  Die <strong>‚ÄûTheorie der neuronalen Netze‚Äú</strong> , in deren Rahmen man systematisch denken und arbeiten kann, ist jedoch nicht aufgetaucht.  Was heute als "Theorie" bezeichnet wird, sind experimentelle heuristische Algorithmen. </p><br><p>  Links zu meinen und nicht nur Ressourcen: </p><br><ul><li>  Data Science Newsletter.  Meistens Bildverarbeitung.  Wer empfangen m√∂chte, soll ihm eine E-Mail senden (foobar167 &lt;gaff-gaf&gt; gmail &lt;dot&gt; com).  Ich sende Links zu Artikeln und Videos, wenn sich Material ansammelt. </li><li>  Eine allgemeine <a href="">Liste der Kurse und Artikel</a> , an denen ich teilgenommen habe und teilnehmen m√∂chte. </li><li>  <a href="">Kurse und Videos f√ºr Anf√§nger</a> , ab denen es sich lohnt, neuronale Netze zu studieren.  Dazu die Brosch√ºre <a href="https://foobar167.github.io/page/vvedeniye-v-mashinnoye-obucheniye-i-iskusstvennyye-neyronnyye-seti.html">"Einf√ºhrung in maschinelles Lernen und k√ºnstliche neuronale Netze".</a> </li><li>  <a href="">N√ºtzliche Tools, bei</a> denen jeder etwas Interessantes f√ºr sich findet. </li><li>  Die <strong>Videokan√§le zur Analyse von wissenschaftlichen Artikeln</strong> √ºber Data Science haben sich als √§u√üerst n√ºtzlich erwiesen.  Suchen, abonnieren und Links an Ihre Kollegen und mich senden.  Beispiele: <br><ul><li>  <a href="https://www.youtube.com/user/keeroyz">Zwei Minutenbl√§tter</a> </li><li>  <a href="https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw">Henry AI Labs</a> </li><li>  <a href="https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew">Yannic Kilcher</a> </li><li>  <a href="https://www.youtube.com/channel/UC5_6ZD6s8klmMu9TXEB_1IA">CodeEmporium</a> </li><li>  <a href="https://www.dlology.com/">Chengwei Zhang</a> aka <a href="https://github.com/Tony607">Tony607 Blog</a> mit Schritt-f√ºr-Schritt-Anleitung und Open Source. </li></ul></li></ul><br><p>  Vielen Dank f√ºr Ihre Aufmerksamkeit! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de482794/">https://habr.com/ru/post/de482794/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de482780/index.html">Experimente mit neuronalen Netzen basierend auf seismischen Daten</a></li>
<li><a href="../de482784/index.html">Das geheime Leben eines Linux-Servers oder Fan-Brute-Force-Angriffs auf das SSH-Subsystem</a></li>
<li><a href="../de482786/index.html">Ungel√∂stes R√§tsel</a></li>
<li><a href="../de482790/index.html">Vergessen Sie die homomorphe Verschl√ºsselung: Jetzt haben wir eine funktionale Verschl√ºsselung</a></li>
<li><a href="../de482792/index.html">ITER-Projekt im Jahr 2019</a></li>
<li><a href="../de482798/index.html">Sehen Sie den Wald hinter den B√§umen</a></li>
<li><a href="../de482800/index.html">Meine Suche nach dem physischen Bedienfeld eines Smart Homes</a></li>
<li><a href="../de482802/index.html">Remote-Einbindung von Mikrotik-Skripten aus Telegram 2.0</a></li>
<li><a href="../de482804/index.html">Java: Reduzieren Sie mehrzeilige Protokolle mithilfe von Spring and Logback oder Log4j2 in ein einzeiliges Protokoll</a></li>
<li><a href="../de482806/index.html">Die Propaganda des totalit√§ren Regimes, des Antisemitismus und der Homophobie im Lehrbuch √ºber die Programmierung von 2019? - Das ist m√∂glich</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
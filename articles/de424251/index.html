<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë∂üèº üëãüèº üë©üèΩ‚Äçüè≠ Wir betrachten Statistiken √ºber Experimente auf hh.ru. üê£ üññüèª üê±</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo allerseits! 

 Heute werde ich Ihnen sagen, wie wir bei hh.ru manuelle Statistiken zu Experimenten betrachten. Wir werden sehen, woher die Daten...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wir betrachten Statistiken √ºber Experimente auf hh.ru.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/hh/blog/424251/">  Hallo allerseits! <br><br>  Heute werde ich Ihnen sagen, wie wir bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hh.ru</a> manuelle Statistiken zu Experimenten betrachten.  Wir werden sehen, woher die Daten stammen, wie wir sie verarbeiten und auf welche Fallstricke wir sto√üen.  In diesem Artikel werde ich eine gemeinsame Architektur und einen gemeinsamen Ansatz vorstellen. Es wird ein Minimum an echten Skripten und Code geben.  Das Hauptpublikum sind unerfahrene Analysten, die sich f√ºr die Struktur der Datenanalyse-Infrastruktur in hh.ru interessieren.  Wenn dieses Thema interessant sein wird - schreiben Sie in die Kommentare, wir k√∂nnen uns mit dem Code in den folgenden Artikeln befassen. <br><br>  In unserem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">anderen Artikel</a> erfahren Sie, wie automatische Metriken f√ºr A / B-Experimente ber√ºcksichtigt werden. <br><br><img src="https://habrastorage.org/webt/2t/ni/z7/2tniz7lywqs_e1q19yafq1n6vss.jpeg" alt="Bild"><br><a name="habracut"></a><br><h2>  Welche Daten analysieren wir und woher kommen sie? </h2><br>  Wir analysieren Zugriffsprotokolle und alle benutzerdefinierten Protokolle, die wir selbst schreiben. <br><br><blockquote>  95.108.213.12 - - [13 / Aug / 2018: 04: 00: 02 +0300] 200 "GET / Arbeitgeber / 2574971 HTTP / 1.1" 12012 "-" Mozilla / 5.0 (kompatibel; YandexBot / 3.0; + http: / /yandex.com/bots) "-" gardabani.headhunter.ge "" 0.063 "-" 1534122002.858 "-" 192.168.2.38:1500 "[0.064] {15341220027959c8c01c51a6e01b682f} 200 https 1 -" - "- - [35827] [0,000 0] <br>  178.23.230.16 - - [13 / Aug / 2018: 04: 00: 02 +0300] 200 "GET / vacancy / 24266672 HTTP / 1.1" 24229 " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hh.ru/vacancy/24007186?query=bmw</a> " "Mozilla / 5.0 ( Macintosh; Intel Mac OS X 10_10_5) AppleWebKit / 603.3.8 (KHTML, wie Gecko) Version / 10.1.2 Safari / 603.3.8 - hh.ru 0.210 last_visit = 1534111115966 :: 1534121915966;  hhrole = anonym;  Regionen = 1;  tmr_detect = 0% 7C1534121918520;  total_searches = 3;  unique_banner_user = 1534121429.273825242076558 1534122002.859 - 192.168.2.239:1500 [0.208] {1534122002649b7eef2e901d8c9c0469} 200 https 1 - "-" - [35927] [0.001] </blockquote><br>  In unserer Architektur schreibt jeder Dienst Protokolle lokal und wird dann √ºber die selbst geschriebenen Client-Server-Protokolle (einschlie√ülich Nginx-Zugriffsprotokollen) in einem zentralen Repository gesammelt (im Folgenden Protokollierung).  Entwickler haben Zugriff auf diesen Computer und k√∂nnen die Protokolle bei Bedarf manuell protokollieren.  Aber wie k√∂nnen in angemessener Zeit mehrere hundert Gigabyte an Protokollen verschlungen werden?  Gie√üen Sie sie nat√ºrlich in Hadoop! <br><br><h3>  Woher kommen die Daten in Hadoop? </h3><br>  Hadoop speichert nicht nur Serviceprotokolle, sondern l√§dt auch die Produktdatenbank hoch.  Jeden Tag laden wir in hadoop einige der Tabellen hoch, die f√ºr die Analyse ben√∂tigt werden. <br><br>  Serviceprotokolle gelangen auf drei Arten in Hadoop. <br><br><ol><li>  <b>Weg zur Stirn</b> - cron wird nachts aus dem Protokollspeicher gestartet, und rsync l√§dt Rohprotokolle auf hdfs hoch. </li><li>  <b>Der Weg ist in Mode</b> - Protokolle von Diensten werden nicht nur in den gemeinsamen Speicher, sondern auch in Kafka gegossen, wo Flume sie liest, vorverarbeitet und in HDFS speichert. </li><li>  <b>Der Pfad ist altmodisch</b> - in den Tagen vor kafka haben wir unseren eigenen Service geschrieben, der Rohprotokolle aus dem Speicher liest, aus der Vorverarbeitung herausholt und auf hdfs hochl√§dt. </li></ol><br>  Lassen Sie uns jeden Ansatz genauer betrachten. <br><br><h4>  Stirnpfad </h4><br>  Cron f√ºhrt ein regul√§res Bash-Skript aus. <br><br><pre><code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash LOGGING_DATE_PATH_PART=$(date -d yesterday +\%Y/\%m/\%d) HADOOP_DATE_PATH_PART=$(date -d yesterday +year=\%Y/month=\%m/day=\%d) ls /logging/java/${LOGGING_DATE_PATH_PART}/hh-banner-sync/banner-versions*.log | while read source_filename; do dest_filename=$(basename "$source_filename") /usr/bin/rsync --no-relative --no-implied-dirs --bwlimit=12288 ${source_filename} rsync://hadoop2.hhnet.ru/hdfs-raw/banner-versions/${HADOOP_DATE_PATH_PART}/${dest_filename}; done</span></span></code> </pre> <br>  Wie wir uns erinnern, haben alle Protokolle im Protokollrepository die Form gew√∂hnlicher Dateien. Die Ordnerstruktur sieht ungef√§hr so ‚Äã‚Äãaus: /logging/java/2018/08/10/{service_nameasure/*.log <br><br>  Hadoop speichert seine Dateien in ungef√§hr derselben Ordnerstruktur wie hdfs-raw / banner-version / year = 2018 / month = 08 / day = 10 <br>  Jahr, Monat, Tag verwenden wir als Partitionen. <br><br>  Daher m√ºssen wir nur die richtigen Pfade bilden (Zeilen 3-4), dann alle erforderlichen Protokolle ausw√§hlen (Zeile 6) und sie mit rsync in hadoop (Zeile 8) f√ºllen. <br><br>  <b>Die Vorteile dieses Ansatzes:</b> <br><br><ul><li>  Schnelle Entwicklung </li><li>  Alles ist transparent und klar. </li></ul><br>  <b>Nachteile:</b> <br><br><ul><li>  Keine Vorverarbeitung </li></ul><br><h4>  Modischer Weg </h4><br>  Da wir die Protokolle mit einem selbstgeschriebenen Skript in das Repository hochladen, war es logisch, die M√∂glichkeit zu schrauben, sie nicht nur auf den Server, sondern auch auf kafka hochzuladen. <br><br>  <b>Vorteile</b> <br><br><ul><li>  Online-Protokolle (Protokolle in Hadoop werden angezeigt, wenn Sie Kafka ausf√ºllen) </li><li>  Sie k√∂nnen eine Vorverarbeitung durchf√ºhren </li><li>  Es h√§lt die Last gut und Sie k√∂nnen gro√üe Protokolle hochladen </li></ul><br>  <b>Nachteile</b> <br><br><ul><li>  Schwierigeres Setup </li><li>  Ich muss Code schreiben </li><li>  Weitere Teile des Gie√üprozesses </li><li>  Kompliziertere √úberwachung und Analyse von Vorf√§llen </li></ul><br><h4>  Altmodische Art und Weise </h4><br>  Es unterscheidet sich von der Mode nur in Abwesenheit von Kafka.  Daher erbt es alle Nachteile und nur einige der Vorteile des vorherigen Ansatzes.  Ein separater Dienst (ustats-uploader) in Java liest regelm√§√üig die erforderlichen Dateien, verarbeitet sie vor und l√§dt sie auf hadoop hoch. <br><br>  <b>Vorteile</b> <br><br><ul><li>  Sie k√∂nnen eine Vorverarbeitung durchf√ºhren </li></ul><br>  <b>Nachteile</b> <br><br><ul><li>  Schwierigeres Setup </li><li>  Ich muss Code schreiben </li></ul><br>  Und so kamen die Daten in Hadoop und bereit f√ºr die Analyse.  Lassen Sie uns ein wenig innehalten und uns daran erinnern, was Hadoop ist und warum Hunderte von Gigabyte viel schneller als normales Grep darauf verbraucht werden k√∂nnen. <br><br><h3>  Hadoop </h3><br>  Hadoop ist ein verteiltes Data Warehouse.  Die Daten liegen nicht auf einem separaten Server, sondern werden auf mehrere Computer verteilt und auch nicht in einer Instanz, sondern in mehreren gespeichert - dies wurde durchgef√ºhrt, um die Zuverl√§ssigkeit sicherzustellen.  Die Basis der Datenverarbeitungsgeschwindigkeit liegt in einer √Ñnderung des Ansatzes im Vergleich zu herk√∂mmlichen Datenbanken. <br><br>  Bei einer regul√§ren Datenbank extrahieren wir Daten daraus und senden sie an den Kunden, der eine Analyse durchf√ºhrt und das Ergebnis an den Analysten zur√ºckgibt.  Um schneller z√§hlen zu k√∂nnen, m√ºssen wir viele Kunden haben und Anforderungen parallelisieren (z. B. um Daten durch Monate zu teilen - und jeder Kunde kann Daten f√ºr seinen Monat lesen). <br><br>  In Hadoop ist das Gegenteil der Fall.  Wir senden den Code (genau das, was wir berechnen m√∂chten) an die Daten, und dieser Code wird im Cluster ausgef√ºhrt.  Wie wir wissen, liegen Daten auf vielen Computern, sodass jeder Computer nur Code f√ºr seine Daten ausf√ºhrt und das Ergebnis an den Client zur√ºckgibt. <br><br>  Viele haben wahrscheinlich von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Map-Reduce geh√∂rt</a> , aber das Schreiben von Code f√ºr Analysen ist nicht sehr bequem und schnell, w√§hrend das Schreiben in SQL viel einfacher ist.  Daher gab es Dienste, die SQL f√ºr den Benutzer transparent in Kartenreduzierung verwandeln k√∂nnen, und der Analyst ahnt m√∂glicherweise nicht, wie seine Anforderung tats√§chlich ber√ºcksichtigt wird. <br><br>  In hh.ru verwenden wir daf√ºr Hive und Presto.  Hive war der erste, aber wir bewegen uns allm√§hlich zu Presto, weil es f√ºr unsere Anfragen viel schneller ist.  Als GUI verwenden wir Farbton und Zeppelin. <br><br>  F√ºr mich ist es bequemer, Analysen in Python in Jupyter zu betrachten. Dadurch k√∂nnen wir sie mit einem Klick lesen und an der Ausgabe korrekt formatierte Excel-Tabellen erhalten, was viel Zeit spart.  Schreiben Sie in die Kommentare, dieses Thema bezieht sich auf einen separaten Artikel. <br><br>  Kehren wir zur Analyse selbst zur√ºck. <br><br><h2>  Wie kann man verstehen, was wir ber√ºcksichtigen wollen? </h2><br><h3>  Der Produktmanager hatte die Aufgabe, die Ergebnisse des Experiments zu berechnen </h3><br>  Wir versenden einen E-Mail-Newsletter, in dem wir geeignete Stellen f√ºr den Bewerber versenden (mag jeder solche Mailings?).  Wir haben beschlossen, das Design des Briefes ein wenig zu √§ndern und wollen verstehen, ob es besser wurde.  Dazu werden wir ber√ºcksichtigen: <br><br><ul><li>  die Anzahl der √úberg√§nge zu offenen Stellen aus dem Brief; </li><li>  Feedback nach dem √úbergang </li></ul><br>  Ich m√∂chte Sie daran erinnern, dass wir nur Zugriffsprotokoll und Datenbank haben.  Wir m√ºssen unsere Metriken in Form von Linkklicks formulieren. <br><br><h4>  Anzahl der √úberg√§nge zu einer offenen Stelle aus einem Brief </h4><br>  Der √úbergang ist eine GET-Anforderung an <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hh.ru/vacancy/26646861</a> .  Um zu verstehen, woher der √úbergang kam, f√ºgen wir utm-Tags des Formulars? Utm_source = email_campaign_123 hinzu.  F√ºr GET-Anfragen im Zugriffsprotokoll werden Informationen zu den Parametern angezeigt, und wir k√∂nnen die √úberg√§nge nur aus unserer Mailingliste herausfiltern. <br><br><h4>  Die Anzahl der Antworten nach dem √úbergang </h4><br>  Hier k√∂nnten wir einfach die Anzahl der Antworten auf offene Stellen aus dem Newsletter berechnen, aber dann w√§ren die Statistiken falsch, da die Antworten durch etwas anderes beeinflusst werden k√∂nnten, au√üer f√ºr unseren Brief, zum Beispiel, dass eine Anzeige in ClickMe f√ºr eine freie Stelle gekauft wurde, und daher die Anzahl der Antworten stark gewachsen. <br><br>  Wir haben zwei M√∂glichkeiten, um die Anzahl der Antworten zu formulieren: <br><br><ol><li>  Die Antwort ist ein POST auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hh.ru/applicant/vacancy_response/popup?vacancy_id=26646861</a> , der einen Referer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hh.ru/vacancy/26646861?utm_source=email_campaign_123 enth√§lt</a> . </li><li>  Die Nuance dieses Ansatzes besteht darin, dass wir den Benutzer nicht z√§hlen, wenn er zu einer freien Stelle gewechselt ist und dann ein wenig auf der Website herumgelaufen ist und dann auf eine freie Stelle geantwortet hat. </li><li>  Wir k√∂nnen uns die ID des Benutzers <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">merken</a> , der zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hh.ru/vacancy/26646861 gewechselt ist</a> , und die Anzahl der Bewertungen f√ºr die freie Stelle w√§hrend des Tages basierend auf der Datenbank berechnen. </li></ol><br>  Die Wahl des Ansatzes wird von den Gesch√§ftsanforderungen bestimmt. Normalerweise reicht die erste Option aus, aber alles h√§ngt davon ab, worauf der Produktmanager wartet. <br><br><h2>  Fallstricke, die auftreten k√∂nnen </h2><br><ol><li>  Nicht alle Daten befinden sich in Hadoop. Sie m√ºssen Daten aus der Produktdatenbank hinzuf√ºgen.  Zum Beispiel in Protokollen normalerweise nur ID, und wenn Sie einen Namen ben√∂tigen, dann ist es in der Datenbank.  Manchmal m√ºssen Sie mit resume_id nach einem Benutzer suchen, und dieser wird auch in der Datenbank gespeichert.  Dazu entladen wir einen Teil der Datenbank in hadoop, damit der Join einfacher wird. </li><li>  Daten k√∂nnen Kurven sein.  Dies ist im Allgemeinen eine Katastrophe f√ºr Hadoop und die Art und Weise, wie wir Daten in ihn laden.  Abh√§ngig von den Daten kann ein leerer Wert null, keine, keine, eine leere Zeichenfolge usw. sein. Sie m√ºssen in jedem Fall vorsichtig sein, da die Daten wirklich unterschiedlich sind, auf unterschiedliche Weise und f√ºr unterschiedliche Zwecke geladen werden. </li><li>  Lange Z√§hlung f√ºr den gesamten Zeitraum.  Zum Beispiel m√ºssen wir unsere √úberg√§nge und Antworten f√ºr den Monat berechnen.  Dies sind ungef√§hr 3 Terabyte an Protokollen.  Sogar Hadoop wird dies f√ºr einige Zeit in Anspruch nehmen.  Normalerweise ist es ziemlich schwierig, eine 100% ige Arbeitsanfrage beim ersten Mal zu schreiben, daher schreiben wir sie durch Ausprobieren.  Jedes Mal 20 Minuten zu warten ist eine sehr lange Zeit.  L√∂sungsm√∂glichkeiten: <br><br><ul><li>  Debuggen der Anforderung in den Protokollen in 1 Tag.  Da wir Daten in hadoop partitioniert hatten, ist es ziemlich schnell, etwas f√ºr einen Tag Protokolle zu berechnen. </li><li>  Laden Sie die erforderlichen Protokolle in die tempor√§re Tabelle hoch.  In der Regel verstehen wir, an welchen URLs wir interessiert sind, und k√∂nnen aus diesen URLs eine tempor√§re Tabelle f√ºr die Protokolle erstellen. </li></ul><br>  Pers√∂nlich ist die erste Option f√ºr mich bequemer, aber manchmal muss ich eine tempor√§re Tabelle erstellen, dies h√§ngt von der Situation ab. </li><li>  Verzerrungen in den endg√ºltigen Metriken <br><ul><li>  Es ist besser, die Protokolle zu filtern.  Sie m√ºssen zum Beispiel auf den Antwortcode, die Umleitung usw. achten. Besser weniger Daten, aber genauer, von denen Sie sicher sind. </li><li>  So wenige Zwischenschritte wie m√∂glich in der Metrik.  Zum Beispiel ist der Wechsel zu einer freien Stelle ein Schritt (GET-Anforderung f√ºr / freie Stelle / 123).  Die Antwort ist zwei (√úbergang zu Vakanz + POST).  Je k√ºrzer die Kette, desto weniger Fehler und genauer die Metrik.  Manchmal kommt es vor, dass die Daten zwischen √úberg√§ngen verloren gehen und es im Allgemeinen unm√∂glich ist, etwas zu berechnen.  Um dieses Problem zu l√∂sen, m√ºssen wir uns √ºberlegen, was und wie wir ber√ºcksichtigen, bevor wir ein Experiment entwickeln.  Ihr separates Protokoll der notwendigen Ereignisse hilft sehr.  Wir k√∂nnen die notwendigen Ereignisse aufnehmen, und somit wird die Ereigniskette genauer und das Z√§hlen ist einfacher. </li><li>  Bots k√∂nnen eine Reihe von √úberg√§ngen erzeugen.  Sie m√ºssen verstehen, wohin Bots gehen k√∂nnen (z. B. auf Seiten, auf denen eine Autorisierung erforderlich ist, sollte dies nicht der Fall sein), und diese Daten filtern. </li><li>  Gro√üe Probleme - zum Beispiel kann es in einer der Gruppen einen Bewerber geben, der 50% aller Antworten generiert.  Es wird eine Reihe von Statistiken geben, solche Daten m√ºssen auch gefiltert werden. </li></ul></li><li>  Es ist schwierig zu formulieren, was im Hinblick auf das Zugriffsprotokoll zu beachten ist.  Dies hilft bei der Kenntnis der Codebasis, der Erfahrung und der Chrome-Entwicklungstools.  Wir lesen die Beschreibung der Metrik aus dem Produkt, wiederholen sie mit unseren H√§nden auf der Website und sehen, welche √úberg√§nge generiert werden. </li></ol><br>  Lassen Sie uns abschlie√üend dar√ºber sprechen, wie das Ergebnis der Berechnungen aussehen soll. <br><br><h2>  Berechnungsergebnis </h2><br>  In unserem Beispiel gibt es 2 Gruppen und 2 Metriken, die einen Trichter bilden. <br><img src="https://habrastorage.org/webt/mn/fx/cm/mnfxcmiwrbhfvxnqomoy_v_zztw.png" alt="Bild"><br>  Empfehlungen f√ºr die Berichterstattung √ºber die Ergebnisse: <br><br><ol><li>  Teile nicht √ºberladen, bis sie ben√∂tigt werden.  Einfach und kleiner ist besser (hier k√∂nnten wir beispielsweise jede freie Stelle einzeln anzeigen oder nach Tag klicken).  Konzentrieren Sie sich auf eine Sache. </li><li>  W√§hrend der Demo-Ergebnisse werden m√∂glicherweise Details ben√∂tigt. √úberlegen Sie sich also, welche Fragen Sie m√∂glicherweise stellen, und bereiten Sie die Details vor.  (In unserem Beispiel kann die Detaillierung der √úbergangsgeschwindigkeit nach dem Senden der E-Mail entsprechen - 1 Tag, 3 Tage, eine Woche, Gruppierung der offenen Stellen nach Berufsfeldern) </li><li>  Denken Sie an die statistische Signifikanz.  Beispielsweise ist eine √Ñnderung von 1% mit 100 Klicks und 15 Klicks unbedeutend und kann zuf√§llig sein.  Verwenden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Taschenrechner</a> </li><li>  Automatisieren Sie so viel wie m√∂glich, da Sie mehrmals z√§hlen m√ºssen.  Normalerweise m√∂chte man schon mitten in einem Experiment verstehen, wie die Dinge laufen.  Nach dem Experiment k√∂nnen Fragen auftauchen und Sie m√ºssen etwas kl√§ren.  Daher ist es notwendig, 3-4 Mal zu z√§hlen, und wenn jede Berechnung eine Folge von 10 Abfragen und anschlie√üendem manuellen Kopieren ist, um zu √ºbertreffen, wird es weh tun und viel Zeit verbringen.  Lernen Sie Python, es wird eine Menge Zeit sparen. </li><li>  Verwenden Sie eine grafische Darstellung der Ergebnisse, wenn dies gerechtfertigt ist.  Mit den integrierten Hive- und Zeppelin-Tools k√∂nnen Sie sofort einfache Diagramme erstellen. </li></ol><br>  Es ist notwendig, verschiedene Metriken h√§ufig zu ber√ºcksichtigen, da wir fast jede Aufgabe im Rahmen eines A / B-Experiments ausgeben.  Die Berechnungen sind nicht kompliziert, nach 2-3 Experimenten wird verstanden, wie das geht.  Denken Sie daran, dass in Zugriffsprotokollen viele n√ºtzliche Informationen gespeichert sind, mit denen Unternehmen Geld sparen, Ihre Idee f√∂rdern und nachweisen k√∂nnen, welche der √Ñnderungsoptionen besser ist.  Die Hauptsache ist, diese Informationen erhalten zu k√∂nnen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de424251/">https://habr.com/ru/post/de424251/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de424241/index.html">Drucken Sie Ihre Welt</a></li>
<li><a href="../de424243/index.html">5 einfache M√∂glichkeiten zur Verbesserung der Kommunikation mit Kunden</a></li>
<li><a href="../de424245/index.html">Write Telegram Client - Einfach</a></li>
<li><a href="../de424247/index.html">KotlinConf 2018 Live - Sehen Sie sich die Sendung vom 4. bis 5. Oktober an</a></li>
<li><a href="../de424249/index.html">Materialien vom Treffen #RuPostgres - Videos, Pr√§sentationen, Analyse des Quiz und Fotobericht</a></li>
<li><a href="../de424255/index.html">So verwenden Sie die statische Analyse richtig</a></li>
<li><a href="../de424257/index.html">Sechseckkarten in Einheit: Teile 1-3</a></li>
<li><a href="../de424259/index.html">Sicherheitswoche 36: Telnet sollte geschlossen sein</a></li>
<li><a href="../de424261/index.html">So l√∂sen Sie Programmierprobleme</a></li>
<li><a href="../de424263/index.html">IDA Pro aktualisieren. Wir beheben Pfosten von Prozessormodulen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîå üòò üåô Le ense√±amos a la computadora a distinguir los sonidos: conocer el concurso DCASE y armar su clasificador de audio en 30 minutos üë± üë®üèª‚Äçüè≠ ü§æ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este art√≠culo fue escrito en conjunci√≥n con ananaskelly . 
 Introduccion 


 Hola a todos, Habr! Trabajando en el Centro de Tecnolog√≠a del Habla en Sa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le ense√±amos a la computadora a distinguir los sonidos: conocer el concurso DCASE y armar su clasificador de audio en 30 minutos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/speechpro/blog/437818/"><p>  Este art√≠culo fue escrito en conjunci√≥n con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">ananaskelly</a> . </p><br><h3 id="vvedenie">  Introduccion </h3><br><p>  Hola a todos, Habr!  Trabajando en el Centro de Tecnolog√≠a del Habla en San Petersburgo, hemos adquirido un poco de experiencia en la soluci√≥n de problemas de clasificaci√≥n y detecci√≥n de eventos ac√∫sticos y decidimos que estamos listos para compartirlo con usted.  El prop√≥sito de este art√≠culo es presentarle algunas tareas y hablar sobre el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">concurso de</a> procesamiento autom√°tico de sonido <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">DCASE 2018</a> .  Al contarle sobre el concurso, lo haremos <u>sin f√≥rmulas y definiciones complejas</u> relacionadas con el aprendizaje autom√°tico, por lo que el <u>p√∫blico</u> entender√° el significado general del art√≠culo. </p><br><p>  Para aquellos que se sintieron atra√≠dos por el <b>ensamblaje del clasificador</b> , preparamos un peque√±o c√≥digo de Python, y desde el enlace en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github</a> puedes encontrar un cuaderno donde, usando la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">segunda pista</a> del concurso DCASE como ejemplo, creamos una red convolucional simple en keras para clasificar archivos de audio.  All√≠ hablamos un poco sobre la red y las caracter√≠sticas utilizadas para la capacitaci√≥n, y c√≥mo usar una arquitectura simple para obtener un resultado cercano a la l√≠nea de base ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MAP @ 3</a> = 0.6). </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cy/xk/ct/cyxkct2xgahwpajkvi4sxzvallu.png"></div><br><p>  Adem√°s, aqu√≠ se describir√°n los enfoques b√°sicos para resolver problemas (l√≠nea de base) propuestos por los organizadores.  Tambi√©n en el futuro habr√° varios art√≠culos donde hablaremos con m√°s detalle y en detalle tanto sobre nuestra experiencia en participar en la competencia como sobre las soluciones propuestas por otros participantes en la competencia.  Los enlaces a estos art√≠culos aparecer√°n gradualmente aqu√≠. </p><a name="habracut"></a><br><p>  Seguramente, muchas personas no tienen absolutamente ninguna idea sobre alg√∫n tipo de <b>"DCASE"</b> , as√≠ que averig√ºemos qu√© tipo de fruta es y con qu√© se come.  La competencia " <abbr title="Detecci√≥n y clasificaci√≥n de escenas y eventos ac√∫sticos (Detecci√≥n y clasificaci√≥n de escenas y eventos ac√∫sticos)">DCASE</abbr> " se celebra anualmente, y cada a√±o se dedican varias tareas a resolver problemas en el campo de la clasificaci√≥n de grabaciones de audio y la detecci√≥n de eventos ac√∫sticos.  Cualquiera puede participar en la competencia, es gratis, para esto es suficiente simplemente registrarse en el sitio como participante.  Como resultado de la competencia, se lleva a cabo una conferencia sobre los mismos temas, pero, a diferencia de la competencia en s√≠, la participaci√≥n en ella ya est√° pagada, y ya no hablaremos m√°s al respecto.  Por lo general, no se conf√≠a en las recompensas por las mejores decisiones, pero hay excepciones (por ejemplo, la tercera tarea en 2018).  Este a√±o, los organizadores propusieron las siguientes 5 tareas: </p><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Clasificaci√≥n de escenas ac√∫sticas (subdivididas en 3 subtareas)</a> <br>  A. Conjuntos de datos de entrenamiento y prueba registrados en el mismo dispositivo <br>  B. conjuntos de datos de entrenamiento y prueba grabados en diferentes dispositivos <br>  C. La capacitaci√≥n se permite utilizando datos no proporcionados por los organizadores. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Clasificaci√≥n de eventos ac√∫sticos</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Detecci√≥n de canto de p√°jaros</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Detecci√≥n de eventos ac√∫sticos en el hogar utilizando un conjunto de datos con etiquetas d√©biles.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Clasificaci√≥n de la actividad del hogar en la sala seg√∫n grabaci√≥n multicanal</a> </li></ol><br><h4 id="o-detektirovanii-i-klassifikacii">  Sobre detecci√≥n y clasificaci√≥n </h4><br><p>  Como podemos ver, los nombres de todas las tareas contienen una de dos palabras: "detecci√≥n" o "clasificaci√≥n".  Aclaremos cu√°l es la diferencia entre estos conceptos para que no haya confusi√≥n. </p><br><p>  Imagine que tenemos una grabaci√≥n de audio en la que un perro ladra en un momento, y un gato ma√∫lla en otro, y simplemente no hay otros eventos all√≠.  Entonces, si queremos entender exactamente cu√°ndo ocurren estos eventos, entonces tenemos que resolver el problema de detectar un evento ac√∫stico.  Es decir, necesitamos averiguar los tiempos de inicio y finalizaci√≥n de cada evento.  Una vez resuelto el problema de detecci√≥n, descubrimos exactamente cu√°ndo ocurren los eventos, pero no sabemos qui√©n hace exactamente los sonidos encontrados, entonces necesitamos resolver el problema de clasificaci√≥n, es decir, determinar qu√© sucedi√≥ exactamente en un per√≠odo de tiempo determinado. </p><br><p>  Para comprender la descripci√≥n de las tareas de la competencia, estos ejemplos ser√°n suficientes, lo que significa que la parte introductoria est√° completa, y podemos proceder a una descripci√≥n detallada de las tareas mismas. </p><br><hr><br><h3 id="anchortrack1anchortrack-1-klassifikaciya-akusticheskih-scen"><a name="Track1"></a>  Pista 1. Clasificaci√≥n de escenas ac√∫sticas </h3><br><p>  La primera tarea es determinar el entorno (escena ac√∫stica) en el que se grab√≥ el audio, por ejemplo, "Estaci√≥n de Metro", "Aeropuerto" o "Calle peatonal".  La soluci√≥n a este problema puede ser √∫til para evaluar el entorno con un sistema de inteligencia artificial, por ejemplo, en autom√≥viles con piloto autom√°tico. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/db/4g/ff/db4gffctu9tgvd4upbse_eaaiwg.jpeg"></div><br><p>  En esta tarea, los conjuntos de datos m√≥viles TUT Urban Acoustic Scenes 2018 y TUT Urban Acoustic Scenes 2018 Mobile, que fueron preparados por la Universidad Tecnol√≥gica de Tampere (Finlandia), se presentaron para capacitaci√≥n.  En el art√≠culo se describe una descripci√≥n detallada de la preparaci√≥n del conjunto de datos, as√≠ como la soluci√≥n b√°sica. </p><br><p>  En total, se presentaron 10 escenas ac√∫sticas para la competencia, que los participantes tuvieron que predecir. </p><br><h4 id="podzadacha-a">  Subtarea A </h4><br><p>  Como ya dijimos, la tarea se divide en 3 subtareas, cada una de las cuales difiere en la calidad de las grabaciones de audio.  Por ejemplo, en la subtarea A, se utilizaron micr√≥fonos especiales para la grabaci√≥n, que se ubicaron en los o√≠dos humanos.  Por lo tanto, la grabaci√≥n est√©reo se hizo m√°s cercana a la percepci√≥n humana del sonido.  Los participantes tuvieron la oportunidad de utilizar este enfoque de grabaci√≥n para mejorar la calidad del reconocimiento de la escena ac√∫stica. </p><br><h4 id="podzadacha-v">  Subtarea B </h4><br><p>  En la subtarea B, tambi√©n se utilizaron otros dispositivos (por ejemplo, tel√©fonos m√≥viles) para la grabaci√≥n.  Los datos de la subtarea A se convirtieron a un formato mono, la frecuencia de muestreo se redujo, no hay simulaci√≥n de la "audibilidad" del sonido por parte de una persona en el conjunto de datos para esta tarea, pero hay m√°s datos para la capacitaci√≥n. </p><br><h4 id="podzadacha-s">  Subtarea C </h4><br><p>  El conjunto de datos para la subtarea C es el mismo que en la subtarea A, pero al resolver este problema se permite usar cualquier dato externo que el participante pueda encontrar.  El objetivo de resolver este problema es descubrir si es posible mejorar el resultado obtenido en la subtarea A utilizando datos de terceros. </p><br><p>  La calidad de las decisiones en esta pista fue evaluada por la m√©trica de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">precisi√≥n</a> . </p><br><p>  La l√≠nea de base para esta tarea es una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">red neuronal convolucional de</a> dos capas que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aprende</a> de los logaritmos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">peque√±os espectrogramas de los</a> datos de audio originales.  La arquitectura propuesta utiliza las t√©cnicas est√°ndar de BatchNormalization y Dropout.  El c√≥digo en GitHub se puede ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . </p><br><hr><br><h3 id="anchortrack2anchortrack-2-klassifikaciya-akusticheskih-sobytiy"><a name="Track2"></a>  Pista 2. Clasificaci√≥n de eventos ac√∫sticos </h3><br><p>  En esta tarea, se propone crear un sistema que clasifique los eventos ac√∫sticos.  Tal sistema puede ser una adici√≥n a hogares inteligentes, aumentar la seguridad en lugares concurridos o facilitar la vida de las personas con discapacidad auditiva. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ut/r5/9_/utr59_-ugehiq9jyhe_hgpgzbrm.jpeg"></div><br><p>  El conjunto de datos para esta tarea consiste en archivos tomados del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">conjunto de datos Freesound</a> y etiquetados con etiquetas del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AudioSet</a> de Google.  M√°s detalladamente, el proceso de preparaci√≥n del conjunto de datos se describe en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un art√≠culo</a> preparado por los organizadores del concurso. </p><br><p>  Volvamos a la tarea en s√≠, que tiene varias caracter√≠sticas. </p><br><p>  En primer lugar, los participantes tuvieron que crear un modelo capaz de identificar diferencias entre eventos ac√∫sticos de una naturaleza muy diferente.  El conjunto de datos se divide en la clase 41, presenta varios instrumentos musicales, sonidos hechos por humanos, animales, sonidos dom√©sticos y m√°s. </p><br><p>  En segundo lugar, adem√°s del marcado habitual de datos, tambi√©n hay informaci√≥n adicional sobre c√≥mo verificar la etiqueta manualmente.  Es decir, los participantes saben qu√© archivos del conjunto de datos fueron verificados por la persona para verificar el cumplimiento de la etiqueta, y cu√°les no.  Como lo ha demostrado la pr√°ctica, los participantes que de alguna manera usaron esta informaci√≥n adicional se llevaron premios para resolver este problema. </p><br><p>  Adem√°s, debe decirse que la duraci√≥n de los registros en el conjunto de datos var√≠a mucho: de 0.3 segundos a 30 segundos.  En este problema, la cantidad de datos por clase, sobre la cual el modelo necesita ser entrenado, tambi√©n var√≠a mucho.  Esto se representa mejor como un histograma, el c√≥digo para construir que se toma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de aqu√≠</a> . </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tw/r4/gq/twr4gqwzkdivbpzkipwh6jesugi.jpeg"></div><br><p>  Como puede ver en el histograma, el marcado manual para las clases presentadas tambi√©n est√° desequilibrado, lo que agrega dificultad si desea utilizar esta informaci√≥n al entrenar modelos. <br>  Los resultados en esta pista se evaluaron utilizando la m√©trica de precisi√≥n promedio (Precisi√≥n media promedio, MAP @ 3), una demostraci√≥n bastante simple de calcular esta m√©trica con ejemplos y c√≥digo se puede encontrar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . </p><br><hr><br><h3 id="anchortrack3anchortrack-3-detektirovanie-ptichego-peniya"><a name="Track3"></a>  Pista 3. Detecci√≥n de canto de p√°jaros </h3><br><p>  La siguiente pista es la detecci√≥n del canto de los p√°jaros.  Un problema similar surge, por ejemplo, en varios sistemas de monitoreo autom√°tico de la vida silvestre: este es el primer paso en el procesamiento de datos antes, por ejemplo, de la clasificaci√≥n.  Dichos sistemas a menudo necesitan ajuste, son inestables a las nuevas condiciones ac√∫sticas, por lo tanto, el prop√≥sito de esta pista es recurrir al poder del aprendizaje autom√°tico para resolver tales problemas. </p><br><p>  Esta pista es una versi√≥n extendida del concurso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Desaf√≠o de detecci√≥n de audio de aves"</a> organizado por la Universidad de Santa Mar√≠a de Londres en 2017/2018.  Para aquellos interesados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">,</a> puede leer el art√≠culo de los autores de la competencia, que proporciona detalles sobre la formaci√≥n de datos, la organizaci√≥n de la competencia y un an√°lisis de las decisiones tomadas. </p><br><p>  Sin embargo, volvamos a la tarea DCASE.  Los organizadores proporcionaron seis conjuntos de datos, tres para entrenamiento, tres para prueba, todos son muy diferentes, grabados en diferentes condiciones ac√∫sticas, usando varios dispositivos de grabaci√≥n, y hay varios ruidos en el fondo.  Por lo tanto, el mensaje principal es que el modelo no debe depender del entorno ni ser capaz de adaptarse a √©l.  A pesar de que el nombre significa "detecci√≥n", la tarea no es determinar los l√≠mites del evento, sino en una clasificaci√≥n simple: la soluci√≥n final es un tipo de clasificador binario que recibe una breve entrada de audio y decide si hay un p√°jaro cantando o no. .  La m√©trica de AUC se utiliz√≥ para evaluar la precisi√≥n. </p><br><p>  En su mayor√≠a, los participantes trataron de lograr la generalizaci√≥n y adaptaci√≥n a trav√©s de varios aumentos de datos.  Uno de los comandos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">describe la</a> aplicaci√≥n de varias t√©cnicas: cambiar la resoluci√≥n de frecuencia en las caracter√≠sticas extra√≠das, reducci√≥n de ruido preliminar, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un m√©todo de adaptaci√≥n</a> basado en la alineaci√≥n de estad√≠sticas de segundo orden para diferentes conjuntos de datos.  Sin embargo, tales m√©todos, as√≠ como los diferentes tipos de aumento, dan un aumento muy peque√±o sobre la soluci√≥n b√°sica, como se√±alan muchos participantes. </p><br><p>  Como soluci√≥n b√°sica, los autores prepararon una modificaci√≥n de la soluci√≥n m√°s exitosa de la competencia original "Bird Audio Detection Challenge".  El c√≥digo, como de costumbre, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">est√° disponible en el github</a> . </p><br><hr><br><h3 id="anchortrack4anchortrack-4-detektirovanie-akusticheskih-sobytiy-v-bytovyh-usloviyah-s-ispolzovaniem-slabo-razmechennogo-nabora-dannyh"><a name="Track4"></a>  Pista 4. Detecci√≥n de eventos ac√∫sticos en el hogar utilizando un conjunto de datos d√©bilmente etiquetado. </h3><br><p>  En la cuarta pista, el problema de detecci√≥n ya est√° resuelto directamente.  Los participantes recibieron un conjunto de datos relativamente peque√±o de datos etiquetados: un total de 1578 grabaciones de audio de 10 segundos cada una, con solo marcado de clase: se sabe que el archivo contiene uno o m√°s eventos de estas clases, pero no hay marcado temporal.  Adem√°s, se proporcionaron dos grandes conjuntos de datos de datos no asignados: 14412 archivos que contienen eventos objetivo de las mismas clases que en las muestras de entrenamiento y prueba, as√≠ como 39999 archivos que contienen eventos arbitrarios que no se incluyeron en los objetivos.  Todos los datos son un subconjunto del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enorme conjunto de datos de audioset compilado por google</a> . </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lx/td/h7/lxtdh7uaqxktdqu2bxzd4drrq0q.jpeg"></div><br><p>  Por lo tanto, los participantes deb√≠an crear un modelo capaz de aprender de datos con etiquetas d√©biles para encontrar marcas de tiempo del comienzo y el final de los eventos (los eventos pueden superponerse) e intentar mejorarlo con una gran cantidad de datos adicionales sin marcar.  Adem√°s, vale la pena se√±alar que se utiliz√≥ una m√©trica bastante r√≠gida en esta pista: era necesario predecir las etiquetas de tiempo de los eventos con una precisi√≥n de 200 ms.  En general, los participantes tuvieron que resolver una tarea bastante dif√≠cil de crear un modelo adecuado, mientras pr√°cticamente no ten√≠an buenos datos para la capacitaci√≥n. <br>  La mayor√≠a de las soluciones se basaron en redes de recurrencia convolucional, una arquitectura bastante popular en el campo de la detecci√≥n de eventos ac√∫sticos en los √∫ltimos tiempos (un ejemplo se puede encontrar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> ). </p><br><p>  La soluci√≥n b√°sica de los autores, tambi√©n en redes recursivas convolucionales, se basa en dos modelos.  Los modelos tienen casi la misma arquitectura: tres capas convolucionales y una recursiva.  La √∫nica diferencia son las redes de salida.  El primer modelo est√° entrenado para marcar datos no asignados para expandir el conjunto de datos original, por lo tanto, en la salida tenemos clases presentes en el archivo de eventos.  El segundo es para resolver el problema de detecci√≥n directamente, es decir, en la salida obtenemos una marca temporal para el archivo.  C√≥digo para el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> . </p><br><hr><br><h3 id="anchortrack5anchortrack-5-klassifikaciya-bytovoy-aktivnosti-v-pomeschenii-po-mnogokanalnoy-zapisi"><a name="Track5"></a>  Pista 5. Clasificaci√≥n de la actividad del hogar en la sala seg√∫n la grabaci√≥n multicanal. </h3><br><p>  La √∫ltima pista difer√≠a de las otras principalmente en que a los participantes se les ofrecieron grabaciones multicanal.  La tarea en s√≠ estaba en la clasificaci√≥n: es necesario predecir la clase de eventos que ocurrieron en el registro.  A diferencia de la pista anterior, la tarea es algo m√°s simple: se sabe que solo hay un evento en el registro. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hr/l1/ud/hrl1udue-onkcjfot9kptycgcw8.jpeg"></div><br><p>  El conjunto de datos est√° representado por aproximadamente 200 horas de grabaciones en una matriz lineal de 4 micr√≥fonos.  Los eventos son todo tipo de actividades cotidianas: cocinar, lavar platos, actividades sociales (hablar por tel√©fono, visitas y conversaciones personales), etc., tambi√©n se destaca la clase de ausencia de eventos. </p><br><p>  Los autores de la pista enfatizan que las condiciones de la tarea son relativamente simples, de modo que los participantes se centran directamente en el uso de informaci√≥n espacial de grabaciones multicanal.  Los participantes tambi√©n tuvieron la oportunidad de utilizar datos adicionales y modelos previamente entrenados.  La calidad se evalu√≥ de acuerdo con la medida F1. </p><br><p>  Como soluci√≥n b√°sica, los autores de la pista propusieron una red convolucional simple con dos capas convolucionales.  En su soluci√≥n, no se utiliz√≥ la informaci√≥n espacial: los datos de cuatro micr√≥fonos se utilizaron para el entrenamiento de forma independiente, y las predicciones se promediaron durante las pruebas.  La descripci√≥n y el c√≥digo est√°n disponibles <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en el enlace</a> . </p><br><hr><br><h3 id="zaklyuchenie">  Conclusi√≥n </h3><br><p>  En el art√≠culo, tratamos de hablar brevemente sobre la detecci√≥n de eventos ac√∫sticos y sobre una competencia como DCASE.  Tal vez pudieron interesar a alguien para participar en 2019: la competencia comienza en marzo. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/437818/">https://habr.com/ru/post/437818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../437808/index.html">Perf y flamegraphs</a></li>
<li><a href="../437810/index.html">Realidad corporativa</a></li>
<li><a href="../437812/index.html">Xcode 10.2, macOS Mojave 10.14.4, iOS 12.1 y otras versiones beta</a></li>
<li><a href="../437814/index.html">Xcode 10.2, macOS Mojave 10.14.4, iOS 12.1 y otras versiones beta</a></li>
<li><a href="../437816/index.html">MPLS est√° en todas partes. ¬øC√≥mo es la infraestructura de red Yandex.Cloud</a></li>
<li><a href="../437820/index.html">50 sombras de seguridad Drupal</a></li>
<li><a href="../437824/index.html">Extensi√≥n universal 1C para Hojas de c√°lculo y Documentos de Google: tomar y usar</a></li>
<li><a href="../437826/index.html">C√≥mo migramos la base de datos de Redis y Riak KV a PostgreSQL. Parte 1: el proceso</a></li>
<li><a href="../437828/index.html">Abra el seminario web "SELECCIONE el orden de ejecuci√≥n de consultas y el plan de consultas en MS SQL Server"</a></li>
<li><a href="../437830/index.html">Programaci√≥n confiable por idioma: revisi√≥n novata. Parte 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
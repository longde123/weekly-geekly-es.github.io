<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>â˜ï¸ ğŸ ğŸœï¸ PrÃ©sentation de la mÃ©thode de vecteur de rÃ©fÃ©rence d'algorithme d'apprentissage automatique (SVM) ğŸ‘µğŸ» ğŸ¦ â›‘ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="PrÃ©face 


 Dans cet article, nous explorerons plusieurs aspects de SVM: 



- composante thÃ©orique de SVM; 
- comment l'algorithme fonctionne sur des...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>PrÃ©sentation de la mÃ©thode de vecteur de rÃ©fÃ©rence d'algorithme d'apprentissage automatique (SVM)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428503/"><h2>  PrÃ©face </h2><br><img src="https://habrastorage.org/webt/eg/fk/rq/egfkrqshjcqqzkc7ktnnyyx9iuy.jpeg"><br><br>  Dans cet article, nous explorerons plusieurs aspects de SVM: <br><br><ul><li>  composante thÃ©orique de SVM; </li><li>  comment l'algorithme fonctionne sur des Ã©chantillons qui ne peuvent pas Ãªtre divisÃ©s en classes de faÃ§on linÃ©aire; </li><li>  Exemple Python et implÃ©mentation de l'algorithme dans la bibliothÃ¨que SciKit Learn. </li></ul><a name="habracut"></a><br>  Dans les articles suivants, je vais essayer de parler de la composante mathÃ©matique de cet algorithme. <br><br>  Comme vous le savez, les tÃ¢ches d'apprentissage automatique sont divisÃ©es en deux catÃ©gories principales: la classification et la rÃ©gression.  En fonction de laquelle de ces tÃ¢ches nous sommes confrontÃ©s et de l'ensemble de donnÃ©es dont nous disposons pour cette tÃ¢che, nous choisissons l'algorithme Ã  utiliser. <br><br>  La mÃ©thode Support Vector Machines ou SVM (de l'anglais Support Vector Machines) est un algorithme linÃ©aire utilisÃ© dans les problÃ¨mes de classification et de rÃ©gression.  Cet algorithme est largement utilisÃ© dans la pratique et peut rÃ©soudre Ã  la fois des problÃ¨mes linÃ©aires et non linÃ©aires.  L'essence des Â«MachinesÂ» des vecteurs de support est simple: l'algorithme crÃ©e une ligne ou un hyperplan qui divise les donnÃ©es en classes. <br><br><h4>  ThÃ©orie </h4><br>  La tÃ¢che principale de l'algorithme est de trouver la ligne ou l'hyperplan le plus correct, en divisant les donnÃ©es en deux classes.  SVM est un algorithme qui reÃ§oit des donnÃ©es Ã  l'entrÃ©e et renvoie une telle ligne de division. <br><br>  Prenons l'exemple suivant.  Supposons que nous ayons un ensemble de donnÃ©es et que nous voulons classer et sÃ©parer les carrÃ©s rouges des cercles bleus (disons positifs et nÃ©gatifs).  Le but principal de cette tÃ¢che sera de trouver la ligne Â«idÃ©aleÂ» qui sÃ©parera ces deux classes. <br><br><img src="https://habrastorage.org/webt/lj/e4/oy/lje4oybbp_pbe_slxkvhm6yqaoy.png"><br><br>  Trouvez la ligne ou l'hyperplan parfait qui divise l'ensemble de donnÃ©es en classes bleues et rouges. <br><br>  Ã€ premiÃ¨re vue, ce n'est pas si difficile, non? <br><br>  Mais, comme vous pouvez le voir, il n'y a pas de ligne unique qui rÃ©soudrait un tel problÃ¨me.  Nous pouvons prendre un nombre infini de lignes qui peuvent sÃ©parer ces deux classes.  Comment SVM trouve-t-il exactement la ligne Â«idÃ©aleÂ» et qu'est-ce qui est Â«idÃ©alÂ» dans sa comprÃ©hension? <br><br>  Jetez un Å“il Ã  l'exemple ci-dessous et pensez Ã  laquelle des deux lignes (jaune ou verte) sÃ©pare le mieux les deux classes, et correspond Ã  la description de Â«idÃ©alÂ»? <br><br><img src="https://habrastorage.org/webt/w4/_f/kz/w4_fkz5krspejxz1o73l1yjnidy.png"><br><br>  Selon vous, quelle ligne sÃ©pare mieux l'ensemble de donnÃ©es? <br><br>  Si vous avez choisi la ligne jaune, je vous fÃ©licite: c'est la ligne que l'algorithme choisirait.  Dans cet exemple, nous pouvons comprendre intuitivement que la ligne jaune sÃ©pare et classe en consÃ©quence les deux classes mieux que la verte. <br><br>  Dans le cas de la ligne verte - elle est situÃ©e trop prÃ¨s de la classe rouge.  MalgrÃ© le fait qu'elle ait correctement classÃ© tous les objets de l'ensemble de donnÃ©es actuel, une telle ligne ne sera pas gÃ©nÃ©ralisÃ©e - elle ne se comportera pas aussi bien avec un ensemble de donnÃ©es inconnu.  La tÃ¢che de trouver une gÃ©nÃ©ralisation sÃ©parant deux classes est l'une des tÃ¢ches principales de l'apprentissage automatique. <br><br><h4>  Comment SVM trouve la meilleure ligne </h4><br>  L'algorithme SVM est conÃ§u de maniÃ¨re Ã  rechercher des points sur le graphique qui sont situÃ©s directement sur la ligne de sÃ©paration la plus proche.  Ces points sont appelÃ©s vecteurs de rÃ©fÃ©rence.  Ensuite, l'algorithme calcule la distance entre les vecteurs de support et le plan de division.  C'est la distance appelÃ©e l'Ã©cart.  L'objectif principal de l'algorithme est de maximiser la distance de dÃ©gagement.  Le meilleur hyperplan est considÃ©rÃ© comme un hyperplan pour lequel cet Ã©cart est le plus grand possible. <br><br><img src="https://habrastorage.org/webt/ps/iy/he/psiyhexemtrhnqukbvmvaqzafvi.png"><br><br>  Assez simple, non?  Prenons l'exemple suivant, avec un ensemble de donnÃ©es plus complexe qui ne peut pas Ãªtre divisÃ© linÃ©airement. <br><br><img src="https://habrastorage.org/webt/jh/5v/bx/jh5vbxwn7vfzyzeuxibxpleejyk.png"><br><br>  De toute Ã©vidence, cet ensemble de donnÃ©es ne peut pas Ãªtre divisÃ© de faÃ§on linÃ©aire.  Nous ne pouvons pas tracer une ligne droite qui classerait ces donnÃ©es.  Mais, cet ensemble de donnÃ©es peut Ãªtre divisÃ© linÃ©airement, en ajoutant une dimension supplÃ©mentaire, que nous appellerons l'axe Z. Imaginez que les coordonnÃ©es sur l'axe Z soient rÃ©gulÃ©es par la restriction suivante: <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2">z</span><span class="MJXp-mo" id="MJXp-Span-3" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-4">x</span><span class="MJXp-mrow" id="MJXp-Span-5"><span class="MJXp-mo" id="MJXp-Span-6" style="margin-left: 0em; margin-right: 0em;">Â²</span></span><span class="MJXp-mo" id="MJXp-Span-7" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-8">y</span><span class="MJXp-mrow" id="MJXp-Span-9"><span class="MJXp-mo" id="MJXp-Span-10" style="margin-left: 0em; margin-right: 0em;">Â²</span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.717ex" height="2.419ex" viewBox="0 -780.1 4614.2 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMATHI-7A" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMAIN-3D" x="746" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMATHI-78" x="1802" y="0"></use><g transform="translate(2375,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">Â²</text></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMAIN-2B" x="2856" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMATHI-79" x="3857" y="0"></use><g transform="translate(4354,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">Â²</text></g></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> z = xÂ² + yÂ² </script></p><br>  Ainsi, l'ordonnÃ©e Z est reprÃ©sentÃ©e Ã  partir du carrÃ© de la distance du point au dÃ©but de l'axe. <br>  Ci-dessous, une visualisation du mÃªme jeu de donnÃ©es sur l'axe Z. <br><br><img src="https://habrastorage.org/webt/vd/nj/ce/vdnjce7p5csbhfp12tkaj6t-4-s.png"><br><br>  Maintenant, les donnÃ©es peuvent Ãªtre divisÃ©es linÃ©airement.  Supposons que la ligne magenta sÃ©parant les donnÃ©es z = k, oÃ¹ k est une constante.  Si <p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-11"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-12">z</span><span class="MJXp-mo" id="MJXp-Span-13" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-14">x</span><span class="MJXp-mrow" id="MJXp-Span-15"><span class="MJXp-mo" id="MJXp-Span-16" style="margin-left: 0em; margin-right: 0em;">Â²</span></span><span class="MJXp-mo" id="MJXp-Span-17" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-18">y</span><span class="MJXp-mrow" id="MJXp-Span-19"><span class="MJXp-mo" id="MJXp-Span-20" style="margin-left: 0em; margin-right: 0em;">Â²</span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.717ex" height="2.419ex" viewBox="0 -780.1 4614.2 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMATHI-7A" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMAIN-3D" x="746" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMATHI-78" x="1802" y="0"></use><g transform="translate(2375,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">Â²</text></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMAIN-2B" x="2856" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMATHI-79" x="3857" y="0"></use><g transform="translate(4354,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">Â²</text></g></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> z = xÂ² + yÂ² </script></p>  alors <p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-21"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-22">k</span><span class="MJXp-mo" id="MJXp-Span-23" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24">x</span><span class="MJXp-mrow" id="MJXp-Span-25"><span class="MJXp-mo" id="MJXp-Span-26" style="margin-left: 0em; margin-right: 0em;">Â²</span></span><span class="MJXp-mo" id="MJXp-Span-27" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-28">y</span><span class="MJXp-mrow" id="MJXp-Span-29"><span class="MJXp-mo" id="MJXp-Span-30" style="margin-left: 0em; margin-right: 0em;">Â²</span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.84ex" height="2.419ex" viewBox="0 -780.1 4667.2 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMATHI-6B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMAIN-3D" x="799" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMATHI-78" x="1855" y="0"></use><g transform="translate(2428,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">Â²</text></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMAIN-2B" x="2909" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhh31x1y-N_Gd3OutW7uxIF32pODiQ#MJMATHI-79" x="3910" y="0"></use><g transform="translate(4407,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">Â²</text></g></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-3"> k = xÂ² + yÂ² </script></p>  - formule du cercle.  Ainsi, nous pouvons projeter notre diviseur linÃ©aire, revenir au nombre d'origine de dimensions d'Ã©chantillon, en utilisant cette transformation. <br><br><img src="https://habrastorage.org/webt/we/nu/zn/wenuznqe4e7n4isscmunomrwzfw.png"><br><br>  Par consÃ©quent, nous pouvons classer un ensemble de donnÃ©es non linÃ©aire en lui ajoutant une dimension supplÃ©mentaire, puis le ramener Ã  sa forme d'origine Ã  l'aide de la transformation mathÃ©matique.  Cependant, pas avec tous les ensembles de donnÃ©es, il est tout aussi facile de lancer une telle transformation.  Heureusement, l'implÃ©mentation de cet algorithme dans la bibliothÃ¨que sklearn rÃ©sout ce problÃ¨me pour nous. <br><br><h4>  Hyperplan </h4><br>  Maintenant que nous nous sommes familiarisÃ©s avec la logique de l'algorithme, nous passons Ã  la dÃ©finition formelle d'un hyperplan <br><br>  Un hyperplan est un sous-plan de dimension n-1 dans un espace euclidien Ã  n dimensions qui divise l'espace en deux parties distinctes. <br><br>  Par exemple, imaginez que notre ligne est reprÃ©sentÃ©e comme un espace euclidien unidimensionnel (c'est-Ã -dire que notre ensemble de donnÃ©es se trouve sur une ligne droite).  SÃ©lectionnez un point sur cette ligne.  Ce point divisera l'ensemble de donnÃ©es, dans notre cas la ligne, en deux parties.  La ligne a une mesure et le point a 0 mesure.  Par consÃ©quent, un point est un hyperplan d'une ligne. <br><br>  Pour l'ensemble de donnÃ©es bidimensionnel que nous avons rencontrÃ© prÃ©cÃ©demment, la ligne de dÃ©marcation Ã©tait le mÃªme hyperplan.  Autrement dit, pour un espace Ã  n dimensions, il y a un hyperplan Ã  n dimensions qui divise cet espace en deux parties. <br><br>  CODE <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np X = np.array([[<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>], [<span class="hljs-number"><span class="hljs-number">-2</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>], [<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]]) y = np.array([<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>])</code> </pre> <br>  Les points sont reprÃ©sentÃ©s comme un tableau de X et les classes auxquelles ils appartiennent comme un tableau de y. <br>  Nous allons maintenant former notre modÃ¨le avec cet Ã©chantillon.  Pour cet exemple, j'ai dÃ©fini le paramÃ¨tre linÃ©aire du Â«noyauÂ» du classificateur (noyau). <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.svm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SVC clf = SVC(kernel=<span class="hljs-string"><span class="hljs-string">'linear'</span></span>) clf = SVC.fit(X, y)</code> </pre><br>  PrÃ©diction de classe d'un nouvel objet <br><br><pre> <code class="python hljs">prediction = clf.predict([[<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>]])</code> </pre> <br><h4>  RÃ©glage des paramÃ¨tres </h4><br>  Les paramÃ¨tres sont les arguments que vous transmettez lors de la crÃ©ation du classificateur.  Ci-dessous, j'ai fourni certains des paramÃ¨tres SVM personnalisÃ©s les plus importants: <br><br>  <b>"C"</b> <br><br>  Ce paramÃ¨tre permet d'ajuster cette fine ligne entre la Â«douceurÂ» et la prÃ©cision de la classification des objets dans l'Ã©chantillon d'apprentissage.  Plus la valeur Â«CÂ» est Ã©levÃ©e, plus les objets de l'ensemble d'apprentissage seront correctement classÃ©s. <br><br><img src="https://habrastorage.org/webt/rq/01/6s/rq016soikp4qfockp86li66s5mq.png"><br><br>  Dans cet exemple, il existe plusieurs seuils de dÃ©cision que nous pouvons dÃ©finir pour cet Ã©chantillon particulier.  Faites attention au seuil de dÃ©cision direct (prÃ©sentÃ© sur le graphique comme une ligne verte).  C'est assez simple, et pour cette raison, plusieurs objets ont Ã©tÃ© mal classÃ©s.  Ces points qui ont Ã©tÃ© mal classÃ©s sont appelÃ©s valeurs aberrantes dans les donnÃ©es. <br><br>  Nous pouvons Ã©galement ajuster les paramÃ¨tres de telle maniÃ¨re qu'Ã  la fin, nous obtenons une ligne plus courbe (seuil de dÃ©cision bleu clair), qui classera absolument toutes les donnÃ©es de l'Ã©chantillon d'apprentissage correctement.  Bien sÃ»r, dans ce cas, les chances que notre modÃ¨le soit en mesure de gÃ©nÃ©raliser et d'afficher des rÃ©sultats tout aussi bons sur de nouvelles donnÃ©es sont catastrophiques.  Par consÃ©quent, si vous essayez d'atteindre la prÃ©cision lors de la formation du modÃ¨le, vous devez viser quelque chose de plus uniforme, direct.  Plus le nombre Â«CÂ» est Ã©levÃ©, plus l'hyperplan est enchevÃªtrÃ© dans votre modÃ¨le, mais plus le nombre d'objets correctement classÃ©s dans l'ensemble d'apprentissage est Ã©levÃ©.  Par consÃ©quent, il est important de Â«tordreÂ» les paramÃ¨tres du modÃ¨le pour un ensemble de donnÃ©es spÃ©cifique afin d'Ã©viter de se recycler mais, en mÃªme temps, d'atteindre une grande prÃ©cision. <br><br>  <b>Gamma</b> <br><br>  Dans la documentation officielle, la bibliothÃ¨que SciKit Learn indique que le gamma dÃ©termine dans quelle mesure chacun des Ã©lÃ©ments de l'ensemble de donnÃ©es a une influence sur la dÃ©termination de la Â«ligne idÃ©aleÂ».  Plus le gamma est bas, plus les Ã©lÃ©ments, mÃªme ceux qui sont suffisamment Ã©loignÃ©s de la ligne de dÃ©marcation, participent au processus de choix de cette mÃªme ligne.  Si le gamma est Ã©levÃ©, l'algorithme ne Â«s'appuieraÂ» que sur les Ã©lÃ©ments les plus proches de la ligne elle-mÃªme. <br>  Si le niveau gamma est trop Ã©levÃ©, seuls les Ã©lÃ©ments les plus proches de la ligne participeront au processus dÃ©cisionnel sur l'emplacement de la ligne.  Cela aidera Ã  ignorer les valeurs aberrantes dans les donnÃ©es.  L'algorithme SVM est conÃ§u pour que les points situÃ©s les plus proches les uns des autres aient plus de poids lors de la prise de dÃ©cision.  Cependant, avec le rÃ©glage correct de "C" et "gamma", un rÃ©sultat optimal peut Ãªtre obtenu qui construira un hyperplan plus linÃ©aire qui ignore les valeurs aberrantes et, par consÃ©quent, est plus gÃ©nÃ©ralisable. <br><br><h4>  Conclusion </h4><br>  J'espÃ¨re sincÃ¨rement que cet article vous a aidÃ© Ã  comprendre l'essence du travail de SVM ou de la mÃ©thode des vecteurs de rÃ©fÃ©rence.  J'attends de vous tout commentaire et conseil.  Dans des publications ultÃ©rieures, je parlerai de la composante mathÃ©matique de SVM et des problÃ¨mes d'optimisation. <br><br>  Sources: <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Documentation SVM officielle dans SciKit Learn</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://towardsdatascience.com/">Vers le blog DataScience</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Siraj Raval: Support des machines Ã  vecteurs</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Intro to Machine Learning Udacity SVM: VidÃ©o du cours Gamma</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">WikipÃ©dia: SVM</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428503/">https://habr.com/ru/post/fr428503/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428493/index.html">Git subrepo</a></li>
<li><a href="../fr428495/index.html">Comment j'ai fait un simulateur de football pendant 13 ans</a></li>
<li><a href="../fr428497/index.html">Gradateur sans fil personnalisÃ© Noolite SUF-1-300</a></li>
<li><a href="../fr428499/index.html">Des gÃ©ants bleus effrayants peuvent rÃ©vÃ©ler les secrets de l'Ã©volution des Ã©toiles</a></li>
<li><a href="../fr428501/index.html">DartUP: la premiÃ¨re confÃ©rence en langue russe sur Dart et Flutter le 1er dÃ©cembre Ã  Saint-PÃ©tersbourg</a></li>
<li><a href="../fr428505/index.html">Obtenir des liens vers l'audio sans VKApi</a></li>
<li><a href="../fr428507/index.html">Nous Ã©crivons un chat bot pour VKontakte sur python en utilisant longpoll</a></li>
<li><a href="../fr428509/index.html">Comment H&M essaie de se sauver avec l'IA et le Big Data</a></li>
<li><a href="../fr428511/index.html">Ã‰nergie hydrogÃ¨ne: le dÃ©but d'un long chemin</a></li>
<li><a href="../fr428513/index.html">500 pointeurs laser au mÃªme endroit</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
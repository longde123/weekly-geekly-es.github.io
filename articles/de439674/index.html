<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìÑ üöë üéí Reinforcement Deep Learning: Ping-Pong mit rohen Pixeln üçµ üëé üí¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dies ist ein l√§ngst √ºberf√§lliger Artikel √ºber Reinforcement Learning (RL). RL ist ein cooles Thema! 

 M√∂glicherweise wissen Sie, dass Computer jetzt ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Reinforcement Deep Learning: Ping-Pong mit rohen Pixeln</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439674/">  Dies ist ein l√§ngst √ºberf√§lliger Artikel √ºber Reinforcement Learning (RL).  RL ist ein cooles Thema! <br><br>  M√∂glicherweise wissen Sie, dass Computer jetzt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">automatisch lernen k√∂nnen, ATARI-Spiele zu spielen</a> (indem sie am Eingang rohe Spielpixel erhalten!).  Sie schlagen die Weltmeister im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Go-</a> Spiel, lernen virtuell vierbeinig <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Laufen und Springen</a> und Roboter lernen komplexe Manipulationsaufgaben auszuf√ºhren, die eine explizite Programmierung herausfordern.  Es stellt sich heraus, dass all diese Erfolge ohne RL nicht vollst√§ndig sind.  Ich habe mich im letzten Jahr auch f√ºr RL interessiert: Ich habe mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Richard Suttons</a> Buch gearbeitet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">(ca. Referenz: ersetzt)</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">David Silvers</a> Kurs gelesen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">John Schulmans Vorlesungen besucht</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die RL-Bibliothek √ºber Javascript geschrieben</a> und in der Sommerpraxis bei DeepMind in einer Gruppe gearbeitet DeepRL und zuletzt in der Entwicklung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenAI Gym</a> ist das neue RL-Toolkit.  Ich bin nat√ºrlich seit mindestens einem Jahr auf dieser Welle, habe mir aber immer noch nicht die M√ºhe gemacht, eine Notiz dar√ºber zu schreiben, warum RL von gro√üer Bedeutung ist, worum es geht, wie sich alles entwickelt. <br><br><img src="https://habrastorage.org/webt/vr/ir/gu/vrirgukar82fw0cg6wbnsklagum.png"><br>  <i>Beispiele f√ºr die Verwendung von Deep Q-Learning.</i>  <i>Von links nach rechts: Das neuronale Netzwerk spielt ATARI, das neuronale Netzwerk spielt AlphaGo, der Roboter faltet Lego, der virtuelle Vierbeiner l√§uft um virtuelle Hindernisse.</i> <br><a name="habracut"></a><br>  Es ist interessant, √ºber die Art der j√ºngsten Fortschritte in RL nachzudenken.  Ich m√∂chte vier verschiedene Faktoren erw√§hnen, die die Entwicklung der KI beeinflussen: <br><br><ol><li>  Rechengeschwindigkeit (GPU, ASIC-Spezialger√§te, Mooresches Gesetz) </li><li>  Ausreichende Daten in verwendbarer Form (z. B. ImageNet) </li><li>  Algorithmen (Forschung und Ideen, z. B. Backprop, CNN, LSTM) </li><li>  Infrastruktur (Linux, TCP / IP, Git, ROS, PR2, AWS, AMT, TensorFlow usw.). </li></ol><br>  Genau wie in der Computer Vision bewegt sich der Fortschritt in RL ... wenn auch nicht so sehr, wie es scheint.  In der Bildverarbeitung ist das neuronale AlexNet 2012-Netzwerk beispielsweise eine Version des ConvNets-neuronalen Netzwerks aus den 1990er Jahren mit gr√∂√üerer Tiefe und Breite.  In √§hnlicher Weise ist ATARI Deep Q-Learning 2013 eine Implementierung des Standard-Q-Learning-Algorithmus, den Sie in Richard Suttons klassischem Buch von 1998 finden.  Dar√ºber hinaus verwendet AlphaGo die Policy Gradient-Technik und die Monte-Carlo-Baumsuche (MCTS) sind ebenfalls alte Ideen oder deren Kombinationen.  Nat√ºrlich erfordert es viel Geschick und Geduld, um sie zum Laufen zu bringen, und viele knifflige Einstellungen wurden auf der Grundlage alter Algorithmen entwickelt.  <b>In erster N√§herung sind jedoch nicht neue Algorithmen und Ideen der Haupttreiber der j√ºngsten Fortschritte, sondern die Intensivierung von Berechnungen, ausreichende Daten und eine ausgereifte Infrastruktur.</b> <br><br>  Nun zur√ºck zu RL.  Viele Menschen k√∂nnen nicht glauben, dass wir einem Computer beibringen k√∂nnen, ATARI-Spiele auf menschlicher Ebene zu spielen, indem rohe Pixel von Grund auf neu verwendet werden und derselbe selbstlernende Algorithmus verwendet wird.  Gleichzeitig f√ºhle ich jedes Mal eine L√ºcke - wie magisch es scheint und wie einfach es wirklich in mir ist. <br><br>  Der grundlegende Ansatz, den wir verwenden, ist eigentlich ziemlich dumm.  Wie dem auch sei, ich m√∂chte Ihnen die Policy Gradient (PG) -Technik vorstellen, unsere derzeit bevorzugte Standardoption zur L√∂sung von Problemen mit RL.  Sie werden vielleicht neugierig sein, warum ich mir stattdessen DQN nicht vorstellen kann, einen alternativen und bekannteren RL-Algorithmus, der auch im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ATARI-Training verwendet wird</a> .  Es stellt sich heraus, dass Q-Learning zwar bekannt ist, aber nicht so perfekt.  Die meisten Menschen entscheiden sich f√ºr Policy Gradient, einschlie√ülich der Autoren des urspr√ºnglichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DQN-Artikels</a> , die gezeigt haben, dass Policy Gradient bei guter Abstimmung sogar noch besser funktioniert als Q-Learning.  PG ist vorzuziehen, weil es explizit ist: Es gibt eine klare Politik und einen koh√§renten Ansatz, der die erwarteten Belohnungen direkt optimiert.  Als Beispiel lernen wir, wie man ATARI Pong spielt: von Grund auf, von rohen Pixeln bis zu einem Policy Gradient mit einem neuronalen Netzwerk.  Und wir werden das alles in 130 Zeilen Python einf√ºgen.  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hauptlink</a> ) Mal sehen, wie das gemacht wird. <br><br><img src="https://habrastorage.org/webt/yy/fk/hg/yyfkhg3xutt4gsualf7l6o0sa4i.gif"><br><img src="https://habrastorage.org/webt/mw/rq/2w/mwrq2wthkobnxuqohcfovs1lgei.jpeg"><br>  <i>Oben: Tischtennis.</i>  <i>Unten: Ping-Pong-Pr√§sentation als Sonderfall des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Markov-Entscheidungsprozesses (MDP)</a> : Jeder Scheitelpunkt des Diagramms entspricht einem bestimmten Spielzustand, und die Kanten bestimmen die Wahrscheinlichkeiten f√ºr den √úbergang in andere Zust√§nde.</i>  <i>Jede Rippe bestimmt auch die Belohnung.</i>  <i>Das Ziel ist es, aus jedem Staat den besten Weg zu finden, um die Belohnung zu maximieren</i> <br><br>  Ping Pong zu spielen ist ein gro√üartiges Beispiel f√ºr eine RL-Herausforderung.  In der ATARI 2600-Version spielen wir selbst einen Schl√§ger.  Ein weiterer Schl√§ger wird von einem eingebauten Algorithmus gesteuert.  Wir m√ºssen den Ball schlagen, damit der andere Spieler keine Zeit hat, ihn zu schlagen.  Ich hoffe, es ist nicht n√∂tig zu erkl√§ren, was Ping Pong ist.  Auf einer niedrigen Ebene funktioniert das Spiel wie folgt: Wir erhalten einen Bilderrahmen - ein Array von 210 x 160 x 3 Bytes - und entscheiden, ob wir den Schl√§ger nach OBEN oder UNTEN bewegen m√∂chten.  Das hei√üt, wir haben nur zwei M√∂glichkeiten, um das Spiel zu verwalten.  Nach jeder Auswahl f√ºhrt der Spielesimulator seine Aktion aus und gibt uns eine Belohnung: entweder +1 Belohnung, wenn der Ball den Schl√§ger des Gegners passiert hat, oder -1, wenn wir den Ball verpasst haben.  Ansonsten 0. Und nat√ºrlich ist es unser Ziel, den Schl√§ger so zu bewegen, dass wir so viel Belohnung wie m√∂glich bekommen. <br><br>  Denken Sie bei der √úberlegung einer L√∂sung daran, dass wir versuchen werden, so wenige Annahmen √ºber Pong zu treffen, da dies in der Praxis nicht besonders wichtig ist.  Bei gro√üen Aufgaben wie der Manipulation von Robotern, der Montage und der Navigation ber√ºcksichtigen wir viel mehr Dinge.  Pong ist nur ein lustiger Spielzeug-Testfall, mit dem wir spielen, w√§hrend wir herausfinden, wie man sehr allgemeine KI-Systeme schreibt, die eines Tages beliebige n√ºtzliche Aufgaben ausf√ºhren k√∂nnen. <br><br>  <b>Neuronales Netz als RL-Richtlinie</b> .  Zun√§chst werden wir die sogenannte Richtlinie festlegen, die unser Spieler (oder "Agent") implementiert.  ((*) "Agent", "Umgebung" und "Agentenrichtlinie" sind Standardbegriffe aus der RL-Theorie).  Die Richtlinienfunktion ist in unserem Fall ein neuronales Netzwerk.  Sie akzeptiert den Stand des Spiels am Eingang und am Ausgang entscheidet sie, was zu tun ist - nach oben oder unten.  Als unseren bevorzugten einfachen Berechnungsblock verwenden wir ein zweischichtiges neuronales Netzwerk, das Rohbildpixel (insgesamt 100.800 Zahlen (210 * 160 * 3)) verwendet und eine einzelne Zahl erzeugt, die die Wahrscheinlichkeit angibt, den Schl√§ger nach oben zu bewegen.  Bitte beachten Sie, dass die Verwendung der stochastischen Politik Standard ist, was bedeutet, dass wir nur die Wahrscheinlichkeit einer Aufw√§rtsbewegung erzeugen.  Um den tats√§chlichen Zug zu erhalten, verwenden wir diese Wahrscheinlichkeit.  Der Grund daf√ºr wird klarer, wenn wir √ºber Training sprechen. <br><br><img src="https://habrastorage.org/webt/cm/n4/ap/cmn4apvesxvu5d8konqytnbk0cm.png"><br>  <i>Unsere Richtlinienfunktion besteht aus einem 2-lagigen, vollst√§ndig verbundenen neuronalen Netzwerk</i> <br><br>  Nehmen wir genauer an, dass wir am Eingang einen Vektor X erhalten, der einen Satz vorverarbeiteter Pixel enth√§lt.  Dann m√ºssen wir mit Python \ numpy rechnen: <br><br><pre><code class="python hljs">h = np.dot(W1, x) <span class="hljs-comment"><span class="hljs-comment"># compute hidden layer neuron activations h[h&lt;0] = 0 # ReLU nonlinearity: threshold at zero logp = np.dot(W2, h) # compute log probability of going up p = 1.0 / (1.0 + np.exp(-logp)) # sigmoid function (gives probability of going up)</span></span></code> </pre> <br>  In diesem Fragment sind W1 und W2 zwei Matrizen, die wir zuf√§llig initialisieren.  Wir verwenden keine Voreingenommenheit, weil wir wollten.  Beachten Sie, dass wir am Ende die Nichtlinearit√§t des Sigmoid verwenden, wodurch die Ausgabewahrscheinlichkeit auf den Bereich [0,1] reduziert wird.  Intuitiv k√∂nnen Neuronen in einer verborgenen Schicht (deren Gewichte sich in W1 befinden) verschiedene Spielszenarien erkennen (zum Beispiel ist der Ball oben und unser Schl√§ger ist in der Mitte), und Gewichte in W2 k√∂nnen dann entscheiden, ob wir jeweils steigen sollen oder runter.  Die anf√§nglichen zuf√§lligen W1 und W2 verursachen nat√ºrlich zuerst Kr√§mpfe und Kr√§mpfe in unserem Neurospieler, was ihn mit einem Dummkopf-Autisten an der Steuerung eines Flugzeugs gleichsetzt.  Die einzige Aufgabe besteht nun darin, W1 und W2 zu finden, was zu einem guten Spiel f√ºhrt! <br><br>  Es gibt eine Bemerkung zur Pixelvorverarbeitung - idealerweise m√ºssen Sie mindestens 2 Frames in das neuronale Netzwerk √ºbertragen, damit es Bewegungen erkennen kann.  Um die Situation zu vereinfachen, wenden wir die Differenz zweier Frames an.  Das hei√üt, wir subtrahieren den aktuellen und den vorherigen Frame und wenden die Differenz erst dann auf die Eingabe des neuronalen Netzwerks an. <br><br>  <b>Klingt nach etwas Unm√∂glichem.</b>  An dieser Stelle m√∂chte ich Sie bitten, zu sch√§tzen, wie komplex das RL-Problem ist.  Wir erhalten 100 800 Nummern (210 x 160 x 3) und senden sie an unser neuronales Netzwerk, das die Richtlinien des Spielers implementiert (die im √úbrigen leicht etwa eine Million Parameter in den Matrizen W1 und W2 enthalten).  Nehmen wir an, wir beschlie√üen irgendwann, nach oben zu gehen.  Der Spielesimulator kann antworten, dass wir diesmal 0 Auszeichnungen erhalten und uns weitere 100 800 Zahlen f√ºr den n√§chsten Frame geben.  Wir k√∂nnen diesen Vorgang hunderte Male wiederholen, bevor wir eine Belohnung ungleich Null erhalten!  Nehmen wir zum Beispiel an, wir haben endlich eine Belohnung von +1 erhalten.  Das ist wunderbar, aber wie k√∂nnen wir dann sagen - was hat dazu gef√ºhrt?  War dies die Aktion, die wir gerade gemacht haben?  Oder vielleicht 76 Frames zur√ºck?  Oder war dies zuerst mit Frame 10 verbunden, und dann haben wir in Frame 90 etwas richtig gemacht?  Und wie finden wir heraus, welche der Millionen "Stifte" gedreht werden m√ºssen, um in Zukunft noch erfolgreicher zu sein?  Wir nennen dies die Aufgabe, den Vertrauenskoeffizienten f√ºr bestimmte Aktionen zu bestimmen.  Im speziellen Fall mit dem Pong wissen wir, dass wir +1 erhalten, wenn der Ball den Gegner passiert hat.  Der wahre Grund ist, dass wir den Ball versehentlich ein paar Frames zur√ºck auf einen guten Weg getreten haben und jede nachfolgende Aktion, die wir ausgef√ºhrt haben, ihn √ºberhaupt nicht beeinflusst hat.  Mit anderen Worten, wir stehen vor einem sehr komplexen Rechenproblem, und alles sieht ziemlich d√ºster aus. <br><br>  <b>Training mit einem Lehrer.</b>  Bevor wir uns mit dem Gradienten der Politik (PG) befassen, m√∂chte ich kurz an das Unterrichten mit einem Lehrer erinnern, da RL, wie wir sehen werden, sehr √§hnlich ist.  Siehe die folgende Tabelle.  Im normalen Unterricht mit einem Lehrer √ºbertragen wir das Bild in das Netzwerk und erhalten am Ausgang einige numerische Wahrscheinlichkeiten f√ºr die Klassen.  In unserem Fall haben wir beispielsweise zwei Klassen: UP und DOWN.  Ich verwende die logarithmischen Wahrscheinlichkeiten (-1,2, -0,36) anstelle der Wahrscheinlichkeiten im 30% - und 70% -Format, weil wir die logarithmische Wahrscheinlichkeit der richtigen Klasse (oder Bezeichnung) optimieren.  Dies macht mathematische Berechnungen eleganter und entspricht der Optimierung nur der Wahrscheinlichkeit, da der Logarithmus monoton ist. <br><br>  In der Ausbildung mit einem Lehrer haben wir sofort Zugriff auf die richtige Klasse (Etikett).  In der Trainingsphase werden sie uns genau sagen, welcher richtige Schritt gerade ben√∂tigt wird (sagen wir, es ist UP, Label 0), obwohl das neuronale Netzwerk m√∂glicherweise anders denkt.  Daher berechnen wir den Gradienten <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1"><span class="MJXp-mtext" id="MJXp-Span-2">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-4"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-5"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">b </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-6"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-7"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-8" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a </font></font></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-9" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-10"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">W</font></font></span></span></span><font style="vertical-align: inherit;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-12"><font style="vertical-align: inherit;"> l </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-13"><font style="vertical-align: inherit;">o </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-14"><font style="vertical-align: inherit;">g </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-15"><font style="vertical-align: inherit;">p </font></span><span class="MJXp-mo" id="MJXp-Span-16" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">( </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-17"><font style="vertical-align: inherit;">y </font></span><span class="MJXp-mo" id="MJXp-Span-18" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;">= </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-19"><font style="vertical-align: inherit;">U </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-20"><font style="vertical-align: inherit;">P </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-22"><font style="vertical-align: inherit;">m </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-23"><font style="vertical-align: inherit;">i </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24"><font style="vertical-align: inherit;">d </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-25"><font style="vertical-align: inherit;">x </font></span><span class="MJXp-mo" id="MJXp-Span-26" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">)</font></span></font><span class="MJXp-mtext" id="MJXp-Span-11">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-12"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-13"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-14"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-15"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-16" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-17"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-18" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-19"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-20"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mtext" id="MJXp-Span-21">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-22"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-23"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-25"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-26" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28.327ex" height="2.66ex" viewBox="0 -832 12196.5 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6E" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-61" x="850" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-62" x="1380" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6C" x="1809" y="0"></use><g transform="translate(2108,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-57" x="748" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6C" x="3728" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6F" x="4027" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-67" x="4512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-70" x="4993" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMAIN-28" x="5496" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-79" x="5886" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMAIN-3D" x="6661" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-55" x="7717" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-50" x="8485" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6D" x="9486" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="10365" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-64" x="10710" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-78" x="11234" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMAIN-29" x="11806" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1"> \ nabla_ {W} \ log p (y = UP \ mid x) </script>  um die Netzwerkeinstellungen zu optimieren.  Dieser Gradient sagt uns nur, wie wir jeden unserer Millionen von Parametern √§ndern sollen, damit das Netzwerk UP in derselben Situation mit etwas h√∂herer Wahrscheinlichkeit vorhersagt.  Beispielsweise kann einer von einer Million Parametern im Netzwerk einen Gradienten von -2,1 haben. Wenn wir diesen Parameter um einen kleinen positiven Wert (z. B. 0,001) erh√∂hen, verringert sich die logarithmische Wahrscheinlichkeit von UP um 2,1 * 0,001.  (Abnahme aufgrund des negativen Vorzeichens).  Wenn wir den Gradienten anwenden und dann den Parameter mithilfe des Backpropagation-Algorithmus aktualisieren, gibt unser Netzwerk eine hohe Wahrscheinlichkeit f√ºr UP, wenn es in Zukunft dasselbe oder ein sehr √§hnliches Bild sieht. <br><br><img src="https://habrastorage.org/webt/-p/r6/bu/-pr6bumeyrk2xdf9nuoulm5oflw.png"><br><br>  <b>Gradienten der Politik (PG)</b> .  OK, aber was machen wir, wenn wir nicht das richtige Etikett f√ºr das Verst√§rkungstraining haben?  Hier ist eine L√∂sung f√ºr PG (siehe Abbildung unten noch einmal).  Unser neuronales Netzwerk berechnete die Wahrscheinlichkeit eines Anstiegs von 30% (logprob -1,2) und von DOWN um 70% (logprob -0,36).  Jetzt treffen wir eine Auswahl aus dieser Distribution und geben an, welche Aktion wir ausf√ºhren werden.  Zum Beispiel haben sie DOWN gew√§hlt und diese Aktion an den Spielesimulator gesendet.  Beachten Sie an dieser Stelle eine interessante Tatsache: Wir k√∂nnten den Gradienten f√ºr die DOWN-Aktion sofort berechnen und anwenden, wie wir es beim Unterrichten mit einem Lehrer getan haben, und dadurch die Wahrscheinlichkeit erh√∂hen, dass das Netzwerk die DOWN-Aktion in Zukunft ausf√ºhrt.  So k√∂nnen wir diesen Gradienten sofort erkennen und uns daran erinnern.  Aber das Problem ist, dass wir im Moment noch nicht wissen - ist es gut, nach unten zu gehen?  <b>Das Interessanteste ist jedoch, dass wir einfach etwas warten und den Farbverlauf sp√§ter anwenden k√∂nnen!</b>  In Pong k√∂nnen wir bis zum Ende des Spiels warten, dann die Belohnung, die wir erhalten haben (entweder +1, wenn wir gewonnen haben, oder -1, wenn wir verloren haben), als Faktor f√ºr den Gradienten eingeben.  Wenn wir also -1 f√ºr die DOWN-Wahrscheinlichkeit einf√ºhren und die Back-Propagation durchf√ºhren, werden wir die Netzwerkparameter neu erstellen, sodass es weniger wahrscheinlich ist, dass die DOWN-Aktion in Zukunft ausgef√ºhrt wird, wenn dasselbe Bild auftritt, da die √úbernahme dieser Aktion dazu gef√ºhrt hat, dass wir das Spiel verloren haben.  Das hei√üt, wir m√ºssen uns irgendwie an alle Aktionen (Ein- und Ausg√§nge des neuronalen Netzwerks) in einer Episode des Spiels erinnern und basierend auf diesem Array das neuronale Netzwerk auf die gleiche Weise verdrehen wie beim Unterrichten mit einem Lehrer. <br><br><img src="https://habrastorage.org/webt/hj/jr/tg/hjjrtgpmkweozlnidrhixsf7jfs.png"><br><br>  Und das ist alles, was ben√∂tigt wird: Wir haben eine stochastische Politik, die Ma√ünahmen ausw√§hlt, und in Zukunft werden Ma√ünahmen, die letztendlich zu guten Ergebnissen f√ºhren, und Ma√ünahmen, die zu schlechten Ergebnissen f√ºhren, nicht gef√∂rdert.  Au√üerdem sollte die Belohnung nicht einmal +1 oder -1 betragen, wenn wir letztendlich das Spiel gewinnen.  Es kann ein beliebiger Wert derselben Bedeutung sein.  Wenn zum Beispiel alles wirklich gut funktioniert, k√∂nnte die Belohnung 10,0 sein, die wir dann als Farbverlauf verwenden, um die Backprop-Backpropagation zu starten.  Das ist das Sch√∂ne an neuronalen Netzen.  Ihre Verwendung mag wie ein Scherz erscheinen: Sie d√ºrfen 1 Million Parameter in 1 Teraflop von Berechnungen einbauen lassen, und Sie k√∂nnen das Programm lernen lassen, beliebige Dinge mit stochastischem Gradientenabstieg (SGD) zu tun.  Es sollte nicht funktionieren, aber es ist lustig, dass wir in einem Universum leben, in dem es funktioniert. <br><br>  Wenn wir einfache Brettspiele wie Dame spielen w√ºrden, w√§re die Reihenfolge ungef√§hr gleich.  Es gibt einen sp√ºrbaren Unterschied zu Minimax- oder Alpha-Beta-Clipping-Algorithmen.  Bei diesen Algorithmen blickt das Programm ein paar Schritte voraus, kennt die Spielregeln und analysiert Millionen von Positionen.  Beim RL-Ansatz werden nur tats√§chlich ausgef√ºhrte Bewegungen analysiert.  Gleichzeitig freut sich das neuronale Netz nicht, da es nichts √ºber die Spielregeln wei√ü. <br><br>  <b>Trainingsreihenfolge im Detail.</b>  Wir erstellen und initialisieren ein neuronales Netzwerk mit einigen W1, W2 und spielen 100 Pong-Spiele (wir nennen es den ‚ÄûRun-In‚Äú der Politik, Policy Rollouts).  Angenommen, jedes Spiel besteht aus 200 Frames. Insgesamt haben wir also 100 * 200 = 20.000 Entscheidungen getroffen, um nach oben oder unten zu gehen.  Und f√ºr jede der L√∂sungen kennen wir einen Gradienten, der uns sagt, wie sich die Parameter √§ndern sollen, wenn wir diese L√∂sung in diesem Zustand in Zukunft f√∂rdern oder verbieten wollen.  Jetzt m√ºssen wir nur noch jede Entscheidung, die wir treffen, als gut oder schlecht bezeichnen.  Angenommen, wir haben 12 Spiele gewonnen und 88 verloren. Wir werden alle 200 * 12 = 2400 Entscheidungen treffen, die wir in den Gewinnspielen getroffen haben, und ein positives Update durchf√ºhren (f√ºr jede Aktion einen Gradienten von +1,0 eingeben, Backprop ausf√ºhren und die Parameter aktualisieren F√∂rderung der Ma√ünahmen, die wir unter all diesen Bedingungen gew√§hlt haben).  Und wir werden die anderen 200 * 88 = 17.600 Entscheidungen treffen, die wir beim Verlust von Spielen getroffen haben, und ein negatives Update vornehmen (ohne zu genehmigen, was wir getan haben).  Und das ist alles was es braucht.  Das Netzwerk wiederholt jetzt eher Aktionen, die funktioniert haben, und etwas weniger wahrscheinlich Aktionen, die nicht funktioniert haben.  Jetzt spielen wir weitere 100 Spiele mit unserer neuen, leicht verbesserten Richtlinie und wiederholen dann die Anwendung von Verl√§ufen. <br><br><img src="https://habrastorage.org/webt/zv/ap/mo/zvapmoiul9plnltsttdsplvze3g.png"><br>  <i>Cartoon-Schema von 4 Spielen.</i>  <i>Jeder schwarze Kreis ist eine Art Spielstatus (drei Beispiele f√ºr Status sind unten dargestellt), und jeder Pfeil ist ein √úbergang, der mit der ausgew√§hlten Aktion markiert ist.</i>  <i>In diesem Fall haben wir 2 Spiele gewonnen und 2 Spiele verloren.</i>  <i>Wir haben die beiden Spiele, die wir gewonnen haben, genommen und jede Aktion, die wir in dieser Episode gemacht haben, leicht ermutigt.</i>  <i>Umgekehrt werden wir auch die beiden verlorenen Spiele nehmen und jede einzelne Aktion, die wir in dieser Episode durchgef√ºhrt haben, leicht entmutigen.</i> <br><br>  Wenn Sie dar√ºber nachdenken, werden Sie einige lustige Eigenschaften finden.  Was w√§re zum Beispiel, wenn wir in Bild 50 eine gute Aktion ausgef√ºhrt h√§tten, den Ball richtig getreten h√§tten, dann aber in Bild 150 den Ball verpasst h√§tten?  Da wir das Spiel verloren haben, wird jede einzelne Aktion jetzt als schlecht markiert. Verhindert dies nicht den korrekten Treffer in Bild 50?  Sie haben Recht - f√ºr diese Party wird es so sein.  Wenn Sie jedoch den Prozess in Tausenden / Millionen von Spielen ber√ºcksichtigen, erh√∂ht die korrekte Ausf√ºhrung des Rebounds Ihre Gewinnwahrscheinlichkeit in der Zukunft.  Im Durchschnitt werden Sie mehr positive als negative Updates f√ºr einen richtigen Schl√§gerschlag sehen.  Und die Implementierungspolitik f√ºr neuronale Netze wird letztendlich die richtigen Reaktionen hervorrufen. <br><br>  <i>Update: Der 9. Dezember 2016</i> ist eine alternative Ansicht.  In meiner obigen Erkl√§rung verwende ich Begriffe wie "Definieren eines Gradienten und Backprop-Back-Propagation", was eine definitiv geschickte Technik ist.  Wenn Sie es gewohnt sind, Ihren eigenen Backprop-Backspread-Code zu schreiben oder Torch zu verwenden, k√∂nnen Sie die Verl√§ufe vollst√§ndig steuern.  Wenn Sie jedoch an Theano oder TensorFlow gew√∂hnt sind, werden Sie ein wenig verwirrt sein, da der Backprop-Code vollst√§ndig automatisiert und schwer anzupassen ist.  In diesem Fall kann die folgende alternative Ansicht produktiver sein.  Im Unterricht mit einem Lehrer ist das √ºbliche Ziel die Maximierung <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-27"><span class="MJXp-mtext" id="MJXp-Span-28">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-29"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-30"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">u </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-31"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-32" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-33" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></span></span><font style="vertical-align: inherit;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-35"><font style="vertical-align: inherit;"> l </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-36"><font style="vertical-align: inherit;">o </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-37"><font style="vertical-align: inherit;">g </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-38"><font style="vertical-align: inherit;">p </font></span><span class="MJXp-mo" id="MJXp-Span-39" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">( </font></span><span class="MJXp-msubsup" id="MJXp-Span-40"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-41" style="margin-right: 0.05em;"><font style="vertical-align: inherit;">y </font></span></span><span class="MJXp-msubsup" id="MJXp-Span-40"><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-42" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;">i</font></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-44"><font style="vertical-align: inherit;"> m </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-45"><font style="vertical-align: inherit;">i </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-46"><font style="vertical-align: inherit;">d </font></span><span class="MJXp-msubsup" id="MJXp-Span-47"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48" style="margin-right: 0.05em;"><font style="vertical-align: inherit;">x </font></span></span><span class="MJXp-msubsup" id="MJXp-Span-47"><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-49" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;">i</font></span></span><span class="MJXp-mo" id="MJXp-Span-50" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"> )</font></span></font><span class="MJXp-mtext" id="MJXp-Span-34">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-35"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-36"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-37"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-38"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-39" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-msubsup" id="MJXp-Span-40"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-41" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-42" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-mtext" id="MJXp-Span-43">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-44"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-45"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-46"><font style="vertical-align: inherit;"></font></span><span class="MJXp-msubsup" id="MJXp-Span-47"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-49" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-mo" id="MJXp-Span-50" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.045ex" height="2.66ex" viewBox="0 -832 9060.9 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-75" x="719" y="0"></use><g transform="translate(1292,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="1242" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6C" x="2764" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6F" x="3063" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-67" x="3548" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-70" x="4029" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMAIN-28" x="4532" y="0"></use><g transform="translate(4922,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="693" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6D" x="6007" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="6885" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-64" x="7231" y="0"></use><g transform="translate(7754,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMAIN-29" x="8671" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-2"> \ sum_i \ log p (y_i \ mid x_i) </script>  wo <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-51"><span class="MJXp-msubsup" id="MJXp-Span-52"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-53" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-54" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-55" style="margin-left: 0em; margin-right: 0.222em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-56"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-57" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-58" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.102ex" height="1.817ex" viewBox="0 -520.7 2196.8 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="809" y="-213"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMAIN-2C" x="916" y="0"></use><g transform="translate(1361,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="693" y="-213"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-3"> x_i, y_i </script>  - Trainingsbeispiele (wie Bilder und deren Etiketten).  Die Anwendung des Gradienten auf die Richtlinienfunktion f√§llt genau mit der Ausbildung beim Lehrer zusammen, jedoch mit zwei kleinen Unterschieden: 1) Wir haben nicht die richtigen Bezeichnungen <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-59"><span class="MJXp-msubsup" id="MJXp-Span-60"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-61" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-62" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.939ex" height="1.817ex" viewBox="0 -520.7 834.8 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="693" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-4"> y_i </script>  Daher verwenden wir als ‚Äûgef√§lschtes Etikett‚Äú die Aktion, die wir erhalten haben, um aus der Richtlinie auszuw√§hlen, als sie angezeigt wurde <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-63"><span class="MJXp-msubsup" id="MJXp-Span-64"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-65" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-66" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.129ex" height="1.817ex" viewBox="0 -520.7 916.8 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="809" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-5"> x_i </script>  und 2) Wir f√ºhren f√ºr jede Aktion einen anderen Zweckm√§√üigkeitskoeffizienten (Vorteil) ein.  Am Ende sieht unser Verlust also so aus <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-67"><span class="MJXp-mtext" id="MJXp-Span-68">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-69"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-70"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">u </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-71"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-72" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-73" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i </font></font></span></span><span class="MJXp-msubsup" id="MJXp-Span-74"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-75" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-76" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></span></span><font style="vertical-align: inherit;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-78"><font style="vertical-align: inherit;"> l </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-79"><font style="vertical-align: inherit;">o </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80"><font style="vertical-align: inherit;">g </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-81"><font style="vertical-align: inherit;">p </font></span><span class="MJXp-mo" id="MJXp-Span-82" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">( </font></span><span class="MJXp-msubsup" id="MJXp-Span-83"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-84" style="margin-right: 0.05em;"><font style="vertical-align: inherit;">y </font></span></span><span class="MJXp-msubsup" id="MJXp-Span-83"><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-85" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;">i</font></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-87"><font style="vertical-align: inherit;"> m </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-88"><font style="vertical-align: inherit;">i </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-89"><font style="vertical-align: inherit;">d </font></span><span class="MJXp-msubsup" id="MJXp-Span-90"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-91" style="margin-right: 0.05em;"><font style="vertical-align: inherit;">x </font></span></span><span class="MJXp-msubsup" id="MJXp-Span-90"><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-92" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;">i</font></span></span><span class="MJXp-mo" id="MJXp-Span-93" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"> )</font></span></font><span class="MJXp-mtext" id="MJXp-Span-77">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-78"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-79"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-81"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-82" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-msubsup" id="MJXp-Span-83"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-84" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-85" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-mtext" id="MJXp-Span-86">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-87"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-88"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-89"><font style="vertical-align: inherit;"></font></span><span class="MJXp-msubsup" id="MJXp-Span-90"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-91" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-92" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-mo" id="MJXp-Span-93" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="23.588ex" height="2.66ex" viewBox="0 -832 10155.7 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-75" x="719" y="0"></use><g transform="translate(1292,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="1242" y="-213"></use></g><g transform="translate(2514,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-41" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="1061" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6C" x="3859" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6F" x="4158" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-67" x="4643" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-70" x="5124" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMAIN-28" x="5627" y="0"></use><g transform="translate(6017,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="693" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6D" x="7101" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="7980" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-64" x="8325" y="0"></use><g transform="translate(8849,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMAIN-29" x="9766" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-6"> \ sum_i A_i \ log p (y_i \ mid x_i) </script>  wo <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-94"><span class="MJXp-msubsup" id="MJXp-Span-95"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-96" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-97" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.939ex" height="1.817ex" viewBox="0 -520.7 834.8 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="693" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-7"> y_i </script>  - Dies ist die Aktion, die wir mit der Probe durchgef√ºhrt haben, und <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-98"><span class="MJXp-msubsup" id="MJXp-Span-99"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-100" style="margin-right: 0.05em;">A</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-101" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.543ex" height="2.419ex" viewBox="0 -780.1 1094.8 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-41" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="1061" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-8"> A_i </script>  Ist die Zahl, die wir den Zweckm√§√üigkeitskoeffizienten nennen.  Zum Beispiel im Fall von Pong der Wert <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-102"><span class="MJXp-msubsup" id="MJXp-Span-103"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-104" style="margin-right: 0.05em;">A</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-105" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.543ex" height="2.419ex" viewBox="0 -780.1 1094.8 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-41" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="1061" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-9"> A_i </script>  Es k√∂nnte 1,0 sein, wenn wir die Episode gewinnen, und -1,0, wenn wir verlieren.  Dies stellt sicher, dass wir die Wahrscheinlichkeit der Aufzeichnung von Aktionen, die zu einem guten Ergebnis gef√ºhrt haben, maximieren und die Wahrscheinlichkeit der Aufzeichnung von Aktionen, die dies nicht getan haben, minimieren.  Und neutrale Aktionen aufgrund vieler Aufrufe werden die Funktion der Politik nicht besonders beeintr√§chtigen.  Daher ist das verst√§rkte Lernen genau das gleiche wie das Lernen mit einem Lehrer, jedoch mit einem sich st√§ndig √§ndernden Datensatz (Episoden), mit einem zus√§tzlichen Faktor. <br><br>  <b>Erweiterte Machbarkeitsfunktionen.</b>  Ich habe auch ein bisschen mehr Informationen versprochen.  Bisher haben wir die Richtigkeit jeder einzelnen Aktion danach bewertet, ob wir gewinnen oder nicht.  In einem allgemeineren RL-Setup erhalten wir eine ‚Äûbedingte Belohnung‚Äú. <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-106"><span class="MJXp-msubsup" id="MJXp-Span-107"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-108" style="margin-right: 0.05em;">r</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-109" style="vertical-align: -0.4em;">t</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.875ex" height="1.817ex" viewBox="0 -520.7 807.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-72" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-74" x="638" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-10"> r_t </script>  f√ºr jeden Schritt, abh√§ngig von der Schrittnummer oder der Zeit.  Eine der g√§ngigen Optionen ist die Verwendung eines diskontierten Koeffizienten, sodass die ‚Äûm√∂gliche Belohnung‚Äú im obigen Diagramm lautet <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-110"><span class="MJXp-msubsup" id="MJXp-Span-111"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-112" style="margin-right: 0.05em;">R</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-113" style="vertical-align: -0.4em;">t</span></span><span class="MJXp-mo" id="MJXp-Span-114" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-115">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-116">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-117">u</span><span class="MJXp-msubsup" id="MJXp-Span-118"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-119" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-124"><span class="MJXp-mtext" id="MJXp-Span-125">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-126">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-127">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-128">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-129">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-130">y</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-120"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-121">k</span><span class="MJXp-mo" id="MJXp-Span-122">=</span><span class="MJXp-mn" id="MJXp-Span-123">0</span></span></span></span></span></span></span><span class="MJXp-mtext" id="MJXp-Span-131">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-132">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-133">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-134">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-135">m</span><span class="MJXp-msubsup" id="MJXp-Span-136"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-137" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-138" style="vertical-align: 0.5em;">k</span></span><span class="MJXp-msubsup" id="MJXp-Span-139"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-140" style="margin-right: 0.05em;">r</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-141" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-142">t</span><span class="MJXp-mo" id="MJXp-Span-143">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-144">k</span></span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-11-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28.746ex" height="3.503ex" viewBox="0 -1091.4 12376.9 1508.3" role="img" focusable="false" style="vertical-align: -0.969ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-52" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-74" x="1074" y="-213"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMAIN-3D" x="1392" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-73" x="2699" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-75" x="3168" y="0"></use><g transform="translate(3741,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6D" x="0" y="0"></use><g transform="translate(878,490)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-69" x="353" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6E" x="699" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-66" x="1299" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-74" x="1850" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-79" x="2211" y="0"></use></g><g transform="translate(878,-327)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6B" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMAIN-3D" x="521" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMAIN-30" x="1300" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-67" x="6885" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-61" x="7365" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6D" x="7895" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6D" x="8773" y="0"></use><g transform="translate(9652,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6B" x="748" y="513"></use></g><g transform="translate(10650,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMAIN-2B" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/439674/&amp;usg=ALkJrhi91hE3Z5QQJo7BjS8O3ku5LBBHmw#MJMATHI-6B" x="1140" y="0"></use></g></g></g></svg></span><script type="math/tex" id="MathJax-Element-11"> R_t = \ sum_ {k = 0} ^ {\ infty} \ gamma ^ k r_ {t + k} </script>  wo <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-145"><span class="MJXp-mtext" id="MJXp-Span-146">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-147">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-148">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-149">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-150">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-151">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-12"> \ gamma </script>  Ist eine Zahl von 0 bis 1, die als Abzinsungskoeffizient bezeichnet wird (z. B. 0,99).  Der Ausdruck besagt, dass die St√§rke, mit der wir zum Handeln ermutigen, die gewichtete Summe aller Belohnungen ist, aber nachfolgende Belohnungen sind exponentiell weniger wichtig.  Das hei√üt, kurze Aktionsketten werden besser gef√∂rdert, und der Schwanz langer Aktionsketten wird weniger wichtig.  In der Praxis m√ºssen Sie sie auch normalisieren.  Nehmen wir zum Beispiel an, wir berechnen <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-152"><span class="MJXp-msubsup" id="MJXp-Span-153"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-154" style="margin-right: 0.05em;">R</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-155" style="vertical-align: -0.4em;">t</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-13-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-13"> R_t </script>  f√ºr alle 20.000 Aktionen in einer Serie von 100 Folgen des Spiels.  Eine sehr gute Idee ist es, diese Werte zu normalisieren (den Durchschnitt zu subtrahieren, durch die Standardabweichung zu dividieren), bevor wir sie mit dem Backprop-Algorithmus verbinden.  Daher ermutigen und entmutigen wir immer etwa die H√§lfte der durchgef√ºhrten Aktionen.  Dies reduziert Schwankungen und macht die Politik konvergenter.  Eine ausf√ºhrlichere Studie finden Sie unter [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a> ]. <br><br>  <b>Abgeleitet von einer Richtlinienfunktion.</b>  Ich wollte auch kurz beschreiben, wie Gradienten mathematisch genommen werden.  Die Gradienten der Funktion der Politik sind ein Sonderfall einer allgemeineren Theorie.  Der allgemeine Fall ist, wenn wir einen Ausdruck der Form haben <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-156"><span class="MJXp-msubsup" id="MJXp-Span-157"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-158" style="margin-right: 0.05em;">E</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-159" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-160">x</span><span class="MJXp-mtext" id="MJXp-Span-161">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-162">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-163">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-164">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-165">p</span><span class="MJXp-mo" id="MJXp-Span-166">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-167">x</span><span class="MJXp-mtext" id="MJXp-Span-168">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-169">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-170">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-171">d</span><span class="MJXp-mtext" id="MJXp-Span-172">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-173">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-174">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-175">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-176">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-177">a</span><span class="MJXp-mo" id="MJXp-Span-178">)</span></span></span><span class="MJXp-mo" id="MJXp-Span-179" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-180">f</span><span class="MJXp-mo" id="MJXp-Span-181" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-182">x</span><span class="MJXp-mo" id="MJXp-Span-183" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-184" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-14-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-14"> E_ {x \ sim p (x \ mid \ theta)} [f (x)] </script>  d.h. die Erwartung einer Skalarfunktion <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-185"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-186">f</span><span class="MJXp-mo" id="MJXp-Span-187" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-188">x</span><span class="MJXp-mo" id="MJXp-Span-189" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-15-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-15"> f (x) </script>  mit einer gewissen Verteilung seines Parameters <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-190"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-191">p</span><span class="MJXp-mo" id="MJXp-Span-192" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-193">x</span><span class="MJXp-mo" id="MJXp-Span-194" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mtext" id="MJXp-Span-195">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-196">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-197">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-198">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-199">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-200">a</span><span class="MJXp-mo" id="MJXp-Span-201" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-16-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-16"> p (x; \ theta) </script>  durch einen Vektor parametrisiert <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-202"><span class="MJXp-mtext" id="MJXp-Span-203">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-204">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-205">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-206">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-207">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-208">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-17-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-17"> \ theta </script>  .  Dann <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-209"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-210">f</span><span class="MJXp-mo" id="MJXp-Span-211" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-212">x</span><span class="MJXp-mo" id="MJXp-Span-213" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-18-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-18"> f (x) </script>  wird unsere Belohnungsfunktion (oder die Funktion der Zweckm√§√üigkeit im allgemeineren Sinne) und die diskrete Verteilung <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-214"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-215">p</span><span class="MJXp-mo" id="MJXp-Span-216" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-217">x</span><span class="MJXp-mo" id="MJXp-Span-218" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-19-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-19"> p (x) </script>  wird unsere Politik sein, die tats√§chlich die Form hat <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-219"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-220">p</span><span class="MJXp-mo" id="MJXp-Span-221" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-222">a</span><span class="MJXp-mtext" id="MJXp-Span-223">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-224">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-225">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-226">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-227">I</span><span class="MJXp-mo" id="MJXp-Span-228" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-20-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-20"> p (a \ mid I) </script>  Geben Sie die Wahrscheinlichkeiten einer Aktion f√ºr das Bild an <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-229"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-230">I</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-21-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-21"> I </script>  .  Dann interessiert uns, wie wir die Verteilung von p durch seine Parameter verschieben k√∂nnen <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-231"><span class="MJXp-mtext" id="MJXp-Span-232">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-233">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-234">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-235">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-236">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-237">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-22-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-22"> \ theta </script>  zu vergr√∂√üern <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-238"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-239">f</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-23-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-23"> f </script>  (d. h. wie √§ndern wir die Netzwerkeinstellungen, damit die Aktionen eine h√∂here Belohnung erhalten).  Wir haben das: <br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-240"><span class="noError" id="MJXp-Span-241" style="display: inline-block;">\&nbsp;begin&nbsp;{align}&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;E_x&nbsp;[f&nbsp;(x)]&nbsp;&amp;&nbsp;=&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;\&nbsp;sum_x&nbsp;p&nbsp;(x)&nbsp;f&nbsp;(x)&nbsp;&amp;&nbsp;\&nbsp;text&nbsp;{Definition&nbsp;der&nbsp;Erwartung}&nbsp;\\&nbsp;&amp;&nbsp;=&nbsp;\&nbsp;sum_x&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;p&nbsp;(x)&nbsp;f&nbsp;(x)&nbsp;&amp;&nbsp;\&nbsp;text&nbsp;{Summe&nbsp;und&nbsp;Gradient&nbsp;tauschen}&nbsp;\\&nbsp;&amp;&nbsp;=&nbsp;\&nbsp;sum_x&nbsp;p&nbsp;(x)&nbsp;\&nbsp;frac&nbsp;{\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;p&nbsp;(x)}&nbsp;{p&nbsp;(x)}&nbsp;f&nbsp;(x)&nbsp;&amp;&nbsp;\&nbsp;text&nbsp;{multiplizieren&nbsp;und&nbsp;dividieren&nbsp;durch}&nbsp;p&nbsp;(x)&nbsp;\\&nbsp;&amp;&nbsp;=&nbsp;\&nbsp;sum_x&nbsp;p&nbsp;(x)&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;\&nbsp;log&nbsp;p&nbsp;(x)&nbsp;f&nbsp;(x)&nbsp;&amp;&nbsp;\&nbsp;text&nbsp;{benutze&nbsp;die&nbsp;Tatsache,&nbsp;dass}&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;\&nbsp;log&nbsp;(z)&nbsp;=&nbsp;\&nbsp;frac&nbsp;{1}&nbsp;{z}&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;z&nbsp;\\&nbsp;&amp;&nbsp;=&nbsp;E_x&nbsp;[f&nbsp;(x)&nbsp;\&nbsp;nabla&nbsp;_&nbsp;{\&nbsp;theta}&nbsp;\&nbsp;log&nbsp;p&nbsp;(x)]&nbsp;&amp;&nbsp;\&nbsp;text&nbsp;{Definition&nbsp;der&nbsp;Erwartung}&nbsp;\&nbsp;end&nbsp;{align}</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-24-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-24"> \ begin {align} \ nabla _ {\ theta} E_x [f (x)] & = \ nabla _ {\ theta} \ sum_x p (x) f (x) & \ text {Definition der Erwartung} \\ & = \ sum_x \ nabla _ {\ theta} p (x) f (x) & \ text {Summe und Gradient tauschen} \\ & = \ sum_x p (x) \ frac {\ nabla _ {\ theta} p (x)} {p (x)} f (x) & \ text {multiplizieren und dividieren durch} p (x) \\ & = \ sum_x p (x) \ nabla _ {\ theta} \ log p (x) f (x) & \ text {benutze die Tatsache, dass} \ nabla _ {\ theta} \ log (z) = \ frac {1} {z} \ nabla _ {\ theta} z \\ & = E_x [f (x) \ nabla _ {\ theta} \ log p (x)] & \ text {Definition der Erwartung} \ end {align} </script><br><br>  Ich werde versuchen, dies zu erkl√§ren.  Wir haben eine gewisse Verteilung <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-242"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-243">p</span><span class="MJXp-mo" id="MJXp-Span-244" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-245">x</span><span class="MJXp-mo" id="MJXp-Span-246" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mtext" id="MJXp-Span-247">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-248">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-249">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-250">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-251">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-252">a</span><span class="MJXp-mo" id="MJXp-Span-253" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-25-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-25"> p (x; \ theta) </script>  (Ich habe die Abk√ºrzung verwendet <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-254"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-255">p</span><span class="MJXp-mo" id="MJXp-Span-256" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-257">x</span><span class="MJXp-mo" id="MJXp-Span-258" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-26-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-26"> p (x) </script>  aus denen wir bestimmte Werte ausw√§hlen k√∂nnen.  Beispielsweise kann es sich um eine Gau√üsche Verteilung handeln, aus der ein Zufallszahlengenerator abtastet.  F√ºr jedes Beispiel k√∂nnen wir auch die Sch√§tzfunktion berechnen <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-259"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-260">f</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-27-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-27"> f </script>  , was nach dem aktuellen Beispiel eine skalare Sch√§tzung ergibt.  Die resultierende Gleichung sagt uns, wie wir die Verteilung durch ihre Parameter verschieben sollen <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-261"><span class="MJXp-mtext" id="MJXp-Span-262">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-263">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-264">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-265">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-266">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-267">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-28-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-28"> \ theta </script>  wenn wir weitere Beispiele f√ºr darauf basierende Ma√ünahmen w√ºnschen, um h√∂here Raten zu erzielen <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-268"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-269">f</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-29-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-29"> f </script>  .  Wir nehmen einige Beispiele f√ºr Ma√ünahmen <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-270"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-271">x</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-30-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-30"> x </script>  und ihre Bewertung <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-272"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-273">f</span><span class="MJXp-mo" id="MJXp-Span-274" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-275">x</span><span class="MJXp-mo" id="MJXp-Span-276" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-31-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-31"> f (x) </script>  und auch f√ºr jedes x bewerten wir auch den zweiten Term <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-277"><span class="MJXp-mtext" id="MJXp-Span-278">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-279">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-280">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-281">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-282">l</span><span class="MJXp-msubsup" id="MJXp-Span-283"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-284" style="margin-right: 0.05em;">a</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-285" style="vertical-align: -0.4em;"><span class="MJXp-mtext" id="MJXp-Span-286">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-287">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-288">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-289">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-290">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-291">a</span></span></span><span class="MJXp-mtext" id="MJXp-Span-292">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-293">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-294">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-295">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-296">p</span><span class="MJXp-mo" id="MJXp-Span-297" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-298">x</span><span class="MJXp-mo" id="MJXp-Span-299" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mtext" id="MJXp-Span-300">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-301">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-302">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-303">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-304">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-305">a</span><span class="MJXp-mo" id="MJXp-Span-306" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-32-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-32"> \ nabla _ {\ theta} \ log p (x; \ theta) </script>  .  Was ist dieser Multiplikator?  Dies ist genau der Vektor - der Gradient, der uns die Richtung im Parameterraum gibt, was zu einer Erh√∂hung der Wahrscheinlichkeit einer bestimmten Aktion f√ºhrt <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-307"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-308">x</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-33-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-33"> x </script>  .  Mit anderen Worten, wenn wir Œ∏ in die Richtung dr√ºcken <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-309"><span class="MJXp-mtext" id="MJXp-Span-310">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-311">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-312">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-313">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-314">l</span><span class="MJXp-msubsup" id="MJXp-Span-315"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-316" style="margin-right: 0.05em;">a</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-317" style="vertical-align: -0.4em;"><span class="MJXp-mtext" id="MJXp-Span-318">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-319">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-320">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-321">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-322">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-323">a</span></span></span><span class="MJXp-mtext" id="MJXp-Span-324">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-325">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-326">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-327">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-328">p</span><span class="MJXp-mo" id="MJXp-Span-329" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-330">x</span><span class="MJXp-mo" id="MJXp-Span-331" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mtext" id="MJXp-Span-332">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-333">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-334">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-335">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-336">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-337">a</span><span class="MJXp-mo" id="MJXp-Span-338" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-34-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-34"> \ nabla _ {\ theta} \ log p (x; \ theta) </script>  w√ºrden wir sehen, dass die neue Wahrscheinlichkeit dieser Aktion leicht zunehmen wird.  Wenn Sie auf die Formel zur√ºckblicken, hei√üt es, dass wir diese Richtung einschlagen und den Skalarwert damit multiplizieren sollten <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-339"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-340">f</span><span class="MJXp-mo" id="MJXp-Span-341" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-342">x</span><span class="MJXp-mo" id="MJXp-Span-343" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-35-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-35"> f (x) </script>  .  Dies stellt sicher, dass Beispiele f√ºr Aktionen mit einer h√∂heren Bewertung (in unserem Fall eine Belohnung) st√§rker ‚Äûziehen‚Äú als Beispiele mit einem niedrigeren Indikator. Wenn wir daher basierend auf mehreren Beispielen aus aktualisieren <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-344"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-345">p</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-36-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-36"> p </script>  w√ºrde sich die Wahrscheinlichkeitsdichte in Richtung h√∂herer resultierender Spielpunkte verschieben, was die Wahrscheinlichkeit erh√∂ht, Beispiele f√ºr Aktionen mit hohen Belohnungen zu erhalten.  Es ist wichtig, dass der Gradient nicht aus der Funktion √ºbernommen wird <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-346"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-347">f</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-37-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-37"> f </script>  , da es in der Regel undifferenziert und unvorhersehbar sein kann.  A. <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-348"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-349">p</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-38-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-38"> p </script>  differenzierbar durch <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-350"><span class="MJXp-mtext" id="MJXp-Span-351">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-352">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-353">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-354">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-355">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-356">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-39-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-39"> \ theta </script>  .  Also <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-357"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-358">p</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-40-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-40"> p </script>  ist eine kontinuierlich einstellbare diskrete Verteilung, bei der Sie die Wahrscheinlichkeiten einzelner Aktionen anpassen k√∂nnen.  Das nehmen wir auch an <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-359"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-360">p</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-41-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-41"> p </script>  normalisiert. <br><br><img src="https://habrastorage.org/webt/xo/qy/9p/xoqy9pzjvy4d3sxosr_irpasic4.png"><br><br>  <i>Gradientenvisualisierung.</i>  <i>Links: Gau√üsche Verteilung und einige Beispiele davon (blaue Punkte).</i>  <i>An jedem blauen Punkt zeichnen wir auch den Gradienten der logarithmischen Wahrscheinlichkeit in Bezug auf den Durchschnittsparameter auf.</i>  <i>Der Pfeil gibt die Richtung an, in die der durchschnittliche Verteilungswert verschoben werden soll, um die Wahrscheinlichkeit dieser Beispielaktion zu erh√∂hen.</i>  <i>In der Mitte: Es wurde eine Bewertungsfunktion hinzugef√ºgt, die √ºberall -1 ergibt, au√üer in einigen kleinen Regionen +1 (beachten Sie, dass dies eine beliebige und nicht unbedingt differenzierbare Skalarfunktion sein kann).</i>  <i>Die Pfeile sind jetzt farbcodiert, da aufgrund der Multiplikation alle gr√ºnen Pfeile mit einer positiven Bewertung und die negativen roten Pfeile gemittelt werden.</i>  <i>Rechts: Nach dem Aktualisieren der Parameter dr√ºcken uns die gr√ºnen Pfeile und die umgekehrten roten Pfeile nach links und unten.</i>  <i>Proben aus dieser Verteilung haben jetzt auf Wunsch eine h√∂here erwartete Bewertung.</i> <br><br>  Ich hoffe der Zusammenhang mit RL ist klar.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unsere Politik gibt uns Beispiele f√ºr Ma√ünahmen, von denen einige besser funktionieren als andere (gemessen an der Zweckm√§√üigkeit). Sie k√∂nnen die Richtlinieneinstellungen √§ndern, indem Sie den Verlauf der ausgew√§hlten Aktionen ausf√ºhren, ihn mit der Bewertung multiplizieren und alles hinzuf√ºgen, was wir oben getan haben. F√ºr eine gr√ºndlichere Schlussfolgerung empfehle ich einen Vortrag von </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">John Shulman. </font></font><br></a> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schulung.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Nun, wir haben die Prinzipien von Gradienten der Funktion der Politik entwickelt. Ich habe den gesamten Ansatz in einem </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Python-Skript mit 130 Zeilen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> implementiert </font><font style="vertical-align: inherit;">, das den vorgefertigten ATAI 2600 Pong-Emulator von </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenAI Gym verwendet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Ich habe ein zweischichtiges neuronales Netzwerk mit 200 Hidden-Layer-Neuronen unter Verwendung des RMSProp-Algorithmus f√ºr eine Reihe von 10 Episoden trainiert (jede Episode nach den Regeln besteht aus mehreren Ballz√ºgen und die Episode erzielt weiterhin 21 Punkte). Ich habe nicht zu viele Hyperparameter eingerichtet und mit meinem langsamen Macbook experimentiert, aber nach einem dreit√§gigen Training habe ich eine Richtlinie erhalten, die etwas besser spielt als der eingebaute Player. Die Gesamtzahl der Episoden betrug ungef√§hr 8.000, so dass der Algorithmus ungef√§hr 200.000 Pong-Spiele spielte, was ziemlich viel ist, und insgesamt ~ 800 Aktualisierungen der Gewichte erzeugte. Wenn ich mit ConvNets auf der GPU trainierte, konnte ich innerhalb weniger Tage gro√üartige Ergebnisse erzielen, und wenn ich die Hyperparameter optimierte, konnte ich immer gewinnen. Ich habe jedoch nicht zu viel Zeit mit Rechnen oder Einrichten verbracht.Stattdessen haben wir Pong AI, das die Hauptideen veranschaulicht und recht gut funktioniert:</font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/cf/gf/jr/cfgfjrkzt_awy-l7f5lcxcrfvki.png"></a> <br> <i>  .      </i> <br><br> <b> .</b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir k√∂nnen uns auch die erhaltenen Gewichte des neuronalen Netzwerks ansehen. Dank der Vorverarbeitung ist jeder unserer Eing√§nge ein Differenzbild von 80 x 80 (aktuelles Bild minus vorheriges Bild). Jedes Neuron aus Schicht W1 ist mit einer verborgenen Schicht W2 verbunden, die aus 200 Neuronen besteht. Die Anzahl der Anleihen betr√§gt 80 * 80 * 200. Versuchen wir, diese Zusammenh√§nge zu analysieren. Wir werden alle Neuronen der W2-Schicht sortieren und visualisieren, welche Gewichte dazu f√ºhren. Aus den Skalen, die von W1-Neuronen zu einem W2-Neuron f√ºhren, werden 80x80-Bilder erstellt. Unten sind 40 solcher Bilder von W2 (insgesamt 200). Wei√üe Pixel sind positive Gewichte und schwarze sind negative Gewichte. Beachten Sie, dass mehrere W2-Neuronen auf einen fliegenden Ball abgestimmt sind, der in gestrichelten Linien codiert ist. In einem Spiel kann der Ball nur an einer Stelle sein,Daher sind diese Neuronen vielseitig einsetzbar und ‚Äûschie√üen‚Äú, wenn sich der Ball irgendwo innerhalb dieser Linien befindet. Der Wechsel von Schwarz und Wei√ü ist interessant, denn wenn sich der Ball entlang der Bahn bewegt, schwingt die Aktivit√§t des Neurons wie eine Sinuswelle. Und wegen ReLU wird er nur an bestimmten Positionen ‚Äûschie√üen‚Äú. Die Bilder enthalten viel Rauschen, was weniger w√§re, wenn ich die L2-Regularisierung verwenden w√ºrde.</font></font><br><br><img src="https://habrastorage.org/webt/1t/n4/le/1tn4lew2rszryk1u9vkbreigku4.png"><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Was passiert nicht?</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wir haben also gelernt, wie man mit dem Gradienten der Richtlinienfunktion Pong auf Bildern spielt, und das funktioniert ziemlich gut. Bei diesem Ansatz handelt es sich um ein bizarres Formular zum Vorschlagen und √úberpr√ºfen, bei dem sich das Erraten auf das Ausf√ºhren unserer Richtlinien f√ºr mehrere Episoden des Spiels bezieht und das √úberpr√ºfen von Aktionen Aktionen f√∂rdert, die zu guten Ergebnissen f√ºhren. Im Allgemeinen entspricht dies dem aktuellen Stand unserer derzeitigen Herangehensweise an die Probleme des verst√§rkten Lernens. Wenn Sie den Algorithmus intuitiv verstehen und wissen, wie er funktioniert, sollten Sie zumindest ein wenig entt√§uscht sein. Insbesondere wann funktioniert es nicht?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vergleichen Sie dies damit, wie eine Person lernen kann, Pong zu spielen. Sie selbst zeigen ihnen das Spiel und sagen etwas wie: ‚ÄûSie steuern den Schl√§ger und k√∂nnen ihn auf und ab bewegen. Ihre Aufgabe ist es, den Ball an einem anderen Spieler vorbei zu werfen, der vom integrierten Programm gesteuert wird.‚Äú Und Sie k√∂nnen loslegen. Bitte beachten Sie einige Unterschiede:</font></font><br><br><ul><li>         - , ,   ,     .     RL       ,        .       ,        (        ),       ,  .         .   ,          ,  ,  ,   ,            , ,   ,  . <br></li><li>      ,     ( ,    ,     ,      ..),    ( ¬´¬ª ¬´ ,  , ,    -  -  . .).      ¬´¬ª          / . ,     ,    (   )   (      ,    ). <br></li><li>    ‚Äî    (brute force),            ,       .              .       ,    ,           ,      .   ,     ¬´¬ª    ,        .   ,    ,         . <br></li><li>        ,    ,     .    ,             ,      .           . <br></li></ul><br><img src="https://habrastorage.org/webt/do/4a/ha/do4ahazbavg7xmlq-a5omrr77vq.png"><br><br> <i>:  :      RL.   ,  ,     .  ,    .     ,  99%        .  ,  ¬´¬ª   . :       ¬´¬ª,    ,  - , -  , -  ,     ,     .                 ¬´ ,      ¬ª.</i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich m√∂chte auch die Tatsache betonen, dass im Gegenteil in vielen Spielen die Gradienten der Politik eine Person ziemlich leicht besiegen w√ºrden. Dies gilt insbesondere f√ºr Spiele mit h√§ufigen Belohnungen, die eine genaue und schnelle Reaktion und ohne langfristige Planung erfordern. Kurzfristige Korrelationen zwischen Belohnungen und Aktionen k√∂nnen durch den PG-Ansatz leicht erkannt werden. Sie k√∂nnen √§hnliche in unserem Agenten Pong sehen. Er entwickelt eine Strategie, wenn er einfach auf den Ball wartet und sich dann schnell bewegt, um ihn nur am √§u√üersten Rand zu fangen, weshalb der Ball mit einer hohen vertikalen Geschwindigkeit springt. Der Agent gewinnt mehrere Siege hintereinander und wiederholt diese einfache Strategie. Es gibt viele Spiele (Flipper, Breakout), in denen Deep Q-Learning eine Person mit ihren einfachen und pr√§zisen Aktionen in den Schlamm zieht und trampelt.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sobald Sie den ‚ÄûTrick‚Äú verstanden haben, mit dem diese Algorithmen arbeiten, k√∂nnen Sie ihre St√§rken und Schw√§chen verstehen. Insbesondere sind diese Algorithmen weit hinter den Menschen zur√ºck, wenn es darum geht, abstrakte Ideen √ºber Spiele zu entwickeln, mit denen Menschen schnell lernen k√∂nnen. Sobald der Computer auf die Anordnung der Pixel schaut und den Schl√ºssel, die T√ºr, bemerkt und sich denkt, dass es wahrscheinlich sch√∂n w√§re, den Schl√ºssel zu nehmen und zur T√ºr zu gelangen. Derzeit gibt es nichts in der N√§he, und der Versuch, dorthin zu gelangen, ist ein aktives Forschungsgebiet. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nicht differenzierbare Berechnungen in neuronalen Netzen.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich m√∂chte eine weitere interessante Anwendung von Nicht-Gaming-Richtlinienverl√§ufen erw√§hnen: Sie erm√∂glicht es uns, neuronale Netze mithilfe von Komponenten zu entwerfen und zu trainieren, die mit nicht differenzierbarem Computing arbeiten (oder interagieren). Diese Idee wurde erstmals </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1992 von Williams eingef√ºhrt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . und wurde k√ºrzlich in </font><a href=""><font style="vertical-align: inherit;">wiederkehrenden visuellen Aufmerksamkeitsmodellen</font></a><font style="vertical-align: inherit;"> popul√§r gemacht </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wird im Kontext eines Modells, das ein Bild mit einer Folge von engen fovealen Blicken mit niedriger Aufl√∂sung verarbeitet, als ‚Äûenge Aufmerksamkeit‚Äú bezeichnet, √§hnlich wie unser Auge Objekte mit einer laufenden zentralen Sicht untersucht. Bei jeder Iteration empf√§ngt der RNN ein kleines Fragment des Bildes und w√§hlt den Ort aus, der weiter untersucht werden muss. Zum Beispiel kann der RNN die Position (5.30) betrachten, ein kleines Fragment des Bildes erhalten, sich dann f√ºr (24, 50) usw. entscheiden. Es gibt einen Abschnitt des neuronalen Netzwerks, der ausw√§hlt, wo weiter gesucht werden soll, und es dann inspiziert. Leider ist diese Operation nicht differenzierbar, da wir nicht wissen, was passieren w√ºrde, wenn wir anderswo eine Probe nehmen w√ºrden. Betrachten Sie in einem allgemeineren Fall ein neuronales Netzwerk mit mehreren Ein- und Ausg√§ngen:</font></font><br><br><img src="https://habrastorage.org/webt/xn/gn/ca/xngncauic38rgmg3bi_srnlevbw.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beachten Sie, dass die meisten blauen Pfeile wie gewohnt differenzierbar sind. Einige Ansichtstransformationen k√∂nnen jedoch auch eine undifferenzierte Auswahloperation enthalten, die rot hervorgehoben ist. Wir k√∂nnen einfach durch die blauen Pfeile in die entgegengesetzte Richtung gehen, aber der rote Pfeil ist eine Abh√§ngigkeit, durch die wir den Backprop nicht r√ºckw√§rts verbreiten k√∂nnen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gradientenpolitik zur Rettung! Lassen Sie uns √ºber den Teil des Netzwerks nachdenken, der die Abtastung durchf√ºhrt, die als Funktion der stochastischen Politik dargestellt werden kann, die in ein gro√ües neuronales Netzwerk eingebettet ist. Daher werden wir w√§hrend des Trainings mehrere Beispiele erstellen (angegeben durch die folgenden Zweige) und dann Proben ermutigen, die letztendlich zu guten Ergebnissen f√ºhren (in diesem Fall zum Beispiel gemessen an den Verlusten am Ende). Mit anderen Worten, wir werden die in den blauen Pfeilen enthaltenen Parameter wie gewohnt mit dem Backprop trainieren, aber die im roten Pfeil enthaltenen Parameter werden jetzt unabh√§ngig vom R√ºckw√§rtsdurchlauf mithilfe von Richtliniengradienten aktualisiert, wodurch Stichproben gef√∂rdert werden, die zu geringen Verlusten f√ºhren. Diese Idee wurde auch k√ºrzlich gut gerahmt.</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gradientensch√§tzung unter Verwendung stochastischer Berechnungsgraphen.</font></font></a> <br><br><img src="https://habrastorage.org/webt/td/vx/lr/tdvxlrd98jepxgmsvpc5gtewlxs.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Geschulte Ein- / Ausgabe im Direktzugriffsspeicher. Sie finden diese Idee auch in vielen anderen Artikeln. Zum Beispiel verf√ºgt die </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neural Turing Machine</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √ºber ein Speicherband, mit dem sie lesen und schreiben k√∂nnen. Um eine Schreiboperation auszuf√ºhren, m√ºssen Sie etwas wie m [i] = x ausf√ºhren, wobei i und x vom neuronalen RNN-Netzwerk vorhergesagt werden. Es gibt jedoch kein Signal, das uns sagt, was mit der Verlustfunktion passieren w√ºrde, wenn wir j schreiben w√ºrden! = I. Daher kann NTM weiche Lese- und Schreibvorg√§nge ausf√ºhren. Er sagt die Aufmerksamkeitsverteilungsfunktion a voraus und f√ºhrt dann f√ºr alle i: m [i] = a [i] * x aus. Es ist jetzt differenzierbar, aber wir m√ºssen einen hohen Rechenpreis zahlen, indem wir alle Zellen sortieren.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir k√∂nnen jedoch Richtlinienverl√§ufe verwenden, um dieses Problem theoretisch zu umgehen, wie dies in </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RL-NTM der Fall ist</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Wir sagen immer noch die Verteilung der Aufmerksamkeit a voraus, aber anstatt eine ersch√∂pfende Suche durchzuf√ºhren, w√§hlen wir zuf√§llig Orte zum Schreiben aus: i = Probe (a); m [i] = x. W√§hrend des Trainings k√∂nnten wir dies f√ºr einen kleinen Satz von i tun und am Ende einen Satz finden, der besser funktioniert als andere. Ein gro√üer Rechenvorteil besteht darin, dass Sie w√§hrend des Testens aus einer Zelle lesen / schreiben k√∂nnen. Wie im Dokument angegeben, ist es jedoch sehr schwierig, diese Strategie zur Arbeit zu bringen, da Sie viele Optionen durchlaufen und fast versehentlich zu Arbeitsalgorithmen wechseln m√ºssen. Derzeit sind sich die Forscher einig, dass PG nur dann gut funktioniert, wenn es mehrere diskrete Optionen gibt, wenn Sie keine gro√üen Suchr√§ume durchk√§mmen m√ºssen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mit Hilfe von Gradienten der Politik und in F√§llen, in denen eine gro√üe Menge an Daten und Rechenleistung verf√ºgbar ist, k√∂nnen wir im Prinzip von viel tr√§umen. Zum Beispiel k√∂nnen wir neuronale Netze entwerfen, die lernen, mit gro√üen nicht differenzierbaren Objekten wie Latex-Compilern zu interagieren. Zum Beispiel, damit char-rnn vorgefertigten Latexcode oder ein SLAM-System oder LQR-L√∂ser oder etwas anderes generiert. Oder Superintelligenz m√∂chte beispielsweise lernen, wie man √ºber TCP / IP (was auch nicht differenzierbar ist) mit dem Internet interagiert, um auf die Informationen zuzugreifen, die zur Erfassung der Welt erforderlich sind. Dies ist ein gro√üartiges Beispiel.</font></font><br><br><h4>  Schlussfolgerungen </h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben gesehen, dass Richtlinienverl√§ufe ein leistungsf√§higer allgemeiner Algorithmus sind, und als Beispiel haben wir den ATARI Pong-Agenten in </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">130 Python-Zeilen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> von Grund auf neu trainiert </font><font style="vertical-align: inherit;">. Im Allgemeinen kann derselbe Algorithmus verwendet werden, um Agenten f√ºr beliebige Spiele zu trainieren, und hoffentlich k√∂nnen wir ihn eines Tages verwenden, um Steuerungsprobleme in der realen Welt zu l√∂sen. Abschlie√üend m√∂chte ich noch einige Kommentare hinzuf√ºgen: </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√úber die Entwicklung der KI</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Wir haben gesehen, dass der Algorithmus mittels Brute-Force-Suche funktioniert, bei der Sie zun√§chst zuf√§llig z√∂gern und mindestens einmal und im Idealfall h√§ufig auf n√ºtzliche Situationen sto√üen m√ºssen, bevor die Richtlinienfunktion ihre Parameter √§ndert. Wir haben auch gesehen, dass eine Person diese L√∂sungen f√ºr diese Probleme auf eine v√∂llig andere Art und Weise angeht, die der schnellen Konstruktion eines abstrakten Modells √§hnelt. Da diese abstrakten Modelle nur sehr schwer (wenn nicht unm√∂glich) explizit vorstellbar sind, ist dies auch der Grund daf√ºr, dass in letzter Zeit so viel Interesse an generativen Modellen und Software-Induktion besteht. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√úber den Einsatz in der Robotik.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der Algorithmus wird nicht angewendet, wenn es schwierig ist, eine gro√üe Menge an Forschung zu erhalten. Sie k√∂nnen beispielsweise einen (oder mehrere) Roboter in Echtzeit mit der Welt interagieren lassen. Dies reicht f√ºr eine naive Anwendung des Algorithmus nicht aus. Ein Arbeitsbereich zur Minderung dieses Problems sind </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">deterministische politische Gradienten</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Anstatt echte Versuche zu unternehmen, erh√§lt dieser Ansatz Gradienteninformationen von einem zweiten neuronalen Netzwerk (als Kritiker bezeichnet), das die Bewertungsfunktion modelliert. Dieser Ansatz kann im Prinzip bei hochdimensionalen Aktionen effektiv sein, bei denen Zufallsstichproben eine schlechte Abdeckung bieten. Ein weiterer verwandter Ansatz besteht darin, die Robotik zu vergr√∂√üern, die wir in der </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google Robot Farm sehen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">oder vielleicht sogar auf einem </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tesla S + mit Autopilot.</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Es gibt auch eine Reihe von Arbeiten, die versuchen, den Suchprozess durch Hinzuf√ºgen zus√§tzlicher Kontrolle weniger hoffnungslos zu machen. In vielen praktischen F√§llen k√∂nnen Sie beispielsweise die anf√§ngliche Entwicklungsrichtung direkt von der Person erhalten. Zum Beispiel verwendet </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AlphaGo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> zuerst das Training mit einem Lehrer, um nur menschliche Handlungen vorherzusagen (z. B. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fernsteuerung des Roboters</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ausbildung</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Flugbahnoptimierung</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vollst√§ndige Richtliniensuche</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). Die daraus resultierende Richtlinie wird sp√§ter mithilfe von PG konfiguriert, um das eigentliche Ziel zu erreichen - das Spiel zu gewinnen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In einigen F√§llen gibt es m√∂glicherweise weniger Voreinstellungen (z. B. zur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fernsteuerung von Robotern</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ), und es gibt Methoden zur Verwendung dieser Daten </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vor dem Praktikum</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Wenn Personen keine spezifischen Daten oder Einstellungen angeben, k√∂nnen sie in einigen F√§llen auch durch Berechnung mit ziemlich teuren Optimierungsmethoden erhalten werden, beispielsweise durch </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Optimieren der Flugbahn</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in einem bekannten dynamischen Modell (wie F = ma in einem physikalischen Simulator) oder in F√§llen wenn ein ungef√§hres lokales Modell erstellt wird (wie aus einer vielversprechenden Struktur f√ºr die Suche nach verwalteten Richtlinien hervorgeht). </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√úber die Verwendung von PG in der Praxis.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich w√ºrde gerne mehr √ºber RNN sprechen. Ich denke, es scheint, dass RNNs magisch sind und automatisch Probleme im Zusammenhang mit beliebigen Sequenzen l√∂sen. Die Wahrheit ist, dass es schwierig sein kann, diese Modelle zum Laufen zu bringen. Sorgfalt und Erfahrung sind erforderlich sowie das Wissen, wann einfachere Methoden Ihnen zu 90% helfen k√∂nnen. Gleiches gilt f√ºr Richtlinienverl√§ufe. Sie funktionieren nicht einfach so automatisch: Sie m√ºssen viele Beispiele haben, sie k√∂nnen f√ºr immer trainieren, sie sind schwer zu debuggen, wenn sie nicht funktionieren. Sie sollten immer versuchen, mit einer kleinen Pistole zu schie√üen, bevor Sie nach Bazooka greifen. Beispielsweise sollte beim Verst√§rkungstraining immer zuerst die </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">Cross-Entropy-Methode (CEM)</font></a><font style="vertical-align: inherit;"> √ºberpr√ºft werden.</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, ein einfacher stochastischer ‚ÄûGuess and Check‚Äú -Ansatz, der von der Evolution inspiriert ist. Und wenn Sie darauf bestehen, Richtlinienverl√§ufe f√ºr Ihre Aufgabe auszuprobieren, stellen Sie sicher, dass Sie die spezifischen Tricks kennen. Starten Sie einfach und verwenden Sie eine PG-Option namens </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TRPO</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , die fast immer besser und konsistenter funktioniert </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">als klassisches PG</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Die Grundidee besteht darin, zu vermeiden, dass Einstellungen aktualisiert werden, die Ihre Richtlinie aufgrund der Verwendung des Kulbak-Leibler-Abstands zwischen der alten und der neuen Richtlinie zu stark √§ndern.</font></font><br><br>  Das ist alles!<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich hoffe, ich habe Ihnen eine Vorstellung davon gegeben, wo wir mit Reinforcement Learning sind, was die Probleme sind, und wenn Sie zur F√∂rderung von RL beitragen m√∂chten, lade ich Sie ein, dies in unserem </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenAI-Fitnessstudio</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> zu tun </font><font style="vertical-align: inherit;">:) Bis zum n√§chsten Mal!</font></font><br><br><hr><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrej Karpathy, </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Forscher, Entwickler, Direktor der Abteilung f√ºr KI und Autopilot Tesla </font></font><br><br> <i><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zus√§tzliche Informationen:</font></font></b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Deep Learning on Fingers- </font><font style="vertical-align: inherit;">Kurs </font><font style="vertical-align: inherit;">2018 </font></font><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://habr.com/de/post/414165/</font></font></a> <font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Deep Learning on Fingers </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Open Course 2019 </font></font><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https: // habr.com/ru/company/ods/blog/438940/</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Physikalische Fakult√§t der NSU </font></font><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">http://www.phys.nsu.ru/</font></font></a></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de439674/">https://habr.com/ru/post/de439674/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de439662/index.html">Ank√ºndigung von TypeScript 3.3</a></li>
<li><a href="../de439664/index.html">Bin√§re C ++ - Kompatibilit√§t und schmerzfreie Upgrades auf Visual Studio 2019</a></li>
<li><a href="../de439668/index.html">Skalieren eines Tech-Newsletters f√ºr 700.000 Abonnenten in 300 St√§dten: Die Geschichte von Techstars Startup Digest</a></li>
<li><a href="../de439670/index.html">Russisches KI-System zur Krebsdiagnose Botkin.AI. Jetzt auf dem Azure-Marktplatz</a></li>
<li><a href="../de439672/index.html">PowerShell-Grundlagen: Erkennen, ob eine Zeichenfolge mit einem bestimmten Zeichen endet</a></li>
<li><a href="../de439676/index.html">Reagieren Sie auf Native- und C ++ - Integration f√ºr iOS und Android</a></li>
<li><a href="../de439678/index.html">Senden Sie an die Applied F # Challenge</a></li>
<li><a href="../de439680/index.html">Etwa 50% der Russen sind bereit, ihre pers√∂nlichen Daten zu verkaufen</a></li>
<li><a href="../de439682/index.html">Schulung Cisco 200-125 CCNA v3.0. Cisco Certified Network Specialist (CCNA). Tag 4. Gateway-Ger√§te</a></li>
<li><a href="../de439684/index.html">Bewerben Sie sich f√ºr die Applied F # Challenge</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
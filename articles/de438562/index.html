<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª‚Äçüè´ ü§ñ üë©üèΩ‚Äçüç≥ XGBoost von Grund auf neu schreiben - Teil 2: Gradientenverst√§rkung üëâüèº üçê ü§∂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo allerseits! 

 Im letzten Artikel haben wir herausgefunden, wie Entscheidungsb√§ume angeordnet sind, und von Grund auf neu implementiert 
 Konstr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>XGBoost von Grund auf neu schreiben - Teil 2: Gradientenverst√§rkung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/438562/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/ll/lb/oe/lllboex0ltvh9n7kpkfomxfz_p8.jpeg"></div><br>  Hallo allerseits! <br><br>  Im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">letzten Artikel haben</a> wir herausgefunden, wie Entscheidungsb√§ume angeordnet sind, und von Grund auf neu implementiert <br>  Konstruktionsalgorithmus, der gleichzeitig optimiert und verbessert wird.  In diesem Artikel werden wir den Gradientenverst√§rkungsalgorithmus implementieren und am Ende unseren eigenen XGBoost erstellen.  Die Erz√§hlung folgt demselben Muster: Wir schreiben einen Algorithmus, beschreiben ihn und fassen ihn zusammen, indem wir die Ergebnisse der Arbeit mit Analoga von Sklearn vergleichen. <br><br>  In diesem Artikel wird der Schwerpunkt auch auf die Implementierung in Code gelegt. Daher ist es besser, die gesamte Theorie zusammen in einer anderen zu lesen (z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im ODS-Kurs</a> ). <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wenn</a> Sie die Theorie bereits kennen, k√∂nnen Sie mit diesem Artikel fortfahren, da das Thema ziemlich kompliziert ist. <br><br><img src="https://habrastorage.org/webt/l0/vy/cx/l0vycx4dsrrohxafyliapuq7nxi.png"><br><a name="habracut"></a><br>  Was ist Gradientenverst√§rkung?  Ein Bild eines Golfspielers beschreibt die Hauptidee perfekt.  Um den Ball in das Loch zu treiben, macht der Golfer bei jedem n√§chsten Schlag die Erfahrung fr√ºherer Schl√§ge - f√ºr ihn ist dies eine notwendige Voraussetzung, um den Ball in das Loch zu legen.  Wenn es sehr unh√∂flich ist (ich bin kein Meister des Golfsports :)), dann ist bei jedem neuen Schlag das erste, was ein Golfer betrachtet, der Abstand zwischen dem Ball und dem Loch nach dem vorherigen Schlag.  Und die Hauptaufgabe ist es, diesen Abstand beim n√§chsten Schlag zu verringern. <br><br>  Boosting ist sehr √§hnlich aufgebaut.  Zun√§chst m√ºssen wir die Definition von ‚ÄûLoch‚Äú einf√ºhren, dh das Ziel, das wir anstreben werden.  Zweitens m√ºssen wir lernen zu verstehen, welche Mannschaft wir mit einem Verein schlagen m√ºssen, um n√§her an das Ziel heranzukommen.  Drittens m√ºssen Sie unter Ber√ºcksichtigung all dieser Regeln die richtige Reihenfolge der Schl√§ge festlegen, damit jeder nachfolgende den Abstand zwischen dem Ball und dem Loch verringert. <br><br>  Jetzt geben wir eine etwas strengere Definition.  Wir f√ºhren das Modell der gewichteten Abstimmung ein: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2">h</span><span class="MJXp-mo" id="MJXp-Span-3" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-4">x</span><span class="MJXp-mo" id="MJXp-Span-5" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-6" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-7">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-8">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-9">u</span><span class="MJXp-msubsup" id="MJXp-Span-10"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-11" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-16">n</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-12"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-13">i</span><span class="MJXp-mo" id="MJXp-Span-14">=</span><span class="MJXp-mn" id="MJXp-Span-15">1</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-17"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-18" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-19" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-msubsup" id="MJXp-Span-20"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-21" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-22" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-23" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24">x</span><span class="MJXp-mtext" id="MJXp-Span-25">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-26">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-27">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-28">X</span><span class="MJXp-mo" id="MJXp-Span-29" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-30"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-31" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-32" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mtext" id="MJXp-Span-33">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-34">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-35">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-36">R</span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="33.839ex" height="2.901ex" viewBox="0 -832 14569.5 1249" role="img" focusable="false" style="vertical-align: -0.969ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-68" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMAIN-28" x="576" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-78" x="966" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMAIN-29" x="1538" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMAIN-3D" x="2205" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-73" x="3512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-75" x="3981" y="0"></use><g transform="translate(4554,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-6E" x="1242" y="499"></use><g transform="translate(878,-308)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-69" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMAIN-3D" x="345" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMAIN-31" x="1124" y="0"></use></g></g><g transform="translate(6681,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-62" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-69" x="607" y="-213"></use></g><g transform="translate(7455,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-69" x="748" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMAIN-2C" x="8328" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-78" x="8774" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-69" x="9596" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-6E" x="9942" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-58" x="10542" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMAIN-2C" x="11395" y="0"></use><g transform="translate(11840,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-62" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-69" x="607" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-69" x="12864" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-6E" x="13209" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/mailru/blog/438562/&amp;usg=ALkJrhj-MkaXBfRGFH2134PGSH0kpRZMfw#MJMATHI-52" x="13810" y="0"></use></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> h (x) = \ sum_ {i = 1} ^ nb_ia_i, x \ in X, b_i \ in R </script></p><br>  Hier <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-37"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-38">X</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-2"> X </script>  Ist der Raum, aus dem wir Objekte nehmen, <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-39"><span class="MJXp-msubsup" id="MJXp-Span-40"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-41" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-42" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-43" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-44"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-45" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-46" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-3"> b_i, a_i </script>  - Dies ist der Koeffizient vor dem Modell und das Modell selbst, dh der Entscheidungsbaum.  Angenommen, es war bereits zu einem bestimmten Zeitpunkt unter Verwendung der beschriebenen Regeln m√∂glich, die Komposition zu erg√§nzen <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-47"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48">T</span><span class="MJXp-mo" id="MJXp-Span-49" style="margin-left: 0.267em; margin-right: 0.267em;">‚àí</span><span class="MJXp-mn" id="MJXp-Span-50">1</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-4"> T-1 </script>  schwacher Algorithmus.  Zu lernen zu verstehen, welche Art von Algorithmus im Schritt sein sollte <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-51"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-52">T</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-5"> T </script>  f√ºhren wir die Fehlerfunktion ein: <br><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-53"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-54">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-55">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-56">r</span><span class="MJXp-mo" id="MJXp-Span-57" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-58">h</span><span class="MJXp-mo" id="MJXp-Span-59" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-60" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-61">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-62">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-63">u</span><span class="MJXp-msubsup" id="MJXp-Span-64"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-65" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-70">N</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-66"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-67">j</span><span class="MJXp-mo" id="MJXp-Span-68">=</span><span class="MJXp-mn" id="MJXp-Span-69">1</span></span></span></span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-71">L</span><span class="MJXp-mo" id="MJXp-Span-72" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-73">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-74">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-75">u</span><span class="MJXp-msubsup" id="MJXp-Span-76"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-77" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-82"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-83">T</span><span class="MJXp-mo" id="MJXp-Span-84">‚àí</span><span class="MJXp-mn" id="MJXp-Span-85">1</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-78"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-79">i</span><span class="MJXp-mo" id="MJXp-Span-80">=</span><span class="MJXp-mn" id="MJXp-Span-81">1</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-86"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-87" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-88" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-msubsup" id="MJXp-Span-89"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-90" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-91" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-92" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-93"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-94" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-95" style="vertical-align: -0.4em;">j</span></span><span class="MJXp-mo" id="MJXp-Span-96" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-97" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-98"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-99" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-100" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-msubsup" id="MJXp-Span-101"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-102" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-103" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-mo" id="MJXp-Span-104" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-105"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-106" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-107" style="vertical-align: -0.4em;">j</span></span><span class="MJXp-mo" id="MJXp-Span-108" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-109" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mtext" id="MJXp-Span-110">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-111">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-112">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-113">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-114">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-115">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-116">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-117">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-118">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-119">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-120">w</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-121">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-122">i</span><span class="MJXp-msubsup" id="MJXp-Span-123"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-124" style="margin-right: 0.05em;">n</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-125" style="vertical-align: -0.4em;"><span class="MJXp-msubsup" id="MJXp-Span-126"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-127" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-128" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-mo" id="MJXp-Span-129">,</span><span class="MJXp-msubsup" id="MJXp-Span-130"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-131" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-132" style="vertical-align: -0.4em;">T</span></span></span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-6"> err (h) = \ sum_ {j = 1} ^ N L (\ sum_ {i = 1} ^ {T-1} a_ib_i (x_j) + b_Ta_T (x_j)) \ rightarrow min_ {a_T, b_T} </script><br><br>  Es stellt sich heraus, dass der beste Algorithmus derjenige ist, der den bei fr√ºheren Iterationen empfangenen Fehler minimieren kann.  Und da die Verst√§rkung ein Gradient ist, muss diese Fehlerfunktion notwendigerweise einen Antigradientenvektor haben, entlang dem Sie sich auf der Suche nach einem Minimum bewegen k√∂nnen.  Das ist alles! <br><br>  Unmittelbar vor der Implementierung werde ich ein paar Worte dazu hinzuf√ºgen, wie alles mit uns arrangiert wird.  Wie im vorherigen Artikel nehmen wir MSE als Verlust.  Berechnen wir den Gradienten: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-133"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-134">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-135">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-136">e</span><span class="MJXp-mo" id="MJXp-Span-137" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-138">y</span><span class="MJXp-mo" id="MJXp-Span-139" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-140">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-141">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-142">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-143">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-144">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-145">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-146">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-147">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-148">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-149">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-150">n</span><span class="MJXp-mo" id="MJXp-Span-151" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-152" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-153" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-154">y</span><span class="MJXp-mo" id="MJXp-Span-155" style="margin-left: 0.267em; margin-right: 0.267em;">‚àí</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-156">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-157">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-158">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-159">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-160">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-161">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-162">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-163">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-164">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-165">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-166">n</span><span class="MJXp-msubsup" id="MJXp-Span-167"><span class="MJXp-mo" id="MJXp-Span-168" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-169" style="vertical-align: 0.5em;">2</span></span><span class="MJXp-mspace" id="MJXp-Span-170" style="width: 0em; height: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-171">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-172">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-173">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-174">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-175">l</span><span class="MJXp-msubsup" id="MJXp-Span-176"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-177" style="margin-right: 0.05em;">a</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-178" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-179">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-180">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-181">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-182">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-183">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-184">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-185">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-186">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-187">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-188">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-189">n</span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-190">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-191">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-192">e</span><span class="MJXp-mo" id="MJXp-Span-193" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-194">y</span><span class="MJXp-mo" id="MJXp-Span-195" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-196">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-197">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-198">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-199">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-200">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-201">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-202">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-203">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-204">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-205">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-206">n</span><span class="MJXp-mo" id="MJXp-Span-207" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-208" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-209">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-210">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-211">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-212">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-213">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-214">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-215">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-216">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-217">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-218">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-219">n</span><span class="MJXp-mo" id="MJXp-Span-220" style="margin-left: 0.267em; margin-right: 0.267em;">‚àí</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-221">y</span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-7"> mse (y, vorhersagen) = (y - vorhersagen) ^ 2 \\ \ nabla_ {vorhersagen} mse (y, vorhersagen) = vorhersagen - y </script></p><br>  Somit ist der Antigradientenvektor gleich <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-222"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-223">y</span><span class="MJXp-mo" id="MJXp-Span-224" style="margin-left: 0.267em; margin-right: 0.267em;">‚àí</span><span class="MJXp-mrow" id="MJXp-Span-225"><span class="MJXp-mo" id="MJXp-Span-226" style="margin-left: 0em; margin-right: 0em;">$</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-227">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-228">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-229">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-230">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-231">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-232">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-233">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-234">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-235">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-236">e</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-8"> y - $ vorhersage</script>  .  Auf dem Schritt <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-237"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-238">i</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-9"> i </script>  Wir betrachten die Fehler des Algorithmus, die bei fr√ºheren Iterationen erhalten wurden.  Als n√§chstes trainieren wir unseren neuen Algorithmus auf diese Fehler und f√ºgen ihn dann mit einem Minuszeichen und einem Koeffizienten zu unserem Ensemble hinzu. <br><br>  Jetzt fangen wir an. <br><br><h3>  1. Implementierung der √ºblichen Gradientenverst√§rkungsklasse </h3><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm_notebook <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datasets <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mean_squared_error <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> mse <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.tree <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> DecisionTreeRegressor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools %matplotlib inline %load_ext Cython %%cython -a <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np cimport numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> * cdef <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RegressionTreeFastMse</span></span></span><span class="hljs-class">:</span></span> cdef public int max_depth cdef public int feature_idx cdef public int min_size cdef public int averages cdef public np.float64_t feature_threshold cdef public np.float64_t value cpdef RegressionTreeFastMse left cpdef RegressionTreeFastMse right <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, max_depth=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">, min_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">4</span></span></span></span><span class="hljs-function"><span class="hljs-params">, averages=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> self.max_depth = max_depth self.min_size = min_size self.value = <span class="hljs-number"><span class="hljs-number">0</span></span> self.feature_idx = <span class="hljs-number"><span class="hljs-number">-1</span></span> self.feature_threshold = <span class="hljs-number"><span class="hljs-number">0</span></span> self.left = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.right = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, np.ndarray[np.float64_t, ndim=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">2</span></span></span></span><span class="hljs-function"><span class="hljs-params">] X, np.ndarray[np.float64_t, ndim=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span><span class="hljs-function"><span class="hljs-params">] y)</span></span></span><span class="hljs-function">:</span></span> cpdef np.float64_t mean1 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.float64_t mean2 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef long N = X.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] cpdef long N1 = X.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] cpdef long N2 = <span class="hljs-number"><span class="hljs-number">0</span></span> cpdef np.float64_t delta1 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.float64_t delta2 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.float64_t sm1 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.float64_t sm2 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef list index_tuples cpdef list stuff cpdef long idx = <span class="hljs-number"><span class="hljs-number">0</span></span> cpdef np.float64_t prev_error1 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.float64_t prev_error2 = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef long thres = <span class="hljs-number"><span class="hljs-number">0</span></span> cpdef np.float64_t error = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.ndarray[long, ndim=<span class="hljs-number"><span class="hljs-number">1</span></span>] idxs cpdef np.float64_t x = <span class="hljs-number"><span class="hljs-number">0.0</span></span> <span class="hljs-comment"><span class="hljs-comment">#   -   y self.value = y.mean() #   - mse     base_error = ((y - self.value) ** 2).sum() error = base_error flag = 0 #     if self.max_depth &lt;= 1: return dim_shape = X.shape[1] left_value, right_value = 0, 0 for feat in range(dim_shape): prev_error1, prev_error2 = base_error, 0 idxs = np.argsort(X[:, feat]) #      mean1, mean2 = y.mean(), 0 sm1, sm2 = y.sum(), 0 N = X.shape[0] N1, N2 = N, 0 thres = 1 while thres &lt; N - 1: N1 -= 1 N2 += 1 idx = idxs[thres] x = X[idx, feat] #   -  ,  ,    delta1 = (sm1 - y[idx]) * 1.0 / N1 - mean1 delta2 = (sm2 + y[idx]) * 1.0 / N2 - mean2 #   sm1 -= y[idx] sm2 += y[idx] #    O(1) prev_error1 += (delta1**2) * N1 prev_error1 -= (y[idx] - mean1)**2 prev_error1 -= 2 * delta1 * (sm1 - mean1 * N1) mean1 = sm1/N1 prev_error2 += (delta2**2) * N2 prev_error2 += (y[idx] - mean2)**2 prev_error2 -= 2 * delta2 * (sm2 - mean2 * N2) mean2 = sm2/N2 #       if thres &lt; N - 1 and np.abs(x - X[idxs[thres + 1], feat]) &lt; 1e-5: thres += 1 continue if (prev_error1 + prev_error2 &lt; error): if (min(N1,N2) &gt; self.min_size): #         self.feature_idx, self.feature_threshold = feat, x #     left_value, right_value = mean1, mean2 #  -     flag = 1 error = prev_error1 + prev_error2 thres += 1 #   ,  if self.feature_idx == -1: return #    self.left = RegressionTreeFastMse(self.max_depth - 1) self.left.value = left_value self.right = RegressionTreeFastMse(self.max_depth - 1) self.right.value = right_value #      idxs_l = (X[:, self.feature_idx] &gt; self.feature_threshold) idxs_r = (X[:, self.feature_idx] &lt;= self.feature_threshold) #   self.left.fit(X[idxs_l, :], y[idxs_l]) self.right.fit(X[idxs_r, :], y[idxs_r]) def __predict(self, np.ndarray[np.float64_t, ndim=1] x): if self.feature_idx == -1: return self.value if x[self.feature_idx] &gt; self.feature_threshold: return self.left.__predict(x) else: return self.right.__predict(x) def predict(self, np.ndarray[np.float64_t, ndim=2] X): y = np.zeros(X.shape[0]) for i in range(X.shape[0]): y[i] = self.__predict(X[i]) return y</span></span></code> </pre> <br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">GradientBoosting</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, n_estimators=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">100</span></span></span></span><span class="hljs-function"><span class="hljs-params">, learning_rate=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, max_depth=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">, random_state=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">17</span></span></span></span><span class="hljs-function"><span class="hljs-params">, n_samples = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">15</span></span></span></span><span class="hljs-function"><span class="hljs-params">, min_size = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">, base_tree=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'Bagging'</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> self.n_estimators = n_estimators self.max_depth = max_depth self.learning_rate = learning_rate self.initialization = <span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> y: np.mean(y) * np.ones([y.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]]) self.min_size = min_size self.loss_by_iter = [] self.trees_ = [] self.loss_by_iter_test = [] self.n_samples = n_samples self.base_tree = base_tree <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, X, y)</span></span></span><span class="hljs-function">:</span></span> self.X = X self.y = y b = self.initialization(y) prediction = b.copy() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm_notebook(range(self.n_estimators)): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> t == <span class="hljs-number"><span class="hljs-number">0</span></span>: resid = y <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-comment"><span class="hljs-comment">#    resid = (y - prediction) #    if self.base_tree == 'Bagging': tree = Bagging(max_depth=self.max_depth, min_size = self.min_size) if self.base_tree == 'Tree': tree = RegressionTreeFastMse(max_depth=self.max_depth, min_size = self.min_size) #     tree.fit(X, resid) #        b = tree.predict(X).reshape([X.shape[0]]) self.trees_.append(tree) prediction += self.learning_rate * b #       if t &gt; 0: self.loss_by_iter.append(mse(y,prediction)) return self def predict(self, X): #   ‚Äì          pred = np.ones([X.shape[0]]) * np.mean(self.y) #    for t in range(self.n_estimators): pred += self.learning_rate * self.trees_[t].predict(X).reshape([X.shape[0]]) return pred</span></span></code> </pre><br>  Wir werden nun die Verlustkurve auf dem Trainingssatz erstellen, um sicherzustellen, dass wir bei jeder Iteration wirklich eine Abnahme haben. <br><br><pre> <code class="python hljs">GDB = GradientBoosting(n_estimators=<span class="hljs-number"><span class="hljs-number">50</span></span>) GDB.fit(X,y) x = GDB.predict(X) plt.grid() plt.title(<span class="hljs-string"><span class="hljs-string">'Loss by iterations'</span></span>) plt.plot(GDB.loss_by_iter)</code> </pre> <br><img src="https://habrastorage.org/webt/je/2u/dp/je2udpxa0zdsvsmjqk4mmwmprlo.png"><br><br><h3>  2. √úber entscheidende B√§ume sacken </h3><br>  Bevor wir die Ergebnisse vergleichen, lassen Sie uns √ºber das Verfahren zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Absacken</a> von B√§umen sprechen. <br><br>  Hier ist alles einfach: Wir wollen uns vor Umschulungen sch√ºtzen und werden daher mit Hilfe von Stichproben mit R√ºckgabe unsere Vorhersagen mitteln, um nicht versehentlich auf Emissionen zu sto√üen (warum dies funktioniert - lesen Sie besser den Link). <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Bagging</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-string"><span class="hljs-string">'''  Bagging -      . '''</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, max_depth = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">, min_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10</span></span></span></span><span class="hljs-function"><span class="hljs-params">, n_samples = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#super(CART, self).__init__() self.max_depth = max_depth self.min_size = min_size self.n_samples = n_samples self.subsample_size = None self.list_of_Carts = [RegressionTreeFastMse(max_depth=self.max_depth, min_size=self.min_size) for _ in range(self.n_samples)] def get_bootstrap_samples(self, data_train, y_train): #      indices = np.random.randint(0, len(data_train), (self.n_samples, self.subsample_size)) samples_train = data_train[indices] samples_y = y_train[indices] return samples_train, samples_y def fit(self, data_train, y_train): #    self.subsample_size = int(data_train.shape[0]) samples_train, samples_y = self.get_bootstrap_samples(data_train, y_train) for i in range(self.n_samples): self.list_of_Carts[i].fit(samples_train[i], samples_y[i].reshape(-1)) return self def predict(self, test_data): #        num_samples = test_data.shape[0] pred = [] for i in range(self.n_samples): pred.append(self.list_of_Carts[i].predict(test_data)) pred = np.array(pred).T return np.array([np.mean(pred[i]) for i in range(num_samples)])</span></span></code> </pre><br>  Nun, als grundlegender Algorithmus k√∂nnen wir nicht nur einen Baum verwenden, sondern von B√§umen einsacken - also werden wir uns wieder vor Umschulungen sch√ºtzen. <br><br><h3>  3. Ergebnisse </h3><br>  Vergleichen Sie die Ergebnisse unserer Algorithmen. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> KFold <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GradientBoostingRegressor <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> GDBSklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> copy <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_metrics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(X,y,n_folds=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, model=None)</span></span></span><span class="hljs-function">:</span></span> kf = KFold(n_splits=n_folds, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) kf.get_n_splits(X) er_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> train_index, test_index <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm_notebook(kf.split(X)): X_train, X_test = X[train_index], X[test_index] y_train, y_test = y[train_index], y[test_index] model.fit(X_train,y_train) predict = model.predict(X_test) er_list.append(mse(y_test, predict)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> er_list data = datasets.fetch_california_housing() X = np.array(data.data) y = np.array(data.target) er_boosting = get_metrics(X,y,<span class="hljs-number"><span class="hljs-number">30</span></span>,GradientBoosting(max_depth=<span class="hljs-number"><span class="hljs-number">3</span></span>, n_estimators=<span class="hljs-number"><span class="hljs-number">40</span></span>, base_tree=<span class="hljs-string"><span class="hljs-string">'Tree'</span></span> )) er_boobagg = get_metrics(X,y,<span class="hljs-number"><span class="hljs-number">30</span></span>,GradientBoosting(max_depth=<span class="hljs-number"><span class="hljs-number">3</span></span>, n_estimators=<span class="hljs-number"><span class="hljs-number">40</span></span>, base_tree=<span class="hljs-string"><span class="hljs-string">'Bagging'</span></span> )) er_sklearn_boosting = get_metrics(X,y,<span class="hljs-number"><span class="hljs-number">30</span></span>,GDBSklearn(max_depth=<span class="hljs-number"><span class="hljs-number">3</span></span>,n_estimators=<span class="hljs-number"><span class="hljs-number">40</span></span>, learning_rate=<span class="hljs-number"><span class="hljs-number">0.1</span></span>)) %matplotlib inline data = [er_sklearn_boosting, er_boosting, er_boobagg] fig7, ax7 = plt.subplots() ax7.set_title(<span class="hljs-string"><span class="hljs-string">''</span></span>) ax7.boxplot(data, labels=[<span class="hljs-string"><span class="hljs-string">'Sklearn Boosting'</span></span>, <span class="hljs-string"><span class="hljs-string">'Boosting'</span></span>, <span class="hljs-string"><span class="hljs-string">'BooBag'</span></span>]) plt.grid() plt.show()</code> </pre> <br>  Erhalten: <br><br><img src="https://habrastorage.org/webt/rd/ih/nb/rdihnby6vylrk7azxytowqvb5uu.png"><br><br>  Wir k√∂nnen das Analogon von Sklearn noch nicht besiegen, da wir wiederum nicht viele Parameter ber√ºcksichtigen, die bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieser Methode verwendet werden</a> .  Wir sehen jedoch, dass das Absacken ein wenig hilft. <br><br>  Lassen Sie uns nicht verzweifeln und XGBoost schreiben. <br><br><h3>  4. XGBoost </h3><br>  Bevor Sie weiterlesen, empfehle ich Ihnen dringend, sich zun√§chst mit dem n√§chsten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Video</a> vertraut zu machen, das die Theorie sehr gut erkl√§rt. <br><br>  Erinnern Sie sich daran, welchen Fehler wir beim normalen Boosten minimieren: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-239"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-240">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-241">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-242">r</span><span class="MJXp-mo" id="MJXp-Span-243" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-244">h</span><span class="MJXp-mo" id="MJXp-Span-245" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-246" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-247">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-248">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-249">u</span><span class="MJXp-msubsup" id="MJXp-Span-250"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-251" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-256">N</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-252"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-253">j</span><span class="MJXp-mo" id="MJXp-Span-254">=</span><span class="MJXp-mn" id="MJXp-Span-255">1</span></span></span></span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-257">L</span><span class="MJXp-mo" id="MJXp-Span-258" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-259">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-260">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-261">u</span><span class="MJXp-msubsup" id="MJXp-Span-262"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-263" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-268"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-269">T</span><span class="MJXp-mo" id="MJXp-Span-270">‚àí</span><span class="MJXp-mn" id="MJXp-Span-271">1</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-264"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-265">i</span><span class="MJXp-mo" id="MJXp-Span-266">=</span><span class="MJXp-mn" id="MJXp-Span-267">1</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-272"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-273" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-274" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-msubsup" id="MJXp-Span-275"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-276" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-277" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-278" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-279"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-280" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-281" style="vertical-align: -0.4em;">j</span></span><span class="MJXp-mo" id="MJXp-Span-282" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-283" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-284"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-285" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-286" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-msubsup" id="MJXp-Span-287"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-288" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-289" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-mo" id="MJXp-Span-290" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-291"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-292" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-293" style="vertical-align: -0.4em;">j</span></span><span class="MJXp-mo" id="MJXp-Span-294" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-295" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-10"> err (h) = \ sum_ {j = 1} ^ N L (\ sum_ {i = 1} ^ {T-1} a_ib_i (x_j) + b_Ta_T (x_j)) </script></p><br>  XGBoost f√ºgt dieser Fehlerfunktionalit√§t explizit eine Regularisierung hinzu: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-296"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-297">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-298">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-299">r</span><span class="MJXp-mo" id="MJXp-Span-300" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-301">h</span><span class="MJXp-mo" id="MJXp-Span-302" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-303" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-304">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-305">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-306">u</span><span class="MJXp-msubsup" id="MJXp-Span-307"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-308" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-313">N</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-309"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-310">j</span><span class="MJXp-mo" id="MJXp-Span-311">=</span><span class="MJXp-mn" id="MJXp-Span-312">1</span></span></span></span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-314">L</span><span class="MJXp-mo" id="MJXp-Span-315" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-316">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-317">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-318">u</span><span class="MJXp-msubsup" id="MJXp-Span-319"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-320" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-325"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-326">T</span><span class="MJXp-mo" id="MJXp-Span-327">‚àí</span><span class="MJXp-mn" id="MJXp-Span-328">1</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-321"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-322">i</span><span class="MJXp-mo" id="MJXp-Span-323">=</span><span class="MJXp-mn" id="MJXp-Span-324">1</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-329"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-330" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-331" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-msubsup" id="MJXp-Span-332"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-333" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-334" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-335" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-336"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-337" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-338" style="vertical-align: -0.4em;">j</span></span><span class="MJXp-mo" id="MJXp-Span-339" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-340" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-341"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-342" style="margin-right: 0.05em;">b</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-343" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-msubsup" id="MJXp-Span-344"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-345" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-346" style="vertical-align: -0.4em;">T</span></span><span class="MJXp-mo" id="MJXp-Span-347" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-348"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-349" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-350" style="vertical-align: -0.4em;">j</span></span><span class="MJXp-mo" id="MJXp-Span-351" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-352" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-353" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mtext" id="MJXp-Span-354">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-355">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-356">u</span><span class="MJXp-msubsup" id="MJXp-Span-357"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-358" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-363">T</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-359"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-360">i</span><span class="MJXp-mo" id="MJXp-Span-361">=</span><span class="MJXp-mn" id="MJXp-Span-362">1</span></span></span></span></span></span></span><span class="MJXp-mtext" id="MJXp-Span-364">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-365">O</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-366">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-367">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-368">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-369">a</span><span class="MJXp-mo" id="MJXp-Span-370" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-371"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-372" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-373" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-374" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-11-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-11"> err (h) = \ sum_ {j = 1} ^ NL (\ sum_ {i = 1} ^ {T-1} a_ib_i (x_j) + b_Ta_T (x_j)) + \ sum_ {i = 1} ^ T \ Omega (a_i) </script></p><br>  Wie ist diese Funktionalit√§t zu ber√ºcksichtigen?  Zuerst approximieren wir es mit Hilfe einer Taylor-Reihe zweiter Ordnung, wobei der neue Algorithmus als Inkrement betrachtet wird, entlang dessen wir uns bewegen werden, und dann malen wir bereits, je nachdem, welche Art von Verlust wir haben: <br><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-428"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-429">f</span><span class="MJXp-mo" id="MJXp-Span-430" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-431">x</span><span class="MJXp-mo" id="MJXp-Span-432" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mtext" id="MJXp-Span-433">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-434">D</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-435">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-436">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-437">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-438">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-439">x</span><span class="MJXp-mo" id="MJXp-Span-440" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mtext" id="MJXp-Span-441">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-442">D</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-443">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-444">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-445">k</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-446">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-447">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-448">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-449">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-450">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-451">x</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-452">f</span><span class="MJXp-mo" id="MJXp-Span-453" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-454">x</span><span class="MJXp-mo" id="MJXp-Span-455" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-456" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-457">f</span><span class="MJXp-mo" id="MJXp-Span-458" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-459">x</span><span class="MJXp-msup" id="MJXp-Span-460"><span class="MJXp-mo" id="MJXp-Span-461" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-462" style="vertical-align: 0.5em;">‚Ä≤</span></span><span class="MJXp-mtext" id="MJXp-Span-463">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-464">D</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-465">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-466">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-467">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-468">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-469">x</span><span class="MJXp-mo" id="MJXp-Span-470" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mn" id="MJXp-Span-471">0</span><span class="MJXp-mo" id="MJXp-Span-472" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mn" id="MJXp-Span-473">5</span><span class="MJXp-mo" id="MJXp-Span-474" style="margin-left: 0.267em; margin-right: 0.267em;">‚àó</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-475">f</span><span class="MJXp-mo" id="MJXp-Span-476" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-477">x</span><span class="MJXp-msup" id="MJXp-Span-478"><span class="MJXp-mo" id="MJXp-Span-479" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mo MJXp-script" id="MJXp-Span-480" style="vertical-align: 0.5em;">‚Ä≥</span></span><span class="MJXp-mo" id="MJXp-Span-481" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-482">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-483">D</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-484">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-485">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-486">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-487">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-488">x</span><span class="MJXp-msubsup" id="MJXp-Span-489"><span class="MJXp-mo" id="MJXp-Span-490" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-491" style="vertical-align: 0.5em;">2</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-12"> f (x + \ Delta x) \ Dickapprox f (x) + f (x) '\ Delta x + 0,5 * f (x)' '(\ Delta x) ^ 2 </script><br><br>  Es ist notwendig zu bestimmen, welchen Baum wir als schlecht und welchen als gut betrachten. <br><br>  Erinnern Sie sich daran, nach welchem ‚Äã‚ÄãPrinzip die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Regression aufgebaut</a> ist <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-492"><span class="MJXp-msubsup" id="MJXp-Span-493"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-494" style="margin-right: 0.05em;">L</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-495" style="vertical-align: -0.4em;">2</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-13-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-13"> L_2 </script>  -regelm√§√üigkeit - Je normaler die Werte der Koeffizienten vor der Regression sind, desto schlechter ist es daher, dass sie so klein wie m√∂glich sind. <br><br>  In XGBoost ist die Idee sehr √§hnlich: Ein Baum wird mit einer Geldstrafe belegt, wenn die Summe der Norm der Werte in den Bl√§ttern darin sehr gro√ü ist.  Daher wird die Komplexit√§t des Baums wie folgt eingef√ºhrt: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-496"><span class="MJXp-mtext" id="MJXp-Span-497">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-498">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-499">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-500">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-501">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-502">a</span><span class="MJXp-mo" id="MJXp-Span-503" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-504">a</span><span class="MJXp-mo" id="MJXp-Span-505" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-506" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-507">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-508">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-509">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-510">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-511">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-512">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-513">Z</span><span class="MJXp-mo" id="MJXp-Span-514" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mn" id="MJXp-Span-515">0</span><span class="MJXp-mo" id="MJXp-Span-516" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mn" id="MJXp-Span-517">5</span><span class="MJXp-mo" id="MJXp-Span-518" style="margin-left: 0.267em; margin-right: 0.267em;">‚àó</span><span class="MJXp-mtext" id="MJXp-Span-519">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-520">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-521">u</span><span class="MJXp-msubsup" id="MJXp-Span-522"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-523" style="margin-right: 0.05em;">m</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mrow" id="MJXp-Span-528"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-529">Z</span></span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-524"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-525">i</span><span class="MJXp-mo" id="MJXp-Span-526">=</span><span class="MJXp-mn" id="MJXp-Span-527">1</span></span></span></span></span></span></span><span class="MJXp-msubsup" id="MJXp-Span-530"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-531" style="margin-right: 0.05em;">w</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-533">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-532">i</span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-14-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-14"> \ omega (a) = \ gamma Z + 0,5 * \ sum_ {i = 1} ^ {Z} w_i ^ 2 </script></p><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-534"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-535">w</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-15-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-15"> w </script>  - Werte in den Bl√§ttern, <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-536"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-537">Z</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-16-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-16"> Z </script>  - Anzahl der Bl√§tter. <br><br>  Das Video enth√§lt √úbergangsformeln. Wir werden sie hier nicht anzeigen.  Es kommt alles auf die Tatsache an, dass wir eine neue Partition ausw√§hlen, um den Gewinn zu maximieren: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-538"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-539">G</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-540">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-541">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-542">n</span><span class="MJXp-mo" id="MJXp-Span-543" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-544">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-545">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-546">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-547">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-548">c</span><span class="MJXp-mrow" id="MJXp-Span-549"><span class="MJXp-msubsup" id="MJXp-Span-550"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-551" style="margin-right: 0.05em;">G</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-553">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-552">l</span></span></span></span></span></span></span><span class="MJXp-mrow" id="MJXp-Span-554"><span class="MJXp-msubsup" id="MJXp-Span-555"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-556" style="margin-right: 0.05em;">S</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-558">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-557">l</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-559" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mtext" id="MJXp-Span-560">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-561">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-562">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-563">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-564">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-565">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-566">a</span></span><span class="MJXp-mo" id="MJXp-Span-567" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mtext" id="MJXp-Span-568">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-569">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-570">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-571">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-572">c</span><span class="MJXp-mrow" id="MJXp-Span-573"><span class="MJXp-msubsup" id="MJXp-Span-574"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-575" style="margin-right: 0.05em;">G</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-577">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-576">r</span></span></span></span></span></span></span><span class="MJXp-mrow" id="MJXp-Span-578"><span class="MJXp-msubsup" id="MJXp-Span-579"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-580" style="margin-right: 0.05em;">S</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-582">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-581">r</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-583" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mtext" id="MJXp-Span-584">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-585">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-586">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-587">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-588">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-589">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-590">a</span></span><span class="MJXp-mo" id="MJXp-Span-591" style="margin-left: 0.267em; margin-right: 0.267em;">‚àí</span><span class="MJXp-mtext" id="MJXp-Span-592">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-593">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-594">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-595">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-596">c</span><span class="MJXp-mrow" id="MJXp-Span-597"><span class="MJXp-mo" id="MJXp-Span-598" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-599"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-600" style="margin-right: 0.05em;">G</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-601" style="vertical-align: -0.4em;">l</span></span><span class="MJXp-mo" id="MJXp-Span-602" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-603"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-604" style="margin-right: 0.05em;">G</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-605" style="vertical-align: -0.4em;">r</span></span><span class="MJXp-msubsup" id="MJXp-Span-606"><span class="MJXp-mo" id="MJXp-Span-607" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-608" style="vertical-align: 0.5em;">2</span></span></span><span class="MJXp-mrow" id="MJXp-Span-609"><span class="MJXp-msubsup" id="MJXp-Span-610"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-611" style="margin-right: 0.05em;">S</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-613">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-612">l</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-614" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-615"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-616" style="margin-right: 0.05em;">S</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-618">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-617">r</span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-619" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mtext" id="MJXp-Span-620">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-621">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-622">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-623">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-624">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-625">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-626">a</span></span><span class="MJXp-mo" id="MJXp-Span-627" style="margin-left: 0.267em; margin-right: 0.267em;">‚àí</span><span class="MJXp-mtext" id="MJXp-Span-628">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-629">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-630">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-631">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-632">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-633">a</span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-17-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-17"> Gain = \ frac {G_l ^ 2} {S_l ^ 2 + \ lambda} + \ frac {G_r ^ 2} {S_r ^ 2 + \ lambda} - \ frac {(G_l + G_r) ^ 2} {S_l ^ 2 + S_r ^ 2 + \ lambda} - \ gamma </script></p><br>  Hier <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-634"><span class="MJXp-mtext" id="MJXp-Span-635">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-636">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-637">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-638">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-639">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-640">a</span><span class="MJXp-mo" id="MJXp-Span-641" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mtext" id="MJXp-Span-642">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-643">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-644">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-645">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-646">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-647">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-648">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-18-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-18"> \ gamma, \ lambda </script>  Sind die numerischen Parameter der Regularisierung und <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-649"><span class="MJXp-msubsup" id="MJXp-Span-650"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-651" style="margin-right: 0.05em;">G</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-652" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-653" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-654"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-655" style="margin-right: 0.05em;">S</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-656" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-19-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-19"> G_i, S_i </script>  - die entsprechenden Summen der ersten und zweiten Ableitung f√ºr diese Partition. <br><br>  Das war's, die Theorie wird sehr kurz formuliert, die Links werden gegeben, jetzt wollen wir dar√ºber sprechen, was die Ableitungen sein werden, wenn wir mit MSE arbeiten.  Es ist einfach: <br><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-657"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-658">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-659">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-660">e</span><span class="MJXp-mo" id="MJXp-Span-661" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-662">y</span><span class="MJXp-mo" id="MJXp-Span-663" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-664">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-665">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-666">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-667">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-668">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-669">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-670">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-671">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-672">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-673">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-674">n</span><span class="MJXp-mo" id="MJXp-Span-675" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-676" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-677" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-678">y</span><span class="MJXp-mo" id="MJXp-Span-679" style="margin-left: 0.267em; margin-right: 0.267em;">‚àí</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-680">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-681">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-682">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-683">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-684">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-685">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-686">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-687">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-688">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-689">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-690">n</span><span class="MJXp-msubsup" id="MJXp-Span-691"><span class="MJXp-mo" id="MJXp-Span-692" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-693" style="vertical-align: 0.5em;">2</span></span><span class="MJXp-mspace" id="MJXp-Span-694" style="width: 0em; height: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-695">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-696">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-697">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-698">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-699">l</span><span class="MJXp-msubsup" id="MJXp-Span-700"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-701" style="margin-right: 0.05em;">a</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-702" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-703">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-704">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-705">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-706">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-707">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-708">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-709">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-710">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-711">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-712">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-713">n</span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-714">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-715">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-716">e</span><span class="MJXp-mo" id="MJXp-Span-717" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-718">y</span><span class="MJXp-mo" id="MJXp-Span-719" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-720">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-721">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-722">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-723">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-724">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-725">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-726">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-727">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-728">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-729">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-730">n</span><span class="MJXp-mo" id="MJXp-Span-731" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-732" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-733">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-734">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-735">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-736">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-737">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-738">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-739">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-740">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-741">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-742">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-743">n</span><span class="MJXp-mo" id="MJXp-Span-744" style="margin-left: 0.267em; margin-right: 0.267em;">‚àí</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-745">y</span><span class="MJXp-mspace" id="MJXp-Span-746" style="width: 0em; height: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-747">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-748">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-749">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-750">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-751">l</span><span class="MJXp-msubsup" id="MJXp-Span-752"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-753" style="margin-right: 0.05em;">a</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mn" id="MJXp-Span-766">2</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-754"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-755">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-756">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-757">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-758">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-759">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-760">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-761">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-762">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-763">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-764">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-765">n</span></span></span></span></span></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-767">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-768">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-769">e</span><span class="MJXp-mo" id="MJXp-Span-770" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-771">y</span><span class="MJXp-mo" id="MJXp-Span-772" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-773">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-774">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-775">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-776">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-777">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-778">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-779">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-780">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-781">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-782">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-783">n</span><span class="MJXp-mo" id="MJXp-Span-784" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-785" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-786">1</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-20-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-20"> mse (y, vorhersagen) = (y - vorhersagen) ^ 2 \\ \ nabla_ {vorhersagen} mse (y, vorhersagen) = vorhersagen - y \\ \ nabla_ {vorhersagen} ^ 2 mse (y, vorhersagen) = 1 </script><br><br>  Wann berechnen wir den Betrag? <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-787"><span class="MJXp-msubsup" id="MJXp-Span-788"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-789" style="margin-right: 0.05em;">G</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-790" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-791" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-msubsup" id="MJXp-Span-792"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-793" style="margin-right: 0.05em;">S</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-794" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-21-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-21"> G_i, S_i </script>  , einfach zum ersten hinzuf√ºgen <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-795"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-796">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-797">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-798">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-799">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-800">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-801">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-802">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-803">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-804">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-805">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-806">n</span><span class="MJXp-mo" id="MJXp-Span-807" style="margin-left: 0.267em; margin-right: 0.267em;">‚àí</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-808">y</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-22-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-22"> vorhersagen - y </script>  und die zweite ist nur die Menge. <br><br><pre> <code class="python hljs">%%cython -a <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np cimport numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np cdef <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RegressionTreeGain</span></span></span><span class="hljs-class">:</span></span> cdef public int max_depth cdef public np.float64_t gain cdef public np.float64_t lmd cdef public np.float64_t gmm cdef public int feature_idx cdef public int min_size cdef public np.float64_t feature_threshold cdef public np.float64_t value cpdef public RegressionTreeGain left cpdef public RegressionTreeGain right <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, int max_depth=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">, np.float64_t lmd=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1.0</span></span></span></span><span class="hljs-function"><span class="hljs-params">, np.float64_t gmm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, min_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> self.max_depth = max_depth self.gmm = gmm self.lmd = lmd self.left = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.right = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.feature_idx = <span class="hljs-number"><span class="hljs-number">-1</span></span> self.feature_threshold = <span class="hljs-number"><span class="hljs-number">0</span></span> self.value = <span class="hljs-number"><span class="hljs-number">-1e9</span></span> self.min_size = min_size <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, np.ndarray[np.float64_t, ndim=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">2</span></span></span></span><span class="hljs-function"><span class="hljs-params">] X, np.ndarray[np.float64_t, ndim=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span><span class="hljs-function"><span class="hljs-params">] y)</span></span></span><span class="hljs-function">:</span></span> cpdef long N = X.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] cpdef long N1 = X.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] cpdef long N2 = <span class="hljs-number"><span class="hljs-number">0</span></span> cpdef long idx = <span class="hljs-number"><span class="hljs-number">0</span></span> cpdef long thres = <span class="hljs-number"><span class="hljs-number">0</span></span> cpdef np.float64_t gl, gr, gn cpdef np.ndarray[long, ndim=<span class="hljs-number"><span class="hljs-number">1</span></span>] idxs cpdef np.float64_t x = <span class="hljs-number"><span class="hljs-number">0.0</span></span> cpdef np.float64_t best_gain = -self.gmm <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> self.value == <span class="hljs-number"><span class="hljs-number">-1e9</span></span>: self.value = y.mean() base_error = ((y - self.value) ** <span class="hljs-number"><span class="hljs-number">2</span></span>).sum() error = base_error flag = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> self.max_depth &lt;= <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> dim_shape = X.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] left_value = <span class="hljs-number"><span class="hljs-number">0</span></span> right_value = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#    # -  -   mse, L = (y - pred)**2 # dL/dpred = pred - y,          - # dL^2/d^2pred = 1 - ,       for feat in range(dim_shape): idxs = np.argsort(X[:, feat]) gl,gr = y.sum(),0.0 N1, N2, thres = N, 0, 0 while thres &lt; N - 1: N1 -= 1 N2 += 1 idx = idxs[thres] x = X[idx, feat] gl -= y[idx] gr += y[idx] #   gn = (gl**2) / (N1 + self.lmd) + (gr**2) / (N2 + self.lmd) gn -= ((gl + gr)**2) / (N1 + N2 + self.lmd) + self.gmm if thres &lt; N - 1 and x == X[idxs[thres + 1], feat]: thres += 1 continue #     if (gn &gt; best_gain) and (min(N1,N2) &gt; self.min_size): flag = 1 best_gain = gn left_value = -gl / (N1 + self.lmd) right_value = -gr / (N2 + self.lmd) self.feature_idx = feat self.feature_threshold = x thres += 1 self.gain = best_gain if self.feature_idx == -1: return self.left = RegressionTreeGain(max_depth=self.max_depth - 1, gmm=self.gmm, lmd=self.lmd) self.left.value = left_value self.right = RegressionTreeGain(max_depth=self.max_depth - 1, gmm=self.gmm, lmd=self.lmd) self.right.value = right_value idxs_l = (X[:, self.feature_idx] &gt; self.feature_threshold) idxs_r = (X[:, self.feature_idx] &lt;= self.feature_threshold) self.left.fit(X[idxs_l, :], y[idxs_l]) self.right.fit(X[idxs_r, :], y[idxs_r]) #    if (self.left.left == None or self.right.left == None): if self.gain &lt; 0.0: self.left = None self.right = None self.feature_idx = -1 def __predict(self, np.ndarray[np.float64_t, ndim=1] x): if self.feature_idx == -1: return self.value if x[self.feature_idx] &gt; self.feature_threshold: return self.left.__predict(x) else: return self.right.__predict(x) def predict(self, np.ndarray[np.float64_t, ndim=2] X): y = np.zeros(X.shape[0]) for i in range(X.shape[0]): y[i] = self.__predict(X[i]) return y</span></span></code> </pre> <br>  Eine kleine Klarstellung: Um die Formeln in den B√§umen mit Gewinn sch√∂ner zu machen, trainieren wir im Boost das Ziel mit einem Minuszeichen. <br><br>  Wir modifizieren unser Boosten leicht und passen einige Parameter an.  Wenn wir beispielsweise feststellen, dass der Verlust ein Plateau erreicht hat, verringern wir die Lernrate und erh√∂hen max_depth f√ºr die folgenden Sch√§tzer.  Wir werden auch eine neue Absackung hinzuf√ºgen - jetzt werden wir die Baumbeutel mit Gewinn steigern: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Bagging</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, max_depth = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">, min_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">, n_samples = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> self.max_depth = max_depth self.min_size = min_size self.n_samples = n_samples self.subsample_size = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.list_of_Carts = [RegressionTreeGain(max_depth=self.max_depth, min_size=self.min_size) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(self.n_samples)] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_bootstrap_samples</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, data_train, y_train)</span></span></span><span class="hljs-function">:</span></span> indices = np.random.randint(<span class="hljs-number"><span class="hljs-number">0</span></span>, len(data_train), (self.n_samples, self.subsample_size)) samples_train = data_train[indices] samples_y = y_train[indices] <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> samples_train, samples_y <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, data_train, y_train)</span></span></span><span class="hljs-function">:</span></span> self.subsample_size = int(data_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) samples_train, samples_y = self.get_bootstrap_samples(data_train, y_train) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(self.n_samples): self.list_of_Carts[i].fit(samples_train[i], samples_y[i].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predict</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, test_data)</span></span></span><span class="hljs-function">:</span></span> num_samples = test_data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] pred = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(self.n_samples): pred.append(self.list_of_Carts[i].predict(test_data)) pred = np.array(pred).T <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array([np.mean(pred[i]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(num_samples)])</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">GradientBoosting</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, n_estimators=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">100</span></span></span></span><span class="hljs-function"><span class="hljs-params">, learning_rate=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, max_depth=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">3</span></span></span></span><span class="hljs-function"><span class="hljs-params">, random_state=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">17</span></span></span></span><span class="hljs-function"><span class="hljs-params">, n_samples = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">15</span></span></span></span><span class="hljs-function"><span class="hljs-params">, min_size = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">, base_tree=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'Bagging'</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> self.n_estimators = n_estimators self.max_depth = max_depth self.learning_rate = learning_rate self.initialization = <span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> y: np.mean(y) * np.ones([y.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]]) self.min_size = min_size self.loss_by_iter = [] self.trees_ = [] self.loss_by_iter_test = [] self.n_samples = n_samples self.base_tree = base_tree <span class="hljs-comment"><span class="hljs-comment">#  -       #   ,   lr   max_depth self.add_to_max_depth = 1 self.init_mse_board = 1.5 def fit(self, X, y): print (self.base_tree) self.X = X self.y = y b = self.initialization(y) prediction = b.copy() for t in tqdm_notebook(range(self.n_estimators)): if t == 0: resid = y else: resid = (y - prediction) if (mse(temp_resid,resid) &lt; self.init_mse_board): self.init_mse_board /= 1.5 self.add_to_max_depth += 1 self.learning_rate /= 1.1 # print ('Alert!', t, self.add_to_max_depth) if self.base_tree == 'Bagging': tree = Bagging(max_depth=self.max_depth+self.add_to_max_depth, min_size = self.min_size) resid = -resid if self.base_tree == 'Tree': tree = RegressionTreeFastMse(max_depth=self.max_depth+self.add_to_max_depth, min_size = self.min_size) if self.base_tree == 'XGBoost': tree = RegressionTreeGain(max_depth=self.max_depth+self.add_to_max_depth, min_size = self.min_size) resid = -resid tree.fit(X, resid) b = tree.predict(X).reshape([X.shape[0]]) # print (b.shape) self.trees_.append(tree) prediction += self.learning_rate * b temp_resid = resid return self def predict(self, X): #   ‚Äì          pred = np.ones([X.shape[0]]) * np.mean(self.y) #    for t in range(self.n_estimators): pred += self.learning_rate * self.trees_[t].predict(X).reshape([X.shape[0]]) return pred</span></span></code> </pre> <br><h3>  5. Ergebnisse </h3><br>  Traditionell vergleichen wir die Ergebnisse: <br><br><pre> <code class="python hljs">data = datasets.fetch_california_housing() X = np.array(data.data) y = np.array(data.target) <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GradientBoostingRegressor <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> GDBSklearn er_boosting_bagging = get_metrics(X,y,<span class="hljs-number"><span class="hljs-number">30</span></span>,GradientBoosting(max_depth=<span class="hljs-number"><span class="hljs-number">3</span></span>, n_estimators=<span class="hljs-number"><span class="hljs-number">150</span></span>,base_tree=<span class="hljs-string"><span class="hljs-string">'Bagging'</span></span>)) er_boosting_xgb = get_metrics(X,y,<span class="hljs-number"><span class="hljs-number">30</span></span>,GradientBoosting(max_depth=<span class="hljs-number"><span class="hljs-number">3</span></span>, n_estimators=<span class="hljs-number"><span class="hljs-number">150</span></span>,base_tree=<span class="hljs-string"><span class="hljs-string">'XGBoost'</span></span>)) er_sklearn_boosting = get_metrics(X,y,<span class="hljs-number"><span class="hljs-number">30</span></span>,GDBSklearn(max_depth=<span class="hljs-number"><span class="hljs-number">3</span></span>,n_estimators=<span class="hljs-number"><span class="hljs-number">150</span></span>,learning_rate=<span class="hljs-number"><span class="hljs-number">0.2</span></span>)) %matplotlib inline data = [er_sklearn_boosting, er_boosting_xgb, er_boosting_bagging] fig7, ax7 = plt.subplots() ax7.set_title(<span class="hljs-string"><span class="hljs-string">''</span></span>) ax7.boxplot(data, labels=[<span class="hljs-string"><span class="hljs-string">'GdbSklearn'</span></span>, <span class="hljs-string"><span class="hljs-string">'Xgboost'</span></span>, <span class="hljs-string"><span class="hljs-string">'XGBooBag'</span></span>]) plt.grid() plt.show()</code> </pre> <br>  Das Bild sieht wie folgt aus: <br><br><img src="https://habrastorage.org/webt/jh/at/2u/jhat2uvy0yetcxkbzkaaix06wki.png"><br><br>  XGBoost hat den niedrigsten Fehler, aber XGBooBag hat einen √ºberf√ºllten Fehler, was definitiv besser ist: Der Algorithmus ist stabiler. <br><br>  Das ist alles  Ich hoffe wirklich, dass das in zwei Artikeln vorgestellte Material n√ºtzlich war und Sie etwas Neues f√ºr sich selbst lernen konnten.  Mein besonderer Dank gilt Dmitry f√ºr umfassendes Feedback und Quellcode, Anton f√ºr Ratschl√§ge und Vladimir f√ºr schwierige Aufgaben f√ºr das Studium. <br><br>  Alles Erfolg! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de438562/">https://habr.com/ru/post/de438562/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de438548/index.html">Lombok, sources.jar und praktisches Debuggen</a></li>
<li><a href="../de438550/index.html">Ein weiteres Manifest</a></li>
<li><a href="../de438554/index.html">Verwalten des Status und der Ereignisse zwischen Komponenten in GameObject</a></li>
<li><a href="../de438556/index.html">Daten bequem s√§gen</a></li>
<li><a href="../de438560/index.html">XGBoost von Grund auf neu schreiben - Teil 1: Entscheidungsb√§ume</a></li>
<li><a href="../de438566/index.html">Apple Strange A12X Mikroprozessorgeh√§use</a></li>
<li><a href="../de438568/index.html">√úber Quantencomputer: Wie verschiedene L√§nder diese Technologie entwickeln</a></li>
<li><a href="../de438570/index.html">CS Center 2018 Silvesterwettbewerb</a></li>
<li><a href="../de438574/index.html">Grundlagen der Flatter-Anwendungsarchitektur: Vanilla, Scoped Model, BLoC</a></li>
<li><a href="../de438576/index.html">Beliebte Open Source - Teil drei: 5 Tools f√ºr Entwickler</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
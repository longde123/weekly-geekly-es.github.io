<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ô•Ô∏è üò´ üé¢ Auf welcher Hardware soll ein riesiger Informationsschacht analysiert werden? üéûÔ∏è üëßüèª üî∂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir sind Big Data bei MTS und dies ist unser erster Beitrag. Heute werden wir dar√ºber sprechen, mit welchen Technologien wir Big Data speichern und ve...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Auf welcher Hardware soll ein riesiger Informationsschacht analysiert werden?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ru_mts/blog/439498/">  Wir sind Big Data bei MTS und dies ist unser erster Beitrag.  Heute werden wir dar√ºber sprechen, mit welchen Technologien wir Big Data speichern und verarbeiten k√∂nnen, damit immer gen√ºgend Ressourcen f√ºr Analysen zur Verf√ºgung stehen und die Kosten f√ºr den Kauf von Eisen nicht in die H√∂he gehen. <br><br>  Sie dachten dar√ºber nach, das Big Data Center bei MTS im Jahr 2014 einzurichten: Es bestand die Notwendigkeit, den klassischen analytischen Speicher und die BI-Berichterstellung dar√ºber zu skalieren.  Zu dieser Zeit war die Datenverarbeitungs- und BI-Engine SAS - dies geschah historisch.  Und obwohl die gesch√§ftlichen Anforderungen an den Speicher geschlossen wurden, wuchs die Funktionalit√§t von BI- und Ad-hoc-Analysen zus√§tzlich zum analytischen Speicher im Laufe der Zeit so stark, dass das Problem der Produktivit√§tssteigerung gel√∂st werden musste, da sich die Anzahl der Benutzer im Laufe der Jahre verzehnfachte und weiter zunahm. <br><br>  Als Ergebnis des Wettbewerbs erschien das Teradata MPP-System in MTS und deckte die damaligen Bed√ºrfnisse der Telekommunikation ab.  Dies war der Ansto√ü, etwas Popul√§reres und Open Source auszuprobieren. <br><br><img src="https://habrastorage.org/webt/3w/vb/oq/3wvboq27onvunkfizv0cfquemou.jpeg" alt="Bild"><br><br>  <i>Auf dem Foto - das Big Data MTS-Team im neuen Descartes-B√ºro in Moskau</i> <a name="habracut"></a><br><br>  Der erste Cluster bestand aus 7 Knoten.  Dies war genug, um mehrere Gesch√§ftshypothesen zu testen und die ersten Probleme zu l√∂sen.  Die Bem√ºhungen waren nicht umsonst: Big Data gibt es in MTS seit drei Jahren und jetzt ist die Datenanalyse in fast allen Funktionsbereichen involviert.  Das Team wuchs von drei auf zweihundert. <br><br>  Wir wollten einfache Entwicklungsprozesse haben und Hypothesen schnell testen.  Dazu ben√∂tigen Sie drei Dinge: ein Team mit Startup-Denken, leichten Entwicklungsprozessen und entwickelter Infrastruktur.  Es gibt viele Orte, an denen Sie die erste und die zweite lesen und anh√∂ren k√∂nnen, aber es lohnt sich, die entwickelte Infrastruktur separat zu beschreiben, da hier Legacy- und Datenquellen in der Telekommunikation wichtig sind.  Eine entwickelte Dateninfrastruktur baut nicht nur einen Datensee, eine detaillierte Datenschicht und eine Storefront-Schicht auf.  Es umfasst auch Tools und Datenzugriffsschnittstellen, die Isolierung von Computerressourcen f√ºr Produkte und Befehle sowie Mechanismen zur Bereitstellung von Daten f√ºr Verbraucher - sowohl in Echtzeit als auch im Batch-Modus.  Und vieles mehr. <br><br>  All diese Arbeiten wurden in einem separaten Bereich hervorgehoben, der sich mit der Entwicklung von Dienstprogrammen und Datentools befasst.  Dieser Bereich wird als Big Data IT-Plattform bezeichnet. <br><br><h3>  Woher kommt Big Data in MTS? </h3><br>  MTS hat viele Datenquellen.  Eine der wichtigsten sind Basisstationen. Wir bedienen die Abonnentenbasis von mehr als 78 Millionen Abonnenten in Russland.  Wir haben auch viele Dienste, die nicht mit Telekommunikation zu tun haben und es Ihnen erm√∂glichen, vielseitigere Daten zu erhalten (E-Commerce, Systemintegration, Internet der Dinge, Cloud-Dienste usw. - alle ‚ÄûNicht-Telekommunikationsdienste‚Äú bringen bereits etwa 20% aller Einnahmen). <br><br>  Kurz gesagt, unsere Architektur kann als solches Diagramm dargestellt werden: <br><br><img src="https://habrastorage.org/webt/ya/cf/mf/yacfmf3ruitbrvmrjlib6kqlywy.png" alt="Bild"><br><br>  Wie Sie in der Tabelle sehen k√∂nnen, k√∂nnen Datenquellen Informationen in Echtzeit liefern.  Wir verwenden die Stream-Schicht - wir k√∂nnen Echtzeitinformationen verarbeiten, daraus einige Ereignisse extrahieren, die f√ºr uns von Interesse sind, und darauf Analysen aufbauen.  Um eine solche Ereignisverarbeitung bereitzustellen, haben wir eine ziemlich standardm√§√üige Implementierung (aus Sicht der Architektur) unter Verwendung von Apache Kafka, Apache Spark und Code in der Scala-Sprache entwickelt.  Informationen, die als Ergebnis einer solchen Analyse erhalten werden, k√∂nnen sowohl innerhalb als auch in Zukunft au√üerhalb von MTS konsumiert werden: Unternehmen sind h√§ufig an der Tatsache bestimmter Aktionen von Abonnenten interessiert. <br><br>  Es gibt auch einen Modus zum Laden von Daten in Chargen - Chargenebene.  Normalerweise erfolgt der Download einmal pro Stunde nach einem Zeitplan, wir verwenden Apache Airflow als Planer und die Batch-Download-Prozesse selbst sind in Python implementiert.  In diesem Fall wird eine erheblich gr√∂√üere Datenmenge in Data Lake geladen, die zum F√ºllen von Big Data mit historischen Daten erforderlich ist, auf denen unsere Data Science-Modelle trainiert werden sollten.  Infolgedessen wird im historischen Kontext ein Teilnehmerprofil basierend auf Daten zu seiner Netzwerkaktivit√§t erstellt.  Dies erm√∂glicht es uns, pr√§diktive Statistiken zu erhalten, Modelle des menschlichen Verhaltens zu erstellen und sogar ein psychologisches Portr√§t von ihm zu erstellen - wir haben ein so separates Produkt.  Diese Informationen sind beispielsweise f√ºr Marketingunternehmen sehr n√ºtzlich. <br><br>  Wir haben auch eine gro√üe Datenmenge, aus der das klassische Repository besteht.  Das hei√üt, wir sammeln Informationen zu verschiedenen Ereignissen - sowohl Benutzer als auch Netzwerk.  All diese anonymisierten Daten helfen auch dabei, Benutzerinteressen und Ereignisse, die f√ºr das Unternehmen wichtig sind, genauer vorherzusagen - beispielsweise um m√∂gliche Ger√§teausf√§lle vorherzusagen und Fehler rechtzeitig zu beheben. <br><br><h3>  Hadoop </h3><br>  Wenn Sie in die Vergangenheit schauen und sich daran erinnern, wie Big Data im Allgemeinen aussah, sollte beachtet werden, dass die Akkumulation von Daten im Wesentlichen zu Marketingzwecken durchgef√ºhrt wurde.  Es gibt keine so klare Definition von Big Data - Gigabyte, Terabyte, Petabyte.  Es ist unm√∂glich, eine Linie zu ziehen.  F√ºr einige sind Big Data mehrere zehn Gigabyte, f√ºr andere Petabyte. <br><br>  So kam es, dass sich im Laufe der Zeit weltweit viele Daten angesammelt haben.  Und um eine mehr oder weniger signifikante Analyse dieser Daten durchzuf√ºhren, reichten die √ºblichen Repositories, die sich seit den 70er Jahren des letzten Jahrhunderts entwickelt haben, nicht mehr aus.  Als der Informationsschacht in den 2000er, 10er Jahren begann und als es viele Ger√§te gab, die √ºber einen Internetzugang verf√ºgten, als das Internet der Dinge erschien, konnten diese Repositories konzeptionell einfach nicht fertig werden.  Die Grundlage dieser Repositories war die relationale Theorie.  Das hei√üt, es gab Beziehungen verschiedener Formen, die miteinander interagierten.  Es gab ein System zur Beschreibung des Erstellens und Entwerfens von Repositorys. <br><br>  Wenn alte Technologien versagen, erscheinen neue.  In der modernen Welt wird das Problem der Big-Data-Analyse auf zwei Arten gel√∂st: <br><br>  Erstellen Sie Ihr eigenes Framework, mit dem Sie gro√üe Informationsmengen verarbeiten k√∂nnen.  In der Regel handelt es sich hierbei um eine verteilte Anwendung von vielen Hunderttausenden von Servern - wie Google und Yandex, die ihre eigenen verteilten Datenbanken erstellt haben, mit denen Sie mit einem solchen Informationsvolumen arbeiten k√∂nnen. <br><br>  Die Entwicklung der Hadoop-Technologie ist ein verteiltes Computer-Framework, ein verteiltes Dateisystem, das eine sehr gro√üe Menge an Informationen speichern und verarbeiten kann.  Data Science-Tools sind haupts√§chlich mit Hadoop kompatibel, und diese Kompatibilit√§t er√∂ffnet viele M√∂glichkeiten f√ºr erweiterte Datenanalysen.  Viele Unternehmen, einschlie√ülich uns, bewegen sich in Richtung Open-Source-Hadoop-√ñkosystem. <br><br>  Der zentrale Hadoop-Cluster befindet sich in Nischni Nowgorod.  Es sammelt Informationen aus fast allen Regionen des Landes.  In Bezug auf das Volumen k√∂nnen dort jetzt etwa 8,5 Petabyte Daten heruntergeladen werden.  Auch in Moskau haben wir separate RND-Cluster, in denen wir Experimente durchf√ºhren. <br><br>  Da wir ungef√§hr tausend Server in verschiedenen Regionen haben, auf denen wir Analysen durchf√ºhren und eine Erweiterung geplant ist, stellt sich die Frage nach der richtigen Auswahl der Ausr√ºstung f√ºr verteilte Analysesysteme.  Sie k√∂nnen Ger√§te kaufen, die f√ºr die Datenspeicherung ausreichen, sich jedoch f√ºr die Analyse als ungeeignet herausstellen - einfach, weil nicht gen√ºgend Ressourcen, die Anzahl der CPU-Kerne und der freie Arbeitsspeicher auf den Knoten vorhanden sind.  Es ist wichtig, ein Gleichgewicht zu finden, um gute Analysem√∂glichkeiten und nicht sehr hohe Ger√§tekosten zu erhalten. <br><br>  Intel bot uns verschiedene Optionen zur Optimierung der Arbeit mit einem verteilten System an, damit Analysen in unserem Datenvolumen f√ºr angemessenes Geld abgerufen werden k√∂nnen.  Intel verbessert die NAND SSD Solid State Drive-Technologie  Es ist hunderte Male schneller als eine normale Festplatte.  Dann ist es gut f√ºr uns: SSD, insbesondere mit NVMe-Schnittstelle, bietet ausreichend schnellen Zugriff auf Daten. <br><br>  Au√üerdem hat Intel Intel Optane SSD-Server-SSDs ver√∂ffentlicht, die auf dem neuen Typ des nichtfl√ºchtigen Speichers Intel 3D XPoint basieren.  Sie bew√§ltigen intensive gemischte Belastungen des Speichersystems und verf√ºgen √ºber eine l√§ngere Ressource als normale NAND-SSDs.  Warum ist es gut f√ºr uns: Mit Intel Optane SSD k√∂nnen Sie unter hoher Last mit geringer Latenz stabil arbeiten.  Wir haben die NAND-SSD zun√§chst als Ersatz f√ºr herk√∂mmliche Festplatten angesehen, da sich sehr viel Daten zwischen Festplatte und RAM bewegen - und wir mussten diese Prozesse optimieren. <br><br><h3>  Erster Test </h3><br>  Der erste Test, den wir 2016 durchgef√ºhrt haben.  Wir haben gerade versucht, die Festplatte durch eine schnelle NAND-SSD zu ersetzen.  Zu diesem Zweck haben wir Muster des neuen Intel-Laufwerks bestellt - damals war es DC P3700.  Und sie haben den Standardtest von Hadoop durchgef√ºhrt - einem √ñkosystem, mit dem Sie bewerten k√∂nnen, wie sich die Leistung unter verschiedenen Bedingungen √§ndert.  Dies sind standardisierte Tests TeraGen, TeraSort, TeraValidate. <br><br><img src="https://habrastorage.org/webt/4t/rv/jg/4trvjgykt92_nv93z6nidrblw8g.png" alt="Bild"><br><br>  Mit TeraGen k√∂nnen Sie k√ºnstliche Daten eines bestimmten Volumens "generieren".  Zum Beispiel haben wir 1 GB und 1 TB genommen.  Mit TeraSort haben wir diese Datenmenge in Hadoop sortiert.  Dies ist eine ziemlich ressourcenintensive Operation.  Mit dem letzten Test - TeraValidate - k√∂nnen Sie sicherstellen, dass die Daten in der richtigen Reihenfolge sortiert sind.  Das hei√üt, wir gehen sie ein zweites Mal durch. <br><br><img src="https://habrastorage.org/webt/dh/26/a8/dh26a8jyr-tzpravvfdpliwvz3m.png" alt="Bild"><br><br>  Als Experiment haben wir Autos nur mit SSDs genommen - das hei√üt, Hadoop wurde nur auf SSDs ohne Festplatten installiert.  In der zweiten Version haben wir SSD zum Speichern tempor√§rer Dateien verwendet, HDD - zum Speichern von Basisdaten.  In der dritten Version wurden f√ºr beide Festplatten verwendet. <br><br>  Die Ergebnisse dieser Experimente waren f√ºr uns nicht sehr erfreulich, da der Unterschied in den Leistungsindikatoren 10-20% nicht √ºberschritt.  Das hei√üt, wir haben festgestellt, dass Hadoop in Bezug auf die Speicherung nicht sehr mit SSDs vertraut ist, da das System urspr√ºnglich zum Speichern gro√üer Datenmengen auf der Festplatte entwickelt wurde und niemand es speziell f√ºr schnelle und teure SSDs optimiert hat.  Und da die Kosten f√ºr SSD zu dieser Zeit ziemlich hoch waren, haben wir uns bisher entschieden, nicht auf diese Geschichte einzugehen und mit Festplatten auszukommen. <br><br><h3>  Zweiter Test </h3><br>  Anschlie√üend f√ºhrte Intel neue serverseitige Intel Optane-SSDs ein, die auf 3D-XPoint-Speicher basieren.  Sie wurden Ende 2017 ver√∂ffentlicht, aber die Muster standen uns fr√ºher zur Verf√ºgung.  Mit den 3D XPoint-Speicherfunktionen k√∂nnen Sie die Intel Optane SSD als RAM-Erweiterung in Servern verwenden.  Da wir bereits erkannt haben, dass es nicht einfach ist, das Leistungsproblem von IO Hadoop auf der Ebene von Blockspeicherger√§ten zu l√∂sen, haben wir uns f√ºr eine neue Option entschieden - die Erweiterung des Arbeitsspeichers mithilfe der Intel Memory Drive Technology (IMDT).  Und zu Beginn dieses Jahres waren wir einer der ersten auf der Welt, die es getestet haben. <br><br>  Das ist gut f√ºr uns: Es ist billiger als RAM, wodurch Sie Server mit Terabyte RAM sammeln k√∂nnen.  Und da RAM schnell genug ist, k√∂nnen Sie gro√üe Datenmengen darin laden und analysieren.  Ich m√∂chte Sie daran erinnern, dass die Besonderheit unseres Analyseprozesses darin besteht, dass wir mehrmals auf die Daten zugreifen.  Um eine Art von Analyse durchzuf√ºhren, m√ºssen wir so viele Daten wie m√∂glich in den Speicher laden und eine Art Analyse dieser Daten mehrmals "scrollen". <br>  Das Intel English Labor in Swindon hat uns einen Cluster von drei Servern zugewiesen, die wir w√§hrend der Tests mit unserem Testcluster in MTS verglichen haben. <br><br><img src="https://habrastorage.org/webt/ph/uc/1h/phuc1hd5_okqgdwgtzbskvvmngm.png" alt="Bild"><br><br>  Wie aus der Grafik ersichtlich ist, haben wir nach den Testergebnissen recht gute Ergebnisse erzielt. <br><br><img src="https://habrastorage.org/webt/nx/02/rz/nx02rzz8cratazithcmus9utpy8.png" alt="Bild"><br><br>  Das gleiche TeraGen zeigte eine fast zweifache Produktivit√§tssteigerung, TeraValidate - um 75%.  Das ist sehr gut f√ºr uns, denn wie gesagt, wir greifen mehrmals auf die Daten zu, die wir in unserem Ged√§chtnis haben.  Wenn wir einen solchen Leistungsgewinn erzielen, hilft uns dies insbesondere bei der Datenanalyse, insbesondere in Echtzeit. <br><br>  Wir haben drei Tests unter verschiedenen Bedingungen durchgef√ºhrt.  100 GB, 250 GB und 500 GB.  Und je mehr Speicher wir verwendeten, desto besser schnitt die Intel Optane SSD mit Intel Memory Drive-Technologie ab.  Das hei√üt, je mehr Daten wir analysieren, desto effizienter werden wir.  Analysen, die auf mehr Knoten durchgef√ºhrt wurden, k√∂nnen auf weniger von ihnen durchgef√ºhrt werden.  Au√üerdem verf√ºgen wir √ºber eine relativ gro√üe Menge an Speicher auf unseren Computern, was f√ºr Data Science-Aufgaben sehr gut ist.  Aufgrund der Testergebnisse haben wir uns entschlossen, diese Laufwerke f√ºr die Arbeit bei MTS zu kaufen. <br><br>  Wenn Sie auch Hardware zum Speichern und Verarbeiten einer gro√üen Datenmenge ausw√§hlen und testen mussten, ist es f√ºr uns interessant zu lesen, auf welche Schwierigkeiten Sie gesto√üen sind und welche Ergebnisse Sie erzielt haben: Schreiben Sie in die Kommentare. <br><br>  <i>Autoren:</i> <i><br></i>  <i>Grigory Koval, Leiter des Kompetenzzentrums f√ºr Angewandte Architektur der Big Data-Abteilung von MTS, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">grigory_koval</a></i> <i><br></i>  <i>Leiter des Datenverwaltungsstammes der Big Data MTS-Abteilung Dmitry Shostko <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">zloi_diman</a></i> <cut></cut></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de439498/">https://habr.com/ru/post/de439498/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de439486/index.html">.NET-Referenztypen im Vergleich zu Werttypen. Teil 1</a></li>
<li><a href="../de439488/index.html">QA Meetup Videoaufzeichnung</a></li>
<li><a href="../de439490/index.html">.NET-Referenztypen im Vergleich zu Werttypen. Teil 2</a></li>
<li><a href="../de439492/index.html">10 Tipps f√ºr einen guten technischen Vorsprung</a></li>
<li><a href="../de439496/index.html">So erfolgt die Abrechnung dort: Wenn Kunde und Entwickler unterschiedliche Sprachen sprechen</a></li>
<li><a href="../de439500/index.html">Warum sind Captchas so kompliziert geworden?</a></li>
<li><a href="../de439502/index.html">Undefiniertes Verhalten und Wahrheit nicht definiert</a></li>
<li><a href="../de439504/index.html">Ben√∂tigt Ihr Team einen Dateningenieur?</a></li>
<li><a href="../de439506/index.html">9 Alternativen zu einem schlechten Team (Designmuster)</a></li>
<li><a href="../de439508/index.html">Mitap √ºber Open Source-Entwicklung in Moskau</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüë©‚Äçüë¶‚Äçüë¶ üë®‚Äçüë®‚Äçüë¶‚Äçüë¶ üíÖüèª A base para uma teoria generalizada das redes neurais √© criada üöµüèª üë∂ ‚è¨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="As tremendas capacidades das redes neurais s√£o algumas vezes compar√°veis ‚Äã‚Äã√† sua imprevisibilidade. Agora, os matem√°ticos come√ßam a entender como a fo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>A base para uma teoria generalizada das redes neurais √© criada</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/442574/"><h3>  As tremendas capacidades das redes neurais s√£o algumas vezes compar√°veis ‚Äã‚Äã√† sua imprevisibilidade.  Agora, os matem√°ticos come√ßam a entender como a forma de uma rede neural afeta seu trabalho. </h3><br><br><img src="https://habrastorage.org/getpro/habr/post_images/856/cbb/518/856cbb5185fda3edec1e6c1096d9226b.jpg"><br><br>  Quando projetamos um arranha-c√©u, esperamos que, no final, ele atenda a todas as especifica√ß√µes: que a torre seja capaz de suportar um peso t√£o grande quanto um terremoto de certa for√ßa. <br><br>  No entanto, uma das tecnologias mais importantes do mundo moderno, de fato, projetamos √†s cegas.  Jogamos com esquemas diferentes, configura√ß√µes diferentes, mas at√© iniciarmos uma avalia√ß√£o do sistema, realmente n√£o temos id√©ia do que ele pode fazer ou de onde ele se recusar√° a trabalhar. <br><a name="habracut"></a><br>  √â sobre a tecnologia de rede neural subjacente aos mais modernos sistemas de intelig√™ncia artificial modernos.  As redes neurais est√£o gradualmente se movendo para as √°reas mais b√°sicas da sociedade: elas determinam o que aprendemos sobre o mundo a partir do feed de not√≠cias nas redes sociais, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ajudam os</a> m√©dicos a fazer um diagn√≥stico e at√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">afetam</a> se um criminoso √© enviado para a pris√£o. <br><br>  E "a melhor descri√ß√£o do que sabemos √© dizer que praticamente nada sabemos sobre como as redes neurais realmente funcionam e qual deveria ser a teoria que as descreve", disse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Boris Ganin</a> , matem√°tico da Universidade do Texas, e um especialista convidado no Facebook AI Research estudando redes neurais. <br><br>  Ele compara a situa√ß√£o com o desenvolvimento de mais uma tecnologia revolucion√°ria: um motor a vapor.  Inicialmente, os motores a vapor s√≥ podiam bombear √°gua.  Ent√£o eles serviram como motores para locomotivas a vapor, e hoje as redes neurais provavelmente atingiram o mesmo n√≠vel.  Cientistas e matem√°ticos desenvolveram uma teoria da termodin√¢mica que lhes permitiu entender o que exatamente est√° acontecendo dentro de qualquer mecanismo.  E, no final, esse conhecimento nos trouxe ao espa√ßo. <br><br>  "No in√≠cio, houve grandes realiza√ß√µes de engenharia, depois grandes trens e, em seguida, foi preciso um entendimento te√≥rico para mudar isso para foguetes", disse Ganin. <br><br>  Na crescente comunidade de desenvolvedores de redes neurais, h√° um pequeno grupo de pesquisadores com um vi√©s matem√°tico tentando criar uma teoria das redes neurais que possa explicar como eles funcionam e garantir que, ap√≥s criar uma rede neural de uma configura√ß√£o espec√≠fica, ele possa executar determinadas tarefas. <br><br>  Enquanto o trabalho est√° em est√°gio inicial, mas ao longo do ano passado, os pesquisadores j√° publicaram v√°rios artigos cient√≠ficos que descrevem em detalhes a rela√ß√£o entre a forma e o funcionamento das redes neurais.  O trabalho descreve as redes neurais na √≠ntegra, at√© seus pr√≥prios fundamentos.  Ela demonstra que muito antes de confirmar a capacidade das redes neurais de dirigir carros, √© necess√°rio provar sua capacidade de multiplicar n√∫meros. <br><br><h2>  A melhor receita para o c√©rebro </h2><br>  As redes neurais se esfor√ßam para imitar o c√©rebro humano - e uma maneira de descrever seu trabalho √© dizer que ele mescla pequenas abstra√ß√µes em outras maiores.  Desse ponto de vista, a complexidade dos pensamentos √© medida pelo n√∫mero de pequenas abstra√ß√µes subjacentes a elas e o n√∫mero de combina√ß√µes de abstra√ß√µes de baixo n√≠vel em abstra√ß√µes de alto n√≠vel - em tarefas como estudar as diferen√ßas entre c√£es e p√°ssaros. <br><br>  "Se uma pessoa aprende a reconhecer um cachorro, ela aprende a reconhecer algo desgrenhado nas quatro pernas", disse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Maitra Ragu</a> , estudante de ci√™ncia da computa√ß√£o na Cornell University, membro da equipe do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Google Brain</a> .  "Idealmente, gostar√≠amos que nossas redes neurais fizessem algo semelhante". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a42/4d2/17d/a424d217dd912526caaa61b33e30e36f.jpg"><br>  <i>Maitra Ragu</i> <br><br>  A abstra√ß√£o se origina no c√©rebro humano de maneira natural.  As redes neurais precisam trabalhar para isso.  As redes neurais, como o c√©rebro, s√£o constitu√≠das por blocos de constru√ß√£o chamados "neur√¥nios", conectados de v√°rias maneiras entre si.  Ao mesmo tempo, os neur√¥nios da rede neural, embora criados √† imagem dos neur√¥nios cerebrais, n√£o tentam imit√°-los completamente.  Cada neur√¥nio pode representar um atributo ou uma combina√ß√£o de atributos que a rede neural considera em cada n√≠vel de abstra√ß√£o. <br><br>  Os engenheiros t√™m v√°rias op√ß√µes para combinar esses neur√¥nios.  Eles precisam decidir quantas camadas de neur√¥nios uma rede neural deve ter (isto √©, determinar sua "profundidade").  Considere, por exemplo, uma rede neural que reconhe√ßa imagens.  A imagem √© inclu√≠da na primeira camada do sistema.  Na pr√≥xima camada, a rede pode ter neur√¥nios que simplesmente reconhecem as bordas da imagem.  A pr√≥xima camada combina as linhas e define as curvas.  O pr√≥ximo combina as curvas em formas e texturas, e o √∫ltimo processa as formas e texturas para tomar uma decis√£o sobre o que ele est√° olhando: o mamute peludo! <br><br>  ‚ÄúA ideia √© que cada camada combine v√°rios aspectos da anterior.  Um c√≠rculo √© uma curva em muitos lugares, uma curva √© uma linha em muitos lugares ‚Äù, diz <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">David Rolnik</a> , matem√°tico da Universidade da Pensilv√¢nia. <br><br>  Os engenheiros tamb√©m precisam escolher a ‚Äúlargura‚Äù de cada camada, correspondendo ao n√∫mero de diferentes recursos que a rede considera em cada n√≠vel de abstra√ß√£o.  No caso do reconhecimento de imagem, a largura das camadas corresponder√° ao n√∫mero de tipos de linhas, curvas ou formas que a rede neural considerar√° em cada n√≠vel. <br><br>  Al√©m da profundidade e largura da rede neural, h√° uma escolha do m√©todo de conex√£o de neur√¥nios nas camadas e entre elas, al√©m de uma escolha de pesos para cada uma das conex√µes. <br><br>  Se voc√™ planeja concluir uma tarefa espec√≠fica, como voc√™ sabe qual arquitetura de rede neural pode execut√°-la da melhor maneira?  Existem regras de amostra bastante gerais.  Para problemas com o reconhecimento de imagens, os programadores costumam usar redes neurais "convolucionais", o sistema de links entre camadas, no qual √© repetido camada a camada.  Para processar uma linguagem natural - reconhecimento de fala ou gera√ß√£o de linguagem - os programadores descobriram que as redes neurais recorrentes s√£o mais adequadas.  Os neur√¥nios neles podem ser conectados com neur√¥nios n√£o apenas das camadas vizinhas. <br><br>  No entanto, fora desses princ√≠pios gerais, os programadores geralmente precisam confiar em evid√™ncias experimentais: eles simplesmente administram 1.000 redes neurais diferentes e veem qual deles faz o trabalho melhor. <br><br>  "Na pr√°tica, essas escolhas geralmente s√£o feitas por tentativa e erro", disse Ganin.  "Esta √© uma maneira bastante complicada, j√° que existem infinitas elei√ß√µes e ningu√©m sabe qual ser√° a melhor." <br><br>  A melhor op√ß√£o seria confiar menos no m√©todo de tentativa e erro e mais no entendimento preexistente do que uma arquitetura de rede neural espec√≠fica pode oferecer a voc√™.  V√°rios artigos cient√≠ficos recentemente publicados avan√ßaram nessa √°rea nessa dire√ß√£o. <br><br>  ‚ÄúEste trabalho visa criar algo como um livro de receitas para projetar uma rede neural adequada.  Se voc√™ sabe o que deseja alcan√ßar com ele, pode escolher a receita certa ‚Äù, disse Rolnik. <br><br><h2>  La√ßo ovelha vermelha </h2><br>  Uma das primeiras garantias te√≥ricas da arquitetura de redes neurais apareceu tr√™s d√©cadas atr√°s.  Em 1989, um cientista da computa√ß√£o provou que, se uma rede neural tem apenas uma camada computacional, na qual pode haver um n√∫mero ilimitado de neur√¥nios e um n√∫mero ilimitado de conex√µes entre eles, a rede neural ser√° capaz de executar qualquer tarefa. <br><br>  Essa foi uma afirma√ß√£o mais ou menos geral, que acabou sendo bastante intuitiva e n√£o particularmente √∫til.  √â o mesmo que dizer que, se voc√™ pode definir um n√∫mero ilimitado de linhas em uma imagem, √© poss√≠vel distinguir todos os objetos com apenas uma camada.  Em princ√≠pio, isso pode ser cumprido, mas tente coloc√°-lo em pr√°tica. <br><br>  Atualmente, os pesquisadores chamam essas redes amplas e planas de "expressivas", porque, em teoria, podem cobrir um conjunto mais rico de rela√ß√µes entre os poss√≠veis dados de entrada (como uma imagem) e os resultados (como a descri√ß√£o da imagem).  Ao mesmo tempo, √© extremamente dif√≠cil treinar essas redes, ou seja, √© praticamente imposs√≠vel faz√™-las realmente fornecer esses dados.  Eles tamb√©m exigem mais poder computacional do que qualquer computador. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1fa/99c/58e/1fa99c58e5bf806edb24c0c47a735a75.jpg"><br>  <i>Boris Ganin</i> <br><br>  Recentemente, os pesquisadores tentaram entender at√© onde voc√™ pode obter redes neurais indo na dire√ß√£o oposta - tornando-as mais estreitas (menos neur√¥nios por camada) e mais profundas (mais camadas).  Voc√™ pode reconhecer apenas 100 linhas diferentes, mas com as conex√µes necess√°rias para transformar 100 dessas linhas em 50 curvas que podem ser combinadas em 10 formas diferentes, voc√™ pode obter todos os componentes necess√°rios para reconhecer a maioria dos objetos. <br><br>  No <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalho</a> conclu√≠do no ano passado, Rolnik e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Max Tegmark,</a> do MIT, provaram que, aumentando a profundidade e diminuindo a largura, √© poss√≠vel executar as mesmas tarefas com um n√∫mero exponencialmente menor de neur√¥nios.  Eles mostraram que se a situa√ß√£o que voc√™ simula tem 100 vari√°veis ‚Äã‚Äãde entrada, √© poss√≠vel obter a mesma confiabilidade usando <sup>2.100</sup> neur√¥nios em uma camada ou 2.10 neur√¥nios em duas camadas.  Eles descobriram que havia vantagens em pegar pequenas pe√ßas e combin√°-las em n√≠veis mais altos de abstra√ß√£o, em vez de tentar cobrir todos os n√≠veis de abstra√ß√£o de uma s√≥ vez. <br><br>  "O conceito de profundidade da rede neural est√° conectado √† possibilidade de expressar algo complexo, executando v√°rias etapas simples", disse Rolnik.  "Parece uma linha de montagem." <br><br>  Rolnik e Tegmark provaram a utilidade da profundidade for√ßando as redes neurais a executar uma tarefa simples: multiplicar fun√ß√µes polinomiais.  (Estas s√£o equa√ß√µes com vari√°veis ‚Äã‚Äãelevadas a graus naturais, por exemplo, y = x <sup>3</sup> + 1).  Eles treinaram as redes, mostrando exemplos de equa√ß√µes e os resultados de sua multiplica√ß√£o.  Ent√£o eles disseram √†s redes neurais para calcular o resultado da multiplica√ß√£o de equa√ß√µes que eles n√£o tinham visto antes.  Redes neurais mais profundas aprenderam como fazer isso com muito menos neur√¥nios do que os pequenos. <br><br>  E, embora seja improv√°vel que a multiplica√ß√£o vire nosso mundo de cabe√ßa para baixo, Rolnik diz que uma id√©ia importante foi descrita no trabalho: "Se uma rede neural superficial n√£o pode sequer se multiplicar, voc√™ n√£o deve confiar nela com outra coisa". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/58d/189/b73/58d189b7307053cde31c537aa8bc5d33.jpg"><br>  <i>David Rolnik</i> <br><br>  Outros pesquisadores est√£o investigando a quest√£o da largura m√≠nima suficiente.  No final de setembro, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Jesse Johnson</a> , ex-matem√°tico da Universidade de Oklahoma e agora pesquisador da empresa farmac√™utica Sanofi, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">provou</a> que, em algum momento, nenhuma profundidade poderia compensar a falta de largura. <br><br>  Para entender isso, imagine os cordeiros no campo, mas que sejam cordeiros do punk rock: cada um deles ser√° pintado em uma de v√°rias cores.  A rede neural deve desenhar uma borda em torno de todas as ovelhas da mesma cor.  Em ess√™ncia, essa tarefa √© semelhante √† classifica√ß√£o de imagens: uma rede neural possui um conjunto de imagens (que representa como pontos em um espa√ßo multidimensional) e precisa agrupar imagens semelhantes. <br><br>  Johnson provou que uma rede neural n√£o lidar√° com essa tarefa se a largura das camadas for menor ou igual √† quantidade de dados de entrada.  Cada uma de nossas ovelhas pode ser descrita por dois dados de entrada: as coordenadas de sua localiza√ß√£o no campo, x e y.  Ent√£o a rede neural marca cada ovelha com cor e desenha uma borda ao redor da ovelha da mesma cor.  Nesse caso, para resolver o problema, voc√™ precisa de pelo menos tr√™s neur√¥nios por camada. <br><br>  Mais especificamente, Johnson mostrou que, se a raz√£o entre a largura e o n√∫mero de vari√°veis ‚Äã‚Äãn√£o for suficiente, a rede neural n√£o ser√° capaz de desenhar loops fechados - e uma rede neural teria que desenhar esse loop se, por exemplo, todas as ovelhas vermelhas tivessem se acumulado no meio do pasto.  "Se nenhuma das camadas for mais espessa que o n√∫mero de medi√ß√µes de entrada, a fun√ß√£o n√£o poder√° criar alguns formul√°rios, independentemente do n√∫mero de camadas", disse Johnson. <br><br>  Esse trabalho come√ßa a construir o n√∫cleo da teoria das redes neurais.  At√© agora, os pesquisadores s√£o capazes de fazer apenas as declara√ß√µes mais simples em rela√ß√£o ao relacionamento entre arquitetura e funcionalidade - e essas declara√ß√µes s√£o muito poucas em compara√ß√£o com o n√∫mero de tarefas resolvidas pelas redes neurais. <br><br>  Portanto, embora a teoria das redes neurais n√£o possa mudar o processo de seu design em um futuro pr√≥ximo, est√£o sendo criados projetos para uma nova teoria de como os computadores s√£o treinados - e suas consequ√™ncias ser√£o ainda mais fortes do que uma pessoa que sai para o espa√ßo. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt442574/">https://habr.com/ru/post/pt442574/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt442562/index.html">Como resfriar equipamentos em um data center - tr√™s novas tecnologias</a></li>
<li><a href="../pt442566/index.html">Igual √† lua: engenharia reversa de um m√≥dulo h√≠brido de amp op</a></li>
<li><a href="../pt442568/index.html">Semana 10 de seguran√ßa: Vulnerabilidades de driver NVIDIA</a></li>
<li><a href="../pt442570/index.html">Regras Sigma. Artesanato ou novo padr√£o para SOC</a></li>
<li><a href="../pt442572/index.html">Usando a ferramenta de configura√ß√£o do Datapath</a></li>
<li><a href="../pt442576/index.html">Overclockers de longa dura√ß√£o: como o resfriamento l√≠quido come√ßou a dominar nos data centers</a></li>
<li><a href="../pt442578/index.html">Lan√ßamento do Linux 5.0</a></li>
<li><a href="../pt442580/index.html">Engenharia reversa de formato bin√°rio usando arquivos .SNG da Korg como exemplo</a></li>
<li><a href="../pt442582/index.html">Como tentamos ass√©dio moral</a></li>
<li><a href="../pt442584/index.html">Documentos sobre o edif√≠cio: pequenas alegrias da automa√ß√£o no exemplo da Torre Negra</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>â™ï¸ ğŸ“‡ ğŸ†“ Meningkatkan agen Q-Learning berbasis saham dengan menambahkan perulangan dan penghargaan ğŸ‘©ğŸ»â€ğŸš’ ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘§ ğŸš…</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pengingat 
 Halo, Habr! Saya memberi perhatian Anda terjemahan lain dari artikel baru saya dari media . 

 Terakhir kali ( artikel pertama ) ( Habr ),...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Meningkatkan agen Q-Learning berbasis saham dengan menambahkan perulangan dan penghargaan</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436628/"><h3>  Pengingat </h3><br>  Halo, Habr!  Saya memberi perhatian Anda terjemahan lain dari artikel baru saya dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">media</a> . <br><br>  Terakhir kali ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel pertama</a> ) ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Habr</a> ), kami menciptakan agen menggunakan teknologi Q-Learning, yang melakukan transaksi pada rangkaian waktu simulasi dan pertukaran riil dan mencoba memeriksa apakah bidang tugas ini cocok untuk pembelajaran yang diperkuat. <br><br>  Kali ini kami akan menambahkan layer LSTM untuk memperhitungkan dependensi waktu akun dalam lintasan dan melakukan teknik pembentukan hadiah berdasarkan presentasi. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3c4/e75/63f/3c4e7563f3cf1e6f158dc0605fe80a78.png" alt="gambar"><br><a name="habracut"></a><br>  Biarkan saya mengingatkan Anda bahwa untuk memverifikasi konsep, kami menggunakan data sintetis berikut: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fb2/f15/3b6/fb2f153b6c4e14ff1dc19d61a524f5e8.png" alt="gambar"><br><br>  Data sintetis: sinus dengan noise putih. <br><br>  Fungsi sinus adalah titik awal pertama.  Dua kurva mensimulasikan harga pembelian dan penjualan suatu aset, di mana spread adalah biaya transaksi minimum. <br><br>  Namun, kali ini kami ingin menyulitkan tugas sederhana ini dengan memperluas jalur penugasan kredit: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/561/c36/928/561c369289780642ca5b22c852d06a8b.png" alt="gambar"><br><br>  Data sintetis: sinus dengan noise putih. <br><br>  Fase sinus digandakan. <br><br>  Ini berarti bahwa hadiah jarang yang kami gunakan harus tersebar di lintasan yang lebih panjang.  Selain itu, kami secara signifikan mengurangi kemungkinan menerima hadiah positif, karena agen harus melakukan serangkaian tindakan yang benar 2 kali lebih lama untuk mengatasi biaya transaksi.  Kedua faktor tersebut sangat menyulitkan tugas RL bahkan dalam kondisi sederhana seperti gelombang sinus. <br><br>  Selain itu, kami ingat bahwa kami menggunakan arsitektur jaringan saraf ini: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3dc/20c/e1e/3dc20ce1eedec47b871ef59ab7911ef3.png" alt="gambar"><br><br><h3>  Apa yang ditambahkan dan mengapa </h3><br><h4>  Lstm </h4><br>  Pertama-tama, kami ingin memberi agen lebih banyak pemahaman tentang dinamika perubahan dalam lintasan.  Sederhananya, agen harus lebih memahami perilakunya sendiri: apa yang dia lakukan sekarang dan untuk beberapa waktu di masa lalu, dan bagaimana distribusi tindakan negara, serta imbalan yang diterima, dikembangkan.  Menggunakan layer perulangan dapat memecahkan masalah ini dengan tepat.  Selamat datang di arsitektur baru yang digunakan untuk meluncurkan serangkaian eksperimen baru: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/09c/b6e/b0d/09cb6eb0d07dd7808657aaeaec5c5c7c.png" alt="gambar"><br><br>  Harap perhatikan bahwa deskripsi saya sedikit ditingkatkan.  Satu-satunya perbedaan dari NN lama adalah lapisan LSTM pertama yang tersembunyi dan bukan yang sepenuhnya terikat. <br><br>  Harap dicatat bahwa dengan LSTM dalam pekerjaan, kita harus mengubah pemilihan contoh reproduksi pengalaman untuk pelatihan: sekarang kita membutuhkan urutan transisi daripada contoh yang terpisah.  Begini cara kerjanya (ini adalah salah satu algoritma).  Kami menggunakan point sampling sebelum: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/51a/d0b/412/51ad0b4125f0d084e19e81d81a6b10a4.png" alt="gambar"><br><br>  Skema fiktif dari buffer pemutaran. <br><br>  Kami menggunakan skema ini dengan LSTM: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1ee/fb7/537/1eefb75379450cf86c03d5cf30e93dd9.png" alt="gambar"><br><br>  Sekarang urutan dipilih (yang panjangnya kita tentukan secara empiris). <br><br>  Seperti sebelumnya, dan sekarang sampel diatur oleh algoritma prioritas berdasarkan kesalahan pembelajaran temporal-temporal. <br><br>  Level rekurensi LSTM memungkinkan penyebaran informasi secara langsung dari deret waktu untuk mencegat sinyal tambahan yang tersembunyi di jeda waktu lalu.  Rangkaian waktu bersama kami adalah tensor dua dimensi dengan ukuran: panjang urutan pada representasi tindakan negara kami. <br><br><h4>  Presentasi </h4><br>  Rekayasa pemenang penghargaan, Potential Based Reward Shaping (PBRS), berdasarkan potensi, adalah alat yang ampuh yang memungkinkan Anda untuk meningkatkan kecepatan, stabilitas dan tidak melanggar optimalitas proses pencarian kebijakan untuk menyelesaikan masalah lingkungan kita.  Saya sarankan membaca setidaknya dokumen asli ini dengan topik: <br><br>  <a href="">people.eecs.berkeley.edu/~russell/papers/ml99-shaping.ps</a> <br><br>  Potensi menentukan seberapa baik keadaan kita saat ini relatif terhadap keadaan target yang ingin kita masukkan.  Pandangan skematis tentang cara kerjanya: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1b1/6f3/85d/1b16f385dedd440d6bd15f74b76f304d.png" alt="gambar"><br><br>  Ada beberapa opsi dan kesulitan yang bisa Anda pahami setelah coba-coba, dan kami menghilangkan detail ini, meninggalkan Anda dengan pekerjaan rumah Anda. <br><br>  Perlu disebutkan satu hal lagi, yaitu PBRS dapat dibenarkan menggunakan presentasi, yang merupakan bentuk pengetahuan ahli (atau simulasi) tentang perilaku agen yang <i>hampir</i> optimal di lingkungan.  Ada cara untuk menemukan presentasi seperti itu untuk tugas kami menggunakan skema optimisasi.  Kami menghilangkan detail pencarian. <br><br>  Potensi hadiah berupa: (persamaan 1): <br><br>  r '= r + gamma * F (s') - F (s) <br><br>  di mana F adalah potensi negara, dan r adalah hadiah awal, gamma adalah faktor diskon (0: 1). <br><br>  <b>Dengan pemikiran ini, kami beralih ke pengkodean.</b> <br><br>  Implementasi dalam R <br>  Berikut adalah kode jaringan saraf berdasarkan API Keras: <br><br><div class="spoiler">  <b class="spoiler_title">Kode</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># configure critic NN â€” â€” â€” â€” â€” â€” library('keras') library('R6') state_names_length &lt;- 12 # just for example lstm_seq_length &lt;- 4 learning_rate &lt;- 1e-3 a_CustomLayer &lt;- R6::R6Class( â€œCustomLayerâ€ , inherit = KerasLayer , public = list( call = function(x, mask = NULL) { x â€” k_mean(x, axis = 2, keepdims = T) } ) ) a_normalize_layer &lt;- function(object) { create_layer(a_CustomLayer, object, list(name = 'a_normalize_layer')) } v_CustomLayer &lt;- R6::R6Class( â€œCustomLayerâ€ , inherit = KerasLayer , public = list( call = function(x, mask = NULL) { k_concatenate(list(x, x, x), axis = 2) } , compute_output_shape = function(input_shape) { output_shape = input_shape output_shape[[2]] &lt;- input_shape[[2]] * 3L output_shape } ) ) v_normalize_layer &lt;- function(object) { create_layer(v_CustomLayer, object, list(name = 'v_normalize_layer')) } noise_CustomLayer &lt;- R6::R6Class( â€œCustomLayerâ€ , inherit = KerasLayer , lock_objects = FALSE , public = list( initialize = function(output_dim) { self$output_dim &lt;- output_dim } , build = function(input_shape) { self$input_dim &lt;- input_shape[[2]] sqr_inputs &lt;- self$input_dim ** (1/2) self$sigma_initializer &lt;- initializer_constant(.5 / sqr_inputs) self$mu_initializer &lt;- initializer_random_uniform(minval = (-1 / sqr_inputs), maxval = (1 / sqr_inputs)) self$mu_weight &lt;- self$add_weight( name = 'mu_weight', shape = list(self$input_dim, self$output_dim), initializer = self$mu_initializer, trainable = TRUE ) self$sigma_weight &lt;- self$add_weight( name = 'sigma_weight', shape = list(self$input_dim, self$output_dim), initializer = self$sigma_initializer, trainable = TRUE ) self$mu_bias &lt;- self$add_weight( name = 'mu_bias', shape = list(self$output_dim), initializer = self$mu_initializer, trainable = TRUE ) self$sigma_bias &lt;- self$add_weight( name = 'sigma_bias', shape = list(self$output_dim), initializer = self$sigma_initializer, trainable = TRUE ) } , call = function(x, mask = NULL) { #sample from noise distribution e_i = k_random_normal(shape = list(self$input_dim, self$output_dim)) e_j = k_random_normal(shape = list(self$output_dim)) #We use the factorized Gaussian noise variant from Section 3 of Fortunato et al. eW = k_sign(e_i) * (k_sqrt(k_abs(e_i))) * k_sign(e_j) * (k_sqrt(k_abs(e_j))) eB = k_sign(e_j) * (k_abs(e_j) ** (1/2)) #See section 3 of Fortunato et al. noise_injected_weights = k_dot(x, self$mu_weight + (self$sigma_weight * eW)) noise_injected_bias = self$mu_bias + (self$sigma_bias * eB) output = k_bias_add(noise_injected_weights, noise_injected_bias) output } , compute_output_shape = function(input_shape) { output_shape &lt;- input_shape output_shape[[2]] &lt;- self$output_dim output_shape } ) ) noise_add_layer &lt;- function(object, output_dim) { create_layer( noise_CustomLayer , object , list( name = 'noise_add_layer' , output_dim = as.integer(output_dim) , trainable = T ) ) } critic_input &lt;- layer_input( shape = list(NULL, as.integer(state_names_length)) , name = 'critic_input' ) common_lstm_layer &lt;- layer_lstm( units = 20 , activation = â€œtanhâ€ , recurrent_activation = â€œhard_sigmoidâ€ , use_bias = T , return_sequences = F , stateful = F , name = 'lstm1' ) critic_layer_dense_v_1 &lt;- layer_dense( units = 10 , activation = â€œtanhâ€ ) critic_layer_dense_v_2 &lt;- layer_dense( units = 5 , activation = â€œtanhâ€ ) critic_layer_dense_v_3 &lt;- layer_dense( units = 1 , name = 'critic_layer_dense_v_3' ) critic_layer_dense_a_1 &lt;- layer_dense( units = 10 , activation = â€œtanhâ€ ) # critic_layer_dense_a_2 &lt;- layer_dense( # units = 5 # , activation = â€œtanhâ€ # ) critic_layer_dense_a_3 &lt;- layer_dense( units = length(actions) , name = 'critic_layer_dense_a_3' ) critic_model_v &lt;- critic_input %&gt;% common_lstm_layer %&gt;% critic_layer_dense_v_1 %&gt;% critic_layer_dense_v_2 %&gt;% critic_layer_dense_v_3 %&gt;% v_normalize_layer critic_model_a &lt;- critic_input %&gt;% common_lstm_layer %&gt;% critic_layer_dense_a_1 %&gt;% #critic_layer_dense_a_2 %&gt;% noise_add_layer(output_dim = 5) %&gt;% critic_layer_dense_a_3 %&gt;% a_normalize_layer critic_output &lt;- layer_add( list( critic_model_v , critic_model_a ) , name = 'critic_output' ) critic_model_1 &lt;- keras_model( inputs = critic_input , outputs = critic_output ) critic_optimizer = optimizer_adam(lr = learning_rate) keras::compile( critic_model_1 , optimizer = critic_optimizer , loss = 'mse' , metrics = 'mse' ) train.x &lt;- array_reshape(rnorm(10 * lstm_seq_length * state_names_length) , dim = c(10, lstm_seq_length, state_names_length) , order = 'C') predict(critic_model_1, train.x) layer_name &lt;- 'noise_add_layer' intermediate_layer_model &lt;- keras_model(inputs = critic_model_1$input, outputs = get_layer(critic_model_1, layer_name)$output) predict(intermediate_layer_model, train.x)[1,] critic_model_2 &lt;- critic_model_1</span></span></code> </pre> <br></div></div><br>  Men-debug keputusan Anda berdasarkan hati nurani Anda ... <br><br><h3>  Hasil dan Perbandingan </h3><br>  Mari selami hasil akhirnya.  <i>Catatan: semua hasil adalah estimasi titik dan mungkin berbeda pada beberapa kali berjalan dengan berbagai sids seed acak.</i> <br><br>  Perbandingan meliputi: <br><br><ul><li>  versi sebelumnya tanpa LSTM dan presentasi </li><li>  LSTM 2-elemen sederhana </li><li>  LSTM 4-elemen </li><li>  LSTM 4 sel dengan imbalan PBRS yang dihasilkan </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/f2f/886/034/f2f886034a399fd4e1ecacf7ad418829.png" alt="gambar"><br><br>  Pengembalian rata-rata per episode rata-rata lebih dari 1000 episode. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/26f/38c/8ef/26f38c8ef64089c605a92abaf899ba10.png" alt="gambar"><br><br>  Total episode kembali. <br><br>  <b>Bagan untuk agen paling sukses:</b> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/30e/304/c65/30e304c65ce97da566c6070b0338d472.jpg" alt="gambar"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/000/7d1/8a0/0007d18a0336590c79e4c3edcf5b0a9f.png" alt="gambar"><br><br>  Kinerja agen. <br><br>  Yah, cukup jelas bahwa agen dalam bentuk PBRS bertemu begitu cepat dan stabil dibandingkan dengan upaya sebelumnya sehingga dapat diterima sebagai hasil yang signifikan.  Kecepatannya sekitar 4-5 kali lebih tinggi daripada tanpa presentasi.  Stabilitas luar biasa. <br><br>  Ketika menggunakan LSTM, 4 sel memiliki kinerja lebih baik dari 2 sel.  LSTM 2 sel tampil lebih baik daripada versi non-LSTM (namun, mungkin ini adalah ilusi dari satu percobaan). <br><br><h3>  Kata-kata terakhir </h3><br>  Kita telah melihat bahwa penghargaan yang berulang dan pembangunan kapasitas membantu.  Saya terutama menyukai kinerja PBRS yang sangat tinggi. <br><br>  Jangan percaya siapa pun yang membuat saya mengatakan bahwa mudah untuk membuat agen RL yang menyatu dengan baik, karena itu bohong.  Setiap komponen baru yang ditambahkan ke sistem membuatnya berpotensi kurang stabil dan membutuhkan banyak konfigurasi dan debugging. <br><br>  Namun demikian, ada bukti jelas bahwa solusi untuk masalah tersebut dapat diperbaiki hanya dengan meningkatkan metode yang digunakan (data tetap utuh).  Adalah fakta bahwa untuk tugas apa pun sejumlah parameter tertentu berfungsi lebih baik daripada yang lain.  Dengan pemikiran ini, Anda memulai jalur pembelajaran yang sukses. <br><br>  <b>Terima kasih</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id436628/">https://habr.com/ru/post/id436628/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id436618/index.html">Apa yang harus dipersiapkan di 2019: tren pemrograman</a></li>
<li><a href="../id436620/index.html">Pendekatan terintegrasi untuk memvisualisasikan peristiwa keamanan dan mengukur efektivitasnya</a></li>
<li><a href="../id436622/index.html">Botovodstvo</a></li>
<li><a href="../id436624/index.html">Belajar: sebagian besar pengguna tidak mengerti bagaimana Facebook menangani data mereka.</a></li>
<li><a href="../id436626/index.html">Python menjadi bahasa pemrograman paling populer di dunia.</a></li>
<li><a href="../id436630/index.html">Layanan microser. Penyatuan dan mengapa itu sangat penting. Bagian 1 - Konfigurasi</a></li>
<li><a href="../id436632/index.html">Bagaimana kami membangun sistem untuk memproses, menyimpan, dan menganalisis data dalam SIBUR</a></li>
<li><a href="../id436634/index.html">Hanya tentang pengaturan internal dan eksternal untuk aplikasi di Unity3D</a></li>
<li><a href="../id436636/index.html">Bagaimana saya membuat layanan rekomendasi komunitas VKontakte</a></li>
<li><a href="../id436638/index.html">Mendistribusikan kembali jendela di antara monitor setelah bangun dari mode tidur</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
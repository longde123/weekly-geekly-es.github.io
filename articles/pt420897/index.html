<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•ê üîÄ üì± Treinamento de refor√ßo PyBullet üî® üìá üéóÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Muitas pessoas que estudam o aprendizado de m√°quina est√£o familiarizadas com o projeto OpenAI, um dos fundadores, Elon Musk, e usam a plataforma OpenA...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Treinamento de refor√ßo PyBullet</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420897/"><img src="https://habrastorage.org/webt/0g/x5/ai/0gx5aizowrlyrgkvekcxlxh9pge.png" alt="imagem"><br><br>  Muitas pessoas que estudam o aprendizado de m√°quina est√£o familiarizadas com o projeto OpenAI, um dos fundadores, Elon Musk, e usam a plataforma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenAI Gym</a> para treinar seus modelos de redes neurais. <br><br>  O gin√°sio cont√©m um enorme conjunto de ambientes, alguns deles s√£o v√°rios tipos de simula√ß√µes f√≠sicas: os movimentos de animais, humanos, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rob√¥s</a> .  Essas simula√ß√µes s√£o baseadas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mecanismo de</a> f√≠sica <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MuJoCo</a> , gratuito para fins educacionais e cient√≠ficos. <br><br>  Neste artigo, criaremos uma simula√ß√£o f√≠sica extremamente simples, semelhante ao ambiente OpenAI Gym, mas baseada no mecanismo de f√≠sica livre Bullet ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PyBullet</a> ).  E tamb√©m crie um agente para trabalhar com esse ambiente. <br><a name="habracut"></a><br>  PyBullet √© um m√≥dulo python para criar um ambiente de simula√ß√£o f√≠sica baseado no mecanismo de f√≠sica <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Bullet Physics</a> .  Como MuJoCo, √© frequentemente usado como est√≠mulo de v√°rios rob√¥s, que est√£o interessados ‚Äã‚Äãem habr. Existe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um artigo</a> com exemplos reais. <br><br>  Existe um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">QuickStartGuide</a> bastante bom para PyBullet que cont√©m links para exemplos na p√°gina de origem no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GitHub</a> . <br><br>  PyBullet permite carregar modelos j√° criados no formato URDF, SDF ou MJCF.  Nas fontes, existe uma biblioteca de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">modelos</a> nesses formatos, bem como ambientes completamente prontos para uso de simuladores de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rob√¥s reais.</a> <br><br>  No nosso caso, n√≥s mesmos criaremos o ambiente usando PyBullet.  A interface do ambiente ser√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">semelhante √†</a> interface do OpenAI Gym.  Dessa forma, podemos treinar nossos agentes tanto em nosso ambiente quanto no ambiente da academia. <br><br>  Todo o c√≥digo (iPython), bem como a opera√ß√£o do programa, podem ser vistos no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Google Colaboratory</a> . <br><br><h2>  Meio ambiente </h2><br>  Nosso ambiente consistir√° em uma bola que pode se mover ao longo do eixo vertical dentro de um certo intervalo de alturas.  A bola tem massa e a gravidade atua sobre ela, e o agente deve, controlando a for√ßa vertical aplicada √† bola, traz√™-la ao alvo.  A altitude alvo muda a cada rein√≠cio da experi√™ncia. <br><br><img src="https://habrastorage.org/webt/w-/wy/jr/w-wyjrj1zphr8aqndhutrnno1po.png" alt="imagem"><br><br>  A simula√ß√£o √© muito simples e, de fato, pode ser considerada como uma simula√ß√£o de algum mecanismo elementar. <br><br>  Para trabalhar com o ambiente, s√£o utilizados tr√™s m√©todos: <i><b>redefinir</b></i> (reiniciar o experimento e criar todos os objetos do ambiente), <i><b>etapa</b></i> (aplicar a a√ß√£o selecionada e obter o estado resultante do ambiente), <i><b>render</b></i> (exibi√ß√£o visual do ambiente). <br><br>  Ao inicializar o ambiente, √© necess√°rio conectar nosso objeto √† simula√ß√£o f√≠sica.  Existem 2 op√ß√µes de conex√£o: com uma interface gr√°fica (GUI) e sem (DIRECT), que, no nosso caso, √© DIRECT. <br><br><pre><code class="python hljs">pb.connect(pb.DIRECT)</code> </pre> <br><h4>  redefinir </h4><br>  A cada nova experi√™ncia, redefinimos a simula√ß√£o <i>pb.resetSimulation ()</i> e criamos todos os objetos do ambiente novamente. <br><br>  No PyBullet, os objetos t√™m duas formas: uma <i>forma de</i> colis√£o e uma <i>forma visual</i> .  O primeiro √© usado pelo mecanismo f√≠sico para calcular colis√µes de objetos e, para acelerar o c√°lculo da f√≠sica, geralmente tem uma forma mais simples que um objeto real.  O segundo √© opcional e √© usado apenas ao formar a imagem do objeto. <br><br>  Os formul√°rios s√£o coletados em um √∫nico objeto (corpo) - <i>MultiBody</i> .  Um corpo pode ser composto de uma forma (par <i>CollisionShape / Visual Shape</i> ), como no nosso caso, ou v√°rias. <br><br>  Al√©m das formas que comp√µem o corpo, √© necess√°rio determinar sua massa, posi√ß√£o e orienta√ß√£o no espa√ßo. <br><br><div class="spoiler">  <b class="spoiler_title">Algumas palavras sobre corpos com v√°rios objetos.</b> <div class="spoiler_text">  Por via de regra, em casos reais, para simular v√°rios mecanismos, s√£o utilizados corpos constitu√≠dos por v√°rias formas.  Ao criar o corpo, al√©m da forma b√°sica de colis√µes e visualiza√ß√£o, o corpo √© transferido para cadeias de formas de objetos filhos ( <i>Links</i> ), sua posi√ß√£o e orienta√ß√£o em rela√ß√£o ao objeto anterior, bem como os tipos de conex√µes (juntas) de objetos entre si ( <i>Articula√ß√£o</i> ).  Os tipos de conex√µes podem ser fixos, prism√°ticos (deslizando no mesmo eixo) ou rotacionais (girando em um eixo).  Os dois √∫ltimos tipos de conex√µes permitem definir os par√¢metros dos tipos correspondentes de motores ( <i>JointMotor</i> ), como for√ßa de atua√ß√£o, velocidade ou torque, simulando assim os motores das "juntas" do rob√¥.  Mais detalhes na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o</a> . <br></div></div><br>  Vamos criar 3 corpos: bola, avi√£o (terra) e ponteiro alvo.  O √∫ltimo objeto ter√° apenas uma forma de visualiza√ß√£o e massa zero, portanto, n√£o participar√° da intera√ß√£o f√≠sica entre os corpos: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  floorColShape = pb.createCollisionShape(pb.GEOM_PLANE) #   (GEOM_PLANE), visualShape -    ,   GEOM_BOX floorVisualShapeId = pb.createVisualShape(pb.GEOM_BOX,halfExtents=[100,100,0.0001], rgbaColor=[1,1,.98,1]) pb_floorId = pb.createMultiBody(0,floorColShape,floorVisualShapeId, [0,0,0], [0,0,0,1]) #  PB_BallRadius = 0.2 PB_BallMass = 1 ballPosition = [0,0,5] ballOrientation=[0,0,0,1] ballColShape = pb.createCollisionShape(pb.GEOM_SPHERE,radius=PB_BallRadius) ballVisualShapeId = pb.createVisualShape(pb.GEOM_SPHERE,radius=PB_BallRadius, rgbaColor=[1,0.27,0,1]) pb_ballId = pb.createMultiBody(PB_BallMass, ballColShape, ballVisualShapeId, ballPosition, ballOrientation) #   TARGET_Z = 8 targetPosition = [0,0,TARGET_Z] targetOrientation=[0,0,0,1] targetVisualShapeId = pb.createVisualShape(pb.GEOM_BOX,halfExtents=[1,0.025,0.025], rgbaColor=[0,0,0,1]) pb_targetId = pb.createMultiBody(0,-1, targetVisualShapeId, targetPosition, targetOrientation)</span></span></code> </pre><br>  Defina a gravidade e o tempo da etapa de simula√ß√£o. <br><br><pre> <code class="python hljs">pb.setGravity(<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">-10</span></span>) pb.setTimeStep(<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">60</span></span>)</code> </pre> <br>  Para evitar que a bola caia imediatamente ap√≥s o in√≠cio da simula√ß√£o, equilibramos a gravidade. <br><br><pre> <code class="python hljs">pb_force = <span class="hljs-number"><span class="hljs-number">10</span></span> * PB_BallMass pb.applyExternalForce(pb_ballId, <span class="hljs-number"><span class="hljs-number">-1</span></span>, [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,pb_force], [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>], pb.LINK_FRAME)</code> </pre> <br><br><h4>  passo </h4><br>  O agente seleciona a√ß√µes com base no estado atual do ambiente, ap√≥s o qual chama o m√©todo <i>step</i> e recebe um novo estado. <br><br>  S√£o definidos 2 tipos de a√ß√£o: aumento e diminui√ß√£o da for√ßa que atua na bola.  Os limites de for√ßa s√£o limitados. <br><br>  Ap√≥s alterar a for√ßa que atua na bola, uma nova etapa da simula√ß√£o f√≠sica <i>pb.stepSimulation () √© iniciada</i> e os seguintes par√¢metros s√£o retornados ao agente: <br><br>  <i>observa√ß√£o</i> - observa√ß√µes (estado do ambiente) <br>  <i>recompensa</i> - recompensa pela a√ß√£o perfeita <br>  <i>done</i> - a bandeira do fim da experi√™ncia <br>  <i>info</i> - informa√ß√µes adicionais <br><br>  Como o estado do ambiente, s√£o retornados 3 valores: a dist√¢ncia do alvo, a for√ßa atual aplicada √† bola e a velocidade da bola.  Os valores s√£o retornados normalizados (0..1), pois os par√¢metros ambientais que determinam esses valores podem variar dependendo do nosso desejo. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     (     Z curPos[2]) curPos, curOrient = pb.getBasePositionAndOrientation(pb_ballId) #     (      Z lin_vel[2]) lin_vel, ang_vel= pb.getBaseVelocity(self.pb_ballId)</span></span></code> </pre> <br>  A recompensa pela a√ß√£o perfeita √© 1 se a bola estiver pr√≥xima do alvo (altura do alvo mais / menos o valor aceit√°vel de rolamento <i>TARGET_DELTA</i> ) e 0 em outros casos. <br>  O experimento √© conclu√≠do se a bola sair da zona (cair no ch√£o ou voar alto).  Se a bola atingir a meta, o experimento tamb√©m termina, mas somente ap√≥s um certo tempo ( <i>STEPS_AFTER_TARGET</i> etapas do experimento).  Assim, nosso agente √© treinado n√£o apenas para avan√ßar em dire√ß√£o √† meta, mas tamb√©m para parar e se aproximar dela.  Dado que a recompensa quando voc√™ est√° perto da meta √© 1, uma experi√™ncia totalmente bem-sucedida deve ter uma recompensa total igual a <i>STEPS_AFTER_TARGET</i> . <br><br>  Como informa√ß√µes adicionais para a exibi√ß√£o de estat√≠sticas, o n√∫mero total de etapas executadas no experimento, bem como o n√∫mero de etapas executadas por segundo, √© retornado. <br><br><h4>  render </h4><br>  O PyBullet possui 2 op√ß√µes de renderiza√ß√£o de imagem - renderiza√ß√£o GPU baseada em OpenGL e CPU baseada em TinyRenderer.  No nosso caso, apenas uma implementa√ß√£o de CPU √© poss√≠vel. <br><br>  Para obter o quadro atual da simula√ß√£o, √© necess√°rio determinar a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">matriz de esp√©cies</a> e a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">matriz de proje√ß√£o</a> e obter a imagem <i>rgb</i> do tamanho especificado na c√¢mera. <br><br><pre> <code class="python hljs">camTargetPos = [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>] <span class="hljs-comment"><span class="hljs-comment">#   ()  camDistance = 10 #     yaw = 0 #     pitch = 0 #     roll=0 #      upAxisIndex = 2 #    (z) fov = 60 #    nearPlane = 0.01 #      farPlane = 20 #      pixelWidth = 320 #   pixelHeight = 200 #   aspect = pixelWidth/pixelHeight; #    #   viewMatrix = pb.computeViewMatrixFromYawPitchRoll(camTargetPos, camDistance, yaw, pitch, roll, upAxisIndex) #   projectionMatrix = pb.computeProjectionMatrixFOV(fov, aspect, nearPlane, farPlane); #     img_arr = pb.getCameraImage(pixelWidth, pixelHeight, viewMatrix, projectionMatrix, shadow=0, lightDirection=[0,1,1],renderer=pb.ER_TINY_RENDERER) w=img_arr[0] #width of the image, in pixels h=img_arr[1] #height of the image, in pixels rgb=img_arr[2] #color data RGB dep=img_arr[3] #depth data</span></span></code> </pre> <br>  No final de cada experi√™ncia, um v√≠deo √© gerado com base nas imagens coletadas. <br><br><pre> <code class="python hljs">ani = animation.ArtistAnimation(plt.gcf(), render_imgs, interval=<span class="hljs-number"><span class="hljs-number">10</span></span>, blit=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>,repeat_delay=<span class="hljs-number"><span class="hljs-number">1000</span></span>) display(HTML(ani.to_html5_video()))</code> </pre><br><h2>  Agente </h2><br>  O c√≥digo de usu√°rio do GitHub <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">jaara</a> foi tomado como base para o Agent, como um exemplo simples e compreens√≠vel de implementa√ß√£o de treinamento de refor√ßo para o ambiente da academia. <br><br>  O agente cont√©m 2 objetos: <i>Mem√≥ria</i> - um armazenamento para a forma√ß√£o de exemplos de treinamento e o <i>pr√≥prio c√©rebro √©</i> a rede neural que ele treina. <br><br>  A rede neural treinada foi criada no TensorFlow usando a biblioteca Keras, que recentemente foi totalmente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">inclu√≠da</a> no TensorFlow. <br>  A rede neural tem uma estrutura simples - 3 camadas, ou seja,  Apenas 1 camada oculta. <br><br>  A primeira camada cont√©m 512 neur√¥nios e possui um n√∫mero de entradas igual ao n√∫mero de par√¢metros do estado do meio (3 par√¢metros: dist√¢ncia ao alvo, for√ßa e velocidade da bola).  A camada oculta tem uma dimens√£o igual √† primeira camada - 512 neur√¥nios, na sa√≠da est√° conectada √† camada de sa√≠da.  O n√∫mero de neur√¥nios da camada de sa√≠da corresponde ao n√∫mero de a√ß√µes executadas pelo agente (2 a√ß√µes: diminuir e aumentar a for√ßa de atua√ß√£o). <br><br>  Assim, o estado do sistema √© fornecido √† entrada da rede e, na sa√≠da, temos um benef√≠cio para cada uma das a√ß√µes. <br><br>  Para as duas primeiras camadas, <i>ReLU</i> (unidade linear retificada) √© usada como fun√ß√£o de ativa√ß√£o; para a √∫ltima - uma <i>fun√ß√£o linear</i> (a soma dos valores de entrada √© simples). <br>  Em fun√ß√£o do erro, <i>MSE</i> (erro padr√£o), como algoritmo de otimiza√ß√£o - <i>RMSprop</i> (Propaga√ß√£o do Quadrado M√©dio Raiz). <br><br><pre> <code class="python hljs">model = Sequential() model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_dim=<span class="hljs-number"><span class="hljs-number">3</span></span>)) model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'linear'</span></span>)) opt = RMSprop(lr=<span class="hljs-number"><span class="hljs-number">0.00025</span></span>) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'mse'</span></span>, optimizer=opt)</code> </pre><br>  Ap√≥s cada etapa da simula√ß√£o, o Agente salva os resultados dessa etapa na forma de uma lista <i>(s, a, r, s_)</i> : <br>  <i>s</i> - observa√ß√£o anterior (estado do ambiente) <br>  <i>a</i> - a√ß√£o conclu√≠da <br>  <i>r</i> - recompensa recebida pela a√ß√£o executada <br>  <i>s_</i> - observa√ß√£o final ap√≥s a a√ß√£o <br><br>  Depois disso, o Agente recebe da mem√≥ria um conjunto aleat√≥rio de exemplos para per√≠odos anteriores e forma um pacote de treinamento ( <i>lote</i> ). <br><br>  Os estados iniciais das etapas aleat√≥rias selecionadas na mem√≥ria s√£o tomados como valores de entrada ( <i>X</i> ) do pacote. <br><br>  Os valores reais da sa√≠da de aprendizado ( <i>Y '</i> ) s√£o calculados da seguinte forma: Na sa√≠da ( <i>Y</i> ) da rede neural para s, haver√° valores da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">fun√ß√£o Q</a> para cada uma das a√ß√µes <i>Q (s)</i> .  Nesse conjunto, o agente selecionou a a√ß√£o com o valor mais alto <i>Q (s, a) = MAX (Q (s))</i> , concluiu e recebeu o pr√™mio <i>r</i> .  O novo valor <i>Q</i> para a a√ß√£o selecionada <i>a</i> ser√° <i>Q (s, a) = Q (s, a) + DF * r</i> , onde <i>DF</i> √© o fator de desconto.  Os valores de sa√≠da restantes permanecer√£o os mesmos. <br><br><pre> <code class="python hljs">STATE_CNT = <span class="hljs-number"><span class="hljs-number">3</span></span> ACTION_CNT = <span class="hljs-number"><span class="hljs-number">2</span></span> batchLen = <span class="hljs-number"><span class="hljs-number">32</span></span> <span class="hljs-comment"><span class="hljs-comment">#     states = numpy.array([ o[0] for o in batch ]) #     states_ = numpy.array([ o[3] for o in batch ]) #     p = agent.brain.predict(states) #     p_ = agent.brain.predict(states_) #     x = numpy.zeros((batchLen, STATE_CNT)) y = numpy.zeros((batchLen, ACTION_CNT)) #   for i in range(batchLen): o = batch[i] s = o[0]; a = o[1]; r = o[2]; s_ = o[3] t = p[i] #      #      ,       t[a] = r + GAMMA * numpy.amax(p_[i]) #            #    batch x[i] = s y[i] = t #      self.brain.train(x, y)</span></span></code> </pre> <br>  O treinamento em rede ocorre no pacote formado <br><br><pre> <code class="python hljs">self.model.fit(x, y, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Ap√≥s a conclus√£o da experi√™ncia, um v√≠deo √© gerado <br><br><img src="https://habrastorage.org/webt/om/ox/rk/omoxrkmnrigllf9hu_8x9ofbd7m.gif" alt="imagem"><br><br>  e estat√≠sticas s√£o exibidas <br><br><img src="https://habrastorage.org/webt/0s/ed/p2/0sedp2zvwqmiiku6emmhp2yxf7m.png" alt="imagem"><br><br>  O agente precisou de 1.200 ensaios para alcan√ßar um resultado de cerca de 95% (n√∫mero de etapas bem-sucedidas).  E no 50¬∫ experimento, o Agente havia aprendido a mover a bola para o alvo (experimentos malsucedidos desaparecem). <br><br>  Para melhorar os resultados, voc√™ pode tentar alterar o tamanho das camadas da rede (LAYER_SIZE), o par√¢metro do fator de desconto (GAMMA) ou a taxa de redu√ß√£o na probabilidade de escolher uma a√ß√£o aleat√≥ria (LAMBDA). <br><br>  Nosso agente possui a arquitetura mais simples - DQN (Deep Q-Network).  Em uma tarefa t√£o simples, basta obter um resultado aceit√°vel. <br><br>  Usando, por exemplo, a arquitetura DDQN (Double DQN) deve fornecer um treinamento mais suave e preciso.  E a rede RDQN (DQN recorrente) poder√° rastrear os padr√µes de mudan√ßa ambiental ao longo do tempo, o que tornar√° poss√≠vel se livrar do par√¢metro de velocidade da bola, reduzindo o n√∫mero de par√¢metros de entrada da rede. <br><br>  Voc√™ tamb√©m pode expandir nossa simula√ß√£o adicionando uma massa vari√°vel da bola ou o √¢ngulo de inclina√ß√£o do seu movimento. <br><br>  Mas esta √© a pr√≥xima vez. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt420897/">https://habr.com/ru/post/pt420897/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt420887/index.html">Relat√≥rio Tele2 Hackathon</a></li>
<li><a href="../pt420889/index.html">Tecnologia militar de detec√ß√£o de minas ajuda os robomobiles a percorrer todas as estradas</a></li>
<li><a href="../pt420891/index.html">Migra√ß√£o para a JUnit 5 em 10 min. Medindo o tempo de teste com extens√µes</a></li>
<li><a href="../pt420893/index.html">Embalagem de franquia A a B</a></li>
<li><a href="../pt420895/index.html">Como ressuscitei um dispositivo (emulador JTAG BH-USB-560v2) via U-Boot</a></li>
<li><a href="../pt420901/index.html">Como eu estudo a estrutura do Spring (ajuda para iniciantes √© o trabalho dos pr√≥prios iniciantes)</a></li>
<li><a href="../pt420903/index.html">Implementa√ß√£o do ERP: como n√£o falhar</a></li>
<li><a href="../pt420905/index.html">Como a ilumina√ß√£o inteligente √© introduzida na R√∫ssia e quanto tempo levar√°</a></li>
<li><a href="../pt420907/index.html">De NOKLA a Xiaomi: a evolu√ß√£o dos telefones celulares chineses</a></li>
<li><a href="../pt420909/index.html">Empresas de TV russas acusam Yandex de pirataria</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
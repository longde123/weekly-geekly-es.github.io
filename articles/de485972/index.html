<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üà∑Ô∏è üîë üçÖ Regressionsanalysemethoden in Data Science üê≠ ‚ôÄÔ∏è üí≠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Am Vorabend des Kursbeginns ‚ÄûMathematik f√ºr Data Science. Advanced Course ‚Äúf√ºhrten wir ein offenes Webinar zum Thema‚Äû Methoden der Regressionsanalyse ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Regressionsanalysemethoden in Data Science</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/485972/">  <i>Am Vorabend des Kursbeginns <a href="https://otus.pw/ImPO/">‚ÄûMathematik f√ºr Data Science.</a></i>  <i><a href="https://otus.pw/ImPO/">Advanced Course ‚Äúf√ºhrten</a> wir ein offenes Webinar zum Thema‚Äû Methoden der Regressionsanalyse in der Datenwissenschaft ‚Äúdurch.</i>  <i>Daraufhin haben wir uns mit dem Konzept der linearen Regressionen vertraut gemacht, untersucht, wo und wie sie in der Praxis angewendet werden k√∂nnen, und erfahren, welche Themen und Abschnitte der mathematischen Analyse, der linearen Algebra und der Wahrscheinlichkeitstheorie in diesem Bereich verwendet werden.</i>  <i>Dozent - <a href="https://otus.pw/vCj4/">Peter Lukyanchenko</a> , Dozent an der Hochschule f√ºr Wirtschaft, Leiter Technologieprojekte.</i> <br><br><img src="https://habrastorage.org/webt/bh/te/w1/bhtew1g0qxqyfzwkhznrxsli-qk.jpeg"><br><hr><br>  Wenn wir im Kontext von Data Science √ºber Mathematik sprechen, k√∂nnen wir die drei am h√§ufigsten gel√∂sten Probleme herausgreifen (obwohl es nat√ºrlich mehr Probleme gibt): <a name="habracut"></a><br><br><img src="https://habrastorage.org/webt/is/0t/zf/is0tzfvkh408lytpjnpwrugh64c.png"><br><br>  Sprechen wir √ºber diese Aufgaben im Detail: <br><br><ol><li>  <b>Die Aufgabe der Regressionsanalyse</b> oder der Identifizierung von Abh√§ngigkeiten (wenn wir eine Reihe von Beobachtungen haben).  In der obigen Grafik k√∂nnen Sie sehen, dass es eine bestimmte Variable x und eine bestimmte Variable y gibt, und wir beobachten die Werte von y f√ºr ein bestimmtes x.  Wir kennen diese Punkte und kennen ihre Koordinaten, und wir wissen auch, dass x y irgendwie beeinflusst, das hei√üt, diese beiden Variablen sind voneinander abh√§ngig.  Nat√ºrlich wollen wir die Abh√§ngigkeitsgleichung berechnen - hierf√ºr verwenden wir das <b>Modell der</b> <b>klassischen paarweisen linearen Regression</b> , wenn angenommen wird, dass ihre Abh√§ngigkeit durch eine bestimmte Gerade beschrieben werden kann.  Dementsprechend werden dann die Geraden-Koeffizienten ausgew√§hlt, um den Fehler in der Beschreibung der Daten zu minimieren.  Und genau davon, welche Art von Fehler (Qualit√§tsmetrik) ausgew√§hlt wird, h√§ngt das tats√§chliche Ergebnis der Konstruktion einer linearen Regression ab. </li><li> Eine weitere Aufgabe der Datenanalyse sind <b>Empfehlungssysteme</b> .  Dies ist, wenn wir sagen, dass es zum Beispiel Online-Shops gibt, die eine bestimmte Menge von Waren haben und eine Person Eink√§ufe t√§tigt.  Basierend auf diesen Informationen ist es m√∂glich, eine Beschreibung dieser Person im Vektorraum bereitzustellen und, nachdem dieser Vektorraum erstellt wurde, eine mathematische Abh√§ngigkeit von der Wahrscheinlichkeit zu erstellen, mit der diese Person dieses oder jenes Produkt in Kenntnis ihrer vorherigen Eink√§ufe kaufen wird.  Dementsprechend sprechen wir von Klassifizierung, wenn wir potenzielle K√§ufer nach den Grunds√§tzen ‚ÄûKaufen-Nicht-Kaufen‚Äú, ‚ÄûInteressant-Uninteressant‚Äú usw. klassifizieren. Es gibt verschiedene Ans√§tze: benutzerbasiert und artikelbasiert. </li><li>  Der dritte Bereich ist <b>Computer Vision</b> .  Im Rahmen dieser Aufgabe versuchen wir festzustellen, wo sich das f√ºr uns interessante Objekt befindet.  Dies ist eigentlich eine L√∂sung f√ºr das Problem der Fehlerminimierung, indem bestimmte Pixel ausgew√§hlt werden, die das Bild des Objekts bilden. </li></ol><br><br>  Bei allen drei Problemen gibt es Optimierung, Fehlerminimierung und das Vorhandensein des einen oder anderen Modells, das die Abh√§ngigkeit von Variablen beschreibt.  Gleichzeitig befindet sich in jedem eine Darstellung von Daten, die in eine Vektorbeschreibung zerlegt werden.  In unserem Artikel widmen wir dem Abschnitt, der sich auf <b>Regressionsmodelle</b> auswirkt, besondere Aufmerksamkeit. <br><br>  Wir haben bereits erw√§hnt, dass es eine Reihe von Datenpaaren gibt: X und Y. Wir wissen, welche Werte Y in Bezug auf X annimmt. Wenn X die Zeit ist, erhalten wir ein Zeitreihenmodell, in dem Y beispielsweise der √ñlpreis ist und zur gleichen Zeit, der Rubel-Dollar-Wechselkurs, und X ist ein bestimmter Zeitraum von 2014 bis 2018: <br><br><img src="https://habrastorage.org/webt/ny/o-/fe/nyo-fezmgc4axf1r14cwebhnr-y.png"><br><br>  Wenn Sie grafisch erstellen, ist klar, dass diese beiden Zeitreihen voneinander abh√§ngig sind.  Nachdem Sie das Konzept der Korrelation definiert haben, k√∂nnen Sie den Grad ihrer Abh√§ngigkeit berechnen. Wenn Sie dann wissen, dass einige Werte perfekt korreliert sind (die Korrelation ist 1 oder -1), k√∂nnen Sie dies entweder f√ºr Prognoseaufgaben oder f√ºr Beschreibungsaufgaben verwenden. <br><br>  Betrachten Sie die folgende Abbildung: <br><br><img src="https://habrastorage.org/webt/e1/ex/g4/e1exg4abmo64pnh7v0ayez8bjqy.png"><br><br>  Der schwierigste Teil bei der Bildung eines Regressionsmodells besteht darin, <b>zun√§chst eine bestimmte Funktion in sein Ged√§chtnis zu √ºbernehmen</b> .  Zum Beispiel ist in Abbildung A Y = kX + b, in Abbildung C ist Y = -kX + b, in Abbildung C ist das ‚ÄûSpiel‚Äú gleich einer Zahl, der Graph in Abbildung D basiert h√∂chstwahrscheinlich auf der Wurzel von X ‚Äù, an der Basis von D, m√∂glicherweise eine Parabel, und an der Basis von E - eine √úbertreibung. <br><br>  Es stellt sich heraus, dass <b>wir ein Modell der Datenabh√§ngigkeit w√§hlen</b> und die Arten der Abh√§ngigkeit zwischen Zufallsvariablen unterschiedlich sind.  Alles ist nicht so offensichtlich, denn auch in diesen einfachen Zeichnungen sehen wir verschiedene Abh√§ngigkeiten.  Durch Auswahl einer bestimmten Beziehung k√∂nnen wir Regressionsmethoden verwenden, um das Modell zu kalibrieren. <br><br>  <b>Die Qualit√§t Ihrer Prognosen h√§ngt davon ab, welches Modell Sie ausw√§hlen</b> .  Wenn wir uns auf lineare Regressionsmodelle konzentrieren, nehmen wir an, dass es eine Reihe von reellen Werten gibt: <br><br><img src="https://habrastorage.org/webt/b4/jw/s3/b4jws3cmqq7vuhi1qihfwg17za0.png"><br><br>  Die Abbildung zeigt die 4 beobachteten Werte von X1, X2, X2, X4.  F√ºr jedes der X ist der Y-Wert bekannt (in unserem Fall sind dies die Punkte: P1, P2, P3, P4).  Dies sind die Punkte, die wir tats√§chlich auf den Daten beobachten.  So haben wir einen bestimmten Datensatz erhalten.  Aus irgendeinem Grund haben wir entschieden, dass die lineare Regression die Beziehung zwischen dem X und dem Spieler am besten beschreibt.  Weiterhin ist die ganze Frage, wie die Gleichung einer geraden Linie Y = b <sub>1</sub> + b <sub>2</sub> X zu konstruieren ist, wobei b <sub>2</sub> der Steigungskoeffizient ist, b <sub>1</sub> der Schnittkoeffizient ist.  Die ganze Frage ist, welche b <sub>2</sub> und b <sub>1 am</sub> besten eingestellt sind, damit diese Gerade die Beziehung zwischen diesen Variablen so genau wie m√∂glich beschreibt. <br><br>  Die Punkte R <sub>1</sub> , R <sub>2</sub> , R <sub>3</sub> , R <sub>4</sub> sind die Werte, die unser Modell bei den Werten von X ausgibt. Was passiert?  Punkte P sind Punkte, die wir tats√§chlich beobachten (tats√§chlich gesammelt), und Punkte R sind Punkte, die wir in unserem Modell beobachten (die, die es produziert).  Was folgt, ist eine wahnsinnig einfache menschliche Logik: Ein <b>Modell wird nur dann als qualitativ angesehen, wenn die Punkte R so nahe wie m√∂glich an den Punkten P liegen</b> . <br><br>  Wenn wir den Abstand zwischen diesen Punkten f√ºr dasselbe ‚ÄûX‚Äú (P <sub>1</sub> - R <sub>1</sub> , P <sub>2</sub> - R <sub>2</sub> usw.) konstruieren, erhalten wir sogenannte lineare Regressionsfehler.  Wir erhalten die Abweichungen in linearer Regression und diese Abweichungen hei√üen U <sub>1</sub> , U <sub>2</sub> , U <sub>3</sub> ... U <sub>n</sub> .  Und diese Fehler k√∂nnen entweder positiv oder negativ sein (wir k√∂nnten sie √ºbersch√§tzen oder untersch√§tzen).  Um diese Abweichungen zu vergleichen, m√ºssen sie analysiert werden.  Hier wird eine sehr gro√üe und sch√∂ne Methode angewendet - Quadrieren (Quadrieren "t√∂tet" das Zeichen).  Und die Summe der Quadrate aller Abweichungen in der mathematischen Statistik hei√üt RSS (Residual Sum of Squares).  Durch Minimieren von RSS um b <sub>1</sub> und durch Minimieren von RSS um b <sub>2</sub> erhalten wir optimale Koeffizienten, die tats√§chlich <b>durch die Methode der kleinsten Quadrate abgeleitet werden</b> . <br><br>  Nachdem wir die Regression aufgebaut haben, die optimalen Koeffizienten b <sub>1</sub> und b <sub>2 bestimmt</sub> haben und die Regressionsgleichung vorliegen, enden die Probleme nicht dort und das Problem entwickelt sich weiter.  Tatsache ist, dass, wenn die Regression selbst in einem Diagramm markiert ist, alle Werte, die wir haben, sowie die Durchschnittswerte der ‚ÄûSpiele‚Äú, die Summe der quadratischen Fehler gekl√§rt werden kann. <br><br><img src="https://habrastorage.org/webt/di/72/fm/di72fm_hyb5h9gzgd5cb-eaa-0u.png"><br><br>  Gleichzeitig wird es als n√ºtzlich erachtet, Fehler bei der Regressionsvorhersage in Bezug auf die Variable X anzuzeigen. Siehe folgende Abbildung: <br><br><img src="https://habrastorage.org/webt/k2/du/8p/k2du8pkdcrzppjzfd5nsiwjntcu.png"><br><br>  Wir haben eine Art Regression und haben die realen Daten gezogen.  Wir haben den Abstand von jedem realen Wert zur Regression.  Und wir haben es relativ zum Nullwert f√ºr die entsprechenden Werte von X gezeichnet. Und in der obigen Abbildung sehen wir ein wirklich schlechtes Bild: Die <b>Fehler h√§ngen von X ab.</b>  Eine gewisse Korrelationsabh√§ngigkeit wird klar ausgedr√ºckt: <b>Je weiter wir uns entlang des "X" bewegen, desto gr√∂√üer ist die Signifikanz von Fehlern</b> .  Das ist sehr schlecht.  Das Vorhandensein einer Korrelation in diesem Fall weist darauf hin, dass wir das Regressionsmodell f√§lschlicherweise √ºbernommen haben und dass es einige Parameter gab, an die wir ‚Äûnicht gedacht‚Äú oder die wir einfach aus den Augen verloren haben.  Wenn alle Variablen im Modell platziert sind, sollten die Fehler vollst√§ndig zuf√§llig sein und nicht davon abh√§ngen, welche Faktoren gleich sind.  <b>Fehler m√ºssen mit der gleichen Wahrscheinlichkeitsverteilung vorliegen</b> , sonst sind Ihre Vorhersagen fehlerhaft.  Wenn Sie die Fehler Ihres Modells in der Ebene gezeichnet haben und auf ein divergierendes Dreieck gesto√üen sind, ist es besser, von vorne zu beginnen und das Modell vollst√§ndig neu zu erz√§hlen. <br><br>  Durch die Analyse von Fehlern k√∂nnen Sie sogar sofort nachvollziehen, wo sie sich verrechnet haben und welche Art von Fehler sie gemacht haben.  Und hier darf der Gau√ü-Markov-Satz nicht fehlen: <br><br><img src="https://habrastorage.org/webt/mj/hk/wf/mjhkwffvsyvehnrhmj9sa_3b0e4.png"><br><br>  Der Satz bestimmt die Bedingungen, unter denen die durch die Methode der kleinsten Quadrate erhaltenen Sch√§tzungen die besten, konsistentesten und effektivsten in der Klasse der linearen unverzerrten Sch√§tzungen sind. <br><br>  Die Schlussfolgerung kann wie folgt gezogen werden: Jetzt verstehen wir, dass der <b>Bereich der Erstellung eines Regressionsmodells gewisserma√üen der H√∂hepunkt aus der Sicht der Mathematik ist</b> , da alle m√∂glichen Abschnitte gleichzeitig zusammengef√ºhrt werden, was zum Beispiel bei der Datenanalyse n√ºtzlich sein kann: <br><br><ul><li>  lineare Algebra mit Datendarstellungsmethoden; </li><li>  mathematische Analyse mit Optimierungstheorie und Mitteln zur Funktionsanalyse; </li><li>  Wahrscheinlichkeitstheorie mit Mitteln zur Beschreibung zuf√§lliger Ereignisse und Gr√∂√üen und zur Modellierung der Beziehung zwischen Variablen. </li></ul><br><hr><br>  <i>Trotzdem schlage ich vor, Kollegen, nicht nur <a href="https://otus.pw/ImPO/">das gesamte Webinar</a> zu lesen und <a href="https://otus.pw/ImPO/">anzusehen</a> .</i>  <i>Der Artikel enthielt keine Momente in Bezug auf lineare Programmierung, Optimierung in Regressionsmodellen und andere Details, die f√ºr Sie n√ºtzlich sein k√∂nnten.</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de485972/">https://habr.com/ru/post/de485972/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de485958/index.html">[Administrator√ºbersicht] Was ist, wenn das Programm Administratorrechte ben√∂tigt und Sie dies nicht tun?</a></li>
<li><a href="../de485962/index.html">Pers√∂nliche Recherche zu 2019-nCoV</a></li>
<li><a href="../de485966/index.html">Reverse USB-SATA Adapter (Verlauf eines Praktikanten)</a></li>
<li><a href="../de485968/index.html">Und wieder Bypass-Schl√∂sser. RouterOS + BGP + OSPF</a></li>
<li><a href="../de485970/index.html">K√ºrzlich 30 Top-Interviews: Entwicklung, Design, Sciencepop und Lebensstil</a></li>
<li><a href="../de485974/index.html">Raspberry Pi und SIM7600E 4G HAT Modem</a></li>
<li><a href="../de485986/index.html">Top 5 Lokalisierungstrends im Jahr 2020</a></li>
<li><a href="../de485988/index.html">[Case Locomizer] So beschleunigen Sie die Berechnung einer Heatmap in zweieinhalb Jahren um das 20.000-fache</a></li>
<li><a href="../de485990/index.html">Automatisierung t√∂tet?</a></li>
<li><a href="../de485996/index.html">Elastic APM in der App</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
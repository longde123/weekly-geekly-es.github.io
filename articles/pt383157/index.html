<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚Äçüî¨ ‚ò¶Ô∏è üé∑ Como testamos o armazenamento definido por software, tamb√©m conhecido como Virtual SAN üå°Ô∏è ü•î üöÜ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Decidimos tentar na pr√°tica uma nova tend√™ncia na comunidade de TI, a saber, armazenamento definido por software.
 
 
 
 Pedimos aos nossos maravilhos...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como testamos o armazenamento definido por software, tamb√©m conhecido como Virtual SAN</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/383157/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Decidimos tentar na pr√°tica uma nova tend√™ncia na comunidade de TI, a saber, armazenamento definido por software.</font></font><br>
<img src="https://habrastorage.org/files/146/dc9/6c2/146dc96c24854245997228a27e86ee41.jpg"><br>
<a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pedimos aos nossos maravilhosos fornecedores um campo de testes. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Configura√ß√£o do suporte:</font></font><br>
<br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3 servidores SuperMicro X9SCL / X9SCM da seguinte configura√ß√£o:</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Processador Intel E3-1220V2: 4 n√∫cleos x 3,1 GHz</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RAM - 16 Gb</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Adaptador Adaptec 6405E RAID: SAS de 2x300GB 10K, SSD de 1x180GB - todas as unidades devem ser configuradas no modo JBOD</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2x500GB SATA 7.4K conectado aos conectores no tapete. </font><font style="vertical-align: inherit;">placa de circuito</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NIC 2x1GB</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Atualmente, existem muitas solu√ß√µes de SAN virtual, o Starwind VSAN caiu devido a limita√ß√µes significativas da vers√£o gratuita, o que matou todos os recursos interessantes, o VMWARE VSAN caiu devido a requisitos de hardware e alto custo de propriedade, o que n√£o √© ideal para pequenos or√ßamentos regionais, bem como pelo fato de que aqueles. Os especialistas em VMWARE √† margem n√£o recomendam o uso do VSAN para aplicativos cr√≠ticos para os neg√≥cios. Como resultado, escolhemos uma solu√ß√£o da Nutanix e EMC ScaleIO. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O ScaleIO √© uma SAN virtial definida por software da EMC</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, pode funcionar no modo livre sem quase nenhuma restri√ß√£o (escrita na licen√ßa para uso que n√£o seja de produ√ß√£o!) - o √∫nico fator menos grave √© que este sistema n√£o possui mecanismos internos para armazenamento autom√°tico de dados ou armazenamento em cache, eu uso discos SSD. concorrentes aos quais o SSD oferece uma vantagem s√©ria na velocidade das m√°quinas virtuais). </font><font style="vertical-align: inherit;">Arquitetonicamente, ele se parece muito com o sistema de armazenamento IBM XIV corporativo de ponta - at√© o tamanho do bloco √© o mesmo - 1 MB. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Li requisitos m√≠nimos contradit√≥rios em diferentes fontes:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Estes s√£o os requisitos m√≠nimos do sistema para uma implementa√ß√£o do ScaleIO 1.31 e 1.32:</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As solu√ß√µes ScaleIO 1.31 e 1.32 s√£o suportadas apenas no ESXi 5.5 GA.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tr√™s servidores ESXi com 100 GB de capacidade livre por servidor</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rede de 1 gbps</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quatro discos SATA de 7.200 rpm por n√≥</font></font></li>
</ul><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No entanto, na pr√°tica, para a vers√£o 1.32, essas restri√ß√µes n√£o foram atendidas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Devido ao fato de que na produ√ß√£o usamos o VMWARE racialmente correto e n√£o gostamos do Hyper-V n√£o ortodoxo, selecionamos a vers√£o de avalia√ß√£o do VMWARE ESXi 6.0 para implanta√ß√£o como hipervisor. Por uma quest√£o de justi√ßa, note-se que o ScaleIO funciona bem nos seguintes hipervisores XEN, ESXi, Hyper-V; neste √∫ltimo, com a ajuda do Windows 2012 r2, os artes√£os contornaram a falta de armazenamento em cache do array SSD usando as ferramentas incorporadas em 2012 R2, que obviamente tiveram um impacto positivo no desempenho do sistema. (existe uma t√©cnica na internet)</font></font><br>
<br>
        ESXi   appliance VCENTER    VMWARE.       ‚Äî ESXi        Adaptec 6405E,      VMWARE HCL. <br>
   Adaptec  (Offline-Bundles and VIB)  VMWARE   VMWARE powercli   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">  </a>        ‚Äî     .<br>
<br>
   VCENTER appliance     vmware powercli   ScaleIO    datastore    ScaleIO   .ova (    ScaleIO).<br>
<br>
          ScaleIO. <br>
 <br>
          :<br>
 ‚Äî       protection domain      storage pool',<br>
 ‚Äî     storage pool' (,     HDD  SSD,    )<br>
 ‚Äî ,   FaultSets,      . ,   ZeroPadding Policy, RAM Cache policy   , Spare policy.  <br>
<br>
<b>ScaleIO     SSD      !    .   SSD  ,      flash-only pool ‚Äî  !<br>
</b><br>
<br>
      read\write cache RAID ,    ,      RAM CACHE,   protection domain,           ! ( 16GB RAM     1.3GB    ,  )<br>
<br>
   2  VLAN: management  data,     4- (  ) SVM (SVM ‚Äî ScaleIO Virtual Machine) management IP  DATA IP     . (     ,        10 ).<br>
<br>
      4 SVM   3-  (SVM ‚Äî ScaleIO Virtual Machine),  8cpu   ( 2  :    2    4 vcpu),  12Gb   .<br>
<br>
SVM  node1 ‚Äî primary mdm, sds, sdc <br>
SVM  node2 ‚Äî secondary mdm, sds, sdc<br>
SVM  node3 ‚Äî tie breaker, sdc<br>
SVM    ‚Äî gateway ‚Äî ( , , maintenance) <br>
<br>
mdm ‚Äî Meta Data Manager ‚Äî       <br>
sds ‚Äî ScaleIO data server ‚Äî      RDM   VMWARE (raw disk mapping)<br>
sdc ‚Äî ScaleIO data client ‚Äî   VMWARE  .  ,      ScaleIO     ,         SVM.<br>
<br>
 ,     SDC    ,    ScaleIO     VMWARE    LUN   datastore,           iSCSI. <br>
<br>
<img src="https://habrastorage.org/files/4c3/4ec/bc3/4c34ecbc3e614098ba3e1ac3c061e78f.png"><br>
<br>
    ,        VLAN  IP   SVM.                  :<br>
<br>
Failed: Add SDS device ScaleIO-4c1885e7 to Storage Pool hdds (ScaleIO ‚Äî Timeout)<br>
<br>
       . ,  ‚Äî  retry.   ,     SVM  2   :<br>
<br>
Failed: Add SDS device ScaleIO-4c1885eb to Storage Pool hdds (ScaleIO ‚Äî The SDS is already attached to this MDM)<br>
<br>
 ‚Ä¶ ,     SVM,   secondary mdm,  -       RDM   ,      SDS.         .<br>
<br>
  ¬´deploy scaleio environment¬ª   ,  ,     ,  ,       VLAN  IP ,      .<br>
<br>
        volume     .        GUI:   GUI dashboard    windows,   GUI VMWARE,   - Gateway.      cli ‚Äî      .<br>
<br>
  ‚Äî      volume  GUI VMWARE.<br>
<br>
<img src="https://habrastorage.org/files/6f3/891/a2a/6f3891a2a60b4135b40a528c2fc7d49e.png"><br>
<br>
, !  ¬´¬ª   .    storage pool   HDDs (    6  SAS   3- )   total capacity limit 1.6B (     6300GB),  volume c    ‚Ä¶       .    ,    CLI   .   SSH    MDM SVM ‚Äî  :<br>
<br>
<pre><code class="cs hljs">ScaleIO<span class="hljs-number">-10</span><span class="hljs-number">-1</span><span class="hljs-number">-4</span><span class="hljs-number">-203</span>:~ <span class="hljs-meta"># scli --query_storage_pool --protection_domain_name pd2 --storage_pool_name hdds</span>
Error: MDM failed command.  Status: Invalid session. Please login and <span class="hljs-keyword">try</span> again.<font></font>
<font></font>
</code></pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O que? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Eu tento no segundo MDM: o erro √© algo como n√£o √© poss√≠vel conectar o host local: 6611 </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No gateway, geralmente dizia que n√£o existem comandos desse tipo. </font><font style="vertical-align: inherit;">Tudo √© um estupor! </font><font style="vertical-align: inherit;">N√£o est√° claro como usar a CLI. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Estudamos cuidadosamente o guia do usu√°rio no ScaleIO, especialmente sobre os princ√≠pios b√°sicos da CLI, e ele diz na parte inferior que voc√™ precisa fazer login adicional na CLI e na data do link, como faz√™-lo, mas √© necess√°rio:</font></font><br>
<pre><code class="bash hljs">ScaleIO-10-1-4-203:~ <span class="hljs-comment"># scli --login --username admin</span><font></font>
Enter password:<font></font>
</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
E depois disso, todas as equipes de CLI come√ßaram a trabalhar maravilhosamente.</font></font><br>
<br>
<pre><code class="bash hljs">scli --query_storage_pool --protection_domain_name pd2 --storage_pool_name hdds<font></font>
<font></font>
Storage Pool hdds (Id: 574711eb00000000) has 0 volumes and<font></font>
544.0 GB (557056 MB) available <span class="hljs-keyword">for</span> volume allocation<font></font>
Background device scanner: Disabled<font></font>
Zero padding is disabled<font></font>
Spare policy: 34% out of total<font></font>
Uses RAM Read Cache<font></font>
RAM Read Cache write handling mode is <span class="hljs-string">'cached'</span><font></font>
 1.6 TB (1667 GB) total capacity<font></font>
 1.1 TB (1100 GB) unused capacity<font></font>
 567.1 GB (580708 MB) spare capacity<font></font>
</code></pre><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Espere o que? o volume dispon√≠vel no nosso caso √© 544GB ?! Qu√£o? Por qu√™? √â necess√°ria uma explica√ß√£o da arquitetura de armazenamento aqui (veja a captura de tela): </font></font><br>
<br>
<img src="https://habrastorage.org/files/372/7c1/3a7/3727c13a7e3e4c9ebfff7b3d9c8dd099.png"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ou seja, volume total do pool de armazenamento bruto denominado HDDs: 1,6 TB menos 567,1 GB de capacidade sobressalente = 1,1 TB de capacidade n√£o utilizada. A capacidade de reposi√ß√£o √© determinada pelo par√¢metro Pol√≠tica de reposi√ß√£o nas configura√ß√µes. De acordo com as recomenda√ß√µes da documenta√ß√£o, para prote√ß√£o completa contra falhas de um n√≥, √© necess√°rio que a Capacidade de Armazenamento seja pelo menos 1 \ N do volume total de todos os discos f√≠sicos de todos os n√≥s inclu√≠dos no conjunto de armazenamentos, em que N √© o n√∫mero de n√≥s que est√£o no conjunto (ou seja, e se tivermos 3 n√≥s com discos nesse pool de armazenamento, a capacidade dispon√≠vel no nosso caso ser√° de 1 \ 3 de 1,6 TB (do volume total), respectivamente 567,1 GB (580708 MB).</font></font><br>
<br>
,  1.1TB    storage pool   volume.        ScaleIO       2    ,   1.1TB    2 ,         volume 544.0 GB.<br>
<br>
         (  85-130\,   ,       ,                 IOPS):<br>
<br>
<img src="https://habrastorage.org/files/21a/8c0/ce3/21a8c0ce34c844ce8a914a7c7b4386b4.png"><br>
<br>
<b>Nutanix Comminity Edition 4.5 ‚Äî   non-commercial </b><br>
<br>
   Nutanix,   ,  ‚Ä¶       . Nutanix     hypervisor      ( VMWARE Vcenter)   ¬´¬ª,          NFS   high-availability.<br>
<br>
 ,    ESXi    .     Community Edition,     :<br>
<br>
 ‚Äî  4 <br>
 ‚Äî  4    ( SSD,      18 TB (3 x 6 TB HDDs))<br>
 ‚Äî  Intel c  VT-x 4  <br>
 ‚Äî  Advanced Host Controller Interface (AHCI) SATA <br>
 ‚Äî LSI    IT mode (Nutanix testing shows better performance than IR)<br>
 ‚Äî  16 GB    (  32 GB     ‚Äî  16   )<br>
 ‚Äî   SSD    200 GB<br>
 ‚Äî   SSD       300GB (  400,480)<br>
<br>
 ADAPTEC 6405E SAS   Nutanix,    SAS    (  SATA  SSD      . ).<br>
<br>
      :           ‚Äî     8GB    (   8GB,  16,    hypervisor KVM (Acropolis)  CVM ‚Äî control virtual machine ‚Äî     !),     CVM   .<br>
<br>
     :<br>
<br>
 ‚Äî 16    <br>
 ‚Äî    2   HDD SATA 500GB<br>
 ‚Äî    1   SSD 500GB<br>
 ‚Äî     24GB    +  300GB SSD  ,      .<br>
<br>
       ‚Ä¶<br>
<br>
 Community Edition    ‚Äî     KVM ‚Äî   ,       VMWARE ESXi.<br>
<br>
         (CVM ‚Äî control virtual machine),   2       12      ‚Äî    .<br>
<br>
          :   StorageContainer  Replication Factor 2,       50%  (      ,    3 ,   2  SATA  500 ,  6  + SSD       2.88 TB     1.44 TB    ).<br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ap√≥s a cria√ß√£o, o conjunto de discos √© acess√≠vel e entregue via NFS: por exemplo, ele se conectou perfeitamente ao cluster VMWARE 5.5 como um armazenamento de dados, respectivamente, o storage vmotion tamb√©m funciona, embora a velocidade seja muito mais lenta em compara√ß√£o com o FC 4Gb \ seg (√© compreens√≠vel com uma conex√£o de gigabit - era interessante dirigiria em 10G ou infinibanda). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Uma m√°quina ativa de 60 GB do cluster VMWARE foi movida cerca de 24 minutos para o armazenamento da Nutanix. Ele retornou 13 minutos para o armazenamento FC no n√≠vel corporativo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gravando o arquivo iso do servidor Windows na m√°quina virtual vmware, localizada no armazenamento nutanix via nfs (1Gb / s) - 34MB / s. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
N√£o h√° ferramenta interativa para gerenciar portgroups e vswitch - tudo √© feito a partir do cli.</font></font><br>
<br>
        :    .     Nutanix   VLAN,           .         VLAN   ‚Äî   ,             ‚Äî  ,    GUI !   . <br>
<br>
  Windows guests       CDROM  VirtIO  (    (  iso   ): <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">fedoraproject.org/wiki/Windows_Virtio_Drivers#Direct_download</a>)<br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O tempo de instala√ß√£o do vm convidado no Windows 2012 R2 foi de apenas 7 minutos desde o in√≠cio at√© a carga total do sistema em funcionamento, a m√°quina virtual funciona visualmente tamb√©m rapidamente - obviamente, a SSD ajuda. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Voc√™ pode colocar uma m√°quina virtual no tipo de cortroler de disco virtual IDE (sem conectar os drivers VirtIO), mas essa n√£o √© uma configura√ß√£o recomendada - o desempenho ser√° muito menor. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Durante uma falha na energia de teste de um dos hosts do cluster, a HA funcionou, o sistema n√£o travou, os recursos de disco est√£o acess√≠veis na rede e localmente, as m√°quinas virtuais que estavam no host desconectado foram reiniciadas em outros hosts (se houver mem√≥ria suficiente),</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
no entanto, depois de ligar a energia do terceiro host, o fato desagrad√°vel foi que o status do sistema foi mantido em Cr√≠tica por um tempo muito longo - n√£o sei o que isso gera, mas o bom n√£o √© suficiente. (de 1 hora a 2). Por exemplo, o mesmo cluster VMWARE ap√≥s conectar o host determina rapidamente seu status e se conecta novamente ao cluster. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em geral, deve-se notar que a interface do Prism para gerenciar um cluster do Nutanix CE possui uma interface bastante ruim (embora agrad√°vel). Somente configura√ß√µes b√°sicas est√£o dispon√≠veis, mas, em geral, s√£o suficientes √† primeira vista, h√° algum tipo de an√°lise gr√°fica personaliz√°vel, embora, √© claro, seja muito mais fraca que no VCENTER.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ainda n√£o est√° claro como fazer backup: afinal, nem os produtos da Symantec nem da Veeam oferecem suporte √† virtualiza√ß√£o KVM ... obviamente, por meio de instant√¢neos, mas e a recupera√ß√£o granular de dados nesse caso (arquivo por arquivo). </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visualmente, o Nutanix era muito mais r√°pido: na fase de c√≥pia de imagens para seu sistema de armazenamento, na fase de instala√ß√£o do sistema operacional em uma nova m√°quina virtual a partir da imagem, na fase de reinicializa√ß√£o da inicializa√ß√£o: quase instantaneamente tudo). </font><font style="vertical-align: inherit;">H√° um desejo de experimentar o Nutanix em uma configura√ß√£o mais poderosa e n√£o se esque√ßa de usar o VMWARE EXSi. </font></font></b><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Obviamente, n√£o posso fornecer dados de desempenho espec√≠ficos para os dois sistemas, mas voc√™ pode obter algumas informa√ß√µes sobre o "rake" no est√°gio de configura√ß√£o. </font><font style="vertical-align: inherit;">Se isso pe√ßo desculpas - a primeira nota sobre Habr√©.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt383157/">https://habr.com/ru/post/pt383157/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt383145/index.html">Revis√£o do transformador notebook ASUS Transformer Book T300 Chi</a></li>
<li><a href="../pt383147/index.html">TV para Algernon: uma vis√£o geral dos decodificadores que tornam a TV mais inteligente</a></li>
<li><a href="../pt383151/index.html">Dr. Tarifa calculada qual operadora de celular possui mais de Internet 4G (parte 2)</a></li>
<li><a href="../pt383153/index.html">M√≥dulos de apartamentos ou o modo de desenvolvimento de instala√ß√µes residenciais</a></li>
<li><a href="../pt383155/index.html">Android deve ter medo apenas Android</a></li>
<li><a href="../pt383159/index.html">Um smartphone com uma bateria poderosa. Vers√£o DEXP: 10 modelos de 4.490 a 13.990 rublos, de 3.000 a 5.200 mAh</a></li>
<li><a href="../pt383163/index.html">Impressora 3D imprime com vidro quente</a></li>
<li><a href="../pt383165/index.html">An√∫ncio do SmartBand 2</a></li>
<li><a href="../pt383167/index.html">IDF 2015. Resumo de amanh√£</a></li>
<li><a href="../pt383169/index.html">Como montar um cinema hi-fi em casa</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
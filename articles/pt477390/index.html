<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèº‚Äçüöí üßëüèº‚Äçü§ù‚Äçüßëüèº ü§∂ Depurando atrasos na rede no Kubernetes üë©üèª‚Äçü§ù‚Äçüë®üèΩ „äôÔ∏è üë¥üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="H√° alguns anos, o Kubernetes j√° foi discutido no blog oficial do GitHub. Desde ent√£o, tornou-se a tecnologia padr√£o para implantar servi√ßos. O Kuberne...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Depurando atrasos na rede no Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/477390/"><img src="https://habrastorage.org/getpro/habr/post_images/c82/5b1/413/c825b1413d9c59cf78c51e6e2c8f8049.png"><br><br>  H√° alguns anos, o Kubernetes <a href="https://github.blog/2017-08-16-kubernetes-at-github/">j√°</a> foi <a href="https://github.blog/2017-08-16-kubernetes-at-github/">discutido</a> no blog oficial do GitHub.  Desde ent√£o, tornou-se a tecnologia padr√£o para implantar servi√ßos.  O Kubernetes agora administra uma parcela significativa dos servi√ßos internos e p√∫blicos.  √Ä medida que nossos clusters aumentavam e os requisitos de desempenho se tornavam mais rigorosos, come√ßamos a perceber que alguns servi√ßos no Kubernetes exibiam esporadicamente atrasos que n√£o podem ser explicados pela carga do pr√≥prio aplicativo. <br><br>  De fato, em aplicativos, ocorre um atraso aleat√≥rio na rede de at√© 100 ms ou mais, o que leva a tempos limites ou novas tentativas.  Esperava-se que os servi√ßos pudessem responder a solicita√ß√µes muito mais r√°pido que 100 ms.  Mas isso n√£o √© poss√≠vel se a conex√£o em si demorar tanto tempo.  Separadamente, observamos consultas MySQL muito r√°pidas, que deveriam levar milissegundos, e o MySQL realmente gerenciava em milissegundos, mas do ponto de vista do aplicativo solicitante, a resposta levou 100 ms ou mais. <br><a name="habracut"></a><br>  Imediatamente ficou claro que o problema ocorre apenas quando se conecta ao host Kubernetes, mesmo se a chamada vier de fora do Kubernetes.  A maneira mais f√°cil de reproduzir o problema √© no teste <a href="https://github.com/tsenart/vegeta">Vegeta</a> , que √© executado em qualquer host interno, testa o servi√ßo Kubernetes em uma porta espec√≠fica e registra esporadicamente um grande atraso.  Neste artigo, veremos como conseguimos rastrear a causa desse problema. <br><br><h1>  Elimine a complexidade desnecess√°ria na cadeia de falhas </h1><br>  Tendo reproduzido o mesmo exemplo, quer√≠amos restringir o foco do problema e remover as camadas extras de complexidade.  Inicialmente, havia muitos elementos no fluxo entre o Vegeta e os pods no Kubernetes.  Para identificar um problema de rede mais profundo, voc√™ precisa excluir alguns deles. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/488/8c1/d29/4888c1d29a8fc1b4a1194c4c3a14c9ff.png"><br><br>  O cliente (Vegeta) cria uma conex√£o TCP com qualquer n√≥ no cluster.  O Kubernetes atua como uma rede de sobreposi√ß√£o (na parte superior da rede de data center existente) que usa <a href="https://en.wikipedia.org/wiki/IP_in_IP">IPIP</a> , ou seja, encapsula os pacotes IP da rede de sobreposi√ß√£o dentro dos pacotes IP do data center.  Quando conectada ao primeiro n√≥, a convers√£o de endere√ßo de rede NAT ( <a href="https://en.wikipedia.org/wiki/Network_address_translation">Network Address Translation</a> ) √© realizada com monitoramento de estado para converter o endere√ßo IP e a porta do host Kubernetes no endere√ßo IP e porta na rede de sobreposi√ß√£o (em particular, o pod com o aplicativo).  Para pacotes recebidos, a sequ√™ncia reversa √© realizada.  Este √© um sistema complexo com muitos estados e muitos elementos que s√£o constantemente atualizados e alterados √† medida que os servi√ßos s√£o implantados e movidos. <br><br>  O utilit√°rio <code>tcpdump</code> no teste Vegeta fornece um atraso durante o handshake TCP (entre SYN e SYN-ACK).  Para remover essa complexidade desnecess√°ria, voc√™ pode usar o <code>hping3</code> para "pings" simples com pacotes SYN.  Verifique se h√° um atraso no pacote de resposta e, em seguida, redefina a conex√£o.  Podemos filtrar os dados incluindo apenas pacotes com mais de 100 ms e obter uma op√ß√£o mais simples para reproduzir o problema do que o teste de n√≠vel de rede 7 completo em Vegeta.  Aqui est√£o os "pings" do host Kubernetes usando o TCP SYN / SYN-ACK na "porta" do host do servi√ßo (30927) com um intervalo de 10 ms, filtrados pelas respostas mais lentas: <br><br> <code>theojulienne@shell ~ $ sudo hping3 172.16.47.27 -S -p 30927 -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=1485 win=29200 rtt=127.1 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=1486 win=29200 rtt=117.0 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=1487 win=29200 rtt=106.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=1488 win=29200 rtt=104.1 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=5024 win=29200 rtt=109.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=5231 win=29200 rtt=109.2 ms</code> <br> <br>  Imediatamente pode fazer a primeira observa√ß√£o.  Os n√∫meros de s√©rie e hor√°rios mostram que esses n√£o s√£o congestionamentos √∫nicos.  O atraso geralmente se acumula e √© finalmente processado. <br><br>  Em seguida, queremos descobrir quais componentes podem estar envolvidos na apar√™ncia de congestionamento.  Talvez estas sejam algumas das centenas de regras do iptables no NAT?  Ou alguns problemas com o tunelamento IPIP na rede?  Uma maneira de verificar isso √© verificar cada etapa do sistema excluindo-a.  O que acontece se voc√™ remover a l√≥gica do NAT e do firewall, deixando apenas uma parte do IPIP: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5b3/e2a/cff/5b3e2acff2ef9f1f8c7c527356741d92.png"><br><br>  Felizmente, o Linux facilita o acesso direto √† camada de sobreposi√ß√£o de IP se a m√°quina estiver na mesma rede: <br><br> <code>theojulienne@kube-node-client ~ $ sudo hping3 10.125.20.64 -S -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=40 ip=10.125.20.64 ttl=64 DF id=0 sport=0 flags=RA seq=7346 win=0 rtt=127.3 ms <br> <br> len=40 ip=10.125.20.64 ttl=64 DF id=0 sport=0 flags=RA seq=7347 win=0 rtt=117.3 ms <br> <br> len=40 ip=10.125.20.64 ttl=64 DF id=0 sport=0 flags=RA seq=7348 win=0 rtt=107.2 ms</code> <br> <br>  A julgar pelos resultados, o problema ainda permanece!  Isso exclui iptables e NAT.  Ent√£o o problema est√° no TCP?  Vamos ver como o ping ICMP normal √© executado: <br><br> <code>theojulienne@kube-node-client ~ $ sudo hping3 10.125.20.64 --icmp -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=28 ip=10.125.20.64 ttl=64 id=42594 icmp_seq=104 rtt=110.0 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49448 icmp_seq=4022 rtt=141.3 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49449 icmp_seq=4023 rtt=131.3 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49450 icmp_seq=4024 rtt=121.2 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49451 icmp_seq=4025 rtt=111.2 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49452 icmp_seq=4026 rtt=101.1 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=50023 icmp_seq=4343 rtt=126.8 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=50024 icmp_seq=4344 rtt=116.8 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=50025 icmp_seq=4345 rtt=106.8 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=59727 icmp_seq=9836 rtt=106.1 ms</code> <br> <br>  Os resultados mostram que o problema n√£o desapareceu.  Talvez este seja um t√∫nel IPIP?  Vamos simplificar o teste: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/267/ff6/137/267ff613754b99f8cc1bb1d89119206e.png"><br><br>  Todos os pacotes s√£o enviados entre esses dois hosts? <br><br> <code>theojulienne@kube-node-client ~ $ sudo hping3 172.16.47.27 --icmp -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41127 icmp_seq=12564 rtt=140.9 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41128 icmp_seq=12565 rtt=130.9 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41129 icmp_seq=12566 rtt=120.8 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41130 icmp_seq=12567 rtt=110.8 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41131 icmp_seq=12568 rtt=100.7 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=9062 icmp_seq=31443 rtt=134.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=9063 icmp_seq=31444 rtt=124.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=9064 icmp_seq=31445 rtt=114.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=9065 icmp_seq=31446 rtt=104.2 ms</code> <br> <br>  Simplificamos a situa√ß√£o para dois hosts Kubernetes enviando qualquer pacote um para o outro, mesmo ping ICMP.  Eles ainda v√™em um atraso se o host de destino for "ruim" (alguns piores que outros). <br><br>  Agora a √∫ltima pergunta: por que o atraso ocorre apenas em servidores de n√≥s do kube?  E isso acontece quando o kube-node √© o remetente ou receptor?  Felizmente, tamb√©m √© f√°cil descobrir isso enviando um pacote de um host fora do Kubernetes, mas com o mesmo destinat√°rio "conhecido como ruim".  Como voc√™ pode ver, o problema n√£o desapareceu: <br><br> <code>theojulienne@shell ~ $ sudo hping3 172.16.47.27 -p 9876 -S -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=46 ip=172.16.47.27 ttl=61 DF id=0 sport=9876 flags=RA seq=312 win=0 rtt=108.5 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 DF id=0 sport=9876 flags=RA seq=5903 win=0 rtt=119.4 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 DF id=0 sport=9876 flags=RA seq=6227 win=0 rtt=139.9 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 DF id=0 sport=9876 flags=RA seq=7929 win=0 rtt=131.2 ms</code> <br> <br>  Em seguida, executamos as mesmas solicita√ß√µes do n√≥ kube de origem anterior para o host externo (que exclui o host original, pois o ping inclui os componentes RX e TX): <br><br> <code>theojulienne@kube-node-client ~ $ sudo hping3 172.16.33.44 -p 9876 -S -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> ^C <br> --- 172.16.33.44 hping statistic --- <br> 22352 packets transmitted, 22350 packets received, 1% packet loss <br> round-trip min/avg/max = 0.2/7.6/1010.6 ms</code> <br> <br>  Depois de examinar as capturas de pacotes atrasadas, obtivemos algumas informa√ß√µes adicionais.  Em particular, que o remetente (abaixo) veja esse tempo limite, mas o receptor (acima) n√£o o veja - veja a coluna Delta (em segundos): <br><br> <a href=""><img src="https://habrastorage.org/webt/4m/-t/dj/4m-tdjzws9lrhnva3xcxijel7eg.png"></a> <br><br>  Al√©m disso, se voc√™ observar a diferen√ßa na ordem dos pacotes TCP e ICMP (por n√∫meros de s√©rie) no lado do destinat√°rio, os pacotes ICMP sempre chegar√£o na mesma sequ√™ncia em que foram enviados, mas com tempo diferente.  Ao mesmo tempo, os pacotes TCP √†s vezes se alternam e alguns ficam presos.  Em particular, se examinarmos as portas dos pacotes SYN, no lado do remetente elas v√£o em ordem, mas no lado do destinat√°rio n√£o. <br><br>  H√° uma diferen√ßa sutil em como <a href="https://en.wikipedia.org/wiki/Network_address_translation">as placas de rede dos</a> servidores modernos (como em nosso data center) processam pacotes contendo TCP ou ICMP.  Quando um pacote chega, o adaptador de rede ‚Äúfaz o hash na conex√£o‚Äù, ou seja, tenta interromper as conex√µes alternadamente e envia cada fila para um n√∫cleo de processador separado.  Para o TCP, esse hash inclui o endere√ßo IP e a porta de origem e de destino.  Em outras palavras, cada conex√£o √© hash (potencialmente) diferente.  Para o ICMP, apenas os endere√ßos IP s√£o hash, pois n√£o h√° portas. <br><br>  Outra nova observa√ß√£o: durante esse per√≠odo, vemos atrasos do ICMP em todas as comunica√ß√µes entre os dois hosts, mas o TCP n√£o.  Isso nos diz que o motivo provavelmente se deve ao hash das filas RX: √© quase certo que o congestionamento ocorre no processamento de pacotes RX, em vez de enviar respostas. <br><br>  Isso exclui o envio de pacotes da lista de poss√≠veis motivos.  Agora sabemos que o problema com o processamento de pacotes est√° no lado de recebimento em alguns servidores do n√≥ kube. <br><br><h1>  Entendendo o processamento de pacotes no kernel do Linux </h1><br>  Para entender por que o problema ocorre com o destinat√°rio em alguns servidores de n√≥s do kube, vamos ver como o kernel do Linux lida com pacotes. <br><br>  Retornando √† implementa√ß√£o tradicional mais simples, a placa de rede recebe o pacote e envia uma <a href="https://en.wikipedia.org/wiki/Interrupt">interrup√ß√£o</a> ao kernel do Linux, que √© o pacote que precisa ser processado.  O kernel interrompe outra opera√ß√£o, alterna o contexto para o manipulador de interrup√ß√µes, processa o pacote e retorna √†s tarefas atuais. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1a2/3c3/4ee/1a23c34eea2236294913fd09a25aa1e4.png"><br><br>  Essa troca de contexto √© lenta: a lat√™ncia pode n√£o ter sido notada em placas de rede de 10 megabytes na d√©cada de 1990, mas em placas 10G modernas com uma taxa de transfer√™ncia m√°xima de 15 milh√µes de pacotes por segundo, cada n√∫cleo de um servidor pequeno de oito n√∫cleos pode ser interrompido milh√µes de vezes por segundo. <br><br>  Para n√£o lidar constantemente com o tratamento de interrup√ß√µes, h√° muitos anos o Linux adicionou o <a href="https://en.wikipedia.org/wiki/New_API">NAPI</a> : uma API de rede que todos os drivers modernos usam para aumentar o desempenho em alta velocidade.  Em baixas velocidades, o kernel ainda aceita interrup√ß√µes da placa de rede da maneira antiga.  Assim que chega um n√∫mero suficiente de pacotes que excede o limite, o kernel desativa as interrup√ß√µes e come√ßa a pesquisar o adaptador de rede e receber pacotes em lotes.  O processamento √© realizado em softirq, ou seja, no <a href="https://www.kernel.org/doc/htmldocs/kernel-hacking/basics-softirqs.html">contexto de interrup√ß√µes de software</a> ap√≥s chamadas do sistema e hardware interrompe quando o kernel (diferente do espa√ßo do usu√°rio) j√° est√° em execu√ß√£o. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/22a/50d/ee1/22a50dee1fffdbc20614db2b1db28fc4.png"><br><br>  Isso √© muito mais r√°pido, mas causa um problema diferente.  Se houver muitos pacotes, o tempo necess√°rio para processar pacotes da placa de rede e os processos de espa√ßo do usu√°rio n√£o ter√£o tempo para realmente esvaziar essas filas (leitura de conex√µes TCP, etc.).  No final, as filas s√£o preenchidas e come√ßamos a soltar pacotes.  Tentando encontrar um equil√≠brio, o kernel define um or√ßamento para o n√∫mero m√°ximo de pacotes processados ‚Äã‚Äãno contexto softirq.  Quando esse or√ßamento √© excedido, um encadeamento separado do <code>ksoftirqd</code> (voc√™ ver√° um deles em <code>ps</code> para cada n√∫cleo), que processa esses softirqs fora do caminho normal do syscall / interrupt.  Esse encadeamento √© planejado usando um agendador de processos padr√£o que tenta distribuir recursos de maneira justa. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d0f/1e6/f0c/d0f1e6f0c54d45c24d62cb2bcf90c674.png"><br><br>  Ap√≥s examinar como o kernel processa pacotes, voc√™ pode ver que h√° uma certa probabilidade de congestionamento.  Se as chamadas softirq forem recebidas com menos frequ√™ncia, os pacotes ter√£o que esperar um pouco para serem processados ‚Äã‚Äãna fila RX na placa de rede.  Talvez isso ocorra devido a alguma tarefa que bloqueia o n√∫cleo do processador, ou algo mais impede o kernel de iniciar o softirq. <br><br><h1>  Limitamos o processamento ao kernel ou m√©todo </h1><br>  Atrasos no Softirq s√£o apenas uma suposi√ß√£o.  Mas faz sentido, e sabemos que estamos vendo algo muito semelhante.  Portanto, o pr√≥ximo passo √© confirmar essa teoria.  E se for confirmado, encontre o motivo dos atrasos. <br><br>  De volta aos nossos pacotes lentos: <br><br> <code>len=46 ip=172.16.53.32 ttl=61 id=29573 icmp_seq=1953 rtt=99.3 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29574 icmp_seq=1954 rtt=89.3 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29575 icmp_seq=1955 rtt=79.2 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29576 icmp_seq=1956 rtt=69.1 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29577 icmp_seq=1957 rtt=59.1 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29790 icmp_seq=2070 rtt=75.7 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29791 icmp_seq=2071 rtt=65.6 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29792 icmp_seq=2072 rtt=55.5 ms</code> <br> <br>  Como discutido anteriormente, esses pacotes ICMP s√£o divididos em hash em uma √∫nica fila NIC RX e processados ‚Äã‚Äãpor um √∫nico n√∫cleo de CPU.  Se quisermos entender como o Linux funciona, √© √∫til saber onde (em qual n√∫cleo da CPU) e como (softirq, ksoftirqd) esses pacotes s√£o processados ‚Äã‚Äãpara acompanhar o processo. <br><br>  Agora √© hora de usar ferramentas que permitem o monitoramento em tempo real do kernel do Linux.  Aqui usamos <a href="https://github.com/iovisor/bcc">cco</a> .  Este kit de ferramentas permite gravar pequenos programas em C que interceptam fun√ß√µes arbitr√°rias no kernel e armazenam eventos em um programa Python no espa√ßo do usu√°rio que pode process√°-las e retornar o resultado.  Ganchos para fun√ß√µes arbitr√°rias no kernel s√£o complexos, mas o utilit√°rio foi projetado para seguran√ßa m√°xima e foi projetado para rastrear com precis√£o esses problemas de produ√ß√£o que n√£o s√£o f√°ceis de reproduzir em um ambiente de teste ou desenvolvimento. <br><br>  O plano aqui √© simples: sabemos que o kernel processa esses pings do ICMP, ent√£o colocamos um gancho na <a href="">fun√ß√£o do</a> kernel <a href="">icmp_echo</a> , que recebe o pacote ICMP de entrada "solicita√ß√£o de eco" e inicia o envio da resposta do ICMP "resposta de eco".  Podemos identificar o pacote aumentando o n√∫mero icmp_seq, que mostra o <code>hping3</code> acima. <br><br>  O c√≥digo de <a href="https://gist.github.com/theojulienne/9d78a0cb68dbe56f19a2ae6316bc6846">script cco</a> parece complicado, mas n√£o √© t√£o assustador quanto parece.  A fun√ß√£o <code>icmp_echo</code> passa <code>struct sk_buff *skb</code> : este √© o pacote com a solicita√ß√£o "echo request".  Podemos rastrear, extrair a sequ√™ncia <code>echo.sequence</code> (que mapeia para <code>icmp_seq</code> de hping3 <code></code> ) e envi√°-la para o espa√ßo do usu√°rio.  Tamb√©m √© conveniente capturar o nome / identificador atual do processo.  Abaixo est√£o os resultados que vemos diretamente durante o processamento de pacotes pelo kernel: <br><br><pre>  NOME DO PROCESSO DO TGID PID ICMP_SEQ
 0 0 trocador / 11.770
 0 0 trocador / 11.771
 0 0 trocador / 1172
 0 0 trocador / 1173
 0 0 trocador / 11.774
 20041 20086 prometheus 775
 0 0 trocador / 11.776
 0 0 trocador / 11.777
 0 0 trocador / 11788
 4512 4542 spokes-report-s 779 </pre><br>  Deve-se notar aqui que, no contexto do <code>softirq</code> processos que fizeram chamadas do sistema aparecem como "processos", embora, de fato, esse kernel processe pacotes com seguran√ßa no contexto do kernel. <br><br>  Com esta ferramenta, podemos estabelecer a conex√£o de processos espec√≠ficos com pacotes espec√≠ficos que mostram um atraso no <code>hping3</code> .  N√≥s fazemos um <code>grep</code> simples nesta captura para valores <code>icmp_seq</code> espec√≠ficos.  Pacotes correspondentes aos valores acima icmp_seq foram marcados com seu RTT, o que observamos acima (entre par√™nteses s√£o os valores RTT esperados para pacotes que filtramos devido a valores RTT inferiores a 50 ms): <br><br><pre>  NOME DO PROCESSO DO TGID PID ICMP_SEQ ** RTT
 -
 10137 10436 cadvisor 1951
 10137 10436 cadvisor 1952
 76 76 ksoftirqd / 11 1953 ** 99ms
 76 76 ksoftirqd / 11 1954 ** 89ms
 76 76 ksoftirqd / 11 1955 ** 79ms
 76 76 ksoftirqd / 11 1956 ** 69ms
 76 76 ksoftirqd / 11 1957 ** 59ms
 76 76 ksoftirqd / 11 1958 ** (49ms)
 76 76 ksoftirqd / 11 1959 ** (39ms)
 76 76 ksoftirqd / 11 1960 ** (29ms)
 76 76 ksoftirqd / 11 1961 ** (19 ms)
 76 76 ksoftirqd / 11 1962 ** (9ms)
 -
 10137 10436 cadvisor 2068
 10137 10436 cadvisor 2069
 76 76 ksoftirqd / 11 2070 ** 75ms
 76 76 ksoftirqd / 11 2071 ** 65ms
 76 76 ksoftirqd / 11 2072 ** 55ms
 76 76 ksoftirqd / 11 2073 ** (45ms)
 76 76 ksoftirqd / 11 2074 ** (35ms)
 76 76 ksoftirqd / 11 2075 ** (25ms)
 76 76 ksoftirqd / 11 2076 ** (15ms)
 76 76 ksoftirqd / 11 2077 ** (5ms) </pre><br>  Os resultados nos dizem algumas coisas.  Primeiro, o contexto do <code>ksoftirqd/11</code> lida com todos esses pacotes.  Isso significa que, para esse par espec√≠fico de m√°quinas, os pacotes ICMP foram divididos em hash no n√∫cleo 11 na extremidade receptora.  Tamb√©m vemos que, a cada congestionamento de tr√°fego, h√° pacotes processados ‚Äã‚Äãno contexto da chamada do sistema do <code>cadvisor</code> .  Ent√£o o <code>ksoftirqd</code> assume a tarefa e preenche a fila acumulada: exatamente o n√∫mero de pacotes acumulados ap√≥s o <code>cadvisor</code> . <br><br>  O fato de um <code>cadvisor</code> sempre trabalhar imediatamente antes disso implica seu envolvimento no problema.  Ironicamente, o objetivo do <a href="https://github.com/google/cadvisor">cadvisor</a> √© "analisar a utiliza√ß√£o de recursos e as caracter√≠sticas de desempenho de cont√™ineres em execu√ß√£o", em vez de causar esse problema de desempenho. <br><br>  Como em outros aspectos do manuseio de cont√™iner, todas essas s√£o ferramentas extremamente avan√ßadas, das quais problemas de desempenho podem ser esperados em algumas circunst√¢ncias imprevistas. <br><br><h1>  O que o cadvisor faz isso retarda a fila de pacotes? </h1><br>  Agora, temos um bom entendimento de como ocorre a falha, qual processo a causa e em qual CPU.  Vemos que, devido ao bloqueio f√≠sico, o kernel do Linux n√£o tem tempo para agendar o <code>ksoftirqd</code> .  E vemos que os pacotes s√£o processados ‚Äã‚Äãno contexto do <code>cadvisor</code> .  √â l√≥gico supor que o <code>cadvisor</code> inicia uma <code>cadvisor</code> lenta, ap√≥s a qual todos os pacotes acumulados no momento s√£o processados: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6fd/6fb/970/6fd6fb970f2d27943039910db9b41743.png"><br><br>  Esta √© uma teoria, mas como test√°-la?  O que podemos fazer √© rastrear a opera√ß√£o do n√∫cleo da CPU ao longo deste processo, encontrar o ponto em que o or√ßamento √© excedido pelo n√∫mero de pacotes e o ksoftirqd √© chamado e, em seguida, olhar um pouco mais cedo - o que exatamente funcionou no n√∫cleo da CPU antes desse momento.  √â como um raio-x de uma CPU a cada poucos milissegundos.  Ser√° algo parecido com isto: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/44a/954/6e8/44a9546e8de19e43cb125eb8a03a8f47.png"><br><br>  Convenientemente, tudo isso pode ser feito com as ferramentas existentes.  Por exemplo, o <a href="https://perf.wiki.kernel.org/index.php/Tutorial">registro perf</a> verifica o n√∫cleo da CPU especificado com a frequ√™ncia indicada e pode gerar um agendamento de chamadas para um sistema em execu√ß√£o, incluindo o espa√ßo do usu√°rio e o kernel do Linux.  Voc√™ pode pegar esse registro e process√°-lo usando uma pequena bifurca√ß√£o do programa <a href="https://github.com/brendangregg/FlameGraph">FlameGraph</a> de Brendan Gregg, que preserva a ordem de rastreamento da pilha.  Podemos salvar rastreamentos de pilha de uma linha a cada 1 ms e, em seguida, selecionar e salvar a amostra por 100 milissegundos antes que o <code>ksoftirqd</code> entre no rastreamento: <br><br> <code># record 999 times a second, or every 1ms with some offset so not to align exactly with timers <br> sudo perf record -C 11 -g -F 999 <br> # take that recording and make a simpler stack trace. <br> sudo perf script 2&gt;/dev/null | ./FlameGraph/stackcollapse-perf-ordered.pl | grep ksoftir -B 100</code> <br> <br>  Aqui est√£o os resultados: <br><br> <code>( ,   ) <br> <br> cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_nr_lru_pages;mem_cgroup_node_nr_lru_pages cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_nr_lru_pages;mem_cgroup_node_nr_lru_pages cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_iter cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_nr_lru_pages;mem_cgroup_node_nr_lru_pages cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_nr_lru_pages;mem_cgroup_node_nr_lru_pages ksoftirqd/11;ret_from_fork;kthread;kthread;smpboot_thread_fn;smpboot_thread_fn;run_ksoftirqd;__do_softirq;net_rx_action;ixgbe_poll;ixgbe_clean_rx_irq;napi_gro_receive;netif_receive_skb_internal;inet_gro_receive;bond_handle_frame;__netif_receive_skb_core;ip_rcv_finish;ip_rcv;ip_forward_finish;ip_forward;ip_finish_output;nf_iterate;ip_output;ip_finish_output2;__dev_queue_xmit;dev_hard_start_xmit;ipip_tunnel_xmit;ip_tunnel_xmit;iptunnel_xmit;ip_local_out;dst_output;__ip_local_out;nf_hook_slow;nf_iterate;nf_conntrack_in;generic_packet;ipt_do_table;set_match_v4;ip_set_test;hash_net4_kadt;ixgbe_xmit_frame_ring;swiotlb_dma_mapping_error;hash_net4_test ksoftirqd/11;ret_from_fork;kthread;kthread;smpboot_thread_fn;smpboot_thread_fn;run_ksoftirqd;__do_softirq;net_rx_action;gro_cell_poll;napi_gro_receive;netif_receive_skb_internal;inet_gro_receive;__netif_receive_skb_core;ip_rcv_finish;ip_rcv;ip_forward_finish;ip_forward;ip_finish_output;nf_iterate;ip_output;ip_finish_output2;__dev_queue_xmit;dev_hard_start_xmit;dev_queue_xmit_nit;packet_rcv;tpacket_rcv;sch_direct_xmit;validate_xmit_skb_list;validate_xmit_skb;netif_skb_features;ixgbe_xmit_frame_ring;swiotlb_dma_mapping_error;__dev_queue_xmit;dev_hard_start_xmit;__bpf_prog_run;__bpf_prog_run</code> <br> <br>  H√° muitas coisas aqui, mas a principal √© que encontramos o modelo "cadvisor before ksoftirqd" que vimos anteriormente no rastreador do ICMP.  O que isso significa? <br><br>  Cada linha √© um rastreio da CPU em um determinado momento.  Cada chamada na pilha em uma linha √© separada por ponto e v√≠rgula.  No meio das linhas, vemos syscall chamado: <code>read(): .... ;do_syscall_64;sys_read; ...</code>  <code>read(): .... ;do_syscall_64;sys_read; ...</code>  Portanto, o cadvisor passa muito tempo na chamada do sistema <code>read()</code> , relacionada √†s fun√ß√µes <code>mem_cgroup_*</code> (parte superior da pilha de chamadas / fim de linha). <br><br>  No rastreamento de chamadas, √© inconveniente ver exatamente o que est√° sendo lido, portanto, execute o <code>strace</code> e veja o que o cadvisor faz e encontre chamadas do sistema com mais de 100 ms: <br><br> <code>theojulienne@kube-node-bad ~ $ sudo strace -p 10137 -T -ff 2&gt;&amp;1 | egrep '&lt;0\.[1-9]' <br> [pid 10436] &lt;... futex resumed&gt; ) = 0 &lt;0.156784&gt; <br> [pid 10432] &lt;... futex resumed&gt; ) = 0 &lt;0.258285&gt; <br> [pid 10137] &lt;... futex resumed&gt; ) = 0 &lt;0.678382&gt; <br> [pid 10384] &lt;... futex resumed&gt; ) = 0 &lt;0.762328&gt; <br> [pid 10436] &lt;... read resumed&gt; "cache 154234880\nrss 507904\nrss_h"..., 4096) = 658 &lt;0.179438&gt; <br> [pid 10384] &lt;... futex resumed&gt; ) = 0 &lt;0.104614&gt; <br> [pid 10436] &lt;... futex resumed&gt; ) = 0 &lt;0.175936&gt; <br> [pid 10436] &lt;... read resumed&gt; "cache 0\nrss 0\nrss_huge 0\nmapped_"..., 4096) = 577 &lt;0.228091&gt; <br> [pid 10427] &lt;... read resumed&gt; "cache 0\nrss 0\nrss_huge 0\nmapped_"..., 4096) = 577 &lt;0.207334&gt; <br> [pid 10411] &lt;... epoll_ctl resumed&gt; ) = 0 &lt;0.118113&gt; <br> [pid 10382] &lt;... pselect6 resumed&gt; ) = 0 (Timeout) &lt;0.117717&gt; <br> [pid 10436] &lt;... read resumed&gt; "cache 154234880\nrss 507904\nrss_h"..., 4096) = 660 &lt;0.159891&gt; <br> [pid 10417] &lt;... futex resumed&gt; ) = 0 &lt;0.917495&gt; <br> [pid 10436] &lt;... futex resumed&gt; ) = 0 &lt;0.208172&gt; <br> [pid 10417] &lt;... futex resumed&gt; ) = 0 &lt;0.190763&gt; <br> [pid 10417] &lt;... read resumed&gt; "cache 0\nrss 0\nrss_huge 0\nmapped_"..., 4096) = 576 &lt;0.154442&gt;</code> <br> <br>  Como voc√™ pode esperar, aqui vemos chamadas de <code>read()</code> lenta <code>read()</code> .  A partir do conte√∫do das opera√ß√µes de leitura e do contexto <code>mem_cgroup</code> , <code>mem_cgroup</code> poss√≠vel observar que essas chamadas <code>read()</code> referem ao arquivo <code>memory.stat</code> , que mostra as limita√ß√µes de uso de mem√≥ria e cgroup (tecnologia de isolamento de recursos do Docker).  A ferramenta cadvisor consulta este arquivo para obter informa√ß√µes de uso de recursos para cont√™ineres.  Vamos verificar se esse core ou cadvisor faz algo inesperado: <br><br> <code>theojulienne@kube-node-bad ~ $ time cat /sys/fs/cgroup/memory/memory.stat &gt;/dev/null <br> <br> real 0m0.153s <br> user 0m0.000s <br> sys 0m0.152s <br> theojulienne@kube-node-bad ~ $</code> <br> <br>  Agora podemos reproduzir o bug e entender que o kernel do Linux est√° enfrentando patologia. <br><br><h1>  O que torna a leitura t√£o lenta? </h1><br>  Nesse momento, √© muito mais f√°cil encontrar mensagens de outros usu√°rios sobre problemas semelhantes.  Como se viu, no rastreador do cadvisor esse bug foi relatado como um <a href="https://github.com/google/cadvisor/issues/1774">problema de uso excessivo da CPU</a> , mas ningu√©m percebeu que o atraso tamb√©m era aleatoriamente refletido na pilha da rede.  De fato, notou-se que o cadvisor consome mais tempo do processador do que o esperado, mas isso n√£o recebeu muita import√¢ncia, porque nossos servidores possuem muitos recursos de processador, portanto, n√£o estudamos cuidadosamente o problema. <br><br>  O problema √© que os grupos de controle (cgroups) levam em considera√ß√£o o uso de mem√≥ria dentro do espa√ßo para nome (cont√™iner).  Quando todos os processos neste cgroup terminam, o Docker libera um grupo de controle de mem√≥ria.  No entanto, "mem√≥ria" n√£o √© apenas uma mem√≥ria de processo.  Embora a pr√≥pria mem√≥ria do processo n√£o seja mais usada, o kernel tamb√©m atribui conte√∫do em cache, como dentries e inodes (metadados de diret√≥rio e arquivo), armazenados em cache no cgroup de mem√≥ria.  A partir da descri√ß√£o do problema: <br><br><blockquote>  cgroups zombies: grupos de controle nos quais n√£o h√° processos e s√£o exclu√≠dos, mas para os quais a mem√≥ria ainda est√° alocada (no meu caso, a partir do cache do dentry, mas tamb√©m pode ser alocada no cache da p√°gina ou tmpfs). </blockquote><br>  O kernel que verifica todas as p√°ginas no cache quando o cgroup √© liberado pode ser muito lento, portanto o processo lento √© escolhido: espere at√© que essas p√°ginas sejam solicitadas novamente e, mesmo quando a mem√≥ria for realmente necess√°ria, limpe o cgroup.  At√© agora, o cgroup ainda √© levado em considera√ß√£o ao coletar estat√≠sticas. <br><br>  Em termos de desempenho, eles sacrificaram a mem√≥ria por desempenho: acelerando a limpeza inicial devido ao fato de que resta um pouco de mem√≥ria em cache.  Isso √© normal.  Quando o kernel usa a √∫ltima parte da mem√≥ria em cache, o cgroup √© eventualmente limpo, ent√£o isso n√£o pode ser chamado de "vazamento".  Infelizmente, a implementa√ß√£o espec√≠fica do mecanismo de pesquisa <code>memory.stat</code> nesta vers√£o do kernel (4.9), combinada com a enorme quantidade de mem√≥ria em nossos servidores, leva ao fato de que leva muito mais tempo para restaurar os dados em cache mais recentes e limpar os zumbis do cgroup. <br><br>  Acontece que havia tantos zumbis cgroup em alguns de nossos n√≥s que a leitura e a lat√™ncia excederam um segundo. <br><br>  Uma solu√ß√£o alternativa para o problema do cadvisor √© limpar imediatamente os caches de dentries / inodes em todo o sistema, o que elimina imediatamente a lat√™ncia de leitura e a lat√™ncia de rede no host, pois a exclus√£o do cache inclui p√°ginas em cache do cgroup zombie e elas tamb√©m s√£o liberadas.  Esta n√£o √© uma solu√ß√£o, mas confirma a causa do problema. <br><br>  Verificou-se que as vers√µes mais recentes do kernel (4.19+) melhoravam o desempenho da chamada <code>memory.stat</code> , portanto, a mudan√ßa para esse kernel corrigiu o problema.  Ao mesmo tempo, t√≠nhamos ferramentas para detectar n√≥s de problemas nos clusters do Kubernetes, drenando-os e reinicializando-os normalmente.  Examinamos todos os clusters, encontramos os n√≥s com um atraso suficientemente alto e os reinicializamos.  Isso nos deu tempo para atualizar o sistema operacional nos demais servidores. <br><br><h1>  Resumir </h1><br>  Como esse bug interrompeu o processamento das filas da NIC RX por centenas de milissegundos, causou simultaneamente um grande atraso em conex√µes curtas e um atraso no meio da conex√£o, por exemplo, entre consultas do MySQL e pacotes de resposta. <br><br>       ,   Kubernetes,            .    Kubernetes    . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt477390/">https://habr.com/ru/post/pt477390/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt477378/index.html">Agile misto - abordagem em cascata ao implementar aplicativos de neg√≥cios (tamb√©m conhecido como Agile)</a></li>
<li><a href="../pt477382/index.html">Esports - lucrando: Mercedes, megafone, apostas e marcas para esports</a></li>
<li><a href="../pt477384/index.html">Confer√™ncia ‚ÄúSeguran√ßa da Informa√ß√£o. Amea√ßas do presente e do futuro ‚Äù</a></li>
<li><a href="../pt477386/index.html">Semana 48 de seguran√ßa: Vazamento de dados gigantesco e vulnerabilidade do WhatsApp</a></li>
<li><a href="../pt477388/index.html">NILFS2 - sistema de arquivos √† prova de balas para / home</a></li>
<li><a href="../pt477392/index.html">Microfone aberto: back-end. Convidamos oradores</a></li>
<li><a href="../pt477396/index.html">Como se matricular em um curso e ... ir at√© o fim</a></li>
<li><a href="../pt477400/index.html">Sobre a profiss√£o de gerente de produto: como alcan√ßar o ideal?</a></li>
<li><a href="../pt477402/index.html">Implantando o Keras Deep Learning Model como um aplicativo da Web Python</a></li>
<li><a href="../pt477404/index.html">O problema de criar e excluir objetos com frequ√™ncia em C ++</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
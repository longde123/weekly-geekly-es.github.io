<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèª‚Äçü§ù‚Äçüßëüèª üì∑ üöè Preguntas frecuentes sobre arquitectura y trabajo VKontakte üî≥ üõµ üç°</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La historia de VKontakte est√° en Wikipedia, seg√∫n cont√≥ el propio Pavel. Parece que todos ya la conocen. Pavel habl√≥ sobre el interior, la arquitectur...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Preguntas frecuentes sobre arquitectura y trabajo VKontakte</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/449254/">  La historia de VKontakte est√° en Wikipedia, seg√∫n cont√≥ el propio Pavel.  Parece que todos ya la conocen.  Pavel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">habl√≥</a> sobre el interior, la arquitectura y el dise√±o del sitio en HighLoad ++ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en 2010</a> .  Desde entonces, se han filtrado muchos servidores, por lo que actualizaremos la informaci√≥n: diseccionamos, sacamos el interior, pesamos: observamos el dispositivo VK desde un punto de vista t√©cnico. <br><br><img src="https://habrastorage.org/webt/_x/zc/wp/_xzcwpb5ze_4e-yx_jw_-8nvnei.jpeg"><br><br>  <strong>Alexey Akulovich</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">AterCattus</a> ) es un desarrollador de back-end en el equipo de VKontakte.  La transcripci√≥n de este informe es una respuesta colectiva a las preguntas frecuentes sobre el funcionamiento de la plataforma, la infraestructura, los servidores y la interacci√≥n entre ellos, pero no sobre el desarrollo, es decir, <strong>sobre el hardware</strong> .  Por separado: sobre las bases de datos y lo que VK tiene en su lugar, sobre la recopilaci√≥n de registros y el seguimiento de todo el proyecto en su conjunto.  Detalles debajo del corte. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/_GqcriadL-s" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><a name="habracut"></a><br>  Durante m√°s de cuatro a√±os he estado haciendo todo tipo de tareas relacionadas con el backend. <br><br><ul><li>  Descarga, almacenamiento, procesamiento, distribuci√≥n de medios: video, transmisi√≥n en vivo, audio, fotos, documentos. </li><li>  Infraestructura, plataforma, monitoreo de desarrolladores, registros, cach√©s regionales, CDN, protocolo RPC patentado. </li><li>  Integraci√≥n con servicios externos: env√≠o de correos, an√°lisis de enlaces externos, fuente RSS. </li><li>  Ayuda a tus colegas en varios temas, para las respuestas a las que tienes que sumergirte en un c√≥digo desconocido. </li></ul><br>  Durante este tiempo, particip√© en muchos componentes del sitio.  Quiero compartir esta experiencia <br><br><h2>  Arquitectura general </h2><br>  Todo, como de costumbre, comienza con un servidor o un grupo de servidores que aceptan solicitudes. <br><br><h3>  Servidor frontal </h3><br>  El servidor frontal acepta solicitudes a trav√©s de HTTPS, RTMP y WSS. <br><br>  <strong>HTTPS</strong> son solicitudes de las versiones web principal y m√≥vil del sitio: vk.com y m.vk.com, y otros clientes oficiales y no oficiales de nuestra API: clientes m√≥viles, mensajer√≠a instant√°nea.  Tenemos una recepci√≥n de tr√°fico <strong>RTMP</strong> para transmisiones en vivo con servidores frontales separados y conexiones <strong>WSS</strong> para Streaming API. <br><br>  Para HTTPS y WSS, <strong>nginx est√°</strong> instalado en los servidores.  Para las transmisiones RTMP, recientemente cambiamos a nuestra propia soluci√≥n <strong>kive</strong> , pero est√° m√°s all√° del alcance del informe.  Para la tolerancia a fallas, estos servidores anuncian direcciones IP compartidas y act√∫an como grupos para que, en caso de problemas en uno de los servidores, no se pierdan las solicitudes de los usuarios.  Para HTTPS y WSS, estos mismos servidores encriptan el tr√°fico para tomar parte de la carga de la CPU en s√≠ mismos. <br><br>  Adem√°s, no hablaremos sobre WSS y RTMP, sino solo sobre solicitudes HTTPS est√°ndar, que generalmente est√°n asociadas con un proyecto web. <br><br><h3>  Backend </h3><br>  Detr√°s del frente suelen estar los servidores de fondo.  Manejan las solicitudes que el servidor frontal recibe de los clientes. <br><br>  Estos son <strong>servidores kPHP que</strong> ejecutan el demonio HTTP porque HTTPS ya est√° descifrado.  kPHP es un servidor que funciona de acuerdo con el <strong>modelo prefork</strong> : inicia el proceso maestro, un grupo de procesos secundarios, les pasa sockets de escucha y procesan sus solicitudes.  Al mismo tiempo, los procesos no se reinician entre cada solicitud del usuario, sino que simplemente restablecen su estado al estado inicial de valor cero: solicitud por solicitud, en lugar de reiniciar. <br><br><h4>  Compartir la carga </h4><br>  Todos nuestros backends no son un gran grupo de m√°quinas que pueden manejar cualquier solicitud.  Los <strong>dividimos en grupos separados</strong> : general, m√≥vil, api, video, puesta en escena ... El problema en un grupo separado de m√°quinas no afectar√° a todos los dem√°s.  En caso de problemas con el video, el usuario que est√° escuchando m√∫sica ni siquiera sabe acerca de los problemas.  A qu√© backend enviar la solicitud se resuelve nginx en la parte delantera de la configuraci√≥n. <br><br><h4>  Recolecci√≥n de m√©tricas y reequilibrio </h4><br>  Para comprender cu√°ntos autom√≥viles necesita en cada grupo, <strong>no confiamos en QPS</strong> .  Los backends son diferentes, tienen solicitudes diferentes, cada solicitud tiene una complejidad de c√°lculo QPS diferente.  Por lo tanto, utilizamos el <strong>concepto de carga en el servidor como un todo, en la CPU y el rendimiento</strong> . <br><br>  Tenemos miles de tales servidores.  El grupo kPHP se ejecuta en cada servidor f√≠sico para utilizar todos los n√∫cleos (porque kPHP es de un solo subproceso). <br><br><h3>  Servidor de contenido </h3><br>  <strong>CS o Content Server es almacenamiento</strong> .  CS es un servidor que almacena archivos y tambi√©n procesa archivos cargados, todo tipo de tareas en segundo plano sincr√≥nicas que la interfaz web principal le plantea. <br><br>  Tenemos decenas de miles de servidores f√≠sicos que almacenan archivos.  A los usuarios les encanta subir archivos, y nos encanta almacenarlos y compartirlos.  Algunos de estos servidores est√°n cerrados por servidores especiales pu / pp. <br><br><h3>  pu / pp </h3><br>  Si abri√≥ la pesta√±a de red en VK, vio pu / pp. <br><br><img src="https://habrastorage.org/webt/fd/am/xo/fdamxolkfxlplnc5h5flbihru3g.png"><br><br>  ¬øQu√© es pu / pp?  Si cerramos un servidor tras otro, existen dos opciones para cargar y descargar un archivo a un servidor que se cerr√≥: <strong>directamente a</strong> trav√©s de <code>http://cs100500.userapi.com/path</code> o a <strong>trav√©s de un servidor intermedio</strong> : <code>http://pu.vk.com/c100500/path</code> . <br><br>  <strong>Pu es el nombre hist√≥rico para subir fotos y pp es proxy de fotos</strong> .  Es decir, un servidor para subir fotos y otro para dar.  Ahora no solo se cargan las fotos, sino que se ha conservado el nombre. <br><br>  Estos servidores <strong>finalizan las sesiones HTTPS</strong> para eliminar la carga del procesador del almacenamiento.  Adem√°s, dado que los archivos de usuario se procesan en estos servidores, cuanto menos informaci√≥n confidencial se almacene en estas m√°quinas, mejor.  Por ejemplo, claves de cifrado HTTPS. <br><br>  Dado que las otras m√°quinas cierran las m√°quinas, podemos darnos el lujo de no darles IP externas "blancas" y <strong>darles "grises"</strong> .  As√≠ que ahorramos en el grupo de IP y garantizamos proteger las m√°quinas del acceso desde el exterior, simplemente no hay IP para acceder. <br><br>  <strong>Tolerancia a fallos a trav√©s de IP compartida</strong> .  En t√©rminos de tolerancia a fallas, el esquema funciona de la misma manera: varios servidores f√≠sicos tienen una IP f√≠sica com√∫n, y el trozo de hierro frente a ellos elige d√≥nde enviar la solicitud.  M√°s adelante hablar√© sobre otras opciones. <br><br>  El punto controvertido es que, en este caso, el <strong>cliente tiene menos conexiones</strong> .  Si hay la misma IP en varias m√°quinas, con el mismo host: pu.vk.com o pp.vk.com, el navegador del cliente tiene un l√≠mite en la cantidad de solicitudes simult√°neas a un host.  Pero durante el ubicuo HTTP / 2, creo que este ya no es el caso. <br><br>  El inconveniente obvio del esquema es que debe <strong>bombear todo el tr√°fico</strong> que va al almacenamiento a trav√©s de otro servidor.  Como bombeamos tr√°fico a trav√©s de autom√≥viles, todav√≠a no podemos bombear tr√°fico pesado de la misma manera, por ejemplo, video.  Lo transferimos directamente, una conexi√≥n directa separada para repositorios individuales espec√≠ficamente para video.  Transmitimos contenido m√°s ligero a trav√©s de un proxy. <br><br>  No hace mucho tiempo, tenemos una versi√≥n mejorada de proxy.  Ahora te dir√© en qu√© se diferencian de los normales y por qu√© es necesario. <br><br><h3>  Sol </h3><br>  En septiembre de 2017, Oracle, que anteriormente hab√≠a comprado Sun, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">despidi√≥ a una gran cantidad de empleados de Sun.</a>  Podemos decir que en este momento la empresa dej√≥ de existir.  Al elegir un nombre para el nuevo sistema, nuestros administradores decidieron rendir homenaje y respeto a esta empresa, y nombraron el nuevo sistema Sun.  Entre nosotros, lo llamamos simplemente "sol". <br><br><img src="https://habrastorage.org/webt/d3/6f/0j/d36f0jjqbwlst9mk2-lcncltkq4.png"><br><br>  Pp tuvo algunos problemas.  <strong>Una IP por grupo es un cach√© ineficiente</strong> .  Varios servidores f√≠sicos tienen una direcci√≥n IP com√∫n, y no hay forma de controlar a qu√© servidor llegar√° la solicitud.  Por lo tanto, si diferentes usuarios vienen para el mismo archivo, entonces si hay una memoria cach√© en estos servidores, el archivo se instala en la memoria cach√© de cada servidor.  Este es un esquema muy ineficiente, pero no se pudo hacer nada. <br><br>  Como resultado, <strong>no podemos compartir el contenido</strong> , porque no podemos seleccionar un servidor espec√≠fico para este grupo; tienen una IP com√∫n.  Adem√°s, por algunas razones internas, <strong>no tuvimos la oportunidad de colocar dichos servidores en las regiones</strong> .  Se quedaron solo en San Petersburgo. <br><br>  Con los soles, cambiamos el sistema de selecci√≥n.  Ahora tenemos <strong>enrutamiento anycast</strong> : <strong>enrutamiento</strong> din√°mico, anycast, self-check daemon.  Cada servidor tiene su propia IP individual, pero al mismo tiempo una subred com√∫n.  Todo est√° configurado de tal manera que, en caso de p√©rdida de un servidor, el tr√°fico se distribuye autom√°ticamente a otros servidores del mismo grupo.  Ahora es posible seleccionar un servidor espec√≠fico, <strong>no hay almacenamiento en cach√© excesivo</strong> y la confiabilidad no se ve afectada. <br><br>  <strong>Soporte de peso</strong> .  Ahora podemos permitirnos poner autos de diferentes capacidades seg√∫n sea necesario, y tambi√©n en caso de problemas temporales, cambiar el peso de los "soles" que trabajan para reducir la carga sobre ellos para que "descansen" y vuelvan a trabajar. <br><br>  <strong>Fragmentaci√≥n por ID de contenido</strong> .  Lo curioso de los fragmentos es que usualmente compartimos contenido para que diferentes usuarios sigan el mismo archivo a trav√©s del mismo "sol" para que tengan un cach√© com√∫n. <br><br>  Recientemente lanzamos la aplicaci√≥n Clover.  Este es un cuestionario de transmisi√≥n en vivo en l√≠nea donde el presentador hace preguntas y los usuarios responden en tiempo real eligiendo opciones.  La aplicaci√≥n tiene un chat donde los usuarios pueden inundar.  <strong>M√°s de 100 mil personas</strong> pueden conectarse simult√°neamente a la transmisi√≥n.  Todos escriben mensajes que se env√≠an a todos los participantes, junto con el mensaje viene otro avatar.  Si 100 mil personas vienen por un avatar en un "sol", entonces a veces puede rodar sobre una nube. <br><br>  Con el fin de resistir las r√°fagas de solicitudes del mismo archivo, es para alg√∫n tipo de contenido que incluimos un esquema tonto que distribuye los archivos a trav√©s de todos los "soles" disponibles en la regi√≥n. <br><br><h4>  Sol adentro </h4><br>  Proxy inverso a nginx, cach√© en RAM o discos r√°pidos Optane / NVMe.  Ejemplo: <code>http://sun4-2.userapi.com/c100500/path</code> : enlace al "sol", que se encuentra en la cuarta regi√≥n, el segundo grupo de servidores.  Cierra el archivo de ruta, que se encuentra f√≠sicamente en el servidor 100500. <br><br><h3>  Cach√© </h3><br>  Agregamos un nodo m√°s a nuestro esquema arquitect√≥nico: el entorno de almacenamiento en cach√©. <br><br><img src="https://habrastorage.org/webt/jp/4p/xv/jp4pxvydhstms-z9bpbmpjy0htk.png"><br><br>  A continuaci√≥n se muestra el dise√±o de <strong>cach√©s regionales</strong> , hay alrededor de 20 de ellos.  Estos son los lugares donde se ubican exactamente los cach√©s y los "soles", que pueden almacenar tr√°fico a trav√©s de ellos. <br><br><img src="https://habrastorage.org/webt/yh/9i/qk/yh9iqkv3dyqd3uox9wgd2cmgqba.png"><br><br>  Esto es el almacenamiento en cach√© de contenido multimedia, los datos del usuario no se almacenan aqu√≠, solo m√∫sica, videos y fotos. <br><br>  Para determinar la regi√≥n del usuario, <strong>recopilamos los prefijos de red BGP anunciados en las regiones</strong> .  En el caso de la reserva, todav√≠a tenemos el an√°lisis de la base de geoip, si no pudimos encontrar IP por prefijos.  <strong>Por IP del usuario, determinamos la regi√≥n</strong> .  En el c√≥digo, podemos ver una o m√°s regiones del usuario, esos puntos a los que est√° geogr√°ficamente m√°s cercano. <br><br><h4>  Como funciona </h4><br>  <strong>Consideramos la popularidad de los archivos por regi√≥n</strong> .  Hay un n√∫mero de cach√© regional donde se encuentra el usuario y un identificador de archivo: tomamos este par e incrementamos la calificaci√≥n para cada descarga. <br><br>  Al mismo tiempo, los demonios (servicios en las regiones) de vez en cuando acuden a la API y dicen: "Tengo tal y tal cach√©, dame una lista de los archivos m√°s populares en mi regi√≥n que a√∫n no tengo".  La API proporciona un mont√≥n de archivos ordenados por clasificaci√≥n, el demonio los bombea, los lleva a las regiones y les da archivos desde all√≠.  Esta es una diferencia fundamental entre pu / pp y Sun de las memorias cach√©: entregan el archivo de forma inmediata, incluso si el archivo no existe en el cach√©, y el cach√© primero descarga el archivo en s√≠ mismo y luego comienza a regalarlo. <br><br>  Al mismo tiempo, acercamos el <strong>contenido a los usuarios</strong> y difuminamos la carga de la red.  Por ejemplo, solo desde el cach√© de Mosc√∫ distribuimos m√°s de 1 Tbit / s durante las horas ocupadas. <br><br>  Pero hay problemas: los <strong>servidores de cach√© no son de goma</strong> .  Para contenido s√∫per popular, a veces no hay suficiente red en un servidor separado.  Tenemos servidores de cach√© de 40-50 Gbit / s, pero hay contenido que obstruye completamente dicho canal.  Nos esforzamos por realizar el almacenamiento de m√°s de una copia de archivos populares en la regi√≥n.  Espero que nos demos cuenta antes de fin de a√±o. <br><br>  Examinamos la arquitectura general. <br><br><ul><li>  Servidores frontales que aceptan solicitudes. </li><li>  Backends que manejan solicitudes. </li><li>  B√≥vedas que est√°n cerradas por dos tipos de servidores proxy. </li><li>  Cach√©s regionales. </li></ul><br>  ¬øQu√© le falta a este esquema?  Por supuesto, las bases de datos en las que almacenamos datos. <br><br><h2>  Bases de datos o motores </h2><br>  Los llamamos no bases de datos, sino motores de motores, porque en el sentido generalmente aceptado pr√°cticamente no tenemos bases de datos. <br><br><img src="https://habrastorage.org/webt/n6/zm/lj/n6zmlj5pwxsnqoqp0xgfhxza_ic.png"><br><br>  <strong>Esta es una medida necesaria</strong> .  Sucedi√≥ porque en 2008-2009, cuando VK tuvo un crecimiento explosivo en popularidad, el proyecto funcion√≥ completamente en MySQL y Memcache, y hubo problemas.  A MySQL le gustaba caer y arruinar los archivos, despu√©s de lo cual no aument√≥, y Memcache gradualmente se degrad√≥ en rendimiento, y tuvo que reiniciarse. <br><br>  Resulta que en el proyecto que estaba ganando popularidad hab√≠a un almacenamiento persistente que corromp√≠a los datos y un cach√© que se ralentizaba.  En tales condiciones, es dif√≠cil desarrollar un proyecto en crecimiento.  Se decidi√≥ intentar reescribir las cosas cr√≠ticas en las que se basaba el proyecto en sus propias bicicletas. <br><br>  <strong>La soluci√≥n fue exitosa</strong> .  La capacidad de hacer esto era, como era una necesidad urgente, porque otros m√©todos de escalado no exist√≠an en ese momento.  No hab√≠a un mont√≥n de bases, NoSQL a√∫n no exist√≠a, solo exist√≠an MySQL, Memcache, PostrgreSQL, y eso es todo. <br><br>  <strong>Operaci√≥n universal</strong> .  El desarrollo fue liderado por nuestro equipo de desarrolladores C, y todo se hizo de la misma manera.  Independientemente del motor, en todas partes hab√≠a aproximadamente el mismo formato de los archivos escritos en el disco, los mismos par√°metros de inicio, las se√±ales se procesaron de la misma manera y se comportaron de la misma manera en caso de situaciones y problemas extremos.  Con el crecimiento de los motores, es conveniente para los administradores operar el sistema: no hay zool√≥gico que deba mantenerse y aprender a operar cada nueva base de terceros nuevamente, lo que permiti√≥ aumentar su n√∫mero de manera r√°pida y conveniente. <br><br><h3>  Tipos de motores </h3><br>  El equipo ha escrito bastantes motores.  Aqu√≠ hay algunos de ellos: amigo, sugerencias, imagen, ipdb, cartas, listas, registros, memcached, meowdb, noticias, nostradamus, fotos, listas de reproducci√≥n, pmemcached, sandbox, b√∫squeda, almacenamiento, me gusta, tareas, ... <br><br>  Para cada tarea que requiere una estructura de datos espec√≠fica o procesa solicitudes at√≠picas, el equipo C escribe un nuevo motor.  Por qu√© no <br><br>  Tenemos un motor de <strong>memoria cach√©</strong> separado, que es similar al habitual, pero con un mont√≥n de cosas buenas, y que no se ralentiza.  No es ClickHouse, pero tambi√©n funciona.  Hay <strong>pmemcached por</strong> separado: es un <strong>memcached persistente</strong> que puede almacenar datos tambi√©n en el disco, y m√°s de lo que ingresa en la RAM para no perder datos al reiniciar.  Hay varios motores para tareas individuales: colas, listas, conjuntos: todo lo que requiere nuestro proyecto. <br><br><h3>  Racimos </h3><br>  Desde el punto de vista del c√≥digo, no hay necesidad de imaginar motores o bases de datos como ciertos procesos, entidades o instancias.  El c√≥digo funciona espec√≠ficamente con grupos, con grupos de motores, <strong>un tipo por grupo</strong> .  Digamos que hay un cl√∫ster de memoria cach√©: es solo un grupo de m√°quinas. <br><br><blockquote>  El c√≥digo no necesita conocer la ubicaci√≥n f√≠sica, el tama√±o y la cantidad de servidores.  √âl va al grupo por alg√∫n identificador. </blockquote><br>  Para que esto funcione, debe agregar otra entidad, que se encuentra entre el c√≥digo y los motores: <strong>proxy</strong> . <br><br><h3>  Proxy RPC </h3><br>  Proxy: un <strong>bus de conexi√≥n</strong> , que ejecuta casi todo el sitio.  Al mismo tiempo, <strong>no tenemos descubrimiento de servicio</strong> ; en su lugar, hay una configuraci√≥n de este proxy, que conoce la ubicaci√≥n de todos los cl√∫steres y todos los fragmentos de este cl√∫ster.  Esto lo hacen los administradores. <br><br>  Los programadores generalmente no les importa cu√°nto, d√≥nde y cu√°nto cuesta, simplemente van al cl√∫ster.  Esto nos permite mucho.  Al recibir la solicitud, el proxy redirige la solicitud, sabiendo d√≥nde, determina esto. <br><br><img src="https://habrastorage.org/webt/7k/pf/ia/7kpfiagxzy2a4mrosc_f4otqnw8.png"><br><br>  Al mismo tiempo, el proxy es un punto de protecci√≥n contra fallas en el servicio.  Si alg√∫n motor se ralentiza o falla, el proxy lo entiende y, en consecuencia, responde al lado del cliente.  Esto le permite eliminar el tiempo de espera: el c√≥digo no espera a que el motor responda, pero comprende que no funciona y debe comportarse de manera diferente.  El c√≥digo debe estar preparado para el hecho de que las bases de datos no siempre funcionan. <br><br><h4>  Implementaciones espec√≠ficas </h4><br>  A veces todav√≠a queremos tener alg√∫n tipo de soluci√≥n personalizada como motor.  Al mismo tiempo, se decidi√≥ no utilizar nuestro proxy rpc listo para usar, creado espec√≠ficamente para nuestros motores, sino crear un proxy separado para la tarea. <br><br>  Para MySQL, que todav√≠a tenemos en algunos lugares, usamos db-proxy y para ClickHouse - <strong>Kittenhouse</strong> . <br><br>  Esto funciona en general as√≠.  Hay un servidor, kPHP, Go, Python se est√°n ejecutando en √©l, en general, cualquier c√≥digo que pueda seguir nuestro protocolo RPC.  El c√≥digo va localmente al proxy RPC: en cada servidor donde hay c√≥digo, se inicia su propio proxy local.  Previa solicitud, el representante entiende a d√≥nde ir. <br><br><img src="https://habrastorage.org/webt/f-/dx/ro/f-dxrox3o97ckejzygz8mgf4tcs.png"><br><br>  Si un motor quiere ir a otro, incluso si es un vecino, pasa por un proxy, porque el vecino puede estar en un centro de datos diferente.  El motor no debe estar vinculado a conocer la ubicaci√≥n de otra cosa que no sea s√≠ mismo: tenemos esta soluci√≥n est√°ndar.  Pero, por supuesto, hay excepciones :) <br><br>  Un ejemplo de un esquema TL seg√∫n el cual funcionan todos los motores. <br><br><pre> <code class="plaintext hljs">memcache.not_found = memcache.Value; memcache.strvalue value:string flags:int = memcache.Value; memcache.addOrIncr key:string flags:int delay:int value:long = memcache.Value; tasks.task fields_mask:# flags:int tag:%(Vector int) data:string id:fields_mask.0?long retries:fields_mask.1?int scheduled_time:fields_mask.2?int deadline:fields_mask.3?int = tasks.Task; tasks.addTask type_name:string queue_id:%(Vector int) task:%tasks.Task = Long;</code> </pre> <br>  Este es un protocolo binario, cuyo an√°logo m√°s cercano es <strong>protobuf.</strong>  El esquema describe de antemano campos opcionales, tipos complejos: extensiones de escalares incorporados y consultas.  Todo funciona de acuerdo con este protocolo. <br><br><h4>  RPC sobre TL sobre TCP / UDP ... UDP? </h4><br>  Tenemos un protocolo RPC para consultar el motor, que se ejecuta sobre el esquema TL.  Todo esto funciona sobre la conexi√≥n TCP / UDP.  TCP: est√° claro por qu√© a menudo se nos pregunta sobre UDP. <br><br>  UDP ayuda a <strong>evitar el problema de una gran cantidad de conexiones entre servidores</strong> .  Si hay un proxy RPC en cada servidor y, en general, puede ir a cualquier motor, entonces obtienes decenas de miles de conexiones TCP al servidor.  Hay una carga, pero es in√∫til.  En el caso de UDP, esto no es un problema. <br><br>  <strong>Sin protocolo de enlace TCP redundante</strong> .  Este es un problema t√≠pico: cuando surge un nuevo motor o un nuevo servidor, se establecen muchas conexiones TCP a la vez.  Para solicitudes peque√±as y livianas, por ejemplo, carga √∫til UDP, toda la comunicaci√≥n entre el c√≥digo y el motor son <strong>dos paquetes UDP:</strong> uno vuela en una direcci√≥n y el otro en la otra.  Un viaje de ida y vuelta, y el c√≥digo recibi√≥ una respuesta del motor sin un apret√≥n de manos. <br><br>  S√≠, todo funciona solo <strong>con un porcentaje muy peque√±o de p√©rdida de paquetes</strong> .  El protocolo tiene soporte para retransmisiones, tiempos de espera, pero si perdemos mucho, obtenemos pr√°cticamente TCP, que no es rentable.  A trav√©s de los oc√©anos, no conduzca UDP. <br><br>  Tenemos miles de estos servidores, y el mismo esquema existe: se coloca un paquete de motores en cada servidor f√≠sico.  B√°sicamente, tienen un solo subproceso para funcionar lo m√°s r√°pido posible sin bloqueo, y se trituran como soluciones de un solo subproceso.  Al mismo tiempo, no tenemos nada m√°s confiable que estos motores, y se presta mucha atenci√≥n al almacenamiento persistente de datos. <br><br><h3>  Almacenamiento de datos persistente </h3><br>  <strong>Los motores escriben binlogs</strong> .  Un binlog es un archivo al final del cual se agrega un evento para cambiar un estado o datos.  En diferentes soluciones se le llama de manera diferente: registro binario, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">WAL</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AOF</a> , pero el principio es uno. <br><br>  Para que el motor no vuelva a leer todo el binlog durante un reinicio durante muchos a√±os, los motores escriben <strong>instant√°neas: el estado actual</strong> .  Si es necesario, primero leen y luego leen el binlog.  Todos los binlogs est√°n escritos en el mismo formato binario, de acuerdo con el esquema TL, para que los administradores puedan administrarlos por igual con sus herramientas.  No hay tal necesidad de instant√°neas.  Hay un encabezado general que indica de qui√©n es la instant√°nea, la magia del motor y qu√© cuerpo no es importante para nadie.  Este es el problema del motor que grab√≥ la instant√°nea. <br><br>  Describir√© brevemente el principio del trabajo.  Hay un servidor en el que se est√° ejecutando el motor.  Abre un nuevo binlog vac√≠o para grabar, escribe un evento de cambio en √©l. <br><br><img src="https://habrastorage.org/webt/dd/w9/9p/ddw99p7g6upg9hci9ou6aln6d_c.png"><br><br>  En alg√∫n momento, decide tomar una instant√°nea o recibe una se√±al.  El servidor crea un nuevo archivo, escribe completamente su estado en √©l, agrega el tama√±o actual del binlog - desplazamiento al final del archivo, y contin√∫a escribiendo m√°s.  No se crea un nuevo binlog. <br><br><img src="https://habrastorage.org/webt/ec/fq/yt/ecfqytibh2tsm5ncd8mfli-b1ta.png"><br><br>  En alg√∫n momento, cuando el motor se reinicie, habr√° un binlog y una instant√°nea en el disco.  El motor lee en una instant√°nea completa, eleva su estado en cierto punto. <br><br><img src="https://habrastorage.org/webt/bg/ph/-u/bgph-uu68nqedhby4a2kf3r9c5u.png"><br><br>  Resta la posici√≥n que estaba en el momento en que se cre√≥ la instant√°nea y el tama√±o del binlog. <br><br><img src="https://habrastorage.org/webt/ar/gs/lq/argslqv8ewosmtic8-zaobq4g5o.png"><br><br>  Lee el final del binlog para obtener el estado actual y contin√∫a escribiendo m√°s eventos.  Este es un esquema simple, todos nuestros motores funcionan en √©l. <br><br><h4>  Replicaci√≥n de datos </h4><br>  Como resultado, la replicaci√≥n de datos est√° <strong>basada en declaraciones</strong> : no estamos escribiendo ning√∫n cambio de p√°gina en el binlog, sino <strong>solicitudes de cambios</strong> .  Muy similar a lo que viene a trav√©s de la red, solo un poco cambiado. <br><br>  El mismo esquema se usa no solo para la replicaci√≥n, sino tambi√©n <strong>para crear copias de seguridad</strong> .  Tenemos un motor: un maestro de la escritura que escribe en un binlog.  En cualquier otro lugar donde configuren los administradores, la copia de este binlog aumenta, y eso es todo: tenemos una copia de seguridad. <br><br><img src="https://habrastorage.org/webt/og/al/sz/ogalszm0wfe3f_064sbjnpo4p9c.png"><br><br>  Si necesita una <strong>r√©plica de lectura</strong> para reducir la carga de lectura en la CPU, el motor de lectura simplemente se eleva, que lee el final del binlog y ejecuta estos comandos localmente. <br><br>  El retraso aqu√≠ es muy peque√±o, y existe la oportunidad de averiguar cu√°nto queda la r√©plica detr√°s del maestro. <br><br><h3>  Fragmentaci√≥n de datos en proxy RPC </h3><br>  ¬øC√≥mo funciona el fragmentaci√≥n?  ¬øC√≥mo entiende el proxy a qu√© fragmento de cl√∫ster enviar?  El c√≥digo no dice: "¬°Enviar a 15 fragmentos!"  - No, hace un proxy. <br><br>  <strong>El esquema m√°s simple es firstint</strong> , el primer n√∫mero en la solicitud. <br><br> <code>get(photo100_500) =&gt; 100 % N.</code> <br> <br>  Este es un ejemplo para un protocolo simple de texto memcached, pero, por supuesto, las solicitudes son complejas y estructuradas.  El ejemplo toma el primer n√∫mero en la consulta y el resto de la divisi√≥n por el tama√±o del cl√∫ster. <br><br>  Esto es √∫til cuando queremos tener la localidad de datos de una entidad.  Digamos que 100 es un ID de usuario o grupo, y queremos que todos los datos de una entidad est√©n en el mismo fragmento para consultas complejas. <br><br>  Si no nos importa c√≥mo se distribuyen las solicitudes en el cl√∫ster, existe otra opci√≥n: <strong>dividir el fragmento completo</strong> . <br><br> <code>hash(photo100_500) =&gt; 3539886280 % N</code> <br> <br>  Tambi√©n obtenemos el hash, el resto de la divisi√≥n y el n√∫mero del fragmento. <br><br>  Ambas opciones funcionan solo si estamos preparados para el hecho de que cuando aumentamos el tama√±o del cl√∫ster, lo dividiremos o lo multiplicaremos por varias veces.  Por ejemplo, ten√≠amos 16 fragmentos, nos faltan, queremos m√°s: puede obtener 32 de forma segura sin tiempo de inactividad.  Si queremos construir varias veces, habr√° un tiempo de inactividad, ya que no ser√° posible aplastar todo cuidadosamente sin p√©rdida.  Estas opciones son √∫tiles, pero no siempre. <br><br>  Si necesitamos agregar o eliminar un n√∫mero arbitrario de servidores, <strong>se utiliza un hashing consistente en el anillo a la Ketama</strong> .  Pero al mismo tiempo, perdemos completamente la localidad de los datos, tenemos que hacer una solicitud de fusi√≥n al cl√∫ster para que cada pieza devuelva su peque√±a respuesta y ya combine las respuestas al proxy. <br><br>  - .   : RPC-proxy  , ,       .     , ,     ,      .    proxy. <br><br><img src="https://habrastorage.org/webt/jx/6t/f9/jx6tf9jlkkmva1qfifzmwrx58wc.png"><br><br><h2>  </h2><br>     .     ‚Äî <strong>   memcache</strong> . <br><br> <code>ring-buffer: prefix.idx = line</code> <br> <br>    ‚Äî  , ,      ‚Äî  .     0     1.   memcache ‚Äî       .        . <br><br>    ,   <strong>Multi Get</strong>  ,   ,         .  ,   -      ,   ,         ,      . <br><br>         <strong>logs-engine</strong> .      ,       .       600   . <br><br>   ,  ,    6‚Äì7 .    ,    , ,    ClickHouse   . <br><br><h3>    ClickHouse </h3><br>   ,      . <br><br><img src="https://habrastorage.org/webt/jm/-j/s0/jm-js04tjh8lb8pii1_dzl_sfa4.png"><br><br>  ,   RPC    RPC-proxy,   ,    .       ClickHouse,        : <br><br><ul><li>  -   ClickHouse; </li><li>  RPC-proxy,      ClickHouse,  - ,  ,   RPC. </li></ul><br>    ‚Äî          ClickHouse. <br><br>     ClickHouse,   <strong>KittenHouse</strong> .      KittenHouse  ClickHouse ‚Äî   .   ,  HTTP-     .   ,    ClickHouse <strong>  reverse proxy</strong> ,   ,     .         . <br><br><img src="https://habrastorage.org/webt/zj/fy/5y/zjfy5yuay9-6wqe3nrgjkeznvny.png"><br><br>      RPC-   , ,  nginx.   KittenHouse      UDP. <br><br><img src="https://habrastorage.org/webt/hq/wl/v_/hqwlv_vnujb-maxakxksbmrf6xo.png"><br><br>         ,    UDP-      .       RPC     ,      UDP.      . <br><br><h2>  Monitoreo </h2><br>     : ,        ,     .     : <strong>  </strong> . <br><br><h3>   </h3><br>       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Netdata</a> ,        <strong>Graphite Carbon</strong> .      ClickHouse,   Whisper, .       ClickHouse,   <strong>Grafana</strong>  ,   .  ,   Netdata  Grafana  . <br><br><h3>   </h3><br>      . ,    ,    Counts, UniqueCounts   ,   - . <br><br><pre> <code class="plaintext hljs">statlogsCountEvent ( 'stat_name', $key1, $key2, ‚Ä¶) statlogsUniqueCount ( 'stat_name', $uid, $key1, $key2, ‚Ä¶) statlogsValuetEvent ( 'stat_name', $value, $key1, $key2, ‚Ä¶) $stats = statlogsStatData($params)</code> </pre><br>      ,    ,     ‚Äî  ,  Wathdogs. <br><br>    <strong> ,</strong>    600   1   .       <strong>   </strong> ,     .     ‚Äî  ,     . ,      . <br><br>    ,     <strong>  memcache</strong> ,    .         <strong>stats-daemon</strong>   .         <strong>logs-collectors</strong> ,       ,      . <br><br><img src="https://habrastorage.org/webt/ih/ab/oy/ihaboy4luh5hriorej9seodbx6u.png"><br><br>        logs-collectors. <br><br><img src="https://habrastorage.org/webt/fq/ta/bj/fqtabjgq556wqfdz5_kfq3mj94c.png"><br><br>          stas-daemom ‚Äî   ,      collector.  ,    -        memcache stats-daemon,   ,    . <br><br>  logs-collectors    <strong>meowDB</strong> ‚Äî   ,      . <br><br><img src="https://habrastorage.org/webt/v_/gb/_y/v_gb_ya-9ywkra7xdh5h_qtqsc4.png"><br><br>      ¬´-SQL¬ª  . <br><br><img src="https://habrastorage.org/webt/1q/gw/wp/1qgwwpyj3ewcwuonshvty_zcfhc.png"><br><br><h3>  </h3><br>  2018     ,          -,      ClickHouse.      ClickHouse ‚Äî    ? <br><br><img src="https://habrastorage.org/webt/wg/mz/kl/wgmzklw41x7ilj0-5hbr_kfdif8.png"><br><br>    ,     KittenHouse. <br><br><img src="https://habrastorage.org/webt/kq/s7/uj/kqs7ujzbhnqzt5f8djepldmwxia.png"><br><br>   <strong>     ¬´*House¬ª</strong> ,        ,       UDP.   *House    inserts,  ,   KittenHouse.        ClickHouse,     . <br><br><img src="https://habrastorage.org/webt/ff/k3/th/ffk3thypln9exuhyuhr-nuj9hr4.png"><br><br>   memcache, stats-daemon  logs-collectors    . <br><br><img src="https://habrastorage.org/webt/r4/g3/e9/r4g3e9yakpzbx5gscmgyl6keqsa.png"><br><br>   memcache, stats-daemon  logs-collectors    . <br><br><ul><li>     ,     StatsHouse. </li><li> StatsHouse   KittenHouse UDP-,    SQL-inserts, . </li><li> KittenHouse    ClickHouse. </li><li>     ,      StatsHouse ‚Äî   ClickHouse  SQL. </li></ul><br>    <strong></strong> ,   ,  .    , , ,    .     . <br><br>  <strong>  </strong> .   ,    stats-daemons  logs-collectors,  ClickHouse   ,  ,     . <strong>  ,       </strong> . <br><br><h2>  </h2><br>     PHP.    <strong>git</strong> :  <strong>GitLab</strong>  <strong>TeamCity</strong>  .     -,       ,   ‚Äî  . <br><br>        ,     diff  ‚Äî : , , .     binlog   copyfast,          .     ,  <strong>gossip replication</strong> ,       ,  ‚Äî  ,   .            .      ,       <strong>  </strong> .       . <br><br>     kPHP         <strong>git</strong>   .    <strong> HTTP-</strong> ,      diff ‚Äî     .     ‚Äî    <strong>binlog copyfast</strong> .     ,      .  <strong>  </strong> .  copyfast' ,   binlog   ,     gossip replication     ,    -,      .   <strong>graceful </strong>   . <br><br>   ,     ,   : <br><br><ul><li> git master branch; </li><li>   <strong>.deb</strong> ; </li><li>    binlog copyfast; </li><li>   ; </li><li>     .dep; </li><li> <strong>dpkg -i</strong> ; </li><li> graceful    . </li></ul><br>   ,        <strong>.deb</strong> ,     <strong>dpkg -i</strong>   .    kPHP  ,   ‚Äî dpkg?  .  ‚Äî  . <br><br> <b> :</b> <br><br><ul><li>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">¬´  Vkontakte. ?¬ª</a>    copyfast  gossip. </li><li>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">¬´ VK    CLickHouse    ¬ª</a> . </li><li>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">¬´     ¬ª</a> ,     ,   . </li></ul><br><blockquote>     ,       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PHP Russia</a>  17          PHP-. ,     ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> (     PHP!) ‚Äî ,      PHP,   . </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/449254/">https://habr.com/ru/post/449254/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../449236/index.html">Ok Google: ¬øC√≥mo paso el captcha?</a></li>
<li><a href="../449240/index.html">La historia de un servicio joven de Daida (arte de suscripci√≥n)</a></li>
<li><a href="../449246/index.html">AX200 - Intel Wi-Fi 6</a></li>
<li><a href="../449248/index.html">IDE moderno. Definitivamente D, hasta cierto punto E, y ciertamente no yo</a></li>
<li><a href="../449252/index.html">Proyectos de zombis: combine los datos del usuario incluso despu√©s de su muerte</a></li>
<li><a href="../449256/index.html">Le√≠ 80 hojas de vida, tengo preguntas</a></li>
<li><a href="../449260/index.html">¬øQu√© es el aprendizaje autom√°tico automatizado (AutoML)?</a></li>
<li><a href="../449262/index.html">√öltimo IRM: actualizaci√≥n de Siebel a IP17 +</a></li>
<li><a href="../449264/index.html">Creaci√≥n de un sistema de informes para 1C: ERP basado en OLAP y Excel</a></li>
<li><a href="../449266/index.html">3 informes con RusCrypto: conferencias con experiencia</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
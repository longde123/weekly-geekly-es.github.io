<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèÇüèø üîü üòû Como o m√©todo Levenberg-Marquardt funciona ‚úñÔ∏è üå± ‚öñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O algoritmo de Levenberg-Marquardt √© simples. O algoritmo de Levenberg-Marquardt √© eficiente. 

 E dizem sobre ele que ele est√° em algum lugar entre a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como o m√©todo Levenberg-Marquardt funciona</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470181/">  O algoritmo de Levenberg-Marquardt √© simples.  O algoritmo de Levenberg-Marquardt √© eficiente. <br><br>  E dizem sobre ele que ele est√° em algum lugar entre a descida do gradiente e o m√©todo de Newton, o que quer que isso signifique.  Bem, √© meio que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">resolvido</a> com o m√©todo de Newton e sua conex√£o com a descida gradiente.  Mas o que eles querem dizer quando pronunciam essa frase profunda?  Vamos tentar uma pequena espreitadela. <br><a name="habracut"></a><br>  Em seus artigos, o camarada Levenberg [K. Um m√©todo para a solu√ß√£o de certos problemas nos √∫ltimos quadrados.  Quart.  Appl.  Math.  1944. Vol.  2. P. 164-168.], E depois dele cidad√£o Marquardt [Marquardt, Donald (1963).  "Um algoritmo para estimativa de m√≠nimos quadrados de par√¢metros n√£o lineares".  Revista SIAM de Matem√°tica Aplicada.  11 (2): 431‚Äì441.] Considerado o problema dos m√≠nimos quadrados, com a seguinte apar√™ncia: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e47/8ff/bd3/e478ffbd37ce67d12a8efa37326ce496.gif" title="&quot;\ sum_ {i = 1} ^ {N} \ left (f (x_ {i}, \ theta) -d_ {i} \ right) ^ {2} \ rightarrow \ min&quot;">  , <br><br>  que pode ser escrito mais facilmente na forma vetorial <br><br><img src="https://habrastorage.org/getpro/habr/post_images/43a/e3d/87f/43ae3d87f8c0662510f39e6a7e1453a0.gif" title="&quot;\ paralelo f (\ theta) -d \ paralelo_ {2} ^ {2} \ rightarrow \ min&quot;">  . <br><br>  E voc√™ pode ainda mais f√°cil marcando completamente nos m√≠nimos quadrados.  Isso n√£o afetar√° a hist√≥ria. <br><br>  Ent√£o, o problema √© considerado <br><br><img src="https://habrastorage.org/getpro/habr/post_images/573/d8c/243/573d8c243893d6b70f894859eebc6e22.gif" title="&quot;\ dfrac {1} {2} \ paralelo f (x) \ paralelo_ {2} ^ {2} = \ dfrac {1} {2} f ^ {T} (x) f (x) \ rightarrow \ min&quot;">  . <br><br>  Esse problema surge com tanta frequ√™ncia que dificilmente pode ser superestimada a import√¢ncia de encontrar um m√©todo eficaz para resolv√™-lo.  Mas vamos come√ßar de outro.  Em um artigo anterior, foi demonstrado que o conhecido m√©todo de descida por gradiente, e n√£o apenas ele, pode ser obtido das seguintes considera√ß√µes.  Digamos que chegamos a algum ponto <img src="https://habrastorage.org/getpro/habr/post_images/779/0dd/0ef/7790dd0efb4a03a4c876741804d9b559.gif" title="x">  em que a fun√ß√£o minimizada √© importante <img src="https://habrastorage.org/getpro/habr/post_images/903/406/15f/90340615fd75f4a3550a82c374838b6b.gif" title="&quot;f (x)&quot;">  .  Definimos uma fun√ß√£o auxiliar neste momento <img src="https://habrastorage.org/getpro/habr/post_images/8bf/1d5/4e1/8bf1d54e1f36dd4c9dfd5720437af51c.gif" title="&quot;g (p) = f (x + p)&quot;">  , bem como alguns de seus modelos <img src="https://habrastorage.org/getpro/habr/post_images/c5b/160/400/c5b1604002da7b2c951dd57929933d24.gif" title="&quot;\ bar {g} (p) \ aprox g (p)&quot;">  .  Para este modelo, colocamos um problema auxiliar <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5ab/24f/2cd/5ab24f2cdd939fb1186c5ebc91807432.gif" title="&quot;\\ bar {g} (p) \ rightarrow \ min \\ p \ in \ Omega&quot;"><br><br>  onde <img src="https://habrastorage.org/getpro/habr/post_images/7e0/838/1ee/7e08381eec55a31db8263ce4d9b04120.gif" title="&quot;\ Omega&quot;">  - um determinado conjunto predeterminado de valores permitidos, escolhido para que o problema tenha uma solu√ß√£o simples e a fun√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/462/957/dda/462957dda265f4fb8be04327f1c12b0f.gif" title="&quot;\ bar {g}&quot;">  aproximado com bastante precis√£o <img src="https://habrastorage.org/getpro/habr/post_images/da7/7c5/b48/da77c5b4891cf3d059f1b04a28b230ef.gif" title="g">  em <img src="https://habrastorage.org/getpro/habr/post_images/7e0/838/1ee/7e08381eec55a31db8263ce4d9b04120.gif" title="&quot;\ Omega&quot;">  .  Esse esquema √© chamado de m√©todo de regi√£o confi√°vel e muitos <img src="https://habrastorage.org/getpro/habr/post_images/7e0/838/1ee/7e08381eec55a31db8263ce4d9b04120.gif" title="&quot;\ Omega&quot;">  em que o valor da fun√ß√£o do modelo √© minimizado - a regi√£o de confian√ßa dessa fun√ß√£o.  Para descida gradiente, levamos <img src="https://habrastorage.org/getpro/habr/post_images/c7e/85c/48e/c7e85c48eb16123c23a9e08714f50a0e.gif" title="&quot;\ Omega = \ esquerda \ {p \ quad | \ paralela p \ paralela_ {2} = \ Delta \ direita \}&quot;">  , para o m√©todo de Newton <img src="https://habrastorage.org/getpro/habr/post_images/7cf/b4b/920/7cfb4b9203c4faccd18c1837b9c0e59f.gif" title="&quot;\ Omega = \ esquerda \ {p \ quad | \ paralela p \ paralela_ {H (x)} = \ Delta \ direita \}&quot;">  e como modelo para <img src="https://habrastorage.org/getpro/habr/post_images/da7/7c5/b48/da77c5b4891cf3d059f1b04a28b230ef.gif" title="g">  a parte linear da expans√£o de Taylor <img src="https://habrastorage.org/getpro/habr/post_images/a98/a08/49f/a98a0849fa75ac2a6bbcbbc2bbda3054.gif" title="&quot;\ bar {g} = f (x) + \ bigtriangledown f ^ {T} (x) p&quot;">  . <br><br>  Vamos ver o que acontece se complicarmos o modelo tomando <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2a/d63/f01/b2ad63f0162c3cad2512d187035cbf2d.gif" title="&quot;\ bar {g} (p) = f (x) + \ bigtriangledown f ^ {T} (x) p + \ dfrac {1} {2} p ^ {T} H (x) p&quot;">  . <br><br>  Minimizamos essa fun√ß√£o de modelo em uma regi√£o de confian√ßa el√≠ptica <img src="https://habrastorage.org/getpro/habr/post_images/e99/c58/ecc/e99c58ecc60ed62c044f7690e444d1d2.gif" title="&quot;\ dfrac {1} {2} \ paralelo p \ paralelo_ {B} ^ {2} = \ Delta&quot;">  (multiplicador adicionado para facilitar o c√°lculo).  Aplicando o m√©todo multiplicador de Lagrange, obtemos o problema <br><br><img src="https://habrastorage.org/getpro/habr/post_images/44c/4c6/050/44c4c6050ba6f69f94a8c222d68c95f3.gif" title="&quot;\ bigtriangledown f ^ {T} (x) p + \ dfrac {1} {2} p ^ {T} H (x) p + \ dfrac {\ lambda} {2} p ^ {T} Bp- \ lambda \ Delta \ rightarrow \ min &quot;">  , <br><br>  cuja solu√ß√£o satisfaz a igualdade <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4a3/851/c83/4a3851c834bc50c9b670673f6665f792.gif" title="&quot;H (x) p + \ lambda Bp + \ bigtriangledown f (x) = 0&quot;"><br><br>  ou <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2c4/7f5/3d4/2c47f53d4e43da14ea21b9fe9d7bb533.gif" title="&quot;\ left (H (x) + \ lambda B \ right) p = - \ bigtriangledown f (x)&quot;"><br><br>  Aqui, em contraste com o que vimos anteriormente ao usar o modelo linear, a dire√ß√£o <i>p</i> <i>n√£o</i> depende <i>apenas da m√©trica</i> <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  , mas tamb√©m na escolha do <i>tamanho da regi√£o de confian√ßa</i> <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  , o que significa que a t√©cnica de pesquisa linear n√£o √© aplic√°vel (pelo menos razoavelmente).  Tamb√©m √© dif√≠cil determinar explicitamente o valor <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  correspondente a <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  .  No entanto, √© √≥bvio que, com um aumento <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  comprimento <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  diminuir√°.  Se, no entanto, ainda impusermos a condi√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/d64/14f/5fb/d6414f5fbe0850f1d6cd0710c69a89fe.gif" title="&quot;\ lambda \ geq0&quot;">  , o comprimento do passo n√£o ser√° mais do que aquele que o m√©todo de Newton daria (na moda, sem modifica√ß√µes e condi√ß√µes). <br><br>  Ent√£o, ao inv√©s disso, podemos <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  procure o valor certo <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  , fa√ßa exatamente o oposto: encontre isso <img src="https://habrastorage.org/getpro/habr/post_images/d64/14f/5fb/d6414f5fbe0850f1d6cd0710c69a89fe.gif" title="&quot;\ lambda \ geq0&quot;">  sob o qual a condi√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/553/80b/dc5/55380bdc5a434366df6d181078d6a8b7.gif" title="&quot;g (p) &amp; lt; g (0)&quot;">  .  Esse √© um tipo de substitui√ß√£o para a pesquisa tardia neste caso.  Marquardt prop√¥s o seguinte procedimento simples: <br><br><ol><li>  <i>se por algum valor</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;"></i>  <i>condi√ß√£o</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/eca/77f/2af/eca77f2af789bf09851ed403e71813c5.gif" title="&quot;g (p (\ lambda)) &amp; lt; g (0)&quot;"></i>  <i>feito, em seguida, repita</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/cc3/5f3/35e/cc35f335e8bf25ccc19e392f3311591a.gif" title="&quot;lambda&quot; \ leftarrow \ alpha \ lambda, \ lambda \ leftarrow \ lambda &quot;&quot;"></i>  <i>at√©</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/3aa/df9/299/3aadf929956784b2e081f8a634cff90f.gif" title="? g (p (\ lambda ') &amp; lt; g (p (\ lambda))?"></i> </li><li>  <i>se</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/22b/75c/294/22b75c29456939ef738c81e53f52db6b.gif" title="&quot;g (p (\ lambda)) \ geq g (0)&quot;"></i>  <i>ent√£o aceite</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/434/e0a/742/434e0a742c4ad3ae7e4cea8c1289d363.gif" title="&quot;\ lambda \ leftarrow \ beta \ lambda&quot;"></i>  <i>e repita.</i> </li></ol><br>  Aqui <img src="https://habrastorage.org/getpro/habr/post_images/4f2/68e/81e/4f268e81e07eb6a87b5798903d82f2c0.gif" title="&quot;0 &amp; lt; \ alpha &amp; lt; 1&quot;">  e <img src="https://habrastorage.org/getpro/habr/post_images/0ea/d14/4f2/0ead144f2f1591e5747e51404639631f.gif" title="&quot;\ beta &amp; gt; 1&quot;">  S√£o constantes que s√£o par√¢metros de m√©todo.  Multiplica√ß√£o por <img src="https://habrastorage.org/getpro/habr/post_images/389/a99/83e/389a9983ea24ad0b3af0559c2aca381b.gif" title="&quot;\ alpha&quot;">  corresponde √† expans√£o da regi√£o de confian√ßa e multiplica√ß√£o por <img src="https://habrastorage.org/getpro/habr/post_images/76d/0eb/69b/76d0eb69ba026a58bbe3edd275fee712.gif" title="&quot;\ beta&quot;">  - est√° se estreitando. <br><br>  A t√©cnica especificada pode ser aplicada a <i>qualquer</i> fun√ß√£o objetivo.  Observe que aqui a defini√ß√£o positiva do Hessian n√£o √© mais necess√°ria, em contraste com o caso considerado anteriormente, quando o m√©todo de Newton foi apresentado como um caso especial do m√©todo de descida sequencial.  Nem mesmo sua n√£o degenera√ß√£o √© necess√°ria, o que, em alguns casos, √© muito importante.  No entanto, nesse caso, o pre√ßo da pesquisa de dire√ß√£o aumenta, pois cada altera√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  leva √† necessidade de resolver um sistema linear para determinar <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  . <br><br>  Vamos ver o que acontece se aplicarmos essa abordagem ao problema dos m√≠nimos quadrados. <br><br>  Fun√ß√£o Gradiente <img src="https://habrastorage.org/getpro/habr/post_images/f58/e0b/7a5/f58e0b7a5457a6f69dd3c16e2d5aadc5.gif" title="&quot;\ bigtriangledown \ left (\ dfrac {1} {2} f ^ {T} f \ right) = J ^ {T} f&quot;">  sua juta <img src="https://habrastorage.org/getpro/habr/post_images/9da/93e/f0a/9da93ef0ae8eda326c977d890c97beac.gif" title="&quot;H = J ^ {T} J + G&quot;">  onde <img src="https://habrastorage.org/getpro/habr/post_images/c7a/314/465/c7a31446512540e721403b61686e91ba.gif" title="&quot;J_ {ij} = \ dfrac {\ parcial f_ {i}} {\ parcial x_ {j}}, G_ {ij} = \ sum_ {k = 1} ^ {M} \ dfrac {\ parcial ^ {2} f_ {i}} {\ parcial x_ {j} \ parcial x_ {k}} f_ {k} &quot;">  .  Substitua e obtenha o seguinte sistema que determina a dire√ß√£o da pesquisa <br><br><img src="https://habrastorage.org/getpro/habr/post_images/148/b56/06f/148b5606f695c8a52b629f69f8c167c5.gif" title="&quot;\ left (J ^ {T} J + G + \ lambda B \ right) p = -J ^ {T} f&quot;">  . <br><br>  √â bastante aceit√°vel, mas calcular as segundas derivadas de uma fun√ß√£o vetorial pode ser bastante caro.  Marquardt prop√¥s usar a pr√≥pria fun√ß√£o para contornar esse problema. <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  , e sua aproxima√ß√£o linear <img src="https://habrastorage.org/getpro/habr/post_images/205/c97/755/205c97755529c6a19a04851f7ec3d7f7.gif" title="&quot;\ bar {f} (x) = f (x_ {0}) + J (x_ {0}) (x-x_ {0})&quot;">  em que a matriz <img src="https://habrastorage.org/getpro/habr/post_images/338/ec0/451/338ec0451e1b4b7e7decd0b4443a8828.gif" title="&quot;G&quot;">  volta a zero.  Se agora como <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  pegue a matriz de identidade <img src="https://habrastorage.org/getpro/habr/post_images/809/326/43e/80932643e100c59ad091cdf4d90a2bd5.gif" title="&quot;Eu&quot;">  , obtemos a forma padr√£o do m√©todo Levenberg-Marquardt para resolver o problema dos m√≠nimos quadrados: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d3e/6e4/48a/d3e6e448ae5465d70cded093a02fdb69.gif" title="&quot;\ left (J ^ {T} J + \ lambda I \ right) p = -J ^ {T} f&quot;">  . <br><br>  Para esse m√©todo de determina√ß√£o da dire√ß√£o da descida, Marquardt provou o teorema de que, com aspira√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  para a dire√ß√£o do infinito <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  tende a anti-gradiente.  O leitor interessado pode encontrar uma prova rigorosa no artigo de base, mas espero que essa afirma√ß√£o tenha se tornado bastante √≥bvia a partir da l√≥gica do m√©todo.  At√© certo ponto, justifica a refer√™ncia onipresente ao fato de que, com um aumento no lambda (que por algum motivo eu frequentemente chamo de par√¢metro de regulariza√ß√£o), obtemos uma descida de gradiente.  Na verdade, nada disso - s√≥ chegar√≠amos no limite, exatamente onde o comprimento do passo tende a zero.  √â muito mais importante que, com um valor lambda suficientemente grande, a dire√ß√£o que obtemos seja a <i>dire√ß√£o da descida</i> , o que significa que obtemos a <i>converg√™ncia global do m√©todo</i> .  E aqui est√° a segunda parte da afirma√ß√£o de que, quando o lambda tende a zero, obtemos o m√©todo de Newton, √© claramente verdade, mas somente se aceitarmos <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  sua aproxima√ß√£o linear <img src="https://habrastorage.org/getpro/habr/post_images/9dc/1fa/a9c/9dc1faa9cf4e8d569afaf161ac627568.gif" title="&quot;\ bar {f.}&quot;">  . <br><br>  Parece que tudo.  Minimizamos a norma da fun√ß√£o vetorial na m√©trica el√≠ptica - usamos o Levenberg-Marquardt.  Estamos lidando com uma fun√ß√£o de uma forma geral e temos a capacidade de calcular a matriz de segundas derivadas - para Wells, use o m√©todo geral de confian√ßa da regi√£o.  Mas h√° pervertidos ... <br><br>  √Äs vezes, o m√©todo de Levenberg-Marquardt para minimizar a fun√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  eles chamam uma express√£o como esta: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/438/a2f/22b/438a2f22ba381c85087a26d2125d1dac.gif" title="&quot;\ left (H ^ {T} H + \ lambda I \ right) p = -H ^ {T} \ bigtriangledown f&quot;">  . <br><br>  Tudo parece ser o mesmo, mas aqui <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="&quot;H&quot;">  - matriz do segundo!  fun√ß√µes derivadas <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  .  Formalmente, isso tem o direito de existir, mas √© uma pervers√£o.  E aqui est√° o porqu√™.  O mesmo Marquardt em seu artigo prop√¥s um m√©todo para resolver um sistema de equa√ß√µes <img src="https://habrastorage.org/getpro/habr/post_images/0a0/ec7/804/0a0ec780406efe57ca6444290ccfde09.gif" title="&quot;F (x) = 0&quot;">  minimizando a fun√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/128/aa6/0b3/128aa60b3bc0593a797bd9ebd308b402.gif" title="&quot;\ paralelo F (x) \ paralelo_ {2} ^ {2}&quot;">  o m√©todo descrito.  Se como <img src="https://habrastorage.org/getpro/habr/post_images/59b/464/0f5/59b4640f5bad6b14066d718cf44e9f9c.gif" title="&quot;F (x)&quot;">  pegue o gradiente da fun√ß√£o objetivo, ent√£o realmente obteremos a express√£o reduzida.  E a pervers√£o √© porque <br><br>  <i>o problema de minimiza√ß√£o gerado pelo sistema de equa√ß√µes n√£o lineares geradas pelo problema de minimiza√ß√£o √© resolvido</i> . <br><br>  Greve dupla.  Essa express√£o, pelo menos, n√£o √© melhor que a primeira equa√ß√£o de uma regi√£o de confian√ßa esf√©rica, mas, em geral, √© muito pior, tanto do ponto de vista da produtividade (opera√ß√µes desnecess√°rias de multiplica√ß√£o e em implementa√ß√µes normais - fatora√ß√£o), quanto do ponto de vista da estabilidade do m√©todo (a multiplica√ß√£o matricial por si s√≥ piora seu condicionamento).  √Äs vezes √© contestado que <img src="https://habrastorage.org/getpro/habr/post_images/e98/c6b/bd7/e98c6bbd7a088cd46c2ed68aac4943ba.gif" title="&quot;H ^ {T} H&quot;">  garantido definido positivamente, mas, neste caso, n√£o importa.  Vejamos o m√©todo de Levenberg-Marquardt da perspectiva do m√©todo de descida sequencial.  Nesse caso, acontece que queremos usar a matriz como uma m√©trica <img src="https://habrastorage.org/getpro/habr/post_images/64b/dbe/dcb/64bdbedcbd61e0741f92025fb7c4a1f8.gif" title="&quot;H (x) + \ lambda B&quot;">  e para que ela possa atuar nessa capacidade, o significado <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  deve garantir a sua certeza positiva.  Dado que <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  valor definido positivo <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  sempre pode ser encontrado - e, portanto, n√£o h√° necessidade de exigir de <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="&quot;H&quot;">  certeza positiva n√£o √© observada. <br><br>  Como uma matriz <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  n√£o √© necess√°rio pegar uma unidade, mas para um modelo quadr√°tico da fun√ß√£o objetivo, especificar uma regi√£o de confian√ßa adequada n√£o √© mais t√£o simples quanto um modelo linear.  Se considerarmos a regi√£o el√≠ptica induzida pelo hessiano, o m√©todo se degenera no m√©todo de Newton (bem, quase) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f31/f2c/82f/f31f2c82f904fd2c95ab33daa112168b.gif" title="&quot;\ left (J ^ {T} J + \ lambda J ^ {T} J \ right) p = \ left (1+ \ lambda \ right) J ^ {T} Jp = -J ^ {T} f \ approx \ left (1+ \ lambda \ right) Hp = - \ bigtriangledown \ left (\ dfrac {1} {2} f ^ {T} f \ right). &quot;"><br><br>  A menos, √© claro, que a matriz hessiana seja definida positivamente.  Caso contr√°rio, ent√£o, como antes, voc√™ pode usar o Hessian corrigido como uma m√©trica, ou alguma matriz que, em certo sentido, esteja pr√≥xima a ela.  H√° tamb√©m uma recomenda√ß√£o para usar uma matriz como m√©trica <img src="https://habrastorage.org/getpro/habr/post_images/e83/ae4/134/e83ae41347e08ce41ff17ee556a7e06b.gif" title="&quot;diag (J ^ {T} J)&quot;">  , que por constru√ß√£o √© garantido como definitivo positivo.  Infelizmente, n√£o conhe√ßo pelo menos nenhuma justificativa rigorosa para essa escolha, mas isso √© mencionado com frequ√™ncia como uma recomenda√ß√£o emp√≠rica. <br><br>  Como ilustra√ß√£o, vamos ver como o m√©todo se comporta na mesma fun√ß√£o de Rosenbrock, e vamos consider√°-lo de duas formas - como uma fun√ß√£o simples escrita no formul√°rio <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b78/272/e1a/b78272e1a4bce3b65e55a7737fd2a1ee.gif" title="&quot;f (x, y) = (1-x) ^ {2} +100 (y-x ^ {2}) ^ {2} \ rightarrow \ min&quot;">  , <br><br>  e como um problema dos m√≠nimos quadrados <br><br><img src="https://habrastorage.org/getpro/habr/post_images/05c/c5a/49e/05cc5a49e94d86e2929c86264cd76f6f.gif" title="&quot;\\ f (x, y) = \ esquerda \ Vert \ begin {array} {c} 1-x \\ 100 (yx ^ {2}) \ end {array} \ right \ Vert _ {2} ^ { 2} \ rightarrow \ min &quot;"><br><br><img src="https://habrastorage.org/webt/0d/bo/bo/0dbobokk7lwzjkd69j9d-wmotks.gif" width="600"><br>  √â assim que um m√©todo com uma regi√£o de confian√ßa esf√©rica se comporta. <br><img src="https://habrastorage.org/webt/l9/57/xb/l957xbscmthhqno0yneburansf4.gif" width="600"><br>  Portanto, o mesmo m√©todo se comporta se a forma da regi√£o de confian√ßa for dada por uma matriz constru√≠da de acordo com a regra de Davidon-Fletcher-Powell.  H√° um efeito na converg√™ncia, mas muito mais modesto do que no caso semelhante ao usar o modelo linear da fun√ß√£o objetivo. <br><img src="https://habrastorage.org/webt/rn/n2/uz/rnn2uzvfkpd7fdrxa26qvdlkcfs.gif" width="600"><br>  E esse √© o comportamento do m√©todo aplicado ao problema dos m√≠nimos quadrados.  Ele converge em 5 itera√ß√µes.  Apenas por favor, <i>n√£o tire dessa conclus√£o que a segunda formula√ß√£o para fun√ß√µes desse tipo √© sempre melhor que a primeira</i> .  N√£o √© assim, apenas aconteceu neste caso em particular. <br><br><h2>  Conclus√£o </h2><br>  O m√©todo Levenberg-Marquardt √©, at√© onde eu sei, o primeiro m√©todo baseado na id√©ia de uma regi√£o confiante.  Ele se mostrou muito bem na pr√°tica ao resolver o problema dos m√≠nimos quadrados.  O m√©todo converge na maioria dos casos (visto por mim) muito rapidamente (eu disse se era bom ou ruim em um artigo anterior).  No entanto, apesar de minimizar as fun√ß√µes gerais, dificilmente √© a melhor op√ß√£o para escolher uma esfera como uma regi√£o confiante.  Al√©m disso, uma desvantagem significativa do m√©todo (em sua formula√ß√£o b√°sica, descrita aqui) √© que o tamanho da regi√£o de confian√ßa √© definido implicitamente.  A desvantagem √© que conhecer o significado <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  √© claro que podemos contar no ponto atual <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  apenas calculando o comprimento da passada <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  .  No entanto, quando passamos para um novo ponto, o mesmo valor <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  um valor completamente diferente da regi√£o de confian√ßa j√° corresponder√°.  Assim, perdemos a capacidade de determinar o tamanho ‚Äúcaracter√≠stica da tarefa‚Äù da regi√£o de confian√ßa e somos for√ßados a determinar seu tamanho de uma nova maneira a cada novo ponto.  Isso pode ser significativo quando um n√∫mero suficientemente grande de itera√ß√µes √© necess√°rio para converg√™ncia, e o c√°lculo do valor de uma fun√ß√£o √© caro.  Problemas semelhantes s√£o resolvidos em m√©todos mais avan√ßados, com base na id√©ia de uma regi√£o confi√°vel. <br><br>  Mas esta √© uma hist√≥ria completamente diferente. <br><br><h2>  Adi√ß√£o </h2><br>  Gra√ßas aos valiosos coment√°rios de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">Dark_Daiver,</a> decidi que o acima deve ser complementado com a seguinte observa√ß√£o.  Certamente, pode-se chegar ao m√©todo Levenberg-Marquardt de uma maneira diferente, puramente emp√≠rica.  Nomeadamente, voltemos ao esquema do m√©todo de descida sequencial descrito no artigo anterior e novamente nos perguntemos a quest√£o de construir uma m√©trica adequada para o modelo linear da fun√ß√£o objetivo. <br>  Suponha que a matriz hessiana no ponto atual no espa√ßo de pesquisa n√£o seja definida positivamente e n√£o possa servir como uma m√©trica (al√©m disso, para verificar se √© assim, n√£o temos a capacidade nem o desejo).  Denotar por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/f06/ee0/4fd/f06ee04fdb8676c6297784f2cc24291b.gif" title="\ lambda _ {\ min}"></a>  seu menor valor pr√≥prio.  Ent√£o, podemos corrigir o Hessiano simplesmente deslocando todos os seus autovalores por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/0b6/187/138/0b61871385159f5f8dff9d81de5171b5.gif" title="\ lambda> - \ lambda _ {\ min}"></a>  .  Para fazer isso, basta adicionar a matriz ao Hessian <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/09f/c07/1d5/09fc071d5e509fe24bd70ca553a899cf.gif" title="\ lambda I"></a>  .  Ent√£o a equa√ß√£o que determina a dire√ß√£o da descida assumir√° a forma <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/3a7/b20/19b/3a7b2019b8c7a99b85121b3512c3fa19.gif" title="\\ (H (x) + \ lambda I) p = - \ bigtriangledown f (x) \\ \ lambda> - \ lambda _ {\ min}"></a> <br><br>  Se tivermos uma boa pontua√ß√£o mais baixa para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/f06/ee0/4fd/f06ee04fdb8676c6297784f2cc24291b.gif" title="\ lambda _ {\ min}"></a>  , ent√£o podemos fazer tudo o que foi feito nos m√©todos de descida sequencial.  No entanto, se n√£o tivermos essa estimativa, leve em considera√ß√£o que, com um aumento <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="\ lambda"></a>  Se o comprimento <i>p</i> diminuir, podemos dizer com seguran√ßa que existe um tamanho suficientemente grande. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="\ lambda"></a>  que ao mesmo tempo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/cc1/d36/8a7/cc1d368a7e0d0614441998db48983d70.gif" title="H (x) + \ lambda I"></a>  definitivo positivo e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/553/80b/dc5/55380bdc5a434366df6d181078d6a8b7.gif" title="g (p) <g (0)"></a>  . <br><br>  Por que considero que essa conclus√£o do m√©todo n√£o √© muito bem-sucedida.  Em primeiro lugar, n√£o √© de todo √≥bvio que a m√©trica constru√≠da dessa maneira seja adequada para uso pr√°tico.  Obviamente, ele usa informa√ß√µes sobre as segundas derivadas, mas n√£o segue de nenhum lugar que a altera√ß√£o dos valores pr√≥prios por um determinado valor n√£o o torne inutiliz√°vel.  Como o colega observou nos coment√°rios, parece √≥bvio que adicionar uma matriz de identidade em escala √† matriz de Hessian leva ao fato de que a regi√£o de confian√ßa el√≠ptica tender√° a ser esf√©rica e aqui novamente (como parece) os problemas de interfer√™ncia no desfiladeiro e outras del√≠cias da descida de gradiente e outras pr√≥ximas para ele m√©todos.  Mas, na pr√°tica, isso n√£o acontece.  De qualquer forma, nunca pude observar exemplos ilustrando esse comportamento.  Nesse caso, surge a pergunta: <i>mas, na verdade, por que</i> ? <br><br>  Mas essa pergunta n√£o surge se considerarmos esse m√©todo n√£o como um caso especial de m√©todos de descida, mas como um m√©todo de regi√£o de confian√ßa com um modelo quadr√°tico da fun√ß√£o objetivo, uma vez que a resposta √© √≥bvia: quando o lambda aumenta, apenas comprimimos a esfera - a regi√£o de confian√ßa para o nosso modelo.  As informa√ß√µes sobre a curvatura n√£o v√£o a lugar algum e n√£o s√£o lavadas por nada - basta escolher o tamanho da regi√£o na qual o modelo quadr√°tico descreve adequadamente a fun√ß√£o objetivo.  Segue-se que dificilmente vale a pena esperar um efeito significativo de uma mudan√ßa na m√©trica, ou seja, o formato da regi√£o de confian√ßa, uma vez que todas as informa√ß√µes que temos sobre a fun√ß√£o objetivo j√° s√£o levadas em considera√ß√£o em seu modelo. <br><br>  Em segundo lugar, ao considerar um m√©todo, √© importante entender a id√©ia principal que levou Marquardt a esse m√©todo, a saber, a ideia de uma regi√£o confiante.  De fato, na an√°lise final, apenas uma compreens√£o dos meandros do m√©todo num√©rico nos permitir√° entender por que ele funciona e, mais importante, por que ele pode n√£o funcionar. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt470181/">https://habr.com/ru/post/pt470181/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt470167/index.html">Confer√™ncia para os interessados ‚Äã‚Äãem ci√™ncia antes de se tornar mainstream</a></li>
<li><a href="../pt470169/index.html">Como impedir que a id√©ia morra e reunir uma equipe que n√£o a mate</a></li>
<li><a href="../pt470173/index.html">Plataforma de integra√ß√£o como servi√ßo</a></li>
<li><a href="../pt470175/index.html">Adicione o login com a Apple ao back-end</a></li>
<li><a href="../pt470179/index.html">PDDM - Novo algoritmo de aprendizado de refor√ßo baseado em modelo com agendador avan√ßado</a></li>
<li><a href="../pt470187/index.html">A faixa de pre√ßo para o design e o design de um servi√ßo on-line √© de 100 mil a 5 milh√µes de rublos. Raz√µes</a></li>
<li><a href="../pt470189/index.html">Enviando mensagens ponto a ponto com o PeerJS</a></li>
<li><a href="../pt470191/index.html">Web Solu√ß√£o de problemas com r0ot-mi. Parte 1</a></li>
<li><a href="../pt470193/index.html">Prote√ß√£o universal contra ataques xss e inje√ß√µes de sql</a></li>
<li><a href="../pt470195/index.html">F # 4: deixe / use / fa√ßa</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
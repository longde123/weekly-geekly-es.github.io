<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèè üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë® üõçÔ∏è Tela de renderiza√ß√£o de √°gua üëâüèΩ ‚úã üì´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Minha √∫ltima tarefa em gr√°ficos t√©cnicos / renderiza√ß√£o foi encontrar uma boa solu√ß√£o para renderizar √°gua. Em particular, a renderiza√ß√£o de jatos fin...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tela de renderiza√ß√£o de √°gua</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420495/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/216/ca8/1f5/216ca81f5eb506eab2dbcfc730a904b4.png" alt="imagem"></div><br>  Minha √∫ltima tarefa em gr√°ficos t√©cnicos / renderiza√ß√£o foi encontrar uma boa solu√ß√£o para renderizar √°gua.  Em particular, a renderiza√ß√£o de jatos finos e velozes de √°gua com base em part√≠culas.  Na semana passada, pensei em bons resultados, por isso vou escrever um artigo sobre isso. <br><br>  Eu realmente n√£o gosto da abordagem de cubos voxelizados / marcadores ao renderizar √°gua (veja, por exemplo, renderizar uma simula√ß√£o de fluido no Blender).  Quando o volume de √°gua est√° na mesma escala da grade usada para renderiza√ß√£o, o movimento √© notavelmente discreto.  Esse problema pode ser resolvido aumentando a resolu√ß√£o da grade, mas para jatos finos em dist√¢ncias relativamente longas em tempo real √© simplesmente impratic√°vel, pois afeta muito o tempo de execu√ß√£o e a mem√≥ria ocupada.  (Existe um precedente para o uso de estruturas esparsas de voxel para melhorar a situa√ß√£o. Mas n√£o tenho certeza de como isso funciona em sistemas din√¢micos. Al√©m disso, esse n√£o √© o n√≠vel de dificuldade com o qual gostaria de trabalhar.) <br><br>  A primeira alternativa que eu explorei foi a Screen Space Malhes de M√ºller.  Eles usam a renderiza√ß√£o de part√≠culas de √°gua em um buffer de profundidade, suavizando-o, reconhecendo fragmentos conectados de profundidade semelhante e construindo uma malha a partir do resultado usando quadrados de marcha.  Hoje, esse m√©todo provavelmente se tornou <i>mais</i> aplic√°vel do que em 2007 (j√° que agora podemos criar uma malha no shader de computa√ß√£o), mas ainda est√° associado a um n√≠vel maior de complexidade e custo do que eu gostaria. <br><br>  No final, encontrei a apresenta√ß√£o de Simon Green com a GDC 2010, Screen Space Fluid Rendering For Games.  Come√ßa exatamente da mesma maneira que as malhas do espa√ßo da tela: renderizando part√≠culas no buffer de profundidade e suavizando-o.  Mas, em vez de construir a malha, o buffer resultante √© usado para sombrear e compor o l√≠quido na cena principal (registrando explicitamente a profundidade.) Decidi implementar esse sistema. <br><a name="habracut"></a><br><h3>  Prepara√ß√£o </h3><br>  V√°rios projetos anteriores do Unity me ensinaram a n√£o lidar com as limita√ß√µes de renderiza√ß√£o do mecanismo.  Portanto, os buffers de fluido s√£o renderizados por uma segunda c√¢mera com uma profundidade de campo mais rasa, para renderizar na frente da cena principal.  Cada sistema de fluido existe em uma camada de renderiza√ß√£o separada;  a c√¢mara principal exclui uma camada de √°gua e a segunda c√¢mara processa apenas √°gua.  Ambas as c√¢meras s√£o filhos de um objeto vazio para garantir sua orienta√ß√£o relativa. <br><br>  Esse esquema significa que eu posso renderizar quase tudo na camada l√≠quida, e parece que eu espero que seja.  No contexto da minha cena demo, isso significa que alguns jatos e respingos de sub-emissores podem se fundir.  Al√©m disso, isso permitir√° a mistura de outros sistemas de √°gua, por exemplo, volumes baseados em campos de altitude, que podem ser renderizados da mesma forma.  (Ainda n√£o testei isso.) <br><br>  A fonte de √°gua na minha cena √© um sistema de part√≠culas padr√£o.  De fato, nenhuma simula√ß√£o de fluido √© realizada.  Isso, por sua vez, significa que as part√≠culas n√£o se sobrep√µem de uma maneira completamente f√≠sica, mas o resultado final parece aceit√°vel na pr√°tica. <br><br><h3>  Renderiza√ß√£o de buffer de fluido </h3><br>  O primeiro passo nesta t√©cnica √© renderizar o buffer do fluido base.  Este √© um buffer fora da tela que cont√©m (no est√°gio atual da minha implementa√ß√£o) o seguinte: largura do fluido, vetor de movimento no espa√ßo na tela e valor do ru√≠do.  Al√©m disso, renderizamos o buffer de profundidade gravando explicitamente a profundidade do shader de fragmento para transformar cada quadril√°tero de uma part√≠cula em uma "bola" esf√©rica (bem, na verdade el√≠ptica). <br><br>  Os c√°lculos de profundidade e largura s√£o bastante simples: <br><br><pre><code class="cpp hljs">frag_out o; float3 N; N.xy = i.uv*<span class="hljs-number"><span class="hljs-number">2.0</span></span> - <span class="hljs-number"><span class="hljs-number">1.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> r2 = dot(N.xy, N.xy); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (r2 &gt; <span class="hljs-number"><span class="hljs-number">1.0</span></span>) discard; Nz = <span class="hljs-built_in"><span class="hljs-built_in">sqrt</span></span>(<span class="hljs-number"><span class="hljs-number">1.0</span></span> - r2); float4 pixel_pos = float4(i.view_pos + N * i.size, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); float4 clip_pos = mul(UNITY_MATRIX_P, pixel_pos); <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> depth = clip_pos.z / clip_pos.w; o.depth = depth; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> thick = Nz * i.size * <span class="hljs-number"><span class="hljs-number">2</span></span>;</code> </pre> <br>  (√â claro que os c√°lculos de profundidade podem ser simplificados; da posi√ß√£o do clipe, precisamos apenas de z e w.) <br><br>  Um pouco mais tarde, retornaremos ao shader de fragmento para os vetores de movimento e ru√≠do. <br><br>  A divers√£o come√ßa no sombreador de v√©rtices, e √© aqui que eu me afasto da t√©cnica de Green.  O objetivo deste projeto √© produzir jatos de √°gua de alta velocidade;  isso pode ser realizado com a ajuda de part√≠culas esf√©ricas, mas uma grande quantidade delas ser√° necess√°ria para criar um jato cont√≠nuo.  Em vez disso, esticarei os quadr√¢ngulos das part√≠culas com base em sua velocidade, que, por sua vez, estica as esferas de profundidade, tornando-as n√£o esf√©ricas, mas el√≠pticas.  (Como os c√°lculos de profundidade s√£o baseados em UV, que n√£o mudam, tudo funciona.) <br><br>  Usu√°rios experientes do Unity podem se perguntar por que eu simplesmente n√£o uso o modo de outdoor estendido dispon√≠vel no sistema de part√≠culas do Unity.  Quadro de avisos esticado realiza alongamentos incondicionais ao longo do vetor de velocidade no espa√ßo do mundo.  No caso geral, isso √© bastante adequado, mas leva a um problema muito percept√≠vel quando o vetor de velocidade √© co-direcionado com o vetor de c√¢mera voltado para a frente (ou muito pr√≥ximo a ele).  O outdoor se estende na tela, o que torna sua natureza bidimensional muito percept√≠vel. <br><br>  Em vez disso, uso um quadro de avisos voltado para a c√¢mera e projeto o vetor de velocidade no plano da part√≠cula, usando-o para esticar o quadril√°tero.  Se o vetor de velocidade √© perpendicular ao plano (direcionado para a tela ou para longe dele), a part√≠cula permanece n√£o esticada e esf√©rica, como deveria, e quando √© inclinada, a part√≠cula √© esticada nessa dire√ß√£o, que √© o que precisamos. <br><br>  Vamos deixar uma longa explica√ß√£o, aqui est√° uma fun√ß√£o bastante simples: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">float3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ComputeStretchedVertex</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float3 p_world, float3 c_world, float3 vdir_world, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> stretch_amount)</span></span></span><span class="hljs-function"> </span></span>{ float3 center_offset = p_world - c_world; float3 stretch_offset = dot(center_offset, vdir_world) * vdir_world; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> p_world + stretch_offset * lerp(<span class="hljs-number"><span class="hljs-number">0.25f</span></span>, <span class="hljs-number"><span class="hljs-number">3.0f</span></span>, stretch_amount); }</code> </pre> <br>  Para calcular o vetor de movimento do espa√ßo da tela, calculamos dois conjuntos de posi√ß√µes de vetores: <br><br><pre> <code class="cpp hljs">float3 vp1 = ComputeStretchedVertex( vertex_wp, center_wp, velocity_dir_w, rand); float3 vp0 = ComputeStretchedVertex( vertex_wp - velocity_w * unity_DeltaTime.x, center_wp - velocity_w * unity_DeltaTime.x, velocity_dir_w, rand); o.motion_0 = mul(_LastVP, float4(vp0, <span class="hljs-number"><span class="hljs-number">1.0</span></span>)); o.motion_1 = mul(_CurrVP, float4(vp1, <span class="hljs-number"><span class="hljs-number">1.0</span></span>));</code> </pre> <br>  Observe que, como computamos vetores de movimento na passagem principal e n√£o na passagem de vetores de velocidade, o Unity n√£o nos fornece uma proje√ß√£o de corrente anterior ou sem distor√ß√£o da vista.  Para corrigir isso, adicionei um script simples aos sistemas de part√≠culas correspondentes: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">ScreenspaceLiquidRenderer</span></span> : <span class="hljs-title"><span class="hljs-title">MonoBehaviour</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> Camera LiquidCamera; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> ParticleSystemRenderer m_ParticleRenderer; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">bool</span></span> m_First; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> Matrix4x4 m_PreviousVP; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Start</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { m_ParticleRenderer = GetComponent(); m_First = <span class="hljs-literal"><span class="hljs-literal">true</span></span>; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnWillRenderObject</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { Matrix4x4 current_vp = LiquidCamera.nonJitteredProjectionMatrix * LiquidCamera.worldToCameraMatrix; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (m_First) { m_PreviousVP = current_vp; m_First = <span class="hljs-literal"><span class="hljs-literal">false</span></span>; } m_ParticleRenderer.material.SetMatrix(<span class="hljs-string"><span class="hljs-string">"_LastVP"</span></span>, GL.GetGPUProjectionMatrix(m_PreviousVP, <span class="hljs-literal"><span class="hljs-literal">true</span></span>)); m_ParticleRenderer.material.SetMatrix(<span class="hljs-string"><span class="hljs-string">"_CurrVP"</span></span>, GL.GetGPUProjectionMatrix(current_vp, <span class="hljs-literal"><span class="hljs-literal">true</span></span>)); m_PreviousVP = current_vp; } }</code> </pre> <br>  Coloco em cache a matriz anterior manualmente porque Camera.previousViewProjectionMatrix fornece resultados incorretos. <br><br>  ¬Ø \ _ („ÉÑ) _ / ¬Ø <br><br>  (Al√©m disso, esse m√©todo viola a renderiza√ß√£o; pode ser prudente definir constantes da matriz global na pr√°tica, em vez de us√°-las para cada material.) <br><br>  Vamos voltar ao shader de fragmento: usamos as posi√ß√µes projetadas para calcular os vetores de movimento do espa√ßo da tela: <br><br><pre> <code class="cpp hljs">float3 hp0 = i.motion_0.xyz / i.motion_0.w; float3 hp1 = i.motion_1.xyz / i.motion_1.w; float2 vp0 = (hp0.xy + <span class="hljs-number"><span class="hljs-number">1</span></span>) / <span class="hljs-number"><span class="hljs-number">2</span></span>; float2 vp1 = (hp1.xy + <span class="hljs-number"><span class="hljs-number">1</span></span>) / <span class="hljs-number"><span class="hljs-number">2</span></span>; <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> UNITY_UV_STARTS_AT_TOP vp0.y = 1.0 - vp0.y; vp1.y = 1.0 - vp1.y; #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endif</span></span></span><span class="hljs-meta"> float2 vel = vp1 - vp0;</span></span></code> </pre> <br>  (O c√°lculo dos vetores de movimento √© praticamente inalterado em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">https://github.com/keijiro/ParticleMotionVector/blob/master/Assets/ParticleMotionVector/Shaders/Motion.cginc</a> ) <br><br>  Finalmente, o √∫ltimo valor no buffer de fluido √© ru√≠do.  Uso um n√∫mero aleat√≥rio est√°vel para cada part√≠cula para selecionar um dos quatro ru√≠dos (agrupados em uma √∫nica textura).  Em seguida, √© dimensionado pela velocidade e pela unidade, menos o tamanho das part√≠culas (portanto, part√≠culas pequenas e r√°pidas s√£o mais ruidosas).  Esse valor de ru√≠do √© usado no passe de sombreamento para distorcer os normais e adicionar uma camada de espuma.  O trabalho de Green usa ru√≠do branco de tr√™s canais, mas um trabalho mais recente (Renderiza√ß√£o de fluidos no espa√ßo da tela com fluxo de curvatura) prop√µe usar o ru√≠do Perlin.  Uso o ru√≠do Voronoi / ru√≠do celular em diferentes escalas: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/743/9f4/c0b/7439f4c0beebbc16cbfa536c516b2fcf.png"></div><br><h3>  Problemas de mistura (e solu√ß√µes alternativas) </h3><br>  E aqui aparecem os primeiros problemas da minha implementa√ß√£o.  Para o c√°lculo correto da espessura das part√≠culas s√£o misturados aditivamente.  Como a mistura afeta toda a sa√≠da, isso significa que os vetores de ru√≠do e movimento tamb√©m s√£o misturados de maneira aditiva.  O ru√≠do aditivo nos conv√©m bastante, mas n√£o os vetores aditivos, e se voc√™ deix√°-los como est√£o, voc√™ obt√©m um tempo repugnante de anti-aliasing (TAA) e desfoque de movimento.  Para resolver esse problema, ao renderizar um buffer de fluido, simplesmente multiplico os vetores de movimento pela espessura e divido pela espessura total no passo de sombreamento.  Isso nos fornece um vetor de movimento m√©dio ponderado para todas as part√≠culas sobrepostas;  n√£o exatamente o que precisamos (artefatos estranhos s√£o criados quando v√°rios jatos se cruzam), mas bastante aceit√°vel. <br><br>  Um problema mais complexo √© a profundidade;  Para uma renderiza√ß√£o adequada do buffer de profundidade, precisamos ter o registro e a verifica√ß√£o de profundidade ativos.  Isso pode causar problemas se as part√≠culas n√£o forem classificadas (porque a diferen√ßa na ordem de renderiza√ß√£o pode fazer com que a sa√≠da de part√≠culas sobrepostas por outras pessoas seja cortada).  Portanto, ordenamos que o sistema de part√≠culas da Unidade classifique as part√≠culas por profundidade e depois cruzamos os dedos e esperamos.  que os sistemas tamb√©m renderizar√£o em profundidade.  Teremos * casos * de sistemas sobrepostos (por exemplo, a interse√ß√£o de dois jatos de part√≠culas) que n√£o s√£o processados ‚Äã‚Äãcorretamente, o que levar√° a uma espessura menor.  Mas isso n√£o acontece com muita frequ√™ncia e n√£o afeta muito a apar√™ncia. <br><br>  Muito provavelmente, a abordagem correta seria separar completamente os buffers de profundidade e cor;  o retorno para isso ser√° a renderiza√ß√£o em duas passagens.  Vale a pena explorar esse problema ao configurar o sistema. <br><br><h3>  Suaviza√ß√£o da profundidade </h3><br>  Finalmente, a coisa mais importante na t√©cnica verde.  N√≥s processamos um monte de bolas esf√©ricas no buffer de profundidade, mas, na realidade, a √°gua n√£o consiste em "bolas".  Ent√£o agora tomamos essa aproxima√ß√£o e a desfocamos para torn√°-la mais parecida com a superf√≠cie de um l√≠quido. <br><br>  A abordagem ing√™nua √© simplesmente aplicar profundidades de ru√≠do gaussianas em todo o buffer.  Cria resultados estranhos - suaviza os pontos distantes mais do que os pr√≥ximos e desfoca as bordas das silhuetas.  Em vez disso, podemos alterar o raio do desfoque em profundidade e usar o desfoque nos dois lados para salvar as bordas. <br><br>  Apenas um problema surge aqui: essas mudan√ßas tornam o desfoque indistingu√≠vel.  O desfoque compartilhado pode ser realizado em duas passagens: desfoque horizontal e verticalmente.  O desfoque indistingu√≠vel √© feito de uma s√≥ vez.  Essa diferen√ßa √© importante porque o desfoque compartilhado √© escalado linearmente (O (w) + O (h)), e o desfoque n√£o compartilhado √© escalado diretamente (O (w * h)).  O desfoque n√£o compartilhado em larga escala est√° rapidamente se tornando inaplic√°vel na pr√°tica. <br><br>  Como adultos, desenvolvedores respons√°veis, podemos fazer a jogada √≥bvia: feche os olhos, finja que o ru√≠do bidirecional * √© * compartilhado e ainda o implemente com corredores horizontais e verticais separados. <br><br>  Green em sua apresenta√ß√£o demonstrou que, embora essa abordagem <i>crie</i> artefatos no resultado resultante (especialmente na reconstru√ß√£o de normais), o est√°gio de sombreamento os oculta bem.  Ao trabalhar com as correntes mais estreitas de √°gua que eu crio, esses artefatos s√£o ainda menos vis√≠veis e n√£o afetam particularmente o resultado. <br><br><h3>  Sombreamento </h3><br>  Finalmente terminamos de trabalhar com o buffer de fluido.  Agora vamos para a segunda parte do efeito: sombreamento e composi√ß√£o da imagem principal. <br><br>  Aqui encontramos muitas restri√ß√µes de renderiza√ß√£o do Unity.  Decidi iluminar a √°gua apenas com a luz do sol e da caixa do c√©u;  O suporte a fontes de ilumina√ß√£o adicionais requer v√°rias passagens (isso √© um desperd√≠cio!) Ou a constru√ß√£o de uma estrutura de pesquisa de ilumina√ß√£o no lado da GPU (cara e bastante complicada).  Al√©m disso, como o Unity n√£o fornece acesso a mapas de sombras e as luzes direcionais usam sombras do espa√ßo da tela (com base em um buffer de profundidade renderizado pela geometria opaca), n√£o temos acesso a informa√ß√µes sobre sombras de uma fonte de luz solar.  Voc√™ pode anexar um buffer de comando a uma fonte de luz solar para criar um mapa de sombra do espa√ßo da tela especificamente para a √°gua, mas at√© agora n√£o o fiz. <br><br>  O √∫ltimo est√°gio do sombreamento √© controlado por meio de um script e usa o buffer de comando para enviar chamadas de empate.  Isso √© <i>necess√°rio</i> porque a textura do vetor de movimento (usada para anti-aliasing tempor√°rio (TAA) e desfoque de movimento) n√£o pode ser usada para renderiza√ß√£o direta usando Graphics.SetRenderTarget ().  No script anexado √† c√¢mera principal, escrevemos o seguinte: <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Start</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { <span class="hljs-comment"><span class="hljs-comment">//... m_QuadMesh = new Mesh(); m_QuadMesh.subMeshCount = 1; m_QuadMesh.vertices = new Vector3[] { new Vector3(0, 0, 0.1f), new Vector3(1, 0, 0.1f), new Vector3(1, 1, 0.1f), new Vector3(0, 1, 0.1f), }; m_QuadMesh.uv = new Vector2[] { new Vector2(0, 0), new Vector2(1, 0), new Vector2(1, 1), new Vector2(0, 1), }; m_QuadMesh.triangles = new int[] { 0, 1, 2, 0, 2, 3, }; m_QuadMesh.UploadMeshData(false); m_CommandBuffer = new CommandBuffer(); m_CommandBuffer.Clear(); m_CommandBuffer.SetProjectionMatrix( GL.GetGPUProjectionMatrix( Matrix4x4.Ortho(0, 1, 0, 1, -1, 100), false)); m_CommandBuffer.SetRenderTarget( BuiltinRenderTextureType.CameraTarget, BuiltinRenderTextureType.CameraTarget); m_CommandBuffer.DrawMesh( m_QuadMesh, Matrix4x4.identity, m_Mat, 0, m_Mat.FindPass("LIQUIDCOMPOSITE")); m_CommandBuffer.SetRenderTarget( BuiltinRenderTextureType.MotionVectors, BuiltinRenderTextureType.Depth); m_CommandBuffer.DrawMesh( m_QuadMesh, Matrix4x4.identity, m_Mat, 0, m_Mat.FindPass("MOTION")); }</span></span></code> </pre> <br>  Buffers de cores e vetores de movimento n√£o podem ser renderizados simultaneamente com o MRT (destinos de renderiza√ß√£o m√∫ltipla).  N√£o consegui descobrir o motivo.  Al√©m disso, eles exigem liga√ß√£o a diferentes buffers de profundidade.  Felizmente, escrevemos a profundidade para esses <i>dois</i> buffers de profundidade, portanto, reprojetar o anti-aliasing tempor√°rio funciona bem (oh, √© um prazer trabalhar com o mecanismo da caixa preta). <br><br>  Em cada quadro, jogamos fora uma renderiza√ß√£o composta de OnPostRender (): <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-function">RenderTexture </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GenerateRefractionTexture</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { RenderTexture result = RenderTexture.GetTemporary(m_MainCamera.activeTexture.descriptor); Graphics.Blit(m_MainCamera.activeTexture, result); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnPostRender</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (ScreenspaceLiquidCamera &amp;&amp; ScreenspaceLiquidCamera.IsReady()) { RenderTexture refraction_texture = GenerateRefractionTexture(); m_Mat.SetTexture(<span class="hljs-string"><span class="hljs-string">"_MainTex"</span></span>, ScreenspaceLiquidCamera.GetColorBuffer()); m_Mat.SetVector(<span class="hljs-string"><span class="hljs-string">"_MainTex_TexelSize"</span></span>, ScreenspaceLiquidCamera.GetTexelSize()); m_Mat.SetTexture(<span class="hljs-string"><span class="hljs-string">"_LiquidRefractTexture"</span></span>, refraction_texture); m_Mat.SetTexture(<span class="hljs-string"><span class="hljs-string">"_MainDepth"</span></span>, ScreenspaceLiquidCamera.GetDepthBuffer()); m_Mat.SetMatrix(<span class="hljs-string"><span class="hljs-string">"_DepthViewFromClip"</span></span>, ScreenspaceLiquidCamera.GetProjection().inverse); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (SunLight) { m_Mat.SetVector(<span class="hljs-string"><span class="hljs-string">"_SunDir"</span></span>, transform.InverseTransformVector(-SunLight.transform.forward)); m_Mat.SetColor(<span class="hljs-string"><span class="hljs-string">"_SunColor"</span></span>, SunLight.color * SunLight.intensity); } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { m_Mat.SetVector(<span class="hljs-string"><span class="hljs-string">"_SunDir"</span></span>, transform.InverseTransformVector(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Vector3(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>))); m_Mat.SetColor(<span class="hljs-string"><span class="hljs-string">"_SunColor"</span></span>, Color.white); } m_Mat.SetTexture(<span class="hljs-string"><span class="hljs-string">"_ReflectionProbe"</span></span>, ReflectionProbe.defaultTexture); m_Mat.SetVector(<span class="hljs-string"><span class="hljs-string">"_ReflectionProbe_HDR"</span></span>, ReflectionProbe.defaultTextureHDRDecodeValues); Graphics.ExecuteCommandBuffer(m_CommandBuffer); RenderTexture.ReleaseTemporary(refraction_texture); } }</code> </pre> <br>  E √© a√≠ que a participa√ß√£o da CPU termina, depois apenas os shaders. <br><br>  Vamos come√ßar com a passagem de vetores de movimento.  Aqui est√° a apar√™ncia de todo o shader: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"UnityCG.cginc"</span></span></span><span class="hljs-meta"> sampler2D _MainDepth; sampler2D _MainTex; struct appdata { float4 vertex : POSITION; float2 uv : TEXCOORD0; }; struct v2f { float2 uv : TEXCOORD0; float4 vertex : SV_POSITION; }; v2f vert(appdata v) { v2f o; o.vertex = mul(UNITY_MATRIX_P, v.vertex); o.uv = v.uv; return o; } struct frag_out { float4 color : SV_Target; float depth : SV_Depth; }; frag_out frag(v2f i) { frag_out o; float4 fluid = tex2D(_MainTex, i.uv); </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> (fluid.a == 0) discard; o.depth = tex2D(_MainDepth, i.uv).r; float2 vel = fluid.gb / fluid.a; o.color = float4(vel, 0, 1); return o; }</span></span></code> </pre> <br>  A velocidade no espa√ßo da tela √© armazenada no canal verde e azul do buffer de fluido.  Como escalamos a velocidade pela espessura ao renderizar o buffer, dividimos novamente a espessura total (localizada no canal alfa) para obter uma velocidade m√©dia ponderada. <br><br>  Vale ressaltar que, ao trabalhar com grandes volumes de √°gua, outro m√©todo de processamento do buffer de velocidade pode ser necess√°rio.  Como renderizamos sem misturar, os vetores de movimento para tudo <i>o que</i> est√° por <i>tr√°s da</i> √°gua s√£o perdidos, destruindo o TAA e o borr√£o de movimento desses objetos.  Ao trabalhar com finas correntes de √°gua, isso n√£o √© um problema, mas pode interferir ao trabalhar com uma piscina ou lago quando precisamos de objetos TAA ou borr√µes de movimento para serem claramente vis√≠veis atrav√©s da superf√≠cie. <br><br>  Mais interessante √© o principal passe de sombreamento.  Nossa primeira prioridade ap√≥s mascarar a espessura do l√≠quido √© reconstruir a posi√ß√£o e o normal do espa√ßo de visualiza√ß√£o (espa√ßo de visualiza√ß√£o). <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">float3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ViewPosition</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float2 uv)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> clip_z = tex2D(_MainDepth, uv).r; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> clip_x = uv.x * <span class="hljs-number"><span class="hljs-number">2.0</span></span> - <span class="hljs-number"><span class="hljs-number">1.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> clip_y = <span class="hljs-number"><span class="hljs-number">1.0</span></span> - uv.y * <span class="hljs-number"><span class="hljs-number">2.0</span></span>; float4 clip_p = float4(clip_x, clip_y, clip_z, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); float4 view_p = mul(_DepthViewFromClip, clip_p); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (view_p.xyz / view_p.w); } <span class="hljs-function"><span class="hljs-function">float3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ReconstructNormal</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float2 uv, float3 vp11)</span></span></span><span class="hljs-function"> </span></span>{ float3 vp12 = ViewPosition(uv + _MainTex_TexelSize.xy * float2(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)); float3 vp10 = ViewPosition(uv + _MainTex_TexelSize.xy * float2(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>)); float3 vp21 = ViewPosition(uv + _MainTex_TexelSize.xy * float2(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)); float3 vp01 = ViewPosition(uv + _MainTex_TexelSize.xy * float2(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)); float3 dvpdx0 = vp11 - vp12; float3 dvpdx1 = vp10 - vp11; float3 dvpdy0 = vp11 - vp21; float3 dvpdy1 = vp01 - vp11; <span class="hljs-comment"><span class="hljs-comment">// Pick the closest float3 dvpdx = dot(dvpdx0, dvpdx0) &gt; dot(dvpdx1, dvpdx1) ? dvpdx1 : dvpdx0; float3 dvpdy = dot(dvpdy0, dvpdy0) &gt; dot(dvpdy1, dvpdy1) ? dvpdy1 : dvpdy0; return normalize(cross(dvpdy, dvpdx)); }</span></span></code> </pre> <br>  Esta √© uma maneira dispendiosa de reconstruir a posi√ß√£o do espa√ßo de visualiza√ß√£o: tomamos a posi√ß√£o no espa√ßo do clipe e realizamos a opera√ß√£o reversa da proje√ß√£o. <br><br>  Depois que conseguimos uma maneira de reconstruir as posi√ß√µes, as normais s√£o mais simples: calculamos a posi√ß√£o dos pontos vizinhos no buffer de profundidade e constru√≠mos uma base tangente a partir deles.  Para trabalhar com as arestas das silhuetas, amostramos nas duas dire√ß√µes e selecionamos o ponto mais pr√≥ximo ao espa√ßo da vista para reconstruir o normal.  Esse m√©todo funciona surpreendentemente bem e causa problemas apenas no caso de objetos muito finos. <br><br>  Isso significa que realizamos cinco opera√ß√µes separadas de proje√ß√£o reversa por pixel (para o ponto atual e quatro vizinhos).  Existe uma maneira menos cara, mas esse post j√° √© muito longo, ent√£o deixarei para depois. <br><br>  As normais resultantes s√£o: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b2c/0ed/7f6/b2c0ed7f6cfcc66473ff4e5380c46894.png"></div><br>  Eu distor√ßo esse normal calculado usando as derivadas do valor do ru√≠do do buffer de fluido, dimensionado pelo par√¢metro force e normalizado dividindo pela espessura do jato (pelo mesmo motivo da velocidade): <br><br><pre> <code class="cpp hljs">N.xy += NoiseDerivatives(i.uv, fluid.r) * (_NoiseStrength / fluid.a); N = normalize(N);</code> </pre> <br>  Finalmente, podemos prosseguir com o sombreamento em si.  O sombreamento da √°gua consiste em tr√™s partes principais: reflex√£o especular, refra√ß√£o especular e espuma. <br><br>  A reflex√£o √© um GGX padr√£o, retirado inteiramente do shader padr√£o do Unity.  (Com uma corre√ß√£o, o F0 correto de 2% √© usado para a √°gua.) <br><br>  Com refra√ß√£o, tudo √© mais interessante.  A refra√ß√£o correta requer rastreamento de raios (ou marca√ß√£o de raios para obter um resultado aproximado).  Felizmente, a refra√ß√£o √© menos intuitiva para os olhos do que a reflex√£o e, portanto, resultados incorretos n√£o s√£o t√£o percept√≠veis.  Portanto, alteramos a amostra UV para a textura refrativa por normais x e y, dimensionadas pelo par√¢metro de espessura e for√ßa: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> aspect = _MainTex_TexelSize.y * _MainTex_TexelSize.z; float2 refract_uv = (i.grab_pos.xy + N.xy * float2(<span class="hljs-number"><span class="hljs-number">1</span></span>, -aspect) * fluid.a * _RefractionMultiplier) / i.grab_pos.w; float4 refract_color = tex2D(_LiquidRefractTexture, refract_uv);</code> </pre> <br>  (Observe que a corre√ß√£o de correla√ß√£o √© usada; √© <i>opcional</i> - afinal, √© apenas uma aproxima√ß√£o, mas a adi√ß√£o √© bastante simples.) <br><br>  Essa luz refratada passa pelo l√≠quido, portanto parte dela √© absorvida: <br><br><pre> <code class="cpp hljs">float3 water_color = _AbsorptionColor.rgb * _AbsorptionIntensity; refract_color.rgb *= <span class="hljs-built_in"><span class="hljs-built_in">exp</span></span>(-water_color * fluid.a);</code> </pre> <br>  Observe que _AbsorptionColor √© determinado exatamente do modo oposto ao esperado: os valores de cada canal indicam a quantidade de luz <i>absorvida</i> e n√£o transmitida.  Portanto, _AbsorptionColor com um valor de (1, 0, 0) n√£o fornece vermelho, mas uma cor turquesa (verde-azulado). <br><br>  Reflex√£o e refra√ß√£o s√£o misturadas usando os coeficientes de Fresnel: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> spec_blend = lerp(<span class="hljs-number"><span class="hljs-number">0.02</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">pow</span></span>(<span class="hljs-number"><span class="hljs-number">1.0</span></span> - ldoth, <span class="hljs-number"><span class="hljs-number">5</span></span>)); float4 clear_color = lerp(refract_color, spec, spec_blend);</code> </pre> <br>  At√© aquele momento, jog√°vamos pelas regras (principalmente) e usamos sombreamento f√≠sico. <br><br>  Ele √© muito bom, mas ele tem um problema com a √°gua.  √â um pouco dif√≠cil de ver: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ff2/4f2/ba2/ff24f2ba2dad5dc6fe7714ad3fd55124.png"></div><br>  Para consertar, vamos adicionar um pouco de espuma. <br><br>  A espuma aparece quando a √°gua √© turbulenta e o ar se mistura com a √°gua para formar bolhas.  Tais bolhas criam todos os tipos de varia√ß√µes de reflex√£o e refra√ß√£o, o que d√° a toda a √°gua uma sensa√ß√£o de ilumina√ß√£o difusa.  Modelarei esse comportamento com luz ambiente envolvida: <br><br><pre> <code class="cpp hljs">float3 foam_color = _SunColor * saturate((dot(N, L)*<span class="hljs-number"><span class="hljs-number">0.25f</span></span> + <span class="hljs-number"><span class="hljs-number">0.25f</span></span>));</code> </pre> <br>  √â adicionado √† cor final usando um fator especial, dependendo do ru√≠do do fluido e do coeficiente de Fresnel amolecido: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> foam_blend = saturate(fluid.r * _NoiseStrength) * lerp(<span class="hljs-number"><span class="hljs-number">0.05f</span></span>, <span class="hljs-number"><span class="hljs-number">0.5f</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">pow</span></span>(<span class="hljs-number"><span class="hljs-number">1.0f</span></span> - ndotv, <span class="hljs-number"><span class="hljs-number">3</span></span>)); clear_color.rgb += foam_color * saturate(foam_blend);</code> </pre> <br>  A ilumina√ß√£o ambiente envolvida √© normalizada para economizar energia, para que possa ser usada como uma aproxima√ß√£o de difus√£o.  A mistura da cor da espuma √© mais vis√≠vel.  √â uma viola√ß√£o bastante clara da lei de conserva√ß√£o de energia. <br><br>  Mas, em geral, tudo parece bom e torna o fluxo mais percept√≠vel: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/216/ca8/1f5/216ca81f5eb506eab2dbcfc730a904b4.png"></div><br><h3>  Mais trabalhos e melhorias </h3><br>  No sistema criado, muito pode ser melhorado. <br><br><ul><li>  Usando v√°rias cores.  No momento, a absor√ß√£o √© calculada apenas no √∫ltimo est√°gio do sombreamento e usa uma cor e brilho constantes para todo o l√≠quido na tela.  O suporte para cores diferentes √© poss√≠vel, mas requer um segundo tamp√£o de cor e a solu√ß√£o da absor√ß√£o integral para cada part√≠cula no processo de renderiza√ß√£o do tamp√£o do fluido base.  Isso pode ser potencialmente uma opera√ß√£o cara. </li><li>  Cobertura total.  Tendo acesso √† estrutura de pesquisa de ilumina√ß√£o no lado da GPU (constru√≠da manualmente ou gra√ßas √† liga√ß√£o ao novo pipeline de renderiza√ß√£o Unity HD), podemos iluminar adequadamente a √°gua com qualquer n√∫mero de fontes de luz e criar a ilumina√ß√£o ambiente correta. </li><li>  Refra√ß√£o aprimorada.  Com as texturas mip borradas da textura de fundo, podemos simular melhor a refra√ß√£o para superf√≠cies √°speras.  Na pr√°tica, isso n√£o √© muito √∫til para pequenos sprays de l√≠quido, mas pode ser √∫til para volumes maiores. </li></ul><br>  Se eu tivesse a oportunidade, melhoraria esse sistema com a perda de um pulso, mas no momento ele pode ser chamado de completo. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt420495/">https://habr.com/ru/post/pt420495/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt420479/index.html">Inje√ß√£o de depend√™ncia no servi√ßo Apache Ignite.NET</a></li>
<li><a href="../pt420487/index.html">As empresas solicitam o direito a dados pessoais dos usu√°rios</a></li>
<li><a href="../pt420489/index.html">Novos processadores ARM podem competir com o Core i5</a></li>
<li><a href="../pt420491/index.html">Meu jeito de guerreiro, ou como eu preparei uma aplica√ß√£o para a vida em Sailfish</a></li>
<li><a href="../pt420493/index.html">O servi√ßo de pedidos de comida americano pode se tornar Amaz√¥nia no mundo dos restaurantes</a></li>
<li><a href="../pt420497/index.html">Singularidade de vegetais: Kroger lan√ßa robocouriers para clientes de frutas e vegetais no Arizona</a></li>
<li><a href="../pt420499/index.html">Anatomia de sistemas de recomenda√ß√£o. Parte um</a></li>
<li><a href="../pt420501/index.html">Linux na RAM: debirf way 2018</a></li>
<li><a href="../pt420503/index.html">JS Developer Day, diferentes cidades e comunidades - um feriado</a></li>
<li><a href="../pt420505/index.html">O OpenAI Five ganhar√° a equipe profissional do The International</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏽‍🎤 👨🏻‍💻 🏦 Mama schläft nachts ruhig - wir sammeln OpenCV für Raspbian'a 🖖🏽 🚵🏻 ⛔️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die letzten Wochen waren für unser Team schwierig. OpenCV 4 wurde veröffentlicht und damit auf das OpenVINO-Toolkit R4 von Intel vorbereitet, das Open...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mama schläft nachts ruhig - wir sammeln OpenCV für Raspbian'a</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/430906/"><p> Die letzten Wochen waren für unser Team schwierig.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenCV 4 wurde veröffentlicht</a> und damit auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das OpenVINO-Toolkit</a> R4 von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Intel</a> vorbereitet, das OpenCV enthält.  Du denkst, ich bin für eine Weile abgelenkt, ich werde mich wie üblich mit OpenCV-Foren und Benutzerkommentaren befassen, und hier ist es Mode für dich zu sagen, dass OpenCV kein IoT ist, dass es unter Raspberry Pi ausreicht, um es zusammenzubauen - es gibt nicht genug Lötmittel, um <code>make -j2</code> zu setzen - Am Morgen ist es fertig, wenn Sie Glück haben. </p><br><p>  Daher schlage ich vor, Hand in Hand zu gehen und zu sehen, wie Sie die OpenCV-Bibliothek für ein 32-Bit-Betriebssystem zusammenstellen können, das auf einem ARM-Prozessor ausgeführt wird. Dabei werden die Ressourcen eines Computers mit 64-Bit-Betriebssystem verwendet, der von einer hervorragenden CPU-Architektur angetrieben wird. <del>  Hexerei </del>  Cross Compilation, sonst nicht! </p><a name="habracut"></a><br><h2 id="postanovka-zadachi">  Erklärung des Problems </h2><br><p>  Das Kompilieren direkt auf der Platine, die allgemein als native bezeichnet wird, ist sehr mühsam. Daher werden wir hier eine Möglichkeit betrachten, ein Projekt zu erstellen, mit dem stärkere Computergeräte (nennen wir sie Hosts) Binärdateien für ihre kleinen Verwandten vorbereiten können.  Darüber hinaus können beide Maschinen unterschiedliche CPU-Architekturen aufweisen.  Dies ist eine Kreuzkompilierung. </p><br><p>  Um einen mit OpenCV gefüllten Himbeerkuchen zuzubereiten, benötigen wir: </p><br><ul><li>  Ubuntu 16.04 Image Docker Kadaver </li><li>  Der Host-Computer ist leistungsstärker als der Raspberry Pi (ansonsten, was ist der Sinn, nicht wahr?) </li><li>  Cross-Compiler für ARMhf sowie Bibliotheken der entsprechenden Architektur </li></ul><br><p>  Der gesamte Prozess der Erstellung von OpenCV findet auf dem Host-Computer statt.  Ich benutze Ubuntu zu Hause.  Bei einer anderen Linux-Version sollten keine Wiedergabeprobleme auftreten.  Für Windows-Benutzer - mein aufrichtiger Wunsch, nicht aufzugeben und zu versuchen, es selbst herauszufinden. </p><br><h2 id="ustanovka-docker">  Installieren Sie Docker </h2><br><p>  Ich begann meine Bekanntschaft mit Docker vor ungefähr einer Woche, also fügen Sie Gourmet-Salz und syntaktischen Zucker hinzu, um zu schmecken.  Drei Zutaten reichen für Sie und mich - Dockerfile, das Konzept von Image und Container. </p><br><p>  Docker selbst ist ein Tool zum Erstellen und Reproduzieren der Konfiguration eines Betriebssystems mit den erforderlichen Komponenten.  Dockerfile ist eine Reihe von Shell-Befehlen, die Sie normalerweise auf dem Host-Computer verwenden. In diesem Fall gelten sie jedoch alle für das sogenannte <code>docker</code> Image. </p><br><p>  Um Docker zu installieren, gehen Sie wie folgt vor: Bestellen Sie ein Paket über den <code>apt-get</code> Lieferservice: </p><br><pre> <code class="bash hljs">sudo apt-get install -y docker.io</code> </pre> <br><p>  Wir geben dem Docker-Daemon alles, was er verlangt, und melden uns vom System ab (beachten Sie die entsprechende Anmeldung). </p><br><pre> <code class="bash hljs">sudo usermod -a -G docker <span class="hljs-variable"><span class="hljs-variable">$USER</span></span></code> </pre> <br><h2 id="podgotavlivaem-rabochee-prostranstvo">  Arbeitsbereich vorbereiten </h2><br><p>  Raspberry Pi (in meinem Fall RPI 2 Modell B) ist in der häufigsten Vorbereitung eine ARMv7-CPU mit dem Betriebssystem Raspbian (Debian-basiert).  Wir werden ein <code>docker</code> Image basierend auf Ubuntu 16.04 erstellen, in dem wir den Cross-Compiler und die Armeebibliotheken melden und OpenCV an derselben Stelle sammeln. </p><br><p>  Erstelle einen Daddy, in dem unsere <code>Dockerfile</code> liegen wird: </p><br><pre> <code class="bash hljs">mkdir ubuntu16_armhf_opencv &amp;&amp; <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ubuntu16_armhf_opencv touch Dockerfile</code> </pre> <br><p>  Fügen Sie Informationen zum Basisbetriebssystem und zur <code>armhf</code> Architektur für das <code>apt-get</code> <code>armhf</code> : </p><br><pre> <code class="plaintext hljs">FROM ubuntu:16.04 USER root RUN dpkg --add-architecture armhf RUN apt-get update</code> </pre> <br><p>  Bitte beachten Sie, dass Befehle wie <code>FROM ...</code> , <code>RUN ...</code> die <code>docker</code> Syntax sind und in die erstellte <code>Dockerfile</code> Testdatei geschrieben werden. </p><br><p>  <code>ubuntu16_armhf_opencv</code> wir zum übergeordneten Verzeichnis <code>ubuntu16_armhf_opencv</code> und versuchen, unser Docker-Image zu erstellen: </p><br><pre> <code class="bash hljs">docker image build ubuntu16_armhf_opencv</code> </pre> <br><p>  Während der Ausführung des Befehls <code>apt-get update</code> sollten Fehler der folgenden Art <code>Err:[] [url] xenial[-] armhf Packages</code> : <code>Err:[] [url] xenial[-] armhf Packages</code> </p><br><pre> <code class="bash hljs">Ign:30 http://archive.ubuntu.com/ubuntu xenial-backports/main armhf Packages Ign:32 http://archive.ubuntu.com/ubuntu xenial-backports/universe armhf Packages Err:7 http://archive.ubuntu.com/ubuntu xenial/main armhf Packages 404 Not Found Ign:9 http://archive.ubuntu.com/ubuntu xenial/restricted armhf Packages Ign:18 http://archive.ubuntu.com/ubuntu xenial/universe armhf Packages Ign:20 http://archive.ubuntu.com/ubuntu xenial/multiverse armhf Packages Err:22 http://archive.ubuntu.com/ubuntu xenial-updates/main armhf Packages 404 Not Found Ign:24 http://archive.ubuntu.com/ubuntu xenial-updates/restricted armhf Packages Ign:26 http://archive.ubuntu.com/ubuntu xenial-updates/universe armhf Packages Ign:28 http://archive.ubuntu.com/ubuntu xenial-updates/multiverse armhf Packages Err:30 http://archive.ubuntu.com/ubuntu xenial-backports/main armhf Packages 404 Not Found Ign:32 http://archive.ubuntu.com/ubuntu xenial-backports/universe armhf Packages</code> </pre> <br><p>  Wenn Sie sich die Datei <code>/etc/apt/sources.list</code> entspricht jeder dieser Fehler einer Zeile, zum Beispiel: </p><br><p>  <strong>Fehler</strong> </p><br><pre> <code class="plaintext hljs">Err:22 http://archive.ubuntu.com/ubuntu xenial-updates/main armhf Packages 404 Not Found</code> </pre> <br><p>  <strong>Zeile in /etc/apt/sources.list</strong> : </p><br><pre> <code class="plaintext hljs">deb http://archive.ubuntu.com/ubuntu/ xenial-updates main restricted</code> </pre> <br><p>  <strong>Lösung</strong> : <br>  In zwei Teile teilen: </p><br><pre> <code class="plaintext hljs">deb [arch=amd64] http://archive.ubuntu.com/ubuntu/ xenial-updates main restricted deb [arch=armhf] http://ports.ubuntu.com/ubuntu-ports/ xenial-updates main restricted</code> </pre> <br><p>  Daher müssen Sie mehrere Paketquellen ersetzen.  In unserem Docker werden wir sie alle durch einen Befehl ersetzen: </p><br><pre> <code class="plaintext hljs">RUN sed -i -E 's|^deb ([^ ]+) (.*)$|deb [arch=amd64] \1 \2\ndeb [arch=armhf] http://ports.ubuntu.com/ubuntu-ports/ \2|' /etc/apt/sources.list</code> </pre> <br><p>  Jetzt sollte <code>apt-get update</code> fehlerfrei funktionieren. </p><br><h2 id="stavim-neobhodimye-pakety">  Wir legen die notwendigen Pakete </h2><br><p>  Wir müssen Host-Pakete wie <code>git</code> , <code>python-pip</code> , <code>cmake</code> und <code>pkg-config</code> sowie <code>crossbuild-essential-armhf</code> , eine Reihe von gcc / g ++ - Cross-Compilern ( <code>arm-linux-gnueabihf-gcc</code> und <code>arm-linux-gnueabihf-g++</code> ) und Systembibliotheken der entsprechenden Architektur: </p><br><pre> <code class="plaintext hljs">RUN apt-get install -y git python-pip cmake pkg-config crossbuild-essential-armhf</code> </pre> <br><p>  Aus dem Ungewöhnlichen - wir laden auch GTK (zum Zeichnen von Fenstern im Highgui-Modul), GStreamer und Python herunter, jedoch mit einem expliziten Hinweis auf eine fremde Architektur: </p><br><pre> <code class="plaintext hljs">RUN apt-get install -y --no-install-recommends \ libgtk2.0-dev:armhf \ libpython-dev:armhf \ libgstreamer1.0-dev:armhf \ libgstreamer-plugins-base1.0-dev:armhf \ libgstreamer-plugins-good1.0-dev:armhf \ libgstreamer-plugins-bad1.0-dev:armhf</code> </pre> <br><p>  Und dann klonen und sammeln wir und geben die erforderlichen Flags an: </p><br><pre> <code class="plaintext hljs">RUN git clone https://github.com/opencv/opencv --depth 1 RUN mkdir opencv/build &amp;&amp; cd opencv/build &amp;&amp; \ export PKG_CONFIG_PATH=/usr/lib/arm-linux-gnueabihf/pkgconfig &amp;&amp; \ cmake -DCMAKE_BUILD_TYPE=Release \ -DOPENCV_CONFIG_INSTALL_PATH="cmake" \ -DCMAKE_TOOLCHAIN_FILE="../opencv/platforms/linux/arm-gnueabi.toolchain.cmake" \ -DWITH_IPP=OFF \ -DBUILD_TESTS=OFF \ -DBUILD_PERF_TESTS=OFF \ -DOPENCV_ENABLE_PKG_CONFIG=ON \ -DPYTHON2_INCLUDE_PATH="/usr/include/python2.7" \ -DPYTHON2_NUMPY_INCLUDE_DIRS="/usr/local/lib/python2.7/dist-packages/numpy/core/include" \ -DENABLE_NEON=ON \ -DCPU_BASELINE="NEON" ..</code> </pre> <br><p>  wo </p><br><ul><li><p>  <code>CMAKE_TOOLCHAIN_FILE</code> - Der Pfad zur cmake-Datei, der den Cross-Compilation-Prozess definiert (legt den gewünschten Compiler fest und schränkt die Verwendung von Host-Bibliotheken ein. </p><br></li><li><p>  <code>WITH_IPP=OFF</code> , - Deaktiviert starke Abhängigkeiten. </p><br></li><li><p>  <code>BUILD_TESTS=OFF</code> , <code>BUILD_PERF_TESTS=OFF</code> , deaktivieren Sie den <code>BUILD_PERF_TESTS=OFF</code> . </p><br></li><li><p>  <code>OPENCV_ENABLE_PKG_CONFIG=ON</code> - damit pkg-config Abhängigkeiten wie GTK finden kann.  <code>PKG_CONFIG_PATH</code> ist der richtige Pfad, in dem <code>pkg-config</code> nach Bibliotheken sucht. </p><br></li><li><p>  <code>PYTHON2_INCLUDE_PATH</code> , <code>PYTHON2_NUMPY_INCLUDE_DIRS</code> - Pfade, die zum Cross-Compilieren von Wrappern für Python2 erforderlich sind. </p><br></li><li><p>  <code>ENABLE_NEON=ON</code> , <code>CPU_BASELINE="NEON"</code> - NEON-Optimierung aktivieren. </p><br></li><li><p>  <code>OPENCV_CONFIG_INSTALL_PATH</code> - <code>OPENCV_CONFIG_INSTALL_PATH</code> den Speicherort der Dateien im <code>install</code> . </p><br></li></ul><br><p>  Die Hauptsache, auf die Sie nach der Ausführung von <code>cmake</code> achten sollten, ist, dass alle erforderlichen Module zusammengesetzt sind (z. B. python2): </p><br><pre> <code class="plaintext hljs">-- OpenCV modules: -- To be built: calib3d core dnn features2d flann gapi highgui imgcodecs imgproc java_bindings_generator ml objdetect photo python2 python_bindings_generator stitching ts video videoio -- Disabled: world -- Disabled by dependency: - -- Unavailable: java js python3 -- Applications: tests perf_tests apps -- Documentation: NO -- Non-free algorithms: NO</code> </pre> <br><p>  und die notwendigen Abhängigkeiten wie GTK wurden gefunden: </p><br><pre> <code class="plaintext hljs">-- GUI: -- GTK+: YES (ver 2.24.30) -- GThread : YES (ver 2.48.2) -- GtkGlExt: NO -- -- Video I/O: -- GStreamer: -- base: YES (ver 1.8.3) -- video: YES (ver 1.8.3) -- app: YES (ver 1.8.3) -- riff: YES (ver 1.8.3) -- pbutils: YES (ver 1.8.3) -- v4l/v4l2: linux/videodev2.h</code> </pre> <br><p>  Sie müssen nur noch <code>make</code> aufrufen, <code>make install</code> und warten, bis der Build abgeschlossen ist: </p><br><pre> <code class="plaintext hljs">Successfully built 4dae6b1a7d32</code> </pre> <br><p>  Verwenden Sie diese Bild- <code>id</code> , um einen Container zu markieren und zu erstellen: </p><br><pre> <code class="plaintext hljs">docker tag 4dae6b1a7d32 ubuntu16_armhf_opencv:latest docker run ubuntu16_armhf_opencv</code> </pre> <br><p>  Und wir müssen nur das zusammengebaute OpenCV aus dem Behälter pumpen.  Schauen wir uns zunächst die Kennung des erstellten Containers an: </p><br><pre> <code class="plaintext hljs">$ docker container ls --all CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e94667fe60d2 ubuntu16_armhf_opencv "/bin/bash" 6 seconds ago Exited (0) 5 seconds ago clever_yalow</code> </pre> <br><p>  Und kopieren Sie das Installationsverzeichnis mit installiertem OpenCV: </p><br><pre> <code class="plaintext hljs">docker cp e94667fe60d2:/opencv/build/install/ ./ mv install ocv_install</code> </pre> <br><h2 id="nakryvaem-na-stol">  Stellen Sie den Tisch ein </h2><br><p>  Kopieren Sie <code>ocv_install</code> auf den Raspberry Pi, legen Sie die Pfade fest und versuchen Sie, OpenCV über Python auszuführen. </p><br><pre> <code class="plaintext hljs">export LD_LIBRARY_PATH=/path/to/ocv_install/lib/:$LD_LIBRARY_PATH export PYTHONPATH=/path/to/ocv_install/python/:$PYTHONPATH</code> </pre> <br><p>  Führen Sie das Erkennungsbeispiel mit dem neuronalen MobileNet-SSD-Netzwerk unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/chuanqi305/MobileNet-SSD aus</a> : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> cv <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> cv.__file__ classes = [<span class="hljs-string"><span class="hljs-string">'backgroud'</span></span>, <span class="hljs-string"><span class="hljs-string">'aeroplane'</span></span>, <span class="hljs-string"><span class="hljs-string">'bicycle'</span></span>, <span class="hljs-string"><span class="hljs-string">'bird'</span></span>, <span class="hljs-string"><span class="hljs-string">'boat'</span></span>, <span class="hljs-string"><span class="hljs-string">'bottle'</span></span>, <span class="hljs-string"><span class="hljs-string">'bus'</span></span>, <span class="hljs-string"><span class="hljs-string">'car'</span></span>, <span class="hljs-string"><span class="hljs-string">'cat'</span></span>, <span class="hljs-string"><span class="hljs-string">'chair'</span></span>, <span class="hljs-string"><span class="hljs-string">'cow'</span></span>, <span class="hljs-string"><span class="hljs-string">'diningtable'</span></span>, <span class="hljs-string"><span class="hljs-string">'dog'</span></span>, <span class="hljs-string"><span class="hljs-string">'horse'</span></span>, <span class="hljs-string"><span class="hljs-string">'motorbike'</span></span>, <span class="hljs-string"><span class="hljs-string">'person'</span></span>, <span class="hljs-string"><span class="hljs-string">'pottedplant'</span></span>, <span class="hljs-string"><span class="hljs-string">'sheep'</span></span>, <span class="hljs-string"><span class="hljs-string">'sofa'</span></span>, <span class="hljs-string"><span class="hljs-string">'train'</span></span>, <span class="hljs-string"><span class="hljs-string">'tvmonitor'</span></span>] cap = cv.VideoCapture(<span class="hljs-number"><span class="hljs-number">0</span></span>) net = cv.dnn.readNet(<span class="hljs-string"><span class="hljs-string">'MobileNetSSD_deploy.caffemodel'</span></span>, <span class="hljs-string"><span class="hljs-string">'MobileNetSSD_deploy.prototxt'</span></span>) cv.namedWindow(<span class="hljs-string"><span class="hljs-string">'Object detection'</span></span>, cv.WINDOW_NORMAL) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> cv.waitKey(<span class="hljs-number"><span class="hljs-number">1</span></span>) != <span class="hljs-number"><span class="hljs-number">27</span></span>: hasFrame, frame = cap.read() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> hasFrame: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> frame_height, frame_width = frame.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], frame.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] blob = cv.dnn.blobFromImage(frame, scalefactor=<span class="hljs-number"><span class="hljs-number">0.007843</span></span>, size=(<span class="hljs-number"><span class="hljs-number">300</span></span>, <span class="hljs-number"><span class="hljs-number">300</span></span>), mean=(<span class="hljs-number"><span class="hljs-number">127.5</span></span>, <span class="hljs-number"><span class="hljs-number">127.5</span></span>, <span class="hljs-number"><span class="hljs-number">127.5</span></span>)) net.setInput(blob) out = net.forward() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> detection <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> out.reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>): classId = int(detection[<span class="hljs-number"><span class="hljs-number">1</span></span>]) confidence = float(detection[<span class="hljs-number"><span class="hljs-number">2</span></span>]) xmin = int(detection[<span class="hljs-number"><span class="hljs-number">3</span></span>] * frame_width) ymin = int(detection[<span class="hljs-number"><span class="hljs-number">4</span></span>] * frame_height) xmax = int(detection[<span class="hljs-number"><span class="hljs-number">5</span></span>] * frame_width) ymax = int(detection[<span class="hljs-number"><span class="hljs-number">6</span></span>] * frame_height) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> confidence &gt; <span class="hljs-number"><span class="hljs-number">0.5</span></span>: cv.rectangle(frame, (xmin, ymin), (xmax, ymax), color=(<span class="hljs-number"><span class="hljs-number">255</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>), thickness=<span class="hljs-number"><span class="hljs-number">3</span></span>) label = <span class="hljs-string"><span class="hljs-string">'%s: %.2f'</span></span> % (classes[classId], confidence) labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) ymin = max(ymin, labelSize[<span class="hljs-number"><span class="hljs-number">1</span></span>]) cv.rectangle(frame, (xmin, ymin - labelSize[<span class="hljs-number"><span class="hljs-number">1</span></span>]), (xmin + labelSize[<span class="hljs-number"><span class="hljs-number">0</span></span>], ymin + baseLine), (<span class="hljs-number"><span class="hljs-number">255</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>), cv.FILLED) cv.putText(frame, label, (xmin, ymin), cv.FONT_HERSHEY_SIMPLEX, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, (<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)) cv.imshow(<span class="hljs-string"><span class="hljs-string">'Object detection'</span></span>, frame)</code> </pre> <br><p><img src="https://habrastorage.org/webt/1h/sd/0m/1hsd0mmmse6gslxx169tw4lc2wu.png"></p><br><p>  Das ist alles, eine komplette Montage dauert nicht länger als 20 Minuten.  Ich habe die endgültige Version der <code>Dockerfile</code> unten aufgeführt und <code>Dockerfile</code> diese Gelegenheit. Ich schlage vor, eine kurze Umfrage des OpenCV-Teams für diejenigen <code>Dockerfile</code> , die einmal Erfahrung mit der Bibliothek hatten: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://opencv.org/survey-2018.html</a> . </p><br><p>  Und ja, herzlichen Glückwunsch zu OpenCV 4!  Dies ist nicht nur die Arbeit eines separaten Teams, sondern die Arbeit der gesamten Community - OpenCV 4 you. </p><br><pre> <code class="plaintext hljs">FROM ubuntu:16.04 USER root RUN dpkg --add-architecture armhf RUN sed -i -E 's|^deb ([^ ]+) (.*)$|deb [arch=amd64] \1 \2\ndeb [arch=armhf] http://ports.ubuntu.com/ubuntu-ports/ \2|' /etc/apt/sources.list RUN apt-get update &amp;&amp; \ apt-get install -y --no-install-recommends \ cmake \ pkg-config \ crossbuild-essential-armhf \ git \ python-pip \ libgtk2.0-dev:armhf \ libpython-dev:armhf \ libgstreamer1.0-dev:armhf \ libgstreamer-plugins-base1.0-dev:armhf \ libgstreamer-plugins-good1.0-dev:armhf \ libgstreamer-plugins-bad1.0-dev:armhf RUN pip install numpy==1.12.1 RUN git clone https://github.com/opencv/opencv --depth 1 RUN mkdir opencv/build &amp;&amp; cd opencv/build &amp;&amp; \ export PKG_CONFIG_PATH=/usr/lib/arm-linux-gnueabihf/pkgconfig &amp;&amp; \ cmake -DCMAKE_BUILD_TYPE=Release \ -DOPENCV_CONFIG_INSTALL_PATH="cmake" \ -DCMAKE_TOOLCHAIN_FILE="../opencv/platforms/linux/arm-gnueabi.toolchain.cmake" \ -DWITH_IPP=OFF \ -DBUILD_TESTS=OFF \ -DBUILD_PERF_TESTS=OFF \ -DOPENCV_ENABLE_PKG_CONFIG=ON \ -DPYTHON2_INCLUDE_PATH="/usr/include/python2.7" \ -DPYTHON2_NUMPY_INCLUDE_DIRS="/usr/local/lib/python2.7/dist-packages/numpy/core/include" \ -DENABLE_NEON=ON \ -DCPU_BASELINE="NEON" .. &amp;&amp; make -j4 &amp;&amp; make install</code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de430906/">https://habr.com/ru/post/de430906/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de430892/index.html">Die Kombination aus plattformübergreifendem und nativem Ansatz bei der Entwicklung mobiler Anwendungen</a></li>
<li><a href="../de430894/index.html">Situation: Marken geben immer mehr Geld für Werbung in Podcasts aus - wir verstehen warum</a></li>
<li><a href="../de430896/index.html">Die Linux Foundation hat Fonds für GraphQL und Ceph eingerichtet - warum werden sie benötigt und was kann man von ihnen erwarten?</a></li>
<li><a href="../de430900/index.html">Der erste Laser in der Geschichte: was es war</a></li>
<li><a href="../de430902/index.html">Elfen in Erinnerung. Ausführen von ELF im Linux-RAM</a></li>
<li><a href="../de430910/index.html">Fulbright-Stipendium: Wie und warum?</a></li>
<li><a href="../de430912/index.html">Wir bringen einen Lügner zu sauberem Wasser: Ein Interview ist kein Arbeitsverhältnis. Natürlich</a></li>
<li><a href="../de430914/index.html">Analyse der Schwarzmarktpreise für personenbezogene Daten und Durchbruch</a></li>
<li><a href="../de430916/index.html">Kohlendioxiddetektor MT8057S. Nichtüberprüfung unter Beteiligung eines Nichtemulators</a></li>
<li><a href="../de430918/index.html">Über Flutter, kurz: Grundlagen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
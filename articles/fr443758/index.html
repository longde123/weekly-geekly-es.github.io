<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéê üèåÔ∏è ‚ò£Ô∏è Reconnaissance rapide de Doodle Draw: comment se faire des amis R, C ++ et Neural Grids üëÜüèº üì® üë®üèΩ‚Äç‚úàÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour, Habr! 

 L'automne dernier, √† Kaggle, un concours a √©t√© organis√© pour le classement des images de reconnaissance de dessin rapide dessin√©es √†...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Reconnaissance rapide de Doodle Draw: comment se faire des amis R, C ++ et Neural Grids</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/443758/"><img src="https://habrastorage.org/webt/cp/ir/jc/cpirjcgr-d52s_br1kqmvzkeawm.png"><br><br>  Bonjour, Habr! <br><br>  L'automne dernier, √† Kaggle, un concours a √©t√© organis√© pour le classement des images de reconnaissance de dessin rapide dessin√©es √† la main, auquel a notamment particip√© une √©quipe de R-schiks compos√©e d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Artem Klevtsov</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Philip Upravitelev</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Andrey Ogurtsov</a> .  Nous ne d√©crirons pas le concours en d√©tail, cela a d√©j√† √©t√© fait dans une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">publication r√©cente</a> . <br><br>  Cette fois, il n'y a pas eu de m√©dailles pour les produits pharmaceutiques agricoles, mais beaucoup d'exp√©rience pr√©cieuse a √©t√© acquise, alors je voudrais parler √† la communaut√© d'un certain nombre de choses les plus int√©ressantes et utiles sur Kagl et dans le travail quotidien.  Parmi les sujets trait√©s: la vie dure sans <strong>OpenCV</strong> , l'analyse des JSON (ces exemples <strong>montrent l'</strong> int√©gration du code C ++ dans des scripts ou des packages dans R √† l'aide de <strong>Rcpp</strong> ), le param√©trage des scripts et la dockerisation de la solution finale.  Tout le code du message sous une forme adapt√©e au lancement est disponible dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©f√©rentiel</a> . <br><br><h3>  Contenu: </h3><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chargement efficace des donn√©es du CSV vers la base de donn√©es MonetDB</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pr√©paration des lots</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">It√©rateurs pour d√©charger des lots de la base de donn√©es</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">S√©lection de l'architecture du mod√®le</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Param√©trage du script</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Scripts d'ancrage</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Utilisation de plusieurs GPU dans Google Cloud</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Au lieu d'une conclusion</a> </li></ol><a name="habracut"></a><br><h4 id="section1">  1. Chargement efficace des donn√©es du CSV vers la base de donn√©es MonetDB </h4><br><p>  Les donn√©es de ce concours ne sont pas fournies sous forme d'images pr√™tes √† l'emploi, mais sous la forme de 340 fichiers CSV (un fichier pour chaque classe) contenant des JSON avec des coordonn√©es ponctuelles.  En connectant ces points avec des lignes, nous obtenons l'image finale mesurant 256x256 pixels.  De plus, pour chaque enregistrement, une √©tiquette indique si l'image a √©t√© correctement reconnue par le classificateur utilis√© au moment de la collecte de l'ensemble de donn√©es, le code √† deux lettres du pays de r√©sidence de l'auteur, un identifiant unique, un horodatage et un nom de classe correspondant au nom du fichier.  Une version simplifi√©e des donn√©es source p√®se 7,4 Go dans l'archive et environ 20 Go apr√®s le d√©ballage, les donn√©es compl√®tes apr√®s le d√©ballage prennent 240 Go.  Les organisateurs ont garanti que les deux versions reproduisent les m√™mes dessins, c'est-√†-dire que la version compl√®te est redondante.  Dans tous les cas, le stockage de 50 millions d'images dans des fichiers graphiques ou dans des tableaux a √©t√© imm√©diatement consid√©r√© comme non rentable, et nous avons d√©cid√© de fusionner tous les fichiers CSV √† partir de l'archive <em>train_simplified.zip</em> dans une base de donn√©es avec la g√©n√©ration ult√©rieure d'images de la bonne taille √† la vol√©e pour chaque lot . </p><br><p>  Le <strong>MonetDB</strong> bien √©tabli a √©t√© choisi comme SGBD, √† savoir l'impl√©mentation de R sous la forme du package <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MonetDBLite</a></strong> .  Le package comprend une version int√©gr√©e du serveur de base de donn√©es et vous permet de soulever le serveur directement √† partir de la session R et d'y travailler.  La cr√©ation d'une base de donn√©es et la connexion √† celle-ci sont effectu√©es par une seule commande: </p><br><pre><code class="plaintext hljs">con &lt;- DBI::dbConnect(drv = MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR"))</code> </pre> <br><p>  Nous devrons cr√©er deux tableaux: un pour toutes les donn√©es, l'autre pour les informations de surcharge sur les fichiers t√©l√©charg√©s (utile en cas de probl√®me et le processus devra √™tre repris apr√®s le chargement de plusieurs fichiers): </p><br><div class="spoiler">  <b class="spoiler_title">Cr√©er des tableaux</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">if (!DBI::dbExistsTable(con, "doodles")) { DBI::dbCreateTable( con = con, name = "doodles", fields = c( "countrycode" = "char(2)", "drawing" = "text", "key_id" = "bigint", "recognized" = "bool", "timestamp" = "timestamp", "word" = "text" ) ) } if (!DBI::dbExistsTable(con, "upload_log")) { DBI::dbCreateTable( con = con, name = "upload_log", fields = c( "id" = "serial", "file_name" = "text UNIQUE", "uploaded" = "bool DEFAULT false" ) ) }</code> </pre> </div></div><br><p>  Le moyen le plus rapide de charger des donn√©es dans la base de donn√©es √©tait de copier directement les fichiers CSV √† l'aide de SQL - la commande <code>COPY OFFSET 2 INTO tablename FROM path USING DELIMITERS ',','\\n','\"' NULL AS '' BEST EFFORT</code> , o√π <code>tablename</code> est le nom de la table et du <code>path</code> est le chemin d'acc√®s au fichier. Plus tard <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">,</a> une autre m√©thode a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©t√© trouv√©e</a> pour augmenter la vitesse: remplacez simplement <code>BEST EFFORT</code> par <code>LOCKED BEST EFFORT</code> . Lorsque vous travaillez avec l'archive, il s'est av√©r√© que l'impl√©mentation de <code>unzip</code> int√©gr√©e dans R ne fonctionne pas correctement avec un certain nombre de fichiers de l'archive, nous avons donc utilis√© <code>unzip</code> syst√®me (en utilisant le <code>getOption("unzip")</code> ). </p><br><div class="spoiler">  <b class="spoiler_title">Fonction d'√©criture dans la base de donn√©es</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#' @title     #' #' @description #'  CSV-  ZIP-       #' #' @param con      ( `MonetDBEmbeddedConnection`). #' @param tablename     . #' @oaram zipfile   ZIP-. #' @oaram filename    ZIP-. #' @param preprocess  ,      . #'     `data` ( `data.table`). #' #' @return `TRUE`. #' upload_file &lt;- function(con, tablename, zipfile, filename, preprocess = NULL) { #   checkmate::assert_class(con, "MonetDBEmbeddedConnection") checkmate::assert_string(tablename) checkmate::assert_string(filename) checkmate::assert_true(DBI::dbExistsTable(con, tablename)) checkmate::assert_file_exists(zipfile, access = "r", extension = "zip") checkmate::assert_function(preprocess, args = c("data"), null.ok = TRUE) #   path &lt;- file.path(tempdir(), filename) unzip(zipfile, files = filename, exdir = tempdir(), junkpaths = TRUE, unzip = getOption("unzip")) on.exit(unlink(file.path(path))) #    if (!is.null(preprocess)) { .data &lt;- data.table::fread(file = path) .data &lt;- preprocess(data = .data) data.table::fwrite(x = .data, file = path, append = FALSE) rm(.data) } #      CSV sql &lt;- sprintf( "COPY OFFSET 2 INTO %s FROM '%s' USING DELIMITERS ',','\\n','\"' NULL AS '' BEST EFFORT", tablename, path ) #     DBI::dbExecute(con, sql) #         DBI::dbExecute(con, sprintf("INSERT INTO upload_log(file_name, uploaded) VALUES('%s', true)", filename)) return(invisible(TRUE)) }</code> </pre> </div></div><br><p>  Si vous devez convertir la table avant d'√©crire dans la base de donn√©es, il suffit de passer la fonction qui convertira les donn√©es en argument de <code>preprocess</code> . </p><br><p>  Code pour le chargement s√©quentiel des donn√©es dans la base de donn√©es: </p><br><div class="spoiler">  <b class="spoiler_title">√âcriture de donn√©es dans la base de donn√©es</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#     files &lt;- unzip(zipfile, list = TRUE)$Name #  ,       to_skip &lt;- DBI::dbGetQuery(con, "SELECT file_name FROM upload_log")[[1L]] files &lt;- setdiff(files, to_skip) if (length(files) &gt; 0L) { #   tictoc::tic() #   pb &lt;- txtProgressBar(min = 0L, max = length(files), style = 3) for (i in seq_along(files)) { upload_file(con = con, tablename = "doodles", zipfile = zipfile, filename = files[i]) setTxtProgressBar(pb, i) } close(pb) #   tictoc::toc() } # 526.141 sec elapsed -  SSD-&gt;SSD # 558.879 sec elapsed -  USB-&gt;SSD</code> </pre> </div></div><br><p>  Le temps de chargement des donn√©es peut varier en fonction des caract√©ristiques de vitesse du lecteur utilis√©.  Dans notre cas, la lecture et l'√©criture sur le m√™me SSD ou depuis une cl√© USB (fichier source) vers un SSD (base de donn√©es) prend moins de 10 minutes. </p><br><p>  Il faut quelques secondes de plus pour cr√©er une colonne avec une √©tiquette de classe enti√®re et une colonne d'index ( <code>ORDERED INDEX</code> ) avec des num√©ros de ligne, qui seront utilis√©es pour s√©lectionner les cas lors de la cr√©ation de lots: </p><br><div class="spoiler">  <b class="spoiler_title">Cr√©er des colonnes et un index suppl√©mentaires</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">message("Generate lables") invisible(DBI::dbExecute(con, "ALTER TABLE doodles ADD label_int int")) invisible(DBI::dbExecute(con, "UPDATE doodles SET label_int = dense_rank() OVER (ORDER BY word) - 1")) message("Generate row numbers") invisible(DBI::dbExecute(con, "ALTER TABLE doodles ADD id serial")) invisible(DBI::dbExecute(con, "CREATE ORDERED INDEX doodles_id_ord_idx ON doodles(id)"))</code> </pre> </div></div><br><p>  Pour r√©soudre le probl√®me de la cr√©ation d'un lot ¬´√† la vol√©e¬ª, nous devions atteindre la vitesse maximale d'extraction de cha√Ænes al√©atoires de la table de <code>doodles</code> .  Pour cela, nous avons utilis√© 3 astuces.  La premi√®re consistait √† r√©duire la dimension du type dans lequel l'ID d'observation est stock√©.  Dans le jeu de donn√©es d'origine, le type <code>bigint</code> est requis pour stocker l'ID, mais le nombre d'observations permet d'ajuster leurs identifiants √©gaux au num√©ro de s√©rie dans le type <code>int</code> .  La recherche est beaucoup plus rapide.  La deuxi√®me astuce consistait √† utiliser <code>ORDERED INDEX</code> - cette d√©cision a √©t√© prise empiriquement, en triant toutes les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">options</a> disponibles.  La troisi√®me consistait √† utiliser des requ√™tes param√©tr√©es.  L'essence de la m√©thode est d'ex√©cuter la commande <code>PREPARE</code> une fois, puis d'utiliser l'expression pr√©par√©e pour cr√©er un tas du m√™me type de requ√™tes, mais en r√©alit√© le gain par rapport au simple <code>SELECT</code> dans le domaine des erreurs statistiques. </p><br><p>  Le processus de remplissage des donn√©es ne consomme pas plus de 450 Mo de RAM.  C'est-√†-dire que l'approche d√©crite vous permet de faire pivoter des ensembles de donn√©es pesant des dizaines de gigaoctets sur presque n'importe quel mat√©riel budg√©taire, y compris certains ordinateurs √† carte unique, ce qui est plut√¥t cool. </p><br><p>  Il reste √† prendre des mesures du taux d'extraction des donn√©es (al√©atoires) et √† √©valuer la mise √† l'√©chelle lors de l'√©chantillonnage de lots de tailles diff√©rentes: </p><br><div class="spoiler">  <b class="spoiler_title">Base de donn√©es de r√©f√©rence</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(ggplot2) set.seed(0) #     con &lt;- DBI::dbConnect(MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR")) #        prep_sql &lt;- function(batch_size) { sql &lt;- sprintf("PREPARE SELECT id FROM doodles WHERE id IN (%s)", paste(rep("?", batch_size), collapse = ",")) res &lt;- DBI::dbSendQuery(con, sql) return(res) } #     fetch_data &lt;- function(rs, batch_size) { ids &lt;- sample(seq_len(n), batch_size) res &lt;- DBI::dbFetch(DBI::dbBind(rs, as.list(ids))) return(res) } #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { rs &lt;- prep_sql(batch_size) bench::mark( fetch_data(rs, batch_size), min_iterations = 50L ) } ) #   cols &lt;- c("batch_size", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # batch_size min median max `itr/sec` total_time n_itr # &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 16 23.6ms 54.02ms 93.43ms 18.8 2.6s 49 # 2 32 38ms 84.83ms 151.55ms 11.4 4.29s 49 # 3 64 63.3ms 175.54ms 248.94ms 5.85 8.54s 50 # 4 128 83.2ms 341.52ms 496.24ms 3.00 16.69s 50 # 5 256 232.8ms 653.21ms 847.44ms 1.58 31.66s 50 # 6 512 784.6ms 1.41s 1.98s 0.740 1.1m 49 # 7 1024 681.7ms 2.72s 4.06s 0.377 2.16m 49 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = 1)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() DBI::dbDisconnect(con, shutdown = TRUE)</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/ys/oj/zq/ysojzqhr14wf8u9k1xsd6ecmlxc.png"><br><h4 id="section2">  2. Pr√©paration des lots </h4><br><p>  L'ensemble du processus de pr√©paration des lots comprend les √©tapes suivantes: </p><br><ol><li>  Analyser plusieurs JSON contenant des vecteurs de ligne avec des coordonn√©es de point. </li><li>  Dessiner des lignes color√©es par les coordonn√©es des points dans l'image de la taille souhait√©e (par exemple, 256x256 ou 128x128). </li><li>  Convertissez les images r√©sultantes en un tenseur. </li></ol><br><p>  Dans le cadre de la concurrence entre les noyaux en Python, le probl√®me a √©t√© r√©solu principalement au moyen d' <strong>OpenCV</strong> .  L'un des analogues les plus simples et les plus √©vidents sur R ressemblera √† ceci: </p><br><div class="spoiler">  <b class="spoiler_title">Impl√©menter la conversion JSON en tensor sur R</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">r_process_json_str &lt;- function(json, line.width = 3, color = TRUE, scale = 1) { #  JSON coords &lt;- jsonlite::fromJSON(json, simplifyMatrix = FALSE) tmp &lt;- tempfile() #       on.exit(unlink(tmp)) png(filename = tmp, width = 256 * scale, height = 256 * scale, pointsize = 1) #   plot.new() #    plot.window(xlim = c(256 * scale, 0), ylim = c(256 * scale, 0)) #   cols &lt;- if (color) rainbow(length(coords)) else "#000000" for (i in seq_along(coords)) { lines(x = coords[[i]][[1]] * scale, y = coords[[i]][[2]] * scale, col = cols[i], lwd = line.width) } dev.off() #    3-   res &lt;- png::readPNG(tmp) return(res) } r_process_json_vector &lt;- function(x, ...) { res &lt;- lapply(x, r_process_json_str, ...) #  3-     4-    res &lt;- do.call(abind::abind, c(res, along = 0)) return(res) }</code> </pre> </div></div><br><p>  Le dessin est effectu√© √† l'aide d'outils R standard et enregistr√© dans un PNG temporaire stock√© dans la RAM (sous Linux, les r√©pertoires R temporaires sont situ√©s dans le <code>/tmp</code> mont√© dans la RAM).  Ensuite, ce fichier est lu sous la forme d'un tableau tridimensionnel avec des nombres compris entre 0 et 1. Ceci est important, car le BMP le plus courant serait lu dans un tableau brut avec des codes de couleur hexad√©cimaux. </p><br><p>  Testez le r√©sultat: </p><br><pre> <code class="plaintext hljs">zip_file &lt;- file.path("data", "train_simplified.zip") csv_file &lt;- "cat.csv" unzip(zip_file, files = csv_file, exdir = tempdir(), junkpaths = TRUE, unzip = getOption("unzip")) tmp_data &lt;- data.table::fread(file.path(tempdir(), csv_file), sep = ",", select = "drawing", nrows = 10000) arr &lt;- r_process_json_str(tmp_data[4, drawing]) dim(arr) # [1] 256 256 3 plot(magick::image_read(arr))</code> </pre> <br><img src="https://habrastorage.org/webt/t3/n2/-u/t3n2-ugr5ilwsygdfsrwd52vspc.png"><br><p>  Le lot lui-m√™me sera form√© comme suit: </p><br><pre> <code class="plaintext hljs">res &lt;- r_process_json_vector(tmp_data[1:4, drawing], scale = 0.5) str(res) # num [1:4, 1:128, 1:128, 1:3] 1 1 1 1 1 1 1 1 1 1 ... # - attr(*, "dimnames")=List of 4 # ..$ : NULL # ..$ : NULL # ..$ : NULL # ..$ : NULL</code> </pre> <br><p>  Cette impl√©mentation ne nous a pas sembl√© optimale, car la formation de gros lots prend ind√©cemment beaucoup de temps, et nous avons d√©cid√© d'utiliser l'exp√©rience de nos coll√®gues utilisant la puissante <strong>biblioth√®que OpenCV</strong> .  √Ä ce moment-l√†, il n'y avait pas de package pr√™t √† l'emploi pour R (il n'y en a m√™me pas maintenant), donc une impl√©mentation minimale des fonctionnalit√©s requises en C ++ a √©t√© √©crite avec int√©gration dans le code R √† l'aide de <strong>Rcpp</strong> . </p><br><p>  Pour r√©soudre le probl√®me, les packages et biblioth√®ques suivants ont √©t√© utilis√©s: </p><br><ol><li>  <strong>OpenCV</strong> pour l'imagerie et le dessin au trait.  Nous avons utilis√© des biblioth√®ques syst√®me et des fichiers d'en-t√™te pr√©install√©s, ainsi qu'une liaison dynamique. </li><li>  <strong>xtensor</strong> pour travailler avec des tableaux et tenseurs multidimensionnels.  Nous avons utilis√© des fichiers d'en-t√™te inclus dans le R-package du m√™me nom.  La biblioth√®que vous permet de travailler avec des tableaux multidimensionnels, √† la fois dans l'ordre des lignes principales et des colonnes. </li><li>  <strong>ndjson</strong> pour analyser JSON.  Cette biblioth√®que est utilis√©e dans <strong>xtensor</strong> automatiquement lorsqu'elle est disponible dans le projet. </li><li>  <strong>RcppThread</strong> pour organiser le traitement multi-thread d'un vecteur de JSON.  Utilis√© les fichiers d'en-t√™te fournis par ce package.  Le package diff√®re du <strong>RcppParallel</strong> plus populaire entre autres par son m√©canisme d'interruption int√©gr√©. </li></ol><br><p>  Il convient de noter que <strong>xtensor</strong> s'est av√©r√© √™tre une trouvaille: en plus d'avoir des fonctionnalit√©s √©tendues et de hautes performances, ses d√©veloppeurs se sont r√©v√©l√©s assez r√©actifs et ont r√©pondu rapidement et en d√©tail aux questions qui se posaient.  Avec leur aide, il a √©t√© possible de mettre en ≈ìuvre la transformation des matrices OpenCV en tenseurs xtensor, ainsi qu'un moyen de combiner des tenseurs d'images en 3 dimensions en un tenseur en 4 dimensions de la dimension correcte (en fait le lot). </p><br><div class="spoiler">  <b class="spoiler_title">Mat√©riel d'√©tude pour Rcpp, xtensor et RcppThread</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://thecoatlessprofessor.com/programming/unofficial-rcpp-api-documentation</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://docs.opencv.org/4.0.1/d7/dbd/group__imgproc.html</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://xtensor.readthedocs.io/en/latest/</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://xtensor.readthedocs.io/en/latest/file_loading.html#loading-json-data-into-xtensor</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://cran.r-project.org/web/packages/RcppThread/vignettes/RcppThread-vignette.pdf</a> </p></div></div><br><p>  Pour compiler des fichiers en utilisant des fichiers syst√®me et une liaison dynamique avec des biblioth√®ques install√©es dans le syst√®me, nous avons utilis√© le m√©canisme de plug-in impl√©ment√© dans le package <strong>Rcpp</strong> .  Pour trouver automatiquement les chemins et les indicateurs, nous avons utilis√© le populaire utilitaire linux <strong>pkg-config</strong> . </p><br><div class="spoiler">  <b class="spoiler_title">Impl√©mentation d'un plugin Rcpp pour l'utilisation de la biblioth√®que OpenCV</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">Rcpp::registerPlugin("opencv", function() { #    pkg_config_name &lt;- c("opencv", "opencv4") #    pkg-config pkg_config_bin &lt;- Sys.which("pkg-config") #      checkmate::assert_file_exists(pkg_config_bin, access = "x") #     OpenCV  pkg-config check &lt;- sapply(pkg_config_name, function(pkg) system(paste(pkg_config_bin, pkg))) if (all(check != 0)) { stop("OpenCV config for the pkg-config not found", call. = FALSE) } pkg_config_name &lt;- pkg_config_name[check == 0] list(env = list( PKG_CXXFLAGS = system(paste(pkg_config_bin, "--cflags", pkg_config_name), intern = TRUE), PKG_LIBS = system(paste(pkg_config_bin, "--libs", pkg_config_name), intern = TRUE) )) })</code> </pre> </div></div><br><p>  √Ä la suite du plugin, les valeurs suivantes seront remplac√©es lors de la compilation: </p><br><pre> <code class="plaintext hljs">Rcpp:::.plugins$opencv()$env # $PKG_CXXFLAGS # [1] "-I/usr/include/opencv" # # $PKG_LIBS # [1] "-lopencv_shape -lopencv_stitching -lopencv_superres -lopencv_videostab -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_datasets -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hdf -lopencv_line_descriptor -lopencv_optflow -lopencv_video -lopencv_plot -lopencv_reg -lopencv_saliency -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_rgbd -lopencv_viz -lopencv_surface_matching -lopencv_text -lopencv_ximgproc -lopencv_calib3d -lopencv_features2d -lopencv_flann -lopencv_xobjdetect -lopencv_objdetect -lopencv_ml -lopencv_xphoto -lopencv_highgui -lopencv_videoio -lopencv_imgcodecs -lopencv_photo -lopencv_imgproc -lopencv_core"</code> </pre> <br><p>  Le code pour impl√©menter l'analyse JSON et cr√©er un lot pour le transfert vers le mod√®le est donn√© sous le spoiler.  Tout d'abord, ajoutez le r√©pertoire local du projet pour rechercher les fichiers d'en-t√™te (n√©cessaires pour ndjson): </p><br><pre> <code class="plaintext hljs">Sys.setenv("PKG_CXXFLAGS" = paste0("-I", normalizePath(file.path("src"))))</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Impl√©mentation de la conversion JSON en tensor en C ++</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">// [[Rcpp::plugins(cpp14)]] // [[Rcpp::plugins(opencv)]] // [[Rcpp::depends(xtensor)]] // [[Rcpp::depends(RcppThread)]] #include &lt;xtensor/xjson.hpp&gt; #include &lt;xtensor/xadapt.hpp&gt; #include &lt;xtensor/xview.hpp&gt; #include &lt;xtensor-r/rtensor.hpp&gt; #include &lt;opencv2/core/core.hpp&gt; #include &lt;opencv2/highgui/highgui.hpp&gt; #include &lt;opencv2/imgproc/imgproc.hpp&gt; #include &lt;Rcpp.h&gt; #include &lt;RcppThread.h&gt; //    using RcppThread::parallelFor; using json = nlohmann::json; using points = xt::xtensor&lt;double,2&gt;; //   JSON   using strokes = std::vector&lt;points&gt;; //   JSON   using xtensor3d = xt::xtensor&lt;double, 3&gt;; //      using xtensor4d = xt::xtensor&lt;double, 4&gt;; //      using rtensor3d = xt::rtensor&lt;double, 3&gt;; //     R using rtensor4d = xt::rtensor&lt;double, 4&gt;; //     R //   //     const static int SIZE = 256; //   // . https://en.wikipedia.org/wiki/Pixel_connectivity#2-dimensional const static int LINE_TYPE = cv::LINE_4; //     const static int LINE_WIDTH = 3; //   // https://docs.opencv.org/3.1.0/da/d54/group__imgproc__transform.html#ga5bb5a1fea74ea38e1a5445ca803ff121 const static int RESIZE_TYPE = cv::INTER_LINEAR; //    OpenCV-   template &lt;typename T, int NCH, typename XT=xt::xtensor&lt;T,3,xt::layout_type::column_major&gt;&gt; XT to_xt(const cv::Mat_&lt;cv::Vec&lt;T, NCH&gt;&gt;&amp; src) { //    std::vector&lt;int&gt; shape = {src.rows, src.cols, NCH}; //      size_t size = src.total() * NCH; //  cv::Mat  xt::xtensor XT res = xt::adapt((T*) src.data, size, xt::no_ownership(), shape); return res; } //  JSON     strokes parse_json(const std::string&amp; x) { auto j = json::parse(x); //      if (!j.is_array()) { throw std::runtime_error("'x' must be JSON array."); } strokes res; res.reserve(j.size()); for (const auto&amp; a: j) { //      2-  if (!a.is_array() || a.size() != 2) { throw std::runtime_error("'x' must include only 2d arrays."); } //    auto p = a.get&lt;points&gt;(); res.push_back(p); } return res; } //   //  HSV cv::Mat ocv_draw_lines(const strokes&amp; x, bool color = true) { //    auto stype = color ? CV_8UC3 : CV_8UC1; //    auto dtype = color ? CV_32FC3 : CV_32FC1; auto bg = color ? cv::Scalar(0, 0, 255) : cv::Scalar(255); auto col = color ? cv::Scalar(0, 255, 220) : cv::Scalar(0); cv::Mat img = cv::Mat(SIZE, SIZE, stype, bg); //   size_t n = x.size(); for (const auto&amp; s: x) { //     size_t n_points = s.shape()[1]; for (size_t i = 0; i &lt; n_points - 1; ++i) { //    cv::Point from(s(0, i), s(1, i)); //    cv::Point to(s(0, i + 1), s(1, i + 1)); //   cv::line(img, from, to, col, LINE_WIDTH, LINE_TYPE); } if (color) { //    col[0] += 180 / n; } } if (color) { //     RGB cv::cvtColor(img, img, cv::COLOR_HSV2RGB); } //     float32   [0, 1] img.convertTo(img, dtype, 1 / 255.0); return img; } //  JSON       xtensor3d process(const std::string&amp; x, double scale = 1.0, bool color = true) { auto p = parse_json(x); auto img = ocv_draw_lines(p, color); if (scale != 1) { cv::Mat out; cv::resize(img, out, cv::Size(), scale, scale, RESIZE_TYPE); cv::swap(img, out); out.release(); } xtensor3d arr = color ? to_xt&lt;double,3&gt;(img) : to_xt&lt;double,1&gt;(img); return arr; } // [[Rcpp::export]] rtensor3d cpp_process_json_str(const std::string&amp; x, double scale = 1.0, bool color = true) { xtensor3d res = process(x, scale, color); return res; } // [[Rcpp::export]] rtensor4d cpp_process_json_vector(const std::vector&lt;std::string&gt;&amp; x, double scale = 1.0, bool color = false) { size_t n = x.size(); size_t dim = floor(SIZE * scale); size_t channels = color ? 3 : 1; xtensor4d res({n, dim, dim, channels}); parallelFor(0, n, [&amp;x, &amp;res, scale, color](int i) { xtensor3d tmp = process(x[i], scale, color); auto view = xt::view(res, i, xt::all(), xt::all(), xt::all()); view = tmp; }); return res; }</code> </pre> </div></div><br><p>  Ce code doit √™tre plac√© dans le <code>src/cv_xt.cpp</code> et compil√© avec la commande <code>Rcpp::sourceCpp(file = "src/cv_xt.cpp", env = .GlobalEnv)</code> ;  vous aurez √©galement besoin de <code>nlohmann/json.hpp</code> du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©f√©rentiel pour fonctionner</a> .  Le code est divis√© en plusieurs fonctions: </p><br><ul><li>  <code>to_xt</code> - une fonction de mod√®le pour convertir la matrice d'image ( <code>cv::Mat</code> ) en le tenseur <code>xt::xtensor</code> ; </li><li>  <code>parse_json</code> - la fonction analyse une cha√Æne JSON, extrait les coordonn√©es des points et les place dans un vecteur; </li><li>  <code>ocv_draw_lines</code> - <code>ocv_draw_lines</code> des lignes multicolores √† partir du vecteur de points re√ßu; </li><li>  <code>process</code> - combine les fonctions ci-dessus et ajoute √©galement la possibilit√© de mettre √† l'√©chelle l'image r√©sultante; </li><li>  <code>cpp_process_json_str</code> - un wrapper sur la fonction de <code>process</code> , qui exporte le r√©sultat vers un objet R (tableau multidimensionnel); </li><li>  <code>cpp_process_json_vector</code> - un wrapper sur la fonction <code>cpp_process_json_str</code> , qui vous permet de traiter un vecteur cha√Æne en mode multi-thread. </li></ul><br><p>  Pour dessiner des lignes multicolores, le mod√®le de couleur HSV a √©t√© utilis√©, suivi d'une conversion en RVB.  Testez le r√©sultat: </p><br><pre> <code class="plaintext hljs">arr &lt;- cpp_process_json_str(tmp_data[4, drawing]) dim(arr) # [1] 256 256 3 plot(magick::image_read(arr))</code> </pre> <br><img src="https://habrastorage.org/webt/23/mm/ro/23mmrob6qhnjgnsaqm-4mno159c.png"><br><div class="spoiler">  <b class="spoiler_title">Comparaison de la vitesse des impl√©mentations en R et C ++</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">res_bench &lt;- bench::mark( r_process_json_str(tmp_data[4, drawing], scale = 0.5), cpp_process_json_str(tmp_data[4, drawing], scale = 0.5), check = FALSE, min_iterations = 100 ) #   cols &lt;- c("expression", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # expression min median max `itr/sec` total_time n_itr # &lt;chr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 r_process_json_str 3.49ms 3.55ms 4.47ms 273. 490ms 134 # 2 cpp_process_json_str 1.94ms 2.02ms 5.32ms 489. 497ms 243 library(ggplot2) #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { .data &lt;- tmp_data[sample(seq_len(.N), batch_size), drawing] bench::mark( r_process_json_vector(.data, scale = 0.5), cpp_process_json_vector(.data, scale = 0.5), min_iterations = 50, check = FALSE ) } ) res_bench[, cols] # expression batch_size min median max `itr/sec` total_time n_itr # &lt;chr&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 r 16 50.61ms 53.34ms 54.82ms 19.1 471.13ms 9 # 2 cpp 16 4.46ms 5.39ms 7.78ms 192. 474.09ms 91 # 3 r 32 105.7ms 109.74ms 212.26ms 7.69 6.5s 50 # 4 cpp 32 7.76ms 10.97ms 15.23ms 95.6 522.78ms 50 # 5 r 64 211.41ms 226.18ms 332.65ms 3.85 12.99s 50 # 6 cpp 64 25.09ms 27.34ms 32.04ms 36.0 1.39s 50 # 7 r 128 534.5ms 627.92ms 659.08ms 1.61 31.03s 50 # 8 cpp 128 56.37ms 58.46ms 66.03ms 16.9 2.95s 50 # 9 r 256 1.15s 1.18s 1.29s 0.851 58.78s 50 # 10 cpp 256 114.97ms 117.39ms 130.09ms 8.45 5.92s 50 # 11 r 512 2.09s 2.15s 2.32s 0.463 1.8m 50 # 12 cpp 512 230.81ms 235.6ms 261.99ms 4.18 11.97s 50 # 13 r 1024 4s 4.22s 4.4s 0.238 3.5m 50 # 14 cpp 1024 410.48ms 431.43ms 462.44ms 2.33 21.45s 50 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = expression, color = expression)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() + scale_color_discrete(name = "", labels = c("cpp", "r")) + theme(legend.position = "bottom")</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/zq/if/sa/zqifsayhpqy-dujaijmn-brk058.png"><br><p>  Comme vous pouvez le voir, l'augmentation de vitesse s'est av√©r√©e tr√®s importante et il n'est pas possible de rattraper le code C ++ en parall√©lisant le code R. </p><br><h4 id="section3">  3. It√©rateurs pour d√©charger des lots de la base de donn√©es </h4><br><p>  R a une r√©putation bien m√©rit√©e en tant que langage de traitement des donn√©es situ√©es dans la RAM, tandis que Python est davantage caract√©ris√© par un traitement it√©ratif des donn√©es, ce qui facilite et simplifie la mise en ≈ìuvre de calculs hors c≈ìur (calculs utilisant la m√©moire externe).  Classiques et pertinents pour nous dans le contexte du probl√®me d√©crit, un exemple de tels calculs est les r√©seaux de neurones profonds, form√©s par la m√©thode de la descente du gradient avec approximation du gradient √† chaque √©tape par une petite portion d'observations, ou un mini-lot. </p><br><p>  Les frameworks d'apprentissage en profondeur √©crits en Python ont des classes sp√©ciales qui impl√©mentent des it√©rateurs bas√©s sur des donn√©es: tableaux, images dans des dossiers, formats binaires, etc. Vous pouvez utiliser des options pr√©d√©finies ou √©crire les v√¥tres pour des t√¢ches sp√©cifiques.  Dans R, nous pouvons tirer pleinement parti de la biblioth√®que Keras Python avec ses diff√©rents backends en utilisant le package du m√™me nom, qui √† son tour fonctionne au-dessus du package <strong>r√©ticul√©</strong> .  Ce dernier m√©rite un grand article s√©par√©;  il vous permet non seulement d'ex√©cuter du code Python √† partir de R, mais fournit √©galement le transfert d'objets entre les sessions R et Python, effectuant automatiquement toutes les conversions de type n√©cessaires. </p><br><p>  Nous nous sommes d√©barrass√©s de la n√©cessit√© de stocker toutes les donn√©es dans la RAM en raison de l'utilisation de MonetDBLite, tout le travail du ¬´r√©seau neuronal¬ª sera effectu√© par le code Python original, nous n'avons qu'√† √©crire un it√©rateur bas√© sur les donn√©es, car il n'y a pas de pr√™t pour une telle situation dans R ou Python.       :              (  R      ).         R  numpy-,     <strong>keras</strong>   . </p><br><p>        : </p><br><div class="spoiler"> <b class="spoiler_title">     </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">train_generator &lt;- function(db_connection = con, samples_index, num_classes = 340, batch_size = 32, scale = 1, color = FALSE, imagenet_preproc = FALSE) { #   checkmate::assert_class(con, "DBIConnection") checkmate::assert_integerish(samples_index) checkmate::assert_count(num_classes) checkmate::assert_count(batch_size) checkmate::assert_number(scale, lower = 0.001, upper = 5) checkmate::assert_flag(color) checkmate::assert_flag(imagenet_preproc) # ,          dt &lt;- data.table::data.table(id = sample(samples_index)) #    dt[, batch := (.I - 1L) %/% batch_size + 1L] #       dt &lt;- dt[, if (.N == batch_size) .SD, keyby = batch] #   i &lt;- 1 #   max_i &lt;- dt[, max(batch)] #     sql &lt;- sprintf( "PREPARE SELECT drawing, label_int FROM doodles WHERE id IN (%s)", paste(rep("?", batch_size), collapse = ",") ) res &lt;- DBI::dbSendQuery(con, sql) #  keras::to_categorical to_categorical &lt;- function(x, num) { n &lt;- length(x) m &lt;- numeric(n * num) m[x * n + seq_len(n)] &lt;- 1 dim(m) &lt;- c(n, num) return(m) } #  function() { #    if (i &gt; max_i) { dt[, id := sample(id)] data.table::setkey(dt, batch) #   i &lt;&lt;- 1 max_i &lt;&lt;- dt[, max(batch)] } # ID    batch_ind &lt;- dt[batch == i, id] #   batch &lt;- DBI::dbFetch(DBI::dbBind(res, as.list(batch_ind)), n = -1) #   i &lt;&lt;- i + 1 #  JSON    batch_x &lt;- cpp_process_json_vector(batch$drawing, scale = scale, color = color) if (imagenet_preproc) { #  c  [0, 1]   [-1, 1] batch_x &lt;- (batch_x - 0.5) * 2 } batch_y &lt;- to_categorical(batch$label_int, num_classes) result &lt;- list(batch_x, batch_y) return(result) } }</code> </pre> </div></div><br><p>         ,   ,  ,  ,  ( <code>scale = 1</code>    256256 , <code>scale = 0.5</code> ‚Äî 128128 ),   ( <code>color = FALSE</code>     ,   <code>color = TRUE</code>     )     ,   imagenet-.    ,       [0, 1]   [-1, 1],        <strong>keras</strong> . </p><br><p>      ,  <code>data.table</code>        <code>samples_index</code>   ,     ,   SQL-     .        <code>keras::to_categorical()</code> .       ,    ,      <code>steps_per_epoch</code>   <code>keras::fit_generator()</code> ,   <code>if (i &gt; max_i)</code>     . </p><br><p>          ,        ,  JSON- ( <code>cpp_process_json_vector()</code> ,   C++)   ,  .   one-hot    ,          ,     .         <code>data.table</code>     ‚Äî   ""  <strong>data.table</strong>       -     R. </p><br><p>       Core i5   : </p><br><div class="spoiler"> <b class="spoiler_title"> </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(Rcpp) library(keras) library(ggplot2) source("utils/rcpp.R") source("utils/keras_iterator.R") con &lt;- DBI::dbConnect(drv = MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR")) ind &lt;- seq_len(DBI::dbGetQuery(con, "SELECT count(*) FROM doodles")[[1L]]) num_classes &lt;- DBI::dbGetQuery(con, "SELECT max(label_int) + 1 FROM doodles")[[1L]] #     train_ind &lt;- sample(ind, floor(length(ind) * 0.995)) #     val_ind &lt;- ind[-train_ind] rm(ind) #   scale &lt;- 0.5 #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { it1 &lt;- train_generator( db_connection = con, samples_index = train_ind, num_classes = num_classes, batch_size = batch_size, scale = scale ) bench::mark( it1(), min_iterations = 50L ) } ) #   cols &lt;- c("batch_size", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # batch_size min median max `itr/sec` total_time n_itr # &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 16 25ms 64.36ms 92.2ms 15.9 3.09s 49 # 2 32 48.4ms 118.13ms 197.24ms 8.17 5.88s 48 # 3 64 69.3ms 117.93ms 181.14ms 8.57 5.83s 50 # 4 128 157.2ms 240.74ms 503.87ms 3.85 12.71s 49 # 5 256 359.3ms 613.52ms 988.73ms 1.54 30.5s 47 # 6 512 884.7ms 1.53s 2.07s 0.674 1.11m 45 # 7 1024 2.7s 3.83s 5.47s 0.261 2.81m 44 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = 1)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() DBI::dbDisconnect(con, shutdown = TRUE)</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/w0/i6/jx/w0i6jxjhgwqs82fbazwxdquqe18.png"><br><p>     ,              (    32 ).       <code>/dev/shm</code> ,     .    ,  <code>/etc/fstab</code> ,     <code>tmpfs /dev/shm tmpfs defaults,size=25g 0 0</code> .     ,   <code>df -h</code> . </p><br><p>       ,       : </p><br><div class="spoiler"> <b class="spoiler_title">   </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">test_generator &lt;- function(dt, batch_size = 32, scale = 1, color = FALSE, imagenet_preproc = FALSE) { #   checkmate::assert_data_table(dt) checkmate::assert_count(batch_size) checkmate::assert_number(scale, lower = 0.001, upper = 5) checkmate::assert_flag(color) checkmate::assert_flag(imagenet_preproc) #    dt[, batch := (.I - 1L) %/% batch_size + 1L] data.table::setkey(dt, batch) i &lt;- 1 max_i &lt;- dt[, max(batch)] #  function() { batch_x &lt;- cpp_process_json_vector(dt[batch == i, drawing], scale = scale, color = color) if (imagenet_preproc) { #  c  [0, 1]   [-1, 1] batch_x &lt;- (batch_x - 0.5) * 2 } result &lt;- list(batch_x) i &lt;&lt;- i + 1 return(result) } }</code> </pre> </div></div><br><h4 id="section4"> 4.    </h4><br><p>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mobilenet v1</a> ,     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> .      <strong>keras</strong> , ,      R.          :       <code>(batch, height, width, 3)</code> ,      .  Python   ,         ,    ( ,    keras- ): </p><br><div class="spoiler"> <b class="spoiler_title"> mobilenet v1</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(keras) top_3_categorical_accuracy &lt;- custom_metric( name = "top_3_categorical_accuracy", metric_fn = function(y_true, y_pred) { metric_top_k_categorical_accuracy(y_true, y_pred, k = 3) } ) layer_sep_conv_bn &lt;- function(object, filters, alpha = 1, depth_multiplier = 1, strides = c(2, 2)) { # NB! depth_multiplier != resolution multiplier # https://github.com/keras-team/keras/issues/10349 layer_depthwise_conv_2d( object = object, kernel_size = c(3, 3), strides = strides, padding = "same", depth_multiplier = depth_multiplier ) %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() %&gt;% layer_conv_2d( filters = filters * alpha, kernel_size = c(1, 1), strides = c(1, 1) ) %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() } get_mobilenet_v1 &lt;- function(input_shape = c(224, 224, 1), num_classes = 340, alpha = 1, depth_multiplier = 1, optimizer = optimizer_adam(lr = 0.002), loss = "categorical_crossentropy", metrics = c("categorical_crossentropy", top_3_categorical_accuracy)) { inputs &lt;- layer_input(shape = input_shape) outputs &lt;- inputs %&gt;% layer_conv_2d(filters = 32, kernel_size = c(3, 3), strides = c(2, 2), padding = "same") %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() %&gt;% layer_sep_conv_bn(filters = 64, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 128, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 128, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 256, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 256, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 1024, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 1024, strides = c(1, 1)) %&gt;% layer_global_average_pooling_2d() %&gt;% layer_dense(units = num_classes) %&gt;% layer_activation_softmax() model &lt;- keras_model( inputs = inputs, outputs = outputs ) model %&gt;% compile( optimizer = optimizer, loss = loss, metrics = metrics ) return(model) }</code> </pre> </div></div><br><p>    .    ,     , ,  .        ,    imagenet-.  ,   .  <code>get_config()</code>          ( <code>base_model_conf$layers</code> ‚Äî  R- ),   <code>from_config()</code>      : </p><br><pre> <code class="plaintext hljs">base_model_conf &lt;- get_config(base_model) base_model_conf$layers[[1]]$config$batch_input_shape[[4]] &lt;- 1L base_model &lt;- from_config(base_model_conf)</code> </pre> <br><p>               <strong>keras</strong>     imagenet-    : </p><br><div class="spoiler"> <b class="spoiler_title">    </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">get_model &lt;- function(name = "mobilenet_v2", input_shape = NULL, weights = "imagenet", pooling = "avg", num_classes = NULL, optimizer = keras::optimizer_adam(lr = 0.002), loss = "categorical_crossentropy", metrics = NULL, color = TRUE, compile = FALSE) { #   checkmate::assert_string(name) checkmate::assert_integerish(input_shape, lower = 1, upper = 256, len = 3) checkmate::assert_count(num_classes) checkmate::assert_flag(color) checkmate::assert_flag(compile) #     keras model_fun &lt;- get0(paste0("application_", name), envir = asNamespace("keras")) #      if (is.null(model_fun)) { stop("Model ", shQuote(name), " not found.", call. = FALSE) } base_model &lt;- model_fun( input_shape = input_shape, include_top = FALSE, weights = weights, pooling = pooling ) #    ,    if (!color) { base_model_conf &lt;- keras::get_config(base_model) base_model_conf$layers[[1]]$config$batch_input_shape[[4]] &lt;- 1L base_model &lt;- keras::from_config(base_model_conf) } predictions &lt;- keras::get_layer(base_model, "global_average_pooling2d_1")$output predictions &lt;- keras::layer_dense(predictions, units = num_classes, activation = "softmax") model &lt;- keras::keras_model( inputs = base_model$input, outputs = predictions ) if (compile) { keras::compile( object = model, optimizer = optimizer, loss = loss, metrics = metrics ) } return(model) }</code> </pre> </div></div><br><p>        .     :    <code>get_weights()</code>        R- ,       ( -       ),         <code>set_weights()</code> .       ,       ,      . </p><br><p>        mobilenet  1  2,   resnet34.         ,   SE-ResNeXt.  ,       ,       (  ). </p><br><h4 id="section5"> 5.   </h4><br><p>             ,    <strong><a href="">docopt</a></strong>  : </p><br><pre> <code class="plaintext hljs">doc &lt;- ' Usage: train_nn.R --help train_nn.R --list-models train_nn.R [options] Options: -h --help Show this message. -l --list-models List available models. -m --model=&lt;model&gt; Neural network model name [default: mobilenet_v2]. -b --batch-size=&lt;size&gt; Batch size [default: 32]. -s --scale-factor=&lt;ratio&gt; Scale factor [default: 0.5]. -c --color Use color lines [default: FALSE]. -d --db-dir=&lt;path&gt; Path to database directory [default: Sys.getenv("db_dir")]. -r --validate-ratio=&lt;ratio&gt; Validate sample ratio [default: 0.995]. -n --n-gpu=&lt;number&gt; Number of GPUs [default: 1]. ' args &lt;- docopt::docopt(doc)</code> </pre> <br><p>  <strong>docopt</strong>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://docopt.org/</a>  R.         <code>Rscript bin/train_nn.R -m resnet50 -c -d /home/andrey/doodle_db</code>  <code>./bin/train_nn.R -m resnet50 -c -d /home/andrey/doodle_db</code> ,   <code>train_nn.R</code>   (     <code>resnet50</code>     128128 ,       <code>/home/andrey/doodle_db</code> ).      ,       .     ,   <code>mobilenet_v2</code>    <strong>keras</strong>  R  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> -   R-  ‚Äî ,  . </p><br><p>                  RStudio (      <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tfruns</a></strong> ).                ,     RStudio. </p><br><h4 id="section6"> 6.   </h4><br><p>                    .        R-    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> . </p><br><p>       ¬´ ¬ª,           .        ,    NVIDIA, CUDA+cuDNN    ‚Äî    ,        <code>tensorflow/tensorflow:1.12.0-gpu</code> ,    R-. </p><br><p>  -  : </p><br><div class="spoiler"> <b class="spoiler_title">Dockerfile</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">FROM tensorflow/tensorflow:1.12.0-gpu MAINTAINER Artem Klevtsov &lt;aaklevtsov@gmail.com&gt; SHELL ["/bin/bash", "-c"] ARG LOCALE="en_US.UTF-8" ARG APT_PKG="libopencv-dev r-base r-base-dev littler" ARG R_BIN_PKG="futile.logger checkmate data.table rcpp rapidjsonr dbi keras jsonlite curl digest remotes" ARG R_SRC_PKG="xtensor RcppThread docopt MonetDBLite" ARG PY_PIP_PKG="keras" ARG DIRS="/db /app /app/data /app/models /app/logs" RUN source /etc/os-release &amp;&amp; \ echo "deb https://cloud.r-project.org/bin/linux/ubuntu ${UBUNTU_CODENAME}-cran35/" &gt; /etc/apt/sources.list.d/cran35.list &amp;&amp; \ apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9 &amp;&amp; \ add-apt-repository -y ppa:marutter/c2d4u3.5 &amp;&amp; \ add-apt-repository -y ppa:timsc/opencv-3.4 &amp;&amp; \ apt-get update &amp;&amp; \ apt-get install -y locales &amp;&amp; \ locale-gen ${LOCALE} &amp;&amp; \ apt-get install -y --no-install-recommends ${APT_PKG} &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/install.r /usr/local/bin/install.r &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/install2.r /usr/local/bin/install2.r &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/installGithub.r /usr/local/bin/installGithub.r &amp;&amp; \ echo 'options(Ncpus = parallel::detectCores())' &gt;&gt; /etc/R/Rprofile.site &amp;&amp; \ echo 'options(repos = c(CRAN = "https://cloud.r-project.org"))' &gt;&gt; /etc/R/Rprofile.site &amp;&amp; \ apt-get install -y $(printf "r-cran-%s " ${R_BIN_PKG}) &amp;&amp; \ install.r ${R_SRC_PKG} &amp;&amp; \ pip install ${PY_PIP_PKG} &amp;&amp; \ mkdir -p ${DIRS} &amp;&amp; \ chmod 777 ${DIRS} &amp;&amp; \ rm -rf /tmp/downloaded_packages/ /tmp/*.rds &amp;&amp; \ rm -rf /var/lib/apt/lists/* COPY utils /app/utils COPY src /app/src COPY tests /app/tests COPY bin/*.R /app/ ENV DBDIR="/db" ENV CUDA_HOME="/usr/local/cuda" ENV PATH="/app:${PATH}" WORKDIR /app VOLUME /db VOLUME /app CMD bash</code> </pre></div></div><br><p>        ;         .       <code>/bin/bash</code>     <code>/etc/os-release</code> .         . </p><br><p>     -,      . ,       ,    ,          : </p><br><div class="spoiler"> <b class="spoiler_title">   </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#!/bin/sh DBDIR=${PWD}/db LOGSDIR=${PWD}/logs MODELDIR=${PWD}/models DATADIR=${PWD}/data ARGS="--runtime=nvidia --rm -v ${DBDIR}:/db -v ${LOGSDIR}:/app/logs -v ${MODELDIR}:/app/models -v ${DATADIR}:/app/data" if [ -z "$1" ]; then CMD="Rscript /app/train_nn.R" elif [ "$1" = "bash" ]; then ARGS="${ARGS} -ti" else CMD="Rscript /app/train_nn.R $@" fi docker run ${ARGS} doodles-tf ${CMD}</code> </pre> </div></div><br><p>   -   ,      <code>train_nn.R</code>    ;     ‚Äî  "bash",         .         : <code>CMD="Rscript /app/train_nn.R $@"</code> . </p><br><p>   ,        ,             ,           . </p><br><h4 id="section7"> 7.   GPU   Google Cloud </h4><br><p>         (.  ,   @Leigh.plt  ODS-).       ,        1 GPU       GPU  .  GoogleCloud ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">    </a> ) -    ,     $300.       4V100  SSD   ,     .     ,       .      K80.       ‚Äî  SSD   c,          <code>dev/shm</code> . </p><br><p>     ,     GPU.     CPU    ,    : </p><br><pre> <code class="plaintext hljs">with(tensorflow::tf$device("/cpu:0"), { model_cpu &lt;- get_model( name = model_name, input_shape = input_shape, weights = weights, metrics =(top_3_categorical_accuracy, compile = FALSE ) })</code> </pre> <br><p>   ( )       GPU,     : </p><br><pre> <code class="plaintext hljs">model &lt;- keras::multi_gpu_model(model_cpu, gpus = n_gpu) keras::compile( object = model, optimizer = keras::optimizer_adam(lr = 0.0004), loss = "categorical_crossentropy", metrics = c(top_3_categorical_accuracy) )</code> </pre> <br><p>      ,  ,   ,        GPU   . </p><br><p>      <strong>tensorboard</strong> ,            : </p><br><div class="spoiler"> <b class="spoiler_title"></b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#     log_file_tmpl &lt;- file.path("logs", sprintf( "%s_%d_%dch_%s.csv", model_name, dim_size, channels, format(Sys.time(), "%Y%m%d%H%M%OS") )) #     model_file_tmpl &lt;- file.path("models", sprintf( "%s_%d_%dch_{epoch:02d}_{val_loss:.2f}.h5", model_name, dim_size, channels )) callbacks_list &lt;- list( keras::callback_csv_logger( filename = log_file_tmpl ), keras::callback_early_stopping( monitor = "val_loss", min_delta = 1e-4, patience = 8, verbose = 1, mode = "min" ), keras::callback_reduce_lr_on_plateau( monitor = "val_loss", factor = 0.5, #  lr  2  patience = 4, verbose = 1, min_delta = 1e-4, mode = "min" ), keras::callback_model_checkpoint( filepath = model_file_tmpl, monitor = "val_loss", save_best_only = FALSE, save_weights_only = FALSE, mode = "min" ) )</code> </pre> </div></div><br><h4 id="section8"> 8.   </h4><br><p>  ,    ,    : </p><br><ul><li>  <strong>keras</strong>          ( <code>lr_finder</code>   <strong>fast.ai</strong> );   ,    R  , , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> ; </li><li>    ,          GPU; </li><li>     ,    imagenet-; </li><li>  one cycle policy  discriminative learning rates (osine annealing     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">skeydan</a> ). </li></ul><br><p>       : </p><br><ul><li>           (   )  .  <strong>data.table</strong>     in-place  ,     ,                   .                  . </li><li>    R     C++    <strong>Rcpp</strong> .    <strong>RcppThread</strong>  <strong>RcppParallel</strong> ,    ,     R   . </li><li>  <strong>Rcpp</strong>      C++,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> .         <strong>xtensor</strong>   CRAN,       ,   R     C++.   ‚Äî        ++  RStudio. </li><li> <strong>docopt</strong>      .       ,  ..  .  RStudio       ,     IDE     . </li><li>               ,      .         . </li><li> Google Cloud ‚Äî      ,     . </li><li>        ,    R  C++,    <strong>bench</strong> ‚Äî    . </li></ul><br><p>       ,          . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr443758/">https://habr.com/ru/post/fr443758/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr443746/index.html">March√© du jeu, tendances et pr√©visions - Excellentes analyses d'App Annie</a></li>
<li><a href="../fr443748/index.html">Pr√©sentation du Tesla Model Y - √† quoi s'attendre et o√π chercher</a></li>
<li><a href="../fr443752/index.html">Kotlin comme l'avenir du d√©veloppement d'applications Android</a></li>
<li><a href="../fr443754/index.html">√Ä propos de la pertinence de Selenium WebDriverWait</a></li>
<li><a href="../fr443756/index.html">Conception de la classe: qu'est-ce qui est bon?</a></li>
<li><a href="../fr443764/index.html">Ce que le cr√©ateur a fum√©: une arme √† feu inhabituelle</a></li>
<li><a href="../fr443766/index.html">Essayer la programmation de contrat C ++ 20 maintenant</a></li>
<li><a href="../fr443768/index.html">Monolith pour des centaines de versions client: comment nous √©crivons et prenons en charge les tests</a></li>
<li><a href="../fr443770/index.html">Conception pilot√©e par domaine: objets de valeur et noyau d'entit√© dans la pratique</a></li>
<li><a href="../fr443774/index.html">Comment la neurobiologie interf√®re dans les √©lections pr√©sidentielles am√©ricaines</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
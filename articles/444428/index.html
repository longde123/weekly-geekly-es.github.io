<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíã üåò ‚õàÔ∏è Mountain Car: resolviendo el desaf√≠o cl√°sico con entrenamiento de refuerzo üèéÔ∏è ü§úüèº üë®‚Äçüëß‚Äçüë¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Como regla general, las modificaciones a los algoritmos que dependen de las caracter√≠sticas espec√≠ficas de una tarea en particular se consideran menos...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mountain Car: resolviendo el desaf√≠o cl√°sico con entrenamiento de refuerzo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/hsespb/blog/444428/">  Como regla general, las modificaciones a los algoritmos que dependen de las caracter√≠sticas espec√≠ficas de una tarea en particular se consideran menos valiosas, ya que son dif√≠ciles de generalizar a una clase m√°s amplia de problemas.  Sin embargo, esto no significa que tales modificaciones no sean necesarias.  Adem√°s, a menudo pueden mejorar significativamente el resultado incluso para problemas cl√°sicos simples, lo cual es muy importante en la aplicaci√≥n pr√°ctica de algoritmos.  Como ejemplo, en esta publicaci√≥n resolver√© el problema del Mountain Car usando entrenamiento de refuerzo y mostrar√© que usando el conocimiento de c√≥mo se organiza la tarea, se puede resolver mucho m√°s r√°pido. <br><br><img src="https://habrastorage.org/webt/xy/ju/ai/xyjuaivxj9j2c5hp2o-2x3cem2y.png"><br><a name="habracut"></a><br><h2>  Sobre mi </h2><br>  Mi nombre es Oleg Svidchenko, ahora estoy estudiando en la Facultad de Ciencias F√≠sicas, Matem√°ticas e Inform√°tica del HSE de San Petersburgo, antes estudi√© en la Universidad de San Petersburgo durante tres a√±os.  Tambi√©n trabajo en JetBrains Research como investigador.  Antes de ingresar a la universidad, estudi√© en el SSC de la Universidad Estatal de Mosc√∫ y me convert√≠ en el ganador de la Olimpiada de Rusia de ni√±os en edad escolar en inform√°tica como parte del equipo de Mosc√∫. <br><br><h2>  Que necesitamos </h2><br>  Si est√° interesado en probar el entrenamiento de refuerzo, el desaf√≠o Mountain Car es excelente para esto.  Hoy necesitamos Python con las <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">bibliotecas</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Gym</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PyTorch</a> instaladas, as√≠ como conocimientos b√°sicos de redes neuronales. <br><br><h2>  Descripci√≥n de la tarea </h2><br>  En un mundo bidimensional, un autom√≥vil debe subir desde el hueco entre dos colinas hasta la cima de la colina derecha.  Es complicado por el hecho de que ella no tiene suficiente potencia del motor para superar la fuerza de la gravedad y entrar all√≠ en el primer intento.  Estamos invitados a entrenar a un agente (en nuestro caso, una red neuronal), que puede, al controlarlo, subir la colina derecha lo m√°s r√°pido posible. <br><br>  El control de la m√°quina se lleva a cabo a trav√©s de la interacci√≥n con el entorno.  Se divide en episodios independientes, y cada episodio se lleva a cabo paso a paso.  En cada paso, el agente recibe los estados y el entorno <i>r</i> del entorno en respuesta a la acci√≥n <i>a</i> .  Adem√°s, a veces el medio tambi√©n puede informar que el episodio ha terminado.  En este problema, <i>s</i> es un par de n√∫meros, el primero de los cuales es la posici√≥n del autom√≥vil en la curva (una coordenada es suficiente, ya que no podemos separarnos de la superficie), y el segundo es su velocidad en la superficie (con un signo).  La recompensa <i>r</i> es un n√∫mero siempre igual a -1 para esta tarea.  De esta manera, alentamos al agente a completar el episodio lo m√°s r√°pido posible.  Solo hay tres acciones posibles: empujar el autom√≥vil hacia la izquierda, no hacer nada y empujar el autom√≥vil hacia la derecha.  Estas acciones corresponden a n√∫meros del 0 al 2. El episodio puede terminar si el autom√≥vil llega a la cima de la colina derecha o si el agente ha dado 200 pasos. <br><br><h2>  Poco de teor√≠a </h2><br>  En Habr√© ya hab√≠a un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo sobre DQN</a> en el que el autor describ√≠a bastante bien toda la teor√≠a necesaria.  Sin embargo, para facilitar la lectura, lo repetir√© aqu√≠ en una forma m√°s formal. <br><br>  La tarea de aprendizaje de refuerzo se define por un conjunto de espacio de estado S, espacio de acci√≥n A, coeficiente <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>g</mi><mi>a</mi><mi>m</mi><mi>m</mi><mi>a</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.237ex" height="1.817ex" viewBox="0 -520.7 3546.5 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-67" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-61" x="730" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6D" x="1260" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6D" x="2138" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-61" x="3017" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>g</mi><mi>a</mi><mi>m</mi><mi>m</mi><mi>a</mi></math></span></span><script type="math/tex" id="MathJax-Element-1"> \ gamma </script>  , las funciones de transici√≥n T y las funciones de recompensa R. En general, la funci√≥n de transici√≥n y la funci√≥n de recompensa pueden ser variables aleatorias, pero ahora consideraremos una versi√≥n m√°s simple en la que se definen de manera √∫nica.  El objetivo es maximizar las recompensas acumulativas. <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mo>=</mo><mn>0</mn></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>T</mi></mrow></msubsup><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mtext>&amp;#xA0;</mtext><mi>g</mi><mi>a</mi><mi>m</mi><mi>m</mi><msup><mi>a</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi></mrow></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="23.676ex" height="3.021ex" viewBox="0 -883.9 10193.7 1300.8" role="img" focusable="false" style="vertical-align: -0.969ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-75" x="719" y="0"></use><g transform="translate(1292,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-54" x="1242" y="488"></use><g transform="translate(878,-308)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-3D" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-30" x="1140" y="0"></use></g></g><g transform="translate(3430,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-72" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-74" x="638" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-63" x="4487" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-64" x="4921" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6F" x="5444" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-74" x="5930" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-67" x="6541" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-61" x="7022" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6D" x="7551" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6D" x="8430" y="0"></use><g transform="translate(9308,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-74" x="748" y="513"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>=</mo><mn>0</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>T</mi></mrow></msubsup><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi></mrow></msub><mtext>&nbsp;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mtext>&nbsp;</mtext><mi>g</mi><mi>a</mi><mi>m</mi><mi>m</mi><msup><mi>a</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-2"> \ sum_ {t = 0} ^ {T} r_ {t} \ cdot \ gamma ^ {t} </script>  , donde t es el n√∫mero de paso en el medio y T es el n√∫mero de pasos en el episodio. <br><br>  Para resolver este problema, definimos la funci√≥n de valor V del estado s como el valor de la recompensa acumulativa m√°xima, siempre que comencemos en el estado s.  Conociendo dicha funci√≥n, podemos resolver el problema simplemente pasando en cada paso a s con el m√°ximo valor posible.  Sin embargo, no todo es tan simple: en la mayor√≠a de los casos, no sabemos qu√© acci√≥n nos llevar√° al estado deseado.  Por lo tanto, agregamos la acci√≥n a como el segundo par√°metro de la funci√≥n.  La funci√≥n resultante se llama funci√≥n Q.  Muestra qu√© recompensa acumulativa m√°xima posible podemos obtener realizando la acci√≥n a en el estado s.  Pero ya podemos usar esta funci√≥n para resolver el problema: estando en estado s, simplemente elegimos un tal que Q (s, a) sea m√°ximo. <br><br>  En la pr√°ctica, no conocemos la funci√≥n Q real, pero podemos aproximarla por varios m√©todos.  Una de esas t√©cnicas es la red Deep Q (DQN).  Su idea es que para cada una de las acciones aproximamos la funci√≥n Q utilizando una red neuronal. <br><br><h2>  El medio ambiente </h2><br>  Ahora vamos a practicar.  Primero, necesitamos aprender a emular el entorno MountainCar.  La biblioteca Gym, que proporciona una gran cantidad de entornos de aprendizaje de refuerzo est√°ndar, nos ayudar√° a hacer frente a esta tarea.  Para crear un entorno, debemos llamar al m√©todo make en el m√≥dulo del gimnasio y pasarle el nombre del entorno deseado como par√°metro: <br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gym env = gym.make(<span class="hljs-string"><span class="hljs-string">"MountainCar-v0"</span></span>)</code> </pre> <br>  La documentaci√≥n detallada se puede encontrar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> , y una descripci√≥n del entorno se puede encontrar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br>  Consideremos con m√°s detalle lo que podemos hacer con el entorno que creamos: <br><br><ul><li>  <code>env.reset()</code> : finaliza el episodio actual y comienza uno nuevo.  Devuelve el estado inicial. </li><li>  <code>env.step(action)</code> : realiza la acci√≥n especificada.  Devuelve un nuevo estado, una recompensa, si el episodio ha finalizado e informaci√≥n adicional que puede usarse para la depuraci√≥n. </li><li>  <code>env.seed(seed)</code> : establece una semilla aleatoria.  Depende de c√≥mo se generar√°n los estados iniciales durante env.reset (). </li><li>  <code>env.render()</code> : muestra el estado actual del entorno. </li></ul><br><h2>  Nos damos cuenta DQN </h2><br>  DQN es un algoritmo que usa una red neuronal para evaluar una funci√≥n Q.  En el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo original,</a> DeepMind defini√≥ la arquitectura est√°ndar para los juegos de Atari utilizando redes neuronales convolucionales.  A diferencia de estos juegos, Mountain Car no usa la imagen como un estado, por lo que tendremos que determinar la arquitectura nosotros mismos. <br><br>  Tomemos, por ejemplo, una arquitectura con dos capas ocultas de 32 neuronas en cada una.  Despu√©s de cada capa oculta, utilizaremos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ReLU</a> como funci√≥n de activaci√≥n.  Dos n√∫meros que describen el estado se alimentan a la entrada de la red neuronal, y en la salida obtenemos una estimaci√≥n de la funci√≥n Q. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ae/jl/mk/aejlmktkosv-jpbne9hqi96enxw.png" alt="Arquitectura de neuronal roja"></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> nn model = nn.Sequential( nn.Linear(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>), nn.ReLU(), nn.Linear(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>), nn.ReLU(), nn.Linear(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) ) target_model = copy.deepcopy(model) <span class="hljs-comment"><span class="hljs-comment">#    def init_weights(layer): if type(layer) == nn.Linear: nn.init.xavier_normal(layer.weight) model.apply(init_weights)</span></span></code> </pre><br>  Como entrenaremos la red neuronal en la GPU, debemos cargar nuestra red all√≠: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     CPU,  ‚Äúcuda‚Äù    ‚Äúcpu‚Äù device = torch.device("cuda") model.to(device) target_model.to(device)</span></span></code> </pre><br>  La variable del dispositivo ser√° global, ya que tambi√©n necesitaremos cargar los datos. <br><br>  Tambi√©n necesitamos definir un optimizador que actualice los pesos del modelo usando el descenso de gradiente.  S√≠, hay muchos m√°s que uno. <br><br><pre> <code class="python hljs">optimizer = optim.Adam(model.parameters(), lr=<span class="hljs-number"><span class="hljs-number">0.00003</span></span>)</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Todos juntos</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> nn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch device = torch.device(<span class="hljs-string"><span class="hljs-string">"cuda"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_new_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model = nn.Sequential( nn.Linear(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>), nn.ReLU(), nn.Linear(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>), nn.ReLU(), nn.Linear(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) ) target_model = copy.deepcopy(model) <span class="hljs-comment"><span class="hljs-comment">#    def init_weights(layer): if type(layer) == nn.Linear: nn.init.xavier_normal(layer.weight) model.apply(init_weights) #   ,     (GPU  CPU) model.to(device) target_model.to(device) #  ,        optimizer = optim.Adam(model.parameters(), lr=0.00003) return model, target_model, optimizer</span></span></code> </pre><br></div></div><br>  Ahora declaramos una funci√≥n que considerar√° la funci√≥n de error, el gradiente a lo largo de ella, y aplicaremos el descenso.  Pero antes de eso, debe descargar los datos del lote a la GPU: <br><br><pre> <code class="python hljs">state, action, reward, next_state, done = batch <span class="hljs-comment"><span class="hljs-comment">#       state = torch.tensor(state).to(device).float() next_state = torch.tensor(next_state).to(device).float() reward = torch.tensor(reward).to(device).float() action = torch.tensor(action).to(device) done = torch.tensor(done).to(device)</span></span></code> </pre><br>  A continuaci√≥n, necesitamos calcular los valores reales de la funci√≥n Q, sin embargo, dado que no los conocemos, los evaluaremos a trav√©s de los valores para el siguiente estado: <br><br><pre> <code class="python hljs">target_q = torch.zeros(reward.size()[<span class="hljs-number"><span class="hljs-number">0</span></span>]).float().to(device) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> torch.no_grad(): <span class="hljs-comment"><span class="hljs-comment">#     Q-function    target_q = target_model(next_state).max(1)[0].view(-1) target_q[done] = 0 target_q = reward + target_q * gamma</span></span></code> </pre><br>  Y la predicci√≥n actual: <br><br><pre> <code class="python hljs">q = model(state).gather(<span class="hljs-number"><span class="hljs-number">1</span></span>, action.unsqueeze(<span class="hljs-number"><span class="hljs-number">1</span></span>))</code> </pre><br>  Usando target_q y q, calculamos la funci√≥n de p√©rdida y actualizamos el modelo: <br><br><pre> <code class="python hljs">loss = F.smooth_l1_loss(q, target_q.unsqueeze(<span class="hljs-number"><span class="hljs-number">1</span></span>)) <span class="hljs-comment"><span class="hljs-comment">#      optimizer.zero_grad() #     loss.backward() #   . ,       for param in model.parameters(): param.grad.data.clamp_(-1, 1) #    optimizer.step()</span></span></code> </pre><br><div class="spoiler">  <b class="spoiler_title">Todos juntos</b> <div class="spoiler_text"><pre> <code class="python hljs">gamma = <span class="hljs-number"><span class="hljs-number">0.99</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(batch, model, target_model, optimizer)</span></span></span><span class="hljs-function">:</span></span> state, action, reward, next_state, done = batch <span class="hljs-comment"><span class="hljs-comment">#       state = torch.tensor(state).to(device).float() next_state = torch.tensor(next_state).to(device).float() reward = torch.tensor(reward).to(device).float() action = torch.tensor(action).to(device) done = torch.tensor(done).to(device) #  ,       target_q = torch.zeros(reward.size()[0]).float().to(device) with torch.no_grad(): #     Q-function    target_q = target_model(next_state).max(1)[0].view(-1) target_q[done] = 0 target_q = reward + target_q * gamma #   q = model(state).gather(1, action.unsqueeze(1)) loss = F.smooth_l1_loss(q, target_q.unsqueeze(1)) #      optimizer.zero_grad() #     loss.backward() #   . ,       for param in model.parameters(): param.grad.data.clamp_(-1, 1) #    optimizer.step()</span></span></code> </pre><br></div></div><br>  Dado que el modelo solo considera la funci√≥n Q, y no realiza acciones, necesitamos determinar la funci√≥n que decidir√° qu√© acciones realizar√° el agente.  Como algoritmo de toma de decisiones, tomamos <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.348ex" height="2.419ex" viewBox="0 -780.1 4886 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-76" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-61" x="735" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-72" x="1265" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-65" x="1716" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-70" x="2183" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-73" x="2686" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-69" x="3156" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6C" x="3501" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6F" x="3800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6E" x="4285" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-3"> \ varepsilon </script>  -pol√≠tica pol√≠tica.  Su idea es que el agente generalmente realiza acciones con avidez, eligiendo el m√°ximo de la funci√≥n Q, pero con probabilidad <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.348ex" height="2.419ex" viewBox="0 -780.1 4886 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-76" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-61" x="735" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-72" x="1265" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-65" x="1716" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-70" x="2183" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-73" x="2686" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-69" x="3156" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6C" x="3501" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6F" x="3800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6E" x="4285" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-4"> \ varepsilon </script>  √©l tomar√° una acci√≥n al azar.  Se necesitan acciones aleatorias para que el algoritmo pueda examinar aquellas acciones que no habr√≠a llevado a cabo guiado solo por una pol√≠tica codiciosa; este proceso se llama exploraci√≥n. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">select_action</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(state, epsilon, model)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> random.random() &lt; epsilon: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> random.randint(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model(torch.tensor(state).to(device).float().unsqueeze(<span class="hljs-number"><span class="hljs-number">0</span></span>))[<span class="hljs-number"><span class="hljs-number">0</span></span>].max(<span class="hljs-number"><span class="hljs-number">0</span></span>)[<span class="hljs-number"><span class="hljs-number">1</span></span>].view(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>).item()</code> </pre><br>  Dado que usamos lotes para entrenar la red neuronal, necesitamos un b√∫fer en el que almacenaremos la experiencia de interactuar con el entorno y desde donde elegiremos lotes: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Memory</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, capacity)</span></span></span><span class="hljs-function">:</span></span> self.capacity = capacity self.memory = [] self.position = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">push</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, element)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""    """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(self.memory) &lt; self.capacity: self.memory.append(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) self.memory[self.position] = element self.position = (self.position + <span class="hljs-number"><span class="hljs-number">1</span></span>) % self.capacity <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sample</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, batch_size)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""    """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> list(zip(*random.sample(self.memory, batch_size))) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__len__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> len(self.memory)</code> </pre><br><h2>  Decisi√≥n ingenua </h2><br>  Primero, declare las constantes que utilizaremos en el proceso de aprendizaje y cree un modelo: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  model   target model target_update = 1000 #  ,      batch_size = 128 #   max_steps = 100001 #  exploration max_epsilon = 0.5 min_epsilon = 0.1 #    memory = Memory(5000) model, target_model, optimizer = create_new_model()</span></span></code> </pre><br>  A pesar del hecho de que ser√≠a l√≥gico dividir el proceso de interacci√≥n en episodios, para describir el proceso de aprendizaje, es m√°s conveniente para nosotros dividirlo en pasos separados, ya que queremos dar un paso de descenso de gradiente despu√©s de cada paso del entorno. <br><br>  Hablemos con m√°s detalle sobre c√≥mo se ve aqu√≠ un paso del aprendizaje.  Suponemos que ahora estamos dando un paso con el n√∫mero de pasos max_steps y el estado actual.  Luego haciendo la acci√≥n con <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.348ex" height="2.419ex" viewBox="0 -780.1 4886 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-76" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-61" x="735" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-72" x="1265" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-65" x="1716" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-70" x="2183" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-73" x="2686" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-69" x="3156" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6C" x="3501" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6F" x="3800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6E" x="4285" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-5"> \ varepsilon </script>  las pol√≠ticas de greedy se ver√≠an as√≠: <br><br><pre> <code class="python hljs">epsilon = max_epsilon - (max_epsilon - min_epsilon)* step / max_steps action = select_action(state, epsilon, model) new_state, reward, done, _ = env.step(action)</code> </pre><br>  Agregue inmediatamente la experiencia adquirida a la memoria y comience un nuevo episodio si el actual ha finalizado: <br><br><pre> <code class="python hljs">memory.push((state, action, reward, new_state, done)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> done: state = env.reset() done = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: state = new_state</code> </pre><br>  Y tomaremos el paso de descenso gradual (si, por supuesto, ya podemos recolectar al menos un lote): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> step &gt; batch_size: fit(memory.sample(batch_size), model, target_model, optimizer)</code> </pre><br>  Ahora queda por actualizar target_model: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> step % target_update == <span class="hljs-number"><span class="hljs-number">0</span></span>: target_model = copy.deepcopy(model)</code> </pre><br>  Sin embargo, tambi√©n nos gustar√≠a seguir el proceso de aprendizaje.  Para hacer esto, jugaremos un episodio adicional despu√©s de cada actualizaci√≥n de target_model con epsilon = 0, almacenando la recompensa total en el b√∫fer rewards_by_target_updates: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> step % target_update == <span class="hljs-number"><span class="hljs-number">0</span></span>: target_model = copy.deepcopy(model) state = env.reset() total_reward = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> done: action = select_action(state, <span class="hljs-number"><span class="hljs-number">0</span></span>, target_model) state, reward, done, _ = env.step(action) total_reward += reward done = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> state = env.reset() rewards_by_target_updates.append(total_reward)</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Todos juntos</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  model   target model target_update = 1000 #  ,      batch_size = 128 #   max_steps = 100001 #  exploration max_epsilon = 0.5 min_epsilon = 0.1 def fit(): #    memory = Memory(5000) model, target_model, optimizer = create_new_model() for step in range(max_steps): #    epsilon = max_epsilon - (max_epsilon - min_epsilon)* step / max_steps action = select_action(state, epsilon, model) new_state, reward, done, _ = env.step(action) #  ,  ,   memory.push((state, action, reward, new_state, done)) if done: state = env.reset() done = False else: state = new_state #  if step &gt; batch_size: fit(memory.sample(batch_size), model, target_model, optimizer) if step % target_update == 0: target_model = copy.deepcopy(model) #Exploitation state = env.reset() total_reward = 0 while not done: action = select_action(state, 0, target_model) state, reward, done, _ = env.step(action) total_reward += reward done = False state = env.reset() rewards_by_target_updates.append(total_reward) return rewards_by_target_updates</span></span></code> </pre><br></div></div><br>  Ejecute este c√≥digo y obtenga algo como este gr√°fico: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e35/952/b37/e35952b375fc831ec4bd405303440509.png" alt="Gr√°fico de referencia en forma de l√≠nea recta y = -200"><br><br><h2>  ¬øQu√© sali√≥ mal? </h2><br>  ¬øEs esto un error?  ¬øEs este el algoritmo incorrecto?  ¬øSon estos malos par√°metros?  En realidad no  De hecho, el problema est√° en la tarea, es decir, en la funci√≥n de la recompensa.  Miremos m√°s de cerca.  En cada paso, nuestro agente recibe una recompensa de -1, y esto sucede hasta que finaliza el episodio.  Tal recompensa motiva al agente a completar el episodio lo m√°s r√°pido posible, pero al mismo tiempo no le dice c√≥mo hacerlo.  Debido a esto, la √∫nica forma de aprender c√≥mo resolver un problema en una formulaci√≥n de este tipo para un agente es resolverlo muchas veces utilizando la exploraci√≥n. <br><br>  Por supuesto, uno podr√≠a intentar usar algoritmos m√°s complejos para estudiar el entorno en lugar del nuestro <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.348ex" height="2.419ex" viewBox="0 -780.1 4886 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-76" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-61" x="735" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-72" x="1265" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-65" x="1716" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-70" x="2183" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-73" x="2686" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-69" x="3156" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6C" x="3501" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6F" x="3800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6E" x="4285" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>v</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-6"> \ varepsilon </script>  -pol√≠ticas pol√≠ticas.  Sin embargo, en primer lugar, debido a su aplicaci√≥n, nuestro modelo se volver√° m√°s complejo, lo que nos gustar√≠a evitar, y en segundo lugar, no el hecho de que funcionar√°n lo suficientemente bien para esta tarea.  En cambio, podemos eliminar la fuente del problema modificando la tarea en s√≠, es decir, cambiando la funci√≥n de recompensa, es decir  aplicando lo que se llama dar forma a la recompensa. <br><br><h2>  Acelerar la convergencia </h2><br>  Nuestro conocimiento intuitivo nos dice que para conducir cuesta arriba necesitas acelerar.  Cuanto mayor sea la velocidad, m√°s cerca estar√° el agente de resolver el problema.  Puede contarle sobre esto, por ejemplo, agregando un m√≥dulo de velocidad con un cierto coeficiente a la recompensa: <pre>  recompensa modificada = recompensa + 10 * abs (nuevo_estado [1]) </pre><br><br>  En consecuencia, una l√≠nea en la funci√≥n encaja <pre>  memory.push ((estado, acci√≥n, recompensa, nuevo_estado, hecho)) </pre>  debe ser reemplazado por <pre>  memory.push ((estado, acci√≥n, recompensa modificada, nuevo_estado, hecho)) </pre>  Ahora veamos el nuevo cuadro (presenta el premio <b>original</b> sin modificaciones): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c19/3c2/925/c193c2925d13ba1977cf525697cba1c2.png" alt="L√≠nea base versus gr√°fico RS"><br>  <i>Aqu√≠ RS es la abreviatura de Reward Shaping.</i> <br><br><h2>  ¬øEs bueno hacer esto? </h2><br>  El progreso es obvio: nuestro agente claramente aprendi√≥ a conducir cuesta arriba, ya que el premio comenz√≥ a diferir de -200.  Solo queda una pregunta: si al cambiar la funci√≥n de la recompensa, tambi√©n cambiamos la tarea en s√≠, ¬øla soluci√≥n al nuevo problema que encontramos ser√° buena para el viejo problema? <br><br>  Para empezar, entendemos lo que significa "bondad" en nuestro caso.  Para resolver el problema, estamos tratando de encontrar la pol√≠tica √≥ptima, una que maximice la recompensa total por el episodio.  En este caso, podemos reemplazar la palabra "bueno" por la palabra "√≥ptimo", porque lo estamos buscando.  Tambi√©n esperamos de manera optimista que tarde o temprano nuestro DQN encuentre la soluci√≥n √≥ptima para el problema modificado y no se quede atascado en un m√°ximo local.  Entonces, la pregunta puede reformularse de la siguiente manera: si al cambiar la funci√≥n de la recompensa, tambi√©n cambiamos el problema en s√≠, ¬øser√° la soluci√≥n √≥ptima para el nuevo problema que encontramos √≥ptimo para el viejo problema? <br><br>  Como resultado, no podemos proporcionar tal garant√≠a en el caso general.  La respuesta depende de c√≥mo cambiamos exactamente la funci√≥n de la recompensa, c√≥mo se organiz√≥ antes y c√≥mo se organiza el entorno en s√≠.  Afortunadamente, hay <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un art√≠culo</a> cuyos autores investigaron c√≥mo el cambio de la funci√≥n de la recompensa afecta la optimizaci√≥n de la soluci√≥n encontrada. <br><br>  Primero, encontraron toda una clase de cambios "seguros" que se basan en el m√©todo potencial: <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>R</mi><mo>&amp;#x2032;</mo></msup><mo>=</mo><mi>R</mi><mo>+</mo><mo stretchy=&quot;false&quot;>(</mo><mtext>&amp;#xA0;</mtext><mi>g</mi><mi>a</mi><mi>m</mi><mi>m</mi><mi>a</mi><mtext>&amp;#xA0;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mtext>&amp;#xA0;</mtext><mi>P</mi><mi>h</mi><mi>i</mi><mo stretchy=&quot;false&quot;>(</mo><mi>n</mi><mi>u</mi><mi>e</mi><mi>v</mi><mi>o</mi><msub><mtext>&amp;#xA0;</mtext><mi>s</mi></msub><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2212;</mo><mtext>&amp;#xA0;</mtext><mi>P</mi><mi>h</mi><mi>i</mi><mo stretchy=&quot;false&quot;>(</mo><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>d</mi><mi>o</mi><mo stretchy=&quot;false&quot;>)</mo><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="58.589ex" height="2.66ex" viewBox="0 -832 25225.7 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-52" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-2032" x="1074" y="513"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-3D" x="1332" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-52" x="2388" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-2B" x="3370" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-28" x="4370" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-67" x="5010" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-61" x="5490" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6D" x="6020" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6D" x="6898" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-61" x="7777" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-63" x="8556" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-64" x="8990" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6F" x="9513" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-74" x="9999" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-50" x="10610" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-68" x="11362" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-69" x="11938" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-28" x="12284" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6E" x="12673" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-75" x="13274" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-65" x="13846" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-76" x="14313" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6F" x="14798" y="0"></use><g transform="translate(15284,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-73" x="353" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-74" x="15966" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-61" x="16327" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-74" x="16857" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-65" x="17218" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-29" x="17685" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-2212" x="18297" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-50" x="19547" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-68" x="20299" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-69" x="20875" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-28" x="21221" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-65" x="21610" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-73" x="22077" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-74" x="22546" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-61" x="22908" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-64" x="23437" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-6F" x="23961" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-29" x="24446" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-29" x="24836" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mo>‚Ä≤</mo></msup><mo>=</mo><mi>R</mi><mo>+</mo><mo stretchy="false">(</mo><mtext>&nbsp;</mtext><mi>g</mi><mi>a</mi><mi>m</mi><mi>m</mi><mi>a</mi><mtext>&nbsp;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mtext>&nbsp;</mtext><mi>P</mi><mi>h</mi><mi>i</mi><mo stretchy="false">(</mo><mi>n</mi><mi>u</mi><mi>e</mi><mi>v</mi><mi>o</mi><msub><mtext>&nbsp;</mtext><mi>s</mi></msub><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo stretchy="false">)</mo><mo>‚àí</mo><mtext>&nbsp;</mtext><mi>P</mi><mi>h</mi><mi>i</mi><mo stretchy="false">(</mo><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>d</mi><mi>o</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-7"> R ‚Äô= R + (\ gamma \ cdot \ Phi (nuevo \ _state) - \ Phi (estado)) </script>  donde <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>P</mi><mi>h</mi><mi>i</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.468ex" height="2.057ex" viewBox="0 -780.1 1923.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-50" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-68" x="1001" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-69" x="1578" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>P</mi><mi>h</mi><mi>i</mi></math></span></span><script type="math/tex" id="MathJax-Element-8"> \ Phi </script>  - potencial, que depende solo del estado.  Para tales funciones, los autores pudieron demostrar que si la soluci√≥n para el nuevo problema es √≥ptima, para el problema anterior tambi√©n es √≥ptima. <br><br>  En segundo lugar, los autores demostraron que para cualquier otro <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>R</mi><mo>&amp;#x2032;</mo></msup><mo>=</mo><mi>R</mi><mo>+</mo><mi>F</mi><mo stretchy=&quot;false&quot;>(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="17.056ex" height="2.66ex" viewBox="0 -832 7343.5 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-52" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-2032" x="1074" y="513"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-3D" x="1332" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-52" x="2388" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-2B" x="3370" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-46" x="4370" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-28" x="5120" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-73" x="5509" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-2C" x="5979" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMATHI-61" x="6424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/hsespb/blog/444428/&amp;usg=ALkJrhimGYh1V-5snW6U1VsMwkbabMFqiQ#MJMAIN-29" x="6953" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mo>‚Ä≤</mo></msup><mo>=</mo><mi>R</mi><mo>+</mo><mi>F</mi><mo stretchy="false">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-9"> R ‚Äô= R + F (s, a) </script>  existe tal problema, la funci√≥n de recompensa R y la soluci√≥n √≥ptima para el problema modificado, que esta soluci√≥n no es √≥ptima para el problema original.  Esto significa que no podemos garantizar la bondad de la soluci√≥n que encontramos si utilizamos un cambio que no se basa en el m√©todo potencial. <br><br>  Por lo tanto, el uso de funciones potenciales para modificar la funci√≥n de recompensa solo puede cambiar la tasa de convergencia del algoritmo, pero no afecta la soluci√≥n final. <br><br><h2>  Acelera la convergencia correctamente </h2><br>  Ahora que sabemos c√≥mo cambiar la recompensa de manera segura, intentemos modificar la tarea nuevamente, utilizando el m√©todo potencial en lugar de la heur√≠stica ingenua: <pre>  recompensa modificada = recompensa + 300 * (gamma * abs (nuevo_estado [1]) - abs (estado [1])) </pre><br>  Veamos el cronograma del premio original: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6ba/a60/5dc/6baa605dc8dd5ad8e7bf154e5dde3c74.png" alt="Gr√°fico que compara la l√≠nea de base, RS y RS con potenciales"><br><br>  Al final result√≥ que, adem√°s de tener garant√≠as te√≥ricas, la modificaci√≥n de la recompensa con la ayuda de funciones potenciales tambi√©n mejor√≥ significativamente el resultado, especialmente en las primeras etapas.  Por supuesto, existe la posibilidad de que sea posible seleccionar hiperpar√°metros m√°s √≥ptimos (semilla aleatoria, gamma y otros coeficientes) para entrenar al agente, sin embargo, la conformaci√≥n de recompensas a√∫n aumenta significativamente la tasa de convergencia del modelo. <br><br><h2>  Ep√≠logo </h2><br>  ¬°Gracias por leer hasta el final!  Espero que hayan disfrutado esta peque√±a excursi√≥n orientada a la pr√°ctica en el aprendizaje reforzado.  Est√° claro que Mountain Car es una tarea de "juguete", sin embargo, como pudimos notar, ense√±arle a un agente a resolver incluso una tarea aparentemente tan simple desde un punto de vista humano puede ser dif√≠cil. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/444428/">https://habr.com/ru/post/444428/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../444418/index.html">Millones de binarios despu√©s. C√≥mo se fortaleci√≥ Linux</a></li>
<li><a href="../444420/index.html">C√≥mo montar dos ruedas para trabajar</a></li>
<li><a href="../444422/index.html">Como lo fue en 2018: impresi√≥n FDM industrial en Top 3D Expo</a></li>
<li><a href="../444424/index.html">AMD Radeon VII: Chip de gama alta (Parte 2)</a></li>
<li><a href="../444426/index.html">Lyft y Uber salen a bolsa p√∫blica. ¬øPor qu√© invertir en Lyft?</a></li>
<li><a href="../444430/index.html">An√°lisis: c√≥mo usar Present Perfect en ingl√©s</a></li>
<li><a href="../444432/index.html">El uso de Linux y software de c√≥digo abierto en nuestra instituci√≥n educativa: ¬øser o no ser?</a></li>
<li><a href="../444434/index.html">¬°Ha llegado el momento de Java 12! Revisi√≥n de los JEP calientes</a></li>
<li><a href="../444436/index.html">¬øQu√© es una botnet Mirai y c√≥mo puedo proteger mis dispositivos?</a></li>
<li><a href="../444438/index.html">Una breve historia del c√≥digo abierto: c√≥mo el software libre luch√≥ con el propietario</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
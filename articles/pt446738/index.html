<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèê üò≠ ü•õ No√ß√µes b√°sicas de processamento de linguagem natural para texto üë®‚Äçüëß üîÄ üëºüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Agora, o processamento de linguagem natural n√£o √© usado, exceto em setores muito conservadores. Na maioria das solu√ß√µes tecnol√≥gicas, o reconhecimento...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>No√ß√µes b√°sicas de processamento de linguagem natural para texto</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/446738/">  Agora, o processamento de linguagem natural n√£o √© usado, exceto em setores muito conservadores.  Na maioria das solu√ß√µes tecnol√≥gicas, o reconhecimento e o processamento de linguagens "humanas" s√£o introduzidos h√° muito tempo: √© por isso que a URA usual com op√ß√µes de resposta codificadas est√° gradualmente se tornando uma coisa do passado, os chatbots est√£o come√ßando a se comunicar de forma mais adequada sem a participa√ß√£o de um operador ativo, os filtros de email funcionam com um estrondo, etc.  Como √© o reconhecimento da fala gravada, ou seja, texto?  Ou melhor, qual ser√° a base das modernas t√©cnicas de reconhecimento e processamento?  A tradu√ß√£o adaptada de hoje responde bem a isso - sob o corte, voc√™ encontrar√° uma longa dist√¢ncia que fechar√° as lacunas no b√°sico da PNL.  Boa leitura! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nw/vz/qn/nwvzqnbpjgc_ndxnjt7eixdynro.jpeg"></div><br><a name="habracut"></a><br><h2>  O que √© processamento de linguagem natural? </h2><br>  Processamento de linguagem natural (doravante denominado PNL) - o processamento de linguagem natural √© uma subse√ß√£o da ci√™ncia da computa√ß√£o e da IA ‚Äã‚Äãdedicada √† maneira como os computadores analisam as linguagens naturais (humanas).  A PNL permite o uso de algoritmos de aprendizado de m√°quina para texto e fala. <br><br>  Por exemplo, podemos usar a PNL para criar sistemas como reconhecimento de fala, generaliza√ß√£o de documentos, tradu√ß√£o autom√°tica, detec√ß√£o de spam, reconhecimento de entidades nomeadas, respostas a perguntas, preenchimento autom√°tico, entrada de texto previsto, etc. <br><br>  Hoje, muitos de n√≥s temos smartphones de reconhecimento de fala - eles usam a PNL para entender nossa fala.  Al√©m disso, muitas pessoas usam laptops com reconhecimento de fala embutido no sistema operacional. <br><br><h2>  Exemplos </h2><br><h3>  Cortana </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ui/aa/hy/uiaahycfbatakz2q9dl0fqfhr-y.png"></div><br><br>  O Windows possui um assistente virtual da Cortana que reconhece a fala.  Com a Cortana, voc√™ pode criar lembretes, abrir aplicativos, enviar cartas, jogar, descobrir o clima etc. <br><br><h3>  Siri </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ew/h7/9p/ewh79pl_rjkufl6seqyih-c_u4c.jpeg"></div><br>  Siri √© assistente do sistema operacional da Apple: iOS, watchOS, macOS, HomePod e tvOS.  Muitas fun√ß√µes tamb√©m funcionam com o controle de voz: ligar / escrever para algu√©m, enviar um e-mail, definir um temporizador, tirar uma foto etc. <br><br><h3>  Gmail </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ec/rw/ii/ecrwii6nml6c6uvxn8vensihku0.gif"></div><br><br>  Um servi√ßo de e-mail conhecido sabe como detectar spam para que n√£o entre na caixa de entrada da sua caixa de entrada. <br><br><h3>  Fluxo de Di√°logo </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mq/vg/iy/mqvgiyi8zv1dwfvwsqj6lvcfzsm.png"></div><br>  Uma plataforma do Google que permite criar bots de PNL.  Por exemplo, voc√™ pode fazer um bot de pedidos de pizza <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">que n√£o precise de uma URA antiquada para aceitar seu pedido</a> . <br><br><hr><br><h2>  Biblioteca Python NLTK </h2><br>  O NLTK (Natural Language Toolkit) √© uma plataforma l√≠der para a cria√ß√£o de programas de PNL em Python.  Possui interfaces f√°ceis de usar para muitos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">grupos de idiomas</a> , al√©m de bibliotecas para processamento de texto para classifica√ß√£o, tokeniza√ß√£o, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">stemming</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">marca√ß√£o</a> , filtragem e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">racioc√≠nio sem√¢ntico</a> .  Bem, e este √© um projeto de c√≥digo aberto gratuito que est√° sendo desenvolvido com a ajuda da comunidade. <br>  Usaremos essa ferramenta para mostrar o b√°sico da PNL.  Para todos os exemplos subseq√ºentes, presumo que o NLTK j√° esteja importado;  isso pode ser feito com o <code>import nltk</code> <br><br><h2>  No√ß√µes b√°sicas de PNL para texto </h2><br>  Neste artigo, abordaremos t√≥picos: <br><br><ol><li>  Tokeniza√ß√£o por ofertas. </li><li>  Tokeniza√ß√£o por palavras. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Lematiza√ß√£o</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">carimbo do</a> texto. </li><li>  Pare de palavras. </li><li>  Express√µes regulares. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Saco de palavras</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TF-IDF</a> . </li></ol><br><h3>  1. Tokeniza√ß√£o por ofertas </h3><br>  Tokeniza√ß√£o (√†s vezes segmenta√ß√£o) de senten√ßas √© o processo de dividir uma linguagem escrita em senten√ßas componentes.  A ideia parece bem simples.  Em ingl√™s e em alguns outros idiomas, podemos isolar uma frase sempre que encontrarmos um determinado sinal de pontua√ß√£o - um ponto. <br><br>  Mas mesmo em ingl√™s essa tarefa n√£o √© trivial, pois o ponto tamb√©m √© usado em abrevia√ß√µes.  A tabela de abreviaturas pode ajudar bastante durante o processamento de texto para evitar extraviar os limites das frases.  Na maioria dos casos, as bibliotecas s√£o usadas para isso, ent√£o voc√™ n√£o precisa se preocupar com detalhes da implementa√ß√£o. <br><br>  <b>Um exemplo:</b> <br><br>  Fa√ßa um texto breve sobre o jogo de tabuleiro de gam√£o: <br><br><pre> <code class="plaintext hljs">Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.</code> </pre> <br>  Para fazer tokeniza√ß√£o de ofertas usando o NLTK, voc√™ pode usar o m√©todo <code>nltk.sent_tokenize</code> <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/39237759c087ac4151b3c06d4e566747.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92859547" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-sentence-tokenization-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-sentence-tokenization-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-sentence-tokenization-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice."</span></td>
      </tr>
      <tr>
        <td id="file-sentence-tokenization-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-sentence-tokenization-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentences</span> <span class="pl-c1">=</span> <span class="pl-s1">nltk</span>.<span class="pl-en">sent_tokenize</span>(<span class="pl-s1">text</span>)</td>
      </tr>
      <tr>
        <td id="file-sentence-tokenization-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-sentence-tokenization-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-k">for</span> <span class="pl-s1">sentence</span> <span class="pl-c1">in</span> <span class="pl-s1">sentences</span>:</td>
      </tr>
      <tr>
        <td id="file-sentence-tokenization-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-sentence-tokenization-py-LC4" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>(<span class="pl-s1">sentence</span>)</td>
      </tr>
      <tr>
        <td id="file-sentence-tokenization-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-sentence-tokenization-py-LC5" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>()</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">sentence tokenization.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Na sa√≠da, temos 3 frases separadas: <br><br><pre> <code class="plaintext hljs">Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.</code> </pre> <br><h3>  2. Tokeniza√ß√£o de acordo com as palavras </h3><br>  Tokeniza√ß√£o (√†s vezes segmenta√ß√£o) de acordo com as palavras √© o processo de dividir senten√ßas em palavras componentes.  Em ingl√™s e em muitos outros idiomas que usam uma ou outra vers√£o do alfabeto latino, um espa√ßo √© um bom separador de palavras. <br><br>  No entanto, podem surgir problemas se usarmos apenas um espa√ßo - em ingl√™s, os substantivos compostos s√£o escritos de maneira diferente e √†s vezes separados por espa√ßos.  E aqui as bibliotecas nos ajudam novamente. <br><br>  <b>Um exemplo:</b> <br><br>  Vamos pegar as frases do exemplo anterior e aplicar o m√©todo <code>nltk.word_tokenize</code> a elas <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/7befd293c570afd70158e954270fc98d.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92859647" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-word-tokenization-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-word-tokenization-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-word-tokenization-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">for</span> <span class="pl-s1">sentence</span> <span class="pl-c1">in</span> <span class="pl-s1">sentences</span>:</td>
      </tr>
      <tr>
        <td id="file-word-tokenization-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-word-tokenization-py-LC2" class="blob-code blob-code-inner js-file-line">    <span class="pl-s1">words</span> <span class="pl-c1">=</span> <span class="pl-s1">nltk</span>.<span class="pl-en">word_tokenize</span>(<span class="pl-s1">sentence</span>)</td>
      </tr>
      <tr>
        <td id="file-word-tokenization-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-word-tokenization-py-LC3" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>(<span class="pl-s1">words</span>)</td>
      </tr>
      <tr>
        <td id="file-word-tokenization-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-word-tokenization-py-LC4" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>()</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">word tokenization.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclus√£o: <br><br><pre> <code class="plaintext hljs">['Backgammon', 'is', 'one', 'of', 'the', 'oldest', 'known', 'board', 'games', '.'] ['Its', 'history', 'can', 'be', 'traced', 'back', 'nearly', '5,000', 'years', 'to', 'archeological', 'discoveries', 'in', 'the', 'Middle', 'East', '.'] ['It', 'is', 'a', 'two', 'player', 'game', 'where', 'each', 'player', 'has', 'fifteen', 'checkers', 'which', 'move', 'between', 'twenty-four', 'points', 'according', 'to', 'the', 'roll', 'of', 'two', 'dice', '.']</code> </pre> <br><h3>  3. Lematiza√ß√£o e carimbo do texto </h3><br>  Geralmente, os textos cont√™m diferentes formas gramaticais da mesma palavra, e tamb√©m podem ocorrer palavras de uma raiz.  A lematiza√ß√£o e a deriva√ß√£o visam trazer todas as formas de palavras que ocorrem para uma √∫nica forma de vocabul√°rio normal. <br><br>  <b>Exemplos:</b> <br><br>  Trazendo diferentes formas de palavras para um: <br><br><pre> <code class="plaintext hljs">dog, dogs, dog's, dogs' =&gt; dog</code> </pre> <br>  O mesmo, mas com refer√™ncia a toda a frase: <br><br><pre> <code class="plaintext hljs">the boy's dogs are different sizes =&gt; the boy dog be differ size</code> </pre> <br>  Lematiza√ß√£o e stemming s√£o casos especiais de normaliza√ß√£o e diferem. <br><br>  O stemming √© um processo heur√≠stico grosseiro que corta o ‚Äúexcesso‚Äù da raiz das palavras, geralmente isso leva √† perda de sufixos de constru√ß√£o de palavras. <br><br>  A lematiza√ß√£o √© um processo mais sutil que utiliza an√°lise morfol√≥gica e de vocabul√°rio para finalmente trazer a palavra para sua forma can√¥nica - o lema. <br><br>  A diferen√ßa √© que o stemmer (uma implementa√ß√£o espec√≠fica do algoritmo stemming - coment√°rio do tradutor) opera sem conhecer o contexto e, portanto, n√£o entende a diferen√ßa entre palavras que t√™m significados diferentes, dependendo da parte da fala.  No entanto, os Stemmers t√™m suas pr√≥prias vantagens: s√£o mais f√°ceis de implementar e trabalham mais rapidamente.  Al√©m disso, menor "precis√£o" pode n√£o ser importante em alguns casos. <br><br>  <b>Exemplos:</b> <br><br><ol><li>  A palavra bom √© um lema para a palavra melhor.  O Stemmer n√£o ver√° essa conex√£o, pois aqui voc√™ precisa consultar o dicion√°rio. </li><li>  O jogo de palavras √© a forma b√°sica do jogo de palavras.  Aqui, tanto a stemming quanto a lematiza√ß√£o ir√£o lidar. </li><li>  A palavra reuni√£o pode ser uma forma normal de um substantivo ou uma forma do verbo, dependendo do contexto.  Ao contr√°rio do stemming, a lematiza√ß√£o tentar√° escolher o lema certo com base no contexto. </li></ol><br>  Agora que sabemos qual √© a diferen√ßa, vejamos um exemplo: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/8c69db03e92337c9bc9a612361c9bcfb.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92909693" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-stemming-vs-lemmatization-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-stemming-vs-lemmatization-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-stemming-vs-lemmatization-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">nltk</span>.<span class="pl-s1">stem</span> <span class="pl-k">import</span> <span class="pl-v">PorterStemmer</span>, <span class="pl-v">WordNetLemmatizer</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-stemming-vs-lemmatization-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">nltk</span>.<span class="pl-s1">corpus</span> <span class="pl-k">import</span> <span class="pl-s1">wordnet</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-stemming-vs-lemmatization-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-stemming-vs-lemmatization-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-k">def</span> <span class="pl-en">compare_stemmer_and_lemmatizer</span>(<span class="pl-s1">stemmer</span>, <span class="pl-s1">lemmatizer</span>, <span class="pl-s1">word</span>, <span class="pl-s1">pos</span>):</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-stemming-vs-lemmatization-py-LC5" class="blob-code blob-code-inner js-file-line">    <span class="pl-s">"""</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-stemming-vs-lemmatization-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-s">    Print the results of stemmind and lemmitization using the passed stemmer, lemmatizer, word and pos (part of speech)</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-stemming-vs-lemmatization-py-LC7" class="blob-code blob-code-inner js-file-line"><span class="pl-s">    """</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-stemming-vs-lemmatization-py-LC8" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>(<span class="pl-s">"Stemmer:"</span>, <span class="pl-s1">stemmer</span>.<span class="pl-en">stem</span>(<span class="pl-s1">word</span>))</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-stemming-vs-lemmatization-py-LC9" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>(<span class="pl-s">"Lemmatizer:"</span>, <span class="pl-s1">lemmatizer</span>.<span class="pl-en">lemmatize</span>(<span class="pl-s1">word</span>, <span class="pl-s1">pos</span>))</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-stemming-vs-lemmatization-py-LC10" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>()</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L11" class="blob-num js-line-number" data-line-number="11"></td>
        <td id="file-stemming-vs-lemmatization-py-LC11" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L12" class="blob-num js-line-number" data-line-number="12"></td>
        <td id="file-stemming-vs-lemmatization-py-LC12" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">lemmatizer</span> <span class="pl-c1">=</span> <span class="pl-v">WordNetLemmatizer</span>()</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L13" class="blob-num js-line-number" data-line-number="13"></td>
        <td id="file-stemming-vs-lemmatization-py-LC13" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">stemmer</span> <span class="pl-c1">=</span> <span class="pl-v">PorterStemmer</span>()</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L14" class="blob-num js-line-number" data-line-number="14"></td>
        <td id="file-stemming-vs-lemmatization-py-LC14" class="blob-code blob-code-inner js-file-line"><span class="pl-en">compare_stemmer_and_lemmatizer</span>(<span class="pl-s1">stemmer</span>, <span class="pl-s1">lemmatizer</span>, <span class="pl-s1">word</span> <span class="pl-c1">=</span> <span class="pl-s">"seen"</span>, <span class="pl-s1">pos</span> <span class="pl-c1">=</span> <span class="pl-s1">wordnet</span>.<span class="pl-v">VERB</span>)</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L15" class="blob-num js-line-number" data-line-number="15"></td>
        <td id="file-stemming-vs-lemmatization-py-LC15" class="blob-code blob-code-inner js-file-line"><span class="pl-en">compare_stemmer_and_lemmatizer</span>(<span class="pl-s1">stemmer</span>, <span class="pl-s1">lemmatizer</span>, <span class="pl-s1">word</span> <span class="pl-c1">=</span> <span class="pl-s">"drove"</span>, <span class="pl-s1">pos</span> <span class="pl-c1">=</span> <span class="pl-s1">wordnet</span>.<span class="pl-v">VERB</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">stemming vs lemmatization.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclus√£o: <br><br><pre> <code class="plaintext hljs">Stemmer: seen Lemmatizer: see Stemmer: drove Lemmatizer: drive</code> </pre> <br><h3>  4. Pare de palavras </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xr/fq/ju/xrfqju0nbugayjd8cnkvlcbiuwa.png"></div><br><br>  Palavras de parada s√£o aquelas que s√£o jogadas fora do texto antes / ap√≥s o processamento do texto.  Quando aplicamos o aprendizado de m√°quina aos textos, essas palavras podem adicionar muito ru√≠do, portanto, voc√™ precisa se livrar de palavras irrelevantes. <br><br>  As palavras de parada s√£o geralmente entendidas por artigos, interjei√ß√µes, uni√µes etc., que n√£o carregam uma carga sem√¢ntica.  Deve-se entender que n√£o existe uma lista universal de palavras de parada, tudo depende do caso em particular. <br><br>  O NLTK possui uma lista predefinida de palavras de parada.  Antes do primeiro uso, voc√™ precisar√° fazer o download: <code>nltk.download(‚Äústopwords‚Äù)</code> .  Ap√≥s o download, voc√™ pode importar o pacote <code>stopwords</code> e examinar as pr√≥prias palavras: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/7d2e8f81219656f6d2e82933c6994cfe.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92916250" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-stop-words-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-stop-words-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-stop-words-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">nltk</span>.<span class="pl-s1">corpus</span> <span class="pl-k">import</span> <span class="pl-s1">stopwords</span></td>
      </tr>
      <tr>
        <td id="file-stop-words-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-stop-words-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">stopwords</span>.<span class="pl-en">words</span>(<span class="pl-s">"english"</span>))</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">stop words.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclus√£o: <br><br><pre> <code class="plaintext hljs">['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself', 'it', "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn', "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't"]</code> </pre> <br>  Considere como voc√™ pode remover palavras de parada de uma frase: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/b1c69457cc0d8eab7b3661533725485a.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92916498" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-stop-words-example-1-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-stop-words-example-1-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-stop-words-example-1-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">stop_words</span> <span class="pl-c1">=</span> <span class="pl-en">set</span>(<span class="pl-s1">stopwords</span>.<span class="pl-en">words</span>(<span class="pl-s">"english"</span>))</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-stop-words-example-1-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentence</span> <span class="pl-c1">=</span> <span class="pl-s">"Backgammon is one of the oldest known board games."</span></td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-stop-words-example-1-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-stop-words-example-1-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">words</span> <span class="pl-c1">=</span> <span class="pl-s1">nltk</span>.<span class="pl-en">word_tokenize</span>(<span class="pl-s1">sentence</span>)</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-stop-words-example-1-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">without_stop_words</span> <span class="pl-c1">=</span> [<span class="pl-s1">word</span> <span class="pl-k">for</span> <span class="pl-s1">word</span> <span class="pl-c1">in</span> <span class="pl-s1">words</span> <span class="pl-k">if</span> <span class="pl-c1">not</span> <span class="pl-s1">word</span> <span class="pl-c1">in</span> <span class="pl-s1">stop_words</span>]</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-stop-words-example-1-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">without_stop_words</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">stop words example 1.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclus√£o: <br><br><pre> <code class="plaintext hljs">['Backgammon', 'one', 'oldest', 'known', 'board', 'games', '.']</code> </pre> <br>  Se voc√™ n√£o estiver familiarizado com a compreens√£o de listas, poder√° descobrir mais <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> .  Aqui est√° outra maneira de obter o mesmo resultado: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/bbfab6573e886bd122aba972048d54cb.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92916520" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-stop-words-example-2-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-stop-words-example-2-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-stop-words-example-2-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">stop_words</span> <span class="pl-c1">=</span> <span class="pl-en">set</span>(<span class="pl-s1">stopwords</span>.<span class="pl-en">words</span>(<span class="pl-s">"english"</span>))</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-stop-words-example-2-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentence</span> <span class="pl-c1">=</span> <span class="pl-s">"Backgammon is one of the oldest known board games."</span></td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-stop-words-example-2-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-stop-words-example-2-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">words</span> <span class="pl-c1">=</span> <span class="pl-s1">nltk</span>.<span class="pl-en">word_tokenize</span>(<span class="pl-s1">sentence</span>)</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-stop-words-example-2-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">without_stop_words</span> <span class="pl-c1">=</span> []</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-stop-words-example-2-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-k">for</span> <span class="pl-s1">word</span> <span class="pl-c1">in</span> <span class="pl-s1">words</span>:</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-stop-words-example-2-py-LC7" class="blob-code blob-code-inner js-file-line">    <span class="pl-k">if</span> <span class="pl-s1">word</span> <span class="pl-c1">not</span> <span class="pl-c1">in</span> <span class="pl-s1">stop_words</span>:</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-stop-words-example-2-py-LC8" class="blob-code blob-code-inner js-file-line">        <span class="pl-s1">without_stop_words</span>.<span class="pl-en">append</span>(<span class="pl-s1">word</span>)</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-stop-words-example-2-py-LC9" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-stop-words-example-2-py-LC10" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">without_stop_words</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">stop words example 2.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  No entanto, lembre-se de que a compreens√£o da lista √© mais r√°pida porque √© otimizada - o int√©rprete revela um padr√£o preditivo durante o loop. <br><br>  Voc√™ pode perguntar por que convertemos a lista para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">muitos</a> .  Um conjunto √© um tipo de dados abstrato que pode armazenar valores exclusivos em uma ordem indefinida.  A pesquisa por conjunto √© muito mais r√°pida do que a pesquisa em uma lista.  Para um pequeno n√∫mero de palavras, isso n√£o importa, mas se estamos falando de um grande n√∫mero de palavras, √© altamente recomend√°vel usar conjuntos.  Se voc√™ quiser saber um pouco mais sobre o tempo necess√°rio para executar v√°rias opera√ß√µes, veja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">esta maravilhosa folha de dicas</a> . <br><br><h3>  5. Express√µes regulares. </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hn/mm/jx/hnmmjxjubpvt7p1uc-lv-t-auhi.jpeg"></div><br>  Uma express√£o regular (regex, regexp, regex) √© uma sequ√™ncia de caracteres que define um padr√£o de pesquisa.  Por exemplo: <br><br><ul><li>  .  - qualquer caractere, exceto o avan√ßo de linha; </li><li>  \ w √© uma palavra; </li><li>  \ d - um d√≠gito; </li><li>  \ s - um espa√ßo; </li><li>  \ W √© uma N√ÉO-Palavra; </li><li>  \ D - um n√£o d√≠gito; </li><li>  \ S - um n√£o-espa√ßo; </li><li>  [abc] - encontra qualquer um dos caracteres especificados que correspondem a qualquer um de a, b ou c; </li><li>  [^ abc] - encontra qualquer caractere, exceto os especificados; </li><li>  [ag] - localiza um caractere no intervalo de a a g. </li></ul><br>  Trecho da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Python</a> : <br><blockquote>  Express√µes regulares usam a barra invertida <code>(\)</code> para indicar formas especiais ou para permitir o uso de caracteres especiais.  Isso contradiz o uso da barra invertida no Python: por exemplo, para denotar literalmente a barra invertida, voc√™ deve escrever <code>'\\\\'</code> como um padr√£o de pesquisa, porque a express√£o regular deve se parecer com <code>\\</code> , onde cada barra invertida deve ser escapada. <br><br>  A solu√ß√£o √© usar a nota√ß√£o de cadeia bruta para padr√µes de pesquisa;  as barras invertidas n√£o ser√£o processadas especialmente se usadas com o prefixo <code>'r'</code> .  Assim, <code>r‚Äù\n‚Äù</code> √© uma sequ√™ncia com dois caracteres <code>('\'  'n')</code> e <code>‚Äú\n‚Äù</code> √© uma sequ√™ncia com um caractere (avan√ßo de linha). <br></blockquote>  Podemos usar regulares para filtrar ainda mais nosso texto.  Por exemplo, voc√™ pode remover todos os caracteres que n√£o s√£o palavras.  Em muitos casos, a pontua√ß√£o n√£o √© necess√°ria e √© f√°cil de remover com a ajuda de regulares. <br><br>  O m√≥dulo <b>re</b> no Python representa opera√ß√µes de express√£o regular.  Podemos usar a fun√ß√£o <b>re.sub</b> para substituir tudo o que se ajusta ao padr√£o de pesquisa pela string especificada.  Portanto, voc√™ pode substituir todas as n√£o palavras por espa√ßos: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/a9a29588061a8c9bb8aeb28140a69f89.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92925716" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-regex-substitute-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-regex-substitute-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-regex-substitute-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> <span class="pl-s1">re</span></td>
      </tr>
      <tr>
        <td id="file-regex-substitute-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-regex-substitute-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentence</span> <span class="pl-c1">=</span> <span class="pl-s">"The development of snowboarding was inspired by skateboarding, sledding, surfing and skiing."</span></td>
      </tr>
      <tr>
        <td id="file-regex-substitute-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-regex-substitute-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">pattern</span> <span class="pl-c1">=</span> <span class="pl-s">r"[^\w]"</span></td>
      </tr>
      <tr>
        <td id="file-regex-substitute-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-regex-substitute-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">re</span>.<span class="pl-en">sub</span>(<span class="pl-s1">pattern</span>, <span class="pl-s">" "</span>, <span class="pl-s1">sentence</span>))</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">regex substitute.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclus√£o: <br><br><pre> <code class="plaintext hljs">'The development of snowboarding was inspired by skateboarding sledding surfing and skiing '</code> </pre> <br>  Os regulares s√£o uma ferramenta poderosa que pode ser usada para criar padr√µes muito mais complexos.  Se voc√™ quiser saber mais sobre express√µes regulares, recomendo esses 2 aplicativos da web: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">regex</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">regex101</a> . <br><br><h3>  6. Saco de palavras </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/oh/va/sp/ohvaspwwyxr6mjgfz1w4vq8znku.png"></div><br>  Os algoritmos de aprendizado de m√°quina n√£o podem trabalhar diretamente com o texto bruto, portanto, voc√™ precisa converter o texto em conjuntos de n√∫meros (vetores).  Isso √© chamado de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">extra√ß√£o de recurso</a> . <br><br>  Um saco de palavras √© uma t√©cnica popular e simples de extra√ß√£o de recursos usada ao trabalhar com texto.  Descreve as ocorr√™ncias de cada palavra no texto. <br><br>  Para usar o modelo, precisamos: <br><br><ol><li>  Defina um dicion√°rio de palavras conhecidas (tokens). </li><li>  Escolha o grau de presen√ßa de palavras famosas. </li></ol><br>  Qualquer informa√ß√£o sobre a ordem ou estrutura das palavras √© ignorada.  √â por isso que √© chamado de SACO de palavras.  Este modelo tenta entender se uma palavra familiar aparece em um documento, mas n√£o sabe onde exatamente ocorre. <br><br>  A intui√ß√£o sugere que <b>documentos</b> <b>semelhantes</b> tenham <b>conte√∫do semelhante</b> .  Al√©m disso, gra√ßas ao conte√∫do, podemos aprender algo sobre o significado do documento. <br><br>  <b>Um exemplo:</b> <br>  Considere as etapas para criar este modelo.  Usamos apenas quatro frases para entender como o modelo funciona.  Na vida real, voc√™ encontrar√° mais dados. <br><br><h4>  1. Baixar dados </h4><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tr/xz/w9/trxzw9m1s7psallg0ulf6wepnsu.png"></div><br>  Imagine que esses s√£o nossos dados e queremos carreg√°-los como uma matriz: <br><br><pre> <code class="plaintext hljs">I like this movie, it's funny. I hate this movie. This was awesome! I like it. Nice one. I love it.</code> </pre> <br>  Para fazer isso, basta ler o arquivo e dividir por linha: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/15abcc02fefb2782ba78ac695d4dda59.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist93035402" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-read-the-movie-reviews-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-read-the-movie-reviews-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-read-the-movie-reviews-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">with</span> <span class="pl-en">open</span>(<span class="pl-s">"simple movie reviews.txt"</span>, <span class="pl-s">"r"</span>) <span class="pl-k">as</span> <span class="pl-s1">file</span>:</td>
      </tr>
      <tr>
        <td id="file-read-the-movie-reviews-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-read-the-movie-reviews-py-LC2" class="blob-code blob-code-inner js-file-line">    <span class="pl-s1">documents</span> <span class="pl-c1">=</span> <span class="pl-s1">file</span>.<span class="pl-en">read</span>().<span class="pl-en">splitlines</span>()</td>
      </tr>
      <tr>
        <td id="file-read-the-movie-reviews-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-read-the-movie-reviews-py-LC3" class="blob-code blob-code-inner js-file-line">    </td>
      </tr>
      <tr>
        <td id="file-read-the-movie-reviews-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-read-the-movie-reviews-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">documents</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">read the movie reviews.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclus√£o: <br><br><pre> <code class="plaintext hljs">["I like this movie, it's funny.", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']</code> </pre> <br><br><h4>  2. Defina um dicion√°rio </h4><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lk/vg/7p/lkvg7pwbgfcd130zn66zx_qhjxq.png"></div><br>  Coletaremos todas as palavras exclusivas de 4 frases carregadas, ignorando mai√∫sculas e min√∫sculas, pontua√ß√£o e tokens de um caractere.  Este ser√° o nosso dicion√°rio (palavras famosas). <br><br>  Para criar um dicion√°rio, voc√™ pode usar a classe CountVectorizer da biblioteca sklearn.  V√° para o pr√≥ximo passo. <br><br><h4>  3. Crie vetores de documentos </h4><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4q/jj/hh/4qjjhhlyqga--r6eh9kkery5jsy.png"></div><br>  Em seguida, precisamos avaliar as palavras no documento.  Nesta etapa, nosso objetivo √© transformar o texto bruto em um conjunto de n√∫meros.  Depois disso, usamos esses conjuntos como entrada para o modelo de aprendizado de m√°quina.  O m√©todo de pontua√ß√£o mais simples √© observar a presen√ßa de palavras, ou seja, colocar 1 se houver uma palavra e 0 se estiver ausente. <br><br>  Agora podemos criar um conjunto de palavras usando a classe CountVectorizer mencionada acima. <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/155e97ad22862a340d941a63e43295d9.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist93036006" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-simple-bag-of-words-example-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-simple-bag-of-words-example-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-simple-bag-of-words-example-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Import the libraries we need</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-simple-bag-of-words-example-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">sklearn</span>.<span class="pl-s1">feature_extraction</span>.<span class="pl-s1">text</span> <span class="pl-k">import</span> <span class="pl-v">CountVectorizer</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-simple-bag-of-words-example-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> <span class="pl-s1">pandas</span> <span class="pl-k">as</span> <span class="pl-s1">pd</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-simple-bag-of-words-example-py-LC4" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-simple-bag-of-words-example-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Step 2. Design the Vocabulary</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-simple-bag-of-words-example-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># The default token pattern removes tokens of a single character. That's why we don't have the "I" and "s" tokens in the output</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-simple-bag-of-words-example-py-LC7" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">count_vectorizer</span> <span class="pl-c1">=</span> <span class="pl-v">CountVectorizer</span>()</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-simple-bag-of-words-example-py-LC8" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-simple-bag-of-words-example-py-LC9" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Step 3. Create the Bag-of-Words Model</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-simple-bag-of-words-example-py-LC10" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">bag_of_words</span> <span class="pl-c1">=</span> <span class="pl-s1">count_vectorizer</span>.<span class="pl-en">fit_transform</span>(<span class="pl-s1">documents</span>)</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L11" class="blob-num js-line-number" data-line-number="11"></td>
        <td id="file-simple-bag-of-words-example-py-LC11" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L12" class="blob-num js-line-number" data-line-number="12"></td>
        <td id="file-simple-bag-of-words-example-py-LC12" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Show the Bag-of-Words Model as a pandas DataFrame</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L13" class="blob-num js-line-number" data-line-number="13"></td>
        <td id="file-simple-bag-of-words-example-py-LC13" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">feature_names</span> <span class="pl-c1">=</span> <span class="pl-s1">count_vectorizer</span>.<span class="pl-en">get_feature_names</span>()</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L14" class="blob-num js-line-number" data-line-number="14"></td>
        <td id="file-simple-bag-of-words-example-py-LC14" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">pd</span>.<span class="pl-v">DataFrame</span>(<span class="pl-s1">bag_of_words</span>.<span class="pl-en">toarray</span>(), <span class="pl-s1">columns</span> <span class="pl-c1">=</span> <span class="pl-s1">feature_names</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">simple bag-of-words example.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclus√£o: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ee/pf/-g/eepf-gw0it8d6a_fwcoew7bwbns.png"></div><br>  Estas s√£o as nossas sugest√µes.  Agora vemos como o modelo "saco de palavras" funciona. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/l3/ep/95/l3ep95r4s_rdnvjfmfy7ebcwuag.png"></div><br><h3>  Algumas palavras sobre o saco de palavras </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/k4/mo/s1/k4mos1faome-c00hjo84v7nt7no.png"></div><br>  A complexidade desse modelo √© como determinar o dicion√°rio e como contar a ocorr√™ncia de palavras. <br><br>  Quando o tamanho do dicion√°rio aumenta, o vetor do documento tamb√©m aumenta.  No exemplo acima, o comprimento do vetor √© igual ao n√∫mero de palavras conhecidas. <br><br>  Em alguns casos, podemos ter uma quantidade incrivelmente grande de dados e o vetor pode consistir em milhares ou milh√µes de elementos.  Al√©m disso, cada documento pode conter apenas uma pequena parte das palavras do dicion√°rio. <br><br>  Como resultado, haver√° muitos zeros na representa√ß√£o vetorial.  Vetores com muitos zeros s√£o chamados vetores esparsos, eles requerem mais mem√≥ria e recursos computacionais. <br><br>  No entanto, podemos reduzir o n√∫mero de palavras conhecidas quando usamos esse modelo para reduzir a demanda por recursos de computa√ß√£o.  Para fazer isso, voc√™ pode usar as mesmas t√©cnicas que j√° consideramos antes de criar um conjunto de palavras: <br><br><ul><li>  ignorando o caso das palavras; </li><li>  ignorando pontua√ß√£o; </li><li>  ejetar palavras de parada; </li><li>  redu√ß√£o de palavras √†s suas formas b√°sicas (lematiza√ß√£o e stemming); </li><li>  corre√ß√£o de palavras com erros ortogr√°ficos. </li></ul><br>  Outra maneira mais complicada de criar um dicion√°rio √© usar palavras agrupadas.  Isso redimensionar√° o dicion√°rio e fornecer√° mais detalhes sobre o documento.  Essa abordagem √© chamada de " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">N-grama</a> ". <br><br>  N-grama √© uma sequ√™ncia de qualquer entidade (palavras, letras, n√∫meros, n√∫meros, etc.).  No contexto dos corpos lingu√≠sticos, o N-grama √© geralmente entendido como uma sequ√™ncia de palavras.  Um unigrama √© uma palavra, um bigram √© uma sequ√™ncia de duas palavras, um trigrama √© tr√™s palavras e assim por diante.  O n√∫mero N indica quantas palavras agrupadas est√£o inclu√≠das no N-grama.  Nem todos os N-gramas poss√≠veis se enquadram no modelo, mas apenas os que aparecem no gabinete. <br><br>  <b>Um exemplo:</b> <br><br>  Considere a seguinte frase: <br><br><pre> <code class="plaintext hljs">The office building is open today</code> </pre> <br>  Aqui est√£o seus bigrams: <br><br><ul><li>  o escrit√≥rio </li><li>  edif√≠cio de escrit√≥rios </li><li>  edif√≠cio √© </li><li>  est√° aberto </li><li>  aberto hoje </li></ul><br>  Como voc√™ pode ver, um pacote de bigrams √© uma abordagem mais eficaz do que um pacote de palavras. <br><br>  <b>Avalia√ß√£o (pontua√ß√£o) de palavras</b> <br><br>  Quando um dicion√°rio √© criado, a presen√ßa de palavras deve ser avaliada.  J√° consideramos uma abordagem simples e bin√°ria (1 - existe uma palavra, 0 - n√£o h√° palavra). <br><br>  Existem outros m√©todos: <br><br><ol><li>  Quantidade.  √â calculado quantas vezes cada palavra aparece no documento. </li><li>  Frequ√™ncia  √â calculado com que frequ√™ncia cada palavra ocorre no texto (em rela√ß√£o ao n√∫mero total de palavras). </li></ol><br><br><h3>  7. TF-IDF </h3><br>  A pontua√ß√£o de frequ√™ncia tem um problema: as palavras com a frequ√™ncia mais alta t√™m, respectivamente, a classifica√ß√£o mais alta.  Nessas palavras, pode n√£o haver tanto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ganho informacional</a> para o modelo quanto em palavras menos frequentes.  Uma maneira de corrigir a situa√ß√£o √© diminuir a pontua√ß√£o da palavra, que geralmente √© encontrada <b>em todos os documentos semelhantes</b> .  Isso √© chamado de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TF-IDF</a> . <br><br>  TF-IDF (abrevia√ß√£o de frequ√™ncia de termo - frequ√™ncia inversa de documento) √© uma medida estat√≠stica para avaliar a import√¢ncia de uma palavra em um documento que faz parte de uma cole√ß√£o ou corpus. <br><br>  A pontua√ß√£o pelo TF-IDF cresce proporcionalmente √† frequ√™ncia de ocorr√™ncia de uma palavra em um documento, mas isso √© compensado pelo n√∫mero de documentos que cont√™m essa palavra. <br><br>  F√≥rmula de pontua√ß√£o para a palavra X no documento Y: <br><br><img src="https://habrastorage.org/webt/_3/bb/xo/_3bbxoimlox11_am3gzyequcjic.png"><br>  <font color="grey">F√≥rmula TF-IDF.</font>  <font color="grey">Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">filotechnologia.blogspot.com/2014/01/a-simple-java-class-for-tfidf-scoring.html</a></font> <br><br>  TF (termo frequ√™ncia) √© a raz√£o entre o n√∫mero de ocorr√™ncias de uma palavra e o n√∫mero total de palavras em um documento. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ai/p0/wk/aip0wkqcynj8q1cxwxlufspqqds.png"></div><br>  IDF (frequ√™ncia inversa do documento) √© o inverso da frequ√™ncia com que uma palavra ocorre nos documentos de cole√ß√£o. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6j/xd/32/6jxd32ydlpkmixkjw6hdgmp6f6m.png"></div><br>  Como resultado, TF-IDF para o <b>termo</b> palavra pode ser calculado da seguinte maneira: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hl/tp/n0/hltpn0vg_gdo8bn1pfimbvu60no.png"></div><br>  <b>Um exemplo:</b> <br><br>  Voc√™ pode usar a classe TfidfVectorizer da biblioteca sklearn para calcular o TF-IDF.  Vamos fazer isso com as mesmas mensagens que usamos no exemplo de saco de palavras. <br><br><pre> <code class="plaintext hljs">I like this movie, it's funny. I hate this movie. This was awesome! I like it. Nice one. I love it.</code> </pre> <br>  C√≥digo: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/c84cfc6fef2dc131236a9fa5c72de3c9.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist93050848" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-tf-idf-example-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-tf-idf-example-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-tf-idf-example-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">sklearn</span>.<span class="pl-s1">feature_extraction</span>.<span class="pl-s1">text</span> <span class="pl-k">import</span> <span class="pl-v">TfidfVectorizer</span></td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-tf-idf-example-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> <span class="pl-s1">pandas</span> <span class="pl-k">as</span> <span class="pl-s1">pd</span></td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-tf-idf-example-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-tf-idf-example-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">tfidf_vectorizer</span> <span class="pl-c1">=</span> <span class="pl-v">TfidfVectorizer</span>()</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-tf-idf-example-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">values</span> <span class="pl-c1">=</span> <span class="pl-s1">tfidf_vectorizer</span>.<span class="pl-en">fit_transform</span>(<span class="pl-s1">documents</span>)</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-tf-idf-example-py-LC6" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-tf-idf-example-py-LC7" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Show the Model as a pandas DataFrame</span></td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-tf-idf-example-py-LC8" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">feature_names</span> <span class="pl-c1">=</span> <span class="pl-s1">tfidf_vectorizer</span>.<span class="pl-en">get_feature_names</span>()</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-tf-idf-example-py-LC9" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">pd</span>.<span class="pl-v">DataFrame</span>(<span class="pl-s1">values</span>.<span class="pl-en">toarray</span>(), <span class="pl-s1">columns</span> <span class="pl-c1">=</span> <span class="pl-s1">feature_names</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">tf-idf example.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclus√£o: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ad/vj/kt/advjktxg44hyhjj63m27igwssiu.png"></div><br><h2>  Conclus√£o </h2><br>  Este artigo abordou os conceitos b√°sicos da PNL para texto, a saber: <br><br><ul><li>  A PNL permite o uso de algoritmos de aprendizado de m√°quina para texto e fala; </li><li>  NLTK (Natural Language Toolkit) - uma plataforma l√≠der para a cria√ß√£o de programas de PNL em Python; </li><li>  a tokeniza√ß√£o da proposta √© o processo de dividir uma linguagem escrita em frases componentes; </li><li>  a tokeniza√ß√£o de palavras √© o processo de dividir senten√ßas em palavras componentes; </li><li>  A lematiza√ß√£o e a deriva√ß√£o visam trazer todas as formas de palavras encontradas para uma √∫nica forma de vocabul√°rio normal; </li><li>  palavras de parada s√£o aquelas que s√£o jogadas fora do texto antes / ap√≥s o processamento do texto; </li><li>  regex (regex, regexp, regex) √© uma sequ√™ncia de caracteres que define um padr√£o de pesquisa; </li><li>  um pacote de palavras √© uma t√©cnica popular e simples de extra√ß√£o de recursos usada ao trabalhar com texto.  Descreve as ocorr√™ncias de cada palavra no texto. </li></ul><br>  √ìtimo!  Agora que voc√™ conhece o b√°sico da extra√ß√£o de recursos, pode us√°-los como entrada para algoritmos de aprendizado de m√°quina. <br><br>  Se voc√™ deseja ver todos os conceitos descritos em um grande exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui est√° voc√™</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt446738/">https://habr.com/ru/post/pt446738/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt446726/index.html">Aprendizagem Profunda em Computa√ß√£o √ìtica de Fluxo</a></li>
<li><a href="../pt446728/index.html">Como a energia recebida do carregamento sem fio muda dependendo da localiza√ß√£o do telefone</a></li>
<li><a href="../pt446730/index.html">Se√ß√£o de back-end no DUMP: sem servidor, Postgres e Go, .NET Core, GraphQL e mais</a></li>
<li><a href="../pt446732/index.html">Fer√≥podes n√£o ajudar√£o: pesquisa e modelagem matem√°tica de armadilhas para larvas de le√µes-formigas</a></li>
<li><a href="../pt446736/index.html">Oracle APEX Relat√≥rios</a></li>
<li><a href="../pt446740/index.html">Usando o Python para gerar relat√≥rios em uma √∫nica empresa</a></li>
<li><a href="../pt446742/index.html">T√≥picos da Top 3D Expo 2019: ‚ÄúAnisoprinting - a tecnologia para a produ√ß√£o de estruturas compostas de uma nova gera√ß√£o‚Äù, Fedor Antonov</a></li>
<li><a href="../pt446744/index.html">VR com interfaces neurais - uma imers√£o completa na realidade virtual</a></li>
<li><a href="../pt446746/index.html">Um funcion√°rio do UBS ouviu uma conversa sobre um vizinho de trem do Eurostar e descobriu um acordo de US $ 15 bilh√µes Agora, ele e o banco ser√£o multados</a></li>
<li><a href="../pt446750/index.html">Not√≠cias do fundo: os gigantes de TI come√ßaram a criar ativamente suas pr√≥prias redes de backbone submarino</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
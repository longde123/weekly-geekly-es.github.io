<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìÄ üë©‚Äçüë©‚Äçüëß‚Äçüë¶ üêè Comment Yandex a appliqu√© la vision par ordinateur pour am√©liorer la qualit√© des √©missions vid√©o. Technologie DeepHD üìá üëù ‚úñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Lorsque les internautes recherchent une image ou une vid√©o sur Internet, ils ajoutent souvent l'expression ¬´de bonne qualit√©¬ª. La qualit√© se r√©f√®re g√©...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment Yandex a appliqu√© la vision par ordinateur pour am√©liorer la qualit√© des √©missions vid√©o. Technologie DeepHD</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/422561/">  Lorsque les internautes recherchent une image ou une vid√©o sur Internet, ils ajoutent souvent l'expression ¬´de bonne qualit√©¬ª.  La qualit√© se r√©f√®re g√©n√©ralement √† la r√©solution - les utilisateurs veulent que l'image soit grande et en m√™me temps belle sur l'√©cran d'un ordinateur, d'un smartphone ou d'un t√©l√©viseur moderne.  Mais que faire si la source de bonne qualit√© n'existe tout simplement pas? <br><br>  Aujourd'hui, nous expliquerons aux lecteurs de Habr comment, gr√¢ce √† des r√©seaux de neurones, nous pouvons augmenter la r√©solution de la vid√©o en temps r√©el.  Vous apprendrez √©galement en quoi l'approche th√©orique pour r√©soudre ce probl√®me diff√®re de l'approche pratique.  Si vous n'√™tes pas int√©ress√© par les d√©tails techniques, vous pouvez faire d√©filer le message en toute s√©curit√© - √† la fin, vous trouverez des exemples de notre travail. <br><br><img width="800" src="https://habrastorage.org/webt/hx/lu/ak/hxluakxdy2mxmmskebqieei5zq4.png"><br><br>  Il y a beaucoup de contenu vid√©o sur Internet en basse qualit√© et r√©solution.  Il peut s'agir de films tourn√©s il y a des d√©cennies ou de cha√Ænes de t√©l√©vision diffus√©es qui, pour diverses raisons, ne sont pas de la meilleure qualit√©.  Lorsque les utilisateurs √©tendent une telle vid√©o en plein √©cran, l'image devient trouble et floue.  Une solution id√©ale pour les vieux films serait de trouver le film original, de le num√©riser avec un √©quipement moderne et de le restaurer manuellement, mais ce n'est pas toujours possible.  Les √©missions sont encore plus compliqu√©es - elles doivent √™tre trait√©es en direct.  √Ä cet √©gard, l'option la plus acceptable pour nous de travailler est d'augmenter la r√©solution et de nettoyer les artefacts en utilisant la technologie de vision par ordinateur. <br><br><a name="habracut"></a>  Dans l'industrie, la t√¢che d'augmenter les images et les vid√©os sans perte de qualit√© est appel√©e le terme super-r√©solution.  De nombreux articles ont d√©j√† √©t√© √©crits sur ce sujet, mais les r√©alit√©s de l'application ¬´combat¬ª se sont av√©r√©es beaucoup plus compliqu√©es et int√©ressantes.  En bref sur les principaux probl√®mes que nous avons d√ª r√©soudre dans notre propre technologie DeepHD: <br><br><ul><li>  Vous devez pouvoir restaurer des d√©tails qui n'√©taient pas sur la vid√©o d'origine en raison de sa faible r√©solution et de sa qualit√©, pour les ¬´terminer¬ª. </li><li>  Les solutions de la zone de super-r√©solution restaurent les d√©tails, mais elles rendent clairs et d√©taill√©s non seulement les objets de la vid√©o, mais aussi les artefacts de compression, ce qui provoque une aversion pour le public. </li><li> Il y a un probl√®me avec la collecte de l'√©chantillon d'apprentissage - un grand nombre de paires sont n√©cessaires dans lesquelles la m√™me vid√©o est pr√©sente √† la fois en basse r√©solution et en qualit√©, et en haute.  En r√©alit√©, il n'y a g√©n√©ralement pas de paire de qualit√© pour un contenu m√©diocre. </li><li>  La solution devrait fonctionner en temps r√©el. </li></ul><br><h3>  S√©lection de technologies </h3><br>  Au cours des derni√®res ann√©es, l'utilisation des r√©seaux de neurones a conduit √† un succ√®s significatif dans la r√©solution de presque toutes les t√¢ches de vision par ordinateur, et la t√¢che de super-r√©solution ne fait pas exception.  Nous avons trouv√© les solutions les plus prometteuses bas√©es sur les GAN (Generative Adversarial Networks, g√©n√©rative rival networks).  Ils vous permettent d'obtenir des images photor√©alistes haute d√©finition, en les compl√©tant avec les d√©tails manquants, par exemple en dessinant des cheveux et des cils sur les images des personnes. <br><br><img src="https://habrastorage.org/webt/gq/hl/kz/gqhlkzdwwmq3ad9p78j7wapfhzs.png"><br><br>  Dans le cas le plus simple, un r√©seau de neurones se compose de deux parties.  La premi√®re partie - le g√©n√©rateur - prend une image d'entr√©e et retourne un grossissement doubl√©.  La deuxi√®me partie - le discriminateur - re√ßoit l'image g√©n√©r√©e et ¬´r√©elle¬ª en entr√©e, et essaie de la distinguer les unes des autres. <br><br><img width="700" src="https://habrastorage.org/webt/kn/3s/sc/kn3sscgtqtwqzcnga59cwaor-8y.png"><br><br><h3>  Pr√©paration du set d'entra√Ænement </h3><br>  Pour la formation, nous avons collect√© des dizaines de clips en qualit√© UltraHD.  Tout d'abord, nous les avons r√©duits √† une r√©solution de 1080p, obtenant ainsi des exemples de r√©f√©rence.  Ensuite, nous avons r√©duit de moiti√© ces vid√©os, en les compressant √† un d√©bit diff√©rent en cours de route pour obtenir quelque chose de similaire √† une vraie vid√©o de faible qualit√©.  Nous avons divis√© les vid√©os r√©sultantes en images et les avons utilis√©es de mani√®re √† former le r√©seau neuronal. <br><br><h3>  D√©blocage </h3><br>  Bien s√ªr, nous voulions obtenir une solution de bout en bout: former le r√©seau neuronal √† g√©n√©rer une vid√©o et une qualit√© haute r√©solution directement √† partir de l'original.  Cependant, les GAN se sont av√©r√©s tr√®s capricieux et ont constamment essay√© d'affiner les artefacts de compression, plut√¥t que de les √©liminer.  J'ai donc d√ª diviser le processus en plusieurs √©tapes.  Le premier est la suppression des artefacts de compression vid√©o, √©galement appel√©s d√©blocage. <br><br>  Un exemple d'une des m√©thodes de publication: <br><br><img src="https://habrastorage.org/webt/0c/sg/zx/0csgzx4zwbtceyujcgcay4mclac.jpeg"><br><br>  √Ä ce stade, nous avons minimis√© l'√©cart type entre le cadre g√©n√©r√© et le cadre d'origine.  Ainsi, bien que nous ayons augment√© la r√©solution de l'image, nous n'avons pas obtenu une r√©elle augmentation de la r√©solution en raison de la r√©gression vers la moyenne: le r√©seau neuronal, ne sachant pas dans quels pixels sp√©cifiques une bordure particuli√®re de l'image passe, a √©t√© forc√© de faire la moyenne de plusieurs options, obtenant un r√©sultat flou.  La principale chose que nous avons r√©alis√©e √† ce stade est l'√©limination des artefacts de compression vid√©o, de sorte que le r√©seau g√©n√©rateur √† l'√©tape suivante n'avait besoin que d'augmenter la clart√© et d'ajouter les petits d√©tails manquants, les textures.  Apr√®s des centaines d'exp√©riences, nous avons s√©lectionn√© l'architecture optimale en termes de performances et de qualit√©, rappelant vaguement l'architecture <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DRCN</a> : <br><br><img width="800" src="https://habrastorage.org/webt/oq/au/pc/oqaupcp8k9m4rdspvx8rrrbhpy0.png"><br><br>  L'id√©e principale d'une telle architecture est le d√©sir d'obtenir l'architecture la plus profonde, sans avoir de probl√®mes de convergence dans sa formation.  D'une part, chaque couche convolutionnelle suivante extrait des caract√©ristiques de plus en plus complexes de l'image d'entr√©e, ce qui vous permet de d√©terminer quel type d'objet se trouve √† un point donn√© de l'image et de restaurer des parties complexes et gravement endommag√©es.  En revanche, la distance dans le graphe d'un r√©seau neuronal de n'importe laquelle de ses couches √† la sortie reste faible, ce qui am√©liore la convergence du r√©seau neuronal et permet d'utiliser un grand nombre de couches. <br><br><h3>  Formation r√©seau g√©n√©rative </h3><br>  Nous avons pris l'architecture <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SRGAN comme</a> base d'un r√©seau neuronal pour augmenter la r√©solution.  Avant de former un r√©seau comp√©titif, vous devez pr√©-entra√Æner le g√©n√©rateur - entra√Ænez-le de la m√™me mani√®re qu'au stade du d√©blocage.  Sinon, au d√©but de la formation, le g√©n√©rateur ne retournera que du bruit, le discriminateur commencera imm√©diatement √† "gagner" - il apprendra facilement √† distinguer le bruit des images r√©elles, et aucune formation ne fonctionnera. <br><br><img width="800" src="https://habrastorage.org/webt/tx/pb/r-/txpbr-pwdisdcwj62mrd6h4wuxm.png"><br><br>  Ensuite, nous formons le GAN, mais il y a quelques nuances.  Il est important pour nous que le g√©n√©rateur cr√©e non seulement des images photor√©alistes, mais stocke √©galement les informations disponibles √† leur sujet.  Pour ce faire, nous ajoutons la fonction de perte de contenu √† l'architecture GAN classique.  Il repr√©sente plusieurs couches du r√©seau neuronal VGG19 entra√Æn√©es sur l'ensemble de donn√©es ImageNet standard.  Ces couches transforment l'image en une carte d'entit√©s qui contient des informations sur le contenu de l'image.  La fonction de perte minimise la distance entre ces cartes obtenues √† partir des trames g√©n√©r√©es et originales.  De plus, la pr√©sence d'une telle fonction de perte vous permet de ne pas g√¢cher le g√©n√©rateur dans les premi√®res √©tapes de la formation, lorsque le discriminateur n'est pas encore form√© et fournit des informations inutiles. <br><br><img width="800" src="https://habrastorage.org/webt/d7/5p/uu/d75puuaa6jqsy6wmvknjqo-hh84.png"><br><br><h3>  Acc√©l√©ration du r√©seau neuronal </h3><br>  Tout s'est bien pass√©, et apr√®s une s√©rie d'exp√©riences, nous avons obtenu un bon mod√®le qui pouvait d√©j√† √™tre appliqu√© aux vieux films.  Cependant, il √©tait encore trop lent pour traiter la vid√©o en streaming.  Il s'est av√©r√© qu'il est impossible de simplement r√©duire le g√©n√©rateur sans perte significative de qualit√© du mod√®le final.  Puis l'approche de la distillation des connaissances est venue √† notre aide.  Cette m√©thode consiste √† entra√Æner un mod√®le plus l√©ger afin qu'il r√©p√®te les r√©sultats d'un mod√®le plus lourd.  Nous avons pris beaucoup de vraies vid√©os en basse qualit√©, les avons trait√©es avec le r√©seau neuronal g√©n√©ratif obtenu √† l'√©tape pr√©c√©dente et form√© le r√©seau plus l√©ger pour obtenir le m√™me r√©sultat √† partir des m√™mes images.  En raison de cette technique, nous avons obtenu un r√©seau qui n'est pas tr√®s inf√©rieur en qualit√© √† celui d'origine, mais dix fois plus rapide que lui: pour traiter une cha√Æne de t√©l√©vision en r√©solution 576p, une carte NVIDIA Tesla V100 est requise. <br><br><img width="800" src="https://habrastorage.org/webt/15/b3/eg/15b3eguc_ikkl-fdaclwdsga2ka.png"><br><br><h3>  √âvaluation de la qualit√© des solutions </h3><br>  Le moment peut-√™tre le plus difficile lorsque l'on travaille avec des r√©seaux g√©n√©ratifs est l'√©valuation de la qualit√© des mod√®les r√©sultants.  Il n'y a pas de fonction d'erreur claire, comme, par exemple, lors de la r√©solution du probl√®me de classification.  Au lieu de cela, nous ne connaissons que l'exactitude du discriminateur, ce qui ne refl√®te pas la qualit√© du g√©n√©rateur qui nous int√©resse (un lecteur qui conna√Æt bien ce domaine pourrait sugg√©rer d'utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la m√©trique Wasserstein</a> , mais, malheureusement, cela a donn√© un r√©sultat sensiblement pire). <br><br>  Les gens nous ont aid√©s √† r√©soudre ce probl√®me.  Nous avons montr√© aux utilisateurs des paires d'images du service <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Yandex.Tolok</a> , dont l'une √©tait la source et l'autre trait√©es par un r√©seau de neurones, ou les deux ont √©t√© trait√©es par diff√©rentes versions de nos solutions.  Moyennant un suppl√©ment, les utilisateurs ont choisi une meilleure vid√©o √† partir d'une paire, nous avons donc obtenu une comparaison statistiquement significative des versions, m√™me avec des changements difficiles √† voir √† l'≈ìil nu.  Nos mod√®les finaux gagnent dans plus de 70% des cas, ce qui est beaucoup, √©tant donn√© que les utilisateurs ne passent que quelques secondes √† √©valuer quelques vid√©os. <br><br>  Un r√©sultat int√©ressant a √©galement √©t√© le fait que la vid√©o en r√©solution 576p, augment√©e par la technologie DeepHD √† 720p, surpasse la m√™me vid√©o originale avec une r√©solution 720p dans 60% des cas - c'est-√†-dire  Le traitement augmente non seulement la r√©solution de la vid√©o, mais am√©liore √©galement sa perception visuelle. <br><br><h3>  Des exemples </h3><br>  Au printemps, nous avons test√© la technologie DeepHD sur plusieurs vieux films qui peuvent √™tre visionn√©s sur KinoPoisk: ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Rainbow</a> ¬ª de Mark Donskoy (1943), ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cranes are Flying</a> ¬ª de Mikhail Kalatozov (1957), ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">My Dear Man</a> ¬ª de Joseph Kheifits (1958), ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">The Fate of a Man</a> ¬ª Sergei Bondarchuk (1959), ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ivan Childhood</a> ¬ª d'Andrei Tarkovsky (1962), ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Father of a Soldier</a> ¬ª Rezo Chkheidze (1964) et ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tango of Our Childhood</a> ¬ª d'Albert Mkrtchyan (1985). <br><br><img width="800" src="https://habrastorage.org/webt/zh/un/-d/zhun-dugkeykn9bmodmrgrjfxma.png"><br><br>  La diff√©rence entre les versions avant et apr√®s le traitement est particuli√®rement visible si vous examinez les d√©tails: √©tudiez les expressions faciales des h√©ros en gros plan, consid√©rez la texture des v√™tements ou un motif de tissu.  Il a √©t√© possible de compenser certaines des lacunes de la num√©risation: par exemple, pour supprimer la surexposition sur les visages ou pour rendre les objets plus visibles plac√©s dans l'ombre. <br><br>  Plus tard, la technologie DeepHD a commenc√© √† √™tre utilis√©e pour am√©liorer la qualit√© des √©missions de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">certaines</a> cha√Ænes du service Yandex.Air.  La reconnaissance d'un tel contenu est facile gr√¢ce √† la balise <b>dHD</b> . <br><br>  Maintenant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur Yandex</a> en qualit√© am√©lior√©e, vous pouvez regarder "The Snow Queen", "Bremen Town Musicians", "Golden Antelope" et d'autres dessins anim√©s populaires du studio de cin√©ma Soyuzmultfilm.  Quelques exemples de dynamique peuvent √™tre vus dans la vid√©o: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/ainlhiNn0Yk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Pour les t√©l√©spectateurs exigeants, la diff√©rence sera particuli√®rement visible: l'image est devenue plus nette, les feuilles des arbres, les flocons de neige, les √©toiles dans le ciel nocturne sur la jungle et d'autres petits d√©tails sont plus visibles. <br><br>  Plus c'est plus. <br><br><h3>  Liens utiles </h3><br>  Jiwon Kim, Jung Kwon Lee, Kyoung Mu Lee R√©seau convolutionnel profond√©ment r√©cursif pour la super-r√©solution d'images [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">arXiv: 1511.04491</a> ]. <br><br>  Christian Ledig et al.  Super-r√©solution d'image unique photo-r√©aliste utilisant un r√©seau <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">contradictoire</a> g√©n√©ratif [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">arXiv: 1609.04802</a> ]. <br><br>  Mehdi SM Sajjadi, Bernhard Sch√∂lkopf, Michael Hirsch EnhanceNet: super-r√©solution d'image unique par synth√®se de texture automatis√©e [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">arXiv: 1612.07919</a> ]. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr422561/">https://habr.com/ru/post/fr422561/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr422547/index.html">Pour √©liminer Spectre et Meltdown, vous devrez peut-√™tre cr√©er un tout nouveau type de processeur</a></li>
<li><a href="../fr422549/index.html">Corda: Kotlin</a></li>
<li><a href="../fr422551/index.html">Comment voler de l'argent avec une carte sans contact et Apple Pay</a></li>
<li><a href="../fr422553/index.html">L'extension de navigateur officielle Mega vole les donn√©es de partage de fichiers et la crypto-monnaie</a></li>
<li><a href="../fr422555/index.html">Architecture multi-modules Android. De A √† Z</a></li>
<li><a href="../fr422565/index.html">Webinaires Skillbox Friday: Tout pour les programmeurs et les concepteurs</a></li>
<li><a href="../fr422569/index.html">Application de suivi horaire</a></li>
<li><a href="../fr422571/index.html">Parall√©lisation des t√¢ches avec les d√©pendances - exemple .NET</a></li>
<li><a href="../fr422573/index.html">L'ing√©nierie inverse du rendu de The Witcher 3</a></li>
<li><a href="../fr422575/index.html">Interphone rare</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
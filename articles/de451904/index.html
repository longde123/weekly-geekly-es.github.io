<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>➖ 👩‍👦 💅🏾 Manchmal ist mehr weniger. Wenn eine Abnahme der Last zu einer Zunahme der Verzögerung führt 💳 👨🏽‍🌾 👈🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wie in den meisten Beiträgen gab es ein Problem mit einem verteilten Dienst. Nennen wir diesen Dienst Alvin. Diesmal habe ich das Problem selbst nicht...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Manchmal ist mehr weniger. Wenn eine Abnahme der Last zu einer Zunahme der Verzögerung führt</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451904/"> Wie in den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">meisten Beiträgen</a> gab es ein Problem mit einem verteilten Dienst. Nennen wir diesen Dienst Alvin.  Diesmal habe ich das Problem selbst nicht gefunden, informierten mich die Jungs vom Client-Teil. <br><br>  Einmal bin ich aus einem verärgerten Brief aufgewacht, wegen der großen Verzögerungen von Alvin, den wir in naher Zukunft starten wollten.  Insbesondere stieß der Kunde auf eine Verzögerung von 99. Perzentilen um 50 ms, die weit über unserem Verzögerungsbudget lag.  Dies war überraschend, da ich den Service gründlich getestet habe, insbesondere auf Verzögerungen, da dies häufig beanstandet wird. <br><br>  Bevor ich Alvin zum Testen gab, führte ich viele Experimente mit 40.000 Anfragen pro Sekunde (QPS) durch, die alle eine Verzögerung von weniger als 10 ms zeigten.  Ich war bereit zu erklären, dass ich mit ihren Ergebnissen nicht einverstanden bin.  Aber als ich den Brief noch einmal betrachtete, machte ich auf etwas Neues aufmerksam: Ich habe die genannten Bedingungen definitiv nicht getestet, ihr QPS war viel niedriger als meiner.  Ich habe auf 40k QPS getestet, und sie nur auf 1k.  Ich habe ein weiteres Experiment durchgeführt, diesmal mit niedrigerem QPS, nur um ihnen zu gefallen. <br><a name="habracut"></a><br>  Da ich darüber in meinem Blog schreibe, haben Sie wahrscheinlich schon verstanden: Ihre Zahlen haben sich als richtig herausgestellt.  Ich habe meinen virtuellen Client immer wieder getestet, alle mit dem gleichen Ergebnis: Eine geringe Anzahl von Anforderungen erhöht nicht nur die Verzögerung, sondern auch die Anzahl von Anforderungen mit einer Verzögerung von mehr als 10 ms.  Mit anderen Worten, wenn bei 40k QPS etwa 50 Anforderungen pro Sekunde 50 ms überstiegen, dann gab es bei 1k QPS pro Sekunde 100 Anforderungen über 50 ms.  Paradox! <br><br><img src="https://habrastorage.org/webt/xd/86/x-/xd86x-er30ek6tg4hkv4qdevvgq.png"><br><br><h1>  Grenzen Sie Ihre Suche ein </h1><br>  Angesichts des Problems der Verzögerung in einem verteilten System mit vielen Komponenten müssen Sie zunächst eine kurze Liste der Verdächtigen erstellen.  Wir gehen etwas tiefer in Alvins Architektur ein: <br><br><img src="https://habrastorage.org/webt/lh/is/s5/lhiss5mqv9dq2h9moyhlss_chlk.png"><br><br>  Ein guter Ausgangspunkt ist eine Liste abgeschlossener E / A-Übergänge (Netzwerkanrufe / Festplattensuchen usw.).  Versuchen wir herauszufinden, wo die Verzögerung liegt.  Neben der offensichtlichen E / A mit dem Kunden unternimmt Alvin einen weiteren Schritt: Er greift auf das Data Warehouse zu.  Dieser Speicher funktioniert jedoch mit Alvin im selben Cluster, sodass weniger Verzögerungen auftreten sollten als mit dem Client.  Also die Liste der Verdächtigen: <br><br><ol><li>  Netzwerkanruf vom Client an Alvin. <br></li><li>  Netzwerkanruf von Alvin an das Data Warehouse. <br></li><li>  Suche auf Datenträger im Data Warehouse. <br></li><li>  Netzwerkanruf vom Data Warehouse an Alvin. <br></li><li>  Netzwerkanruf von Alvin an den Client. </li></ol><br>  Versuchen wir, einige Punkte zu streichen. <br><br><h3>  Data Warehouse </h3><br>  Als erstes habe ich Alvin in einen Ping-Ping-Server konvertiert, der keine Anforderungen verarbeitet.  Nach Erhalt der Anfrage wird eine leere Antwort zurückgegeben.  Wenn die Verzögerung abnimmt, ist ein Fehler bei der Implementierung von Alvin oder des Data Warehouse nichts Unbekanntes.  Im ersten Experiment erhalten wir die folgende Grafik: <br><br><img src="https://habrastorage.org/webt/i4/zs/9s/i4zs9saymr5ra4tmry3diqbgdyy.png"><br><br>  Wie Sie sehen, gibt es bei Verwendung des Ping-Ping-Servers keine Verbesserungen.  Dies bedeutet, dass das Data Warehouse die Verzögerung nicht erhöht und die Liste der Verdächtigen halbiert wird: <br><br><ol><li>  Netzwerkanruf vom Client an Alvin. <br></li><li>  Netzwerkanruf von Alvin an den Client. </li></ol><br>  Wow!  Die Liste wird immer kleiner.  Ich dachte, ich hätte fast den Grund herausgefunden. <br><br><h3>  gRPC </h3><br>  Jetzt ist es an der Zeit, Ihnen einen neuen Spieler vorzustellen: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gRPC</a> .  Dies ist eine Open Source-Bibliothek von Google für die In-Process- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RPC-</a> Kommunikation.  Obwohl <code>gRPC</code> gut optimiert und weit verbreitet ist, habe ich es zum ersten Mal auf einem System dieser Größenordnung verwendet und erwartet, dass meine Implementierung - gelinde gesagt - nicht optimal ist. <br><br>  Das Vorhandensein von <code>gRPC</code> im Stapel warf eine neue Frage auf: Vielleicht ist dies meine Implementierung oder verursacht <code>gRPC</code> selbst ein Verzögerungsproblem?  Zur Liste des neuen Verdächtigen hinzufügen: <br><br><ol><li>  Der Client ruft die <code>gRPC</code> Bibliothek auf <br></li><li>  Die <code>gRPC</code> Bibliothek auf dem Client ruft die <code>gRPC</code> Bibliothek auf dem Server im Netzwerk auf <br></li><li>  <code>gRPC</code> Bibliothek greift auf Alvin zu (keine Operation bei Ping-Pong-Server) </li></ol><br>  Damit Sie verstehen, wie der Code aussieht, unterscheidet sich meine Client / Alvin-Implementierung nicht wesentlich von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">asynchronen</a> Client-Server- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beispielen</a> . <br><br><blockquote>  <i>Hinweis: Die obige Liste ist etwas vereinfacht, da Sie mit <code>gRPC</code> Ihr eigenes (Vorlagen-?) Stream-Modell verwenden können, in dem der <code>gRPC</code> Ausführungsstapel und die Benutzerimplementierung miteinander verflochten sind.</i>  <i>Der Einfachheit halber werden wir uns an dieses Modell halten.</i> </blockquote><br><h3>  Durch die Profilerstellung wird alles behoben </h3><br>  Als ich die Data Warehouses durchgestrichen hatte, dachte ich, ich wäre fast fertig: „Jetzt einfach!  Wir werden das Profil anwenden und herausfinden, wo die Verzögerung auftritt. "  Ich bin ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">großer Fan von genauem Profiling,</a> weil die CPUs sehr schnell sind und meistens keinen Engpass darstellen.  Die meisten Verzögerungen treten auf, wenn der Prozessor die Verarbeitung stoppen muss, um etwas anderes zu tun.  Genau dafür wurde eine genaue Profilerstellung der CPU vorgenommen: Sie zeichnet alle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kontextwechsel</a> genau auf und macht deutlich, wo Verzögerungen auftreten. <br><br>  Ich habe vier Profile erstellt: unter hohem QPS (niedrige Latenz) und mit einem Ping-Pong-Server mit niedrigem QPS (hohe Latenz), sowohl auf der Clientseite als auch auf der Serverseite.  Und für alle Fälle habe ich auch ein Beispielprozessorprofil genommen.  Beim Vergleichen von Profilen suche ich normalerweise nach einem abnormalen Aufrufstapel.  Auf der schlechten Seite mit einer hohen Verzögerung gibt es beispielsweise viel mehr Kontextwechsel (10 oder mehr Mal).  In meinem Fall stimmte die Anzahl der Kontextwechsel jedoch fast überein.  Zu meinem Entsetzen gab es dort nichts Bedeutendes. <br><br><h1>  Zusätzliches Debugging </h1><br>  Ich war verzweifelt.  Ich wusste nicht, welche anderen Werkzeuge verwendet werden könnten, und mein nächster Plan bestand im Wesentlichen darin, Experimente mit verschiedenen Variationen zu wiederholen und das Problem nicht eindeutig zu diagnostizieren. <br><br><h3>  Was wäre wenn </h3><br>  Ich war von Anfang an besorgt über die spezifische Verzögerungszeit von 50 ms.  Dies ist eine sehr große Zeit.  Ich beschloss, die Teile aus dem Code herauszuschneiden, bis ich genau herausfinden konnte, welcher Teil diesen Fehler verursachte.  Dann folgte ein Experiment, das funktionierte. <br><br>  Wie immer scheint im Hinterkopf alles offensichtlich zu sein.  Ich habe den Client mit Alvin auf denselben Computer gestellt - und die Anfrage an <code>localhost</code> gesendet.  Und die Zunahme der Verzögerung ist verschwunden! <br><br><img src="https://habrastorage.org/webt/kl/bk/fv/klbkfv7ajppr9uqp_tywvxwgjre.png"><br><br>  Mit dem Netzwerk stimmte etwas nicht. <br><br><h3>  Erlernen der Fähigkeiten eines Netzwerktechnikers </h3><br>  Ich muss zugeben: Mein Wissen über Netzwerktechnologien ist schrecklich, insbesondere angesichts der Tatsache, dass ich täglich mit ihnen arbeite.  Aber das Netzwerk war der Hauptverdächtige, und ich musste lernen, wie man es debuggt. <br><br>  Glücklicherweise liebt das Internet diejenigen, die lernen wollen.  Die Kombination von Ping und Tracert schien ein guter Anfang zu sein, um Netzwerktransportprobleme zu beheben. <br><br>  Zuerst habe ich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PsPing</a> auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Alvins</a> TCP-Port ausgeführt.  Ich habe die Standardoptionen verwendet - nichts Besonderes.  Von den mehr als tausend Pings überschritt keiner 10 ms, mit Ausnahme des ersten zum Aufwärmen.  Dies widerspricht dem beobachteten Anstieg der Verzögerung von 50 ms im 99. Perzentil: Dort sollten wir für jeweils 100 Anfragen etwa eine Anfrage mit einer Verzögerung von 50 ms sehen. <br><br>  Dann habe ich es mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tracert</a> versucht: Vielleicht liegt das Problem an einem der Knoten entlang der Route zwischen Alvin und dem Client.  Aber der Tracer kam mit leeren Händen zurück. <br><br>  Der Grund für die Verzögerung war also nicht mein Code, nicht die Implementierung von gRPC und nicht das Netzwerk.  Ich habe bereits angefangen, mir Sorgen zu machen, dass ich das nie verstehen werde. <br><br><h3>  Auf welchem ​​Betriebssystem sind wir jetzt? </h3><br>  <code>gRPC</code> unter Linux weit verbreitet, für Windows jedoch exotisch.  Ich entschied mich für ein Experiment, das funktionierte: Ich erstellte eine virtuelle Linux-Maschine, kompilierte Alvin für Linux und stellte sie bereit. <br><br><img src="https://habrastorage.org/webt/z1/t8/tk/z1t8tkyhrobvurzcdqlmpdtetzc.png"><br><br>  Und hier ist, was passiert ist: Der Ping-Pong-Linux-Server hatte keine Verzögerungen wie ein ähnlicher Windows-Knoten, obwohl sich die Datenquelle nicht unterschied.  Es stellt sich heraus, dass das Problem in der Implementierung von gRPC für Windows liegt. <br><br><h3>  Nagle-Algorithmus </h3><br>  Die ganze Zeit dachte ich, ich hätte die <code>gRPC</code> Flagge verpasst.  Jetzt wurde mir klar, dass das Windows-Flag in <code>gRPC</code> fehlt.  Ich fand die interne RPC-Bibliothek, in der ich sicher war, dass sie für alle installierten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Winsock-</a> Flags gut funktioniert.  Dann fügte er all diese Flags zu gRPC hinzu und stellte Alvin für Windows auf dem festen Ping-Pong-Server für Windows bereit! <br><br><img src="https://habrastorage.org/webt/7o/it/sf/7oitsfp2rzxotix0cf1xhktbrri.png"><br><br>  <i>Fast</i> fertig: Ich fing an, die hinzugefügten Flags einzeln zu löschen, bis die Regression zurückkehrte, damit ich die Ursache ermitteln konnte.  Es war der berüchtigte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TCP_NODELAY</a> , ein Schalter des Nagle-Algorithmus. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Neigl-Algorithmus</a> versucht, die Anzahl der über das Netzwerk gesendeten Pakete zu reduzieren, indem die Übertragung von Nachrichten verzögert wird, bis die Paketgröße eine bestimmte Anzahl von Bytes überschreitet.  Obwohl dies für den durchschnittlichen Benutzer angenehm sein kann, ist es für Echtzeitserver destruktiv, da das Betriebssystem einige Nachrichten verzögert und Verzögerungen bei niedrigem QPS verursacht.  <code>gRPC</code> hatte dieses Flag in der Linux-Implementierung für TCP-Sockets gesetzt, jedoch nicht für Windows.  Ich habe es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">repariert</a> . <br><br><h1>  Fazit </h1><br>  Eine große Verzögerung bei niedrigem QPS wurde durch die Betriebssystemoptimierung verursacht.  Rückblickend hat die Profilerstellung keine Verzögerung festgestellt, da sie im Kernelmodus und nicht im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Benutzermodus ausgeführt wurde</a> .  Ich weiß nicht, ob es möglich ist, den Nagle-Algorithmus durch ETW-Captures zu beobachten, aber das wäre interessant. <br><br>  Das localhost-Experiment hat wahrscheinlich den tatsächlichen Netzwerkcode nicht berührt, und der Neigl-Algorithmus wurde nicht gestartet, sodass die Verzögerungsprobleme verschwanden, als der Client Alvin über localhost kontaktierte. <br><br>  Wenn Sie das nächste Mal eine Erhöhung der Latenz feststellen und gleichzeitig die Anzahl der Anforderungen pro Sekunde verringern, sollte der Neigl-Algorithmus auf Ihrer Liste der Verdächtigen stehen! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de451904/">https://habr.com/ru/post/de451904/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de451894/index.html">Ein kurzer und übersichtlicher Überblick über die Compiler-Architektur</a></li>
<li><a href="../de451896/index.html">Eine "unzerbrechliche" eyeDisk ist durch einen Iris-Scan geschützt, überträgt jedoch ein Passwort im Klartext</a></li>
<li><a href="../de451898/index.html">Innovation auf Russisch</a></li>
<li><a href="../de451900/index.html">Erster Beitrag zur Browser-API von Facebook</a></li>
<li><a href="../de451902/index.html">Microsoft Azure Developer Camp Russland</a></li>
<li><a href="../de451906/index.html">Exchange-Sicherheitsanfälligkeit: Ermitteln der Erhöhung der Berechtigung für einen Domänenadministrator</a></li>
<li><a href="../de451908/index.html">Die Geschichte der Computer: eine Nacht im Yandex Museum</a></li>
<li><a href="../de451912/index.html">Das tiefe neuronale Netzwerk von MuseNet schreibt Musik</a></li>
<li><a href="../de451916/index.html">Asynchrones PHP und die Geschichte eines Fahrrads</a></li>
<li><a href="../de451918/index.html">Auf die Frage von TI</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
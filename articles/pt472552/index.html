<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòá üßìüèª üåÇ 63 n√∫cleos bloqueados por sete instru√ß√µes ‚ù§Ô∏è üöµüèΩ üëãüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Parece que tenho o h√°bito de escrever sobre m√°quinas poderosas , onde muitos n√∫cleos ficam ociosos devido a bloqueios incorretos. Ent√£o ... sim. Mais ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>63 n√∫cleos bloqueados por sete instru√ß√µes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/472552/"> Parece que tenho o h√°bito de escrever sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">m√°quinas poderosas</a> , onde muitos n√∫cleos ficam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ociosos</a> devido a bloqueios incorretos.  Ent√£o ... sim.  Mais uma vez sobre isso. <br><br>  Esta hist√≥ria √© especialmente impressionante.  De fato, com que freq√º√™ncia voc√™ tem um thread girado por alguns segundos em um ciclo de sete comandos, mantendo um bloqueio que interrompe o trabalho de 63 outros processadores?  √â simplesmente incr√≠vel, em um sentido terr√≠vel. <br><br>  Ao contr√°rio da cren√ßa popular, na verdade n√£o tenho uma m√°quina com 64 processadores l√≥gicos e nunca vi esse problema em particular.  Mas meu amigo correu para l√°, <s><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">esse nerd me enganou,</a></s> ele pediu ajuda, e eu decidi que o problema era bastante interessante.  Ele enviou um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rastreio ETW</a> com informa√ß√µes suficientes para que a mente coletiva no Twitter resolvesse rapidamente o problema. <br><a name="habracut"></a><br>  A reclama√ß√£o do amigo foi bem simples: ele coletou a compila√ß√£o usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ninja</a> .  Normalmente, o ninja faz um √≥timo trabalho ao aumentar a carga, oferecendo suporte constante aos processos n + 2 para evitar o tempo de inatividade.  Mas aqui, o uso da CPU nos primeiros 17 segundos da montagem ficou assim: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/708/9d6/808/7089d68083b016688e6ec980981f52a4.png"><br><br>  Se voc√™ der uma olhada mais de perto (uma piada), poder√° ver uma linha fina em que a carga total da CPU cai de 100% para 0% em alguns segundos.  Em apenas meio segundo, a carga √© reduzida de 64 para dois ou tr√™s threads.  Aqui est√° um fragmento ampliado de uma dessas quedas - os segundos s√£o marcados ao longo do eixo horizontal: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/14a/f7a/6c3/14af7a6c3dbdb7563fa6e316ad7a21e2.png"><br><br>  O primeiro pensamento foi que o ninja n√£o pode criar processos rapidamente.  Eu j√° vi isso muitas vezes, geralmente devido √† interven√ß√£o de um software antiv√≠rus.  Mas quando eu classifiquei os gr√°ficos no final do per√≠odo, descobri que durante essas falhas nenhum processo foi conclu√≠do, ent√£o o ninja n√£o √© o culpado. <br><br>  A tabela <i>Uso da CPU (Precisa)</i> √© ideal para identificar a causa do tempo de inatividade.  Os logs de todas as altern√¢ncias de contexto s√£o armazenados l√°, incluindo registros precisos de cada in√≠cio do fluxo, incluindo o local e o tempo limite. <br><br>  O truque √© que n√£o h√° nada errado com o tempo de inatividade.  O problema surge quando realmente queremos que o encadeamento fa√ßa o trabalho, mas est√° ocioso.  Portanto, voc√™ precisa selecionar certos momentos de inatividade. <br><br>  Ao analisar, √© importante entender que a altern√¢ncia de contexto ocorre quando um encadeamento retoma a opera√ß√£o.  Se olharmos para esses lugares quando a carga do processador come√ßar a cair, n√£o encontraremos nada.  Em vez disso, concentre-se em quando o sistema come√ßou a funcionar novamente.  Essa fase de rastreamento √© ainda mais dram√°tica.  Enquanto a queda de carga da CPU leva meio segundo, o processo inverso de um thread usado para um carregamento completo leva apenas doze milissegundos!  O gr√°fico abaixo √© bastante ampliado e, no entanto, a transi√ß√£o da ociosidade para a carga √© quase uma linha vertical: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d7f/cd4/cc6/d7fcd4cc68e55c5d6c7ff16cc8a5b32d.png"><br><br>  Aumentei o zoom para doze milissegundos e encontrei 500 comutadores de contexto, uma an√°lise cuidadosa √© necess√°ria aqui. <br><br>  A tabela de altern√¢ncia de contexto possui muitas colunas que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documentei aqui</a> .  Quando um processo congela, para encontrar o motivo, fa√ßo um agrupamento por novos processos, novos threads, novas pilhas de threads, etc. ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">discutido aqui</a> ), mas isso n√£o funciona em centenas de processos interrompidos.  Se eu estudei algum processo errado, √© claro que ele foi preparado pelo processo anterior, que foi preparado pelo anterior, e percorrerei uma longa cadeia para encontrar o primeiro elo que (presumivelmente) mant√©m uma trava importante por um longo tempo. <br><br>  Ent√£o, tentei um layout de coluna diferente no programa: <br><br><ul><li>  <i>Hora da</i> altern√¢ncia (quando ocorreu a altern√¢ncia de contexto) <br></li><li>  <i>Processo de prepara√ß√£o</i> (que liberou o bloqueio depois de esperar) <br></li><li>  <i>Novo processo</i> (quem come√ßou a trabalhar) <br></li><li>  <i>Tempo desde a √∫ltima vez</i> (h√° quanto tempo o novo processo est√° aguardando) </li></ul><br>  Isso fornece uma lista ordenada por tempo de altern√¢ncias de contexto com uma anota√ß√£o de quem preparou quem e por quanto tempo os processos estavam prontos para funcionar. <br><br>  Acabou que isso √© suficiente.  A tabela abaixo fala por si s√≥, se voc√™ souber ler.  As primeiras poucas altern√¢ncias de contexto n√£o s√£o interessantes, porque o tempo de espera para um novo processo (Tempo desde a √∫ltima vez) √© muito pequeno, mas na linha destacada (# 4) come√ßa uma coisa interessante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0d7/106/72f/0d710672f2cafc1bd7a2953a42ea55dd.png"><br><br>  Esta linha diz que o <i>Sistema (4)</i> preparou o <i>Exe (3032)</i> , que esperou 3,368 segundos.  A linha seguinte diz que em menos de 0,1 ms, o <i>cl Exe (3032)</i> preparou o <i>cl.exe (16232)</i> , que esperou 3,367 segundos.  E assim por diante <br><br>  V√°rias op√ß√µes de contexto, como na linha 7, n√£o est√£o inclu√≠das na cadeia de espera, mas simplesmente refletem outros trabalhos no sistema, mas, em geral, a cadeia √© esticada para v√°rias dezenas de elementos. <br><br>  Isso significa que todos esses processos est√£o aguardando o lan√ßamento do mesmo bloqueio.  Quando o processo do <i>sistema (4)</i> libera o bloqueio (depois de pression√°-lo por 3.368 segundos!), Os processos em espera, por sua vez, o capturam, realizam seu pequeno trabalho e passam o bloqueio.  A fila de espera possui cerca de cem processos, o que mostra o grau de influ√™ncia de um √∫nico bloqueio. <br><br>  Um pequeno estudo do <i>Ready Thread Stacks</i> mostrou que a maioria das expectativas vem do <i>KernelBase.dllWriteFile</i> .  Pedi ao WPA para exibir os chamadores dessa fun√ß√£o, com agrupamento.  L√° voc√™ pode ver que, em 12 milissegundos dessa catarse, 174 threads saem da espera do <i>WriteFile</i> e esperaram uma m√©dia de 1.184 segundos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c63/a77/73d/c63a7773d08b42f2def485247d57e916.png"><br>  <i><font color="gray">174 threads aguardando WriteFile, tempo m√©dio de espera 1.184 segundos</font></i> <br><br>  Esse √© um atraso incr√≠vel e, de fato, nem toda a extens√£o do problema, porque muitos threads de outras fun√ß√µes, como <i>KernelBase.dll! GetQueuedCompletionStatus,</i> esperam o lan√ßamento do mesmo bloqueio. <br><br><h2>  O que o sistema faz (4) </h2><br>  Nesse ponto, eu sabia que o progresso da compila√ß√£o parou porque todos os processos do compilador e outros esperavam o <i>WriteFile</i> , pois o <i>System (4)</i> retinha o bloqueio.  Outra coluna <i>Ready Id do segmento</i> mostrou que o segmento 3276 liberou o bloqueio no processo do sistema. <br><br>  Durante todos os "travamentos" da montagem, o encadeamento 3276 foi 100% carregado, portanto, √© claro que ele trabalhou na CPU enquanto mantinha a trava travada.  Para descobrir onde o tempo da CPU √© gasto, vejamos o <i>gr√°fico Uso</i> da <i>CPU (Amostrado)</i> do thread 3276. Os dados de uso da CPU foram surpreendentemente claros.  Quase todo o tempo √© necess√°rio o trabalho de uma fun√ß√£o <i>ntoskrnl.exe! RtlFindNextForwardRunClear</i> (o n√∫mero de amostras √© indicado na coluna com n√∫meros): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0fc/0ce/2fc/0fc0ce2fc4485818ba45f9504f4c8181.png"><br>  <i><font color="gray">A pilha de chamadas leva ao ntoskrnl.exe! RtlFindNextForwardRunClear</font></i> <br><br>  A exibi√ß√£o da <i>ID de thread de</i> <i>prepara√ß√£o</i> da pilha de <i>threads</i> confirmou que o <i>NtfsCheckpointVolume</i> liberou o bloqueio ap√≥s 3.368 s: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a43/225/a97/a43225a974de7651a6b51dc04b339364.png"><br>  <i><font color="gray">Pilha de chamadas de NtfsCheckpointVolume para ExReleaseResourceLite</font></i> <br><br>  Nesse momento, pareceu-me que estava na hora de usar o rico conhecimento de meus seguidores no Twitter, ent√£o postei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">essa pergunta</a> e mostrei uma pilha de chamadas completa.  Os tweets com essas perguntas podem ser muito eficazes se voc√™ fornecer informa√ß√µes suficientes. <br><br>  Nesse caso, a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">resposta certa</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Caitlin Gadd</a> veio muito rapidamente, juntamente com muitas outras √≥timas sugest√µes.  Ela desativou o recurso de recupera√ß√£o do sistema - e de repente a compila√ß√£o foi duas a tr√™s vezes mais r√°pida! <br><br><h2>  Mas espere, mais ainda √© melhor </h2><br>  Bloquear a execu√ß√£o em todo o sistema por mais de 3 segundos √© bastante impressionante, mas a situa√ß√£o √© ainda mais impressionante se voc√™ adicionar a coluna <i>Endere√ßo</i> √† tabela <i>Uso de CPU (Amostrada)</i> e classific√°-la.  Ele mostra onde exatamente <i>as</i> amostras <i>RtlFindNextForwardRunClear s√£o</i> obtidas - e 99% delas se enquadram em uma instru√ß√£o! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aec/1e3/9b6/aec1e39b65cddb3473242514e7cea1a9.png"><br><br>  Peguei os <i>arquivos ntoskrnl.exe</i> e <i>ntkrnlmp.pdb</i> (a mesma vers√£o do meu amigo) e executei o <code>dumpbin /disasm</code> para visualizar a fun√ß√£o de interesse no assembler.  Os primeiros d√≠gitos dos endere√ßos s√£o diferentes porque o c√≥digo √© movido na inicializa√ß√£o, mas os √∫ltimos quatro valores hexadecimais s√£o os mesmos (eles n√£o mudam ap√≥s o ASLR): <br><br><pre>  RtlFindNextForwardRunClear:
 ...
 14006464F: 4C 3B C3 cmp r8, rbx
 140064652: 73 0F jae 0000000140064663
 140064654: 41 39 28 cmp dword ptr [r8], ebp
 140064657: 75 0A jne 0000000140064663
 140064659: 49 83 C0 04 adicionar r8.4
 14006465D: 41 83 C1 20 add r9d, 20h
 140064661: EB CE jmp 000000014006464F
 ... </pre><br>  Vemos que as instru√ß√µes em ... 4657 est√£o inclu√≠das em um ciclo de sete instru√ß√µes, encontradas em outras amostras.  O n√∫mero de tais amostras √© indicado √† direita: <br><br><pre>  RtlFindNextForwardRunClear:
 ...
 14006464F: 4C 3B C3 cmp r8, rbx 4
 140064652: 73 0F jae 0000000140064663 41
 140064654: 41 39 28 cmp dword ptr [r8], ebp     
 140064657: 75 0A jne 0000000140064663 7498
 140064659: 49 83 C0 04 adicionar r8.4 2
 14006465D: 41 83 C1 20 add r9d, 20h 1
 140064661: EB CE jmp 000000014006464F 1
 ... </pre><br>  Como exerc√≠cio para o leitor, deixemos a interpreta√ß√£o do n√∫mero de amostras em um processador superescalar com uma execu√ß√£o extraordin√°ria de instru√ß√µes, embora algumas boas id√©ias possam ser encontradas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste artigo</a> .  Nesse caso, temos um AMD Ryzen Threadripper 2990WX de 32 n√∫cleos.  Aparentemente, a fun√ß√£o de processador do Micro-Up Fusion com a execu√ß√£o de cinco instru√ß√µes por vez permite que cada ciclo seja conclu√≠do em jne, uma vez que a instru√ß√£o ap√≥s a instru√ß√£o mais cara cai na maioria das interrup√ß√µes na sele√ß√£o. <br><br>  Portanto, uma m√°quina com 64 processadores l√≥gicos para em um ciclo de sete comandos no processo do sistema, mantendo um bloqueio NTFS vital, que √© corrigido pela desativa√ß√£o da recupera√ß√£o do sistema. <br><br><h2>  Coda </h2><br>  N√£o est√° claro por que esse c√≥digo se comportou mal nessa m√°quina espec√≠fica.  Suponho que isso esteja relacionado √† distribui√ß√£o de dados em um disco de 2 TB quase vazio.  Quando a recupera√ß√£o do sistema foi reativada, o problema tamb√©m voltou, mas n√£o t√£o grave.  Talvez haja algum tipo de patologia para discos com enormes fragmentos de espa√ßo vazio? <br><br>  Outro seguidor no Twitter mencionou o bug Volume Shadow Copy do Windows 7, que permite a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">execu√ß√£o durante O (n ^ 2)</a> .  Este erro foi corrigido no Windows 8, mas pode ter sido preservado de alguma forma.  Meus rastreamentos de pilha mostram claramente que <i>VspUpperFindNextForwardRunClearLimited</i> (localizando um bit usado nesta √°rea de 16 megabytes) chama <i>VspUpperFindNextForwardRunClear</i> (procurando o pr√≥ximo bit usado em qualquer lugar, mas n√£o o retorna se estiver fora da √°rea especificada).  Obviamente, isso causa um certo senso de d√©j√† vu.  Como eu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">disse recentemente</a> , O (n ^ 2) √© um ponto fraco de algoritmos pouco escal√°veis.  Dois fatores coincidem aqui: esse c√≥digo √© r√°pido o suficiente para entrar em produ√ß√£o, mas lento o suficiente para interromper essa produ√ß√£o. <br><br>  Houve relatos de que um problema semelhante ocorre com uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">exclus√£o maci√ßa de arquivos</a> , mas nosso rastreamento n√£o mostra muitas exclus√µes; portanto, o problema, aparentemente, n√£o √© esse. <br><br>  Concluindo, duplicarei a programa√ß√£o de carregamento da CPU em todo o sistema desde o in√≠cio do artigo, mas desta vez indicando o uso da CPU pelo processo de problemas do <i>sistema</i> (em verde abaixo).  Nessa imagem, o problema √© completamente √≥bvio.  O processo do sistema √© tecnicamente vis√≠vel no gr√°fico superior, mas nessa escala √© f√°cil perder. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4fb/ca1/9ff/4fbca19ffabb57dd7f17d40417eee0ca.png"><br><br>  Embora o problema esteja claramente vis√≠vel no gr√°fico, na verdade n√£o prova nada.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Como se costuma dizer</a> , a correla√ß√£o n√£o √© uma rela√ß√£o causal.  Somente uma an√°lise dos eventos de altern√¢ncia de contexto mostra que √© esse fluxo que mant√©m o bloqueio cr√≠tico - e ent√£o voc√™ pode ter certeza de que encontramos a causa real, e n√£o apenas uma correla√ß√£o aleat√≥ria. <br><br><h2>  Inqu√©ritos </h2><br>  Como sempre, concluo esta investiga√ß√£o com uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">chamada para melhor nomear os threads</a> .  O processo do sistema possui dezenas de threads, muitos dos quais com uma finalidade especial e nenhum com um nome.  O segmento do sistema mais ocupado nesse rastreamento foi o <i>MiZeroPageThread</i> .  Eu mergulhava repetidamente em sua pilha, e cada vez que lembrava que n√£o era do seu interesse.  O compilador VC ++ tamb√©m n√£o nomeia seus threads.  N√£o leva muito tempo para renomear os fluxos e √© realmente √∫til.  Apenas d√™ o nome.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">√â simples</a>  O Chromium ainda inclui uma ferramenta para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">listar nomes de fluxos em um processo</a> . <br><br>  Se algu√©m da equipe NTFS da Microsoft quiser falar sobre esse t√≥pico, informe-me e eu posso conect√°-lo ao autor do relat√≥rio original e fornecer um rastreamento ETW. <br><br><h2>  Refer√™ncias </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">T√≥pico</a> original no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Twitter</a> <br></li><li>  An√∫ncio de publica√ß√£o no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Twitter</a> <br></li><li>  Discuss√£o em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hacker News</a> <br></li><li>  Discuss√£o no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Reddit</a> <br></li><li>  Aprecia√ß√£o do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Windows / NTFS</a> possivelmente relevante </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt472552/">https://habr.com/ru/post/pt472552/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt472536/index.html">Smart IdReader SDK - incorporar reconhecimento em projetos em Python e PHP</a></li>
<li><a href="../pt472540/index.html">Eles acordam! (n¬∫ hist√≥ria, parte 2 e a √∫ltima)</a></li>
<li><a href="../pt472544/index.html">Truques de marketing do Pornhub: o que o site mais tocante de hoje diz</a></li>
<li><a href="../pt472548/index.html">Como fomos ao mercado (e n√£o conseguimos nada de especial)</a></li>
<li><a href="../pt472550/index.html">Lan√ßamento de um neg√≥cio de TI: as 4 principais franquias tecnol√≥gicas de 2019</a></li>
<li><a href="../pt472556/index.html">O segredo da felicidade dos funcion√°rios √© a natureza no escrit√≥rio?</a></li>
<li><a href="../pt472560/index.html">Teste Gestalt: uma nova abordagem para otimiza√ß√£o de mala direta com base na teoria bayesiana e aprendizado de m√°quina</a></li>
<li><a href="../pt472562/index.html">Tend√™ncias financeiras: grandes empresas precisam de mais e mais profissionais de TI</a></li>
<li><a href="../pt472566/index.html">O inferno pessoal do escritor Fraerman, ou o Conto do Primeiro Amor</a></li>
<li><a href="../pt472568/index.html">Apache Ignite Zero Deployment: exatamente zero?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
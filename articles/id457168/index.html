<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏽‍🤝‍👨🏻 👧🏾 🏺 Analisis Sentimen Prototipe dengan Python dan TextBlob 📧 👁‍🗨 💆🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Apa yang penting bagi tim pengembangan yang baru mulai membangun sistem pembelajaran mesin? Arsitektur, komponen, kemampuan pengujian menggunakan inte...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analisis Sentimen Prototipe dengan Python dan TextBlob</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457168/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/8l/ir/g2/8lirg2klkrmofom9vhhcgldh-qo.jpeg" alt="gambar"></div><br>  Apa yang penting bagi tim pengembangan yang baru mulai membangun sistem pembelajaran mesin?  Arsitektur, komponen, kemampuan pengujian menggunakan integrasi dan pengujian unit, membuat prototipe dan mendapatkan hasil pertama.  Dan selanjutnya untuk penilaian input tenaga kerja, pengembangan perencanaan dan implementasi. <br><br>  Artikel ini akan fokus pada prototipe.  Yang dibuat beberapa saat setelah berbicara dengan Manajer Produk: mengapa kita tidak "menyentuh" ​​Pembelajaran Mesin?  Secara khusus, NLP dan Analisis Sentimen? <br><a name="habracut"></a><br>  "Kenapa tidak?"  Saya jawab.  Namun, saya sudah melakukan pengembangan backend selama lebih dari 15 tahun, saya suka bekerja dengan data dan memecahkan masalah kinerja.  Tapi saya masih harus mencari tahu, "seberapa dalam lubang kelinci". <br><br><h2>  Pilih komponen </h2><br>  Untuk menjabarkan sekumpulan komponen yang menerapkan logika inti ML kami, mari kita lihat contoh sederhana penerapan analisis sentimen, salah satu dari banyak yang tersedia di GitHub. <br><br><div class="spoiler">  <b class="spoiler_title">Salah satu contoh analisis sentimen dengan Python</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nltk <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( datasets, model_selection, feature_extraction, linear_model ) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">extract_features</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(corpus)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">'''Extract TF-IDF features from corpus'''</span></span> <span class="hljs-comment"><span class="hljs-comment"># vectorize means we turn non-numerical data into an array of numbers count_vectorizer = feature_extraction.text.CountVectorizer( lowercase=True, # for demonstration, True by default tokenizer=nltk.word_tokenize, # use the NLTK tokenizer stop_words='english', # remove stop words min_df=1 # minimum document frequency, ie the word must appear more than once. ) processed_corpus = count_vectorizer.fit_transform(corpus) processed_corpus = feature_extraction.text.TfidfTransformer().fit_transform( processed_corpus) return processed_corpus data_directory = 'movie_reviews' movie_sentiment_data = datasets.load_files(data_directory, shuffle=True) print('{} files loaded.'.format(len(movie_sentiment_data.data))) print('They contain the following classes: {}.'.format( movie_sentiment_data.target_names)) movie_tfidf = extract_features(movie_sentiment_data.data) X_train, X_test, y_train, y_test = model_selection.train_test_split( movie_tfidf, movie_sentiment_data.target, test_size=0.30, random_state=42) # similar to nltk.NaiveBayesClassifier.train() model = linear_model.LogisticRegression() model.fit(X_train, y_train) print('Model performance: {}'.format(model.score(X_test, y_test))) y_pred = model.predict(X_test) for i in range(5): print('Review:\n{review}\n-\nCorrect label: {correct}; Predicted: {predict}'.format( review=X_test[i], correct=y_test[i], predict=y_pred[i] ))</span></span></code> </pre> <br></div></div><br>  Mengurai contoh seperti itu merupakan tantangan tersendiri bagi pengembang. <br>  Hanya 45 baris kode, dan 4 (empat, Karl!) Blok logis sekaligus: <br><br><ol><li>  Mengunduh data untuk pelatihan model (baris 25-26) </li><li>  Mempersiapkan data yang diunggah - ekstraksi fitur (baris 31-34) </li><li>  Membuat dan melatih model (baris 36-39) </li><li>  Menguji model yang terlatih dan mengeluarkan hasil (baris 41-45) </li></ol><br>  Masing-masing poin ini layak mendapat artikel terpisah.  Dan itu tentu membutuhkan registrasi dalam modul terpisah.  Setidaknya untuk kebutuhan pengujian unit. <br><br>  Secara terpisah, ada baiknya menyoroti komponen-komponen persiapan data dan pelatihan model. <br>  Dalam setiap cara untuk membuat model lebih tepat, ratusan jam kerja ilmiah dan teknik diinvestasikan. <br><br>  Untungnya, untuk memulai dengan NLP dengan cepat, ada solusi siap pakai - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">perpustakaan NLTK</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">TextBlob</a> .  Yang kedua adalah pembungkus NLTK yang melakukan tugas - membuat ekstraksi fitur dari set pelatihan, dan kemudian melatih model pada permintaan klasifikasi pertama. <br><br>  Tetapi sebelum Anda melatih model, Anda harus menyiapkan data untuk itu. <br><br><h2>  Mempersiapkan data </h2><br><h3>  Unduh data </h3><br>  Jika kita berbicara tentang prototipe, maka memuat data dari file CSV / TSV adalah dasar.  Anda cukup memanggil fungsi <b>read_csv</b> dari panda library: <br><br><pre> <code class="plaintext hljs">import pandas as pd data = pd.read_csv(data_path, delimiter)</code> </pre><br>  Tetapi itu tidak akan menjadi data yang siap digunakan dalam model. <br><br>  Pertama, jika kita sedikit mengabaikan format csv, maka mudah untuk berharap bahwa setiap sumber akan menyediakan data dengan karakteristiknya sendiri, dan oleh karena itu kita memerlukan semacam persiapan data yang bergantung pada sumber.  Bahkan untuk kasus paling sederhana dari file CSV, untuk hanya menguraikannya, kita perlu mengetahui pembatas. <br><br>  Selain itu, Anda harus menentukan entri mana yang positif dan mana yang negatif.  Tentu saja, informasi ini ditunjukkan dalam anotasi ke kumpulan data yang ingin kita gunakan.  Tetapi kenyataannya adalah bahwa dalam satu kasus tanda pos / neg adalah 0 atau 1, di lain itu adalah logis Benar / Salah, dalam ketiga itu hanya string pos / neg, dan dalam beberapa kasus, sebuah tupel bilangan bulat dari 0 hingga 5 Yang terakhir ini relevan untuk kasus klasifikasi multi-kelas, tetapi siapa yang mengatakan bahwa kumpulan data seperti itu tidak dapat digunakan untuk klasifikasi biner?  Anda hanya perlu mengidentifikasi batas nilai positif dan negatif secara memadai. <br><br>  Saya ingin mencoba model pada set data yang berbeda, dan diperlukan, setelah pelatihan, model mengembalikan hasilnya dalam satu format tunggal.  Dan untuk ini, data heterogennya harus dibawa ke satu bentuk. <br><br>  Jadi, ada tiga fungsi yang kita butuhkan pada tahap pemuatan data: <br><br><ol><li>  Koneksi ke sumber data adalah untuk CSV, dalam kasus kami ini diterapkan di dalam fungsi read_csv; </li><li>  Dukungan untuk fitur format; </li><li>  Persiapan data awal. </li></ol><br>  Ini adalah tampilannya dalam kode. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># linear algebra import pandas as pd # data processing, CSV file I/O (eg pd.read_csv) import logging log = logging.getLogger() class CsvSentimentDataLoader(): def __init__(self, file_path, delim, text_attr, rate_attr, pos_rates): self.data_path = file_path self.delimiter = delim self.text_attr = text_attr self.rate_attr = rate_attr self.pos_rates = pos_rates def load_data(self): #     csv  tsv  data = pd.read_csv(self.data_path, self.delimiter) data.head() #   , #      data = data[[self.text_attr, self.rate_attr]] #    #     'pos'  'neg' data[self.rate_attr] = np.where( data[self.rate_attr].isin(self.pos_rates), 'pos', 'neg') return data</span></span></code> </pre><br>  Kelas <b>CsvSentimentDataLoader</b> dibuat, yang dalam konstruktor melewati path ke csv, pemisah, nama teks dan atribut klasifikasi, serta daftar nilai yang menyarankan nilai positif dari teks. <br><br>  Pemuatan itu sendiri terjadi dalam metode <b>load_data</b> . <br><br><h3>  Kami membagi data menjadi set tes dan pelatihan </h3><br>  Oke, kami mengunggah data, tetapi kami masih perlu membaginya ke dalam set pelatihan dan tes. <br><br>  Ini dilakukan dengan fungsi <b>train_test_split</b> dari pustaka <b>sklearn</b> .  Fungsi ini dapat mengambil banyak parameter sebagai input, menentukan bagaimana tepatnya dataset ini akan dibagi menjadi kereta dan pengujian.  Parameter ini secara signifikan mempengaruhi hasil pelatihan dan set tes, dan mungkin akan mudah bagi kita untuk membuat kelas (sebut saja SimpleDataSplitter) yang akan mengelola parameter ini dan mengagregasikan panggilan ke fungsi ini. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-comment"><span class="hljs-comment"># to split the training and testing data import logging log = logging.getLogger() class SimpleDataSplitter(): def __init__(self, text_attr, rate_attr, test_part_size=.3): self.text_attr = text_attr self.rate_attr = rate_attr self.test_part_size = test_part_size def split_data(self, data): x = data[self.text_attr] y = data[self.rate_attr] x_train, x_test, y_train, y_test = train_test_split( x, y, test_size = self.test_part_size) return x_train, x_test, y_train, y_test</span></span></code> </pre><br>  Sekarang kelas ini termasuk implementasi paling sederhana, yang, ketika dibagi, akan mempertimbangkan hanya satu parameter - persentase catatan yang harus diambil sebagai set uji. <br><br><h3>  Kumpulan data </h3><br>  Untuk melatih model, saya menggunakan dataset yang tersedia secara bebas dalam format CSV: <br><br><ul><li>  Kumpulan Data Ulasan Amazon Alexa, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tersedia di Kaggle</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kumpulan Data Kalimat Berlabel Sentimen</a> Universitas California </li></ul><br>  Dan agar lebih nyaman, untuk masing-masing dataset saya membuat kelas yang memuat data dari file CSV yang sesuai dan membaginya menjadi pelatihan dan set tes. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> web.data.loaders <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> CsvSentimentDataLoader <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> web.data.splitters <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SimpleDataSplitter, TdIdfDataSplitter log = logging.getLogger() <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AmazonAlexaDataset</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self.file_path = os.path.normpath(os.path.join(os.path.dirname(__file__), <span class="hljs-string"><span class="hljs-string">'amazon_alexa/train.tsv'</span></span>)) self.delim = <span class="hljs-string"><span class="hljs-string">'\t'</span></span> self.text_attr = <span class="hljs-string"><span class="hljs-string">'verified_reviews'</span></span> self.rate_attr = <span class="hljs-string"><span class="hljs-string">'feedback'</span></span> self.pos_rates = [<span class="hljs-number"><span class="hljs-number">1</span></span>] self.data = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.train = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.test = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> loader = CsvSentimentDataLoader(self.file_path, self.delim, self.text_attr, self.rate_attr, self.pos_rates) splitter = SimpleDataSplitter(self.text_attr, self.rate_attr, test_part_size=<span class="hljs-number"><span class="hljs-number">.3</span></span>) self.data = loader.load_data() x_train, x_test, y_train, y_test = splitter.split_data(self.data) self.train = [x <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(x_train, y_train)] self.test = [x <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(x_test, y_test)]</code> </pre><br>  Ya, untuk pemuatan data, ternyata sedikit lebih dari 5 baris kode dalam contoh asli. <br>  Tapi sekarang sekarang mungkin untuk membuat dataset baru dengan menyulap sumber data dan pelatihan algoritma persiapan set. <br><br>  Plus, masing-masing komponen jauh lebih nyaman untuk pengujian unit. <br><br><h2>  Kami melatih model </h2><br>  Model ini telah belajar selama beberapa waktu.  Dan ini harus dilakukan sekali, pada awal aplikasi. <br>  Untuk tujuan ini, pembungkus kecil dibuat yang memungkinkan Anda mengunduh dan menyiapkan data, serta melatih model pada saat inisialisasi aplikasi. <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TextBlobWrapper</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self.log = logging.getLogger() self.is_model_trained = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> self.classifier = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">init_app</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self.log.info(<span class="hljs-string"><span class="hljs-string">'&gt;&gt;&gt;&gt;&gt; TextBlob initialization started'</span></span>) self.ensure_model_is_trained() self.log.info(<span class="hljs-string"><span class="hljs-string">'&gt;&gt;&gt;&gt;&gt; TextBlob initialization completed'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ensure_model_is_trained</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> self.is_model_trained: ds = SentimentLabelledDataset() ds.load_data() <span class="hljs-comment"><span class="hljs-comment"># train the classifier and test the accuracy self.classifier = NaiveBayesClassifier(ds.train) acr = self.classifier.accuracy(ds.test) self.log.info(str.format('&gt;&gt;&gt;&gt;&gt; NaiveBayesClassifier trained with accuracy {}', acr)) self.is_model_trained = True return self.classifier</span></span></code> </pre><br>  Pertama kita mendapatkan data pelatihan dan tes, kemudian kita melakukan ekstraksi fitur, dan akhirnya kita melatih classifier dan memeriksa akurasi pada set tes. <br><br><h2>  Pengujian </h2><br>  Setelah inisialisasi, kami mendapatkan log, dilihat dari mana, data diunduh dan model berhasil dilatih.  Dan dilatih dengan akurasi (untuk pemula) yang sangat bagus - 0,8878. <br><br><img src="https://habrastorage.org/webt/nl/hw/pt/nlhwptjx8xnwfao2anynttvbr1u.png" alt="gambar"><br><br>  Setelah menerima angka seperti itu, saya sangat antusias.  Namun sayangnya, kegembiraan saya tidak lama.  Model yang dilatih pada set ini adalah seorang optimis yang tidak dapat ditembus dan, pada prinsipnya, tidak dapat mengenali komentar negatif. <br><br>  Alasan untuk ini adalah dalam data set pelatihan.  Jumlah ulasan positif di set lebih dari 90%.  Dengan demikian, dengan akurasi model sekitar 88%, ulasan negatif hanya jatuh ke dalam 12% yang diharapkan dari klasifikasi yang salah. <br><br>  Dengan kata lain, dengan set pelatihan seperti itu, tidak mungkin untuk melatih model untuk mengenali komentar negatif. <br><br>  Untuk benar-benar memastikan hal ini, saya melakukan tes unit yang menjalankan klasifikasi secara terpisah untuk 100 frasa positif dan 100 negatif dari kumpulan data lain - untuk pengujian saya mengambil <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Set Data Sentimen berlabel Kalimat Data</a> dari University of California. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta"> @loggingtestcase.capturelogs(None, level='INFO') def test_classifier_on_separate_set(self, logs): tb = TextBlobWrapper() # Going to be trained on Amazon Alexa dataset ds = SentimentLabelledDataset() # Test dataset ds.load_data() # Check poisitives true_pos = 0 data = ds.data.to_numpy() seach_mask = np.isin(data[:, 1], ['pos']) data = data[seach_mask][:100] for e in data[:]: # Model train will be performed on first classification call r = tb.do_sentiment_classification(e[0]) if r == e[1]: true_pos += 1 self.assertLessEqual(true_pos, 100) print(str.format('\n\nTrue Positive answers - {} of 100', true_pos))</span></span></code> </pre><br>  Algoritma untuk menguji klasifikasi nilai-nilai positif adalah sebagai berikut: <br><br><ul><li>  Unduh data uji; </li><li>  Ambil 100 pos yang ditandai 'pos' </li><li>  Kami menjalankan masing-masing melalui model dan menghitung jumlah hasil yang benar </li><li>  Tampilkan hasil akhir di konsol. </li></ul><br>  Demikian pula, penghitungan dibuat untuk komentar negatif. <br><br><div class="spoiler">  <b class="spoiler_title">Hasil</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/79/lj/px/79ljpxifxo5sl1kpdt_h0q4zd58.png" alt="gambar"><br></div></div><br>  Seperti yang diharapkan, semua komentar negatif diakui sebagai positif. <br><br>  Dan jika Anda melatih model pada dataset yang digunakan untuk pengujian - <b>Sentimen berlabel</b> ?  Di sana, distribusi komentar negatif dan positif tepat 50 hingga 50. <br><br><div class="spoiler">  <b class="spoiler_title">Ubah kode dan uji, jalankan</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/tj/cw/oo/tjcwoocc2qodmbd5zl7emwqt8ve.png" alt="gambar"><br></div></div><br>  Sudah ada sesuatu.  Akurasi aktual dari 200 entri dari set pihak ketiga adalah 76%, sedangkan akurasi klasifikasi komentar negatif adalah 79%. <br><br>  Tentu saja, 76% akan melakukan prototipe, tetapi tidak cukup untuk produksi.  Ini berarti bahwa langkah-langkah tambahan akan diperlukan untuk meningkatkan akurasi algoritma.  Tapi ini adalah topik untuk laporan lain. <br><br><h2>  Ringkasan </h2><br>  Pertama, kami mendapat aplikasi dengan selusin kelas dan 200+ baris kode, yang sedikit lebih dari contoh aslinya sebanyak 30 baris.  Dan Anda harus jujur ​​- ini hanya petunjuk pada struktur, klarifikasi pertama batas aplikasi masa depan.  Prototipe. <br><br>  Dan prototipe ini memungkinkan untuk menyadari seberapa jauh jarak antara pendekatan ke kode dari sudut pandang spesialis Pembelajaran Mesin dan dari sudut pandang pengembang aplikasi tradisional.  Dan ini, menurut saya, adalah kesulitan utama bagi pengembang yang memutuskan untuk mencoba pembelajaran mesin. <br><br>  Hal berikutnya yang dapat membuat pemula dalam keadaan pingsan - data tidak kalah penting dari model yang dipilih.  Ini telah ditunjukkan dengan jelas. <br><br>  Lebih lanjut, selalu ada kemungkinan bahwa model yang dilatih pada beberapa data akan menunjukkan dirinya tidak memadai pada orang lain, atau pada titik tertentu akurasinya akan mulai menurun. <br>  Oleh karena itu, metrik diperlukan untuk memantau keadaan model, fleksibilitas saat bekerja dengan data, kemampuan teknis untuk menyesuaikan pembelajaran dengan cepat.  Dan sebagainya. <br><br>  Bagi saya, semua ini harus diperhitungkan saat merancang arsitektur dan proses pengembangan bangunan. <br><br>  Secara umum, "lubang kelinci" tidak hanya sangat dalam, tetapi juga sangat cerdik.  Namun yang lebih menarik bagi saya, sebagai pengembang, untuk mempelajari topik ini di masa depan. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id457168/">https://habr.com/ru/post/id457168/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id457152/index.html">Konferensi DEFCON 25. Garry Kasparov. "Pertempuran terakhir otak." Bagian 1</a></li>
<li><a href="../id457154/index.html">Desain aplikasi responsif untuk setiap pengguna</a></li>
<li><a href="../id457156/index.html">Apa yang mungkin menjadi sistem komputasi masa depan</a></li>
<li><a href="../id457160/index.html">Pendekatan saya untuk mengimplementasikan delegasi di C ++: memanggil fungsi dengan parameter yang tidak diketahui saat runtime</a></li>
<li><a href="../id457164/index.html">Navigasi dalam aplikasi .NET Core lintas platform dengan kondisi penyimpanan ke disk menggunakan contoh ReactiveUI dan Avalonia</a></li>
<li><a href="../id457172/index.html">ScreenLogger - senyum, Anda difilmkan oleh kamera tersembunyi</a></li>
<li><a href="../id457178/index.html">Bagaimana prosesor dirancang dan diproduksi: desain CPU</a></li>
<li><a href="../id457180/index.html">Situs resmi Node.js sekarang dalam bahasa Rusia</a></li>
<li><a href="../id457182/index.html">Bahasa REXX, Hari Jadi ke-40</a></li>
<li><a href="../id457184/index.html">Secara dinamis membuat robots.txt untuk situs ASP.NET Core</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
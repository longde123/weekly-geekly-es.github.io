<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßôüèæ üêé üíì Tri√°ngulo de Pascal frente a cadenas del tipo "000 ... / 111 ..." en filas binarias y redes neuronales üì∫ üë®‚Äçüë©‚Äçüë¶‚Äçüë¶ üö≥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Serie "El ruido blanco dibuja un cuadrado negro" 

 La historia del ciclo de estas publicaciones comienza con el hecho de que en el libro de G. Sekey ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tri√°ngulo de Pascal frente a cadenas del tipo "000 ... / 111 ..." en filas binarias y redes neuronales</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/466761/"><h3>  Serie "El ruido blanco dibuja un cuadrado negro" </h3><br><br>  La historia del ciclo de estas publicaciones comienza con el hecho de que en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el</a> libro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de G. Sekey "Paradoxes in Probability Theory and Mathematical Statistics"</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">p. 43</a> ), se descubri√≥ la siguiente afirmaci√≥n: <br><br><img src="https://habrastorage.org/webt/cn/-m/ef/cn-mefhn6b-qjrp9hz2j68cqsek.jpeg"><br>  Fig.  1) <br><br>  Seg√∫n el an√°lisis, el comentario sobre las primeras publicaciones ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">parte 1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">parte 2</a> ) y el razonamiento posterior han madurado la idea de presentar este teorema en una forma m√°s visual. <br><br>  La mayor√≠a de los miembros de la comunidad est√°n familiarizados con el tri√°ngulo de Pascal, como consecuencia de la distribuci√≥n de probabilidad binomial y muchas leyes relacionadas.  Para comprender el mecanismo de la formaci√≥n del tri√°ngulo de Pascal, lo expandiremos con m√°s detalle, con el despliegue de los flujos de su formaci√≥n.  En el tri√°ngulo de Pascal, los nodos est√°n formados por la relaci√≥n de 0 y 1, la figura a continuaci√≥n. <br><br><img src="https://habrastorage.org/webt/qk/0v/l3/qk0vl3bjkxjbiwv--tb--seaw5u.jpeg"><br>  Fig.  2) <br><br>  Para comprender el teorema de Erds-Renyi, compondremos un modelo similar, pero los nodos se formar√°n a partir de los valores en los que est√°n presentes las cadenas m√°s grandes, que consisten secuencialmente en los mismos valores.  La agrupaci√≥n se realizar√° de acuerdo con la siguiente regla: cadenas 01/10, para agrupar "1";  cadena 00/11, para agrupar "2";  cadenas 000/111, para agrupar "3", etc.  En este caso, dividiremos la pir√°mide en dos componentes sim√©tricos Figura 3. <br><br><img src="https://habrastorage.org/webt/gc/vu/st/gcvustybe9qafooe2bqj6i-dg5i.jpeg"><br>  Fig.  3) <br><br>  Lo primero que llama la atenci√≥n es que todos los movimientos se producen desde un grupo inferior a uno superior y viceversa.  Esto es natural, ya que si se ha formado una cadena de tama√±o j, ya no puede desaparecer. <br><a name="habracut"></a><br>  Al determinar el algoritmo de concentraci√≥n de n√∫meros, logramos obtener la siguiente f√≥rmula de recurrencia, cuyo mecanismo se muestra en las Figuras 4-6. <br><br>  Denote los elementos en los que se concentran los n√∫meros, donde n es el n√∫mero de caracteres en el n√∫mero (n√∫mero de bits) y la longitud de la cadena m√°xima es m.  Y cada elemento recibir√° un √≠ndice n; mJ. <br>  Denota que el n√∫mero de elementos pas√≥ de n; mJ a n + 1; m + 1J, n; mjn + 1; m + 1. <br><br><img src="https://habrastorage.org/webt/fl/sb/4n/flsb4nctewg4uxq6n7yzknjtdz0.jpeg"><br>  Fig.  4) <br><br>  La Figura 4 muestra que para el primer grupo no es dif√≠cil determinar los valores de cada fila.  Y esta dependencia es igual a: <br><br><img src="https://habrastorage.org/webt/bj/x6/ig/bjx6ig0vj9ycnwweybiwz8j8rg8.jpeg"><br>  Fig.  5) <br><br>  Determinamos para el segundo grupo, con la longitud de la cadena m = 2, Figura 6. <br><br><img src="https://habrastorage.org/webt/r2/7e/d-/r27ed-q3l9neyfprl8d5mgegmus.jpeg"><br>  Fig.  6) <br><br>  La Figura 6 muestra que para el segundo grupo, la dependencia es igual a: <br><br><img src="https://habrastorage.org/webt/gg/z6/mh/ggz6mhj5eq0t_k2gq-g0-pds0as.jpeg"><br>  Fig.  7) <br><br>  Determinamos para el tercer grupo, con la longitud de la cadena m = 3, Figura 8. <br><br><img src="https://habrastorage.org/webt/4a/le/uv/4aleuv3tpdjmlz48clj24l1kln0.jpeg"><br>  Fig.  8) <br><img src="https://habrastorage.org/webt/fw/8e/b-/fw8eb-nnm6tcf6da0kezh6kllmc.jpeg"><br>  Fig.  9) <br><br>  La f√≥rmula general de cada elemento toma la forma: <br><br><img src="https://habrastorage.org/webt/bg/0y/nv/bg0ynvrzu3ngmncslxwkcldvw9c.jpeg"><br>  Fig.  10) <br><br><img src="https://habrastorage.org/webt/rn/cg/jj/rncgjjxoczai2jax_igxo4_kn3m.jpeg"><br>  Fig.  11) <br><br>  Verificaci√≥n <br><br>  Para la verificaci√≥n, utilizamos la propiedad de esta secuencia, que se muestra en la Figura 12. Consiste en el hecho de que los √∫ltimos miembros de una l√≠nea desde una determinada posici√≥n toman un solo valor para todas las l√≠neas con una longitud de l√≠nea creciente. <br><br><img src="https://habrastorage.org/webt/kx/9a/_p/kx9a_pcgyqmzfd7eyprkscp0zuc.jpeg"><br>  Fig.  12) <br><br>  Esta propiedad se debe al hecho de que con una longitud de cadena de m√°s de la mitad de la fila completa, solo es posible una de esas cadenas.  Mostramos esto en el diagrama de la Figura 13. <br><br><img src="https://habrastorage.org/webt/qw/nj/k3/qwnjk3jdgrzjksshn8x1z78a04e.jpeg"><br>  Fig.  13) <br><br>  En consecuencia, para valores de k &lt;n-2, obtenemos la f√≥rmula: <br><br><img src="https://habrastorage.org/webt/ab/5k/s3/ab5ks3z_8udvmlwgd3-egvimika.jpeg"><br>  Fig.  14) <br><br>  De hecho, el valor de Z es el n√∫mero potencial de n√∫meros (opciones en una cadena de n bits) que contienen una cadena de k elementos id√©nticos.  Y de acuerdo con la f√≥rmula de recurrencia, determinamos el n√∫mero de n√∫meros (opciones en una cadena de n bits) en los que la cadena de k elementos id√©nticos es la m√°s grande.  Por ahora, supongo que el valor Z es virtual.  Por lo tanto, en la regi√≥n n / 2, pasa al espacio real.  En la Figura 15, una pantalla con c√°lculos. <br><br><img src="https://habrastorage.org/webt/-c/ov/ns/-covnsdqijdgkdr3xkdwy1c6ovc.jpeg"><br>  Fig.  15) <br><br>  Perm√≠tanos mostrar un ejemplo de una palabra de 256 bits, que puede determinarse mediante este algoritmo. <br><br><img src="https://habrastorage.org/webt/gz/bm/vd/gzbmvdp_csg-9il2z4w9jpey8mo.jpeg"><br>  Fig.  16) <br><br>  Si lo determinan los est√°ndares de confiabilidad del 99.9% para el GSPCH, entonces la clave de 256 bits debe contener cadenas consecutivas de caracteres id√©nticos con un n√∫mero del 5 al 17. Es decir, de acuerdo con los est√°ndares del GSPCH, para que cumpla con el requisito de similitud de aleatoriedad con una confiabilidad del 99.9%, GSPCH, en las pruebas de 2000 (emitiendo un resultado en forma de un n√∫mero binario de 256 bits) solo deber√≠a dar un resultado en el que la longitud m√°xima de la serie de los mismos valores: menos de 4 o m√°s de 17. <br><br><img src="https://habrastorage.org/webt/lx/rz/ny/lxrzny4i3s6kjnu2g9-ty6uf_a8.jpeg"><br>  Fig.  17) <br><br>  Como se puede ver en el diagrama que se muestra en la Figura 17, la cadena log2N es un modo para la distribuci√≥n en consideraci√≥n. <br><br>  Durante el estudio, se encontraron muchos signos de varias propiedades de esta secuencia.  Aqu√≠ hay algunos de ellos: <br><br><ul><li>  debe ser bien probado por el criterio de chi-cuadrado; </li><li>  da signos de la existencia de propiedades fractales; </li><li>  pueden ser buenos criterios para identificar varios procesos aleatorios. </li></ul><br>  Y muchas m√°s otras conexiones. <br><br>  Se verific√≥ si dicha secuencia tambi√©n existe en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enciclopedia en l√≠nea de secuencias enteras (OEIS)</a> (Enciclopedia en l√≠nea de secuencias <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enteras</a> ) en el n√∫mero de secuencia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">A006980</a> , se hace referencia a la publicaci√≥n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">JL Yucas, Contando conjuntos especiales de palabras binarias Lyndon, Ars Combin. 31 (1991), p√°g.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">21-29</a> , donde la secuencia se muestra en la p√°gina 28 (en la tabla).  En la publicaci√≥n, las l√≠neas est√°n numeradas 1 menos, pero los valores son los mismos.  En general, la publicaci√≥n trata sobre las <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">palabras de Lyndon</a> , es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">decir</a> , es muy posible que el investigador ni siquiera sospechara que esta serie estaba relacionada con este aspecto. <br><br>  Volvamos al teorema de Erds-Renyi.  De acuerdo con los resultados de esta publicaci√≥n, se puede decir que en la formulaci√≥n presentada, este teorema se refiere al caso general, que est√° determinado por el teorema de Muavre-Laplace.  Y el teorema indicado, en esta formulaci√≥n, no puede ser un criterio inequ√≠voco para la aleatoriedad de una serie.  Pero la fractalidad, y para este caso se expresa que las cadenas de la longitud indicada pueden combinarse con cadenas de mayor longitud, no nos permiten rechazar este teorema tan inequ√≠vocamente, ya que es posible una inexactitud en la formulaci√≥n.  Un ejemplo es el hecho de que si, para uno de 256 bits, la probabilidad de un n√∫mero donde la cadena m√°xima de 8 bits es 0.244235, entonces, junto con las otras secuencias m√°s largas, la probabilidad de que haya un n√∫mero de 8 bits en el n√∫mero ya es - 0.490234375.  Es decir, hasta ahora, no hay una oportunidad inequ√≠voca de rechazar este teorema.  Pero este teorema encaja bastante bien en otro aspecto, que se mostrar√° m√°s adelante. <br><br>  Aplicaci√≥n pr√°ctica <br><br>  Veamos el ejemplo presentado por el usuario de VDG: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">‚Äú... Las ramas dendr√≠ticas de una neurona se pueden representar como una secuencia de bits.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Una rama, y ‚Äã‚Äãluego toda la neurona, se activa cuando se activa una cadena de sinapsis en cualquiera de sus lugares.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La neurona tiene la tarea de no responder al ruido blanco, respectivamente, la longitud m√≠nima de la cadena, por lo que recuerdo con Numenty, es de 14 sinapsis en la neurona piramidal con sus 10 mil sinapsis.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Y de acuerdo con la f√≥rmula que obtenemos: Log_ {2} 10000 = 13.287.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Es decir, se producir√°n cadenas de menos de 14 de longitud debido al ruido natural, pero no activar√°n la neurona.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Est√° perfectamente establecido "</a> . <br><br>  Construiremos un gr√°fico, pero teniendo en cuenta el hecho de que Excel no considera valores superiores a 2 ^ 1024, nos limitaremos al n√∫mero de sinapsis 1023 y, teniendo esto en cuenta, interpolaremos el resultado por comentario, como se muestra en la Figura 18. <br><br><img src="https://habrastorage.org/webt/qh/zb/-2/qhzb-2e6zwkyndi9_egc1s_putm.jpeg"><br>  Fig.  18) <br><br>  Hay una red neuronal biol√≥gica que funciona cuando se compila una cadena de m = log2N = 11. Esta cadena es un valor modal y se alcanza un valor umbral, la probabilidad, de alg√∫n tipo de cambio en la situaci√≥n de 0,78.  Y la probabilidad de error es 1- 0.78 = 0.22.  Supongamos que funciona una cadena de 9 sensores, donde la probabilidad de determinar el evento es 0.37, respectivamente, la probabilidad de error es 1 - 0.37 = 0.63.  Es decir, para lograr una disminuci√≥n en la probabilidad de error de 0.63 a 0.37, es necesario que funcionen 3.33 cadenas de 9 elementos.  La diferencia entre 11 y 9 elementos es de segundo orden, es decir 2 ^ 2 = 4 veces, que si se redondea a enteros, ya que los elementos dan un valor entero, entonces 3.33 = 4. Buscamos reducir el error al procesar una se√±al de 8- elementos, ya necesitamos 11 cadenas de activaci√≥n de 8 elementos.  Supongo que este es un mecanismo que le permite evaluar la situaci√≥n y tomar una decisi√≥n sobre cambiar el comportamiento de un objeto biol√≥gico.  Razonable y eficientemente suficiente, en mi opini√≥n.  Y teniendo en cuenta el hecho de que sabemos acerca de la naturaleza que utiliza los recursos de la manera m√°s econ√≥mica posible, la hip√≥tesis de que el sistema biol√≥gico utiliza este mecanismo est√° justificada.  Y cuando entrenamos la red neuronal, de hecho, reducimos la probabilidad de error, ya que para eliminar completamente el error necesitamos encontrar una relaci√≥n anal√≠tica. <br><br>  Pasamos al an√°lisis de datos num√©ricos.  En el an√°lisis de datos num√©ricos, tratamos de elegir una dependencia anal√≠tica en la forma y = f (xi).  Y en la primera etapa la encontramos.  Despu√©s de encontrarlo, las series existentes se pueden representar como binarias, en relaci√≥n con la ecuaci√≥n de regresi√≥n, donde asignamos 1 a valores positivos y 0 a valores negativos, y luego analizamos una serie de elementos id√©nticos.  Determinamos la distribuci√≥n m√°s grande, a lo largo de la cadena, de cadenas m√°s cortas. <br><br>  Luego, pasamos al teorema de Erdos-Renyi, se deduce que al realizar una gran cantidad de pruebas de un valor aleatorio, se debe formar una cadena de elementos id√©nticos en todos los registros del n√∫mero generado, es decir, m = log2N.  Ahora, cuando examinamos los datos, no sabemos cu√°l es realmente el volumen de la serie.  Pero si mira hacia atr√°s, esta cadena m√°xima nos da razones para suponer que R es un par√°metro que caracteriza un campo de variable aleatoria, Figura 19. <br><br><img src="https://habrastorage.org/webt/cu/ro/0w/curo0wzknncrkyhrzsdqs1ws8nq.jpeg"><br>  Fig.  19) <br><br>  Es decir, comparando R y N, podemos sacar varias conclusiones: <br><br><ol><li>  Si R &lt;N, entonces el proceso aleatorio se repite varias veces en datos hist√≥ricos. </li><li>  Si R&gt; N, entonces el proceso aleatorio tiene una dimensi√≥n m√°s alta que los datos disponibles, o determinamos incorrectamente la ecuaci√≥n de la funci√≥n objetivo. </li></ol><br>  Luego, para el primer caso, estamos dise√±ando una red neuronal con sensores de 2 ^ m, supongo que podemos agregar un par de sensores para captar las transiciones, y entrenamos esta red en datos hist√≥ricos.  Si la red como resultado del entrenamiento no puede aprender y producir√° el resultado correcto con una probabilidad del 50%, entonces esto significa que la funci√≥n objetivo encontrada es √≥ptima y es imposible mejorarla.  Si la red puede aprender, mejoraremos a√∫n m√°s la dependencia anal√≠tica. <br><br>  Si la dimensi√≥n de la serie es mayor que la dimensi√≥n de una variable aleatoria, entonces se puede usar la propiedad de fractalidad de la variable aleatoria, ya que cualquier serie de tama√±o m contiene todos los subespacios de dimensiones inferiores.  Supongo que en este caso tiene sentido entrenar la red neuronal en todos los datos, excepto en las cadenas m. <br><br>  Otro enfoque para el dise√±o de redes neuronales puede ser el per√≠odo de pron√≥stico. <br><br>  En conclusi√≥n, debe decirse que, en el camino a esta publicaci√≥n, se descubrieron muchos aspectos en los que la magnitud de la dimensi√≥n de una variable aleatoria y sus propiedades descubiertas se cruzaban con otras tareas en el an√°lisis de los datos.  Pero por ahora, todo esto est√° en una forma muy cruda y se dejar√° para futuras publicaciones. <br><br>  Parte anterior: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 2</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/466761/">https://habr.com/ru/post/466761/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../466747/index.html">Desarrolladores de Mitap iOS en Redmadrobot</a></li>
<li><a href="../466753/index.html">Administraci√≥n de red r√°pida y eficiente - Network MACMonitor</a></li>
<li><a href="../466755/index.html">La computadora te har√° sabrosa</a></li>
<li><a href="../466757/index.html">El primer mitap de Flutter en San Petersburgo - 26 de septiembre</a></li>
<li><a href="../466759/index.html">Acerca de los programas de afiliaci√≥n de la empresa de hosting</a></li>
<li><a href="../466763/index.html">DataLine Insight Brut Day, 3 de octubre, Mosc√∫</a></li>
<li><a href="../466765/index.html">Desarrollo de un sistema operativo monol√≠tico similar a Unix - Kernel System Log (3)</a></li>
<li><a href="../466769/index.html">Daga 2 es elemental (Parte 2)</a></li>
<li><a href="../466773/index.html">Semana de la seguridad 37: vulnerabilidad en Android, Microsoft frente a deepfakes, popularidad de Windows 7</a></li>
<li><a href="../466775/index.html">C√≥mo funciona: selecci√≥n de frecuencia para 5G</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
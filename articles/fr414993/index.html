<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèΩ‚Äçü§ù‚ÄçüßëüèΩ üë©üèø‚Äçü§ù‚Äçüë®üèº üöø Identification et classification des commentaires toxiques. Conf√©rence √† Yandex üßóüèª üà∫ üë©üèΩ‚Äç‚úàÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Tous les syst√®mes de mod√©ration modernes utilisent le crowdsourcing ou l'apprentissage automatique qui est d√©j√† devenu un classique. Lors de la procha...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Identification et classification des commentaires toxiques. Conf√©rence √† Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/414993/">  Tous les syst√®mes de mod√©ration modernes utilisent le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">crowdsourcing</a> ou l'apprentissage automatique qui est d√©j√† devenu un classique.  Lors de la prochaine formation ML √† Yandex, Konstantin Kotik, Igor Galitsky et Alexey Noskov ont parl√© de leur participation au concours pour l'identification en masse des commentaires offensants.  Le concours s'est d√©roul√© sur la plateforme Kaggle. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3mL9iP8g3fA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - Bonjour √† tous!  Je m'appelle Konstantin Kotik, je suis un data scientist de la soci√©t√© Button of Life, un √©tudiant du d√©partement de physique et de la Graduate School of Business de l'Universit√© d'√âtat de Moscou. <br><a name="habracut"></a><br>  Aujourd'hui, nos coll√®gues, Igor Galitsky et Alexei Noskov, vous parleront du concours Toxic Comment Classification Challenge Challenge, dans lequel notre √©quipe DecisionGuys a pris la 10e place parmi 4551 √©quipes. <br><br>  Une discussion en ligne sur des sujets qui nous importent peut √™tre difficile.  Les insultes, l'agression et le harc√®lement qui se produisent en ligne obligent souvent de nombreuses personnes √† abandonner la recherche d'opinions appropri√©es sur des questions qui les int√©ressent, √† refuser de s'exprimer. <br><br>  De nombreuses plateformes ont du mal √† communiquer efficacement en ligne, mais cela conduit souvent de nombreuses communaut√©s √† simplement fermer les commentaires des utilisateurs. <br><br>  Une √©quipe de recherche de Google et d'une autre soci√©t√© travaille sur des outils pour am√©liorer la discussion en ligne. <br><br>  L'une des astuces sur lesquelles ils se concentrent consiste √† explorer les comportements n√©gatifs en ligne tels que les commentaires toxiques.  Ce sont des commentaires qui peuvent √™tre offensants, irrespectueux ou simplement forcer l'utilisateur √† quitter la discussion. <br><br><img src="https://habrastorage.org/webt/y2/o4/oz/y2o4ozi061ri0lyir_c9szxsmko.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien</a></sup></sub> </h5><br>  √Ä ce jour, ce groupe a d√©velopp√© une API publique qui peut d√©terminer le degr√© de toxicit√© d'un commentaire, mais leurs mod√®les actuels font encore des erreurs.  Et dans ce concours, nous, les Kegglers, avons √©t√© mis au d√©fi de construire un mod√®le capable d'identifier les commentaires contenant des menaces, de la haine, des insultes, etc.  Et id√©alement, ce mod√®le devait √™tre meilleur que le mod√®le actuel pour leur API. <br><br>  Nous avons pour t√¢che de traiter du texte: identifier puis classer les commentaires.  En tant qu'exemples de formation et de test, des commentaires ont √©t√© fournis √† partir des pages de discussion Wikip√©dia.  Il y avait environ 160 000 commentaires dans le train, 154 000 dans le test. <br><br><img src="https://habrastorage.org/webt/u5/ys/we/u5yswe0_sb618cfq9rlilpykuke.jpeg" width="700"><br><br>  L'√©chantillon de formation a √©t√© marqu√© comme suit.  Chaque commentaire comporte six √©tiquettes.  Les √©tiquettes prennent la valeur 1 si le commentaire contient ce type de toxicit√©, 0 sinon.  Et il se peut que toutes les √©tiquettes soient nulles, un cas de commentaire ad√©quat.  Ou il se peut qu'un commentaire contienne plusieurs types de toxicit√©, imm√©diatement une menace et une obsc√©nit√©. <br><br>  En raison du fait que nous sommes en ondes, je ne peux pas d√©montrer d'exemples sp√©cifiques de ces classes.  En ce qui concerne l'√©chantillon d'essai, pour chaque commentaire, il √©tait n√©cessaire de pr√©voir la probabilit√© de chaque type de toxicit√©. <br><br>  La m√©trique de qualit√© est l'AUC ROC moyenne sur les types de toxicit√©, c'est-√†-dire la moyenne arithm√©tique de l'AUC ROC pour chaque classe s√©par√©ment. <br><br><img src="https://habrastorage.org/webt/17/cm/gk/17cmgklewbzg00esfhzii641og4.jpeg" width="700"><br><br>  Voici la r√©partition des objets par classes dans l'ensemble d'apprentissage.  On peut voir que les donn√©es sont tr√®s d√©s√©quilibr√©es.  Je dois dire tout de suite que notre √©quipe a obtenu un score sur un √©chantillon de m√©thodes pour travailler avec des donn√©es d√©s√©quilibr√©es, par exemple le sur√©chantillonnage ou le sous-√©chantillonnage. <br><br><img src="https://habrastorage.org/webt/og/t6/gy/ogt6gyfkpmslose73rrxl4v_7ci.jpeg" width="700"><br><br>  Lors de la construction du mod√®le, j'ai utilis√© un pr√©traitement des donn√©es en deux √©tapes.  La premi√®re √©tape est le pr√©traitement de base des donn√©es, ce sont les transformations de la vue sur la diapositive, cela am√®ne le texte en minuscules, supprimant les liens, les adresses IP, les nombres et la ponctuation. <br><br><img src="https://habrastorage.org/webt/xb/5v/kq/xb5vkq8juiimjekysw3e0we4vgq.jpeg" width="700"><br><br>  Pour tous les mod√®les, ce pr√©traitement de base des donn√©es a √©t√© utilis√©.  Lors de la deuxi√®me √©tape, un pr√©traitement partiel des donn√©es a √©t√© effectu√© - en rempla√ßant les √©motic√¥nes par les mots correspondants, en d√©chiffrant les abr√©viations, en corrigeant les fautes de frappe en profanant, en ramenant les diff√©rents types de tapis sous la m√™me forme, et en supprimant √©galement les images.  Dans certains commentaires, des liens vers des images √©taient indiqu√©s, nous les avons simplement supprim√©s. <br><br>  Pour chacun des mod√®les, un pr√©traitement partiel des donn√©es et de ses diff√©rents √©l√©ments a √©t√© utilis√©.  Tout cela a √©t√© fait pour que les mod√®les de base r√©duisent la corr√©lation crois√©e entre les mod√®les de base lors de la construction d'une composition suppl√©mentaire. <br>  Passons √† la partie la plus int√©ressante - la construction d'un mod√®le. <br><br>  J'ai imm√©diatement abandonn√© l'approche classique du sac de mots.  En raison du fait que dans cette approche, chaque mot est un attribut distinct.  Cette approche ne prend pas en compte l'ordre g√©n√©ral des mots, on suppose que les mots sont ind√©pendants.  Dans cette approche, la g√©n√©ration du texte se produit de sorte qu'il y ait une certaine distribution dans les mots, un mot est s√©lectionn√© au hasard dans cette distribution et ins√©r√© dans le texte. <br><br>  Bien s√ªr, il existe des processus g√©n√©ratifs plus complexes, mais l'essence ne change pas - cette approche ne prend pas en compte l'ordre g√©n√©ral des mots.  Vous pouvez aller aux engrammes, mais seul l'ordre des mots des fen√™tres y sera pris en compte, et non g√©n√©ral.  Par cons√©quent, j'ai √©galement compris mes co√©quipiers qu'ils devaient utiliser quelque chose de plus intelligent. <br><br><img src="https://habrastorage.org/webt/7q/1q/2v/7q1q2v5h2q8c8ngog4foqvsabbm.jpeg" width="700"><br><h5>  <sub><sup><a href="">Lien</a></sup></sub> </h5><br>  La premi√®re chose intelligente qui m'est venue √† l'esprit a √©t√© d'utiliser une repr√©sentation vectorielle √† l'aide de Doc2vec.  Il s'agit de Word2vec plus un vecteur qui prend en compte l'unicit√© d'un document particulier.  Dans l'article d'origine, ce vecteur est appel√© paragraphe id. <br><br>  Ensuite, selon une telle repr√©sentation vectorielle, une r√©gression logistique a √©t√© √©tudi√©e, o√π chaque document √©tait repr√©sent√© par un vecteur de 10 000 dimensions.  L'√©valuation de la qualit√© a √©t√© r√©alis√©e sur une validation crois√©e de dix plis, elle a √©t√© stratifi√©e, et il est important de noter que la r√©gression logistique a √©t√© √©tudi√©e pour chaque classe, six probl√®mes de classification ont √©t√© r√©solus s√©par√©ment.  Et √† la fin, le r√©sultat a √©t√© une distribution de probabilit√© par classe. <br><br>  La r√©gression logistique est entra√Æn√©e depuis tr√®s longtemps.  Je ne rentre g√©n√©ralement pas dans la RAM.  Dans les installations d'Igor, ils ont pass√© une journ√©e quelque part pour obtenir le r√©sultat, comme sur une diapositive.  Pour cette raison, nous avons imm√©diatement refus√© d'utiliser Doc2vec en raison d'attentes √©lev√©es, bien qu'il puisse √™tre am√©lior√© de 1 000 si un commentaire avec un pr√©traitement de donn√©es suppl√©mentaire √©tait effectu√©. <br><br><img src="https://habrastorage.org/webt/kt/0i/ks/kt0iksctnlf6kobgk1e0xnkomee.jpeg" width="700"><br><br>  Les plus intelligents que nous et les autres concurrents avons utilis√©s √©taient des r√©seaux de neurones r√©currents.  Ils re√ßoivent s√©quentiellement les mots √† l'entr√©e, mettant √† jour leur √©tat cach√© apr√®s chaque mot.  Igor et moi avons utilis√© le r√©seau r√©current GRU pour l'int√©gration de mots fastText, ce qui est sp√©cial en ce qu'il r√©sout de nombreux probl√®mes de classification binaire ind√©pendants.  Pr√©disez la pr√©sence ou l'absence du mot de contexte ind√©pendamment. <br><br>  Nous avons √©galement effectu√© une √©valuation de la qualit√© sur la validation crois√©e de dix plis, elle n'a pas √©t√© stratifi√©e ici, et ici la distribution de probabilit√© a √©t√© imm√©diatement obtenue par classe.  Chaque probl√®me de classification binaire n'a pas √©t√© r√©solu s√©par√©ment, mais un vecteur √† six dimensions a √©t√© imm√©diatement g√©n√©r√©.  C'√©tait notre l'un des meilleurs mod√®les simples. <br><br>  Vous demandez, quel √©tait le secret du succ√®s? <br><br><img src="https://habrastorage.org/webt/aq/ik/nm/aqiknmpv8txoen1uollbhmy3iz8.jpeg" width="700"><br><br>  Cela consistait √† m√©langer, il y en avait beaucoup, avec empilement et mise en r√©seau dans l'approche.  L'approche de r√©seautage doit √™tre repr√©sent√©e sous forme de graphique dirig√©. <br><br><img src="https://habrastorage.org/webt/uj/hl/9r/ujhl9rp1pse-y-0euvxutavnrpa.jpeg" width="700"><br><br>  Au d√©but du concours, l'√©quipe de DecisionGuys √©tait compos√©e de deux personnes.  Ensuite, Pavel Pleskov dans la cha√Æne ODS Slack a exprim√© le d√©sir de faire √©quipe avec quelqu'un du top 200.  A cette √©poque, nous √©tions quelque part √† la 157e place, et Pavel Pleskov √† la 154e place, quelque part dans le quartier.  Igor a remarqu√© son d√©sir de se joindre et je l'ai invit√© dans l'√©quipe.  Andrey Litvinov nous a ensuite rejoint, puis Pavel a invit√© le grand ma√Ætre Alexei Noskov dans notre √©quipe.  Igor - Eugene.  Et le dernier partenaire de notre √©quipe √©tait le Bulgare Atanas Atanasov, et c'√©tait le r√©sultat d'un ensemble international humain. <br><br>  Maintenant, Igor Galitsky racontera comment il a enseign√© le gru, plus en d√©tail il parlera des id√©es et des approches de Pavel Pleskov, Andrei Litvinov et Atanas Atanasov. <br><br>  Igor Galitsky: <br>  - Je suis data scientist chez Epoch8, et je vais parler de la plupart des architectures que nous avons utilis√©es. <br><br><img src="https://habrastorage.org/webt/l1/ah/jz/l1ahjzsk3hgrivbmffam4eb_9vy.jpeg" width="700"><br><br>  Tout a commenc√© avec le gru didirectionnel standard √† deux couches, presque toutes les √©quipes l'ont utilis√©, et fastText, la fonction d'activation EL, a √©t√© utilis√©e comme int√©gration. <br><br>  Il n'y a rien de sp√©cial √† dire, une architecture simple, sans fioritures.  Pourquoi nous a-t-elle donn√© de si bons r√©sultats avec lesquels nous sommes rest√©s dans le top 150 pendant un certain temps?  Nous avons eu un bon pr√©traitement du texte.  Il fallait continuer. <br><br><img src="https://habrastorage.org/webt/ni/ny/dx/ninydx6a2wsofsa-qdqncx904ou.jpeg" width="700"><br><br>  Paul avait sa propre approche.  Apr√®s avoir fusionn√© avec le n√¥tre, cela a donn√© une augmentation significative.  Avant cela, nous avions un m√©lange de gru et de mod√®le sur Doc2vec, cela donnait 61 LB. <br><br><img src="https://habrastorage.org/webt/hq/uk/lg/hquklgojqvgbhidth4gqgv5lctg.jpeg" width="700"><br><br>  Je vais vous parler des approches d'Atanas Atanasov, il est directement un passionn√© de tout nouvel article.  Voici gru avec attention, tous les param√®tres de la diapositive.  Il avait beaucoup d'approches vraiment cool, mais jusqu'au dernier moment, il a utilis√© son pr√©traitement, et tous les b√©n√©fices ont √©t√© nivel√©s.  Vitesse sur la diapositive. <br><br><img src="https://habrastorage.org/webt/1f/3w/_h/1f3w_hiemppymuwtyvt4xjd04so.jpeg" width="700"><br><br>  Ensuite, il y a eu une attention hi√©rarchique, elle a donn√© des r√©sultats encore pires, car au d√©part c'√©tait un r√©seau de classification des documents compos√©s de phrases.  Il l'a foutu, mais l'approche n'est pas tr√®s. <br><br><img src="https://habrastorage.org/webt/dp/pn/su/dppnsuijdyfefmos-rmpecohrsu.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien</a></sup></sub> </h5><br>  Il y avait une approche int√©ressante, nous pouvons initialement obtenir des fonctionnalit√©s de l'offre depuis le d√©but et la fin.  Avec l'aide de la convolution, des couches convolutionnelles, nous obtenons s√©par√©ment des fonctionnalit√©s √† gauche et √† droite de l'arborescence.  C'est du d√©but et de la fin de la phrase, puis ils fusionnent et parcourent √† nouveau gru. <br><br><img src="https://habrastorage.org/webt/j7/gp/vr/j7gpvrmt3s3tf04qidvcfobmzvs.jpeg" width="700"><br><br>  √âgalement Bi-GRU avec bloc d'attention.  C'est l'un des meilleurs sur le priv√© √©tait un r√©seau assez profond, a montr√© de bons r√©sultats. <br><br><img src="https://habrastorage.org/webt/d9/tw/_v/d9tw_v7n_nkvuxnxctppb2lvbyo.jpeg" width="700"><br><br>  La prochaine approche consiste √† mettre en √©vidence les fonctionnalit√©s autant que possible?  Apr√®s la couche du r√©seau r√©current, nous faisons trois autres couches parall√®les de convolution.  Et ici, nous n'avons pas pris des phrases aussi longues, les avons r√©duites √† 250, mais en raison de trois circonvolutions, cela a donn√© un bon r√©sultat. <br><br><img src="https://habrastorage.org/webt/ft/hq/xy/fthqxy5pglwimem_-h46ieewheq.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien</a></sup></sub> </h5><br>  C'√©tait le r√©seau le plus profond.  Comme Atanas l'a dit, il voulait juste enseigner quelque chose de grand et d'int√©ressant.  Une grille convolutionnelle ordinaire qui a appris des caract√©ristiques du texte, les r√©sultats n'ont rien de sp√©cial. <br><br><img src="https://habrastorage.org/webt/pq/d6/eh/pqd6eh0_hxzqvb6hkwkjzkyws1u.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien</a></sup></sub> </h5><br>  C'est une nouvelle approche assez int√©ressante, en 2017 il y avait un article sur ce sujet, il a √©t√© utilis√© pour ImageNet, et l√† cela nous a permis d'am√©liorer le r√©sultat pr√©c√©dent de 25%.  Sa principale caract√©ristique est qu'une petite couche est lanc√©e parall√®lement au bloc de convolution, qui enseigne les poids pour chaque convolution dans ce bloc.  Elle a donn√© une approche tr√®s cool, malgr√© la r√©duction des peines. <br><br>  Le probl√®me est que la longueur maximale des phrases dans ces t√¢ches atteint 1 500 mots, il y a eu de tr√®s gros commentaires.  D'autres √©quipes ont √©galement r√©fl√©chi √† la fa√ßon d'attraper cette grande offre, comment la trouver, car tout n'est pas tr√®s pouss√©.  Et beaucoup ont dit qu'√† la fin de la phrase il y avait un INFA tr√®s important.  Malheureusement, dans toutes ces approches, cela n'a pas √©t√© pris en compte, car le d√©but a √©t√© pris.  Cela donnerait peut-√™tre une nouvelle augmentation. <br><br><img src="https://habrastorage.org/webt/mn/aq/om/mnaqomuiugd3p8_bpnrphhxrcmm.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien</a></sup></sub> </h5><br>  Voici l'architecture AC-BLSTM.  L'essentiel est que si la division inf√©rieure en deux parties, en plus de l'attention, est une traction intelligente, mais en parall√®le, il est toujours normal, et tout cela se concr√©tise.  Aussi de bons r√©sultats. <br><br><img src="https://habrastorage.org/webt/tw/qa/-c/twqa-cw8om3ingxliha5wrf3brg.jpeg" width="700"><br><br>  Et Atanas tout son zoo de mannequins, alors c'√©tait un m√©lange cool.  En plus des mod√®les eux-m√™mes, j'ai ajout√© quelques fonctionnalit√©s de texte, g√©n√©ralement la longueur, le nombre de lettres majuscules, le nombre de mauvais mots, le nombre de caract√®res, tout cela ajout√©.  Validation crois√©e de cinq plis, et obtenu d'excellents r√©sultats sur le LB 0.9867 priv√©. <br><br><img src="https://habrastorage.org/webt/jk/m-/ev/jkm-evezbsayfconwk3cc1uke2s.jpeg" width="700"><br><h5>  <sub><sup><a href="">Lien</a></sup></sub> </h5><br>  Et la deuxi√®me approche, il a enseign√© avec une int√©gration diff√©rente, mais les r√©sultats √©taient pires.  Presque tout le monde a utilis√© fastText. <br><br>  Je voulais parler de l'approche de notre autre coll√®gue, Andrei, avec le surnom de Laol √† ODS.  Il a enseign√© beaucoup de noyaux publics, il les buvait comme s'il √©tait hors de lui, et cela a vraiment donn√© des r√©sultats tr√®s cool.  Vous ne pourriez pas faire tout cela, mais prenez simplement un tas de noyaux publics diff√©rents, m√™me sur tf-idf, il existe toutes sortes de gru convolutionnaires. <br><br><img src="https://habrastorage.org/webt/re/gq/cg/regqcgtzm_teedu_brcisgw2hkw.jpeg" width="700"><br><h5>  <sub><sup><a href="">Lien</a></sup></sub> </h5><br>  Il a eu l'une des meilleures approches, avec laquelle nous sommes rest√©s longtemps dans le top 15, jusqu'√† ce qu'Alexey et Atanas nous rejoignent, il a combin√© le m√©lange et l'empilement de tout cela.  Et aussi un moment tr√®s cool, dont, si je comprends bien, aucune des √©quipes n'a utilis√©, nous avons √©galement cr√©√© des fonctionnalit√©s √† partir des r√©sultats de l'API des organisateurs.  √Ä ce sujet, dites-le √† Alex. <br><br>  Alexey Noskov: <br>  - salut.  Je vais vous parler de l'approche que j'ai utilis√©e et de la fa√ßon dont nous l'avons mise en ≈ìuvre. <br><br><img src="https://habrastorage.org/webt/st/ol/im/stolimynmwutbmyfpce9qgmcvjg.jpeg" width="700"><br><br>  Tout √©tait assez simple pour moi: 10 plis de validation crois√©e, des mod√®les pr√©-entra√Æn√©s sur diff√©rents vecteurs avec diff√©rents pr√©traitements, pour qu'ils aient plus de diversit√© dans l'ensemble, une petite augmentation et deux cycles de d√©veloppement.  Le premier, qui fonctionnait essentiellement au d√©but, a form√© un certain nombre de mod√®les, examin√© les erreurs de validation crois√©e, sur les exemples o√π il fait des erreurs √©videntes et corrig√© le pr√©traitement en fonction de cela, car il est plus clair comment les corriger. <br><br>  Et la deuxi√®me approche, qui a √©t√© plus utilis√©e √† la fin, a enseign√© un certain nombre de mod√®les, examin√© les corr√©lations, trouv√© des blocs de mod√®les faiblement corr√©l√©s les uns aux autres, renforc√© la partie qui les constituait.  Il s'agit de la matrice de corr√©lation de validation crois√©e entre mes mod√®les. <br><br><img src="https://habrastorage.org/webt/lu/e2/ul/lue2ullofbhfzn1v1x0zk92wam4.jpeg" width="700"><br><br>  On peut voir qu'il a une structure en blocs √† certains endroits, alors que certains mod√®les √©taient de bonne qualit√©, ils √©taient faiblement corr√©l√©s avec les autres, et de tr√®s bons r√©sultats ont √©t√© obtenus lorsque j'ai pris ces mod√®les comme base, leur ai enseign√© plusieurs variations diff√©rentes qui diff√®rent dans diff√©rents hyperparam√®tres ou pr√©traitement, puis ajout√©s √† l'ensemble. <br><br><img src="https://habrastorage.org/webt/r_/m3/5l/r_m35le0i7o8cujs5osoyq8t9h4.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien</a></sup></sub> </h5><br>  Pour l'augmentation, l'id√©e qui a √©t√© publi√©e sur le forum par Pavel Ostyakov a le plus suscit√©.  Cela consistait dans le fait que nous pouvons prendre un commentaire, le traduire dans une autre langue, puis revenir.  En raison de la double traduction, une reformulation est obtenue, quelque chose est un peu perdu, mais dans l'ensemble un texte similaire l√©g√®rement diff√©rent est obtenu, qui peut √©galement √™tre class√© et ainsi √©largir l'ensemble de donn√©es. <br><br>  Et la deuxi√®me approche, qui n'a pas beaucoup aid√©, mais aussi aid√©, est que vous pouvez essayer de prendre deux commentaires arbitraires, g√©n√©ralement pas tr√®s longs, les coller et prendre comme √©tiquette sur la cible une combinaison d'√©tiquettes ou un peu de zeste o√π il n'y a qu'une seule des ils contenaient une √©tiquette. <br><br>  Ces deux approches ont bien fonctionn√© si elles n'√©taient pas appliqu√©es √† l'avance √† l'ensemble d'ensemble complet, mais pour changer l'ensemble d'exemples auxquels l'augmentation devrait √™tre appliqu√©e √† chaque √©poque.  A chaque √©poque du processus de constitution d'un lot, on choisit, disons, 30% des exemples qu'il passe par des traductions.  Au contraire, √† l'avance, quelque part en parall√®le se trouve d√©j√† en m√©moire, nous s√©lectionnons simplement la version √† traduire en fonction de celle-ci et l'ajoutons au lot pendant sa formation. <br><br><img src="https://habrastorage.org/webt/gp/84/92/gp8492suelagjk9stcprkcgdi_y.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Premier lien</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">deuxi√®me lien</a></sup></sub> </h5><br>  Une diff√©rence int√©ressante r√©side dans les mod√®les form√©s au BPE.  Il y a un SentencePiece - un tokenizer Google qui vous permet de vous diviser en tokens dans lesquels il n'y aura aucun UNK.  Un dictionnaire limit√© dans lequel toute cha√Æne est divis√©e en quelques jetons.  Si le nombre de mots dans le texte r√©el est sup√©rieur √† la taille cible du dictionnaire, ils commencent √† se diviser en morceaux plus petits, et une approche interm√©diaire est obtenue entre les mod√®les de niveau caract√®re et de niveau mot. <br><br>  Deux algorithmes de construction principaux y sont utilis√©s: BPE et Unigram.  Pour l'algorithme BPE, il √©tait assez facile de trouver des int√©grations pr√©-d√©pos√©es sur le r√©seau, et avec un vocabulaire fixe - j'avais juste un bon vocabulaire de 50k - je pouvais aussi former des mod√®les qui √©taient bons (inaudible - environ Ed.), Un peu pire que d'habitude sur fastText, mais ils √©taient tr√®s faiblement corr√©l√©s avec tous les autres et ont donn√© un bon coup de pouce. <br><br><img src="https://habrastorage.org/webt/ny/et/hs/nyeths5qlmvbeegudjhpi3jgrpy.jpeg" width="700"><br><br>  Il s'agit d'un sch√©ma d'empilement classique.  En r√®gle g√©n√©rale, pour la plupart de la comp√©tition, avant de combiner, je m√©langeais simplement tous mes mod√®les sans poids.  Cela a donn√© les meilleurs r√©sultats.  Mais apr√®s la fusion, j'ai pu obtenir un sch√©ma un peu plus complexe, ce qui a finalement donn√© un bon coup de pouce. <br><br><img src="https://habrastorage.org/webt/zg/vu/th/zgvuthkjtwku6kiaaexiagevq7s.jpeg" width="700"><br><br>  J'avais un grand nombre de mod√®les.  Jetez-les tous dans une sorte d'empileur?  Cela n'a pas tr√®s bien fonctionn√©, a-t-il recycl√©, mais comme les mod√®les √©taient des groupes qui √©taient assez fortement corr√©l√©s, je les ai simplement unis dans ces groupes, au sein de chaque groupe, j'ai fait la moyenne et j'ai re√ßu 5-7 groupes de mod√®les tr√®s similaires, dont Le niveau suivant utilisait des valeurs moyennes.  J'ai form√© LightGBM √† ce sujet, bugg√© 20 lancements avec divers √©chantillons, t√©l√©charg√© un peu de m√©ta-fonctionnalit√© similaire √† ce qu'Atanas a fait, et finalement, il a finalement commenc√© √† fonctionner, donnant un coup de pouce √† la moyenne simple. <br><br><img src="https://habrastorage.org/webt/of/vg/b0/ofvgb0ucc3da92cftyrou5ngvye.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien</a></sup></sub> </h5><br>  Surtout, j'ai ajout√© l'API que Andrei a trouv√©e et qui contient un ensemble d'√©tiquettes similaire.  Les organisateurs ont construit des mod√®les pour eux au d√©part.  Comme il √©tait √† l'origine diff√©rent, les participants ne l'ont pas utilis√©, il √©tait impossible de le comparer simplement avec ceux que nous devions pr√©voir.  Mais s'il se jetait dans un empilement qui fonctionnait bien en tant que m√©ta-fonctionnalit√©, il donnerait un formidable coup de pouce, en particulier dans la classe TOXIC, qui, apparemment, √©tait la plus difficile du classement et nous permettait de sauter √† plusieurs endroits √† la fin, litt√©ralement le dernier jour. . <br><br><img src="https://habrastorage.org/webt/g-/ip/8f/g-ip8f1wpu7jq35ilzgcbnuphhk.jpeg" width="700"><br><br>  Depuis que nous avons trouv√© que l'empilement et l'API fonctionnaient si bien pour nous, avant les soumissions finales, nous avions peu de doute sur la fa√ßon dont cela serait port√© √† des fins priv√©es.  Cela a tr√®s bien fonctionn√© de mani√®re tr√®s suspecte, nous avons donc choisi deux soumissions selon le principe suivant: l'une - un m√©lange de mod√®les sans API re√ßu avant cela, plus un empilement avec la m√©taphysique de l'API.  Ici, il s'est av√©r√© 0,9880 en public et 0,9874 en priv√©.  Ici, mes marques sont confuses. <br><br><img src="https://habrastorage.org/webt/cg/d2/4o/cgd24objdrwraciizrqugzuf8t8.jpeg" width="700"><br><br>  Et le second est un m√©lange de mod√®les sans API, sans utiliser d'empilement et sans utiliser LightGBM, car il y avait des craintes que ce soit une sorte de reconversion mineure pour le public, et nous pourrions voler avec cela.  C'est arriv√©, ils n'ont pas d√©coll√©, et en cons√©quence, avec le r√©sultat de 0,9876 en priv√©, nous avons obtenu la dixi√®me position.  C‚Äôest tout. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr414993/">https://habr.com/ru/post/fr414993/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr414979/index.html">Concept Bitcoin MAST</a></li>
<li><a href="../fr414981/index.html">Biblioth√®que non √©crite</a></li>
<li><a href="../fr414983/index.html">Alan Kay: Qu'est-ce qui a rendu Xerox PARC sp√©cial et qui leur ressemble encore aujourd'hui</a></li>
<li><a href="../fr414989/index.html">Lancement d'un satellite de d√©bris spatiaux depuis l'ISS</a></li>
<li><a href="../fr414991/index.html">D√©tection et reconnaissance d'objets de la cam√©ra dans ROS √† l'aide du package find_object_2d</a></li>
<li><a href="../fr414995/index.html">Notes amateurs, ou l'histoire de la configuration du d√©veloppeur Scala FPGA</a></li>
<li><a href="../fr414997/index.html">ML-Blitz: analyse des t√¢ches du premier tour de qualification</a></li>
<li><a href="../fr414999/index.html">Watchman 3D et testeur de thermistance</a></li>
<li><a href="../fr415001/index.html">L'op√©rateur de la voiture robotique Uber, qui a abattu un cycliste, a regard√© l'√©mission Voice au moment de la collision</a></li>
<li><a href="../fr415003/index.html">T√©l√©chargement de fichiers sans restriction sur Apple.com</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
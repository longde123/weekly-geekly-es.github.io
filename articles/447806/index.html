<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåµ üöé ‚èØÔ∏è Acelerar el rendimiento de las redes neuronales utilizando hashing üë®üèæ‚Äçüé® üêè üôáüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La industria se ha centrado en acelerar la multiplicaci√≥n de matrices, pero mejorar el algoritmo de b√∫squeda puede conducir a un aumento m√°s serio en ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Acelerar el rendimiento de las redes neuronales utilizando hashing</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/447806/"><h3>  La industria se ha centrado en acelerar la multiplicaci√≥n de matrices, pero mejorar el algoritmo de b√∫squeda puede conducir a un aumento m√°s serio en el rendimiento </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/8e7/9a0/8e3/8e79a08e31fdeadd8258ab001cc23ec5.jpg"><br><br>  En los √∫ltimos a√±os, la industria de la computaci√≥n ha estado ocupada tratando de acelerar los c√°lculos necesarios para las redes neuronales artificiales, tanto para el entrenamiento como para sacar conclusiones de su trabajo.  En particular, se hizo un gran esfuerzo en el desarrollo de hierro especial sobre el cual se pueden realizar estos c√°lculos.  Google desarroll√≥ la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Unidad de procesamiento de tensor</a> , o TPU, que se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">present√≥ por</a> primera <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">vez</a> al p√∫blico en 2016.  Posteriormente, Nvidia present√≥ la Unidad de procesamiento de gr√°ficos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">V100</a> , describi√©ndola como un chip dise√±ado espec√≠ficamente para la capacitaci√≥n y el uso de IA, as√≠ como para otras necesidades inform√°ticas de alto rendimiento.  Lleno de otras startups, concentr√°ndose en otros tipos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aceleradores</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hardware</a> . <br><a name="habracut"></a><br>  Quiz√°s todos cometen un gran error. <br><br>  Esta idea se expres√≥ en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">trabajo</a> , que apareci√≥ a mediados de marzo en el sitio arXiv.  En ella, sus autores, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Beidi Chen</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tarun Medini</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Anshumali Srivastava</a> de la Universidad de Rice, sostienen que quiz√°s el equipo especial desarrollado para el funcionamiento de las redes neuronales se est√° optimizando para el algoritmo incorrecto. <br><br>  La cuesti√≥n es que el trabajo de las redes neuronales generalmente depende de la rapidez con que el equipo puede realizar la multiplicaci√≥n de las matrices utilizadas para determinar los par√°metros de salida de cada neutr√≥n artificial, su "activaci√≥n", para un conjunto dado de valores de entrada.  Las matrices se usan porque cada valor de entrada para una neurona se multiplica por el par√°metro de peso correspondiente, y luego se suman, y esta multiplicaci√≥n con la suma es la operaci√≥n b√°sica de la multiplicaci√≥n de matrices. <br><br>  Los investigadores de la Universidad de Rice, como algunos otros cient√≠ficos, se dieron cuenta de que la activaci√≥n de muchas neuronas en una capa particular de la red neuronal es demasiado peque√±a y no afecta el valor de salida calculado por las capas posteriores.  Por lo tanto, si sabe cu√°les son estas neuronas, simplemente puede ignorarlas. <br><br>  Puede parecer que la √∫nica forma de descubrir qu√© neuronas en una capa no est√°n activadas es realizar primero todas las operaciones de multiplicaci√≥n de matrices para esta capa.  Pero los investigadores se dieron cuenta de que en realidad puedes decidir sobre esta forma m√°s eficiente si miras el problema desde un √°ngulo diferente.  "Enfocamos este problema como una soluci√≥n al problema de b√∫squeda", dice Srivastava. <br><br>  Es decir, en lugar de calcular las multiplicaciones de la matriz y observar qu√© neuronas se activaron para una entrada determinada, puede ver qu√© tipo de neuronas hay en la base de datos.  La ventaja de este enfoque en el problema es que puede usar una estrategia generalizada que los cient√≠ficos inform√°ticos han mejorado durante mucho tiempo para acelerar la b√∫squeda de datos en la base de datos: hashing. <br><br>  Hashing le permite verificar r√°pidamente si hay un valor en la tabla de la base de datos, sin tener que pasar por cada fila en una fila.  Utiliza un hash, que se calcula f√°cilmente aplicando una funci√≥n hash al valor deseado, que indica d√≥nde se debe almacenar este valor en la base de datos.  Luego puede verificar solo un lugar para averiguar si este valor est√° almacenado all√≠. <br><br>  Los investigadores hicieron algo similar para los c√°lculos relacionados con las redes neuronales.  El siguiente ejemplo ayudar√° a ilustrar su enfoque: <br><br>  Supongamos que hemos creado una red neuronal que reconoce la entrada manuscrita de n√∫meros.  Suponga que la entrada es p√≠xeles grises en una matriz de 16x16, es decir, un total de 256 n√∫meros.  Alimentamos estos datos a una capa oculta de 512 neuronas, cuyos resultados de activaci√≥n son alimentados por la capa de salida de 10 neuronas, una para cada uno de los n√∫meros posibles. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e73/dec/941/e73dec9413ed37b2235bbd1ee8369ca6.jpg"><br><br>  <i>Tablas de redes: antes de calcular la activaci√≥n de las neuronas en capas ocultas, usamos hashes para ayudarnos a determinar qu√© neuronas se activar√°n.</i>  <i>Aqu√≠, el hash de los valores de entrada H1 se usa para buscar las neuronas correspondientes en la primera capa oculta; en este caso, ser√°n las neuronas 2 y 4. El segundo hash H2 muestra qu√© neuronas de la segunda capa oculta contribuir√°n.</i>  <i>Dicha estrategia reduce la cantidad de activaciones que deben calcularse.</i> <br><br>  Es bastante dif√≠cil entrenar una red de este tipo, pero por ahora omita este momento e imagine que ya hemos ajustado todos los pesos de cada neurona para que la red neuronal reconozca perfectamente los n√∫meros escritos a mano.  Cuando un n√∫mero escrito legiblemente llega a su entrada, la activaci√≥n de una de las neuronas de salida (correspondiente a este n√∫mero) estar√° cerca de 1. La activaci√≥n de las otras nueve estar√° cerca de 0. Cl√°sicamente, el funcionamiento de dicha red requiere una multiplicaci√≥n de matriz para cada una de 512 neuronas ocultas, y uno m√°s para cada fin de semana, lo que nos da muchas multiplicaciones. <br><br>  Los investigadores toman un enfoque diferente.  El primer paso es calcular los pesos de cada una de las 512 neuronas en la capa oculta utilizando "hashing sensible a la localidad", una de cuyas propiedades es que los datos de entrada similares dan valores de hash similares.  Luego puede agrupar las neuronas con hashes similares, lo que significar√≠a que estas neuronas tienen conjuntos de pesos similares.  Cada grupo puede almacenarse en una base de datos y determinarse por el hash de los valores de entrada que conducir√°n a la activaci√≥n de este grupo de neuronas. <br><br>  Despu√©s de todo este hashing, resulta f√°cil determinar qu√© neuronas ocultas se activar√°n mediante alguna nueva entrada.  Debe ejecutar 256 valores de entrada a trav√©s de funciones hash calculadas f√°cilmente y usar el resultado para buscar en la base de datos las neuronas que se activar√°n.  De esta forma, tendr√° que calcular los valores de activaci√≥n para solo unas pocas neuronas que importan.  No es necesario calcular la activaci√≥n de todas las dem√°s neuronas en la capa solo para descubrir que no contribuyen al resultado. <br><br>  La entrada de dicha red neuronal de datos puede representarse como la ejecuci√≥n de una consulta de b√∫squeda en una base de datos que solicita encontrar todas las neuronas que se activar√≠an por conteo directo.  Obtiene la respuesta r√°pidamente porque usa hashes para buscar.  Y luego simplemente puede calcular la activaci√≥n de una peque√±a cantidad de neuronas que realmente importan. <br><br>  Los investigadores han utilizado esta t√©cnica, que llamaron SLIDE (motor de aprendizaje profundo Sub-LInear), para entrenar una red neuronal, para un proceso que tiene m√°s solicitudes computacionales de las que tiene para el prop√≥sito previsto.  Luego compararon el rendimiento del algoritmo de aprendizaje con un enfoque m√°s tradicional utilizando una GPU potente, espec√≠ficamente, la GPU Nvidia V100.  Como resultado, obtuvieron algo sorprendente: "Nuestros resultados muestran que, en promedio, la tecnolog√≠a CPU SLIDE puede funcionar en √≥rdenes de magnitud m√°s r√°pido que la mejor alternativa posible, implementada en el mejor equipo y con cualquier precisi√≥n". <br><br>  Es demasiado pronto para sacar conclusiones sobre si estos resultados (que los expertos a√∫n no han evaluado) resistir√°n las pruebas y si obligar√°n a los fabricantes de chips a mirar de manera diferente el desarrollo de equipos especiales para el aprendizaje profundo.  Pero el trabajo definitivamente enfatiza el peligro de arrastre de cierto tipo de hierro en los casos en que existe la posibilidad de un algoritmo nuevo y mejor para el funcionamiento de las redes neuronales. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/447806/">https://habr.com/ru/post/447806/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../447792/index.html">Patrones oscuros y la ley: c√≥mo los reguladores estadounidenses intentan controlar la mec√°nica de los productos y reducir la influencia de las empresas tecnol√≥gicas</a></li>
<li><a href="../447794/index.html">Sobre cosas simples, complicadas. Una carta de un qu√≠mico a una impresora 3D. Disolventes para pl√°sticos y protecci√≥n contra ellos.</a></li>
<li><a href="../447798/index.html">¬øC√≥mo generar una gran gr√°fica financiera con patrones de lavado de dinero?</a></li>
<li><a href="../447802/index.html">Isabella 2</a></li>
<li><a href="../447804/index.html">La fortaleza enana abandona los gr√°ficos de texto, pero no su esencia.</a></li>
<li><a href="../447808/index.html">Aprendiendo a escribir contratos inteligentes de Waves en RIDE y RIDE4DAPPS. Parte 2 (DAO - Organizaci√≥n aut√≥noma descentralizada)</a></li>
<li><a href="../447810/index.html">Analytics para Azure DevOps Services ahora est√° disponible p√∫blicamente</a></li>
<li><a href="../447812/index.html">C√≥mo implementamos la entrega continua de actualizaciones a la plataforma del cliente</a></li>
<li><a href="../447814/index.html">¬øD√≥nde y c√≥mo abrir un centro de desarrollo?</a></li>
<li><a href="../447816/index.html">Un poco de magia de plantilla C ++ y CRTP para controlar la correcci√≥n de las acciones del programador en tiempo de compilaci√≥n</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßÄ üçø üë®üèæ‚Äç‚öïÔ∏è 6 erros divertidos do sistema na opera√ß√£o do Kubernetes [e sua solu√ß√£o] ü§ûüèø üîî üôä</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ao longo dos anos em que operamos o Kubernetes em produ√ß√£o, acumulamos muitas hist√≥rias interessantes, pois bugs em v√°rios componentes do sistema leva...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>6 erros divertidos do sistema na opera√ß√£o do Kubernetes [e sua solu√ß√£o]</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/443458/"><img src="https://habrastorage.org/webt/7o/mz/o2/7omzo2vcqpqijlxsewel9gyhcsq.png"><br><br>  Ao longo dos anos em que operamos o Kubernetes em produ√ß√£o, acumulamos muitas hist√≥rias interessantes, pois bugs em v√°rios componentes do sistema levavam a conseq√º√™ncias desagrad√°veis ‚Äã‚Äãe / ou incompreens√≠veis que afetam a opera√ß√£o de cont√™ineres e vagens.  Neste artigo, fizemos uma sele√ß√£o de alguns dos mais frequentes ou interessantes.  Mesmo que voc√™ nunca tenha a sorte de encontrar tais situa√ß√µes, ler sobre esses breves detetives - tanto em primeira m√£o - √© sempre divertido, n√£o √©? <a name="habracut"></a><br><br><h2>  Hist√≥ria 1. Docker supercr√¥nico e congelante </h2><br>  Em um dos clusters, recebemos periodicamente um Docker congelado, que interferia no funcionamento normal do cluster.  Ao mesmo tempo, o seguinte foi observado nos logs do Docker <br><br><pre><code class="plaintext hljs">level=error msg="containerd: start init process" error="exit status 2: \"runtime/cgo: pthread_create failed: No space left on device SIGABRT: abort PC=0x7f31b811a428 m=0 goroutine 0 [idle]: goroutine 1 [running]: runtime.systemstack_switch() /usr/local/go/src/runtime/asm_amd64.s:252 fp=0xc420026768 sp=0xc420026760 runtime.main() /usr/local/go/src/runtime/proc.go:127 +0x6c fp=0xc4200267c0 sp=0xc420026768 runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:2086 +0x1 fp=0xc4200267c8 sp=0xc4200267c0 goroutine 17 [syscall, locked to thread]: runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:2086 +0x1 ‚Ä¶</code> </pre> <br>  Nesse erro, estamos mais interessados ‚Äã‚Äãna mensagem: <code>pthread_create failed: No space left on device</code> .  Um r√°pido estudo da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o</a> explicou que o Docker n√£o p√¥de bifurcar o processo, o que causou o congelamento peri√≥dico. <br><br>  Ao monitorar o que est√° acontecendo, a seguinte imagem corresponde: <br><br><img src="https://habrastorage.org/webt/7r/cq/gv/7rcqgvafvtlmis1kl7maxyz5jgk.png"><br><br>  Uma situa√ß√£o semelhante √© observada em outros n√≥s: <br><br><img src="https://habrastorage.org/webt/lj/mw/-h/ljmw-hrrlyukwgmigltivjwyxig.png"><br><br><img src="https://habrastorage.org/webt/ap/tw/5u/aptw5ufxl-9woo5zszegfg1nqvc.png"><br><br>  Nos mesmos n√≥s, vemos: <br><br><pre> <code class="bash hljs">root@kube-node-1 ~ <span class="hljs-comment"><span class="hljs-comment"># ps auxfww | grep curl -c 19782 root@kube-node-1 ~ # ps auxfww | grep curl | head root 16688 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 17398 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 16852 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 9473 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 4664 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 30571 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 24113 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 16475 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 7176 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 1090 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt;</span></span></code> </pre> <br>  Acontece que esse comportamento √© uma consequ√™ncia do trabalho do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pod</a> com <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">supercronic</a> (o utilit√°rio Go que usamos para executar tarefas cron em pods): <br><br><pre> <code class="plaintext hljs"> \_ docker-containerd-shim 833b60bb9ff4c669bb413b898a5fd142a57a21695e5dc42684235df907825567 /var/run/docker/libcontainerd/833b60bb9ff4c669bb413b898a5fd142a57a21695e5dc42684235df907825567 docker-runc | \_ /usr/local/bin/supercronic -json /crontabs/cron | \_ /usr/bin/newrelic-daemon --agent --pidfile /var/run/newrelic-daemon.pid --logfile /dev/stderr --port /run/newrelic.sock --tls --define utilization.detect_aws=true --define utilization.detect_azure=true --define utilization.detect_gcp=true --define utilization.detect_pcf=true --define utilization.detect_docker=true | | \_ /usr/bin/newrelic-daemon --agent --pidfile /var/run/newrelic-daemon.pid --logfile /dev/stderr --port /run/newrelic.sock --tls --define utilization.detect_aws=true --define utilization.detect_azure=true --define utilization.detect_gcp=true --define utilization.detect_pcf=true --define utilization.detect_docker=true -no-pidfile | \_ [newrelic-daemon] &lt;defunct&gt; | \_ [curl] &lt;defunct&gt; | \_ [curl] &lt;defunct&gt; | \_ [curl] &lt;defunct&gt; ‚Ä¶</code> </pre> <br>  O problema √© o seguinte: quando uma tarefa come√ßa em supercr√¥nica, o processo gerado por ela <b>n√£o pode ser conclu√≠do corretamente</b> , transformando-se em um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">zumbi</a> . <br><br>  <i><b>Nota</b> : Para ser mais preciso, os processos s√£o gerados pelas tarefas cron, no entanto, supercronic n√£o √© um sistema init e n√£o pode "adotar" os processos que seus filhos geraram.</i>  <i>Quando os sinais SIGHUP ou SIGTERM ocorrem, eles n√£o s√£o transmitidos para os processos gerados, como resultado dos processos filhos n√£o terminam, permanecendo no status de zumbi.</i>  <i>Voc√™ pode ler mais sobre tudo isso, por exemplo, em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um artigo desse tipo</a> .</i> <br><br>  Existem algumas maneiras de resolver problemas: <br><br><ol><li>  Como solu√ß√£o tempor√°ria - aumente o n√∫mero de PIDs no sistema em um √∫nico momento: <br><br><pre> <code class="plaintext hljs"> /proc/sys/kernel/pid_max (since Linux 2.5.34) This file specifies the value at which PIDs wrap around (ie, the value in this file is one greater than the maximum PID). PIDs greater than this value are not allo‚Äê cated; thus, the value in this file also acts as a system-wide limit on the total number of processes and threads. The default value for this file, 32768, results in the same range of PIDs as on earlier kernels</code> </pre> </li><li>  Ou fa√ßa o lan√ßamento de tarefas no supercronic n√£o diretamente, mas com a ajuda do mesmo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tini</a> , capaz de finalizar corretamente os processos e n√£o gerar um zumbi. </li></ol><br><h2>  Hist√≥rico 2. "Zumbis" ao remover o cgroup </h2><br>  O Kubelet come√ßou a consumir muita CPU: <br><br><img src="https://habrastorage.org/webt/ns/lh/mp/nslhmpwfnmennya-btg5icbkh8e.png"><br><br>  Ningu√©m gosta disso, ent√£o nos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">preparamos</a> com <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">perf</a> e come√ßamos a lidar com o problema.  Os resultados da investiga√ß√£o foram os seguintes: <br><br><ul><li>  O Kubelet gasta mais de um ter√ßo do tempo da CPU puxando dados da mem√≥ria de todos os cgroups: <br><br><img src="https://habrastorage.org/webt/yf/u7/qv/yfu7qvvcnryl5iknz4zosagh0is.png"></li><li>  Na lista de discuss√£o dos desenvolvedores do kernel, voc√™ pode encontrar uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">discuss√£o sobre o problema</a> .  Resumindo, a conclus√£o √© que <b>diferentes arquivos tmpfs e outras coisas semelhantes n√£o s√£o completamente removidos do sistema</b> quando o cgroup √© exclu√≠do - o chamado <b>zumbi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">memcg</a></b> permanece.  Mais cedo ou mais tarde, eles ainda ser√£o removidos do cache da p√°gina, mas a mem√≥ria no servidor √© grande e o kernel n√£o v√™ o ponto de perder tempo.  Portanto, eles continuam a se acumular.  Por que isso est√° acontecendo?  Este √© um servidor com tarefas cron que constantemente cria novas tarefas e, com elas, novos pods.  Assim, novos cgroups s√£o criados para cont√™ineres neles, que ser√£o exclu√≠dos em breve. </li><li>  Por que o cAdvisor em kubelet gasta tanto tempo?  Isso √© facilmente visto pela execu√ß√£o mais simples do <code>time cat /sys/fs/cgroup/memory/memory.stat</code> .  Se a opera√ß√£o demorar 0,01 segundos em uma m√°quina √≠ntegra, 1,2 segundos em um cron02 problem√°tico.  O problema √© que o cAdvisor, que l√™ os dados do sysfs muito lentamente, tamb√©m leva em considera√ß√£o a mem√≥ria usada nos cgroups de zumbis. </li><li>  Para remover zumbis √† for√ßa, tentamos limpar os caches, conforme recomendado em LKML: <code>sync; echo 3 &gt; /proc/sys/vm/drop_caches</code>  <code>sync; echo 3 &gt; /proc/sys/vm/drop_caches</code> , mas o kernel acabou por ser mais complicado e travou a m√°quina. </li></ul><br>  O que fazer?  O problema foi corrigido ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">confirma√ß√£o</a> e descri√ß√£o, veja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a mensagem de lan√ßamento</a> ) atualizando o kernel do Linux para a vers√£o 4.16. <br><br><h2>  Hist√≥ria 3. Systemd e sua montagem </h2><br>  Novamente, o kubelet consome muitos recursos em alguns n√≥s, mas desta vez j√° √© mem√≥ria: <br><br><img src="https://habrastorage.org/webt/ud/l3/vl/udl3vlr9r5c6hzxoamdmnzvvm5m.png"><br><br>  Aconteceu que h√° um problema no systemd usado no Ubuntu 16.04, e isso ocorre ao controlar as montagens criadas para conectar <code>subPath</code> partir do ConfigMaps ou de segredos.  Ap√≥s a conclus√£o do pod, o <b>servi√ßo systemd e sua montagem de servi√ßo permanecem</b> no sistema.  Com o tempo, eles acumulam uma quantidade enorme.  Existem at√© quest√µes sobre este t√≥pico: <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pulos # 5916</a> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">kubernetes # 57345</a> . </li></ol><br>  ... no √∫ltimo dos quais se refere ao PR no systemd: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="># 7811</a> (o problema no systemd √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="># 7798</a> ). <br><br>  O problema n√£o est√° mais no Ubuntu 18.04, mas se voc√™ quiser continuar usando o Ubuntu 16.04, nossa solu√ß√£o alternativa para este t√≥pico pode ser √∫til. <br><br>  Ent√£o, criamos o seguinte DaemonSet: <br><br><pre> <code class="plaintext hljs">--- apiVersion: extensions/v1beta1 kind: DaemonSet metadata: labels: app: systemd-slices-cleaner name: systemd-slices-cleaner namespace: kube-system spec: updateStrategy: type: RollingUpdate selector: matchLabels: app: systemd-slices-cleaner template: metadata: labels: app: systemd-slices-cleaner spec: containers: - command: - /usr/local/bin/supercronic - -json - /app/crontab Image: private-registry.org/systemd-slices-cleaner/systemd-slices-cleaner:v0.1.0 imagePullPolicy: Always name: systemd-slices-cleaner resources: {} securityContext: privileged: true volumeMounts: - name: systemd mountPath: /run/systemd/private - name: docker mountPath: /run/docker.sock - name: systemd-etc mountPath: /etc/systemd - name: systemd-run mountPath: /run/systemd/system/ - name: lsb-release mountPath: /etc/lsb-release-host imagePullSecrets: - name: antiopa-registry priorityClassName: cluster-low tolerations: - operator: Exists volumes: - name: systemd hostPath: path: /run/systemd/private - name: docker hostPath: path: /run/docker.sock - name: systemd-etc hostPath: path: /etc/systemd - name: systemd-run hostPath: path: /run/systemd/system/ - name: lsb-release hostPath: path: /etc/lsb-release</code> </pre> <br>  ... e usa o seguinte script: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash # we will work only on xenial hostrelease="/etc/lsb-release-host" test -f ${hostrelease} &amp;&amp; grep xenial ${hostrelease} &gt; /dev/null || exit 0 # sleeping max 30 minutes to dispense load on kube-nodes sleep $((RANDOM % 1800)) stoppedCount=0 # counting actual subpath units in systemd countBefore=$(systemctl list-units | grep subpath | grep "run-" | wc -l) # let's go check each unit for unit in $(systemctl list-units | grep subpath | grep "run-" | awk '{print $1}'); do # finding description file for unit (to find out docker container, who born this unit) DropFile=$(systemctl status ${unit} | grep Drop | awk -F': ' '{print $2}') # reading uuid for docker container from description file DockerContainerId=$(cat ${DropFile}/50-Description.conf | awk '{print $5}' | cut -d/ -f6) # checking container status (running or not) checkFlag=$(docker ps | grep -c ${DockerContainerId}) # if container not running, we will stop unit if [[ ${checkFlag} -eq 0 ]]; then echo "Stopping unit ${unit}" # stoping unit in action systemctl stop $unit # just counter for logs ((stoppedCount++)) # logging current progress echo "Stopped ${stoppedCount} systemd units out of ${countBefore}" fi done</span></span></code> </pre> <br>  ... e come√ßa a cada 5 minutos com o supercr√¥nico j√° mencionado.  O arquivo Dockerfile fica assim: <br><br><pre> <code class="plaintext hljs">FROM ubuntu:16.04 COPY rootfs / WORKDIR /app RUN apt-get update &amp;&amp; \ apt-get upgrade -y &amp;&amp; \ apt-get install -y gnupg curl apt-transport-https software-properties-common wget RUN add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu xenial stable" &amp;&amp; \ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add - &amp;&amp; \ apt-get update &amp;&amp; \ apt-get install -y docker-ce=17.03.0* RUN wget https://github.com/aptible/supercronic/releases/download/v0.1.6/supercronic-linux-amd64 -O \ /usr/local/bin/supercronic &amp;&amp; chmod +x /usr/local/bin/supercronic ENTRYPOINT ["/bin/bash", "-c", "/usr/local/bin/supercronic -json /app/crontab"]</code> </pre> <br><h2>  Hist√≥ria 4. Competi√ß√£o no planejamento de pods </h2><br>  Observou-se que: se um pod √© colocado em nosso n√≥ e sua imagem √© bombeada por um per√≠odo muito longo, o outro pod que "chegou" ao mesmo n√≥ simplesmente <b>n√£o come√ßa a puxar a imagem do novo pod</b> .  Em vez disso, ele espera que a imagem do pod anterior seja puxada.  Como resultado, um pod que j√° foi planejado e cuja imagem pode ser baixada em apenas um minuto terminar√° no status <code>containerCreating</code> por um longo tempo. <br><br>  Nos eventos, haver√° algo parecido com isto: <br><br><pre> <code class="plaintext hljs">Normal Pulling 8m kubelet, ip-10-241-44-128.ap-northeast-1.compute.internal pulling image "registry.example.com/infra/openvpn/openvpn:master"</code> </pre> <br>  Acontece que <b>uma √∫nica imagem do registro lento pode bloquear a implanta√ß√£o</b> no n√≥. <br><br>  Infelizmente, n√£o h√° muitas maneiras de sair da situa√ß√£o: <br><br><ol><li>  Tente usar o Docker Registry diretamente no cluster ou diretamente com o cluster (por exemplo, GitLab Registry, Nexus etc.); </li><li>  Use utilit√°rios como o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">kraken</a> . </li></ol><br><h2>  Hist√≥rico 5. Pendurar n√≥s com mem√≥ria insuficiente </h2><br>  Durante a opera√ß√£o de v√°rios aplicativos, tamb√©m recebemos uma situa√ß√£o em que o n√≥ deixa completamente de ser acess√≠vel: o SSH n√£o responde, todos os daemons de monitoramento caem e, em seguida, nada (ou quase nada) √© anormal nos logs. <br><br>  Vou lhe dizer nas imagens no exemplo de um n√≥ em que o MongoDB funcionava. <br><br>  √â assim que o topo fica <b>antes do</b> acidente: <br><br><img src="https://habrastorage.org/webt/l5/ef/az/l5efazbhjmzsuxdv6puz1tlvbzs.png"><br><br>  E assim - <b>ap√≥s o</b> acidente: <br><br><img src="https://habrastorage.org/webt/wx/mh/q7/wxmhq71060dhvxsxk-dh8m--pas.png"><br><br>  Tamb√©m no monitoramento, h√° um salto acentuado no qual o n√≥ deixa de ser acess√≠vel: <br><br><img src="https://habrastorage.org/webt/tp/fm/wf/tpfmwftsui_eoz91ojyy5rzektc.png"><br><br>  Assim, as capturas de tela mostram que: <br><br><ol><li>  RAM na m√°quina est√° perto do fim; </li><li>  √â observado um salto acentuado no consumo de RAM, ap√≥s o qual o acesso a toda a m√°quina √© fortemente desativado; </li><li>  Uma grande tarefa chega ao Mongo, o que for√ßa o processo DBMS a usar mais mem√≥ria e ler ativamente do disco. </li></ol><br>  Acontece que, se o Linux ficar sem mem√≥ria livre (ocorre press√£o de mem√≥ria) e n√£o houver troca, <b>antes que</b> o killer do OOM chegue, um equil√≠brio poder√° ocorrer entre jogar p√°ginas no cache da p√°gina e grav√°-las no disco.  Isso √© feito pelo kswapd, que corajosamente libera o m√°ximo de p√°ginas de mem√≥ria poss√≠vel para distribui√ß√£o posterior. <br><br>  Infelizmente, com uma grande carga de E / S, juntamente com uma pequena quantidade de mem√≥ria livre, o <b>kswapd se torna o gargalo de todo o sistema</b> , porque <b>todas as</b> falhas de p√°gina das p√°ginas de mem√≥ria do sistema est√£o ligadas a ele.  Isso pode durar muito tempo se os processos n√£o quiserem mais usar mem√≥ria, mas estiverem fixos no limite do abismo do OOM. <br><br>  A quest√£o l√≥gica √©: por que o assassino da OOM chega t√£o tarde?  Na itera√ß√£o atual do OOM, o killer √© extremamente est√∫pido: ele mata o processo apenas quando a tentativa de alocar uma p√°gina de mem√≥ria falha, ou seja,  se a falha da p√°gina falhar.  Isso n√£o acontece por um longo tempo, porque o kswapd libera corajosamente as p√°ginas de mem√≥ria liberando o cache da p√°gina (de fato, todas as E / S de disco do sistema) de volta ao disco.  Mais detalhadamente, com uma descri√ß√£o das etapas necess√°rias para eliminar esses problemas no kernel, voc√™ pode ler <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br>  Esse comportamento <a href="">deve melhorar</a> com o kernel Linux 4.6+. <br><br><h2>  Hist√≥ria 6. Pods est√£o pendentes </h2><br>  Em alguns clusters, nos quais existem realmente muitos pods, come√ßamos a perceber que a maioria deles fica suspensa por um per√≠odo muito longo no estado <code>Pending</code> , embora, ao mesmo tempo, os cont√™ineres do Docker j√° estejam em execu√ß√£o nos n√≥s e voc√™ possa trabalhar manualmente com eles. <br><br>  N√£o h√° nada de errado em <code>describe</code> : <br><br><pre> <code class="plaintext hljs"> Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 1m default-scheduler Successfully assigned sphinx-0 to ss-dev-kub07 Normal SuccessfulAttachVolume 1m attachdetach-controller AttachVolume.Attach succeeded for volume "pvc-6aaad34f-ad10-11e8-a44c-52540035a73b" Normal SuccessfulMountVolume 1m kubelet, ss-dev-kub07 MountVolume.SetUp succeeded for volume "sphinx-config" Normal SuccessfulMountVolume 1m kubelet, ss-dev-kub07 MountVolume.SetUp succeeded for volume "default-token-fzcsf" Normal SuccessfulMountVolume 49s (x2 over 51s) kubelet, ss-dev-kub07 MountVolume.SetUp succeeded for volume "pvc-6aaad34f-ad10-11e8-a44c-52540035a73b" Normal Pulled 43s kubelet, ss-dev-kub07 Container image "registry.example.com/infra/sphinx-exporter/sphinx-indexer:v1" already present on machine Normal Created 43s kubelet, ss-dev-kub07 Created container Normal Started 43s kubelet, ss-dev-kub07 Started container Normal Pulled 43s kubelet, ss-dev-kub07 Container image "registry.example.com/infra/sphinx/sphinx:v1" already present on machine Normal Created 42s kubelet, ss-dev-kub07 Created container Normal Started 42s kubelet, ss-dev-kub07 Started container</code> </pre> <br>  Depois de pesquisar, assumimos que o kubelet simplesmente n√£o tem tempo para enviar ao servidor da API todas as informa√ß√µes sobre o estado dos pods, amostras de vitalidade / prontid√£o. <br><br>  E, tendo estudado a ajuda, encontramos os seguintes par√¢metros: <br><br><pre> <code class="plaintext hljs">--kube-api-qps - QPS to use while talking with kubernetes apiserver (default 5) --kube-api-burst - Burst to use while talking with kubernetes apiserver (default 10) --event-qps - If &gt; 0, limit event creations per second to this value. If 0, unlimited. (default 5) --event-burst - Maximum size of a bursty event records, temporarily allows event records to burst to this number, while still not exceeding event-qps. Only used if --event-qps &gt; 0 (default 10) --registry-qps - If &gt; 0, limit registry pull QPS to this value. --registry-burst - Maximum size of bursty pulls, temporarily allows pulls to burst to this number, while still not exceeding registry-qps. Only used if --registry-qps &gt; 0 (default 10)</code> </pre> <br>  Como voc√™ pode ver, os <b>valores padr√£o s√£o muito pequenos</b> e, em 90%, cobrem todas as necessidades ... No entanto, no nosso caso, isso n√£o foi suficiente.  Portanto, definimos estes valores: <br><br><pre> <code class="plaintext hljs">--event-qps=30 --event-burst=40 --kube-api-burst=40 --kube-api-qps=30 --registry-qps=30 --registry-burst=40</code> </pre> <br><br>  ... e reiniciou os kubelets, ap√≥s o que viram a seguinte imagem nos gr√°ficos de acesso ao servidor da API: <br><br><img src="https://habrastorage.org/webt/nq/-i/oq/nq-ioqoyt6_qudmacm5dwfe8hnk.png"><br><br>  ... e sim, tudo come√ßou a voar! <br><br><h2>  PS </h2><br>  Para obter ajuda na coleta de bugs e na prepara√ß√£o do artigo, expresso minha profunda gratid√£o aos in√∫meros engenheiros de nossa empresa e, em particular, a Andrei Klimentyev (colega de nossa equipe de P&amp;D) ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">zuzzas</a> ). <br><br><h2>  PPS </h2><br>  Leia tamb√©m em nosso blog: <br><br><ul><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Plugin Kubectl-debug para depura√ß√£o nos pods do Kubernetes</a> ‚Äù; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Monitoramento e Kubernetes (revis√£o e reportagem em v√≠deo)</a> ‚Äù; </li><li>  Ciclo de dicas e truques do Kubernetes: <ul><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Transfer√™ncia de recursos trabalhando em um cluster para gerenciamento do Helm 2</a> ‚Äù; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Sobre a aloca√ß√£o de n√≥s e a carga na aplica√ß√£o web</a> ‚Äù; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Acesso a sites de desenvolvimento</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Acelerando a inicializa√ß√£o de grandes bancos de dados.</a> " </li></ul></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt443458/">https://habr.com/ru/post/pt443458/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt443438/index.html">7 extens√µes √∫teis do Firefox para aprender ingl√™s</a></li>
<li><a href="../pt443440/index.html">M√≥dulo PHP para trabalhar com dados hier√°rquicos no InterSystems IRIS</a></li>
<li><a href="../pt443450/index.html">Por que os pobres n√£o podem ser saud√°veis</a></li>
<li><a href="../pt443452/index.html">Militares russos criar√£o sua pr√≥pria Internet fechada</a></li>
<li><a href="../pt443456/index.html">Convidamos voc√™ a Yandex PNL por uma semana</a></li>
<li><a href="../pt443460/index.html">11 respostas sobre Yandex.Directory</a></li>
<li><a href="../pt443462/index.html">Hackeando c√¢meras: vetores de ataque, ferramentas de pesquisa de vulnerabilidades e anti-rastreamento</a></li>
<li><a href="../pt443464/index.html">Guia completo para alternar express√µes em Java 12</a></li>
<li><a href="../pt443466/index.html">Rei do desenvolvimento</a></li>
<li><a href="../pt443468/index.html">Quais ferramentas de monitoramento de rede se tornaram l√≠deres na vers√£o do Gartner</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
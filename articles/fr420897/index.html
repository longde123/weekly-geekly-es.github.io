<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíÉ üöÜ üë©üèø‚Äçü§ù‚Äçüë®üèæ Formation de renforcement PyBullet ‚úãüèæ üèÖ üë®üèæ‚Äçüöí</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="De nombreuses personnes qui √©tudient l'apprentissage automatique connaissent le projet OpenAI, dont l'un des fondateurs est Elon Musk, et utilisent la...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Formation de renforcement PyBullet</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420897/"><img src="https://habrastorage.org/webt/0g/x5/ai/0gx5aizowrlyrgkvekcxlxh9pge.png" alt="image"><br><br>  De nombreuses personnes qui √©tudient l'apprentissage automatique connaissent le projet OpenAI, dont l'un des fondateurs est Elon Musk, et utilisent la plate-forme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenAI Gym</a> pour former leurs mod√®les de r√©seau neuronal. <br><br>  La salle de gym contient un vaste ensemble d'environnements, certains d'entre eux sont diff√©rents types de simulations physiques: les mouvements des animaux, des humains, des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">robots</a> .  Ces simulations sont bas√©es sur le moteur physique <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MuJoCo</a> , qui est gratuit √† des fins √©ducatives et scientifiques. <br><br>  Dans cet article, nous allons cr√©er une simulation physique extr√™mement simple similaire √† l'environnement OpenAI Gym, mais bas√©e sur le moteur de physique gratuit Bullet ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PyBullet</a> ).  Et cr√©ez √©galement un agent pour travailler avec cet environnement. <br><a name="habracut"></a><br>  PyBullet est un module python pour cr√©er un environnement de simulation physique bas√© sur le moteur physique <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bullet Physics</a> .  Il, comme MuJoCo, est souvent utilis√© comme stimulation de divers robots, qui sont int√©ress√©s par habr il y a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un article</a> avec des exemples r√©els. <br><br>  Il existe un tr√®s bon <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">QuickStartGuide</a> pour PyBullet qui contient des liens vers des exemples sur la page source de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GitHub</a> . <br><br>  PyBullet vous permet de charger des mod√®les d√©j√† cr√©√©s au format URDF, SDF ou MJCF.  Dans les sources, il y a une biblioth√®que de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mod√®les</a> dans ces formats, ainsi que des environnements compl√®tement pr√™ts √† l'emploi de simulateurs de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vrais robots.</a> <br><br>  Dans notre cas, nous cr√©erons nous-m√™mes l'environnement en utilisant PyBullet.  L'interface d'environnement sera <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">similaire √†</a> l'interface d'OpenAI Gym.  De cette fa√ßon, nous pouvons former nos agents √† la fois dans notre environnement et dans l'environnement Gym. <br><br>  Tout le code (iPython), ainsi que le fonctionnement du programme sont visibles dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Google Colaboratory</a> . <br><br><h2>  L'environnement </h2><br>  Notre environnement sera constitu√© d'une balle qui peut se d√©placer le long de l'axe vertical dans une certaine plage de hauteurs.  La balle a une masse et la gravit√© agit sur elle, et l'agent doit, en contr√¥lant la force verticale appliqu√©e √† la balle, la ramener √† la cible.  L'altitude cible change √† chaque red√©marrage de l'exp√©rience. <br><br><img src="https://habrastorage.org/webt/w-/wy/jr/w-wyjrj1zphr8aqndhutrnno1po.png" alt="image"><br><br>  La simulation est tr√®s simple et peut en fait √™tre consid√©r√©e comme une simulation de quelque √©l√©mentaire. <br><br>  Pour travailler avec l'environnement, 3 m√©thodes sont utilis√©es: <i><b>reset</b></i> (red√©marrage de l'exp√©rience et cr√©ation de tous les objets de l'environnement), <i><b>√©tape</b></i> (application de l'action s√©lectionn√©e et obtention de l'√©tat r√©sultant de l'environnement), <i><b>rendu</b></i> (affichage visuel de l'environnement). <br><br>  Lors de l'initialisation de l'environnement, il est n√©cessaire de connecter notre objet √† la simulation physique.  Il existe 2 options de connexion: avec une interface graphique (GUI) et sans (DIRECT) Dans notre cas, c'est DIRECT. <br><br><pre><code class="python hljs">pb.connect(pb.DIRECT)</code> </pre> <br><h4>  r√©initialiser </h4><br>  Avec chaque nouvelle exp√©rience, nous r√©initialisons la simulation <i>pb.resetSimulation ()</i> et cr√©ons √† nouveau tous les objets d'environnement. <br><br>  Dans PyBullet, les objets ont 2 formes: une <i>forme de</i> collision et une <i>forme visuelle</i> .  Le premier est utilis√© par le moteur physique pour calculer les collisions d'objets et, pour acc√©l√©rer le calcul de la physique, a g√©n√©ralement une forme plus simple qu'un objet r√©el.  Le second est facultatif et n'est utilis√© que lors de la formation de l'image de l'objet. <br><br>  Les formulaires sont collect√©s dans un seul objet (corps) - <i>MultiBody</i> .  Un corps peut √™tre constitu√© d'une seule forme (paire <i>CollisionShape / Visual Shape</i> ), comme dans notre cas, ou de plusieurs. <br><br>  En plus des formes qui composent le corps, il est n√©cessaire de d√©terminer sa masse, sa position et son orientation dans l'espace. <br><br><div class="spoiler">  <b class="spoiler_title">Quelques mots sur les corps multi-objets.</b> <div class="spoiler_text">  En r√®gle g√©n√©rale, dans des cas r√©els, pour simuler divers m√©canismes, des corps compos√©s de nombreuses formes sont utilis√©s.  Lors de la cr√©ation du corps, en plus de la forme de base des collisions et de la visualisation, le corps est transf√©r√© des cha√Ænes de formes d'objets enfants ( <i>Liens</i> ), leur position et leur orientation par rapport √† l'objet pr√©c√©dent, ainsi que les types de connexions (articulations) d'objets entre eux ( <i>Articulation</i> ).  Les types de connexions peuvent √™tre fixes, prismatiques (glissant sur le m√™me axe) ou rotatifs (tournant sur un axe).  Les 2 derniers types de connexions vous permettent de d√©finir les param√®tres des types de moteurs correspondants ( <i>JointMotor</i> ), tels que la force agissante, la vitesse ou le couple, simulant ainsi les moteurs des "articulations" du robot.  Plus de d√©tails dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation</a> . <br></div></div><br>  Nous allons cr√©er 3 corps: Ball, Plane (Earth) et Target Pointer.  Le dernier objet n'aura qu'une forme de visualisation et une masse nulle, il ne participera donc pas √† l'interaction physique entre les corps: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  floorColShape = pb.createCollisionShape(pb.GEOM_PLANE) #   (GEOM_PLANE), visualShape -    ,   GEOM_BOX floorVisualShapeId = pb.createVisualShape(pb.GEOM_BOX,halfExtents=[100,100,0.0001], rgbaColor=[1,1,.98,1]) pb_floorId = pb.createMultiBody(0,floorColShape,floorVisualShapeId, [0,0,0], [0,0,0,1]) #  PB_BallRadius = 0.2 PB_BallMass = 1 ballPosition = [0,0,5] ballOrientation=[0,0,0,1] ballColShape = pb.createCollisionShape(pb.GEOM_SPHERE,radius=PB_BallRadius) ballVisualShapeId = pb.createVisualShape(pb.GEOM_SPHERE,radius=PB_BallRadius, rgbaColor=[1,0.27,0,1]) pb_ballId = pb.createMultiBody(PB_BallMass, ballColShape, ballVisualShapeId, ballPosition, ballOrientation) #   TARGET_Z = 8 targetPosition = [0,0,TARGET_Z] targetOrientation=[0,0,0,1] targetVisualShapeId = pb.createVisualShape(pb.GEOM_BOX,halfExtents=[1,0.025,0.025], rgbaColor=[0,0,0,1]) pb_targetId = pb.createMultiBody(0,-1, targetVisualShapeId, targetPosition, targetOrientation)</span></span></code> </pre><br>  D√©finissez la gravit√© et le temps de l'√©tape de simulation. <br><br><pre> <code class="python hljs">pb.setGravity(<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">-10</span></span>) pb.setTimeStep(<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">60</span></span>)</code> </pre> <br>  Pour emp√™cher la balle de tomber imm√©diatement apr√®s le d√©but de la simulation, nous √©quilibrons la gravit√©. <br><br><pre> <code class="python hljs">pb_force = <span class="hljs-number"><span class="hljs-number">10</span></span> * PB_BallMass pb.applyExternalForce(pb_ballId, <span class="hljs-number"><span class="hljs-number">-1</span></span>, [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,pb_force], [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>], pb.LINK_FRAME)</code> </pre> <br><br><h4>  pas </h4><br>  L'agent s√©lectionne des actions en fonction de l'√©tat actuel de l'environnement, apr√®s quoi il appelle la m√©thode <i>step</i> et re√ßoit un nouvel √©tat. <br><br>  2 types d'action sont d√©finis: augmentation et diminution de la force agissant sur le ballon.  Les limites de force sont limit√©es. <br><br>  Apr√®s avoir modifi√© la force agissant sur la balle, une nouvelle √©tape de simulation physique <i>pb.stepSimulation () est lanc√©e</i> et les param√®tres suivants sont renvoy√©s √† l'agent: <br><br>  <i>observation</i> - observations (√©tat de l'environnement) <br>  <i>r√©compense</i> - r√©compense pour une action parfaite <br>  <i>fait</i> - le drapeau de la fin de l'exp√©rience <br>  <i>info</i> - informations suppl√©mentaires <br><br>  Comme l'√©tat de l'environnement, 3 valeurs sont renvoy√©es: la distance √† la cible, la force actuelle appliqu√©e √† la balle et la vitesse de la balle.  Les valeurs sont retourn√©es normalis√©es (0..1), car les param√®tres environnementaux qui d√©terminent ces valeurs peuvent varier en fonction de notre d√©sir. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     (     Z curPos[2]) curPos, curOrient = pb.getBasePositionAndOrientation(pb_ballId) #     (      Z lin_vel[2]) lin_vel, ang_vel= pb.getBaseVelocity(self.pb_ballId)</span></span></code> </pre> <br>  La r√©compense pour l'action parfaite est 1 si le ballon est proche de la cible (hauteur cible plus / moins la valeur de roulement acceptable <i>TARGET_DELTA</i> ) et 0 dans les autres cas. <br>  L'exp√©rience est termin√©e si le ballon sort de la zone (tombe au sol ou vole haut).  Si le ballon atteint le but, l'exp√©rience se termine √©galement, mais seulement apr√®s un certain temps (√©tapes <i>STEPS_AFTER_TARGET</i> de l'exp√©rience).  Ainsi, notre agent est form√© non seulement pour avancer vers le but, mais aussi pour s'arr√™ter et en est proche.  √âtant donn√© que la r√©compense lorsque vous √™tes proche de l'objectif est de 1, une exp√©rience pleinement r√©ussie devrait avoir une r√©compense totale √©gale √† <i>STEPS_AFTER_TARGET</i> . <br><br>  En tant qu'informations suppl√©mentaires pour l'affichage des statistiques, le nombre total d'√©tapes effectu√©es dans l'exp√©rience, ainsi que le nombre d'√©tapes effectu√©es par seconde, est renvoy√©. <br><br><h4>  rendre </h4><br>  PyBullet dispose de 2 options de rendu d'image - le rendu GPU bas√© sur OpenGL et le processeur bas√© sur TinyRenderer.  Dans notre cas, seule une impl√©mentation CPU est possible. <br><br>  Pour obtenir la trame actuelle de la simulation, il est n√©cessaire de d√©terminer la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">matrice des esp√®ces</a> et la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">matrice de projection</a> , puis d'obtenir l'image <i>rgb</i> de la taille donn√©e √† partir de la cam√©ra. <br><br><pre> <code class="python hljs">camTargetPos = [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>] <span class="hljs-comment"><span class="hljs-comment">#   ()  camDistance = 10 #     yaw = 0 #     pitch = 0 #     roll=0 #      upAxisIndex = 2 #    (z) fov = 60 #    nearPlane = 0.01 #      farPlane = 20 #      pixelWidth = 320 #   pixelHeight = 200 #   aspect = pixelWidth/pixelHeight; #    #   viewMatrix = pb.computeViewMatrixFromYawPitchRoll(camTargetPos, camDistance, yaw, pitch, roll, upAxisIndex) #   projectionMatrix = pb.computeProjectionMatrixFOV(fov, aspect, nearPlane, farPlane); #     img_arr = pb.getCameraImage(pixelWidth, pixelHeight, viewMatrix, projectionMatrix, shadow=0, lightDirection=[0,1,1],renderer=pb.ER_TINY_RENDERER) w=img_arr[0] #width of the image, in pixels h=img_arr[1] #height of the image, in pixels rgb=img_arr[2] #color data RGB dep=img_arr[3] #depth data</span></span></code> </pre> <br>  √Ä la fin de chaque exp√©rience, une vid√©o est g√©n√©r√©e sur la base des images collect√©es. <br><br><pre> <code class="python hljs">ani = animation.ArtistAnimation(plt.gcf(), render_imgs, interval=<span class="hljs-number"><span class="hljs-number">10</span></span>, blit=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>,repeat_delay=<span class="hljs-number"><span class="hljs-number">1000</span></span>) display(HTML(ani.to_html5_video()))</code> </pre><br><h2>  Agent </h2><br>  Le code utilisateur GitHub <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">jaara a</a> √©t√© pris comme base pour l'agent, comme un exemple simple et compr√©hensible de mise en ≈ìuvre de l'entra√Ænement de renforcement pour l'environnement Gym. <br><br>  L'agent contient 2 objets: la <i>m√©moire</i> - un stockage pour la formation d'exemples d'entra√Ænement et le <i>cerveau lui-m√™me est</i> le r√©seau neuronal qu'il forme. <br><br>  Le r√©seau neuronal form√© a √©t√© cr√©√© sur TensorFlow √† l'aide de la biblioth√®que Keras, qui a r√©cemment √©t√© enti√®rement <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">incluse</a> dans TensorFlow. <br>  Le r√©seau neuronal a une structure simple - 3 couches, c'est-√†-dire  Seulement 1 couche cach√©e. <br><br>  La premi√®re couche contient 512 neurones et poss√®de un nombre d'entr√©es √©gal au nombre de param√®tres de l'√©tat du milieu (3 param√®tres: distance √† la cible, force et vitesse de la balle).  La couche cach√©e a une dimension √©gale √† la premi√®re couche - 512 neurones, en sortie elle est connect√©e √† la couche de sortie.  Le nombre de neurones de la couche de sortie correspond au nombre d'actions effectu√©es par l'agent (2 actions: diminution et augmentation de la force agissante). <br><br>  Ainsi, l'√©tat du syst√®me est fourni √† l'entr√©e du r√©seau, et √† la sortie, nous avons un avantage pour chacune des actions. <br><br>  Pour les deux premi√®res couches, <i>ReLU</i> (unit√© lin√©aire rectifi√©e) est utilis√©e comme fonctions d'activation, pour la derni√®re - une <i>fonction lin√©aire</i> (la somme des valeurs d'entr√©e est simple). <br>  En fonction de l'erreur, <i>MSE</i> (erreur standard), comme algorithme d'optimisation - <i>RMSprop</i> (Root Mean Square Propagation). <br><br><pre> <code class="python hljs">model = Sequential() model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_dim=<span class="hljs-number"><span class="hljs-number">3</span></span>)) model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'linear'</span></span>)) opt = RMSprop(lr=<span class="hljs-number"><span class="hljs-number">0.00025</span></span>) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'mse'</span></span>, optimizer=opt)</code> </pre><br>  Apr√®s chaque √©tape de simulation, l'agent enregistre les r√©sultats de cette √©tape sous forme de liste <i>(s, a, r, s_)</i> : <br>  <i>s</i> - observation pr√©c√©dente (√©tat de l'environnement) <br>  <i>a</i> - action termin√©e <br>  <i>r</i> - r√©compense re√ßue pour l'action effectu√©e <br>  <i>s_</i> - observation finale apr√®s l'action <br><br>  Apr√®s cela, l'agent re√ßoit de la m√©moire un ensemble al√©atoire d'exemples pour les p√©riodes pr√©c√©dentes et forme un package de formation ( <i>batch</i> ). <br><br>  L'√©tat initial <i>s</i> des √©tapes al√©atoires s√©lectionn√©es dans la m√©moire est pris comme valeurs d'entr√©e ( <i>X</i> ) du paquet. <br><br>  Les valeurs r√©elles de la sortie d'apprentissage ( <i>Y '</i> ) sont calcul√©es comme suit: √Ä la sortie ( <i>Y</i> ) du r√©seau neuronal pour s, il y aura des valeurs de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">fonction Q</a> pour chacune des actions <i>Q (s)</i> .  Dans cet ensemble, l'agent a s√©lectionn√© l'action avec la valeur la plus √©lev√©e <i>Q (s, a) = MAX (Q (s))</i> , l'a termin√©e et a re√ßu le prix <i>r</i> .  La nouvelle valeur <i>Q</i> pour l'action s√©lectionn√©e <i>a</i> sera <i>Q (s, a) = Q (s, a) + DF * r</i> , o√π <i>DF</i> est le facteur d'actualisation.  Les valeurs de sortie restantes resteront les m√™mes. <br><br><pre> <code class="python hljs">STATE_CNT = <span class="hljs-number"><span class="hljs-number">3</span></span> ACTION_CNT = <span class="hljs-number"><span class="hljs-number">2</span></span> batchLen = <span class="hljs-number"><span class="hljs-number">32</span></span> <span class="hljs-comment"><span class="hljs-comment">#     states = numpy.array([ o[0] for o in batch ]) #     states_ = numpy.array([ o[3] for o in batch ]) #     p = agent.brain.predict(states) #     p_ = agent.brain.predict(states_) #     x = numpy.zeros((batchLen, STATE_CNT)) y = numpy.zeros((batchLen, ACTION_CNT)) #   for i in range(batchLen): o = batch[i] s = o[0]; a = o[1]; r = o[2]; s_ = o[3] t = p[i] #      #      ,       t[a] = r + GAMMA * numpy.amax(p_[i]) #            #    batch x[i] = s y[i] = t #      self.brain.train(x, y)</span></span></code> </pre> <br>  La formation r√©seau a lieu sur le pack form√© <br><br><pre> <code class="python hljs">self.model.fit(x, y, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Une fois l'exp√©rience termin√©e, une vid√©o est g√©n√©r√©e <br><br><img src="https://habrastorage.org/webt/om/ox/rk/omoxrkmnrigllf9hu_8x9ofbd7m.gif" alt="image"><br><br>  et les statistiques sont affich√©es <br><br><img src="https://habrastorage.org/webt/0s/ed/p2/0sedp2zvwqmiiku6emmhp2yxf7m.png" alt="image"><br><br>  L'agent a eu besoin de 1 200 essais pour obtenir un r√©sultat d'environ 95% (nombre d'√©tapes r√©ussies).  Et √† la 50e exp√©rience, l'agent avait appris √† d√©placer la balle vers la cible (les exp√©riences infructueuses disparaissent). <br><br>  Pour am√©liorer les r√©sultats, vous pouvez essayer de modifier la taille des couches r√©seau (LAYER_SIZE), le param√®tre du facteur d'actualisation (GAMMA) ou le taux de diminution de la probabilit√© de choisir une action al√©atoire (LAMBDA). <br><br>  Notre agent a l'architecture la plus simple - DQN (Deep Q-Network).  Sur une t√¢che aussi simple, il suffit d'obtenir un r√©sultat acceptable. <br><br>  L'utilisation, par exemple, de l'architecture DDQN (Double DQN) devrait fournir une formation plus fluide et plus pr√©cise.  Et le r√©seau RDQN (DQN r√©current) sera en mesure de suivre les mod√®les de changement environnemental au fil du temps, ce qui permettra de se d√©barrasser du param√®tre de vitesse de balle, r√©duisant le nombre de param√®tres d'entr√©e du r√©seau. <br><br>  Vous pouvez √©galement √©tendre notre simulation en ajoutant une masse de balle variable ou l'angle d'inclinaison de son mouvement. <br><br>  Mais c'est la prochaine fois. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr420897/">https://habr.com/ru/post/fr420897/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr420887/index.html">Rapport Tele2 Hackathon</a></li>
<li><a href="../fr420889/index.html">La technologie de d√©tection des mines militaires aide les robots √† naviguer sur toutes les routes</a></li>
<li><a href="../fr420891/index.html">Migration vers JUnit 5 en 10 min. Mesurer le temps de test avec des extensions</a></li>
<li><a href="../fr420893/index.html">Emballage de franchise A √† B</a></li>
<li><a href="../fr420895/index.html">Comment j'ai r√©anim√© un appareil (√©mulateur JTAG BH-USB-560v2) via U-Boot</a></li>
<li><a href="../fr420901/index.html">Comment j'√©tudie le cadre Spring (l'aide aux d√©butants est le travail des d√©butants eux-m√™mes)</a></li>
<li><a href="../fr420903/index.html">Impl√©mentation de l'ERP: comment ne pas √©chouer</a></li>
<li><a href="../fr420905/index.html">Comment l'√©clairage intelligent est introduit en Russie et combien de temps cela prendra</a></li>
<li><a href="../fr420907/index.html">De NOKLA √† Xiaomi: l'√©volution des t√©l√©phones mobiles chinois</a></li>
<li><a href="../fr420909/index.html">Les t√©l√©visions russes accusent Yandex de piraterie</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
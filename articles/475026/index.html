<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>游놊游낖 游놌游 游걏 3 historias de accidentes de Kubernetes en producci칩n: anti-afinidad, cierre elegante, webhook 游땵 游 游걊</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nota perev. : Presentamos una mini-selecci칩n de autopsias sobre los problemas fatales que enfrentaron los ingenieros de diferentes compa침칤as al operar...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>3 historias de accidentes de Kubernetes en producci칩n: anti-afinidad, cierre elegante, webhook</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/475026/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/y7/_c/ra/y7_cracjhm0ke_mtazml1fhzprk.jpeg"></div><br>  <i><b>Nota</b></i>  <i><b>perev.</b></i>  <i>: Presentamos una mini-selecci칩n de autopsias sobre los problemas fatales que enfrentaron los ingenieros de diferentes compa침칤as al operar la infraestructura basada en Kubernetes.</i>  <i>Cada nota habla sobre el problema en s칤, sus causas y consecuencias y, por supuesto, sobre una soluci칩n que ayuda a evitar situaciones similares en el futuro.</i> <i><br><br></i>  <i>Como sabes, aprender de la experiencia de otra persona es m치s barato y, por lo tanto, deja que estas historias te ayuden a estar preparado para posibles sorpresas.</i>  <i>Por cierto, en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este sitio</a> se publica una selecci칩n amplia y actualizada de enlaces a tales "historias de fallas" (seg칰n los datos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este repositorio de Git</a> ).</i> <a name="habracut"></a><br><br><h2>  No 1.  C칩mo el p치nico del n칰cleo bloque칩 un sitio </h2><br>  <i>Original: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">luz de luna</a> .</i> <br><br>  Entre el 18 y el 22 de enero, el sitio web de Moonlight y API experimentaron fallas intermitentes.  Todo comenz칩 con errores aleatorios de la API y termin칩 con un apagado completo.  Los problemas se resolvieron y la aplicaci칩n volvi칩 a la normalidad. <br><br><h3>  Informaci칩n general </h3><br>  Moonlight utiliza un software conocido como Kubernetes.  Kubernetes ejecuta aplicaciones en grupos de servidores.  Estos servidores se llaman nodos.  Las copias de la aplicaci칩n que se ejecutan en el nodo se denominan pods.  Kubernetes tiene un planificador que determina din치micamente qu칠 pods en qu칠 nodos deber칤an funcionar. <br><br><h3>  Cronograma </h3><br>  Los primeros errores del viernes estuvieron relacionados con problemas para conectarse a la base de datos Redis.  Moonlight API usa Redis para verificar las sesiones para cada solicitud autenticada.  Nuestra herramienta de monitoreo Kubernetes ha notificado que algunos nodos y pods no responden.  Al mismo tiempo, Google Cloud inform칩 un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">mal funcionamiento de los servicios de red</a> y decidimos que eran la causa de nuestros problemas. <br><br>  A medida que disminu칤a el tr치fico el fin de semana, los errores parec칤an resolverse en su mayor parte.  Sin embargo, el martes por la ma침ana, el sitio de Moonlight cay칩 y el tr치fico externo no lleg칩 al cl칰ster.  Encontramos a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">otra persona en Twitter</a> con s칤ntomas similares y decidimos que el alojamiento de Google ten칤a una falla en la red.  Nos contactamos con el servicio de asistencia de Google Cloud, que r치pidamente remiti칩 el problema al equipo de asistencia t칠cnica. <br><br>  El equipo de soporte t칠cnico de Google revel칩 algunos patrones en el comportamiento de los nodos en nuestro cl칰ster de Kubernetes.  La utilizaci칩n de CPU de los nodos individuales alcanz칩 el 100%, despu칠s de lo cual se produjo el p치nico del kernel en la m치quina virtual y se bloque칩. <br><br><h3>  Razones </h3><br>  El ciclo que caus칩 la falla fue el siguiente: <br><br><ul><li>  El planificador de Kubernetes aloj칩 varios pods con alto consumo de CPU en el mismo nodo. </li><li>  Los pods se comieron todos los recursos de la CPU en el nodo. </li><li>  Luego vino el p치nico del kernel, que condujo a un per칤odo de inactividad durante el cual el nodo no respondi칩 al planificador. </li><li>  El programador movi칩 todas las c치psulas ca칤das a un nuevo nodo, y el proceso se repiti칩, exacerbando la situaci칩n general. </li></ul><br>  Inicialmente, el error ocurri칩 en el pod de Redis, pero al final todos los pod que trabajan con tr치fico cayeron, lo que condujo a un apagado completo.  Los retrasos exponenciales durante la reprogramaci칩n han llevado a per칤odos m치s largos de inactividad. <br><br><h3>  Soluci칩n </h3><br>  Pudimos restaurar el sitio agregando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">reglas anti-afinidad</a> a todas las implementaciones principales.  Distribuyen autom치ticamente los pods sobre los nodos, aumentando la tolerancia a fallas y el rendimiento. <br><br>  Kubernetes est치 dise침ado como un sistema host tolerante a fallas.  Moonlight utiliza tres nodos en diferentes servidores para mayor estabilidad, y ejecutamos tres copias de cada aplicaci칩n que sirve el tr치fico.  La idea es tener una copia en cada nodo.  En este caso, incluso una falla de dos nodos no conducir치 al tiempo de inactividad.  Sin embargo, Kubernetes a veces coloc칩 las tres c치psulas con el sitio en el mismo nodo, creando as칤 un cuello de botella en el sistema.  Al mismo tiempo, otras aplicaciones que demandaban potencia de procesador (es decir, representaci칩n del lado del servidor) estaban en el mismo nodo, y no en uno separado. <br><br>  Se requiere un cl칰ster de Kubernetes correctamente configurado y que funcione correctamente para hacer frente a largos per칤odos de alta carga de CPU y colocar pods de manera que se maximice el uso de los recursos disponibles.  Continuamos trabajando con el soporte de Google Cloud para identificar y abordar la causa ra칤z del kernel panic en los servidores. <br><br><h3>  Conclusi칩n </h3><br>  Las reglas anti-afinidad le permiten hacer que las aplicaciones que funcionan con tr치fico externo sean m치s tolerantes a fallas.  Si tiene un servicio similar en Kubernetes, considere agregarlos. <br><br>  Continuamos trabajando con los chicos de Google para encontrar y eliminar la causa de fallas en el n칰cleo del sistema operativo en los nodos. <br><br><h2>  No 2.  El secreto "sucio" de Kubernetes y el punto final de Ingress </h2><br>  <i>Original: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Phil Pearl de Ravelin</a> .</i> <br><br><h3>  La elegancia est치 sobrevalorada </h3><br>  Nosotros en Ravelin migramos a Kubernetes (en GKE).  El proceso ha sido muy exitoso.  Nuestros presupuestos de interrupci칩n de pods est치n tan completos como siempre, los estados son verdaderamente majestuosos <i>(un juego de palabras dif칤cil de traducir: "nuestros conjuntos con estado son muy majestuosos" - aprox. Transl.)</i> , Y el reemplazo deslizante de los nodos funciona como un reloj. <br><br>  La pieza final del rompecabezas es mover la capa API de m치quinas virtuales antiguas al cl칰ster de Kubernetes.  Para hacer esto, necesitamos configurar Ingress para que la API sea accesible desde el mundo exterior. <br><br>  Al principio, la tarea parec칤a simple.  Simplemente definimos el controlador Ingress, modificamos el Terraform para obtener un cierto n칰mero de direcciones IP, y Google se encarga de casi todo lo dem치s.  Y todo esto funcionar치 como por arte de magia.  Clase! <br><br>  Sin embargo, con el tiempo, comenzaron a notar que las pruebas de integraci칩n reciben peri칩dicamente errores 502. A partir de esto, nuestro viaje comenz칩.  Sin embargo, le ahorrar칠 tiempo e ir칠 directamente a las conclusiones. <br><br><h3>  Cierre elegante </h3><br>  Todo el mundo habla de un cierre elegante ("elegante", cierre gradual).  Pero realmente no debes confiar en 칠l en Kubernetes.  O al menos no deber칤a ser el cierre elegante que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://golang.org/pkg/net/">absorbi칩 con la leche de su madre</a> .  En el mundo de Kubernetes, este nivel de "elegancia" es innecesario y amenaza con serios problemas. <br><br><h3>  Mundo perfecto </h3><br>  As칤 es como, en la vista mayoritaria, el pod se elimina del servicio o del equilibrador de carga en Kubernetes: <br><br><ol><li>  El controlador de replicaci칩n decide eliminar el pod. </li><li>  El pod de punto final se elimina del servicio o equilibrador de carga.  Ya no llega nuevo tr치fico al pod. </li><li>  Se llama a un gancho previo a la parada, o el pod recibe una se침al SIGTERM. </li><li>  El pod "con gracia" est치 desconectado.  Deja de aceptar conexiones entrantes. </li><li>  La desconexi칩n "agraciada" se completa y el pod se destruye despu칠s de que todas sus conexiones existentes se detienen o finalizan. </li></ol><br>  Desafortunadamente, la realidad es completamente diferente. <br><br><h3>  Mundo real </h3><br>  La mayor parte de la documentaci칩n sugiere que todo sucede de manera un poco diferente, pero no escriben expl칤citamente sobre esto en ning칰n lado.  El principal problema es que el paso 3 no sigue al paso 2. Se producen simult치neamente.  En los servicios ordinarios, la eliminaci칩n de puntos finales es tan r치pida que la probabilidad de encontrar problemas es extremadamente baja.  Sin embargo, con Ingresss, todo es diferente: generalmente responden mucho m치s lentamente, por lo que el problema se vuelve obvio.  Pod puede obtener SIGTERM mucho antes de que los cambios en los puntos finales entren en Ingress. <br><br>  Como resultado, un apagado correcto no es lo que se requiere de un pod.  Recibir치 nuevas conexiones y debe continuar proces치ndolas, de lo contrario, los clientes comenzar치n a recibir los errores n칰mero 500 y toda la maravillosa historia sobre implementaciones y escalas sin complicaciones comenzar치 a desmoronarse. <br><br>  Esto es lo que realmente sucede: <br><br><ol><li>  El controlador de replicaci칩n decide eliminar el pod. </li><li>  El pod de punto final se elimina del servicio o equilibrador de carga.  En el caso de Ingresss, esto puede llevar alg칰n tiempo, y el nuevo tr치fico continuar치 fluyendo hacia el pod. </li><li>  Se llama a un gancho previo a la parada, o el pod recibe una se침al SIGTERM. </li><li>  En gran medida, el pod debe ignorar esto, continuar trabajando y mantener nuevas conexiones.  Si es posible, deber칤a indicarles a los clientes que ser칤a bueno cambiarse a otro lugar.  Por ejemplo, en el caso de HTTP, puede enviar <code>Connection: close</code> en los encabezados de respuesta. </li><li>  La c치psula sale solo cuando el per칤odo de espera "elegante" expira y SIGKILL la mata. </li><li>  Aseg칰rese de que este per칤odo sea m치s largo que el tiempo que lleva reprogramar el equilibrador de carga. </li></ol><br>  Si se trata de un c칩digo de terceros y no puede cambiar su comportamiento, entonces lo mejor que puede hacer es agregar un gancho previo a la detenci칩n que solo duerma durante un per칤odo "elegante", de modo que el pod contin칰e funcionando como si nada sucedi칩 <br><br><h2>  N칰mero 3.  C칩mo un webhook simple caus칩 una falla del cl칰ster </h2><br>  <i>Original: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Jetstack</a> .</i> <br><br>  Jetstack ofrece a sus clientes plataformas multiempresa en Kubernetes.  A veces hay requisitos especiales que no podemos satisfacer con la configuraci칩n est치ndar de Kubernetes.  Para implementarlos, recientemente comenzamos a usar el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Open Policy Agent</a> <i>(escribimos sobre el proyecto con m치s detalle en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">esta revisi칩n</a> , aprox. Transl.)</i> Como controlador de acceso para implementar pol칤ticas especiales. <br><br>  Este art칤culo describe el error causado por esta integraci칩n mal configurada. <br><br><h3>  Incidente </h3><br>  Nos dedicamos a actualizar el asistente para el cl칰ster de desarrollo, en el que varios equipos probaron sus aplicaciones durante la jornada laboral.  Era un cl칰ster regional en la zona europa-oeste1 en Google Kubernetes Engine (GKE). <br><br>  Se advirti칩 a los comandos que se estaba realizando una actualizaci칩n, sin tiempo de inactividad esperado.  Ese mismo d칤a, ya hicimos una actualizaci칩n similar a otro entorno de preproducci칩n. <br><br>  Comenzamos la actualizaci칩n usando nuestra tuber칤a GKE Terraform.  La actualizaci칩n del asistente no se complet칩 hasta que expir칩 el tiempo de espera de Terraform, que configuramos durante 20 minutos.  Esta fue la primera llamada de atenci칩n de que algo sali칩 mal, aunque en la consola GKE el cl칰ster todav칤a figuraba como "actualizaci칩n". <br><br>  Reiniciar la tuber칤a condujo al siguiente error <br><br><pre> <code class="bash hljs">google_container_cluster.cluster: Error waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> updating GKE master version: All cluster resources were brought up, but the cluster API is reporting that: component <span class="hljs-string"><span class="hljs-string">"kube-apiserver"</span></span> from endpoint <span class="hljs-string"><span class="hljs-string">"gke-..."</span></span> is unhealthy</code> </pre> <br>  Esta vez, la conexi칩n con el servidor API comenz칩 a interrumpirse peri칩dicamente y los equipos no pudieron implementar sus aplicaciones. <br><br>  Mientras est치bamos tratando de entender lo que estaba sucediendo, todos los nodos comenzaron a destruirse y recrearse en un ciclo sin fin.  Esto ha llevado a una denegaci칩n indiscriminada de servicio para todos nuestros clientes. <br><br><h3>  Establecemos la causa ra칤z de la falla </h3><br>  Con el soporte de Google, pudimos determinar la secuencia de eventos que condujeron a la falla: <br><br><ol><li>  GKE complet칩 la actualizaci칩n en una instancia del asistente y comenz칩 a aceptar todo el tr치fico al servidor API en 칠l a medida que se actualizaban los siguientes asistentes. </li><li>  Durante la actualizaci칩n de la segunda instancia del asistente, el servidor API no pudo ejecutar <a href="">PostStartHook</a> para <a href="">registrar la CA.</a> </li><li>  Durante la ejecuci칩n de este enlace, el servidor API intent칩 actualizar ConfigMap llamado <code>extension-apiserver-authentication</code> en <code>kube-system</code> .  No fue posible hacer esto porque el backend para el webhook de comprobaci칩n de Open Policy Agent (OPA) que configuramos no respondi칩. </li><li>  Para que el asistente pase una comprobaci칩n de estado, esta operaci칩n debe completarse correctamente.  Como esto no sucedi칩, el segundo maestro ingres칩 al ciclo de emergencia y detuvo la actualizaci칩n. </li></ol><br>  El resultado fueron bloqueos peri칩dicos de la API, debido a que los kubelets no pudieron informar el estado del nodo.  A su vez, esto condujo al hecho de que el mecanismo para la restauraci칩n autom치tica de los nodos GKE <i>(reparaci칩n</i> autom치tica de nodos <i>)</i> comenz칩 a reiniciar los nodos.  Esta caracter칤stica se describe en detalle en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentaci칩n</a> : <br><br><blockquote>  <i>Un estado no saludable puede significar: Dentro de un tiempo determinado (aproximadamente 10 minutos), el nodo no da ning칰n estado en absoluto.</i> </blockquote><br><h3>  Soluci칩n </h3><br>  Cuando descubrimos que el recurso <code>ValidatingAdmissionWebhook</code> estaba causando un acceso intermitente al servidor API, lo eliminamos y restauramos el cl칰ster para que funcione. <br><br>  Desde entonces, han configurado <code>ValidatingAdmissionWebhook</code> para OPA para monitorear solo aquellos espacios de nombres donde la pol칤tica es aplicable y a los que los equipos de desarrollo tienen acceso.  Tambi칠n limitamos el webhook a <code>Ingress</code> and <code>Service</code> , los 칰nicos con los que funciona nuestra pol칤tica. <br><br>  Desde que implementamos la OPA por primera vez, la documentaci칩n se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ha actualizado</a> para reflejar este cambio. <br><br>  Tambi칠n agregamos una prueba de vida para asegurar que la OPA se reinicie en caso de que no est칠 disponible (e hicimos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">las modificaciones apropiadas</a> a la documentaci칩n). <br><br>  Tambi칠n consideramos deshabilitar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el mecanismo de</a> recuperaci칩n autom치tica para los nodos GKE, pero a칰n as칤 decidimos abandonar esta idea. <br><br><h3>  Resumen </h3><br>  Si habilitamos las alertas de tiempo de respuesta del servidor API, inicialmente podr칤amos notar su aumento global para todas las solicitudes <code>CREATE</code> y <code>UPDATE</code> despu칠s de implementar el webhook para OPA. <br><br>  Esto subraya la importancia de configurar pruebas para todas las cargas de trabajo.  Mirando hacia atr치s, podemos decir que el despliegue de OPA fue tan enga침osamente simple que ni siquiera nos involucramos en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tabla de Helm</a> (aunque deber칤a).  El cuadro realiza una serie de ajustes m치s all치 de la configuraci칩n b치sica descrita en el manual, incluida la configuraci칩n de livenessProbe para contenedores con un controlador de admisi칩n. <br><br>  No fuimos los primeros en encontrar este problema: el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">problema aguas arriba</a> permanece abierto.  La funcionalidad en este asunto puede mejorarse claramente (y haremos un seguimiento de esto). <br><br><h2>  PD del traductor </h2><br>  Lea tambi칠n en nuestro blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C칩mo las prioridades de los pods en Kubernetes causaron tiempo de inactividad en Grafana Labs</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">De la vida con Kubernetes: c칩mo los espa침oles no se quejaron del servidor HTTP</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">6 errores de sistema entretenidos en el funcionamiento de Kubernetes [y su soluci칩n]</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">6 historias pr치cticas de nuestra vida cotidiana SRE</a> ". </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/475026/">https://habr.com/ru/post/475026/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../475016/index.html">QA mitap en Redmadrobot 22 de noviembre</a></li>
<li><a href="../475018/index.html">Alteraci칩n de columnas Radiotehnika S-30</a></li>
<li><a href="../475020/index.html">C칩mo la tecnolog칤a moderna est치 reemplazando gradualmente a las torres de incendios</a></li>
<li><a href="../475022/index.html">Esquizofrenia arquitect칩nica Facebook Libra</a></li>
<li><a href="../475024/index.html">Correr es un deporte ideal para un trabajador remoto. Parte 1: el camino hacia la primera carrera de cien kil칩metros</a></li>
<li><a href="../475032/index.html">Gartner Hype Cycle 2019: informe</a></li>
<li><a href="../475034/index.html">Gr치fico en el navegador para Arduino y STM32</a></li>
<li><a href="../475036/index.html">Migraci칩n de Cassandra a Kubernetes: caracter칤sticas y soluciones</a></li>
<li><a href="../475038/index.html">El primer conjunto de "Matem치tica Aplicada y Ciencias de la Computaci칩n" en el HSE de San Petersburgo: 쯤ui칠nes son y c칩mo trabajar con ellos?</a></li>
<li><a href="../475044/index.html">Construyendo su propio servidor sin servidor basado en Fn</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏾‍🔧 🔽 🤹🏿 Wir bewerten russische Städte nach Straßenqualität 🆒 🤓 🕺🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Noch einmal, als ich mit dem Auto durch meine Heimatstadt fuhr und eine andere Grube umrundete, dachte ich: Gab es überall in unserem Land so „gute“ S...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wir bewerten russische Städte nach Straßenqualität</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/437542/"><img src="https://habrastorage.org/webt/qg/pm/pf/qgpmpfivqp5xqw2c8-qvxjp4-dq.jpeg"><br><br>  Noch einmal, als ich mit dem Auto durch meine Heimatstadt fuhr und eine andere Grube umrundete, dachte ich: Gab es überall in unserem Land so „gute“ Straßen und ich entschied, dass wir die Situation objektiv anhand der Straßenqualität in unserem Land bewerten sollten. <br><a name="habracut"></a><br><h2>  Aufgabenformalisierung </h2><br>  In Russland sind die Anforderungen an die Straßenqualität in GOST R 50597-2017 „Straßen und Wege.  Anforderungen an den Betriebszustand, die unter den Bedingungen der Gewährleistung der Verkehrssicherheit akzeptabel sind.  Kontrollmethoden. "  In diesem Dokument werden die Anforderungen für die Abdeckung der Fahrbahn, der Straßenränder, der Trennstreifen, der Bürgersteige, der Fußgängerwege usw. definiert und die Arten von Schäden festgelegt. <br><br>  Da die Ermittlung aller Parameter der Straßen sehr umfangreich ist, habe ich mich entschlossen, sie einzugrenzen und mich nur auf das Problem der Ermittlung von Fehlern in der Fahrbahnabdeckung zu konzentrieren.  In GOST R 50597-2017 werden folgende Mängel in der Fahrbahnbeschichtung unterschieden: <br><br><ul><li>  Schlaglöcher </li><li>  bricht </li><li>  Drawdowns </li><li>  verschiebt sich </li><li>  Kämme </li><li>  verfolgen </li><li>  schwitzender Binder </li></ul><br>  Ich habe mich entschlossen, diese Mängel zu beheben. <br><br><h2>  Datenerfassung </h2><br>  Wo kann ich Fotos bekommen, die ausreichend große Abschnitte der Fahrbahn und sogar in Bezug auf die Geolokalisierung darstellen?  Die Antwort kam in Strasssteinen - Panoramen auf den Karten von Yandex (oder Google), aber nach einigem Suchen fand ich mehrere weitere alternative Optionen: <br><br><ul><li>  Ausgabe von Suchmaschinen für Bilder für relevante Anfragen; </li><li>  Fotos auf Websites für den Empfang von Beschwerden (Rosyama, Angry Citizen, Tugend usw.) </li><li>  Opendatascience veranlasste ein Projekt, Straßenfehler mit einem markierten Datensatz zu erkennen - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">github.com/sekilab/RoadDamageDetector</a> </li></ul><br>  Leider hat eine Analyse dieser Optionen ergeben, dass sie für mich nicht sehr geeignet sind: Die Ausgabe von Suchmaschinen ist sehr laut (viele Fotos sind keine Straßen, verschiedene Renderings usw.), Fotos von Websites, auf denen Beschwerden eingehen, enthalten nur Fotos mit großen Verstößen gegen die Asphaltoberfläche Es gibt einige Fotos mit kleinen Verstößen gegen die Abdeckung und ohne Verstöße auf diesen Websites. Der Datensatz aus dem RoadDamageDetector-Projekt wird in Japan gesammelt und enthält keine Beispiele mit großen Verstößen gegen die Abdeckung sowie Straßen ohne Abdeckung. <br><br>  Da alternative Optionen nicht geeignet sind, verwenden wir Yandex-Panoramen (ich habe die Google-Panoramaoption ausgeschlossen, da der Dienst in weniger Städten in Russland angeboten und weniger häufig aktualisiert wird).  Er beschloss, Daten in Städten mit mehr als 100.000 Einwohnern sowie in Bundeszentren zu sammeln.  Ich habe eine Liste mit Städtenamen erstellt - es gab 176, später stellte sich heraus, dass nur 149 von ihnen Panoramen haben.  Ich werde mich nicht mit den Funktionen des Parsens von Kacheln befassen. Ich werde sagen, dass ich am Ende 149 Ordner (einen für jede Stadt) erhalten habe, in denen sich insgesamt 1,7 Millionen Fotos befanden.  Für Novokuznetsk sah der Ordner beispielsweise folgendermaßen aus: <br><br><img src="https://habrastorage.org/webt/aw/fa/73/awfa73gw128fyrvl8au2b_brjb8.png"><br><br>  Durch die Anzahl der heruntergeladenen Fotos wurden die Städte wie folgt verteilt: <br><br><div class="spoiler">  <b class="spoiler_title">Tabelle</b> <div class="spoiler_text"><table><tbody><tr><th>  Stadt <br></th><th>  Anzahl der Fotos, Stk <br></th></tr><tr><td>  Moskau <br><br></td><td>  86048 <br><br></td></tr><tr><td>  Sankt Petersburg <br><br></td><td>  41376 <br><br></td></tr><tr><td>  Saransk <br><br></td><td>  18880 <br><br></td></tr><tr><td>  Podolsk <br><br></td><td>  18560 <br><br></td></tr><tr><td>  Krasnogorsk <br><br></td><td>  18208 <br><br></td></tr><tr><td>  Lyubertsie <br><br></td><td>  17760 <br><br></td></tr><tr><td>  Kaliningrad <br><br></td><td>  16928 <br><br></td></tr><tr><td>  Kolomna <br><br></td><td>  16832 <br><br></td></tr><tr><td>  Mytishchi <br><br></td><td>  16192 <br><br></td></tr><tr><td>  Wladiwostok <br><br></td><td>  16096 <br><br></td></tr><tr><td>  Balashikha <br><br></td><td>  15968 <br><br></td></tr><tr><td>  Petrosawodsk <br><br></td><td>  15968 <br><br></td></tr><tr><td>  Jekaterinburg <br><br></td><td>  15808 <br><br></td></tr><tr><td>  Veliky Novgorod <br><br></td><td>  15744 <br><br></td></tr><tr><td>  Naberezhnye Chelny <br><br></td><td>  15680 <br><br></td></tr><tr><td>  Krasnodar <br><br></td><td>  15520 <br><br></td></tr><tr><td>  Nizhny Novgorod <br><br></td><td>  15488 <br><br></td></tr><tr><td>  Khimki <br><br></td><td>  15296 <br><br></td></tr><tr><td>  Tula <br><br></td><td>  15296 <br><br></td></tr><tr><td>  Nowosibirsk <br><br></td><td>  15264 <br><br></td></tr><tr><td>  Tver <br><br></td><td>  15200 <br><br></td></tr><tr><td>  Miass <br><br></td><td>  15104 <br><br></td></tr><tr><td>  Ivanovo <br><br></td><td>  15072 <br><br></td></tr><tr><td>  Vologda <br><br></td><td>  15008 <br><br></td></tr><tr><td>  Schukowski <br><br></td><td>  14976 <br><br></td></tr><tr><td>  Kostroma <br><br></td><td>  14912 <br><br></td></tr><tr><td>  Samara <br><br></td><td>  14880 <br><br></td></tr><tr><td>  Korolev <br><br></td><td>  14784 <br><br></td></tr><tr><td>  Kaluga <br><br></td><td>  14720 <br><br></td></tr><tr><td>  Cherepovets <br><br></td><td>  14720 <br><br></td></tr><tr><td>  Sewastopol <br><br></td><td>  14688 <br><br></td></tr><tr><td>  Pushkino <br><br></td><td>  14528 <br><br></td></tr><tr><td>  Jaroslawl <br><br></td><td>  14464 <br><br></td></tr><tr><td>  Uljanowsk <br><br></td><td>  14400 <br><br></td></tr><tr><td>  Rostow am Don <br><br></td><td>  14368 <br><br></td></tr><tr><td>  Domodedovo <br><br></td><td>  14304 <br><br></td></tr><tr><td>  Kamensk-Uralsky <br><br></td><td>  14208 <br><br></td></tr><tr><td>  Pskov <br><br></td><td>  14144 <br><br></td></tr><tr><td>  Yoshkar-Ola <br><br></td><td>  14080 <br><br></td></tr><tr><td>  Kertsch <br><br></td><td>  14080 <br><br></td></tr><tr><td>  Murmansk <br><br></td><td>  13920 <br><br></td></tr><tr><td>  Togliatti <br><br></td><td>  13920 <br><br></td></tr><tr><td>  Wladimir <br><br></td><td>  13792 <br><br></td></tr><tr><td>  Adler <br><br></td><td>  13792 <br><br></td></tr><tr><td>  Syktyvkar <br><br></td><td>  13728 <br><br></td></tr><tr><td>  Dolgoprudny <br><br></td><td>  13696 <br><br></td></tr><tr><td>  Khanty-Mansiysk <br><br></td><td>  13664 <br><br></td></tr><tr><td>  Kasan <br><br></td><td>  13600 <br><br></td></tr><tr><td>  Engels <br><br></td><td>  13440 <br><br></td></tr><tr><td>  Archangelsk <br><br></td><td>  13280 <br><br></td></tr><tr><td>  Brjansk <br><br></td><td>  13216 <br><br></td></tr><tr><td>  Omsk <br><br></td><td>  13120 <br><br></td></tr><tr><td>  Syzran <br><br></td><td>  13088 <br><br></td></tr><tr><td>  Krasnojarsk <br><br></td><td>  13056 <br><br></td></tr><tr><td>  Shchelkovo <br><br></td><td>  12928 <br><br></td></tr><tr><td>  Penza <br><br></td><td>  12864 <br><br></td></tr><tr><td>  Tscheljabinsk <br><br></td><td>  12768 <br><br></td></tr><tr><td>  Cheboksary <br><br></td><td>  12768 <br><br></td></tr><tr><td>  Nischni Tagil <br><br></td><td>  12672 <br><br></td></tr><tr><td>  Stavropol <br><br></td><td>  12672 <br><br></td></tr><tr><td>  Ramenskoye <br><br></td><td>  12640 <br><br></td></tr><tr><td>  Irkutsk <br><br></td><td>  12608 <br><br></td></tr><tr><td>  Angarsk <br><br></td><td>  12608 <br><br></td></tr><tr><td>  Tjumen <br><br></td><td>  12512 <br><br></td></tr><tr><td>  Odintsovo <br><br></td><td>  12512 <br><br></td></tr><tr><td>  Ufa <br><br></td><td>  12512 <br><br></td></tr><tr><td>  Magadan <br><br></td><td>  12512 <br><br></td></tr><tr><td>  Perm <br><br></td><td>  12448 <br><br></td></tr><tr><td>  Kirov <br><br></td><td>  12256 <br><br></td></tr><tr><td>  Nischnekamsk <br><br></td><td>  12224 <br><br></td></tr><tr><td>  Makhachkala <br><br></td><td>  12096 <br><br></td></tr><tr><td>  Nischnewartowsk <br><br></td><td>  11936 <br><br></td></tr><tr><td>  Kursk <br><br></td><td>  11904 <br><br></td></tr><tr><td>  Sotschi <br><br></td><td>  11872 <br><br></td></tr><tr><td>  Tambow <br><br></td><td>  11840 <br><br></td></tr><tr><td>  Pjatigorsk <br><br></td><td>  11808 <br><br></td></tr><tr><td>  Wolgodonsk <br><br></td><td>  11712 <br><br></td></tr><tr><td>  Rjasan <br><br></td><td>  11680 <br><br></td></tr><tr><td>  Saratow <br><br></td><td>  11616 <br><br></td></tr><tr><td>  Dzerzhinsk <br><br></td><td>  11456 <br><br></td></tr><tr><td>  Orenburg <br><br></td><td>  11456 <br><br></td></tr><tr><td>  Hügel <br><br></td><td>  11424 <br><br></td></tr><tr><td>  Wolgograd <br><br></td><td>  11264 <br><br></td></tr><tr><td>  Ischewsk <br><br></td><td>  11168 <br><br></td></tr><tr><td>  Chrysostomus <br><br></td><td>  11136 <br><br></td></tr><tr><td>  Lipetsk <br><br></td><td>  11072 <br><br></td></tr><tr><td>  Kislowodsk <br><br></td><td>  11072 <br><br></td></tr><tr><td>  Surgut <br><br></td><td>  11040 <br><br></td></tr><tr><td>  Magnitogorsk <br><br></td><td>  10912 <br><br></td></tr><tr><td>  Smolensk <br><br></td><td>  10784 <br><br></td></tr><tr><td>  Chabarowsk <br><br></td><td>  10752 <br><br></td></tr><tr><td>  Kopeysk <br><br></td><td>  10688 <br><br></td></tr><tr><td>  Maykop <br><br></td><td>  10656 <br><br></td></tr><tr><td>  Petropawlowsk-Kamtschatski <br><br></td><td>  10624 <br><br></td></tr><tr><td>  Taganrog <br><br></td><td>  10560 <br><br></td></tr><tr><td>  Barnaul <br><br></td><td>  10528 <br><br></td></tr><tr><td>  Sergiev Posad <br><br></td><td>  10368 <br><br></td></tr><tr><td>  Elista <br><br></td><td>  10304 <br><br></td></tr><tr><td>  Sterlitamak <br><br></td><td>  9920 <br><br></td></tr><tr><td>  Simferopol <br><br></td><td>  9824 <br><br></td></tr><tr><td>  Tomsk <br><br></td><td>  9760 <br><br></td></tr><tr><td>  Orekhovo-Zuevo <br><br></td><td>  9728 <br><br></td></tr><tr><td>  Astrachan <br><br></td><td>  9664 <br><br></td></tr><tr><td>  Evpatoria <br><br></td><td>  9568 <br><br></td></tr><tr><td>  Noginsk <br><br></td><td>  9344 <br><br></td></tr><tr><td>  Chita <br><br></td><td>  9216 <br><br></td></tr><tr><td>  Belgorod <br><br></td><td>  9120 <br><br></td></tr><tr><td>  Biysk <br><br></td><td>  8928 <br><br></td></tr><tr><td>  Rybinsk <br><br></td><td>  8896 <br><br></td></tr><tr><td>  Sewerodwinsk <br><br></td><td>  8832 <br><br></td></tr><tr><td>  Woronesch <br><br></td><td>  8768 <br><br></td></tr><tr><td>  Blagoveshchensk <br><br></td><td>  8672 <br><br></td></tr><tr><td>  Novorossiysk <br><br></td><td>  8608 <br><br></td></tr><tr><td>  Ulan-Ude <br><br></td><td>  8576 <br><br></td></tr><tr><td>  Serpukhov <br><br></td><td>  8320 <br><br></td></tr><tr><td>  Komsomolsk-on-Amur <br><br></td><td>  8192 <br><br></td></tr><tr><td>  Abakan <br><br></td><td>  8128 <br><br></td></tr><tr><td>  Norilsk <br><br></td><td>  8096 <br><br></td></tr><tr><td>  Juschno-Sachalininsk <br><br></td><td>  8032 <br><br></td></tr><tr><td>  Obninsk <br><br></td><td>  7904 <br><br></td></tr><tr><td>  Essentuki <br><br></td><td>  7712 <br><br></td></tr><tr><td>  Bataysk <br><br></td><td>  7648 <br><br></td></tr><tr><td>  Wolzhsky <br><br></td><td>  7584 <br><br></td></tr><tr><td>  Novocherkassk <br><br></td><td>  7488 <br><br></td></tr><tr><td>  Berdsk <br><br></td><td>  7456 <br><br></td></tr><tr><td>  Arzamas <br><br></td><td>  7424 <br><br></td></tr><tr><td>  Pervouralsk <br><br></td><td>  7392 <br><br></td></tr><tr><td>  Kemerowo <br><br></td><td>  7104 <br><br></td></tr><tr><td>  Elektrostal <br><br></td><td>  6720 <br><br></td></tr><tr><td>  Derbent <br><br></td><td>  6592 <br><br></td></tr><tr><td>  Jakutsk <br><br></td><td>  6528 <br><br></td></tr><tr><td>  Murom <br><br></td><td>  6240 <br><br></td></tr><tr><td>  Nefteyugansk <br><br></td><td>  5792 <br><br></td></tr><tr><td>  Reutov <br><br></td><td>  5696 <br><br></td></tr><tr><td>  Birobidschan <br><br></td><td>  5440 <br><br></td></tr><tr><td>  Novokuybyshevsk <br><br></td><td>  5248 <br><br></td></tr><tr><td>  Salekhard <br><br></td><td>  5184 <br><br></td></tr><tr><td>  Nowokusnezk <br><br></td><td>  5152 <br><br></td></tr><tr><td>  Novy Urengoy <br><br></td><td>  4736 <br><br></td></tr><tr><td>  Noyabrsk <br><br></td><td>  4416 <br><br></td></tr><tr><td>  Novocheboksarsk <br><br></td><td>  4352 <br><br></td></tr><tr><td>  Yelets <br><br></td><td>  3968 <br><br></td></tr><tr><td>  Kaspiysk <br><br></td><td>  3936 <br><br></td></tr><tr><td>  Stary Oskol <br><br></td><td>  3840 <br><br></td></tr><tr><td>  Artyom <br><br></td><td>  3744 <br><br></td></tr><tr><td>  Zheleznogorsk <br><br></td><td>  3584 <br><br></td></tr><tr><td>  Salavat <br><br></td><td>  3584 <br><br></td></tr><tr><td>  Prokopyevsk <br><br></td><td>  2816 <br><br></td></tr><tr><td>  Gorno-Altaysk <br><br></td><td>  2464 <br><br></td></tr></tbody></table><br></div></div><br><h2>  Vorbereiten eines Datensatzes für das Training </h2><br>  Und so wird der Datensatz zusammengestellt. Wie können Sie nun anhand eines Fotos des Straßenabschnitts und der umgebenden Objekte die Qualität des darauf abgebildeten Asphalts herausfinden?  Ich beschloss, ein Stück des Fotos mit einer Größe von 350 * 244 Pixel in der Mitte des Originalfotos direkt unterhalb der Mitte auszuschneiden.  Reduzieren Sie dann das geschnittene Stück horizontal auf eine Größe von 244 Pixel.  Das resultierende Bild (244 * 244 groß) ist die Eingabe für den Faltungscodierer: <br><br><img src="https://habrastorage.org/webt/ya/tt/s8/yatts8qbzq9ddnxql_cydrmfeug.png"><br><br>  Um besser zu verstehen, mit welchen Daten ich zu tun habe, wurden die ersten 2000 Bilder, die ich selbst markiert habe, und die restlichen Bilder von Yandex.Tolki-Mitarbeitern markiert.  Vor ihnen habe ich im folgenden Wortlaut eine Frage gestellt. <br><br>  Geben Sie an, welche Straßenoberfläche Sie auf dem Foto sehen: <br><br><ol><li>  Boden / Schutt </li><li>  Pflastersteine, Fliesen, Pflaster </li><li>  Schienen, Eisenbahnschienen </li><li>  Wasser, große Pfützen </li><li>  Asphalt </li><li>  Es gibt keine Straße auf dem Foto / Fremdkörper / Die Abdeckung ist aufgrund von Autos nicht sichtbar </li></ol><br>  Wenn der Darsteller „Asphalt“ wählte, erschien ein Menü, in dem die Qualität bewertet werden konnte: <br><br><ol><li>  Hervorragende Abdeckung </li><li>  Leichte Einzelrisse / flache Schlaglöcher </li><li>  Große Risse / Gitterrisse / einzelne kleine Schlaglöcher </li><li>  Große Schlaglöcher / tiefe Schlaglöcher / zerstörte Beschichtung </li></ol><br>  Wie Testläufe der Aufgaben zeigten, unterscheiden sich die Darsteller von Y. Toloki nicht in der Integrität der Arbeit - sie klicken versehentlich mit der Maus auf die Felder und betrachten die Aufgabe als erledigt.  Ich musste Kontrollfragen hinzufügen (in der Aufgabe gab es 46 Fotos, von denen 12 Kontrollfragen waren) und eine verzögerte Annahme ermöglichen.  Als Kontrollfragen habe ich die Bilder verwendet, die ich selbst markiert habe.  Ich habe die verzögerte Annahme automatisiert. Mit Y. Toloka können Sie die Arbeitsergebnisse in eine CSV-Datei hochladen und die Ergebnisse der Überprüfung der Antworten laden.  Die Überprüfung der Antworten funktionierte wie folgt: Wenn die Aufgabe mehr als 5% falsche Antworten auf Kontrollfragen enthält, gilt sie als unerfüllt.  Wenn der Auftragnehmer eine Antwort angibt, die logisch nahe an der Wahrheit liegt, wird seine Antwort als richtig angesehen. <br>  Als Ergebnis erhielt ich ungefähr 30.000 getaggte Fotos, die ich für das Training in drei Klassen verteilte: <br><br><ul><li>  "Gut" - Fotos mit den Bezeichnungen "Asphalt: Ausgezeichnete Beschichtung" und "Asphalt: Kleinere Einzelrisse" </li><li>  "Mitte" - Fotos mit den Bezeichnungen "Pflastersteine, Fliesen, Pflaster", "Schienen, Eisenbahnschienen" und "Asphalt: Große Risse / Gitterrisse / einzelne kleine Schlaglöcher" </li><li>  "Groß" - Fotos mit den Bezeichnungen "Boden / Schotter", "Wasser, große Pfützen" und "Asphalt: Eine große Anzahl von Schlaglöchern / tiefen Schlaglöchern / zerstörten Gehwegen" </li><li>  Fotos mit dem Tag „Es gibt keine Straße auf dem Foto / Fremdkörper / Abdeckung ist aufgrund von Autos nicht sichtbar“ gab es nur sehr wenige (22 Stück). Und ich habe sie von weiteren Arbeiten ausgeschlossen </li></ul><br><h2>  Entwicklung und Schulung von Klassifikatoren </h2><br>  Also, die Daten werden gesammelt und beschriftet, fahren wir mit der Entwicklung des Klassifikators fort.  Normalerweise wird für die Aufgaben der Bildklassifizierung, insbesondere beim Training mit kleinen Datensätzen, ein vorgefertigter Faltungscodierer verwendet, an dessen Ausgabe ein neuer Klassifizierer angeschlossen wird.  Ich entschied mich für einen einfachen Klassifikator ohne versteckte Ebene, eine Eingabeebene der Größe 128 und eine Ausgabeebene der Größe 3. Ich entschied mich, sofort mehrere vorgefertigte Optionen zu verwenden, die in ImageNet als Encoder trainiert wurden: <br><br><ul><li>  Xception </li><li>  Resnet </li><li>  Inception </li><li>  Vgg16 </li><li>  Densenet121 </li><li>  Mobilenet </li></ul><br>  Hier ist die Funktion, die das Keras-Modell mit dem angegebenen Encoder erstellt: <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(typeModel)</span></span></span><span class="hljs-function">:</span></span> conv_base = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"nasnet"</span></span>): conv_base = keras.applications.nasnet.NASNetMobile(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"xception"</span></span>): conv_base = keras.applications.xception.Xception(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"resnet"</span></span>): conv_base = keras.applications.resnet50.ResNet50(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"inception"</span></span>): conv_base = keras.applications.inception_v3.InceptionV3(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"densenet121"</span></span>): conv_base = keras.applications.densenet.DenseNet121(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"mobilenet"</span></span>): conv_base = keras.applications.mobilenet_v2.MobileNetV2(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"vgg16"</span></span>): conv_base = keras.applications.vgg16.VGG16(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) conv_base.trainable = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> model = Sequential() model.add(conv_base) model.add(Flatten()) model.add(Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, kernel_regularizer=regularizers.l2(<span class="hljs-number"><span class="hljs-number">0.0002</span></span>))) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)) model.compile(optimizer=keras.optimizers.Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br>  Für das Training habe ich einen Generator mit Augmentation verwendet (da mir die Möglichkeiten der in Keras integrierten Augmentation unzureichend erschienen, habe ich die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Augmentor-</a> Bibliothek verwendet): <br><br><ul><li>  Pisten </li><li>  Zufällige Verzerrung </li><li>  Dreht sich </li><li>  Farbtausch </li><li>  Schichten </li><li>  Ändern Sie Kontrast und Helligkeit </li><li>  Zufälliges Rauschen hinzufügen </li><li>  Ernte </li></ul><br>  Nach der Vergrößerung sahen die Fotos folgendermaßen aus: <br><br><img src="https://habrastorage.org/webt/yc/qy/uh/ycqyuh1no4h57-or062y3epc4yy.png"><br><br>  Generatorcode: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_datagen</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> train_dir=<span class="hljs-string"><span class="hljs-string">'~/data/train_img'</span></span> test_dir=<span class="hljs-string"><span class="hljs-string">'~/data/test_img'</span></span> testDataGen = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span> / <span class="hljs-number"><span class="hljs-number">255</span></span>) train_generator = datagen.flow_from_directory( train_dir, target_size=img_size, batch_size=<span class="hljs-number"><span class="hljs-number">16</span></span>, class_mode=<span class="hljs-string"><span class="hljs-string">'categorical'</span></span>) p = Augmentor.Pipeline(train_dir) p.skew(probability=<span class="hljs-number"><span class="hljs-number">0.9</span></span>) p.random_distortion(probability=<span class="hljs-number"><span class="hljs-number">0.9</span></span>,grid_width=<span class="hljs-number"><span class="hljs-number">3</span></span>,grid_height=<span class="hljs-number"><span class="hljs-number">3</span></span>,magnitude=<span class="hljs-number"><span class="hljs-number">8</span></span>) p.rotate(probability=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, max_left_rotation=<span class="hljs-number"><span class="hljs-number">5</span></span>, max_right_rotation=<span class="hljs-number"><span class="hljs-number">5</span></span>) p.random_color(probability=<span class="hljs-number"><span class="hljs-number">0.7</span></span>, min_factor=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, max_factor=<span class="hljs-number"><span class="hljs-number">1</span></span>) p.flip_left_right(probability=<span class="hljs-number"><span class="hljs-number">0.7</span></span>) p.random_brightness(probability=<span class="hljs-number"><span class="hljs-number">0.7</span></span>, min_factor=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, max_factor=<span class="hljs-number"><span class="hljs-number">1.2</span></span>) p.random_contrast(probability=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, min_factor=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, max_factor=<span class="hljs-number"><span class="hljs-number">1</span></span>) p.random_erasing(probability=<span class="hljs-number"><span class="hljs-number">1</span></span>,rectangle_area=<span class="hljs-number"><span class="hljs-number">0.2</span></span>) p.crop_by_size(probability=<span class="hljs-number"><span class="hljs-number">1</span></span>, width=<span class="hljs-number"><span class="hljs-number">244</span></span>, height=<span class="hljs-number"><span class="hljs-number">244</span></span>, centre=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) train_generator = keras_generator(p,batch_size=<span class="hljs-number"><span class="hljs-number">16</span></span>) test_generator = testDataGen.flow_from_directory( test_dir, target_size=img_size, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, class_mode=<span class="hljs-string"><span class="hljs-string">'categorical'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (train_generator, test_generator)</code> </pre> <br>  Der Code zeigt, dass die Erweiterung nicht für Testdaten verwendet wird. <br><br>  Wenn Sie einen abgestimmten Generator haben, können Sie mit dem Training des Modells beginnen. Wir führen es in zwei Schritten durch: Trainieren Sie zuerst nur unseren Klassifikator, dann das gesamte Modell. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">evalModelstep1</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(typeModel)</span></span></span><span class="hljs-function">:</span></span> K.clear_session() gc.collect() model=createModel(typeModel) traiGen,testGen=getDatagen() model.fit_generator(generator=traiGen, epochs=<span class="hljs-number"><span class="hljs-number">4</span></span>, steps_per_epoch=<span class="hljs-number"><span class="hljs-number">30000</span></span>/<span class="hljs-number"><span class="hljs-number">16</span></span>, validation_steps=len(testGen), validation_data=testGen, ) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">evalModelstep2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model)</span></span></span><span class="hljs-function">:</span></span> early_stopping_callback = EarlyStopping(monitor=<span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, patience=<span class="hljs-number"><span class="hljs-number">3</span></span>) model.layers[<span class="hljs-number"><span class="hljs-number">0</span></span>].trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span> model.trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span> model.compile(optimizer=keras.optimizers.Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-5</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) traiGen,testGen=getDatagen() model.fit_generator(generator=traiGen, epochs=<span class="hljs-number"><span class="hljs-number">25</span></span>, steps_per_epoch=<span class="hljs-number"><span class="hljs-number">30000</span></span>/<span class="hljs-number"><span class="hljs-number">16</span></span>, validation_steps=len(testGen), validation_data=testGen, callbacks=[early_stopping_callback] ) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">full_fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model_names=[ <span class="hljs-string"><span class="hljs-string">"xception"</span></span>, <span class="hljs-string"><span class="hljs-string">"resnet"</span></span>, <span class="hljs-string"><span class="hljs-string">"inception"</span></span>, <span class="hljs-string"><span class="hljs-string">"vgg16"</span></span>, <span class="hljs-string"><span class="hljs-string">"densenet121"</span></span>, <span class="hljs-string"><span class="hljs-string">"mobilenet"</span></span> ] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> model_name <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> model_names: print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(model_name) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) model = evalModelstep1(model_name) model = evalModelstep2(model) model.save(<span class="hljs-string"><span class="hljs-string">"~/data/models/model_new_"</span></span>+str(model_name)+<span class="hljs-string"><span class="hljs-string">".h5"</span></span>)</code> </pre><br>  Rufen Sie full_fit () auf und warten Sie.  Wir warten lange. <br><br>  Als Ergebnis werden wir sechs trainierte Modelle haben. Wir werden die Genauigkeit dieser Modelle anhand eines separaten Teils der gekennzeichneten Daten überprüfen. Ich habe Folgendes erhalten: <br><br><table><tbody><tr><td><p>  Modellname </p><br></td><td><p>  Genauigkeit% </p><br></td></tr><tr><td><p>  Xception </p><br></td><td><p>  87.3 </p><br></td></tr><tr><td><p>  Resnet </p><br></td><td><p>  90,8 </p><br></td></tr><tr><td><p>  Inception </p><br></td><td><p>  90.2 </p><br></td></tr><tr><td><p>  Vgg16 </p><br></td><td><p>  89.2 </p><br></td></tr><tr><td><p>  Densenet121 </p><br></td><td><p>  90.6 </p><br></td></tr><tr><td><p>  Mobilenet </p><br></td><td><p>  86,5 </p><br></td></tr></tbody></table><br>  Im Allgemeinen nicht viel, aber mit einer so kleinen Trainingsstichprobe kann man nicht mehr erwarten.  Um die Genauigkeit leicht zu erhöhen, habe ich die Ausgaben der Modelle durch Mittelwertbildung kombiniert: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_meta_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model_names=[ <span class="hljs-string"><span class="hljs-string">"xception"</span></span>, <span class="hljs-string"><span class="hljs-string">"resnet"</span></span>, <span class="hljs-string"><span class="hljs-string">"inception"</span></span>, <span class="hljs-string"><span class="hljs-string">"vgg16"</span></span>, <span class="hljs-string"><span class="hljs-string">"densenet121"</span></span>, <span class="hljs-string"><span class="hljs-string">"mobilenet"</span></span> ] model_input = Input(shape=(<span class="hljs-number"><span class="hljs-number">244</span></span>,<span class="hljs-number"><span class="hljs-number">244</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) submodels=[] i=<span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> model_name <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> model_names: filename= <span class="hljs-string"><span class="hljs-string">"~/data/models/model_new_"</span></span>+str(model_name)+<span class="hljs-string"><span class="hljs-string">".h5"</span></span> submodel = keras.models.load_model(filename) submodel.name = model_name+<span class="hljs-string"><span class="hljs-string">"_"</span></span>+str(i) i+=<span class="hljs-number"><span class="hljs-number">1</span></span> submodels.append(submodel(model_input)) out=average(submodels) model = Model(inputs = model_input,outputs=out) model.compile(optimizer=keras.optimizers.Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br>  Die resultierende Genauigkeit betrug 91,3%.  Aufgrund dieses Ergebnisses habe ich beschlossen, aufzuhören. <br><br><h2>  Klassifikator verwenden </h2><br>  Endlich ist der Klassifikator fertig und kann in Aktion gesetzt werden!  Ich bereite die Eingabedaten vor und starte den Klassifikator - etwas mehr als einen Tag und 1,7 Millionen Fotos wurden verarbeitet.  Jetzt ist der lustige Teil das Ergebnis.  Bringen Sie sofort die ersten und letzten zehn Städte in die relative Anzahl der Straßen mit guter Abdeckung: <br><br><img src="https://habrastorage.org/webt/mf/vl/xu/mfvlxuvjesvy2leqhplfnik4mm8.png"><br><br><div class="spoiler">  <b class="spoiler_title">Vollständige Tabelle (anklickbares Bild)</b> <div class="spoiler_text"> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/9d8/4fd/38c/9d84fd38c07014be4f68499489ce19bc.png"></a> <br></div></div><br><br>  Und hier ist die Straßenqualitätsbewertung nach Bundesfächern: <br><br><img src="https://habrastorage.org/webt/ih/kq/xq/ihkqxqskkfcfib90gc68ivmxo2i.png"><br><br><div class="spoiler">  <b class="spoiler_title">Voller Tisch</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/md/6j/-m/md6j-mv6jt27zsxgu8wkd2pimmy.png"><br></div></div><br>  Bewertung nach Bundesbezirken: <br><br><img src="https://habrastorage.org/webt/ro/qq/ry/roqqryu12toajz6cgeals3vzuxc.png"><br><br>  Verteilung der Straßenqualität in Russland insgesamt: <br><br><img src="https://habrastorage.org/webt/ow/rt/h1/owrth1ro6yu3svxdpwiyfedzeby.png"><br><br>  Nun, das ist alles, jeder kann selbst Schlussfolgerungen ziehen. <br><br>  Schließlich werde ich die besten Fotos in jeder Kategorie geben (die den Maximalwert in ihrer Klasse erhalten haben): <br><br><div class="spoiler">  <b class="spoiler_title">Bild</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/k9/yf/dl/k9yfdlmiuynquyqhoxjuowvzcsu.jpeg"><br></div></div><br><br>  PS In den Kommentaren wurde zu Recht auf das Fehlen von Statistiken über die Jahre des Eingangs der Fotos hingewiesen.  Ich korrigiere und gebe eine Tabelle: <br><table><tbody><tr><td><p>  Jahr </p><br></td><td><p>  Anzahl der Fotos, Stk </p><br></td></tr><tr><td>  2008 </td><td>  37 </td></tr><tr><td>  2009 </td><td>  13 </td></tr><tr><td>  2010 </td><td>  157030 </td></tr><tr><td>  2011 </td><td>  60724 </td></tr><tr><td>  2012 </td><td>  42387 </td></tr><tr><td>  2013 </td><td>  12148 <br><br></td></tr><tr><td>  2014 </td><td>  141021 <br><br></td></tr><tr><td>  2015 </td><td>  46143 <br><br></td></tr><tr><td>  2016 </td><td>  410385 <br><br></td></tr><tr><td>  2017 </td><td>  324279 <br><br></td></tr><tr><td>  2018 </td><td>  581961 <br><br></td></tr></tbody></table></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de437542/">https://habr.com/ru/post/de437542/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de437532/index.html">Die Robomobilindustrie wird endlich realistischer</a></li>
<li><a href="../de437534/index.html">Wie Retentioneering in der App in the Air implementiert wird</a></li>
<li><a href="../de437536/index.html">Das Beste der Welt von Angular für die Woche - Digest Nr. 1 (18. Januar - 25. Januar)</a></li>
<li><a href="../de437538/index.html">Das neuronale Netzwerk AlphaStar schlug die Profis StarCraft II mit einer Punktzahl von 10-1</a></li>
<li><a href="../de437540/index.html">So verwalten Sie Teamkonflikte</a></li>
<li><a href="../de437544/index.html">Was ist der Unterschied zwischen E-Book-Displays und Smartphones und Tablets?</a></li>
<li><a href="../de437546/index.html">Linux-Computer in einer Windows AD-Domäne mit sssd und krb5</a></li>
<li><a href="../de437548/index.html">Nicht nur uBlock Origin wird unter neuen APIs in Chromium leiden, sondern auch unter anderen Erweiterungen</a></li>
<li><a href="../de437550/index.html">Wochenendlesung: 10 Vinylmaterialien - von der Produktion bis zum Hören und Pflegen zu Hause</a></li>
<li><a href="../de437552/index.html">Ausflug zur Produktion von Promobot. Interview mit CTO</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
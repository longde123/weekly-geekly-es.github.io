<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏻‍🏭 👨🏽‍🔬 👧🏽 Descripción general del método de vector de referencia de algoritmo de aprendizaje automático (SVM) 👍🏿 🌻 ❤️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Prólogo 


 En este artículo, exploraremos varios aspectos de SVM: 



- componente teórico de SVM; 
- cómo funciona el algoritmo en muestras que no s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Descripción general del método de vector de referencia de algoritmo de aprendizaje automático (SVM)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428503/"><h2>  Prólogo </h2><br><img src="https://habrastorage.org/webt/eg/fk/rq/egfkrqshjcqqzkc7ktnnyyx9iuy.jpeg"><br><br>  En este artículo, exploraremos varios aspectos de SVM: <br><br><ul><li>  componente teórico de SVM; </li><li>  cómo funciona el algoritmo en muestras que no se pueden dividir en clases linealmente; </li><li>  Ejemplo de Python e implementación del algoritmo en la biblioteca SciKit Learn. </li></ul><a name="habracut"></a><br>  En los siguientes artículos, trataré de hablar sobre el componente matemático de este algoritmo. <br><br>  Como sabe, las tareas de aprendizaje automático se dividen en dos categorías principales: clasificación y regresión.  Dependiendo de a cuál de estas tareas nos enfrentamos y qué conjunto de datos tenemos para esta tarea, elegimos qué algoritmo usar. <br><br>  El método de máquinas de vectores de soporte o SVM (del inglés Support Vector Machines) es un algoritmo lineal utilizado en problemas de clasificación y regresión.  Este algoritmo se usa ampliamente en la práctica y puede resolver problemas tanto lineales como no lineales.  La esencia de las "máquinas" de los vectores de soporte es simple: el algoritmo crea una línea o hiperplano que divide los datos en clases. <br><br><h4>  Teoría </h4><br>  La tarea principal del algoritmo es encontrar la línea o hiperplano más correcta, dividiendo los datos en dos clases.  SVM es un algoritmo que recibe datos en la entrada y devuelve dicha línea divisoria. <br><br>  Considere el siguiente ejemplo.  Supongamos que tenemos un conjunto de datos y queremos clasificar y separar los cuadrados rojos de los círculos azules (digamos positivo y negativo).  El objetivo principal en esta tarea será encontrar la línea "ideal" que separará estas dos clases. <br><br><img src="https://habrastorage.org/webt/lj/e4/oy/lje4oybbp_pbe_slxkvhm6yqaoy.png"><br><br>  Encuentre la línea perfecta, o hiperplano, que divide el conjunto de datos en clases azul y rojo. <br><br>  A primera vista, no es tan difícil, ¿verdad? <br><br>  Pero, como puede ver, no hay una línea única que resuelva ese problema.  Podemos recoger un número infinito de líneas que pueden separar estas dos clases.  ¿Cómo exactamente SVM encuentra la línea "ideal" y qué es "ideal" en su comprensión? <br><br>  Eche un vistazo al siguiente ejemplo y piense cuál de las dos líneas (amarilla o verde) separa mejor las dos clases y se ajusta a la descripción de "ideal". <br><br><img src="https://habrastorage.org/webt/w4/_f/kz/w4_fkz5krspejxz1o73l1yjnidy.png"><br><br>  ¿Qué línea separa mejor el conjunto de datos en su opinión? <br><br>  Si elige la línea amarilla, lo felicito: esta es la línea que elegiría el algoritmo.  En este ejemplo, podemos entender intuitivamente que la línea amarilla se separa y, en consecuencia, clasifica las dos clases mejor que la verde. <br><br>  En el caso de la línea verde, se encuentra demasiado cerca de la clase roja.  A pesar de que clasificó correctamente todos los objetos del conjunto de datos actual, dicha línea no se generalizará, no se comportará tan bien con un conjunto de datos desconocido.  La tarea de encontrar una separación generalizada de dos clases es una de las tareas principales en el aprendizaje automático. <br><br><h4>  Cómo SVM encuentra la mejor línea </h4><br>  El algoritmo SVM está diseñado de tal manera que busca puntos en el gráfico que se encuentran directamente en la línea de separación más cercana.  Estos puntos se denominan vectores de referencia.  Luego, el algoritmo calcula la distancia entre los vectores de soporte y el plano divisorio.  Esta es la distancia llamada brecha.  El objetivo principal del algoritmo es maximizar la distancia de separación.  Se considera que el mejor hiperplano es un hiperplano para el cual esta brecha es lo más grande posible. <br><br><img src="https://habrastorage.org/webt/ps/iy/he/psiyhexemtrhnqukbvmvaqzafvi.png"><br><br>  Bastante simple, ¿verdad?  Considere el siguiente ejemplo, con un conjunto de datos más complejo que no se puede dividir linealmente. <br><br><img src="https://habrastorage.org/webt/jh/5v/bx/jh5vbxwn7vfzyzeuxibxpleejyk.png"><br><br>  Obviamente, este conjunto de datos no se puede dividir linealmente.  No podemos dibujar una línea recta que clasifique estos datos.  Pero, este conjunto de datos se puede dividir linealmente agregando una dimensión adicional, que llamaremos eje Z. Imagine que las coordenadas en el eje Z están reguladas por la siguiente restricción: <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2">z</span><span class="MJXp-mo" id="MJXp-Span-3" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-4">x</span><span class="MJXp-mrow" id="MJXp-Span-5"><span class="MJXp-mo" id="MJXp-Span-6" style="margin-left: 0em; margin-right: 0em;">²</span></span><span class="MJXp-mo" id="MJXp-Span-7" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-8">y</span><span class="MJXp-mrow" id="MJXp-Span-9"><span class="MJXp-mo" id="MJXp-Span-10" style="margin-left: 0em; margin-right: 0em;">²</span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.717ex" height="2.419ex" viewBox="0 -780.1 4614.2 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMATHI-7A" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMAIN-3D" x="746" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMATHI-78" x="1802" y="0"></use><g transform="translate(2375,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">²</text></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMAIN-2B" x="2856" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMATHI-79" x="3857" y="0"></use><g transform="translate(4354,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">²</text></g></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> z = x² + y² </script></p><br>  Por lo tanto, la ordenada Z se representa desde el cuadrado de la distancia del punto hasta el comienzo del eje. <br>  A continuación se muestra una visualización del mismo conjunto de datos en el eje Z. <br><br><img src="https://habrastorage.org/webt/vd/nj/ce/vdnjce7p5csbhfp12tkaj6t-4-s.png"><br><br>  Ahora los datos se pueden dividir linealmente.  Suponga que la línea magenta que separa los datos z = k, donde k es una constante.  Si <p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-11"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-12">z</span><span class="MJXp-mo" id="MJXp-Span-13" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-14">x</span><span class="MJXp-mrow" id="MJXp-Span-15"><span class="MJXp-mo" id="MJXp-Span-16" style="margin-left: 0em; margin-right: 0em;">²</span></span><span class="MJXp-mo" id="MJXp-Span-17" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-18">y</span><span class="MJXp-mrow" id="MJXp-Span-19"><span class="MJXp-mo" id="MJXp-Span-20" style="margin-left: 0em; margin-right: 0em;">²</span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.717ex" height="2.419ex" viewBox="0 -780.1 4614.2 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMATHI-7A" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMAIN-3D" x="746" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMATHI-78" x="1802" y="0"></use><g transform="translate(2375,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">²</text></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMAIN-2B" x="2856" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMATHI-79" x="3857" y="0"></use><g transform="translate(4354,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">²</text></g></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> z = x² + y² </script></p>  entonces <p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-21"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-22">k</span><span class="MJXp-mo" id="MJXp-Span-23" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24">x</span><span class="MJXp-mrow" id="MJXp-Span-25"><span class="MJXp-mo" id="MJXp-Span-26" style="margin-left: 0em; margin-right: 0em;">²</span></span><span class="MJXp-mo" id="MJXp-Span-27" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-28">y</span><span class="MJXp-mrow" id="MJXp-Span-29"><span class="MJXp-mo" id="MJXp-Span-30" style="margin-left: 0em; margin-right: 0em;">²</span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.84ex" height="2.419ex" viewBox="0 -780.1 4667.2 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMATHI-6B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMAIN-3D" x="799" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMATHI-78" x="1855" y="0"></use><g transform="translate(2428,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">²</text></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMAIN-2B" x="2909" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/428503/&amp;usg=ALkJrhi0bQJQhvmB1vyTUGASjg7x7o5N8A#MJMATHI-79" x="3910" y="0"></use><g transform="translate(4407,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">²</text></g></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-3"> k = x² + y² </script></p>  - fórmula circular.  Por lo tanto, podemos proyectar nuestro divisor lineal, de vuelta al número original de dimensiones de muestra, utilizando esta transformación. <br><br><img src="https://habrastorage.org/webt/we/nu/zn/wenuznqe4e7n4isscmunomrwzfw.png"><br><br>  Como resultado, podemos clasificar un conjunto de datos no lineal al agregarle una dimensión adicional y luego devolverlo a su forma original mediante transformación matemática.  Sin embargo, no con todos los conjuntos de datos, es igual de fácil acelerar tal transformación.  Afortunadamente, la implementación de este algoritmo en la biblioteca sklearn nos resuelve este problema. <br><br><h4>  Hiperplano </h4><br>  Ahora que nos hemos familiarizado con la lógica del algoritmo, pasamos a la definición formal de un hiperplano <br><br>  Un hiperplano es un subplano n-1 dimensional en un espacio euclidiano n-dimensional que divide el espacio en dos partes separadas. <br><br>  Por ejemplo, imagine que nuestra línea se representa como un espacio euclidiano unidimensional (es decir, nuestro conjunto de datos se encuentra en una línea recta).  Seleccione un punto en esta línea.  Este punto dividirá el conjunto de datos, en nuestro caso la línea, en dos partes.  La línea tiene una medida y el punto tiene 0 medidas.  Por lo tanto, un punto es un hiperplano de una línea. <br><br>  Para el conjunto de datos bidimensionales que conocimos anteriormente, la línea divisoria era el mismo hiperplano.  En pocas palabras, para un espacio n-dimensional hay un hiperplano n-1 dimensional que divide este espacio en dos partes. <br><br>  CÓDIGO <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np X = np.array([[<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>], [<span class="hljs-number"><span class="hljs-number">-2</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>], [<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]]) y = np.array([<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>])</code> </pre> <br>  Los puntos se representan como una matriz de X, y las clases a las que pertenecen como una matriz de y. <br>  Ahora entrenaremos a nuestro modelo con esta muestra.  Para este ejemplo, configuro el parámetro lineal del "núcleo" del clasificador (núcleo). <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.svm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SVC clf = SVC(kernel=<span class="hljs-string"><span class="hljs-string">'linear'</span></span>) clf = SVC.fit(X, y)</code> </pre><br>  Predicción de clase de un nuevo objeto. <br><br><pre> <code class="python hljs">prediction = clf.predict([[<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>]])</code> </pre> <br><h4>  Ajuste de parámetros </h4><br>  Los parámetros son los argumentos que pasa al crear el clasificador.  A continuación, proporcioné algunas de las configuraciones SVM personalizadas más importantes: <br><br>  <b>"C"</b> <br><br>  Este parámetro ayuda a ajustar esa línea fina entre la "suavidad" y la precisión de la clasificación de los objetos en la muestra de entrenamiento.  Cuanto mayor sea el valor de "C", más objetos en el conjunto de entrenamiento se clasificarán correctamente. <br><br><img src="https://habrastorage.org/webt/rq/01/6s/rq016soikp4qfockp86li66s5mq.png"><br><br>  En este ejemplo, hay varios umbrales de decisión que podemos definir para esta muestra en particular.  Preste atención al umbral de decisión directa (presentado en el cuadro como una línea verde).  Es bastante simple, y por esta razón, varios objetos se clasificaron incorrectamente.  Estos puntos que se han clasificado incorrectamente se denominan valores atípicos en los datos. <br><br>  También podemos ajustar los parámetros de tal manera que al final obtengamos una línea más curva (umbral de decisión azul claro), que clasificará absolutamente todos los datos de muestra de entrenamiento correctamente.  Por supuesto, en este caso, las posibilidades de que nuestro modelo pueda generalizar y mostrar resultados igualmente buenos en nuevos datos son catastróficamente pequeñas.  Por lo tanto, si está tratando de lograr la precisión al entrenar el modelo, debe apuntar a algo más uniforme, directo.  Cuanto mayor sea el número "C", más enredado estará el hiperplano en su modelo, pero mayor será el número de objetos clasificados correctamente en el conjunto de entrenamiento.  Por lo tanto, es importante "torcer" los parámetros del modelo para un conjunto de datos específico con el fin de evitar el reentrenamiento pero, al mismo tiempo, lograr una alta precisión. <br><br>  <b>Gamma</b> <br><br>  En la documentación oficial, la biblioteca SciKit Learn dice que la gamma determina hasta qué punto cada uno de los elementos del conjunto de datos influye en la determinación de la "línea ideal".  Cuanto más baja sea la gama, más elementos, incluso aquellos que están lo suficientemente lejos de la línea divisoria, participan en el proceso de elegir esta misma línea.  Si la gamma es alta, entonces el algoritmo "dependerá" solo de aquellos elementos que estén más cerca de la línea misma. <br>  Si el nivel gamma se establece demasiado alto, solo los elementos más cercanos a la línea participarán en el proceso de toma de decisiones sobre la ubicación de la línea.  Esto ayudará a ignorar los valores atípicos en los datos.  El algoritmo SVM está diseñado para que los puntos ubicados más cerca uno del otro tengan más peso al tomar una decisión.  Sin embargo, con la configuración correcta de "C" y "gamma", se puede lograr un resultado óptimo que construirá un hiperplano más lineal que ignore los valores atípicos y, por lo tanto, sea más generalizable. <br><br><h4>  Conclusión </h4><br>  Espero sinceramente que este artículo le haya ayudado a comprender la esencia del trabajo de SVM o el Método de vector de referencia.  Espero de usted cualquier comentario y consejo.  En publicaciones posteriores, hablaré sobre el componente matemático de SVM y los problemas de optimización. <br><br>  Fuentes: <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Documentación oficial de SVM en SciKit Learn</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://towardsdatascience.com/">Blog de TowardsDataScience</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Siraj Raval: Máquinas de vectores de soporte</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Introducción a Machine Learning Udacity SVM: video del curso Gamma</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Wikipedia: SVM</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es428503/">https://habr.com/ru/post/es428503/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es428493/index.html">Git subrepo</a></li>
<li><a href="../es428495/index.html">Como hice un simulador de fútbol durante 13 años</a></li>
<li><a href="../es428497/index.html">Atenuador inalámbrico personalizado Noolite SUF-1-300</a></li>
<li><a href="../es428499/index.html">Espeluznantes gigantes azules pueden revelar los secretos de la evolución de las estrellas</a></li>
<li><a href="../es428501/index.html">DartUP: la primera conferencia en ruso sobre Dart y Flutter el 1 de diciembre en San Petersburgo</a></li>
<li><a href="../es428505/index.html">Obtener enlaces a audio sin VKApi</a></li>
<li><a href="../es428507/index.html">Escribimos un chat bot para VKontakte en python usando longpoll</a></li>
<li><a href="../es428509/index.html">Cómo H&M está tratando de salvarse con IA y Big Data</a></li>
<li><a href="../es428511/index.html">Energía de hidrógeno: el comienzo de un largo camino</a></li>
<li><a href="../es428513/index.html">500 punteros láser en un solo lugar</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
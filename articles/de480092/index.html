<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úäüèæ üïó üëØ So l√∂sen Sie das Problem der Audioerkennung auf GO ‚¨ÜÔ∏è üôéüèΩ üé≠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vor kurzem hat BI.ZONE an der HighLoad ++ Konferenz teilgenommen. Es ist klar, dass wir dort angekommen sind, um nicht nur auf die St√§nde anderer Leut...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>So l√∂sen Sie das Problem der Audioerkennung auf GO</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/bizone/blog/480092/">  Vor kurzem hat BI.ZONE an der HighLoad ++ Konferenz teilgenommen.  Es ist klar, dass wir dort angekommen sind, um nicht nur auf die St√§nde anderer Leute zu starren, sondern etwas Interessantes mitgebracht haben.  Mitarbeiter aus verschiedenen Abteilungen des Unternehmens bereiteten Aufgaben f√ºr die Konferenzg√§ste vor, f√ºr deren L√∂sung wir Preise verliehen.  Eine Aufgabe von Golang war die Erkennung von Ger√§uschen.  Wir haben ihre Autorin gebeten, von ihr zu erz√§hlen. <br><br><h2>  Erkl√§rung des Problems </h2><br>  In unserer Aufgabe m√ºssen wir eine bestimmte Anzahl von Titeln indizieren und lernen, wie die urspr√ºngliche Komposition anhand ihres Samples in der Datenbank gesucht wird.  In diesem Fall ist das Sample m√∂glicherweise verrauscht, auf einem schlechten Mikrofon aufgenommen und hat m√∂glicherweise eine andere Frequenz.  Der gr√∂√üte Teil des Codes wurde bereits f√ºr den Teilnehmer geschrieben, er muss lediglich die Fingerabdruckfunktion implementieren, mit der der Fingerabdruck vom Track entfernt wird. <br><a name="habracut"></a><br><h2>  Wie man einen Ton aufnimmt </h2><br>  Es ist klar, dass jede Spur eine mechanische Welle ist, die analoger Natur ist.  Wellen in der Physik haben zwei Eigenschaften: Frequenz und Amplitude.  In Bezug auf Schallwellen k√∂nnen wir der Einfachheit halber annehmen, dass die Amplitude die Lautst√§rke und die Frequenz die Tonh√∂he ist, obwohl hohe T√∂ne f√ºr eine Person mit derselben Amplitude lauter erscheinen. <br><br>  Das hei√üt, aus der Sicht der Physik wird jede Komposition durch eine kontinuierliche Funktion beschrieben, was bedeutet, dass jedes beliebige kleine St√ºck des Songs eine unendliche Menge an Informationen enth√§lt (obwohl es sich bei dieser Art von Post-Punk wahrscheinlich um ein wenig Information in den Tracks handelt weniger).  Aus diesem Grund kann das analoge Signal nicht gespeichert werden, Sie m√ºssen sich mit seiner Digitalisierung befassen.  Der Hauptansatz zur Digitalisierung von Analogsignalen ist die Pulscodemodulation, die in diesem Abschnitt er√∂rtert wird.  PCM besteht aus drei Stufen: Diskretisierung, Quantisierung und Codierung.  Lassen Sie uns kurz analysieren, was auf jedem von ihnen passiert. <br><br><h3>  Diskretisierung </h3><br>  Wir haben also eine Funktion der Amplitude gegen die Zeit.  Wenn jemand eine Frage hat, wo ist die Frequenz, dann ist sie hinter den Kurven des Funktionsgraphen verborgen.  Sie ist noch nicht sichtbar, aber sp√§ter werden wir sie herausziehen.  Da es sich um ein analoges Signal handelt, ist die Funktion kontinuierlich und f√ºr alle m√∂glichen Argumente definiert (jede reelle Zahl von Null bis zum Ende der Spur).  Das hei√üt, wir kennen den Wert der Funktion zu jedem Zeitpunkt und wir haben viele Momente.  Wir brauchen offensichtlich nicht so viel, nehmen Sie einfach eine diskrete Teilmenge.  Dazu speichern wir den Signalwert in einem festen kleinen Intervall.  Es sollte klein genug sein, damit wir den Unterschied nicht mit dem Ohr h√∂ren, aber gro√ü genug, um nicht zu viel zu sparen, da dies auch unerw√ºnscht ist. <br><br>  Tats√§chlich wird beim Digitalisieren nicht das Intervall eingestellt, sondern die Frequenz, die als "Abtastfrequenz" bezeichnet wird.  Abh√§ngig von den Aufgaben kann die Abtastfrequenz bei Telefonen zwischen 8 kHz und bei professionellen Audioger√§ten zwischen mehreren tausend kHz liegen.  Musik f√ºr das normale H√∂ren au√üerhalb von Aufnahmestudios wird normalerweise mit einer Frequenz von 44,1 kHz oder 48 kHz gespeichert. <br><br><h3>  Quantisierung </h3><br>  Dank der Diskretisierung haben wir jetzt eine Reihe von Punkten anstelle eines kontinuierlichen Funktionsgraphen, aber wir k√∂nnen immer noch nicht damit arbeiten, wir m√ºssen den Klang noch mehr verderben.  Die Anfangsfunktion der Amplitude gegen die Zeit verglich die Kontinuumsamplitude mit der Kontinuumszeit.  Im Laufe der Zeit haben wir es herausgefunden, und jetzt m√ºssen wir uns etwas mit der Amplitude einfallen lassen, weil die aktuellen Werte zu chaotisch √ºber die reellen Zahlen verstreut sind, als dass wir sie problemlos speichern k√∂nnten.  Zum Beispiel gibt es unter ihnen sicherlich irrationale, die wir auf keine Weise ohne Rundung speichern k√∂nnen. <br><br>  Quantisierung ist ein Prozess, bei dem Amplituden auf Werte aus einer vorgew√§hlten Menge gerundet werden.  Nat√ºrlich wollen wir, dass die Anzahl der Amplituden eine Zweierpotenz ist.  F√ºr normale Audiospuren wird eine 16-Bit-Quantisierung verwendet, dh die Anzahl der Amplituden betr√§gt 65.536 (2 bis 16 Grad).  Professionelle Tonaufnahmen k√∂nnen mit gr√∂√üerer Genauigkeit durchgef√ºhrt werden, aber nur wenige Menschen k√∂nnen die 16-Bit-Quantisierung von der 24-Bit-Quantisierung unterscheiden.  Also nehmen wir die Potenz von zwei, nehmen ein paar ganzzahlige Amplituden und nennen sie Quantisierungsstufen.  Dann kann man sagen, dass das Signal √ºber 65.536 Pegel quantisiert ist (klingt ma√ügeblich, oder?).  Jede Amplitude wird auf einen der Pegel gerundet, sodass Sie ihren Wert letztendlich in 16 Bit speichern k√∂nnen. Nach Geh√∂r ist eine solche Aufzeichnung nicht von analogem Dauerton zu unterscheiden. <br><br>  Zur Veranschaulichung k√∂nnen Sie das folgende Bild sehen oder Ihre eigenen Bilder in Python erstellen (der Code ist noch niedriger).  Oben rechts in der Abbildung sind f√ºnf Quantisierungsstufen dargestellt.  Das hei√üt, die Spur hat nur f√ºnf Lautst√§rkestufen. <br><br><img src="https://habrastorage.org/webt/9c/44/ma/9c44marhas3olwvom6w5lhjcxx4.png" alt="Bild"><br>  <i>Einige Beispiele</i> <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> m <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">f</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> m.sin(x) q = <span class="hljs-number"><span class="hljs-number">1</span></span>/<span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-comment"><span class="hljs-comment">#      k = 0 #      1/2  1/4 vf = np.vectorize(f) orig_f = vf(np.arange(0, 4 * m.pi, 0.001)) quanted_f = q * np.round(orig_f/q + k) plt.plot(orig_f) plt.plot(quanted_f)</span></span></code> </pre> <br><h3>  Codierung </h3><br>  In der Codierungsphase speichern wir die Ergebnisse der vorherigen Schritte in einer verst√§ndlichen Form.  Alle Aktionen davor werden normalerweise von speziellen Ger√§ten ausgef√ºhrt. Wir m√∂chten jedoch eine Datei auf dem Computer oder ein Array im Speicher haben, in dem Amplituden auftreten.  Dementsprechend werden in diesem Stadium die Signale der Ger√§te in eine Reihe von Zahlen umgewandelt, die wir in Zukunft als PCM (Pulscodemodulation) bezeichnen werden.  Seine Indizes sind die bedingte Zeit (Intervallindex nach der Abtastung), und die Amplituden werden darin gespeichert und in der Quantisierungsstufe auf ganze Zahlen gerundet. <br><br><h2>  Fourier-Transformation </h2><br>  Urspr√ºnglich hatten wir eine mechanische Welle und den Wunsch, sie zu digitalisieren, aber jetzt haben wir ein digitalisiertes Signal und den Wunsch, Frequenzen daraus zu gewinnen.  Das Gew√ºnschte kann mit der Fourier-Transformation erreicht werden.  Nur f√ºr den Fall, werde ich seinen angewandten Wert in diesem Problem nacherz√§hlen.  Mit der Fourier-Transformation k√∂nnen Sie jede Funktion in die Summe von Sinus und Cosinus zerlegen.  Das interessiert uns, denn bei Sinus- und Kosinuswellen geht es um Schwingungen, und bei Schall geht es um Schwingungen.  Das hei√üt, mit der Fourier-Transformation k√∂nnen Sie die Komponenten einer komplexen Schwingung ermitteln und deren Amplitude und Frequenz ermitteln, indem Sie sich nur ansehen, welche Koeffizienten vor den Sinus- und Sinus- (oder Cosinus-) Argumenten stehen.  Zum Beispiel gibt es eine solche Welle. <br><br><img src="https://habrastorage.org/webt/jo/l2/cn/jol2cnvs7nfgyxwrbvbxr3jesvi.png" alt="Bild"><br>  <i>Die Welle</i> <br><br>  Tats√§chlich wissen wir, dass es durch die Funktion 10sin (3x) + sin (x) + 4sin (4x) + 20sin (2x) definiert ist, aber das ist es jetzt, und die reale Schallwelle besteht aus einer Vielzahl solcher Ausdr√ºcke, und das m√∂chten wir k√∂nnen arbeite damit.  Lassen Sie uns diese Funktion also mit dem <a href="http://www.siarion.net/rus/free/fourierscope/">FourierScope-</a> Programm durch die Fourier-Transformation <a href="http://www.siarion.net/rus/free/fourierscope/">f√ºhren</a> und das Amplitudenspektrum betrachten. <br><br><img src="https://habrastorage.org/webt/wa/i0/xe/wai0xeqihurjmrbsul2p01dotja.png" alt="Bild"><br>  <i>Amplitudenspektrum</i> <br><br>  So sehen die vier Sinusse aus.  Es ist leicht zu erkennen, dass der Graph den Koeffizienten der Sinusse und ihrer Argumente entspricht. <br><br>  Es sollte klargestellt werden, dass es sich in der Tat um eine Demonstration der Leistung nicht der Fourier-Transformation selbst, sondern ihrer diskreten Version handelte, die f√ºr Signale geeignet ist, die eine Pulscodemodulation mit all ihren Diskretisierungen und Quantisierungen durchlaufen.  Es w√§re √ºberfl√ºssig, einen Algorithmus f√ºr die diskrete Fouriertransformation vorzulegen, also stimmen wir nur der Tatsache zu, dass es so etwas wie die DFT und ihre Modifikation, die schnelle Fouriertransformation (FFT), gibt.  In diesem Fall lautet die angewandte Bedeutung der FFT wie folgt: Der Algorithmus empf√§ngt ein St√ºck PCM am Eingang und gibt ein Array mit den Amplituden aus, und die Frequenzbereiche sind die Indizes.  Es handelt sich um Frequenzbereiche, nicht nur um Frequenzen, da die Umwandlung diskret ist.  In der Tat war es naiv zu erwarten, dass Sie das Signal im gesamten Artikel vergr√∂bern und dann nur Frequenzen ohne Probleme und Ungenauigkeiten erhalten k√∂nnen.  Tats√§chlich ist der Frequenzbereich eine ganze Reihe von Frequenzen, die die FFT nicht voneinander unterscheiden kann. <br><br>  Es ist erw√§hnenswert, dass FFTs h√§ufig falsch geschrieben werden, wenn ein Algorithmus aus B√ºchern und Artikeln neu geschrieben wird.  Im Folgenden finden Sie einen genaueren Code f√ºr die Arbeit mit FFT, genau das, was wir von den Teilnehmern an ihrer L√∂sung erwartet haben. <br><br><pre> <code class="plaintext hljs">import "github.com/mjibson/go-dsp/fft" ... blocksCount := len(pcm) / fftWindowSize for i := 0; i &lt; blocksCount; i++ { complexArray := fft.FFTReal(pcm[i*fftWindowSize : i*fftWindowSize+fftWindowSize]) // use complexArray... }</code> </pre><br>  Dank moderner Technologie k√∂nnen Sie eine schnelle Fourier-Transformation in nur wenigen Zeilen schreiben.  FFT wird f√ºr Segmente der Gr√∂√üe fftWindowSize verwendet und gibt ein Array komplexer Zahlen zur√ºck, die wir in Zukunft f√ºr den Fingerabdruck verwenden werden. <br><br>  Im Allgemeinen ist die Fourier-Transformation die d√ºnnste Stelle im gesamten Problem.  Erstens ist die Beh√§ltergr√∂√üe $ \ frac {Frequenz \ Abtastrate} {Gr√∂√üe \ Fenster} $.  Dementsprechend kann man das Fenster vergr√∂√üern und mehr Frequenzen erhalten, was zwar nett ist, aber nat√ºrlich negative Konsequenzen hat.  Die Zunahme der Fenstergr√∂√üe f√ºhrt dazu, dass wir PCM in gro√üen Abst√§nden analysieren und Ger√§usche von kurzer Dauer verlieren.  Unter verschiedenen Umst√§nden kann dies das Programm wiederholt verschlechtern, wenn kurze Sounds Teil der Komposition waren, oder es kann sich verbessern, wenn es nur um Ger√§usche handelt.  Oder vielleicht gar nichts beeinflussen.  In solch einer schwierigen Situation muss der Programmierer entschlossen handeln: Nehmen Sie eine gute Zahl, wie z. B. 2 ^ 9 $ oder 2 ^ {10} $, und versuchen Sie, sich nicht um die Feinheiten zu k√ºmmern, bei denen dies nicht erforderlich ist.  Genug, um das Problem zu l√∂sen, aber in einer ernsthaften Anwendung m√ºssen Sie immer noch ein Hamming-Fenster und vieles mehr verwenden, um dar√ºber nachzudenken. <br><br><h2>  Fingerabdruck </h2><br>  Die Aufgabe besteht darin, zu lernen, wie ein Hash erstellt werden kann, der auf eine Spur abgebildet werden kann und der gegen√ºber √Ñnderungen unempfindlich ist und die Frequenzen und Amplituden der Komposition aufweist.  Sie k√∂nnen sehr unterschiedlich sein: ein wenig Rauschen, eine Verschiebung aller Frequenzen, das parallele Abspielen eines anderen Songs und so weiter.  Sie m√ºssen auch ber√ºcksichtigen, dass die Datenbank gleichzeitig viele √§hnliche Spuren enthalten kann, die voneinander unterschieden werden m√ºssen.  Oder vielleicht sind alle Tracks unterschiedlich, und das Problem wird nicht darin bestehen, herauszufinden, welcher besser geeignet ist, sondern zu verstehen, dass nicht einer geeignet ist.  Generell gibt es einen gewissen Spielraum f√ºr Kreativit√§t. <br><br>  Sie k√∂nnen einen Ausdruck auf verschiedene Arten erstellen.  Nehmen wir an, Sie erstellen einen Hash in Form einer Liste mit mehreren verschiedenen Indikatoren.  Darunter k√∂nnen zum Beispiel die durchschnittliche Anzahl von Null-Signal-Durchg√§ngen, BPM, durchschnittliche Frequenzwerte sein.  Ich habe dies in fr√ºheren Versionen von <a href="https://github.com/metabrainz">Musicbrainz</a> getan, und die Probleme dieses Ansatzes sind <a href="https://wiki.musicbrainz.org/Fingerprinting">hier</a> geschrieben.  Sie k√∂nnen auch abstraktere Konzepte wie den Rhythmus in Betracht ziehen und die Spur mit dem EM-Algorithmus analysieren ( <a href="https://ieeexplore.ieee.org/document/1203279">Artikel</a> ).  Im Allgemeinen v√∂llige Meinungsfreiheit.  Leider haben die meisten vorgeschlagenen Algorithmen anscheinend keine √∂ffentliche Implementierung, so dass es nicht funktioniert, sie nur zu nehmen und zu vergleichen. <br><br>  Die Mainstream-Implementierung wird in <a href="https://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf">diesem</a> Artikel beschrieben.  Besonders sch√∂n ist, dass Sie diesen Algorithmus in mehreren Zeilen implementieren k√∂nnen.  Zum Beispiel wird im urspr√ºnglichen Artikel vorgeschlagen, die Frequenzen in 6 Intervalle zu unterteilen, die maximale Amplitude in jedem zu finden, den Durchschnitt aller sechs zu bilden und die √ºber dem Durchschnitt liegenden F√§cher zu speichern, aber viele andere Implementierungen sind m√∂glich. <br><br><pre> <code class="plaintext hljs">var freqBins = [...]int16{40, 80, 120, 180, 300} func getKeyPoints(frame []freq_domain) int { highScores := make([]float64, len(freqBins)) recordPoints := make([]uint, len(freqBins)) for bin := freqBins[0]; bin &lt; freqBins[len(freqBins)-1]; bin++ { magnitude := frame[bin] binIdx := 0 for freqBins[binIdx] &lt; bin { binIdx++ } if magnitude &gt; highScores[binIdx] { highScores[binIdx] = magnitude recordPoints[binIdx] = (uint)(bin) } } return hash(recordPoints) }</code> </pre><br>  Die obige Funktion implementiert den Fingerabdruck-Algorithmus.  Am Ende wird ein Array von Frequenzen (oder besser Bins) an die Funktion "hash ()" √ºbergeben, die ein Array von mehreren Zahlen in eine Zahl umwandeln soll.  Sie k√∂nnen dies auf jede geeignete Weise tun, Sie k√∂nnen sogar versuchen, md5 zu verwenden (obwohl dies eine schlechte Idee ist). <br><br><h2>  √úber das Testen </h2><br>  <b>Es wurden mehrere Testf√§lle vorbereitet:</b> <br><br><ol><li>  Normaler Vortest mit einer Spur.  Das Original und das Muster stimmten vollst√§ndig √ºberein. </li><li>  Ein weiterer Vortest mit zwei Spuren.  Die Originale stimmten mit den Mustern √ºberein. </li><li>  Eine etwas gr√∂√üere Anzahl von Titeln wird indiziert, alle werden abwechselnd durchsucht. </li><li>  Es wird eine gro√üe Anzahl von Spuren geladen, nach denen gesucht wird, jedoch nach einem Downsampling. </li><li>  Die Tracks werden nach dem Downsampling indiziert, die Originale werden durchsucht. </li><li>  Indizierte mehrere √§hnliche Titel, suchte nach einem √§hnlichen, aber nicht in der Datenbank. </li><li>  Es werden mehrere Titel indiziert, nach denen gesucht wird, jedoch mit Rauschen. </li></ol><br><br><h2>  Einige interessante Links </h2><br>  <a href="https://metacpan.org/pod/Audio::Ofa::Util">https://metacpan.org/pod/Audio::Ofa::Util</a> <br>  <a href="https://www.researchgate.net/publication/228347102_A_Review_of_Audio_Fingerprinting">https://www.researchgate.net/publication/228347102_A_Review_of_Audio_Fingerprinting</a> <br>  <a href="http://www.freshmeat.net/projects/songprint">http://www.freshmeat.net/projects/songprint</a> <br>  <a href="https://link.springer.com/article/10.1007/s11265-005-4152-2">https://link.springer.com/article/10.1007/s11265-005-4152-2</a> <br>  <a href="https://github.com/acoustid/chromaprint">https://github.com/acoustid/chromaprint</a> <br>  <a href="https://laplacian.wordpress.com/2009/01/10/how-shazam-works/">https://laplacian.wordpress.com/2009/01/10/how-shazam-works/</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de480092/">https://habr.com/ru/post/de480092/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de480080/index.html">Was ben√∂tigen Sie f√ºr Notizen?</a></li>
<li><a href="../de480082/index.html">Verwenden der Partitionierung in MySQL f√ºr Zabbix mit einer gro√üen Anzahl von √úberwachungsobjekten</a></li>
<li><a href="../de480086/index.html">Wie Sie die Anforderungen von 152-FZ erf√ºllen, die pers√∂nlichen Daten unserer Kunden sch√ºtzen und nicht auf unseren Rechen treten</a></li>
<li><a href="../de480088/index.html">DevOps - OK, aber was tun? So reduzieren Sie die Handarbeit und erzielen das gew√ºnschte Ergebnis</a></li>
<li><a href="../de480090/index.html">Open Source ist alles</a></li>
<li><a href="../de480096/index.html">Ende der Kindheit: Urheberrecht an Werken k√ºnstlicher Intelligenz (KI)</a></li>
<li><a href="../de480098/index.html">JH Regenwasser "Wie man Katzen weidet": auf der anderen Seite der Entwicklung</a></li>
<li><a href="../de480100/index.html">Anf√§nger √ºber SEO</a></li>
<li><a href="../de480102/index.html">November Product Management Digest</a></li>
<li><a href="../de480104/index.html">9 n√ºtzliche HTML-Tricks</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
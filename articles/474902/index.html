<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úàÔ∏è ü§ñ üë®üèª‚Äçüç≥ Tendencias en visi√≥n por computadora. Lo m√°s destacado ICCV 2019 üé¨ üßÄ üë®‚Äçüë©‚Äçüëß‚Äçüë¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Las redes neuronales en visi√≥n artificial se est√°n desarrollando activamente, muchas tareas a√∫n est√°n lejos de resolverse. Para estar de moda en su ca...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tendencias en visi√≥n por computadora. Lo m√°s destacado ICCV 2019</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/474902/"><img src="https://habrastorage.org/webt/in/lj/qf/inljqfmjnklszyujlyua8n_w0bo.jpeg"><br><br>  Las redes neuronales en visi√≥n artificial se est√°n desarrollando activamente, muchas tareas a√∫n est√°n lejos de resolverse.  Para estar de moda en su campo, solo siga a los influencers en Twitter y lea los art√≠culos relevantes en arXiv.org.  Pero tuvimos la oportunidad de asistir a la Conferencia Internacional sobre Visi√≥n por Computadora (ICCV) 2019. Este a√±o se celebra en Corea del Sur.  Ahora queremos compartir con los lectores de Habr lo que vimos y aprendimos. <br><a name="habracut"></a><br>  Hab√≠a muchos de nosotros de Yandex: desarrolladores de veh√≠culos no tripulados, investigadores y aquellos involucrados en tareas de CV en los servicios llegaron.  Pero ahora queremos presentar un punto de vista ligeramente subjetivo de nuestro equipo: el laboratorio de inteligencia artificial (Yandex MILAB).  Otros tipos probablemente miraron la conferencia desde su √°ngulo. <br><br><div class="spoiler">  <b class="spoiler_title">¬øQu√© hace el laboratorio?</b> <div class="spoiler_text">  Realizamos proyectos experimentales relacionados con la generaci√≥n de im√°genes y m√∫sica con fines de entretenimiento.  Estamos especialmente interesados ‚Äã‚Äãen las redes neuronales que le permiten cambiar el contenido del usuario (para una foto, esta tarea se denomina manipulaci√≥n de im√°genes).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Un ejemplo del</a> resultado de nuestro trabajo de la conferencia YaC 2019. </div></div><br>  Hay muchas conferencias cient√≠ficas, pero las principales conferencias llamadas A * se destacan de ellas, donde generalmente se publican art√≠culos sobre las tecnolog√≠as m√°s interesantes e importantes.  No hay una lista exacta de conferencias A *, aqu√≠ hay un ejemplo incompleto: NeurIPS (anteriormente NIPS), ICML, SIGIR, WWW, WSDM, KDD, ACL, CVPR, ICCV, ECCV.  Los tres √∫ltimos se especializan en el tema de CV. <br><br><h2>  ICCV de un vistazo: carteles, tutoriales, talleres, stands </h2><br>  Se aceptaron 1075 documentos en la conferencia, los participantes fueron 7,500. 103 personas vinieron de Rusia, hab√≠a art√≠culos de empleados de Yandex, Skoltech, Samsung AI Center Moscow y Samara University.  Este a√±o, no muchos investigadores importantes visitaron el ICCV, pero aqu√≠, por ejemplo, Alexey (Alyosha) Efros, que siempre re√∫ne a mucha gente: <br><br><img src="https://habrastorage.org/webt/4g/ie/3w/4gie3wyqaablh0wmnxbq4ucdwbs.jpeg"><br><br><div class="spoiler">  <b class="spoiler_title">Estad√≠sticas</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/1e/lz/am/1elzamxsr2xf9k_gqrwvvvrwey0.jpeg" width="500"><br><br><img src="https://habrastorage.org/webt/vb/yr/1i/vbyr1im56rz6ib-6sj_0fjiokjc.jpeg" width="500"><br><br><img src="https://habrastorage.org/webt/l6/wc/iy/l6wciy-qakwq9wwe65hz9-pqjl8.jpeg" width="500"><br><br><img src="https://habrastorage.org/webt/jb/dr/rq/jbdrrqkeo6mw26wx3zi5taa_zog.jpeg" width="500"><br><br><img src="https://habrastorage.org/webt/2g/rb/rt/2grbrtsd1xwbzwzxfstgdck6jis.jpeg" width="500"><br></div></div><br>  En todas esas conferencias, los art√≠culos se presentan en forma de carteles ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">m√°s</a> sobre el formato), y los mejores tambi√©n se presentan en forma de informes breves. <br><br><div class="spoiler">  <b class="spoiler_title">Aqu√≠ es parte del trabajo de Rusia</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/iu/sc/po/iuscpof__g3ikvdguuy94javuvo.jpeg"><br><br><img src="https://habrastorage.org/webt/ae/e0/xj/aee0xjbluiby-b_xxoednb7yfws.jpeg"><br><br><img src="https://habrastorage.org/webt/1s/qt/la/1sqtla2h9xgccuhu2dr1iyvxuek.jpeg"><br></div></div><br>  En los tutoriales puedes sumergirte en alguna materia, se parece a una conferencia en una universidad.  Es le√≠da por una persona, generalmente sin hablar de trabajos espec√≠ficos.  Ejemplo de tutorial genial ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Michael Brown, Comprensi√≥n del color y la canalizaci√≥n de procesamiento de im√°genes en la c√°mara para visi√≥n artificial</a> ): <br><br><img src="https://habrastorage.org/webt/2z/sq/e6/2zsqe6wgv1rtrl0tpvwl-eu5enw.jpeg"><br><br>  En los talleres, por el contrario, hablan de art√≠culos.  Por lo general, este es un trabajo en un tema limitado, historias de l√≠deres de laboratorio sobre el √∫ltimo trabajo de los estudiantes o art√≠culos que no fueron aceptados en la conferencia principal. <br><br>  Las empresas patrocinadoras llegan al ICCV con stands.  Este a√±o, llegaron Google, Facebook, Amazon y muchas otras compa√±√≠as internacionales, as√≠ como una gran cantidad de nuevas empresas: coreanas y chinas.  Hubo especialmente muchas nuevas empresas que se especializan en el marcado de datos.  Hay actuaciones en los stands, puedes llevar mercader√≠a y hacer preguntas.  Las empresas patrocinadoras tienen fiestas para cazar.  Se las arreglan para seguir adelante si convencen a los reclutadores de que est√° interesado y que potencialmente puede ser entrevistado.  Si public√≥ un art√≠culo (o, adem√°s, realiz√≥ una presentaci√≥n con √©l), inici√≥ o finaliz√≥ el doctorado; esto es una ventaja, pero a veces puede ponerse de acuerdo sobre un stand, haciendo preguntas interesantes a los ingenieros de la compa√±√≠a. <br><br><h2>  Tendencias </h2><br>  La conferencia le permite echar un vistazo a toda el √°rea de CV.  Por la cantidad de carteles de un tema en particular, puede evaluar qu√© tan caliente es el tema.  Algunas conclusiones piden las palabras clave: <br><br><img src="https://habrastorage.org/webt/7u/td/1v/7utd1vf3hcbbhtrgl3xvldtjnjc.jpeg"><br><br><h4>  Zero-shot, one-shot, pocos disparos, auto-supervisado y semi-supervisado: nuevos enfoques para problemas estudiados durante mucho tiempo </h4><br>  Las personas aprenden a usar los datos de manera m√°s eficiente.  Por ejemplo, en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">FUNIT,</a> puede generar expresiones faciales de animales que no estaban en el conjunto de entrenamiento (aplicando varias im√°genes de referencia en la aplicaci√≥n).  Se han desarrollado las ideas de Deep Image Prior, y ahora las redes <abbr title="Redes de confrontaci√≥n generativas, redes de confrontaci√≥n generativas.">GAN</abbr> se pueden entrenar en una sola imagen. Hablaremos de esto m√°s adelante <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en los aspectos</a> m√°s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">destacados</a> .  Puede usar la auto-supervisi√≥n para la capacitaci√≥n previa (resolver un problema para el cual puede sintetizar datos alineados, por ejemplo, para predecir el √°ngulo de rotaci√≥n de una imagen) o aprender al mismo tiempo de datos marcados y no etiquetados.  En este sentido, la corona de la creaci√≥n puede considerarse un art√≠culo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">S4L: Aprendizaje semi-supervisado auto supervisado</a> .  Pero la capacitaci√≥n previa en ImageNet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">no siempre</a> ayuda. <br><br><img src="https://habrastorage.org/webt/gj/yy/n4/gjyyn40ktbwpjaslfp0v7c-avhi.jpeg"><br><br><img src="https://habrastorage.org/webt/x5/6-/l8/x56-l8y26lyq9unxyt0soa8koay.jpeg"><br><br><h4>  3D y 360 ¬∞ </h4><br>  Las tareas, en su mayor√≠a resueltas para fotos (segmentaci√≥n, detecci√≥n), requieren investigaci√≥n adicional para modelos 3D y videos panor√°micos.  Vimos muchos art√≠culos sobre la conversi√≥n de RGB y <abbr title="Imagen de profundidad RGB. Para cada punto, no solo se conoce su color, sino tambi√©n su &quot;profundidad&quot;: la distancia desde el punto de vista / disparo.">RGB-D</abbr> a 3D.  Algunas tareas, como determinar la pose de una persona (estimaci√≥n de pose), se resuelven de forma m√°s natural si vamos a modelos tridimensionales.  Pero hasta ahora no hay consenso sobre c√≥mo representar exactamente los modelos 3D, en forma de cuadr√≠cula, nube de puntos, <abbr title="An√°logos de p√≠xeles en 3D.">v√≥xel</abbr> o <abbr title="Campos de distancia firmados: campos de distancia firmados.">SDF</abbr> .  Aqu√≠ hay otra opci√≥n: <br><br><img src="https://habrastorage.org/webt/n7/i-/1x/n7i-1xtwmc5xxvs4cfsf4vt4srw.jpeg"><br><br>  En los panoramas, las convoluciones en la esfera se est√°n desarrollando activamente (ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Segmentaci√≥n sem√°ntica consciente de la orientaci√≥n en esferas de icosaedro</a> ) y la b√∫squeda de objetos clave en el marco. <br><br><img src="https://habrastorage.org/webt/bk/4l/gw/bk4lgwc3dzrh_uliw83x21hskyy.png"><br><br><h4>  Definici√≥n de postura y predicci√≥n de movimientos humanos. </h4><br>  Para determinar la pose en 2D, ya hay √©xito: ahora el enfoque se ha desplazado hacia trabajar con m√∫ltiples c√°maras y en 3D.  Por ejemplo, puede determinar el esqueleto a trav√©s de la pared, siguiendo los cambios en la se√±al de Wi-Fi a medida que pasa a trav√©s del cuerpo humano. <br><br>  Se ha realizado mucho trabajo en el √°rea de detecci√≥n de puntos clave manuales.  Aparecieron nuevos conjuntos de datos, incluidos los basados ‚Äã‚Äãen video con di√°logos de dos personas: ¬°ahora puede predecir gestos con las manos por audio o texto de una conversaci√≥n!  Se ha hecho el mismo progreso en las tareas de evaluaci√≥n de la mirada. <br><br><img src="https://habrastorage.org/webt/j0/-j/kv/j0-jkvftadbawqem0ccmm7qmdpa.jpeg"><br><br><img src="https://habrastorage.org/webt/u_/gj/j6/u_gjj6f2d-icebbun428-1e0ztc.jpeg"><br><br>  Tambi√©n puede resaltar un gran grupo de trabajos relacionados con la predicci√≥n del movimiento humano (por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Predicci√≥n del movimiento humano a trav√©s de la pintura espacio-temporal</a> o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">predicci√≥n estructurada ayuda al modelado del movimiento humano en 3D</a> ).  La tarea es importante y, seg√∫n las conversaciones con los autores, se usa con mayor frecuencia para analizar el comportamiento de los peatones en la conducci√≥n aut√≥noma. <br><br><h4>  Manipulaci√≥n de personas en fotos y videos, probadores virtuales </h4><br>  La tendencia principal es cambiar las im√°genes faciales en t√©rminos de par√°metros interpretados.  Ideas: <abbr title="Sustituci√≥n de extra√±os en el video.">falsificaci√≥n profunda</abbr> en una imagen, cambio de expresi√≥n mediante renderizado facial ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PuppetGAN</a> ), cambio de par√°metros de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">avance</a> (por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">edad</a> ).  Las transferencias de estilo se movieron del t√≠tulo del tema al trabajo de la aplicaci√≥n.  Otra historia: los probadores virtuales, casi siempre funcionan mal, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠ hay un ejemplo de una</a> demostraci√≥n. <br><br><img src="https://habrastorage.org/webt/u-/q9/rw/u-q9rwdkgxxor2snnsrkstmykbe.jpeg"><br><br><img src="https://habrastorage.org/webt/qw/f4/ys/qwf4ys-wamesjxss4gs30v9wbpq.jpeg"><br><br><h4>  Bosquejo / Generaci√≥n de Gr√°ficos </h4><br>  El desarrollo de la idea "Dejar que la cuadr√≠cula genere algo basado en la experiencia previa" se ha vuelto diferente: "Vamos a mostrarle a la cuadr√≠cula qu√© opci√≥n nos interesa". <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SC-FEGAN le</a> permite hacer una pintura guiada: el usuario puede dibujar parte de la cara en el √°rea borrada de la imagen y obtener la imagen restaurada dependiendo del renderizado. <br><br><img src="https://habrastorage.org/webt/kn/pv/0d/knpv0dzfajvu2hhcbqdgiw-sbek.gif"><br><br>  En uno de los 25 art√≠culos de Adobe para ICCV, se combinan dos GAN: uno dibuja un boceto para el usuario, el otro genera una imagen fotorrealista a partir del boceto ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">p√°gina del proyecto</a> ). <br><br><img src="https://habrastorage.org/webt/ua/ba/ap/uabaap4mv5jwm9tdc0qgsxty3ho.gif"><br><br>  Anteriormente en la generaci√≥n de im√°genes, no se necesitaban gr√°ficos, pero ahora se han convertido en un contenedor de conocimiento sobre la escena.  El premio de Menciones de Honor al Mejor Papel del ICCV tambi√©n se otorg√≥ al art√≠culo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Especificaci√≥n de atributos y relaciones de objetos en la generaci√≥n de escenas interactivas</a> .  En general, puede usarlos de diferentes maneras: generar gr√°ficos a partir de im√°genes o im√°genes y textos a partir de gr√°ficos. <br><br><img src="https://habrastorage.org/webt/5h/qf/zw/5hqfzwxfjjt-1bnyqopp7ozoqi4.png"><br><br><h4>  Reidentificaci√≥n de personas y m√°quinas, contando el n√∫mero de multitudes (!) </h4><br>  Muchos art√≠culos est√°n dedicados a rastrear personas y <abbr title="Reidentificaci√≥n: se puede traducir libremente como &quot;desanonimizaci√≥n&quot;.">reidentificar</abbr> personas y m√°quinas.  Pero lo que nos sorprendi√≥ fue un mont√≥n de art√≠culos sobre contar personas en una multitud, y todos de China. <br><br><div class="spoiler">  <b class="spoiler_title">Carteles</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/fh/cn/ma/fhcnma3kitjamuo8yty7hjp1loa.jpeg"><br><br><img src="https://habrastorage.org/webt/ej/_p/66/ej_p66wxpnx52yzlv97osbkys1u.jpeg"><br><br><img src="https://habrastorage.org/webt/j7/7z/bv/j77zbvjegwrfp6emzv-ddcylgmm.jpeg"><br><br><img src="https://habrastorage.org/webt/q9/lw/kr/q9lwkrpkzozcvfa609k6t5krmnw.jpeg"><br><br><img src="https://habrastorage.org/webt/3x/rv/1i/3xrv1ibiocsa5cgbmdvecwxbkyu.jpeg"></div></div><br>  Pero Facebook, por el contrario, anonimiza la foto.  Adem√°s, lo hace de una manera interesante: ense√±a a la red neuronal a generar una cara sin detalles √∫nicos, similar, pero no tanto como para que sea detectada correctamente por los sistemas de reconocimiento facial. <br><br><img src="https://habrastorage.org/webt/jg/az/oe/jgazoe4ptlfckqpaxdgri2kdlwc.jpeg"><br><br><h4>  Protecci√≥n contra ataques adversos </h4><br>  Con el desarrollo de aplicaciones de visi√≥n por computadora en el mundo real (en veh√≠culos no tripulados, en reconocimiento facial), surge con mayor frecuencia la cuesti√≥n de la confiabilidad de tales sistemas.  Para hacer un uso completo de CV, debe asegurarse de que el sistema sea resistente a los ataques adversos, por lo tanto, no hubo menos art√≠culos sobre protecci√≥n contra ellos que sobre los ataques mismos.  Se trabaj√≥ mucho para explicar las predicciones de la red (mapa de prominencia) y medir la confianza en el resultado. <br><br><h4>  Tareas combinadas </h4><br>  En la mayor√≠a de las tareas con un objetivo, las posibilidades de mejorar la calidad est√°n casi agotadas; una de las nuevas √°reas de mayor crecimiento de calidad es ense√±ar a las redes neuronales a resolver varios problemas similares al mismo tiempo.  Ejemplos: <br>  - predicci√≥n de acciones + predicci√≥n de flujo √≥ptico, <br>  - presentaci√≥n en video + representaci√≥n en el idioma ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VideoBERT</a> ), <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Super-resoluci√≥n + HDR</a> . <br><br>  ¬°Y hab√≠a art√≠culos sobre segmentaci√≥n, determinaci√≥n de la postura y reidentificaci√≥n de animales! <br><br><img src="https://habrastorage.org/webt/qe/gk/fi/qegkfif0smvsnit1kjrpdbkajco.jpeg"><br><br><img src="https://habrastorage.org/webt/tz/hk/fo/tzhkfogbi5sxyvzbhu5bjaoii54.jpeg"><br><br><a name="highlights"></a><h2>  Destacados </h2><br>  Casi todos los art√≠culos se conoc√≠an de antemano, el texto estaba disponible en arXiv.org.  Por lo tanto, la presentaci√≥n de obras como Everybody Dance Now, FUNIT, Image2StyleGAN parece bastante extra√±a: estas son obras muy √∫tiles, pero no son nuevas en absoluto.  Parece que el proceso cl√°sico de publicaci√≥n cient√≠fica est√° fallando aqu√≠: la ciencia se est√° desarrollando demasiado r√°pido. <br><br>  Es muy dif√≠cil determinar los mejores trabajos: hay muchos de ellos, los temas son diferentes.  Varios art√≠culos han recibido <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">premios y referencias</a> . <br><br>  Queremos resaltar trabajos que son interesantes en t√©rminos de manipulaci√≥n de im√°genes, ya que este es nuestro tema.  Result√≥ ser bastante fresco e interesante para nosotros (no pretendemos ser objetivos). <br><br><h4>  SinGAN (premio al mejor papel) e InGAN </h4>  SinGAN: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">p√°gina del proyecto</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arXiv</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">c√≥digo</a> . <br>  InGAN: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">p√°gina del proyecto</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arXiv</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">c√≥digo</a> . <br><br>  El desarrollo de la idea de Deep Image Prior por Dmitry Ulyanov, Andrea Vedaldi y Victor Lempitsky.  En lugar de entrenar a GAN en un conjunto de datos, las redes aprenden de fragmentos de la misma imagen para recordar las estad√≠sticas que contiene.  La red entrenada le permite editar y animar fotos (SinGAN) o generar nuevas im√°genes de cualquier tama√±o a partir de las texturas de la imagen original, manteniendo la estructura local (InGAN). <br><br>  SinGAN: <br><br><img src="https://habrastorage.org/webt/oc/ba/pt/ocbaptuxkshaswnhnfhloplqmrm.png"><br><br>  InGAN: <br><br><img src="https://habrastorage.org/webt/xn/cc/i0/xncci0dgonpmajjiv0fisak0twa.gif"><br><br><h4>  Ver lo que una GAN no puede generar </h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">P√°gina del proyecto</a> <br><br>  Las redes neuronales generadoras de im√°genes a menudo reciben un vector de ruido aleatorio como entrada.  En una red entrenada, muchos vectores de entrada forman un espacio, peque√±os movimientos que conducen a peque√±os cambios en la imagen.  Usando la optimizaci√≥n, puede resolver el problema inverso: encontrar un vector de entrada adecuado para una imagen del mundo real.  El autor muestra que casi nunca es posible encontrar una imagen completamente coincidente en una red neuronal casi nunca.  Algunos objetos en la imagen no se generan (aparentemente, debido a la gran variabilidad de estos objetos). <br><br><img src="https://habrastorage.org/webt/pv/pa/f2/pvpaf2havdxksu-mhmbus-naina.png"><br><br>  El autor plantea la hip√≥tesis de que la GAN no cubre todo el espacio de las im√°genes, sino solo un subconjunto relleno de agujeros, como el queso.  Cuando intentamos encontrar fotos del mundo real en √©l, siempre fallaremos, porque la GAN todav√≠a no genera fotos reales.  Puede superar las diferencias entre im√°genes reales y generadas solo cambiando el peso de la red, es decir, volvi√©ndola a entrenar para una foto espec√≠fica. <br><br><img src="https://habrastorage.org/webt/ci/vg/bp/civgbpxixfgs_76svkwewjksn3a.jpeg"><br><br>  Cuando la red se vuelve a entrenar para una foto espec√≠fica, puede intentar realizar varias manipulaciones con esta imagen.  En el ejemplo a continuaci√≥n, se agreg√≥ una ventana a la foto, y la red adem√°s gener√≥ reflejos en el juego de cocina.  Esto significa que la red despu√©s del reentrenamiento para fotograf√≠a no perdi√≥ la capacidad de ver la conexi√≥n entre los objetos de la escena. <br><br><img src="https://habrastorage.org/webt/ov/gp/qd/ovgpqdyldwsdptpav699a_vl2qo.jpeg"><br><br><h4>  GANalyze: hacia las definiciones visuales de las propiedades de imagen cognitiva </h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">P√°gina del proyecto</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arXiv</a> . <br><br>  Usando el enfoque de este trabajo, puede visualizar y analizar lo que la red neuronal ha aprendido.  Los autores proponen capacitar a GAN para crear im√°genes para las cuales la red generar√° predicciones dadas.  Se usaron varias redes como ejemplos en el art√≠culo, incluida MemNet, que predice la memorabilidad de las fotos.  Result√≥ que para una mejor memorabilidad, el objeto en la foto deber√≠a: <br><br><ul><li>  estar m√°s cerca del centro </li><li>  tienen una forma redonda o cuadrada y una estructura simple, </li><li>  estar en un fondo uniforme, </li><li>  contener ojos expresivos (al menos para fotos de perros), </li><li>  ser m√°s brillante, m√°s rico, en algunos casos, m√°s rojo. </li></ul><br><img src="https://habrastorage.org/webt/9y/b2/wd/9yb2wdgndc2qvmugfdk5yctxfbg.png"><br><br><h4>  Liquid Warping GAN: un marco unificado para imitaci√≥n de movimiento humano, transferencia de apariencia y s√≠ntesis de vista novedosa </h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">P√°gina del proyecto</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arXiv</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">c√≥digo</a> . <br><br>  Canalizaci√≥n para generar fotos de personas a partir de una foto.  Los autores muestran ejemplos exitosos de transferir el movimiento de una persona a otra, transferir ropa entre personas y generar nuevas perspectivas de una persona, todo desde una fotograf√≠a.  A diferencia de trabajos anteriores, aqu√≠, para crear condiciones, no se utilizan puntos clave en 2D (pose), sino una malla 3D del cuerpo (pose + forma).  Los autores tambi√©n descubrieron c√≥mo transferir informaci√≥n de la imagen original a la generada (Liquid Warping Block).  Los resultados parecen decentes, pero la resoluci√≥n de la imagen resultante es de solo 256x256.  En comparaci√≥n, vid2vid, que apareci√≥ hace un a√±o, es capaz de generar con una resoluci√≥n de 2048x1024, pero necesita hasta 10 minutos de grabaci√≥n de video como un conjunto de datos. <br><br><img src="https://habrastorage.org/webt/el/m1/eh/elm1ehlgjasetl9leqejn9elvbu.png"><br><br><h4>  FSGAN: Intercambio de rostros agn√≥sticos de sujetos y recreaci√≥n </h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">P√°gina del proyecto</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arXiv</a> . <br><br>  Al principio parece que nada inusual: deepfake con calidad m√°s o menos normal.  Pero el logro principal del trabajo es la sustituci√≥n de caras en una imagen.  A diferencia de trabajos anteriores, se requer√≠a capacitaci√≥n en una variedad de fotograf√≠as de una persona en particular.  La tuber√≠a result√≥ ser engorrosa (recreaci√≥n y segmentaci√≥n, vista de interpolaci√≥n, pintura, mezcla) y con muchos trucos t√©cnicos, pero el resultado vale la pena. <br><br><img src="https://habrastorage.org/webt/43/33/zn/4333zncbuoqflhf2srkk-05e6m0.png"><br><br><h4>  Detectando lo inesperado mediante la res√≠ntesis de imagen </h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arXiv</a> . <br><br>  ¬øC√≥mo puede un dron comprender que un objeto apareci√≥ de repente frente a √©l que no cae en ninguna clase de segmentaci√≥n sem√°ntica?  Existen varios m√©todos, pero los autores ofrecen un nuevo algoritmo intuitivo que funciona mejor que sus predecesores.  La segmentaci√≥n sem√°ntica se predice a partir de la imagen de entrada de la carretera.  Se alimenta a la GAN (pix2pixHD), que intenta restaurar la imagen original solo desde el mapa sem√°ntico.  Las anomal√≠as que no caen en ninguno de los segmentos diferir√°n significativamente en la fuente y la imagen generada.  Luego, tres im√°genes (inicial, segmentaci√≥n y reconstrucci√≥n) se env√≠an a otra red, que predice anomal√≠as.  El conjunto de datos para esto se gener√≥ a partir del conocido conjunto de datos Cityscapes, que cambi√≥ accidentalmente las clases de segmentaci√≥n sem√°ntica.  Curiosamente, en este contexto, un perro parado en medio del camino, pero correctamente segmentado (lo que significa que hay una clase para eso), no es una anomal√≠a, ya que el sistema pudo reconocerlo. <br><br><img src="https://habrastorage.org/webt/fc/1_/ug/fc1_ugp2xbh5qxttjgskyxprji4.png"><br><br><h2>  Conclusi√≥n </h2><br>  Antes de la conferencia es importante saber cu√°les son sus intereses cient√≠ficos, a qu√© discursos me gustar√≠a hablar, con qui√©n hablar.  Entonces todo ser√° mucho m√°s productivo. <br><br>  ICCV es principalmente redes.  Entiendes que existen las mejores instituciones y los mejores cient√≠ficos, comienzas a entender esto, a conocer gente.  Y puede leer art√≠culos en arXiv, y por cierto, es genial que no pueda ir a ninguna parte para obtener conocimiento. <br><br>  Adem√°s, en la conferencia puede profundizar en temas que no est√°n cerca de usted, ver tendencias.  Bueno, escriba una lista de art√≠culos para leer.  Si eres un estudiante, esta es una oportunidad para que te familiarices con un cient√≠fico potencial, si eres de la industria, luego con un nuevo empleador y, si es la empresa, mu√©strate. <br><br>  ¬°Suscr√≠bete a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">@loss_function_porn</a> !  Este es un proyecto personal: estamos juntos con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">Karfly</a> .  Todo el trabajo que nos gust√≥ durante la conferencia, lo publicamos aqu√≠: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">@loss_function_live</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/474902/">https://habr.com/ru/post/474902/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../474890/index.html">Prueba comparativa de c√°maras de tel√©fonos m√≥viles viejos y un poco de historia</a></li>
<li><a href="../474892/index.html">Programaci√≥n para ni√±os. Cinco de los mejores juegos HTML y JavaScript</a></li>
<li><a href="../474894/index.html">Resumen a trav√©s de los ojos de un entrevistador</a></li>
<li><a href="../474896/index.html">Los cient√≠ficos han descubierto un nuevo factor en la entrega efectiva de medicamentos en el tumor</a></li>
<li><a href="../474900/index.html">El chip de chip abierto OpenTitan reemplaza las ra√≠ces de confianza propietarias de Intel y ARM</a></li>
<li><a href="../474906/index.html">Xamarin.Forms - Mapeo decorativo de QRCode con SkiaSharp</a></li>
<li><a href="../474910/index.html">Que jugar con los ni√±os antes de la escuela</a></li>
<li><a href="../474912/index.html">Mensajes y alertas en Android a trav√©s de JSON</a></li>
<li><a href="../474916/index.html">Aplicar el entorno Nix-Shell en Visual Studio Code</a></li>
<li><a href="../474918/index.html">Mejora del dise√±o conjunto de componentes electromec√°nicos.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
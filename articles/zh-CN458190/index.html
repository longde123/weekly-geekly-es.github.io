<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎽 🖕🏽 🌔 我知道，这意味着我存在：计算机视觉深度学习的回顾（第2部分） 👩🏿‍🏭 👸🏼 👨🏾‍🚒</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="我们继续理解现代魔术（计算机视觉）。 第2部分并不意味着您需要先阅读第1部分，第2部分意味着现在一切都变得很重要-我们想了解视觉中神经网络的全部功能。 检测，跟踪，分割，姿势评估，动作识别...最时尚，最酷的体系结构，数百个层次和数十个绝妙的主意已经在切切等待着您！ 



 在上个系列中 
 让我...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>我知道，这意味着我存在：计算机视觉深度学习的回顾（第2部分）</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mipt/blog/458190/">我们继续理解现代魔术（计算机视觉）。 第2部分并不意味着您需要先阅读第1部分，第2部分意味着现在一切都变得很重要-我们想了解视觉中神经网络的全部功能。 检测，跟踪，分割，姿势评估，动作识别...最时尚，最酷的体系结构，数百个层次和数十个绝妙的主意已经在切切等待着您！ <br><br><img src="https://habrastorage.org/webt/yt/nk/uu/ytnkuundiudek47rjvlmlujrrm4.jpeg"><br><a name="habracut"></a><br><h2> 在上个系列中 </h2><br> 让我提醒您，在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">第一部分中，</a>我们熟悉了卷积神经网络及其可视化，以及图像分类和构建其有效表示（嵌入）的任务。 我们甚至讨论了人脸识别和重新识别的任务。 <br><br> 即使在上一篇文章中，我们也讨论了不同类型的架构（是的， <s>我生产一个月的</s>平板电脑），而Google在这里并没有浪费时间：他们发布了又一种非常快速和准确的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">EfficientNet</a>架构。 他们使用<abbr title="神经建筑搜索">NAS</abbr>和特殊的Composite Scaling程序创建了它。 查看<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">这篇文章</a> ，这是值得的。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9m/_h/5c/9m_h5cc1tsxs7bfkainm5zom-wg.jpeg" width="500"></div><br> 同时，一些研究人员<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">制作了动画面孔，</a>并<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在电影中寻找接吻</a> ，我们将处理更多紧迫的问题。 <br><br> 人们在这里说：“图像识别”。 但是什么是“识别”？ 什么是“理解（场景）”？ 我认为，对这些问题的答案取决于我们到底想“识别”什么，以及我们到底想“理解”什么。 如果我们建立了人工智能，它将像人类一样有效（甚至更好）地从视觉流中提取有关世界的信息，那么我们就需要从任务和需求出发。 从历史上看，现代的“识别”和“场景理解”可以分为几个特定的​​任务：分类，检测，跟踪，姿势和面部识别，分割，视频上的动作识别以及文本图像描述。 本文将重点介绍列表中的前两个任务（ups，第三部分的破坏者），因此当前的计划是这样的： <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">如果可以找到我：对象检测</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">脸部侦测：未被发现-不是小偷</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">许多字母：文本检测（和识别）</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">视频和跟踪：在单个流中</a> </li></ol><br> 让我们摇滚，超级巨星！ <br><br><a name="1"></a><h2> 如果可以找到我：对象检测 </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-q/9e/on/-q9eonan6thdv5jivk8kq0h7gm0.jpeg" width="700"></div><br> 因此，这项任务听起来很简单-给了一张图片，您需要在上面找到预定义类的对象（人，书，苹果，自流诺曼·诺曼·巴塞特-格里芬等）。 为了在神经网络的帮助下解决这个问题，我们以张量和机器学习的形式提出它。 <br><br> 我们记得彩色图片是张量（H，W，3）（如果我们不记得，那就是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">第1部分</a> ）。 以前，我们只知道如何对整个图片进行分类，但是现在我们的目标是预测图片中感兴趣的对象（像素坐标）及其类的位置。 <br><br> 这里的关键思想是立即解决两个问题-分类和回归。 我们使用神经网络对坐标进行回归并对其内部的对象进行分类。 <br><br><div class="spoiler">  <b class="spoiler_title">分类？</b>  <b class="spoiler_title">回归？</b> <div class="spoiler_text"> 让我提醒您，我们正在谈论机器学习的任务。 在<b>分类</b>问题中， <b>类</b>标签充当对象的真实标签的质量，并且我们预测对象的类。 在<b>回归</b>问题中， <b>实数</b>是<b>实数</b> ，我们可以预测数字（例如：体重，身高，薪水，在下一系列《权力的游戏》中死亡的角色数量...）。 更详细地讲- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">欢迎</a>您<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">参加DLSchool的第三届演讲（FPMI MIPT）</a> 。 <br></div></div><br> 但是，一般来讲，对象的坐标可以以不同的方式形式化，在DL中，主要有三种方式： <i>检测</i> （对象<abbr title="包围对象的矩形">盒</abbr> ）， <i>姿势评估</i> （对象的关键点）和<i>分割</i> （对象的“蒙版”）。 现在<abbr title="包围对象的矩形"><b>让我们</b></abbr>谈谈精确预测<abbr title="包围对象的矩形"><b>边界框</b></abbr> ，点和分割的内容。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ki/wt/xm/kiwtxmvvhmwsvqn3_5dovlmp8w8.jpeg" width="500"></div><br> 基本上，检测数据集用以下格式的框标记：“每个图片中每个对象的左上角和右下角的坐标”（此格式也称为<abbr title="“ Tlbr”">左上角，右下角</abbr> ），并且大多数神经网络方法会预测这些坐标。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uo/zs/tj/uozstjspdifxpslvqyuurauxs2g.png" width="500"></div><br><div class="spoiler">  <b class="spoiler_title">关于检测问题中的数据集和指标</b> <div class="spoiler_text"> 设置任务后，最好查看可用于培训的数据以及用于衡量质量的指标。 这是我在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">深度学习学院第13堂讲座</a>的前半部分（在x2.0上最多）所谈论的话题。 <br></div></div><br> 在深入研究神经网络的类型之前，让我们一起思考如何解决检测图像中任何东西的问题。 可能是，如果我们想在图片中找到某个对象，则可以大致知道它的外观以及应该在图像中占据什么区域（尽管它可以更改）。 <br><br><div class="spoiler">  <b class="spoiler_title">从头开始进行检测</b> <div class="spoiler_text"> 天真的和最简单的方法是简单地进行“模板搜索”算法：让图片为100x100像素，而我们正在寻找一个足球。 设一个20x20像素的球形图案。 以这个模板为例，我们将像遍历整个图片的卷积一样遍历它，计算逐像素差异。 这就是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">模板匹配的</a>工作方式（通常使用某种类型的相关性来代替逐像素差异）。 <br><br> 如果没有模板，但是有一个神经网络分类器，那么我们可以这样做：我们将在图片中经过一个固定大小的窗口，并预测图片当前区域的类别。 然后，我们只说对象最可能的区域是分类器自信地回答的区域。 因此，我们可以解决以下问题：对象在外观上看起来有所不同（因为它经过训练可以在非常多样的样本上进行分类）。 <br><br> 但随后出现一个问题-图片中的对象具有不同的大小。 相同的足球可以在图片的整个高度/宽度内，也可以在目标上很远，仅占1000个像素中的10-20像素。我想编写“蛮力”算法：我们只是循环浏览窗口的大小。 假设我们有100x200像素，那么我们将转到2x2、2X3、3x2、2x4、4x2、3x3窗口...，3x4、4x3 ... ，执行（100-W_window）*（200-H_window）分类操作，这需要很多时间。 恐怕我们不会等到这种算法起作用。 <br><br> 当然，您可以根据对象选择最具特色的窗口，但是它也可以工作很长时间，而且如果速度很快，就不太可能准确-在实际应用中，图像中对象的大小会发生疯狂的变化。 <br></div></div><br> 此外，我有时会依赖于<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">2019年1月对检测区域</a>进行的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">新审查</a> （图片也会来自此）。 如果您想快速了解检测中的DL，那么这只是必须阅读的内容。 <br><br> 有关使用CNN进行检测和定位的第一篇文章之一是<a href="">Overfeat</a> 。 作者声称，他们首先使用神经网络在ImageNet上进行检测，从而重新构造了问题并改变了损耗。 顺便说一下，这种方法几乎是端到端的（以下是Overfeat方案）。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/8o/5v/tv/8o5vtvhgukkn7frba0nx8yltfis.png" width="700"></div><br> 下一个重要的体系结构是<abbr>FAIR</abbr>的研究人员于2014年发明<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">的基于区域的卷积神经网络</a> （ <b>RCNN</b> ）。 其本质是，它首先预测了很多所谓的“感兴趣区域”（RoI），在其中可能存在对象（使用“选择性搜索”算法），然后将其分类并使用CNN来优化框的坐标。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2r/2p/kp/2r2pkpcoysglv4z_v-ll_y14mqw.png" width="700"></div><br> 没错，这样的管道会使整个系统变慢，因为我们通过神经网络运行了每个区域（我们确实进行了数千次前移）。 一年后，同一个FAIR Ross Girshick将RCNN升级为<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Fast-RCNN</a> 。 这里的想法是交换选择性搜索和网络预测：首先，将整个图片传递给经过预先训练的神经网络，然后我们在骨干网发布的特征图上预测感兴趣的区域（例如，使用相同的选择性搜索，但是还有<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">其他算法</a> ）。 它仍然相当慢，比实时要慢得多（就目前而言，我们假设每张图片的实时时间少于40毫秒）。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tn/uc/d-/tnucd-y6i7tr4edgjeudtrsj16u.png" width="700"></div><br> 速度受CNN的影响最大，但不受盒生成算法本身的影响，因此决定将其替换为第二个神经网络-区域提议网络（ <b>RPN</b> ），该网络将被训练以预测物体感兴趣的区域。 这就是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Faster-RCNN的出现方式</a> （是的，很明显他们很久没有想到这个名称了）。 方案： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6v/h_/ye/6vh_yee2zrsflyhh8jdvtm_bbgy.png" width="700"></div><br> 然后， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">R-FCN</a>的形式有了另一个改进，我们将不做详细讨论，但是我想提到<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Mask-RCNN</a> 。  Mask-RCNN是一个独特的神经网络，它是第一个同时解决<b>检测和实例分割问题的</b>神经网络-它预测边界框内对象的精确遮罩（轮廓）。 她的想法实际上很简单-有两个分支：用于检测和分段，您需要同时为这两项任务训练网络。 最主要的是要标记数据。  Mask-RCNN本身与Faster-RCNN非常相似：主干是相同的，但最后有两个<b>“头”</b> （通常称为神经网络的<b>最后一层</b> ）来完成两个不同的任务。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/7w/ig/hq/7wighq6ox7tptik5f_7d7cez2hg.png" width="700"></div><br> 这些就是所谓的<b>两阶段</b> （或<b>基于区域的</b> ）方法。 与之并行，在DL检测- <b>一阶段</b>法中开发了类似物。 这些包括神经网络，例如：单发检测器（SSD），一次只看一次（YOLO），深度监督对象检测器（DSOD），感受野块网络（RFBNet）以及许多其他神经网络（请参见下面的地图，来自<a href="">此存储库</a> ）。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ue/lc/-y/uelc-yeav4_avjdkycglf9uwrmm.png" width="750"></div><br> 与两阶段方法不同，一阶段方法不使用单独的算法来生成框，而只是为卷积神经网络生成的每个特征图预测几个框坐标。  YOLO的行为类似，SSD稍有不同，但思想是相同的：1x1卷积可从接收到的特征图预测深度上的许多数字，但是我们预先同意它的含义。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qj/ml/w_/qjmlw_ympdcib6jkpfdjdvcirdy.png" width="600"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jr/i3/oy/jri3oymb48sv5vq9dwwdxbndszg.png" width="600"></div><br> 例如，我们根据特征图预测大小为13x13x256的特征图为13x13x（4 *（5 + 80））个数字，在深度上我们预测4个盒子的85个数字：序列中的前4个数字始终是盒子的坐标，第5个-对拳击的信心和80个数字-每个类别（分类）的概率。 这是必要的，以便随后将必要的数字提交给必要的损失并正确地训练神经网络。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ao/xi/o2/aoxio2rty3hgpu2f8mduomvs9nu.png" width="800"></div><br> 我想提请注意以下事实：检测器的工作质量取决于提取特征（即<b>主干神经网络</b> ）的<b>神经网络的质量</b> 。 通常，此角色是由我在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">上一篇文章中</a>提到过的一种架构（ResNet，SENet等）扮演的，但有时作者会提出自己的最佳架构（例如YOLOv3中的Darknet-53）或修改（例如， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">功能金字塔池）</a> （FPN））。 <br><br> 同样，我注意到我们同时对网络进行分类和回归训练。 在社区中，这称为多任务损失：多个任务（具有某些系数）的损失总和显示为一个损失。 <br><br><div class="spoiler">  <b class="spoiler_title">领先的多任务损失新闻</b> <div class="spoiler_text"> 在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Machines Can See 2019上，</a>其中一位演讲者同时使用多任务丢失功能完成了7个任务<s>，卡尔</s> 。 事实证明，最初将某些任务设置为彼此抵消，并获得了“冲突”，这使得网络无法像单独训练每个任务那样学习得更好。 结论：如果您使用的是多任务丢失，请确保这些相同的多任务不会与语句冲突（例如，预测对象的边界及其内部分段可能会相互干扰，因为这些东西可能依赖于网络内部的不同符号）。 作者通过<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">为每个任务添加单独的“挤压和激励”块来</a>规避此问题。 <br></div></div><br> 最近，出现了2019年的文章，其中作者使用<b>基于点的盒子预测</b>在检测任务中声明了更高的速度/准确性比。 我正在谈论文章<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">“以点为对象”</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">“ CornerNet-Lite”</a> 。  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ExtremeNet</a>是CornerNet的修改。 看起来现在可以将它们称为使用神经网络进行检测的SOTA（但这并不准确）。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wk/qf/mr/wkqfmrenwm3u5f6c6bzinjcffga.png" width="900"></div><br> 如果突然我对探测器的解释仍然显得混乱而难以理解，那么在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">我们的视频中，</a>我会慢慢地讨论它。 也许您应该首先看到它。 <br><br> 下面我给出了用于检测的神经网络表，其中包含代码链接和每个网络芯片的简要说明。 我试图只收集那些真正重要的网络（至少是它们的想法），以便对当今的对象检测有一个好主意： <br><br><div class="spoiler">  <b class="spoiler_title">神经网络检测器（两阶段）</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th> 年份 </th><th> 文章 </th><th> 关键思想 </th><th> 代号 </th></tr><tr><td>  2013-2014 </td><td>  <a href="">神经网络</a> </td><td> 感兴趣区域的生成以及其中的类的神经网络预测 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">咖啡</a> </td></tr><tr><td>  2015年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">快速rcnn</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">首先将图片通过网络，然后生成感兴趣的区域</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">咖啡</a> </td></tr><tr><td>  2016年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Faster-rcnn</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">使用RPN生成感兴趣的区域</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">火炬</a> </td></tr><tr><td>  2016年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">流式网络</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">全卷积方法而不是生成感兴趣区域</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">咖啡</a> </td></tr><tr><td>  2017年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">遮罩</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">RoI-Align可同时解决两个任务的两个“负责人”</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TF凯拉斯</a> </td></tr><tr><td>  2019年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">推理</a> </td><td> 通过构造对象的语义关系图来提高RCNN的质量 </td><td>  --- </td></tr></tbody></table></div><br></div></div><br><br><div class="spoiler">  <b class="spoiler_title">神经网络检测器（一级）</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th> 年份 </th><th> 文章 </th><th> 关键思想 </th><th> 代号 </th></tr><tr><td>  2013-2014 </td><td>  <a href="">夸大其词</a> </td><td> 首批神经网络检测器之一 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">C ++（带有其他语言的包装器）</a> </td></tr><tr><td>  2015年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">固态硬盘</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">现在在许多应用中使用的非常灵活的一阶段方法</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">火炬</a> </td></tr><tr><td>  2015年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">尤洛</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">与SSD类似的想法正在并行发展，并且同样受欢迎（有新版本）</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">C ++</a> </td></tr><tr><td>  2016年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">YOLOv2（又名YOLO9000）</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">YOLO的许多改进</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">火炬</a> </td></tr><tr><td>  2017年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">YOLOv3</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">YOLOv2的许多改进</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">火炬</a> </td></tr><tr><td>  2017-2018 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">DSOD</a> </td><td> 深度监管理念和DenseNet理念 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">咖啡</a> </td></tr><tr><td>  2017-2018 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">射频网</a> </td><td> 根据人类视觉系统（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">RF</a>块）的结构巧妙地选择卷积滤波器 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">火炬</a> </td></tr></tbody></table></div><br></div></div><br><br><div class="spoiler">  <b class="spoiler_title">神经网络检测器（其他）</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th> 年份 </th><th> 文章 </th><th> 关键思想 </th><th> 代号 </th></tr><tr><td>  2018年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">视网膜网</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">解决特殊的焦点损失问题</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">凯拉斯</a> </td></tr><tr><td>  2014-2015 </td><td>  <a href="">SPP</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">模块，可让您有效处理不同尺寸的图像</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">凯拉斯</a> </td></tr><tr><td>  2016-2017 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">FPN</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">具有特征金字塔，可以更好地检测不同大小的物体</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">张量流</a> </td></tr><tr><td>  2019年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">NAS-FPN</a> </td><td> 通过神经架构搜索找到最佳的FPN </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">张量流</a> </td></tr><tr><td>  2019年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">代达罗斯</a> </td><td> 如何通过对抗攻击破坏探测器 </td><td>  --- </td></tr></tbody></table></div><br></div></div><br><br><div class="spoiler">  <b class="spoiler_title">神经网络检测器（基于点）</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th> 年份 </th><th> 文章 </th><th> 关键思想 </th><th> 代号 </th></tr><tr><td>  2019年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">中心网</a> </td><td> 一种新的检测方法，可以快速有效地解决同时发现点，盒子和3D盒子的问题 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">火炬</a> </td></tr><tr><td>  2019年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">角落网</a> </td><td> 基于对角点的盒子预测 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">火炬</a> </td></tr><tr><td>  2019年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">CornerNet-Lite</a> </td><td> 加速角网 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">火炬</a> </td></tr><tr><td>  2019年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">至尊网</a> </td><td> 预测对象的“极端”点（几何上精确的边界） </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">火炬</a> </td></tr></tbody></table></div><br></div></div><br> 为了了解每种架构的速度/质量之间的关系，您可以查看<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此评论</a>或其<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">更流行的版本</a> 。 <br><br> 架构很好，但检测主要是一项实际任务。  “没有一百个网络，但是至少有一个正在运行”-这是我的信息。 上表中有指向代码的链接，但是我个人很少遇到直接从存储库启动检测器的情况（至少是为了进一步部署到生产环境）。 通常，为此使用一个库，例如TensorFlow对象检测API（请参阅本<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">课程</a>的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">实际部分</a> ）或<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">来自中大研究人员</a>的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">库</a> 。 我提请您注意另一个超级表（您喜欢它们，对吗？）： <br><br><div class="spoiler">  <b class="spoiler_title">用于运行检测模型的库</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th> 职称 </th><th> 作者 </th><th> 内容描述 </th><th> 实施的神经网络 </th><th> 构架 </th></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">侦探</a> </td><td>  Facebook AI研究 </td><td> 具有各种模型代码的Facebook存储库，用于检测和评估姿势 </td><td> 所有地区 </td><td>  Caffe2 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TF对象检测API</a> </td><td>  TensorFlow团队 </td><td> 许多模型可供使用（已给出权重） </td><td> 所有基于区域的SSD和SSD（具有不同的主干） </td><td> 张量流 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">暗流</a> </td><td> 特里乌 </td><td> 即用型YOLO和YOLOv2实现 </td><td>  YOLOv3以外的所有YOLO类型（经过修改） </td><td> 张量流 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">毫米波检测</a> </td><td> 开设MMLab（香港中文大学） </td><td>  PyTorch上的大量检测器， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">请参阅他们的文章</a> </td><td> 除YOLO系列外，几乎所有型号 </td><td> 火炬 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">暗网（已修改）</a> </td><td> 亚历克斯 </td><td>  YOLOv3的便捷实现，对<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">原始存储库</a>进行了许多改进 </td><td>  YOLOv3 </td><td>  C ++ </td></tr></tbody></table></div><br></div></div><br> 通常，您只需要检测一个类别，但是特定且高度可变的对象。 例如，检测照片中的所有面孔（用于进一步验证/对人计数），检测整个人（用于重新识别/计数/跟踪）或检测场景中的文本（用于<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">OCR</a> /翻译照片中的单词）。 通常，此处的“常规”检测方法在一定程度上会起作用，但是这些子任务中的每一个都有其自己的技巧来提高质量。 <br><br><a name="2"></a><h2> 脸部侦测：未被发现-不是小偷 </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ic/ul/rp/iculrpbc7niyrdxg1yk_8r82nsw.jpeg" width="700"></div><br> 由于面部通常只占据图像的一小部分，因此此处会出现一些特殊性。 另外，人们并不总是看着相机，通常只有从侧面才能看到面部。 最早的人脸识别方法之一是2001年发明的基于Haar级联的著名的Viola-Jones检测器。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hc/tf/zn/hctfzn0xudbedi_aymhmlcwkamu.png" width="400"></div><br>  <s>那时的</s>神经网络<s>还不流行，</s>它们的视野还不那么强，但是，良好的旧手工方法就可以了。 几种类型的特殊滤镜已被积极使用，这有助于从图像及其符号中提取面部区域，然后将这些符号提交给AdaBoost分类器。 顺便说一句，这种方法确实可以正常工作，现在它足够快并且可以<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">使用OpenCV</a>开箱即<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">用</a> 。 该检测器的缺点是只能看到在摄像机前面展开的面部。 一个人只需要转一下就可以了，这破坏了检测的稳定性。 <br><br> 对于更复杂的情况，可以使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">dlib</a> 。 这是C ++-一个在其中实现许多视觉算法（包括用于面部检测）的库。 <br><br> 在人脸检测的神经网络方法中， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">多任务级联CNN（MTCNN）</a> （ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">MatLab</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TensorFlow</a> ）尤其重要。 通常，它现在已被积极使用（在同一<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">facenet中</a> ）。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/80/wn/vu/80wnvuf59poodmodzswcgjlyjt4.jpeg" width="400"></div><br>  MTCNN的想法是顺序使用三个神经网络（因此称为<b>“级联”</b> ）来预测面部的位置及其奇异点。 在这种情况下，脸上恰好有5个特殊点：左眼，右眼，嘴唇的左边缘，嘴唇和鼻子的右边缘。<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">来自级联的第一个神经网络（</font></font><abbr title="提案网"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">P-Net</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）用于生成人脸的潜在区域。</font><font style="vertical-align: inherit;">第二（</font></font><abbr title="细网"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R-Net</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）-改善接收框的坐标。</font><font style="vertical-align: inherit;">第三个（</font></font><abbr title="面部地标网"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O-Net</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）神经网络再次回归盒子的坐标，此外，还预测了面部的5个关键点。</font><font style="vertical-align: inherit;">该网络是多任务的，因为解决了三个任务：框点的回归，每个框的人脸/非人脸分类以及人脸点的回归。</font><font style="vertical-align: inherit;">此外，MTCNN实时完成所有操作，即每个图像所需的时间少于40毫秒。</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/5e/iz/d5/5eizd5lwag9umfo1ccypep42eik.jpeg" width="800"></div><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">如何，您仍然不自己阅读ArXiv的文章？</font></font></b> <div class="spoiler_text"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在这种情况下，</font><font style="vertical-align: inherit;">如果您已经在卷积网络中有了一些背景知识，那么</font><font style="vertical-align: inherit;">我建议您尝试阅读</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">有关MTCNN</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">的</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">原始文章</font></a><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">本文仅占</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5页</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，但列出了理解该方法所需的所有信息。</font><font style="vertical-align: inherit;">尝试一下，它会被延迟:)</font></font><br></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在现代技术中，可以注意到</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">双镜头面部检测器（DSFD）</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FaceBoxes</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">FaceBoxes具有在CPU（！）上快速启动的能力，而DSFD具有最佳质量（于2019年4月发布）。</font><font style="vertical-align: inherit;">DSFD比MTCNN更为复杂，因为在网络内部使用了一个用于改善特征的特殊模块（具有</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">扩展的卷积</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">），其处理的两个分支以及特殊类型的损耗。</font><font style="vertical-align: inherit;">顺便说一下，通过膨胀的卷积，我们将在下一部分有关分割的文章中多次遇到。</font><font style="vertical-align: inherit;">以下是DSFD的示例（令人印象深刻，不是吗？）。</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xv/or/it/xvoritceua0_ocjteyvm4xvisbq.jpeg"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">要学习如何</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">识别人</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">脸，请不要忘记阅读</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">本系列</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">的</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">上一篇文章</font></a><font style="vertical-align: inherit;">，我</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">在</font></a><font style="vertical-align: inherit;">其中进行了简要介绍。</font></font><br><br><a name="3"></a><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 许多字母：文本检测（和识别） </font></font></h2><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qn/v9/wo/qnv9woeqru3dioeennrkvalkjqg.png" width="500"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">注意上面的照片。</font><font style="vertical-align: inherit;">很容易看到，如果您预测平行于坐标轴的边界框（就像我们之前所做的那样），结果将是非常差的质量。</font><font style="vertical-align: inherit;">例如，如果我们要将这些框提交给识别神经网络的输入，这</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">将</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">非常关键，该输入</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">将根据图片预测文本</font></a><font style="vertical-align: inherit;">。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在这种情况下，通常会预测旋转的边界框，或者如果文本是弯曲的，则甚至将文本限制为多边形而不是矩形（以下示例）。</font><font style="vertical-align: inherit;">旋转箱子的预测例如由</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">EAST检测器处理</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/j3/hd/bj/j3hdbj-xozs4voec8ekiz4k1eo0.png" width="500"></div><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> EAST检测器的思想不是预测盒子角的坐标，而是预测以下三件事： </font></font><br><br><ol><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 文本分数图（在每个像素中查找文本的可能性） </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 每个盒子的旋转角度 </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 每个像素到矩形边框的距离 </font></font></li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">因此，这比检测更让人联想到分段（突出显示文本掩码）的任务。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arxiv文章的</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">解释性图片</font><font style="vertical-align: inherit;">：</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/dj/vt/uu/djvtuu36dzinoratlumncsgb5t8.png" width="700"></div><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">文本识别（及其检测）的任务非常流行，因此有类似的东西：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TextBoxes ++</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caffe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）和</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SegLinks</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，但是我认为EAST是最简单且负担得起的。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在检测到文本之后，我想立即将其提供给另一个神经网络以</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">识别</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">它并产生一个字符串。</font><font style="vertical-align: inherit;">在这里，您会注意到模态的一个有趣变化-从图像到文本。</font><font style="vertical-align: inherit;">您完全不必担心这一点，因为一切仅取决于网络体系结构，在最后一层上准确预测的内容以及所使用的损耗类型。</font><font style="vertical-align: inherit;">例如，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MORAN</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">PyTorch </font></a></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">代码</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）和</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ASTER</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TensorFlow代码）</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ）完全应付任务。 </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vt/ot/nc/vtotncz1d1zhhsiytuzmarta9ta.png" width="700"></div><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">它们没有什么超自然的东西，但是可以非常熟练地同时使用非常根本不同类型的神经网络：CNN和RNN。第一个用于从图片中提取特征，第二个用于生成文本。有关MORAN的示例的更多信息：下面是其识别网络的体系结构。</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hu/qx/_2/huqx_2jakjcggsgacvhj9a8vce4.png" width="300"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">但是，尽管EAST旋转了框，但可识别的网络仍会收到矩形图片，这意味着其中的文本可能会占据所有空间。为了使识别器更容易从图片中直接预测文本，您可以按某种方式进行转换。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们可以将</font></font><b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">仿射变换</font></font></a></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">应用于输入图像以拉伸/旋转文本。这可以使用</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">空间变换网络（STN）</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">来实现</font><font style="vertical-align: inherit;">，因为它可以独立学习这种变换并且可以轻松地集成到其他神经网络中（顺便说一下，您可以对任何图片进行对齐，而不仅仅是对文本进行对齐）。以下是STN之前/之后的示例。</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6y/z1/p9/6yz1p942ensgepwirqrtzpcnb7q.jpeg" width="700"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在这里详细讨论STN是没有意义的，因为</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在Habré上</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">有一篇很棒的</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">文章</font></a><font style="vertical-align: inherit;">（感谢作者，这张照片是从那里拍摄的）和</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PyTorch代码</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">但是MORAN（用于文本识别的同一个神经网络）甚至更智能-它不仅限于仿射变换族，而且可以预测输入图像每个像素的</font><font style="vertical-align: inherit;">x和y </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">位移图</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，从而实现任何可改善识别网络的学习的变换。</font><font style="vertical-align: inherit;">这种方法称为“ </font></font><i><abbr title="纠正，纠正"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">校正”</font></font></abbr></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，即使用辅助神经网络（</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">整流器</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）</font><font style="vertical-align: inherit;">校正图片</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">以下是亲和力转换后和校正后图像的比较：</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/n4/az/du/n4azduih5p7wd9sx-tqhpgy-p20.png" width="300"></div><br> 但是，除了“模块化”地进行文本识别的方法（检测网络-&gt;识别网络）外，还有一种端到端的体系结构：输入是图片，输出是检测并且在其中识别文本。 所有这一切都是一个单一的管道，可以同时学习两个任务。 在这个方向上，存在着令人印象深刻的工作，即<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">使用统一网络（ <b>FOTS</b> ）</a>进行<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">快速定向文本<b>点选</b> （ <b>PyTorch</b></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">代码</a> ），作者还注意到端到端方法的速度是“检测+识别”的两倍。 下面是FOTS神经网络图，RoiRotate块扮演着特殊的角色，因此有可能从网络“投射梯度”以在神经网络上进行识别以进行检测（这实际上比看起来复杂得多）。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/a5/xh/ch/a5xhchryrwf-zpfudielmab9pqu.png" width="800"></div><br> 顺便说一下，每年都<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">举行ICDAR</a>会议，并安排<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">了几场比赛</a>以识别各种图像中的文本。 <br><br><h3> 当前检测中的问题 </h3><br> 在我看来，现在检测中的主要问题不是检测器模型的质量，而是数据：它们通常很长且标记起来很昂贵，尤其是在需要检测许多类的情况下（顺便说一下，有<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">一个解决</a> 500个类<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">的示例</a> ）。 因此，现在有<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">许多作品</a>致力于“综合”生成最合理的数据并“免费”获得标记。 以下是<s>我</s> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">从Nvidia</a> <s>毕业的文凭的</s>照片<s>，该</s> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">文章</a>专门处理合成数据的生成。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6k/mn/wh/6kmnwhvc1pgahzwtjloa4dy9sbm.png" width="800"></div><br> 但仍然很高兴，现在我们可以确定在图片中的位置。 例如，如果我们要计算框架上的物体数量，则足以检测到该物体并给出箱子数量。 在检测人员方面，通常的YOLO效果也很好，只是主要的是提交大量数据。 相同的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Darkflow也是</a>合适的，并且在几乎所有主要检测数据集中都可以找到“人类”类。 因此，如果我们要使用摄像头来计算一天中路过的人数或某人在一家商店中拿走的商品数量，则只需检测并给出数量即可... <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/m2/ts/pl/m2tsplbgrnmoauvlghy8ivq2jdm.jpeg" width="700"></div><br> 停下 但是，如果我们要从相机中检测每个图像中的人物，则可以在一帧或两帧中计算他们的人数-不再，因为我们无法确切地说出哪个人在哪里。 我们需要一种算法，使我们能够计算视频流中的唯一身份用户。 它可能是一种<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">重新识别</a>算法，但在视频和检测方面，不使用跟踪算法是一个罪过。 <br><br><a name="4"></a><h3> 视频和跟踪：在单个流中 </h3><br> 到目前为止，我们仅谈论图片中的任务，但是最有趣的事情发生在视频上。 为了解决对动作的相同识别，我们不仅需要使用所谓的<i>空间</i>成分，还需要使用<i>时间</i>成分，因为视频是时间上的图像序列。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qm/da/pa/qmdapao0kcytnxhorj7htm6susy.jpeg" width="700"></div><br> 跟踪是图像检测的模拟，但用于视频。 也就是说，我们要教导网络预测的不是图片中的装箱，而是时间上的小轨迹（本质上是一系列箱子）。 以下是显示“尾巴”的图像示例-视频中这些人的踪迹。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xz/yv/c_/xzyvc_oumhrnf_-bmf8gz5l_hli.png" width="600"></div><br> 让我们考虑一下如何解决跟踪问题。 假设有一个视频及其第1帧和第2帧。 让我们考虑到目前为止，只有一个物体-我们跟踪一个球。 在第1帧，我们可以使用检测器进行检测。 在第二个上，我们还可以检测到一个球，如果单独存在，那么一切都很好：我们说前一帧的拳击与第2帧的拳击相同。 您还可以继续查看<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">pyimagesearch</a>视觉<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">课程</a> gif下方的其余帧。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_w/et/ak/_wetakdpybemefhert6cxslqaju.gif" width="600"></div><br> 顺便说一句，为了节省时间，我们无法在第二帧中启动神经网络，而只是从第一帧中“切出”球框，并在第二帧或逐像素中寻找完全相同的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">相关性</a> 。  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">相关跟踪器</a>利用这种方法，如果我们处理诸如“在空荡荡的房间中在摄像机前面跟踪一个球”这样的简单情况，它们就会被认为是简单的或差不多可靠的。 此任务也称为<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">可视对象跟踪</a> 。 以下是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">一个人的示例的</a>相关跟踪器<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">的工作</a>示例。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cv/fp/qd/cvfpqdd5ghelxfpucxrejxq6vpm.gif" width="600"></div><br> 但是，如果有多个检测/人，则需要能够匹配第1帧和第2帧中的框。 我想到的第一个想法是尝试将盒子与具有最大交叉区域（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">IoU</a> ）的盒子匹配。 的确，在多次检测重叠的情况下，这样的跟踪器将变得不稳定，因此您需要使用更多信息。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qx/i2/t1/qxi2t1ejpnir0h52ip-23zpf4ti.png" width="600"></div><br> 使用IoU的方法仅依赖于检测的<i>“几何”符号</i> ，也就是说，它只是尝试通过帧上的接近度来比较它们。 但是我们可以使用整个图像（在这种情况下甚至是两个），并且可以利用以下事实：在这些检测中有<i>“视觉”符号</i> 。 另外，我们还有每个人的检测历史，这使我们能够根据速度和运动方向更准确地预测他的下一个位置，这可以有条件地称为<i>“物理”标志</i> 。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mc/ay/se/mcaysee7xq25-j6hnvjalhfy5z0.gif" width="700"></div><br>  2016年， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Simple Online and Realtime Traker（SORT）</a> （ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Python代码</a> ）发布了首批完全可靠且能够应对困难情况的实时跟踪器之一。  SORT不使用任何视觉信号和神经网络，而仅估计每个框上每个框的许多参数：当前速度（分别为x和y）和大小（高度和宽度）。 框的长宽比始终是从该框的首次检测中得出的。 此外，使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">卡尔曼滤波器</a>预测速度（在信号处理领域中通常情况下它们很好并且很轻），通过IoU建立盒子的相交矩阵，并通过<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">匈牙利算法</a>分配检测结果。 <br><br> 如果在您看来数学已经变得很多，那么在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">本文中，</a>所有内容都将以<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">一种</a>易于使用的方式进行解释（这是中等:)。 <br><br> 早在2017年，SORT的一种修改就以<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">DeepSORT</a> （ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TensorFlow的代码</a> ）的形式发布了。  DeepSORT已经开始使用神经网络来提取视觉符号，并使用它们来解决冲突。 跟踪的质量不断提高-它被认为是当今最好的在线跟踪器之一。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/15/it/ny/15itnyht32oes3n-keaqk36jnpq.gif" width="800"></div><br> 跟踪领域的确在积极发展：有<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">具有暹罗神经网络的</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">跟踪器和具有RNN的跟踪器</a> 。 请随时注意，因为在任何一天，甚至可能会出现（甚至已经出现）更加准确，快速的架构。 顺便说一句，在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">PapersWithCode</a>上关注此类内容非常方便，始终有指向文章和代码的链接（如果有）。 <br><br><h3> 后记 </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jb/yh/bf/jbyhbf2ovu_ynurp_t_d9_hi4vg.jpeg" width="600"></div><br><br> 我们真的经历了很多，学到了很多。 但是计算机视觉是一个极其广阔的领域，我是一个非常固执的人。 这就是为什么我们会在本周期的第三篇文章中看到您（这是最后一篇？谁知道...），在那儿我们将更详细地讨论分段，姿势评估，视频动作识别以及使用神经网络从图像生成描述。 <br><br>  PS：我要特别感谢Vadim Gorbachev在编写本文和上一篇文章时提出的宝贵建议和意见。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN458190/">https://habr.com/ru/post/zh-CN458190/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN458176/index.html">exaflops障碍将在2021年克服</a></li>
<li><a href="../zh-CN458180/index.html">基于Kea的故障转移DHCP服务器</a></li>
<li><a href="../zh-CN458182/index.html">我们通过RSS阅读VKontakte</a></li>
<li><a href="../zh-CN458184/index.html">Haxe和PHP：静态输入，箭头功能，元编程等等</a></li>
<li><a href="../zh-CN458186/index.html">PostgreSQL中的WAL：1.缓冲区缓存</a></li>
<li><a href="../zh-CN458202/index.html">如果要在C ++项目中使用Actor或CSP，只需看一下SObjectizer</a></li>
<li><a href="../zh-CN458204/index.html">如何评估Linux上的存储性能：使用开放工具进行基准测试</a></li>
<li><a href="../zh-CN458206/index.html">Sublime Text 3用于网站布局。 自定义外观并安装插件。 初学者指南</a></li>
<li><a href="../zh-CN458208/index.html">7月1日至7月7日在莫斯科举行的数字活动</a></li>
<li><a href="../zh-CN458214/index.html">Pentest实验室的“ Pentestit测试实验室12”-全部通过</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
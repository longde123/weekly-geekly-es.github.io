<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèø‚Äçü§ù‚Äçüë®üèæ üë¶üèΩ üë®üèø‚Äçüíª JAVA SOUND API Conceptos b√°sicos üí≤ üçâ üåù</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola Habr! Le presento la traducci√≥n del art√≠culo "Sonido Java, Primeros pasos, Parte 1, Reproducci√≥n" . 

 Sonido en JAVA, Primera parte, El comienzo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>JAVA SOUND API Conceptos b√°sicos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/434424/">  Hola Habr!  Le presento la traducci√≥n del art√≠culo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Sonido Java, Primeros pasos, Parte 1, Reproducci√≥n"</a> . <br><br><h3>  Sonido en JAVA, Primera parte, El comienzo.  Reproducci√≥n de sonido </h3><br><iframe width="560" height="315" src="https://www.youtube.com/embed/1JZnj4eNHXE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Este es el comienzo de una serie de ocho lecciones que lo familiarizar√°n completamente con la API de Java Sound. <br><a name="habracut"></a><br>  ¬øQu√© es el sonido en la percepci√≥n humana?  Esta es la sensaci√≥n que experimentamos cuando un cambio en la presi√≥n del aire se transmite a las peque√±as √°reas sensoriales dentro de nuestros o√≠dos. <br><br>  Y el objetivo principal de crear la API de sonido es proporcionarle medios para escribir c√≥digo, lo que ayudar√° a transferir ondas de presi√≥n a los o√≠dos del sujeto correcto en el momento correcto. <br><br>  Tipos de sonido en Java: <br><br><ol><li>  La API de sonido Java admite dos tipos principales de audio (sonido). </li><li>  Sonido digitalizado y grabado directamente como un archivo </li><li>  Grabar como un archivo MIDI.  Muy distante, pero similar a la notaci√≥n musical, donde los instrumentos musicales se tocan en la secuencia deseada. </li></ol><br>  Estos tipos son bastante diferentes en su esencia y nos concentraremos en el primero, ya que en la mayor√≠a de los casos tratamos con sonido que necesita ser digitalizado para grabar desde una fuente externa a un archivo o viceversa para reproducir el sonido previamente grabado desde dicho archivo. <br><br><h3>  Vista previa </h3><br>  La API de Java Sound se basa en el concepto de <i>l√≠neas y mezcladores.</i> <br><br>  Siguiente: <br>  Describiremos las caracter√≠sticas f√≠sicas y el√©ctricas de la representaci√≥n anal√≥gica del sonido aplicada a un <i>mezclador de audio</i> . <br><br>  Pasaremos al escenario de la banda de rock inicial, que utiliza seis micr√≥fonos y dos altavoces est√©reo en este caso.  Necesitamos esto para comprender el funcionamiento del mezclador de audio. <br><br>  A continuaci√≥n, observamos una serie de temas de Java Sound para programaci√≥n, como l√≠neas, mezcladores, formatos para datos de audio y m√°s. <br><br>  Entenderemos las relaciones existentes entre los objetos SourceDataLine, Clip, Mixer, AudioFormat y crearemos un programa simple que reproduzca audio. <br><br>  A continuaci√≥n le damos un ejemplo de este programa, que puede usar para grabar y luego reproducir el sonido grabado. <br><br>  En el futuro, proporcionaremos una explicaci√≥n completa del c√≥digo del programa utilizado para este prop√≥sito.  Pero de ninguna manera completamente en esta lecci√≥n. <br><br><h3>  Ejemplo de c√≥digo y consideraci√≥n </h3><br>  <b>Caracter√≠sticas f√≠sicas y el√©ctricas del sonido anal√≥gico.</b> <br><br>  El prop√≥sito de nuestra lecci√≥n es presentarle los conceptos b√°sicos de la programaci√≥n Java utilizando la API de sonido Java. <br><br>  La API de sonido de Java se basa en el concepto de un mezclador de audio, que es un dispositivo com√∫nmente utilizado para reproducir sonido en casi cualquier lugar: desde conciertos de rock hasta escuchar CD en casa.  Pero antes de embarcarse en una explicaci√≥n detallada del funcionamiento del mezclador de audio, ser√° √∫til familiarizarse con las caracter√≠sticas f√≠sicas y el√©ctricas del sonido anal√≥gico. <br><br>  <i>Mira la fig.</i>  <i>1</i> <br><br><img src="https://habrastorage.org/webt/ez/tu/sq/eztusq7byax0l9nu-5r6vj3vkxe.gif"><br><br>  Vasya Pupyrkin empuja un discurso. <br><br>  Esta figura muestra a Vasya haciendo un discurso usando un sistema conocido como de direcci√≥n amplia.  Tal sistema t√≠picamente incluye un micr√≥fono, amplificador y altavoz.  El prop√≥sito de este sistema es fortalecer la voz de Vasya para que pueda ser escuchado incluso en una gran multitud. <br><br>  <b>Bamboleo en el aire</b> <br><br>  Brevemente, cuando Vasya habla, sus cuerdas vocales hacen que las part√≠culas de aire vibren en su laringe.  Esto conduce a la aparici√≥n de ondas de sonido, que, a su vez, hacen que la membrana del micr√≥fono vibre y luego se convierta en vibraciones el√©ctricas de muy peque√±a amplitud que simulan exactamente las vibraciones del sonido del original de Vasya.  Un amplificador, como su nombre lo indica, amplifica estas vibraciones el√©ctricas.  Luego llegan al altavoz, que realiza la conversi√≥n inversa de vibraciones el√©ctricas amplificadas en ondas de sonido muy amplificadas, pero que sin embargo repiten exactamente las mismas ondas generadas en las cuerdas vocales de Vasya Pupyrkin. <br><br>  <b>Micr√≥fono din√°mico</b> <br><br>  Ahora echemos un vistazo a la Fig.  2, que muestra un diagrama esquem√°tico de un micr√≥fono llamado din√°mico. <br><br><img src="https://habrastorage.org/webt/hz/1v/ui/hz1vui2-yqnq4cg3xdpi5iy-1w0.gif"><br>  <i>Fig.</i>  <i>2 circuito de micr√≥fono din√°mico</i> <br><br>  <b>Las vibraciones sonoras afectan la membrana.</b> <br><br>  La presi√≥n de las vibraciones sonoras act√∫a sobre una membrana flexible dentro del micr√≥fono.  Esto hace que la membrana vibre, mientras que las vibraciones de la membrana repiten las vibraciones de las ondas sonoras. <br><br>  <b>Bobina m√≥vil</b> <br><br>  Una bobina de alambre delgado est√° unida a la membrana del micr√≥fono.  A medida que la membrana oscila, la bobina tambi√©n hace movimientos alternativos en el campo magn√©tico del n√∫cleo hecho de un fuerte im√°n permanente.  Y como Faraday tambi√©n estableci√≥, surge una corriente el√©ctrica en la bobina. <br><br>  <b>Una se√±al el√©ctrica sigue la forma de las ondas sonoras.</b> <br><br>  Por lo tanto, a partir de una corriente muy d√©bil inducida en la bobina, se obtiene una se√±al el√©ctrica alterna, que repite la forma de ondas de sonido que act√∫an sobre la membrana del micr√≥fono.  Adem√°s, esta se√±al en forma de voltaje alterno se alimenta a la entrada del amplificador de la Fig.  1) <br><br>  <b>Altavoz</b> <br><br>  De hecho, el principio de funcionamiento del altavoz repite el dispositivo de un micr√≥fono din√°mico, solo encendido en la direcci√≥n opuesta.  <i>(Naturalmente, en este caso, los cables de bobinado son mucho m√°s gruesos y la membrana es mucho m√°s grande para garantizar el funcionamiento con una se√±al amplificada)</i> <i><br></i> <br><br><img src="https://habrastorage.org/webt/0e/ec/4x/0eec4xwyiyp2icsx69azgymv78c.gif"><br><br>  Las oscilaciones de la membrana del altavoz afectan las part√≠culas de aire y crean potentes ondas de sonido.  La forma de estas ondas repite exactamente la forma de las ondas sonoras de mucha menor intensidad creadas por las cuerdas vocales de Vasya.  Pero la intensidad de las nuevas olas ahora es suficiente para garantizar que las vibraciones de sonido de Vasya lleguen a los o√≠dos de las personas que se encuentran incluso en las filas traseras de una gran multitud. <br><br>  <b>Concierto de rock</b> <br><br>  En este momento, es posible que se pregunte, ¬øqu√© tiene que ver todo esto con la API de Java Sound?  Pero espere un poco m√°s, estamos abriendo el camino a los conceptos b√°sicos del mezclador de audio. <br><br>  El circuito descrito anteriormente era bastante simple.  Consist√≠a en Vasya Pupyrkin, un micr√≥fono, un amplificador y un altavoz.  Ahora considere el circuito con la Fig.  4, que presenta el escenario preparado para el concierto de rock del grupo musical principiante. <br><br><img src="https://habrastorage.org/webt/jh/zh/qo/jhzhqouio0xa25axcr164jch4du.gif"><br><br>  <b>Seis micr√≥fonos y dos altavoces.</b> <br><br>  En la fig.  4 seis micr√≥fonos se encuentran en el escenario.  Dos altavoces (altavoces) se encuentran a los lados del escenario.  Cuando comienza el concierto, los artistas cantan o tocan m√∫sica en cada uno de los seis micr√≥fonos.  En consecuencia, tendremos seis se√±ales el√©ctricas, que deben amplificarse individualmente y luego alimentarse a ambos altavoces.  Adem√°s de esto, los artistas pueden usar varios efectos especiales de sonido, por ejemplo, reverberaci√≥n, que tambi√©n deber√°n convertirse en se√±ales el√©ctricas antes de aplicarlos a los altavoces. <br><br>  Dos altavoces a los lados del escenario est√°n dise√±ados para crear el efecto del sonido est√©reo.  Es decir, la se√±al el√©ctrica que proviene del micr√≥fono ubicado en el escenario a la derecha debe caer en el altavoz ubicado tambi√©n a la derecha.  Del mismo modo, la se√±al del micr√≥fono a la izquierda se debe alimentar al altavoz ubicado a la izquierda de la escena.  Pero las se√±ales el√©ctricas de otros micr√≥fonos ubicados m√°s cerca del centro del escenario ya deber√≠an transmitirse a ambos altavoces en proporciones apropiadas.  Y dos micr√≥fonos justo en el centro deben transmitir su se√±al a ambos altavoces por igual. <br><br>  <b>Mezclador de audio</b> <br><br>  La tarea discutida anteriormente solo la realiza un dispositivo electr√≥nico llamado mezclador de audio. <br><br>  <b>L√≠nea de audio (canal)</b> <br><br>  Aunque el autor no es un experto en mezcladores de audio, en su humilde entendimiento, un mezclador de audio t√≠pico tiene la capacidad de recibir en la entrada un cierto n√∫mero de se√±ales el√©ctricas independientes entre s√≠, cada una de las cuales representa la se√±al o l√≠nea de audio original <i>(canal).</i> <br><br>  (El concepto de un canal de audio ser√° muy importante cuando comencemos a comprender la API de Java Sound en detalle. <br><br>  <b>Procesamiento independiente de cada canal de audio.</b> <br><br>  En cualquier caso, el mezclador de audio est√°ndar tiene la capacidad de amplificar cada l√≠nea de audio independientemente de los otros canales.  Adem√°s, el mezclador generalmente tiene la capacidad de imponer efectos especiales de sonido, como, por ejemplo, reverberaci√≥n a cualquiera de las l√≠neas de audio.  Al final, el mezclador, como su nombre lo indica, puede mezclar todas las se√±ales el√©ctricas individuales en los canales de salida como se establecer√°, para controlar la contribuci√≥n de cada l√≠nea de audio a los canales de salida. (Este control generalmente se llama pan o pan - distribuci√≥n en el espacio). <br><br>  <b>Volviendo al sonido est√©reo</b> <br><br>  Por lo tanto, en el diagrama con la Fig.  4, el ingeniero de sonido del mezclador de audio tiene la capacidad de combinar se√±ales de seis micr√≥fonos para obtener dos se√±ales de salida, cada una de las cuales se transmite a su altavoz. <br><br>  Para una operaci√≥n exitosa, la se√±al de cada micr√≥fono debe ser suministrada en la proporci√≥n apropiada, dependiendo de la ubicaci√≥n f√≠sica del micr√≥fono en el escenario.  (Al cambiar el panorama, un ingeniero de sonido calificado puede cambiar la contribuci√≥n de cada micr√≥fono si es necesario, si, por ejemplo, el vocalista principal se mueve por el escenario durante un concierto). <br><br>  <b>Es hora de volver al mundo de la programaci√≥n.</b> <br><br>  Regresemos ahora del mundo f√≠sico al mundo de la programaci√≥n.  Seg√∫n Sun: <i>‚ÄúJava Sound no implica ninguna configuraci√≥n de hardware especial;</i>  <i>Est√° dise√±ado para permitir que varios componentes de audio se instalen en el sistema y se pongan a disposici√≥n del usuario a trav√©s de la API.</i>  <i>Java Sound admite la funcionalidad de entrada y salida est√°ndar de una tarjeta de sonido (por ejemplo, para grabar y reproducir archivos de audio), as√≠ como la capacidad de mezclar m√∫ltiples transmisiones de audio "</i> <br><br>  <b>Mezcladores y canales</b> <br><br>  Como ya se mencion√≥, la API de Java Sound se basa en el concepto de mezcladores y canales.  Si te mueves del mundo f√≠sico al mundo de la programaci√≥n, entonces Sun escribe lo siguiente con respecto al mezclador: <br><br>  <i>‚ÄúUn mezclador es un dispositivo de audio con uno o m√°s canales.</i>  <i>Pero el mezclador que realmente mezcla la se√±al de audio debe tener varios canales de entrada de fuentes de origen y al menos un canal de salida de destino ".</i> <br><br>  Las l√≠neas de entrada pueden ser instancias de clases con objetos SourceDataLine, y las l√≠neas de salida pueden ser objetos TargetDataLine.  El mezclador tambi√©n puede recibir sonido pregrabado y en bucle como entrada, definiendo sus canales de fuente de entrada como instancias de objetos de clase que implementan la interfaz Clip. <br><br>  Interfaz de l√≠nea de canal. <br><br>  Sun informa lo siguiente desde la interfaz de l√≠nea: ‚ÄúLa <i>l√≠nea es un elemento de una tuber√≠a de audio digital, como un puerto de audio de entrada o salida, un mezclador o una ruta de audio hacia o desde un mezclador.</i>  <i>Los datos de audio que pasan por el canal pueden ser mono o multicanal (por ejemplo, est√©reo).</i>  <i>... Un canal puede tener controles, como ganancia, panorama y reverberaci√≥n ".</i> <br><br>  <b>Poniendo los t√©rminos juntos</b> <br><br>  Entonces, las citas anteriores de Sun denotan los siguientes t√©rminos <br><br>  Fuente de datos <br>  Targetgetataline <br>  Puerto <br>  Clip <br>  Controles <br><br>  <i>Fig.</i>  <i>5 muestra un ejemplo del uso de estos t√©rminos para construir un programa de salida de audio simple.</i> <br><br><img src="https://habrastorage.org/webt/e1/5r/gh/e15rghejgy0b2reeciyvircdvua.gif"><br><br>  <b>Guion de programa</b> <br><br>  Desde el punto de vista del software  5 muestra un objeto Mixer obtenido con un objeto Clip y dos objetos SourceDataLine. <br><br>  <b>¬øQu√© es el clip?</b> <br><br>  Clip es un objeto en la entrada del mezclador, cuyo contenido no cambia con el tiempo.  En otras palabras, carga los datos de audio en el objeto Clip antes de reproducirlo.  El contenido de audio del objeto Clip se puede reproducir una o m√°s veces.  Puede hacer un loopback del Clip y luego el contenido se reproducir√° una y otra vez. <br><br>  <b>Flujo de entrada</b> <br><br>  El objeto SourceDataLine, por otro lado, es un objeto continuo en la entrada del mezclador.  Un objeto de este tipo puede recibir un flujo de datos de audio y enviarlo al mezclador en tiempo real.  Los datos de audio necesarios se pueden obtener de varias fuentes, como archivos de audio, conexi√≥n de red o memoria intermedia. <br><br>  <b>Diferentes tipos de canales</b> <br><br>  Por lo tanto, los objetos Clip y SourceDataLine pueden considerarse como canales de entrada para el objeto Mixer.  Cada uno de estos canales de entrada puede tener los suyos: panor√°mica, ganancia y reverberaci√≥n. <br><br>  <b>Reproduce contenido de audio</b> <br><br>  En un sistema tan simple, Mixer lee datos de l√≠neas de entrada, usa el control para mezclar se√±ales de entrada y proporciona salida a uno o m√°s canales de salida, como un altavoz, salida de l√≠nea, conector para auriculares, etc. <br><br>  El Listado 11 muestra un programa simple que captura datos de audio de un puerto de micr√≥fono, almacena estos datos en la memoria y luego los reproduce a trav√©s del puerto del altavoz. <br><br>  Discutiremos solo la captura y reproducci√≥n.  La mayor parte del programa anterior es crear una ventana y una interfaz gr√°fica para el usuario para que sea posible controlar la grabaci√≥n y la reproducci√≥n.  No discutiremos esta parte como ir m√°s all√° de la meta.  Pero luego consideraremos la captura y reproducci√≥n de datos.  Discutiremos perder en esta lecci√≥n y capturaremos en la pr√≥xima.  En el camino, ilustraremos el uso del canal de audio con la API de sonido Java. <br><br>  Los datos capturados se almacenan en un objeto ByteArrayOutputStream. <br><br>  Un fragmento de c√≥digo proporciona la lectura de datos de audio de un micr√≥fono y su almacenamiento como un objeto ByteArrayOutputStream. <br><br>  El m√©todo, llamado playAudio, que comienza en el Listado 1, reproduce los datos de audio que fueron capturados y almacenados en el objeto ByteArrayOutputStream. <br><br><pre><code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">playAudio</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span> audioData[] = byteArrayOutputStream. toByteArray(); InputStream byteArrayInputStream = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ByteArrayInputStream( audioData);</code> </pre> <br>  <i>Listado 1</i> <br><br>  <b>Comenzamos con el c√≥digo est√°ndar.</b> <br><br>  El fragmento de programa en el Listado 1 en realidad a√∫n no est√° relacionado con Java Sound. <br><br>  Su prop√≥sito es: <br><br><ul><li>  Convierta datos previamente guardados en una matriz de tipo byte. </li><li>  Obtenga el flujo de entrada para una matriz de datos de bytes. </li></ul><br>  Necesitamos esto para que los datos de audio est√©n disponibles para su posterior reproducci√≥n. <br><br>  <b>Ir a la API de sonido</b> <br><br>  La l√≠nea de c√≥digo en el Listado 2 ya est√° relacionada con la API de Java Sound. <br><br><pre> <code class="java hljs"> AudioFormat audioFormat = getAudioFormat();</code> </pre><br>  <i>Listado 2</i> <br><br>  Aqu√≠ tocaremos brevemente el tema, que se discutir√° en detalle en la pr√≥xima lecci√≥n. <br><br>  <b>Dos formatos independientes</b> <br><br>  Muy a menudo estamos tratando con dos formatos independientes para datos de audio. <br><br>  Formato de archivo, (cualquiera) que contiene datos de audio (en nuestro programa a√∫n no lo est√°, ya que los datos se almacenan en la memoria) <br><br>  El formato de los datos de audio enviados es en s√≠ mismo. <br><br>  <b>¬øQu√© es un formato de audio?</b> <br><br>  Esto es lo que Sun escribe al respecto: <br><br>  <i>‚ÄúCada canal de datos tiene su propio formato de audio asociado con su flujo de datos.</i>  <i>El formato (una instancia de AudioFormat) determina el orden de bytes de la secuencia de audio.</i>  <i>Los par√°metros de formato pueden ser el n√∫mero de canales, la frecuencia de muestreo, el bit de cuantificaci√≥n, el m√©todo de codificaci√≥n, etc. Los m√©todos de codificaci√≥n habituales pueden ser la modulaci√≥n de c√≥digo de pulso lineal del PCM y sus variantes ".</i> <br><br>  <b>Secuencia de bytes</b> <br><br>  La fuente de datos de audio es una secuencia de bytes de datos binarios.  Hay varias opciones para organizar e interpretar esta secuencia.  No comenzaremos a tratar todas estas opciones en detalle, pero discutiremos un poco el formato de audio que usamos aqu√≠ en nuestro programa. <br><br>  <b>Peque√±a digresi√≥n</b> <br><br>  Aqu√≠ dejamos el m√©todo playAudio por ahora y miramos el m√©todo getAudioFormat del Listado 2. <br><br>  <i>El m√©todo completo getAudioFormat se muestra en el Listado 3.</i> <br><br><pre> <code class="java hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> AudioFormat </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getAudioFormat</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> sampleRate = <span class="hljs-number"><span class="hljs-number">8000.0F</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> sampleSizeInBits = <span class="hljs-number"><span class="hljs-number">16</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> channels = <span class="hljs-number"><span class="hljs-number">1</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">boolean</span></span> signed = <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">boolean</span></span> bigEndian = <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AudioFormat( sampleRate, sampleSizeInBits, channels, signed, bigEndian); }<span class="hljs-comment"><span class="hljs-comment">//end getAudioFormat</span></span></code> </pre><br>  <i>Listado 3</i> <br><br>  Adem√°s de declarar variables inicializadas, el c√≥digo en el Listado 3 contiene una expresi√≥n ejecutable. <br><br>  <b>AudioFormat Object</b> <br><br>  El m√©todo getAudioFormat crea y devuelve una instancia de un objeto de la clase AudioFormat.  Esto es lo que Sun escribe sobre esta clase: <br><br>  <i>‚ÄúLa clase AudioFormat define el orden espec√≠fico de los datos en una secuencia de audio.</i>  <i>Volviendo a los campos del objeto AudioFormat, puede obtener informaci√≥n sobre c√≥mo interpretar correctamente los bits en una secuencia de datos binarios ".</i> <br><br>  <b>Usamos el constructor m√°s simple.</b> <br><br>  La clase AudioFormat tiene dos tipos de constructores (tomaremos el m√°s trivial).  Los siguientes par√°metros son necesarios para este constructor: <br><br><ul><li>  Frecuencia de muestreo o frecuencia de muestreo por segundo (valores disponibles: 8000, 11025, 16000, 22050 y 44100 muestras por segundo) </li><li>  Profundidad de datos en bits (8 y 16 bits por conteo est√°n disponibles) </li><li>  N√∫mero de canales (un canal para mono y dos para est√©reo) </li><li>  Datos firmados o sin firmar que se utilizan en la secuencia (por ejemplo, el valor var√≠a de 0 a 255 o de -127 a +127) </li><li>  El orden de bytes de Big-endian o little-endian.  (si est√° transmitiendo una secuencia de bytes de valores de 16 bits, es importante saber qu√© byte viene primero, bajo o alto, ya que hay ambas opciones). </li></ul><br>  Como puede ver en el Listado 3, en nuestro caso, utilizamos los siguientes par√°metros para una instancia del objeto AudioFormat. <br><br><ul><li>  8000 muestras por segundo </li><li>  16 tama√±o de datos </li><li>  datos significativos </li><li>  Orden little-endian </li></ul><br>  Por defecto, los datos est√°n codificados por PCM lineal. <br><br>  El constructor que utilizamos crea una instancia del objeto AudioFormat usando la modulaci√≥n de c√≥digo de pulso lineal y los par√°metros indicados anteriormente (Volveremos a PCM lineal y otros m√©todos de codificaci√≥n en las siguientes lecciones) <br><br>  <b>Volver al m√©todo playAudio nuevamente</b> <br><br>  Ahora que entendemos c√≥mo funciona el formato de datos de audio en el sonido Java, volvamos al m√©todo playAudio.  Tan pronto como queramos reproducir los datos de audio disponibles, necesitamos un objeto de la clase AudioInputStream.  Obtenemos una instancia de esto en el Listado 4. <br><br><pre> <code class="java hljs"> audioInputStream = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AudioInputStream( byteArrayInputStream, audioFormat, audioData.length/audioFormat. getFrameSize());</code> </pre><br>  <i>Listado 4</i> <br><br>  <b>Par√°metros para el constructor AudioInputStream</b> <br><br><ul><li>  El constructor para la clase AudioInputStream requiere los siguientes tres par√°metros: </li><li>  La secuencia en la que se basar√° la instancia del objeto AudioInputStream (como vemos para este prop√≥sito, usamos la instancia del objeto ByteArrayInputStream creado anteriormente) </li><li>  El formato de datos de audio para esta secuencia (para este fin ya hemos creado una instancia del objeto AudioFormat) </li><li>  El tama√±o del marco (marco) para los datos en esta secuencia (consulte la descripci√≥n a continuaci√≥n) </li><li>  Los primeros dos par√°metros son claros del c√≥digo en el Listado 4. Sin embargo, el tercer par√°metro no es tan obvio en s√≠ mismo. </li></ul><br>  <b>Obtener tama√±o de cuadro</b> <br><br>  Como podemos ver en el Listado 4, el valor del tercer par√°metro se crea usando c√°lculos.  Este es solo uno de los atributos del formato de audio que no hemos mencionado antes, y se llama marco. <br><br>  <b>¬øQu√© es un marco?</b> <br><br>  Para un PCM lineal simple utilizado en nuestro programa, el marco contiene un conjunto de muestras para todos los canales en un momento dado. <br><br>  Por lo tanto, el tama√±o de la trama es igual al tama√±o del recuento en bytes multiplicado por el n√∫mero de canales. <br><br>  Como habr√°s adivinado, un m√©todo llamado getFrameSize devuelve el tama√±o del cuadro en bytes. <br><br>  <b>C√°lculo del tama√±o del marco</b> <br><br>  Por lo tanto, la longitud de los datos de audio en un cuadro puede calcularse dividiendo el n√∫mero total de bytes en la secuencia de datos de audio por el n√∫mero de bytes en un cuadro.  Este c√°lculo se usa para el tercer par√°metro en el Listado 4. <br><br>  <b>Obteniendo un objeto SourceDataLine</b> <br><br>  La siguiente parte del programa que discutiremos es un sistema de salida de audio simple.  Como podemos ver en el diagrama de la Fig. 5, para resolver este problema, necesitamos un objeto SourceDataLine. <br><br>  Hay varias formas de obtener una instancia del objeto SourceDataLine, todas las cuales son muy complicadas.  El c√≥digo en el Listado 5 recupera y almacena una referencia a una instancia del objeto SourceDataLine. <br><br>  (Tenga en cuenta que este c√≥digo no solo crea una instancia del objeto SourceDataLine. Lo obtiene de una manera indirecta). <br><br><pre> <code class="java hljs"> DataLine.Info dataLineInfo = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> DataLine.Info( SourceDataLine.class, audioFormat); sourceDataLine = (SourceDataLine) AudioSystem.getLine( dataLineInfo);</code> </pre><br>  <i>Listado 5</i> <br><br>  ¬øQu√© es un objeto SourceDataLine? <br><br>  Sobre esto, Sun escribe lo siguiente: <br><br>  <i>‚ÄúSourceDataLine es un canal de datos en el que se pueden escribir datos.</i>  <i>Funciona como una entrada para un mezclador.</i>  <i>Una aplicaci√≥n escribe una secuencia de bytes en una SourceDataLine, que almacena los datos y los entrega a su mezclador.</i>  <i>El mezclador puede transmitir los datos que procesa para la siguiente etapa, por ejemplo, al puerto de salida.</i> <i><br><br></i>  <i>Tenga en cuenta que la convenci√≥n de nomenclatura para este emparejamiento refleja la relaci√≥n entre el canal y su mezclador ".</i> <br><br>  <b>M√©todo GetLine para la clase AudioSystem</b> <br><br>  Una de las formas de obtener una instancia del objeto SourceDataLine es llamar al m√©todo getLine est√°tico desde la clase AudioSystem (Tendremos mucho que informar sobre ello en las pr√≥ximas lecciones). <br><br>  El m√©todo getLine requiere un par√°metro de entrada de tipo Line.Info y devuelve un objeto Line que coincide con la descripci√≥n en el objeto Line.Info ya definido. <br><br>  <b>Otra breve digresi√≥n</b> <br><br>  Sun informa la siguiente informaci√≥n sobre el objeto Line.Info: <br><br>  ‚ÄúEl canal tiene su propio objeto de informaci√≥n (una instancia de Line.Info), que muestra qu√© mezclador (si lo hay) env√≠a los datos de audio mezclados como salida directamente al canal, y qu√© mezclador (si lo hay) recibe los datos de audio como entrada directamente desde el canal.  Las variedades de l√≠nea pueden corresponder a subclases de Line.Info, que le permite especificar otros tipos de par√°metros relacionados con tipos espec√≠ficos de canales " <br><br>  <b>DataLine.Info Object</b> <br><br>  La primera expresi√≥n en el Listado 5 crea una nueva instancia del objeto DataLine.Info, que es una forma especial (subclase) del objeto Line.Info. <br><br>  Hay varios constructores sobrecargados para la clase DataLine.Info.  Hemos elegido el m√°s f√°cil de usar.  Este constructor requiere dos par√°metros. <br><br>  <b>Objeto de clase</b> <br><br>  El primer par√°metro es Class, que representa la clase que definimos como SourceDataLine.class <br><br>  El segundo par√°metro determina el formato de datos deseado para el canal.  Usamos una instancia del objeto AudioFormat para √©l, que ya se ha definido anteriormente. <br><br>  <b>Donde ya estamos</b> <br><br>  Desafortunadamente, todav√≠a no tenemos el objeto SourceDataLine m√°s requerido.  Hasta ahora, tenemos un objeto que solo proporciona informaci√≥n sobre el objeto SourceDataLine que necesitamos. <br><br>  <b>Obteniendo un objeto SourceDataLine</b> <br><br>  La segunda expresi√≥n en el Listado 5 finalmente crea y almacena la instancia de SourceDataLine que necesitamos.  Esto sucede llamando al m√©todo est√°tico getLine de la clase AudioSystem y pasando dataLineInfo como par√°metro.  (En la pr√≥xima lecci√≥n, veremos c√≥mo obtener el objeto Line, trabajando directamente con el objeto Mixer). <br><br>  El m√©todo getLine devuelve una referencia a un objeto de tipo Line, que es el padre de SourceDataLine.  Por lo tanto, se requiere un downcast aqu√≠ antes de que el valor de retorno se guarde como SourceDataLine. <br><br>  <b>Prepar√©monos para usar el objeto SourceDataLine</b> <br><br>  Una vez que obtengamos una instancia del objeto SourceDataLine, debemos prepararlo para abrirlo y ejecutarlo, como se muestra en el Listado 6. <br><br><pre> <code class="java hljs"> sourceDataLine.open(audioFormat); sourceDataLine.start();</code> </pre><br>  <i>Listado 6</i> <br><br>  <b>M√©todo de apertura</b> <br><br>  Como puede ver en el Listado 6, enviamos el objeto AudioFormat al m√©todo de apertura para el objeto SourceDataLine. <br><br>  Seg√∫n Sun, este es un m√©todo: <br><br>  <i>"Abre una l√≠nea (canal) con un formato previamente definido, lo que le permite recibir los recursos del sistema que necesita y estar en condiciones de trabajo".</i> <br><br>  <b>Estado de descubrimiento</b> <br><br>  Hay poco m√°s que Sun escribe sobre √©l en este hilo. <br><br>  <i>‚ÄúAbrir y cerrar el canal afecta la distribuci√≥n de los recursos del sistema.</i>  <i>La apertura exitosa del canal asegura que todos los recursos necesarios se proporcionen al canal.</i> <i><br><br></i>  <i>La apertura del mezclador, que tiene sus puertos de entrada y salida para datos de audio, incluye, entre otras cosas, el uso del hardware de la plataforma en la que se lleva a cabo el trabajo y la inicializaci√≥n de los componentes de software necesarios.</i> <i><br><br></i>  <i>Abrir un canal, que es una ruta para datos de audio hacia o desde un mezclador, incluye inicializarlo y recibir de ninguna manera recursos ilimitados del mezclador.</i>  <i>En otras palabras, el mezclador tiene un n√∫mero finito de canales, por lo que varias aplicaciones con sus propias necesidades de canal (e incluso a veces una aplicaci√≥n) deben compartir correctamente los recursos del mezclador) "</i> <br><br>  <b>Llamar al m√©todo de inicio en un canal</b> <br><br>  Seg√∫n Sun, llamar al m√©todo de inicio de un canal significa lo siguiente: <br><br>  <i>‚ÄúEl canal puede usar l√≠neas de E / S.</i>  <i>Si se intenta utilizar una l√≠nea ya operativa, el m√©todo no hace nada.</i>  <i>Pero despu√©s de que el b√∫fer de datos est√© vac√≠o, la l√≠nea reanuda el inicio de E / S, comenzando con el primer fotograma que no logr√≥ procesar despu√©s de que el b√∫fer se haya cargado por completo ".</i> <br><br>  En nuestro caso, por supuesto, el canal no se detuvo.  Desde que lo lanzamos por primera vez. <br><br>  <b>Ahora tenemos casi todo lo que necesitamos.</b> <br><br>  En este punto, hemos recibido todos los recursos de audio que necesitamos para reproducir los datos de audio que previamente hemos grabado y almacenado en una instancia del objeto ByteArrayOutputStream.  (Recuerde que este objeto solo existe en la RAM de la computadora). <br><br>  <b>Comenzamos flujos</b> <br><br>  Crearemos e iniciaremos la transmisi√≥n para reproducir el audio.  El c√≥digo en el Listado 7 crea e inicia este hilo. <br><br>  (No confunda la llamada al m√©todo de inicio en este hilo con la llamada al m√©todo de inicio en el objeto SourceDataLine del Listado 6. Estas son operaciones completamente diferentes) <br><br><pre> <code class="java hljs">Thread playThread = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Thread(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> PlayThread()); playThread.start(); } <span class="hljs-keyword"><span class="hljs-keyword">catch</span></span> (Exception e) { System.out.println(e); System.exit(<span class="hljs-number"><span class="hljs-number">0</span></span>); }<span class="hljs-comment"><span class="hljs-comment">//end catch }//end playAudio</span></span></code> </pre><br>  <i>Listado 7</i> <br><br>  <b>C√≥digo sin pretensiones</b> <br><br>  El fragmento del programa en el Listado 7, aunque es muy simple, muestra un ejemplo de programaci√≥n multiproceso en Java.  Si no lo comprende, debe familiarizarse con este tema en temas especializados para aprender Java. <br><br>  Una vez que se inicia la transmisi√≥n, funcionar√° hasta que todos los datos de audio pregrabados se hayan reproducido hasta el final. <br><br>  <b>Nuevo objeto de hilo</b> <br><br>  El c√≥digo en el Listado 7 crea una instancia del objeto Thread de la clase PlayThread.  Esta clase se define como una clase interna en nuestro programa.  Su descripci√≥n comienza en el Listado 8. <br><br><pre> <code class="java hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PlayThread</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Thread</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span> tempBuffer[] = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[<span class="hljs-number"><span class="hljs-number">10000</span></span>];</code> </pre><br>  <i>Listado 8</i> <br><br>  <b>El m√©todo de ejecuci√≥n en la clase Thread</b> <br><br>  Excepto por declarar una variable tempBuffer (que se refiere a una matriz de bytes), una definici√≥n completa de esta clase es solo una definici√≥n del m√©todo de ejecuci√≥n.  Como ya deber√≠a saber, llamar al m√©todo de inicio en un objeto Thread hace que se ejecute el m√©todo de ejecuci√≥n de este objeto <br><br>  El m√©todo de ejecuci√≥n para este hilo comienza en el Listado 9. <br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">run</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> cnt; <span class="hljs-comment"><span class="hljs-comment">//  //    -1 // while((cnt = audioInputStream. read(tempBuffer, 0, tempBuffer.length)) != -1){ if(cnt &gt; 0){ //   //    //    //   . sourceDataLine.write( tempBuffer, 0, cnt); }//end if }//end while</span></span></code> </pre><br>  <i>Listado 9</i> <br><br>  <b>La primera parte del fragmento de programa en el m√©todo de ejecuci√≥n.</b> <br><br>  El m√©todo de ejecuci√≥n contiene dos partes importantes, la primera de las cuales se muestra en el Listado 9. <br><br>  En resumen, aqu√≠ se usa un bucle para leer datos de audio de AudioInputStream y pasarlos a SourceDataLine. <br><br>  Los datos enviados al objeto SourceDataLine se transfieren autom√°ticamente a la salida de audio predeterminada.  Puede ser un altavoz de computadora incorporado o una salida de l√≠nea.  (Aprenderemos a determinar los dispositivos de sonido necesarios en las siguientes lecciones).  La variable cnt y el b√∫fer de datos tempBuffer se utilizan para controlar el flujo de datos entre las operaciones de lectura y escritura. <br><br>  <b>Lectura de datos de AudioInputStream</b> <br><br>  El ciclo de lectura del objeto AudioInputStream lee el n√∫mero m√°ximo especificado de bytes de datos del AudioInputStream y coloca su matriz de bytes. <br><br>  <b>Valor de retorno</b> <br><br>  Adem√°s, este m√©todo devuelve el n√∫mero total de bytes le√≠dos, o -1, si se alcanz√≥ el final de la secuencia registrada.  El n√∫mero de bytes le√≠dos se almacena en la variable cnt. <br><br>  <b>Bucle de escritura SourceDataLine</b> <br><br>  Si el n√∫mero de bytes le√≠dos es mayor que cero, entonces hay una transici√≥n al ciclo de escritura de datos en SourceDataLine.  En este bucle, los datos de audio ingresan al mezclador.  Los bytes se leen de la matriz de bytes de acuerdo con sus √≠ndices y se escriben en el b√∫fer del canal. <br><br>  <b>Cuando la secuencia de entrada se seca</b> <br><br>  Cuando el ciclo de lectura devuelve -1, esto significa que todos los datos de audio previamente grabados han finalizado y se pasa m√°s control al fragmento de programa en el Listado 10. <br><br><pre> <code class="java hljs"> sourceDataLine.drain(); sourceDataLine.close(); }<span class="hljs-keyword"><span class="hljs-keyword">catch</span></span> (Exception e) { System.out.println(e); System.exit(<span class="hljs-number"><span class="hljs-number">0</span></span>); }<span class="hljs-comment"><span class="hljs-comment">//end catch }//end run }//   PlayThread</span></span></code> </pre><br>  <i>Listado 10</i> <br><br>  <b>Bloquear y esperar</b> <br><br>  El c√≥digo en el Listado 10 llama al m√©todo de drenaje en el objeto SourceDataLine para que el programa pueda bloquear y esperar a que el b√∫fer interno se vac√≠e en SourceDataLine.  Cuando el b√∫fer est√° vac√≠o, significa que toda la siguiente porci√≥n se entrega a la salida de sonido de la computadora. <br><br>  <b>Cerrando SourceDataLine</b> <br><br>  Luego, el programa llama al m√©todo de cierre para cerrar el canal, lo que muestra que todos los recursos del sistema utilizados por el canal ahora son libres.  Sun informa el siguiente cierre del canal: <br><br>  <i>‚ÄúCerrar el canal indica que todos los recursos involucrados para este canal pueden ser liberados.</i>  <i>Para liberar recursos, la aplicaci√≥n debe cerrar los canales, ya est√©n involucrados o no, as√≠ como cu√°ndo finaliza la aplicaci√≥n.</i>  <i>Se supone que los mezcladores comparten recursos del sistema y pueden cerrarse y abrirse repetidamente.</i>  <i>Otros canales pueden o no admitir la reapertura despu√©s de que se hayan cerrado.</i>  <i>En general, los mecanismos para abrir l√≠neas var√≠an seg√∫n los diferentes subtipos ".</i> <br><br>  <b>Y ahora el final de la historia.</b> <br><br>  As√≠ que aqu√≠ explicamos c√≥mo nuestro programa usa la API de sonido Java para garantizar la entrega de datos de audio desde la memoria interna de la computadora a la tarjeta de sonido. <br><br>  <b>Ejecuta el programa</b> <br><br>  Ahora puede compilar y ejecutar el programa desde el Listado 11, que corona el final de nuestra lecci√≥n. <br><br>  <b>Captura y reproduce datos de audio</b> <br><br>  El programa demuestra la capacidad de grabar datos desde un micr√≥fono y reproducirlos a trav√©s de la tarjeta de sonido de su computadora.  Las instrucciones para usarlo son muy simples. <br><br>  Ejecute el programa  La simple GUI GUI, que se muestra en la Figura 6, deber√≠a aparecer en la pantalla. <br><br><img src="https://habrastorage.org/webt/lf/7l/ew/lf7lew65yqcqstjqvdvmptmhevy.gif"><br><br><ul><li>  Haga clic en el bot√≥n Capturar y grabe cualquier sonido en el micr√≥fono. </li><li>  Haga clic en el bot√≥n Detener para detener la grabaci√≥n. </li><li>  Haga clic en el bot√≥n Reproducci√≥n para reproducir la grabaci√≥n a trav√©s de la salida de sonido de su computadora. </li></ul><br>  Si no escucha nada, intente aumentar la sensibilidad del micr√≥fono o el volumen del altavoz. <br><br>  El programa guarda un registro en la memoria de la computadora, as√≠ que tenga cuidado.  Si intenta guardar demasiados datos de audio, puede quedarse sin RAM. <br><br>  <b>Conclusi√≥n</b> <br><br><ul><li>  Descubrimos que la API de Java Sound se basa en el concepto de canales y mezcladores. </li><li>  Obtuvimos la informaci√≥n inicial sobre las caracter√≠sticas f√≠sicas y el√©ctricas del sonido anal√≥gico, para luego entender el dispositivo del mezclador de audio. </li><li>  Utilizamos un escenario de concierto de rock amateur con seis micr√≥fonos y dos altavoces est√©reo para describir la posibilidad de usar un mezclador de audio. </li><li>  Discutimos una serie de temas de programaci√≥n de Java Sound, incluidos mezcladores, canales, formato de datos y m√°s. </li><li>  Explicamos la relaci√≥n general entre los objetos SourceDataLine, Clip, Mixer, AudioFormat y los puertos en un programa simple para generar datos de audio. </li><li>  Nos familiarizamos con un programa que nos permite grabar inicialmente y luego reproducir datos de audio. </li><li>  Recibimos una explicaci√≥n detallada del c√≥digo utilizado para reproducir datos de audio grabados previamente en la memoria de la computadora. </li></ul><br>  <b>Que sigue</b> <br><br>  En este tutorial, descubrimos que la API de Java Sound se basa en el concepto de mezcladores y canales.  Sin embargo, el c√≥digo que discutimos no inclu√≠a mezcladores expl√≠citamente.  La clase AudioSystem nos proporcion√≥ m√©todos est√°ticos que hacen posible escribir programas de procesamiento de audio sin acceder directamente a los mezcladores.  En otras palabras, estos m√©todos est√°ticos nos quitan los mezcladores. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En la pr√≥xima lecci√≥n, presentamos un c√≥digo de captura de datos modificado en comparaci√≥n con el presentado en esta lecci√≥n. </font><font style="vertical-align: inherit;">La nueva versi√≥n usar√° expl√≠citamente mezcladores para mostrarle c√≥mo usarlos cuando realmente los necesite.</font></font><br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> javax.swing.*; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.awt.*; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.awt.event.*; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.io.*; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> javax.sound.sampled.*; <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AudioCapture01</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">JFrame</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">boolean</span></span> stopCapture = <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>; ByteArrayOutputStream byteArrayOutputStream; AudioFormat audioFormat; TargetDataLine targetDataLine; AudioInputStream audioInputStream; SourceDataLine sourceDataLine; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( String args[])</span></span></span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AudioCapture01(); }<span class="hljs-comment"><span class="hljs-comment">//end main public AudioCapture01(){ final JButton captureBtn = new JButton("Capture"); final JButton stopBtn = new JButton("Stop"); final JButton playBtn = new JButton("Playback"); captureBtn.setEnabled(true); stopBtn.setEnabled(false); playBtn.setEnabled(false); captureBtn.addActionListener( new ActionListener(){ public void actionPerformed( ActionEvent e){ captureBtn.setEnabled(false); stopBtn.setEnabled(true); playBtn.setEnabled(false); //  //   //   Stop captureAudio(); } } ); getContentPane().add(captureBtn); stopBtn.addActionListener( new ActionListener(){ public void actionPerformed( ActionEvent e){ captureBtn.setEnabled(true); stopBtn.setEnabled(false); playBtn.setEnabled(true); //  //    stopCapture = true; } } ); getContentPane().add(stopBtn); playBtn.addActionListener( new ActionListener(){ public void actionPerformed( ActionEvent e){ //  //    playAudio(); } } ); getContentPane().add(playBtn); getContentPane().setLayout( new FlowLayout()); setTitle("Capture/Playback Demo"); setDefaultCloseOperation( EXIT_ON_CLOSE); setSize(250,70); setVisible(true); } //    //     //   ByteArrayOutputStream private void captureAudio(){ try{ //    audioFormat = getAudioFormat(); DataLine.Info dataLineInfo = new DataLine.Info( TargetDataLine.class, audioFormat); targetDataLine = (TargetDataLine) AudioSystem.getLine( dataLineInfo); targetDataLine.open(audioFormat); targetDataLine.start(); //     //    //   //    Thread captureThread = new Thread( new CaptureThread()); captureThread.start(); } catch (Exception e) { System.out.println(e); System.exit(0); } } //    // ,    //  ByteArrayOutputStream private void playAudio() { try{ //  //  byte audioData[] = byteArrayOutputStream. toByteArray(); InputStream byteArrayInputStream = new ByteArrayInputStream( audioData); AudioFormat audioFormat = getAudioFormat(); audioInputStream = new AudioInputStream( byteArrayInputStream, audioFormat, audioData.length/audioFormat. getFrameSize()); DataLine.Info dataLineInfo = new DataLine.Info( SourceDataLine.class, audioFormat); sourceDataLine = (SourceDataLine) AudioSystem.getLine( dataLineInfo); sourceDataLine.open(audioFormat); sourceDataLine.start(); //    //     //     //      Thread playThread = new Thread(new PlayThread()); playThread.start(); } catch (Exception e) { System.out.println(e); System.exit(0); } } //     //  AudioFormat private AudioFormat getAudioFormat(){ float sampleRate = 8000.0F; //8000,11025,16000,22050,44100 int sampleSizeInBits = 16; //8,16 int channels = 1; //1,2 boolean signed = true; //true,false boolean bigEndian = false; //true,false return new AudioFormat( sampleRate, sampleSizeInBits, channels, signed, bigEndian); } //===================================// //    //    class CaptureThread extends Thread{ byte tempBuffer[] = new byte[10000]; public void run(){ byteArrayOutputStream = new ByteArrayOutputStream(); stopCapture = false; try{ while(!stopCapture){ int cnt = targetDataLine.read( tempBuffer, 0, tempBuffer.length); if(cnt &gt; 0){ //     byteArrayOutputStream.write( tempBuffer, 0, cnt); } } byteArrayOutputStream.close(); }catch (Exception e) { System.out.println(e); System.exit(0); } } } //===================================// //   //     class PlayThread extends Thread{ byte tempBuffer[] = new byte[10000]; public void run(){ try{ int cnt; //     -1 while((cnt = audioInputStream. read(tempBuffer, 0, tempBuffer.length)) != -1){ if(cnt &gt; 0){ //    //   //    //    sourceDataLine.write( tempBuffer, 0, cnt); } } sourceDataLine.drain(); sourceDataLine.close(); }catch (Exception e) { System.out.println(e); System.exit(0); } } } //===================================// }//end outer class AudioCapture01.java</span></span></code> </pre><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Listado 11</font></font></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es434424/">https://habr.com/ru/post/es434424/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es434412/index.html">Retirada de cohetes antes del lanzamiento en Vostochny</a></li>
<li><a href="../es434414/index.html">Iceberg</a></li>
<li><a href="../es434416/index.html">Leer en vacaciones. Las mejores publicaciones en nuestro blog para 2018</a></li>
<li><a href="../es434418/index.html">M√°s r√°pido, m√°s fuerte, m√°s brillante: la f√≠sica del apareamiento de los colibr√≠es "bailando"</a></li>
<li><a href="../es434422/index.html">Cosas no rentables</a></li>
<li><a href="../es434426/index.html">Lista de verificaci√≥n: c√≥mo presentar informes sobre el sistema tributario simplificado para 2018</a></li>
<li><a href="../es434428/index.html">Montamos, reparamos y usamos un reloj digital vintage</a></li>
<li><a href="../es434430/index.html">IBM mostr√≥ un chip de memoria anal√≥gica de cambio de fase de 8 bits</a></li>
<li><a href="../es434440/index.html">[Video] Barcos de guerra, bots y dinero para disparar en servidores</a></li>
<li><a href="../es434442/index.html">Cosmon√°utica 2018 - resultados del a√±o</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
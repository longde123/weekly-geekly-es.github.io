<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§ûüèø üë∑üèª üë®üèΩ‚Äçüéì Le livre "Les architectes de l'intelligence" ‚òéÔ∏è ü§≥üèæ üëçüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'intelligence artificielle (IA) passe rapidement de la science-fiction √† la vie quotidienne. Les appareils modernes reconnaissent la parole humaine, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le livre "Les architectes de l'intelligence"</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/476466/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/mb/12/np/mb12npah994j7jq-gm2outusizg.jpeg" align="left" alt="image"></a>  L'intelligence artificielle (IA) passe rapidement de la science-fiction √† la vie quotidienne.  Les appareils modernes reconnaissent la parole humaine, sont capables de r√©pondre aux questions et d'effectuer une traduction automatique.  Dans divers domaines, de la conduite d'un v√©hicule sans pilote au diagnostic du cancer, des algorithmes de reconnaissance d'objets bas√©s sur l'IA sont utilis√©s, dont les capacit√©s sont sup√©rieures √† celles des humains.  Les grandes soci√©t√©s de m√©dias utilisent le journalisme robotis√© pour cr√©er des articles similaires au droit d'auteur √† partir des donn√©es collect√©es.  L'IA est √©videmment pr√™te √† devenir une technologie v√©ritablement universelle, comme l'√©lectricit√©. <br><br>  Quelles approches et technologies sont consid√©r√©es comme les plus prometteuses?  Quelles d√©couvertes majeures sont possibles dans les ann√©es √† venir?  Est-il possible de cr√©er une machine ou une intelligence artificielle vraiment comparable √† l'homme, et dans combien de temps?  Quels risques et menaces sont associ√©s √† l'IA, et comment les √©viter?  L'IA causera-t-elle le chaos dans l'√©conomie et le march√© du travail?  Les machines superintelligentes √©chapperont-elles au contr√¥le humain et deviendront-elles une v√©ritable menace? <br><br>  Bien s√ªr, il est impossible de pr√©dire l'avenir.  N√©anmoins, les experts en savent plus que quiconque sur l'√©tat actuel de la technologie, ainsi que sur les innovations dans un avenir proche.  Vous aurez de brillantes rencontres avec des personnes reconnues comme R. Kurzweil, D. Hassabis, J. Hinton, R. Brooks et bien d'autres. <br><a name="habracut"></a><br><h3>  Yan Lekun </h3><br>  VICE-PR√âSIDENT ET FONDATEUR DU LABORATOIRE DE RECHERCHE EN IA √Ä FACEBOOK (FAIR), PROFESSEUR EN INFORMATIQUE √Ä L'UNIVERSIT√â DE NEW YORK <br><br>  <i>Avec Jeffrey Hinton et Joshua Benjio, Ian Lekun fait partie d'un groupe de chercheurs dont les efforts et la pers√©v√©rance ont conduit √† la r√©volution actuelle en relation avec les r√©seaux de neurones et l'apprentissage profond.</i>  <i>Tout en travaillant aux Bell Labs, il a invent√© les r√©seaux de neurones convolutionnels.</i>  <i>Il a obtenu un dipl√¥me d'ing√©nieur √©lectricien √† Paris de l'ESIEE, et un doctorat en informatique de l'Universit√© Pierre et Marie Curie.</i>  <i>Apr√®s ses √©tudes sup√©rieures, il a travaill√© au laboratoire Jeffrey Hinton de l'Universit√© de Toronto.</i> <br><br>  <b>Martin Ford:</b> L'explosion d'int√©r√™t pour l'apprentissage en profondeur au cours des 10 derni√®res ann√©es est une cons√©quence de l'am√©lioration simultan√©e des r√©seaux de neurones, augmentant la puissance des ordinateurs et la quantit√© de donn√©es disponibles? <br><br>  <b>Yang Lekun:</b> Oui, mais le processus √©tait plus d√©lib√©r√©.  Apparu en 1986-1987.  l'algorithme de r√©tropropagation a permis de former des r√©seaux de neurones multicouches.  Cela a provoqu√© une vague d‚Äôint√©r√™t qui a dur√© jusqu‚Äôen 1995. En 2003, Jeffrey Hinton, Joshua Benggio et moi avons propos√© un plan pour renouveler l‚Äôint√©r√™t de la communaut√© pour ces m√©thodes parce qu‚Äôils √©taient convaincus de leur victoire imminente.  On peut donc dire qu'il y a eu une conspiration d√©lib√©r√©e. <br><br>  <b>M.F .:</b> Avez-vous d√©j√† compris toutes les perspectives?  L'IA et le deep learning sont d√©sormais consid√©r√©s comme synonymes. <br><br>  <b>I. L .:</b> Oui et non.  Nous savions que les m√©thodes formeraient la base de la vision par ordinateur, de la reconnaissance vocale et peut-√™tre de quelques autres choses, mais personne ne s'attendait √† ce qu'elles s'√©tendent √† la compr√©hension du langage naturel, de la robotique, de l'analyse de l'imagerie m√©dicale et m√™me contribuent √† l'√©mergence de v√©hicules sans pilote.  Au d√©but des ann√©es 1990.  Je pensais que le mouvement vers ces choses serait plus fluide, et ils appara√Ætraient un peu plus t√¥t.  Nous attendions la r√©volution qui s'est produite vers 2013. <br><br>  <b>M.F.:</b> Et comment est <b>n√©</b> votre int√©r√™t pour l'IA et l'apprentissage automatique? <br><br>  <b>Y. L.:</b> D√®s mon enfance, je m'int√©ressais aux sciences, √† la technologie et aux probl√®mes mondiaux concernant l'origine de la vie, l'intelligence, l'origine de l'humanit√©.  L'id√©e de l'IA m'a fascin√©.  Mais dans les ann√©es 1960-1970.  personne ne faisait √ßa en France, donc apr√®s l'√©cole, je suis all√© √©tudier en tant qu'ing√©nieur. <br><br>  En 1980, j'ai beaucoup aim√© le livre sur la philosophie du langage et de l'apprentissage: le d√©bat entre Jean Piaget et Noam Chomsky ("Langage et apprentissage: une discussion entre Jean Piaget et Noam Chomsky"), dans lequel le cr√©ateur de la th√©orie du d√©veloppement cognitif et le linguiste ont discut√© de la nature et de l'√©ducation , ainsi que l'√©mergence du langage et de l'intelligence. <br><br>  Du c√¥t√© de Piaget, le professeur du MIT, Seymour Peypert, a parl√© des origines de l'apprentissage automatique √† la fin des ann√©es 1960.  effectivement contribu√© √† l'arr√™t du travail avec les r√©seaux de neurones.  Et maintenant, apr√®s 10 ans, il a vant√© le soi-disant perceptron - un mod√®le tr√®s simple d'apprentissage automatique qui est apparu dans les ann√©es 1950.  et sur lequel il a travaill√© dans les ann√©es 1960.  Donc, pour la premi√®re fois, je me suis familiaris√© avec le concept d'apprentissage automatique et j'√©tais absolument fascin√© par celui-ci.  La capacit√© d'apprendre, je consid√©rais une partie int√©grante de l'intelligence. <br><br>  En tant qu'√©tudiant, j'ai lu tout ce que je pouvais trouver sur l'apprentissage automatique et j'ai r√©alis√© plusieurs projets sur ce sujet.  Il s'est av√©r√© qu'en Occident, personne ne travaille avec les r√©seaux de neurones.  Certains chercheurs japonais ont travaill√© sur ce qui deviendra plus tard ce terme.  Dans notre pays, ce sujet n‚Äôint√©ressait personne, en partie √† cause de ce qui apparaissait √† la fin des ann√©es 60.  livres de Peypert et Minsky. <br><br>  J'ai entam√© des recherches ind√©pendantes et en 1987, j'ai soutenu ma th√®se de doctorat Modeles connexionnistes de l'apprentissage.  Mon manager Maurice Milgram n'a pas trait√© de ce sujet et m'a directement dit qu'il pouvait officiellement devenir mon consultant, mais il ne pouvait pas m'aider techniquement. <br><br>  Au d√©but des ann√©es 80  J'ai d√©couvert une communaut√© de personnes qui travaillaient sur des r√©seaux de neurones et les ai contact√©s.  En cons√©quence, en parall√®le avec David Rumelhart et Jeffrey Hinton, j'ai d√©couvert une chose telle que la m√©thode de propagation arri√®re de l'erreur. <br><br>  <b>M.F.:</b> C'est-√†-dire au d√©but des ann√©es 80.  Au Canada, il y a eu de nombreuses √©tudes dans ce domaine? <br><br>  <b>Y. L.:</b> Non, tout s'est pass√© aux √âtats-Unis.  Au Canada, de telles √©tudes n'ont pas encore √©t√© men√©es.  Au d√©but des ann√©es 80  Jeffrey Hinton √©tait un employ√© de l'Universit√© de Californie √† San Diego, o√π il a travaill√© avec des psychologues cognitifs tels que David Rumelhart et James McClelland.  En cons√©quence, un livre est apparu expliquant la psychologie √† l'aide de r√©seaux neuronaux simples et de mod√®les informatiques.  Jeffrey est ensuite devenu professeur adjoint √† l'Universit√© Carnegie Mellon.  Il n'a d√©m√©nag√© √† Toronto qu'en 1987. Ensuite, j'ai d√©m√©nag√© √† Toronto et j'ai travaill√© dans son laboratoire pendant un an. <br><br>  M.F .: Au d√©but des ann√©es 80.  J'√©tais √©tudiant en informatique et je ne me souviens pas que les r√©seaux de neurones √©taient utilis√©s quelque part.  Maintenant, la situation a radicalement chang√©. <br><br>  <b>Y. L .:</b> Les r√©seaux de neurones ne sont pas seulement en marge de la science.  Dans les ann√©es 1970  et au d√©but des ann√©es 80.  ils √©taient en fait anath√©matis√©s.  Les articles ont √©t√© rejet√©s pour une mention des r√©seaux de neurones. <br><br>  L'article bien connu Optimal Perceptual Inference, qui a √©t√© publi√© en 1983 par Jeffrey Hinton et Terry Seinowski.  Pour y d√©crire l'un des premiers mod√®les d'apprentissage profond et de r√©seau neuronal, ils ont utilis√© des mots de code, m√™me dans le nom. <br><br>  <b>M.F.:</b> Vous √™tes connu comme l'auteur d'un r√©seau neuronal convolutif.  Veuillez expliquer de quoi il s'agit? <br><br>  <b>Y. L .:</b> Initialement, ce r√©seau de neurones a √©t√© optimis√© pour la reconnaissance d'objets dans les images.  Mais il s'est av√©r√© qu'elle peut √™tre appliqu√©e √† un large √©ventail de t√¢ches, telles que la reconnaissance vocale et la traduction automatique.  L'id√©e de sa cr√©ation a √©t√© servie par les caract√©ristiques du cortex visuel du cerveau des animaux et des humains, √©tudi√©es dans les ann√©es 1950 et 1960.  David Hubel et Thorsten Wiesel, qui ont re√ßu plus tard le prix Nobel de neurobiologie. <br><br>  Le r√©seau convolutionnel est un moyen sp√©cial de connecter des neurones qui ne sont pas une copie exacte des neurones biologiques.  Dans la premi√®re couche - la couche de convolution - chaque neurone est associ√© √† un petit nombre de pixels d'image et calcule la somme pond√©r√©e de ses donn√©es d'entr√©e.  Pendant l'entra√Ænement, les poids changent.  Des groupes de neurones voient de petites zones de l'image.  Si un neurone d√©tecte une caract√©ristique sp√©cifique dans une zone, un autre neurone d√©tectera exactement la m√™me caract√©ristique dans la zone adjacente, et tous les autres neurones dans les zones restantes de l'image.  L'op√©ration math√©matique que les neurones effectuent ensemble est appel√©e convolution discr√®te.  D'o√π le nom. <br><br>  Vient ensuite la couche non lin√©aire, o√π chaque neurone s'allume ou s'√©teint, selon que la somme pond√©r√©e calcul√©e par la couche de convolution s'est av√©r√©e sup√©rieure ou inf√©rieure au seuil sp√©cifi√©.  Enfin, la troisi√®me couche effectue une op√©ration de sous-√©chantillonnage pour s'assurer qu'une l√©g√®re polarisation ou d√©formation de l'image d'entr√©e ne modifie pas consid√©rablement la sortie.  Cela offre une ind√©pendance vis-√†-vis des d√©formations de l'image d'entr√©e. <br><br>  En fait, un r√©seau convolutionnel est une pile organis√©e √† partir de couches de convolution, de non-lin√©arit√© et de sous-√©chantillonnage.  Lorsqu'ils sont pli√©s, des neurones apparaissent qui reconnaissent les objets.  Par exemple, un neurone qui s'allume lorsque le cheval est sur l'image, un autre neurone pour les voitures, un troisi√®me pour les personnes, etc., pour toutes les cat√©gories dont vous avez besoin. <br><br>  De plus, ce que fait le r√©seau neuronal est d√©termin√© par la force des connexions entre les neurones, c'est-√†-dire les poids.  Et ces poids ne sont pas programm√©s, mais sont le r√©sultat de l'entra√Ænement. <br><br>  L'image du cheval est montr√©e au r√©seau, et s'il ne r√©pond pas ¬´cheval¬ª, il sera inform√© que c'est faux et sera invit√© avec la bonne r√©ponse.  Apr√®s cela, en utilisant l'algorithme de propagation d'erreur de retour, le r√©seau ajuste les poids de toutes les connexions de sorte que la prochaine fois que la m√™me image sera affich√©e, le r√©sultat sera plus proche de celui souhait√©.  En m√™me temps, vous devez lui montrer des milliers d'images. <br><br>  <b>M. F.:</b> S'agit-il d'un enseignement avec un enseignant?  Si je comprends bien, c'est maintenant l'approche dominante. <br><br>  <b>Y. L .:</b> Exactement.  Presque toutes les applications modernes d'apprentissage en profondeur utilisent la formation des enseignants.  La magie est que le r√©seau form√© donne la plupart du temps les bonnes r√©ponses m√™me pour des images auxquelles il n'avait pas √©t√© montr√© auparavant.  Mais il a besoin d'un grand nombre d'exemples. <br><br>  <b>M.F.:</b> Et √† quoi peut-on s'attendre √† l'avenir?  Sera-t-il possible d'enseigner une voiture √† un enfant qui n'a qu'√† montrer une fois un chat et √† le nommer? <br><br>  <b>I. L .:</b> En fait, vous n'avez pas tout √† fait raison.  Les premi√®res formations convolutionnelles se d√©roulent r√©ellement sur des millions d'images de diff√©rentes cat√©gories.  Et puis, si vous devez ajouter une nouvelle cat√©gorie, par exemple, apprendre √† un ordinateur √† reconna√Ætre les chats, quelques √©chantillons suffisent.  Apr√®s tout, le r√©seau est d√©j√† form√© pour reconna√Ætre des objets de presque n'importe quel type.  Les ajouts √† la formation concernent une paire de couches sup√©rieures. <br><br>  <b>MF:</b> Cela ressemble d√©j√† √† la fa√ßon dont les enfants √©tudient. <br><br>  <b>Y. L.:</b> Non, malheureusement, ce n'est pas du tout comme √ßa.  Les enfants obtiennent la plupart des informations avant que quelqu'un ne leur dise: "Ceci est un chat."  Au cours des premiers mois de la vie, les enfants apprennent sans avoir la moindre id√©e de la langue.  Ils reconnaissent la structure du monde en observant simplement le monde et en interagissant un peu avec lui.  Cette fa√ßon d'accumuler des connaissances n'est pas disponible pour les machines.  Comment l'appeler n'est pas clair.  Certains utilisent le terme provocateur ¬´enseignement sans enseignant¬ª.  Cette formation est parfois appel√©e formation anticipative ou inductive.  J'appelle cela l'auto-apprentissage.  Lors de la formation de ce type, il n'est pas question de se pr√©parer √† effectuer une t√¢che, il s'agit simplement d'observer le monde et son fonctionnement. <br><br>  <b>M.F.:</b> L'apprentissage renforc√© entre-t <b>-</b> il dans cette cat√©gorie? <br><br>  <b>Y. L.:</b> Non, c'est une cat√©gorie compl√®tement diff√©rente.  En fait, il existe trois cat√©gories principales: l'apprentissage renforc√©, la formation des enseignants et l'auto-apprentissage. <br><br>  L'entra√Ænement avec renforcement se fait par essais et erreurs et fonctionne bien pour les jeux o√π vous pouvez faire autant de tentatives que vous le souhaitez.  Les bonnes performances d'AlphaGo ont √©t√© obtenues apr√®s que la machine ait jou√© plus de jeux que toute l'humanit√© au cours des trois mille derni√®res ann√©es.  Aux probl√®mes du monde r√©el, une telle approche n'est pas pratique. <br><br>  Une personne peut apprendre √† conduire une voiture en 15 heures de formation sans s'√©craser.  Si vous utilisez les m√©thodes d'entra√Ænement existantes avec des renforts, la voiture, pour apprendre √† rouler sans chauffeur, devra tomber 10 000 fois d'une falaise avant de comprendre comment l'√©viter. <br><br>  <b>M.F .:</b> Il me semble que c'est un argument en faveur de la mod√©lisation. <br><br>  <b>Y. L.: C'est</b> plut√¥t une confirmation que le type de formation que les gens utilisent est tr√®s diff√©rent de l'apprentissage renforc√©.  Ceci est similaire √† la formation de renforcement bas√©e sur un mod√®le.  Apr√®s tout, une personne qui conduit pour la premi√®re fois a un mod√®le du monde et peut pr√©dire les cons√©quences de ses actes.  Comment amener une machine √† √©tudier ind√©pendamment des mod√®les pr√©dictifs est un probl√®me majeur non r√©solu. <br><br>  <b>M.F.:</b> C'est √† √ßa que <b>sert</b> votre travail avec Facebook? <br><br>  <b>I. L .:</b> Oui, c'est l'une des choses sur lesquelles nous travaillons.  Nous formons √©galement la machine √† observer diff√©rentes sources de donn√©es.  Nous construisons un mod√®le du monde, en esp√©rant y refl√©ter le bon sens, afin qu'il puisse plus tard servir de pronostic. <br><br>  <b>M.F.:</b> Certaines personnes pensent que le deep learning seul ne suffit pas, et dans les r√©seaux il devrait d'abord y avoir une structure responsable de l'intelligence.  Et vous semblez convaincu que l'intelligence peut √©merger organiquement √† partir de r√©seaux neuronaux relativement universels. <br><br>  Y. L.: Vous exag√©rez.  Tout le monde est d'accord avec la n√©cessit√© de la structure, la question est de savoir √† quoi elle devrait ressembler.  Et en parlant de gens qui croient qu'il devrait y avoir des structures qui fournissent une r√©flexion logique et la capacit√© de discuter, vous voulez probablement dire Gary Marcus et, √©ventuellement, Oren Etzioni.  Nous nous sommes disput√©s avec Gary sur ce sujet ce matin.  Son opinion n'est pas bien re√ßue dans la communaut√©, car, sans apporter la moindre contribution √† l'apprentissage en profondeur, il a √©crit de mani√®re critique √† ce sujet.  Oren a travaill√© dans ce domaine pendant un certain temps et en m√™me temps parle beaucoup plus doucement. <br><br>  En fait, l'id√©e de r√©seaux convolutionnels est n√©e comme une tentative d'ajouter de la structure aux r√©seaux de neurones.  La question est: qui permet √† la machine de manipuler des caract√®res ou, par exemple, de correspondre aux caract√©ristiques hi√©rarchiques de la langue? <br><br>  Beaucoup de mes coll√®gues, dont Jeffrey Hinton et Joshua Benggio, conviennent que t√¥t ou tard nous pouvons nous passer de structures.  Ils peuvent √™tre utiles √† court terme, car un moyen d'auto-apprentissage n'a pas encore √©t√© invent√©.  Ce point peut √™tre contourn√© en reliant tout √† l'architecture.  Mais la microstructure du cortex, √† la fois visuelle et pr√©frontal, semble compl√®tement homog√®ne. <br><br>  <b>M.F .:</b> Le cerveau utilise-t-il quelque chose de similaire √† la m√©thode de propagation des erreurs? <br><br>  <b>I. L .:</b> C'est inconnu.  Il peut s'av√©rer que ce n'est pas la r√©tropropagation dans la forme telle que nous la connaissons, mais une forme similaire d'approximation de l'estimation du gradient.  Joshua Benggio a travaill√© sur des formes biologiquement plausibles d'estimation de gradient.  Il est possible que le cerveau estime le gradient de toute fonction cible. <br><br>  <b>M.F.: Sur</b> quelles autres choses importantes travaillez-vous sur Facebook? <br><br>  <b>Y. L.:</b> Nous sommes engag√©s dans une vari√©t√© de recherches fondamentales, ainsi que des probl√®mes d'apprentissage automatique, par cons√©quent, nous traitons principalement des math√©matiques appliqu√©es et de l'optimisation.  Des travaux sont en cours sur l'apprentissage renforc√© et les mod√®les dits g√©n√©ratifs, qui sont une forme d'auto-apprentissage ou d'apprentissage anticipatif. <br><br>  <b>MF:</b> Facebook d√©veloppe-t <b>-</b> il des syst√®mes capables de maintenir une conversation? <br><br>  <b>Y. L.:</b> J'ai √©num√©r√© les sujets de recherche fondamentale ci-dessus, mais il existe √©galement de nombreux domaines d'application.  Facebook d√©veloppe activement des d√©veloppements dans le domaine de la vision par ordinateur, et on peut affirmer que nous avons le meilleur groupe de recherche au monde.  Nous travaillons beaucoup sur le traitement de texte en langage naturel.  Cela comprend la traduction, la g√©n√©ralisation, la cat√©gorisation (trouver le sujet discut√©) et les syst√®mes de dialogue pour les assistants virtuels, les syst√®mes de questions et r√©ponses, etc. <br><br>  <b>M.F.:</b> Pensez-vous qu'un jour il y aura une IA qui pourra passer le test de Turing? <br><br>  <b>I. L .:</b> √Ä un moment donn√©, cela se produira, mais je ne consid√®re pas le test de Turing comme un bon crit√®re: il est facile de tromper et il est quelque peu d√©pass√©.  Beaucoup oublient ou refusent de croire que la langue est un ph√©nom√®ne secondaire par rapport √† l'intelligence. <br><br>  ¬ªPlus d'informations sur le livre sont disponibles sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le site Web de l'√©diteur</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Contenu</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Extrait</a> <br><br>  25% de r√©duction sur les colporteurs - <b>Intelligence Architects</b> <br><br>  Lors du paiement de la version papier du livre, un livre √©lectronique est envoy√© par e-mail. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr476466/">https://habr.com/ru/post/fr476466/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr476452/index.html">Stockage de valeur-cl√© ou comment nos applications sont devenues plus pratiques</a></li>
<li><a href="../fr476454/index.html">La 5G arrive: quelles entreprises assureront l'introduction de nouvelles technologies en 2020</a></li>
<li><a href="../fr476456/index.html">Le syst√®me chinois de cr√©dit social n'est tout d'abord pas un syst√®me d'√©valuation des citoyens, mais une API massive</a></li>
<li><a href="../fr476460/index.html">Le premier format de fichier √† succ√®s sur Internet n'√©tait pas MP3, mais MIDI</a></li>
<li><a href="../fr476464/index.html">Probl√®mes de journalisation des √©v√©nements de s√©curit√© du syst√®me Windows</a></li>
<li><a href="../fr476468/index.html">Nouveau cours gratuit d'analyse de texte en ligne sur le r√©seau neuronal de Samsung</a></li>
<li><a href="../fr476474/index.html">Nous renvoyons Keenetic au support KN-1310 du modem USB</a></li>
<li><a href="../fr476476/index.html">Afficher Gmail en html uniquement</a></li>
<li><a href="../fr476478/index.html">√âtapes de l'introduction de mod√®les d'apprentissage automatique dans les grandes entreprises</a></li>
<li><a href="../fr476480/index.html">Comment d√©velopper un d√©veloppeur dans une petite ville peu informatique</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
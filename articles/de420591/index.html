<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêù ‚úåüèº ü§±üèª √úbersetzung von Andrew Un's Buch, Leidenschaft f√ºr maschinelles Lernen, Kapitel 20 - 27 üë©üèø‚Äç‚úàÔ∏è üåì üôÜüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="vorherige Kapitel 
 20 Offset und Streuung: Zwei Hauptfehlerquellen 


 Anmerkung des √úbersetzers Vor der √Ñnderung hie√ü dieses Kapitel ‚ÄûSystematisch u...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>√úbersetzung von Andrew Un's Buch, Leidenschaft f√ºr maschinelles Lernen, Kapitel 20 - 27</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420591/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorherige Kapitel</a> </p><br><h1 id="20-smeschenie-i-razbros-dva-osnovnyh-istochnika-oshibok">  20 Offset und Streuung: Zwei Hauptfehlerquellen </h1><br><p>  <em><u>Anmerkung</u> des <u>√úbersetzers</u> Vor der √Ñnderung hie√ü dieses Kapitel <strong>‚ÄûSystematisch und zuf√§llig: Zwei Hauptfehlerquellen‚Äú</strong> , <strong>dh</strong> ich habe die Begriffe ‚Äûzuf√§llige Fehler‚Äú und ‚Äûsystematische Fehler‚Äú verwendet, um Verzerrung und Varianz zu √ºbersetzen.</em>  <em>Das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Forummitglied robot @ Phaker hat jedoch</a> in einem Kommentar zu Recht festgestellt, dass im Bereich des maschinellen Lernens in der russischen Terminologie f√ºr diese Begriffe die Konzepte "Verschiebung" und "Streuung" festgelegt sind.</em>  <em>Ich habe mir die Arbeit von K.V.</em>  <em>Woronzow, der zu Recht eine der Autorit√§ten auf dem Gebiet des maschinellen Lernens in Russland und der Ressourcen der Fachwelt ist, stimmte der Bemerkung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">robot @ Phaker zu</a> .</em>  <em>Trotz der Tatsache, dass es aus meiner Sicht eine tiefe sinnvolle Analogie zwischen der ‚ÄûVerzerrung‚Äú und der ‚ÄûVarianz‚Äú beim Training von Algorithmen und dem ‚Äûsystematischen Fehler‚Äú und dem ‚Äûzuf√§lligen Fehler‚Äú eines physikalischen Experiments gibt, werden sie au√üerdem gleicherma√üen mathematisch ausgedr√ºckt Es ist jedoch richtig, die in diesem Bereich festgelegten Begriffe zu verwenden.</em>  <em>Daher habe ich die √úbersetzung dieses und der folgenden Kapitel √ºberarbeitet und die "Systematischen und zuf√§lligen Fehler" durch "Versatz und Streuung" ersetzt. Ich werde mich in Zukunft an diesen Ansatz halten.</em> </p><a name="habracut"></a><br><p>  Angenommen, Ihre Trainings-, Validierungs- und Testmuster haben dieselbe Verteilung.  Dann m√ºssen Sie mehr Daten f√ºr das Training nehmen, dies wird nur die Qualit√§t des Algorithmus verbessern, stimmt das? </p><br><p>  Obwohl das Abrufen von mehr Daten den Job nicht beeintr√§chtigen kann, helfen neue Daten leider nicht immer so viel, wie Sie vielleicht erwarten.  In einigen F√§llen kann die Arbeit, zus√§tzliche Daten zu erhalten, eine Verschwendung von Aufwand sein.  Wie man eine Entscheidung trifft - in welchen F√§llen Daten hinzugef√ºgt werden sollen und wann man sich keine Sorgen machen muss. </p><br><p>  Beim maschinellen Lernen gibt es zwei Hauptfehlerquellen: Verzerrung und Streuung (Varianz).  Wenn Sie wissen, was sie sind, k√∂nnen Sie entscheiden, ob Sie weitere Daten hinzuf√ºgen m√∂chten. Au√üerdem k√∂nnen Sie Taktiken ausw√§hlen, um die Qualit√§t des Klassifikators zu verbessern. </p><br><p>  Angenommen, Sie hoffen, eine Katzen-ID mit einem Fehler von 5% zu erstellen.  Im Moment betr√§gt Ihr Klassifikatorfehler in der Trainingsstichprobe 15%, in der Validierungsstichprobe 16%.  In diesem Fall ist es unwahrscheinlich, dass das Hinzuf√ºgen von Trainingsdaten die Qualit√§t signifikant erh√∂ht.  Sie sollten sich auf andere System√§nderungen konzentrieren.  Wenn Sie Ihrem Trainingssatz weitere Beispiele hinzuf√ºgen, wird es f√ºr Ihren Algorithmus nur schwieriger, ein gutes Ergebnis f√ºr diesen Satz zu erzielen (warum dies in den folgenden Kapiteln erl√§utert wird). </p><cut></cut><br><p>  Wenn der Prozentsatz Ihrer Fehler in der Trainingsstichprobe 15% betr√§gt (was einer Genauigkeit von 85% entspricht), Ihr Ziel jedoch der Prozentsatz der Fehler in 5% (95% Genauigkeit) ist, m√ºssen Sie zun√§chst die Qualit√§t Ihres Algorithmus in der Trainingsstichprobe verbessern.  Die Qualit√§t des Algorithmus in den Validierungs- / Testmustern ist normalerweise schlechter als die Qualit√§t seiner Arbeit in der Trainingsprobe (in der Trainingsprobe).  Sie m√ºssen verstehen, dass die Ans√§tze, die Sie in Beispielen, mit denen Ihr Algorithmus vertraut ist, zu einer Genauigkeit von nicht mehr als 85% gef√ºhrt haben, es Ihnen nicht erm√∂glichen, in Beispielen, die dieser Algorithmus noch nicht einmal gesehen hat, eine Genauigkeit von 95% zu erzielen. </p><cut></cut><br><p>  Angenommen, wie oben angegeben, betr√§gt die Fehlerrate Ihres Algorithmus in der Validierungsstichprobe 16% (Genauigkeit 84%).  Wir m√ºssen den 16% -Fehler in zwei Komponenten aufteilen: </p><br><ul><li>  Erstens der Anteil der Algorithmusfehler in der Trainingsstichprobe.  In diesem Beispiel sind es 15%.  Wir nennen es informell <strong>Voreingenommenheit</strong> . </li><li>  Zweitens, wie viel schlechter der Algorithmus bei der Validierungs- (oder Test-) Probe funktioniert als bei der Trainingsprobe.  In unserem Beispiel ist es bei der Validierungsstichprobe 1% schlechter als bei der Trainingsstichprobe.  Wir werden es auch inoffiziell als <strong>Varianz des</strong> Algorithmus betrachten. </li></ul><br><p>  <em><u>Anmerkung des Autors</u> In der Statistik gibt es eine genauere Definition f√ºr Verzerrung und Streuung (systematische und zuf√§llige Fehler), aber dies sollte uns nicht st√∂ren.</em>  <em>Grob gesagt gehen wir davon aus, dass die Verzerrung ein Fehler in Ihrem Algorithmus in Ihrem Trainingssatz ist, wenn Sie einen sehr gro√üen Trainingssatz haben.</em>  <em>Streuung - so viel schlechter arbeitet der Algorithmus an der Testprobe im Vergleich zur Trainingsprobe mit denselben Parametereinstellungen.</em>  <em>Wenn Sie den Standardfehler verwenden, k√∂nnen Sie die Formeln schreiben, die diese beiden Gr√∂√üen definieren, und beweisen, dass der Gesamtfehler gleich der Summe aus Bias und Scatter (der Summe aus zuf√§lligen und systematischen Fehlern) ist.</em>  <em>F√ºr unsere Zwecke zur Verbesserung von Algorithmen bei Problemen des maschinellen Lernens reicht jedoch eine informelle Definition von Verzerrung und Streuung aus.</em> </p><br><p>  Einige √Ñnderungen im Training des Algorithmus wirken sich auf die erste Komponente der Fehlerverzerrung aus und verbessern die Leistung des Algorithmus in der Trainingsprobe.  Einige √Ñnderungen wirken sich auf die zweite Komponente aus - die <strong>Varianz -</strong> und helfen, den Algorithmus besser auf Validierungs- und Testproben zu verallgemeinern.  Um die effektivsten √Ñnderungen auszuw√§hlen, die am System vorgenommen werden m√ºssen, ist es √§u√üerst hilfreich zu verstehen, wie sich jede dieser beiden Fehlerkomponenten auf den Gesamtsystemfehler auswirkt. </p><br><p>  <em><u>Anmerkung des Autors:</u> Es gibt auch einige Ans√§tze, die gleichzeitig Verschiebung und Streuung reduzieren und die Systemarchitektur erheblich √§ndern.</em>  <em>In der Regel sind sie jedoch schwieriger zu finden und umzusetzen.</em> </p><br><p>  Um die effektivsten √Ñnderungen auszuw√§hlen, die am System vorgenommen werden m√ºssen, ist es √§u√üerst hilfreich zu verstehen, wie sich jede dieser beiden Fehlerkomponenten auf den Gesamtsystemfehler auswirkt. </p><br><p>  Die Entwicklung der Intuition, um zu verstehen, wie Beitrag zum Fehler beitr√§gt und welche Streuung, hilft Ihnen dabei, effektiv M√∂glichkeiten zur Verbesserung Ihres Algorithmus auszuw√§hlen. </p><cut></cut><br><h1 id="21-primery-klassifikacii-oshibok">  21 Beispiele f√ºr die Fehlerklassifizierung </h1><br><p>  Betrachten Sie unser Katzenklassifizierungsproblem.  Ein idealer Klassifikator (zum Beispiel eine Person) kann eine hervorragende Qualit√§t dieser Aufgabe erreichen. </p><br><p>  Angenommen, die Qualit√§t unseres Algorithmus ist wie folgt: </p><br><ul><li>  Fehler in der Trainingsstichprobe = 1% </li><li>  Fehler in der Validierungsstichprobe = 11% </li></ul><br><p>  Was ist das Problem mit diesem Klassifikator?  Unter Anwendung der Definitionen aus dem vorherigen Kapitel sch√§tzen wir den Bias auf 1% und den Spread auf 10% (= 11% - 1%).  Somit hat unser Algorithmus eine gro√üe <strong>Verbreitung</strong> .  Der Klassifikator weist einen sehr geringen Fehler in der Trainingsstichprobe auf, kann die Trainingsergebnisse jedoch nicht auf eine Validierungsstichprobe verallgemeinern.  Mit anderen Worten, wir haben es mit <strong>√úberanpassung zu</strong> tun. </p><br><p>  Betrachten Sie nun diese Situation: </p><br><ul><li>  Fehler in der Trainingsstichprobe = 15% </li><li>  Fehler in der Validierungsstichprobe = 16% </li></ul><br><p>  Dann sch√§tzen wir den <strong>Bias</strong> auf 15% und den <strong>Spread</strong> auf 1%.  Dieser Klassifikator war in der Trainingsprobe schlecht trainiert, w√§hrend sein Fehler in der Validierungsprobe etwas gr√∂√üer ist als in der Trainingsprobe.  Somit hat dieser Klassifikator eine gro√üe Vorspannung, aber eine kleine Streuung.  Es kann gefolgert werden, dass dieser Algorithmus <strong>unteranpasst</strong> . </p><cut></cut><br><p>  Wir ber√ºcksichtigen auch die folgende Fehlerverteilung: </p><br><ul><li>  Fehler in der Trainingsstichprobe = 15% </li><li>  Fehler in der Validierungsstichprobe = 30% </li></ul><br><p>  In diesem Fall betr√§gt der Bias 15% und der Spread ebenfalls 15%.  Dieser Klassifikator hat eine hohe Vorspannung und Streuung: Er funktioniert in der Trainingsprobe nicht gut, hat eine hohe Vorspannung und seine Qualit√§t in der Validierungsprobe ist viel schlechter als in der Trainingsprobe, d. H.  Die Streuung ist ebenfalls gro√ü.  Dieser Fall ist im Hinblick auf Umschulung / Untererziehung schwer zu beschreiben, da dieser Klassifikator sowohl umgeschult als auch untererzogen ist. </p><cut></cut><br><p>  Betrachten Sie abschlie√üend diese Situation: </p><br><ul><li>  Fehler in der Trainingsstichprobe = 0,5% </li><li>  Fehler in der Validierungsstichprobe = 1% </li></ul><br><p>  Dies ist ein gro√üartiger Klassifikator mit geringer Vorspannung und Streuung.  Herzlichen Gl√ºckwunsch an die Ingenieure zu einem hervorragenden Ergebnis! </p><cut></cut><br><h1 id="22-sravnenie-s-optimalnoy-doley-oshibok">  22 Vergleich mit optimaler Fehlerrate </h1><br><p>  In unserem Beispiel f√ºr die Erkennung von Katzen ist der ideale Fehleranteil das Niveau, das dem ‚Äûoptimalen‚Äú Klassifikator zur Verf√ºgung steht, und dieses Niveau liegt nahe bei 0%.  Eine Person, die ein Bild betrachtet, kann fast immer erkennen, ob eine Katze auf dem Bild vorhanden ist oder nicht, und wir k√∂nnen hoffen, dass die Maschine dies fr√ºher oder sp√§ter genauso gut tut. </p><br><p>  Es gibt jedoch komplexere Aufgaben.  Stellen Sie sich zum Beispiel vor, Sie entwickeln ein Spracherkennungssystem und stellen fest, dass 14% der Audioaufnahmen so viele Hintergrundger√§usche oder so unleserliche Sprache aufweisen, dass selbst eine Person nicht erkennen kann, was dort gesagt wurde.  In diesem Fall kann sogar das "optimalste" Spracherkennungssystem einen Fehler im Bereich von 14% aufweisen. </p><br><p>  Angenommen, unser Algorithmus hat in unserer Spracherkennungsaufgabe die folgenden Ergebnisse erzielt: </p><br><ul><li>  Fehler in der Trainingsstichprobe = 15% </li><li>  Fehler in der Validierungsstichprobe = 30% </li></ul><cut></cut><br><p>  Die Qualit√§t des Klassifikators in der Trainingsstichprobe ist mit einer Fehlerrate von 14% bereits nahezu optimal.  In diesem Fall haben wir daher nicht viele M√∂glichkeiten, die <strong>Verzerrung</strong> zu verringern (den Algorithmus in der Trainingsstichprobe zu verbessern).  Es ist jedoch nicht m√∂glich, die Funktionsweise dieses Algorithmus auf eine Validierungsprobe zu verallgemeinern, daher gibt es ein gro√ües Feld f√ºr <strong>Streuungsreduktionsaktivit√§ten</strong> . </p><br><p>  Dieser Fall √§hnelt dem dritten Beispiel aus dem vorherigen Kapitel, in dem der Fehler in der Trainingsstichprobe ebenfalls 15% und der Fehler in der Validierungsstichprobe 30% betr√§gt.  Wenn die optimale Fehlerrate bei etwa 0% liegt, bietet der Fehler in der Trainingsstichprobe von 15% viel Raum f√ºr Arbeiten zur Verbesserung des Algorithmus.  Mit dieser Annahme k√∂nnen Bem√ºhungen zur Verringerung der <strong>Verzerrung</strong> im Algorithmus sehr fruchtbar sein.  Wenn jedoch der optimale Anteil an Klassifizierungsfehlern nicht unter 14% liegen kann, deutet ein √§hnlicher Anteil an Algorithmusfehlern in der Trainingsstichprobe (d. H. Im Bereich von 14 bis 15%) darauf hin, dass die M√∂glichkeiten zur Verringerung der <strong>Vorspannung</strong> nahezu ausgesch√∂pft sind. </p><br><p>  F√ºr Probleme, bei denen sich der optimale Anteil der Klassifizierungsfehler erheblich von Null unterscheidet, kann eine detailliertere Fehlerstrukturierung vorgeschlagen werden.  Wir betrachten weiterhin das obige Beispiel mit Spracherkennung. Ein Gesamtfehler von 30% in der Validierungsprobe kann in die folgenden Komponenten zerlegt werden (die Fehler in der Testprobe k√∂nnen auf die gleiche Weise analysiert werden): </p><cut></cut><br><ul><li>  <strong>Optimale Verzerrung (unvermeidbare Verzerrung):</strong> 14%.  Stellen Sie sich vor, wir haben beschlossen, dass selbst das bestm√∂gliche Spracherkennungssystem der Welt eine Fehlerrate von 14% aufweist.  Wir werden dies als den ‚Äûunvermeidbaren‚Äú Teil des Versatzes des Lernalgorithmus bezeichnen. </li><li>  <strong>Vermeidbare Verzerrung</strong> : 1%.  Dieser Wert wird als Differenz zwischen dem Fehleranteil in der Trainingsstichprobe und dem optimalen Fehleranteil berechnet. </li></ul><br><p>  <em><u>Anmerkung des Autors:</u> Wenn sich herausstellt, dass dieser Wert negativ ist, zeigt Ihr Algorithmus in der Trainingsprobe einen kleineren Fehler als den ‚Äûoptimalen‚Äú.</em>  <em>Dies bedeutet, dass Sie den Trainingssatz umgeschult haben und Ihr Algorithmus sich an die Beispiele (und deren Klassen) des Trainingssatzes erinnert hat.</em>  <em>In diesem Fall sollten Sie sich auf Methoden konzentrieren, um die Streuung zu verringern, anstatt die Verzerrung weiter zu verringern.</em> </p><br><ul><li>  <strong>Varianz</strong> : 15%.  Der Unterschied zwischen Fehlern in der Trainingsstichprobe und in der Validierungsstichprobe </li></ul><br><p>  In Bezug auf unsere vorherigen Definitionen h√§ngen Verschiebung und Wegwerfverschiebung wie folgt zusammen: </p><br><p>  <strong>Vorspannung (Vorspannung)</strong> = Optimale Vorspannung ( <strong>"unvermeidbare Vorspannung"</strong> ) + Einwegvorspannung ( <strong>"vermeidbare Vorspannung"</strong> ) </p><br><p>  <em><u>Anmerkung des Autors</u> : Diese Definitionen werden ausgew√§hlt, um besser zu erkl√§ren, wie die Qualit√§t des Lernalgorithmus verbessert werden kann.</em>  <em>Diese Definitionen unterscheiden sich von den formalen Definitionen von Verzerrung und Streuung in der Statistik.</em>  <em>Technisch gesehen sollte das, was ich als "Versatz" definiere, als "Fehler in der Datenstruktur (er kann nicht identifiziert und beseitigt werden)" und "Verzerrung beseitigen" als "Lernalgorithmus-Verzerrung, die die optimale Verzerrung √ºberschreitet" definiert werden. .</em> </p><br><p>  Die vermeidbare Verzerrung zeigt, wie schlechter die Qualit√§t Ihres Algorithmus in der Trainingsstichprobe ist als die Qualit√§t des ‚Äûoptimalen Klassifikators‚Äú. </p><br><p>  Die Grundidee der Varianz bleibt dieselbe.  Theoretisch k√∂nnen wir die Streuung immer auf nahezu Null reduzieren, indem wir an einer ausreichend gro√üen Trainingsstichprobe trainieren.  Daher ist jede Streuung ‚Äûvermeidbar‚Äú, wenn eine ausreichend gro√üe Stichprobe vorhanden ist, sodass es keine ‚Äûunvermeidbare Ausbreitung‚Äú (unvermeidbare Varianz) geben kann. </p><cut></cut><br><p>  Stellen Sie sich ein anderes Beispiel vor, bei dem der optimale Fehler 14% betr√§gt und wir haben: </p><br><ul><li>  Fehler in der Trainingsstichprobe = 15% </li><li>  Fehler in der Validierungsstichprobe = 16% </li></ul><br><p>  Im vorherigen Kapitel haben wir einen Klassifikator mit solchen Indikatoren als High-Bias-Klassifikator klassifiziert. Unter den gegenw√§rtigen Bedingungen sagen wir, dass der ‚Äûvermeidbare Bias‚Äú 1% und der Spread etwa 1% betr√§gt.  Somit funktioniert der Algorithmus bereits recht gut und es gibt fast keine Reserven, um die Qualit√§t seiner Arbeit zu verbessern.  Die Qualit√§t dieses Algorithmus liegt nur 2% unter dem Optimum. </p><br><p>  Aus diesen Beispielen geht hervor, dass die Kenntnis des Ausma√ües des schwerwiegenden Fehlers hilfreich ist, um √ºber weitere Ma√ünahmen zu entscheiden.  In der Statistik wird die optimale <strong>Fehlerrate</strong> auch als <strong>Bayes-Fehlerrate bezeichnet</strong> . </p><br><p>  Wie finde ich die Gr√∂√üe der optimalen Fehlerrate heraus?  Bei Aufgaben, mit denen eine Person gut zurechtkommt, wie z. B. Bilderkennung oder Dekodierung von Audioclips, k√∂nnen Sie die Pr√ºfer bitten, die Daten zu markieren und anschlie√üend die Genauigkeit des menschlichen Markups im Trainingsmuster zu messen.  Dies gibt eine Sch√§tzung der optimalen Fehlerrate.  Wenn Sie an einem Problem arbeiten, mit dem selbst eine Person nur schwer fertig werden kann (z. B. um vorherzusagen, welcher Film empfohlen oder welche Werbung dem Benutzer gezeigt werden soll), ist es in diesem Fall ziemlich schwierig, den optimalen Fehleranteil zu ermitteln. </p><br><p>  Im Abschnitt Vergleich mit der Leistung auf menschlicher Ebene, Kapitel 33 bis 35, werde ich den Prozess des Vergleichs der Qualit√§t eines Lernalgorithmus mit dem Qualit√§tsniveau, das eine Person erreichen kann, ausf√ºhrlicher er√∂rtern. </p><cut></cut><br><p>  In den letzten Kapiteln haben Sie gelernt, wie Sie die entfernbare / nicht behebbare Verzerrung und Streuung bewerten, indem Sie den Anteil der Klassifizierungsfehler in den Trainings- und Validierungsbeispielen analysieren.  Im n√§chsten Kapitel wird untersucht, wie Sie anhand der Schlussfolgerungen aus einer solchen Analyse entscheiden k√∂nnen, ob Sie sich auf Methoden konzentrieren m√∂chten, die die Verzerrung verringern, oder auf Methoden, die die Ausbreitung verringern.  Ans√§tze zur Bek√§mpfung von Verzerrungen unterscheiden sich stark von Ans√§tzen zur Verringerung der Streuung. Daher h√§ngen die Techniken, die Sie in Ihrem Projekt anwenden m√ºssen, um die Qualit√§t zu verbessern, stark von dem ab, was derzeit das Problem ist - gro√üe Verzerrung oder gro√üe Streuung. </p><cut></cut><br><p>  Lesen Sie weiter! </p><br><h1 id="23-ustranenie-smescheniya-i-razbrosa">  23 Offsets und Streuung beseitigen </h1><br><p>  Hier ist eine einfache Formel zur Beseitigung von Verzerrung und Streuung: </p><br><ul><li>  Wenn Sie eine gro√üe vermeidbare Verzerrung haben, erh√∂hen Sie die Komplexit√§t Ihres Modells (z. B. erh√∂hen Sie Ihr neuronales Netzwerk durch Hinzuf√ºgen von Schichten oder (und) Neuronen). </li><li>  Wenn Sie weit verbreitet sind, f√ºgen Sie Ihrem Trainingssatz Beispiele hinzu. </li></ul><br><p>  Wenn Sie die M√∂glichkeit haben, das neuronale Netzwerk zu vergr√∂√üern und dem Trainingssatz unbegrenzt Daten hinzuzuf√ºgen, k√∂nnen Sie ein gutes Ergebnis f√ºr eine gro√üe Anzahl von maschinellen Lernaufgaben erzielen. </p><br><p>  In der Praxis f√ºhrt das Vergr√∂√üern des Modells letztendlich zu Rechenschwierigkeiten, da das Training sehr gro√üer Modelle langsam ist.  Sie k√∂nnen auch die f√ºr das Training verf√ºgbaren Daten aussch√∂pfen.  (Auch im Internet nat√ºrlich die Anzahl der Bilder mit Katzen!) </p><br><p>  Unterschiedliche Architekturen von Algorithmusmodellen, z. B. unterschiedliche Architekturen neuronaler Netze, ergeben unterschiedliche Werte f√ºr Verzerrung und Streuung in Bezug auf Ihre Aufgabe.  Ein Schacht der j√ºngsten Deep-Learning-Forschung hat eine gro√üe Anzahl innovativer Modellarchitekturen f√ºr neuronale Netze geschaffen.  Wenn Sie also neuronale Netze verwenden, kann Sachb√ºcher eine gro√üartige Inspirationsquelle sein.  Es gibt auch eine gro√üe Anzahl hervorragender Implementierungen von Algorithmen in Open Source, beispielsweise auf GitHub.  Die Ergebnisse von Versuchen, neue Architekturen zu verwenden, sind jedoch wesentlich weniger vorhersehbar als die oben angegebene einfache Formel: Erh√∂hen Sie die Gr√∂√üe des Modells und f√ºgen Sie Daten hinzu. </p><br><p>  Eine Vergr√∂√üerung des Modells verringert normalerweise die Verzerrung, kann jedoch auch zu einer Erh√∂hung der Streuung f√ºhren, und das Risiko einer Umschulung steigt ebenfalls.  Das Problem der Umschulung tritt jedoch nur auf, wenn Sie keine Regularisierung verwenden.  Wenn Sie eine gut konzipierte Regularisierungsmethode in Ihr Modell aufnehmen, k√∂nnen Sie das Modell normalerweise sicher vergr√∂√üern, ohne eine Umschulung zuzulassen. </p><br><p>  Angenommen, Sie wenden Deep Learning mithilfe der L2-Regularisierung oder des Dropout an ( <em><u>Anmerkung des √úbersetzers</u> : <strong>Informationen</strong> zum <strong>Dropout</strong> finden Sie beispielsweise hier: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://habr.com/company/wunderfund/blog/330814/</a></em> ), wobei Sie Regularisierungsparameter verwenden, die einwandfrei funktionieren Validierungsprobe.  Wenn Sie das Modell vergr√∂√üern, bleibt die Qualit√§t Ihres Algorithmus normalerweise gleich oder w√§chst.  ein deutlicher R√ºckgang ist unwahrscheinlich.  Der einzige Grund, warum wir uns weigern m√ºssen, das Modell zu vergr√∂√üern, ist der gro√üe Rechenaufwand. </p><br><h1 id="24-kompromiss-mezhdu-smescheniem-i-razbrosom">  24 Der Kompromiss zwischen Offset und Spread </h1><br><p>  Sie haben vielleicht von dem "Kompromiss zwischen Offset und Streuung" geh√∂rt.  Unter den vielen √Ñnderungen, die an Lernalgorithmen vorgenommen werden k√∂nnen, gibt es solche, die die Verzerrung verringern und die Streuung erh√∂hen oder umgekehrt.      ¬´¬ª    . </p><br><p> ,    ‚Äî    ()   ,       ,    . ,     ,   . </p><br><p>                      (  ).  ,      ,          ,       . </p><br><p> ,            ,       .     ,  ,  ,  ,    . </p><br><p>     ,   ,       .        . </p><br><p>    ,     ,       . </p><br><h1 id="25-podhody-k-umensheniyu-ustranimogo-smescheniya"> 25      </h1><br><p>        ,     : </p><br><ul><li> <strong>  </strong> (,     ):    ,            .   ,     ,  ,     . </li><li> <strong>  ,   ,    </strong> .         ,         (      ).        ,    .        ;    ,     , ,  ,     . </li><li> <strong>    </strong> (L2 , L1 , Dropout):     , ,    . </li><li> <strong>  </strong> (,   )       :      ,     </li></ul><br><p>     : </p><br><ul><li> <strong>    </strong> :     ,        . </li></ul><br><h1 id="26-analiz-oshibok-na-trenirovochnoy-vyborke"> 26      </h1><br><p>        ,        / . </p><br><p>    ,  ,    ,           ,    ,        .   ,      , . .         . </p><br><p> ,        -         .         ,      ,   100 ,       ,        .      ,       : </p><br><div class="scrollable-table"><table><thead><tr><th>   </th><th>    </th><th>     </th><th>     </th><th>  Kommentare </th></tr></thead><tbody><tr><td>  1 </td><td>  X. </td><td></td><td></td><td>    </td></tr><tr><td>  2 </td><td>  X. </td><td></td><td>  X. </td><td>   </td></tr><tr><td>  3 </td><td></td><td>  X. </td><td>  X. </td><td>     </td></tr><tr><td>  4 </td><td>  X. </td><td></td><td></td><td>   </td></tr><tr><td> %   - </td><td>  75% </td><td>  25% </td><td>  50% </td><td></td></tr></tbody></table></div><br><p>       ,         ,    .       ,           . </p><br><p>      ,      -,      ,    .       ,    - ,   ,     ,  -     .      ,          ,  . </p><br><h1 id="27-podhody-k-umensheniyu-razbrosa"> 27     </h1><br><p>       ,     : </p><br><ul><li> <strong>     </strong> :         ,     ,                  . </li><li> <strong> </strong> (L1 , L2 , dropout):    ,   . </li><li> <strong>  </strong> (. .    ,       ):    ,   .      ,       . </li><li> <strong>    /  </strong> :       ,     .     (,  1000   900)       .   (  1000   100  10  )     ,      ,        .    ,   ,      ,        ,          ,     ,    ,      . ,     ,      . </li><li> <strong>  () </strong> (    / ). <em>  !</em>       , ,  . ,          .        .                  .       ,        . ,              ,     . </li></ul><br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Hier gebe ich zwei zus√§tzliche taktische Techniken an, die das wiederholen, was in den vorhergehenden Kapiteln in Bezug auf die Verringerung der Voreingenommenheit gesagt wurde: </font></font></p><br><ul><li> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Ñndern Sie die eingehenden Zeichen basierend auf dem Verst√§ndnis der Fehleranalyse</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Angenommen, Ihre Fehleranalyse hat zu der Idee gef√ºhrt, dass Sie zus√§tzliche Symptome erstellen k√∂nnen, die dem Algorithmus helfen, einige Fehlerkategorien zu beseitigen. </font><font style="vertical-align: inherit;">Diese neuen Funktionen reduzieren sowohl die Streuung als auch den Versatz. </font><font style="vertical-align: inherit;">Theoretisch kann das Hinzuf√ºgen neuer Merkmale die Verbreitung erh√∂hen; </font><font style="vertical-align: inherit;">In diesem Fall k√∂nnen Sie jedoch jederzeit die Regularisierung nutzen, die normalerweise die Zunahme der Streuung ausgleicht.</font></font></li><li> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Ñndern Sie die Modellarchitektur</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (z. B. die neuronale Netzwerkarchitektur), um sie f√ºr Ihre Aufgabe besser geeignet zu machen: Dieser Ansatz kann sowohl die Verzerrung als auch die Streuung verringern.</font></font></li></ul><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fortsetzung</font></font></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de420591/">https://habr.com/ru/post/de420591/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de420579/index.html">24-Kern-CPU, aber ich kann keine E-Mail eingeben</a></li>
<li><a href="../de420581/index.html">Prognose von Immobilienverk√§ufen. Vortrag in Yandex</a></li>
<li><a href="../de420585/index.html">Barcode-Datenbank kostenloser Download ohne Registrierung (und andere Persimonen)</a></li>
<li><a href="../de420587/index.html">Wo soll man diese Motoren jetzt hinstellen?</a></li>
<li><a href="../de420589/index.html">Worauf Sie bei der Auswahl eines Protokollierungssystems achten sollten und warum wir uns f√ºr ELK entschieden haben</a></li>
<li><a href="../de420593/index.html">Optimierung der mobilen Webnavigation (2 j√ºngste Erfolge)</a></li>
<li><a href="../de420595/index.html">Automatische Generierung von Programmen, inverses Problem und einige verwandte L√∂sungen</a></li>
<li><a href="../de420597/index.html">Datenschutzbeauftragter - GDPR aktualisiert Beruf</a></li>
<li><a href="../de420599/index.html">Dreizehn Dinge, die Lem vorausgesehen hat</a></li>
<li><a href="../de420603/index.html">Statistiken des Besitzers von Tesla Model S.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
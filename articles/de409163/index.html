<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõ∏ üß¶ ü§±üèº Warum das Verbot autonomer Killerroboter nichts l√∂st üëµüèº üíÖüèæ üñêüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Autonome Waffen - Killerroboter, die ohne menschliches Eingreifen angreifen k√∂nnen - dies ist ein sehr gef√§hrliches Werkzeug. Daran besteht kein Zweif...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Warum das Verbot autonomer Killerroboter nichts l√∂st</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/409163/"><img src="https://habrastorage.org/getpro/geektimes/post_images/092/080/d72/092080d723efe4713fc974aa6c426320.jpg"><br><br>  Autonome Waffen - Killerroboter, die ohne menschliches Eingreifen angreifen k√∂nnen - dies ist ein sehr gef√§hrliches Werkzeug.  Daran besteht kein Zweifel.  Wie in seinem offenen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Brief</a> an die UNO angegeben, unterzeichnete Ilon Musk, der unter ihm unterschrieb, Mustava Suleiman [ <i>Mitbegr√ºnder der KI-Firma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DeepMind</a> / ca.</i>  <i>perev.</i>  ] und anderen Autoren k√∂nnen autonome Waffen zu "Einsch√ºchterungswaffen werden, Waffen, die Tyrannen und Terroristen gegen eine unschuldige Bev√∂lkerung einsetzen k√∂nnen, Waffen, die gehackt und auf unerw√ºnschte Weise zum Funktionieren gebracht werden k√∂nnen". <br><br>  Dies bedeutet jedoch nicht, dass die Vereinten Nationen ein vorbeugendes Verbot der weiteren Erforschung solcher Waffen einf√ºhren sollten, wie die Autoren des Briefes fordern. <br><br>  Erstens werden manchmal gef√§hrliche Werkzeuge ben√∂tigt, um w√ºrdige Ziele zu erreichen.  Erinnern Sie sich an den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">V√∂lkermord in Ruanda,</a> als die Welt bereit stand und nichts tat.  Wenn es 1994 autonome Waffen g√§be, w√ºrden wir vielleicht nicht zur Seite schauen.  Es ist wahrscheinlich, dass es einfacher w√§re, √∂ffentliche Unterst√ºtzung f√ºr solche Interventionen zu erhalten, wenn die Kosten f√ºr humanit√§re Interventionen nur mit Geld gemessen werden k√∂nnten. <br><a name="habracut"></a><br>  Zweitens ist es naiv zu glauben, dass wir die Vorteile der j√ºngsten Durchbr√ºche in der KI genie√üen k√∂nnen, ohne einige ihrer M√§ngel feststellen zu m√ºssen.  Angenommen, die UNO f√ºhrt ein vorbeugendes Verbot jeglicher Technologie autonomer Waffen ein.  Wir gehen auch - schon recht optimistisch - davon aus, dass alle Armeen der Welt dieses Verbot respektieren und die Entwicklung autonomer Waffenprogramme aufheben werden.  Und selbst dann m√ºssen wir uns noch darum k√ºmmern.  Ein Robomobil kann leicht in ein autonomes Waffensystem verwandelt werden: Anstatt Fu√üg√§nger zu umgehen, k√∂nnen Sie ihm beibringen, sie zu bewegen. <br><br>  Im Allgemeinen sind KI-Technologien √§u√üerst n√ºtzlich und dringen bereits in unser Leben ein, auch wenn wir dies manchmal nicht sehen und es nicht vollst√§ndig realisieren k√∂nnen.  Angesichts dieser Durchdringung w√§re es kurzsichtig zu glauben, dass der Missbrauch von Technologie einfach durch ein Verbot der Entwicklung autonomer Waffen verboten werden k√∂nnte.  Vielleicht sind es gerade die ausgekl√ºgelten und selektiv funktionierenden autonomen Waffensysteme, die von verschiedenen Armeen auf der ganzen Welt entwickelt wurden, die den raueren autonomen Waffen, die leicht zu entwickeln sind, durch Umprogrammierung der scheinbar friedlichen KI-Technologie wie der gleichen Robomobile wirksam entgegenwirken k√∂nnen. <br><br>  Dar√ºber hinaus bietet die Idee eines einfachen Verbots auf internationaler Ebene einen stark vereinfachten Ansatz f√ºr die Ber√ºcksichtigung autonomer Waffen.  Ein solches Konzept erkennt nicht die lange Geschichte der Ursachen und Auswirkungen von Ma√ünahmen und Vereinbarungen verschiedener L√§nder untereinander und allein an, die durch Tausende kleiner Ma√ünahmen und Unterlassungen zur Entwicklung solcher Technologien gef√ºhrt haben.  W√§hrend die Debatte √ºber autonome Waffen haupts√§chlich auf UN-Ebene gef√ºhrt wird, kann dem Durchschnittsb√ºrger, Soldaten oder Programmierer vergeben werden, dass er keine moralischen Verpflichtungen f√ºr den durch autonome Waffen verursachten Schaden √ºbernommen hat.  Dies ist jedoch eine sehr gef√§hrliche Annahme, die zu einer Katastrophe f√ºhren kann. <br><br>  Alle Menschen, die in irgendeiner Weise mit automatischen Waffentechnologien verwandt sind, sollten die gebotene Sorgfalt walten lassen, und jeder von uns muss sorgf√§ltig dar√ºber nachdenken, welchen Beitrag sein Handeln oder seine Unt√§tigkeit zur Liste der potenziellen Gefahren dieser Technologie leistet.  Dies bedeutet nicht, dass L√§nder und internationale Agenturen ihre wichtige Rolle nicht spielen.  Dies wird durch die Tatsache unterstrichen, dass, wenn wir die potenzielle Gefahr automatischer Waffen beseitigen wollen, die Ethik der pers√∂nlichen Verantwortung gef√∂rdert werden muss und diese Propaganda die niedrigsten Ebenen erreichen sollte, auf denen Entscheidungen getroffen werden.  Zun√§chst ist es √§u√üerst wichtig, ausf√ºhrlich und vollst√§ndig √ºber die Entwicklung autonomer Waffen zu sprechen - einschlie√ülich der Konsequenzen des Handelns aller, die auf allen Ebenen Entscheidungen treffen. <br><br>  Schlie√ülich wird manchmal argumentiert, dass eine autonome Waffe nicht deshalb gef√§hrlich ist, weil dieses Werkzeug an sich gef√§hrlich ist, sondern weil es unabh√§ngig werden und anfangen kann, in seinem eigenen Interesse zu handeln.  Dies ist ein falscher Fehler, und au√üerdem wird das Verbot der Entwicklung autonomer Waffen nicht dazu beitragen, diese Gefahr zu verhindern.  Wenn Superintelligenz eine Bedrohung f√ºr die Menschheit darstellt, m√ºssen wir dringend nach Wegen suchen, um dieser Bedrohung wirksam entgegenzuwirken, und dies unabh√§ngig davon, ob die Technologie der automatischen Waffen weiterentwickelt wird. <br><br><h2>  Offener Brief an das √úbereinkommen der Vereinten Nationen √ºber bestimmte konventionelle Waffen </h2><br>  Da einige Unternehmen Technologien im Zusammenhang mit k√ºnstlicher Intelligenz und Robotik entwickeln, die auf die Entwicklung autonomer Waffen umgeleitet werden k√∂nnen, f√ºhlen wir uns besonders daf√ºr verantwortlich, diesen Alarm auszul√∂sen.  Wir begr√º√üen die Entscheidung der UN-Konferenz √ºber die Annahme des "√úbereinkommens √ºber bestimmte Arten konventioneller Waffen" zur Ernennung einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://www.unog.ch/80256EE600585943/(">Gruppe von Regierungsexperten</a> (Gruppe von Regierungsexperten, GGE) zu t√∂dlichen autonomen Waffensystemen sehr.  Viele unserer Forscher und Ingenieure sind bereit, technologische Ratschl√§ge zu geben, um dieses Problem zu l√∂sen. <br><br>  Wir begr√º√üen die Ernennung von Botschafter Amandip Singh Gill aus Indien zum Vorsitzenden der GGE.  Wir fordern die an der GGE beteiligten Hohen Vertragsparteien auf, aktiv daran zu arbeiten, Wege zu finden, um diese Art von Wettr√ºsten zu verhindern, die B√ºrger vor ihrem Missbrauch zu sch√ºtzen und die destabilisierenden Auswirkungen dieser Technologien zu vermeiden.  Wir bedauern, dass das erste GGE-Treffen, das f√ºr August 2017 geplant ist, abgesagt wurde, da einige L√§nder keinen finanziellen Beitrag zur UN geleistet haben.  Wir fordern die Hohen Vertragsparteien nachdr√ºcklich auf, ihre Bem√ºhungen beim ersten GGE-Treffen im November zu verdoppeln. <br><br>  Detaillierte autonome Waffen drohen eine dritte Revolution in milit√§rischen Angelegenheiten herbeizuf√ºhren.  Nach seiner Entwicklung wird es m√∂glich sein, milit√§rische Konflikte in einem bisher nicht gekannten Ausma√ü und in k√ºrzeren Zeitr√§umen als dem, was eine Person wahrnehmen kann, zu f√ºhren.  Es kann eine Waffe der Einsch√ºchterung werden, eine Waffe, die Tyrannen und Terroristen gegen eine unschuldige Bev√∂lkerung einsetzen k√∂nnen, eine Waffe, die gehackt und auf unerw√ºnschte Weise zum Funktionieren gebracht werden kann.  Wir haben wenig Zeit √ºbrig.  Nach dem √ñffnen der B√ºchse dieser Pandora wird es schwierig sein, sie zu schlie√üen.  Daher bitten wir die Hohen Vertragsparteien, Wege zu finden, um uns alle vor diesen Bedrohungen zu sch√ºtzen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de409163/">https://habr.com/ru/post/de409163/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de409153/index.html">Die ‚ÄûKreativit√§t‚Äú der k√ºnstlichen Intelligenz ver√§ndert unser Verst√§ndnis des Realen</a></li>
<li><a href="../de409155/index.html">China baut Autobahn mit Sonnenkollektoren und transparentem Beton</a></li>
<li><a href="../de409157/index.html">Menschliches Bewusstsein. Kopie kann nicht √ºbertragen werden?</a></li>
<li><a href="../de409159/index.html">SIGSALY oder The Green Hornet: Verteidigung der Verbindung Washington - London</a></li>
<li><a href="../de409161/index.html">Der Einfluss des Rahmens auf die Eigenschaften des Hubschraubers</a></li>
<li><a href="../de409165/index.html">Spieltheorie, Mausaufheben und platter Reifen</a></li>
<li><a href="../de409167/index.html">Nicht so war es! 5 Hauptmissverst√§ndnisse √ºber das √úbertakten von "Eisen"</a></li>
<li><a href="../de409169/index.html">Wie man Make-up liest</a></li>
<li><a href="../de409171/index.html">So montieren Sie einen Smart Cat Feeder</a></li>
<li><a href="../de409173/index.html">KI f√ºr den pers√∂nlichen Gebrauch: Hilfe bei Bildung, Arbeit und Planung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
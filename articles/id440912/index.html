<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👊🏿 🙇 🤹🏾 Seperti rasa sakit, rasa sakit, infrastruktur sebagai layanan 1: 0 🚡 🙍 🤛🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kami membuat sistem deteksi pinjaman terbaik di Rusia dan negara-negara tetangga. Di dunia yang ideal, kita hanya akan berurusan dengan desain dan pen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Seperti rasa sakit, rasa sakit, infrastruktur sebagai layanan 1: 0</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/antiplagiat/blog/440912/"><p>  Kami membuat sistem deteksi pinjaman terbaik di Rusia dan negara-negara tetangga.  Di dunia yang ideal, kita hanya akan berurusan dengan desain dan pengembangan sistem.  Namun, sayangnya, Anti-plagiarisme tidak berfungsi dalam ruang hampa, dan agar pengguna kami dapat menggunakan perkembangan kami dengan nyaman dan nyaman, kami juga perlu mengembangkan lingkungan di sekitar layanan kami.  Perangkat lunak kami tidak berfungsi tanpa besi, pengguna perlu memberikan dukungan teknis, perlu menerima pembayaran dari pengguna tanpa melanggar hukum, dll.  Singkatnya, rutinitas sudah cukup. </p><br><p>  Artikel ini adalah yang pertama dari serangkaian <strike>drama produksi</strike> tentang bagaimana kami membuat layanan kami lebih baik dengan outsourcing.  Kami berbagi masalah dan kesimpulan nyata. </p><br><h1>  Awan, kuda berambut pirang ... </h1><br><img src="https://habrastorage.org/webt/zv/gk/jj/zvgkjjsz7yiiggzxydco6uvippi.png"><br>  <sup><em>(dari suatu tempat di Internet, saya pertama kali melihatnya di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> .)</em></sup> <br><p>  Beban pada sistem kami sangat tidak merata: pertama, pada siang hari beban berubah 5 kali.  Kedua, ada musiman diucapkan.  Maksimum harian cek setelah akhir sesi musim panas berkurang 10 kali!  Sesi musim dingin tidak begitu cerah, tetapi juga bukan hadiah.  Plus, setiap sesi musim panas berikutnya lebih berat (dalam hal jumlah pemeriksaan) dan lebih sulit (teknologi pencarian dan fungsi baru) dari yang sebelumnya.  Oleh karena itu, di satu sisi, saya ingin memiliki persediaan sumber daya yang baik, di sisi lain, tidak membayar terlalu banyak selama penurunan aktivitas.  Dalam satu sesi, Anda dapat menggunakan lebih banyak server, dan di musim panas mengurangi jumlah sumber daya yang dikonsumsi.  Jelas, ini hanya terjadi dengan penyedia cloud.  Pada artikel ini, saya akan berbicara tentang berbagai aspek berinteraksi dengan beberapa penyedia cloud (AWS, IT Grad, MCS, YC).  Jika kelihatannya seseorang bahwa ini adalah tangisan jiwa, dia tidak akan sangat keliru.  Jadi ayo pergi! <br></p><a name="habracut"></a><br><h2>  Aws </h2><br><p>  Kami mulai menggunakan sumber daya cloud pada Februari 2013 ketika kami menyewa server pertama kami di AWS.  Faktanya, Amazon adalah pengalaman Anti-Plagiarisme pertama dan terpanjang dengan awan.  Lalu kami mulai dengan satu mesin, dan sekarang anggaran kami di AWS adalah urutan besarnya lebih tinggi dari anggaran untuk semua cloud Rusia.  Cinta pertama, seperti yang Anda tahu, tidak pernah dilupakan.  Semua masalah dan peluang dengan cloud lain dalam artikel ini saya pertimbangkan berdasarkan pengalaman menggunakan AWS. </p><br><p>  Benar, ada juga lalat di salep dalam hubungan dengan Amazon.  Berikut ini adalah fitur atau ketidaknyamanan yang kami miliki dengan Amazon: <br><br></p><ol><li>  Anda tidak dapat mengakses konsol mesin virtual melalui browser.  Dan terkadang itu di sini benar-benar dibutuhkan!  Setelah kami keliru menghapus antarmuka jaringan, dan akses hilang di salah satu mesin.  Beruntung seseorang telah mengalami masalah seperti itu, dalam setengah jam kami menemukan dan berhasil menerapkan solusi.  Melalui konsol, operasi seperti itu dapat dilakukan dalam satu menit. </li><li> Biaya dalam dolar, dan kami dapatkan dalam rubel.  Dengan demikian, profitabilitas tergantung pada dolar. </li><li>  Tidak ada pusat data di Rusia, yang terdekat ketika kami memulai adalah di Irlandia.  Ini berarti ping besar dan beberapa pembatasan penyimpanan data yang muncul karena persyaratan hukum Rusia. </li><li>  Roskomnadzor secara teratur memblokir alamat AWS.  Saat ini, ada ketersediaan server yang berbeda di AWS dari situs yang berbeda.  Untuk alasan yang tidak diketahui, koneksi ke mesin mungkin jatuh.  Biasanya, mengubah alamat IP, VPN, dan proksi membantu. </li><li>  Amazon secara signifikan lebih mahal daripada awan Rusia.  Benar, Anda dapat mengurangi biaya melalui program <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">cadangan yang</a> fleksibel dan penggunaan mesin <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">virtual</a> .  Dan kami secara aktif menggunakan keduanya.  Sayangnya, kami belum melihat fungsi seperti itu di cloud domestik (pembaruan: YC mengumumkan "VM terputus" pada buletin 18 Februari, kami sedang menunggu detailnya). </li><li>  Masalah dengan pesan yang kurang informatif.  Selama transisi dari mesin generasi ke-3 ke ke-4 atau ke-5, perangkat keras virtual berubah secara serius, khususnya, metode menghubungkan drive, dan mesin-mesin itu baru saja mulai setelah jenisnya diubah.  Antarmuka manajemen instance mengembalikan pesan singkat: kapasitas tidak mencukupi.  Ada cukup banyak batasan untuk membuat jenis mesin yang diperlukan dengan margin, dan selama sekitar enam bulan kami gagal mencoba dukungan teknis gratis untuk mengubah batas.  Itu tidak membantu.  Sebagai hasilnya, mereka mencari sendiri solusinya - rekreasi dangkal dari alat berat itu membantu. </li><li>  Beberapa kali kami menghapus SSD hingga berlubang: disk hilang begitu saja dari sistem beserta semua data.  Mengingat bahwa ini adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">disk yang sementara</a> , mis.  data hilang ketika mesin berhenti, kami tidak menyimpan sesuatu yang tak tergantikan pada mereka. </li></ol><br><p>  Pada prinsipnya, adalah mungkin untuk hidup dengan kekurangan-kekurangan ini.  Namun, tepat pada saat ketika Amazon akhirnya memperhatikan pasar Rusia, akun kami menjadi sangat tidak nyaman untuk pembayaran dari kartu.  Untungnya, Amazon dengan cepat memperbaiki situasi dan memberi kami manajer akun yang membantu kami beralih dari pembayaran melalui kartu ke kontrak langsung dan membayar tagihan serta membuat berbagai jenis perjanjian.  Secara umum, ia secara teratur datang ke Rusia, dan ketika ia mendatangi kami, ia berbicara tentang peluang untuk mengoptimalkan infrastruktur dan pembayaran.  Terkadang dia membawa Solusi Arsitek, yang dengannya dia dapat mendiskusikan arsitektur solusi kami saat ini, berbicara tentang "Wishlist" dan masalah, dan mendapatkan beberapa solusi, tidak hanya melalui layanan AWS.  Karyawan Amazon menyatakan bahwa tujuan mereka bukan untuk menyediakan lebih banyak layanan, tetapi untuk memastikan bahwa layanan yang dibeli bermanfaat bagi bisnis.  Sepertinya ini benar.  Jumlah layanan, kecepatan pengembangan mereka dan kedalaman integrasi timbal balik sangat mengesankan.  AWS memiliki segalanya untuk mengatur proses pengembangan dan pengoperasian sistem yang sangat dimuat dalam skala apa pun.  Sejauh ini, hanya satu masalah global yang mahal! </p><br><h2>  IT Grad 2016 </h2><br><p>  Pada 2015, kami memutuskan bahwa sudah waktunya bagi kami untuk sepenuhnya meninggalkan besi kami sendiri.  Saya ingin meletakkan masalah pada keandalan peralatan secara khusus pada orang lain dan lebih berkonsentrasi pada peningkatan proses pengembangan kita sendiri.  Menurut perkiraan kami, pada tahun 2016 kami akan memiliki cukup peralatan yang kami miliki saat ini, dan kami ingin memiliki cadangan untuk setiap peristiwa kebakaran.  Kami mendekati pilihan penyedia secara menyeluruh: kami menyiapkan tes beban dan kuesioner dengan pertanyaan-pertanyaan penting bagi kami dan dengan cermat memilih dari lima penyedia: ActiveCloud, Cloud4Y, CloudOne, IT Grad, Softline. </p><br><p>  Sebagai hasilnya, kami memilih awan IT Grad.  Keuntungan mereka: <br></p><ol><li>  Posisi hidup aktif, jawaban pertanyaan kami diberikan dengan cepat, mudah berkomunikasi. </li><li>  Kehadiran drive SSD cepat, hingga 30 IOPS per GB.  Jumlah operasi baca acak adalah indikator yang sangat penting bagi kami, karena nilai yang tinggi memungkinkan kami untuk menempatkan modul pindaian kami di cloud. </li><li>  Platform VCloud dengan kemampuan untuk mengendalikan mesin dan kehadiran konsol untuk setiap mesin. </li><li>  Kemampuan untuk meningkatkan sumber daya mesin virtual tanpa me-reboot. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tagihan fleksibel</a> - pembayaran dilakukan untuk sumber daya yang digunakan pada hari di tengah periode pelaporan (pada tanggal 14-15 setiap bulan).  Selain itu, ada opsi "Pay-As-You-Go", namun, itu lebih mahal dan perhitungan jumlah sumber daya yang dikonsumsi dilakukan oleh beban rata-rata CPU dan RAM setiap 2 jam. </li></ol><br><p>  Pada 2016, kami pindah ke IT Grad.  Inilah yang terjadi dalam tiga tahun kehidupan kita yang tidak lengkap: <br><br></p><ol><li>  Dulu kami punya masalah.  Tepat pada pukul 21:00, terjadi penurunan kinerja yang aneh.  Jumlah cek yang dapat dilakukan sistem turun dari 150 menjadi 20-30 per menit, sementara setelah beberapa jam semuanya dipulihkan dan diselesaikan dengan kecepatan 600 cek per menit.  Kami mencari selama seminggu di rumah, memeriksa pengguna, menangkap bot dan DDoS, tetapi tidak menemukan apa pun.  Kami beralih ke dukungan IT-Grad, menemukan bahwa "oh, dan kami sedang membuat cadangan di sini."  Akibatnya, mereka menghancurkan kami dengan sumber masalah pada sistem disk yang berbeda dan mengatur pekerjaan. </li><li>  Biasanya (fitur menggunakan produk), selama sesi, lalu lintas kami melebihi 100 megabit per detik.  Nilai ini, by the way, sering ditetapkan secara default untuk saluran yang tidak dicadangkan di banyak penyedia cloud.  Ketika kami pertama kali melewati perbatasan ini, sejumlah masalah muncul: Edge bawaan tidak dapat mengatasi VPN antara titik masuk yang terletak di peralatan kami dan mesin virtual server web yang terletak di cloud.  Seperti yang diharapkan, mereka beralih ke dukungan, di mana kami ditawari untuk meningkatkan sumber daya di Edge.  Oke, tidak ada pertanyaan, kami mengganti konfigurasinya dari kecil ke besar, dan juga memperluas saluran ke ukuran lalu lintas puncak kami dengan margin.  Itu tidak membantu.  Secara umum, kami tidak dapat menemukan solusi optimal, saya harus mengurangi volume lalu lintas dengan memindahkan sebagian produksi ke situs lain. </li><li>  Koneksi VPN ke situs IT Grad terkadang putus selama 1-2 menit.  Untuk pertanyaan mengapa ini terjadi, baik kami maupun dukungan teknis tidak dapat menemukan jawabannya.  Sejauh ini saya harus hidup dengan masalah ini. </li><li>  Mekanisme untuk mengubah ukuran sumber daya bekerja dengan buruk, baik dengan cepat maupun dalam kondisi tidak aktif.  Sepertinya saya, bagaimanapun, ini agak masalah dengan vendor platform (VMware).  Namun demikian, kami telah menemukan fakta bahwa untuk dapat menerapkan semua ekstensi secara andal, perlu menyalakan ulang mesin tamu (Windows Server 2012 R2).  Setelah mengubah ukuran, mesin itu sendiri tidak bisa boot beberapa kali.  Dukungan sekali memperbaiki masalah ini dari 2 hingga 4 di pagi hari selama sesi - musim kami.  Itu panas bahkan di malam hari! </li><li>  Pada 2016, kami memiliki monolit besar, seperti Everest, yang membutuhkan banyak sumber daya.  Begitu banyak yang kadang-kadang kita perlu melebihi ukuran maksimum mesin tamu yang direkomendasikan untuk host yang diberikan.  Dukungan terus-menerus meminta kami untuk mengurangi ukuran mesin virtual hingga setidaknya setengah dari ukuran host.  Kami harus membayar upeti kepada IT Grad - kami ditawari untuk menggunakan perangkat keras terpisah dengan kemampuan untuk menggunakannya sepenuhnya, namun, untuk beberapa uang besar lainnya, dan fleksibilitas cloud hilang. </li><li>  Tagihan sebulan sekali untuk mengukur jumlah sumber daya yang dikonsumsi telah menipu kami dua kali.  Pada awalnya, kami langsung bertanya tentang kesempatan untuk mengurangi sumber daya pada tanggal 14-15 dalam sebulan untuk membayar lebih sedikit.  Kami langsung menjawab bahwa ini cara kerjanya.  Pertama kali itu menghantam kami dengan susah payah selama transfer sebagian dari penjualan ke cloud kami.  Faktor manusia bekerja - mereka mencoba menyelesaikan semuanya dengan cepat pada tanggal 14, kemudian mereka menyapu bersihnya.  Kedua kalinya kami mengambil kesempatan ini setelah hampir 3 tahun bekerja sama, setelah itu kami ditagih rata-rata pada hari ke 5, 15, 20.  Kemudian faktor manusia bekerja untuk mereka - setelah panggilan itu ternyata mereka melakukan kesalahan yang menguntungkan mereka (perhitungan ulang dilakukan secara manual), meminta maaf, memberikan diskon. </li><li>  Kinerja disk dan mesin secara keseluruhan memenuhi karakteristik yang dinyatakan.  Namun demikian, beberapa kali kami tidak dapat memahami mengapa semuanya bekerja sangat lambat, bahkan antarmuka melambat tanpa ampun.  Dukungan meyakinkan bahwa semuanya beres dan mereka tidak memiliki masalah dengan peralatan.  Apa yang terjadi di sana - server kami pada saat itu bermigrasi ke host tetangga atau seseorang membuat cadangan dari subsistem disk - itu tetap menjadi misteri bagi kami. </li><li>  Disk dapat beralih antara mesin secara mandiri hanya melalui dukungan.  Pada awal penggunaan, tidak mungkin memiliki disk dengan jenis berbeda di mesin, Anda harus keluar (iSCSI, Samba dan NFS).  Setelah beberapa waktu, menggunakan berbagai jenis disk dalam satu mesin menjadi mungkin pertama melalui dukungan, dan kemudian sendiri (tampaknya dilakukan di vCloudDirector).  Omong-omong, memperbarui sistem manajemen virtualisasi terjadi secara teratur.  Kami menerima surat 1-2 kali sebulan yang menyatakan bahwa selama satu atau dua jam sistem kontrol mesin virtual mengambil pekerjaan teknis dan tidak akan tersedia untuk beberapa waktu, mesin itu sendiri terus bekerja pada saat ini. </li><li>  Pada 16 Februari 2018, bagian dari penjualan kami yang berlokasi di IT Grad terletak karena masalah pasokan daya dari pusat data di mana peralatan itu berada.  Kami mengetahui tentang kejadian tersebut secara de facto, kami tidak dapat menghubungi dukungan teknis.  Saya harus menghubungi manajer akun kami, dia segera berkata apa dan bagaimana, dan terputus, tampaknya mengatakan sisanya.  Dari yang menyenangkan - kami berbaring di sebelah VKontakte. </li></ol><br><p>  Setelah menghabiskan beberapa waktu di rumah sewaan dan menghadapi semua hal di atas, pada tahun 2017 kami memutuskan bahwa itu baik untuk dikunjungi, tetapi lebih baik di rumah, dan mulai membuat cloud dengan disk NVMe yang cepat dan kemampuan untuk sepenuhnya mengendalikan semuanya.  Tidak lama setelah selesai mengatakan: mereka memindahkan penjualan ke cloud mereka dari klien korporat dan modul pencarian (total lebih dari 90% dari beban), meninggalkan pemantauan, statistik dan klien pribadi di IT Grad.  Pada tahun 2018, semua orang sekali lagi menghitung semuanya dan ternyata lebih menguntungkan untuk membagi produksi: tetap menjadi bagian dalam cloud yang disewa, dan bagian dalam diri mereka sendiri.  Apa yang terjadi dengan ini - kami ceritakan lebih lanjut. </p><br><h2>  Solusi cloud mail </h2><br><p>  Jujur, saya ingin, seperti di AWS, tetapi di Rusia.  Oleh karena itu, kami mulai melihat ke arah awan dengan serangkaian layanan serupa (yang saya tipu, paling tidak dengan analog EC2 dan S3).  Pencarian berumur pendek - kami menemukan "Amazon Rusia" dalam pribadi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MCS</a> .  Sebuah perusahaan besar dengan beragam layanan yang beragam, dengan semua indikasi mereka harus dapat mempersiapkan awan! </p><br><p>  Awal dari kenalan itu luar biasa.  Seorang manajer akun datang ke kantor kami, menceritakan semuanya secara terperinci, menggambarkan peluang dan rencana saat ini untuk waktu dekat.  Outputnya adalah gambar yang luar biasa: harga rendah untuk sumber daya komputasi, ada penyimpanan objek dan keluar awal ke produksi basis data (mirip dengan RDS).  Kami juga diberi batas uang tunai untuk pengujian (bahkan lebih dari yang diberikan Azure). </p><br><p>  Pada saat itu, kami sudah memiliki bagian IaC siap untuk menyebarkan semua mesin melalui terraform.  MCS memiliki openstack dan didukung dengan baik!  Ngomong-ngomong, dukungan teknis dilakukan melalui saluran telegram - komunikasi "langsung" dan jelas bahwa mereka ingin membantu.  Ada sistem tiket, tapi kami belum menggunakannya.  Dukungan Teknis SLA mengacu pada permintaan yang dibuat dalam sistem tiket. </p><br><p>  Pada Desember 2018, kami telah menulis skrip penyebaran infrastruktur melalui terraform.  Saatnya bergerak.  Untuk mulai dengan, kami memutuskan untuk mentransfer sistem dengan klien pribadi, yang selama ini hidup dengan peralatan di IT Grad.  Maka semuanya seperti dalam film: <br></p><blockquote><code>7  (), 18:00     .  ,          . <br> 10  (), 10:00   –     . <br> 12  () –  . <br> 10:00     terraform.     ,   ,    . <br> 12:00   ansible'.   .   ! <br> 15:30  .         30 ,            16:30. <br> 15:45      .      . <br> 15:55     .     :  ,     . <br> 16:20 ,       .   ,    . ,     -            . <br> 17:30     ,    ,    . <br> 18:00        .       1,5 . <br></code> </blockquote><br><p>  Masalah yang diidentifikasi dengan format berbeda dengan upaya baru seharusnya tidak muncul, tetapi kami menemukannya dan kalau-kalau diperbaiki. <br></p><blockquote> <code>17  (),   . <br> 15:30    .      ,      . <br> 16:00        .   . <br> 16:30      ,      100%.   -?   ! <br> 17:00       ,   ,  , , iotop, top, ProcessExplorer, PerformanceMonitor.  . <br> 21:45    ,   ,  ,    2000 . <br> 22:00  ,  . <br></code> </blockquote><br><p>  Produk lama pada IT Grad dengan mudah memenuhi permintaan yang ditangguhkan untuk cek pengguna, tidak masalah. </p>  Hari berikutnya (18 Desember), kami menyadari hal berikut: <br><br><ol><li>  Kami tidak tahu apa yang memperlambat sistem secara khusus.  Sebelum dekorasi, praktis tidak ada beban di mana pun.  Ya, kami masih memiliki panggilan pemblokiran yang dalam di dalam sistem dan kemungkinan besar ada penyumbatan di suatu tempat, tetapi di mana tepatnya, kami tidak dapat menemukan, perlu untuk menyelidiki lebih lanjut. </li><li>  Tes beban kami saat ini tidak cocok dengan profil beban untuk prod.  Itu luar biasa karena  berkat tes ini, kami bersiap untuk sesi terakhir, mengidentifikasi dan menghilangkan sejumlah besar kemacetan.  Tapi itulah kenyataannya - perlu untuk mengulang tes dengan mempertimbangkan pengalaman yang didapat. </li><li>  Diproduksi pada IT Grade dengan sumber daya CPU dan RAM yang sebanding, dapat dengan mudah mengatasi beban dua kali lipat. </li></ol><br>  Jadi, kami dengan cepat membangun tes yang mencapai hasil yang sama dengan yang kami lihat secara langsung.  Kami pergi ke dukungan MCS untuk mengetahui apakah kami makan di luar batas CPU, tetapi secara umum itu adalah milik kami sepenuhnya atau tidak, dan semuanya baik-baik saja dengan jaringan.  Mereka masih belum menjawab pertanyaan kedua, mereka menemukan sesuatu pada yang ketiga dan merekomendasikan kami untuk melakukan perubahan pada sistem multi-core.  Secara umum, kami telah mengembangkan kegiatan yang bersemangat, akhir tahun sudah dekat, dan semua orang ingin pergi untuk liburan dengan rasa prestasi. <br><p>  Inilah yang akhirnya kami lakukan saat bekerja dengan MCS: <br><br></p><ol><li>  Bahkan pada tahap seleksi, kami dikirimi meja dengan karakteristik perangkat keras virtual dan SLA oleh disk.  Salah satu kelebihannya adalah bahwa mereka menjanjikan 50 IOPS / GB (IT Grad: 30 IOPS / GB) untuk SSD.  Kontrak ternyata berbeda: "membaca: 5000 IOPS, menulis: 2000 IOPS", dan kami melewatkan ini, kami tidak mengharapkan ini.  Tabelnya identik, perbedaannya hanya di satu tempat!  Omong-omong, kami tidak melihat dependensi kinerja pada ukuran disk.  Saat kami uji, ternyata dengan drive yang lebih besar, kecepatannya menurun.  Rahasia dari indikator kecil tersebut adalah bahwa MCS memiliki geo-didistribusikan ceph, yang berarti bahwa sampai node jauh mengatakan bahwa data telah ditulis, klien tidak akan diberitahu bahwa rekaman selesai.  Ngomong-ngomong, tidak ada yang tampaknya memiliki keandalan seperti itu "di luar kotak" di antara penyedia layanan yang berbicara dengan kami.  Tetapi bagi kami keandalan seperti itu hanya menempatkan tongkat di roda!  Jika sesuatu terjadi, kita perlu dengan cepat pindah ke DC lain ketika masalah muncul, dan karena itu kita memiliki replikasi asinkron kita sendiri.  Kami memiliki <abbr title="Rencana pemulihan bencana">DRP</abbr> , dan kami siap untuk kehilangan sejumlah kecil data jika terjadi kecelakaan.  Kita harus membayar upeti kepada MCS, mereka mempercepat commissioning array SSD lokal, yang kinerjanya jauh lebih tinggi. </li><li>  Adapun parameter mesin, mereka tidak sewenang-wenang.  Ada serangkaian CPU-RAM- {SSD / HDD} (hampir seperti pada AWS), dan jenis mesin lainnya hanya dapat dibuat melalui dukungan.  Seluruh proses memakan waktu sekitar 2 jam, tidak ada batasan pada jumlah jenis, yang utama adalah bahwa jumlah core harus tidak lebih dari setengah dari prosesor hypervisor ~ 40-48.  Selama pembuatan mesin, Anda dapat menambahkan disk sendiri dan beralih di antara mesin. </li><li>  Setelah menyalakan SSD lokal, mengubah parameter mesin membuatnya mustahil untuk memulai.  Mereka hanya bisa diluncurkan melalui dukungan.  Di suatu tempat dalam sebulan mereka memecahkan masalah. </li><li>  Untuk pertama kalinya dihadapkan dengan dukungan teknis oleh telegram.  Secara umum, itu nyaman, terutama di awal, ketika ada banyak pertanyaan dan ada banyak ke layanan.  Tetapi semakin jauh, semakin sulit pertanyaan yang muncul dan kecepatan respon dan konten informasi perlahan-lahan menurun.  Pada akhir tahun, ketika, tentu saja, tenggat waktu semua orang, kecepatan respon yang rendah membuat saya sangat marah.  Pada titik tertentu, mereka bahkan bertanya tentang SLA.  Di sinilah pemahaman muncul bahwa SLA ada di sistem tiket, dan bukan di telegram!  Pada saat 19 Februari, beberapa pertanyaan kami yang belum terjawab yang diajukan pada tanggal 24 Desember digantung di saluran ini ... </li><li>  Dukungan teknis melalui sistem tiket tidak memperhitungkan bahwa kami login, dan memerlukan pemberitahuan tambahan dari nomor kontrak.  Sebagai tanggapan, ia mengirim surat "kami akan menghubungi Anda", tetapi tidak menunjukkan nomor tiket atau status. </li></ol><br><p>  Saat bekerja dengan MCS, awan lain mulai terlihat paralel. </p><br><h2>  Namun Awan lain (Awan Yandex) </h2><br><p>  Yang pertama adalah Yandex.  Pada akhir 2018, mereka hanya memiliki mesin virtual dan penyimpanan objek, shell sistem virtualisasi mereka sendiri, API terbuka.  Plugin terraform berada di alfa dan disetujui oleh HashiCorp.  Dukungan, seperti biasa, adalah melalui telegram, tetapi kurang aktif daripada di MCS.  Batas uang uji cukup kecil dan tidak memungkinkan kami melakukan pengujian normal.  Saya harus buru-buru membuat perjanjian (3 hari kerja) dan membayar untuk pengujian.  Menurut hasil tes, kami mendapat hal yang sama seperti pada MCS.  Bagi kami, tampaknya ada dua masalah: setiap orang memiliki drive yang terlalu lambat, dan kami memiliki tes yang terlalu berat. </p><br><h2>  IT Grad 2019 </h2><br><p>  Secara umum, kami menetapkan tenggat waktu untuk pindah sudah pada 22 Desember, sehingga akan ada satu minggu lagi untuk mengidentifikasi dan memecahkan masalah tersembunyi dari tempat tinggal baru.  Setelah kehilangan harapan untuk pindah ke tenggat waktu dan sedikit lelah dengan banyaknya informasi baru dalam diri MCS dan YC, kami memutuskan bahwa IT Grad tidak terlalu buruk dengan latar belakang mereka.  Kami bahkan merasa sedikit nostalgia dan berpikir bahwa segala sesuatu yang baru sudah lama mapan.  Sudah di IT Grad kita pasti akan bekerja dengan baik - ada preseden.  Ditambah IT Grad memompa: ada pusat data Moskow, Tier III, saat ini masih memiliki 100% (tidak pernah gagal), dan peralatan di dalamnya adalah 4-socket Intel Xeon Scalable (hingga 42 core x 3 GHz Xeon Gold 6154).  Apa-apaan ini bukan bercanda, kami akan memberikan kesempatan kedua! <br></p><blockquote> <code>28  (), 18:10   -     vDC      ,    ,          . <br> 29  ( ), 17:04    ,   .   .iso  ,          .           ,   .  ,    .   ,    . <br> 30  (), 22:00 ,            .iso,             .       ,   - . <br> 31  (), 3:15    Edge   vDC    vDC. ,              .      . <br> <br>  ,   . <br> <br> 2  (), 15:30       . <br> 2  (), 21:50 ,   Guest OS Customization  . <br> 3  (), 18:05   !</code> </blockquote> <br><p></p><ol><li>  Sekarang, dalam persiapan artikel, mereka menemukan bahwa waktu yang tepat untuk permintaan dan jawaban tidak tercermin dalam sistem tiket.  Sebaliknya, ia mengatakan "sekitar 2 bulan yang lalu," waktu yang tepat hanya ditampilkan di tooltip.  Melalui surat, juga sulit untuk memulihkan urutan kejadian.  Pesan-pesan ke email datang dengan logika yang tidak jelas dan tidak mengandung deskripsi tindakan.  Tiket dibuat dalam sistem setelah beberapa waktu atas nama karyawan dukungan teknis IT Grad. </li><li>  Setelah melihat lebih dekat peralatan setelah liburan, kami melihat Xeon v2 di sana.  Bukan itu yang kami sepakati.  Oke, kami memutuskan pertanyaan ini dengan manajer akun.  Ada beberapa kesulitan karena fakta bahwa pada tahun 2019 IT Grad baru <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dimasukkan dalam MTS</a> , dan tepat setelah liburan ada sedikit kekacauan.  Dari vDC pada peralatan baru di DC Moskow tidak terlihat vDC dibuat sebelum tahun baru.  Hanya melalui Internet yang terbuka, dukungan teknis “menyenangkan” kami bahwa kecepatan bergerak tidak melebihi 1TB / hari.  Dan kami telah mengunggah 7TB data!  Hasilnya, mereka membuat aplikasi untuk pindah pada Kamis malam.  Sehari kemudian, pada Jumat malam, saya bertanya apa kabar Anda dan kapan mereka berencana untuk memulai (tunggu hampir seminggu!)?  Sehari kemudian, pada Sabtu malam, kami diberi tahu bahwa semua mobil telah pindah.  Saya tidak suka bahwa 2,5 hari tidak ada informasi tentang kemajuan pekerjaan dan bahwa perkiraan bergerak terlalu pesimistis. </li><li>  Pada bulan September 2018, ketika kami mulai menerapkan IaC, kami menyadari bahwa terraform bekerja sangat buruk dengan vCloudDirector (pembaruan: pada saat penulisan, kami mengetahui bahwa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">VMware vCloud Director Provider 2.0 muncul</a> , tetapi belum mencobanya).  Pada awalnya, kami bahkan tidak dapat membuat mesin karena fakta bahwa vCloud memberi tahu kami tentang kesalahan dalam semangat "ada yang salah, Anda memiliki kesalahan 512 karakter 136 baris (garis lebih pendek!) Xml dari konfigurasi mesin".  Kami meminta dukungan.  Pertanyaan itu dialihkan ke para insinyur, pada akhirnya kami diberitahu bahwa terraform tidak didukung - atur sendiri.  Ngomong-ngomong, kami menemukan bahwa pengepakan yang harus disalahkan, yang dengannya kami mengumpulkan gambar mesin, ia tidak dapat mengatasi format konfigurasi VMware yang dipatenkan.  Terraform sangat buruk dengan vCloudDirector, semuanya single-threaded perlahan, dan konektor telah ditinggalkan untuk waktu yang lama dan tidak berkembang.  Tidak ada yang akan memberi kami akses ke vSphere.  Jika Anda tetap menggunakan VMware, maka Anda perlu melihat otomasi Anda melalui api mereka. </li></ol><br><p>  Kami mengatur bangku tes di lokasi baru.  Hasilnya luar biasa - tes gagal, gejalanya sama seperti pada MCS.  Mungkin, dalam dorongan saat ini dalam panasnya pertempuran untuk sesi ini, beberapa pengaturan OS diubah yang mencegah sistem dari pembekuan, tetapi yang sekarang tidak dapat dipulihkan.  Untuk mencegah hal ini terjadi lagi, kami memperkenalkan IaC.  Kami melakukan 2 tes lagi: menciptakan mesin baru dari gambar bersih dari sistem operasi penjualan saat ini - kegagalan;  pada mesin produksi yang ada - sukses.  Dengan demikian, dikonfirmasi bahwa kami melakukan beberapa penyetelan di OS atau basis data, tetapi kami tidak ingat yang mana.  Pada titik ini, solusi dari pengembangan kami tiba tepat waktu: jalur berhenti ketika sesi yang andal dinonaktifkan di WCF. </p><br><p>  Kami menjalankan uji beban dengan pengaturan yang direkomendasikan oleh pengembang secara paralel pada MCS (2 GHz, Xeon v4) dan IT Grad (3 GHz, Xeon v2) - jumlah inti dan memori adalah sama.  Pada MCS, tes lulus lebih cepat (seperempat) dan lebih halus (pada IT Grad, tes menjadi tersentak-sentak, kemudian lebih cepat, lalu lebih lambat). </p><br><h2>  Perbandingan Kinerja Disk </h2><br><p>  Kami paling khawatir tentang kinerja disk untuk database dan indeks, itulah sebabnya kami menguji terutama SSD.  Jangan menilai secara ketat untuk pengujian, ketika kami perlu memahami kinerja cloud, di habr.com belum ada beberapa tes disk, prosesor, memori ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sekali</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dua</a> ) penyedia cloud.  Kami memiliki keterbatasan waktu dan kami perlu dengan cepat membandingkan kinerja untuk mendapatkan gambaran tentang perbedaan kinerja.  Oleh karena itu, persyaratan untuk tes itu satu - dapat dengan cepat diulang di lokasi mana pun.  Kami menggunakan mesin sedekat mungkin dengan parameter yang telah kami sebarkan, untuk menguji kinerja disk dan pgbench - untuk mengevaluasi kinerja database pada disk ini.  Sebagai standar, kami melakukan pengukuran dari produksi saat ini - MARS (karena peralatan kami dinamai sesuai pahlawan seri animasi tentang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tikus batu dari Mars</a> ). </p><br><p>  Biasanya, kinerja disk tergantung pada ukurannya.  Kami mengamati perilaku ini di IT City dan AWS, tetapi di MCS kami tidak melihat ketergantungan seperti itu, itu juga tidak ada di SLA, dan tes memberikan hasil yang paradoks (dan mungkin tidak akurat) - kinerja menurun dengan meningkatnya disk. </p><br><p>  Kami menghitung iops untuk disk HDD dan SSD, serta tps (transaksi per detik) untuk basis data postgres pada disk SSD.  Ada dua jenis disk dalam MCS: SSD cef geo-didistribusikan reguler dan HDD dan SSD lokal (hanya dalam satu DC) (kinerjanya ditunjukkan dalam tanda kurung).  Juga pada Januari 2019, dalam surat dari MCS, kami membaca bahwa mereka meningkatkan kinerja disk sebesar 20%, hasil tes juga ada dalam tabel (MCS 2019).  Pada bulan Februari, akselerasi lain dilaporkan, tetapi kami tidak melakukan tes di sini. </p><br><p>  Hasil: </p><div class="scrollable-table"><table><tbody><tr><th><br></th><th colspan="2">  HDD, iops </th><th colspan="2">  SSD, iops </th><th>  SSD, tps </th></tr><tr><th><br></th><th>  baca </th><th colspan="1">  tulis </th><th>  baca </th><th colspan="1">  tulis </th><th>  baca tulis </th></tr><tr><th><p>  Mars </p></th><td>  1336 </td><td colspan="1">  445 </td><td>  17196 </td><td colspan="1">  5729 </td><td>  2000 </td></tr><tr><th><p>  Lulusan IT <br></p></th><td>  4544 </td><td colspan="1">  1515 </td><td>  13231 </td><td colspan="1">  4407 </td><td>  3063 </td></tr><tr><th colspan="1">  MC </th><td colspan="1">  1185 </td><td colspan="1">  395 </td><td colspan="1">  8931 (22857) </td><td colspan="1">  2980 (7637) </td><td colspan="1">  497 (1.402) </td></tr><tr><th colspan="1">  MCS 2019 </th><td colspan="1">  3229 </td><td colspan="1">  1080 </td><td colspan="1">  9334 (22270) </td><td colspan="1">  3113 (7418) </td><td colspan="1">  463 (1342) </td></tr><tr><th colspan="1">  Yc </th><td colspan="1">  2202 </td><td colspan="1">  735 </td><td colspan="1">  5522 </td><td colspan="1">  1843 </td><td colspan="1">  1824 </td></tr></tbody></table></div><br><h3>  Metodologi pengujian </h3><br><p>  <strong>iops</strong> dihitung sebagai rata-rata 4 fio run: <br> <code>/root/fio-2.0.9/fio --randrepeat=1 --ioengine=libaio --direct=1 --gtod_reduce=1 --name=test --filename=test --bs=4k --iodepth=64 --size=4G --readwrite=randrw --rwmixread=75</code> </p> <br><p>  <strong>tps</strong> , dengan rata-rata 3 pgbench berjalan: <br> <code>pgbench -c 10 -j 2 -t 10000 example</code> </p> <br><h3>  Deskripsi tribun </h3><br><h4>  Mars </h4><br><p>  Xeon v4, 2 GHz <strong>;</strong>  <strong>HDD:</strong> ceph, 3 Node dari ST2000NX0253 9x 2Tb, replika 2;  <strong>SSD:</strong> ceph, 3 node pada 2Tb NVMe Intel DC P4600, replika 2 </p><p>  <strong>CPU</strong> : 4, <strong>RAM</strong> : 8GB, <strong>HDD</strong> : 32GB, <strong>SSD</strong> : 150GB;  Produksi paralel berputar. </p><br><h4>  Lulusan IT </h4><br><p>  Xeon v4 / v2, 2 GHz <strong>;</strong>  <strong>HDD</strong> : 0,1 IOPS / GB <strong>;</strong>  <strong>SSD:</strong> 30 IOPS / GB </p><p>  <strong>CPU</strong> : 4, <strong>RAM</strong> : 4GB, <strong>HDD</strong> : 250GB, <strong>SSD</strong> : 200GB </p><br><h4>  MC </h4><br><p>  Xeon v4;  HDD: r / w: 1500/1000 IOPS;  SSD: r / w: 5000/2000 IOPS </p><p>  Untuk menguji <strong>HDD: CPU</strong> : 2, <strong>RAM</strong> : 4GB, <strong>HDD</strong> : 50GB </p><p>  Untuk menguji <strong>SSD, TPS</strong> : <strong>CPU</strong> : 8, <strong>RAM</strong> : 16GB, <strong>SSD</strong> : 600GB </p><br><h4>  Y </h4><br><p>  Xeon v4, 2GHz <strong><br></strong> </p><p>  <strong>CPU</strong> : 8, <strong>RAM</strong> : 8GB, <strong>HDD</strong> : 20GB, <strong>SSD</strong> : 50GB </p><br><h2>  Perbandingan perkiraan TCO untuk tahun ini </h2><br><p>  Kami menghitung <abbr title="Total biaya kepemilikan">TCO</abbr> untuk empat opsi.  Nilai relatif ditunjukkan pada tabel di bawah ini.  Saya harus mengatakan bahwa ini adalah perhitungan untuk kasus khusus kami dan semuanya mungkin berubah berbeda untuk Anda. <br></p><div class="scrollable-table"><table><tbody><tr><th>  MC </th><th>  Yc </th><th>  Lulusan IT </th><th>  Aws </th></tr><tr><td>  1 </td><td>  1.23 </td><td>  1.37 </td><td>  2.28 </td></tr></tbody></table></div><br><p>  Kami melakukan perhitungan sebagai berikut.  Tahun ini dibagi menjadi dua bagian: sesi (dengan peningkatan beban kerja) dan sisa waktu.  Untuk setiap bagian, jumlah sumber daya CPU dan RAM yang diperlukan dihitung.  Volume disk yang diperlukan, karena pertumbuhan layanan yang konstan, hanya bertambah seiring waktu, oleh karena itu, kami mengambil rata-rata antara awal dan akhir tahun untuk evaluasi. </p><br><p>  Ada sedikit kesulitan dalam mengevaluasi dengan AWS, seperti  tidak ada biaya langsung untuk kernel dan memori gigabytes.  Kami mengambil 3 mesin minimal c5.large, r5.large dan m5.large dan menghitung biayanya dengan harga MCS (secara proporsional mengubah biaya inti CPU, karena MCS memiliki frekuensi 2 GHz).  Ternyata seperti ini: rata-rata, biaya instance AWS sederhana adalah 2,5-2,8 kali lebih tinggi daripada biaya MCS.  AWS menerbitkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">harga</a> tanpa PPN.  Oleh karena itu, untuk biaya AWS kami tambahkan 20%, nilai dolar tahunan rata-rata adalah 70 rubel.  Disk dianggap cukup sederhana dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">harga EBS</a> (kami menggunakan berbagai jenis gp2, sc1, st1).  Di beberapa tempat kita membutuhkan drive NVMe dari instance keluarga i3.  Harga per gigabyte dihitung sangat sederhana: perbedaan biaya antara i3 dan prosesor analog dan contoh memori dari keluarga r4, dibagi dengan jumlah NVMe.  Ternyata 3,1 rubel per gigabyte dalam 30 hari. </p><br><p>  Bahkan dalam percakapan tentang anggaran, saya ingin mencatat perbedaan dalam biaya lisensi Windows untuk satu inti per bulan untuk semua penyedia cloud.  Pada AWS, perbedaan antara biaya Linux OnDemand dan contoh Windows OnDemand dibagi dengan jumlah core adalah konstan sekitar 2.800 rubel per bulan.  Di YC, lisensi kernel Windows harganya 3 kali lebih murah, sekitar 900 rubel per bulan, dan di MCS, hampir 9 (!) Kali lebih murah, sekitar 300 rubel per bulan.  Kami masih sangat bergantung pada Windows: sekarang, terima kasih kepada .net core, kami mulai membuat lintas-platform Anti-Plagiarisme, termasuk untuk mengurangi biaya perawatan. </p><p>  Biaya agregat YC juga termasuk biaya lalu lintas. </p><br><h2>  Kesimpulan </h2><br><h3>  Melalui awan </h3><br><p>  <strong>AWS</strong>  Mereka mengatakan bahwa di Rusia ada 4 penyedia cloud yang bagus: AWS, GCP, Azure dan DO, dan semuanya tidak ada di Rusia. <br>  <em><u>Kelebihan:</u></em> layanan hebat, peralatan modern berkualitas tinggi, konfigurasi bagus di EC2, sejumlah besar layanan. <br>  <em><u>Cons:</u></em> mahal (ditambah risiko nilai tukar) dan tidak di Rusia (ILV, firewall Rusia besar di cakrawala).  Saya benar-benar ingin awan kita mengikuti contoh ini untuk diikuti. <br>  <em><u>Fitur:</u></em> Dukungan teknis gratis dapat menyelesaikan masalah minimum, tetapi, jujur ​​saja, kami hanya menghubunginya untuk memperluas batas penggunaan.  Omong-omong, biayanya sekitar 10% dari akun. </p><br><p>  <strong>Lulusan IT</strong> .  Layanan yang baik untuk cloud perusahaan.  Ada analog EC2 dan S3 berdasarkan Swift. <br>  <em><u>Kelebihan:</u></em> kinerja yang baik (CPU 1-2-3 GHz, SSD, HDD), peralatan baru (di salah satu DC) di antara awan domestik, konfigurasi mesin sewenang-wenang. <br>  <em><u>Cons:</u></em> penagihan yang tidak dapat dimengerti, VMware (antarmuka flash yang tidak otomatis), sedikit kekacauan dan mencungkil dukungan teknis. <br>  <em><u>Fitur:</u></em> dipertajam lebih banyak di bawah penggunaan perusahaan (sekali dikonfigurasi, kemudian perubahan langka) daripada di bawah sistem publik yang sangat dimuat (pembaruan sering, perubahan konstan).  Sejak 2019, bisnis IaaS telah dijual bersama dengan orang-orang dan peralatan di MTS, sekarang semuanya dapat berubah ke segala arah.  Komunikasi melalui sistem tiket dan telepon, saya ingin reaksi dan pesan lebih cepat dari tenggat waktu yang diharapkan. </p><br><p>  <strong>MCS</strong> .  Ada analog layanan EC2 (Ada GPU), S3, ECS, RDS, EMR, layanan mereka sendiri: Machine Learning, Cloud Disaster Recovery, Cloud Backup <br>  <em><u>Pro:</u></em> murah, aktif berkembang, ada GPU (Tesla V100 dan Grid K2). <br>  <em><u>Cons:</u></em> drive lambat, basah, karma buruk dari perusahaan induk. <br>  <em><u>Fitur:</u></em> dukungan teknis pada awalnya bermanfaat, sejumlah besar karyawan aktif, bantuan terasa, tetapi kemudian ada penurunan aktivitas yang nyata (mereka tidak menjawab apa pun sejak 24 Desember, saya bahkan khawatir tentang mereka). </p><br><p>  <strong>YC</strong> .  Kami memiliki sedikit pengalaman bekerja dengan penyedia ini, sulit untuk mengatakan sesuatu yang spesifik.  Ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">analog</a> EC2, S3, RDS, DS, SQS (alfa), ELB (alfa), layanan unik mereka: SpeechKit, Translate. <br>  <em><u>Pro:</u></em> Drive lebih cepat dari MCS. <br>  <em><u>Cons:</u></em> penyedia untuk terraform lembab;  perangkat lunak dari shell virtualisasi dengan api terbuka tidak terlalu besar untuk komunitas, yang berarti sejauh ini Anda hanya dapat mengandalkan kekuatan tim YC dalam pengembangan penyedia untuk terraform. <br>  <em><u>Fitur:</u></em> bayar untuk lalu lintas. </p><br><br><h3>  Pelajaran yang dipetik </h3><br><ol><li>  Kami menyadari bahwa tes stres sudah usang secara moral.  Mereka memperbarui tes, menemukan kemacetan baru, memperbaikinya, membuat produk lebih baik.  Kami ingat bahwa tes beban harus memadai dan harus ada konfigurasi yang tidak lulus sehingga Anda dapat melihat batas penerapannya. </li><li>  Terlepas dari kepercayaan yang meluas bahwa perangkat lunak tidak dioptimalkan saat ini, dan bahwa semua kemacetan dibanjiri dengan sumber daya, kami harus mencari tahu dan mengoptimalkan sistem kami.  Ternyata lebih baik daripada sebelumnya, versi baru Anti-Plagiarisme membutuhkan lebih sedikit sumber daya dan bekerja lebih cepat.  Sudah diuraikan beberapa tempat lagi di mana Anda dapat mengurangi konsumsi sumber daya. </li><li>  Kami melakukan IaC, penyebaran dan pembaruan melalui ansible, belajar bagaimana pindah dari cloud ke cloud (dengan replikasi data awal) dalam hampir 10-15 menit.  Jika data disalin dan replikasi reguler dikonfigurasi, maka ini dia Disaster Recovery Plan: bergerak dalam setengah jam dengan kehilangan data dalam 15 menit terakhir. </li></ol><br><h3>  Apa yang kita inginkan dari awan </h3><br><ol><li>  Jawaban cepat dari dukungan teknis.  Sayangnya, kami tidak dapat menggunakannya seperti pada AWS, sejauh ini - terlalu sedikit informasi yang tersedia. </li><li>  Dukungan untuk otomatisasi penyebaran infrastruktur melalui dana gratis (terraform). </li><li>  Prediktabilitas dalam kinerja.  Ini berlaku untuk penagihan, kinerja CPU, RAM, disk. </li><li>  Kehadiran analog fungsional EC2, S3, RDS sekarang.  Dalam waktu dekat, kami membutuhkan dukungan untuk k8 dan perhitungan GPU (kami sudah menggunakannya pada AWS). </li></ol><br><p>  Selain pindah ke awan, selama beberapa bulan terakhir kami telah berhasil menyentuh penggaruk di area lain.  Bagaimana itu - kami akan memberi tahu nanti. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id440912/">https://habr.com/ru/post/id440912/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id440902/index.html">Setengah kerajaan untuk AI: berapa banyak bank yang dihemat untuk pembelajaran mesin, jaringan saraf, dan obrolan bot</a></li>
<li><a href="../id440904/index.html">Perbandingan arsitektur Viper dan MVVM: Bagaimana cara menerapkan keduanya</a></li>
<li><a href="../id440906/index.html">Webinar "167-ФЗ. Bagaimana bank dapat memenuhi persyaratan Bank Sentral untuk sistem antifraud ”- 26 Februari 2019, 11:00 waktu Moskow</a></li>
<li><a href="../id440908/index.html">Sajikan semuanya</a></li>
<li><a href="../id440910/index.html">Mengapa bank memonopoli blockchain?</a></li>
<li><a href="../id440914/index.html">Saya kehilangan kepercayaan pada industri, terbakar, tetapi kultus alat menyelamatkan saya</a></li>
<li><a href="../id440916/index.html">Radiasi: unit</a></li>
<li><a href="../id440918/index.html">Minggu Keamanan 08: meretas VFEMail langsung</a></li>
<li><a href="../id440920/index.html">Menerapkan UI di iOS: Lebih baik, lebih cepat, dan skala</a></li>
<li><a href="../id440922/index.html">Bagaimana Level Flow bekerja di Uncharted 4 dan The Last Of Us</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë¨ üë®‚Äçüë©‚Äçüë¶‚Äçüë¶ ü•¶ Voc√™ ainda n√£o disse a palavra "ol√°" e j√° sabemos quem voc√™ √© üë∏üèæ üë®üèø‚ÄçüöÄ ‚úåüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nossa rede neural pode fazer isso, reconhecendo uma pessoa por uma s√≠laba pronunciada. No entanto, o t√≥pico deste artigo n√£o est√° diretamente relacion...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Voc√™ ainda n√£o disse a palavra "ol√°" e j√° sabemos quem voc√™ √©</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/neurodatalab/blog/422635/">  Nossa rede neural pode fazer isso, reconhecendo uma pessoa por uma s√≠laba pronunciada.  No entanto, o t√≥pico deste artigo n√£o est√° diretamente relacionado √† identifica√ß√£o por voz, embora esteja relacionado a ele.  Falaremos sobre os recursos da rede neural, o chamado vetor-d, que pode ser usado em tarefas de processamento de som: da verifica√ß√£o ao reconhecimento de fala e emo√ß√µes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/eo/h5/k8/eoh5k8gwhm9ep4wpove1up9gljg.jpeg" alt="imagem"></div><br><a name="habracut"></a><br><h4>  <b>Material</b> </h4><br>  Dependendo da taxa de amostragem, um segundo de som pode conter de 8 a 48 mil n√∫meros.  Eles podem ser representados como desvios da posi√ß√£o de equil√≠brio da membrana ou microfone do alto-falante.  De fato, essa descri√ß√£o do som √© redundante: a amplitude do sinal no momento seguinte depende fortemente da anterior, o que sugere que esse sinal pode ser efetivamente compactado sem muita perda de informa√ß√£o.  Existem in√∫meras maneiras de reduzir a dimens√£o de um sinal, e a maioria delas se baseia nas propriedades f√≠sicas do som e nas caracter√≠sticas da audi√ß√£o humana. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fh/n4/qj/fhn4qjskpumyiosbtjxzik7e9yg.jpeg" alt="imagem"></div><br>  <i>Meme 1.</i> <br><br>  Antes de as redes neurais funcionarem bem (em um sentido amplo), a comunidade trabalhava com os chamados atributos artesanais.  Os mais famosos e amplamente utilizados deles s√£o o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pitch</a> e o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MFCC</a> .  O primeiro tem um significado f√≠sico da frequ√™ncia de oscila√ß√µes das cordas vocais, que diferem, por exemplo, para pessoas diferentes, e tamb√©m dependem da entona√ß√£o.  A ideia dos coeficientes cepstrais (MFCC) baseia-se na n√£o linearidade da percep√ß√£o humana do som, ou seja, frequ√™ncia e volume.  Parece a uma pessoa que um som √© mais alto que outro em certa medida, se, na realidade, suas frequ√™ncias diferem um certo n√∫mero de vezes. <br><br>  Esses e outros recursos calculados manualmente s√£o irrevers√≠veis no sentido de que parte do sinal √© perdida para sempre.  Em algumas tarefas, isso n√£o √© cr√≠tico, mas eu gostaria de apresentar uma abordagem mais universal e de trabalho. <br><br>  A chave para resolver esse problema √© a transforma√ß√£o de Fourier.  Usando-o, voc√™ pode imaginar um sinal de √°udio como a soma de ondas com diferentes frequ√™ncias e amplitudes.  De fato, a fala n√£o √© estacion√°ria no sentido de que seu espectro ser√° qualitativamente diferente em diferentes momentos no tempo.  Isso nos permite consider√°-lo na representa√ß√£o de frequ√™ncia e tempo, usando <i>espectrogramas</i> . <br><br>  Para construir um espectrograma, voc√™ precisa dividir o som em se√ß√µes que se cruzam (quadros sobrepostos) com v√°rias dezenas de milissegundos de comprimento, para cada um deles calcular a transforma√ß√£o de Fourier e escrever seus m√≥dulos em colunas nos espectrogramas.  Al√©m disso, essa transforma√ß√£o √© quase inversa entre si, ou seja, usando a transformada inversa de Fourier e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o algoritmo Griffin-Lim,</a> voc√™ pode restaurar o sinal sonoro original (de fato, h√° perda de informa√ß√µes, pois a transforma√ß√£o de Fourier √© complexa no caso geral e o espectrograma √© de valor real e, para aproximar a recupera√ß√£o de fase, o algoritmo iterativo Griffin-Lim √© geralmente usado).  Total, se tomarmos o logaritmo das amplitudes, obtemos as seguintes imagens: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ux/ig/xz/uxigxzafbu938strrzeepi8s-ro.png" alt="imagem"></div><br>  <i>Espectrograma de 5 segundos de fala.</i> <br><br>  E eles s√£o convenientemente processados ‚Äã‚Äãpor redes convolucionais. <br><br>  Esse hack √© frequentemente usado em tarefas de processamento de imagens: existem grandes bancos de dados com exemplos de objetos diferentes (por exemplo, ImageNet).  Voc√™ pode treinar uma grade grande para reconhec√™-los e trein√°-la novamente em nossa tarefa espec√≠fica ou obter o resultado da sa√≠da de uma das camadas internas totalmente conectadas.  Acredita-se que essa arquitetura calcule boas caracter√≠sticas informativas para imagens de entrada.  A experi√™ncia sugere que quase sempre os resultados ser√£o melhores do que se trein√°ssemos a rede neural do zero. <br><br>  A id√©ia de vetores-d (geralmente vetores-d, mas √†s vezes denominados vetores-x) √© semelhante ao uso de grades pr√©-treinadas no ImageNet, exceto pelo fato de n√£o haver bases semelhantes para espectrogramas.  Como uma poss√≠vel sa√≠da, os codificadores autom√°ticos podem ser considerados, mas a priori n√£o sabem o que procurar no espectrograma; portanto, eles funcionam de maneira insatisfat√≥ria. <br><br><h4>  <b>Precisamos ir mais fundo</b> </h4><br>  Aten√ß√£o, a parte principal deste artigo come√ßa. <br><br>  A tarefa de verificar uma pessoa por voz √© amplamente conhecida, onde √© necess√°rio determinar pelo segmento de entrada de fala qual das pessoas no banco de dados o disse.  De fato, a constru√ß√£o de tais sistemas √© uma ci√™ncia separada e existem muitos complementos diferentes (dura√ß√£o da fala; √© necess√°rio que todos falem o mesmo texto; encenando um contra um ou um contra todos), que s√£o cr√≠ticos sob condi√ß√µes diferentes, mas para n√≥s voc√™ precisa prestar aten√ß√£o em outra coisa. <br><br>  A saber: qu√£o boas ser√£o as caracter√≠sticas se pr√©-treinarmos a grade para reconhecer uma pessoa.  Tudo √© feito por uma quest√£o de sinais. <br><br>  Isso nos ajudar√° a intui√ß√£o e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo de</a> 2015.  Nele, os autores ensinam a grade a reconhecer uma pessoa pelo rosto (reconhecimento de rosto).  A chave para este trabalho √© usar a perda de trig√™meos. <br><br>  Sua ideia √© muito simples: normalizamos os recursos da pen√∫ltima camada para que eles fiquem em uma esfera unit√°ria e exigimos que os pontos de uma classe fiquem pr√≥ximos e distantes de diferentes.  Isso pode ser alcan√ßado da seguinte forma: para cada exemplo de treinamento (√¢ncora), encontramos mais dois da mesma e de outra classe na amostra - positiva e negativa.  Ent√£o, para esses triplos pontos, formamos uma perda: <br><br>  \ begin {equation} <br>  \ Big [\ Vert f (x ^ a) - f (x ^ p) \ Vert - \ Vert f (x ^ a) - f (x ^ n) \ Vert + \ alpha \ Big] _ +, <br>  \ end {equa√ß√£o} <br><br>  onde x √© a imagem de entrada, f √© a sa√≠da da grade ap√≥s a normaliza√ß√£o, alfa √© o par√¢metro selecionado manualmente, [] _ ‚Äã‚Äã{+} √© a fun√ß√£o ReLU.  Qualitativamente, o valor dessa perda √© zero se a dist√¢ncia entre a √¢ncora e os pontos positivos for maior que a dist√¢ncia entre a √¢ncora e a negativa por pelo menos alfa, e quanto maior, menor a diferen√ßa entre duas classes diferentes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fp/k6/yy/fpk6yyh_hd1hb00bsdcg39xyuqc.png" alt="imagem"></div><br>  <i>Uma ilustra√ß√£o do que acontece com os recursos ap√≥s o treinamento com Triplet Loss.</i> <br><br>  A prop√≥sito, voc√™ pode formar triplos de maneira inteligente.  Em algum momento, a magnitude da perda se tornar√° pequena e, para acelerar o aprendizado, voc√™ pode procurar exemplos negativos n√£o entre todas as outras classes, mas considerar apenas aqueles pr√≥ximos √† √¢ncora.  Por√©m, para conjuntos de dados grandes, isso √© dif√≠cil, porque √© necess√°rio considerar as dist√¢ncias entre pares que mudam ap√≥s cada itera√ß√£o do aprendizado de rede. <br><br>  A perda de trig√™meos tem uma vantagem sobre a entropia cruzada categ√≥rica, usada na classifica√ß√£o convencional.  Um modelo treinado com entropia cruzada tentar√° colocar todos os pontos de uma classe em uma √°rea cada vez menor, e informa√ß√µes sup√©rfluas para uma tarefa espec√≠fica podem ser perdidas.  Mas n√£o queremos isso, porque vamos usar a rede neural como um gerador de recursos, e n√£o para verifica√ß√£o.  Triplet Loss tem essa propriedade em uma extens√£o muito menor: √© mais importante espalhar classes diferentes em √°reas diferentes em uma √∫nica esfera do que gerar uma classe. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pn/pt/nz/pnptnzxqejabade7orpavbtx5se.jpeg" alt="imagem"></div><br>  <i>Meme 2.</i> <br><br>  A √∫ltima coisa a fazer antes de treinar o gerador de recursos em espectrogramas √© determinar seus tamanhos.  Obviamente, a precis√£o da classifica√ß√£o ser√° maior, maior ser√° o per√≠odo de tempo que consideraremos, mas mais sinais "m√©dios" aparecer√£o.  Portanto, √© razo√°vel usar esse comprimento de sinal para que 1-3 fonemas (s√≠labas) caiam nele - meio segundo parece apropriado. <br><br>  Para treinamento, tomamos o conjunto de dados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">VoxCeleb2</a> , onde para cada um dos 6300 alto-falantes h√° v√°rias grava√ß√µes de √°udio separadas de v√°rios minutos cada (feitas em diferentes condi√ß√µes).  Usamos parte dos arquivos de √°udio para treinamento e o restante para valida√ß√£o, selecionamos a arquitetura de rede de convolu√ß√£o, adicionamos Triplet Loss a ela e aprendemos. <br><br>  Os resultados foram muito legais.  Em quase duas semanas de treinamento em 1080Ti (sim, por tanto tempo), a precis√£o da classifica√ß√£o atingiu 55%.  Parece que n√£o muito, mas a precis√£o do top 5 √© de 78%, e se considerarmos apenas a metade mais alta dos fragmentos, que s√£o principalmente vogais estressadas, a precis√£o do top 5 aumentar√° para 91%.  Podemos dizer que podemos identificar uma pessoa por uma de suas frases com precis√£o razo√°vel.  Mas isso n√£o importa. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vz/el/21/vzel21arcsvyrco_kg_95usxziy.jpeg" alt="imagem"></div><br>  <i>Meme 3.</i> <br><br>  Afinal, tudo foi iniciado para recursos que podem ser obtidos como uma sa√≠da do pen√∫ltimo antes de classificar a camada de rede neural.  N√≥s os testamos em nossas tarefas, e em todos os lugares os resultados foram melhores do que usar abordagens cl√°ssicas para calcular atributos.  Por exemplo, no problema do reconhecimento de emo√ß√µes, o uso de vetores-d permitiu-nos ignorar o estado da arte em 4%, e o artigo correspondente foi aceito na confer√™ncia da FICC 2019. No entanto, o reconhecimento de emo√ß√µes √© uma hist√≥ria completamente diferente, sobre a qual falaremos mais adiante. <br><br>  Publicado por <b>Gregory Sterling</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">sterling239</a> , Especialista em Deep Learning, Neurodata Lab. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt422635/">https://habr.com/ru/post/pt422635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt422625/index.html">Conversamos com Troy Miles - o programador do "Neuromancer"</a></li>
<li><a href="../pt422627/index.html">Pesquisa de mercado de trabalho MongoDB e TI</a></li>
<li><a href="../pt422629/index.html">Pare de alimentar os madeireiros! D√™ mais modificadores! Campos finais est√°ticos pregui√ßosos. Esbo√ßo de recurso de rascunho</a></li>
<li><a href="../pt422631/index.html">Terminais QIWI. Como tirar o m√°ximo proveito das tecnologias simples</a></li>
<li><a href="../pt422633/index.html">Como automatizamos o monitoramento do trabalho dos funcion√°rios da rede federal de postos de gasolina</a></li>
<li><a href="../pt422637/index.html">Presente de Geek: Prote√ß√£o Autom√°tica de Alkash</a></li>
<li><a href="../pt422641/index.html">Noite polar, bombeamento de √°gua e cofre inteligente: 5 projetos de estudantes no campo da IoT</a></li>
<li><a href="../pt422643/index.html">Novos dispositivos com o IFA 2018</a></li>
<li><a href="../pt422645/index.html">Qual √© a import√¢ncia de 196 884 = 196 883 + 1? Como explicar isso nos dedos?</a></li>
<li><a href="../pt422649/index.html">VR multiplayer: como implementar?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßíüèø üéä üë©üèª‚Äçü§ù‚Äçüë®üèø Notre chemin vers un stockage centralis√© des journaux üé≠ üë®üèø‚Äçüè≠ üêô</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Salutations √† tous! Je travaille comme ing√©nieur syst√®me chez Onlanta . Dans l'un de nos projets, j'ai particip√© √† la mise en ≈ìuvre et √† la maintenanc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Notre chemin vers un stockage centralis√© des journaux</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/429260/">  Salutations √† tous!  Je travaille comme ing√©nieur syst√®me chez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Onlanta</a> .  Dans l'un de nos projets, j'ai particip√© √† la mise en ≈ìuvre et √† la maintenance d'Elastic Stack.  Nous sommes pass√©s de la collecte des journaux virtuellement √† la main √† un processus centralis√© et automatis√©.  Depuis deux ans maintenant, nous n'avons pratiquement pas chang√© l'architecture de la solution et pr√©voyons d'utiliser un outil pratique dans d'autres projets.  Je partage avec vous notre historique de sa mise en ≈ìuvre, ainsi que certaines forces et faiblesses de ce billet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/23f/a8d/39d/23fa8d39daef5063c297e7cff9f3bbdc.png"></div>  <a href="">Source</a> <br><a name="habracut"></a><br>  Au d√©but de 2016, les journaux de nos administrateurs et d√©veloppeurs √©taient, pour ainsi dire, ¬´√† port√©e de main¬ª, c'est-√†-dire un ing√©nieur pour travailler avec eux connect√©s via SSH √† l'h√¥te o√π le service qui l'int√©ressait, a d√©couvert l'ensemble universel de tail / grep / sed / awk et esp√©rait qu'il serait possible de trouver les donn√©es n√©cessaires sur cet h√¥te. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2b5/8cb/c53/2b58cbc53de559d692a6a0295f7fde4e.png"></div> <a href="">Source</a> <br><br>  Nous avions √©galement un serveur s√©par√©, o√π tous les r√©pertoires contenant les journaux de tous les serveurs √©taient mont√©s via NFS, et qui √©tait parfois longuement r√©fl√©chi √† ce que tout le monde voulait faire avec les journaux qu'il contenait.  Eh bien, tmux avec plusieurs panneaux tournant sur certains journaux activement mis √† jour semblait tr√®s impressionnant pour les √©trangers sur un grand moniteur et a cr√©√© une atmosph√®re passionnante d'implication dans les sacrements de la production. <br><br>  Tout cela a m√™me fonctionn√©, mais exactement jusqu'√† ce qu'il soit n√©cessaire de traiter rapidement une grande quantit√© de donn√©es, et cela √©tait le plus souvent requis aux moments o√π quelque chose √©tait tomb√© dans la prod. <br><br>  Parfois, il fallait un temps ind√©cent pour enqu√™ter sur des incidents.  Une partie importante de celui-ci a √©t√© consacr√©e √† l'agr√©gation manuelle des journaux, au lancement de <s>b√©quilles de</s> divers scripts dans Bash et Python, en attendant que les journaux soient t√©l√©charg√©s quelque part pour l'analyse, etc. <br><br>  En un mot, tout cela a √©t√© tr√®s lent, inspir√© par le d√©couragement et laiss√© entendre sans √©quivoque qu'il √©tait temps de s'occuper du stockage centralis√© des journaux. <br><br>  Pour √™tre honn√™te, il n'y avait pas de processus compliqu√© de s√©lection des candidats pour le r√¥le de la pile technologique qui nous fournirait cela: alors le bundle ELK √©tait d√©j√† populaire √† l'√©poque, avait une bonne documentation, il y avait un grand nombre d'articles sur Internet pour tous les composants.  La d√©cision a √©t√© imm√©diate: il faut essayer. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ce1/6aa/c04/ce16aac040da82a959333b390b8fe04b.png"></div>  <a href="">Source</a> <br><br>  La toute premi√®re installation de la pile a √©t√© effectu√©e apr√®s avoir regard√© le webinaire ¬´Logstash: 0-60 en 60¬ª sur trois machines virtuelles, chacune ayant lanc√© une instance d'Elasticsearch, Logstash et Kibana. <br><br>  De plus, nous avons rencontr√© des probl√®mes avec la livraison des journaux des h√¥tes finaux aux serveurs Logstash.  Le fait est qu'√† cette √©poque, Filebeat (une solution de pile standard pour fournir des journaux √† partir de fichiers texte) fonctionnait bien pire avec des fichiers volumineux et rapidement mis √† jour, r√©guli√®rement divulgu√©s en RAM et dans notre cas dans son ensemble, ne pouvait pas faire face √† sa t√¢che. <br><br>  √Ä cela a √©t√© ajout√©e la n√©cessit√© de trouver un moyen de fournir des journaux de serveur d'applications √† partir de machines ex√©cutant IBM AIX: la majeure partie de nos applications ont ensuite √©t√© lanc√©es dans WebSphere Application Server, qui fonctionnait sp√©cifiquement sous ce syst√®me d'exploitation.  Filebeat est √©crit en Go, il n'y avait pas de compilateur Go plus ou moins efficace pour AIX en 2016, et je ne voulais vraiment pas utiliser Logstash comme agent de livraison. <br><br>  Nous avons test√© plusieurs agents de livraison de journaux: Filebeat, logstash-forwarder-java, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">log-courier</a> , python-beaver et NXLog.  De la part des agents, nous nous attendions √† des performances √©lev√©es, une faible consommation de ressources syst√®me, une int√©gration facile avec Logstash et la possibilit√© d'effectuer des manipulations de donn√©es de base avec les forces de l'agent (par exemple, l'assemblage d'√©v√©nements multilignes). <br><br>  √Ä propos de l'assemblage d'√©v√©nements multilignes, il convient de mentionner s√©par√©ment.  En effet, il ne peut √™tre ex√©cut√© que du c√¥t√© de l'agent qui lit un fichier sp√©cifique.  Malgr√© le fait que Logstash avait autrefois un filtre multiligne et dispose d√©sormais d'un codec multiligne, toutes nos tentatives pour combiner l'√©quilibrage des √©v√©nements sur plusieurs serveurs Logstash avec un traitement multiligne ont √©chou√©.  Cette configuration rend l'√©quilibrage efficace des √©v√©nements presque impossible, par cons√©quent, pour nous, le facteur le plus important lors du choix des agents √©tait le support multiligne. <br><br>  Les gagnants √©taient les suivants: log-courrier pour les machines avec Linux, NXLog pour les machines avec AIX.  Avec cette configuration, nous avons v√©cu presque un an sans aucun probl√®me: les logs ont √©t√© livr√©s, les agents ne sont pas tomb√©s (enfin, presque), tout le monde √©tait content. <br><br>  En octobre 2016, la cinqui√®me version des composants d'Elastic Stack a √©t√© lanc√©e, notamment Beats 5.0.  Beaucoup de travail a √©t√© fait sur tous les agents Beats dans cette version, et nous avons pu remplacer le journal-messagerie (qui √† ce moment-l√† avait ses propres probl√®mes) par Filebeat, que nous utilisons toujours. <br><br>  Lors de la migration vers la version 5.0, nous avons commenc√© √† collecter non seulement des journaux, mais aussi certaines mesures: Packetbeat a commenc√© √† √™tre utilis√© ici et l√† comme alternative √† l'√©criture de journaux de requ√™tes HTTP dans des fichiers, et Metricbeat a collect√© des m√©triques syst√®me et des m√©triques de certains services. <br><br>  √Ä ce stade, le travail de nos ing√©nieurs avec les journaux est devenu beaucoup plus simple: maintenant, il n'√©tait plus n√©cessaire de savoir sur quel serveur aller pour consulter le journal qui vous int√©resse, l'√©change d'informations trouv√© a √©t√© simplifi√© en transf√©rant simplement le lien vers Kibana dans les salles de discussion ou le courrier, et les rapports qui ont √©t√© pr√©c√©demment cr√©√©s en quelques heures, a commenc√© √† √™tre cr√©√© en quelques secondes.  On ne peut pas dire que ce n'√©tait qu'une question de confort: nous avons constat√© des changements dans la qualit√© de notre travail, dans la quantit√© et la qualit√© des t√¢ches ferm√©es, dans la rapidit√© de r√©ponse aux probl√®mes sur nos stands. <br><br>  √Ä un moment donn√©, nous avons commenc√© √† utiliser l'utilitaire ElastAlert de Yelp pour envoyer des alertes aux ing√©nieurs.  Et puis nous avons pens√©: pourquoi ne pas l'int√©grer √† notre Zabbix pour que toutes les alertes aient un format standard et soient envoy√©es de mani√®re centralis√©e?  La solution a √©t√© trouv√©e assez rapidement: ElastAlert vous permet d'ex√©cuter toutes les commandes au lieu d'envoyer des alertes, que nous avons utilis√©es. <br><br>  D√©sormais, nos r√®gles ElastAlert, lorsqu'elles sont d√©clench√©es, ex√©cutent un script bash sur plusieurs lignes, auquel les donn√©es n√©cessaires sont transmises dans les arguments de l'√©v√©nement qui a d√©clench√© la r√®gle, et zabbix_sender est appel√© √† partir du script, qui envoie les donn√©es √† Zabbix pour le n≈ìud souhait√©. <br><br>  √âtant donn√© que toutes les informations sur qui a g√©n√©r√© l'√©v√©nement et o√π sont toujours disponibles dans Elasticsearch, il n'y a eu aucune difficult√© d'int√©gration.  Par exemple, nous avions auparavant un m√©canisme pour d√©tecter automatiquement les serveurs d'applications WAS, et dans les √©v√©nements qu'ils g√©n√®rent, le nom du serveur, du cluster, de la cellule, etc. est toujours √©crit.  Cela nous a permis d'utiliser l'option query_key dans les r√®gles ElastAlert afin que les conditions des r√®gles soient trait√©es s√©par√©ment pour chaque serveur.  Le script avec zabbix_sender obtient alors les "coordonn√©es" exactes du serveur et les donn√©es sont envoy√©es √† Zabbix pour le n≈ìud correspondant. <br><br>  Une autre solution que nous aimons vraiment et qui a √©t√© rendue possible gr√¢ce √† la collecte centralis√©e des journaux est un script pour cr√©er automatiquement des t√¢ches dans JIRA: une fois par jour, il supprime toutes les erreurs des journaux et, s'il n'y a pas encore de t√¢ches, les d√©marre.  Dans le m√™me temps, √† partir de diff√©rents index par un ID de demande unique, toutes les informations pouvant √™tre utiles dans l'enqu√™te sont r√©cup√©r√©es dans la t√¢che.  Le r√©sultat est une sorte de pi√®ce standard avec les informations minimales n√©cessaires, que les ing√©nieurs peuvent compl√©ter si n√©cessaire. <br><br>  Bien s√ªr, nous avons √©t√© confront√©s √† la question de la surveillance de la pile elle-m√™me.  Ceci est partiellement impl√©ment√© en utilisant Zabbix, en utilisant partiellement le m√™me ElastAlert, et nous obtenons les principales mesures de performances pour Elasticsearch, Logstash et Kibana en utilisant la surveillance standard int√©gr√©e √† la pile (composant de surveillance dans le X-Pack).  De plus, sur les serveurs avec les services de pile eux-m√™mes, nous avons install√© des donn√©es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©seau</a> de Firehol.  Il est utile lorsque vous avez besoin de voir ce qui arrive √† un n≈ìud particulier en ce moment, en temps r√©el et √† haute r√©solution. <br><br>  Il √©tait une fois, le module de surveillance Elasticsearch √©tait l√©g√®rement cass√©, nous l'avons trouv√©, corrig√©, ajout√© toutes sortes de m√©triques utiles et fait une demande de pull.  D√©sormais, netdata peut surveiller les derni√®res versions d'Elasticsearch, y compris les m√©triques JVM de base, l'indexation, les indicateurs de performance de recherche, les statistiques du journal des transactions, les segments d'index, etc.  Nous aimons Netdata et nous sommes ravis d'avoir pu y apporter une petite contribution. <br><br>  Aujourd'hui, apr√®s presque trois ans, notre pile √©lastique ressemble √† ceci: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b0b/fc6/ab5/b0bfc6ab50dede8cdb09d80e22f90f07.png"></div><br>  Les ing√©nieurs travaillent avec la pile de trois mani√®res principales: <br><br><ul><li>  afficher et analyser les journaux et les mesures dans Kibana; </li><li>  tableaux de bord √† Grafana et Kibana; </li><li>  diriger les requ√™tes vers Elasticsearch √† l'aide de SQL ou de la requ√™te DSL int√©gr√©e. </li></ul><br>  Au total, toutes ces ressources sont allou√©es: 146 CPU, 484 Go de RAM, 17 To sont allou√©s √† l'entrep√¥t de donn√©es Elasticsearch. <br><br>  Au total, nous avons 13 machines virtuelles fonctionnant dans le cadre d'Elastic Stack: 4 machines pour les n≈ìuds Elasticsearch ¬´chauds¬ª, 4 pour les n≈ìuds ¬´chauds¬ª, 4 machines avec Logstash et une machine d'√©quilibrage.  Sur chaque n≈ìud actif, Elasticsearch ex√©cute une instance Kibana.  Cela s'est produit d√®s le d√©but, et jusqu'√† pr√©sent, nous n'avons pas eu √† d√©placer Kibana vers des voitures s√©par√©es. <br><br>  Mais la d√©cision de prendre Logstash sur des machines s√©par√©es s'est av√©r√©e √™tre l'une des plus correctes et efficaces pendant le fonctionnement de la pile: la forte concurrence pour le temps CPU entre JVM Elasticsearch et Logstash a conduit √† des effets sp√©ciaux pas tr√®s agr√©ables lors des rafales de charge.  Les √©boueurs ont le plus souffert. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d15/1cb/e24/d151cbe24f19860ee8f88e6ff4d86fd6.jpg"></div>  <a href="">Source</a> <br><br>  Nous stockons les donn√©es des 30 derniers jours dans le cluster: il s'agit maintenant d'environ 12 milliards d'√©v√©nements.  Chaque jour, les n≈ìuds actifs √©crivent sur le disque 400-500 Go de nouvelles donn√©es avec un taux de compression maximal (y compris les donn√©es de r√©plique de partition).  Notre cluster Elasticsearch a une architecture chaude / chaude, mais nous y sommes pass√©s relativement r√©cemment, donc moins de donn√©es sont encore stock√©es sur des n≈ìuds ¬´chauds¬ª que sur des n≈ìuds ¬´chauds¬ª. <br><br>  Notre charge de travail typique: <br><br><ul><li>  indexation - en moyenne 13 000 rps avec des pics allant jusqu'√† 30 000 (hors indexation en fragments de r√©plique); </li><li>  Recherche - 5200 rps. </li></ul><br>  Nous essayons de maintenir une marge CPU de 40 √† 50% sur les n≈ìuds chauds Elasticsearch afin que nous puissions facilement rencontrer des pics soudains dans le nombre d'√©v√©nements index√©s et les demandes lourdes de Kibana / Grafana ou des syst√®mes de surveillance externes.  Environ 50% de la RAM sur les h√¥tes avec des n≈ìuds Elasticsearch est toujours disponible pour les besoins de cache de page et hors segment de la JVM. <br><br>  Pendant le temps √©coul√© depuis le lancement du premier cluster, nous avons r√©ussi √† identifier pour nous-m√™mes certains des aspects positifs et n√©gatifs d'Elastic Stack comme moyen d'agr√©gation de journaux et d'une plateforme de recherche et d'analyse. <br><br>  <b>Ce que nous aimons particuli√®rement dans la pile:</b> <br><br><ul><li>  Un √©cosyst√®me unique de produits bien int√©gr√©s les uns aux autres, qui a presque tout ce dont vous avez besoin.  Les Beats n'√©taient autrefois pas tr√®s bons, mais maintenant nous n'avons rien √† redire √† leur sujet. </li><li>  Logstash, avec toute sa monstruosit√©, est un pr√©processeur tr√®s flexible et puissant et vous permet de faire beaucoup avec des donn√©es brutes (et si quelque chose ne le permet pas, vous pouvez toujours √©crire un extrait dans Ruby). </li><li>  Elasticsearch avec des plugins (et plus r√©cemment pr√™t √† l'emploi) prend en charge SQL en tant que langage de requ√™te, ce qui simplifie son int√©gration avec d'autres logiciels et des personnes plus proches de SQL en tant que langage de requ√™te. </li><li>  Une documentation de haute qualit√© qui vous permet d'initier rapidement de nouveaux employ√©s au projet.  Le fonctionnement de la pile ne devient donc pas l'affaire d'une seule personne ayant une exp√©rience sp√©cifique et des ¬´connaissances secr√®tes¬ª. </li><li>  Il n'est pas n√©cessaire de conna√Ætre √† l'avance la structure des donn√©es re√ßues pour commencer √† les collecter: vous pouvez commencer √† agr√©ger les √©v√©nements tels qu'ils sont, puis, lorsque vous comprenez quelles informations utiles vous pouvez en extraire, changez l'approche de leur traitement sans perdre la ¬´compatibilit√© descendante¬ª.  Il existe de nombreux outils pratiques sur la pile pour cela: alias de champ dans les index, champs script√©s, etc. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/dcc/e5b/075/dcce5b0751ee3394dd2426b878c24169.png"></div>  <a href="">Source</a> <br><br>  <b>Ce que nous n'aimons pas:</b> <br><br><ul><li>  Les composants X-Pack sont distribu√©s uniquement en fonction du mod√®le d'abonnement et rien d'autre: si de Gold, par exemple, ne prend en charge que les rapports RBAC ou PDF, vous devrez payer pour tout ce que Gold a.  Cela est particuli√®rement frustrant lorsque, par exemple, vous n'avez besoin que de Graph from Platinum, et de Machine Learning et d'un autre ensemble d'autres fonctionnalit√©s dont vous n'avez peut-√™tre pas vraiment besoin sont disponibles √† l'achat.  Nos tentatives de communiquer avec le service commercial d'Elastic au sujet de l'octroi de licences pour des composants X-Pack individuels il y a environ un an n'ont abouti √† rien, mais peut-√™tre que quelque chose a chang√© depuis. </li><li>  Des versions assez fr√©quentes dans lesquelles, d'une mani√®re ou d'une autre (√† chaque fois nouvelle), la compatibilit√© descendante est rompue.  Vous devez lire le journal des modifications tr√®s attentivement et pr√©parer les mises √† jour √† l'avance.  Chaque fois que vous devez choisir: restez sur l'ancienne version, qui fonctionne de mani√®re stable, ou essayez de mettre √† niveau pour de nouvelles fonctionnalit√©s et des gains de performances. </li></ul><br>  En g√©n√©ral, nous sommes tr√®s satisfaits de notre choix fait en 2016, et nous pr√©voyons de transf√©rer l'exp√©rience de l'exploitation d'Elastic Stack √† nos autres projets: les outils fournis par la pile sont tr√®s √©troitement int√©gr√©s dans notre workflow et il serait tr√®s difficile de les refuser maintenant. <br><br><div class="spoiler">  <b class="spoiler_title">Et dans notre entreprise, un certain nombre de postes vacants sont ouverts.</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chef d'√©quipe</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chef d'√©quipe (Windows)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ing√©nieur s√©curit√© des informations r√©seau</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pr√©vente Manager (services cloud)</a> </li></ul></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr429260/">https://habr.com/ru/post/fr429260/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr429250/index.html">Cent recettes de tenue de livres num√©riques</a></li>
<li><a href="../fr429252/index.html">Analyse statique des applications mobiles</a></li>
<li><a href="../fr429254/index.html">Sur les courbes de B√©zier et la vitesse Arduino, deuxi√®me partie</a></li>
<li><a href="../fr429256/index.html">Comment faire pousser une for√™t sur Actionscript3 / Flash en quelques * lignes de code</a></li>
<li><a href="../fr429258/index.html">Comment cr√©er des m√©canismes de jeu fiables en utilisant uniquement Excel: mod√©lisation et optimisation de solutions</a></li>
<li><a href="../fr429262/index.html">Bienvenue au Meetup Autumn DIYorDIE du 17 novembre</a></li>
<li><a href="../fr429264/index.html">Li-ion UPS time: un risque d'incendie ou une √©tape s√ªre vers l'avenir?</a></li>
<li><a href="../fr429266/index.html">Quels salaires pour les informaticiens sont propos√©s par les employeurs My Circle, donn√©es de mai √† octobre 2018</a></li>
<li><a href="../fr429268/index.html">Araign√©e g√©ante et minotaure dans les rues de Toulouse</a></li>
<li><a href="../fr429270/index.html">Journalisme adulte: de la Russie au Kremlin</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
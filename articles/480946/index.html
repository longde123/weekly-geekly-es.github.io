<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>游둤游낗 游녦游 游댳 Inicia sesi칩n en Kubernetes (y no solo) hoy: expectativas y realidad 游볫 游 游볞</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Era 2019, y todav칤a no tenemos una soluci칩n est치ndar para la agregaci칩n de registros en Kubernetes. En este art칤culo, nos gustar칤a, utilizando ejemplo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Inicia sesi칩n en Kubernetes (y no solo) hoy: expectativas y realidad</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/480946/"><img src="https://habrastorage.org/webt/b1/zh/it/b1zhitohqlji21qhzypqn8k_n2s.png"><br><br>  Era 2019, y todav칤a no tenemos una soluci칩n est치ndar para la agregaci칩n de registros en Kubernetes.  En este art칤culo, nos gustar칤a, utilizando ejemplos de la pr치ctica real, compartir nuestras b칰squedas, los problemas encontrados y sus soluciones. <br><br>  Sin embargo, para comenzar, har칠 una reserva para que diferentes clientes comprendan cosas muy diferentes al recopilar registros: <br><br><ul><li>  alguien quiere ver registros de seguridad y auditor칤a; </li><li>  alguien: registro centralizado de toda la infraestructura; </li><li>  y para alguien es suficiente recopilar solo los registros de la aplicaci칩n, excluyendo, por ejemplo, los equilibradores. </li></ul><br>  Acerca de c칩mo implementamos varias "Lista de deseos" y qu칠 dificultades encontramos, debajo del corte. <a name="habracut"></a><br><br><h2>  Teor칤a: acerca de las herramientas de registro </h2><br><h3>  Antecedentes sobre los componentes del sistema de registro. </h3><br>  El registro ha recorrido un largo camino, como resultado de lo cual hemos desarrollado metodolog칤as para recopilar y analizar registros, que utilizamos hoy.  En la d칠cada de 1950, Fortran introdujo un an치logo de flujos de E / S est치ndar que ayud칩 al programador a depurar su programa.  Estos fueron los primeros registros de computadora que facilitaron la vida de los programadores de aquellos tiempos.  Hoy vemos en ellos el primer componente del sistema de registro: la <b>fuente o "productor" de los registros</b> . <br><br>  La inform치tica no se detuvo: aparecieron las redes inform치ticas, los primeros grupos ... Los sistemas complejos que constaban de varias computadoras comenzaron a funcionar.  Ahora los administradores del sistema se vieron obligados a recopilar registros de varias m치quinas y, en casos especiales, pod칤an agregar mensajes del kernel del sistema operativo en caso de que necesitaran investigar una falla del sistema.  Para describir los sistemas centralizados de recopilaci칩n de registros, <a href="https://tools.ietf.org/html/rfc3164">RFC 3164</a> sali칩 a principios de la d칠cada de 2000, que estandariz칩 remote_syslog.  Entonces apareci칩 otro componente importante: el <b>recolector (recolector) de registros</b> y su almacenamiento. <br><br>  Con el aumento en el volumen de registros y la adopci칩n generalizada de tecnolog칤as web, surgi칩 la pregunta de qu칠 registros deber칤an mostrarse convenientemente a los usuarios.  Las herramientas de consola simples (awk / sed / grep) fueron reemplazadas por <b>visores de registro</b> m치s avanzados: el tercer componente. <br><br>  En relaci칩n con el aumento en el volumen de registros, otra cosa qued칩 clara: se necesitan registros, pero no todos.  Y diferentes registros requieren diferentes niveles de seguridad: algunos se pueden perder cada dos d칤as, mientras que otros deben almacenarse durante 5 a침os.  Por lo tanto, se agreg칩 un componente de filtraci칩n y enrutamiento para flujos de datos al sistema de registro, llam칠moslo <b>filtro</b> . <br><br>  Los repositorios tambi칠n dieron un gran salto: cambiaron de archivos normales a bases de datos relacionales y luego a repositorios orientados a documentos (por ejemplo, Elasticsearch).  Entonces el almacenamiento se separ칩 del colector. <br><br>  Al final, el concepto del registro en s칤 se ha expandido a un flujo abstracto de eventos que queremos mantener para la historia.  M치s precisamente, en el caso de que sea necesario realizar una investigaci칩n o elaborar un informe anal칤tico ... <br><br>  Como resultado, durante un per칤odo de tiempo relativamente corto, la recopilaci칩n de registros se ha convertido en un subsistema importante, que leg칤timamente se puede llamar una de las subsecciones en Big Data. <br><br><img src="https://habrastorage.org/webt/ld/ax/r6/ldaxr6rvel45_k3jyu3d1eddcgw.png"><br>  <i>Si alguna vez las impresiones normales podr칤an ser suficientes para un "sistema de registro", ahora la situaci칩n ha cambiado mucho.</i> <br><br><h3>  Kubernetes y Registros </h3><br>  Cuando Kubernetes entr칩 en la infraestructura, el problema existente de recolectar registros no pas칩 por alto.  En cierto sentido, se ha vuelto a칰n m치s doloroso: la administraci칩n de la plataforma de infraestructura no solo se simplific칩, sino que tambi칠n fue complicada.  Muchos servicios antiguos comenzaron a migrar a pistas de microservicios.  En el contexto de los registros, esto dio como resultado un n칰mero creciente de fuentes de registro, su ciclo de vida especial y la necesidad de rastrear a trav칠s de los registros las interconexiones de todos los componentes del sistema ... <br><br>  Mirando hacia el futuro, puedo decir que ahora, desafortunadamente, no hay una opci칩n de registro estandarizada para Kubernetes que ser칤a favorablemente diferente de todos los dem치s.  Los esquemas m치s populares en la comunidad son los siguientes: <br><br><ul><li>  alguien est치 implementando una pila <b>EFK</b> (Elasticsearch, Fluentd, Kibana); </li><li>  alguien est치 probando el <a href="https://grafana.com/oss/loki/"><b>Loki</b></a> recientemente lanzado o usando el <a href="https://banzaicloud.com/products/logging-operator/"><b>operador Logging</b></a> ; </li><li>  nosotros <i>(쯫 quiz치s no solo nosotros?)</i> estamos en gran medida satisfechos con nuestro propio desarrollo: <a href="https://github.com/flant/loghouse"><b>loghouse</b></a> ... </li></ul><br>  Como regla, utilizamos tales paquetes en cl칰steres K8 (para soluciones autohospedadas): <br><br><ul><li>  <a href="https://github.com/kiwigrid/helm-charts/tree/master/charts/fluentd-elasticsearch">Fluentd + Elasticsearch + Kibana</a> ; </li><li>  <a href="https://github.com/flant/loghouse">Fluentd + ClickHouse + loghouse</a> . </li></ul><br>  Sin embargo, no me detendr칠 en las instrucciones para su instalaci칩n y configuraci칩n.  En cambio, me centrar칠 en sus defectos y conclusiones m치s globales sobre la situaci칩n con los registros en general. <br><br><h2>  Practica con registros en K8s </h2><br><img src="https://habrastorage.org/webt/zv/p8/lj/zvp8ljnjmqen_8c0svhhh2kezyc.jpeg" align="left"><br><h3>  "Registros diarios", 쯖u치ntos de ustedes? .. </h3><br>  La recolecci칩n centralizada de registros con una infraestructura suficientemente grande requiere recursos considerables que se gastar치n en recolectar, almacenar y procesar registros.  Durante la operaci칩n de varios proyectos, enfrentamos varios requisitos y los problemas operativos resultantes. <br><br><h4>  Probemos ClickHouse </h4><br>  Echemos un vistazo a un repositorio centralizado en un proyecto con una aplicaci칩n que genera muchos registros: m치s de 5000 l칤neas por segundo.  Comencemos a trabajar con sus registros, agreg치ndolos a ClickHouse. <br><br>  Tan pronto como se requiera el tiempo real m치ximo, el servidor ClickHouse de 4 n칰cleos ya estar치 sobrecargado en el subsistema de disco: <br><br><img src="https://habrastorage.org/webt/i4/zy/i6/i4zyi6fxq4175ljs3slazm9rgxc.png"><br><br>  Este tipo de descarga se debe al hecho de que estamos tratando de escribir en ClickHouse lo m치s r치pido posible.  Y la base de datos responde a esto con una mayor carga de disco, lo que puede causar los siguientes errores: <br><br> <code>DB::Exception: Too many parts (300). Merges are processing significantly slower than inserts</code> <br> <br>  El hecho es que <a href="https://clickhouse.yandex/docs/en/operations/table_engines/mergetree/">las tablas MergeTree</a> en ClickHouse (contienen datos de registro) tienen sus propias dificultades durante las operaciones de escritura.  Los datos insertados en ellos generan una partici칩n temporal, que luego se fusiona con la tabla principal.  Como resultado, la grabaci칩n es muy exigente en el disco y se aplica la restricci칩n, cuya notificaci칩n recibimos anteriormente: no se pueden fusionar m치s de 300 subparticiones en 1 segundo (de hecho, esto es 300 insert'ov por segundo). <br><br>  Para evitar este comportamiento, <a href="https://github.com/ClickHouse/ClickHouse/issues/3174">debe escribir en ClickHouse con la</a> mayor cantidad de fragmentos posible y no m치s de 1 vez en 2 segundos.  Sin embargo, escribir en grandes lotes sugiere que deber칤amos escribir con menos frecuencia en ClickHouse.  Esto, a su vez, puede provocar desbordamientos del b칰fer y p칠rdida de registros.  La soluci칩n es aumentar el b칰fer de Fluentd, pero luego aumentar치 el consumo de memoria. <br><br>  <i><b>Nota</b> : Otro lado problem치tico de nuestra soluci칩n ClickHouse fue que la partici칩n en nuestro caso (loghouse) se implement칩 a trav칠s de tablas externas vinculadas por una <a href="https://clickhouse.yandex/docs/ru/operations/table_engines/merge/">tabla Merge</a> .</i>  <i>Esto lleva al hecho de que al muestrear intervalos de tiempo grandes, se requiere RAM excesiva, ya que la metatabla pasa por todas las particiones, incluso aquellas que obviamente no contienen los datos necesarios.</i>  <i>Sin embargo, ahora este enfoque se puede declarar obsoleto de forma segura para las versiones actuales de ClickHouse (desde <a href="">18.16</a> ).</i> <br><br>  Como resultado, queda claro que ClickHouse no tiene suficientes recursos para cada proyecto para recopilar registros en tiempo real (m치s precisamente, su distribuci칩n no ser치 conveniente).  Adem치s, deber치 usar una <b>bater칤a</b> , a la que volveremos.  El caso descrito anteriormente es real.  Y en ese momento no pod칤amos ofrecer una soluci칩n confiable y estable que se adaptara al cliente y permitiera recopilar registros con un retraso m칤nimo ... <br><br><h4>  쯈u칠 hay de Elasticsearch? </h4><br>  Elasticsearch es conocido por manejar cargas pesadas.  Prob칠moslo en el mismo proyecto.  Ahora la carga es la siguiente: <br><br><img src="https://habrastorage.org/webt/jh/we/7o/jhwe7ok8_l0alrlv5j72p5lgha0.png"><br><br>  Elasticsearch fue capaz de digerir el flujo de datos, sin embargo, escribir tales vol칰menes en 칠l utiliza en gran medida la CPU.  Esto lo decide la organizaci칩n del cl칰ster.  Desde el punto de vista t칠cnico, esto no es un problema, pero resulta que solo para el funcionamiento del sistema de recopilaci칩n de registros ya utilizamos alrededor de 8 n칰cleos y tenemos un componente adicional altamente cargado en el sistema ... <br><br>  En pocas palabras: esta opci칩n puede justificarse, pero solo si el proyecto es grande y su administraci칩n est치 lista para gastar recursos significativos en un sistema de registro centralizado. <br><br>  Entonces surge una pregunta l칩gica: <br><br><h3>  쯈u칠 registros se necesitan realmente? </h3><br><img src="https://habrastorage.org/webt/hl/3h/ei/hl3heiig0t7nluwc_bvorqrrndk.jpeg" align="left">  Intentemos cambiar el enfoque en s칤: los registros deben ser informativos al mismo tiempo y no cubrir <i>todos los</i> eventos del sistema. <br><br>  Digamos que tenemos una tienda en l칤nea pr칩spera.  쯈u칠 registros son importantes?  Recopilar tanta informaci칩n como sea posible, por ejemplo, de una pasarela de pago es una gran idea.  Pero del servicio de corte de im치genes en el cat치logo de productos, no todos los registros son cr칤ticos para nosotros: solo los errores y la supervisi칩n avanzada son suficientes (por ejemplo, el porcentaje de 500 errores que genera este componente). <br><br>  Entonces llegamos a la <b>conclusi칩n de</b> que <b>el registro centralizado est치 lejos de estar siempre justificado</b> .  Muy a menudo, el cliente quiere recopilar todos los registros en un solo lugar, aunque de hecho solo el 5% de los mensajes que son cr칤ticos para el negocio se requieren de todo el registro: <br><br><ul><li>  A veces es suficiente configurar, por ejemplo, solo el tama침o del registro del contenedor y el recopilador de errores (por ejemplo, Centinela). </li><li>  Para investigar incidentes, las alertas de error y un gran registro local a menudo pueden ser suficientes. </li><li>  Ten칤amos proyectos que costaban completamente solo pruebas funcionales y sistemas de recolecci칩n de errores.  El desarrollador no necesitaba los registros como tales: vieron todo en las trazas de errores. </li></ul><br><h4>  Ilustraci칩n de la vida </h4><br>  Un buen ejemplo es otra historia.  Recibimos una solicitud del equipo de seguridad de uno de los clientes que ya ten칤a una soluci칩n comercial que se desarroll칩 mucho antes de la implementaci칩n de Kubernetes. <br><br>  Se necesit칩 "hacer amigos" un sistema centralizado de recopilaci칩n de registros con un sensor corporativo para detectar problemas: QRadar.  Este sistema puede recibir registros utilizando el protocolo syslog, para tomarlo desde FTP.  Sin embargo, integrarlo con el complemento remote_syslog para fluentd no funcion칩 de inmediato <i>(como result칩, <a href="https://developer.ibm.com/answers/questions/429729/using-fluentd-to-streamfilter-data-to-qradar/">no somos los 칰nicos</a> )</i> .  Los problemas con la configuraci칩n de QRadar estaban del lado del equipo de seguridad del cliente. <br><br>  Como resultado, parte de los registros cr칤ticos para los negocios se cargaron a FTP QRadar, y la otra parte se redirigi칩 a trav칠s de syslog remoto directamente desde los nodos.  Para hacer esto, incluso escribimos un <a href="https://github.com/flant/examples/tree/master/2019/10-remote-syslog">gr치fico simple</a> : tal vez ayude a alguien a resolver un problema similar ... Gracias al esquema resultante, el cliente mismo recibi칩 y analiz칩 registros cr칤ticos (usando sus herramientas favoritas), y pudimos reducir el costo del sistema de registro, manteniendo solo el 칰ltimo mes <br><br>  Otro ejemplo es bastante indicativo de c칩mo no hacerlo.  Uno de nuestros clientes para manejar <i>cada</i> evento proveniente del usuario, realiz칩 una <i>salida de</i> informaci칩n no <i>estructurada</i> multil칤nea al registro.  Como puede suponer, tales registros eran extremadamente inconvenientes para leer y almacenar. <br><br><h3>  Criterios para los registros </h3><br>  Tales ejemplos llevan a la conclusi칩n de que, adem치s de elegir un sistema para recopilar registros, 춰tambi칠n debe <i>dise침ar los registros ellos mismos</i> !  쮺u치les son los requisitos aqu칤? <br><br><ul><li>  Los registros deben estar en un formato legible por m치quina (por ejemplo, JSON). </li><li>  Los registros deben ser compactos y con la capacidad de cambiar el grado de registro para depurar posibles problemas.  Al mismo tiempo, en entornos de producci칩n, debe ejecutar sistemas con un nivel de registro como <i>Advertencia</i> o <i>Error</i> . </li><li>  Los registros deben estar normalizados, es decir, en el objeto de registro, todas las l칤neas deben tener el mismo tipo de campo. </li></ul><br>  Los registros no estructurados pueden provocar problemas al cargar registros en el repositorio y detener su procesamiento por completo.  Para ilustrar, aqu칤 hay un ejemplo con un error 400, que muchos seguramente encontraron en los registros fluidos: <br><br> <code>2019-10-29 13:10:43 +0000 [warn]: dump an error event: error_class=Fluent::Plugin::ElasticsearchErrorHandler::ElasticsearchError error="400 - Rejected by Elasticsearch"</code> <br> <br>  Un error significa que est치 enviando un campo cuyo tipo es inestable al 칤ndice con una asignaci칩n lista.  El ejemplo m치s simple es un campo en el registro nginx con la variable <code>$upstream_status</code> .  Puede tener un n칰mero o una cadena.  Por ejemplo: <br><br> <code>{ "ip": "1.2.3.4", "http_user": "-", "request_id": "17ee8a579e833b5ab9843a0aca10b941", "time": "29/Oct/2019:16:18:57 +0300", "method": "GET", "uri": "/staffs/265.png", "protocol": "HTTP/1.1", "status": "200", "body_size": "906", "referrer": "https://example.com/staff", "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36", "request_time": "0.001", "cache_status": "-", "upstream_response_time": "0.001, 0.007", "upstream_addr": "127.0.0.1:9000", "upstream_status": "200", "upstream_response_length": "906", "location": "staff"} <br> { "ip": "1.2.3.4", "http_user": "-", "request_id": "47fe42807f2a7d8d5467511d7d553a1b", "time": "29/Oct/2019:16:18:57 +0300", "method": "GET", "uri": "/staff", "protocol": "HTTP/1.1", "status": "200", "body_size": "2984", "referrer": "-", "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36", "request_time": "0.010", "cache_status": "-", "upstream_response_time": "0.001, 0.007", "upstream_addr": "10.100.0.10:9000, 10.100.0.11:9000", "upstream_status": "404, 200", "upstream_response_length": "0, 2984", "location": "staff"}</code> <br> <br>  Los registros muestran que el servidor 10.100.0.10 respondi칩 con el error 404 y la solicitud fue a otro almac칠n de contenido.  Como resultado, en los registros, el significado se ha convertido as칤: <br><br> <code>"upstream_response_time": "0.001, 0.007"</code> <br> <br>  Esta situaci칩n est치 tan extendida que incluso gan칩 una <a href="https://github.com/uken/fluent-plugin-elasticsearch">menci칩n por</a> separado <a href="https://github.com/uken/fluent-plugin-elasticsearch">en la documentaci칩n</a> . <br><br><h4>  쯏 qu칠 hay de la fiabilidad? </h4><br>  Hay momentos en que todos los registros son vitales sin excepci칩n.  Y con esto, los esquemas t칤picos de recopilaci칩n de registros para K8 propuestos / discutidos anteriormente tienen problemas. <br><br>  Por ejemplo, fluentd no puede recolectar registros de contenedores de corta duraci칩n.  En uno de nuestros proyectos, el contenedor con la migraci칩n de la base de datos dur칩 menos de 4 segundos y luego se elimin칩, de acuerdo con la anotaci칩n correspondiente: <br><br> <code>"helm.sh/hook-delete-policy": hook-succeeded</code> <br> <br>  Debido a esto, el registro de migraci칩n no entr칩 en el repositorio.  La pol칤tica de <code>before-hook-creation</code> puede ayudar en este caso. <br><br>  Otro ejemplo es la rotaci칩n de los registros de Docker.  Supongamos que hay una aplicaci칩n que escribe activamente en los registros.  En condiciones normales, logramos procesar todos los registros, pero tan pronto como surge un problema, por ejemplo, como se describi칩 anteriormente con el formato incorrecto, el procesamiento se detiene y Docker gira el archivo.  En pocas palabras: los registros cr칤ticos para el negocio pueden perderse. <br><br>  Por eso <b>es importante separar el flujo de registros</b> , integrando el env칤o de los m치s valiosos directamente en la aplicaci칩n para garantizar su seguridad.  Adem치s, no ser치 superfluo crear una especie de <b>"acumulador" de registros</b> que pueda sobrevivir a la breve falta de disponibilidad del almacenamiento mientras se mantienen los mensajes cr칤ticos. <br><br>  Finalmente, no olvide que <b>es importante monitorear cualquier subsistema de manera de calidad</b> .  De lo contrario, es f치cil encontrar una situaci칩n en la que fluentd est칠 en el estado <code>CrashLoopBackOff</code> y no env칤e nada, lo que promete la p칠rdida de informaci칩n importante. <br><br><h2>  Conclusiones </h2><br>  En este art칤culo, no consideramos soluciones SaaS como Datadog.  Muchos de los problemas descritos aqu칤 ya han sido resueltos de una forma u otra por empresas comerciales especializadas en recopilar registros, pero no todos pueden usar SaaS por varias razones <i>(las principales son el costo y el cumplimiento de 152-)</i> . <br><br>  La colecci칩n centralizada de registros al principio parece una tarea simple, pero no lo es en absoluto.  Es importante recordar que: <br><br><ul><li>  El registro detallado solo es un componente cr칤tico y, para otros sistemas, puede configurar la supervisi칩n y la recopilaci칩n de errores. </li><li>  Los registros en la producci칩n deben minimizarse para no dar una carga adicional. </li><li>  Los registros deben ser legibles por m치quina, normalizados, tener un formato estricto. </li><li>  Los registros realmente cr칤ticos deben enviarse en una secuencia separada, que debe separarse de las principales. </li><li>  Vale la pena considerar una bater칤a de registro, que puede ahorrar de estallidos de alta carga y hacer que la carga en el almacenamiento sea m치s uniforme. </li></ul><br><img src="https://habrastorage.org/webt/ss/hd/9f/sshd9fqiav2abndbb_uqo0mdjke.jpeg" align="left"><br>  Estas reglas simples, si se aplican en todas partes, permitir칤an que los circuitos descritos anteriormente funcionen, a pesar de que carecen de componentes importantes (bater칤a).  Si no se adhiere a dichos principios, la tarea lo llevar치 f치cilmente a usted y a la infraestructura a otro componente del sistema altamente cargado (y al mismo tiempo ineficaz). <br><br><h2>  PS </h2><br>  Lea tambi칠n en nuestro blog: <br><br><ul><li>  " <a href="https://habr.com/ru/company/flant/blog/341386/">Presentaci칩n de loghouse: un sistema de c칩digo abierto para trabajar con registros en Kubernetes</a> "; </li><li>  " <a href="https://m.habr.com/ru/news/t/476966/">Lanzamientos para el ecosistema de Kubernetes con KubeCon'19: JFrog Container Registry, Kui de IBM, Loki 1.0.0 ...</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/412901/">Monitoreo y Kubernetes (revisi칩n e informe de video)</a> ". </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/480946/">https://habr.com/ru/post/480946/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../480930/index.html">Escribe todo</a></li>
<li><a href="../480936/index.html">IntelliJ IDEA conversi칩n r치pida UPPER_CASE a camelCase</a></li>
<li><a href="../480938/index.html">Criptomoneda a trav칠s de los ojos de los jueces rusos</a></li>
<li><a href="../480940/index.html">Ejecute la prueba de interfaz de usuario de navegador cruzado con Cucumber y Selenoid en Gitlab CI con el informe Allure</a></li>
<li><a href="../480944/index.html">Las 5 principales tendencias en marketing por correo electr칩nico en 2020</a></li>
<li><a href="../480948/index.html">Mitap marketing y relaciones p칰blicas en Ivanovo</a></li>
<li><a href="../480950/index.html">An치lisis del cuestionario de Android desde el stand hh.ru en Mobius 2019 Mosc칰</a></li>
<li><a href="../480954/index.html">Tarea n칰mero 1. Descubre g칠nero y grado de relaci칩n</a></li>
<li><a href="../480956/index.html">C칩mo encontr칠 una manera de rastrear a todos los conductores de Citimobil</a></li>
<li><a href="../480958/index.html">Conexi칩n satelital. Descripci칩n general de las compa침칤as operadoras y un poco sobre la calificaci칩n</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
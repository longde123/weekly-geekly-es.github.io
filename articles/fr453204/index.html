<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üè∞ ü•ù üë∞üèæ Conteneurs, microservices et maillages de service ü•î üßëüèª üñ≤Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il y a des tonnes d' articles sur le maillage des services sur Internet, et en voici un autre. Hourra! Mais pourquoi? Ensuite, ce que je veux exprimer...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Conteneurs, microservices et maillages de service</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/453204/">  Il y a des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tonnes d'</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">articles</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur le</a> maillage des services <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur</a> Internet, et en voici un autre.  Hourra!  Mais pourquoi?  Ensuite, ce que je veux exprimer, c'est qu'il serait pr√©f√©rable que les maillages de service apparaissent il y a 10 ans, avant l'√©mergence de plates-formes de conteneurs telles que Docker et Kubernetes.  Je ne pr√©tends pas que mon point de vue est meilleur ou pire que les autres, mais comme les mailles de service sont des animaux assez complexes, la multiplicit√© des points de vue aidera √† mieux les comprendre. <br><br>  Je vais parler de la plate-forme dotCloud, qui a √©t√© construite sur plus d'une centaine de microservices et a pris en charge des milliers d'applications dans des conteneurs.  Je vais vous expliquer les probl√®mes que nous avons rencontr√©s lors de son d√©veloppement et de son lancement, et comment les maillages de service peuvent aider (ou pas). <br><a name="habracut"></a><br><h1>  Histoire de dotCloud </h1><br>  J'ai d√©j√† √©crit sur l'histoire de dotCloud et le choix de l'architecture de cette plate-forme, mais j'ai parl√© un peu du niveau du r√©seau.  Si vous ne voulez pas vous plonger dans la lecture de l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article pr√©c√©dent</a> sur dotCloud, voici un bref r√©sum√©: c'est une plate-forme PaaS en tant que service qui permet aux clients de lancer une large gamme d'applications (Java, PHP, Python ...), avec la prise en charge d'une large gamme de services de donn√©es (MongoDB, MySQL, Redis ...) et un workflow comme Heroku: vous t√©l√©chargez votre code sur la plateforme, il construit des images de conteneurs et les d√©ploie. <br><br>  Je vais vous expliquer comment le trafic a √©t√© dirig√© vers la plate-forme dotCloud.  Non pas parce qu'il √©tait particuli√®rement cool (bien que le syst√®me ait bien fonctionn√© pour l'√©poque!), Mais principalement parce qu'avec l'aide d'outils modernes, une telle conception peut facilement √™tre mise en ≈ìuvre en peu de temps par une √©quipe modeste si elle a besoin d'un moyen d'acheminer le trafic entre un tas de microservices ou un tas d'applications.  Ainsi, vous pouvez comparer les options: que se passe-t-il si vous d√©veloppez tout vous-m√™me ou utilisez le maillage de service existant.  Choix standard: faites-le vous-m√™me ou achetez. <br><br><h1>  Routage du trafic pour les applications h√©berg√©es </h1><br>  Les applications DotCloud peuvent fournir des points de terminaison HTTP et TCP. <br><br>  <b>Les points de terminaison HTTP sont</b> ajout√©s dynamiquement √† la configuration du cluster d'√©quilibrage de charge <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Hipache</a> .  Ceci est similaire √† ce que font les ressources Kubernetes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ingress</a> et un √©quilibreur de charge comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Traefik aujourd'hui</a> . <br><br>  Les clients se connectent aux points de terminaison HTTP via leurs domaines respectifs, √† condition que le nom de domaine pointe vers des √©quilibreurs de charge dotCloud.  Rien de sp√©cial. <br><br>  <b>Les points de terminaison TCP</b> sont associ√©s √† un num√©ro de port, qui est ensuite transmis √† tous les conteneurs de cette pile via des variables d'environnement. <br><br>  Les clients peuvent se connecter aux points de terminaison TCP en utilisant le nom d'h√¥te appropri√© (quelque chose comme gateway-X.dotcloud.com) et le num√©ro de port. <br><br>  Ce nom d'h√¥te se r√©sout en cluster de serveurs ¬´nats¬ª (non li√© √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">NATS</a> ), qui acheminera les connexions TCP entrantes vers le conteneur appropri√© (ou, dans le cas de services √† charge √©quilibr√©e, vers les conteneurs appropri√©s). <br><br>  Si vous connaissez Kubernetes, cela vous rappellera probablement les services <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">NodePort</a> . <br><br>  Il n'y avait pas d'√©quivalent des services <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ClusterIP</a> sur la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plate</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">forme dotCloud</a> : pour simplifier, l'acc√®s aux services √©tait le m√™me de l'int√©rieur et de l'ext√©rieur de la plate-forme. <br><br>  Tout √©tait organis√© tout simplement: les impl√©mentations initiales des r√©seaux de routage HTTP et TCP, probablement quelques centaines de lignes de Python.  Algorithmes simples (je dirais na√Øfs) qui ont √©t√© finalis√©s avec la croissance de la plate-forme et l'av√®nement d'exigences suppl√©mentaires. <br><br>  Une refactorisation approfondie du code existant n'√©tait pas n√©cessaire.  En particulier, les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">applications √† 12 facteurs</a> peuvent utiliser directement l'adresse obtenue via les variables d'environnement. <br><br><h1>  En quoi cela diff√®re-t-il d'un maillage de service moderne? </h1><br>  <b>Visibilit√©</b> limit√©e.  Nous n'avions g√©n√©ralement pas de m√©triques pour la grille de routage TCP.  En ce qui concerne le routage HTTP, les versions ult√©rieures ont des m√©triques HTTP d√©taill√©es avec des codes d'erreur et des temps de r√©ponse, mais les maillages de service modernes vont encore plus loin, offrant une int√©gration avec des syst√®mes de collecte de m√©triques comme Prometheus, par exemple. <br><br>  La visibilit√© est importante non seulement d'un point de vue op√©rationnel (pour aider √† r√©soudre les probl√®mes), mais aussi lorsque de nouvelles fonctionnalit√©s sont publi√©es.  Il s'agit d'un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©ploiement bleu-vert</a> s√ªr et d'un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©ploiement de canaris</a> . <br><br>  <b>L'efficacit√© du routage est</b> √©galement limit√©e.  Dans la grille de routage dotCloud, tout le trafic devait passer par un cluster de n≈ìuds de routage d√©di√©s.  Cela signifiait un franchissement potentiel de plusieurs fronti√®res AZ (zones d'accessibilit√©) et une augmentation significative des retards.  Je me souviens comment j'ai r√©solu des probl√®mes avec du code qui faisait plus d'une centaine de requ√™tes SQL par page et pour chaque requ√™te, j'ouvrais une nouvelle connexion au serveur SQL.  Lorsqu'elle est lanc√©e localement, la page se charge instantan√©ment, mais dans dotCloud, le chargement prend quelques secondes, car cela prend des dizaines de millisecondes pour chaque connexion TCP (et la requ√™te SQL suivante).  Dans ce cas particulier, les connexions persistantes ont r√©solu le probl√®me. <br><br>  Les maillages de service modernes font mieux avec de tels probl√®mes.  Tout d'abord, ils v√©rifient que les connexions sont achemin√©es <i>√† la source</i> .  Le flux logique est le m√™me: <code> ‚Üí  ‚Üí </code> , mais maintenant le mesh fonctionne localement et non sur des n≈ìuds distants, donc la connexion <code> ‚Üí </code> est locale et tr√®s rapide (microsecondes au lieu de millisecondes). <br><br>  Les maillages de service modernes impl√©mentent √©galement des algorithmes d'√©quilibrage de charge plus intelligents.  En contr√¥lant les performances des backends, ils peuvent envoyer plus de trafic vers des backends plus rapides, ce qui entra√Æne une augmentation des performances globales. <br><br>  <b>La s√©curit√©</b> est √©galement meilleure.  La grille de routage dotCloud a fonctionn√© compl√®tement sur EC2 Classic et n'a pas chiffr√© le trafic (en supposant que si quelqu'un a r√©ussi √† mettre un renifleur sur le trafic r√©seau EC2, vous avez d√©j√† de gros probl√®mes).  Les maillages de service modernes prot√®gent de mani√®re transparente tout notre trafic, par exemple, avec l'authentification TLS mutuelle et le cryptage ult√©rieur. <br><br><h1>  Routage du trafic pour les services de plate-forme </h1><br>  Ok, nous avons discut√© du trafic entre les applications, mais qu'en est-il de la plate-forme dotCloud elle-m√™me? <br><br>  La plateforme elle-m√™me √©tait constitu√©e d'une centaine de microservices charg√©s de diff√©rentes fonctions.  Certains ont re√ßu des demandes d'autres, et certains √©taient des travailleurs de fond qui se connectaient √† d'autres services mais n'acceptaient pas les connexions.  Dans tous les cas, chaque service doit conna√Ætre les noeuds finaux des adresses auxquelles il est n√©cessaire de se connecter. <br><br>  De nombreux services de haut niveau peuvent utiliser la grille de routage d√©crite ci-dessus.  En fait, bon nombre des centaines de microservices dotCloud ont √©t√© d√©ploy√©s en tant qu'applications r√©guli√®res sur la plate-forme dotCloud elle-m√™me.  Mais un petit nombre de services de bas niveau (en particulier, qui impl√©mentent cette grille de routage) avaient besoin de quelque chose de plus simple, avec moins de d√©pendances (car ils ne pouvaient pas d√©pendre d'eux-m√™mes pour le travail - un bon vieux probl√®me de poule et d'oeuf). <br><br>  Ces services importants de bas niveau ont √©t√© d√©ploy√©s en ex√©cutant des conteneurs directement sur plusieurs n≈ìuds cl√©s.  Dans le m√™me temps, les services de plate-forme standard n'√©taient pas impliqu√©s: l'√©diteur de liens, le planificateur et le coureur.  Si vous voulez comparer avec les plates-formes de conteneurs modernes, c'est comme lancer un plan de contr√¥le avec <code>docker run</code> directement sur les n≈ìuds, au lieu de d√©l√©guer la t√¢che Kubernetes.  Ceci est assez similaire au concept de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">modules statiques (foyers)</a> que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">kubeadm</a> ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bootkube utilise</a> lors du chargement d'un cluster autonome. <br><br>  Ces services ont √©t√© expos√©s de mani√®re simple et grossi√®re: leurs noms et adresses ont √©t√© r√©pertori√©s dans le fichier YAML;  et chaque client devait prendre une copie de ce fichier YAML pour le d√©ploiement. <br><br>  D'une part, il est extr√™mement fiable, car il ne n√©cessite pas de prise en charge d'un stockage de cl√© / valeur externe tel que Zookeeper (n'oubliez pas, √† ce moment-l√†, etcd ou Consul n'existaient pas encore).  D'un autre c√¥t√©, cela a rendu difficile le transfert de services.  √Ä chaque d√©placement, tous les clients doivent avoir re√ßu un fichier YAML mis √† jour (et potentiellement red√©marrer).  Pas tr√®s pratique! <br><br>  Par la suite, nous avons commenc√© √† introduire un nouveau sch√©ma, o√π chaque client se connectait √† un serveur proxy local.  Au lieu de l'adresse et du port, il lui suffit de conna√Ætre uniquement le num√©ro de port du service et de se connecter via <code>localhost</code> .  Le serveur proxy local traite cette connexion et l'achemine vers le serveur r√©el.  Maintenant, lorsque vous d√©placez le backend vers une autre machine ou que vous faites √©voluer au lieu de mettre √† jour tous les clients, vous devez mettre √† jour uniquement tous ces proxys locaux;  et un red√©marrage n'est plus n√©cessaire. <br><br>  (Il √©tait √©galement pr√©vu d'encapsuler le trafic dans les connexions TLS et de placer un autre serveur proxy du c√¥t√© de la r√©ception, ainsi que de v√©rifier les certificats TLS sans la participation du service de r√©ception, qui est configur√© pour accepter les connexions uniquement sur l' <code>localhost</code> . Plus d'informations √† ce sujet plus tard). <br><br>  Ceci est tr√®s similaire au <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SmartStack</a> d'Airbnb, mais la diff√©rence significative est que SmartStack est impl√©ment√© et d√©ploy√© en production, tandis que le syst√®me de routage interne dotCloud a √©t√© mis dans une bo√Æte lorsque dotCloud est devenu Docker. <br><br>  Personnellement, je consid√®re SmartStack comme l'un des pr√©d√©cesseurs de syst√®mes tels que Istio, Linkerd et Consul Connect, car ils suivent tous le m√™me mod√®le: <br><br><ul><li>  Ex√©cution de proxys sur chaque n≈ìud. <br></li><li>  Les clients se connectent au proxy. <br></li><li>  Le plan de gestion met √† jour la configuration du proxy lors du changement de backends. <br></li><li>  ... Profit! </li></ul><br><h1>  Impl√©mentation moderne d'un maillage de service </h1><br>  Si nous devons mettre en ≈ìuvre une grille similaire aujourd'hui, nous pouvons utiliser des principes similaires.  Par exemple, configurez la zone DNS interne en mappant les noms de service aux adresses dans <code>127.0.0.0/8</code> .  Ex√©cutez ensuite HAProxy sur chaque n≈ìud du cluster, en acceptant les connexions √† chaque adresse de service ( <code>127.0.0.0/8</code> dans ce sous-r√©seau) et en redirigeant / √©quilibrant la charge vers les backends correspondants.  La configuration HAProxy peut √™tre contr√¥l√©e par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">confd</a> , vous permettant de stocker des informations de backend dans etcd ou Consul et de pousser automatiquement la configuration mise √† jour vers HAProxy si n√©cessaire. <br><br>  Voil√† comment Istio fonctionne!  Mais avec quelques diff√©rences: <br><br><ul><li>  Utilise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Envoy Proxy</a> au lieu de HAProxy. <br></li><li>  Enregistre la configuration du backend via l'API Kubernetes au lieu de etcd ou Consul. <br></li><li>  Les services se voient allouer des adresses sur le sous-r√©seau interne (adresses Kubernetes ClusterIP) au lieu de 127.0.0.0/8. <br></li><li>  Il dispose d'un composant facultatif (Citadel) pour ajouter une authentification TLS mutuelle entre le client et les serveurs. <br></li><li>  Prend en charge de nouvelles fonctionnalit√©s telles que la coupure de circuit, le tra√ßage distribu√©, le d√©ploiement de canaris, etc. </li></ul><br>  Jetons un coup d'≈ìil √† certaines des diff√©rences. <br><br><h3>  Envoy proxy </h3><br>  Enftoy Proxy a √©t√© √©crit par Lyft [concurrent Uber sur le march√© des taxis - env.  trans.].  Il est tr√®s similaire aux autres proxys √† bien des √©gards (par exemple, HAProxy, Nginx, Traefik ...), mais Lyft a √©crit la sienne car ils avaient besoin de fonctions qui ne sont pas dans d'autres proxys, et il semblait plus raisonnable d'en cr√©er une nouvelle que de d√©velopper celle existante. <br><br>  Envoy peut √™tre utilis√© seul.  Si j'ai un service sp√©cifique qui doit se connecter √† d'autres services, je peux le configurer pour se connecter √† Envoy, puis configurer et reconfigurer dynamiquement Envoy avec l'emplacement d'autres services, tout en recevant de nombreuses excellentes fonctionnalit√©s suppl√©mentaires, par exemple, la visibilit√©.  Au lieu d'une biblioth√®que cliente personnalis√©e ou de l'int√©gration du suivi des appels dans le code, nous dirigeons le trafic vers Envoy, et il recueille des m√©triques pour nous. <br><br>  Mais Envoy est √©galement capable de fonctionner comme un plan de donn√©es pour un maillage de service.  Cela signifie que pour ce maillage de service, Envoy est maintenant configur√© <i>par le</i> plan de contr√¥le. <br><br><h3>  Avion de contr√¥le </h3><br>  Dans le plan de gestion, Istio s'appuie sur l'API Kubernetes.  <i>Ce n'est pas tr√®s diff√©rent de l'utilisation de confd</i> , qui s'appuie sur etcd ou Consul pour afficher un ensemble de cl√©s dans un entrep√¥t de donn√©es.  Istio, via l'API Kubernetes, affiche l'ensemble de ressources Kubernetes. <br><br>  <i>Entre les deux</i> : j'ai personnellement trouv√© cette <a href="">description de l'API Kubernetes utile</a> , qui se lit comme suit: <br><br><blockquote>  Le serveur API Kubernetes est un ¬´serveur stupide¬ª qui offre le stockage, la gestion des versions, la validation, la mise √† jour et la s√©mantique des ressources API. </blockquote><br>  Istio est con√ßu pour fonctionner avec Kubernetes;  et si vous souhaitez l'utiliser en dehors de Kubernetes, vous devez ex√©cuter une instance du serveur API Kubernetes (et le service auxiliaire, etc.). <br><br><h3>  Adresses de service </h3><br>  Istio s'appuie sur les adresses ClusterIP que Kubernetes alloue, donc les services Istio obtiennent une adresse interne (pas dans la plage <code>127.0.0.0/8</code> ). <br><br>  Le trafic vers l'adresse ClusterIP pour un service sp√©cifique dans le cluster Kubernetes sans Istio est intercept√© par kube-proxy et envoy√© √† la partie serveur de ce proxy.  Si vous √™tes int√©ress√© par les d√©tails techniques, alors kube-proxy d√©finit les r√®gles iptables (ou les √©quilibreurs de charge IPVS, selon la fa√ßon dont vous les configurez) pour r√©√©crire les adresses IP de destination des connexions allant √† l'adresse ClusterIP. <br><br>  Apr√®s avoir install√© Istio dans le cluster Kubernetes, rien ne change jusqu'√† ce qu'il soit explicitement activ√© pour le consommateur donn√© ou m√™me l'espace de noms entier en introduisant le conteneur <code>sidecar</code> dans des foyers personnalis√©s.  Ce conteneur d√©marrera une instance d'Envoy et d√©finira une s√©rie de r√®gles iptables pour intercepter le trafic vers d'autres services et rediriger ce trafic vers Envoy. <br><br>  Lorsqu'il est int√©gr√© √† Kubernetes DNS, cela signifie que notre code peut se connecter par le nom du service, et tout "fonctionne simplement".  En d'autres termes, notre code √©met des requ√™tes comme <code>http://api/v1/users/4242</code> , puis <code>api</code> r√©sout la requ√™te en <code>10.97.105.48</code> , les r√®gles iptables interceptent les connexions de 10.97.105.48 et les redirigent vers le proxy Envoy local, et ce proxy local dirigera demande de l'API backend r√©elle.  Fuh! <br><br><h3>  Petits trucs suppl√©mentaires </h3><br>  Istio fournit √©galement un chiffrement et une authentification de bout en bout via mTLS (Mutual TLS).  Le composant appel√© <i>Citadelle en</i> est responsable. <br><br>  Il existe √©galement un composant <i>Mixer</i> qu'Envoy peut demander pour <i>chaque</i> demande afin de prendre une d√©cision sp√©ciale √† propos de cette demande, en fonction de divers facteurs, tels que les en-t√™tes, le chargement du backend, etc. ... (ne vous inqui√©tez pas: il existe de nombreuses fa√ßons de s'assurer que le Mixer fonctionne, et m√™me s'il se bloque, Envoy continuera de fonctionner normalement en tant que proxy). <br><br>  Et, bien s√ªr, nous avons mentionn√© la visibilit√©: Envoy collecte un grand nombre de m√©triques, tout en fournissant un suivi distribu√©.  Dans l'architecture des microservices, si une demande d'API doit passer par les microservices A, B, C et D, puis lorsque vous vous connectez au syst√®me, la trace distribu√©e ajoutera un identifiant unique √† la demande et enregistrera cet identifiant via des sous-requ√™tes √† tous ces microservices, vous permettant d'enregistrer tous les appels associ√©s, leurs retards, etc. <br><br><h1>  D√©velopper ou acheter </h1><br>  Istio a la r√©putation d'√™tre un syst√®me complexe.  En revanche, la construction d'une grille de routage, que j'ai d√©crite au d√©but de cet article, est relativement simple √† l'aide des outils existants.  Alors, est-il judicieux de cr√©er votre propre maillage de service √† la place? <br><br>  Si nous avons des besoins modestes (vous n'avez pas besoin de visibilit√©, d'un disjoncteur et d'autres subtilit√©s), alors des r√©flexions viennent sur le d√©veloppement de votre propre outil.  Mais si nous utilisons Kubernetes, cela peut m√™me ne pas √™tre n√©cessaire, car Kubernetes fournit d√©j√† des outils de base pour la d√©couverte de services et l'√©quilibrage de charge. <br><br>  Mais si nous avons des exigences avanc√©es, ¬´acheter¬ª un maillage de service semble √™tre une bien meilleure option.  (Ce n'est pas toujours un ¬´achat¬ª, car Istio est livr√© avec du code open source, mais nous devons encore investir du temps d'ing√©nierie pour comprendre son travail, le d√©ployer et le g√©rer). <br><br><h1>  Que choisir: Istio, Linkerd ou Consul Connect? </h1><br>  Jusqu'√† pr√©sent, nous n'avons parl√© que d'Istio, mais ce n'est pas le seul maillage de service.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Linkerd</a> est une alternative populaire et il existe √©galement <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Consul Connect</a> . <br><br>  Que choisir? <br><br>  Honn√™tement, je ne sais pas.  Pour le moment, je ne me consid√®re pas assez comp√©tent pour r√©pondre √† cette question.  Il existe des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">articles</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">int√©ressants</a> comparant ces outils et m√™me des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©f√©rences</a> . <br><br>  Une approche prometteuse consiste √† utiliser un outil comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SuperGloo</a> .  Il impl√©mente une couche d'abstraction pour simplifier et unifier les API fournies par les maillages de service.  Au lieu d'√©tudier des API sp√©cifiques (et, √† mon avis, relativement complexes) de divers maillages de service, nous pouvons utiliser des constructions SuperGloo plus simples - et passer facilement de l'une √† l'autre, comme si nous avions un format de configuration interm√©diaire qui d√©crit les interfaces HTTP et backends capables de g√©n√©rer la configuration r√©elle pour Nginx, HAProxy, Traefik, Apache ... <br><br>  Je me suis un peu laiss√© aller √† Istio et SuperGloo, et dans l'article suivant, je veux montrer comment ajouter Istio ou Linkerd √† un cluster existant √† l'aide de SuperGloo, et dans quelle mesure ce dernier fera face √† son travail, c'est-√†-dire qu'il vous permet de passer d'un maillage de service √† un autre sans r√©√©crire les configurations. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr453204/">https://habr.com/ru/post/fr453204/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr453190/index.html">ANPR utilisant RoR & React Native</a></li>
<li><a href="../fr453192/index.html">Synchronisation et asynchronie des processus</a></li>
<li><a href="../fr453194/index.html">Nous r√©solvons le probl√®me du meilleur inverseur avec PHDays 9</a></li>
<li><a href="../fr453196/index.html">Forrester Research: une comparaison des dix meilleurs fournisseurs d'analyse de composition logicielle</a></li>
<li><a href="../fr453200/index.html">Discussion: le projet OpenROAD entend r√©soudre la t√¢che d'automatisation de la conception des processeurs</a></li>
<li><a href="../fr453206/index.html">Entretien avec Kelsey Moody: comment cr√©er une entreprise et mettre fin aux pathologies li√©es √† l'√¢ge</a></li>
<li><a href="../fr453212/index.html">Consumer Reports: le dernier pilote automatique de Tesla est loin d'√™tre parfait</a></li>
<li><a href="../fr453214/index.html">Comment et pourquoi rester en forme si vous √™tes un informaticien sur un site distant</a></li>
<li><a href="../fr453216/index.html">Syst√®mes de surveillance du trafic dans les r√©seaux VoIP. Deuxi√®me partie - Principes d'organisation</a></li>
<li><a href="../fr453218/index.html">L'essentiel avec YaC 2019: une centaine de drones sur les routes, Yandex.Module, food, smart home</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤴🏻 🈶 ✅ 介绍识别情绪的任务 👨🏿‍🌾 😊 👱🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="情感识别是人工智能领域的热门话题。 此类技术最有趣的应用领域包括：驾驶员识别，市场研究，智能城市的视频分析系统，人机交互，监控在线课程的学生，可穿戴设备等。 


 今年，MDG将其夏季机器学习学校专用于此主题。 在本文中，我将简要介绍识别人的情绪状态的问题，并介绍解决方法。 

 什么是情感？ 
...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>介绍识别情绪的任务</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/speechpro/blog/418151/"><p> 情感识别是人工智能领域的热门话题。 此类技术最有趣的应用领域包括：驾驶员识别，市场研究，智能城市的视频分析系统，人机交互，监控在线课程的学生，可穿戴设备等。 </p><br><p> 今年，MDG将其<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">夏季机器学习学校</a>专用于此主题。 在本文中，我将简要介绍识别人的情绪状态的问题，并介绍解决方法。 </p><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/626/db4/5bb/626db45bb7b0aad7fdbc2970c0b4183f.jpg" alt="图片"></div><a name="habracut"></a><br><h3 id="chto-takoe-emocii"> 什么是情感？ </h3><br><p> 情绪是一种特殊的心理过程，表达一个人对自己与世界和自己的关系的体验。 根据其中一种理论，作者是俄罗斯生理学家P.K.  Anokhin，体验情绪的能力是在进化过程中发展起来的，是使生物更成功地适应存在条件的一种手段。 情绪对于生存非常有用，它可以使生物快速，最经济地应对外部影响。 </p><br><p> 情感在人类生活和人际交往中发挥着重要作用。 它们可以通过多种方式表达：面部表情，姿势，运动反应，声音和自主反应（心率，血压，呼吸频率）。 但是，人的脸最具表现力。 </p><br><p> 每个人都以几种不同的方式表达情感。 美国著名心理学家<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">保罗·埃克曼</a> （ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Paul Ekman</a> ）研究了上个世纪70年代在巴布亚新几内亚孤立的部落的非语言行为，发现许多情绪是普遍的，可以是愤怒，恐惧，悲伤，厌恶，蔑视，惊奇和喜悦。被人所理解，无论其文化如何。 </p><br><p> 人们能够表达广泛的情感。 人们认为它们可以描述为基本情绪的组合（例如，怀旧是介于悲伤和喜悦之间的某种东西）。 但是这种分类方法并不总是很方便，因为 不允许量化情感的力量。 因此，连同离散的情感模型一起，开发了许多连续的情感模型。 罗素（J. Russell）的模型具有二维基础，其中每种情感都以符号（化合价）和强度（刺激性）为特征。 由于其简单性，Russell模型最近在自动分类面部表情的任务中变得越来越流行。 </p><br><div style="text-align:center;"><img height="300" src="https://habrastorage.org/getpro/habr/post_images/f59/cd1/a24/f59cd1a24e77d64759641a076d86bef1.png" alt="图片"></div><br><p> 因此，我们发现，如果您不打算隐藏情绪唤醒，那么您的当前状态可以通过面部表情来估计。 此外，利用深度学习领域的现代成就，甚至有可能基于“对我说谎”（Lie to me）系列构建测谎器，该系列的科学基础由Paul Ekman直接提供。 但是，此任务远非简单。 正如神经科学家丽莎·费尔德曼·巴雷特（Lisa Feldman Barrett）的研究表明，在识别情绪时，一个人会积极地使用上下文信息：声音，动作，情况。 看看下面的照片，确实如此。 仅使用脸部区域，就不可能做出正确的预测。 在这方面，为了解决该问题，有必要使用附加的模态和关于信号随时间变化的信息。 </p><br><div style="text-align:center;"><img height="200" src="https://habrastorage.org/webt/el/a6/t7/ela6t7ig73rti-peenhb7_f0sgs.jpeg" alt="图片"></div><br><p> 在这里，我们将考虑仅分析两种模态的方法：音频和视频，因为这些信号可以非接触方式获得。 要完成该任务，您首先需要获取数据。 这是我所知道的最大的公开情感数据库列表。 这些数据库中的图像和视频已手动标记，其中一些使用Amazon Mechanical Turk。 </p><br><table><thead><tr><th> 职称 </th><th> 资料 </th><th> 标记 </th><th> 制造年份 </th></tr></thead><tbody><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">OMG情感挑战</a> </td><td> 音频/视频 </td><td> 价/唤醒7类 </td><td>  2018年 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Emotiw挑战</a> </td><td> 音频/视频 </td><td>  6类 </td><td>  2018年 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">影响网</a> </td><td> 图片 </td><td> 价/唤醒7类 </td><td>  2017年 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">AFEW-VA</a> </td><td> 影片 </td><td> 价/唤醒 </td><td>  2017年 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">EmotioNet挑战</a> </td><td> 图片 </td><td>  16类 </td><td>  2017年 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Emoreact</a> </td><td> 音频/视频 </td><td>  17类 </td><td>  2016年 </td></tr></tbody></table><br><h3 id="klassicheskiy-podhod-k-zadache-klassifikacii-emociy"> 情感分类的经典方法 </h3><br><p> 从面部图像确定情感的最简单方法是基于关键点（面部标志）的分类，可以使用各种算法<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">PDM</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">CML</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">AAM</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">DPM</a>或<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">CNN</a>获得其坐标。 通常将其标记为5到68点，将它们与眉毛，眼睛，嘴唇，鼻子，下巴的位置绑在一起，从而可以部分捕获面部表情。 点的标准化坐标可以直接提交给分类器（例如，SVM或随机森林），并获得基本的解决方案。 自然，人员位置应保持一致。 </p><br><div style="text-align:center;"><img height="300" src="https://habrastorage.org/getpro/habr/post_images/c60/24a/dbe/c6024adbeaecca98404dcaae3361785e.jpg" alt="图片"></div><br><p> 简单使用没有视觉分量的坐标会导致有用信息的大量丢失，因此，在这些点上计算了各种描述符以改善系统： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">LBP</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">HOG</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">SIFT</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">LATCH</a>等。将描述符连接起来并使用PCA缩小维数后，可以将所得的特征向量用于分类情绪。 </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/u7/lh/oa/u7lhoatsm4vbqzb_zlksw9ekygy.jpeg" alt="图片"></div><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">链接到文章</a> </p><br><p> 但是，这种方法已经被认为是过时的，因为众所周知，深度卷积网络是可视数据分析的最佳选择。 </p><br><h3 id="klassifikaciya-emociy-s-primeneniem-deep-learning"> 使用深度学习对情绪进行分类 </h3><br><p> 为了构建神经网络分类器，只需将一些具有基本架构的网络（先前在ImageNet上进行过训练）并重新训练最后几层就足够了。 因此，您可以获得用于分类各种数据的良好基本解决方案，但是考虑到任务的具体情况，用于大规模<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">人脸识别</a>任务的神经网络将更合适。 </p><br><p> 因此，为单个图像构建情感分类器非常简单，但是正如我们发现的那样，快照不能完全准确地反映人在特定情况下所经历的真实情感。 因此，为了提高系统的准确性，有必要分析帧的顺序。 有两种方法可以做到这一点。 第一种方法是将从CNN接收到的高级功能（将每个单独的帧分类到一个循环网络（例如LSTM）中）以捕获时间分量。 </p><br><div style="text-align:center;"><img height="300" src="https://habrastorage.org/webt/ik/wi/zh/ikwizhwy65xydfoyu15ql3szjbi.jpeg" alt="图片"></div><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">链接到文章</a> </p><br><p> 第二种方法是将在某些步骤中从视频中获取的一系列帧直接馈送到3D-CNN输入。 类似的CNN使用具有三个自由度的卷积将四维输入转换为三维特征图。 </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/iv/a2/kd/iva2kdloqzpghk8gfcymk6g5sc4.jpeg" alt="图片"></div><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">链接到文章</a> </p><br><p> 实际上，在一般情况下，可以通过构造这样的怪物来结合这两种方法。 </p><br><div style="text-align:center;"><img height="400" src="https://habrastorage.org/webt/oo/ir/yo/ooiryorm9sh8n0cht5oud1yqbd4.jpeg" alt="图片"></div><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">链接到文章</a> </p><br><h3 id="klassifikaciya-emociy-po-rechi"> 情感的语音分类 </h3><br><p> 基于视觉数据，可以高精度地预测情绪的迹象，但是优选在确定强度时使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">语音信号</a> 。 由于语音持续时间和说话者语音的高度可变性，因此分析音频要困难一些。 通常，它们不使用原始声波，而是使用各种<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">符号</a>集，例如：F0，MFCC，LPC，i-vector等<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">。OpenSMILE</a>开放库包含用于分析语音和音乐的丰富算法集，在识别语音情感方面非常有效。信号。 提取后，可以将属性提交给SVM或LSTM进行分类。 </p><br><p> 然而，最近，卷积神经网络也开始渗透到声音分析领域，取代了已建立的方法。 为了应用它们，声音以线性或梅尔尺度的频谱图的形式表示，然后，将它们与获得的频谱图一起使用，就像普通的二维图像一样。 在这种情况下，可以使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">统计池</a>或通过在体系结构中合并循环网络来优雅地解决沿时间轴的频谱图任意大小的问题。 </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/kq/4d/ts/kq4dtsbybmnn3nsq6cwq_wek19u.jpeg" alt="图片"></div><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">链接到文章</a> </p><br><h3 id="audiovizualnoe-raspoznavanie-emociy"> 视听情感识别 </h3><br><p> 因此，我们研究了许多分析音频和视频模态的方法，最后阶段仍然存在-分类器的组合以输出最终解决方案。 最简单的方法是直接合并其评分。 在这种情况下，取最大值或平均值就足够了。 一个更困难的选择是在每种模式的嵌入级别进行组合。  SVM通常用于此目的，但这并不总是正确的，因为嵌入的速率可能不同。 在这方面，开发了更高级的算法，例如： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">多核</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">学习</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ModDrop</a> 。 </p><br><p> 当然，值得一提的是一类所谓<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">的端到端</a>解决方案，可以直接对来自多个传感器的原始数据进行训练，而无需任何初步处理。 </p><br><p> 通常，自动识别情绪的任务还远远没有解决。 从去年“野外”竞赛中的“情感识别”结果来看， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">最佳解决方案的</a>准确率约为60％。 我希望本文中提供的信息足以尝试建立我们自己的识别情绪的系统。 </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN418151/">https://habr.com/ru/post/zh-CN418151/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN418139/index.html">微分方程组给出的物体数学模型的数值解</a></li>
<li><a href="../zh-CN418141/index.html">RE：Ghat / AFR初学者船长竞赛</a></li>
<li><a href="../zh-CN418143/index.html">PVS-Studio作为SAST解​​决方案</a></li>
<li><a href="../zh-CN418145/index.html">当Telegram被封锁时，公司遭受的第一起针对Roskomnadzor的诉讼</a></li>
<li><a href="../zh-CN418147/index.html">沉默的Ruby执行：事务性Rails / PostgreSQL惊悚片</a></li>
<li><a href="../zh-CN418153/index.html">Kolesa Android Meetup视频：关于MVVM，反模式和模块化开发</a></li>
<li><a href="../zh-CN418155/index.html">二极体 发光二极管 齐纳二极管</a></li>
<li><a href="../zh-CN418157/index.html">该书“优雅的对象。 Java版»</a></li>
<li><a href="../zh-CN418159/index.html">设计师去哪儿：俄罗斯，东欧和独联体国家的著名奖项</a></li>
<li><a href="../zh-CN418161/index.html">在斯坦福大学，开发了室温流电池</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
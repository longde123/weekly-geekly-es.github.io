<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßöüèø üë©üèæ‚Äçüíº üë®üèº‚Äç‚úàÔ∏è Procurando espa√ßo de estacionamento gratuito com o Python üàÅ üßëüèæ‚Äçü§ù‚Äçüßëüèª üå®Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eu moro em uma boa cidade. Mas, como em muitos outros, a busca por um estacionamento sempre se transforma em um teste. Os espa√ßos livres ocupam rapida...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Procurando espa√ßo de estacionamento gratuito com o Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451164/"><img src="https://habrastorage.org/webt/vz/x5/od/vzx5odyqel0ow-z2qolfdo1htd4.gif" alt="imagem"><br><br>  Eu moro em uma boa cidade.  Mas, como em muitos outros, a busca por um estacionamento sempre se transforma em um teste.  Os espa√ßos livres ocupam rapidamente e, mesmo se voc√™ tiver o seu, ser√° dif√≠cil para os amigos ligar para voc√™, porque eles n√£o ter√£o onde estacionar. <br><br>  Por isso, decidi apontar a c√¢mera para fora da janela e usar o aprendizado profundo para que meu computador me diga quando o espa√ßo est√° dispon√≠vel: <br><br><img src="https://habrastorage.org/webt/lx/md/gy/lxmdgyxkvnwtwc5nsqccy83mp34.gif" alt="imagem"><br><br>  Pode parecer complicado, mas escrever um prot√≥tipo funcional com aprendizado profundo √© r√°pido e f√°cil.  Todos os componentes necess√°rios j√° est√£o l√° - voc√™ s√≥ precisa saber onde encontr√°-los e como mont√°-los. <br><br>  Ent√£o, vamos nos divertir e escrever um sistema preciso de notifica√ß√£o de estacionamento gratuito usando Python e aprendizado profundo <a name="habracut"></a><br><br><h3>  Decompondo a tarefa </h3><br>  Quando temos uma tarefa dif√≠cil que queremos resolver usando o aprendizado de m√°quina, o primeiro passo √© dividi-la em uma sequ√™ncia de tarefas simples.  Ent√£o, podemos usar v√°rias ferramentas para resolver cada uma delas.  Ao combinar v√°rias solu√ß√µes simples, obtemos um sistema capaz de algo complexo. <br><br>  Aqui est√° como eu quebrei minha tarefa: <br><br><img src="https://habrastorage.org/webt/q7/gi/hi/q7gihifth7-k9mad7fhgbj4itcc.jpeg" alt="imagem"><br><br>  O fluxo de v√≠deo da webcam direcionado para a janela entra na entrada do transportador: <br><br><img src="https://habrastorage.org/webt/aa/wk/ig/aawkigsexhbk5s4slqmvksvofcm.gif" alt="imagem"><br><br>  Atrav√©s do pipeline, transmitiremos cada quadro do v√≠deo, um de cada vez. <br><br>  O primeiro passo √© reconhecer todos os lugares de estacionamento poss√≠veis no quadro.  Obviamente, antes que possamos procurar lugares desocupados, precisamos entender em quais partes da imagem h√° estacionamento. <br><br>  Em cada quadro, voc√™ precisa encontrar todos os carros.  Isso nos permitir√° rastrear o movimento de cada m√°quina de quadro a quadro. <br><br>  O terceiro passo √© determinar quais locais s√£o ocupados por m√°quinas e quais n√£o s√£o.  Para fazer isso, combine os resultados das duas primeiras etapas. <br><br>  Por fim, o programa deve enviar um alerta quando o estacionamento ficar livre.  Isso ser√° determinado pelas altera√ß√µes na localiza√ß√£o das m√°quinas entre os quadros do v√≠deo. <br><br>  Cada uma dessas etapas pode ser conclu√≠da de diferentes maneiras, usando diferentes tecnologias.  N√£o existe uma maneira certa ou errada de compor esse transportador; abordagens diferentes ter√£o suas vantagens e desvantagens.  Vamos lidar com cada etapa com mais detalhes. <br><br><h3>  Reconhecemos vagas de estacionamento </h3><br>  Aqui est√° o que nossa c√¢mera v√™: <br><br><img src="https://habrastorage.org/webt/2u/zl/xt/2uzlxtgxbn6jvfkhfy0e523ow88.png" alt="imagem"><br><br>  De alguma forma, precisamos digitalizar esta imagem e obter uma lista de lugares para estacionar: <br><br><img src="https://habrastorage.org/webt/m-/bq/xb/m-bqxb9ybcjc44blvsuzhnw6xyk.png" alt="imagem"><br><br>  A solu√ß√£o ‚Äúna testa‚Äù seria simplesmente codificar manualmente os locais de todos os lugares de estacionamento em vez de reconhec√™-los automaticamente.  Mas, neste caso, se movermos a c√¢mera ou quisermos procurar vagas em outra rua, teremos que executar todo o procedimento novamente.  Parece t√£o, ent√£o vamos procurar uma maneira autom√°tica de reconhecer vagas de estacionamento. <br><br>  Como alternativa, voc√™ pode procurar parqu√≠metros na imagem e supor que haja um espa√ßo de estacionamento pr√≥ximo a cada um deles: <br><br><img src="https://habrastorage.org/webt/qi/g8/cj/qig8cjwmp7dmduejcddjk6tnoiw.png" alt="imagem"><br><br>  No entanto, com essa abordagem, nem tudo √© t√£o tranquilo.  Em primeiro lugar, nem todos os lugares de estacionamento possuem um medidor de estacionamento e, de fato, estamos mais interessados ‚Äã‚Äãem encontrar vagas de estacionamento pelas quais voc√™ n√£o precisa pagar.  Em segundo lugar, a localiza√ß√£o do medidor de estacionamento n√£o nos diz nada sobre onde fica o espa√ßo de estacionamento, mas apenas nos permite fazer uma suposi√ß√£o. <br><br>  Outra id√©ia √© criar um modelo de reconhecimento de objeto que procure por marcas de vagas de estacionamento desenhadas na estrada: <br><br><img src="https://habrastorage.org/webt/bo/vv/nu/bovvnu6rsl-zimlr1gtpp1a_egm.png" alt="imagem"><br><br>  Mas essa abordagem √© mais ou menos.  Em primeiro lugar, na minha cidade todas essas marcas s√£o muito pequenas e dif√≠ceis de ver √† dist√¢ncia, por isso ser√° dif√≠cil detect√°-las usando um computador.  Em segundo lugar, a rua est√° cheia de todos os tipos de outras linhas e marcas.  Ser√° dif√≠cil separar as marcas de estacionamento dos divisores de faixa e travessias de pedestres. <br><br>  Quando voc√™ encontrar um problema que, √† primeira vista, parece dif√≠cil, dedique alguns minutos para encontrar outra abordagem para resolv√™-lo, o que ajudar√° a contornar alguns problemas t√©cnicos.  O que h√° um espa√ßo de estacionamento?  Este √© apenas um lugar onde um carro fica estacionado por um longo tempo.  Talvez n√£o precisemos reconhecer vagas de estacionamento.  Por que simplesmente n√£o reconhecemos os carros que ficam parados por um longo tempo e n√£o assumimos que eles est√£o no estacionamento? <br><br>  Em outras palavras, os espa√ßos de estacionamento est√£o localizados onde os carros ficam por muito tempo: <br><br><img src="https://habrastorage.org/webt/b8/tb/ua/b8tbuafyf4uci3jy61jnjlwanqa.png" alt="imagem"><br><br>  Assim, se pudermos reconhecer os carros e descobrir quais deles n√£o se movem entre os quadros, podemos adivinhar onde est√£o os lugares de estacionamento.  Simples assim - v√° para o reconhecimento da m√°quina! <br><br><h3>  Reconhecer carros </h3><br>  O reconhecimento de carros em um quadro de v√≠deo √© uma tarefa cl√°ssica de reconhecimento de objetos.  Existem muitas abordagens de aprendizado de m√°quina que poder√≠amos usar para reconhecimento.  Aqui est√£o alguns deles, desde a "velha escola" at√© a "nova escola": <br><br><ul><li>  Voc√™ pode treinar o detector com base no HOG (Histograma de gradientes orientados, histogramas de gradientes direcionais) e percorrer toda a imagem para encontrar todos os carros.  Essa abordagem antiga, que n√£o usa aprendizado profundo, funciona relativamente r√°pido, mas n√£o lida muito bem com m√°quinas localizadas de maneiras diferentes. </li><li>  Voc√™ pode treinar o detector baseado na CNN (Rede Neural Convolucional, uma rede neural convolucional) e percorrer toda a imagem at√© encontrar todos os carros.  Essa abordagem funciona exatamente, mas n√£o com tanta efici√™ncia, pois precisamos digitalizar a imagem v√°rias vezes usando a CNN para encontrar todas as m√°quinas.  E embora possamos encontrar m√°quinas localizadas de maneiras diferentes, precisamos de muito mais dados de treinamento do que para um detector HOG. </li><li>  Voc√™ pode usar uma nova abordagem com aprendizado profundo, como Mask R-CNN, Faster R-CNN ou YOLO, que combina a precis√£o da CNN e um conjunto de truques t√©cnicos que aumentam bastante a velocidade do reconhecimento.  Esses modelos funcionar√£o relativamente rapidamente (na GPU) se tivermos muitos dados para treinar o modelo. </li></ul><br>  No caso geral, precisamos da solu√ß√£o mais simples, que funcionar√° como deveria e exigir√° a menor quantidade de dados de treinamento.  N√£o √© necess√°rio que seja o algoritmo mais recente e mais r√°pido.  No entanto, especificamente no nosso caso, o Mask R-CNN √© uma escolha razo√°vel, apesar de ser bastante novo e r√°pido. <br><br>  A arquitetura Mask R-CNN foi projetada de forma a reconhecer objetos em toda a imagem, gastando efetivamente recursos e n√£o usar a abordagem de janela deslizante.  Em outras palavras, funciona muito r√°pido.  Com uma GPU moderna, poderemos reconhecer objetos em v√≠deo em alta resolu√ß√£o a uma velocidade de v√°rios quadros por segundo.  Para o nosso projeto, isso deve ser suficiente. <br><br>  Al√©m disso, o Mask R-CNN fornece muitas informa√ß√µes sobre cada objeto reconhecido.  A maioria dos algoritmos de reconhecimento retorna apenas uma caixa delimitadora para cada objeto.  No entanto, o Mask R-CNN n√£o apenas nos fornecer√° a localiza√ß√£o de cada objeto, mas tamb√©m seu contorno (m√°scara): <br><br><img src="https://habrastorage.org/webt/n2/b0/hp/n2b0hpwgwpkn6ahfhqetvbhq1rg.png" alt="imagem"><br><br>  Para treinar o Mask R-CNN, precisamos de muitas imagens de objetos que queremos reconhecer.  Poder√≠amos sair, tirar fotos de carros e marc√°-los em fotografias, o que exigiria v√°rios dias de trabalho.  Felizmente, os carros s√£o um daqueles objetos que as pessoas geralmente querem reconhecer, por isso j√° existem v√°rios conjuntos de dados p√∫blicos com imagens de carros. <br><br>  Um deles √© o popular <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">conjunto de dados</a> SOCO (abrevia√ß√£o de Common Objects In Context), que possui imagens anotadas com m√°scaras de objetos.  Este conjunto de dados cont√©m mais de 12.000 imagens com m√°quinas j√° rotuladas.  Aqui est√° um exemplo de imagem do conjunto de dados: <br><br><img src="https://habrastorage.org/webt/dv/lz/7l/dvlz7ltgwmudog9-b2f6i7tlmhe.jpeg" alt="imagem"><br><br>  Esses dados s√£o excelentes para o treinamento de um modelo baseado no Mask R-CNN. <br><br>  Mas segure os cavalos, h√° not√≠cias ainda melhores!  N√£o somos os primeiros a querer treinar seu modelo usando o conjunto de dados COCO - muitas pessoas j√° fizeram isso antes de n√≥s e compartilharam seus resultados.  Portanto, em vez de treinar nosso modelo, podemos usar um modelo pronto que j√° pode reconhecer carros.  Para o nosso projeto, usaremos o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">modelo de c√≥digo aberto da Matterport.</a> <br><br>  Se dermos uma imagem da c√¢mera para a entrada deste modelo, √© isso que j√° obtemos "fora da caixa": <br><br><img src="https://habrastorage.org/webt/vy/kq/50/vykq50pcxhyt_vkmfzmxk_fgl5g.png" alt="imagem"><br><br>  O modelo reconheceu n√£o apenas carros, mas tamb√©m objetos como sem√°foros e pessoas.  √â engra√ßado que ela reconheceu a √°rvore como planta de casa. <br><br>  Para cada objeto reconhecido, o modelo Mask R-CNN retorna 4 itens: <br><br><ul><li>  Tipo de objeto detectado (inteiro).  O modelo COCO pr√©-treinado pode reconhecer 80 objetos comuns diferentes, como carros e caminh√µes.  Uma lista completa deles pode ser encontrada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui.</a> </li><li>  O grau de confian√ßa nos resultados do reconhecimento.  Quanto maior o n√∫mero, mais forte o modelo confia no reconhecimento do objeto. </li><li>  Uma caixa delimitadora para um objeto na forma de coordenadas XY de pixels na imagem. </li><li>  Uma "m√°scara" que mostra quais pixels dentro da caixa delimitadora fazem parte do objeto.  Usando os dados da m√°scara, voc√™ pode encontrar o contorno do objeto. </li></ul><br>  Abaixo est√° o c√≥digo Python para detectar a caixa delimitadora de m√°quinas usando os modelos Mask R-CNN e OpenCV pr√©-treinados: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.config <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.utils <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> mrcnn.model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MaskRCNN <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pathlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Path <span class="hljs-comment"><span class="hljs-comment"># ,     Mask-RCNN. class MaskRCNNConfig(mrcnn.config.Config): NAME = "coco_pretrained_model_config" IMAGES_PER_GPU = 1 GPU_COUNT = 1 NUM_CLASSES = 1 + 80 #   COCO  80  + 1  . DETECTION_MIN_CONFIDENCE = 0.6 #    ,    . def get_car_boxes(boxes, class_ids): car_boxes = [] for i, box in enumerate(boxes): #     ,   . if class_ids[i] in [3, 8, 6]: car_boxes.append(box) return np.array(car_boxes) #   . ROOT_DIR = Path(".") #       . MODEL_DIR = ROOT_DIR / "logs" #       . COCO_MODEL_PATH = ROOT_DIR / "mask_rcnn_coco.h5" #   COCO  . if not COCO_MODEL_PATH.exists(): mrcnn.utils.download_trained_weights(COCO_MODEL_PATH) #     . IMAGE_DIR = ROOT_DIR / "images" #      ‚Äî   0,    ,   . VIDEO_SOURCE = "test_images/parking.mp4" #   Mask-RCNN   . model = MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=MaskRCNNConfig()) #   . model.load_weights(COCO_MODEL_PATH, by_name=True) #   . parked_car_boxes = None #  ,     . video_capture = cv2.VideoCapture(VIDEO_SOURCE) #      . while video_capture.isOpened(): success, frame = video_capture.read() if not success: break #      BGR ( OpenCV)  RGB. rgb_image = frame[:, :, ::-1] #    Mask R-CNN   . results = model.detect([rgb_image], verbose=0) # Mask R-CNN ,       . #     ,     . r = results[0] #  r    : # - r['rois'] ‚Äî      ; # - r['class_ids'] ‚Äî  () ; # - r['scores'] ‚Äî  ; # - r['masks'] ‚Äî   (    ). #      . car_boxes = get_car_boxes(r['rois'], r['class_ids']) print("Cars found in frame of video:") #     . for box in car_boxes: print("Car:", box) y1, x1, y2, x2 = box #  . cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1) #    . cv2.imshow('Video', frame) #  'q',  . if cv2.waitKey(1) &amp; 0xFF == ord('q'): break #    . video_capture.release() cv2.destroyAllWindows()</span></span></code> </pre> <br>  Depois de executar este script, uma imagem com um quadro ao redor de cada m√°quina detectada aparecer√° na tela: <br><br><img src="https://habrastorage.org/webt/_p/il/0r/_pil0reoz3gj7dtqboav_rgerl8.jpeg" alt="imagem"><br><br>  Al√©m disso, as coordenadas de cada m√°quina ser√£o exibidas no console: <br><br><pre> <code class="python hljs">Cars found <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> frame of video: Car: [<span class="hljs-number"><span class="hljs-number">492</span></span> <span class="hljs-number"><span class="hljs-number">871</span></span> <span class="hljs-number"><span class="hljs-number">551</span></span> <span class="hljs-number"><span class="hljs-number">961</span></span>] Car: [<span class="hljs-number"><span class="hljs-number">450</span></span> <span class="hljs-number"><span class="hljs-number">819</span></span> <span class="hljs-number"><span class="hljs-number">509</span></span> <span class="hljs-number"><span class="hljs-number">913</span></span>] Car: [<span class="hljs-number"><span class="hljs-number">411</span></span> <span class="hljs-number"><span class="hljs-number">774</span></span> <span class="hljs-number"><span class="hljs-number">470</span></span> <span class="hljs-number"><span class="hljs-number">856</span></span>]</code> </pre><br>  Ent√£o aprendemos a reconhecer carros na imagem. <br><br><h3>  Reconhecemos vagas vazias </h3><br>  Conhecemos as coordenadas de pixel de cada m√°quina.  Observando v√°rios quadros consecutivos, podemos determinar facilmente qual dos carros n√£o se moveu e assumir que h√° vagas de estacionamento.  Mas como entender que o carro saiu do estacionamento? <br><br>  O problema √© que os quadros das m√°quinas se sobrep√µem parcialmente: <br><br><img src="https://habrastorage.org/webt/7t/vi/4q/7tvi4q1rgvkfkaljrsp8sjathr0.jpeg" alt="imagem"><br><br>  Portanto, se voc√™ imaginar que cada quadro representa um espa√ßo de estacionamento, pode ser que ele esteja parcialmente ocupado pela m√°quina, quando na verdade est√° vazio.  Precisamos encontrar uma maneira de medir o grau de interse√ß√£o de dois objetos para procurar apenas os quadros "mais vazios". <br><br>  Usaremos uma medida chamada Intersec√ß√£o sobre uni√£o (propor√ß√£o da √°rea de interse√ß√£o com a √°rea total) ou IoU.  A IoU pode ser encontrada calculando o n√∫mero de pixels em que dois objetos se cruzam e divida pelo n√∫mero de pixels ocupados por esses objetos: <br><br><img src="https://habrastorage.org/webt/zs/c0/sz/zsc0szsct8xjwkx5eo-6ieynfuc.png" alt="imagem"><br><br>  Assim, podemos entender como a estrutura delimitadora do carro se cruza com a estrutura do estacionamento.  Isso facilitar√° determinar se o estacionamento √© gratuito.  Se o valor de IoU for baixo, como 0,15, o carro ocupar√° uma pequena parte do espa√ßo de estacionamento.  E se for alto, como 0,6, isso significa que o carro ocupa a maior parte do espa√ßo e voc√™ n√£o pode estacionar l√°. <br><br>  Como a IoU √© usada com bastante frequ√™ncia na vis√£o computacional, √© muito prov√°vel que as bibliotecas correspondentes implementem essa medida.  Na nossa biblioteca Mask R-CNN, √© implementada como uma fun√ß√£o mrcnn.utils.compute_overlaps (). <br><br>  Se tivermos uma lista de caixas delimitadoras para vagas de estacionamento, voc√™ poder√° adicionar uma verifica√ß√£o da presen√ßa de carros nessa estrutura adicionando uma linha inteira ou duas de c√≥digo: <br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#      . car_boxes = get_car_boxes(r['rois'], r['class_ids']) # ,        . overlaps = mrcnn.utils.compute_overlaps(car_boxes, parking_areas) print(overlaps)</span></span></code> </pre><br>  O resultado deve ser algo como isto: <br><br><pre> <code class="python hljs">[ [<span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-number"><span class="hljs-number">0.07040032</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span>] [<span class="hljs-number"><span class="hljs-number">0.07040032</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-number"><span class="hljs-number">0.07673165</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span>] [<span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-number"><span class="hljs-number">0.02332112</span></span> <span class="hljs-number"><span class="hljs-number">0.</span></span>] ]</code> </pre><br>  Nesta matriz bidimensional, cada linha reflete um quadro do espa√ßo de estacionamento.  E cada coluna indica com que intensidade cada um dos lugares se cruza com uma das m√°quinas detectadas.  Um resultado de 1.0 significa que todo o local est√° completamente ocupado pelo carro, e um valor baixo como 0,02 indica que o carro subiu um pouco no lugar, mas voc√™ ainda pode estacionar nele. <br><br>  Para encontrar lugares desocupados, basta verificar cada linha dessa matriz.  Se todos os n√∫meros estiverem pr√≥ximos de zero, provavelmente o local √© gratuito! <br><br>  No entanto, lembre-se de que o reconhecimento de objetos nem sempre funciona perfeitamente com v√≠deos em tempo real.  Embora o modelo baseado no Mask R-CNN seja bastante preciso, de tempos em tempos ele pode perder um carro ou dois em um quadro do v√≠deo.  Portanto, antes de afirmar que o local √© gratuito, √© necess√°rio garantir que ele permane√ßa assim pelos pr√≥ximos 5 a 10 pr√≥ximos quadros do v√≠deo.  Dessa forma, podemos evitar situa√ß√µes em que o sistema marca erroneamente um local vazio devido a uma falha em um quadro do v√≠deo.  Assim que garantirmos que o local permane√ßa livre por v√°rios quadros, voc√™ poder√° enviar uma mensagem! <br><br><h3>  Enviar SMS </h3><br>  A √∫ltima parte do nosso transportador est√° enviando notifica√ß√µes por SMS quando aparece um espa√ßo de estacionamento gratuito. <br><br>  Enviar uma mensagem do Python √© muito f√°cil se voc√™ usar o Twilio.  O Twilio √© uma API popular que permite enviar SMS de quase qualquer linguagem de programa√ß√£o com apenas algumas linhas de c√≥digo.  Obviamente, se voc√™ preferir um servi√ßo diferente, poder√° us√°-lo.  N√£o tenho nada a ver com o Twilio, √© apenas a primeira coisa que vem √† mente. <br><br>  Para usar o Twilio, inscreva-se em uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">conta de avalia√ß√£o</a> , crie um n√∫mero de telefone Twilio e obtenha as informa√ß√µes de autentica√ß√£o da sua conta.  Em seguida, instale a biblioteca do cliente: <br><br><pre> <code class="python hljs">$ pip3 install twilio</code> </pre><br>  Depois disso, use o seguinte c√≥digo para enviar a mensagem: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> twilio.rest <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Client <span class="hljs-comment"><span class="hljs-comment">#   Twilio. twilio_account_sid = ' Twilio SID' twilio_auth_token = '   Twilio' twilio_source_phone_number = '   Twilio' #    Twilio. client = Client(twilio_account_sid, twilio_auth_token) #  SMS. message = client.messages.create( body=" ", from_=twilio_source_phone_number, to=" ,   " )</span></span></code> </pre><br>  Para adicionar a capacidade de enviar mensagens para o nosso script, basta copiar esse c√≥digo l√°.  No entanto, voc√™ precisa garantir que a mensagem n√£o seja enviada em todos os quadros, onde poder√° ver o espa√ßo livre.  Portanto, teremos um sinalizador que no estado instalado n√£o permitir√° o envio de mensagens por algum tempo ou at√© que outro local seja desocupado. <br><br><h3>  Juntando tudo </h3><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.config <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.utils <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> mrcnn.model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MaskRCNN <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pathlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Path <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> twilio.rest <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Client <span class="hljs-comment"><span class="hljs-comment"># ,     Mask-RCNN. class MaskRCNNConfig(mrcnn.config.Config): NAME = "coco_pretrained_model_config" IMAGES_PER_GPU = 1 GPU_COUNT = 1 NUM_CLASSES = 1 + 80 #   COCO  80  + 1  . DETECTION_MIN_CONFIDENCE = 0.6 #    ,    . def get_car_boxes(boxes, class_ids): car_boxes = [] for i, box in enumerate(boxes): #     ,   . if class_ids[i] in [3, 8, 6]: car_boxes.append(box) return np.array(car_boxes) #  Twilio. twilio_account_sid = ' Twilio SID' twilio_auth_token = '   Twilio' twilio_phone_number = '   Twilio' destination_phone_number = ',   ' client = Client(twilio_account_sid, twilio_auth_token) #   . ROOT_DIR = Path(".") #       . MODEL_DIR = ROOT_DIR / "logs" #       . COCO_MODEL_PATH = ROOT_DIR / "mask_rcnn_coco.h5" #   COCO  . if not COCO_MODEL_PATH.exists(): mrcnn.utils.download_trained_weights(COCO_MODEL_PATH) #     . IMAGE_DIR = ROOT_DIR / "images" #      ‚Äî   0,   ,   . VIDEO_SOURCE = "test_images/parking.mp4" #   Mask-RCNN   . model = MaskRCNN(mode="inference", model_dir=MODEL_DIR, config=MaskRCNNConfig()) #   . model.load_weights(COCO_MODEL_PATH, by_name=True) #   . parked_car_boxes = None #  ,     . video_capture = cv2.VideoCapture(VIDEO_SOURCE) #         . free_space_frames = 0 #    SMS? sms_sent = False #      . while video_capture.isOpened(): success, frame = video_capture.read() if not success: break #      BGR  RGB. rgb_image = frame[:, :, ::-1] #    Mask R-CNN   . results = model.detect([rgb_image], verbose=0) # Mask R-CNN ,       . #     ,     . r = results[0] #  r    : # - r['rois'] ‚Äî      ; # - r['class_ids'] ‚Äî  () ; # - r['scores'] ‚Äî  ; # - r['masks'] ‚Äî   (    ). if parked_car_boxes is None: #     ‚Äî ,       . #            . parked_car_boxes = get_car_boxes(r['rois'], r['class_ids']) else: #   ,  . ,   . #     . car_boxes = get_car_boxes(r['rois'], r['class_ids']) # ,         . overlaps = mrcnn.utils.compute_overlaps(parked_car_boxes, car_boxes) # ,    ,      . free_space = False #        . for parking_area, overlap_areas in zip(parked_car_boxes, overlaps): #        #    (, ). max_IoU_overlap = np.max(overlap_areas) #         . y1, x1, y2, x2 = parking_area # ,   ,   IoU. if max_IoU_overlap &lt; 0.15: #  !     . cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3) # ,        . free_space = True else: #     ‚Äî   . cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 1) #   IoU  . font = cv2.FONT_HERSHEY_DUPLEX cv2.putText(frame, f"{max_IoU_overlap:0.2}", (x1 + 6, y2 - 6), font, 0.3, (255, 255, 255)) #       ,   . #   ,  ,     #      . if free_space: free_space_frames += 1 else: #   ,  . free_space_frames = 0 #       ,  ,   . if free_space_frames &gt; 10: #   SPACE AVAILABLE!!  . font = cv2.FONT_HERSHEY_DUPLEX cv2.putText(frame, f"SPACE AVAILABLE!", (10, 150), font, 3.0, (0, 255, 0), 2, cv2.FILLED) #  ,     . if not sms_sent: print("SENDING SMS!!!") message = client.messages.create( body="Parking space open - go go go!", from_=twilio_phone_number, to=destination_phone_number ) sms_sent = True #    . cv2.imshow('Video', frame) #  'q',  . if cv2.waitKey(1) &amp; 0xFF == ord('q'): break #  'q',  . video_capture.release() cv2.destroyAllWindows()</span></span></code> </pre><br>  Para executar esse c√≥digo, primeiro voc√™ precisa instalar o Python 3.6+, o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Matterport Mask R-CNN</a> e o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenCV</a> . <br><br>  Escrevi especificamente o c√≥digo o mais simples poss√≠vel.  Por exemplo, se ele v√™ um carro no primeiro quadro, ele conclui que todos eles est√£o estacionados.  Tente experiment√°-lo e veja se voc√™ pode melhorar sua confiabilidade. <br><br>  Apenas alterando os identificadores dos objetos que o modelo est√° procurando, voc√™ pode transformar o c√≥digo em algo completamente diferente.  Por exemplo, imagine que voc√™ est√° trabalhando em uma esta√ß√£o de esqui.  Depois de fazer algumas altera√ß√µes, voc√™ pode transformar esse script em um sistema que reconhe√ßa automaticamente os praticantes de snowboard pulando da rampa e grave v√≠deos com saltos frios.  Ou, se voc√™ trabalha em uma reserva natural, pode criar um sistema que conta zebras.  Voc√™ √© limitado apenas pela sua imagina√ß√£o. <br><br>  Mais artigos desse tipo podem ser lidos no canal de telegrama <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Neuron</a> (@neurondata) <br><br>  Link de tradu√ß√£o alternativo: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tproger.ru/translations/parking-searching/</a> <br><br>  Todo conhecimento.  Experimente! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt451164/">https://habr.com/ru/post/pt451164/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt451152/index.html">O resistor no circuito do port√£o ou como faz√™-lo corretamente</a></li>
<li><a href="../pt451154/index.html">Sistema local de aquisi√ß√£o de dados aut√¥nomos (continua√ß√£o)</a></li>
<li><a href="../pt451158/index.html">Circuitos el√©tricos. Tipos de circuitos</a></li>
<li><a href="../pt451160/index.html">Apache Kafka e Streaming com Spark Streaming</a></li>
<li><a href="../pt451162/index.html">Corre√ß√£o de Erros - Constantes F√≠sicas no Presente e Novas Vers√µes do Sistema Internacional de Unidades (SI)</a></li>
<li><a href="../pt451166/index.html">O que os novos reposit√≥rios para sistemas AI e MO oferecem?</a></li>
<li><a href="../pt451170/index.html">Jeff Bezos anunciou planos para conquistar a lua</a></li>
<li><a href="../pt451172/index.html">Julia: fun√ß√µes e estruturas-como-fun√ß√µes</a></li>
<li><a href="../pt451174/index.html">Adapta√ß√£o de programas do ZX Spectrum ao TR-DOS por meios modernos. Parte 1</a></li>
<li><a href="../pt451176/index.html">Not√≠cias do mundo do OpenStreetMap n¬∫ 458 (23/04/2019 - 09/04/2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
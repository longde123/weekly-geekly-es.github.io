<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëáüèΩ üë®üèø‚Äçüîß üò∑ BigData hecho en casa. Parte 1. Pr√°ctica de Spark Streaming en un cl√∫ster de AWS üë®üèæ‚Äçüöí üïµüèø üöµüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola 

 Hay muchos servicios en Internet que brindan servicios en la nube. Con su ayuda, puede aprender la tecnolog√≠a de BigData. 

 En este art√≠culo,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>BigData hecho en casa. Parte 1. Pr√°ctica de Spark Streaming en un cl√∫ster de AWS</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/homecredit/blog/452752/">  Hola <br><br>  Hay muchos servicios en Internet que brindan servicios en la nube.  Con su ayuda, puede aprender la tecnolog√≠a de BigData. <br><br>  En este art√≠culo, instalaremos Apache Kafka, Apache Spark, Zookeeper, Spark-shell en la plataforma EC2 AWS (Amazon Web Services) en casa y aprenderemos c√≥mo usarlo todo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/51c/95c/810/51c95c8104a988a0288067e9eaaf700f.jpg" alt="imagen"></div><br><a name="habracut"></a><br><h3>  Presentaci√≥n de los servicios web de Amazon </h3><br>  Deber√° registrarse en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aws.amazon.com/console</a> .  Ingrese un nombre y recuerde la contrase√±a. <br><br>  Configure instancias de nodo para los servicios de Zookeeper y Kafka. <br><br><ul><li>  Seleccione "Servicios-&gt; EC2" en el men√∫.  A continuaci√≥n, seleccione la versi√≥n del sistema operativo de la imagen de la m√°quina virtual, seleccione Ubuntu Server 16.04 LTS (HVM), tipo de volumen SSD, haga clic en "Seleccionar". Procedemos a configurar la instancia del servidor: escriba "t3.medium" con los par√°metros 2vCPU, 4 GB de memoria, uso general Haga clic en "Siguiente: Configurar detalles de la instancia". </li><li>  Agregue el n√∫mero de instancias 1, haga clic en "Siguiente: Agregar almacenamiento" </li><li>  Aceptamos el valor predeterminado para el tama√±o de disco de 8 GB y cambiamos el tipo a Magn√©tico (en la configuraci√≥n de Producci√≥n en funci√≥n del volumen de datos y SSD de alto rendimiento) </li><li>  En la secci√≥n "Instancias de etiqueta" para "Nombre", ingrese el nombre de la instancia del nodo "Inicio1" (donde 1 es solo un n√∫mero de serie) y haga clic en "Siguiente: ..." </li><li>  En la secci√≥n "Configurar grupos de seguridad", seleccione la opci√≥n "Usar grupo de seguridad existente" seleccionando el nombre del grupo de seguridad ("Spark_Kafka_Zoo_Project") y establezca las reglas para el tr√°fico entrante.  Haga clic en "Siguiente: ..." </li><li>  Despl√°cese por la pantalla Revisar para verificar sus entradas e inicie Iniciar. </li><li>  Para conectarse a los nodos del cl√∫ster, debe crear (en nuestro caso, usar el existente) un par de claves p√∫blicas para identificaci√≥n y autorizaci√≥n.  Para hacer esto, seleccione el tipo de operaci√≥n "Usar par existente" en la lista. </li></ul><br><h3>  Creaci√≥n de clave </h3><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Descargue Putty</a> (https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html) para el cliente o utilice la conexi√≥n SSH desde el terminal. </li><li>  El archivo de clave .pem usa el formato antiguo por conveniencia, lo convertimos al formato ppk utilizado por Putty.  Para hacer esto, ejecute la utilidad PuTTYgen, cargue la clave en el antiguo formato .pem en la utilidad.  Convertimos la clave y la guardamos (Guardar clave privada) para su uso posterior en la carpeta de inicio con la extensi√≥n .ppk. </li></ul><br><h3>  Lanzamiento de cl√∫ster </h3><br>  Para mayor comodidad, cambie el nombre de los nodos del cl√∫ster en la notaci√≥n Nodo01-04.  Para conectarse a los nodos del cl√∫ster desde la computadora local a trav√©s de SSH, debe determinar la direcci√≥n IP del nodo y su nombre DNS p√∫blico / privado, seleccionar cada uno de los nodos del cl√∫ster uno por uno y para la instancia seleccionada, anote su nombre DNS p√∫blico / privado para conectarse a trav√©s de SSH y para la instalaci√≥n Software para el archivo de texto HadoopAdm01.txt. <br><br>  Ejemplo: ec2-35-162-169-76.us-west-2.compute.amazonaws.com <br><br><h3>  Instale Apache Kafka en modo SingleNode en un nodo de cl√∫ster de AWS </h3><br>  Para instalar el software, seleccione nuestro nodo (copie su DNS p√∫blico) para conectarse a trav√©s de SSH.  Configuramos la conexi√≥n a trav√©s de SSH.  Usamos el nombre guardado del primer nodo para configurar la conexi√≥n a trav√©s de SSH usando el par de claves Privado / P√∫blico "HadoopUser01.ppk" creado en la cl√°usula 1.3.  Vamos a la secci√≥n Conexi√≥n / Autenticaci√≥n a trav√©s del bot√≥n Examinar y buscamos la carpeta donde guardamos previamente el archivo "HadoopUserXX.ppk". <br><br>  Guardamos la configuraci√≥n de conexi√≥n en la configuraci√≥n. <br><br>  Estamos conectados al nodo y usamos login: ubuntu. <br><br><ul><li>  Utilizando los privilegios de root, actualizamos los paquetes e instalamos paquetes adicionales necesarios para una mayor instalaci√≥n y configuraci√≥n del cl√∫ster. <br><br><pre><code class="plaintext hljs">sudo apt-get update sudo apt-get -y install wget net-tools netcat tar</code> </pre> </li><li>  Instale Java 8 jdk y verifique la versi√≥n de Java. <br><br><pre> <code class="plaintext hljs">sudo apt-get -y install openjdk-8-jdk</code> </pre> </li><li>  Para el rendimiento normal del nodo del cl√∫ster, debe ajustar la configuraci√≥n de intercambio de memoria.  VM swappines est√° configurado en 60% de forma predeterminada, lo que significa que cuando se utiliza la memoria en 60%, el sistema intercambiar√° activamente datos de RAM a disco.  Dependiendo de la versi√≥n de Linux, el par√°metro VM swappines se puede establecer en 0 o 1: <br><br><pre> <code class="plaintext hljs">sudo sysctl vm.swappiness=1</code> </pre> <br></li><li>  Para guardar la configuraci√≥n durante el reinicio, agregue una l√≠nea al archivo de configuraci√≥n. <br><br><pre> <code class="plaintext hljs">echo 'vm.swappiness=1' | sudo tee --append /etc/sysctl.conf</code> </pre> <br></li><li>  Edici√≥n de entradas en el archivo / etc / hosts para la resoluci√≥n conveniente de los nombres de nodo del cl√∫ster kafka y <br>  Zookeeper en direcciones IP privadas a los nodos de cl√∫ster asignados. <br><br><pre> <code class="plaintext hljs">echo "172.31.26.162 host01" | sudo tee --append /etc/hosts</code> </pre> <br>  Verificamos el reconocimiento correcto de los nombres usando ping en cualquiera de las entradas. <br><br></li><li>  Descargue las √∫ltimas versiones actuales (http://kafka.apache.org/downloads) de las distribuciones kafka y scala y prepare el directorio con los archivos de instalaci√≥n. <br><br><pre> <code class="plaintext hljs">wget http://mirror.linux-ia64.org/apache/kafka/2.1.0/kafka_2.12-2.1.0.tgz tar -xvzf kafka_2.12-2.1.0.tgz ln -s kafka_2.12-2.1.0 kafka</code> </pre> <br></li><li>  Elimine el archivo tgz, ya no lo necesitaremos <br><br></li><li>  Intentemos iniciar el servicio Zookeeper, para esto: <br><br><pre> <code class="plaintext hljs">~/kafka/bin/zookeeper-server-start.sh -daemon ~/kafka/config/zookeeper.properties</code> </pre> <br>  Zookeeper comienza con las opciones de inicio predeterminadas.  Puedes consultar el registro: <br><br><pre> <code class="plaintext hljs">tail -n 5 ~/kafka/logs/zookeeper.out</code> </pre> <br>  Para garantizar que se inicia el demonio Zookeeper, despu√©s de reiniciar, necesitamos iniciar Zookeper como un servicio en segundo plano: <br><br><pre> <code class="plaintext hljs">bin/zookeeper-server-start.sh -daemon config/zookeeper.properties</code> </pre> <br>  Para verificar el lanzamiento de Zookepper, verifique <br><br><pre> <code class="plaintext hljs">netcat -vz localhost 2181</code> </pre> <br>  Configuramos el servicio Zookeeper y Kafka para el trabajo.  Inicialmente, edite / cree el archivo /etc/systemd/system/zookeeper.service (contenido del archivo a continuaci√≥n). <br><br><pre> <code class="plaintext hljs">[Unit] Description=Apache Zookeeper server Documentation=http://zookeeper.apache.org Requires=network.target remote-fs.target After=network.target remote-fs.target [Service] Type=simple ExecStart=/home/ubuntu/kafka/bin/zookeeper-server-start.sh /home/ubuntu/kafka/config/zookeeper.properties ExecStop=/home/ubuntu/kafka/bin/zookeeper-server-stop.sh [Install] WantedBy=multi-user.target</code> </pre> <br>  A continuaci√≥n, para Kafka, edite / cree el archivo /etc/systemd/system/kafka.service (contenido del archivo a continuaci√≥n). <br><br><pre> <code class="plaintext hljs">[Unit] Description=Apache Kafka server (broker) Documentation=http://kafka.apache.org/documentation.html Requires=zookeeper.service [Service] Type=simple ExecStart=/home/ubuntu/kafka/bin/kafka-server-start.sh /home/ubuntu/kafka/config/server.properties ExecStop=/home/ubuntu/kafka/bin/kafka-server-stop.sh [Install] WantedBy=multi-user.target</code> </pre> <br></li><li>  Activamos scripts systemd para los servicios de Kafka y Zookeeper. <br><br><pre> <code class="plaintext hljs">sudo systemctl enable zookeeper sudo systemctl enable kafka</code> </pre> <br></li><li>  Verifique el funcionamiento de los scripts systemd. <br><br><pre> <code class="plaintext hljs">sudo systemctl start zookeeper sudo systemctl start kafka sudo systemctl status zookeeper sudo systemctl status kafka sudo systemctl stop zookeeper sudo systemctl stop kafka</code> </pre> <br></li><li>  Verificaremos la funcionalidad de los servicios de Kafka y Zookeeper. <br><br><pre> <code class="plaintext hljs">netcat -vz localhost 2181 netcat -vz localhost 9092</code> </pre> <br></li><li>  Verifique el archivo de registro del cuidador del zool√≥gico. <br><br><pre> <code class="plaintext hljs">cat logs/zookeeper.out</code> </pre> </li></ul><br><h3>  Primera alegr√≠a </h3><br>  Creamos nuestro primer tema en el servidor kafka ensamblado. <br><br><ul><li>  Es importante utilizar la conexi√≥n a "host01: 2181" como indic√≥ en el archivo de configuraci√≥n server.properties. <br></li><li>  Escribimos algunos datos en el tema. <br><br><pre> <code class="plaintext hljs">kafka-console-producer.sh --broker-list host01:9092 --topic first_topic    </code> </pre> <br>  Ctrl-C: sale de la consola de temas. <br><br></li><li>  Ahora intente leer los datos del tema. <br><br><pre> <code class="plaintext hljs">kafka-console-consumer.sh --bootstrap-server host01:9092 --topic last_topic --from-beginning</code> </pre> <br></li><li>  Veamos la lista de temas de kafka. <br><br><pre> <code class="plaintext hljs">bin/kafka-topics.sh --zookeeper spark01:2181 --list</code> </pre> <br></li><li>  Edici√≥n de la configuraci√≥n del servidor kafka para ajustar la configuraci√≥n de un solo cl√∫ster <br>  # necesita cambiar el par√°metro ISR a 1. <br><br><pre> <code class="plaintext hljs">bin/kafka-topics.sh --zookeeper spark01:2181 --config min.insync.replicas=1 --topic __consumer_offsets --alter</code> </pre> <br></li><li>  Reiniciamos el servidor Kafka e intentamos conectar el consumidor ohm nuevamente <br><br></li><li>  Veamos la lista de temas. <br><br><pre> <code class="plaintext hljs">bin/kafka-topics.sh --zookeeper host01:2181 --list</code> </pre> </li></ul><br><h3>  Configure Apache Spark en un cl√∫ster de nodo √∫nico </h3><br>  Preparamos una instancia del nodo con los servicios Zookeeper y Kafka instalados en AWS, ahora necesita instalar Apache Spark, para esto: <br><br>  Descargue la √∫ltima distribuci√≥n de Apache Spark. <br><br><pre> <code class="plaintext hljs">wget https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.6.tgz</code> </pre> <br><br><ul><li>  Descomprima la distribuci√≥n y cree un enlace simb√≥lico para provocar y elimine los archivos innecesarios. <br><br><pre> <code class="plaintext hljs">tar -xvf spark-2.4.0-bin-hadoop2.6.tgz ln -s spark-2.4.0-bin-hadoop2.6 spark rm spark*.tgz</code> </pre> <br></li><li>  Vaya al directorio sbin y ejecute el asistente de chispa. <br><br><pre> <code class="plaintext hljs">./start-master.sh</code> </pre> <br></li><li>  Nos conectamos mediante un navegador web al servidor Spark en el puerto 8080. <br><br></li><li>  Ejecute esclavos de chispa en el mismo nodo <br><br><pre> <code class="plaintext hljs">./start-slave.sh spark://host01:7077</code> </pre> <br></li><li>  Ejecute el shell de chispa con el maestro en host01. <br><br><pre> <code class="plaintext hljs">./spark-shell --master spark://host01:7077</code> </pre> <br></li><li>  Si el inicio no funciona, agregue la ruta a Spark en bash. <br><br><pre> <code class="plaintext hljs">vi ~/.bashrc #      SPARK_HOME=/home/ubuntu/spark export PATH=$SPARK_HOME/bin:$PATH</code> </pre> <br><pre> <code class="plaintext hljs">source ~/.bashrc</code> </pre> <br></li><li>  Ejecute el shell de chispa nuevamente con el maestro en host01. <br><br><pre> <code class="plaintext hljs">./spark-shell --master spark://host01:7077</code> </pre> <br>  Un cl√∫ster de nodo √∫nico con Kafka, Zookeeper y Spark funciona.  ¬°Hurra! </li></ul><br><h3>  Un poco de creatividad </h3><br>  Descargue el editor Scala-IDE (en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">scala-ide.org</a> ).  Comenzamos y comenzamos a escribir c√≥digo.  Aqu√≠ ya no me repetir√© m√°s, ya que hay un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">buen art√≠culo sobre Habr√©</a> . <br><br>  Literatura √∫til y cursos para ayudar: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cursos.hadoopinrealworld.com/courses/enrolled/319237</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">data-flair.training/blogs/kafka-consumer</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">www.udemy.com/apache-spark-with-scala-hands-on-with-big-data</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/452752/">https://habr.com/ru/post/452752/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../452742/index.html">Configurar pruebas autom√°ticas de una aplicaci√≥n h√≠brida</a></li>
<li><a href="../452744/index.html">¬øExiste una vida completa de un control remoto sin intercambios independientes?</a></li>
<li><a href="../452746/index.html">El libro "El arte de la programaci√≥n en R. Inmersi√≥n en Big Data"</a></li>
<li><a href="../452748/index.html">Principios para desarrollar aplicaciones modernas de NGINX. Parte 1</a></li>
<li><a href="../452750/index.html">Nextcloud dentro y fuera de OpenLiteSpeed: configurar proxy inverso</a></li>
<li><a href="../452754/index.html">El 19% de las im√°genes Docker m√°s populares no tienen una contrase√±a de root</a></li>
<li><a href="../452756/index.html">Creando Tower Defense en Unity: Enemies</a></li>
<li><a href="../452760/index.html">Vitamina D. Beber o no beber, esa es la cuesti√≥n. (O una historia sobre c√≥mo pas√© un an√°lisis que no me recetaron)</a></li>
<li><a href="../452762/index.html">MVCC-7. Limpieza autom√°tica</a></li>
<li><a href="../452764/index.html">[Peter] Reuni√≥n JUG.ru con Sergei Melnikov - Perfilando con velocidad superluminal: teor√≠a y pr√°ctica</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
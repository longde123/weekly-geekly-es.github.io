<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üò≥ üîâ üßê ¬øCu√°nto son los datos para el entrenamiento modelo (no) similar a una muestra de prueba? üéôÔ∏è üïî üëäüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Considere un escenario en el que su modelo de aprendizaje autom√°tico podr√≠a no tener valor. 

 Hay un dicho: "No compares manzanas con naranjas" . Per...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>¬øCu√°nto son los datos para el entrenamiento modelo (no) similar a una muestra de prueba?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/422185/">  Considere un escenario en el que su modelo de aprendizaje autom√°tico podr√≠a no tener valor. <br><br>  Hay un dicho: <i>"No compares manzanas con naranjas"</i> .  Pero, ¬øqu√© sucede si necesita comparar un conjunto de manzanas con naranjas con otro, pero la distribuci√≥n de frutas en los dos conjuntos es diferente?  ¬øSe puede trabajar con datos?  ¬øY c√≥mo lo har√°s? <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lt/0y/oi/lt0yoiaq5fua0l1gfpguoigfxfa.png"></div><a name="habracut"></a><br>  En casos reales, esta situaci√≥n es com√∫n.  Al desarrollar modelos de aprendizaje autom√°tico, nos enfrentamos a una situaci√≥n en la que nuestro modelo funciona bien con un conjunto de entrenamiento, pero la calidad del modelo cae bruscamente en los datos de prueba. <br><br>  Y esto no se trata de reentrenamiento.  Digamos que hemos construido un modelo que da un resultado excelente en la validaci√≥n cruzada, pero muestra un resultado pobre en la prueba.  Entonces, en la muestra de prueba hay informaci√≥n que no tenemos en cuenta. <br><br>  Imagine una situaci√≥n en la que predecimos el comportamiento del cliente en una tienda.  Si las muestras de entrenamiento y prueba se parecen a la imagen a continuaci√≥n, este es un problema claro: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vk/ki/j2/vkkij2n5rlshttroh8mqfse-zf4.png"></div><br>  <i>En este ejemplo, el modelo est√° entrenado en datos con un valor promedio del atributo "edad del cliente" menor que el valor promedio de un atributo similar en la prueba.</i>  <i>En el proceso de aprendizaje, el modelo nunca ha "visto" los valores m√°s grandes del atributo "edad".</i>  <i>Si la edad es una caracter√≠stica importante para el modelo, entonces uno no deber√≠a esperar buenos resultados en la muestra de prueba.</i> <br><br>  En este texto, hablaremos sobre enfoques "ingenuos" que nos permiten identificar tales fen√≥menos y tratar de eliminarlos. <br><br><h3>  Cambio covariante </h3><br>  Demos una definici√≥n m√°s precisa de este concepto.  <b>La covarianza se</b> refiere a los valores de las caracter√≠sticas, y el <b>cambio covariante se</b> refiere a una situaci√≥n en la que la distribuci√≥n de los valores de las caracter√≠sticas en las muestras de entrenamiento y prueba tienen diferentes caracter√≠sticas (par√°metros). <br><br>  En problemas del mundo real con una gran cantidad de variables, el cambio covariante es dif√≠cil de detectar.  El art√≠culo discute el m√©todo para identificar, as√≠ como explicar el cambio covariante en los datos. <br><br><img src="https://habrastorage.org/webt/no/ta/lj/notaljh1r3c8nimkt45_lp3yyco.png"><br><br><h3>  Idea principal </h3><br>  <i>Si hay un cambio en los datos, al mezclar las dos muestras, podemos construir un clasificador que pueda determinar si el objeto pertenece a una muestra de entrenamiento o prueba.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pw/v-/42/pwv-42li1_tl9jqyghnph6czcsg.png"></div><br>  Vamos a entender por qu√© esto es as√≠.  Volvamos al ejemplo con los clientes, donde la edad era un signo "desplazado" de las muestras de entrenamiento y prueba.  Si tomamos un clasificador (por ejemplo, basado en un bosque aleatorio) y tratamos de dividir la muestra mixta en entrenamiento y prueba, entonces la edad ser√° un signo muy importante para dicha clasificaci√≥n. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/j1/29/wf/j129wfqmbguam_2axs1h6liyt4e.png"></div><br><h3>  Implementaci√≥n </h3><br>  Intentemos aplicar la idea descrita a un conjunto de datos real.  Use el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">conjunto</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">datos</a> de la competencia de Kaggle. <br><br><h4>  Paso 1: preparaci√≥n de datos </h4><br>  Primero, seguiremos una serie de pasos est√°ndar: limpiar, completar los espacios en blanco, realizar la codificaci√≥n de etiquetas para signos categ√≥ricos.  No se requiri√≥ ning√∫n paso para el conjunto de datos en cuesti√≥n, por lo tanto, omita su descripci√≥n. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-comment"><span class="hljs-comment">#  train  test train = pd.read_csv('train.csv',low_memory=True) test = pd.read_csv('test.csv',low_memory=True)</span></span></code> </pre> <br><h4>  Paso 2: agregar un indicador de fuente de datos </h4><br>  Es necesario agregar un nuevo indicador indicador a ambas partes del conjunto de datos: capacitaci√≥n y prueba.  Para la muestra de entrenamiento con el valor "1", para la prueba, respectivamente, "0". <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    ,   test,   train test['is_train'] = 0 train['is_train'] = 1</span></span></code> </pre><br><h4>  Paso 3: combinaci√≥n de las muestras de aprendizaje y prueba </h4><br>  Ahora necesita combinar los dos conjuntos de datos.  Dado que el conjunto de datos de entrenamiento contiene una columna de valores objetivo 'objetivo', que no est√° en el conjunto de datos de prueba, esta columna debe eliminarse. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  train, test df_combine = pd.concat([train, test], axis=0, ignore_index=True) #  target df_combine = df_combine.drop('target', axis =1) y = df_combine['is_train'].values #  x = df_combine.drop('is_train', axis=1).values #  tst, trn = test.values, train.values</span></span></code> </pre><br><h4>  Paso 4: compilar y probar el clasificador </h4><br>  Para fines de clasificaci√≥n, utilizaremos el Clasificador de bosque aleatorio, que configuraremos para predecir las etiquetas de la fuente de datos en el conjunto de datos combinado.  Puedes usar cualquier otro clasificador. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np rfc = RandomForestClassifier(n_jobs=<span class="hljs-number"><span class="hljs-number">-1</span></span>, max_depth=<span class="hljs-number"><span class="hljs-number">5</span></span>, min_samples_leaf = <span class="hljs-number"><span class="hljs-number">5</span></span>) predictions = np.zeros(y.shape) <span class="hljs-comment"><span class="hljs-comment">#    </span></span></code> </pre><br>  Utilizamos una divisi√≥n aleatoria estratificada de 4 pliegues.  De esta manera, mantendremos la proporci√≥n de las etiquetas 'is_train' en cada pliegue como en la muestra combinada original.  Para cada partici√≥n, entrenamos al clasificador en la mayor√≠a de la partici√≥n y predecimos la etiqueta de clase para la parte diferida m√°s peque√±a. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StratifiedKFold, cross_val_score skf = StratifiedKFold(n_splits=<span class="hljs-number"><span class="hljs-number">4</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">100</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> fold, (train_idx, test_idx) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(skf.split(x, y)): X_train, X_test = x[train_idx], x[test_idx] y_train, y_test = y[train_idx], y[test_idx] rfc.fit(X_train, y_train) probs = rfc.predict_proba(X_test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-comment"><span class="hljs-comment">#   predictions[test_idx] = probs</span></span></code> </pre><br><h4>  Paso 5: interpreta los resultados </h4><br>  Calculamos el valor de la m√©trica ROC AUC para nuestro clasificador.  Con base en este valor, concluimos cu√°n bien nuestro clasificador revela un cambio covariante en los datos. <br><br>  <i>Si el clasificador c separa bien los objetos en los conjuntos de datos de entrenamiento y prueba, entonces el valor de la m√©trica ROC AUC deber√≠a ser significativamente mayor que 0.5, idealmente cercano a 1. Esta imagen indica un fuerte cambio covariante en los datos.</i> <br><br>  Encuentre el valor de ROC AUC: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> roc_auc_score print(<span class="hljs-string"><span class="hljs-string">'ROC-AUC:'</span></span>, roc_auc_score(y_true=y, y_score=predictions)) <span class="hljs-comment"><span class="hljs-comment"># ROC-AUC: 0.49974692698385287</span></span></code> </pre><br>  El valor resultante es cercano a 0.5.  Y esto significa que nuestro clasificador de calidad es el mismo que un predictor de etiqueta aleatorio.  No hay evidencia de un cambio covariante en los datos. <br><br>  Dado que el conjunto de datos se toma de Kaggle, el resultado es bastante predecible.  Como en otras competencias de aprendizaje autom√°tico, los datos se verifican cuidadosamente para garantizar que no haya cambios. <br><br>  Pero este enfoque se puede aplicar en otros problemas de la ciencia de datos para verificar la presencia de un cambio covariante justo antes del inicio de la soluci√≥n. <br><br><h2>  Pasos adicionales </h2><br>  Entonces, o observamos un cambio covariante o no.  ¬øQu√© hacer para mejorar la calidad del modelo en la prueba? <br><br><ol><li>  Eliminar caracter√≠sticas sesgadas </li><li>  Usar pesos de importancia de objeto basados ‚Äã‚Äãen estimaciones de coeficientes de densidad </li></ol><br><h3>  Eliminar caracter√≠sticas sesgadas: </h3><br>  <i><b>Nota: el</b> m√©todo es aplicable si hay un cambio covariante en los datos.</i> <br><br><ul><li>  Extraiga la importancia de los atributos del Clasificador de bosque aleatorio, que creamos y capacitamos anteriormente. </li><li>  Los signos m√°s importantes son precisamente aquellos que est√°n sesgados y causan un cambio en los datos. </li><li>  Comenzando por lo m√°s importante, elimine sobre una base, cree el modelo de destino y observe su calidad.  Recoge todos los signos para los que la calidad del modelo no disminuye. </li><li>  Descarte las caracter√≠sticas recopiladas de los datos y cree el modelo final. </li></ul><br><img src="https://habrastorage.org/webt/oa/ga/08/oaga08t43dtyoazhcor8bk3mb8w.png"><br>  <i>Este algoritmo le permite eliminar signos de la canasta roja en el diagrama.</i> <br><br><h3>  Uso de pesos de importancia de objeto basados ‚Äã‚Äãen estimaciones de coeficientes de densidad </h3><br>  <i><b>Nota: el</b> m√©todo es aplicable independientemente de si hay un cambio covariante en los datos.</i> <br><br>  Veamos las predicciones que recibimos en la secci√≥n anterior.  Para cada objeto, la predicci√≥n contiene la probabilidad de que este objeto pertenezca al conjunto de entrenamiento para nuestro clasificador. <br><br><pre> <code class="python hljs">predictions[:<span class="hljs-number"><span class="hljs-number">10</span></span>] <span class="hljs-comment"><span class="hljs-comment">#array([0.39743827 ...</span></span></code> </pre><br>  Por ejemplo, para el primer objeto, nuestro Clasificador de bosque aleatorio cree que pertenece al conjunto de entrenamiento con una probabilidad de 0.397.  Llamar a este valor <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi><mo stretchy=&quot;false&quot;>(</mo><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.921ex" height="2.66ex" viewBox="0 -832 3410.5 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-50" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMAIN-28" x="751" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-74" x="1141" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-72" x="1502" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-65" x="1954" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-6E" x="2420" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMAIN-29" x="3021" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mo stretchy="false">(</mo><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> P (tren) </script>  .  O podemos decir que la probabilidad de pertenecer a los datos de prueba es 0.603.  Del mismo modo, llamamos probabilidad <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>P</mi><mo stretchy=&quot;false&quot;>(</mo><mi>p</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>b</mi><mi>a</mi><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.413ex" height="2.66ex" viewBox="0 -832 4483.5 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-50" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMAIN-28" x="751" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-70" x="1141" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-72" x="1644" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-75" x="2096" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-65" x="2668" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-62" x="3135" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-61" x="3564" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMAIN-29" x="4094" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mo stretchy="false">(</mo><mi>p</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>b</mi><mi>a</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-2"> P (prueba) </script>  . <br><br>  Ahora un peque√±o truco: para cada objeto del conjunto de datos de entrenamiento, calculamos el coeficiente <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>w</mi><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>P</mi><mo stretchy=&quot;false&quot;>(</mo><mi>p</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>b</mi><mi>a</mi><mo stretchy=&quot;false&quot;>)</mo></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>P</mi><mo stretchy=&quot;false&quot;>(</mo><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28.242ex" height="2.66ex" viewBox="0 -832 12159.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-77" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMAIN-3D" x="994" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-66" x="2300" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-72" x="2851" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-61" x="3302" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-63" x="3832" y="0"></use><g transform="translate(4265,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-50" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMAIN-28" x="751" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-70" x="1141" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-72" x="1644" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-75" x="2096" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-65" x="2668" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-62" x="3135" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-61" x="3564" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMAIN-29" x="4094" y="0"></use></g><g transform="translate(8749,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-50" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMAIN-28" x="751" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-74" x="1141" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-72" x="1502" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-65" x="1954" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-6E" x="2420" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMAIN-29" x="3021" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>w</mi><mo>=</mo><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mi>P</mi><mo stretchy="false">(</mo><mi>p</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>b</mi><mi>a</mi><mo stretchy="false">)</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mi>P</mi><mo stretchy="false">(</mo><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mo stretchy="false">)</mo></mrow></math></span></span><script type="math/tex" id="MathJax-Element-3"> w = \ frac {P (prueba)} {P (tren)} </script>  . <br><br>  Coeficiente <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>w</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.664ex" height="1.455ex" viewBox="0 -520.7 716.5 626.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-77" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>w</mi></math></span></span><script type="math/tex" id="MathJax-Element-4"> w </script>  nos dice qu√© tan cerca est√° un objeto del conjunto de entrenamiento para probar datos.  La idea principal: <br><br>  <i>Podemos usar</i> <math> </math><i><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>w</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.664ex" height="1.455ex" viewBox="0 -520.7 716.5 626.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/422185/&amp;usg=ALkJrhgemmGNOjK4XOYvr2yIUIrM56CdpA#MJMATHI-77" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>w</mi></math></span></span><script type="math/tex" id="MathJax-Element-5"> w </script></i>   <i>como pesos en cualquiera de los modelos para aumentar el peso de esas observaciones que se parecen a la muestra de prueba.</i>  <i>Intuitivamente, esto tiene sentido, ya que nuestro modelo estar√° m√°s orientado a los datos como en un conjunto de pruebas.</i> <br><br>  Estos pesos se pueden calcular usando el c√≥digo: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>)) predictions_train = predictions[:len(trn)] weights = (<span class="hljs-number"><span class="hljs-number">1.</span></span>/predictions_train) - <span class="hljs-number"><span class="hljs-number">1.</span></span> weights /= np.mean(weights) <span class="hljs-comment"><span class="hljs-comment">#  plt.xlabel('  w') plt.ylabel(' ') sns.distplot(weights, kde=False)</span></span></code> </pre><br>  Los coeficientes obtenidos se pueden transferir al modelo, por ejemplo, de la siguiente manera: <br><br><pre> <code class="python hljs">rfc = RandomForestClassifier(n_jobs=<span class="hljs-number"><span class="hljs-number">-1</span></span>,max_depth=<span class="hljs-number"><span class="hljs-number">5</span></span>) m.fit(X_train, y_train, sample_weight=weights)</code> </pre><br><br><img src="https://habrastorage.org/webt/_z/nw/rn/_znwrn70amqpw4xosahu1hgj6oa.png"><br><br>  Algunas palabras sobre el histograma resultante: <br><br><ul><li>  Los valores de peso mayores corresponden a observaciones m√°s similares a la muestra de prueba. </li><li>  Casi el 70% de los objetos del conjunto de entrenamiento tienen un peso cercano a 1 y, por lo tanto, se encuentran en un subespacio que es similar al conjunto de entrenamiento y al conjunto de prueba.  Esto corresponde al valor de AUC que calculamos anteriormente. </li></ul><br><h2>  Conclusi√≥n </h2><br>  Esperamos que esta publicaci√≥n lo ayude a identificar el "cambio covariante" en los datos y a combatirlo. <br><br><h2>  Referencias </h2><br>  [1] Shimodaira, H. (2000).  Mejora de la inferencia predictiva bajo desplazamiento covariable al ponderar la funci√≥n de log-verosimilitud.  Revista de planificaci√≥n estad√≠stica e inferencia, 90, 227-244. <br>  [2] Bickel, S. y col.  (2009)  Aprendizaje discriminativo bajo cambio covariable.  Journal of Machine Learning Research, 10, 2137‚Äì2155 <br>  [3] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github.com/erlendd/covariate-shift-adaption</a> <br>  [4] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace al conjunto de datos utilizado</a> <br><br>  PD: La computadora port√°til con el c√≥digo del art√≠culo se puede ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es422185/">https://habr.com/ru/post/es422185/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es422175/index.html">La contaminaci√≥n ambiental reduce las capacidades cognitivas humanas.</a></li>
<li><a href="../es422177/index.html">¬øPor qu√© Arduino es tan lento y qu√© se puede hacer al respecto?</a></li>
<li><a href="../es422179/index.html">De las nubes a la tierra: c√≥mo crear Kubernetes de grado de producci√≥n en cualquier entorno</a></li>
<li><a href="../es422181/index.html">C√≥mo recopilar servicios corporativos en una plataforma en l√≠nea: la historia de MegaFon.</a></li>
<li><a href="../es422183/index.html">¬øY qu√©, podr√≠a ser m√°s barato?</a></li>
<li><a href="../es422187/index.html">Sberseasons: como pas√© este verano</a></li>
<li><a href="../es422189/index.html">La verdad sobre la implementaci√≥n del portal de intranet</a></li>
<li><a href="../es422191/index.html">C√≥mo cre√© una aplicaci√≥n de reconocimiento de texto Android rentable</a></li>
<li><a href="../es422195/index.html">El uso de ACS en miner√≠a</a></li>
<li><a href="../es422197/index.html">Decimos una palabra sobre el relevo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üé¢ üôéüèæ üõÄüèø Die neun Elasticsearch-Rechen, auf die ich getreten bin üàØÔ∏è üéí ‚õìÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="‚ÄûEine ausgebildete Person tritt auch auf einen Rechen. 
 Aber auf der anderen Seite, wo der Stift ist. ‚Äú 

 Elasticsearch ist ein gro√üartiges Werkzeug...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Die neun Elasticsearch-Rechen, auf die ich getreten bin</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yamoney/blog/419041/"><img src="https://habrastorage.org/webt/ap/2k/jc/ap2kjcsehhaliahrmgg6a3r27xw.jpeg" alt="Illustration von Anton Gudim"><br><br><br>  <i>‚ÄûEine ausgebildete Person tritt auch auf einen Rechen.</i> <i><br></i>  <i>Aber auf der anderen Seite, wo der Stift ist. ‚Äú</i> <br><br>  Elasticsearch ist ein gro√üartiges Werkzeug, aber jedes Werkzeug erfordert nicht nur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Optimierung</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wartung</a> , sondern auch Liebe zum Detail.  Einige sind unbedeutend und liegen an der Oberfl√§che, w√§hrend andere so tief verborgen sind, dass die Suche mehr als einen Tag dauert, nicht ein Dutzend Tassen Kaffee und nicht einen Kilometer Nerven.  In diesem Artikel erz√§hle ich Ihnen von neun wunderbaren Rechen in den elastischen Einstellungen, auf die ich getreten bin. <br><a name="habracut"></a><br>  Ich werde den Rechen in absteigender Reihenfolge der Beweise anordnen.  Von denen, die beim Aufbau und Eintritt in einen Cluster im Produktionszustand vorausgesehen und umgangen werden k√∂nnen, bis zu sehr seltsamen, die die meiste Erfahrung bringen (und Sterne in den Augen). <br><br><h2>  Datenknoten m√ºssen gleich sein </h2><br>  "Der Cluster l√§uft mit der Geschwindigkeit des langsamsten Datenknotens" - ein qualvolles Axiom.  Es gibt jedoch noch einen weiteren offensichtlichen Punkt, der nicht mit der Leistung zusammenh√§ngt: Der Elastiker denkt nicht im Speicherplatz, sondern in Shards und versucht, sie gleichm√§√üig auf die Datenknoten zu verteilen.  Wenn einige der Datenknoten mehr Speicherplatz als andere haben, ist es sinnlos, unt√§tig zu bleiben. <br><br><h2>  Deprecation.log </h2><br>  Es kann vorkommen, dass jemand nicht die modernsten Mittel zum Senden von Daten an das Gummiband verwendet, wodurch der Inhaltstyp bei der Ausf√ºhrung von Abfragen nicht festgelegt werden kann.  In dieser Liste zum Beispiel heka oder wenn die Protokolle die Ger√§te mit ihren eingebauten Mitteln verlassen).  In diesem Fall Verfall.  Das Protokoll beginnt mit alarmierender Geschwindigkeit zu wachsen, und f√ºr jede Anforderung werden die folgenden Zeilen angezeigt: <br><br><pre><code class="hljs markdown">[<span class="hljs-string"><span class="hljs-string">2018-07-07T14:10:26,659</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">WARN </span></span>][<span class="hljs-string"><span class="hljs-string">oedrRestController</span></span>] Content type detection for rest requests is deprecated. Specify the content type using the [<span class="hljs-string"><span class="hljs-string">Content-Type</span></span>] header. [<span class="hljs-string"><span class="hljs-string">2018-07-07T14:10:26,670</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">WARN </span></span>][<span class="hljs-string"><span class="hljs-string">oedrRestController</span></span>] Content type detection for rest requests is deprecated. Specify the content type using the [<span class="hljs-string"><span class="hljs-string">Content-Type</span></span>] header. [<span class="hljs-string"><span class="hljs-string">2018-07-07T14:10:26,671</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">WARN </span></span>][<span class="hljs-string"><span class="hljs-string">oedrRestController</span></span>] Content type detection for rest requests is deprecated. Specify the content type using the [<span class="hljs-string"><span class="hljs-string">Content-Type</span></span>] header. [<span class="hljs-string"><span class="hljs-string">2018-07-07T14:10:26,673</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">WARN </span></span>][<span class="hljs-string"><span class="hljs-string">oedrRestController</span></span>] Content type detection for rest requests is deprecated. Specify the content type using the [<span class="hljs-string"><span class="hljs-string">Content-Type</span></span>] header. [<span class="hljs-string"><span class="hljs-string">2018-07-07T14:10:26,677</span></span>][<span class="hljs-symbol"><span class="hljs-symbol">WARN </span></span>][<span class="hljs-string"><span class="hljs-string">oedrRestController </span></span>] Content type detection for rest requests is deprecated. Specify the content type using the [Content-Type] header.</code> </pre> <br>  Anfragen kommen durchschnittlich alle 5-10 ms - und jedes Mal, wenn eine neue Zeile zum Protokoll hinzugef√ºgt wird.  Dies wirkt sich negativ auf die Leistung des Festplattensubsystems aus und erh√∂ht iowait.  Deprecation.log kann deaktiviert werden, ist aber nicht sinnvoll.  Um elastische Protokolle darin zu sammeln, aber nicht zu verschmutzen, deaktiviere ich nur Protokolle der Klasse oedrRestController. <br><br>  F√ºgen Sie dazu logs4j2.properties die folgende Konstruktion hinzu: <br><br><pre> <code class="hljs pgsql">logger.restcontroller.name = org.elasticsearch.deprecation.rest.RestController logger.restcontroller.<span class="hljs-keyword"><span class="hljs-keyword">level</span></span> = error</code> </pre><br>  Dadurch werden die Protokolle dieser Klasse auf die Fehlerstufe angehoben, und sie fallen nicht mehr in deprecation.log. <br><br><h2>  .kibana </h2><br>  Wie sieht ein typischer Cluster-Installationsprozess aus?  Wir setzen die Knoten, kombinieren sie zu einem Cluster, setzen das X-Pack (wer es braucht) und nat√ºrlich Kibana.  Wir starten, √ºberpr√ºfen, ob alles funktioniert und Kibana den Cluster sieht, und konfigurieren weiter.  Das Problem ist, dass in einem frisch installierten Cluster die Standardvorlage ungef√§hr so ‚Äã‚Äãaussieht: <br><br><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"default"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"order"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"template"</span></span>: <span class="hljs-string"><span class="hljs-string">"*"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"settings"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"number_of_shards"</span></span>: <span class="hljs-string"><span class="hljs-string">"1"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"number_of_replicas"</span></span>: <span class="hljs-string"><span class="hljs-string">"0"</span></span> } }, <span class="hljs-attr"><span class="hljs-attr">"mappings"</span></span>: {}, <span class="hljs-attr"><span class="hljs-attr">"aliases"</span></span>: {} }</code> </pre> <br>  Der .kibana-Index, in dem alle Einstellungen gespeichert sind, wird in einer einzigen Kopie erstellt. <br><br>  Es gab einmal einen Fall, in dem aufgrund eines Hardwarefehlers einer der Datenknoten im Cluster get√∂tet wurde.  Es kam schnell zu einem konsistenten Zustand und erzeugte Replikate von Shards von benachbarten Datenknoten, aber gl√ºcklicherweise befand sich auf diesem Datenknoten der einzige Shard mit dem .kibana-Index.  Die Situation ist eine Pattsituation - der Cluster ist in Betrieb, in einem funktionierenden Zustand, und Kibana befindet sich in einem roten Status, und mein Telefon ist von Anrufen von Mitarbeitern zerrissen, die ihre Protokolle dringend ben√∂tigen. <br><br>  All dies wird einfach gel√∂st.  Bisher ist nichts gefallen: <br><br><pre> <code class="hljs objectivec">XPUT .kibana/_settings { <span class="hljs-string"><span class="hljs-string">"index"</span></span>: { <span class="hljs-string"><span class="hljs-string">"number_of_replicas"</span></span>: <span class="hljs-string"><span class="hljs-string">"&lt;__&gt;"</span></span> } }</code> </pre> <br><h2>  XMX / XMS </h2><br>  In der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> steht zu Recht ‚ÄûNicht mehr als 32 GB‚Äú.  Es ist aber auch richtig, dass Sie nicht in den Diensteinstellungen installieren m√ºssen <br><pre> <code class="hljs powershell"><span class="hljs-literal"><span class="hljs-literal">-Xms32g</span></span> <span class="hljs-literal"><span class="hljs-literal">-Xmx32g</span></span></code> </pre> <br>  Weil es bereits mehr als 32 Gigabyte sind und wir hier auf eine interessante Nuance von Java sto√üen, das mit Speicher arbeitet.  Ab einem bestimmten Grenzwert verwendet Java keine komprimierten Zeiger mehr und verbraucht unangemessen viel Speicher.  Es ist sehr einfach zu √ºberpr√ºfen, ob komprimierte Zeiger einen Java-Computer verwenden, auf dem Elasticsearch ausgef√ºhrt wird.  Wir schauen im Serviceprotokoll nach: <br><br><pre> <code class="hljs powershell">[<span class="hljs-number"><span class="hljs-number">2018</span></span>-<span class="hljs-number"><span class="hljs-number">07</span></span>-<span class="hljs-number"><span class="hljs-number">29</span></span><span class="hljs-type"><span class="hljs-type">T15</span></span>:<span class="hljs-number"><span class="hljs-number">04</span></span>:<span class="hljs-number"><span class="hljs-number">22</span></span>,<span class="hljs-number"><span class="hljs-number">041</span></span>][<span class="hljs-type"><span class="hljs-type">INFO</span></span>][<span class="hljs-type"><span class="hljs-type">oeeNodeEnvironment</span></span>][<span class="hljs-type"><span class="hljs-type">log</span></span>-<span class="hljs-type"><span class="hljs-type">elastic</span></span>-<span class="hljs-type"><span class="hljs-type">hot3</span></span>] heap size [<span class="hljs-number"><span class="hljs-number">31.6</span></span><span class="hljs-type"><span class="hljs-type">gb</span></span>], compressed ordinary object pointers [<span class="hljs-type"><span class="hljs-type">true</span></span>]</code> </pre> <br>  Die Speichermenge, die nicht √ºberschritten werden darf, h√§ngt unter anderem von der verwendeten Java-Version ab.  Informationen zur Berechnung des genauen Volumens in Ihrem Fall finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> . <br><br>  Jetzt habe ich auf allen Datenknoten des Gummibandes installiert: <br><br><pre> <code class="hljs powershell"><span class="hljs-literal"><span class="hljs-literal">-Xms32766m</span></span> <span class="hljs-literal"><span class="hljs-literal">-Xmx32766m</span></span></code> </pre> <br>  Es scheint eine banale Tatsache zu sein, und die Dokumentation ist gut beschrieben, aber ich sto√üe regelm√§√üig auf Elasticsearch-Installationen, bei denen ich diesen Punkt verpasst habe, und Xms / Xmx sind auf 32 g eingestellt. <br><br><h2>  / var / lib / elasticsearch </h2><br>  Dies ist der Standardpfad zum Speichern von Daten in Elasticsearch.  yml: <br><br><pre> <code class="hljs kotlin">path.<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>: /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/elasticsearch</code> </pre> <br>  Dort mounte ich normalerweise ein gro√ües RAID-Array, und hier ist der Grund: Wir geben ES verschiedene M√∂glichkeiten zum Speichern von Daten an, zum Beispiel wie folgt: <br><br><pre> <code class="hljs kotlin">path.<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>: /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/elasticsearch/data1, /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/elasticsearch/data2</code> </pre> <br>  In data1 und data2 sind verschiedene Festplatten oder RAID-Arrays gemountet.  Das Gummiband gleicht sich jedoch nicht aus und verteilt die Last nicht auf diese Pfade.  Zuerst f√ºllt er einen Abschnitt aus und beginnt dann, in einen anderen zu schreiben, damit die Belastung des Speichers ungleichm√§√üig ist.  Da ich das wusste, traf ich eine eindeutige Entscheidung - ich kombinierte alle Festplatten in RAID0 / 1 und mounte sie in den in path.data angegebenen Pfad. <br><br><h2>  verf√ºgbare_Prozessoren </h2><br>  Und nein, ich meine jetzt nicht Prozessoren auf Aufnahmeknoten.  Wenn Sie sich die Eigenschaften eines laufenden Knotens (√ºber die _nodes-API) ansehen, sehen Sie Folgendes: <br><br><pre> <code class="hljs objectivec"><span class="hljs-string"><span class="hljs-string">"os"</span></span>. { <span class="hljs-string"><span class="hljs-string">"refresh_interval_in_millis"</span></span>: <span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-string"><span class="hljs-string">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"Linux"</span></span>, <span class="hljs-string"><span class="hljs-string">"arch"</span></span>: <span class="hljs-string"><span class="hljs-string">"amd64"</span></span>, <span class="hljs-string"><span class="hljs-string">"version"</span></span>: <span class="hljs-string"><span class="hljs-string">"4.4.0-87-generic"</span></span>, <span class="hljs-string"><span class="hljs-string">"available_processors"</span></span>: <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-string"><span class="hljs-string">"allocated_processors"</span></span>: <span class="hljs-number"><span class="hljs-number">28</span></span> }</code> </pre> <br>  Es ist ersichtlich, dass der Knoten auf einem Host mit 28 Kernen ausgef√ºhrt wird und das Gummiband seine Anzahl korrekt bestimmt und auf allen gestartet hat.  Aber wenn es mehr als 32 Kerne gibt, passiert es manchmal so: <br><br><pre> <code class="hljs objectivec"><span class="hljs-string"><span class="hljs-string">"os"</span></span>: { <span class="hljs-string"><span class="hljs-string">"refresh_interval_in_millis"</span></span>: <span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-string"><span class="hljs-string">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"Linux"</span></span>, <span class="hljs-string"><span class="hljs-string">"arch"</span></span>: <span class="hljs-string"><span class="hljs-string">"amd64"</span></span>, <span class="hljs-string"><span class="hljs-string">"version"</span></span>: <span class="hljs-string"><span class="hljs-string">"4.4.0-116-generic"</span></span>, <span class="hljs-string"><span class="hljs-string">"available_processors"</span></span>: <span class="hljs-number"><span class="hljs-number">72</span></span>, <span class="hljs-string"><span class="hljs-string">"allocated_processors"</span></span>: <span class="hljs-number"><span class="hljs-number">32</span></span> }</code> </pre> <br>  Sie m√ºssen die Anzahl der Prozessoren erzwingen, die dem Dienst zur Verf√ºgung stehen - dies wirkt sich positiv auf die Leistung des Knotens aus. <br><br><pre> <code class="hljs">processors: 72</code> </pre> <br><h2>  thread_pool.bulk.queue_size </h2><br>  Im Abschnitt thread_pool.bulk.rejected des letzten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikels gab es</a> eine solche Metrik - die Anzahl der Fehler bei Anforderungen zum Hinzuf√ºgen von Daten. <br><br>  Ich habe geschrieben, dass das Wachstum dieses Indikators ein sehr schlechtes Zeichen ist, und die Entwickler empfehlen, keine Thread-Pools einzurichten, sondern neue Knoten zum Cluster hinzuzuf√ºgen - angeblich l√∂st dies Leistungsprobleme.  Aber die Regeln werden ben√∂tigt, um sie manchmal zu brechen.  Und es ist nicht immer m√∂glich, "das Problem mit Eisen zu l√∂sen". Eine der Ma√ünahmen zur Bek√§mpfung von Fehlern bei Massenanfragen besteht darin, die Gr√∂√üe dieser Warteschlange zu erh√∂hen. <br><br>  Standardm√§√üig sehen die Warteschlangeneinstellungen folgenderma√üen aus: <br><br><pre> <code class="hljs objectivec"><span class="hljs-string"><span class="hljs-string">"thread_pool"</span></span>: { <span class="hljs-string"><span class="hljs-string">"bulk"</span></span>: { <span class="hljs-string"><span class="hljs-string">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"fixed"</span></span>, <span class="hljs-string"><span class="hljs-string">"min"</span></span>: <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-string"><span class="hljs-string">"max"</span></span>: <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-string"><span class="hljs-string">"queue_size"</span></span>: <span class="hljs-number"><span class="hljs-number">200</span></span> } }</code> </pre> <br>  Der Algorithmus ist wie folgt: <br><br><ol><li>  Wir sammeln Statistiken √ºber die durchschnittliche Warteschlangengr√∂√üe w√§hrend des Tages (der Sofortwert wird in thread_pool.bulk.queue gespeichert). </li><li>  Erh√∂hen Sie queue_size vorsichtig auf Gr√∂√üen, die geringf√ºgig gr√∂√üer als die durchschnittliche Gr√∂√üe der aktiven Warteschlange sind, da ein Fehler auftritt, wenn er √ºberschritten wird. </li><li>  Wir vergr√∂√üern den Pool - dies ist nicht notwendig, aber akzeptabel. </li></ol><br>  F√ºgen Sie dazu den Host-Einstellungen Folgendes hinzu (Sie haben nat√ºrlich Ihre eigenen Werte): <br><br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">thread_pool</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.bulk</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.size</span></span>: 32 <span class="hljs-selector-tag"><span class="hljs-selector-tag">thread_pool</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.bulk</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.queue_size</span></span>: 500</code> </pre> <br>  Und nach dem Neustart des Knotens werden wir definitiv die Last, die E / A und den Speicherverbrauch √ºberwachen.  und alles, was m√∂glich ist, um die Einstellungen bei Bedarf zur√ºckzusetzen. <br><br>  <i>Wichtig: Diese Einstellungen sind nur auf Knoten sinnvoll, die neue Daten empfangen.</i> <br><br><h2>  Vorl√§ufige Indexerstellung </h2><br>  Wie ich im ersten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel der</a> Serie sagte, verwenden wir Elasticsearch, um die Protokolle aller Microservices zu speichern.  Das Endergebnis ist einfach: Ein Index speichert die Protokolle einer Komponente an einem Tag. <br><br>  Daraus folgt, dass jeden Tag neue Indizes durch die Anzahl der Mikrodienste erstellt werden - daher fiel das Gummiband fr√ºher jede Nacht f√ºr etwa 8 Minuten in den Clinch, w√§hrend hundert neue Indizes erstellt wurden, mehrere hundert neue Shards, der Zeitplan f√ºr das Laden der Festplatte ‚Äûins Regal‚Äú ging und die Warteschlangen wuchsen Zabbix bl√ºhte mit Warnungen wie ein Weihnachtsbaum. <br><br>  Um dies zu vermeiden, war es normal, ein Python-Skript zu schreiben, um Indizes vorab zu erstellen.  Das Skript funktioniert folgenderma√üen: Es findet die Indizes f√ºr heute, extrahiert ihre Zuordnungen und erstellt neue Indizes mit denselben Zuordnungen, jedoch f√ºr den kommenden Tag.  Es l√§uft auf Cron, l√§uft in den Stunden, in denen der Elastic am wenigsten belastet ist.  Das Skript verwendet die Elasticsearch-Bibliothek und ist auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GitHub</a> verf√ºgbar. <br><br><h2>  Transparente √ºbergeordnete riesige Seiten </h2><br>  Als wir feststellten, dass die elastischen Knoten, die den Datenempfang bedienen, w√§hrend der Sto√üzeiten unter Last zu h√§ngen begannen.  Und mit sehr seltsamen Symptomen: Die Verwendung aller Prozessorkerne sinkt auf Null, aber der Dienst bleibt im Speicher h√§ngen, h√∂rt ordnungsgem√§√ü auf den Port, tut nichts, reagiert nicht auf Anforderungen und f√§llt nach einiger Zeit aus dem Cluster heraus.  Der Dienst reagiert nicht auf einen Neustart des Systems.  Nur der gute alte Kill ‚àí9 hilft. <br><br>  Dies wird von Standard√ºberwachungstools in den Diagrammen erst im Moment des Sturzes erfasst, in dem das regul√§re Bild in den Serviceprotokollen leer ist.  Der Speicherauszug der Java-Maschine war zu diesem Zeitpunkt ebenfalls nicht m√∂glich. <br><br>  Aber wie sie sagen: "Wir sind Profis, also haben wir nach einiger Zeit die L√∂sung gegoogelt."  Ein √§hnliches Problem wurde im Thread auf " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Diskussion.elastic.co" behandelt</a> und stellte sich als Kernel-Fehler heraus, der mit transparenten gro√üen Seiten zusammenh√§ngt.  Alles wurde gel√∂st, indem thp im Kernel mit dem sysfsutils-Paket deaktiviert wurde. <br><br>  Es ist einfach zu √ºberpr√ºfen, ob transparente gro√üe Seiten aktiviert sind: <br><br><pre> <code class="hljs powershell">cat /sys/kernel/mm/transparent_hugepage/enabled always madvise [<span class="hljs-type"><span class="hljs-type">never</span></span>]</code> </pre> <br>  Wenn [immer] da ist, sind Sie m√∂glicherweise gef√§hrdet. <br><br><h2>  Fazit </h2><br>  Dies ist der Hauptrechen (tats√§chlich gab es nat√ºrlich noch mehr), den ich als Administrator des Elasticsearch-Clusters anderthalb Jahre lang betreten habe.  Ich hoffe, diese Informationen sind n√ºtzlich auf dem schwierigen und mysteri√∂sen Weg zum idealen Elasticsearch-Cluster. <br><br>  Vielen Dank f√ºr die Illustration, Anton Gudim - in seinem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Instagram</a> steckt noch viel Gutes. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de419041/">https://habr.com/ru/post/de419041/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de419027/index.html">Informationssicherheit bei bargeldlosen Bankzahlungen. Teil 6 - Analyse der Bankenkriminalit√§t</a></li>
<li><a href="../de419029/index.html">Fortnite ist zu einem sozialen Ph√§nomen geworden. Eltern stellen zunehmend Trainer f√ºr ihre Kinder ein und spielen mit ihnen</a></li>
<li><a href="../de419033/index.html">Ein kleiner Hinweis zum Thema Ausf√ºhren von vue.js im kubernetes-Cluster</a></li>
<li><a href="../de419035/index.html">Buch ‚ÄûHead First Agile. Flexibles Projektmanagement ‚Äú</a></li>
<li><a href="../de419037/index.html">PPPOS-Implementierung bei stm32f4-Discovery</a></li>
<li><a href="../de419043/index.html">Das schwer fassbare Problem mit dem Frame-Timing</a></li>
<li><a href="../de419047/index.html">Reddit gehackte, durchgesickerte Datenbank mit Passw√∂rtern und E-Mail f√ºr 2005-2007</a></li>
<li><a href="../de419049/index.html">GeekBrains startet den kostenlosen Online-Bildungsmarathon ‚ÄûFind Yourself in Digital‚Äú</a></li>
<li><a href="../de419051/index.html">Wie Flant Anf√§ngern hilft</a></li>
<li><a href="../de419053/index.html">Testen der Adaptec RAID Cache-Technologie</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë∑üèº üéÖüèø üê° Como ensinar um telefone a ver a beleza üõê üë®üèΩ‚Äç‚öïÔ∏è üë®üèæ‚Äçüç≥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recentemente, li um livro sobre matem√°tica e a beleza das pessoas e pensei sobre o que h√° uma d√©cada atr√°s, a id√©ia de como entender o que a beleza hu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como ensinar um telefone a ver a beleza</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/485858/"><img src="https://habrastorage.org/webt/-f/0z/on/-f0zonxrb_qtnmaxp2bt34gu-d4.png" alt="imagem"><br><br>  Recentemente, li um livro sobre matem√°tica e a beleza das pessoas e pensei sobre o que h√° uma d√©cada atr√°s, a id√©ia de como entender o que a beleza humana era bastante primitiva.  O racioc√≠nio sobre qual rosto √© considerado bonito do ponto de vista da matem√°tica se resumiu ao fato de que deveria ser sim√©trico.  Al√©m disso, desde o Renascimento, houve tentativas de descrever rostos bonitos usando as rela√ß√µes entre dist√¢ncias em alguns pontos do rosto e mostrar, por exemplo, que rostos bonitos t√™m algum tipo de relacionamento pr√≥ximo √† propor√ß√£o √°urea.  Ideias semelhantes sobre a localiza√ß√£o dos pontos agora s√£o usadas como um dos m√©todos para identificar faces (pesquisa de pontos de refer√™ncia de face).  No entanto, como mostra a experi√™ncia, se voc√™ n√£o limitar o conjunto de sinais √† posi√ß√£o de pontos espec√≠ficos no rosto, poder√° obter melhores resultados em v√°rias tarefas, <a href="https://arxiv.org/abs/1603.01249" rel="nofollow">incluindo determinar idade, sexo</a> ou mesmo <a href="https://www.gsb.stanford.edu/sites/gsb/files/publication-pdf/wang_kosinski.pdf" rel="nofollow">orienta√ß√£o sexual</a> .  J√° √© evidente aqui que a quest√£o da √©tica de publicar os resultados de tais estudos pode ser aguda. <br><a name="habracut"></a><br>  O tema da beleza das pessoas e sua avalia√ß√£o tamb√©m pode ser eticamente controverso.  Ao desenvolver o aplicativo, muitos dos meus amigos se recusaram a usar suas fotos para testes ou simplesmente n√£o queriam saber o resultado (√© engra√ßado que a maioria das meninas se recusasse a saber os resultados).  Al√©m disso, o objetivo de automatizar a avalia√ß√£o da beleza pode levantar quest√µes filos√≥ficas interessantes.  At√© que ponto o conceito de beleza √© determinado pela cultura?  Qu√£o verdadeira √© a ‚Äúbeleza nos olhos de quem v√™‚Äù?  √â poss√≠vel destacar sinais objetivos de beleza? <br><br>  Para responder a essas perguntas, voc√™ precisa estudar as estat√≠sticas sobre as classifica√ß√µes de algumas pessoas por outras.  Tentei projetar e treinar um modelo de rede neural que avaliasse a beleza, al√©m de execut√°-lo em um telefone Android. <br><br><h2>  Parte 0. Pipeline </h2><br>  Para entender como as pr√≥ximas etapas est√£o relacionadas, desenhei um diagrama do projeto: <br><br><img src="https://habrastorage.org/webt/cy/jp/zh/cyjpzhhy_hiczxqefjp9qgaohf0.png" alt="imagem"><br><br>  Azul - bibliotecas importantes e dados externos.  Amarelo - controla no aplicativo. <br><br><h2>  Parte 1. Python </h2><br>  Como a avalia√ß√£o da beleza √© um t√≥pico bastante delicado, n√£o h√° muitos conjuntos de dados no dom√≠nio p√∫blico que contenham fotos com uma avalia√ß√£o (tenho certeza de que servi√ßos de namoro online como o tinder t√™m conjuntos de estat√≠sticas muito maiores).  Encontrei <a href="https://github.com/HCIILAB/SCUT-FBP5500-Database-Release" rel="nofollow">um banco de dados</a> compilado em uma das universidades da China, contendo 5500 fotografias, cada uma avaliada por 7 avaliadores dentre estudantes chineses.  Das 5.500 fotografias, 2.000 s√£o homens asi√°ticos (AM), 2000 s√£o mulheres asi√°ticas (AF) e 750 homens Europioid (CM) e mulheres (CF) cada. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fcf/1db/f9b/fcf1dbf9b67fee5543fdc9833d429676.jpg" alt="imagem"><br><br>  Vamos ler os dados usando o m√≥dulo pandas Python e dar uma olhada r√°pida nos dados.  Distribui√ß√£o estimada para diferentes g√™neros e ra√ßas: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt ratingDS=pd.read_excel(<span class="hljs-string"><span class="hljs-string">'../input/faces-scut/scut-fbp5500_v2/SCUT-FBP5500_v2/All_Ratings.xlsx'</span></span>) Answer=ratingDS.groupby(<span class="hljs-string"><span class="hljs-string">'Filename'</span></span>).mean()[<span class="hljs-string"><span class="hljs-string">'Rating'</span></span>] ratingDS[<span class="hljs-string"><span class="hljs-string">'race'</span></span>]=ratingDS[<span class="hljs-string"><span class="hljs-string">'Filename'</span></span>].apply(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x:x[:<span class="hljs-number"><span class="hljs-number">2</span></span>]) fig, ax = plt.subplots(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, sharex=<span class="hljs-string"><span class="hljs-string">'col'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, race <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate([<span class="hljs-string"><span class="hljs-string">'CF'</span></span>,<span class="hljs-string"><span class="hljs-string">'CM'</span></span>,<span class="hljs-string"><span class="hljs-string">'AF'</span></span>,<span class="hljs-string"><span class="hljs-string">'AM'</span></span>]): sbp=ax[i%<span class="hljs-number"><span class="hljs-number">2</span></span>,i//<span class="hljs-number"><span class="hljs-number">2</span></span>] ratingDS[ratingDS[<span class="hljs-string"><span class="hljs-string">'race'</span></span>]==race].groupby(<span class="hljs-string"><span class="hljs-string">'Filename'</span></span>)[<span class="hljs-string"><span class="hljs-string">'Rating'</span></span>].mean().hist(alpha=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, bins=<span class="hljs-number"><span class="hljs-number">20</span></span>,label=race,grid=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>,rwidth=<span class="hljs-number"><span class="hljs-number">0.9</span></span>,ax=sbp) sbp.set_title(race)</code> </pre> <br><img src="https://habrastorage.org/webt/fz/1q/fo/fz1qfoby_-ijefbbl4ifctz3llo.png" alt="imagem"><br><br>  Percebe-se que, em geral, os homens s√£o considerados menos bonitos que as mulheres, a distribui√ß√£o √© bimodal - existem.  que s√£o considerados bonitos e "m√©dios".  Quase n√£o existem classifica√ß√µes baixas, portanto os dados podem ser renormalizados.  Mas vamos deix√°-los por enquanto. <br><br>  Vejamos o desvio padr√£o nas estimativas: <br><br><pre> <code class="python hljs">ratingDS.groupby(<span class="hljs-string"><span class="hljs-string">'Filename'</span></span>)[<span class="hljs-string"><span class="hljs-string">'Rating'</span></span>].std().mean()</code> </pre><br>  √â 0,64, o que significa que a diferen√ßa nas avalia√ß√µes de diferentes avaliadores √© inferior a 1 ponto em 5, o que indica unanimidade nas avalia√ß√µes de beleza.  Pode-se dizer razoavelmente que "a beleza N√ÉO est√° nos olhos de quem v√™".  Ao calcular a m√©dia, voc√™ pode usar os dados de maneira confi√°vel para treinar o modelo e n√£o se preocupar com a impossibilidade fundamental da avalia√ß√£o program√°tica. <br><br>  No entanto, apesar do pequeno valor do desvio padr√£o da estimativa, a opini√£o de alguns avaliadores pode ser muito diferente da "comum".  Vamos construir a distribui√ß√£o da diferen√ßa entre a estimativa e a mediana: <br><br><pre> <code class="python hljs">R2=ratingDS.join(ratingDS.groupby(<span class="hljs-string"><span class="hljs-string">'Filename'</span></span>)[<span class="hljs-string"><span class="hljs-string">'Rating'</span></span>].median(), on=<span class="hljs-string"><span class="hljs-string">'Filename'</span></span>, how=<span class="hljs-string"><span class="hljs-string">'inner'</span></span>,rsuffix =<span class="hljs-string"><span class="hljs-string">' median'</span></span>) R2[<span class="hljs-string"><span class="hljs-string">'ratingdiff'</span></span>]=(R2[<span class="hljs-string"><span class="hljs-string">'Rating median'</span></span>]-R2[<span class="hljs-string"><span class="hljs-string">'Rating'</span></span>]).astype(int) print(set(R2[<span class="hljs-string"><span class="hljs-string">'ratingdiff'</span></span>])) R2[<span class="hljs-string"><span class="hljs-string">'ratingdiff'</span></span>].hist(label=<span class="hljs-string"><span class="hljs-string">'difference of raings'</span></span>,bins=[<span class="hljs-number"><span class="hljs-number">-3.5</span></span>,<span class="hljs-number"><span class="hljs-number">-2.5</span></span>,<span class="hljs-number"><span class="hljs-number">-1.5</span></span>,<span class="hljs-number"><span class="hljs-number">-0.5</span></span>,<span class="hljs-number"><span class="hljs-number">0.5</span></span>,<span class="hljs-number"><span class="hljs-number">1.5</span></span>,<span class="hljs-number"><span class="hljs-number">2.5</span></span>,<span class="hljs-number"><span class="hljs-number">3.5</span></span>,<span class="hljs-number"><span class="hljs-number">4.5</span></span>],grid=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>,rwidth=<span class="hljs-number"><span class="hljs-number">0.5</span></span>)</code> </pre><br><img src="https://habrastorage.org/webt/ww/qb/7w/wwqb7wdyk_neg_semros1qthb_g.png" alt="imagem"><br><br>  Um padr√£o interessante √© encontrado.  Pessoas cuja pontua√ß√£o difere da mediana em mais de 1 ponto <br><br><pre> <code class="python hljs">len(R2[R2[<span class="hljs-string"><span class="hljs-string">'ratingdiff'</span></span>].abs()&gt;<span class="hljs-number"><span class="hljs-number">1</span></span>])/len(R2)</code> </pre><br>  0.02943333333333333332 <br>  Menos de 3%.  Ou seja, a impressionante unanimidade √© novamente confirmada em quest√µes de avalia√ß√£o da beleza. <br>  Crie uma tabela com as classifica√ß√µes m√©dias necess√°rias <br><br><pre> <code class="python hljs">Answer=ratingDS.groupby(<span class="hljs-string"><span class="hljs-string">'Filename'</span></span>).mean()[<span class="hljs-string"><span class="hljs-string">'Rating'</span></span>]</code> </pre><br>  Nosso banco de dados √© pequeno;  Al√©m disso, todas as fotos cont√™m principalmente imagens de rosto inteiro e eu gostaria de obter um resultado confi√°vel para qualquer posi√ß√£o do rosto.  Para resolver problemas com uma pequena quantidade de dados, a t√©cnica de aprendizado de transfer√™ncia √© frequentemente usada - o uso de modelos pr√©-treinados para tarefas semelhantes e sua modifica√ß√£o.  Perto da minha tarefa est√° a tarefa de reconhecimento de rosto.  Geralmente √© resolvido de uma maneira de tr√™s est√°gios. <br><br>  1. H√° uma detec√ß√£o de rosto na imagem e em sua escala. <br><br>  2. Usando uma rede neural convolucional, a imagem da face √© convertida em um vetor de caracter√≠stica, e as propriedades de tal transforma√ß√£o s√£o tais que a transforma√ß√£o √© invari√°vel em rela√ß√£o √† rota√ß√£o da face e √† mudan√ßa no penteado.  manifesta√ß√µes de emo√ß√µes e quaisquer imagens tempor√°rias.  Aprender essa rede √© uma tarefa interessante por si s√≥, que pode ser escrita por um longo tempo.  Al√©m disso, novos desenvolvimentos est√£o constantemente aparecendo para melhorar essa convers√£o e melhorar os algoritmos de rastreamento e identifica√ß√£o em massa.  Eles otimizam a arquitetura de rede e o m√©todo de treinamento (por exemplo, perda tripla - perda de face-arcface). <br><br>  3. Compara√ß√£o do vetor de recurso com os armazenados no banco de dados. <br><br>  Para nossa tarefa, usei solu√ß√µes prontas de 1 a 2 pontos.  A tarefa de detectar rostos geralmente √© resolvida de v√°rias maneiras; al√©m disso, quase qualquer dispositivo m√≥vel possui detectores de rostos (no Android, eles fazem parte do pacote de servi√ßos padr√£o do GooglePlay), que s√£o usados ‚Äã‚Äãpara focar nos rostos ao fotografar.  Quanto √† tradu√ß√£o de pessoas em forma vetorial, h√° um ponto sutil n√£o √≥bvio.  O fato √© que os sinais.  extra√≠dos para resolver o problema de reconhecimento - s√£o caracter√≠sticos de uma pessoa, mas podem n√£o se correlacionar com a beleza.  al√©m disso.  devido √†s peculiaridades das redes neurais convolucionais, esses sinais s√£o principalmente locais e, em geral, isso pode causar muitos problemas (ataque de pixel √∫nico).  No entanto, descobri que os resultados s√£o altamente dependentes da dimens√£o do vetor e, se 128 sinais n√£o forem suficientes para determinar a beleza, 512 ser√£o suficientes.  Com <a href="https://github.com/shaoanlu/face_toolbox_keras" rel="nofollow">base nisso,</a> foi escolhida uma <a href="https://github.com/shaoanlu/face_toolbox_keras" rel="nofollow">rede insightFace pr√©-treinada e baseada em Reset</a> .  Tamb√©m usaremos keras como uma estrutura para aprendizado de m√°quina. <br>  Um c√≥digo detalhado para o download de modelos pr√©-treinados pode ser encontrado <a href="https://www.kaggle.com/alexanderkhar/face-beauty-ranking-ported-to-android" rel="nofollow">aqui.</a> <br><br><pre> <code class="python hljs">model=LResNet100E_IR()</code> </pre><br>  O detector de <a href="https://github.com/ipazc/mtcnn" rel="nofollow">rosto mtcnn</a> foi usado como um detector de rosto para pr√©-processamento <a href="https://github.com/ipazc/mtcnn" rel="nofollow">.</a> <br><br><pre> <code class="python hljs">detector = MtcnnDetector(model_folder=mtcnn_path, ctx=ctx, num_worker=<span class="hljs-number"><span class="hljs-number">1</span></span>, accurate_landmark = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, threshold=det_threshold)</code> </pre><br>  Alinhar, cortar e vetorizar imagens do conjunto de dados: <br><br><pre> <code class="python hljs">imgpath=<span class="hljs-string"><span class="hljs-string">'../input/faces-scut/scut-fbp5500_v2/SCUT-FBP5500_v2/Images/'</span></span> <span class="hljs-comment"><span class="hljs-comment">#    facevecs=[] for name in tqdm.tqdm(Answer.index): #   img1 = cv2.imread(imgpath+name) # ,     pre1 = np.moveaxis(get_input(detector,img1),0,-1) #  vec = model.predict(np.stack([pre1])) #   facevecs.append(vec)</span></span></code> </pre><br>  Prepararemos os dados dividindo-os em vetores de treinamento (90% deles, estudaremos sobre eles) e valida√ß√£o (verificaremos o trabalho do modelo neles).  Normalizamos os dados para um intervalo de 0-1. <br><br><pre> <code class="python hljs">X=np.stack(facevecs)[:,<span class="hljs-number"><span class="hljs-number">0</span></span>,:] Y=(Answer[:])/<span class="hljs-number"><span class="hljs-number">5</span></span> Indicies=np.arange(len(Answer)) X,Y,Indicies=sklearn.utils.shuffle(X,Y,Indicies) Xtrain=X[:int(len(facevecs)*<span class="hljs-number"><span class="hljs-number">0.9</span></span>)] Ytrain=Y[:int(len(facevecs)*<span class="hljs-number"><span class="hljs-number">0.9</span></span>)] Indtrain=Indicies[:int(len(facevecs)*<span class="hljs-number"><span class="hljs-number">0.9</span></span>)] Xval=X[int(len(facevecs)*<span class="hljs-number"><span class="hljs-number">0.9</span></span>):] Yval=Y[int(len(facevecs)*<span class="hljs-number"><span class="hljs-number">0.9</span></span>):] Indval=Indicies[int(len(facevecs)*<span class="hljs-number"><span class="hljs-number">0.9</span></span>):]</code> </pre><br>  Agora vamos para o modelo.  descrevendo a beleza. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Createheadmodel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> inp=keras.layers.Input((<span class="hljs-number"><span class="hljs-number">512</span></span>,)) x=keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">32</span></span>,activation=<span class="hljs-string"><span class="hljs-string">'elu'</span></span>)(inp) x=keras.layers.Dropout(<span class="hljs-number"><span class="hljs-number">0.1</span></span>)(x) out=keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>,activation=<span class="hljs-string"><span class="hljs-string">'hard_sigmoid'</span></span>,use_bias=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>,kernel_initializer=keras.initializers.Ones())(x) model=keras.models.Model(input=inp,output=out) model.layers[<span class="hljs-number"><span class="hljs-number">-1</span></span>].trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span> model.compile(optimizer=keras.optimizers.Adam(lr=<span class="hljs-number"><span class="hljs-number">0.0001</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'mse'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model modelhead=Createheadmodel()</code> </pre><br>  Este modelo √© uma rede neural totalmente conectada de camada √∫nica com 32 neur√¥nios e 512 n√≥s de entrada - uma das arquiteturas mais simples, que, no entanto, √© bem treinada: <br><br><pre> <code class="python hljs">hist=modelhead.fit(Xtrain,Ytrain, epochs=<span class="hljs-number"><span class="hljs-number">4000</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">5000</span></span>, validation_data=(Xval,Yval) )</code> </pre><br>  4950/4950 [===============================] - 0s 3us / passo - perda: 0.0069 - val_loss: 0.0071 <br>  Vamos construir curvas de aprendizado <br><br><pre> <code class="python hljs">plt.plot(hist.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>][<span class="hljs-number"><span class="hljs-number">100</span></span>:], label=<span class="hljs-string"><span class="hljs-string">'loss'</span></span>) plt.plot(hist.history[<span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>][<span class="hljs-number"><span class="hljs-number">100</span></span>:],label=<span class="hljs-string"><span class="hljs-string">'validation_loss'</span></span>) plt.legend(bbox_to_anchor=(<span class="hljs-number"><span class="hljs-number">0.95</span></span>, <span class="hljs-number"><span class="hljs-number">0.95</span></span>), loc=<span class="hljs-string"><span class="hljs-string">'upper right'</span></span>, borderaxespad=<span class="hljs-number"><span class="hljs-number">0.</span></span>)</code> </pre><br>  Vemos que a perda (desvio quadrado m√©dio) √© de 0,0071 nos dados de valida√ß√£o, portanto o desvio padr√£o = 0,084 ou 0,42 pontos em uma escala de cinco pontos, que √© menor que o spread nas estimativas dadas pelas pessoas (0,6 pontos).  Nosso modelo est√° funcionando. <br><br>  Para visualizar como o modelo funciona, voc√™ pode usar o diagrama de dispers√£o - para cada foto dos dados de valida√ß√£o, constru√≠mos um ponto em que uma das coordenadas corresponde √† classifica√ß√£o m√©dia da face e a segunda √† classifica√ß√£o m√©dia prevista: <br><br><pre> <code class="python hljs">Answer2=Answer.to_frame()[:<span class="hljs-number"><span class="hljs-number">5500</span></span>] Answer2[<span class="hljs-string"><span class="hljs-string">'ans'</span></span>]=<span class="hljs-number"><span class="hljs-number">0</span></span> Answer2[<span class="hljs-string"><span class="hljs-string">'race'</span></span>]=Answer2.index Answer2[<span class="hljs-string"><span class="hljs-string">'race'</span></span>]=Answer2[<span class="hljs-string"><span class="hljs-string">'race'</span></span>].apply(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:<span class="hljs-number"><span class="hljs-number">2</span></span>]) Answer2[<span class="hljs-string"><span class="hljs-string">'ans'</span></span>]=modelhead.predict(np.stack(facevecs)[:,<span class="hljs-number"><span class="hljs-number">0</span></span>,:])*<span class="hljs-number"><span class="hljs-number">5</span></span> xy=np.array(Answer2.iloc[Indval][[<span class="hljs-string"><span class="hljs-string">'ans'</span></span>,<span class="hljs-string"><span class="hljs-string">'Rating'</span></span>]]) plt.scatter(xy[:,<span class="hljs-number"><span class="hljs-number">1</span></span>],xy[:,<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br><img src="https://habrastorage.org/webt/w2/t9/dd/w2t9ddnfyzjpx-xp7q3_wmsubzk.png" alt="imagem"><br><br>  Eixo Y - valores previstos pelo modelo, eixo X - valores m√©dios das estimativas das pessoas.  Vemos uma alta correla√ß√£o (o diagrama √© alongado ao longo da diagonal).  Voc√™ tamb√©m pode verificar nossos resultados visualmente - veja as faces de cada uma das categorias com classifica√ß√µes previstas de 1 a 5 <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.image <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> mpimg f, axarr = plt.subplots(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>,figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, race <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate([<span class="hljs-string"><span class="hljs-string">'AF'</span></span>,<span class="hljs-string"><span class="hljs-string">'CF'</span></span>, <span class="hljs-string"><span class="hljs-string">"AM"</span></span>, <span class="hljs-string"><span class="hljs-string">'CM'</span></span>]): <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> rating <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>): <span class="hljs-comment"><span class="hljs-comment">#axarr[i,rating-1].axis('off') axarr[i,rating-1].tick_params(# changes apply to the x-axis which='both', # both major and minor ticks are affected bottom=False, # ticks along the bottom edge are off top=False, # ticks along the top edge are off right=False, left=False, labelbottom=False, labelleft=False ) picname=(Answer2[Answer2['race']==race]['ans']-rating).abs().argmin() axarr[i,rating-1].set_xlabel(Answer2.loc[picname]['ans']) axarr[i,rating-1].imshow(mpimg.imread(imgpath+picname))</span></span></code> </pre><br><img src="https://habrastorage.org/webt/i4/az/pe/i4azpe-biju4pozojrgpiyxkoag.png" alt="imagem"><br><br>  Vemos que o resultado da classifica√ß√£o por beleza parece razo√°vel. <br><br>  Agora, criaremos um modelo completo no qual enviaremos uma face para a entrada; na sa√≠da, obteremos uma classifica√ß√£o de 0 a 1 e a converteremos no formato tflite adequado para o telefone. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf finmodel=Model(input=model.input, output=modelhead(model.output)) finmodel.save(<span class="hljs-string"><span class="hljs-string">'finmodel.h5'</span></span>) converter = tf.lite.TFLiteConverter.from_keras_model_file(<span class="hljs-string"><span class="hljs-string">'finmodel.h5'</span></span>) converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE] tflite_quant_model = converter.convert() open (<span class="hljs-string"><span class="hljs-string">"modelquant.tflite"</span></span> , <span class="hljs-string"><span class="hljs-string">"wb"</span></span>).write(tflite_quant_model) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> IPython.display <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> FileLink FileLink(<span class="hljs-string"><span class="hljs-string">r'modelquant.tflite'</span></span>)</code> </pre><br>  Este modelo recebe uma imagem de um rosto com um tamanho de 112 * 112 * 3 na entrada e, na sa√≠da, fornece um n√∫mero √∫nico de 0 a 1, o que significa a beleza do rosto (embora tenhamos de lembrar que no conjunto de dados as classifica√ß√µes n√£o variaram de 0 a 5, mas de 1 a 5). <br><br><h2>  Parte 2. JAVA </h2><br>  Vamos tentar escrever um aplicativo simples para um telefone Android.  A linguagem Java √© nova para mim e nunca estive envolvido no desenvolvimento para o Android; portanto, o projeto n√£o utiliza otimiza√ß√£o do trabalho, n√£o usa controle de fluxo e outras coisas que exigem muito trabalho para iniciantes.  Como o c√≥digo java √© bastante complicado, aqui darei apenas as partes mais importantes para o programa funcionar.  O c√≥digo completo do aplicativo est√° dispon√≠vel <a href="https://github.com/Alexankharin/HowCuteAmI" rel="nofollow">aqui</a> .  O aplicativo abre uma foto, detecta e avalia um rosto usando uma rede salva anteriormente e exibe o resultado: <br><br><img src="https://habrastorage.org/webt/7s/si/a-/7ssia-98n-lxqpitskjaudyohpc.png" alt="imagem"><br><br>  Do ponto de vista do desenvolvimento, as seguintes fun√ß√µes s√£o importantes nele. <br><br>  1. A fun√ß√£o de carregar a rede neural do arquivo model.tflite na pasta assets no objeto int√©rprete <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.tensorflow.lite.Interpreter; Interpreter interpreter; <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> { interpreter=<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Interpreter(loadModelFile(MainActivity.<span class="hljs-keyword"><span class="hljs-keyword">this</span></span>)); Log.e(<span class="hljs-string"><span class="hljs-string">"TIME"</span></span>, <span class="hljs-string"><span class="hljs-string">"Interpreter_started "</span></span>); } <span class="hljs-keyword"><span class="hljs-keyword">catch</span></span> (IOException e) { e.printStackTrace(); Log.e(<span class="hljs-string"><span class="hljs-string">"TIME"</span></span>, <span class="hljs-string"><span class="hljs-string">"Interpreter NOT started "</span></span>); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> MappedByteBuffer </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">loadModelFile</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Activity activity)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> IOException </span></span>{ AssetFileDescriptor fileDescriptor = activity.getAssets().openFd(<span class="hljs-string"><span class="hljs-string">"model.tflite"</span></span>); FileInputStream inputStream = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> FileInputStream(fileDescriptor.getFileDescriptor()); FileChannel fileChannel = inputStream.getChannel(); <span class="hljs-keyword"><span class="hljs-keyword">long</span></span> startOffset = fileDescriptor.getStartOffset(); <span class="hljs-keyword"><span class="hljs-keyword">long</span></span> declaredLength = fileDescriptor.getDeclaredLength(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength); }</code> </pre><br>  2. Detectando rostos usando o m√≥dulo FaceDetector, que faz parte do pacote de biblioteca padr√£o do google, usando uma rede neural e exibindo os resultados. <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.google.android.gms.vision.face.Face; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.google.android.gms.vision.face.FaceDetector; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">detectFace</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{ <span class="hljs-comment"><span class="hljs-comment">//Create a Paint object for drawing with Paint myRectPaint = new Paint(); myRectPaint.setStrokeWidth(5); myRectPaint.setColor(Color.GREEN); myRectPaint.setStyle(Paint.Style.STROKE); Paint fontPaint = new Paint(); fontPaint.setStrokeWidth(3); fontPaint.setTextSize(70); fontPaint.setColor(Color.BLUE); fontPaint.setStyle(Paint.Style.FILL_AND_STROKE); //Create a Canvas object for drawing on tempBitmap = Bitmap.createBitmap(myBitmap.getWidth(), myBitmap.getHeight(), Bitmap.Config.RGB_565); Canvas tempCanvas = new Canvas(tempBitmap); tempCanvas.drawBitmap(myBitmap, 0, 0, null); //Detect the Faces FaceDetector faceDetector = new FaceDetector.Builder(getApplicationContext()).build(); Frame frame = new Frame.Builder().setBitmap(myBitmap).build(); SparseArray&lt;Face&gt; faces = faceDetector.detect(frame); Face face; float[][] labelProbArray = new float[1][1]; imgData.order(ByteOrder.nativeOrder()); //Draw Rectangles on the Faces if (faces.size()&gt;0){ for (int i = 0; i &lt; faces.size(); i++) { face = faces.valueAt(i); isFaceFound=true; float x1 = Math.max(face.getPosition().x,0); float y1 = Math.max(face.getPosition().y,0); float x2 = Math.min(x1 + face.getWidth(),frame.getBitmap().getWidth()); float y2 = Math.min(y1 + face.getHeight(),frame.getBitmap().getHeight()); Bitmap tempbitmap2 = Bitmap.createBitmap(tempBitmap, (int)x1, (int)y1, (int) (x2-x1), (int) (y2-y1)); tempbitmap2 = Bitmap.createScaledBitmap(tempbitmap2, 112, 112, true); convertBitmapToByteBuffer(tempbitmap2); interpreter.run(imgData, labelProbArray); String textToShow = String.format("%.1f", (Answer[0][0]*5-1)/4 * 10); textToShow = textToShow + "/10"; int width= tempCanvas.getWidth(); //int height=tempCanvas.getHeight(); int fontsize=Math.max(width/20,imgView.getWidth()/20); fontPaint.setTextSize(fontsize); tempCanvas.drawText(textToShow, x1, y1-10, fontPaint); tempCanvas.drawRoundRect(new RectF(x1, y1, x2, y2), 2, 2, myRectPaint) } imgView.setImageDrawable(new BitmapDrawable(getResources(),tempBitmap)); } }</span></span></code> </pre><br>  Se voc√™ quiser jogar com a classifica√ß√£o no seu telefone, pode fazer o download do <a href="https://play.google.com/store/apps/details%3Fid%3Dcom.beautyfromphoto.androidfacedetection" rel="nofollow">aplicativo no mercado do GooglePlay</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt485858/">https://habr.com/ru/post/pt485858/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt485844/index.html">Cabelos grisalhos at√≠picos: despigmenta√ß√£o dos cabelos devido ao estresse</a></li>
<li><a href="../pt485846/index.html">Webinar conjunto Fujitsu e SUSE: ‚ÄúSolu√ß√µes abertas e confi√°veis ‚Äã‚Äãpara a era digital‚Äù</a></li>
<li><a href="../pt485852/index.html">10 raz√µes para N√ÉO encomendar loja online de auditoria de usabilidade</a></li>
<li><a href="../pt485854/index.html">Ajude o compilador C ++ na resolu√ß√£o de sobrecarga de fun√ß√£o</a></li>
<li><a href="../pt485856/index.html">Como imprimimos hexapod e o que veio dele</a></li>
<li><a href="../pt485862/index.html">DDoS da cafeteira</a></li>
<li><a href="../pt485868/index.html">Ilumina√ß√£o para salas de aula e salas de aula</a></li>
<li><a href="../pt485870/index.html">Existe um GameDev em Sakhalin? 2.V</a></li>
<li><a href="../pt485872/index.html">Regress√£o log√≠stica de mastiga√ß√£o</a></li>
<li><a href="../pt485874/index.html">O livro ‚ÄúLearning Python: programa√ß√£o de jogos, visualiza√ß√£o de dados, aplicativos da web. 3rd ed.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
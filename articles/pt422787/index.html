<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üå¨Ô∏è üö± üë®‚Äç‚ù§Ô∏è‚Äçüë® Grandes mudan√ßas nas principais arquiteturas de chips ‚ô•Ô∏è ü•§ üôÜüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A introdu√ß√£o da IA ‚Äã‚Äãno n√≠vel do chip permite processar mais dados localmente, porque um aumento no n√∫mero de dispositivos n√£o causa mais o mesmo efei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Grandes mudan√ßas nas principais arquiteturas de chips</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/422787/"><h4>  <font color="gray">A introdu√ß√£o da IA ‚Äã‚Äãno n√≠vel do chip permite processar mais dados localmente, porque um aumento no n√∫mero de dispositivos n√£o causa mais o mesmo efeito</font> </h4><br>  Os fabricantes de chips est√£o trabalhando em novas arquiteturas que aumentam significativamente a quantidade de dados processados ‚Äã‚Äãpor watt e ciclo.  O terreno est√° preparado para uma das maiores revolu√ß√µes na arquitetura de chips nas √∫ltimas d√©cadas. <br><br>  Todos os principais fabricantes de chips e sistemas est√£o mudando a dire√ß√£o do desenvolvimento.  Eles entraram na corrida das arquiteturas, que prev√™ uma mudan√ßa de paradigma em tudo: dos m√©todos de leitura e grava√ß√£o √† mem√≥ria, ao processamento e, finalmente, ao layout de v√°rios elementos em um chip.  Embora a miniaturiza√ß√£o continue, ningu√©m est√° apostando no dimensionamento para lidar com o crescimento explosivo de dados de sensores e aumentar o volume de tr√°fego entre m√°quinas. <br><a name="habracut"></a><br>  Entre as mudan√ßas nas novas arquiteturas: <br><br><ul><li>  Novos m√©todos para processar uma quantidade maior de dados em 1 ciclo de clock, √†s vezes com menos precis√£o ou com prioridade de determinadas opera√ß√µes, dependendo da aplica√ß√£o. </li><li>  Novas arquiteturas de mem√≥ria que alteram a maneira como armazenamos, lemos, escrevemos e acessamos dados. </li><li>  M√≥dulos de processamento mais especializados, localizados em todo o sistema, perto da mem√≥ria.  Em vez de um processador central, os aceleradores s√£o selecionados dependendo do tipo de dados e aplicativo. </li><li>  No campo da IA, est√° em andamento o trabalho para combinar v√°rios tipos de dados na forma de modelos, o que aumenta efetivamente a densidade dos dados e minimiza discrep√¢ncias entre os diferentes tipos. </li><li>  Agora, o layout do gabinete √© o principal componente da arquitetura, com mais e mais aten√ß√£o sendo prestada √† facilidade de alterar esses projetos. </li></ul><br>  "Existem v√°rias tend√™ncias que afetam os avan√ßos tecnol√≥gicos", disse Stephen Wu, um distinto engenheiro da Rambus.  - Nos data centers, voc√™ aproveita ao m√°ximo o hardware e o software.  Sob esse √¢ngulo, os propriet√°rios do data center est√£o olhando para a economia.  Introduzir algo novo √© caro.  Mas os gargalos est√£o mudando, ent√£o chips especializados est√£o sendo introduzidos para uma computa√ß√£o mais eficiente.  E se voc√™ reduzir os fluxos de dados para a E / S e a mem√≥ria, isso poder√° ter um grande impacto. ‚Äù <br><br>  As mudan√ßas s√£o mais √≥bvias na borda da infraestrutura de computa√ß√£o, ou seja, entre os sensores finais.  De repente, os fabricantes perceberam que dezenas de bilh√µes de dispositivos gerariam muitos dados: esse volume n√£o poderia ser enviado √† nuvem para processamento.  Mas o processamento de todos esses dados no limite apresenta outros problemas: exige grandes melhorias de desempenho sem um aumento significativo no consumo de energia. <br><br>  "H√° uma nova tend√™ncia para menor precis√£o", disse Robert Ober, arquiteto l√≠der de plataforma da Tesla na Nvidia.  - Estes n√£o s√£o apenas ciclos computacionais.  √â um empacotamento de dados mais intensivo na mem√≥ria, onde o formato das instru√ß√µes de 16 bits √© usado. ‚Äù <br><br>  Aubert acredita que, gra√ßas a uma s√©rie de otimiza√ß√µes arquiteturais no futuro pr√≥ximo, voc√™ pode dobrar a velocidade de processamento a cada dois anos.  "Veremos um aumento dram√°tico na produtividade", disse ele.  - Para isso, voc√™ precisa fazer tr√™s coisas.  O primeiro √© a computa√ß√£o.  O segundo √© a mem√≥ria.  A terceira √°rea √© a largura de banda do host e a largura de banda de E / S.  Muito trabalho precisa ser feito para otimizar o armazenamento e a pilha de rede. ‚Äù <br><br>  Algo j√° est√° sendo implementado.  Em uma apresenta√ß√£o na confer√™ncia Hot Chips de 2018, Jeff Rupley, arquiteto-chefe do Austin Research Center da Samsung, apontou v√°rias mudan√ßas importantes na arquitetura do processador M3.  Um inclui mais instru√ß√µes por batida - seis em vez de quatro no √∫ltimo chip M2.  Al√©m disso, a previs√£o de ramifica√ß√£o em redes neurais foi implementada e a fila de instru√ß√µes foi duplicada. <br><br>  Tais mudan√ßas mudam o ponto de inova√ß√£o da fabrica√ß√£o direta de microcircuitos para a arquitetura e o design, por um lado, e para o layout dos elementos do outro lado da cadeia de produ√ß√£o.  Embora as inova√ß√µes continuem sendo continuadas nos processos tecnol√≥gicos, √© apenas √†s custas disso que √© incrivelmente dif√≠cil alcan√ßar um aumento de 15 a 20% na produtividade e pot√™ncia em cada novo modelo de chip - e isso n√£o √© suficiente para lidar com o r√°pido crescimento no volume de dados. <br><br>  "As mudan√ßas est√£o ocorrendo a uma taxa exponencial", disse Victor Pan, presidente e CEO da Xilinx, em um discurso na confer√™ncia Hot Chips, "10 zettabytes [10 <sup>21</sup> bytes] de dados ser√£o gerados a cada ano, e a maioria √© desestruturada". <br><br><h1>  Novas abordagens para a mem√≥ria </h1><br>  Trabalhar com tantos dados requer repensar cada componente do sistema, desde os m√©todos de processamento de dados at√© o armazenamento. <br><br>  "Houve muitas tentativas de criar novas arquiteturas de mem√≥ria", disse Carlos Machin, diretor s√™nior de inova√ß√£o da eSilicon EMEA.  - O problema √© que voc√™ precisa ler todas as linhas e selecionar um bit em cada uma.  Uma op√ß√£o √© criar uma mem√≥ria que possa ser lida da esquerda para a direita, bem como para cima e para baixo.  Voc√™ pode ir ainda mais longe e adicionar computa√ß√£o √† mem√≥ria. ‚Äù <br><br>  Essas mudan√ßas incluem a altera√ß√£o dos m√©todos de leitura da mem√≥ria, a localiza√ß√£o e o tipo de elementos de processamento, bem como a introdu√ß√£o da IA ‚Äã‚Äãpara priorizar o armazenamento, o processamento e a movimenta√ß√£o de dados em todo o sistema. <br><br>  ‚ÄúE se, no caso de dados esparsos, pudermos ler apenas um byte dessa matriz por vez - ou talvez oito bytes consecutivos do mesmo caminho, sem desperdi√ßar energia em outros bytes ou caminhos de bytes nos quais n√£o estamos interessados? ?  "Pergunta a Mark Greenberg, diretor de marketing de produtos da Cadence."  - No futuro, isso √© poss√≠vel.  Se voc√™ observar a arquitetura do HBM2, por exemplo, a pilha ser√° organizada em 16 canais virtuais de 64 bits cada, e voc√™ precisar√° obter apenas 4 palavras consecutivas de 64 bits para acessar qualquer canal virtual.  Assim, √© poss√≠vel criar matrizes de dados com uma largura de 1024 bits, escrever horizontalmente, mas ler verticalmente quatro palavras de 64 bits por vez. " <br><br>  A mem√≥ria √© um dos principais componentes da arquitetura de von Neumann, mas agora tamb√©m se tornou uma das principais arenas para experimentos.  "O principal inimigo s√£o os sistemas de mem√≥ria virtual, onde os dados s√£o movidos de maneiras menos naturais", disse Dan Bouvier, arquiteto-chefe de produtos para clientes da AMD.  - Esta √© uma transmiss√£o de transmiss√£o.  Estamos acostumados a isso no campo dos gr√°ficos.  Mas se resolvermos os conflitos no banco de mem√≥ria DRAM, obteremos um fluxo muito mais eficiente.  Em seguida, uma GPU separada pode usar DRAM na faixa de 90% de efici√™ncia, o que √© muito bom.  Mas se voc√™ configurar o streaming sem interrup√ß√µes, a CPU e a APU tamb√©m cair√£o na faixa de efici√™ncia de 80% a 85%. ‚Äù <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6af/814/e8c/6af814e8c5d0a2f4b9274d165aa8f622.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">1. Arquitetura von Neumann.</font></i>  <i><font color="gray">Fonte: Engenharia de Semicondutores</font></i> <br><br>  A IBM est√° desenvolvendo um tipo diferente de arquitetura de mem√≥ria, que √© essencialmente uma vers√£o atualizada da agrega√ß√£o de disco.  O objetivo √© que, em vez de usar uma √∫nica unidade, o sistema possa usar arbitrariamente qualquer mem√≥ria dispon√≠vel por meio de um conector, que Jeff Stucheli, arquiteto de hardware da IBM, chama de "canivete su√≠√ßo" para conectar elementos.  A vantagem da abordagem √© que ela permite misturar e combinar diferentes tipos de dados. <br><br>  "O processador est√° se transformando no centro de uma interface de sinaliza√ß√£o de alto desempenho", diz Stucelli.  "Se voc√™ alterar a microarquitetura, o n√∫cleo realiza mais opera√ß√µes por ciclo na mesma frequ√™ncia." <br><br>  Conectividade e taxa de transfer√™ncia devem garantir o processamento de um volume radicalmente aumentado de dados gerados.  "Os principais gargalos est√£o agora nos locais de movimenta√ß√£o de dados", disse Wu, da Rambus.  "A ind√∫stria fez um √≥timo trabalho aumentando a velocidade da computa√ß√£o".  Mas se voc√™ espera dados ou modelos de dados especializados, precisa executar a mem√≥ria mais rapidamente.  Portanto, se voc√™ observar DRAM e NVM, o desempenho depende do padr√£o de tr√°fego.  Se os dados estiverem fluindo, a mem√≥ria fornecer√° um desempenho muito bom.  Mas se os dados chegarem aleatoriamente, ser√° menos eficiente.  E n√£o importa o que voc√™ fa√ßa, com um aumento no volume, voc√™ ainda precisar√° faz√™-lo mais rapidamente. ‚Äù <br><br><h1>  Mais computa√ß√£o, menos tr√°fego. </h1><br>  O problema √© agravado pelo fato de que existem v√°rios tipos diferentes de dados gerados em diferentes frequ√™ncias e velocidades por dispositivos na borda.  Para que esses dados se movam livremente entre diferentes m√≥dulos de processamento, o gerenciamento deve se tornar muito mais eficiente do que no passado. <br><br>  "Existem quatro configura√ß√µes principais: muitos para muitos, subsistemas de mem√≥ria, E / S de baixa pot√™ncia e topologias de grades e an√©is", diz Charlie Janak, presidente e CEO da Arteris IP.  - Voc√™ pode colocar todos os quatro em um chip, o que acontece com os principais chips IoT.  Ou voc√™ pode adicionar subsistemas HBM de alto rendimento.  Mas a complexidade √© enorme, porque algumas dessas cargas de trabalho s√£o muito espec√≠ficas e o chip possui v√°rias tarefas de trabalho diferentes.  Se voc√™ olhar para alguns desses microchips, eles obt√™m grandes quantidades de dados.  Isso ocorre em sistemas como radares de autom√≥veis e lidares.  Eles n√£o podem existir sem algumas interconex√µes avan√ßadas. ‚Äù <br><br>  A tarefa √© como minimizar a movimenta√ß√£o de dados, mas ao mesmo tempo maximizar o fluxo de dados quando necess√°rio - e de alguma forma encontrar um equil√≠brio entre o processamento local e o centralizado, sem aumentar desnecessariamente o consumo de energia. <br><br>  "Por um lado, esse √© um problema de largura de banda", disse Rajesh Ramanujam, gerente de marketing de produtos da NetSpeed ‚Äã‚ÄãSystems.  - Voc√™ deseja reduzir o tr√°fego o m√°ximo poss√≠vel, portanto transfira os dados para mais perto do processador.  Mas se voc√™ ainda precisar mover os dados, √© recomend√°vel compact√°-los o m√°ximo poss√≠vel.  Mas nada existe por si s√≥.  Tudo precisa ser planejado a partir do n√≠vel do sistema.  Em cada etapa, v√°rios eixos interdependentes devem ser considerados.  Eles determinam se voc√™ usa a mem√≥ria da maneira tradicional de ler e escrever ou se utiliza novas tecnologias.  Em alguns casos, pode ser necess√°rio alterar a maneira como voc√™ armazena os dados.  Se voc√™ precisar de um desempenho mais alto, isso geralmente significa um aumento na √°rea do chip, o que afeta a dissipa√ß√£o de calor.  E agora, considerando a seguran√ßa funcional, a sobrecarga de dados n√£o pode ser permitida. ‚Äù <br><br>  √â por isso que tanta aten√ß√£o √© dada ao processamento de dados na borda e na largura de banda do canal por v√°rios m√≥dulos de processamento de dados.  Mas, √† medida que voc√™ desenvolve arquiteturas diferentes, √© muito diferente como e onde esse processamento de dados √© implementado. <br><br>  Por exemplo, a Marvell introduziu um controlador SSD com IA incorporada para lidar com a pesada carga de computa√ß√£o no limite.  O mecanismo de IA pode ser usado para an√°lises dentro da unidade SSD. <br><br>  "Voc√™ pode carregar modelos diretamente no hardware e processar o hardware no controlador SSD", disse Ned Varnitsa, engenheiro-chefe da Marvell.  - Hoje faz o servidor na nuvem (host).  Mas se cada disco enviar dados para a nuvem, isso criar√° uma enorme quantidade de tr√°fego de rede.  √â melhor fazer o processamento no limite, e o host emite apenas um comando, que s√£o apenas metadados.  Quanto mais unidades voc√™ tiver, mais poder de processamento.  Este √© um grande benef√≠cio da redu√ß√£o de tr√°fego. ‚Äù <br><br>  Essa abordagem √© particularmente interessante porque se adapta a dados diferentes, dependendo da aplica√ß√£o.  Portanto, o host pode gerar uma tarefa e envi√°-la ao dispositivo de armazenamento para processamento, ap√≥s o qual apenas os resultados de metadados ou c√°lculos s√£o enviados de volta.  Em outro cen√°rio, um dispositivo de armazenamento pode armazenar dados, pr√©-process√°-los e gerar metadados, tags e √≠ndices, que s√£o recuperados pelo host conforme necess√°rio para an√°lises adicionais. <br><br>  Essa √© uma das op√ß√µes poss√≠veis.  Tem outros  O Rupli da Samsung enfatizou a import√¢ncia de processar e mesclar idiomas que podem decodificar duas instru√ß√µes e combin√°-las em uma √∫nica opera√ß√£o. <br><br><h1>  A IA lida com controle e otimiza√ß√£o </h1><br>  Em todos os n√≠veis de otimiza√ß√£o, a Intelig√™ncia Artificial √© usada - este √© um dos elementos verdadeiramente novos na arquitetura de chips.  Em vez de permitir que o sistema operacional e o middleware gerenciem fun√ß√µes, essa fun√ß√£o de monitoramento √© distribu√≠da pelo chip, entre os chips e no n√≠vel do sistema.  Em alguns casos, redes neurais de hardware s√£o introduzidas. <br><br>  "O objetivo n√£o √© tanto empacotar mais juntos, mas mudar a arquitetura tradicional", diz Mike Gianfanya, vice-presidente de marketing da eSilicon.  - Com a ajuda da IA ‚Äã‚Äãe do aprendizado de m√°quina, voc√™ pode distribuir elementos pelo sistema, obtendo um processamento mais eficiente com a previs√£o.  Ou voc√™ pode usar chips separados que funcionam independentemente no sistema ou no m√≥dulo. ‚Äù <br><br>  A ARM desenvolveu seu primeiro chip de aprendizado de m√°quina, que planeja lan√ßar ainda este ano para v√°rios mercados.  "Este √© um novo tipo de processador", disse Ian Bratt, Engenheiro Homenageado da ARM.  - Inclui um bloco fundamental - √© um mecanismo de computa√ß√£o, bem como um mecanismo MAC, um mecanismo DMA com um m√≥dulo de controle e uma rede de transmiss√£o.  No total, existem 16 n√∫cleos de computa√ß√£o fabricados usando a tecnologia de processo de 7 nm, que produz 4 TeraOps a uma frequ√™ncia de 1 GHz. ‚Äù <br><br>  Como o ARM trabalha com um ecossistema de parceiros, seu chip √© mais vers√°til e personaliz√°vel do que outros chips de AI / ML que est√£o sendo desenvolvidos.  Em vez de uma estrutura monol√≠tica, ela separa o processamento por fun√ß√£o, para que cada m√≥dulo de computa√ß√£o funcione em um mapa de recursos separado.  Bratt identificou quatro ingredientes principais: planejamento est√°tico, dobragem eficiente, mecanismos de estreitamento e adapta√ß√£o programada para futuras mudan√ßas no projeto. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fbe/7e4/ab1/fbe7e4ab11731ad3dafebc992b9c7bf2.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">2. Arquitetura ML do processador ARM.</font></i>  <i><font color="gray">Fonte: ARM / Hot Chips</font></i> <br><br>  Enquanto isso, a Nvidia escolheu uma t√°tica diferente: criar um mecanismo de aprendizado profundo dedicado ao lado da GPU para otimizar o processamento de imagem e v√≠deo. <br><br><h1>  Conclus√£o </h1><br>  Usando algumas ou todas essas abordagens, os fabricantes de chips esperam dobrar o desempenho a cada dois anos, acompanhando o crescimento explosivo dos dados, mantendo-se dentro da estrutura r√≠gida dos or√ßamentos de energia.  Mas isso n√£o √© apenas mais computa√ß√£o.  Essa √© uma mudan√ßa na plataforma de design de chips e sistemas, quando o crescente volume de dados, em vez de limita√ß√µes de hardware e software, se torna o principal fator. <br><br>  "Quando os computadores apareceram nas empresas, parecia para muitos que o mundo ao nosso redor havia se acelerado", disse Aart de Gues, presidente e CEO da Synopsys.  - Eles faziam contabilidade em peda√ßos de papel com pilhas de livros.  O livro se transformou em uma pilha de cart√µes perfurados para impress√£o e computa√ß√£o.  Uma tremenda mudan√ßa ocorreu e a vemos novamente.  Com o advento de computadores de computa√ß√£o simples mentalmente, o algoritmo de a√ß√µes n√£o mudou: voc√™ pode rastrear todas as etapas.  Mas agora est√° acontecendo outra coisa que pode levar a uma nova acelera√ß√£o.  √â como em um campo agr√≠cola incluir a rega e aplicar um certo tipo de fertilizante apenas em um determinado dia, quando a temperatura atingir o n√≠vel desejado.  Esse uso do aprendizado de m√°quina √© uma otimiza√ß√£o que n√£o era √≥bvia no passado. ‚Äù <br><br>  Ele n√£o est√° sozinho nesta avalia√ß√£o.  "As novas arquiteturas ser√£o adotadas", disse Wally Raines, presidente e CEO da Mentor, Siemens Business.  - Eles ser√£o projetados.  O aprendizado de m√°quina ser√° usado em muitos ou na maioria dos casos, porque seu c√©rebro aprende com sua pr√≥pria experi√™ncia.  Visitei 20 ou mais empresas que desenvolvem processadores de IA especializados de um tipo ou outro, e cada uma delas tem seu pr√≥prio nicho.  Mas voc√™ ver√° cada vez mais sua aplica√ß√£o em aplica√ß√µes espec√≠ficas, e elas complementar√£o a arquitetura tradicional de von Neumann.  A computa√ß√£o neurom√≥rfica se tornar√° popular.  Este √© um grande passo na efici√™ncia da computa√ß√£o e redu√ß√£o de custos.  Dispositivos m√≥veis e sensores come√ßar√£o a fazer o trabalho que os servidores fazem hoje. ‚Äù </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt422787/">https://habr.com/ru/post/pt422787/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt422775/index.html">Confer√™ncia DEFCON 22. Andrew "Zoz" Brooks. N√£o estrague tudo! Parte 1</a></li>
<li><a href="../pt422777/index.html">Uma introdu√ß√£o simples √† ALU para redes neurais: explica√ß√£o, significado f√≠sico e implementa√ß√£o</a></li>
<li><a href="../pt422781/index.html">Resumo da Fintech: SWIFT continuar√° trabalhando na Federa√ß√£o Russa, o VISA permitir√° a transfer√™ncia de fundos por n√∫mero de telefone, biometria cara</a></li>
<li><a href="../pt422783/index.html">Melhor, mais r√°pido, mais poderoso: componentes com estilo v4</a></li>
<li><a href="../pt422785/index.html">Digitaliza√ß√£o de f√°brica: um olhar pela frente</a></li>
<li><a href="../pt422789/index.html">@Pythonetc Aug de 2018</a></li>
<li><a href="../pt422791/index.html">Como N√ÉO Aprender Ingl√™s: Erros Comuns</a></li>
<li><a href="../pt422793/index.html">Confer√™ncia DEFCON 22. Andrew "Zoz" Brooks. N√£o estrague tudo! Parte 2</a></li>
<li><a href="../pt422795/index.html">Tecnologia e neg√≥cios: um novo modelo de coopera√ß√£o com a Zyxel na R√∫ssia</a></li>
<li><a href="../pt422797/index.html">Como criamos um gravador de v√≠deo em nuvem de tamanho pequeno a partir de uma c√¢mera IP comum</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîò üë©‚Äçüëß üò£ L'analyse des donn√©es Scala - un besoin urgent ou une opportunit√© agr√©able? üïû üêµ üöü</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Les outils traditionnels dans le domaine de la science des donn√©es sont des langages tels que R et Python - la syntaxe d√©tendue et un grand nombre de ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>L'analyse des donn√©es Scala - un besoin urgent ou une opportunit√© agr√©able?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/442688/"><p><img src="https://habrastorage.org/webt/5q/1e/fr/5q1efrbkxbuk_ndqoensinfl80a.jpeg"></p><br><p>  Les outils traditionnels dans le domaine de la science des donn√©es sont des langages tels que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">R</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Python</a> - la syntaxe d√©tendue et un grand nombre de biblioth√®ques pour l'apprentissage automatique et le traitement des donn√©es vous permettent d'obtenir rapidement des solutions de travail.  Cependant, il existe des situations o√π les limites de ces outils deviennent un obstacle important - tout d'abord, s'il est n√©cessaire d'atteindre des performances √©lev√©es en termes de vitesse de traitement et / ou de travailler avec de tr√®s grands ensembles de donn√©es.  Dans ce cas, le sp√©cialiste doit se tourner √† contrec≈ìur vers l'aide du "c√¥t√© obscur" et connecter des outils dans les langages de programmation "industriels": <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Scala</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Java</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">C ++</a> . </p><br><p> Mais ce c√¥t√© est-il si sombre?  Au fil des ann√©es de d√©veloppement, les outils de la Data Science ¬´industrielle¬ª ont parcouru un long chemin et sont aujourd'hui tr√®s diff√©rents de leurs propres versions il y a 2-3 ans.  Essayons d'utiliser l'exemple de la t√¢che <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SNA Hackathon 2019</a> pour comprendre dans quelle mesure l'√©cosyst√®me Scala + Spark peut correspondre √† Python Data Science. </p><a name="habracut"></a><br><p>  Dans le cadre du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SNA Hackathon 2019, les</a> participants r√©solvent le probl√®me de trier le fil d'actualit√© d'un utilisateur d'un r√©seau social dans l'une des trois ¬´disciplines¬ª: utiliser des donn√©es de textes, d'images ou de journaux de fonctionnalit√©s.  Dans cette publication, nous verrons comment dans Spark il est possible de r√©soudre un probl√®me bas√© sur un journal de fonctionnalit√©s en utilisant des outils classiques d'apprentissage automatique. </p><br><p>  Pour r√©soudre le probl√®me, nous suivrons le chemin standard suivi par tout sp√©cialiste de l'analyse de donn√©es lors du d√©veloppement d'un mod√®le: </p><br><ul><li>  Nous effectuerons une analyse des donn√©es de recherche, construirons des graphiques. </li><li>  Nous analysons les propri√©t√©s statistiques des signes dans les donn√©es, examinons leurs diff√©rences entre les ensembles d'apprentissage et de test. </li><li>  Nous proc√©derons √† une premi√®re s√©lection de fonctionnalit√©s en fonction des propri√©t√©s statistiques. </li><li>  Nous calculons les corr√©lations entre les signes et la variable cible, ainsi que la corr√©lation crois√©e entre les signes. </li><li>  Nous formerons l'ensemble final des fonctionnalit√©s, formerons le mod√®le et v√©rifierons sa qualit√©. </li><li>  Analysons la structure interne du mod√®le pour identifier les points de croissance. </li></ul><br><p>  Au cours de notre ¬´voyage¬ª, nous nous familiariserons avec des outils tels que le cahier interactif <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Zeppelin</a> , la biblioth√®que d'apprentissage automatique <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Spark ML</a> et son extension <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PravdaML</a> , le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">package</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">graphique</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GraphX</a> , la biblioth√®que de visualisation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vegas</a> et, bien s√ªr, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apache Spark</a> dans toute sa splendeur: )  Tous les r√©sultats de code et d'exp√©rience sont disponibles sur la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plate-forme de</a> cahier collaboratif <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Zepl</a> . </p><br><h1 id="zagruzka-dannyh">  Chargement des donn√©es </h1><br><p>  La particularit√© des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">donn√©es</a> pr√©sent√©es au <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SNA Hackathon 2019</a> est qu'il est possible de les traiter directement en utilisant Python, mais c'est difficile: les donn√©es originales sont assez efficacement compress√©es gr√¢ce aux capacit√©s du format de colonne Apache Parquet et lors de la lecture en m√©moire ¬´par le front¬ª, elles sont d√©compress√©es en plusieurs dizaines de gigaoctets.  Lorsque vous travaillez avec Apache Spark, il n'est pas n√©cessaire de charger compl√®tement les donn√©es en m√©moire, l'architecture Spark est con√ßue pour traiter les donn√©es en morceaux, en les chargeant √† partir du disque selon les besoins. </p><br><p>  Par cons√©quent, la premi√®re √©tape - v√©rifier la distribution des donn√©es par jour - est facilement r√©alis√©e par des outils en bo√Æte: </p><br><pre><code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> train = sqlContext.read.parquet(<span class="hljs-string"><span class="hljs-string">"/events/hackatons/SNAHackathon/2019/collabTrain"</span></span>) z.show(train.groupBy($<span class="hljs-string"><span class="hljs-string">"date"</span></span>).agg( functions.count($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>).as(<span class="hljs-string"><span class="hljs-string">"count"</span></span>), functions.countDistinct($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>).as(<span class="hljs-string"><span class="hljs-string">"users"</span></span>), functions.countDistinct($<span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>).as(<span class="hljs-string"><span class="hljs-string">"objects"</span></span>), functions.countDistinct($<span class="hljs-string"><span class="hljs-string">"metadata_ownerId"</span></span>).as(<span class="hljs-string"><span class="hljs-string">"owners"</span></span>)) .orderBy(<span class="hljs-string"><span class="hljs-string">"date"</span></span>))</code> </pre> <br><p>  Ce que le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">graphique</a> correspondant affichera dans Zeppelin: </p><br><p><img src="https://habrastorage.org/webt/jp/lh/pw/jplhpwwz4tfgdtrs1u_u-tqsvzi.png"></p><br><p>  Je dois dire que la syntaxe Scala est assez flexible, et le m√™me code peut ressembler, par exemple, √† ceci: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> train = sqlContext.read.parquet(<span class="hljs-string"><span class="hljs-string">"/events/hackatons/SNAHackathon/2019/collabTrain"</span></span>) z.show( train groupBy $<span class="hljs-string"><span class="hljs-string">"date"</span></span> agg( count($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>) as <span class="hljs-string"><span class="hljs-string">"count"</span></span>, countDistinct($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>) as <span class="hljs-string"><span class="hljs-string">"users"</span></span>, countDistinct($<span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>) as <span class="hljs-string"><span class="hljs-string">"objects"</span></span>, countDistinct($<span class="hljs-string"><span class="hljs-string">"metadata_ownerId"</span></span>) as <span class="hljs-string"><span class="hljs-string">"owners"</span></span>) orderBy <span class="hljs-string"><span class="hljs-string">"date"</span></span> )</code> </pre> <br><p>  Un avertissement important doit √™tre fait ici: lorsque vous travaillez dans une grande √©quipe, o√π chacun aborde l'√©criture du code Scala exclusivement du point de vue de son propre go√ªt, la communication est beaucoup plus difficile.  Il est donc pr√©f√©rable de d√©velopper un concept unifi√© de style de code. </p><br><p>  Mais revenons √† notre t√¢che.  Une simple analyse de jour a montr√© la pr√©sence de points anormaux les 17 et 18 f√©vrier;  ces jours-ci, des donn√©es incompl√®tes ont probablement √©t√© recueillies et la distribution des caract√®res peut √™tre biais√©e.  Cela devrait √™tre pris en compte dans une analyse plus approfondie.  De plus, il est frappant de constater que le nombre d'utilisateurs uniques est tr√®s proche du nombre d'objets, il est donc logique d'√©tudier la r√©partition des utilisateurs avec diff√©rents nombres d'objets: </p><br><pre> <code class="scala hljs">z.show(filteredTrain .groupBy($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>).count .groupBy(<span class="hljs-string"><span class="hljs-string">"count"</span></span>).agg(functions.log(functions.count(<span class="hljs-string"><span class="hljs-string">"count"</span></span>)).as(<span class="hljs-string"><span class="hljs-string">"withCount"</span></span>)) .orderBy($<span class="hljs-string"><span class="hljs-string">"withCount"</span></span>.desc) .limit(<span class="hljs-number"><span class="hljs-number">100</span></span>) .orderBy($<span class="hljs-string"><span class="hljs-string">"count"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/dh/i-/pp/dhi-ppdka19zurhimccpq7tij5w.png"></p><br><p>  On s'attend √† voir une distribution proche de l'exponentielle, avec une tr√®s longue queue.  Dans de telles t√¢ches, en r√®gle g√©n√©rale, il est possible d'obtenir une am√©lioration de la qualit√© du travail en segmentant les mod√®les pour les utilisateurs avec diff√©rents niveaux d'activit√©.  Afin de v√©rifier si cela vaut la peine, comparez la distribution du nombre d'objets par utilisateur dans l'ensemble de test: </p><br><p><img src="https://habrastorage.org/webt/du/sy/xt/dusyxten5shm24an736n7akolnm.png"></p><br><p>  La comparaison avec le test montre que les utilisateurs du test ont au moins deux objets dans les journaux (puisque le probl√®me de classement est r√©solu sur le hackathon, c'est une condition n√©cessaire pour √©valuer la qualit√©).  √Ä l'avenir, je recommande de regarder de plus pr√®s les utilisateurs dans l'ensemble de formation, pour lesquels nous d√©clarons la fonction d√©finie par l'utilisateur avec un filtre: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//  ,     "",   , //     val testSimilar = sc.broadcast(filteredTrain.groupBy($"instanceId_userId") .agg( functions.count("feedback").as("count"), functions.sum(functions.expr("IF(array_contains(feedback, 'Liked'), 1.0, 0.0)")).as("sum") ) .where("count &gt; sum AND sum &gt; 0") .select("instanceId_userId").rdd.map(_.getInt(0)).collect.sorted) //           // User Defined Function val isTestSimilar = sqlContext.udf.register("isTestSimilar", (x: Int) =&gt; java.util.Arrays.binarySearch(testSimilar.value, x) &gt;= 0)</span></span></code> </pre> <br><p>  Une remarque importante doit √©galement √™tre faite ici: c'est du point de vue de la d√©finition de l'UDF que l'utilisation de Spark sous Scala / Java et sous Python est tr√®s diff√©rente.  Bien que le code PySpark utilise les fonctionnalit√©s de base, tout fonctionne presque aussi rapidement, mais lorsque des fonctions remplac√©es apparaissent, les performances de PySpark se d√©gradent d'un ordre de grandeur. </p><br><h1 id="pervyy-ml-konveyer">  Le premier pipeline ML </h1><br><p>  Dans l'√©tape suivante, nous essaierons de calculer les statistiques de base sur les actions et les attributs.  Mais pour cela, nous avons besoin des capacit√©s de SparkML, nous allons donc d'abord examiner son architecture g√©n√©rale: </p><br><p><img src="https://habrastorage.org/webt/j7/ev/en/j7evenhyzzfvzouqfkbfq1j9hvu.png"></p><br><p>  SparkML est construit sur la base des concepts suivants: </p><br><ul><li>  Transformer - prend un ensemble de donn√©es en entr√©e et retourne un ensemble modifi√© (transformation).  En r√®gle g√©n√©rale, il est utilis√© pour impl√©menter des algorithmes de pr√© et post-traitement, d'extraction de fonctionnalit√©s et peut √©galement repr√©senter les mod√®les ML r√©sultants. </li><li>  Estimateur - prend un ensemble de donn√©es en entr√©e et retourne Transformer (fit).  Naturellement, Estimator peut repr√©senter l'algorithme ML. </li><li>  Pipeline est un cas particulier d'Estimator, compos√© d'une cha√Æne de transformateurs et d'estimateurs.  Lorsque la m√©thode est appel√©e, fit passe par la cha√Æne, et s'il voit un transformateur, il l'applique aux donn√©es, et s'il voit un estimateur, il entra√Æne le transformateur avec lui, l'applique aux donn√©es et va plus loin. </li><li>  PipelineModel - le r√©sultat de Pipeline contient √©galement une cha√Æne √† l'int√©rieur, mais compos√©e exclusivement de transformateurs.  En cons√©quence, PipelineModel lui-m√™me est √©galement un transformateur. </li></ul><br><p>  Une telle approche de la formation d'algorithmes ML permet d'obtenir une structure modulaire claire et une bonne reproductibilit√© - les mod√®les et les pipelines peuvent √™tre enregistr√©s. </p><br><p>  Pour commencer, nous allons construire un pipeline simple avec lequel nous calculons les statistiques de la r√©partition des actions (champ de r√©troaction) des utilisateurs dans l'ensemble de formation: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> feedbackAggregator = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-comment"><span class="hljs-comment">//         (feedback)  one-hot  new MultinominalExtractor().setInputCol("feedback").setOutputCol("feedback"), //       new VectorStatCollector() .setGroupByColumns("date").setInputCol("feedback") .setPercentiles(Array(0.1,0.5,0.9)), //        new VectorExplode().setValueCol("feedback") )).fit(train) z.show(feedbackAggregator .transform(filteredTrain) .orderBy($"date", $"feedback"))</span></span></code> </pre> <br><p>  Dans ce pipeline, la fonctionnalit√© de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PravdaML</a> est activement utilis√©e - biblioth√®ques avec des blocs utiles √©tendus pour SparkML, √† savoir: </p><br><ul><li>  MultinominalExtractor est utilis√© pour coder un caract√®re de type "tableau de cha√Ænes" en un vecteur selon le principe de l'un chaud.  Il s'agit du seul estimateur du pipeline (pour cr√©er un codage, vous devez collecter des lignes uniques √† partir de l'ensemble de donn√©es). </li><li>  VectorStatCollector est utilis√© pour calculer des statistiques vectorielles. </li><li>  VectorExplode est utilis√© pour convertir le r√©sultat dans un format pratique pour la visualisation. </li></ul><br><p>  Le r√©sultat du travail sera un graphique montrant que les classes de l'ensemble de donn√©es ne sont pas √©quilibr√©es, cependant, le d√©s√©quilibre pour la classe Aim√©e cible n'est pas extr√™me: </p><br><p><img src="https://habrastorage.org/webt/aa/db/x4/aadbx4el5s5lhuyput_cj4ns9zo.png"></p><br><p>  L'analyse d'une distribution similaire parmi les utilisateurs similaire √† ceux test√©s (ayant √† la fois "positif" et "n√©gatif" dans les journaux) montre qu'elle est biais√©e vers la classe positive: </p><br><p><img src="https://habrastorage.org/webt/x5/lu/px/x5lupxmayvvodo7lsb3meob1dou.png"></p><br><h1 id="statisticheskiy-analiz-priznakov">  Analyse statistique des signes </h1><br><p>  √Ä l'√©tape suivante, nous effectuerons une analyse d√©taill√©e des propri√©t√©s statistiques des attributs.  Cette fois, nous avons besoin d'un convoyeur plus grand: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> statsAggregator = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">NullToDefaultReplacer</span></span>(), <span class="hljs-comment"><span class="hljs-comment">//          new AutoAssembler() .setColumnsToExclude( (Seq("date", "feedback") ++ train.schema.fieldNames.filter(_.endsWith("Id")) : _*)) .setOutputCol("features"), new VectorStatCollector() .setGroupByColumns("date").setInputCol("features") .setPercentiles(Array(0.1,0.5,0.9)), new VectorExplode().setValueCol("features") ))</span></span></code> </pre> <br><p>  Puisque maintenant nous devons travailler non pas avec un champ s√©par√©, mais avec tous les attributs √† la fois, nous utiliserons deux autres utilitaires <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PravdaML</a> utiles: </p><br><ul><li>  NullToDefaultReplacer vous permet de remplacer les √©l√©ments manquants dans les donn√©es par leurs valeurs par d√©faut (0 pour les nombres, false pour les variables logiques, etc.).  Si vous ne faites pas cette conversion, les valeurs NaN appara√Ætront dans les vecteurs r√©sultants, ce qui est fatal pour de nombreux algorithmes (bien que, par exemple, XGBoost puisse survivre √† cela).  Une alternative au remplacement par des z√©ros peut √™tre le remplacement par des moyennes, ceci est impl√©ment√© dans NaNToMeanReplacerEstimator. </li><li>  AutoAssembler est un utilitaire tr√®s puissant qui analyse la disposition du tableau et s√©lectionne pour chaque colonne un sch√©ma de vectorisation qui correspond au type de colonne. </li></ul><br><p>  En utilisant le pipeline r√©sultant, nous calculons les statistiques pour trois ensembles (formation, formation avec filtre utilisateur et test) et enregistrons dans des fichiers s√©par√©s: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//   (   AutoAssembler  ) val trained = statsAggregator.fit(filteredTrain) //       - ,     . trained .transform(filteredTrain .withColumn("date", //  ,      ,     , //        All   functions.explode(functions.array(functions.lit("All"), $"date")))) .coalesce(7).write.mode("overwrite").parquet("sna2019/featuresStat") trained .transform(filteredTrain .where(isTestSimilar($"instanceId_userId")) .withColumn("date", functions.explode(functions.array(functions.lit("All"), $"date")))) .coalesce(7).write.mode("overwrite").parquet("sna2019/filteredFeaturesStat") trained .transform(filteredTest.withColumn("date", functions.explode(functions.array(functions.lit("All"), $"date")))) .coalesce(3).write.mode("overwrite").parquet("sna2019/testFeaturesStat")</span></span></code> </pre> <br><p>  Apr√®s avoir re√ßu trois ensembles de donn√©es avec des statistiques d'attributs, nous analysons les choses suivantes: </p><br><ul><li>  Avons-nous des signes pour lesquels il y a de grandes √©missions. <br>  - Ces signes doivent √™tre limit√©s ou les enregistrements aberrants doivent √™tre filtr√©s. </li><li>  Avons-nous des signes avec un biais important de la moyenne par rapport √† la m√©diane. <br>  - Un tel changement se produit souvent en pr√©sence d'une distribution d'√©nergie, il est logique de logarithmer ces signes. </li><li>  Y a-t-il un changement dans les r√©partitions moyennes entre les ensembles de formation et de test. </li><li>  Comment bien rempli notre matrice de fonctionnalit√©s. </li></ul><br><p>  Pour clarifier ces aspects, une telle demande nous aidera √†: </p><br><pre> <code class="scala hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">compareWithTest</span></span></span></span>(data: <span class="hljs-type"><span class="hljs-type">DataFrame</span></span>) : <span class="hljs-type"><span class="hljs-type">DataFrame</span></span> = { data.where(<span class="hljs-string"><span class="hljs-string">"date = 'All'"</span></span>) .select( $<span class="hljs-string"><span class="hljs-string">"features"</span></span>, <span class="hljs-comment"><span class="hljs-comment">//         // ( ) functions.log($"features_mean" / $"features_p50").as("skewenes"), //    90-      //    90-  ‚Äî    functions.log( ($"features_max" - $"features_p90") / ($"features_p90" - $"features_p50")).as("outlieres"), //       ,  //    ($"features_nonZeros" / $"features_count").as("train_fill"), $"features_mean".as("train_mean")) .join(testStat.where("date = 'All'") .select($"features", $"features_mean".as("test_mean"), ($"features_nonZeros" / $"features_count").as("test_fill")), Seq("features")) //          .withColumn("meanDrift", (($"train_mean" - $"test_mean" ) / ($"train_mean" + $"test_mean"))) //      .withColumn("fillDrift", ($"train_fill" - $"test_fill") / ($"train_fill" + $"test_fill")) } //         val comparison = compareWithTest(trainStat).withColumn("mode", functions.lit("raw")) .unionByName(compareWithTest(filteredStat).withColumn("mode", functions.lit("filtered")))</span></span></code> </pre> <br><p>  √Ä ce stade, la question de la visualisation est urgente: il est difficile d'afficher imm√©diatement tous les aspects √† l'aide des outils Zeppelin standard, et les blocs-notes avec un grand nombre de graphiques commencent √† ralentir sensiblement en raison du DOM gonfl√©.  La biblioth√®que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vegas</a> - DSL sur Scala pour la construction de sp√©cifications <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vega-lite</a> peut r√©soudre ce probl√®me.  Vegas offre non seulement des capacit√©s de visualisation plus riches (comparables √† matplotlib), mais les dessine √©galement sur Canvas sans gonfler le DOM :). </p><br><p>  La sp√©cification du graphique qui nous int√©resse ressemblera √† ceci: </p><br><pre> <code class="scala hljs">vegas.<span class="hljs-type"><span class="hljs-type">Vegas</span></span>(width = <span class="hljs-number"><span class="hljs-number">1024</span></span>, height = <span class="hljs-number"><span class="hljs-number">648</span></span>) <span class="hljs-comment"><span class="hljs-comment">//   .withDataFrame(comparison.na.fill(0.0)) //           .encodeX("meanDrift", Quant, scale = Scale(domainValues = List(-1.0, 1.0), clamp = true)) //   -       .encodeY("train_fill", Quant) //       .encodeColor("outlieres", Quant, scale=Scale( rangeNominals=List("#00FF00", "#FF0000"), domainValues = List(0.0, 5), clamp = true)) //       .encodeSize("skewenes", Quant) //   -   (   ) .encodeShape("mode", Nom) .mark(vegas.Point) .show</span></span></code> </pre> <br><p>  Le tableau ci-dessous devrait se lire comme suit: </p><br><ul><li>  L'axe des X montre le d√©placement des centres de distribution entre les ensembles de test et d'apprentissage (plus pr√®s de 0, plus le signe est stable). </li><li>  Le pourcentage d'√©l√©ments non nuls est trac√© le long de l'axe Y (plus il y a, plus il y a de donn√©es pour le plus grand nombre de points par attribut). </li><li>  La taille montre le d√©placement de la moyenne par rapport √† la m√©diane (plus le point est grand, plus la distribution de la loi de puissance est probable). </li><li>  La couleur indique les √©missions (le plus rouge, le plus d'√©missions). </li><li>  Eh bien, le formulaire se distingue par un mode de comparaison: avec un filtre utilisateur dans l'ensemble de formation ou sans filtre. </li></ul><br><p><img src="https://habrastorage.org/webt/op/hb/6g/ophb6gi3wa_uvsld9rre6ujzquu.png"></p><br><p>  Nous pouvons donc tirer les conclusions suivantes: </p><br><ul><li>  Certains panneaux n√©cessitent un filtre d'√©mission - nous limiterons les valeurs maximales pour le 90e centile. </li><li>  Certains signes montrent une distribution proche de l'exponentielle - nous prendrons le logarithme. </li><li>  Certaines fonctionnalit√©s ne sont pas pr√©sent√©es dans le test - nous les exclurons de la formation. </li></ul><br><h1 id="korrelyacionnyy-analiz">  Analyse de corr√©lation </h1><br><p>  Apr√®s avoir eu une id√©e g√©n√©rale de la fa√ßon dont les attributs sont distribu√©s et de leur relation entre les ensembles d'apprentissage et de test, essayons d'analyser les corr√©lations.  Pour ce faire, configurez l'extracteur de fonctionnalit√©s en fonction des observations pr√©c√©dentes: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//             val expressions = filteredTrain.schema.fieldNames //          .filterNot(x =&gt; x == "date" || x == "audit_experiment" || idsColumns(x) || x.contains("vd_")) .map(x =&gt; if(skewedFeautres(x)) { //      s"log($x) AS $x" } else { //     cappedFeatures.get(x).map(capping =&gt; s"IF($x &lt; $capping, $x, $capping) AS $x").getOrElse(x) }) val rawFeaturesExtractor = new Pipeline().setStages(Array( new SQLTransformer().setStatement(s"SELECT ${expressions.mkString(", ")} FROM __THIS__"), new NullToDefaultReplacer(), new AutoAssembler().setOutputCol("features") )) //       val raw = rawFeaturesExtractor.fit(filteredTrain).transform( filteredTrain.where(isTestSimilar($"instanceId_userId")))</span></span></code> </pre> <br><p>  Parmi les nouvelles machines de ce pipeline, l'utilitaire SQLTransformer attire l'attention, ce qui permet des transformations SQL arbitraires de la table d'entr√©e. </p><br><p>  Lors de l'analyse des corr√©lations, il est important de filtrer le bruit cr√©√© par la corr√©lation naturelle des caract√©ristiques uniques.  Pour ce faire, je voudrais comprendre quels √©l√©ments du vecteur correspondent √† quelles colonnes sources.  Cette t√¢che dans Spark est effectu√©e √† l'aide de m√©tadonn√©es de colonne (stock√©es avec des donn√©es) et de groupes d'attributs.  Le bloc de code suivant est utilis√© pour filtrer les paires de noms d'attribut provenant de la m√™me colonne de type String: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> attributes = <span class="hljs-type"><span class="hljs-type">AttributeGroup</span></span>.fromStructField(raw.schema(<span class="hljs-string"><span class="hljs-string">"features"</span></span>)).attributes.get <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> originMap = filteredTrain .schema.filter(_.dataType == <span class="hljs-type"><span class="hljs-type">StringType</span></span>) .flatMap(x =&gt; attributes.map(_.name.get).filter(_.startsWith(x.name + <span class="hljs-string"><span class="hljs-string">"_"</span></span>)).map(_ -&gt; x.name)) .toMap <span class="hljs-comment"><span class="hljs-comment">//   ,          val isNonTrivialCorrelation = sqlContext.udf.register("isNonTrivialCorrelation", (x: String, y : String) =&gt; //    Scala-quiz   Option originMap.get(x).map(_ != originMap.getOrElse(y, "")).getOrElse(true))</span></span></code> </pre> <br><p>  Avoir sous la main un ensemble de donn√©es avec une colonne vectorielle, calculer les corr√©lations crois√©es √† l'aide de Spark est assez simple, mais le r√©sultat est une matrice, pour le d√©ploiement de laquelle vous devrez jouer un peu dans un ensemble de paires: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> pearsonCorrelation = <span class="hljs-comment"><span class="hljs-comment">//    Pearson  Spearman Correlation.corr(raw, "features", "pearson").rdd.flatMap( //           _.getAs[Matrix](0).rowIter.zipWithIndex.flatMap(x =&gt; { //   ,   (  , //  ) val name = attributes(x._2).name.get //    ,     x._1.toArray.zip(attributes).map(y =&gt; (name, y._2.name.get, y._1)) } //     DataFrame )).toDF("feature1", "feature2", "corr") .na.drop //   .where(isNonTrivialCorrelation($"feature1", $"feature2")) //    . pearsonCorrelation.coalesce(1).write.mode("overwrite") .parquet("sna2019/pearsonCorrelation")</span></span></code> </pre> <br><p>  Et, bien s√ªr, la visualisation: nous aurons encore besoin de l'aide de Vegas pour dessiner une carte thermique: </p><br><pre> <code class="scala hljs">vegas.<span class="hljs-type"><span class="hljs-type">Vegas</span></span>(<span class="hljs-string"><span class="hljs-string">"Pearson correlation heatmap"</span></span>) .withDataFrame(pearsonCorrelation .withColumn(<span class="hljs-string"><span class="hljs-string">"isPositive"</span></span>, $<span class="hljs-string"><span class="hljs-string">"corr"</span></span> &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) .withColumn(<span class="hljs-string"><span class="hljs-string">"abs_corr"</span></span>, functions.abs($<span class="hljs-string"><span class="hljs-string">"corr"</span></span>)) .where(<span class="hljs-string"><span class="hljs-string">"feature1 &lt; feature2 AND abs_corr &gt; 0.05"</span></span>) .orderBy(<span class="hljs-string"><span class="hljs-string">"feature1"</span></span>, <span class="hljs-string"><span class="hljs-string">"feature2"</span></span>)) .encodeX(<span class="hljs-string"><span class="hljs-string">"feature1"</span></span>, <span class="hljs-type"><span class="hljs-type">Nom</span></span>) .encodeY(<span class="hljs-string"><span class="hljs-string">"feature2"</span></span>, <span class="hljs-type"><span class="hljs-type">Nom</span></span>) .encodeColor(<span class="hljs-string"><span class="hljs-string">"abs_corr"</span></span>, <span class="hljs-type"><span class="hljs-type">Quant</span></span>, scale=<span class="hljs-type"><span class="hljs-type">Scale</span></span>(rangeNominals=<span class="hljs-type"><span class="hljs-type">List</span></span>(<span class="hljs-string"><span class="hljs-string">"#FFFFFF"</span></span>, <span class="hljs-string"><span class="hljs-string">"#FF0000"</span></span>))) .encodeShape(<span class="hljs-string"><span class="hljs-string">"isPositive"</span></span>, <span class="hljs-type"><span class="hljs-type">Nom</span></span>) .mark(vegas.<span class="hljs-type"><span class="hljs-type">Point</span></span>) .show</code> </pre> <br><p>  Le r√©sultat est pr√©f√©rable de regarder dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Zepl-e</a> .  Pour une compr√©hension g√©n√©rale: </p><br><p><img src="https://habrastorage.org/webt/nm/d9/bm/nmd9bmrion4goaov9_vgx5vbjoy.png"></p><br><p>  La carte thermique montre que certaines corr√©lations sont clairement pr√©sentes.  Essayons de s√©lectionner les blocs des fonctionnalit√©s les plus fortement corr√©l√©es, pour cela nous utilisons la biblioth√®que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GraphX</a> : nous transformons la matrice de corr√©lation en graphique, filtrons les bords par poids, apr√®s quoi nous trouvons les composants connect√©s et ne laissons que des composants non d√©g√©n√©r√©s (√† partir de plusieurs √©l√©ments).  Une telle proc√©dure est essentiellement similaire √† l'application de l'algorithme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DBSCAN</a> et se pr√©sente comme suit: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//   (GrpahX   ID) val featureIndexMap = spearmanCorrelation.select("feature1").distinct.rdd.map( _.getString(0)).collect.zipWithIndex.toMap val featureIndex = sqlContext.udf.register("featureIndex", (x: String) =&gt; featureIndexMap(x)) //    val vertices = sc.parallelize(featureIndexMap.map(x =&gt; x._2.toLong -&gt; x._1).toSeq, 1) //    val edges = spearmanCorrelation.select(featureIndex($"feature1"), featureIndex($"feature2"), $"corr") //     .where("ABS(corr) &gt; 0.7") .rdd.map(r =&gt; Edge(r.getInt(0), r.getInt(1), r.getDouble(2))) //       val components = Graph(vertices, edges).connectedComponents() val reversedMap = featureIndexMap.map(_.swap) //    ,    ,   //   val clusters = components .vertices.map(x =&gt; reversedMap(x._2.toInt) -&gt; reversedMap(x._1.toInt)) .groupByKey().map(x =&gt; x._2.toSeq) .filter(_.size &gt; 1) .sortBy(-_.size) .collect</span></span></code> </pre> <br><p>  Le r√©sultat est pr√©sent√© sous forme de tableau: </p><br><p><img src="https://habrastorage.org/webt/4b/t2/bl/4bt2blcjzmxbzucnm7zynpvpj-q.png"></p><br><p>  Sur la base des r√©sultats du clustering, nous pouvons conclure que les groupes les plus corr√©l√©s se sont form√©s autour des signes associ√©s √† l'appartenance des utilisateurs au groupe (membership_status_A), ainsi qu'autour du type d'objet (instanceId_objectType).  Pour la meilleure mod√©lisation de l'interaction des signes, il est judicieux d'appliquer la segmentation du mod√®le - pour former diff√©rents mod√®les pour diff√©rents types d'objets, s√©par√©ment pour les groupes dans lesquels l'utilisateur est et n'est pas. </p><br><h1 id="mashinnoe-obuchenie">  Apprentissage automatique </h1><br><p>  Nous abordons la chose la plus int√©ressante - l'apprentissage automatique.  Le pipeline pour la formation du mod√®le le plus simple (r√©gression logistique) √† l'aide des extensions SparkML et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PravdaML</a> est le suivant: </p><br><pre> <code class="scala hljs"> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">SQLTransformer</span></span>().setStatement( <span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">"SELECT *, IF(array_contains(feedback, 'Liked'), 1.0, 0.0) AS label FROM __THIS__"</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">NullToDefaultReplacer</span></span>(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">AutoAssembler</span></span>() .setColumnsToExclude(<span class="hljs-string"><span class="hljs-string">"date"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>, <span class="hljs-string"><span class="hljs-string">"feedback"</span></span>, <span class="hljs-string"><span class="hljs-string">"label"</span></span>) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"features"</span></span>), <span class="hljs-type"><span class="hljs-type">Scaler</span></span>.scale(<span class="hljs-type"><span class="hljs-type">Interceptor</span></span>.intercept(<span class="hljs-type"><span class="hljs-type">UnwrappedStage</span></span>.repartition( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">LogisticRegressionLBFSG</span></span>(), numPartitions = <span class="hljs-number"><span class="hljs-number">127</span></span>)))</code> </pre> <br><p>  Ici, nous voyons non seulement de nombreux √©l√©ments familiers, mais aussi plusieurs nouveaux: </p><br><ul><li>  LogisticRegressionLBFSG est un estimateur √† entra√Ænement distribu√© de r√©gression logistique. </li><li>  Afin d'obtenir des performances maximales √† partir d'algorithmes ML distribu√©s.  les donn√©es doivent √™tre r√©parties de mani√®re optimale sur les partitions.  L'utilitaire UnwrappedStage.repartition vous y aidera, en ajoutant une op√©ration de r√©partition au pipeline de telle sorte qu'elle ne soit utilis√©e qu'au stade de la formation (apr√®s tout, lors de la cr√©ation de pr√©visions, elle n'est plus n√©cessaire). </li><li>  Pour que le mod√®le lin√©aire puisse donner un bon r√©sultat.  les donn√©es doivent √™tre mises √† l'√©chelle, dont l'utilitaire Scaler.scale est responsable.  Cependant, la pr√©sence de deux transformations lin√©aires cons√©cutives (mise √† l'√©chelle et multiplication par les poids de r√©gression) entra√Æne des d√©penses inutiles, et il est souhaitable de r√©duire ces op√©rations.  Lorsque vous utilisez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PravdaML,</a> la sortie sera un mod√®le propre avec une transformation :). </li><li>  Eh bien, bien s√ªr, pour de tels mod√®les, vous avez besoin d'un membre gratuit, que nous ajoutons en utilisant l'op√©ration Interceptor.intercept. </li></ul><br><p>  Le pipeline r√©sultant, appliqu√© √† toutes les donn√©es, donne AUC par utilisateur 0,68889 (le code de validation est disponible sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Zepl</a> ).  Il reste maintenant √† appliquer toutes nos recherches: filtrer les donn√©es, transformer les entit√©s et les mod√®les de segment.  Le pipeline final ressemblera √† ceci: </p><br><pre> <code class="scala hljs"> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">SQLTransformer</span></span>().setStatement(<span class="hljs-string"><span class="hljs-string">s"SELECT instanceId_userId, instanceId_objectId, </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${expressions.mkString(", ")}</span></span></span><span class="hljs-string"> FROM __THIS__"</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">SQLTransformer</span></span>().setStatement(<span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">"SELECT *, IF(array_contains(feedback, 'Liked'), 1.0, 0.0) AS label, concat(IF(membership_status = 'A', 'OwnGroup_', 'NonUser_'), instanceId_objectType) AS type FROM __THIS__"</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">NullToDefaultReplacer</span></span>(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">AutoAssembler</span></span>() .setColumnsToExclude(<span class="hljs-string"><span class="hljs-string">"date"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>, <span class="hljs-string"><span class="hljs-string">"feedback"</span></span>, <span class="hljs-string"><span class="hljs-string">"label"</span></span>, <span class="hljs-string"><span class="hljs-string">"type"</span></span>,<span class="hljs-string"><span class="hljs-string">"instanceId_objectType"</span></span>) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"features"</span></span>), <span class="hljs-type"><span class="hljs-type">CombinedModel</span></span>.perType( <span class="hljs-type"><span class="hljs-type">Scaler</span></span>.scale(<span class="hljs-type"><span class="hljs-type">Interceptor</span></span>.intercept(<span class="hljs-type"><span class="hljs-type">UnwrappedStage</span></span>.repartition( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">LogisticRegressionLBFSG</span></span>(), numPartitions = <span class="hljs-number"><span class="hljs-number">127</span></span>))), numThreads = <span class="hljs-number"><span class="hljs-number">6</span></span>) ))</code> </pre> <br><p>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PravdaML</a> ‚Äî    CombinedModel.perType.       ,     numThreads = 6.             . </p><br><p> ,   ,  per-user AUC 0.7004.    ?  ,   " "    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">XGBoost</a> : </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">SQLTransformer</span></span>().setStatement(<span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">"SELECT *, IF(array_contains(feedback, 'Liked'), 1.0, 0.0) AS label FROM __THIS__"</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">NullToDefaultReplacer</span></span>(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">AutoAssembler</span></span>() .setColumnsToExclude(<span class="hljs-string"><span class="hljs-string">"date"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>, <span class="hljs-string"><span class="hljs-string">"feedback"</span></span>, <span class="hljs-string"><span class="hljs-string">"label"</span></span>) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"features"</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">XGBoostRegressor</span></span>() .setNumRounds(<span class="hljs-number"><span class="hljs-number">100</span></span>) .setMaxDepth(<span class="hljs-number"><span class="hljs-number">15</span></span>) .setObjective(<span class="hljs-string"><span class="hljs-string">"reg:logistic"</span></span>) .setNumWorkers(<span class="hljs-number"><span class="hljs-number">17</span></span>) .setNthread(<span class="hljs-number"><span class="hljs-number">4</span></span>) .setTrackerConf(<span class="hljs-number"><span class="hljs-number">600000</span></span>L, <span class="hljs-string"><span class="hljs-string">"scala"</span></span>) ))</code> </pre> <br><p> ,     ‚Äî XGBoost  Spark !         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DLMC</a> ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PravdaML</a> ,       (  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a> ).  XGboost " "   10     per-user AUC 0.6981. </p><br><h1 id="analiz-rezultatov">   </h1><br><p> ,     ,  ,       .    SparkML     ,      .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PravdaML</a>  :      Parquet            Spark: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//     val perTypeWeights = sqlContext.read.parquet("sna2019/perType/stages/*/weights") //     20    ( //  ) val topFeatures = new TopKTransformer[Double]() .setGroupByColumns("type") .setColumnToOrderGroupsBy("abs_weight") .setTopK(20) .transform(perTypeWeights.withColumn("abs_weight", functions.abs($"unscaled_weight"))) .orderBy("type", "unscaled_weight")</span></span></code> </pre> <br><p>     Parquet,        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PravdaML</a> ‚Äî TopKTransformer,           . </p><br><p>      Vegas (   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Zepl</a> ): </p><br><p><img src="https://habrastorage.org/webt/q7/_n/fn/q7_nfnto-hw-9nbdgjf3chhm0oc.png"></p><br><p> ,    -   .      XGBoost? </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> significance = sqlContext.read.parquet( <span class="hljs-string"><span class="hljs-string">"sna2019/xgBoost15_100_raw/stages/*/featuresSignificance"</span></span> vegas.<span class="hljs-type"><span class="hljs-type">Vegas</span></span>() .withDataFrame(significance.na.drop.orderBy($<span class="hljs-string"><span class="hljs-string">"significance"</span></span>.desc).limit(<span class="hljs-number"><span class="hljs-number">40</span></span>)) .encodeX(<span class="hljs-string"><span class="hljs-string">"name"</span></span>, <span class="hljs-type"><span class="hljs-type">Nom</span></span>, sortField = <span class="hljs-type"><span class="hljs-type">Sort</span></span>(<span class="hljs-string"><span class="hljs-string">"significance"</span></span>, <span class="hljs-type"><span class="hljs-type">AggOps</span></span>.<span class="hljs-type"><span class="hljs-type">Mean</span></span>)) .encodeY(<span class="hljs-string"><span class="hljs-string">"significance"</span></span>, <span class="hljs-type"><span class="hljs-type">Quant</span></span>) .mark(vegas.<span class="hljs-type"><span class="hljs-type">Bar</span></span>) .show</code> </pre> <br><p><img src="https://habrastorage.org/webt/i2/oy/zb/i2oyzbrjlo15x7u1uwadmeswocq.png"></p><br><p>  ,   ,   XGBoost,         ,    .           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> .   ,  XGBoost     ,    ,   . </p><br><h1 id="vyvody">  Conclusions </h1><br><p>  ,       :).     : </p><br><ol><li>    ,     Scala  Spark    ,      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">  </a> ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a> ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a> . </li><li>    Scala  Spark        Python:    ETL  ML,    ,      ,     . </li><li>  ,   ,   ,    (,  )    ,     ,      . </li><li> ,     ,       .          ,      ,     , -, . </li></ol><br><p> ,       ,    ,        ,    -.        , ,  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">   Scala</a> "  Newprolab. </p><br><p> ,  ,      ‚Äî   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SNA Hackathon 2019</a> . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr442688/">https://habr.com/ru/post/fr442688/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr442676/index.html">O√π les r√™ves m√®nent: souterrain</a></li>
<li><a href="../fr442678/index.html">Plus grand projet en st√©r√©olithographie: squelette de mammouth imprim√© sur une imprimante 3D</a></li>
<li><a href="../fr442680/index.html">Les technologies de remplacement sensoriel vous permettront de voir le monde √† l'aide des sons: comment fonctionne la neuroplasticit√© du cerveau humain</a></li>
<li><a href="../fr442684/index.html">Performance du site √©quilibr√©e. Partie 3: Contenu</a></li>
<li><a href="../fr442686/index.html">Tutoriel DataPower</a></li>
<li><a href="../fr442690/index.html">Mission lunaire "Bereshit" - selfie sur le fond de la Terre</a></li>
<li><a href="../fr442692/index.html">Blockchain sans interm√©diaires: comment nous avons envoy√© des titres √† un registre distribu√©</a></li>
<li><a href="../fr442694/index.html">L'un des g√©ants du streaming lanc√© en Inde et a attir√© un million d'utilisateurs en une semaine</a></li>
<li><a href="../fr442696/index.html">S for Security: Internet Security of Things and reports at InoThings ++ 2019</a></li>
<li><a href="../fr442698/index.html">Application du m√©tro de Moscou pour le Windows Store</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
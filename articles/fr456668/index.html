<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèΩ üé™ üñêüèø Microsoft ML Spark: une extension Spark qui rend SparkML plus humain et LightGBM en bonus ‚ÜîÔ∏è üë©üèΩ‚Äçüéì üóúÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Beaucoup de ceux qui ont travaill√© avec Spark ML savent que certaines des choses qu'ils ont faites l√†-bas "ne sont pas enti√®rement r√©ussies". 
 ou pas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Microsoft ML Spark: une extension Spark qui rend SparkML plus humain et LightGBM en bonus</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/raiffeisenbank/blog/456668/"><p>  Beaucoup de ceux qui ont travaill√© avec Spark ML savent que certaines des choses qu'ils ont faites l√†-bas "ne sont pas enti√®rement r√©ussies". <br>  ou pas du tout fait.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La position des d√©veloppeurs Spark est</a> que SparkML est la plate-forme de base, et toutes les extensions doivent √™tre des packages s√©par√©s.  Mais ce n'est pas toujours pratique, car le Data Scientist et les analystes veulent travailler avec des outils familiers (Jupter, Zeppelin), o√π il y a la plupart de ce qui est n√©cessaire.  Ils ne veulent pas collecter des fichiers JAR de 500 m√©gaoctets avec maven-assembly ou t√©l√©charger des d√©pendances entre leurs mains et les ajouter aux param√®tres de d√©marrage de Spark.  Un travail plus fin avec les syst√®mes de construction de projets JVM peut n√©cessiter beaucoup d'efforts suppl√©mentaires de la part des analystes et des DataScientists habitu√©s √† Jupyter / Zeppelin.  Demander √† DevOps et aux administrateurs de cluster de mettre un paquet de packages sur les n≈ìuds de calcul est clairement une mauvaise id√©e.  Quiconque a √©crit des extensions pour SparkML par lui-m√™me sait combien de difficult√©s cach√©es il y a avec les classes et m√©thodes importantes (qui pour une raison quelconque sont priv√©es [ml]), les restrictions sur les types de param√®tres stock√©s, etc. </p><br><p>  Et il semble que maintenant, avec la biblioth√®que MMLSpark, la vie sera un peu plus facile, et le seuil pour entrer dans le machine learning √©volutif avec SparkML et Scala est l√©g√®rement plus bas. </p><a name="habracut"></a><br><h2 id="vvedenie">  Pr√©sentation </h2><br><p> En raison d'un certain nombre de difficult√©s, ainsi que d'un ensemble clairsem√© de m√©thodes et de solutions pr√™tes √† l'emploi dans SparkML, de nombreuses entreprises √©crivent leurs extensions pour Spark.  Un exemple est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PravdaML</a> , qui est en cours de d√©veloppement √† Odnoklassniki et qui, √† en juger par une √©valuation rapide de ce qui se trouve sur GitHub, semble tr√®s prometteur.  Malheureusement, la plupart de ces solutions sont g√©n√©ralement ferm√©es ou ouvertes, mais n'ont pas la possibilit√© d'installer via Maven / sbt et la documentation de l'API, ce qui rend tr√®s difficile de travailler avec elles. </p><br><p>  Aujourd'hui, nous regardons la biblioth√®que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MMLSpark</a> . </p><br><p>  Nous consid√©rerons, comme d'habitude, l'exemple de la t√¢che de classement des passagers du Titanic.  Le but est de montrer autant de fonctionnalit√©s de la biblioth√®que MMLSpark que possible, pas <del>  assommer SOTA sur ImageNet </del>  montrer un apprentissage machine cool.  Alors le Titanic fera l'affaire. </p><br><p><img src="https://habrastorage.org/webt/rg/bt/sf/rgbtsf7j0ovmfa5lpjkfpfapzti.jpeg"></p><br><p>  La biblioth√®que elle-m√™me poss√®de une API native pour Scala ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation</a> ), Python API ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation</a> ) et, √† en juger par certains endroits du r√©f√©rentiel GitHub, elle aura bient√¥t une API pour R. </p><br><p>  Il existe de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bons exemples d'ordinateurs portables dans le</a> projet GitHub <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">(PySpark + Jupyter)</a> , mais nous irons dans l'autre sens.  Comme l'√©crivait Dmitry Bugaychenko, si vous d√©veloppez pour Spark, c'est-√†-dire que vous avez toutes les raisons d'utiliser Scala pour cela, de plus, Scala vous permet de d√©finir de mani√®re beaucoup plus efficace et plus flexible vos propres Transformer et Estimator pour les incorporer dans SparkML Pipeline, mais la lenteur avec laquelle Numpy fonctionne Le code / pandas en UDF (appel√© sur les ex√©cutables de la JVM) a d√©j√† √©t√© beaucoup √©crit. </p><br><h2 id="kratko-ob-ustanovke">  Dossier d'installation </h2><br><p>  L'ordinateur portable entier est disponible <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  Pour fonctionner avec le Titanic, l'image Zeppelin Docker s'ex√©cutant localement sur un ordinateur portable avec des param√®tres par d√©faut est suffisante pour les yeux.  Docker peut √™tre trouv√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  La biblioth√®que MMLSpark n'est pas dans Maven Central, mais dans des spark-packages, et pour l'ajouter √† Zeppelin, vous devez ex√©cuter le bloc suivant au d√©but de l'ordinateur portable: </p><br><pre><code class="plaintext hljs">%spark.dep z.addRepo("bintray.com").url("http://dl.bintray.com/spark-packages/maven/") z.load("Azure:mmlspark:0.17")</code> </pre> <br><p>  Il vaut la peine de dire que la biblioth√®que a une excellente compatibilit√© descendante: contrairement, par exemple, au XGBoost4j-spark, qui n√©cessite un minimum de Spark 2.3+, cette chose est entr√©e dans Spark 2.2.1, fourni avec l'image Zeppelin Docker, et toutes les difficult√©s Je ne l'ai pas remarqu√©. </p><br><p>  <strong>Remarque: la</strong> plupart de la biblioth√®que MMLSpark est d√©di√©e √† l'inf√©rence de grilles sur le cluster, pour lesquelles CNTK est pr√©sent (qui, √† en juger par la documentation, devrait lire des mod√®les cntk pr√™ts √† l'emploi) et un √©norme bloc OpenCV.  Nous allons nous concentrer sur des t√¢ches plus banales et essayer de ¬´simuler¬ª le cas lorsque nous avons d'√©normes tableaux de donn√©es tabulaires qui se trouvent dans HDFS sous la forme de .csv, de tableaux ou dans un autre format.  Nous devons donc les pr√©-traiter et construire un mod√®le, alors que ces donn√©es ne rentrent pas dans la m√©moire d'une machine.  Par cons√©quent, nous effectuerons toutes les actions sur le cluster. </p><br><h2 id="chtenie-i-razvedochnyy-analiz">  Lecture et analyse de l'intelligence </h2><br><p>  En g√©n√©ral, Spark + Zeppelin n'est pas mal du tout et peut faire face √† la t√¢che EDA, mais nous allons essayer d'√©tendre leurs capacit√©s.  Tout d'abord, nous importons les classes dont nous avons besoin: </p><br><ul><li>  Tout de spark.sql.types pour d√©clarer un sch√©ma et lire les donn√©es correctement </li><li>  Tout depuis spark.sql.functions pour acc√©der aux colonnes et utiliser les fonctions int√©gr√©es </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">com.microsoft.ml.spark.SummarizeData</a> , qui peut √™tre appel√© un analogue de pandas.DataFrame.describe </li></ul><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.microsoft.ml.spark.<span class="hljs-type"><span class="hljs-type">SummarizeData</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.sql.functions._ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.sql.types._</code> </pre> <br><p>  Nous lisons notre dossier: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> titanicSchema = <span class="hljs-type"><span class="hljs-type">StructType</span></span>( <span class="hljs-type"><span class="hljs-type">StructField</span></span>(<span class="hljs-string"><span class="hljs-string">"Passanger"</span></span>, <span class="hljs-type"><span class="hljs-type">ShortType</span></span>) :: <span class="hljs-type"><span class="hljs-type">StructField</span></span>(<span class="hljs-string"><span class="hljs-string">"Survived"</span></span>, <span class="hljs-type"><span class="hljs-type">ShortType</span></span>) :: <span class="hljs-type"><span class="hljs-type">StructField</span></span>(<span class="hljs-string"><span class="hljs-string">"PClass"</span></span>, <span class="hljs-type"><span class="hljs-type">ShortType</span></span>) :: <span class="hljs-type"><span class="hljs-type">StructField</span></span>(<span class="hljs-string"><span class="hljs-string">"Name"</span></span>, <span class="hljs-type"><span class="hljs-type">StringType</span></span>) :: <span class="hljs-type"><span class="hljs-type">StructField</span></span>(<span class="hljs-string"><span class="hljs-string">"Sex"</span></span>, <span class="hljs-type"><span class="hljs-type">StringType</span></span>) :: <span class="hljs-type"><span class="hljs-type">StructField</span></span>(<span class="hljs-string"><span class="hljs-string">"Age"</span></span>, <span class="hljs-type"><span class="hljs-type">ShortType</span></span>) :: <span class="hljs-type"><span class="hljs-type">StructField</span></span>(<span class="hljs-string"><span class="hljs-string">"SibSp"</span></span>, <span class="hljs-type"><span class="hljs-type">ShortType</span></span>) :: <span class="hljs-type"><span class="hljs-type">StructField</span></span>(<span class="hljs-string"><span class="hljs-string">"Parch"</span></span>, <span class="hljs-type"><span class="hljs-type">ShortType</span></span>) :: <span class="hljs-type"><span class="hljs-type">StructField</span></span>(<span class="hljs-string"><span class="hljs-string">"Ticket"</span></span>, <span class="hljs-type"><span class="hljs-type">StringType</span></span>) :: <span class="hljs-type"><span class="hljs-type">StructField</span></span>(<span class="hljs-string"><span class="hljs-string">"Fare"</span></span>, <span class="hljs-type"><span class="hljs-type">FloatType</span></span>) :: <span class="hljs-type"><span class="hljs-type">StructField</span></span>(<span class="hljs-string"><span class="hljs-string">"Cabin"</span></span>, <span class="hljs-type"><span class="hljs-type">StringType</span></span>) :: <span class="hljs-type"><span class="hljs-type">StructField</span></span>(<span class="hljs-string"><span class="hljs-string">"Embarked"</span></span>, <span class="hljs-type"><span class="hljs-type">StringType</span></span>) :: <span class="hljs-type"><span class="hljs-type">Nil</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> train = spark .read .schema(titanicSchema) .option(<span class="hljs-string"><span class="hljs-string">"header"</span></span>, <span class="hljs-literal"><span class="hljs-literal">true</span></span>) .csv(<span class="hljs-string"><span class="hljs-string">"/mountV/titanic/train.csv"</span></span>)</code> </pre> <br><p>  Et maintenant, regardons les donn√©es elles-m√™mes, ainsi que leur taille: </p><br><pre> <code class="scala hljs">println(<span class="hljs-string"><span class="hljs-string">s"Train shape is: </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${train.count}</span></span></span><span class="hljs-string"> x </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${train.columns.length}</span></span></span><span class="hljs-string">"</span></span>) train.limit(<span class="hljs-number"><span class="hljs-number">5</span></span>).createOrReplaceTempView(<span class="hljs-string"><span class="hljs-string">"trainHead"</span></span>)</code> </pre> <br><p>  <strong>Remarque:</strong> Il n'est vraiment pas n√©cessaire d'utiliser createOrReplaceTempView lorsque vous pouvez simplement √©crire .show (5).  Mais show a un probl√®me: lorsque les donn√©es sont "larges", alors la repr√©sentation textuelle de la plaque "flotte", et rien ne devient clair du tout. </p><br><p>  Obtenez la taille de nos donn√©es: La <code>Train shape is: 891 x 12</code> <br>  Et maintenant, dans la cellule sql, nous pouvons regarder les 5 premi√®res lignes: </p><br><pre> <code class="sql hljs">%sql <span class="hljs-keyword"><span class="hljs-keyword">select</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> trainHead</code> </pre> <br><p><img src="https://habrastorage.org/webt/qe/jc/wj/qejcwjvi65jp6xucnorcdfdmxo4.png"></p><br><p>  Eh bien, voyons le r√©sum√© sur notre table: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">SummarizeData</span></span>() .setBasic(<span class="hljs-literal"><span class="hljs-literal">true</span></span>) .setCounts(<span class="hljs-literal"><span class="hljs-literal">true</span></span>) .setPercentiles(<span class="hljs-literal"><span class="hljs-literal">false</span></span>) .setSample(<span class="hljs-literal"><span class="hljs-literal">true</span></span>) .setErrorThreshold(<span class="hljs-number"><span class="hljs-number">0.25</span></span>) .transform(train) .createOrReplaceTempView(<span class="hljs-string"><span class="hljs-string">"summary"</span></span>)</code> </pre> <br><p>  La classe SummarizeData pr√©sente plusieurs avantages par rapport au simple Dataset.describe, car elle vous permet de compter le nombre de valeurs manquantes et uniques, et vous permet √©galement de sp√©cifier la pr√©cision du calcul des quantiles.  Cela peut √™tre critique pour les tr√®s gros volumes de donn√©es. <br><img src="https://habrastorage.org/webt/91/g4/8c/91g48c0oaqiuz8pjgklo38jaiis.png"></p><br><div class="spoiler">  <b class="spoiler_title">Quelques r√©flexions personnelles</b> <div class="spoiler_text"><p>  En g√©n√©ral, il me semblait personnellement que Odnoklassniki dans PravdaML avait une meilleure impl√©mentation de l'analogue SummarizeData.  Microsoft a opt√© pour la simplicit√© et utilise <code>org.apache.spark.sql.functions</code> , c'est juste que tout est commod√©ment emball√© dans une seule classe.  Pour Odnoklassniki, cela est impl√©ment√© via leur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>VectorStatCollector</code></a> , qui n√©cessite un code un peu plus complexe lors de l'appel (vous devez d'abord ajouter toutes les fonctionnalit√©s √† un vecteur) et peut n√©cessiter des op√©rations suppl√©mentaires (par exemple, <code>VectorAssembler</code> refuse g√©n√©ralement de dig√©rer <code>DecimalType</code> ).  Mais j'ai une hypoth√®se bas√©e sur mon exp√©rience avec Spark que SummarizeData de MMLSpark pourrait planter avec des erreurs comme <code>StackOverflow</code> dans <code>org.apache.spark.sql.catalyst</code> s'il y a <strong>vraiment beaucoup de</strong> colonnes, et le graphique de calcul n'est pas petit au moment o√π il d√©marre ( bien que sp√©cialement pour ces fans de "l'extr√™me" dans Spark 2.4, ils ont ajout√© la possibilit√© de r√©duire l'optimiseur de graphique <code>Catalyst</code> ).  Eh bien, il semble qu'avec un <strong>tr√®s grand</strong> nombre de colonnes, la version de Microsoft sera plus lente.  Mais cela, bien s√ªr, doit √™tre v√©rifi√© s√©par√©ment. </p></div></div><br><h2 id="ochistka-dannyh">  Nettoyage des donn√©es </h2><br><p>  Dans le Titanic, tout est comme d'habitude - un tas de colonnes de cha√Ænes ont des valeurs manquantes.  Et une sorte de d√©vers dans les donn√©es (il semble que cette version particuli√®re des donn√©es ne soit pas tr√®s sp√©cifique) - 25 lignes √† partir des valeurs manquantes.  Tout d'abord, corrigez ceci: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> trainFiltered = train.filter(!(isnan(col(<span class="hljs-string"><span class="hljs-string">"Survived"</span></span>)) || isnull(col(<span class="hljs-string"><span class="hljs-string">"Survived"</span></span>))))</code> </pre> <br><h3 id="obrabotka-strokovyh-dannyh">  Traitement des donn√©es de cha√Æne </h3><br><p>  Pour autant que je m'en souvienne, les attributs sortis des champs <code>Name</code> et <code>Cabin</code> √©taient les meilleurs apport√©s dans le Titanic.  Vous pouvez en fournir beaucoup, mais nous nous limiterons √† quelques-uns, juste pour ne pas donner d'exemples de presque le m√™me code. </p><br><p>  Habituellement, il est pratique d'utiliser des expressions r√©guli√®res pour de telles choses. <br>  Mais nous voulons dans ce cas: </p><br><ul><li>  tout a √©t√© distribu√©, les donn√©es ont √©t√© trait√©es au m√™me endroit; </li><li>  tout a √©t√© con√ßu en tant que classes SpakrML Transformer ou Spark ML Estimator, afin que plus tard, il puisse √™tre assembl√© dans Pipeline. </li></ul><br><p>  <strong>Remarque:</strong> Pipeline, tout d'abord, nous garantit que nous appliquons toujours les m√™mes transformations au train et au test, et nous permet √©galement de d√©tecter l'erreur de ¬´regarder vers l'avenir¬ª dans la validation crois√©e.  Et cela nous donne √©galement des capacit√©s simples pour enregistrer, charger et pr√©voir √† l'aide de notre pipeline. </p><br><p>  SparkML a une classe ¬´presque universelle¬ª pour de telles t√¢ches - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SQLTranformer</a> , mais l'√©criture en SQL est clairement pire que l'√©criture en Scala, ne serait-ce que parce qu'il est possible d'attraper la syntaxe ou des erreurs typiques lors de la compilation et de la coloration syntaxique dans Idea.  Et ici MMLSpark vient √† notre aide, o√π un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">UDFTransformer</a> vraiment universel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">est impl√©ment√©</a> : </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.microsoft.ml.spark.<span class="hljs-type"><span class="hljs-type">UDFTransformer</span></span></code> </pre> <br><p>  Pour commencer, nous allons cr√©er notre fonction de transformation, qui est tr√®s simple √† la limite, mais notre objectif est maintenant de montrer le processus de cr√©ation de UDFTransformer.  En principe, sur la base d'exemples aussi simples, n'importe qui peut ajouter de la logique √† n'importe quel niveau de complexit√©. </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> miss = <span class="hljs-string"><span class="hljs-string">".*miss\\..*"</span></span>.r <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> mr = <span class="hljs-string"><span class="hljs-string">".*mr\\..*"</span></span>.r <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> mrs = <span class="hljs-string"><span class="hljs-string">".*mrs\\..*"</span></span>.r <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> master = <span class="hljs-string"><span class="hljs-string">".*master.*"</span></span>.r <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">convertNames</span></span></span></span>(input: <span class="hljs-type"><span class="hljs-type">String</span></span>): <span class="hljs-type"><span class="hljs-type">Option</span></span>[<span class="hljs-type"><span class="hljs-type">String</span></span>] = { <span class="hljs-type"><span class="hljs-type">Option</span></span>(input).map(x =&gt; { x.toLowerCase <span class="hljs-keyword"><span class="hljs-keyword">match</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> miss() =&gt; <span class="hljs-string"><span class="hljs-string">"Miss"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> mr() =&gt; <span class="hljs-string"><span class="hljs-string">"Mr"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> mrs() =&gt; <span class="hljs-string"><span class="hljs-string">"Mrs"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> master() =&gt; <span class="hljs-string"><span class="hljs-string">"Master"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> _ =&gt; <span class="hljs-string"><span class="hljs-string">"Unknown"</span></span> } }) }</code> </pre> <br><p>  (Vous pouvez imm√©diatement voir √† quel point Scala est pratique pour travailler avec des valeurs manquantes qui, soit dit en passant, sont non seulement <code>null</code> , mais aussi <code>Double.NaN</code> , mais il y a <del>  une telle blague </del>  une chose aussi rare que les omissions dans les variables <code>BooleanType</code> , etc.) </p><br><p>  <code>UserDefinedFunction</code> maintenant notre <code>UserDefinedFunction</code> et cr√©ez imm√©diatement un <code>Transformer</code> bas√© sur lui: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> nameTransformUDF = udf(convertNames _) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> nameTransformer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">UDFTransformer</span></span>() .setUDF(nameTransformUDF) .setInputCol(<span class="hljs-string"><span class="hljs-string">"Name"</span></span>) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"NameType"</span></span>)</code> </pre> <br><p>  <strong>Remarque:</strong> Dans un ordinateur portable Zeppelin, c'est toujours la m√™me chose, mais quand tout est r√©uni plus tard dans le code de production, il est important que tous les UDF soient dans des classes ou des objets qui sont <code>extends Serializable</code> .  La chose √©vidente que vous pouvez parfois oublier puis vous plonger pendant longtemps est ce qui ne va pas avec la lecture des longues traces de pile des erreurs Spark. </p><br><p>  Maintenant, nous avons encore le champ <code>Cabin</code> .  Examinons-le de plus pr√®s: <br><img src="https://habrastorage.org/webt/1m/sn/n2/1msnn2zqeyerzpysj2ma3bwzuda.png"></p><br><p>  On voit qu'il y a beaucoup de valeurs manquantes, il y a des lettres, des chiffres, diff√©rentes combinaisons, etc.  Prenons le nombre de cabines (s'il y en a plusieurs), ainsi que les nombres - ils ont probablement une sorte de logique, par exemple, si la num√©rotation se fait √† une extr√©mit√© du navire, alors les cabines √† l'avant avaient moins de chance.  Nous allons √©galement cr√©er des fonctions, puis en nous basant sur <code>UDFTransformer</code> : </p><br><pre> <code class="scala hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getCabinsCount</span></span></span></span>(input: <span class="hljs-type"><span class="hljs-type">String</span></span>): <span class="hljs-type"><span class="hljs-type">Int</span></span> = { <span class="hljs-type"><span class="hljs-type">Option</span></span>(input) <span class="hljs-keyword"><span class="hljs-keyword">match</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-type"><span class="hljs-type">Some</span></span>(x) =&gt; x.split(<span class="hljs-string"><span class="hljs-string">" "</span></span>).length <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-type"><span class="hljs-type">None</span></span> =&gt; <span class="hljs-number"><span class="hljs-number">-1</span></span> } } <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> numPattern = <span class="hljs-string"><span class="hljs-string">"([az])([0-9]+)"</span></span>.r <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getNumbersFromCabin</span></span></span></span>(input: <span class="hljs-type"><span class="hljs-type">String</span></span>): <span class="hljs-type"><span class="hljs-type">Int</span></span> = { <span class="hljs-type"><span class="hljs-type">Option</span></span>(input) <span class="hljs-keyword"><span class="hljs-keyword">match</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-type"><span class="hljs-type">Some</span></span>(x) =&gt; { x.split(<span class="hljs-string"><span class="hljs-string">" "</span></span>)(<span class="hljs-number"><span class="hljs-number">0</span></span>).toLowerCase <span class="hljs-keyword"><span class="hljs-keyword">match</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> numPattern(sym, num) =&gt; <span class="hljs-type"><span class="hljs-type">Integer</span></span>.parseInt(num) <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> _ =&gt; <span class="hljs-number"><span class="hljs-number">-1</span></span> } } <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-type"><span class="hljs-type">None</span></span> =&gt; <span class="hljs-number"><span class="hljs-number">-2</span></span> } } <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> cabinsCountUDF = udf(getCabinsCount _) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> numbersFromCabinUDF = udf(getNumbersFromCabin _) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> cabinsCountTransformer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">UDFTransformer</span></span>() .setInputCol(<span class="hljs-string"><span class="hljs-string">"Cabin"</span></span>) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"CabinCount"</span></span>) .setUDF(cabinsCountUDF) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> numbersFromCabinTransformer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">UDFTransformer</span></span>() .setInputCol(<span class="hljs-string"><span class="hljs-string">"Cabin"</span></span>) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"CabinNumber"</span></span>) .setUDF(numbersFromCabinUDF)</code> </pre> <br><p>  Commen√ßons maintenant par les valeurs manquantes, √† savoir l'√¢ge.  Tout d'abord, profitons des capacit√©s de visualisation de Zeppelin: </p><br><p><img src="https://habrastorage.org/webt/h-/cj/l6/h-cjl6tzbakgmqxc1w-gt_kgwk0.png"></p><br><p>  Et voyez comment les valeurs manquantes g√¢chent tout.  Il serait logique de les remplacer par un milieu (ou m√©diane), mais notre objectif est de consid√©rer toutes les fonctionnalit√©s de la biblioth√®que MMLSpark.  Par cons√©quent, nous √©crirons notre propre <code>Estimator</code> , qui consid√©rera les groupes / moyennes sur l'√©chantillon de formation et les remplacera par les lacunes correspondantes. </p><br><p>  Nous aurons besoin de: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.sql.{<span class="hljs-type"><span class="hljs-type">Dataset</span></span>, <span class="hljs-type"><span class="hljs-type">DataFrame</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.ml.{<span class="hljs-type"><span class="hljs-type">Estimator</span></span>, <span class="hljs-type"><span class="hljs-type">Model</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.ml.param.{<span class="hljs-type"><span class="hljs-type">Param</span></span>, <span class="hljs-type"><span class="hljs-type">ParamMap</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.ml.util.<span class="hljs-type"><span class="hljs-type">Identifiable</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.ml.util.<span class="hljs-type"><span class="hljs-type">DefaultParamsWritable</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.microsoft.ml.spark.{<span class="hljs-type"><span class="hljs-type">HasInputCol</span></span>, <span class="hljs-type"><span class="hljs-type">HasOutputCol</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.microsoft.ml.spark.<span class="hljs-type"><span class="hljs-type">ConstructorWritable</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.microsoft.ml.spark.<span class="hljs-type"><span class="hljs-type">ConstructorReadable</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.microsoft.ml.spark.<span class="hljs-type"><span class="hljs-type">Wrappable</span></span></code> </pre> <br><p>  Prenons attention √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>ConstructorWritable</code></a> , qui simplifie consid√©rablement la vie.  Si notre <code>Model</code> est un mod√®le ¬´entra√Æn√©¬ª renvoy√© par la m√©thode <code>fit(),</code> , qui est enti√®rement d√©termin√© par son constructeur (et c'est probablement 99% des cas), alors nous ne pouvons pas du tout √©crire la s√©rialisation avec nos mains.  Cela simplifie et acc√©l√®re consid√©rablement le d√©veloppement, √©limine les erreurs et abaisse √©galement le seuil d'entr√©e pour DataScientist et les analystes qui ne sont g√©n√©ralement pas des programmeurs professionnels. </p><br><p>  D√©finissez notre classe <code>Estimator</code> .  En fait, la chose la plus importante ici est la m√©thode d' <code>fit</code> , les autres sont des points techniques: </p><br><pre> <code class="scala hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">GroupImputerEstimator</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">override val uid: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Estimator</span></span></span><span class="hljs-class">[</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">GroupImputerModel</span></span></span><span class="hljs-class">] </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">with</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">HasInputCol</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">with</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">HasOutputCol</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">with</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Wrappable</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">with</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">DefaultParamsWritable</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">this</span></span></span></span>() = <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>(<span class="hljs-type"><span class="hljs-type">Identifiable</span></span>.randomUID(<span class="hljs-string"><span class="hljs-string">"GroupImputer"</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> groupCol: <span class="hljs-type"><span class="hljs-type">Param</span></span>[<span class="hljs-type"><span class="hljs-type">String</span></span>] = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Param</span></span>[<span class="hljs-type"><span class="hljs-type">String</span></span>]( <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>, <span class="hljs-string"><span class="hljs-string">"groupCol"</span></span>, <span class="hljs-string"><span class="hljs-string">"Groupping column"</span></span> ) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setGroupCol</span></span></span></span>(v: <span class="hljs-type"><span class="hljs-type">String</span></span>): <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">type</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>.set(groupCol, v) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getGroupCol</span></span></span></span>: <span class="hljs-type"><span class="hljs-type">String</span></span> = $(groupCol) <span class="hljs-keyword"><span class="hljs-keyword">override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fit</span></span></span></span>(dataset: <span class="hljs-type"><span class="hljs-type">Dataset</span></span>[_]): <span class="hljs-type"><span class="hljs-type">GroupImputerModel</span></span> = { <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> meanDF = dataset .toDF .groupBy($(groupCol)) .agg(mean(col($(inputCol))).alias(<span class="hljs-string"><span class="hljs-string">"groupMean"</span></span>)) .select(col($(groupCol)), col(<span class="hljs-string"><span class="hljs-string">"groupMean"</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">GroupImputerModel</span></span>( uid, meanDF, getInputCol, getOutputCol, getGroupCol ) } <span class="hljs-keyword"><span class="hljs-keyword">override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">transformSchema</span></span></span></span>(schema: <span class="hljs-type"><span class="hljs-type">StructType</span></span>): <span class="hljs-type"><span class="hljs-type">StructType</span></span> = schema .add( <span class="hljs-type"><span class="hljs-type">StructField</span></span>( $(outputCol), schema.filter(x =&gt; x.name == $(inputCol))(<span class="hljs-number"><span class="hljs-number">0</span></span>).dataType ) ) <span class="hljs-keyword"><span class="hljs-keyword">override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">copy</span></span></span></span>(extra: <span class="hljs-type"><span class="hljs-type">ParamMap</span></span>): <span class="hljs-type"><span class="hljs-type">Estimator</span></span>[<span class="hljs-type"><span class="hljs-type">GroupImputerModel</span></span>] = { <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> to = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">GroupImputerEstimator</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.uid) copyValues(to, extra).asInstanceOf[<span class="hljs-type"><span class="hljs-type">GroupImputerEstimator</span></span>] } }</code> </pre> <br><p>  <strong>Remarque:</strong> Je n'ai pas utilis√© defaultCopy, car lorsque j'ai appel√©, pour une raison quelconque, il a jur√© que je n'avais pas de constructeur. \ &lt;init&gt; (java.lang.String), bien qu'il semble que cela n'aurait pas d√ª se produire.  Dans tous les cas, l'impl√©mentation de la <code>copy</code> facile. </p><br><p>  Vous devez maintenant impl√©menter <code>Model</code> - une classe qui d√©crit le mod√®le entra√Æn√© et impl√©mente la m√©thode de <code>transform</code> .  Nous allons le construire sur la base de la fonction <code>coalesce</code> int√©gr√©e dans <code>org.apache.spark.sql.functions</code> : </p><br><pre> <code class="scala hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">GroupImputerModel</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params"> val uid: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, val meanDF: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">DataFrame</span></span></span></span><span class="hljs-class"><span class="hljs-params">, val inputCol: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, val outputCol: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, val groupCol: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params"> </span></span></span><span class="hljs-class">) </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Model</span></span></span><span class="hljs-class">[</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">GroupImputerModel</span></span></span><span class="hljs-class">] </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">with</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ConstructorWritable</span></span></span><span class="hljs-class">[</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">GroupImputerModel</span></span></span><span class="hljs-class">] </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> ttag: <span class="hljs-type"><span class="hljs-type">TypeTag</span></span>[<span class="hljs-type"><span class="hljs-type">GroupImputerModel</span></span>] = typeTag[<span class="hljs-type"><span class="hljs-type">GroupImputerModel</span></span>] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">objectsToSave</span></span></span></span>: <span class="hljs-type"><span class="hljs-type">List</span></span>[<span class="hljs-type"><span class="hljs-type">Any</span></span>] = <span class="hljs-type"><span class="hljs-type">List</span></span>(uid, meanDF, inputCol, outputCol, groupCol) <span class="hljs-keyword"><span class="hljs-keyword">override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">copy</span></span></span></span>(extra: <span class="hljs-type"><span class="hljs-type">ParamMap</span></span>): <span class="hljs-type"><span class="hljs-type">GroupImputerModel</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">GroupImputerModel</span></span>(uid, meanDF, inputCol, outputCol, groupCol) <span class="hljs-keyword"><span class="hljs-keyword">override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">transform</span></span></span></span>(dataset: <span class="hljs-type"><span class="hljs-type">Dataset</span></span>[_]): <span class="hljs-type"><span class="hljs-type">DataFrame</span></span> = { dataset .toDF .join(meanDF, <span class="hljs-type"><span class="hljs-type">Seq</span></span>(groupCol), <span class="hljs-string"><span class="hljs-string">"left"</span></span>) .withColumn( outputCol, coalesce(col(inputCol), col(<span class="hljs-string"><span class="hljs-string">"groupMean"</span></span>)) .cast(<span class="hljs-type"><span class="hljs-type">IntegerType</span></span>)) .drop(<span class="hljs-string"><span class="hljs-string">"groupMean"</span></span>) } <span class="hljs-keyword"><span class="hljs-keyword">override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">transformSchema</span></span></span><span class="hljs-function"> </span></span>(schema: <span class="hljs-type"><span class="hljs-type">StructType</span></span>): <span class="hljs-type"><span class="hljs-type">StructType</span></span> = schema .add( <span class="hljs-type"><span class="hljs-type">StructField</span></span>(outputCol, schema.filter(x =&gt; x.name == inputCol)(<span class="hljs-number"><span class="hljs-number">0</span></span>).dataType) ) }</code> </pre> <br><p>  Le dernier objet que nous devons d√©clarer est un <code>Reader</code> , que nous impl√©mentons √† l'aide de la classe MMLSpark <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ConstructorReadable</a> : </p><br><pre> <code class="scala hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">object</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">GroupImputerModel</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ConstructorReadable</span></span></span><span class="hljs-class">[</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">GroupImputerModel</span></span></span><span class="hljs-class">]</span></span></code> </pre> <br><h2 id="sozdanie-pipeline">  Cr√©ation de pipeline </h2><br><p>  Dans Pipeline, je voudrais montrer √† la fois les classes SparkML habituelles et la chose incroyablement pratique de MMLSpark - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MultiColumnAdapter</a> , qui vous permet d'appliquer des transformateurs SparkML √† plusieurs colonnes √† la fois (pour r√©f√©rence, par exemple, StringIndexer et OneHotEncoder prennent exactement une colonne √† l'entr√©e, ce qui les transforme annonce dans la douleur): </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.ml.feature.{<span class="hljs-type"><span class="hljs-type">StringIndexer</span></span>, <span class="hljs-type"><span class="hljs-type">VectorAssembler</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.ml.<span class="hljs-type"><span class="hljs-type">Pipeline</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.microsoft.ml.spark.{<span class="hljs-type"><span class="hljs-type">MultiColumnAdapter</span></span>, <span class="hljs-type"><span class="hljs-type">LightGBMClassifier</span></span>}</code> </pre> <br><p>  Tout d'abord, nous allons d√©clarer quelles colonnes nous avons: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> catCols = <span class="hljs-type"><span class="hljs-type">Array</span></span>(<span class="hljs-string"><span class="hljs-string">"Sex"</span></span>, <span class="hljs-string"><span class="hljs-string">"Embarked"</span></span>, <span class="hljs-string"><span class="hljs-string">"NameType"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> numCols = <span class="hljs-type"><span class="hljs-type">Array</span></span>(<span class="hljs-string"><span class="hljs-string">"PClass"</span></span>, <span class="hljs-string"><span class="hljs-string">"AgeNoMissings"</span></span>, <span class="hljs-string"><span class="hljs-string">"SibSp"</span></span>, <span class="hljs-string"><span class="hljs-string">"Parch"</span></span>, <span class="hljs-string"><span class="hljs-string">"CabinCount"</span></span>, <span class="hljs-string"><span class="hljs-string">"CabinNumber"</span></span>)</code> </pre> <br><p>  Cr√©ez maintenant un encodeur de cha√Ænes: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> stringEncoder = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">MultiColumnAdapter</span></span>() .setBaseStage(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">StringIndexer</span></span>().setHandleInvalid(<span class="hljs-string"><span class="hljs-string">"keep"</span></span>)) .setInputCols(catCols) .setOutputCols(catCols.map(x =&gt; x + <span class="hljs-string"><span class="hljs-string">"_freqEncoded"</span></span>))</code> </pre> <br><p>  <strong>Remarque:</strong> contrairement √† scikit-learn dans SparkML, <code>StringIndexer</code> fonctionne sur le principe de l'encodeur de fr√©quence, et il peut √™tre utilis√© pour sp√©cifier une relation d'ordre (c'est-√†-dire cat√©gorie 0 &lt;cat√©gorie 1, et cela a du sens) - cette approche fonctionne souvent bien pour arbres d√©cisifs. </p><br><p>  <code>Imputer</code> notre <code>Imputer</code> : </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> missingImputer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">GroupImputerEstimator</span></span>() .setInputCol(<span class="hljs-string"><span class="hljs-string">"Age"</span></span>) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"AgeNoMissings"</span></span>) .setGroupCol(<span class="hljs-string"><span class="hljs-string">"Sex"</span></span>)</code> </pre> <br><p>  Et <code>VectorAssembler</code> , puisque les classificateurs SparkML sont plus √† l'aise de travailler avec <code>VectorType</code> : </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> assembler = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">VectorAssembler</span></span>() .setInputCols(stringEncoder.getOutputCols ++ numCols) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"features"</span></span>)</code> </pre> <br><p>  Nous allons maintenant utiliser le boost de gradient fourni avec MMLSpark - LightGBM, qui est inclus dans le "Big Three" des meilleures impl√©mentations de cet algorithme avec XGBoost et CatBoost.  Il fonctionne beaucoup plus rapidement, mieux et plus stable que l'impl√©mentation GBM de SparkML (m√™me en tenant compte du fait que le port JVM est toujours en d√©veloppement actif): </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> catColIndices = <span class="hljs-type"><span class="hljs-type">Array</span></span>(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> lgbClf = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">LightGBMClassifier</span></span>() .setFeaturesCol(<span class="hljs-string"><span class="hljs-string">"features"</span></span>) .setLabelCol(<span class="hljs-string"><span class="hljs-string">"Survived"</span></span>) .setProbabilityCol(<span class="hljs-string"><span class="hljs-string">"predictedProb"</span></span>) .setPredictionCol(<span class="hljs-string"><span class="hljs-string">"predictedLabel"</span></span>) .setRawPredictionCol(<span class="hljs-string"><span class="hljs-string">"rawPrediction"</span></span>) .setIsUnbalance(<span class="hljs-literal"><span class="hljs-literal">true</span></span>) .setCategoricalSlotIndexes(catColIndices) .setObjective(<span class="hljs-string"><span class="hljs-string">"binary"</span></span>)</code> </pre> <br><p>  <strong>Remarque:</strong> LightGBM prend en charge le travail avec des variables cat√©gorielles (presque comme catboost), nous lui avons donc indiqu√© √† l'avance o√π se trouvent les attributs de cat√©gorie dans notre vecteur, et lui-m√™me saura quoi faire avec eux et comment les coder. </p><br><div class="spoiler">  <b class="spoiler_title">En savoir plus sur les fonctionnalit√©s LightGBM pour Spark</b> <div class="spoiler_text"><ul><li>  Sur les n≈ìuds ex√©cutant RadHat LightGBM, toute version, √† l'exception de la toute derni√®re, plantera du fait qu'il <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">n'aime pas la</a> version <code>glibc</code> .  Cela a √©t√© r√©solu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©cemment</a> , cependant, lors de l'installation via Maven, MMLSpark extrait l'avant-derni√®re version de LightGBM lors de l'installation via Maven, vous devez donc ajouter la d√©pendance de la derni√®re version sur RadHat avec vos mains. </li><li>  LightGBM dans son travail cr√©e une socket sur le pilote pour la communication avec les dirigeants, et il le fait en utilisant le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>new java.net.ServerSocket(0)</code></a> , et donc un port al√©atoire des ports √©ph√©m√®res du syst√®me d'exploitation est utilis√©.  Si la plage de ports √©ph√©m√®res diff√®re de la plage de ports ouverts par le pare-feu, alors <del>  peut br√ªler beaucoup </del>  Vous pouvez obtenir un effet int√©ressant lorsque LightGBM fonctionne parfois (lorsque j'ai choisi un bon port), et parfois non.  Et il y aura des erreurs comme <code>ConnectionTimeOut</code> , qui peuvent √©galement indiquer, par exemple, l'option lorsque GC se bloque sur des cadres ou quelque chose comme √ßa.  En g√©n√©ral, ne r√©p√©tez pas mes erreurs. </li></ul></div></div><br><p>  Enfin, d√©clarons notre Pipeline: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> pipeline = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>() .setStages( <span class="hljs-type"><span class="hljs-type">Array</span></span>( missingImputer, nameTransformer, cabinsCountTransformer, numbersFromCabinTransformer, stringEncoder, assembler, lgbClf ) )</code> </pre> <br><h2 id="obuchenie">  La formation </h2><br><p>  Nous allons briser notre ensemble de formation en un train et un test et v√©rifier notre pipeline.  Ici, vous pouvez simplement √©valuer la commodit√© du pipeline, car il est compl√®tement ind√©pendant de la partition et garantit que nous appliquerons les m√™mes transformations pour former et tester, et tous les param√®tres de transformation seront appris sur le train: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> <span class="hljs-type"><span class="hljs-type">Array</span></span>(trainDF, testDF) = trainFiltered.randomSplit(<span class="hljs-type"><span class="hljs-type">Array</span></span>(<span class="hljs-number"><span class="hljs-number">0.8</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>)) println(<span class="hljs-string"><span class="hljs-string">s"Train rows: </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${trainDF.count}</span></span></span><span class="hljs-string">\nTest rows: </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${testDF.count}</span></span></span><span class="hljs-string">"</span></span>) <span class="hljs-comment"><span class="hljs-comment">// Train rows: 708 // Test rows: 158 val predictions = pipeline .fit(trainDF) .transform(testDF)</span></span></code> </pre> <br><p>  Pour un calcul pratique des m√©triques, nous utiliserons une autre classe de MMLSpark - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ComputeModelStatistics</a> : </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.microsoft.ml.spark.<span class="hljs-type"><span class="hljs-type">ComputeModelStatistics</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.microsoft.ml.spark.metrics.<span class="hljs-type"><span class="hljs-type">MetricConstants</span></span> <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> modelEvaluator = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">ComputeModelStatistics</span></span>() .setLabelCol(<span class="hljs-string"><span class="hljs-string">"Survived"</span></span>) .setScoresCol(<span class="hljs-string"><span class="hljs-string">"predictedProb"</span></span>) .setScoredLabelsCol(<span class="hljs-string"><span class="hljs-string">"predictedLabel"</span></span>) .setEvaluationMetric(<span class="hljs-type"><span class="hljs-type">MetricConstants</span></span>.<span class="hljs-type"><span class="hljs-type">ClassificationMetrics</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/webt/we/rc/ba/wercbac58qpt0hsygugtqqkhc3u.png"></p><br><p>  Pas mal, √©tant donn√© que nous n'avons pas modifi√© les param√®tres par d√©faut. </p><br><h2 id="podbor-giperparametrov">  S√©lection d'hyperparam√®tres </h2><br><p>  Pour s√©lectionner des hyperparam√®tres dans MMLSpark, il y a une chose sympa distincte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>TuneHyperparameters</code></a> , qui impl√©mente une recherche al√©atoire sur la grille.  Cependant, malheureusement, il ne prend pas encore en charge <code>Pipeline</code> , nous allons donc utiliser le SparkML <code>CrossValidator</code> habituel: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.ml.tuning.{<span class="hljs-type"><span class="hljs-type">ParamGridBuilder</span></span>, <span class="hljs-type"><span class="hljs-type">CrossValidator</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.ml.evaluation.<span class="hljs-type"><span class="hljs-type">BinaryClassificationEvaluator</span></span> <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> paramSpace = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">ParamGridBuilder</span></span>() .addGrid(lgbClf.maxDepth, <span class="hljs-type"><span class="hljs-type">Array</span></span>(<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) .addGrid(lgbClf.learningRate, <span class="hljs-type"><span class="hljs-type">Array</span></span>(<span class="hljs-number"><span class="hljs-number">0.05</span></span>, <span class="hljs-number"><span class="hljs-number">0.1</span></span>)) .addGrid(lgbClf.numIterations, <span class="hljs-type"><span class="hljs-type">Array</span></span>(<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">300</span></span>)) .build println(<span class="hljs-string"><span class="hljs-string">s"Size of ParamsGrid: </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${paramSpace.size}</span></span></span><span class="hljs-string">"</span></span>) <span class="hljs-comment"><span class="hljs-comment">// Size of ParamsGrid: 8 val crossValidator = new CrossValidator() .setEstimator(pipeline) .setEstimatorParamMaps(paramSpace) .setNumFolds(3) .setSeed(42L) .setEvaluator( new BinaryClassificationEvaluator() .setMetricName("areaUnderROC") .setLabelCol("Survived") .setRawPredictionCol("rawPrediction") ) val bestModel = crossValidator .fit(trainFiltered)</span></span></code> </pre> <br><p>  Malheureusement, je n'ai pas trouv√© de moyen pratique de voir les r√©sultats avec les param√®tres sur lesquels ils ont √©t√© obtenus.  Par cons√©quent, il est n√©cessaire d'utiliser des conceptions "monstrueuses": </p><br><pre> <code class="scala hljs">crossValidator .getEstimatorParamMaps .zip(bestModel.avgMetrics) .foreach(x =&gt; { println( <span class="hljs-string"><span class="hljs-string">"\n"</span></span> + x._1 .toSeq .foldLeft(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">StringBuilder</span></span>())( (a, b) =&gt; a .append(<span class="hljs-string"><span class="hljs-string">s"\n\t</span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${b.param.name}</span></span></span><span class="hljs-string"> : </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${b.value}</span></span></span><span class="hljs-string">"</span></span>)) .toString + <span class="hljs-string"><span class="hljs-string">s"\n\tMetric: </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${x._2}</span></span></span><span class="hljs-string">"</span></span> ) })</code> </pre> <br><p>  Ce qui nous donne quelque chose comme √ßa: <br><img src="https://habrastorage.org/webt/xl/li/o7/xllio7tbr67gq_wqolrqwzkzswu.png"></p><br><p>  Nous avons obtenu le meilleur r√©sultat en r√©duisant la vitesse d'apprentissage et en augmentant la profondeur des arbres.  Sur cette base, il serait possible d'ajuster l'espace de recherche et d'arriver √† un r√©sultat encore plus optimal, mais nous n'avons tout simplement pas un tel objectif. </p><br><h2 id="zaklyuchenie">  Conclusion </h2><br><p>  En fait, alors que MMLSpark a la version 0.17 et contient toujours des bogues distincts.  Mais de toutes les extensions Spark que j'ai vues, MMLSpark a √† mon avis la documentation la plus compl√®te et le processus d'installation et de mise en ≈ìuvre le plus compr√©hensible.  Microsoft ne l'a pas encore vraiment promu, il n'y avait qu'un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rapport sur les Databricks</a> , mais il s'agissait davantage de DeepLearning, et non des choses de routine sur lesquelles j'ai √©crit. </p><br><p>  Personnellement, dans nos t√¢ches, cette biblioth√®que m'a beaucoup aid√©, me permettant de parcourir un peu moins la jungle des sources Spark et de ne pas utiliser la r√©flexion pour acc√©der aux m√©thodes priv√©es [ml], et un de mes coll√®gues a trouv√© la biblioth√®que presque par accident.  Dans le m√™me temps, en raison du fait que la biblioth√®que est en d√©veloppement actif, la structure du fichier source <del>  bouillie pleine </del>  quelque peu d√©routant.  Eh bien, en raison du fait qu'il n'y a pas d'exemples sp√©ciaux ou d'autre documentation (√† l'exception de scaladoc nu), au d√©but, je devais explorer la source tout le temps. </p><br><p>  Par cons√©quent, j'esp√®re vraiment que ce mini-tutoriel (malgr√© toute son √©vidence et sa simplicit√©) sera utile √† quelqu'un et permettra d'√©conomiser beaucoup de temps et d'efforts! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr456668/">https://habr.com/ru/post/fr456668/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr456656/index.html">Le√ßons sur SDL 2: Le√ßon 4 - Etirement PNG</a></li>
<li><a href="../fr456658/index.html">Growth up: comment nous √©valuons les comp√©tences en √©quipe</a></li>
<li><a href="../fr456662/index.html">Comment √©conomiser de l'argent sur un th√©rapeute en utilisant le d√©veloppement pilot√© par les tests</a></li>
<li><a href="../fr456664/index.html">Qui poursuivre lorsqu'un robot perd votre argent</a></li>
<li><a href="../fr456666/index.html">WebTotem ou comment nous voulons rendre Internet plus s√ªr</a></li>
<li><a href="../fr456670/index.html">√Ä propos de la m√©thode d'authentification tr√®s espion</a></li>
<li><a href="../fr456672/index.html">Recettes Nginx: notifications asynchrones de PostgreSQL vers websocket</a></li>
<li><a href="../fr456674/index.html">De nouvelles opportunit√©s de promotion sur Facebook que vous ne connaissiez pas</a></li>
<li><a href="../fr456676/index.html">Connexion √† une application PHP distribu√©e</a></li>
<li><a href="../fr456680/index.html">Huit lois de d√©nomination dans la conception UX (partie 2)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🍴 🍙 🦕 Modelos de sequência 2 para sequência 🤶🏿 🌟 🙇🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Olá pessoal! 

 A segunda parte da tradução, que publicamos algumas semanas atrás, em preparação para o lançamento do segundo fluxo do curso "Cientist...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Modelos de sequência 2 para sequência</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/432302/"> Olá pessoal! <br><br>  A segunda parte da tradução, que publicamos algumas semanas atrás, em preparação para o lançamento do segundo fluxo do curso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">"Cientista de dados"</a> .  À frente é outro material interessante e uma lição aberta. <br><br>  Enquanto isso, fomos mais longe na selva de modelos. <br><br>  <b>Modelo de tradução neural</b> <br><br>  Embora o núcleo do modelo de sequência a sequência seja criado por funções de <code>tensorflow/tensorflow/python/ops/seq2seq.py</code> , ainda existem alguns truques usados ​​em nosso modelo de tradução em <code>models/tutorials/rnn/translate/seq2seq_model.py</code> , sobre vale a pena mencionar. <br><br><img src="https://habrastorage.org/webt/3z/s9/fy/3zs9fym7zcpeqweylxlqhknznko.png"><a name="habracut"></a><br><br>  <b>Softmax amostrado e projeção de saída</b> <br><br>  Como mencionado acima, queremos usar o softmax amostrado para trabalhar com um grande dicionário de saída.  Para decodificar, é necessário rastrear a projeção da saída.  A perda softmax amostrada e a projeção de saída são geradas pelo código a seguir em <code>seq2seq_model.py</code> . <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> num_samples &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> num_samples &lt; self.target_vocab_size: w_t = tf.get_variable(<span class="hljs-string"><span class="hljs-string">"proj_w"</span></span>, [self.target_vocab_size, size], dtype=dtype) w = tf.transpose(w_t) b = tf.get_variable(<span class="hljs-string"><span class="hljs-string">"proj_b"</span></span>, [self.target_vocab_size], dtype=dtype) output_projection = (w, b) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sampled_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(labels, inputs)</span></span></span><span class="hljs-function">:</span></span> labels = tf.reshape(labels, [<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) <span class="hljs-comment"><span class="hljs-comment"># We need to compute the sampled_softmax_loss using 32bit floats to # avoid numerical instabilities. local_w_t = tf.cast(w_t, tf.float32) local_b = tf.cast(b, tf.float32) local_inputs = tf.cast(inputs, tf.float32) return tf.cast( tf.nn.sampled_softmax_loss( weights=local_w_t, biases=local_b, labels=labels, inputs=local_inputs, num_sampled=num_samples, num_classes=self.target_vocab_size), dtype)</span></span></code> </pre><br>  Primeiro, observe que apenas criamos softmax amostrado se o número de amostras (512 por padrão) for menor que o tamanho do dicionário de destino.  Para dicionários menores que 512, é melhor usar a perda softmax padrão. <br><br>  Em seguida, crie uma projeção da saída.  Este é um par que consiste em uma matriz de pesos e um vetor de deslocamento.  Quando usada, a célula rnn retorna os vetores de forma do número de amostras de treinamento por <code>size</code> , e não o número de amostras de treinamento por <code>target_vocab_size</code> .  Para restaurar logits, você precisa multiplicá-lo pela matriz de pesos e adicionar um deslocamento, o que ocorre nas linhas 124-126 em <code>seq2seq_model.py</code> . <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> output_projection <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> b <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> xrange(len(buckets)): self.outputs[b] = [tf.matmul(output, output_projection[<span class="hljs-number"><span class="hljs-number">0</span></span>]) + output_projection[<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ...]</code> </pre> <br>  <b>Bucketing and padding</b> <br><br>  Além do softmax amostrado, nosso modelo de tradução também usa o <i>bucketing</i> , um método que permite gerenciar com eficiência frases de diferentes comprimentos.  Para começar, explique o problema.  Ao traduzir do inglês para o francês, temos sentenças em inglês de diferentes comprimentos L1 na entrada e sentenças em francês de diferentes comprimentos L1 na saída.  Como a sentença em inglês é transmitida como <code>encoder_inputs</code> e a sentença em francês é exibida como <code>decoder_inputs</code> (com o prefixo do símbolo GO), é necessário criar um modelo seq2seq para cada par (L1, L2 + 1) de comprimentos de sentenças em inglês e francês.  Como resultado, obtemos um gráfico enorme que consiste em muitos subgráficos semelhantes.  Por outro lado, podemos “preencher” cada frase com caracteres especiais do PAD.  E então precisamos de apenas um modelo seq2seq para comprimentos "compactados".  Mas esse modelo será ineficaz em frases curtas - você precisa codificar e decodificar muitos caracteres inúteis do PAD. <br><br>  Como um compromisso entre a criação de um gráfico para cada par de comprimentos e o preenchimento em um único comprimento, usamos um certo número de intervalos e preenchemos cada sentença pelo comprimento do grupo acima.  No <code>translate.py</code> , usamos os seguintes grupos por padrão. <br><br><pre> <code class="python hljs">buckets = [(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>), (<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">15</span></span>), (<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">25</span></span>), (<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">50</span></span>)]</code> </pre> <br><br>  Assim, se uma frase em inglês com 3 tokens chegar na entrada e a sentença francesa correspondente contiver 6 tokens na saída, eles irão para o primeiro grupo e serão preenchidos com o comprimento 5 na entrada do codificador e o comprimento 10 na entrada do decodificador.  E se houver 8 tokens na oferta em inglês e no francês correspondente 18, eles não pertencerão ao grupo (10, 15) e serão transferidos para o grupo (20, 25), ou seja, a oferta em inglês aumentará para 20 e a francesa para 25. <br><br>  Lembre-se de que, ao criar a entrada do decodificador, adicionamos o caractere <code>GO</code> especial à entrada.  Isso acontece na função <code>get_batch()</code> em <code>seq2seq_model.py</code> , que também inverte a sentença em inglês.  A inversão da entrada ajudou a melhorar os resultados do modelo de tradução neural de <a href="">Sutskever et al., 2014 (pdf).</a>  Para finalmente descobrir, imagine que a entrada seja “eu vou.”, Dividida em tokens <code>["I", "go", "."]</code> , E a saída é a frase "Je vais.", Dividida em tokens <code>["Je", "vais", "."]</code> .  Eles serão adicionados ao grupo (5, 10), com uma representação do codificador de entrada <code>[PAD PAD "." "go" "I"]</code>  <code>[PAD PAD "." "go" "I"]</code> e entrada do decodificador <code>[GO "Je" "vais" "." EOS PAD PAD PAD PAD PAD]</code>  <code>[GO "Je" "vais" "." EOS PAD PAD PAD PAD PAD]</code> . <br><br>  <b>Execute</b> <br><br>  Para treinar o modelo descrito acima, você precisará de um grande corpo anglo-francês.  Para treinamento, usaremos o corpo de 10 ^ 9 francês-inglês do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site WMT'15</a> e testaremos notícias no mesmo site como uma amostra de trabalho.  Os dois conjuntos de dados serão carregados no <code>train_dir</code> quando o próximo comando for executado. <br><br><pre> <code class="plaintext hljs">python translate.py --data_dir [your_data_directory] --train_dir [checkpoints_directory] --en_vocab_size=40000 --fr_vocab_size=40000</code> </pre> <br>  Você precisará de 18 GB de espaço no disco rígido e de várias horas para preparar o prédio de treinamento.  O caso é descompactado, os arquivos de dicionário são criados em <code>data_dir,</code> e <code>data_dir,</code> depois disso, o caso é tokenizado e convertido em identificadores inteiros.  Preste atenção aos parâmetros responsáveis ​​pelo tamanho do dicionário.  No exemplo acima, todas as palavras fora das 40.000 palavras usadas com mais freqüência serão convertidas em um token UNK que representa uma palavra desconhecida.  Assim, ao alterar o tamanho do dicionário, o binário reformará o alojamento pelo ID do token.  Após o início da preparação dos dados, o treinamento. <br><br>  Os valores especificados na <code>translate</code> são muito altos por padrão.  Modelos grandes que aprendem por muito tempo mostram bons resultados, mas isso pode levar muito tempo ou muita memória da GPU.  Você pode especificar um treino de modelo menor, como no exemplo abaixo. <br><br><pre> <code class="plaintext hljs">python translate.py --data_dir [your_data_directory] --train_dir [checkpoints_directory] --size=256 --num_layers=2 --steps_per_checkpoint=50</code> </pre> <br>  O comando acima treinará o modelo com duas camadas (há três por padrão), cada uma com 256 unidades (1024 por padrão), com um ponto de verificação a cada 50 etapas (200 por padrão).  Experimente essas opções para ver qual modelo de tamanho é adequado para sua GPU. <br><br>  Durante o treinamento, cada etapa do binário <code>steps_per_checkpoin</code> t fornecerá estatísticas sobre as etapas anteriores.  Com parâmetros padrão (3 camadas do tamanho 1024), a primeira mensagem é a seguinte: <br><br><pre> <code class="plaintext hljs">global step 200 learning rate 0.5000 step-time 1.39 perplexity 1720.62 eval: bucket 0 perplexity 184.97 eval: bucket 1 perplexity 248.81 eval: bucket 2 perplexity 341.64 eval: bucket 3 perplexity 469.04 global step 400 learning rate 0.5000 step-time 1.38 perplexity 379.89 eval: bucket 0 perplexity 151.32 eval: bucket 1 perplexity 190.36 eval: bucket 2 perplexity 227.46 eval: bucket 3 perplexity 238.66</code> </pre> <br>  Observe que cada etapa leva um pouco menos de 1,4 segundos, confundindo a amostra de treinamento e confundindo a amostra de trabalho em cada grupo.  Após cerca de 30 mil etapas, vemos como os perplexos das frases curtas (grupos 0 e 1) se tornam inequívocos.  O edifício de treinamento contém cerca de 22 milhões de frases, uma iteração (uma série de dados de treinamento) leva cerca de 340 mil etapas com o número de amostras de treinamento no valor de 64. Nesta fase, o modelo pode ser usado para traduzir frases em inglês para o francês usando a opção <code>--decode</code> . <br><br><pre> <code class="plaintext hljs">python translate.py --decode --data_dir [your_data_directory] --train_dir [checkpoints_directory] Reading model parameters from /tmp/translate.ckpt-340000 &gt; Who is the president of the United States? Qui est le président des États-Unis ?</code> </pre> <br>  <b>O que vem a seguir?</b> <br><br>  O exemplo acima mostra como criar seu próprio tradutor inglês-francês de ponta a ponta.  Execute-o e veja como o modelo funciona.  A qualidade é aceitável, mas um modelo de conversão ideal não pode ser obtido com parâmetros padrão.  Aqui estão algumas coisas que você pode melhorar. <br><br>  Primeiro, usamos a tokenização primitiva, a função básica do <code>basic_tokenizer</code> em <code>data_utils</code> .  Um tokenizador melhor pode ser encontrado no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site do WMT'15</a> .  Se você o usar e um dicionário grande, poderá obter melhores traduções. <br><br>  Além disso, os parâmetros padrão do modelo de conversão não estão configurados perfeitamente.  Você pode tentar alterar a velocidade de aprendizado, atenuação e inicialização dos pesos do modelo.  Você também pode substituir o <code>GradientDescentOptimizer</code> padrão no <code>seq2seq_model.py</code> por algo mais avançado, como o <code>AdagradOptimizer</code> .  Experimente e assista para obter melhores resultados! <br><br>  Finalmente, o modelo apresentado acima pode ser usado não apenas para tradução, mas também para qualquer outra tarefa de sequência a sequência.  Mesmo que você queira transformar uma sequência em uma árvore, por exemplo, gerar uma árvore de análise, esse modelo pode produzir resultados de última geração, como mostra <a href="">Vinyals &amp; Kaiser et al., 2014 (pdf)</a> .  Assim, você pode criar não apenas um tradutor, mas também um analisador, bot de bate-papo ou qualquer outro programa que desejar.  Experimente! <br><br>  Isso é tudo! <br><br>  Estamos aguardando seus comentários e perguntas aqui ou convidamos você a perguntar ao <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">professor</a> em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">uma aula aberta</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt432302/">https://habr.com/ru/post/pt432302/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt432292/index.html">Fontes variáveis ​​e paramétricas - ganha-ganha para designers</a></li>
<li><a href="../pt432294/index.html">Torre Ansible: modelos de trabalho de fluxo de trabalho</a></li>
<li><a href="../pt432296/index.html">O Google mantém você em um "balão de pesquisa" pessoal, mesmo que você saia da sua conta</a></li>
<li><a href="../pt432298/index.html">A Timeweb inseriu os 10 principais registradores de domínio na zona .RU</a></li>
<li><a href="../pt432300/index.html">Suporte, serviço, dor de cabeça e tudo-tudo-tudo</a></li>
<li><a href="../pt432304/index.html">Um neurocientista brilhante que pode ter a chave para criar verdadeira inteligência artificial</a></li>
<li><a href="../pt432306/index.html">Classe de armazenamento Memória no armazenamento - se você precisar ainda mais rápido</a></li>
<li><a href="../pt432308/index.html">Nível de ficção científica modular UE4: inspirado em Nostromo e Serenity</a></li>
<li><a href="../pt432310/index.html">Ktor como um cliente HTTP para Android</a></li>
<li><a href="../pt432312/index.html">Criar um mapa de formas do mapa de RF no Power BI</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
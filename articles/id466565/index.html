<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🦔 🏴󠁧󠁢󠁳󠁣󠁴󠁿 🖕🏼 Python + OpenCV + Keras: membuat pengenalan teks dalam setengah jam 🤙🏿 👩🏽‍⚖️ 🤩</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hai Habr. 

 Setelah bereksperimen dengan basis 60.000 angka tulisan tangan yang terkenal, MNIST, muncul pertanyaan logis apakah ada sesuatu yang seru...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Python + OpenCV + Keras: membuat pengenalan teks dalam setengah jam</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/466565/">  Hai Habr. <br><br>  Setelah bereksperimen dengan basis 60.000 angka tulisan tangan yang terkenal, MNIST, muncul pertanyaan logis apakah ada sesuatu yang serupa, tetapi dengan dukungan tidak hanya untuk angka, tetapi juga untuk huruf.  Ternyata, ada, dan disebut basis seperti itu, seperti yang Anda duga, Extended MNIST (EMNIST). <br><br>  Jika ada yang tertarik bagaimana menggunakan database ini Anda dapat membuat pengenalan teks sederhana, selamat datang di cat. <br><br><img src="https://habrastorage.org/webt/kq/bl/4r/kqbl4rtgmtvz1xl50tzbulmdmlw.png"><br><a name="habracut"></a><br>  <i>Catatan</i> : contoh ini eksperimental dan mendidik, saya hanya tertarik untuk melihat apa yang terjadi.  Saya tidak berencana dan tidak berencana untuk melakukan FineReader kedua, jadi banyak hal di sini, tentu saja, tidak dilaksanakan.  Karenanya, klaim dengan gaya “mengapa,” “sudah lebih baik,” dll., Tidak diterima.  Mungkin sudah ada pustaka OCR siap pakai untuk Python, tapi itu menarik untuk melakukannya sendiri.  Ngomong-ngomong, bagi mereka yang ingin melihat bagaimana FineReader asli dibuat, ada dua artikel di blog mereka di Habr pada tahun 2014: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">1</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">2</a> (tapi tentu saja, tanpa kode sumber dan detail, seperti di blog perusahaan mana pun).  Baiklah, mari kita mulai, semuanya terbuka di sini dan semuanya open source. <br><br>  Sebagai contoh, kami akan mengambil teks biasa.  Ini satu: <br><br><h3>  Neraka dunia </h3><br>  Dan mari kita lihat apa yang bisa dilakukan dengannya. <br><br><h2>  Memecah teks menjadi huruf </h2><br>  Langkah pertama adalah memecah teks menjadi huruf-huruf terpisah.  OpenCV berguna untuk ini, lebih tepatnya fungsi findContours-nya. <br><br>  Buka gambar (cv2.imread), terjemahkan ke dalam b / w (cv2.cvtColor + cv2.threshold), sedikit meningkat (cv2.erode) dan temukan garis besarnya. <br><br><pre><code class="python hljs">image_file = <span class="hljs-string"><span class="hljs-string">"text.png"</span></span> img = cv2.imread(image_file) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>, cv2.THRESH_BINARY) img_erode = cv2.erode(thresh, np.ones((<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), np.uint8), iterations=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Get contours contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) output = img.copy() for idx, contour in enumerate(contours): (x, y, w, h) = cv2.boundingRect(contour) # print("R", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx]) # hierarchy[i][0]: the index of the next contour of the same level # hierarchy[i][1]: the index of the previous contour of the same level # hierarchy[i][2]: the index of the first child # hierarchy[i][3]: the index of the parent if hierarchy[0][idx][3] == 0: cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1) cv2.imshow("Input", img) cv2.imshow("Enlarged", img_erode) cv2.imshow("Output", output) cv2.waitKey(0)</span></span></code> </pre> <br>  Kami mendapatkan hierarki hierarki kontur (parameter cv2.RETR_TREE).  Pertama datang garis besar umum dari gambar, kemudian garis besar dari surat-surat, kemudian garis besar bagian dalam.  Kami hanya perlu garis besar surat-surat, jadi saya memeriksa bahwa "garis besar" adalah garis besar keseluruhan.  Ini adalah pendekatan yang disederhanakan, dan untuk pemindaian nyata ini mungkin tidak berfungsi, meskipun tidak penting untuk mengenali tangkapan layar. <br><br>  Hasil: <br><br><img src="https://habrastorage.org/webt/7j/zi/pg/7jzipgqvc9ebvxgu2j7c_ubr-rw.png"><br><br>  Langkah selanjutnya adalah menyimpan setiap huruf, setelah sebelumnya menskalanya menjadi 28x28 persegi (dalam format inilah database MNIST disimpan).  OpenCV dibangun atas dasar numpy, sehingga kita dapat menggunakan fungsi bekerja dengan array untuk memotong dan menskala. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">letters_extract</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image_file: str, out_size=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">28</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> -&gt; List[Any]:</span></span> img = cv2.imread(image_file) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">255</span></span>, cv2.THRESH_BINARY) img_erode = cv2.erode(thresh, np.ones((<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), np.uint8), iterations=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Get contours contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) output = img.copy() letters = [] for idx, contour in enumerate(contours): (x, y, w, h) = cv2.boundingRect(contour) # print("R", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx]) # hierarchy[i][0]: the index of the next contour of the same level # hierarchy[i][1]: the index of the previous contour of the same level # hierarchy[i][2]: the index of the first child # hierarchy[i][3]: the index of the parent if hierarchy[0][idx][3] == 0: cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1) letter_crop = gray[y:y + h, x:x + w] # print(letter_crop.shape) # Resize letter canvas to square size_max = max(w, h) letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8) if w &gt; h: # Enlarge image top-bottom # ------ # ====== # ------ y_pos = size_max//2 - h//2 letter_square[y_pos:y_pos + h, 0:w] = letter_crop elif w &lt; h: # Enlarge image left-right # --||-- x_pos = size_max//2 - w//2 letter_square[0:h, x_pos:x_pos + w] = letter_crop else: letter_square = letter_crop # Resize letter to 28x28 and add letter and its X-coordinate letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA))) # Sort array in place by X-coordinate letters.sort(key=lambda x: x[0], reverse=False) return letters</span></span></code> </pre><br>  Pada akhirnya, kami mengurutkan huruf berdasarkan koordinat X, seperti yang Anda lihat, kami menyimpan hasilnya dalam bentuk tuple (x, w, letter), sehingga spasi dapat dipilih dari spasi di antara huruf-huruf. <br><br>  Pastikan semuanya berfungsi: <br><br><pre> <code class="python hljs">cv2.imshow(<span class="hljs-string"><span class="hljs-string">"0"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.imshow(<span class="hljs-string"><span class="hljs-string">"1"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.imshow(<span class="hljs-string"><span class="hljs-string">"2"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">2</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.imshow(<span class="hljs-string"><span class="hljs-string">"3"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">3</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.imshow(<span class="hljs-string"><span class="hljs-string">"4"</span></span>, letters[<span class="hljs-number"><span class="hljs-number">4</span></span>][<span class="hljs-number"><span class="hljs-number">2</span></span>]) cv2.waitKey(<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/j-/uw/yh/j-uwyhhh8l0yrapth5u6fy9na0u.png"><br><br>  Surat siap untuk dikenali, kami akan mengenalinya menggunakan jaringan convolutional - jenis jaringan ini sangat cocok untuk tugas-tugas seperti itu. <br><br><h2>  Jaringan Saraf Tiruan (CNN) untuk pengakuan </h2><br>  Dataset sumber EMNIST memiliki 62 karakter berbeda (A..Z, 0..9, dll.): <br><br><pre> <code class="python hljs">emnist_labels = [<span class="hljs-number"><span class="hljs-number">48</span></span>, <span class="hljs-number"><span class="hljs-number">49</span></span>, <span class="hljs-number"><span class="hljs-number">50</span></span>, <span class="hljs-number"><span class="hljs-number">51</span></span>, <span class="hljs-number"><span class="hljs-number">52</span></span>, <span class="hljs-number"><span class="hljs-number">53</span></span>, <span class="hljs-number"><span class="hljs-number">54</span></span>, <span class="hljs-number"><span class="hljs-number">55</span></span>, <span class="hljs-number"><span class="hljs-number">56</span></span>, <span class="hljs-number"><span class="hljs-number">57</span></span>, <span class="hljs-number"><span class="hljs-number">65</span></span>, <span class="hljs-number"><span class="hljs-number">66</span></span>, <span class="hljs-number"><span class="hljs-number">67</span></span>, <span class="hljs-number"><span class="hljs-number">68</span></span>, <span class="hljs-number"><span class="hljs-number">69</span></span>, <span class="hljs-number"><span class="hljs-number">70</span></span>, <span class="hljs-number"><span class="hljs-number">71</span></span>, <span class="hljs-number"><span class="hljs-number">72</span></span>, <span class="hljs-number"><span class="hljs-number">73</span></span>, <span class="hljs-number"><span class="hljs-number">74</span></span>, <span class="hljs-number"><span class="hljs-number">75</span></span>, <span class="hljs-number"><span class="hljs-number">76</span></span>, <span class="hljs-number"><span class="hljs-number">77</span></span>, <span class="hljs-number"><span class="hljs-number">78</span></span>, <span class="hljs-number"><span class="hljs-number">79</span></span>, <span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">81</span></span>, <span class="hljs-number"><span class="hljs-number">82</span></span>, <span class="hljs-number"><span class="hljs-number">83</span></span>, <span class="hljs-number"><span class="hljs-number">84</span></span>, <span class="hljs-number"><span class="hljs-number">85</span></span>, <span class="hljs-number"><span class="hljs-number">86</span></span>, <span class="hljs-number"><span class="hljs-number">87</span></span>, <span class="hljs-number"><span class="hljs-number">88</span></span>, <span class="hljs-number"><span class="hljs-number">89</span></span>, <span class="hljs-number"><span class="hljs-number">90</span></span>, <span class="hljs-number"><span class="hljs-number">97</span></span>, <span class="hljs-number"><span class="hljs-number">98</span></span>, <span class="hljs-number"><span class="hljs-number">99</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">101</span></span>, <span class="hljs-number"><span class="hljs-number">102</span></span>, <span class="hljs-number"><span class="hljs-number">103</span></span>, <span class="hljs-number"><span class="hljs-number">104</span></span>, <span class="hljs-number"><span class="hljs-number">105</span></span>, <span class="hljs-number"><span class="hljs-number">106</span></span>, <span class="hljs-number"><span class="hljs-number">107</span></span>, <span class="hljs-number"><span class="hljs-number">108</span></span>, <span class="hljs-number"><span class="hljs-number">109</span></span>, <span class="hljs-number"><span class="hljs-number">110</span></span>, <span class="hljs-number"><span class="hljs-number">111</span></span>, <span class="hljs-number"><span class="hljs-number">112</span></span>, <span class="hljs-number"><span class="hljs-number">113</span></span>, <span class="hljs-number"><span class="hljs-number">114</span></span>, <span class="hljs-number"><span class="hljs-number">115</span></span>, <span class="hljs-number"><span class="hljs-number">116</span></span>, <span class="hljs-number"><span class="hljs-number">117</span></span>, <span class="hljs-number"><span class="hljs-number">118</span></span>, <span class="hljs-number"><span class="hljs-number">119</span></span>, <span class="hljs-number"><span class="hljs-number">120</span></span>, <span class="hljs-number"><span class="hljs-number">121</span></span>, <span class="hljs-number"><span class="hljs-number">122</span></span>]</code> </pre> <br>  Sebuah jaringan saraf, dengan demikian, memiliki 62 output, pada input akan menerima 28x28 gambar, setelah pengakuan "1" akan berada pada output jaringan yang sesuai. <br><br>  Buat model jaringan. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> optimizers <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SGD, RMSprop, Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.constraints <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> maxnorm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">emnist_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model = Sequential() model.add(Convolution2D(filters=<span class="hljs-number"><span class="hljs-number">32</span></span>, kernel_size=(<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Convolution2D(filters=<span class="hljs-number"><span class="hljs-number">64</span></span>, kernel_size=(<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(MaxPooling2D(pool_size=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.25</span></span>)) model.add(Flatten()) model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)) model.add(Dense(len(emnist_labels), activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adadelta'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br>  Seperti yang Anda lihat, ini adalah jaringan konvolusional klasik yang menyoroti fitur-fitur tertentu dari gambar (jumlah filter 32 dan 64), ke "output" yang terhubung ke jaringan MLP "linear", yang membentuk hasil akhir. <br><br><h2>  Pelatihan jaringan saraf </h2><br>  Kami lolos ke pelatihan tahap jaringan terpanjang.  Untuk melakukan ini, kami mengambil basis data EMNIST, yang dapat diunduh <a href="">dari tautan</a> (ukuran arsip 536Mb). <br><br>  Untuk membaca database, gunakan perpustakaan idx2numpy.  Kami akan menyiapkan data untuk pelatihan dan validasi. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> idx2numpy emnist_path = <span class="hljs-string"><span class="hljs-string">'/home/Documents/TestApps/keras/emnist/'</span></span> X_train = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string"><span class="hljs-string">'emnist-byclass-train-images-idx3-ubyte'</span></span>) y_train = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string"><span class="hljs-string">'emnist-byclass-train-labels-idx1-ubyte'</span></span>) X_test = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string"><span class="hljs-string">'emnist-byclass-test-images-idx3-ubyte'</span></span>) y_test = idx2numpy.convert_from_file(emnist_path + <span class="hljs-string"><span class="hljs-string">'emnist-byclass-test-labels-idx1-ubyte'</span></span>) X_train = np.reshape(X_train, (X_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) X_test = np.reshape(X_test, (X_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, len(emnist_labels)) k = <span class="hljs-number"><span class="hljs-number">10</span></span> X_train = X_train[:X_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] // k] y_train = y_train[:y_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] // k] X_test = X_test[:X_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] // k] y_test = y_test[:y_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] // k] <span class="hljs-comment"><span class="hljs-comment"># Normalize X_train = X_train.astype(np.float32) X_train /= 255.0 X_test = X_test.astype(np.float32) X_test /= 255.0 x_train_cat = keras.utils.to_categorical(y_train, len(emnist_labels)) y_test_cat = keras.utils.to_categorical(y_test, len(emnist_labels))</span></span></code> </pre><br>  Kami telah menyiapkan dua set untuk pelatihan dan validasi.  Karakter itu sendiri adalah array biasa yang mudah ditampilkan: <br><br><img src="https://habrastorage.org/webt/lb/uj/yt/lbujytoizk2gxviahqxz5emvgay.png"><br><br>  Kami juga hanya menggunakan 1/10 dataset untuk pelatihan (parameter k), jika tidak, prosesnya akan memakan waktu setidaknya 10 jam. <br><br>  Kami memulai pelatihan jaringan, pada akhir proses kami menyimpan model terlatih ke disk. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Set a learning rate reduction learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001) # Required for learning_rate_reduction: keras.backend.get_session().run(tf.global_variables_initializer()) model.fit(X_train, x_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction], batch_size=64, epochs=30) model.save('emnist_letters.h5')</span></span></code> </pre> <br>  Proses pembelajaran itu sendiri memakan waktu sekitar setengah jam: <br><br><img src="https://habrastorage.org/webt/vu/xv/_s/vuxv_s6hsxg1q0gxcqapd0o3bv8.png"><br><br>  Ini perlu dilakukan hanya sekali, maka kita akan menggunakan file model yang sudah disimpan.  Ketika pelatihan selesai, semuanya sudah siap, Anda dapat mengenali teks. <br><br><h2>  Pengakuan </h2><br>  Untuk pengakuan, kami memuat model dan memanggil fungsi predict_classes. <br><br><pre> <code class="python hljs">model = keras.models.load_model(<span class="hljs-string"><span class="hljs-string">'emnist_letters.h5'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">emnist_predict_img</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, img)</span></span></span><span class="hljs-function">:</span></span> img_arr = np.expand_dims(img, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) img_arr = <span class="hljs-number"><span class="hljs-number">1</span></span> - img_arr/<span class="hljs-number"><span class="hljs-number">255.0</span></span> img_arr[<span class="hljs-number"><span class="hljs-number">0</span></span>] = np.rot90(img_arr[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">3</span></span>) img_arr[<span class="hljs-number"><span class="hljs-number">0</span></span>] = np.fliplr(img_arr[<span class="hljs-number"><span class="hljs-number">0</span></span>]) img_arr = img_arr.reshape((<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) result = model.predict_classes([img_arr]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> chr(emnist_labels[result[<span class="hljs-number"><span class="hljs-number">0</span></span>]])</code> </pre> <br>  Ternyata, gambar dalam dataset awalnya diputar, jadi kita harus memutar gambar sebelum pengenalan. <br><br>  Fungsi terakhir, yang menerima file dengan gambar pada input dan memberikan garis pada output, hanya membutuhkan 10 baris kode: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">img_to_str</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model: Any, image_file: str)</span></span></span><span class="hljs-function">:</span></span> letters = letters_extract(image_file) s_out = <span class="hljs-string"><span class="hljs-string">""</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(letters)): dn = letters[i+<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] - letters[i][<span class="hljs-number"><span class="hljs-number">0</span></span>] - letters[i][<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> i &lt; len(letters) - <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> s_out += emnist_predict_img(model, letters[i][<span class="hljs-number"><span class="hljs-number">2</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (dn &gt; letters[i][<span class="hljs-number"><span class="hljs-number">1</span></span>]/<span class="hljs-number"><span class="hljs-number">4</span></span>): s_out += <span class="hljs-string"><span class="hljs-string">' '</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s_out</code> </pre> <br>  Di sini kita menggunakan lebar karakter yang disimpan sebelumnya untuk menambahkan spasi jika jarak antar huruf lebih dari 1/4 karakter. <br><br>  Contoh penggunaan: <br><pre> <code class="python hljs">model = keras.models.load_model(<span class="hljs-string"><span class="hljs-string">'emnist_letters.h5'</span></span>) s_out = img_to_str(model, <span class="hljs-string"><span class="hljs-string">"hello_world.png"</span></span>) print(s_out)</code> </pre><br>  Hasil: <br><img src="https://habrastorage.org/webt/ck/r5/iq/ckr5iqlfoiokza60cleu3w1x-hg.png"><br><br>  Fitur yang lucu adalah bahwa jaringan saraf "membingungkan" huruf "O" dan angka "0", yang, bagaimanapun, tidak mengejutkan karena  Set asli EMNIST berisi huruf dan angka <i>tulisan tangan</i> yang tidak persis seperti yang dicetak.  Idealnya, untuk mengenali teks layar, Anda perlu menyiapkan satu set terpisah berdasarkan font layar, dan sudah melatih jaringan saraf di atasnya. <br><br><h2>  Kesimpulan </h2><br>  Seperti yang Anda lihat, bukan para dewa yang membakar pot, dan apa yang sebelumnya tampak sebagai "sihir" dengan bantuan perpustakaan modern dibuat cukup sederhana. <br><br>  Karena Python adalah lintas-platform, kode akan berfungsi di mana saja, di Windows, Linux, dan OSX.  Like Keras porting ke iOS / Android, jadi secara teoritis, model yang terlatih juga dapat digunakan pada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">perangkat seluler</a> . <br><br>  Bagi mereka yang ingin bereksperimen sendiri, kode sumbernya ada di bawah spoiler. <br><br><div class="spoiler">  <b class="spoiler_title">keras_emnist.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Code source: dmitryelj@gmail.com import os # Force CPU # os.environ["CUDA_VISIBLE_DEVICES"] = "-1" # Debug messages # 0 = all messages are logged (default behavior) # 1 = INFO messages are not printed # 2 = INFO and WARNING messages are not printed # 3 = INFO, WARNING, and ERROR messages are not printed os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' import cv2 import imghdr import numpy as np import pathlib from tensorflow import keras from keras.models import Sequential from keras import optimizers from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization from keras.optimizers import SGD, RMSprop, Adam from keras import backend as K from keras.constraints import maxnorm import tensorflow as tf from scipy import io as spio import idx2numpy # sudo pip3 install idx2numpy from matplotlib import pyplot as plt from typing import * import time # Dataset: # https://www.nist.gov/node/1298471/emnist-dataset # https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip def cnn_print_digit(d): print(d.shape) for x in range(28): s = "" for y in range(28): s += "{0:.1f} ".format(d[28*y + x]) print(s) def cnn_print_digit_2d(d): print(d.shape) for y in range(d.shape[0]): s = "" for x in range(d.shape[1]): s += "{0:.1f} ".format(d[x][y]) print(s) emnist_labels = [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122] def emnist_model(): model = Sequential() model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='valid', input_shape=(28, 28, 1), activation='relu')) model.add(Convolution2D(filters=64, kernel_size=(3, 3), activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(512, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(len(emnist_labels), activation='softmax')) model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy']) return model def emnist_model2(): model = Sequential() # In Keras there are two options for padding: same or valid. Same means we pad with the number on the edge and valid means no padding. model.add(Convolution2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28, 28, 1))) model.add(MaxPooling2D((2, 2))) model.add(Convolution2D(64, (3, 3), activation='relu', padding='same')) model.add(MaxPooling2D((2, 2))) model.add(Convolution2D(128, (3, 3), activation='relu', padding='same')) model.add(MaxPooling2D((2, 2))) # model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) # model.add(MaxPooling2D((2, 2))) ## model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(512, activation='relu')) model.add(Dropout(0.5)) model.add(Dense(len(emnist_labels), activation='softmax')) model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy']) return model def emnist_model3(): model = Sequential() model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', input_shape=(28, 28, 1), activation='relu')) model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25)) model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')) model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')) model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) model.add(Dropout(0.25)) model.add(Flatten()) model.add(Dense(512, activation="relu")) model.add(Dropout(0.5)) model.add(Dense(len(emnist_labels), activation="softmax")) model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), metrics=['accuracy']) return model def emnist_train(model): t_start = time.time() emnist_path = 'D:\\Temp\\1\\' X_train = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-train-images-idx3-ubyte') y_train = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-train-labels-idx1-ubyte') X_test = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-test-images-idx3-ubyte') y_test = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-test-labels-idx1-ubyte') X_train = np.reshape(X_train, (X_train.shape[0], 28, 28, 1)) X_test = np.reshape(X_test, (X_test.shape[0], 28, 28, 1)) print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, len(emnist_labels)) # Test: k = 10 X_train = X_train[:X_train.shape[0] // k] y_train = y_train[:y_train.shape[0] // k] X_test = X_test[:X_test.shape[0] // k] y_test = y_test[:y_test.shape[0] // k] # Normalize X_train = X_train.astype(np.float32) X_train /= 255.0 X_test = X_test.astype(np.float32) X_test /= 255.0 x_train_cat = keras.utils.to_categorical(y_train, len(emnist_labels)) y_test_cat = keras.utils.to_categorical(y_test, len(emnist_labels)) # Set a learning rate reduction learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001) # Required for learning_rate_reduction: keras.backend.get_session().run(tf.global_variables_initializer()) model.fit(X_train, x_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction], batch_size=64, epochs=30) print("Training done, dT:", time.time() - t_start) def emnist_predict(model, image_file): img = keras.preprocessing.image.load_img(image_file, target_size=(28, 28), color_mode='grayscale') emnist_predict_img(model, img) def emnist_predict_img(model, img): img_arr = np.expand_dims(img, axis=0) img_arr = 1 - img_arr/255.0 img_arr[0] = np.rot90(img_arr[0], 3) img_arr[0] = np.fliplr(img_arr[0]) img_arr = img_arr.reshape((1, 28, 28, 1)) result = model.predict_classes([img_arr]) return chr(emnist_labels[result[0]]) def letters_extract(image_file: str, out_size=28): img = cv2.imread(image_file) gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY) img_erode = cv2.erode(thresh, np.ones((3, 3), np.uint8), iterations=1) # Get contours contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) output = img.copy() letters = [] for idx, contour in enumerate(contours): (x, y, w, h) = cv2.boundingRect(contour) # print("R", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx]) # hierarchy[i][0]: the index of the next contour of the same level # hierarchy[i][1]: the index of the previous contour of the same level # hierarchy[i][2]: the index of the first child # hierarchy[i][3]: the index of the parent if hierarchy[0][idx][3] == 0: cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1) letter_crop = gray[y:y + h, x:x + w] # print(letter_crop.shape) # Resize letter canvas to square size_max = max(w, h) letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8) if w &gt; h: # Enlarge image top-bottom # ------ # ====== # ------ y_pos = size_max//2 - h//2 letter_square[y_pos:y_pos + h, 0:w] = letter_crop elif w &lt; h: # Enlarge image left-right # --||-- x_pos = size_max//2 - w//2 letter_square[0:h, x_pos:x_pos + w] = letter_crop else: letter_square = letter_crop # Resize letter to 28x28 and add letter and its X-coordinate letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA))) # Sort array in place by X-coordinate letters.sort(key=lambda x: x[0], reverse=False) # cv2.imshow("Input", img) # # cv2.imshow("Gray", thresh) # cv2.imshow("Enlarged", img_erode) # cv2.imshow("Output", output) # cv2.imshow("0", letters[0][2]) # cv2.imshow("1", letters[1][2]) # cv2.imshow("2", letters[2][2]) # cv2.imshow("3", letters[3][2]) # cv2.imshow("4", letters[4][2]) # cv2.waitKey(0) return letters def img_to_str(model: Any, image_file: str): letters = letters_extract(image_file) s_out = "" for i in range(len(letters)): dn = letters[i+1][0] - letters[i][0] - letters[i][1] if i &lt; len(letters) - 1 else 0 s_out += emnist_predict_img(model, letters[i][2]) if (dn &gt; letters[i][1]/4): s_out += ' ' return s_out if __name__ == "__main__": # model = emnist_model() # emnist_train(model) # model.save('emnist_letters.h5') model = keras.models.load_model('emnist_letters.h5') s_out = img_to_str(model, "hello_world.png") print(s_out)</span></span></code> </pre><br></div></div><br>  Seperti biasa, semua percobaan berhasil. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id466565/">https://habr.com/ru/post/id466565/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id466553/index.html">6 pelajaran dari menemukan solusi untuk masalah besar di gitlab.com. Bagian 2</a></li>
<li><a href="../id466555/index.html">6 pelajaran dari menemukan solusi untuk masalah besar di gitlab.com. Bagian 1</a></li>
<li><a href="../id466559/index.html">Biarkan adalah Var baru</a></li>
<li><a href="../id466561/index.html">Butuh pilihan yang benar-benar transparan? - Saya memilikinya</a></li>
<li><a href="../id466563/index.html">KOST: apa yang termasuk dalam tumpukan teknologi baru untuk mengembangkan aplikasi cloud</a></li>
<li><a href="../id466567/index.html">Toolkit untuk penyedia: webinar tematik tentang sistem untuk bekerja dengan lalu lintas dan konfigurasi mereka</a></li>
<li><a href="../id466569/index.html">IPO di Bursa Moskow: mengapa diperlukan, siapa yang melakukannya, dan cara membeli saham</a></li>
<li><a href="../id466571/index.html">Tesseract OCR tips - buat kosa kata Anda sendiri untuk meningkatkan kinerja OCR</a></li>
<li><a href="../id466573/index.html">Pertanyaan untuk majikan di masa depan</a></li>
<li><a href="../id466575/index.html">Melewati daftar dua dimensi dari python ke DLL</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤑 🧑🏾‍🤝‍🧑🏻 🙀 Comme Redash l'a remarqué et a corrigé un problème qui provoquait une dégradation des performances du code Python 👨‍👧‍👦 🕖 📸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Redash a récemment commencé à passer d'un système d'exécution de tâches à un autre. À savoir, ils ont commencé la transition de Céleri à RQ. À la prem...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comme Redash l'a remarqué et a corrigé un problème qui provoquait une dégradation des performances du code Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/475250/">  Redash a récemment commencé à passer d'un système d'exécution de tâches à un autre.  À savoir, ils ont commencé la transition de Céleri à RQ.  À la première étape, seules les tâches qui n'exécutent pas directement les demandes ont été transférées vers la nouvelle plateforme.  Parmi ces tâches figurent l'envoi d'e-mails, la détermination des demandes à mettre à jour, l'enregistrement des événements utilisateur et d'autres tâches de support. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/0h/9y/wb/0h9ywbok79_xnw71erdzqpiydzq.jpeg"></a> <br><br>  Après avoir déployé tout cela, il a été remarqué que les employés de RQ ont besoin de beaucoup plus de ressources informatiques pour résoudre le même volume de tâches que Celery avait l'habitude de résoudre. <br><br>  Le matériel, dont nous publions la traduction aujourd'hui, est consacré à l'histoire de la façon dont Redash a découvert la cause du problème et l'a résolu. <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Quelques mots sur les différences entre le céleri et le RQ</font> </h2><br>  Le céleri et RQ ont le concept de travailleurs de processus.  Là et là pour l'organisation de l'exécution parallèle des tâches grâce à la création de fourches.  Lorsque le travailleur Celery démarre, plusieurs processus fork sont créés, chacun traitant de manière autonome les tâches.  Dans le cas de RQ, l'instance de l'ouvrier contient un seul sous-processus (appelé "cheval de bataille"), qui effectue une tâche, puis est détruit.  Lorsque le travailleur télécharge la tâche suivante de la file d'attente, il crée un nouveau «cheval de bataille». <br><br>  Lorsque vous travaillez avec RQ, vous pouvez obtenir le même niveau de parallélisme que lorsque vous travaillez avec Celery, simplement en exécutant plus de processus de travail.  Cependant, il existe une différence subtile entre le céleri et le RQ.  Dans Celery, un travailleur crée de nombreuses instances de sous-processus au démarrage, puis les utilise à plusieurs reprises pour effectuer de nombreuses tâches.  Et dans le cas de RQ, pour chaque travail, vous devez créer une nouvelle fourche.  Les deux approches ont leurs avantages et leurs inconvénients, mais ici, nous n'en parlerons pas. <br><br><h2>  <font color="#3AC1EF">Mesure du rendement</font> </h2><br>  Avant de commencer le profilage, j'ai décidé de mesurer les performances du système en découvrant combien de temps le conteneur de travail a besoin pour traiter 1000 travaux.  J'ai décidé de me concentrer sur la tâche <code>record_event</code> , car il s'agit d'une opération légère courante.  Pour mesurer les performances, j'ai utilisé la commande <code>time</code> .  Cela a nécessité quelques modifications au code du projet: <br><br><ol><li>  Pour mesurer les performances de l'exécution de 1000 tâches, j'ai décidé d'utiliser le mode batch RQ, dans lequel, après le traitement des tâches, le processus est quitté. </li><li>  Je voulais éviter d'influencer mes mesures avec d'autres tâches qui auraient pu être planifiées à l'époque où je mesurais les performances du système.  J'ai donc déplacé <code>record_event</code> vers une file d'attente distincte appelée <code>benchmark</code> , en remplaçant <code>@job('default')</code> par <code>@job('benchmark')</code> .  Cela a été fait juste avant la <code>record_event</code> dans <code>tasks/general.py</code> . </li></ol><br>  Il était maintenant possible de commencer les mesures.  Pour commencer, je voulais savoir combien de temps il faut pour démarrer et arrêter un travailleur sans charge.  Ce temps pourrait être soustrait des résultats finaux obtenus ultérieurement. <br><br><pre> <code class="python hljs">$ docker-compose <span class="hljs-keyword"><span class="hljs-keyword">exec</span></span> worker bash -c <span class="hljs-string"><span class="hljs-string">"time ./manage.py rq workers 4 benchmark"</span></span> real <span class="hljs-number"><span class="hljs-number">0</span></span>m14<span class="hljs-number"><span class="hljs-number">.728</span></span>s user <span class="hljs-number"><span class="hljs-number">0</span></span>m6<span class="hljs-number"><span class="hljs-number">.810</span></span>s sys <span class="hljs-number"><span class="hljs-number">0</span></span>m2<span class="hljs-number"><span class="hljs-number">.750</span></span>s</code> </pre> <br>  Il a fallu 14,7 secondes pour initialiser le travailleur sur mon ordinateur.  Je m'en souviens. <br><br>  Ensuite, j'ai mis 1000 <code>record_event</code> test <code>record_event</code> dans la file d'attente de <code>benchmark</code> : <br><br><pre> <code class="python hljs">$ docker-compose run --rm server manage shell &lt;&lt;&lt; <span class="hljs-string"><span class="hljs-string">"from redash.tasks.general import record_event; [record_event.delay({ 'action': 'create', 'timestamp': 0, 'org_id': 1, 'user_id': 1, 'object_id': 0, 'object_type': 'dummy' }) for i in range(1000)]"</span></span></code> </pre> <br>  Après cela, j'ai démarré le système de la même manière qu'auparavant et j'ai découvert combien de temps il faut pour traiter 1000 tâches. <br><br><pre> <code class="python hljs">$ docker-compose <span class="hljs-keyword"><span class="hljs-keyword">exec</span></span> worker bash -c <span class="hljs-string"><span class="hljs-string">"time ./manage.py rq workers 4 benchmark"</span></span> real <span class="hljs-number"><span class="hljs-number">1</span></span>m57<span class="hljs-number"><span class="hljs-number">.332</span></span>s user <span class="hljs-number"><span class="hljs-number">1</span></span>m11<span class="hljs-number"><span class="hljs-number">.320</span></span>s sys <span class="hljs-number"><span class="hljs-number">0</span></span>m27<span class="hljs-number"><span class="hljs-number">.540</span></span>s</code> </pre> <br>  En soustrayant 14,7 secondes de ce qui s'est passé, j'ai découvert que 4 travailleurs traitent 1000 tâches en 102 secondes.  Essayons maintenant de savoir pourquoi il en est ainsi.  Pour ce faire, nous, pendant que les travailleurs sont occupés, les rechercherons à l'aide de <code>py-spy</code> . <br><br><h2>  <font color="#3AC1EF">Profilage</font> </h2><br>  Nous ajoutons 1 000 tâches supplémentaires à la file d'attente (cela doit être fait car, lors des mesures précédentes, toutes les tâches ont été traitées), exécutons les travailleurs et les espions. <br><br><pre> <code class="python hljs">$ docker-compose run --rm server manage shell &lt;&lt;&lt; <span class="hljs-string"><span class="hljs-string">"from redash.tasks.general import record_event; [record_event.delay({ 'action': 'create', 'timestamp': 0, 'org_id': 1, 'user_id': 1, 'object_id': 0, 'object_type': 'dummy' }) for i in range(1000)]"</span></span> $ docker-compose <span class="hljs-keyword"><span class="hljs-keyword">exec</span></span> worker bash -c <span class="hljs-string"><span class="hljs-string">'nohup ./manage.py rq workers 4 benchmark &amp; sleep 15 &amp;&amp; pip install py-spy &amp;&amp; rq info -u "redis://redis:6379/0" | grep busy | awk "{print $3}" | grep -o -P "\s\d+" | head -n 1 | xargs py-spy record -d 10 --subprocesses -o profile.svg -p'</span></span> $ open -a <span class="hljs-string"><span class="hljs-string">"Google Chrome"</span></span> profile.svg</code> </pre> <br>  Je sais que l'équipe précédente était très longue.  Idéalement, pour améliorer sa lisibilité, il vaudrait la peine de le diviser en fragments séparés, de le diviser aux endroits où se trouvent des séquences de <code>&amp;&amp;</code> caractères.  Mais les commandes doivent être exécutées séquentiellement dans la même session <code>docker-compose exec worker bash</code> , donc tout ressemble à ça.  Voici une description de ce que fait cette commande: <br><br><ol><li>  Lance 4 batch batch en arrière-plan. </li><li>  Il attend 15 secondes (il en faut environ beaucoup pour terminer leur téléchargement). </li><li>  Installe <code>py-spy</code> . </li><li>  Exécute <code>rq-info</code> et découvre le PID de l'un des employés. </li><li>  Enregistre des informations sur le travail du travailleur avec le PID précédemment reçu pendant 10 secondes et enregistre les données dans le fichier <code>profile.svg</code> </li></ol><br>  En conséquence, le «calendrier ardent» suivant a été obtenu. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/456/89a/2f6/45689a2f6406fe5659d7417396665c6d.jpg"><br>  <i><font color="#999999">Visualisation des données collectées par py-spy</font></i> <br><br>  Après avoir analysé ces données, j'ai remarqué que la tâche <code>record_event</code> passe beaucoup de temps à l'exécuter dans <code>sqlalchemy.orm.configure_mappers</code> .  Cela se produit lors de chaque tâche.  De la documentation, j'ai appris qu'au moment qui m'intéresse, les relations de tous les mappeurs créés précédemment sont initialisées. <br><br>  De telles choses ne doivent absolument pas se produire avec chaque fourche.  Nous pouvons initialiser la relation une fois chez le parent travailleur et éviter de répéter cette tâche dans les «chevaux de trait». <br><br>  Par conséquent, j'ai ajouté un appel à <code>sqlalchemy.org.configure_mappers()</code> au code avant de démarrer le «cheval de bataille» et j'ai pris de nouveau des mesures. <br><br><pre> <code class="python hljs">$ docker-compose run --rm server manage shell &lt;&lt;&lt; <span class="hljs-string"><span class="hljs-string">"from redash.tasks.general import record_event; [record_event.delay({ 'action': 'create', 'timestamp': 0, 'org_id': 1, 'user_id': 1, 'object_id': 0, 'object_type': 'dummy' }) for i in range(1000)] $ docker-compose exec worker bash -c "</span></span>time ./manage.py rq workers <span class="hljs-number"><span class="hljs-number">4</span></span> benchmark<span class="hljs-string"><span class="hljs-string">" real 0m39.348s user 0m15.190s sys 0m10.330s</span></span></code> </pre> <br>  Si vous soustrayez 14,7 secondes de ces résultats, il s'avère que nous avons amélioré le temps nécessaire à 4 travailleurs pour traiter 1000 tâches de 102 secondes à 24,6 secondes.  Il s'agit d'une quadruple amélioration des performances!  Grâce à ce correctif, nous avons pu quadrupler les ressources de production RQ et conserver la même bande passante système. <br><br><h2>  <font color="#3AC1EF">Résumé</font> </h2><br>  De tout cela, j'ai tiré la conclusion suivante: il convient de rappeler que l'application se comporte différemment s'il s'agit du seul processus et s'il s'agit de fourches.  Si au cours de chaque tâche, il est nécessaire de résoudre certaines tâches officielles difficiles, il est préférable de les résoudre à l'avance, après l'avoir fait une fois avant que la fourche ne soit terminée.  De telles choses ne sont pas détectées lors des tests et du développement.Par conséquent, après avoir senti que quelque chose ne va pas avec le projet, mesurez sa vitesse et arrivez à la fin tout en recherchant les causes des problèmes de performances. <br><br>  <b>Chers lecteurs!</b>  Avez-vous rencontré des problèmes de performances dans les projets Python que vous pourriez résoudre en analysant soigneusement un système qui fonctionne? <br><br><div style="text-align:center;"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/-o/2e/tu/-o2etuqogwhmdnmysb9_vivc9v4.png"></a> </div><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr475250/">https://habr.com/ru/post/fr475250/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr475240/index.html">Utilisation de modules stricts dans des projets Python à grande échelle: expérience Instagram. Partie 1</a></li>
<li><a href="../fr475242/index.html">Utilisation de modules stricts dans des projets Python à grande échelle: expérience Instagram. 2e partie</a></li>
<li><a href="../fr475244/index.html">Nouvelles fonctionnalités JavaScript attendues que vous devez connaître</a></li>
<li><a href="../fr475246/index.html">Programmation asynchrone Python: un bref aperçu</a></li>
<li><a href="../fr475248/index.html">L'utilisation de polyfills lors de l'écriture d'applications inter-navigateurs</a></li>
<li><a href="../fr475252/index.html">Comment critiquer Microsoft</a></li>
<li><a href="../fr475254/index.html">Architecture AERODISK vAIR ou caractéristiques de la construction d'un cluster national</a></li>
<li><a href="../fr475258/index.html">Une représentation visuelle des élections à Saint-Pétersbourg - la magie de l'habillage vocal</a></li>
<li><a href="../fr475260/index.html">La différence entre une fonction asynchrone et une fonction qui renvoie une promesse</a></li>
<li><a href="../fr475262/index.html">Le condensé de matières fraîches du monde du front-end de la dernière semaine n ° 388 (4-10 novembre 2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
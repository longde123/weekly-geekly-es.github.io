<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§ë üßëüèæ‚Äçü§ù‚Äçüßëüèª üôÄ Comme Redash l'a remarqu√© et a corrig√© un probl√®me qui provoquait une d√©gradation des performances du code Python üë®‚Äçüëß‚Äçüë¶ üïñ üì∏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Redash a r√©cemment commenc√© √† passer d'un syst√®me d'ex√©cution de t√¢ches √† un autre. √Ä savoir, ils ont commenc√© la transition de C√©leri √† RQ. √Ä la prem...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comme Redash l'a remarqu√© et a corrig√© un probl√®me qui provoquait une d√©gradation des performances du code Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/475250/">  Redash a r√©cemment commenc√© √† passer d'un syst√®me d'ex√©cution de t√¢ches √† un autre.  √Ä savoir, ils ont commenc√© la transition de C√©leri √† RQ.  √Ä la premi√®re √©tape, seules les t√¢ches qui n'ex√©cutent pas directement les demandes ont √©t√© transf√©r√©es vers la nouvelle plateforme.  Parmi ces t√¢ches figurent l'envoi d'e-mails, la d√©termination des demandes √† mettre √† jour, l'enregistrement des √©v√©nements utilisateur et d'autres t√¢ches de support. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/0h/9y/wb/0h9ywbok79_xnw71erdzqpiydzq.jpeg"></a> <br><br>  Apr√®s avoir d√©ploy√© tout cela, il a √©t√© remarqu√© que les employ√©s de RQ ont besoin de beaucoup plus de ressources informatiques pour r√©soudre le m√™me volume de t√¢ches que Celery avait l'habitude de r√©soudre. <br><br>  Le mat√©riel, dont nous publions la traduction aujourd'hui, est consacr√© √† l'histoire de la fa√ßon dont Redash a d√©couvert la cause du probl√®me et l'a r√©solu. <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Quelques mots sur les diff√©rences entre le c√©leri et le RQ</font> </h2><br>  Le c√©leri et RQ ont le concept de travailleurs de processus.  L√† et l√† pour l'organisation de l'ex√©cution parall√®le des t√¢ches gr√¢ce √† la cr√©ation de fourches.  Lorsque le travailleur Celery d√©marre, plusieurs processus fork sont cr√©√©s, chacun traitant de mani√®re autonome les t√¢ches.  Dans le cas de RQ, l'instance de l'ouvrier contient un seul sous-processus (appel√© "cheval de bataille"), qui effectue une t√¢che, puis est d√©truit.  Lorsque le travailleur t√©l√©charge la t√¢che suivante de la file d'attente, il cr√©e un nouveau ¬´cheval de bataille¬ª. <br><br>  Lorsque vous travaillez avec RQ, vous pouvez obtenir le m√™me niveau de parall√©lisme que lorsque vous travaillez avec Celery, simplement en ex√©cutant plus de processus de travail.  Cependant, il existe une diff√©rence subtile entre le c√©leri et le RQ.  Dans Celery, un travailleur cr√©e de nombreuses instances de sous-processus au d√©marrage, puis les utilise √† plusieurs reprises pour effectuer de nombreuses t√¢ches.  Et dans le cas de RQ, pour chaque travail, vous devez cr√©er une nouvelle fourche.  Les deux approches ont leurs avantages et leurs inconv√©nients, mais ici, nous n'en parlerons pas. <br><br><h2>  <font color="#3AC1EF">Mesure du rendement</font> </h2><br>  Avant de commencer le profilage, j'ai d√©cid√© de mesurer les performances du syst√®me en d√©couvrant combien de temps le conteneur de travail a besoin pour traiter 1000 travaux.  J'ai d√©cid√© de me concentrer sur la t√¢che <code>record_event</code> , car il s'agit d'une op√©ration l√©g√®re courante.  Pour mesurer les performances, j'ai utilis√© la commande <code>time</code> .  Cela a n√©cessit√© quelques modifications au code du projet: <br><br><ol><li>  Pour mesurer les performances de l'ex√©cution de 1000 t√¢ches, j'ai d√©cid√© d'utiliser le mode batch RQ, dans lequel, apr√®s le traitement des t√¢ches, le processus est quitt√©. </li><li>  Je voulais √©viter d'influencer mes mesures avec d'autres t√¢ches qui auraient pu √™tre planifi√©es √† l'√©poque o√π je mesurais les performances du syst√®me.  J'ai donc d√©plac√© <code>record_event</code> vers une file d'attente distincte appel√©e <code>benchmark</code> , en rempla√ßant <code>@job('default')</code> par <code>@job('benchmark')</code> .  Cela a √©t√© fait juste avant la <code>record_event</code> dans <code>tasks/general.py</code> . </li></ol><br>  Il √©tait maintenant possible de commencer les mesures.  Pour commencer, je voulais savoir combien de temps il faut pour d√©marrer et arr√™ter un travailleur sans charge.  Ce temps pourrait √™tre soustrait des r√©sultats finaux obtenus ult√©rieurement. <br><br><pre> <code class="python hljs">$ docker-compose <span class="hljs-keyword"><span class="hljs-keyword">exec</span></span> worker bash -c <span class="hljs-string"><span class="hljs-string">"time ./manage.py rq workers 4 benchmark"</span></span> real <span class="hljs-number"><span class="hljs-number">0</span></span>m14<span class="hljs-number"><span class="hljs-number">.728</span></span>s user <span class="hljs-number"><span class="hljs-number">0</span></span>m6<span class="hljs-number"><span class="hljs-number">.810</span></span>s sys <span class="hljs-number"><span class="hljs-number">0</span></span>m2<span class="hljs-number"><span class="hljs-number">.750</span></span>s</code> </pre> <br>  Il a fallu 14,7 secondes pour initialiser le travailleur sur mon ordinateur.  Je m'en souviens. <br><br>  Ensuite, j'ai mis 1000 <code>record_event</code> test <code>record_event</code> dans la file d'attente de <code>benchmark</code> : <br><br><pre> <code class="python hljs">$ docker-compose run --rm server manage shell &lt;&lt;&lt; <span class="hljs-string"><span class="hljs-string">"from redash.tasks.general import record_event; [record_event.delay({ 'action': 'create', 'timestamp': 0, 'org_id': 1, 'user_id': 1, 'object_id': 0, 'object_type': 'dummy' }) for i in range(1000)]"</span></span></code> </pre> <br>  Apr√®s cela, j'ai d√©marr√© le syst√®me de la m√™me mani√®re qu'auparavant et j'ai d√©couvert combien de temps il faut pour traiter 1000 t√¢ches. <br><br><pre> <code class="python hljs">$ docker-compose <span class="hljs-keyword"><span class="hljs-keyword">exec</span></span> worker bash -c <span class="hljs-string"><span class="hljs-string">"time ./manage.py rq workers 4 benchmark"</span></span> real <span class="hljs-number"><span class="hljs-number">1</span></span>m57<span class="hljs-number"><span class="hljs-number">.332</span></span>s user <span class="hljs-number"><span class="hljs-number">1</span></span>m11<span class="hljs-number"><span class="hljs-number">.320</span></span>s sys <span class="hljs-number"><span class="hljs-number">0</span></span>m27<span class="hljs-number"><span class="hljs-number">.540</span></span>s</code> </pre> <br>  En soustrayant 14,7 secondes de ce qui s'est pass√©, j'ai d√©couvert que 4 travailleurs traitent 1000 t√¢ches en 102 secondes.  Essayons maintenant de savoir pourquoi il en est ainsi.  Pour ce faire, nous, pendant que les travailleurs sont occup√©s, les rechercherons √† l'aide de <code>py-spy</code> . <br><br><h2>  <font color="#3AC1EF">Profilage</font> </h2><br>  Nous ajoutons 1 000 t√¢ches suppl√©mentaires √† la file d'attente (cela doit √™tre fait car, lors des mesures pr√©c√©dentes, toutes les t√¢ches ont √©t√© trait√©es), ex√©cutons les travailleurs et les espions. <br><br><pre> <code class="python hljs">$ docker-compose run --rm server manage shell &lt;&lt;&lt; <span class="hljs-string"><span class="hljs-string">"from redash.tasks.general import record_event; [record_event.delay({ 'action': 'create', 'timestamp': 0, 'org_id': 1, 'user_id': 1, 'object_id': 0, 'object_type': 'dummy' }) for i in range(1000)]"</span></span> $ docker-compose <span class="hljs-keyword"><span class="hljs-keyword">exec</span></span> worker bash -c <span class="hljs-string"><span class="hljs-string">'nohup ./manage.py rq workers 4 benchmark &amp; sleep 15 &amp;&amp; pip install py-spy &amp;&amp; rq info -u "redis://redis:6379/0" | grep busy | awk "{print $3}" | grep -o -P "\s\d+" | head -n 1 | xargs py-spy record -d 10 --subprocesses -o profile.svg -p'</span></span> $ open -a <span class="hljs-string"><span class="hljs-string">"Google Chrome"</span></span> profile.svg</code> </pre> <br>  Je sais que l'√©quipe pr√©c√©dente √©tait tr√®s longue.  Id√©alement, pour am√©liorer sa lisibilit√©, il vaudrait la peine de le diviser en fragments s√©par√©s, de le diviser aux endroits o√π se trouvent des s√©quences de <code>&amp;&amp;</code> caract√®res.  Mais les commandes doivent √™tre ex√©cut√©es s√©quentiellement dans la m√™me session <code>docker-compose exec worker bash</code> , donc tout ressemble √† √ßa.  Voici une description de ce que fait cette commande: <br><br><ol><li>  Lance 4 batch batch en arri√®re-plan. </li><li>  Il attend 15 secondes (il en faut environ beaucoup pour terminer leur t√©l√©chargement). </li><li>  Installe <code>py-spy</code> . </li><li>  Ex√©cute <code>rq-info</code> et d√©couvre le PID de l'un des employ√©s. </li><li>  Enregistre des informations sur le travail du travailleur avec le PID pr√©c√©demment re√ßu pendant 10 secondes et enregistre les donn√©es dans le fichier <code>profile.svg</code> </li></ol><br>  En cons√©quence, le ¬´calendrier ardent¬ª suivant a √©t√© obtenu. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/456/89a/2f6/45689a2f6406fe5659d7417396665c6d.jpg"><br>  <i><font color="#999999">Visualisation des donn√©es collect√©es par py-spy</font></i> <br><br>  Apr√®s avoir analys√© ces donn√©es, j'ai remarqu√© que la t√¢che <code>record_event</code> passe beaucoup de temps √† l'ex√©cuter dans <code>sqlalchemy.orm.configure_mappers</code> .  Cela se produit lors de chaque t√¢che.  De la documentation, j'ai appris qu'au moment qui m'int√©resse, les relations de tous les mappeurs cr√©√©s pr√©c√©demment sont initialis√©es. <br><br>  De telles choses ne doivent absolument pas se produire avec chaque fourche.  Nous pouvons initialiser la relation une fois chez le parent travailleur et √©viter de r√©p√©ter cette t√¢che dans les ¬´chevaux de trait¬ª. <br><br>  Par cons√©quent, j'ai ajout√© un appel √† <code>sqlalchemy.org.configure_mappers()</code> au code avant de d√©marrer le ¬´cheval de bataille¬ª et j'ai pris de nouveau des mesures. <br><br><pre> <code class="python hljs">$ docker-compose run --rm server manage shell &lt;&lt;&lt; <span class="hljs-string"><span class="hljs-string">"from redash.tasks.general import record_event; [record_event.delay({ 'action': 'create', 'timestamp': 0, 'org_id': 1, 'user_id': 1, 'object_id': 0, 'object_type': 'dummy' }) for i in range(1000)] $ docker-compose exec worker bash -c "</span></span>time ./manage.py rq workers <span class="hljs-number"><span class="hljs-number">4</span></span> benchmark<span class="hljs-string"><span class="hljs-string">" real 0m39.348s user 0m15.190s sys 0m10.330s</span></span></code> </pre> <br>  Si vous soustrayez 14,7 secondes de ces r√©sultats, il s'av√®re que nous avons am√©lior√© le temps n√©cessaire √† 4 travailleurs pour traiter 1000 t√¢ches de 102 secondes √† 24,6 secondes.  Il s'agit d'une quadruple am√©lioration des performances!  Gr√¢ce √† ce correctif, nous avons pu quadrupler les ressources de production RQ et conserver la m√™me bande passante syst√®me. <br><br><h2>  <font color="#3AC1EF">R√©sum√©</font> </h2><br>  De tout cela, j'ai tir√© la conclusion suivante: il convient de rappeler que l'application se comporte diff√©remment s'il s'agit du seul processus et s'il s'agit de fourches.  Si au cours de chaque t√¢che, il est n√©cessaire de r√©soudre certaines t√¢ches officielles difficiles, il est pr√©f√©rable de les r√©soudre √† l'avance, apr√®s l'avoir fait une fois avant que la fourche ne soit termin√©e.  De telles choses ne sont pas d√©tect√©es lors des tests et du d√©veloppement.Par cons√©quent, apr√®s avoir senti que quelque chose ne va pas avec le projet, mesurez sa vitesse et arrivez √† la fin tout en recherchant les causes des probl√®mes de performances. <br><br>  <b>Chers lecteurs!</b>  Avez-vous rencontr√© des probl√®mes de performances dans les projets Python que vous pourriez r√©soudre en analysant soigneusement un syst√®me qui fonctionne? <br><br><div style="text-align:center;"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/-o/2e/tu/-o2etuqogwhmdnmysb9_vivc9v4.png"></a> </div><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr475250/">https://habr.com/ru/post/fr475250/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr475240/index.html">Utilisation de modules stricts dans des projets Python √† grande √©chelle: exp√©rience Instagram. Partie 1</a></li>
<li><a href="../fr475242/index.html">Utilisation de modules stricts dans des projets Python √† grande √©chelle: exp√©rience Instagram. 2e partie</a></li>
<li><a href="../fr475244/index.html">Nouvelles fonctionnalit√©s JavaScript attendues que vous devez conna√Ætre</a></li>
<li><a href="../fr475246/index.html">Programmation asynchrone Python: un bref aper√ßu</a></li>
<li><a href="../fr475248/index.html">L'utilisation de polyfills lors de l'√©criture d'applications inter-navigateurs</a></li>
<li><a href="../fr475252/index.html">Comment critiquer Microsoft</a></li>
<li><a href="../fr475254/index.html">Architecture AERODISK vAIR ou caract√©ristiques de la construction d'un cluster national</a></li>
<li><a href="../fr475258/index.html">Une repr√©sentation visuelle des √©lections √† Saint-P√©tersbourg - la magie de l'habillage vocal</a></li>
<li><a href="../fr475260/index.html">La diff√©rence entre une fonction asynchrone et une fonction qui renvoie une promesse</a></li>
<li><a href="../fr475262/index.html">Le condens√© de mati√®res fra√Æches du monde du front-end de la derni√®re semaine n ¬∞ 388 (4-10 novembre 2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
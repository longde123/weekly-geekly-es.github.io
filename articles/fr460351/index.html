<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👆🏾 ☝🏻 👩‍🔧 werf - notre outil pour CI / CD à Kubernetes (revue et reportage vidéo) 🌈 🛌🏻 🛣️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le 27 mai, dans le hall principal de la conférence DevOpsConf 2019, organisée dans le cadre du festival RIT ++ 2019 , dans le cadre de la section Livr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>werf - notre outil pour CI / CD à Kubernetes (revue et reportage vidéo)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/460351/">  Le 27 mai, dans le hall principal de la conférence DevOpsConf 2019, organisée dans le cadre du festival <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RIT ++ 2019</a> , dans le cadre de la section Livraison continue, un rapport a été rédigé «werf est notre outil pour CI / CD à Kubernetes».  Il parle des <b>problèmes et des défis auxquels tout le monde est confronté lors du déploiement sur Kubernetes</b> , ainsi que des nuances qui peuvent ne pas être immédiatement perceptibles.  En analysant les solutions possibles, nous montrons comment cela est mis en œuvre dans l'outil <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">werf</a> Open Source. <br><br>  Depuis le salon, notre utilitaire (anciennement connu sous le nom de dapp) a dépassé la limite historique de <b>1000 étoiles sur GitHub</b> - nous espérons que la communauté croissante de ses utilisateurs simplifiera la vie de nombreux ingénieurs DevOps. <br><br><img src="https://habrastorage.org/webt/lh/k9/x1/lhk9x1wf3gzo6bk1lsjosnvjg1g.jpeg"><br><br>  Nous présentons donc la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><b>vidéo avec le rapport</b></a> (~ 47 minutes, beaucoup plus informatif que l'article) et son extrait principal sous forme de texte.  C'est parti! <a name="habracut"></a><br><br><h2>  Livraison de code dans Kubernetes </h2><br>  La discussion ne portera plus sur werf, mais sur CI / CD dans Kubernetes, ce qui implique que notre logiciel est emballé dans des conteneurs Docker <i>(j'en ai parlé dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le rapport 2016</a> )</i> , et des K8 seront utilisés pour le lancer en production <i>(à propos de ce - en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2017</a> )</i> . <br><br>  À quoi ressemble la livraison de Kubernetes? <br><br><ul><li>  Il existe un référentiel Git avec du code et des instructions pour le construire.  L'application est compilée dans une image Docker et publiée dans le registre Docker. </li><li>  Dans le même référentiel, il y a des instructions sur la façon de déployer et d'exécuter l'application.  Au stade du déploiement, ces instructions sont envoyées à Kubernetes, qui reçoit l'image souhaitée du registre et la démarre. </li><li>  De plus, il y a généralement des tests.  Certains d'entre eux peuvent être effectués lors de la publication d'une image.  Vous pouvez également (par les mêmes instructions) déployer une copie de l'application (dans un espace de noms K8 séparé ou dans un cluster séparé) et y exécuter des tests. </li><li>  Enfin, nous avons besoin d'un système CI qui reçoit les événements de Git (ou clics sur les boutons) et appelle toutes les étapes indiquées: construire, publier, déployer, tester. </li></ul><br><img src="https://habrastorage.org/webt/vd/jh/ks/vdjhksq3874swybast6v7oerqe4.gif"><br><br>  Il y a quelques notes importantes ici: <br><br><ol><li>  Comme nous avons une infrastructure immuable, l'image de l'application utilisée à toutes les étapes (mise en scène, production, etc.) <b>doit être une</b> .  <i>J'en ai parlé davantage et avec des exemples <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .</i> </li><li>  Étant donné que nous <i>suivons</i> l'infrastructure en tant <i>qu'approche de</i> code <i>(IaC)</i> , le code de l'application et les instructions pour sa création et son exécution doivent se trouver <b>dans un référentiel</b> .  <i>Pour en savoir plus à ce sujet, voir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le même rapport</a> .</i> </li><li>  Nous voyons généralement la chaîne de livraison <i>(livraison)</i> comme ceci: l'application a été assemblée, testée, publiée <i>(étape de publication)</i> et c'est tout - la livraison a eu lieu.  Mais en réalité, l'utilisateur reçoit ce que vous avez déployé, <b>non pas</b> lorsque vous l'avez livré à la production, mais quand il a pu s'y rendre et que cette production a fonctionné.  Par conséquent, je pense que la chaîne de livraison <b>ne</b> se termine <b>qu'au stade opérationnel</b> <i>(run)</i> , et plus précisément, même au moment où le code a été retiré de la production (en le remplaçant par un nouveau). </li></ol><br>  Revenons au schéma de livraison de Kubernetes décrit ci-dessus: il a été inventé non seulement par nous, mais littéralement par tous ceux qui ont traité ce problème.  Essentiellement, ce modèle est maintenant appelé GitOps <i>(vous</i> trouverez <i>plus d'informations sur le terme et les idées qui le sous-tendent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> )</i> .  Regardons les étapes du schéma. <br><br><h2>  Étape de construction </h2><br>  Il semblerait qu'en 2019, vous pouvez parler de l'assemblage d'images Docker, quand tout le monde sait comment écrire des Dockerfiles et exécuter la <code>docker build</code> de Docker? .. Voici les nuances auxquelles je voudrais faire attention: <br><br><ol><li>  <b>Le poids de l'image est</b> important, utilisez donc <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plusieurs étapes</a> pour ne laisser que l'application vraiment nécessaire à l'image. </li><li>  <b>Le nombre de couches</b> doit être minimisé en combinant les chaînes de commandes <code>RUN</code> dans le sens. </li><li>  Cependant, cela ajoute aux problèmes de <b>débogage</b> , car lorsque l'assembly se bloque, vous devez trouver la commande nécessaire dans la chaîne à l'origine du problème. </li><li>  <b>La vitesse de construction est</b> importante car nous voulons déployer rapidement les modifications et regarder le résultat.  Par exemple, je ne veux pas réassembler les dépendances dans les bibliothèques de langues avec chaque build de l'application. </li><li>  Souvent, à partir d'un référentiel Git, de <b>nombreuses images</b> sont requises, qui peuvent être résolues par un ensemble de Dockerfiles (ou des étapes nommées dans un seul fichier) et un script Bash avec leur assemblage séquentiel. </li></ol><br>  Ce n'était que la pointe de l'iceberg à laquelle tout le monde fait face.  Mais il y a d'autres problèmes, et en particulier: <br><br><ol><li>  Souvent, au stade de l'assemblage, nous devons <b>monter</b> quelque chose (par exemple, mettre en cache le résultat d'une commande comme apt dans un répertoire tiers). </li><li>  Nous voulons <b>Ansible</b> au lieu d'écrire sur le shell. </li><li>  Nous voulons <b>construire sans Docker</b> (pourquoi avons-nous besoin d'une machine virtuelle supplémentaire dans laquelle vous devez tout configurer pour cela alors qu'il existe déjà un cluster Kubernetes dans lequel vous pouvez exécuter des conteneurs?). </li><li>  <b>Assemblage parallèle</b> , qui peut être compris de différentes manières: différentes commandes du Dockerfile (si plusieurs étapes sont utilisées), plusieurs validations d'un référentiel, plusieurs Dockerfiles. </li><li>  <b>Assemblage distribué</b> : nous voulons collecter quelque chose dans des pods qui sont «éphémères», car  leur cache disparaît, ce qui signifie qu'il doit être stocké quelque part séparément. </li><li>  Enfin, j'ai appelé <b>le</b> summum de l'auto- <b>magie</b> des désirs: il serait idéal d'aller dans le référentiel, de taper une équipe et d'obtenir une image prête à l'emploi, assemblée avec une compréhension de comment et quoi faire correctement.  Cependant, je ne suis personnellement pas sûr que toutes les nuances puissent être prévues de cette manière. </li></ol><br>  Et voici les projets: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">moby / buildkit</a> - un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">constructeur</a> de la société Docker Inc (déjà intégré dans les versions actuelles de Docker), qui essaie de résoudre tous ces problèmes; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">kaniko</a> - un collectionneur de Google, qui vous permet de construire sans Docker; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Buildpacks.io</a> - une tentative de la CNCF de faire de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'</a> automagie et, en particulier, une solution intéressante avec rebase pour les couches; </li><li>  et un tas d'autres utilitaires comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">buildah</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">genuinetools / img</a> ... </li></ul><br>  ... et voyez combien d'étoiles ils ont sur GitHub.  C'est-à-dire, d'une part, que la <code>docker build</code> est et peut faire quelque chose, mais en réalité, le <b>problème n'a pas été complètement résolu</b> - cela est démontré par le développement parallèle de constructeurs alternatifs, chacun résolvant certains des problèmes. <br><br><h2>  Construire en werf </h2><br>  Nous sommes donc arrivés à <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">werf</a> <i>(anciennement <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">connu</a> sous <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le</a> nom de dapp)</i> - l'utilitaire Open Source de Flant, ce que nous faisons depuis de nombreuses années.  Tout a commencé il y a environ 5 ans avec des scripts Bash qui optimisent l'assemblage des Dockerfiles, et les 3 dernières années, le développement complet s'est poursuivi dans le cadre d'un projet avec son propre référentiel Git <i>(d'abord en Ruby, puis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">réécrit</a> en Go, et en même temps renommé)</i> .  Quels problèmes de build sont résolus dans werf? <br><br><img src="https://habrastorage.org/webt/--/1-/ca/--1-cakzswwfhrcrgnees6cvf-a.png"><br><br>  Les problèmes ombrés de bleu ont déjà été mis en œuvre, l'assemblage parallèle a été fait au sein du même hôte, et nous prévoyons de terminer les questions jaunes d'ici la fin de l'été. <br><br><h2>  Stade de publication dans le registre (publier) </h2><br>  Nous avons tapé <code>docker push</code> ... - qu'est-ce qui peut être difficile à télécharger une image dans le registre?  Et puis la question se pose: "Quelle balise pour mettre l'image?"  Cela vient du fait que nous avons <b>Gitflow</b> (ou une autre stratégie Git) et Kubernetes, et l'industrie est déterminée à s'assurer que ce qui se passe à Kubernetes suit ce qui se fait à Git.  Git est notre seule source de vérité. <br><br>  Qu'est-ce qui est si compliqué?  <b>Assurer la reproductibilité</b> : d'une validation dans Git, qui est intrinsèquement <i>immuable</i> , à une image Docker qui doit rester la même. <br><br>  Il est également important pour nous de <b>déterminer l'origine</b> , car nous voulons comprendre à partir de quel commit l'application lancée dans Kubernetes a été construite (nous pouvons alors faire des différences et des choses similaires). <br><br><h3>  Stratégies de marquage </h3><br>  Le premier est une simple <b>balise git</b> .  Nous avons un registre avec une image étiquetée <code>1.0</code> .  Kubernetes a une scène et une production où cette image est pompée.  Dans Git, nous faisons des commits et à un moment donné nous mettons le tag <code>2.0</code> .  Nous le collectons selon les instructions du référentiel et le mettons dans le registre avec la balise <code>2.0</code> .  Nous le déployons sur scène et, si tout va bien, alors en production. <br><br><img src="https://habrastorage.org/webt/4f/ub/u4/4fubu4r-0obh9gkzs4_kftnlqxs.gif"><br><br>  Le problème avec cette approche est que nous avons d'abord défini la balise, puis seulement testé et déployé.  Pourquoi?  Tout d'abord, c'est tout simplement illogique: nous distribuons une version de logiciel que nous n'avons même pas testée (nous ne pouvons pas faire autrement, car pour vérifier, vous devez mettre une balise).  Deuxièmement, cette façon n'est pas compatible avec Gitflow. <br><br>  La deuxième option est <b>git commit + tag</b> .  Il y a une balise <code>1.0</code> dans la branche principale;  pour lui dans le registre - une image déployée en production.  De plus, le cluster Kubernetes possède des boucles de prévisualisation et de transfert.  Ensuite, nous suivons Gitflow: dans la branche principale pour le développement, nous <code>develop</code> nouvelles fonctionnalités, à la suite desquelles il y a un commit avec l'identifiant <code>#c1</code> .  Nous le collectons et le publions dans le registre en utilisant cet identifiant ( <code>#c1</code> ).  Nous déployons l'aperçu avec le même identifiant.  Nous faisons de même avec les commits <code>#c2</code> et <code>#c3</code> . <br><br>  Lorsque nous avons réalisé qu'il y avait suffisamment de fonctionnalités, nous commençons à tout stabiliser.  Dans Git, créez la branche <code>release_1.1</code> (basée sur <code>#c3</code> de <code>develop</code> ).  La collecte de cette version n'est pas requise, car  Cela a été fait à l'étape précédente.  Par conséquent, nous pouvons simplement le déployer vers la mise en scène.  Nous corrigeons les bogues dans <code>#c4</code> et <code>#c4</code> même manière sur la mise en scène.  Dans le même temps, le développement est en cours à <code>develop</code> , où des modifications par rapport à la <code>release_1.1</code> sont effectuées périodiquement.  À un moment donné, nous obtenons un commit validé et pompé pour la mise en scène, ce dont nous sommes satisfaits ( <code>#c25</code> ). <br><br>  Ensuite, nous faisons une fusion (avec avance rapide) de la branche de publication ( <code>release_1.1</code> ) dans master.  Nous avons mis une balise avec la nouvelle version ( <code>1.1</code> ) sur ce commit.  Mais cette image est déjà assemblée dans le registre, donc afin de ne pas la collecter à nouveau, nous ajoutons juste une deuxième balise à l'image existante (maintenant elle a les balises <code>#c25</code> et <code>1.1</code> dans le registre).  Après cela, nous le déployons en production. <br><br>  Il y a un inconvénient qu'une image ( <code>#c25</code> ) est <code>#c25</code> sur la mise en scène, et une autre ( <code>1.1</code> ) est <code>#c25</code> sur la production, mais nous savons que «physiquement», c'est la même image du registre. <br><br><img src="https://habrastorage.org/webt/mb/pq/iu/mbpqiumzomvrouhp8llx5aishza.gif"><br><br>  Le vrai inconvénient est qu'il n'y a pas de support pour merge commit'ov, vous devez faire une avance rapide. <br><br>  Vous pouvez aller plus loin et faire l'affaire ... Prenons un exemple de Dockerfile simple: <br><br><pre> <code class="plaintext hljs">FROM ruby:2.3 as assets RUN mkdir -p /app WORKDIR /app COPY . ./ RUN gem install bundler &amp;&amp; bundle install RUN bundle exec rake assets:precompile CMD bundle exec puma -C config/puma.rb FROM nginx:alpine COPY --from=assets /app/public /usr/share/nginx/www/public</code> </pre> <br>  Nous en construisons un fichier selon ce principe, que nous prenons: <br><br><ul><li>  SHA256 à partir des identifiants des images utilisées ( <code>ruby:2.3</code> et <code>nginx:alpine</code> ), qui sont des sommes de contrôle de leur contenu; </li><li>  toutes les équipes ( <code>RUN</code> , <code>CMD</code> , etc.); </li><li>  SHA256 à partir de fichiers ajoutés. </li></ul><br>  ... et prenez la somme de contrôle (à nouveau SHA256) d'un tel fichier.  Il s'agit de la <b>signature de</b> tout ce qui définit le contenu d'une image Docker. <br><br><img src="https://habrastorage.org/webt/zp/w2/ju/zpw2jup54xa66mit1bt9u7amwlk.gif"><br><br>  Revenons au schéma et <b>au lieu des validations, nous utiliserons de telles signatures</b> , c'est-à-dire  étiqueter les images avec des signatures. <br><br><img src="https://habrastorage.org/webt/pr/d3/wf/prd3wfn6ctkod9ddqqmgtqnr1ew.gif"><br><br>  Maintenant, lorsque vous avez besoin, par exemple, de fusionner des modifications de la version au master, nous pouvons faire un vrai commit de fusion: il aura un identifiant différent, mais la même signature.  Avec le même identifiant, nous déploierons également l'image en production. <br><br>  L'inconvénient est qu'il ne sera désormais plus possible de déterminer quel type d'engagement a été injecté dans la production - les sommes de contrôle ne fonctionnent que dans un sens.  Ce problème est résolu par une couche supplémentaire avec des métadonnées - je vous en dirai plus plus tard. <br><br><h3>  Marquage dans werf </h3><br>  Dans werf, nous sommes allés encore plus loin et nous nous préparons à faire un assemblage distribué avec un cache qui n'est pas stocké sur la même machine ... Donc, nous avons deux types d'images Docker, nous les appelons <i>stage</i> et <i>image</i> . <br><br>  Le référentiel werf Git stocke des instructions de build spécifiques qui décrivent les différentes étapes de la build ( <i>beforeInstall</i> , <i>install</i> , <i>beforeSetup</i> , <i>setup</i> ).  Nous collectons l'image de la première étape avec une signature définie comme la somme de contrôle des premières étapes.  Ensuite, nous ajoutons le code source, pour la nouvelle image de scène, nous considérons sa somme de contrôle ... Ces opérations sont répétées pour toutes les étapes, à la suite de quoi nous obtenons un ensemble d'images de scène.  Ensuite, nous faisons l'image-image finale contenant également des métadonnées sur son origine.  Et nous marquons cette image de différentes manières (détails plus tard). <br><br><img src="https://habrastorage.org/webt/4a/uw/am/4auwamdra7bm0xtvht35kpbstye.gif"><br><br>  Après cela, un nouveau commit apparaît, dans lequel seul le code d'application est modifié.  Que va-t-il se passer?  Un patch sera créé pour les changements de code, une nouvelle image de stage sera préparée.  Sa signature sera définie comme la somme de contrôle de l'ancienne image de la scène et du nouveau patch.  A partir de cette image, une nouvelle image-image finale sera formée.  Un comportement similaire se produira avec des changements à d'autres étapes. <br><br>  Ainsi, les images de scène sont un cache qui peut être distribué distribué, et les images d'image déjà créées à partir de celui-ci sont chargées dans le Docker Registry. <br><br><img src="https://habrastorage.org/webt/sc/8j/me/sc8jme4f1jfqbrbwt1anf2-rja8.gif"><br><br><h3>  Nettoyage du registre </h3><br>  Il ne s'agit pas de supprimer des couches qui restent suspendues après la suppression de balises - c'est une fonctionnalité standard du Docker Registry lui-même.  Il s'agit d'une situation où de nombreuses balises Docker s'accumulent et nous comprenons que nous n'en avons plus besoin et qu'elles prennent de la place (et / ou nous la payons). <br><br>  Quelles sont les stratégies de nettoyage? <br><br><ol><li>  Vous ne pouvez <b>rien nettoyer</b> .  Parfois, il est vraiment plus facile de payer un peu pour l'espace supplémentaire que de démêler une énorme boule de balises.  Mais cela ne fonctionne que jusqu'à un certain point. </li><li>  <b>Réinitialisation complète</b> .  Si vous supprimez toutes les images et reconstruisez uniquement les images pertinentes dans le système CI, un problème peut survenir.  Si le conteneur redémarre en production, une nouvelle image sera chargée pour celui-ci - celle qui n'a encore été testée par personne.  Cela tue l'idée d'une infrastructure immuable. </li><li>  <b>Bleu-vert</b> .  Un registre a commencé à déborder - chargeant des images dans un autre.  Le même problème que dans la méthode précédente: à quel moment pouvez-vous nettoyer le registre qui a commencé à déborder? </li><li>  <b>Par le temps</b> .  Supprimer toutes les images de plus d'un mois?  Mais il y a sûrement un service qui n'a pas été mis à jour depuis un mois ... </li><li>  Déterminez <b>manuellement</b> ce qui peut déjà être supprimé. </li></ol><br>  Il existe deux options vraiment viables: ne pas nettoyer ou une combinaison de bleu-vert + manuellement.  Dans ce dernier cas, nous parlons de ce qui suit: lorsque vous comprenez qu'il est temps de nettoyer le registre, créez-en un nouveau et ajoutez-y toutes les nouvelles images pendant, par exemple, un mois.  Un mois plus tard, voyez quels pods dans Kubernetes utilisent toujours l'ancien registre et transférez-les également dans le nouveau registre. <br><br>  <b>Où</b> sommes-nous <b>allés</b> à <b>werf</b> ?  Nous collectons: <br><br><ol><li>  Git head: toutes les balises, toutes les branches, - en supposant que tout ce qui est testé dans Git, nous en avons besoin dans les images (et sinon, nous devons les supprimer dans le Git lui-même); </li><li>  tous les pods qui sont maintenant téléchargés dans Kubernetes; </li><li>  anciens ReplicaSets (quelque chose qui a été récemment pompé), ainsi que nous prévoyons de numériser les versions de Helm et de sélectionner les dernières images là-bas. </li></ol><br>  ... et nous faisons une liste blanche à partir de cet ensemble - une liste d'images que nous ne supprimerons pas.  Nous nettoyons tout le reste, après quoi nous trouvons les images de scène orphelines et les supprimons aussi. <br><br><h2>  Étape de déploiement (déploiement) </h2><br><h3>  Déclaration forte </h3><br>  Le premier point sur lequel je voudrais attirer l'attention dans le déploiement est de déployer la configuration de ressource mise à jour, déclarée de manière déclarative.  Le document YAML d'origine décrivant les ressources Kubernetes est toujours très différent du résultat qui fonctionne réellement dans le cluster.  Parce que Kubernetes ajoute à la configuration: <br><br><ol><li>  identifiants </li><li>  informations de service; </li><li>  de nombreuses valeurs par défaut; </li><li>  section avec l'état actuel; </li><li>  les modifications apportées dans le cadre du webhook d'admission; </li><li>  le résultat du travail de différents contrôleurs (et ordonnanceur). </li></ol><br>  Par conséquent, lorsqu'une nouvelle configuration d'une ressource ( <i>nouvelle</i> ) apparaît, nous ne pouvons pas simplement prendre et écraser avec elle la configuration actuelle «en direct» (en <i>direct</i> ).  Pour ce faire, nous devons comparer <i>nouveau</i> avec la dernière configuration appliquée ( <i>dernière appliquée</i> ) et lancer le patch résultant en <i>direct</i> . <br><br>  Cette approche est appelée <b>fusion bidirectionnelle</b> .  Il est utilisé, par exemple, dans Helm. <br><br>  Il existe également une <b>fusion à 3 voies</b> , qui diffère en ce que: <br><br><ul><li>  en comparant la <i>dernière application</i> et la <i>nouvelle</i> , nous examinons ce qui a été supprimé; </li><li>  en comparant le <i>nouveau</i> et le <i>vivant</i> , nous voyons ce qui a été ajouté ou changé; </li><li>  appliquer le patch résumé pour <i>vivre</i> . </li></ul><br>  Nous déployons plus de 1000 applications avec Helm, nous vivons donc réellement avec une fusion bidirectionnelle.  Cependant, il a un certain nombre de problèmes que nous avons résolus avec nos correctifs qui aident Helm à fonctionner normalement. <br><br><h3>  Statut de déploiement réel </h3><br>  Après le prochain événement, notre système CI a généré une nouvelle configuration pour Kubernetes, il l'envoie à <i>appliquer</i> au cluster en utilisant Helm ou <code>kubectl apply</code> .  Ensuite, la fusion N-way déjà décrite a lieu, à laquelle l'API Kubernetes approuve le système CI, et ce dernier répond à son utilisateur. <br><br><img src="https://habrastorage.org/webt/sk/vh/-u/skvh-uifcwg6_d5mgxhehh39q9i.png"><br><br>  Cependant, il y a un énorme problème: après tout, une <b>application réussie ne signifie pas un déploiement réussi</b> .  Si Kubernetes comprend les changements à appliquer, l'applique - nous ne savons toujours pas quel sera le résultat.  Par exemple, la mise à jour et le redémarrage des pods dans le frontend peuvent réussir, mais pas dans le backend, et nous obtiendrons différentes versions des images d'application en cours d'exécution. <br><br>  Pour tout faire correctement, un lien supplémentaire apparaît dans ce schéma - un tracker spécial qui recevra les informations d'état de l'API Kubernetes et les transmettra pour une analyse plus approfondie de l'état réel des choses.  Nous avons créé une bibliothèque Open Source sur Go - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><b>kubedog</b></a> <i>(voir son annonce <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> )</i> - qui résout ce problème et est intégrée à werf. <br><br>  Le comportement de ce tracker au niveau werf est configuré à l'aide d'annotations placées sur Deployments ou StatefulSets.  L'annotation principale, <code>fail-mode</code> , comprend les significations suivantes: <br><br><ul><li>  <code>IgnoreAndContinueDeployProcess</code> - ignore les problèmes de <code>IgnoreAndContinueDeployProcess</code> de ce composant et continue le déploiement; </li><li>  <code>FailWholeDeployProcessImmediately</code> - une erreur dans ce composant arrête le processus de déploiement; </li><li>  <code>HopeUntilEndOfDeployProcess</code> - nous espérons que ce composant fonctionnera d'ici la fin du déploiement. </li></ul><br>  Par exemple, une combinaison de ressources et de valeurs d'annotation en <code>fail-mode</code> : <br><br><img src="https://habrastorage.org/webt/ja/qf/ot/jaqfotxaxoxwznieu2lvnnyhih0.png"><br><br>  Lors du premier déploiement, la base de données (MongoDB) n'est peut-être pas encore prête - Les déploiements se bloqueront.  Mais vous pouvez attendre le moment où il démarre et le déploiement se poursuivra. <br><br>  Il y a deux annotations supplémentaires pour kubedog dans werf: <br><br><ul><li>  <code>failures-allowed-per-replica</code> - le nombre de suppressions autorisées par réplique; </li><li>  <code>show-logs-until</code> - ajuste le moment jusqu'à lequel werf affiche (dans stdout) les journaux de tous les pods en cours de déploiement.  Par défaut, il s'agit de <code>PodIsReady</code> (pour ignorer les messages dont nous avons à peine besoin lorsque le trafic commence à arriver sur le pod), cependant, les valeurs <code>ControllerIsReady</code> et <code>EndOfDeploy</code> également <code>EndOfDeploy</code> . </li></ul><br><h3>  Que voulons-nous d'autre du déploiement? </h3><br>  En plus des deux points déjà décrits, nous souhaitons: <br><br><ul><li>  pour voir les <b>journaux</b> - et seulement nécessaire, mais pas tout; </li><li>  suivre les <b>progrès</b> , car si un travail se "suspend" en silence pendant plusieurs minutes, il est important de comprendre ce qui s'y passe; </li><li>  avoir une <b>restauration automatique</b> en cas de problème (et il est donc essentiel de connaître l'état réel du déploiement).  Le déploiement doit être atomique: soit il se termine, soit tout revient à son état précédent. </li></ul><br><h2>  Résumé </h2><br>  En tant qu'entreprise, pour nous, pour implémenter toutes les nuances décrites à différents stades de livraison (construire, publier, déployer), le système CI et l'utilitaire <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">werf suffisent</a> . <br><br>  Au lieu d'une conclusion: <br><br><img src="https://habrastorage.org/webt/ja/1y/tc/ja1ytcqobpkbw5rtf78ykb4clnm.png"><br><br>  Avec l'aide de werf, nous avons bien progressé dans la résolution d'un grand nombre de problèmes des ingénieurs DevOps et serons heureux si la communauté plus large essaie au moins cet utilitaire dans la pratique.  Obtenir un bon résultat ensemble sera plus facile. <br><br><h2>  Vidéos et diapositives </h2><br>  Vidéo de la performance (~ 47 minutes): <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/cK3ackGUTLw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Présentation du rapport: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/https://translate" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2>  PS </h2><br>  Autres rapports Kubernetes sur notre blog: <br><br><ul><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Auto-scaling et gestion des ressources à Kubernetes</a> » <i>(Dmitry Stolyarov; 27 avril 2019 lors de la «Strike»)</i> ; </li><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Étendre et compléter Kubernetes</a> » <i>(Andrey Polov; 8 avril 2019 à Saint HighLoad ++)</i> ; </li><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bases de données et Kubernetes</a> » <i>(Dmitry Stolyarov; 8 novembre 2018 sur HighLoad ++)</i> ; </li><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Monitoring and Kubernetes</a> » <i>(Dmitry Stolyarov; 28 mai 2018 à RootConf)</i> ; </li><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Meilleures pratiques CI / CD avec Kubernetes et GitLab</a> » <i>(Dmitry Stolyarov; 7 novembre 2017 à HighLoad ++)</i> ; </li><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Notre expérience avec Kubernetes dans les petits projets</a> » <i>(Dmitry Stolyarov; 6 juin 2017 chez RootConf)</i> . </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr460351/">https://habr.com/ru/post/fr460351/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr460341/index.html">Poursuite de l'ASO: tendances, notes et commentaires</a></li>
<li><a href="../fr460343/index.html">L'histoire de la façon dont le développement de jeux est devenu une partie de ma vie</a></li>
<li><a href="../fr460345/index.html">Installer et configurer Sonata Admin sur Symfony 4</a></li>
<li><a href="../fr460347/index.html">Gestion des appareils mobiles et plus encore avec la solution UEM de Sophos</a></li>
<li><a href="../fr460349/index.html">Cartes d'accélération Check Point Falcon - Accélération du traitement du trafic</a></li>
<li><a href="../fr460353/index.html">Réseau de neurones dans le verre. Ne nécessite pas d'alimentation, reconnaît les chiffres</a></li>
<li><a href="../fr460355/index.html">Sauver la noyade est notre métier: comment gérer la démotivation des équipes</a></li>
<li><a href="../fr460359/index.html">Cours Young Game Designer 2: équilibrer la progression et la dynamique sans mathématiques</a></li>
<li><a href="../fr460361/index.html">Grande FAQ sur la cybersécurité des systèmes d'information médicale</a></li>
<li><a href="../fr460363/index.html">7 facteurs manquants dans l'approche 12 Factor App</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
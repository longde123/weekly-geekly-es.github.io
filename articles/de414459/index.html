<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧐 🐅 👨🏻‍🌾 Detektoren und Deskriptoren von singulären Punkten FAST, BRIEF, ORB 🖕 🧑🏾‍🤝‍🧑🏽 🔻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dieser Artikel konzentriert sich auf einige Suchalgorithmen und Beschreibungen bestimmter Bildpunkte. Hier wurde dieses Thema bereits mehr als einmal ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Detektoren und Deskriptoren von singulären Punkten FAST, BRIEF, ORB</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414459/">  Dieser Artikel konzentriert sich auf einige Suchalgorithmen und Beschreibungen bestimmter Bildpunkte.  Hier wurde dieses Thema bereits mehr <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">als einmal</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">angesprochen</a> .  Ich werde berücksichtigen, dass die grundlegenden Definitionen dem Leser bereits bekannt sind. Wir werden die heuristischen Algorithmen FAST, FAST-9, FAST-ER, BRIEF, rBRIEF, ORB im Detail untersuchen und die ihnen zugrunde liegenden funkelnden Ideen diskutieren.  Zum Teil wird dies eine freie Übersetzung des Wesens mehrerer Artikel sein [1,2,3,4,5], es wird einen Code für "try" geben. <br><br><img src="https://pp.userapi.com/c846418/v846418322/73b6d/09CAYMQuFMs.jpg" alt="Bild"><br><a name="habracut"></a><br><h1>  SCHNELLER Algorithmus </h1><br>  FAST, erstmals 2005 in [1] vorgeschlagen, war eine der ersten heuristischen Methoden zum Auffinden einzelner Punkte, die aufgrund ihrer Recheneffizienz große Popularität erlangte.  Um zu entscheiden, ob ein bestimmter Punkt C als speziell betrachtet werden soll oder nicht, berücksichtigt diese Methode die Helligkeit von Pixeln auf einem Kreis, der auf Punkt C und Radius 3 zentriert ist: <br><br><img src="https://pp.userapi.com/c848536/v848536622/5559/qPxNkhmqJSU.jpg" alt="Bild"><br><br>  Wenn wir die Helligkeit der Pixel des Kreises mit der Helligkeit des Zentrums C vergleichen, erhalten wir jeweils drei mögliche Ergebnisse (heller, dunkler, wie es scheint): <br><br><math> </math> $ inline $ \ begin {array} {l} {I_p}&gt; {I_C} + t \\ {I_p} &lt;{I_C} -t \\ {I_C} -t &lt;{I_p} &lt;{I_C} + t \ end {array} $ inline $ <br><br>  Hier ist I die Helligkeit der Pixel, t ist eine vorbestimmte Helligkeitsschwelle. <br>  Ein Punkt wird als speziell markiert, wenn in einer Reihe n = 12 Pixel dunkler oder 12 Pixel heller als die Mitte sind. <br><br>  Wie die Praxis im Durchschnitt gezeigt hat, mussten für eine Entscheidung etwa 9 Punkte überprüft werden.  Um den Prozess zu beschleunigen, schlugen die Autoren vor, zunächst nur vier Pixel mit Zahlen zu überprüfen: 1, 5, 9, 13. Wenn unter ihnen 3 Pixel heller oder dunkler sind, wird eine vollständige Überprüfung an 16 Punkten durchgeführt, andernfalls wird der Punkt sofort als „markiert nicht besonders. "  Dies verkürzt die Arbeitszeit erheblich. Für eine Entscheidung im Durchschnitt reicht es aus, nur etwa 4 Punkte eines Kreises abzufragen. <br><br>  Hier liegt ein bisschen naiver Code <br>  Variable Parameter (im Code beschrieben): Kreisradius (nimmt die Werte 1,2,3 an), Parameter n (im Original n = 12), Parameter t.  Der Code öffnet die Datei in.bmp, verarbeitet das Bild und speichert es in out.bmp.  Bilder sind gewöhnliche 24-Bit. <br><br><h1>  Erstellen eines Entscheidungsbaums, Tree FAST, FAST-9 </h1><br>  Im Jahr 2006 war es in [2] möglich, eine originelle Idee mithilfe von maschinellem Lernen und Entscheidungsbäumen zu entwickeln. <br><br>  Das Original FAST hat folgende Nachteile: <br><br><ul><li>  Mehrere benachbarte Pixel können als Sonderpunkte markiert werden.  Wir brauchen ein gewisses Maß für die "Stärke" eines Features.  Eine der ersten vorgeschlagenen Maßnahmen ist der Maximalwert von t, bei dem der Punkt noch als Sonderwert angenommen wird. </li><li>  Ein schneller 4-Punkte-Test wird nicht für n weniger als 12 verallgemeinert. So werden beispielsweise visuell die besten Ergebnisse der Methode mit n = 9 und nicht mit 12 erzielt. </li><li>  Ich möchte auch den Algorithmus beschleunigen! </li></ul><br>  Anstatt eine Kaskade von zwei Tests mit 4 und 16 Punkten zu verwenden, wird vorgeschlagen, alles in einem Durchgang durch den Entscheidungsbaum zu erledigen.  Ähnlich wie bei der ursprünglichen Methode werden wir die Helligkeit des Mittelpunkts mit den Punkten auf dem Kreis vergleichen, aber in dieser Reihenfolge, um die Entscheidung so schnell wie möglich zu treffen.  Und es stellt sich heraus, dass Sie im Durchschnitt nur für ~ 2 (!!!) Vergleiche eine Entscheidung treffen können. <br><br>  Das Salz ist, wie man die richtige Reihenfolge für den Vergleich von Punkten findet.  Finden Sie mit maschinellem Lernen.  Angenommen, jemand hat für uns auf dem Bild viele Besonderheiten festgestellt.  Wir werden sie als eine Reihe von Schulungsbeispielen verwenden, und die Idee ist, <u>eifrig</u> diejenige auszuwählen, die in diesem Schritt die größte Menge an Informationen als nächsten Punkt liefert.  Angenommen, anfangs gab es in unserer Stichprobe 5 singuläre Punkte und 5 nicht singuläre Punkte.  In Form einer Tablette wie dieser: <br><br><img src="https://pp.userapi.com/c848536/v848536622/5596/A83hqZFlbWY.jpg" alt="Bild"><br><br>  Jetzt wählen wir eines der Pixel p des Kreises und vergleichen für alle singulären Punkte das zentrale Pixel mit dem ausgewählten.  Abhängig von der Helligkeit des ausgewählten Pixels in der Nähe jedes bestimmten Punkts kann die Tabelle das folgende Ergebnis haben: <br><br><img src="https://pp.userapi.com/c848536/v848536622/559d/A1CIWhE_LV8.jpg" alt="Bild"><br><br>  Die Idee ist, einen Punkt p so zu wählen, dass die Zahlen in den Spalten der Tabelle so unterschiedlich wie möglich sind.  Und wenn wir jetzt für einen neuen unbekannten Punkt das Vergleichsergebnis „Leichter“ erhalten, können wir bereits sofort sagen, dass der Punkt „nicht speziell“ ist (siehe Tabelle).  Der Prozess wird rekursiv fortgesetzt, bis die Punkte nur einer der Klassen in jede Gruppe fallen, nachdem sie in "dunkler wie heller" unterteilt wurden.  Es stellt sich ein Baum der folgenden Form heraus: <br><br><img src="https://pp.userapi.com/c848536/v848536622/55a4/W7idq5TQQZ4.jpg" alt="Bild"><br><br>  Der Binärwert befindet sich in den Blättern des Baums (Rot ist speziell, Grün ist nicht speziell) und an den anderen Eckpunkten des Baums befindet sich die Nummer des Punkts, der analysiert werden muss.  Insbesondere schlagen sie im Originalartikel vor, die Punktnummer durch Ändern der Entropie zu wählen.  Die Entropie der Punktmenge wird berechnet: <br><br><p><math> </math> $$ display $$ H = \ left ({c + \ overline c} \ right) {\ log _2} \ left ({c + \ overline c} \ right) - c {\ log _2} c - \ overline c {\ log _2} \ overline c $$ display $$ </p><br><br>  c ist die Anzahl der singulären Punkte, <math> </math> $ inline $ {\ bar c} $ inline $   Ist die Anzahl der nicht singulären Punkte der Menge <br><br>  Entropieänderung nach Verarbeitungspunkt p: <br><br><p><math> </math> $$ Anzeige $$ \ Delta H = H - {H_ {dunkel}} - {H_ {gleich}} - {H_ {hell}} $$ Anzeige $$ </p><br><br>  Dementsprechend wird ein Punkt ausgewählt, für den die Änderung der Entropie maximal ist.  Der Aufteilungsprozess stoppt, wenn die Entropie Null ist, was bedeutet, dass alle Punkte entweder singulär sind oder umgekehrt - alle sind nicht speziell.  Bei einer Software-Implementierung wird der gefundene Entscheidungsbaum nach alledem in eine Reihe von Konstruktionen vom Typ "if-else" konvertiert. <br><br>  Der letzte Schritt des Algorithmus ist die Unterdrückung von Nichtmaxima, um einen von mehreren benachbarten Punkten zu erhalten.  Die Entwickler schlagen vor, das ursprüngliche Maß basierend auf der Summe der absoluten Differenzen zwischen dem Mittelpunkt und den Punkten des Kreises in dieser Form zu verwenden: <br><br><p><math> </math> $$ display $$ V = \ max \ left ({\ sum \ limit_ {x \ in {S_ {bright}}} {\ left | {{I_x} - {I_p}} \ right | - t, \ sum \ Limits_ {x \ in {S_ {dark}}} {\ left | {{I_p} - {I_x}} \ right | - t}}} \ right) $$ display $$ </p><br><br>  Hier <math> </math> $ inline $ {S_ {bright}} $ inline $   und <math> </math> $ inline $ {S_ {dark}} $ inline $   Gruppen von Pixeln sind heller und dunkler, t ist der Schwellenhelligkeitswert, <math> </math> $ inline $ {I_p} $ inline $   - Helligkeit des zentralen Pixels, <math> </math> $ inline $ {{I_x}} $ inline $   - Helligkeit des Pixels auf dem Kreis.  Sie können den Algorithmus mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">folgenden Code</a> ausprobieren.  Der Code wird aus OpenCV übernommen und von allen Abhängigkeiten befreit. Führen Sie ihn einfach aus. <br><br><h1>  Entscheidungsbaum optimieren - FAST-ER </h1><br>  FAST-ER [3] ist ein Algorithmus der gleichen Autoren wie der vorherige, ein schneller Detektor ist ähnlich aufgebaut, die optimale Folge von Punkten wird ebenfalls zum Vergleich gesucht, ein Entscheidungsbaum wird ebenfalls erstellt, jedoch unter Verwendung einer anderen Methode - der Optimierungsmethode. <br><br>  Wir verstehen bereits, dass ein Detektor als Entscheidungsbaum dargestellt werden kann.  Wenn wir ein Kriterium zum Vergleichen der Leistung verschiedener Bäume hatten, können wir dieses Kriterium maximieren, indem wir verschiedene Baumvarianten sortieren.  Als solches Kriterium wird vorgeschlagen, "Wiederholbarkeit" zu verwenden. <br><br>  Die Wiederholbarkeit zeigt, wie gut die einzelnen Punkte einer Szene aus verschiedenen Winkeln erfasst werden.  Für ein Paar von Bildern wird ein Punkt als "nützlich" bezeichnet, wenn er auf einem Rahmen gefunden wird und theoretisch auf einem anderen gefunden werden kann, d. H.  Blockieren Sie nicht die Elemente der Szene.  Und der Punkt heißt "wiederholt" (wiederholt), wenn er auch im zweiten Frame gefunden wird.  Da die Kameraoptik nicht ideal ist, befindet sich der Punkt auf dem zweiten Bild möglicherweise nicht im berechneten Pixel, sondern irgendwo in der Nähe.  Die Entwickler nahmen eine Nachbarschaft von 5 Pixeln.  Wir definieren Wiederholbarkeit als das Verhältnis der Anzahl der wiederholten Punkte zur Anzahl der nützlichen: <br><br><p><math> </math> $$ Anzeige $$ R = \ frac {{{N_ {wiederholt}}}} {{{N_ {nützlich}}} $$ Anzeige $$ </p><br><br>  Um den besten Detektor zu finden, wird eine Tempersimulationsmethode verwendet.  Es gibt bereits einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ausgezeichneten Artikel</a> über Habré über ihn.  Kurz gesagt, das Wesentliche der Methode ist wie folgt: <br><br><ul><li>  Es wird eine erste Lösung für das Problem ausgewählt (in unserem Fall handelt es sich um eine Art Detektorbaum). </li><li>  Wiederholbarkeit wird berücksichtigt. </li><li>  Der Baum wird zufällig geändert. </li><li>  Wenn die modifizierte Version nach dem Kriterium der Wiederholbarkeit besser ist, wird die Modifikation akzeptiert, und wenn sie schlechter ist, kann sie mit einer gewissen Wahrscheinlichkeit, die von einer reellen Zahl namens "Temperatur" abhängt, entweder akzeptiert werden oder nicht.  Mit zunehmender Anzahl von Iterationen fällt die Temperatur auf Null. </li></ul><br>  Außerdem umfasst der Aufbau des Detektors jetzt nicht mehr wie zuvor 16 Punkte des Kreises, sondern 47, aber die Bedeutung ändert sich überhaupt nicht: <br><br><img src="https://pp.userapi.com/c824411/v824411841/1607f1/5szVOBYHeck.jpg" alt="Bild"><br><br>  Nach der simulierten Glühmethode definieren wir drei Funktionen: <br><br>  • Kostenfunktion k.  In unserem Fall verwenden wir die Wiederholbarkeit als Wert.  Es gibt jedoch ein Problem.  Stellen Sie sich vor, dass alle Punkte auf jedem der beiden Bilder als Singular erkannt werden.  Dann stellt sich heraus, dass die Wiederholbarkeit 100% ist - Absurdität.  Auf der anderen Seite, auch wenn wir einen bestimmten Punkt in zwei Bildern gefunden haben und diese Punkte übereinstimmen - die Wiederholbarkeit ist ebenfalls 100%, aber das interessiert uns auch nicht.  Und deshalb schlugen die Autoren vor, dies als Qualitätskriterium zu verwenden: <br><br><p><math> </math> $$ display $$ k = \ left ({1 + {{\ left ({\ frac {{{w_r}}} {R}} \ right)} ^ 2}} \ right) \ left ({1 + \ frac {1} {N} \ sum \ limit_ {i = 1} {{{\ left ({\ frac {{{d_i}}} {{{w_n}}} right)} ^ 2}} \ rechts) \ links ({1 + {{\ links ({\ frac {s} {{{w_s}}}} rechts)} ^ 2}} \ rechts) $$ display $$ </p><br><br>  r ist die Wiederholbarkeit <math> </math> $ inline $ {{d_i}} $ inline $   Ist die Anzahl der erkannten Winkel auf Bild i, N ist die Anzahl der Bilder und s ist die Größe des Baums (Anzahl der Eckpunkte).  W sind benutzerdefinierte Methodenparameter.] <br><br>  • Funktion der Temperaturänderung über die Zeit: <br><br><p><math> </math> $$ display $$ T \ left (I \ right) = \ beta \ exp \ left ({- \ frac {{\ alpha I}} {{{I _ {\ max}}} \ right) $$ display $$ </p><br><br>  wo <math> </math> $ inline $ \ alpha, \ beta $ inline $   Sind die Koeffizienten, ist Imax die Anzahl der Iterationen. <br><br>  • Eine Funktion, die eine neue Lösung generiert.  Der Algorithmus nimmt zufällige Änderungen am Baum vor.  Wählen Sie zunächst einen Scheitelpunkt aus.  Wenn der ausgewählte Scheitelpunkt ein Blatt eines Baumes ist, gehen wir mit gleicher Wahrscheinlichkeit wie folgt vor: <br><br><ol><li>  Ersetzen Sie den Scheitelpunkt durch einen zufälligen Teilbaum mit der Tiefe 1 </li><li>  Ändern Sie die Klasse dieses Blattes (Singular-Nicht-Singular-Punkte) </li></ol><br>  Wenn dies KEIN Blatt ist: <br><br><ol><li>  Ersetzen Sie die Nummer des getesteten Punktes durch eine Zufallszahl von 0 bis 47 </li><li>  Ersetzen Sie den Scheitelpunkt durch ein Blatt mit einer zufälligen Klasse </li><li>  Tauschen Sie zwei Teilbäume von diesem Scheitelpunkt aus </li></ol><br>  Die Wahrscheinlichkeit P, die Änderung bei Iteration I zu akzeptieren, ist: <br><math> </math> $ inline $ P = \ exp \ left ({\ frac {{k \ left ({i - 1} \ right) - k \ left (i \ right)}} {T}} \ right) $ inline $ <br>  k ist die Kostenfunktion, T ist die Temperatur, i ist die Iterationszahl. <br><br>  Diese Änderungen am Baum ermöglichen sowohl das Wachstum des Baumes als auch dessen Reduzierung.  Die Methode ist zufällig und garantiert nicht, dass der beste Baum erhalten wird.  Führen Sie die Methode viele Male aus und wählen Sie die beste Lösung aus.  Im Originalartikel werden sie beispielsweise 100 Mal pro 100.000 Iterationen ausgeführt, was 200 Stunden Prozessorzeit in Anspruch nimmt.  Wie die Ergebnisse zeigen, ist das Ergebnis besser als Tree FAST, insbesondere bei verrauschten Bildern. <br><br><h1>  KURZER Deskriptor </h1><br>  Nachdem die singulären Punkte gefunden wurden, werden ihre Deskriptoren berechnet, d.h.  Sätze von Merkmalen, die die Nachbarschaft jedes einzelnen Punktes charakterisieren.  BRIEF [4] ist ein schneller heuristischer Deskriptor, der aus 256 binären Vergleichen zwischen der Helligkeit der Pixel in einem <u>verschwommenen</u> Bild aufgebaut ist.  Der binäre Test zwischen den Punkten x und y ist wie folgt definiert: <br><br><p><math> </math> $$ display $$ \ tau \ left ({P, x, y} \ right): = \ left \ {{\ begin {array} {* {20} {c}} {1: p \ left (x \ rechts) &lt;p \ left (y \ right)} \\ {0: p \ left (x \ right) \ ge p \ left (y \ right)} \ end {array}} \ right. $$ display $$ </p><br><br><img src="https://pp.userapi.com/c824411/v824411841/160801/dMWJxyV422c.jpg" alt="Bild"><br><br>  Im ursprünglichen Artikel wurden verschiedene Methoden zur Auswahl von Punkten für binäre Vergleiche berücksichtigt.  Wie sich herausstellte, besteht eine der besten Möglichkeiten darin, Punkte mithilfe einer Gaußschen Verteilung um ein zentrales Pixel zufällig auszuwählen.  Diese zufällige Folge von Punkten wird einmal ausgewählt und ändert sich nicht weiter.  Die Größe der betrachteten Nachbarschaft des Punktes beträgt 31 x 31 Pixel, und die Unschärfeöffnung beträgt 5. <br><br>  Der resultierende binäre Deskriptor ist resistent gegen Änderungen der Beleuchtung, perspektivische Verzerrungen, wird schnell berechnet und verglichen, ist jedoch sehr instabil gegenüber Rotationen in der Bildebene. <br><br><h1>  ORB - schnell und effizient </h1><br>  Die Entwicklung all dieser Ideen war der ORB-Algorithmus (Oriented FAST and Rotated BRIEF) [5], bei dem versucht wurde, die BRIEF-Leistung während der Bildrotation zu verbessern.  Es wird vorgeschlagen, zuerst die Orientierung des Singularpunkts zu berechnen und dann binäre Vergleiche gemäß dieser Orientierung durchzuführen.  Der Algorithmus funktioniert folgendermaßen: <br><br>  1) Feature-Punkte werden mithilfe des schnellen FAST-Baums im Originalbild und in mehreren Bildern aus der Miniaturpyramide erkannt. <br><br>  2) Für die erkannten Punkte wird das Harris-Maß berechnet, Kandidaten mit einem niedrigen Wert des Harris-Maßes werden verworfen. <br><br>  3) Der Orientierungswinkel des Singularpunktes wird berechnet.  Dazu werden zunächst die Helligkeitsmomente für die Nachbarschaft des Singularpunktes berechnet: <br><br><math> </math> $ inline $ {m_ {pq}} = \ sum \ limit_ {x, y} {{x ^ p} {y ^ q} I \ left ({x, y} \ right)} $ inline $ <br>  x, y - Pixelkoordinaten, I - Helligkeit.  Und dann der Orientierungswinkel des singulären Punktes: <br><math> </math> $ inline $ \ theta = {\ rm {atan2}} \ left ({{m_ {01}}, {m_ {10}}} \ right) $ inline $ <br><br>  All dies nannten die Autoren die "Schwerpunktorientierung".  Als Ergebnis erhalten wir eine bestimmte Richtung für die Nachbarschaft des singulären Punktes. <br><br>  4) Mit dem Orientierungswinkel des Singularpunkts dreht sich die Folge von Punkten für binäre Vergleiche im BRIEF-Deskriptor entsprechend diesem Winkel, zum Beispiel: <br><br><img src="https://pp.userapi.com/c824411/v824411841/160813/y5R3uZYvsfQ.jpg" alt="Bild"><br><br>  Formal werden die neuen Positionen für die binären Testpunkte wie folgt berechnet: <br><br><p><math> </math> $$ display $$ \ left ({\ begin {array} {* {20} {c}} {{x_i} '} \\ {{y_i}'} \ end {array}} \ right) = R \ left (\ theta \ right) \ cdot \ left ({\ begin {array} {* {20} {c}} {{x_i}} \\ {{y_i}} \ end {array}} \ right) $$ Anzeige $$ </p><br><br>  5) Basierend auf den empfangenen Punkten wird der BRIEF-Binärdeskriptor berechnet <br><br>  Und das ist ... nicht alles!  Es gibt ein weiteres interessantes Detail in ORB, das einer gesonderten Erläuterung bedarf.  Tatsache ist, dass in dem Moment, in dem wir alle singulären Punkte auf einen Nullwinkel „drehen“, die zufällige Auswahl von binären Vergleichen im Deskriptor nicht mehr zufällig ist.  Dies führt dazu, dass sich erstens einige binäre Vergleiche als voneinander abhängig herausstellen und zweitens ihr Durchschnitt nicht mehr gleich 0,5 ist (1 ist heller, 0 ist dunkler, wenn die Auswahl zufällig war, es war durchschnittlich 0,5). All dies verringert die Fähigkeit des Deskriptors, einzelne Punkte untereinander zu unterscheiden, erheblich. <br><br>  Lösung - Sie müssen im Lernprozess die „richtigen“ Binärtests auswählen. Diese Idee hat den gleichen Geschmack wie das Baumtraining für den FAST-9-Algorithmus.  Angenommen, wir haben bereits eine Reihe einzelner Punkte gefunden.  Berücksichtigen Sie alle möglichen Optionen für binäre Tests.  Wenn die Nachbarschaft 31 x 31 ist und der Binärtest ein Paar von 5 x 5 Teilmengen ist (aufgrund von Unschärfe), gibt es viele Optionen für die Auswahl von N = (31-5) ^ 2.  Der Suchalgorithmus für "gute" Tests lautet wie folgt: <br><br><ol><li>  Wir berechnen das Ergebnis aller Tests für alle singulären Punkte </li><li>  Ordnen Sie die gesamte Testreihe entsprechend ihrem Abstand vom Durchschnitt von 0,5 an </li><li>  Erstellen Sie eine Liste mit den ausgewählten "guten" Tests. Rufen Sie die Liste R auf. </li><li>  Fügen Sie den ersten Test aus dem sortierten Satz zu R hinzu </li><li>  Wir nehmen den nächsten Test und vergleichen ihn mit allen Tests in R. Wenn die Korrelation größer als der Schwellenwert ist, verwerfen wir den neuen Test, andernfalls fügen wir ihn hinzu. </li><li>  Wiederholen Sie Schritt 5, bis Sie die erforderliche Anzahl von Tests eingegeben haben. </li></ol><br>  Es stellt sich heraus, dass die Tests so ausgewählt werden, dass einerseits der Durchschnittswert dieser Tests so nahe wie möglich bei 0,5 liegt, andererseits die Korrelation zwischen verschiedenen Tests minimal ist.  Und das brauchen wir.  Vergleichen Sie, wie es war und wie es wurde: <br><br><img src="https://pp.userapi.com/c824411/v824411841/160829/ozQhEUvtdBs.jpg" alt="Bild"><br><br>  Glücklicherweise ist der ORB-Algorithmus in der OpenCV-Bibliothek in der Klasse cv :: ORB implementiert.  Ich benutze Version 2.4.13.  Der Klassenkonstruktor akzeptiert die folgenden Parameter: <br><br>  nfeatures - maximale Anzahl von Einzelpunkten <br>  scaleFactor - Multiplikator für die Bildpyramide, mehr als eine.  Wert 2 implementiert die klassische Pyramide. <br>  Ebenen - die Anzahl der Ebenen in der Bildpyramide. <br>  edgeThreshold - Die Anzahl der Pixel am Bildrand, an denen einzelne Punkte nicht erkannt werden. <br>  firstLevel - lass Null. <br>  WTA_K - Die Anzahl der Punkte, die für ein Element des Deskriptors erforderlich sind.  Wenn gleich 2, wird die Helligkeit von zwei zufällig ausgewählten Pixeln verglichen.  Dies ist, was benötigt wird. <br>  scoreType - wenn 0, dann wird harris als Merkmalsmaß verwendet, andernfalls - das FAST-Maß (basierend auf der Summe der Module der Helligkeitsunterschiede an den Punkten des Kreises).  Das FAST-Maß ist etwas weniger stabil, aber schneller. <br>  patchSize - Die Größe der Nachbarschaft, aus der zufällige Pixel zum Vergleich ausgewählt werden.  Der Code sucht und vergleicht die einzelnen Punkte in zwei Bildern, "templ.bmp" und "img.bmp". <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre><code class="cpp hljs">cv::Mat img_object=cv::imread(<span class="hljs-string"><span class="hljs-string">"templ.bmp"</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>); <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;cv::KeyPoint&gt; keypoints_object, keypoints_scene; cv::Mat descriptors_object, descriptors_scene; cv::<span class="hljs-function"><span class="hljs-function">ORB </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">orb</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">500</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">4</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">31</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">31</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span></span>; <span class="hljs-comment"><span class="hljs-comment">//    orb.detect(img_object, keypoints_object); orb.compute(img_object, keypoints_object, descriptors_object); //    cv::Mat img = cv::imread("img.bmp", 1); cv::Mat img_scene = cv::Mat(img.size(), CV_8UC1); orb.detect(img, keypoints_scene); orb.compute(img, keypoints_scene, descriptors_scene); cv::imshow("desrs", descriptors_scene); cvWaitKey(); int test[10]; for (int q = 0; q&lt;10 ; q++) test[q]=descriptors_scene.data[q]; //-- matching descriptor vectors using FLANN matcher cv::BFMatcher matcher; std::vector&lt;cv::DMatch&gt; matches; cv::Mat img_matches; if(!descriptors_object.empty() &amp;&amp; !descriptors_scene.empty()) { matcher.match (descriptors_object, descriptors_scene, matches); double max_dist = 0; double min_dist = 100; // calculation of max and min idstance between keypoints for( int i = 0; i &lt; descriptors_object.rows; i++) { double dist = matches[i].distance; if( dist &lt; min_dist ) min_dist = dist; if( dist &gt; max_dist ) max_dist = dist; } //-- Draw only good matches (ie whose distance is less than 3*min_dist) std::vector&lt; cv::DMatch &gt;good_matches; for( int i = 0; i &lt; descriptors_object.rows; i++ ) if( matches[i].distance &lt; (max_dist/1.6) ) good_matches.push_back(matches[i]); cv::drawMatches(img_object, keypoints_object, img_scene, keypoints_scene, good_matches, img_matches, cv::Scalar::all(-1), cv::Scalar::all(-1), std::vector&lt;char&gt;(), cv::DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS); } cv::imshow("match result", img_matches ); cv::waitKey(); return 0;</span></span></code> </pre> <br></div></div><br>  Wenn jemand geholfen hat, die Essenz der Algorithmen zu verstehen, ist dies nicht umsonst.  An alle Habr. <br><br>  Referenzen: <br><br>  1. Zusammenführen von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Punkten und Linien für die Hochleistungsverfolgung</a> <br>  2. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Maschinelles Lernen zur schnellen Kurvenerkennung</a> <br>  3. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schneller und besser: Ein Ansatz des maschinellen Lernens zur Eckenerkennung</a> <br>  4. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">KURZDARSTELLUNG: Binär robuste, unabhängige Elementarfunktionen</a> <br>  5. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ORB: eine effiziente Alternative zu SIFT oder SURF</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de414459/">https://habr.com/ru/post/de414459/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de414447/index.html">Sorten aller Zeiten</a></li>
<li><a href="../de414449/index.html">Wie man sich mit allen Betreibern im Stadion anfreundet und es nicht mit Hunderten von Antennen sät</a></li>
<li><a href="../de414451/index.html">"Testerkalender" für Juni. Der Tester muss den Fehler erkennen, Caner lesen und den Umzug organisieren.</a></li>
<li><a href="../de414453/index.html">Implementieren Sie den Pfadfinder für KI-Agenten mit NavMesh</a></li>
<li><a href="../de414455/index.html">Algorithmus zur Erzeugung von Farbpaletten</a></li>
<li><a href="../de414463/index.html">AI selbst hat gelernt, wie man einen Zauberwürfel baut</a></li>
<li><a href="../de414465/index.html">Meta Crush Saga: Spiel zur Kompilierungszeit</a></li>
<li><a href="../de414467/index.html">Beiträge von der Minsk C ++ Konferenz CoreHard Spring 2018</a></li>
<li><a href="../de414469/index.html">Sicherheitswoche 22: Zwei Sekunden Smart Locks</a></li>
<li><a href="../de414471/index.html">11 Höllenkreise für diejenigen, denen es an Erfahrung in einem neuen Job mangelt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌀 🙍 🗣️ Le livre "Deep reinforcement learning in Python. OpenAI Gym et TensorFlow pour les pros » 👩🏻‍🤝‍👨🏼 👩🏾‍🤝‍👩🏻 👩🏻‍💼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Salut, habrozhiteli! L'apprentissage par renforcement est le domaine le plus populaire et prometteur de l'intelligence artificielle. L'apprentissage p...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le livre "Deep reinforcement learning in Python. OpenAI Gym et TensorFlow pour les pros »</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/465605/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/hf/sc/yz/hfscyzhjnopaerkvbdvf89gflfc.jpeg" align="left" alt="image"></a>  Salut, habrozhiteli!  L'apprentissage par renforcement est le domaine le plus populaire et prometteur de l'intelligence artificielle.  L'apprentissage pratique du RL en Python vous aidera à maîtriser non seulement les algorithmes de base, mais également les apprentissages approfondis avancés avec renforcement.  Ce livre est destiné aux développeurs de MO et aux passionnés de deep learning qui s'intéressent à l'intelligence artificielle et souhaitent apprendre la méthode d'apprentissage par renforcement.  Lisez ce livre et devenez un expert de l'apprentissage renforcé en mettant en œuvre des exemples pratiques au travail ou hors du travail.  Des connaissances en algèbre linéaire, en analyse mathématique et en langage de programmation Python vous aideront à comprendre la logique de la présentation. <br><a name="habracut"></a><br><h3>  Extrait.  Génération de paroles à l'aide de LSTM RNN </h3><br>  Voyons maintenant comment utiliser LSTM pour générer des paroles de Zayn Malik.  Le jeu de données de paroles de chansons de Zane peut être téléchargé à <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://github.com/sudharsan13296/Hands-On-Reinforcement-Learning-With-Python/blob/master/07.%20Deep%20Learning%20Fundamentals/data/ZaynLyrics.txt</a> . <br><br>  Le travail commence par l'importation des bibliothèques nécessaires: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np</code> </pre> <br>  Ensuite, le fichier avec les paroles est lu: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">"Zayn_Lyrics.txt"</span></span>,<span class="hljs-string"><span class="hljs-string">"r"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: data=f.read() data=data.replace(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>,<span class="hljs-string"><span class="hljs-string">''</span></span>) data = data.lower()</code> </pre> <br>  Assurez-vous que les données ont bien été téléchargées: <br><br><pre> <code class="python hljs">data[:<span class="hljs-number"><span class="hljs-number">50</span></span>] <span class="hljs-string"><span class="hljs-string">"now i'm on the edge can't find my way it's inside "</span></span></code> </pre> <br>  Maintenant, tous les caractères sont stockés dans la variable all_chars: <br><br><pre> <code class="plaintext hljs">all_chars=list(set(data))</code> </pre> <br>  Le nombre de caractères uniques est stocké dans unique_chars: <br><br><pre> <code class="python hljs">unique_chars = len(all_chars)</code> </pre> <br>  Et le nombre total de caractères est stocké dans la variable total_chars: <br><br><pre> <code class="python hljs">total_chars =len(data)</code> </pre> <br>  Nous attribuons d'abord à chaque caractère un index.  char_to_ix contiendra le mappage du caractère à l'index, et ix_to_char contiendra le mappage du caractère à l'index: <br><br><pre> <code class="python hljs">char_to_ix = { ch:i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i,ch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(all_chars) } ix_to_char = { i:ch <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i,ch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(all_chars) }</code> </pre> <br>  Un exemple: <br><br><pre> <code class="python hljs">char_to_ix[<span class="hljs-string"><span class="hljs-string">'e'</span></span>] <span class="hljs-number"><span class="hljs-number">9</span></span> ix_to_char[<span class="hljs-number"><span class="hljs-number">9</span></span>] e</code> </pre> <br>  Ensuite, la fonction generate_batch est définie, ce qui génère les valeurs d'entrée et cible.  Les valeurs cibles sont égales au décalage de la valeur d'entrée fois i. <br><br>  Par exemple, si input = [12,13,24] avec une valeur de décalage de 1, alors les valeurs cibles seront [13,24]: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generate_batch</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(seq_length,i)</span></span></span><span class="hljs-function">:</span></span> inputs = [char_to_ix[ch] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data[i:i+seq_length]] targets = [char_to_ix[ch] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data[i+<span class="hljs-number"><span class="hljs-number">1</span></span>:i+seq_length+<span class="hljs-number"><span class="hljs-number">1</span></span>]] inputs=np.array(inputs).reshape(seq_length,<span class="hljs-number"><span class="hljs-number">1</span></span>) targets=np.array(targets).reshape(seq_length,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> inputs,targets</code> </pre> <br>  Nous déterminerons la longueur de la séquence, la vitesse d'apprentissage et le nombre de nœuds, qui est égal au nombre de neurones: <br><br><pre> <code class="python hljs">seq_length = <span class="hljs-number"><span class="hljs-number">25</span></span> learning_rate = <span class="hljs-number"><span class="hljs-number">0.1</span></span> num_nodes = <span class="hljs-number"><span class="hljs-number">300</span></span></code> </pre> <br>  Construisez le LSTM RNN.  TensorFlow fournit la fonction BasicLSTMCell () pour construire des cellules LSTM;  vous devez spécifier le nombre d'unités dans la cellule LSTM et le type de fonction d'activation utilisé. <br><br>  Ainsi, nous créons la cellule LSTM et construisons le réseau RNN avec cette cellule en utilisant la fonction tf.nn.dynamic_rnn (), qui renvoie la sortie et la valeur d'état: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_rnn</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> cell= tf.contrib.rnn.BasicLSTMCell(num_units=num_nodes, activation=tf.nn.relu) outputs, states = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> outputs,states</code> </pre> <br>  Créez maintenant un substitut pour l'entrée X et la cible Y: <br><br><pre> <code class="python hljs">X=tf.placeholder(tf.float32,[<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>]) Y=tf.placeholder(tf.float32,[<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br>  Convertissez X et Y en int: <br><br><pre> <code class="python hljs">X=tf.cast(X,tf.int32) Y=tf.cast(Y,tf.int32)</code> </pre> <br>  Créez également des vues onehot pour X et Y: <br><br><pre> <code class="python hljs">X_onehot=tf.one_hot(X,unique_chars) Y_onehot=tf.one_hot(Y,unique_chars)</code> </pre> <br>  Obtenez les sorties et les états du RNN en appelant la fonction build_rnn: <br><br><pre> <code class="python hljs">outputs,states=build_rnn(X_onehot)</code> </pre> <br>  Transposer la sortie: <br><br><pre> <code class="python hljs">outputs=tf.transpose(outputs,perm=[<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>])</code> </pre> <br>  Nous initialisons les poids et les décalages: <br><br><pre> <code class="python hljs">W=tf.Variable(tf.random_normal((num_nodes,unique_chars),stddev=<span class="hljs-number"><span class="hljs-number">0.001</span></span>)) B=tf.Variable(tf.zeros((<span class="hljs-number"><span class="hljs-number">1</span></span>,unique_chars)))</code> </pre> <br>  Nous calculons la sortie en multipliant la sortie par le poids et en ajoutant le décalage: <br><br><pre> <code class="python hljs">Ys=tf.matmul(outputs[<span class="hljs-number"><span class="hljs-number">0</span></span>],W)+B</code> </pre> <br>  Nous allons maintenant effectuer une activation softmax et obtenir les probabilités: <br><br><pre> <code class="python hljs">prediction = tf.nn.softmax(Ys)</code> </pre> <br>  La perte de cross_entropy sera calculée comme suit: <br><br><pre> <code class="python hljs">cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels =Y_onehot,logits=Ys))</code> </pre> <br>  Notre objectif est de minimiser les pertes, nous allons donc effectuer une rétropropagation pour le réseau et effectuer une descente de gradient: <br><br><pre> <code class="python hljs">optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cro ss_entropy)</code> </pre> <br>  Ensuite, la fonction auxiliaire prédite sera définie, ce qui donnera les indices du prochain symbole prédit conformément au modèle RNN: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predict</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(seed,i)</span></span></span><span class="hljs-function">:</span></span> x=np.zeros((<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>)) x[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]= seed indices=[] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(i): p=sess.run(prediction,{X:x}) index = np.random.choice(range(unique_chars), p=p.ravel()) x[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]=index indices.append(index) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> indices</code> </pre> <br>  Ensuite, la taille du paquet batch_size, le nombre de paquets et le nombre d'eras, ainsi que la valeur de décalage pour générer le paquet seront définis: <br><br><pre> <code class="python hljs">batch_size=<span class="hljs-number"><span class="hljs-number">100</span></span> total_batch=int(total_chars//batch_size) epochs=<span class="hljs-number"><span class="hljs-number">1000</span></span> shift=<span class="hljs-number"><span class="hljs-number">0</span></span></code> </pre> <br>  Enfin, nous créons une session TensorFlow et construisons un modèle: <br><br><pre> <code class="python hljs">init=tf.global_variables_initializer() <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.Session() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sess: sess.run(init) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> epoch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(epoch): print(<span class="hljs-string"><span class="hljs-string">"Epoch {}:"</span></span>.format(epoch)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> shift + batch_size+<span class="hljs-number"><span class="hljs-number">1</span></span> &gt;= len(data): shift =<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#         # generate_batch,      shift, #    for i in range(total_batch): inputs,targets=generate_batch(batch_size,shift) shift += batch_size # calculate loss if(i%100==0): loss=sess.run(cross_entropy,feed_dict={X:inputs, Y:targets}) #      #    predict index =predict(inputs[0],200) #     ix_to_char #    txt = ''.join(ix_to_char[ix] for ix in index) print('Iteration %i: '%(i)) print ('\n %s \n' % (txt, )) sess.run(optimiser,feed_dict={X:inputs,Y:targets})</span></span></code> </pre> <br>  Comme vous pouvez le voir sur les résultats, à l'ère initiale, la sortie se compose de caractères aléatoires, mais comme vous l'apprenez, les résultats s'améliorent: <br><br><pre> <code class="python hljs">Epoch <span class="hljs-number"><span class="hljs-number">0</span></span>: Iteration <span class="hljs-number"><span class="hljs-number">0</span></span>: wsadrpud,kpswkypeqawnlfyweudkgt,khdi nmgo<span class="hljs-string"><span class="hljs-string">f' u vnvlmbis . snsblp,podwjqehb,e;g- '</span></span>fyqjsyeg,byjgyotsrdf;;u,ha;ik<span class="hljs-string"><span class="hljs-string">'sfc;dvtauofd.,q.;npsw'</span></span>wjy-quw<span class="hljs-string"><span class="hljs-string">'quspfqw- . . . Epoch 113: Iteration 0: i wanna see you, yes, and she said yes!</span></span></code> </pre> <br><h3>  À propos de l'auteur </h3><br>  <i>Sudharsan Ravichandiran</i> est un spécialiste du traitement et de l'analyse des données, un ardent fan de l'intelligence artificielle et un blogueur vidéo.  Il a obtenu un baccalauréat en informatique de l'Université Anne et mène des recherches sur la mise en œuvre pratique de l'apprentissage en profondeur et de l'apprentissage renforcé, y compris le traitement du langage naturel et la vision par ordinateur.  Auparavant, il a travaillé en tant que concepteur et développeur Web indépendant, a participé à la création de plusieurs sites primés.  Il participe actuellement à des projets open source et répond souvent aux questions sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Stack Overflow</a> . <br><br><h3>  À propos des rédacteurs scientifiques </h3><br>  <i>Sujit Pal</i> est directeur de la recherche technique chez Elsevier Labs, la dernière équipe de développement technologique du groupe Reed-Elsevier.  Il est engagé dans la recherche dans le domaine de la recherche sémantique, du traitement du langage naturel, de la machine et du deep learning.  Chez Elsevier, il a travaillé sur plusieurs projets d'initiative, notamment l'évaluation et l'amélioration de la qualité de la recherche, la classification des images et l'identification des doublons, l'annotation et le développement d'anthologies de textes médicaux et scientifiques.  Il a écrit un livre d'apprentissage approfondi avec Antonio Gulli et écrit sur la technologie sur son blog <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Salmon Run</a> . <br><br>  <i>Suriyadeepan Ramamoorthy</i> est un chercheur et ingénieur en intelligence artificielle d'un chercheur et ingénieur en intelligence artificielle à Pondichéry (Inde).  Le sujet principal de son travail est la compréhension des langues naturelles et la formation du raisonnement.  Il écrit beaucoup sur un blog d'apprentissage en profondeur.  Chez SAAMA Technologies, il utilise des méthodes avancées d'apprentissage en profondeur pour analyser des textes biomédicaux.  Fervent partisan du logiciel libre, il participe activement à des projets pour son développement dans la communauté FSFTN.  Il s'intéresse également aux réseaux collaboratifs, à la visualisation de données et à la programmation créative. <br><br>  »Plus d'informations sur le livre sont disponibles sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le site Web de l'éditeur</a> <br>  » <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Contenu</a> <br>  » <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Extrait</a> <br><br>  25% de réduction sur les colporteurs - <b>Python</b> <br><br>  Lors du paiement de la version papier du livre, un livre électronique est envoyé par e-mail. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr465605/">https://habr.com/ru/post/fr465605/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr465595/index.html">La 5G vient à nous?</a></li>
<li><a href="../fr465597/index.html">Apprentissage du démarrage lent de STM8S. Partie 0</a></li>
<li><a href="../fr465599/index.html">IPFS sans douleur (mais ce n'est pas précis)</a></li>
<li><a href="../fr465601/index.html">Pourquoi avez-vous besoin de DevOps et qui sont des spécialistes DevOps</a></li>
<li><a href="../fr465603/index.html">Cours vs stage. Comment enseignons-nous les midbells chez SimbirSoft</a></li>
<li><a href="../fr465607/index.html">Comprendre le Lean et l'Agile dans le développement de logiciels</a></li>
<li><a href="../fr465609/index.html">Pourquoi 1C-Bitrix du 1er décembre 2019 peut se transformer en citrouille</a></li>
<li><a href="../fr465611/index.html">Musique pour le programmeur</a></li>
<li><a href="../fr465613/index.html">Un guide complet des tableaux et des tranches de Golang</a></li>
<li><a href="../fr465615/index.html">Verrous intelligents: ce qu'ils sont, comment ils fonctionnent (et qui les installe)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
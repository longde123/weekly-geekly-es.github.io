<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ¤šğŸ¿ ğŸ–ğŸ¾ ğŸ’†ğŸ» Cassandra Sinkç”¨äºSparkç»“æ„åŒ–æµ ğŸ‘†ğŸ¼ ğŸ’„ â®ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="å‡ ä¸ªæœˆå‰ï¼Œæˆ‘å¼€å§‹ç ”ç©¶Sparkï¼Œåœ¨æŸä¸ªæ—¶å€™ï¼Œæˆ‘é¢ä¸´ç€å°†ç»“æ„åŒ–æµè®¡ç®—ä¿å­˜åœ¨Cassandraæ•°æ®åº“ä¸­çš„é—®é¢˜ã€‚ 

 åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ç»™å‡ºäº†ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼Œè¯¥ç¤ºä¾‹åˆ›å»ºå’Œä½¿ç”¨Cassandra Sinkè¿›è¡ŒSparkç»“æ„åŒ–æµä¼ è¾“ã€‚ æˆ‘å¸Œæœ›è¯¥å¸–å­å¯¹æœ€è¿‘å¼€å§‹ä½¿ç”¨Spark Structured Streaming...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cassandra Sinkç”¨äºSparkç»“æ„åŒ–æµ</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/425503/"> å‡ ä¸ªæœˆå‰ï¼Œæˆ‘å¼€å§‹ç ”ç©¶Sparkï¼Œåœ¨æŸä¸ªæ—¶å€™ï¼Œæˆ‘é¢ä¸´ç€å°†ç»“æ„åŒ–æµè®¡ç®—ä¿å­˜åœ¨Cassandraæ•°æ®åº“ä¸­çš„é—®é¢˜ã€‚ <br><br> åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ç»™å‡ºäº†ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼Œè¯¥ç¤ºä¾‹åˆ›å»ºå’Œä½¿ç”¨Cassandra Sinkè¿›è¡ŒSparkç»“æ„åŒ–æµä¼ è¾“ã€‚ æˆ‘å¸Œæœ›è¯¥å¸–å­å¯¹æœ€è¿‘å¼€å§‹ä½¿ç”¨Spark Structured Streamingå¹¶æƒ³çŸ¥é“å¦‚ä½•å°†è®¡ç®—ç»“æœä¸Šè½½åˆ°æ•°æ®åº“çš„äººå‘˜æœ‰ç”¨ã€‚ <br><br> è¯¥åº”ç”¨ç¨‹åºçš„æƒ³æ³•éå¸¸ç®€å•-æ¥æ”¶å’Œè§£ææ¥è‡ªKafkaçš„æ¶ˆæ¯ï¼Œæˆå¯¹æ‰§è¡Œç®€å•çš„è½¬æ¢å¹¶å°†ç»“æœä¿å­˜åœ¨cassandraä¸­ã€‚ <br><a name="habracut"></a><br><h3> ç»“æ„åŒ–æµçš„ä¼˜ç‚¹ </h3><br> æ‚¨å¯ä»¥åœ¨<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">æ–‡æ¡£ä¸­</a>é˜…è¯»æœ‰å…³ç»“æ„åŒ–æµçš„æ›´å¤šä¿¡æ¯ã€‚ ç®€è€Œè¨€ä¹‹ï¼Œç»“æ„åŒ–æµæ˜¯åŸºäºSpark SQLå¼•æ“çš„å¯æ‰©å±•çš„æµä¿¡æ¯å¤„ç†å¼•æ“ã€‚ å®ƒå…è®¸æ‚¨ä½¿ç”¨Dataset / DataFrameèšåˆæ•°æ®ï¼Œè®¡ç®—çª—å£å‡½æ•°ï¼Œè¿æ¥ç­‰ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œç»“æ„åŒ–æµå…è®¸æ‚¨ä½¿ç”¨è‰¯å¥½çš„æ—§SQLå¤„ç†æ•°æ®æµã€‚ <br><br><h3> æ€ä¹ˆäº† </h3><br>  Sparkç»“æ„åŒ–æµçš„ç¨³å®šç‰ˆæœ¬äº2017å¹´å‘å¸ƒã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªç›¸å½“æ–°çš„APIï¼Œå¯å®ç°åŸºæœ¬åŠŸèƒ½ï¼Œä½†æŸäº›äº‹æƒ…å¿…é¡»ç”±æˆ‘ä»¬è‡ªå·±å®Œæˆã€‚ ä¾‹å¦‚ï¼Œç»“æ„åŒ–æµä¼ è¾“å…·æœ‰ç”¨äºå°†è¾“å‡ºå†™å…¥æ–‡ä»¶ï¼Œå›¾å—ï¼Œæ§åˆ¶å°æˆ–å†…å­˜çš„æ ‡å‡†åŠŸèƒ½ï¼Œä½†ä¸ºäº†å°†æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“ï¼Œæ‚¨å¿…é¡»ä½¿ç”¨ç»“æ„åŒ–æµä¼ è¾“ä¸­å¯ç”¨çš„<i>foreach</i>æ¥æ”¶å™¨å¹¶å®ç°<i>ForeachWriter</i>æ¥å£ã€‚  <b>ä»Spark 2.3.1å¼€å§‹ï¼Œæ­¤åŠŸèƒ½åªèƒ½åœ¨Scalaå’ŒJavaä¸­å®ç°</b> ã€‚ <br><br> æˆ‘å‡å®šè¯»è€…å·²ç»çŸ¥é“ç»“æ„åŒ–æµä¸€èˆ¬å¦‚ä½•å·¥ä½œï¼ŒçŸ¥é“å¦‚ä½•å®ç°å¿…è¦çš„è½¬æ¢ï¼Œå¹¶ä¸”ç°åœ¨å‡†å¤‡å°†ç»“æœä¸Šä¼ åˆ°æ•°æ®åº“ã€‚ å¦‚æœä¸Šè¿°æ­¥éª¤ä¸­çš„æŸäº›æ­¥éª¤ä¸æ¸…æ¥šï¼Œåˆ™å®˜æ–¹æ–‡æ¡£å¯ä»¥ä½œä¸ºå­¦ä¹ ç»“æ„åŒ–æµåª’ä½“çš„ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚ åœ¨æœ¬æ–‡ä¸­ï¼Œå½“æ‚¨éœ€è¦å°†ç»“æœä¿å­˜åˆ°æ•°æ®åº“ä¸­æ—¶ï¼Œæˆ‘æƒ³ç€é‡ä»‹ç»æœ€åä¸€æ­¥ã€‚ <br><br> ä¸‹é¢ï¼Œæˆ‘å°†æè¿°ç”¨äºç»“æ„åŒ–æµçš„Cassandraæ¥æ”¶å™¨çš„ç¤ºä¾‹å®ç°ï¼Œå¹¶è¯´æ˜å¦‚ä½•åœ¨é›†ç¾¤ä¸­è¿è¡Œå®ƒã€‚ å®Œæ•´çš„ä»£ç <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">åœ¨è¿™é‡Œ</a> ã€‚ <br><br> å½“æˆ‘ç¬¬ä¸€æ¬¡é‡åˆ°ä¸Šè¿°é—®é¢˜æ—¶ï¼Œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">è¿™ä¸ªé¡¹ç›®</a>éå¸¸æœ‰ç”¨ã€‚ ä½†æ˜¯ï¼Œå¦‚æœè¯»è€…åˆšåˆšå¼€å§‹ä½¿ç”¨ç»“æ„åŒ–æµå¹¶ä¸”æ­£åœ¨å¯»æ‰¾æœ‰å…³å¦‚ä½•å°†æ•°æ®ä¸Šä¼ åˆ°cassandraçš„ç®€å•ç¤ºä¾‹ï¼Œåˆ™ä¼¼ä¹æœ‰ç‚¹å¤æ‚ã€‚ å¦å¤–ï¼Œè¯¥é¡¹ç›®è¢«ç¼–å†™ä¸ºä»¥æœ¬åœ°æ¨¡å¼å·¥ä½œï¼Œå¹¶ä¸”éœ€è¦è¿›è¡Œä¸€äº›æ›´æ”¹æ‰èƒ½åœ¨é›†ç¾¤ä¸­è¿è¡Œã€‚ <br><br> æˆ‘è¿˜æƒ³ä¸¾ä¾‹è¯´æ˜å¦‚ä½•ä½¿ç”¨<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">JDBC</a>å°†æ•°æ®ä¿å­˜åˆ°<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">MongoDB</a>å’Œä»»ä½•å…¶ä»–æ•°æ®åº“ã€‚ <br><br><h3> ç®€å•çš„è§£å†³æ–¹æ¡ˆ </h3><br> è¦å°†æ•°æ®ä¸Šä¼ åˆ°å¤–éƒ¨ç³»ç»Ÿï¼Œå¿…é¡»ä½¿ç”¨<i>foreach</i>æ¥æ”¶å™¨ã€‚  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">åœ¨è¿™é‡Œ</a>é˜…è¯»æ›´å¤šæœ‰å…³æ­¤çš„å†…å®¹ã€‚ ç®€è€Œè¨€ä¹‹ï¼Œå¿…é¡»å®ç°<i>ForeachWriter</i>æ¥å£ã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œæœ‰å¿…è¦ç¡®å®šå¦‚ä½•æ‰“å¼€è¿æ¥ï¼Œå¦‚ä½•å¤„ç†æ¯æ¡æ•°æ®ä»¥åŠå¦‚ä½•åœ¨å¤„ç†ç»“æŸæ—¶å…³é—­è¿æ¥ã€‚ æºä»£ç å¦‚ä¸‹ï¼š <br><br><pre><code class="scala hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CassandraSinkForeach</span></span></span><span class="hljs-class">(</span><span class="hljs-params"></span><span class="hljs-class"><span class="hljs-params"></span>) </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ForeachWriter</span></span></span><span class="hljs-class">[org.apache.spark.sql.</span><span class="hljs-type"><span class="hljs-class"><span class="hljs-type">Row</span></span></span><span class="hljs-class">] </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// This class implements the interface ForeachWriter, which has methods that get called // whenever there is a sequence of rows generated as output val cassandraDriver = new CassandraDriver(); def open(partitionId: Long, version: Long): Boolean = { // open connection println(s"Open connection") true } def process(record: org.apache.spark.sql.Row) = { println(s"Process new $record") cassandraDriver.connector.withSessionDo(session =&gt; session.execute(s""" insert into ${cassandraDriver.namespace}.${cassandraDriver.foreachTableSink} (fx_marker, timestamp_ms, timestamp_dt) values('${record(0)}', '${record(1)}', '${record(2)}')""") ) } def close(errorOrNull: Throwable): Unit = { // close the connection println(s"Close connection") } }</span></span></code> </pre> <br> æˆ‘ç¨åå°†æè¿°<i>CassandraDriver</i>çš„å®šä¹‰å’Œè¾“å‡ºè¡¨çš„ç»“æ„ï¼Œä½†æ˜¯ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä»”ç»†çœ‹çœ‹ä¸Šé¢çš„ä»£ç æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚ ä¸ºäº†ä»Sparkè¿æ¥åˆ°Kasandraï¼Œæˆ‘åˆ›å»ºäº†ä¸€ä¸ª<i>CassandraDriver</i>å¯¹è±¡ï¼Œè¯¥å¯¹è±¡æä¾›å¯¹<i>CassandraConnector</i> ï¼ˆç”±<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">DataStax</a>å¼€å‘çš„è¿æ¥å™¨ï¼‰çš„è®¿é—®ã€‚  CassandraConnectorè´Ÿè´£æ‰“å¼€å’Œå…³é—­ä¸æ•°æ®åº“çš„è¿æ¥ï¼Œå› æ­¤æˆ‘ä»…åœ¨<i>CassandraSinkForeach</i>ç±»çš„<i>open</i>å’Œ<i>close</i>æ–¹æ³•ä¸­æ˜¾ç¤ºè°ƒè¯•æ¶ˆæ¯ã€‚ <br><br> ä»ä¸»åº”ç”¨ç¨‹åºè°ƒç”¨ä»¥ä¸Šä»£ç ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> sink = parsed .writeStream .queryName(<span class="hljs-string"><span class="hljs-string">"KafkaToCassandraForeach"</span></span>) .outputMode(<span class="hljs-string"><span class="hljs-string">"update"</span></span>) .foreach(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">CassandraSinkForeach</span></span>()) .start()</code> </pre><br> ä¸ºæ•°æ®çš„æ¯ä¸€è¡Œåˆ›å»º<i>CassandraSinkForeach</i> ï¼Œå› æ­¤æ¯ä¸ªå·¥ä½œèŠ‚ç‚¹éƒ½å°†å…¶éƒ¨åˆ†è¡Œæ’å…¥æ•°æ®åº“ä¸­ã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸ªå·¥ä½œèŠ‚ç‚¹éƒ½æ‰§è¡Œ<i>val cassandraDriver = new CassandraDriverï¼ˆï¼‰;</i> è¿™æ˜¯CassandraDriverçš„æ ·å­ï¼š <br><br><pre> <code class="scala hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CassandraDriver</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">SparkSessionBuilder</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// This object will be used in CassandraSinkForeach to connect to Cassandra DB from an executor. // It extends SparkSessionBuilder so to use the same SparkSession on each node. val spark = buildSparkSession import spark.implicits._ val connector = CassandraConnector(spark.sparkContext.getConf) // Define Cassandra's table which will be used as a sink /* For this app I used the following table: CREATE TABLE fx.spark_struct_stream_sink ( fx_marker text, timestamp_ms timestamp, timestamp_dt date, primary key (fx_marker)); */ val namespace = "fx" val foreachTableSink = "spark_struct_stream_sink" }</span></span></code> </pre><br> è®©æˆ‘ä»¬ä»”ç»†çœ‹çœ‹<i>spark</i>å¯¹è±¡ã€‚  <i>SparkSessionBuilder</i>çš„ä»£ç å¦‚ä¸‹ï¼š <br><br><pre> <code class="scala hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">SparkSessionBuilder</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Serializable</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// Build a spark session. Class is made serializable so to get access to SparkSession in a driver and executors. // Note here the usage of @transient lazy val def buildSparkSession: SparkSession = { @transient lazy val conf: SparkConf = new SparkConf() .setAppName("Structured Streaming from Kafka to Cassandra") .set("spark.cassandra.connection.host", "ec2-52-23-103-178.compute-1.amazonaws.com") .set("spark.sql.streaming.checkpointLocation", "checkpoint") @transient lazy val spark = SparkSession .builder() .config(conf) .getOrCreate() spark } }</span></span></code> </pre><br> åœ¨æ¯ä¸ªå·¥ä½œèŠ‚ç‚¹ä¸Šï¼Œ <i>SparkSessionBuilder</i>æä¾›å¯¹åœ¨é©±åŠ¨ç¨‹åºä¸Šåˆ›å»ºçš„<i>SparkSessionçš„</i>è®¿é—®ã€‚ ä¸ºäº†ä½¿è¿™ç§è®¿é—®æˆä¸ºå¯èƒ½ï¼Œå¿…é¡»åºåˆ—åŒ–<i>SparkSessionBuilder</i>å¹¶ä½¿ç”¨<i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" class="user_link">ç¬æ€</a> lazy val</i> ï¼Œå®ƒå…è®¸åºåˆ—åŒ–ç³»ç»Ÿåœ¨ç¨‹åºåˆå§‹åŒ–æ—¶å¿½ç•¥<i>conf</i>å’Œ<i>spark</i>å¯¹è±¡ï¼Œç›´åˆ°è®¿é—®å¯¹è±¡ä¸ºæ­¢ã€‚ å› æ­¤ï¼Œåœ¨ç¨‹åºå¯åŠ¨æ—¶ï¼Œ <i>buildSparkSessionè¢«</i>åºåˆ—åŒ–å¹¶å‘é€åˆ°æ¯ä¸ªå·¥ä½œèŠ‚ç‚¹ï¼Œä½†æ˜¯ä»…å½“å·¥ä½œèŠ‚ç‚¹æ­£åœ¨è®¿é—®<i>conf</i>å’Œ<i>spark</i>å¯¹è±¡æ—¶ï¼Œæ‰å…è®¸<i>conf</i>å’Œ<i>spark</i>å¯¹è±¡ã€‚ <br><br> ç°åœ¨è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹ä¸»è¦çš„åº”ç”¨ç¨‹åºä»£ç ï¼š <br><br><pre> <code class="scala hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">object</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">KafkaToCassandra</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">SparkSessionBuilder</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// Main body of the app. It also extends SparkSessionBuilder. def main(args: Array[String]) { val spark = buildSparkSession import spark.implicits._ // Define location of Kafka brokers: val broker = "ec2-18-209-75-68.compute-1.amazonaws.com:9092,ec2-18-205-142-57.compute-1.amazonaws.com:9092,ec2-50-17-32-144.compute-1.amazonaws.com:9092" /*Here is an example massage which I get from a Kafka stream. It contains multiple jsons separated by \n {"timestamp_ms": "1530305100936", "fx_marker": "EUR/GBP"} {"timestamp_ms": "1530305100815", "fx_marker": "USD/CHF"} {"timestamp_ms": "1530305100969", "fx_marker": "EUR/CHF"} {"timestamp_ms": "1530305100011", "fx_marker": "USD/CAD"} */ // Read incoming stream val dfraw = spark .readStream .format("kafka") .option("kafka.bootstrap.servers", broker) .option("subscribe", "currency_exchange") .load() val schema = StructType( Seq( StructField("fx_marker", StringType, false), StructField("timestamp_ms", StringType, false) ) ) val df = dfraw .selectExpr("CAST(value AS STRING)").as[String] .flatMap(_.split("\n")) val jsons = df.select(from_json($"value", schema) as "data").select("data.*") // Process data. Create a new date column val parsed = jsons .withColumn("timestamp_dt", to_date(from_unixtime($"timestamp_ms"/1000.0, "yyyy-MM-dd HH:mm:ss.SSS"))) .filter("fx_marker != ''") // Output results into a database val sink = parsed .writeStream .queryName("KafkaToCassandraForeach") .outputMode("update") .foreach(new CassandraSinkForeach()) .start() sink.awaitTermination() } }</span></span></code> </pre><br> å½“å‘é€åº”ç”¨ç¨‹åºæ‰§è¡Œæ—¶ï¼Œ <i>buildSparkSessionè¢«</i>åºåˆ—åŒ–å¹¶å‘é€åˆ°å·¥ä½œèŠ‚ç‚¹ï¼Œä½†æ˜¯<i>conf</i>å’Œ<i>spark</i>å¯¹è±¡ä»æœªè§£æã€‚ ç„¶åï¼Œé©±åŠ¨ç¨‹åºåœ¨<i>KafkaToCassandra</i>å†…éƒ¨åˆ›å»ºä¸€ä¸ªsparkå¯¹è±¡ï¼Œå¹¶åœ¨å·¥ä½œèŠ‚ç‚¹ä¹‹é—´åˆ†é…å·¥ä½œã€‚ æ¯ä¸ªå·¥ä½œèŠ‚ç‚¹éƒ½ä»Kafkaè¯»å–æ•°æ®ï¼Œå¯¹è®°å½•çš„æ¥æ”¶éƒ¨åˆ†è¿›è¡Œç®€å•çš„è½¬æ¢ï¼Œå½“å·¥ä½œèŠ‚ç‚¹å‡†å¤‡å¥½å°†ç»“æœå†™å…¥æ•°æ®åº“æ—¶â€‹â€‹ï¼Œå®ƒå…è®¸<i>conf</i>å’Œ<i>spark</i>å¯¹è±¡ï¼Œä»è€Œè·å¾—å¯¹åœ¨é©±åŠ¨ç¨‹åºä¸Šåˆ›å»ºçš„<i>SparkSessionçš„</i>è®¿é—®æƒé™ã€‚ <br><br><h3> å¦‚ä½•æ„å»ºå’Œè¿è¡Œåº”ç”¨ç¨‹åºï¼Ÿ </h3><br> å½“æˆ‘ä»PySparkè¿ç§»åˆ°Scalaæ—¶ï¼ŒèŠ±äº†æˆ‘ä¸€æ®µæ—¶é—´æ‰å¼„æ¸…æ¥šå¦‚ä½•æ„å»ºåº”ç”¨ç¨‹åºã€‚ å› æ­¤ï¼Œæˆ‘åœ¨é¡¹ç›®ä¸­åŒ…å«äº†Maven <i>pom.xml</i> ã€‚ è¯»è€…å¯ä»¥é€šè¿‡è¿è¡Œ<i>mvn package</i>å‘½ä»¤ä½¿ç”¨Mavenæ„å»ºåº”ç”¨ç¨‹åºã€‚ å¯ä»¥å°†åº”ç”¨ç¨‹åºå‘é€ç»™æ‰§è¡Œå <br><br><pre> <code class="bash hljs">./bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.1,datastax:spark-cassandra-connector:2.3.0-s_2.11 --class com.insight.app.CassandraSink.KafkaToCassandra --master spark://ec2-18-232-26-53.compute-1.amazonaws.com:7077 target/cassandra-sink-0.0.1-SNAPSHOT.jar</code> </pre><br> ä¸ºäº†æ„å»ºå’Œè¿è¡Œåº”ç”¨ç¨‹åºï¼Œæœ‰å¿…è¦ç”¨æ‚¨è‡ªå·±çš„AWSæœºå™¨åç§°æ›¿æ¢ï¼ˆå³æ›¿æ¢æ‰€æœ‰ç±»ä¼¼ec2-xx-xxx-xx-xx.compute-1.amazonaws.comçš„åç§°ï¼‰ã€‚ <br><br> ç«èŠ±å’Œç»“æ„åŒ–æµç‰¹åˆ«æ˜¯å¯¹æˆ‘æ¥è¯´æ˜¯ä¸€ä¸ªæ–°ä¸»é¢˜ï¼Œå› æ­¤ï¼Œæˆ‘å°†éå¸¸æ„Ÿè°¢è¯»è€…æå‡ºæ„è§ï¼Œè®¨è®ºå’Œæ›´æ­£ã€‚ </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN425503/">https://habr.com/ru/post/zh-CN425503/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN425489/index.html">è‡ªåŠ¨åŒ–ï¼šå¤¸å¤§çš„æœºå™¨äººå¨èƒ</a></li>
<li><a href="../zh-CN425493/index.html">ä¸ºIPTV Beelineé…ç½®MikroTik hAP mini</a></li>
<li><a href="../zh-CN425497/index.html">Tutu PHPèšä¼šï¼ƒ2ï¼šç°åœºç›´æ’­</a></li>
<li><a href="../zh-CN425499/index.html">HyperX Impact DDR4-å¯ä»¥çš„SO-DIMMï¼ è¿˜æ˜¯ä¸ºä»€ä¹ˆåœ¨ç¬”è®°æœ¬ç”µè„‘ä¸­ä»¥3200 MHzçš„é¢‘ç‡å­˜å‚¨64 GBå†…å­˜ï¼Ÿ</a></li>
<li><a href="../zh-CN425501/index.html">ä»Aåˆ°Zåœ¨Androidä¸Šè¿›è¡ŒA / Bæµ‹è¯•</a></li>
<li><a href="../zh-CN425505/index.html">Linuxå†…æ ¸å¯åŠ¨è¿‡ç¨‹åˆ†æ</a></li>
<li><a href="../zh-CN425507/index.html">Parsim Wikipediaè´Ÿè´£4ä¸ªå›¢é˜Ÿçš„NLPä»»åŠ¡</a></li>
<li><a href="../zh-CN425511/index.html">Rotativaåº”ç”¨ç¨‹åºçš„éæ˜¾è€Œæ˜“è§çš„åŠŸèƒ½ï¼Œç”¨äºåœ¨ASP.NET MVCåº”ç”¨ç¨‹åºä¸­ç”ŸæˆPDF</a></li>
<li><a href="../zh-CN425515/index.html">Appleé˜»æ­¢å¯¹æ–°MacBookå‹å·è¿›è¡Œç‹¬ç«‹ç»´ä¿®</a></li>
<li><a href="../zh-CN425517/index.html">Yandexå¦‚ä½•ä½¿ç”¨é›·è¾¾å’Œå«æ˜Ÿåˆ›å»ºå…¨çƒé™æ°´é¢„æŠ¥</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
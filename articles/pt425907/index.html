<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëµüèæ üö¶ üò¨ Estamos desenvolvendo um projeto de aprendizado de m√°quina em Python. Parte 2 üöÅ üóÉÔ∏è üíæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Um passo a passo completo do aprendizado de m√°quina em Python: parte dois 

 Juntar todas as partes de um projeto de aprendizado de m√°quina pode ser c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Estamos desenvolvendo um projeto de aprendizado de m√°quina em Python. Parte 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nix/blog/425907/"><img src="https://habrastorage.org/getpro/habr/post_images/225/910/6f3/2259106f3ccc19ae2b8b1ec9f316c4f2.png"><br><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Um passo a passo completo do aprendizado de m√°quina em Python: parte dois</a></i> <br><br>  Juntar todas as partes de um projeto de aprendizado de m√°quina pode ser complicado.  Nesta s√©rie de artigos, percorreremos todas as etapas da implementa√ß√£o do processo de aprendizado de m√°quina usando dados reais e descobriremos como as v√°rias t√©cnicas s√£o combinadas entre si. <br><br>  No <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">primeiro artigo,</a> limpamos e estruturamos os dados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">,</a> realizamos uma an√°lise explorat√≥ria, coletamos um conjunto de atributos para uso no modelo e definimos uma linha de base para avaliar os resultados.  Com a ajuda deste artigo, aprenderemos como implementar no Python e comparar v√°rios modelos de aprendizado de m√°quina, executar o ajuste hiperparam√©trico para otimizar o melhor modelo e avaliar o desempenho do modelo final em um conjunto de dados de teste. <br><br>  Todo o c√≥digo do projeto est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no GitHub</a> , e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> est√° o segundo bloco de anota√ß√µes relacionado ao artigo atual.  Voc√™ pode usar e modificar o c√≥digo como desejar! <br><a name="habracut"></a><br><h2>  Avalia√ß√£o e Sele√ß√£o de Modelos </h2><br>  Lembrete: Estamos trabalhando em uma tarefa de regress√£o controlada, usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">as informa√ß√µes de energia para edif√≠cios em Nova York</a> para criar um modelo que prediz qual <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Energy Star Score um</a> edif√≠cio em particular receber√°.  Estamos interessados ‚Äã‚Äãtanto na precis√£o da previs√£o quanto na interpretabilidade do modelo. <br><br>  Hoje voc√™ pode escolher entre os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">v√°rios modelos de aprendizado de m√°quina dispon√≠veis</a> , e essa abund√¢ncia pode ser intimidadora.  Obviamente, existem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">an√°lises comparativas</a> na rede que o ajudar√£o a navegar na escolha de um algoritmo, mas prefiro tentar algumas e ver qual √© melhor.  Na maioria das vezes, o aprendizado de m√°quina √© baseado em resultados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">emp√≠ricos e n√£o te√≥ricos</a> , e √© quase <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">imposs√≠vel entender com anteced√™ncia qual modelo √© mais preciso</a> . <br><br>  Geralmente, √© recomend√°vel que voc√™ comece com modelos simples e interpret√°veis, como regress√£o linear, e se os resultados forem insatisfat√≥rios, passe para m√©todos mais complexos, mas geralmente mais precisos.  Este gr√°fico (muito anticient√≠fico) mostra a rela√ß√£o entre a precis√£o e a interpretabilidade de alguns algoritmos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1a1/602/9a1/1a16029a1b75b5ba4022d477615f352f.png"><br>  <i>Interpretabilidade e precis√£o ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">fonte</a> ).</i> <br><br>  Vamos avaliar cinco modelos de graus variados de complexidade: <br><br><ul><li>  Regress√£o linear. </li><li>  O m√©todo dos k-vizinhos mais pr√≥ximos. </li><li>  "Floresta aleat√≥ria". </li><li>  Aumento de gradiente. </li><li>  M√©todo de vetores de suporte. </li></ul><br>  Consideraremos n√£o o aparato te√≥rico desses modelos, mas sua implementa√ß√£o.  Se voc√™ estiver interessado em teoria, consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Introdu√ß√£o √† aprendizagem estat√≠stica</a> (dispon√≠vel gratuitamente) ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aprendizado de m√°quina pr√°tico com o Scikit-Learn e o TensorFlow</a> .  Nos dois livros, a teoria √© perfeitamente explicada e a efic√°cia do uso dos m√©todos mencionados nas linguagens R e Python √© mostrada, respectivamente. <br><br><h4>  Preencha os valores ausentes </h4><br>  Embora quando limpamos os dados, descartamos as colunas nas quais mais da metade dos valores est√° ausente, ainda temos muitos valores.  Os modelos de aprendizado de m√°quina n√£o podem funcionar com dados ausentes, portanto, precisamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">preench√™-</a> los. <br><br>  Primeiro, consideramos os dados e lembramos como eles se parecem: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># Read in data into dataframes train_features = pd.read_csv('data/training_features.csv') test_features = pd.read_csv('data/testing_features.csv') train_labels = pd.read_csv('data/training_labels.csv') test_labels = pd.read_csv('data/testing_labels.csv') Training Feature Size: (6622, 64) Testing Feature Size: (2839, 64) Training Labels Size: (6622, 1) Testing Labels Size: (2839, 1)</span></span></code> </pre> <br>  Cada valor <code>NaN</code> √© um registro ausente nos dados.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Voc√™ pode preench√™-los de maneiras diferentes</a> , e usaremos o m√©todo de imputa√ß√£o mediana bastante simples, que substitui os dados ausentes pelos valores m√©dios das colunas correspondentes. <br><br>  No c√≥digo abaixo, criaremos um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">objeto Scikit-Learn</a> Imputer com uma estrat√©gia mediana.  Em seguida, treinamos nos dados de treinamento (usando <code>imputer.fit</code> ) e aplicamos para preencher os valores ausentes nos conjuntos de treinamento e teste (usando <code>imputer.transform</code> ).  Ou seja, os registros ausentes nos <i>dados de teste</i> ser√£o preenchidos com o valor mediano correspondente dos <i>dados de treinamento</i> . <br><br>  Realizamos o preenchimento e n√£o treinamos o modelo nos dados como est√£o, para evitar o problema de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">vazamento dos dados de teste</a> quando as informa√ß√µes do conjunto de dados de teste entram no treinamento. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Create an imputer object with a median filling strategy imputer = Imputer(strategy='median') # Train on the training features imputer.fit(train_features) # Transform both training data and testing data X = imputer.transform(train_features) X_test = imputer.transform(test_features) Missing values in training features: 0 Missing values in testing features: 0</span></span></code> </pre> <br>  Agora todos os valores est√£o preenchidos, n√£o h√° lacunas. <br><br><h4>  Escala de recursos </h4><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Escala</a> √© o processo geral de alterar o alcance de uma caracter√≠stica.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Este √© um passo necess√°rio</a> , porque os sinais s√£o medidos em unidades diferentes, o que significa que cobrem intervalos diferentes.  Isso distorce bastante os resultados de algoritmos como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o</a> m√©todo do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">vetor de suporte</a> e o m√©todo vizinho k-mais pr√≥ximo, que levam em considera√ß√£o as dist√¢ncias entre as medi√ß√µes.  E o dimensionamento permite evitar isso.  Embora m√©todos como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">regress√£o linear e ‚Äúfloresta aleat√≥ria‚Äù</a> n√£o exijam escala de recursos, √© melhor n√£o negligenciar esta etapa ao comparar v√°rios algoritmos. <br><br>  Escalaremos usando cada atributo para um intervalo de 0 a 1. Pegamos todos os valores do atributo, selecionamos o m√≠nimo e dividimos pela diferen√ßa entre o m√°ximo e o m√≠nimo (intervalo).  Esse m√©todo de dimensionamento √© geralmente chamado de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">normaliza√ß√£o e a outra maneira principal √© a padroniza√ß√£o</a> . <br><br>  Esse processo √© f√°cil de implementar manualmente, portanto, usaremos o objeto MinMaxScaler do Scikit-Learn.  O c√≥digo para esse m√©todo √© id√™ntico ao c√≥digo para preencher os valores ausentes, somente a escala √© usada em vez de colar.  Lembre-se de que aprendemos o modelo apenas no conjunto de treinamento e depois transformamos todos os dados. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Create the scaler object with a range of 0-1 scaler = MinMaxScaler(feature_range=(0, 1)) # Fit on the training data scaler.fit(X) # Transform both the training and testing data X = scaler.transform(X) X_test = scaler.transform(X_test)</span></span></code> </pre> <br>  Agora, cada atributo tem um valor m√≠nimo de 0 e m√°ximo de 1. Preenchendo os valores ausentes e a escala dos atributos - esses dois est√°gios s√£o necess√°rios em quase qualquer processo de aprendizado de m√°quina. <br><br><h4>  Implementamos modelos de aprendizado de m√°quina no Scikit-Learn </h4><br>  Depois de todo o trabalho preparat√≥rio, o processo de cria√ß√£o, treinamento e execu√ß√£o de modelos √© relativamente simples.  Usaremos a biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Scikit-Learn</a> em Python, que √© lindamente documentada e com sintaxe elaborada para a constru√ß√£o de modelos.  Ao aprender como criar um modelo no Scikit-Learn, voc√™ pode implementar rapidamente todos os tipos de algoritmos. <br><br>  Ilustraremos o processo de cria√ß√£o, treinamento ( <code>.fit</code> ) e teste ( <code>.predict</code> ) usando o aumento de gradiente: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GradientBoostingRegressor <span class="hljs-comment"><span class="hljs-comment"># Create the model gradient_boosted = GradientBoostingRegressor() # Fit the model on the training data gradient_boosted.fit(X, y) # Make predictions on the test data predictions = gradient_boosted.predict(X_test) # Evaluate the model mae = np.mean(abs(predictions - y_test)) print('Gradient Boosted Performance on the test set: MAE = %0.4f' % mae) Gradient Boosted Performance on the test set: MAE = 10.0132</span></span></code> </pre> <br>  Apenas uma linha de c√≥digo para cria√ß√£o, treinamento e teste.  Para construir outros modelos, usamos a mesma sintaxe, alterando apenas o nome do algoritmo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/215/58f/ab4/21558fab42e2669b96132dff6a5b2691.png"><br><br>  Para avaliar objetivamente os modelos, calculamos o n√≠vel base usando o valor mediano da meta e obtivemos 24,5.  E os resultados foram muito melhores, para que nosso problema possa ser resolvido usando o aprendizado de m√°quina. <br><br>  No nosso caso, o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aumento do gradiente</a> (MAE = 10,013) acabou sendo um pouco melhor que a "floresta aleat√≥ria" (10,014 MAE).  Embora esses resultados n√£o possam ser considerados completamente honestos, porque para os hiperpar√¢metros usamos principalmente os valores padr√£o.  A efic√°cia dos modelos depende fortemente dessas configura√ß√µes, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">especialmente no m√©todo do vetor de suporte</a> .  No entanto, com base nesses resultados, escolheremos o aumento de gradiente e come√ßaremos a otimiz√°-lo. <br><br><h2>  Otimiza√ß√£o de modelo hiperparam√©trico </h2><br>  Depois de escolher um modelo, voc√™ pode otimiz√°-lo para a tarefa a ser resolvida ajustando os hiper par√¢metros. <br><br>  Mas antes de tudo, vamos entender o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">que s√£o hiperpar√¢metros e como eles diferem dos par√¢metros comuns</a> ? <br><br><ul><li>  Os hiperpar√¢metros do modelo podem ser considerados as configura√ß√µes do algoritmo, que definimos antes do in√≠cio de seu treinamento.  Por exemplo, o hiperpar√¢metro √© o n√∫mero de √°rvores na "floresta aleat√≥ria" ou o n√∫mero de vizinhos no m√©todo k-vizinhos mais pr√≥ximos. </li><li>  Par√¢metros do modelo - o que ela aprende durante o treinamento, por exemplo, pesos em regress√£o linear. </li></ul><br>  Ao controlar o hiperpar√¢metro, influenciamos os resultados do modelo, alterando o equil√≠brio entre a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">falta de educa√ß√£o e a reciclagem</a> .  Sob a aprendizagem, h√° uma situa√ß√£o em que o modelo n√£o √© complexo o suficiente (possui poucos graus de liberdade) para estudar a correspond√™ncia de sinais e objetivos.  Um modelo pouco treinado tem um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">alto</a> vi√©s, que pode ser corrigido complicando o modelo. <br><br>  A reciclagem √© uma situa√ß√£o em que o modelo essencialmente se lembra dos dados de treinamento.  O modelo reciclado possui uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">alta</a> varia√ß√£o, que pode ser ajustada limitando a complexidade do modelo atrav√©s da regulariza√ß√£o.  Os modelos mal treinados e reciclados n√£o ser√£o capazes de generalizar bem os dados de teste. <br><br>  A dificuldade em escolher os hiperpar√¢metros certos √© que, para cada tarefa, haver√° um conjunto ideal exclusivo.  Portanto, a √∫nica maneira de escolher as melhores configura√ß√µes √© tentar combina√ß√µes diferentes no novo conjunto de dados.  Felizmente, o Scikit-Learn possui v√°rios m√©todos que permitem avaliar efetivamente os hiperpar√¢metros.  Al√©m disso, projetos como o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TPOT</a> est√£o tentando otimizar a busca por hiperpar√¢metros usando abordagens como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a programa√ß√£o gen√©tica</a> .  Neste artigo, nos restringimos ao uso do Scikit-Learn. <br><br><h4>  Pesquisa aleat√≥ria cruzada </h4><br>  Vamos implementar um m√©todo de ajuste de hiperpar√¢metro chamado pesquisas aleat√≥rias de valida√ß√£o cruzada: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pesquisa aleat√≥ria</a> - uma t√©cnica para selecionar hiperpar√¢metros.  Definimos uma grade e, em seguida, selecionamos aleatoriamente v√°rias combina√ß√µes, em contraste com a pesquisa de grade, na qual tentamos sucessivamente cada combina√ß√£o.  A prop√≥sito, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a pesquisa aleat√≥ria funciona quase t√£o bem quanto a pesquisa em grade</a> , mas muito mais r√°pido. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A verifica√ß√£o cruzada</a> √© uma maneira de avaliar a combina√ß√£o selecionada de hiperpar√¢metros.  Em vez de dividir os dados em conjuntos de treinamento e teste, o que reduz a quantidade de dados dispon√≠veis para treinamento, usaremos a valida√ß√£o cruzada do bloco k (valida√ß√£o cruzada do K-Fold).  Para fazer isso, dividiremos os dados de treinamento em k blocos e, em seguida, executaremos o processo iterativo, durante o qual treinamos primeiro o modelo em blocos k-1 e, em seguida, comparamos o resultado ao aprender no k-√©simo bloco.  Repetiremos o processo k vezes e, no final, obteremos o valor m√©dio do erro para cada itera√ß√£o.  Essa ser√° a avalia√ß√£o final. </li></ul><br>  Aqui est√° uma ilustra√ß√£o gr√°fica da valida√ß√£o cruzada do bloco k em k = 5: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e17/94b/51e/e1794b51eded0314afd9f594a8e9ee5e.png"><br><br>  Todo o processo de pesquisa aleat√≥ria de valida√ß√£o cruzada se parece com o seguinte: <br><br><ol><li>  Estabelecemos uma grade de hiperpar√¢metros. </li><li>  Selecione aleatoriamente uma combina√ß√£o de hiperpar√¢metros. </li><li>  Crie um modelo usando essa combina√ß√£o. </li><li>  Avaliamos o resultado do modelo usando a valida√ß√£o cruzada do bloco k. </li><li>  Decidimos quais hiperpar√¢metros d√£o o melhor resultado. </li></ol><br>  Obviamente, tudo isso √© feito n√£o manualmente, mas usando o <code>RandomizedSearchCV</code> do Scikit-Learn! <br><br><h4>  Pequena digress√£o: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">m√©todos de aumento de gradiente</a> </h4><br>  Usaremos um modelo de regress√£o baseado em aumento de gradiente.  Este √© um m√©todo coletivo, ou seja, o modelo consiste em numerosos "alunos fracos", neste caso, de √°rvores de decis√£o separadas.  Se os alunos aprendem em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">algoritmos</a> paralelos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">como ‚Äúfloresta aleat√≥ria‚Äù</a> e o resultado da previs√£o √© selecionado por vota√ß√£o, em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">algoritmos de otimiza√ß√£o</a> como aumento de gradiente, os alunos aprendem em sequ√™ncia e cada um deles ‚Äúse concentra‚Äù nos erros cometidos por seus antecessores. <br><br>  Nos √∫ltimos anos, os algoritmos de otimiza√ß√£o tornaram-se populares e geralmente vencem em competi√ß√µes de aprendizado de m√°quina.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O aumento de gradiente</a> √© uma das implementa√ß√µes nas quais o Gradient Descent √© usado para minimizar o custo da fun√ß√£o.  A implementa√ß√£o do aumento de gradiente no Scikit-Learn √© considerada n√£o t√£o eficaz quanto em outras bibliotecas, por exemplo, no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">XGBoost</a> , mas funciona bem em pequenos conjuntos de dados e fornece previs√µes bastante precisas. <br><br><h4>  Voltar para a configura√ß√£o hiperparam√©trica </h4><br>  Na regress√£o usando o aumento de gradiente, h√° muitos hiperpar√¢metros que precisam ser configurados. Para obter detalhes, refiro-o √† documenta√ß√£o do Scikit-Learn.  Vamos otimizar: <br><br><ul><li>  <code>loss</code> : minimiza√ß√£o da fun√ß√£o de perda; </li><li>  <code>n_estimators</code> : o n√∫mero de √°rvores de decis√£o fracas usadas (√°rvores de decis√£o); </li><li>  <code>max_depth</code> : profundidade m√°xima de cada √°rvore de decis√£o; </li><li>  <code>min_samples_leaf</code> : o n√∫mero m√≠nimo de exemplos que devem estar no n√≥ folha da √°rvore de decis√£o; </li><li>  <code>min_samples_split</code> : o n√∫mero m√≠nimo de exemplos necess√°rios para dividir o n√≥ da √°rvore de decis√£o; </li><li>  <code>max_features</code> : o n√∫mero m√°ximo de recursos usados ‚Äã‚Äãpara separar n√≥s. </li></ul><br>  N√£o tenho certeza se algu√©m realmente entende como tudo funciona, e a √∫nica maneira de encontrar a melhor combina√ß√£o √© tentar op√ß√µes diferentes. <br><br>  Nesse c√≥digo, criamos uma grade de hiperpar√¢metros, depois criamos um objeto <code>RandomizedSearchCV</code> e pesquisamos usando a valida√ß√£o cruzada em quatro blocos para 25 combina√ß√µes diferentes de hiperpar√¢metros: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Loss function to be optimized loss = ['ls', 'lad', 'huber'] # Number of trees used in the boosting process n_estimators = [100, 500, 900, 1100, 1500] # Maximum depth of each tree max_depth = [2, 3, 5, 10, 15] # Minimum number of samples per leaf min_samples_leaf = [1, 2, 4, 6, 8] # Minimum number of samples to split a node min_samples_split = [2, 4, 6, 10] # Maximum number of features to consider for making splits max_features = ['auto', 'sqrt', 'log2', None] # Define the grid of hyperparameters to search hyperparameter_grid = {'loss': loss, 'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf, 'min_samples_split': min_samples_split, 'max_features': max_features} # Create the model to use for hyperparameter tuning model = GradientBoostingRegressor(random_state = 42) # Set up the random search with 4-fold cross validation random_cv = RandomizedSearchCV(estimator=model, param_distributions=hyperparameter_grid, cv=4, n_iter=25, scoring = 'neg_mean_absolute_error', n_jobs = -1, verbose = 1, return_train_score = True, random_state=42) # Fit on the training data random_cv.fit(X, y) After performing the search, we can inspect the RandomizedSearchCV object to find the best model: # Find the best combination of settings random_cv.best_estimator_ GradientBoostingRegressor(loss='lad', max_depth=5, max_features=None, min_samples_leaf=6, min_samples_split=6, n_estimators=500)</span></span></code> </pre> <br>  Voc√™ pode usar esses resultados para uma pesquisa em grade, selecionando par√¢metros para a grade que est√£o pr√≥ximos desses valores √≥timos.  Por√©m, √© improv√°vel que ajustes adicionais melhorem significativamente o modelo.  Existe uma regra geral: a constru√ß√£o competente de recursos ter√° um impacto muito maior na precis√£o do modelo do que na configura√ß√£o mais cara do hiperpar√¢metro.  Esta √© a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">lei da diminui√ß√£o da lucratividade em rela√ß√£o ao aprendizado de m√°quina</a> : o design de atributos oferece o maior retorno e o ajuste hiperparam√©trico traz apenas benef√≠cios modestos. <br><br>  Para alterar o n√∫mero de estimadores (√°rvores de decis√£o) e preservar os valores de outros hiperpar√¢metros, pode ser realizado um experimento que demonstrar√° o papel dessa configura√ß√£o.  A implementa√ß√£o √© dada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> , mas aqui est√° o resultado: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aca/18e/d51/aca18ed519f22d26c6b78af3324b8614.png"><br><br>  √Ä medida que o n√∫mero de √°rvores usadas pelo modelo aumenta, o n√≠vel de erros durante o treinamento e o teste diminui.  Mas os erros de aprendizado diminuem muito mais rapidamente e, como resultado, o modelo √© treinado novamente: mostra excelentes resultados nos dados de treinamento, mas funciona pior nos dados de teste. <br><br>  Nos dados de teste, a precis√£o sempre diminui (porque o modelo v√™ as respostas corretas para o conjunto de dados de treinamento), mas uma queda significativa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">indica reciclagem</a> .  Esse problema pode ser resolvido aumentando a quantidade de dados de treinamento ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">reduzindo a complexidade do modelo usando hiperpar√¢metros</a> .  Aqui n√£o abordaremos os hiperpar√¢metros, mas recomendo que voc√™ sempre preste aten√ß√£o ao problema da reciclagem. <br><br>  Para o nosso modelo final, levaremos 800 avaliadores, pois isso nos dar√° o menor n√≠vel de erro na valida√ß√£o cruzada.  Agora teste o modelo! <br><br><h2>  Avalia√ß√£o usando dados de teste </h2><br>  Como pessoas respons√°veis, garantimos que nosso modelo n√£o tivesse acesso aos dados de teste durante o treinamento.  Portanto, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">podemos usar a precis√£o ao trabalhar com dados de teste como um indicador de</a> qualidade do modelo quando ele √© admitido em tarefas reais. <br><br>  Alimentamos os dados de teste do modelo e calculamos o erro.  Aqui est√° uma compara√ß√£o dos resultados do algoritmo padr√£o de aumento de gradiente e nosso modelo personalizado: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Make predictions on the test set using default and final model default_pred = default_model.predict(X_test) final_pred = final_model.predict(X_test) Default model performance on the test set: MAE = 10.0118. Final model performance on the test set: MAE = 9.0446.</span></span></code> </pre> <br>  O ajuste hiperparam√©trico ajudou a melhorar a precis√£o do modelo em cerca de 10%.  Dependendo da situa√ß√£o, isso pode ser uma melhoria muito significativa, mas leva muito tempo. <br><br>  Voc√™ pode comparar o tempo de treinamento para ambos os modelos usando o <code>%timeit</code> magic <code>%timeit</code> nos cadernos Jupyter.  Primeiro, me√ßa a dura√ß√£o padr√£o do modelo: <br><br><pre> <code class="python hljs">%%timeit -n <span class="hljs-number"><span class="hljs-number">1</span></span> -r <span class="hljs-number"><span class="hljs-number">5</span></span> default_model.fit(X, y) <span class="hljs-number"><span class="hljs-number">1.09</span></span> s ¬± <span class="hljs-number"><span class="hljs-number">153</span></span> ms per loop (mean ¬± std. dev. of <span class="hljs-number"><span class="hljs-number">5</span></span> runs, <span class="hljs-number"><span class="hljs-number">1</span></span> loop each)</code> </pre> <br>  Um segundo para estudar √© muito decente.  Mas o modelo ajustado n√£o √© t√£o r√°pido: <br><br><pre> <code class="python hljs">%%timeit -n <span class="hljs-number"><span class="hljs-number">1</span></span> -r <span class="hljs-number"><span class="hljs-number">5</span></span> final_model.fit(X, y) <span class="hljs-number"><span class="hljs-number">12.1</span></span> s ¬± <span class="hljs-number"><span class="hljs-number">1.33</span></span> s per loop (mean ¬± std. dev. of <span class="hljs-number"><span class="hljs-number">5</span></span> runs, <span class="hljs-number"><span class="hljs-number">1</span></span> loop each)</code> </pre> <br>  Essa situa√ß√£o ilustra o aspecto fundamental do aprendizado de m√°quina: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trata-se de compromissos</a> .  √â constantemente necess√°rio escolher um equil√≠brio entre precis√£o e interpretabilidade, entre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">deslocamento e dispers√£o</a> , entre precis√£o e tempo de opera√ß√£o, e assim por diante.  A combina√ß√£o certa √© completamente determinada pela tarefa espec√≠fica.  No nosso caso, um aumento de 12 vezes na dura√ß√£o do trabalho em termos relativos √© grande, mas em termos absolutos √© insignificante. <br><br>  Obtivemos os resultados finais da previs√£o, agora vamos analis√°-los e descobrir se h√° algum desvio percept√≠vel.  √Ä esquerda, h√° um gr√°fico da densidade da previs√£o e dos valores reais, √† direita, um histograma do erro <br><br><img src="https://habrastorage.org/getpro/habr/post_images/817/ea7/f23/817ea7f2371b83ff0ae6ae5fa02b5a1e.png" width="350"><img src="https://habrastorage.org/getpro/habr/post_images/f49/f42/5cc/f49f425cc56d717a1e75b9478d1a24d1.png" width="340"><br><br>  A previs√£o do modelo repete bem a distribui√ß√£o dos valores reais, enquanto nos dados de treinamento, o pico de densidade est√° localizado mais pr√≥ximo do valor mediano (66) do que o pico de densidade real (cerca de 100).  Os erros t√™m uma distribui√ß√£o quase normal, embora existam v√°rios valores negativos grandes quando a previs√£o do modelo √© muito diferente dos dados reais.  No pr√≥ximo artigo, examinaremos mais detalhadamente a interpreta√ß√£o dos resultados. <br><br><h2>  Conclus√£o </h2><br>  Neste artigo, examinamos v√°rias etapas da solu√ß√£o do problema de aprendizado de m√°quina: <br><br><ul><li>  Preenchendo valores ausentes e recursos de dimensionamento. </li><li>  Avalia√ß√£o e compara√ß√£o dos resultados de v√°rios modelos. </li><li>  Ajuste hiperparam√©trico usando pesquisa aleat√≥ria em grade e valida√ß√£o cruzada. </li><li>  Avalia√ß√£o do melhor modelo usando dados de teste. </li></ul><br>  Os resultados indicam que podemos usar o aprendizado de m√°quina para prever o Energy Star Score com base nas estat√≠sticas dispon√≠veis.  Com a ajuda do aumento de gradiente, foi obtido um erro de 9,1 nos dados de teste.  O ajuste hiperparam√©trico pode melhorar muito os resultados, mas ao custo de uma desacelera√ß√£o significativa.  Esse √© um dos muitos compromissos a serem considerados no aprendizado de m√°quina. <br><br>  No pr√≥ximo artigo, tentaremos descobrir como nosso modelo funciona.  Tamb√©m veremos os principais fatores que influenciam o Energy Star Score.  Se soubermos que o modelo √© preciso, tentaremos entender por que ele prediz dessa maneira e o que isso nos diz sobre o problema em si. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt425907/">https://habr.com/ru/post/pt425907/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt425897/index.html">Recursos do uso da biblioteca RxJs em um sistema banc√°rio online</a></li>
<li><a href="../pt425899/index.html">Formigueiro ou fortaleza? Estou construindo uma casa pelo pre√ßo de um apartamento. 1 parte</a></li>
<li><a href="../pt425901/index.html">Esta√ß√£o meteorol√≥gica no Arduino de A a Z. Parte 1</a></li>
<li><a href="../pt425903/index.html">O feriado chega at√© n√≥s: o SCRF dobrou a banda ISM de 868 MHz</a></li>
<li><a href="../pt425905/index.html">Como escrever c√≥digo assembler com instru√ß√µes sobrepostas (outra t√©cnica para ofuscar bytecode)</a></li>
<li><a href="../pt425911/index.html">Transferir o CRM da nuvem para a vers√£o em caixa</a></li>
<li><a href="../pt425915/index.html">Como as comunica√ß√µes transfronteiri√ßas podem substituir os sem√°foros e diminuir o caminho para o trabalho</a></li>
<li><a href="../pt425917/index.html">Lutador da justi√ßa impede Waymo de patentear a tecnologia chave do lidar</a></li>
<li><a href="../pt425919/index.html">Mapas hexagonais no Unity: salvamento e carregamento, texturas, dist√¢ncias</a></li>
<li><a href="../pt425921/index.html">Reuni√£o da comunidade .NET no CLRium # 4 + online</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
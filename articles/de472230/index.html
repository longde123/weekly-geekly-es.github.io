<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ôüÔ∏è üïâÔ∏è üëë Chips f√ºr ML - sprechen Sie √ºber neue Produkte üßô ü§æüèº üßú</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir sprechen √ºber neue Architekturen sowohl von gro√üen globalen Herstellern als auch von Start-ups - Wafer-Scale-Chips, Tensor-Prozessoren und graphba...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Chips f√ºr ML - sprechen Sie √ºber neue Produkte</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/1cloud/blog/472230/">  Wir sprechen √ºber neue Architekturen sowohl von gro√üen globalen Herstellern als auch von Start-ups - Wafer-Scale-Chips, Tensor-Prozessoren und graphbasierte Ger√§te. <br><br>  <sup><font color="#A9A9A9">Themenauswahl:</font></sup> <sup><font color="#A9A9A9"><br><br></font></sup> <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tools f√ºr Softwareentwickler: Offene Frameworks und Bibliotheken von MO</a> </li></ul><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/ja/oa/lt/jaoaltprurinq8iyqnzfdqbnmto.jpeg"></a> <a name="habracut"></a><br>  <font color="#A9A9A9"><i>Fotos - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Jason Leung</a> - Unsplash</i></font> <br><br><h2>  Wafer f√ºr tiefes Lernen </h2><br>  Bei der Herstellung klassischer Prozessoren wird ein Siliziumsubstrat in einzelne Kristalle unterteilt.  Bei Wafer-Scale-Prozessoren wird der Halbleiterwafer jedoch nicht geteilt, sondern zu einem gro√üen Chip.  Infolgedessen sind die Komponenten n√§her beieinander und die Systemleistung steigt. <br><br>  Dieser Ansatz wurde von Ingenieuren von Cerebras Systems und TSMC verfolgt, die einen Chip f√ºr tiefes Lernen entwickelten - <b>Cerebras WSE</b> .  Es wurde auf der Hot Chips-Konferenz im Sp√§tsommer gezeigt.  Das Ger√§t <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ist</a> ein quadratischer Kristall mit einer Seitenl√§nge von 21,5 cm. Es besteht aus 1,2 Billionen Transistoren, die in 400.000 Kernen kombiniert sind.  Diese Kerne ‚Äûkommunizieren‚Äú miteinander √ºber das propriet√§re Swarm-System mit einer Bandbreite von 100 Pbit / s. <br><br>  Die Entwickler sagen, dass der Chip <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Berechnungen</a> durch Herausfiltern von Nulldaten in Matrixoperationen voroptimiert - sie machen 50 bis 98% aller Werte aus.  Das Erlernen eines Modells auf Cerebras ist daher hundertmal schneller als auf klassischen GPUs.  NYTimes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">reagierte</a> jedoch mit einem gewissen Anteil an Skepsis auf solche Aussagen - unabh√§ngige Experten haben die Hardware noch nicht getestet. <br><br>  Cerebras-Rechenkerne sind programmierbar.  Sie k√∂nnen f√ºr die Arbeit mit beliebigen neuronalen Netzen optimiert werden.  Es wird erwartet, dass der neue Chip in Cloud-Systemen und Anwendungen f√ºr maschinelles Lernen Anwendung findet: von Drohnen bis zu Sprachassistenten.  Es ist noch nicht bekannt, wann der Chip in den Handel kommen wird, aber einige Unternehmen testen ihn bereits auf Workloads. <br><br>  <b>Silicon Interconnect Fabric</b> (Si-IF) ist ein weiteres Wafer-Scale-Ger√§t f√ºr MO-Anwendungen.  Es wird im Labor der University of California entwickelt.  Si-IF ist ein Ger√§t, das Dutzende von GPUs auf einem einzigen Siliziumwafer kombiniert.  Die Entwickler haben bereits zwei Prototypen f√ºr 24 und 40 GPUs vorgestellt.  Ihre Leistung ist 2,5-mal h√∂her als die der klassischen Ger√§te.  Sie planen, das System im Rechenzentrum einzusetzen. <br><br><h2>  Tensorprozessoren </h2><br>  Im Mai 2018 k√ºndigte Google <b>TPU v3 an</b> , die dritte Generation seiner Tensorprozessoren f√ºr die Arbeit mit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow-Bibliothek</a> f√ºr maschinelles Lernen.  √úber die technischen Eigenschaften des neuen Ger√§ts ist wenig bekannt.  Die Serienversion wird in 12- oder 16-nm-Prozesstechnologie hergestellt.  Thermische Entwurfsleistung - 200 Watt, Leistung - 105 TFLOPS bei der Arbeit mit bfloat 16. Dies ist ein 16-Bit-Gleitkomma-Darstellungssystem, das beim Deep Learning verwendet wird. <br><br>  Bei einer Reihe von Aufgaben hat die Leistung des Google TPU der zweiten Generation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die</a> F√§higkeiten des NVIDIA Tesla V100 um das F√ºnffache <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√ºbertroffen</a> .  Ingenieure sagen, die dritte Generation sei achtmal leistungsst√§rker als ihre Vorg√§ngerin.  Wir mussten sogar Fl√ºssigkeitsk√ºhlung auf den Chips <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">installieren</a> . <br><br><img src="https://habrastorage.org/webt/b9/nr/qg/b9nrqgg4kzwjtpslnxji5a6q8p4.jpeg"><br>  <font color="#A9A9A9"><i>Foto - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Cineca</a> - CC BY</i></font> <br><br>  Das Unternehmen plant, eine Reihe seiner Systeme auf die neuen Tensorprozessoren zu √ºbertragen: Sprachassistent, Fotoverarbeitungsdienst und RankBrain-Algorithmus f√ºr das Ranking von Suchanfragen.  Das Unternehmen m√∂chte au√üerdem Cloud-basierte skalierbare Supercomputer auf Basis von TPU bauen und Wissenschaftlern, die an der Untersuchung von KI-Systemen beteiligt sind, den Zugang zu diesen Computern erm√∂glichen.  Im sp√§ten Fr√ºhjahr wurde der Dienst im Beta-Modus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gestartet</a> . <br><br><h2>  Chips, die mit komplexen Graphen arbeiten </h2><br>  Das britische Startup Graphcore hat einen Chip f√ºr Deep-Learning-Aufgaben entwickelt - die <b>Colossus IPU</b> (Intelligence Processing Unit).  Es enth√§lt 1200 Kerne und eine Reihe spezialisierter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">transzendentaler Funktionen</a> .  Jeder Kern verarbeitet sechs Threads.  Eisen wird mit Pappel-Software gepaart.  Es kompiliert Modelle und baut auf ihrer Basis komplexe mehrstufige algorithmische Diagramme auf, die auf IPU-Prozessoren ausgef√ºhrt werden.  Tests der ersten Graphcore-Beispiele zeigten, dass sie hundertmal mehr Leistung haben als herk√∂mmliche GPUs. <br><br>  Startup liefert <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bereits eine</a> PCI-E-Karte in voller Gr√∂√üe f√ºr Server aus.  Es hat in seiner Zusammensetzung zwei IPU-Chips, die nach der 16-nm-Prozesstechnologie hergestellt wurden und aus 24 Milliarden Transistoren bestehen.  Die Rechenleistung eines solchen Ger√§ts betr√§gt 125 TFLOPS.  Karten funktionieren in Rechenzentren von IaaS-Anbietern und Autos mit Autopilot.  Die Gr√ºnder des Startups <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sagen,</a> dass mehr als hundert Kunden mit ihren Ger√§ten arbeiten, aber sie nennen keine bestimmten Unternehmen. <br><br>  <i>Der Wettbewerb auf dem Gebiet der Hardwareger√§te f√ºr maschinelles Lernen wird immer ernster.</i>  <i>Neue Akteure treten in den Markt ein und bieten innovative Architekturen. Namhafte Unternehmen erh√∂hen weiterhin die Kapazit√§t bestehender L√∂sungen.</i>  <i>In jedem Fall spielt dies Rechenzentrumsbesitzern, Data Science-Ingenieuren und anderen Spezialisten, die Systeme f√ºr k√ºnstliche Intelligenz entwickeln, in die H√§nde.</i> <br><br><hr><img src="https://habrastorage.org/webt/em/zi/pq/emzipq7g4fpas60ehj7ykxsg-iu.png" width="40" align="left">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Partnerprogramm 1cloud.ru</a> .  Benutzer unserer Cloud k√∂nnen Einnahmen erzielen und die Kosten f√ºr die Anmietung einer virtuellen Infrastruktur senken. <br><hr><img src="https://habrastorage.org/webt/od/tw/fh/odtwfhtjb34yfqnzw3zfagzwsoc.png" width="40" align="left">  Zum Beispiel bieten wir den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Private Cloud</a> Service an.  Mit seiner Hilfe k√∂nnen Sie die IT-Infrastruktur f√ºr Projekte beliebiger Komplexit√§t bereitstellen. <br><hr></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de472230/">https://habr.com/ru/post/de472230/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de472220/index.html">Warum Spitzenphysiker eine Multi-World-Interpretation nicht m√∂gen</a></li>
<li><a href="../de472222/index.html">"Lesen, wenn Sie gerne zuh√∂ren": B√ºcher f√ºr diejenigen, denen Musik nicht gleichg√ºltig ist - von Klassik bis Hip-Hop</a></li>
<li><a href="../de472224/index.html">Mit dem neuen NVMe SSD als Boot - Laufwerk auf √§lteren Systemen mit Legacy - BIOS (f√ºr jedes OS)</a></li>
<li><a href="../de472226/index.html">Verbessern der Formularsteuerung in Microsoft Edge und Chromium</a></li>
<li><a href="../de472228/index.html">9 Tricks zum Arbeiten mit Visual Studio-Code</a></li>
<li><a href="../de472232/index.html">Vom ‚ÄûColor Extender f√ºr ZX-Spectrum‚Äú bis zum ZX-Poly</a></li>
<li><a href="../de472234/index.html">Kryptow√§hrung: Ist es immer noch ein Freeloader oder ein Partner?</a></li>
<li><a href="../de472240/index.html">√úber Gamification. Was ist das, warum und wie geht das? Entwickler-Look</a></li>
<li><a href="../de472242/index.html">Wir haben den Tokio-Scheduler zehnmal beschleunigt</a></li>
<li><a href="../de472246/index.html">Reagieren + IndexDb + Auto-Update = fast AsyncRedux</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👆 👩🏻‍🍳 📸 Pengelompokan hirarki data kategorikal dalam R 👩🏼‍⚕️ 🙍🏿 🤸🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Terjemahan disiapkan untuk siswa dari kursus "Analisis Terapan pada R" . 




 Ini adalah upaya pertama saya untuk mengelompokkan klien berdasarkan da...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pengelompokan hirarki data kategorikal dalam R</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/461741/">  <i>Terjemahan disiapkan untuk siswa dari kursus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"Analisis Terapan pada R"</a> .</i> <br><br><img src="https://habrastorage.org/webt/wq/q0/sp/wqq0sphqihtnsg1f8eor15ffkgi.png"><br><hr><br><br>  Ini adalah upaya pertama saya untuk mengelompokkan klien berdasarkan data nyata, dan itu memberi saya pengalaman berharga.  Ada banyak artikel di Internet tentang pengelompokan menggunakan variabel numerik, tetapi menemukan solusi untuk data kategorikal, yang agak lebih sulit, tidak begitu sederhana.  Metode pengelompokan untuk data kategorikal masih dalam pengembangan, dan di pos lain saya akan mencoba yang lain. <br><a name="habracut"></a><br>  Di sisi lain, banyak orang percaya bahwa pengelompokan data kategorikal mungkin tidak menghasilkan hasil yang bermakna - dan ini sebagian benar (lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">diskusi yang sangat baik tentang CrossValidated</a> ).  Pada satu titik, saya berpikir: “Apa yang saya lakukan?  Mereka dapat dengan mudah dibagi menjadi beberapa kelompok. ”  Namun, analisis kohort juga tidak selalu disarankan, terutama dengan sejumlah besar variabel kategori dengan sejumlah besar level: Anda dapat dengan mudah menangani 5-7 kohort, tetapi jika Anda memiliki 22 variabel dan masing-masing memiliki 5 level (misalnya, survei pelanggan dengan perkiraan terpisah 1 , 2, 3, 4 dan 5), dan Anda perlu memahami kelompok karakteristik apa dari klien yang Anda hadapi - Anda akan mendapatkan 22x5 kohort.  Tidak ada yang mau repot dengan tugas seperti itu.  Dan di sini pengelompokan bisa membantu.  Jadi dalam posting ini saya akan berbicara tentang apa yang ingin saya ketahui segera setelah saya mulai mengelompokkan. <br><br>  Proses pengelompokan itu sendiri terdiri dari tiga langkah: <br><br><ol><li>  Membangun matriks ketidaksamaan tidak diragukan lagi adalah keputusan paling penting dalam pengelompokan.  Semua langkah selanjutnya akan didasarkan pada matriks ketidaksamaan yang Anda buat. </li><li>  Pilihan metode pengelompokan. </li><li>  Evaluasi Cluster. </li></ol><br>  Posting ini akan menjadi semacam pengantar yang menjelaskan prinsip-prinsip dasar pengelompokan dan implementasinya di lingkungan R. <br><br><h2>  Matriks dissimilaritas </h2><br>  Dasar pengelompokan akan menjadi matriks ketidaksamaan, yang dalam istilah matematika menggambarkan betapa berbedanya titik-titik dalam kumpulan data (dihapus) dari satu sama lain.  Ini memungkinkan Anda untuk lebih lanjut menggabungkan dalam kelompok titik-titik yang paling dekat satu sama lain, atau untuk memisahkan yang paling jauh satu sama lain - ini adalah gagasan utama pengelompokan. <br><br>  Pada tahap ini, perbedaan antara tipe data adalah penting, karena matriks ketidaksamaan didasarkan pada jarak antara titik data individu.  Mudah untuk membayangkan jarak antara titik-titik data numerik (contoh yang terkenal adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">jarak Euclidean</a> ), tetapi dalam kasus data kategorikal (faktor dalam R), semuanya tidak begitu jelas. <br><br>  Untuk membangun matriks ketidaksamaan dalam hal ini, yang disebut jarak Gover harus digunakan.  Saya tidak akan mempelajari bagian matematika dari konsep ini, saya hanya akan memberikan tautan: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">di</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sana</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> .  Untuk ini, saya lebih suka menggunakan <code>daisy()</code> dengan <code>metric = c("gower")</code> dari paket <code>cluster</code> . <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#-----   -----# #    ,       ,     ,   ,    library(dplyr) #     set.seed(40) #     #    ;   data.frame()     #    ,   200   1  200 id.s &lt;- c(1:200) %&gt;% factor() budget.s &lt;- sample(c("small", "med", "large"), 200, replace = T) %&gt;% factor(levels=c("small", "med", "large"), ordered = TRUE) origins.s &lt;- sample(c("x", "y", "z"), 200, replace = T, prob = c(0.7, 0.15, 0.15)) area.s &lt;- sample(c("area1", "area2", "area3", "area4"), 200, replace = T, prob = c(0.3, 0.1, 0.5, 0.2)) source.s &lt;- sample(c("facebook", "email", "link", "app"), 200, replace = T, prob = c(0.1,0.2, 0.3, 0.4)) ##   —      dow.s &lt;- sample(c("mon", "tue", "wed", "thu", "fri", "sat", "sun"), 200, replace = T, prob = c(0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2)) %&gt;% factor(levels=c("mon", "tue", "wed", "thu", "fri", "sat", "sun"), ordered = TRUE) #  dish.s &lt;- sample(c("delicious", "the one you don't like", "pizza"), 200, replace = T) #   data.frame()      synthetic.customers &lt;- data.frame(id.s, budget.s, origins.s, area.s, source.s, dow.s, dish.s) #-----   -----# library(cluster) #       #   : daisy(), diana(), clusplot() gower.dist &lt;- daisy(synthetic.customers[ ,2:7], metric = c("gower")) # class(gower.dist) ## , </span></span></code> </pre> <br>  Matriks ketidaksamaan siap.  Untuk 200 pengamatan, ini dibangun dengan cepat, tetapi mungkin membutuhkan perhitungan yang sangat besar jika Anda berurusan dengan kumpulan data yang besar. <br><br>  Dalam praktiknya, sangat mungkin Anda pertama-tama harus membersihkan set data, melakukan transformasi yang diperlukan dari baris menjadi faktor, dan melacak nilai yang hilang.  Dalam kasus saya, kumpulan data juga berisi deretan nilai-nilai yang hilang yang indah mengelompok setiap kali, jadi sepertinya itu adalah harta - sampai saya melihat nilai-nilai (sayangnya!). <br><br><h2>  Algoritma Clustering </h2><br>  Anda mungkin sudah tahu bahwa pengelompokan adalah <i>k-means dan hierarkis</i> .  Dalam posting ini, saya fokus pada metode kedua, karena lebih fleksibel dan memungkinkan berbagai pendekatan: Anda dapat memilih algoritma pengelompokan <i>aglomeratif</i> (dari bawah ke atas) atau <i>divisi</i> (atas ke bawah). <br><br><img src="https://habrastorage.org/webt/nl/vp/u4/nlvpu4e8ykoh_nd_el_4i6plh8q.png"><br>  <i>Sumber: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Panduan Pemrograman UC Business Analytics R</a></i> <br><br>  Pengelompokan aglomeratif dimulai dengan <code>n</code> cluster, di mana <code>n</code> adalah jumlah pengamatan: diasumsikan bahwa masing-masing dari mereka adalah cluster yang terpisah.  Kemudian algoritma mencoba untuk menemukan dan mengelompokkan titik data yang paling mirip di antara mereka sendiri - ini adalah bagaimana pembentukan cluster dimulai. <br><br>  Clustering divisi dilakukan dengan cara yang berlawanan - pada awalnya diasumsikan bahwa semua n titik data yang kita miliki adalah satu cluster besar, dan kemudian yang paling mirip dibagi menjadi kelompok-kelompok yang terpisah. <br><br>  Ketika memutuskan metode mana yang harus dipilih, selalu masuk akal untuk mencoba semua opsi, namun, secara umum, <i>pengelompokan aglomeratif lebih baik untuk mengidentifikasi kelompok kecil dan digunakan oleh sebagian besar program komputer, dan pengelompokan divisi lebih cocok untuk mengidentifikasi kelompok besar</i> . <br><br>  Secara pribadi, sebelum memutuskan metode mana yang akan digunakan, saya lebih suka melihat dendrogram - representasi grafis dari clustering.  Seperti yang akan Anda lihat nanti, beberapa dendrogram sangat seimbang, sementara yang lain sangat kacau. <br><br>  # Input utama untuk kode di bawah ini adalah ketidaksamaan (matriks jarak) <br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#             #            —         —    #------------  ------------# divisive.clust &lt;- diana(as.matrix(gower.dist), diss = TRUE, keep.diss = TRUE) plot(divisive.clust, main = "Divisive")</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/54/mp/m1/54mpm19v8jkkpmj6usehxlgr5qk.png"><br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#------------   ------------# #      #         —     ,      #    (complete linkages) aggl.clust.c &lt;- hclust(gower.dist, method = "complete") plot(aggl.clust.c, main = "Agglomerative, complete linkages")</span></span></code> </pre> <br><h2>  Penilaian Kualitas Clustering </h2><br>  Pada tahap ini, perlu untuk memilih antara algoritma clustering yang berbeda dan jumlah cluster yang berbeda.  Anda dapat menggunakan berbagai metode penilaian, tidak lupa dibimbing oleh <b>akal sehat</b> .  Saya menggarisbawahi kata-kata ini dalam huruf tebal dan miring, karena kebermaknaan pilihan <b>sangat penting</b> - jumlah kelompok dan metode pembagian data ke dalam kelompok harus praktis dari sudut pandang praktis.  Jumlah kombinasi nilai-nilai variabel kategorik adalah terbatas (karena mereka diskrit), tetapi tidak ada gangguan berdasarkan mereka akan bermakna.  Anda mungkin juga tidak ingin memiliki sangat sedikit cluster - dalam hal ini mereka akan terlalu digeneralisasi.  Pada akhirnya, itu semua tergantung pada tujuan Anda dan tugas analisis. <br><br>  Secara umum, saat membuat cluster, Anda tertarik untuk memperoleh kelompok titik data yang terdefinisi dengan jelas, sehingga jarak antara titik-titik tersebut dalam kelompok ( <i>atau kekompakan</i> ) minimal, dan jarak antara kelompok ( <i>pemisahan</i> ) semaksimal mungkin.  Ini mudah dipahami secara intuitif: jarak antar titik adalah ukuran ketidaksamaan mereka, yang diperoleh berdasarkan matriks ketidaksamaan.  Dengan demikian, penilaian kualitas clustering didasarkan pada penilaian kekompakan dan keterpisahan. <br><br>  Selanjutnya, saya akan menunjukkan dua pendekatan dan menunjukkan bahwa salah satunya dapat memberikan hasil yang tidak berarti. <br><br><ul><li>  <i>Metode siku</i> : mulailah dengan itu jika faktor yang paling penting untuk analisis Anda adalah kekompakan cluster, yaitu kesamaan dalam kelompok. </li><li>  <i>Metode Penilaian Siluet</i> : Grafik <i>siluet yang</i> digunakan sebagai ukuran konsistensi data menunjukkan seberapa dekat masing-masing titik dalam satu kluster dengan titik-titik dalam kelompok tetangga. </li></ul><br>  Dalam praktiknya, kedua metode ini sering memberikan hasil yang berbeda, yang dapat menyebabkan kebingungan - kekompakan maksimum dan pemisahan paling jelas akan dicapai dengan jumlah cluster yang berbeda, sehingga akal sehat dan pemahaman tentang apa yang sebenarnya berarti data Anda akan memainkan peran penting saat membuat keputusan akhir. <br><br>  Ada juga sejumlah metrik yang dapat Anda analisis.  Saya akan menambahkannya langsung ke kode. <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#      ,        #      ,     ,   —   #     ,      ,         ,   ,     library(fpc) cstats.table &lt;- function(dist, tree, k) { clust.assess &lt;- c("cluster.number","n","within.cluster.ss","average.within","average.between", "wb.ratio","dunn2","avg.silwidth") clust.size &lt;- c("cluster.size") stats.names &lt;- c() row.clust &lt;- c() output.stats &lt;- matrix(ncol = k, nrow = length(clust.assess)) cluster.sizes &lt;- matrix(ncol = k, nrow = k) for(i in c(1:k)){ row.clust[i] &lt;- paste("Cluster-", i, " size") } for(i in c(2:k)){ stats.names[i] &lt;- paste("Test", i-1) for(j in seq_along(clust.assess)){ output.stats[j, i] &lt;- unlist(cluster.stats(d = dist, clustering = cutree(tree, k = i))[clust.assess])[j] } for(d in 1:k) { cluster.sizes[d, i] &lt;- unlist(cluster.stats(d = dist, clustering = cutree(tree, k = i))[clust.size])[d] dim(cluster.sizes[d, i]) &lt;- c(length(cluster.sizes[i]), 1) cluster.sizes[d, i] } } output.stats.df &lt;- data.frame(output.stats) cluster.sizes &lt;- data.frame(cluster.sizes) cluster.sizes[is.na(cluster.sizes)] &lt;- 0 rows.all &lt;- c(clust.assess, row.clust) # rownames(output.stats.df) &lt;- clust.assess output &lt;- rbind(output.stats.df, cluster.sizes)[ ,-1] colnames(output) &lt;- stats.names[2:k] rownames(output) &lt;- rows.all is.num &lt;- sapply(output, is.numeric) output[is.num] &lt;- lapply(output[is.num], round, 2) output } #     :      7 #     ,            stats.df.divisive &lt;- cstats.table(gower.dist, divisive.clust, 7) stats.df.divisive</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/r-/g_/ou/r-g_oukwyorhqnsls_cbg4c8spw.png"><br><br>  Jadi, indikator average.within, yang mewakili jarak rata-rata antara pengamatan di dalam cluster, berkurang, seperti halnya di dalam.cluster.ss (jumlah kuadrat dari jarak antara pengamatan dalam sebuah cluster).  Lebar rata-rata siluet (avg.silwidth) bervariasi tidak begitu jelas, namun, hubungan terbalik masih dapat dilihat. <br>  Perhatikan bagaimana ukuran cluster yang tidak proporsional.  Saya tidak akan tergesa-gesa bekerja dengan jumlah pengamatan yang tidak ada bandingannya.  Salah satu alasannya adalah bahwa kumpulan data mungkin tidak seimbang, dan beberapa kelompok pengamatan akan melebihi semua yang lain dalam analisis - ini tidak baik dan kemungkinan besar akan menyebabkan kesalahan. <br><br> <code>stats.df.aggl &lt;-cstats.table(gower.dist, aggl.clust.c, 7) #      </code> <br> <br> <code>stats.df.aggl</code> <br> <br><img src="https://habrastorage.org/webt/a_/-u/aa/a_-uaa_nff99nuyobulroyk_hka.png"><br><br>  Perhatikan betapa jauh lebih baik jumlah pengamatan per kelompok diseimbangkan dengan pengelompokan hierarkis aglomeratif berdasarkan metode komunikasi penuh. <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment"># ---------    ---------# #   «»       #    ,     7  library(ggplot2) #  #   ggplot(data = data.frame(t(cstats.table(gower.dist, divisive.clust, 15))), aes(x=cluster.number, y=within.cluster.ss)) + geom_point()+ geom_line()+ ggtitle("Divisive clustering") + labs(x = "Num.of clusters", y = "Within clusters sum of squares (SS)") + theme(plot.title = element_text(hjust = 0.5))</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/kw/kz/xy/kwkzxyuuzwhe0yst9kteg9inias.png"><br><br>  Jadi, kami telah membuat grafik "siku".  Ini menunjukkan bagaimana jumlah jarak kuadrat antara pengamatan (kami menggunakannya sebagai ukuran kedekatan pengamatan - semakin kecil, semakin dekat pengukuran di dalam cluster satu sama lain) bervariasi untuk jumlah cluster yang berbeda.  Idealnya, kita harus melihat "tikungan siku" yang berbeda pada titik di mana pengelompokan lebih lanjut hanya memberikan sedikit penurunan dalam jumlah kuadrat (SS).  Untuk grafik di bawah ini, saya akan berhenti di sekitar 7. Meskipun dalam kasus ini salah satu cluster hanya akan terdiri dari dua pengamatan.  Mari kita lihat apa yang terjadi selama pengelompokan aglomeratif. <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#       ggplot(data = data.frame(t(cstats.table(gower.dist, aggl.clust.c, 15))), aes(x=cluster.number, y=within.cluster.ss)) + geom_point()+ geom_line()+ ggtitle("Agglomerative clustering") + labs(x = "Num.of clusters", y = "Within clusters sum of squares (SS)") + theme(plot.title = element_text(hjust = 0.5))</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/y0/ck/q-/y0ckq-zxtzg0fbjr9gcq1jgorvq.png"><br><br>  "Siku" agglomeratif mirip dengan divisional, tetapi grafiknya terlihat lebih halus - lengkungan tidak terlalu terasa.  Seperti halnya pengelompokan divisional, saya akan fokus pada 7 klaster, namun, ketika memilih di antara kedua metode ini, saya lebih suka ukuran kluster yang diperoleh dengan metode aglomerasi - lebih baik bahwa mereka dapat dibandingkan satu sama lain. <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#  ggplot(data = data.frame(t(cstats.table(gower.dist, divisive.clust, 15))), aes(x=cluster.number, y=avg.silwidth)) + geom_point()+ geom_line()+ ggtitle("Divisive clustering") + labs(x = "Num.of clusters", y = "Average silhouette width") + theme(plot.title = element_text(hjust = 0.5))</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/u9/nj/nf/u9njnfcjqbxbzlfgpl5sxqailra.png"><br><br>  Saat menggunakan metode estimasi siluet, Anda harus memilih jumlah yang memberikan koefisien siluet maksimum, karena Anda memerlukan kelompok yang terpisah cukup jauh untuk dianggap terpisah. <br><br>  Koefisien siluet dapat berkisar dari -1 hingga 1, dengan 1 sesuai dengan konsistensi yang baik dalam kelompok, dan –1 tidak terlalu baik. <br>  Dalam kasus grafik di atas, Anda akan memilih 9 daripada 5 cluster. <br><br>  Sebagai perbandingan: dalam kasus "sederhana", grafik siluet mirip dengan yang di bawah ini.  Tidak seperti kita, tetapi hampir. <br><br><img src="https://habrastorage.org/webt/18/yw/uj/18ywujz8uh4q5hhnhtxlzrgs1nm.png"><br>  <i>Sumber: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pelaut Data</a></i> <br><br><pre> <code class="sql hljs">ggplot(data = data.frame(t(cstats.table(gower.dist, aggl.clust.c, 15))), aes(x=cluster.number, y=avg.silwidth)) + geom_point()+ geom_line()+ ggtitle("Agglomerative clustering") + labs(x = "Num.of clusters", y = "Average silhouette width") + theme(plot.title = element_text(hjust = 0.5))</code> </pre> <br><img src="https://habrastorage.org/webt/vk/f1/fl/vkf1fln-v-nedwuh6rzbjkxz2pg.png"><br><br>  Bagan lebar siluet memberi tahu kami: semakin banyak Anda membagi kumpulan data, semakin jelas klaster menjadi.  Namun, pada akhirnya Anda akan mencapai poin individual, dan Anda tidak membutuhkan ini.  Namun, inilah yang akan Anda lihat jika Anda mulai menambah jumlah <i>k</i> .  Misalnya, untuk <code>k=30</code> saya mendapat grafik berikut: <br><br><img src="https://habrastorage.org/webt/sz/nq/sy/sznqsykdros9uf8clfabfg8yb94.png"><br><br>  Untuk meringkas: semakin Anda membagi dataset, semakin baik cluster, tetapi kami tidak dapat mencapai poin individu (misalnya, dalam bagan di atas kami memilih 30 cluster, dan kami hanya memiliki 200 poin data). <br><br>  Jadi, pengelompokan aglomeratif dalam kasus kami bagi saya jauh lebih seimbang: ukuran klaster lebih atau kurang sebanding (lihat saja satu klaster yang hanya memiliki dua pengamatan ketika membaginya dengan metode pembagian!), Dan saya akan berhenti di 7 klaster yang diperoleh dengan metode ini.  Mari kita lihat bagaimana mereka terlihat dan terbuat dari apa mereka. <br><br>  Kumpulan data terdiri dari 6 variabel yang perlu divisualisasikan dalam 2D ​​atau 3D, jadi Anda harus bekerja keras!  Sifat data kategorikal juga membebankan beberapa batasan, sehingga solusi yang sudah jadi mungkin tidak berfungsi.  Saya perlu: a) melihat bagaimana pengamatan dibagi menjadi beberapa kelompok, b) memahami bagaimana pengamatan dikategorikan.  Oleh karena itu, saya membuat a) dendrogram warna, b) peta panas dari jumlah pengamatan per variabel di dalam setiap cluster. <br><br><pre> <code class="sql hljs">library("ggplot2") library("reshape2") library("purrr") library("dplyr") <span class="hljs-comment"><span class="hljs-comment">#    library("dendextend") dendro &lt;- as.dendrogram(aggl.clust.c) dendro.col &lt;- dendro %&gt;% set("branches_k_color", k = 7, value = c("darkslategray", "darkslategray4", "darkslategray3", "gold3", "darkcyan", "cyan3", "gold3")) %&gt;% set("branches_lwd", 0.6) %&gt;% set("labels_colors", value = c("darkslategray")) %&gt;% set("labels_cex", 0.5) ggd1 &lt;- as.ggdend(dendro.col) ggplot(ggd1, theme = theme_minimal()) + labs(x = "Num. observations", y = "Height", title = "Dendrogram, k = 7")</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/iy/hf/jx/iyhfjxt9q7vztvwbaazmqlzzno0.png"><br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#     ( ) ggplot(ggd1, labels = T) + scale_y_reverse(expand = c(0.2, 0)) + coord_polar(theta="x")</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/if/4g/yv/if4gyv42vtgecjd9n-b_0bb91rs.png"><br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#  —   #    —       #    ,      clust.num &lt;- cutree(aggl.clust.c, k = 7) synthetic.customers.cl &lt;- cbind(synthetic.customers, clust.num) cust.long &lt;- melt(data.frame(lapply(synthetic.customers.cl, as.character), stringsAsFactors=FALSE), id = c("id.s", "clust.num"), factorsAsStrings=T) cust.long.q &lt;- cust.long %&gt;% group_by(clust.num, variable, value) %&gt;% mutate(count = n_distinct(id.s)) %&gt;% distinct(clust.num, variable, value, count) # heatmap.c ,      — ,   ,     heatmap.c &lt;- ggplot(cust.long.q, aes(x = clust.num, y = factor(value, levels = c("x","y","z", "mon", "tue", "wed", "thu", "fri","sat","sun", "delicious", "the one you don't like", "pizza", "facebook", "email", "link", "app", "area1", "area2", "area3", "area4", "small", "med", "large"), ordered = T))) + geom_tile(aes(fill = count))+ scale_fill_gradient2(low = "darkslategray1", mid = "yellow", high = "turquoise4") #            cust.long.p &lt;- cust.long.q %&gt;% group_by(clust.num, variable) %&gt;% mutate(perc = count / sum(count)) %&gt;% arrange(clust.num) heatmap.p &lt;- ggplot(cust.long.p, aes(x = clust.num, y = factor(value, levels = c("x","y","z", "mon", "tue", "wed", "thu", "fri","sat", "sun", "delicious", "the one you don't like", "pizza", "facebook", "email", "link", "app", "area1", "area2", "area3", "area4", "small", "med", "large"), ordered = T))) + geom_tile(aes(fill = perc), alpha = 0.85)+ labs(title = "Distribution of characteristics across clusters", x = "Cluster number", y = NULL) + geom_hline(yintercept = 3.5) + geom_hline(yintercept = 10.5) + geom_hline(yintercept = 13.5) + geom_hline(yintercept = 17.5) + geom_hline(yintercept = 21.5) + scale_fill_gradient2(low = "darkslategray1", mid = "yellow", high = "turquoise4") heatmap.p</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/c5/gg/y5/c5ggy5vih07qcfi4h26mgcvkfgy.png"><br><br>  Peta panas menunjukkan secara grafis berapa banyak pengamatan yang dilakukan untuk setiap tingkat faktor untuk faktor awal (variabel yang kami mulai dengan).  Warna biru gelap sesuai dengan jumlah pengamatan yang relatif besar di dalam cluster.  Peta panas ini juga menunjukkan bahwa untuk hari dalam seminggu (matahari, sat ... mon) dan ukuran keranjang (besar, med, kecil), jumlah pelanggan di setiap sel hampir sama - ini mungkin berarti bahwa kategori ini tidak determinatif untuk analisis, dan Mungkin mereka tidak perlu diperhitungkan. <br><br><h2>  Kesimpulan </h2><br>  Dalam artikel ini, kami menghitung matriks ketidaksamaan, menguji metode aglomerasi dan divisi pengelompokan hierarkis, dan membiasakan diri dengan metode siku dan siluet untuk menilai kualitas cluster. <br><br>  Pengelompokan hierarkis divisi dan aglomeratif adalah awal yang baik untuk mempelajari topik tersebut, tetapi jangan berhenti di situ jika Anda ingin benar-benar menguasai analisis klaster.  Ada banyak metode dan teknik lain.  Perbedaan utama dari pengelompokan data numerik adalah perhitungan matriks perbedaan.  Ketika menilai kualitas pengelompokan, tidak semua metode standar akan memberikan hasil yang andal dan bermakna - metode siluet sangat mungkin tidak cocok. <br><br>  Dan akhirnya, karena beberapa waktu telah berlalu sejak saya membuat contoh ini, sekarang saya melihat sejumlah kekurangan dalam pendekatan saya dan akan dengan senang hati menerima umpan balik.  Salah satu masalah signifikan dari analisis saya tidak terkait dengan pengelompokan seperti itu - <i>set data saya tidak seimbang</i> dalam banyak hal, dan saat ini tetap tidak terhitung.  Ini memiliki efek yang nyata pada pengelompokan: 70% klien termasuk dalam satu tingkat faktor “kewarganegaraan”, dan kelompok ini mendominasi sebagian besar kelompok yang diperoleh, sehingga sulit untuk menghitung perbedaan dalam tingkat faktor lainnya.  Lain kali saya akan mencoba menyeimbangkan kumpulan data dan membandingkan hasil pengelompokan.  Tetapi lebih lanjut tentang itu di pos lain. <br><br>  Terakhir, jika Anda ingin mengkloning kode saya, berikut ini tautan ke github: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://github.com/khunreus/cluster-categorical</a> <br>  Saya harap Anda menikmati artikel ini! <br><br><h3>  <i>Sumber yang membantu saya:</i> </h3><br>  Panduan pengelompokan hierarki (persiapan data, pengelompokan, visualisasi) - blog ini akan menarik bagi mereka yang tertarik dengan analitik bisnis di lingkungan R: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">http://uc-r.github.io/hc_clustering</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https: // uc-r. github.io/kmeans_clustering</a> <br><br>  Validasi Cluster: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">http://www.sthda.com/english/articles/29-cluster-validation-essentials/97-cluster-validation-statistics-must-ofu-methods/</a> <br><br>    (   k-): <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://eight2late.wordpress.com/2015/07/22/a-gentle-introduction-to-cluster-analysis-using-r/</a> <br><br>    denextend,        : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://cran.r-project.org/web/packages/dendextend/vignettes/introduction.html#the-set-function</a> <br><br>    ,   : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://www.r-statistics.com/2010/06/clustergram-visualization-and-diagnostics-for-cluster-analysis-r-code/</a> <br><br>     : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://jcoliver.github.io/learn-r/008-ggplot-dendrograms-and-heatmaps.html</a> <br><br>       ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5025633/</a> (  GitHub: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://github.com/khunreus/EnsCat</a> ). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id461741/">https://habr.com/ru/post/id461741/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id461731/index.html">DPKI: Mengatasi Kerugian PKI Terpusat oleh Cara Blockchain</a></li>
<li><a href="../id461733/index.html">Belajar Bahasa Inggris: 9 idiom gaya Amerika</a></li>
<li><a href="../id461735/index.html">Praktek Decoding Perangkat Keras FFmpeg DXVA2</a></li>
<li><a href="../id461737/index.html">Kami mengumpulkan lingkungan untuk TDD modern pada kode JavaScript + VS</a></li>
<li><a href="../id461739/index.html">Backend United 4: Okroshka. Insiden</a></li>
<li><a href="../id461743/index.html">Minggu Keamanan 31: Kerentanan VLC dan telepon rusak</a></li>
<li><a href="../id461745/index.html">DeviceLock DLP: Harga pasar gelap Rusia karena menerobos data pribadi (ditambah respons terhadap jawaban Tinkoff Bank)</a></li>
<li><a href="../id461747/index.html">Bagaimana kami menerapkan ML dalam aplikasi dengan hampir 50 juta pengguna. Pengalaman Sberbank</a></li>
<li><a href="../id461749/index.html">Keindahan di mata yang melihatnya</a></li>
<li><a href="../id461751/index.html">Kontribusi desainer untuk pengembangan aplikasi seluler</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
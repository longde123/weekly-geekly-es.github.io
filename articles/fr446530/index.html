<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòº ‚§µÔ∏è üßöüèª Word2vec en images üíå üöÄ üë∏üèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬´ Tout rec√®le un motif qui fait partie de l'univers. Il a la sym√©trie, l'√©l√©gance et la beaut√© - des qualit√©s qui sont d'abord saisies par tout v√©rita...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Word2vec en images</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/446530/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/85d/ad8/627/85dad8627ae6845b62f5bb965c291b19.png"></div><br><br><blockquote>  <font color="gray">¬´ <b>Tout rec√®le un motif qui fait partie de l'univers.</b></font>  <font color="gray"><b>Il a la sym√©trie, l'√©l√©gance et la beaut√©</b> - des qualit√©s qui sont d'abord saisies par tout v√©ritable artiste qui capture le monde.</font>  <font color="gray">Ce motif peut √™tre pris dans le changement de saison, dans la fa√ßon dont le sable s'√©coule le long de la pente, dans les branches emm√™l√©es d'un arbuste cr√©osote, dans le motif de sa feuille.</font> <font color="gray"><br><br></font>  <font color="gray">Nous essayons de copier ce mod√®le dans notre vie et notre soci√©t√© et donc nous aimons le rythme, le chant, la danse, diverses formes qui nous rendent heureux et nous r√©confortent.</font>  <font color="gray">Cependant, on peut √©galement discerner le danger qui se cache dans la recherche de la perfection absolue, car il est √©vident que le mod√®le parfait est inchang√©.</font>  <font color="gray">Et √† l'approche de la perfection, tout va √† la mort ¬ª- <i>Dune</i> (1965)</font> </blockquote><br>  Je pense que le concept d'int√©gration est l'une des id√©es les plus remarquables de l'apprentissage automatique.  Si vous avez d√©j√† utilis√© Siri, Google Assistant, Alexa, Google Translate ou m√™me un clavier de smartphone avec la pr√©diction du mot suivant, vous avez d√©j√† travaill√© avec le mod√®le de traitement du langage naturel bas√© sur les pi√®ces jointes.  Au cours des derni√®res d√©cennies, ce concept a subi un d√©veloppement important pour les mod√®les neuronaux (les d√©veloppements r√©cents incluent des int√©grations de mots contextualis√©es dans des mod√®les avanc√©s tels que BERT et GPT2). <br><a name="habracut"></a><br>  Word2vec est une m√©thode de cr√©ation d'investissement efficace d√©velopp√©e en 2013.  En plus de travailler avec des mots, certains de ses concepts ont √©t√© efficaces pour d√©velopper des m√©canismes de recommandation et donner du sens aux donn√©es m√™me dans des t√¢ches commerciales non linguistiques.  Cette technologie a √©t√© utilis√©e par des soci√©t√©s comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Airbnb</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Alibaba</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Spotify</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Anghami</a> dans leurs moteurs de recommandation. <br><br>  Dans cet article, nous examinerons le concept et la m√©canique de g√©n√©ration de pi√®ces jointes √† l'aide de word2vec.  Commen√ßons par un exemple pour vous familiariser avec la fa√ßon de repr√©senter des objets sous forme vectorielle.  Savez-vous combien une liste de cinq nombres (vectoriels) peut dire de votre personnalit√©? <br><br><h1>  Personnalisation: qu'√™tes-vous? </h1><br><blockquote>  <font color="gray">¬´Je vous donne le cam√©l√©on du d√©sert;</font>  <font color="gray">sa capacit√© √† fusionner avec le sable vous dira tout ce que vous devez savoir sur les racines de l'√©cologie et les raisons de pr√©server votre personnalit√©. ¬ª</font>  <font color="gray">- <i>Enfants de la Dune</i></font> </blockquote><br>  Sur une √©chelle de 0 √† 100, avez-vous un type de personnalit√© introverti ou extraverti (o√π 0 est le type le plus introverti et 100 est le type le plus extraverti)?  Avez-vous d√©j√† pass√© un test de personnalit√©: par exemple, MBTI, ou mieux encore <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">, les Big Five</a> ?  On vous donne une liste de questions puis vous √©valuez sur plusieurs axes, dont l'introversion / extroversion. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/79f/11e/e22/79f11ee220ebf9d6f52f51a5b780b090.png"></div><br>  <i><font color="gray">Exemple des r√©sultats du test Big Five.</font></i>  <i><font color="gray">Il en dit long sur la personnalit√© et est capable de pr√©dire la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©ussite scolaire</a> , <a href="">personnelle</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">professionnelle</a> .</font></i>  <i><font color="gray">Par exemple, vous pouvez le parcourir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .</font></i> <br><br>  Supposons que j'obtienne un score de 38 sur 100 pour l'√©valuation de l'introversion / extraversion.  Cela peut √™tre repr√©sent√© comme suit: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e56/729/35d/e5672935d7de17d41e78354d3742e6bc.png"></div><br><br>  Ou sur une √©chelle de -1 √† +1: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b39/e23/ce1/b39e23ce1c036b11763e3c45c3659a3e.png"></div><br><br>  Dans quelle mesure reconnaissons-nous une personne uniquement √† partir de cette √©valuation?  Pas vraiment.  Les humains sont des cr√©atures complexes.  Par cons√©quent, nous ajoutons une dimension de plus: une caract√©ristique de plus du test. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2aa/ab2/ebc/2aaab2ebc1ff30f1fd832e5cf5bf9cb1.png"></div><br>  <i><font color="gray">Vous pouvez imaginer ces deux dimensions comme un point sur le graphique, ou, mieux encore, comme un vecteur de l'origine √† ce point.</font></i>  <i><font color="gray">Il existe d'excellents outils vectoriels qui seront tr√®s utiles tr√®s bient√¥t.</font></i> <br><br>  Je ne montre pas quels traits de personnalit√© nous mettons sur le graphique afin que vous ne vous attachiez pas √† des traits sp√©cifiques, mais comprenez imm√©diatement la repr√©sentation vectorielle de la personnalit√© d'une personne dans son ensemble. <br><br>  Maintenant, nous pouvons dire que ce vecteur refl√®te partiellement ma personnalit√©.  Ceci est une description utile lors de la comparaison de diff√©rentes personnes.  Supposons que j'ai √©t√© frapp√© par un bus rouge et que vous deviez me remplacer par une personne similaire.  Laquelle des deux personnes du tableau suivant me ressemble le plus? <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/de5/380/b84/de5380b84dc9fec4bb8b52ebe6519e15.png"></div><br><br>  Lorsque vous travaillez avec des vecteurs, la similitude est g√©n√©ralement calcul√©e par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le coefficient Otiai</a> (coefficient g√©om√©trique): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/640/e59/7dd/640e597dd741a28bcec986454633e31d.png"></div><br>  <i><font color="green">La personne n ¬∞ 1</font> <font color="gray">me ressemble davantage.</font></i>  <i><font color="gray">Les vecteurs dans une direction (la longueur est √©galement importante) donnent un coefficient Otiai plus grand</font></i> <br><br>  Encore une fois, deux dimensions ne suffisent pas pour √©valuer les gens.  Des d√©cennies de d√©veloppement de la science psychologique ont conduit √† la cr√©ation d'un test pour cinq caract√©ristiques de base de la personnalit√© (avec de nombreuses autres).  Alors, utilisons les cinq dimensions: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/df5/3ae/d7b/df53aed7b1e439561a01e69b3f765487.png"></div><br><br>  Le probl√®me avec les cinq dimensions est qu'il ne sera plus possible de dessiner des fl√®ches soign√©es en 2D.  Il s'agit d'un probl√®me courant dans l'apprentissage automatique, o√π vous devez souvent travailler dans un espace multidimensionnel.  Il est bon que le coefficient g√©om√©trique fonctionne avec n'importe quel nombre de mesures: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/521/ab3/bf1/521ab3bf1374c5b37115441b7c2d27cc.png"></div><br>  <i><font color="gray">Le coefficient g√©om√©trique fonctionne pour n'importe quel nombre de mesures.</font></i>  <i><font color="gray">En cinq dimensions, le r√©sultat est beaucoup plus pr√©cis.</font></i> <br><br>  √Ä la fin de ce chapitre, je veux r√©p√©ter deux id√©es principales: <br><br><ol><li>  Les gens (et d'autres objets) peuvent √™tre repr√©sent√©s comme des vecteurs num√©riques (ce qui est id√©al pour les voitures!). <br></li><li>  Nous pouvons facilement calculer la similitude des vecteurs. </li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/195/73d/16d/19573d16de1150ac1874640c79e0b381.png"></div><br><br><h1>  Incorporation de mots </h1><br><blockquote>  <font color="gray">"Le don des mots est le don de la tromperie et de l'illusion."</font>  <font color="gray">- <i>Enfants de la Dune</i></font> </blockquote><br>  Avec cette compr√©hension, nous allons passer aux repr√©sentations vectorielles des mots obtenus √† la suite de la formation (ils sont aussi appel√©s attachements) et examiner leurs propri√©t√©s int√©ressantes. <br><br>  Voici la pi√®ce jointe pour le mot ¬´roi¬ª (vecteur GloVe, form√© sur Wikip√©dia): <br><br> <code>[ 0.50451 , 0.68607 , -0.59517 , -0.022801, 0.60046 , -0.13498 , -0.08813 , 0.47377 , -0.61798 , -0.31012 , -0.076666, 1.493 , -0.034189, -0.98173 , 0.68229 , 0.81722 , -0.51874 , -0.31503 , -0.55809 , 0.66421 , 0.1961 , -0.13495 , -0.11476 , -0.30344 , 0.41177 , -2.223 , -1.0756 , -1.0783 , -0.34354 , 0.33505 , 1.9927 , -0.04234 , -0.64319 , 0.71125 , 0.49159 , 0.16754 , 0.34344 , -0.25663 , -0.8523 , 0.1661 , 0.40102 , 1.1685 , -1.0137 , -0.21585 , -0.15155 , 0.78321 , -0.91241 , -1.6106 , -0.64426 , -0.51042 ]</code> <br> <br>  Nous voyons une liste de 50 num√©ros, mais il est difficile de dire quelque chose.  Visualisons-les pour comparer avec d'autres vecteurs.  Mettez les chiffres sur une ligne: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/516/c90/5ac/516c905ac831fe8688db73f0a63d325b.png"></div><br><br>  Coloriez les cellules par leurs valeurs (rouge pour pr√®s de 2, blanc pour pr√®s de 0, bleu pour pr√®s de -2): <br><br><div style="text-align:center;"> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/46f/7cb/1d5/46f7cb1d5adc32bd16368b2681ab26a4.png"></a> </div><br><br>  Maintenant, oubliez les chiffres, et seulement par les couleurs, nous contrastons le ¬´roi¬ª avec d'autres mots: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1c8/6b2/909/1c86b290963e8a42b375cb6a71245185.png"></div><br><br>  Vous voyez que ¬´l'homme¬ª et la ¬´femme¬ª sont beaucoup plus proches l'un de l'autre que du ¬´roi¬ª?  √áa dit quelque chose.  Les repr√©sentations vectorielles capturent beaucoup d'informations / sens / associations de ces mots. <br><br>  Voici une autre liste d'exemples (comparer des colonnes avec des couleurs similaires): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d61/30b/d45/d6130bd4502710631a8c812923230f47.png"></div><br><br>  Il y a plusieurs choses √† noter: <br><br><ol><li>  √Ä travers tous les mots passe une colonne rouge.  Autrement dit, ces mots sont similaires dans cette dimension particuli√®re (et nous ne savons pas ce qui y est cod√©). <br></li><li>  Vous pouvez voir que ¬´femme¬ª et ¬´fille¬ª sont tr√®s similaires.  La m√™me chose avec ¬´homme¬ª et ¬´gar√ßon¬ª. <br></li><li>  ¬´Gar√ßon¬ª et ¬´fille¬ª sont √©galement similaires dans certaines dimensions, mais diff√®rent de ¬´femme¬ª et ¬´homme¬ª.  Serait-ce une vague id√©e cod√©e de la jeunesse?  Probablement. <br></li><li>  Tout sauf le dernier mot, ce sont les id√©es des gens.  J'ai ajout√© un objet (eau) pour montrer les diff√©rences entre les cat√©gories.  Par exemple, vous pouvez voir comment la colonne bleue descend et s'arr√™te devant le vecteur d'eau. <br></li><li>  Il y a des dimensions claires o√π le ¬´roi¬ª et la ¬´reine¬ª sont similaires et diff√©rents les uns des autres.  Peut-√™tre qu'un vague concept de redevance y est cod√©? </li></ol><br><h1>  Analogies </h1><br><blockquote>  <font color="gray">¬´Les mots supportent toutes les charges que nous souhaitons.</font>  <font color="gray">Tout ce qu'il faut, c'est un accord sur la tradition, selon lequel nous construisons des concepts. ¬ª</font>  <font color="gray">- <i>Dieu l'empereur de Dune</i></font> </blockquote><br>  Des exemples c√©l√®bres qui montrent les propri√©t√©s incroyables des investissements sont le concept d'analogies.  Nous pouvons ajouter et soustraire des vecteurs de mots, obtenant des r√©sultats int√©ressants.  L'exemple le plus c√©l√®bre est la formule ¬´roi - homme + femme¬ª: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c23/71f/ead/c2371feadc58f2f2a1236c94b6b05eff.png"></div><br>  <i><font color="gray">En utilisant la biblioth√®que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Gensim</a> en python, nous pouvons ajouter et soustraire des vecteurs de mots, et la biblioth√®que trouvera les mots les plus proches du vecteur r√©sultant.</font></i>  <i><font color="gray">L'image montre une liste des mots les plus similaires, chacun avec un coefficient de similitude g√©om√©trique</font></i> <br><br>  Nous visualisons cette analogie comme pr√©c√©demment: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a19/84b/fea/a1984bfeab5a597c6fb6300f7d694901.png"></div><br>  <i><font color="gray">Le vecteur r√©sultant du calcul ¬´roi - homme + femme¬ª n'est pas tout √† fait √©gal √† la ¬´reine¬ª, mais c'est le r√©sultat le plus proche de 400 000 pi√®ces jointes de mots dans l'ensemble de donn√©es</font></i> <br><br>  Apr√®s avoir consid√©r√© l'attachement des mots, apprenons comment se d√©roule l'apprentissage.  Mais avant de passer √† word2vec, vous devez jeter un ≈ìil √† l'anc√™tre conceptuel de l'int√©gration de mots: un mod√®le de langage neuronal. <br><br><h1>  Mod√®le de langage </h1><br><blockquote>  <font color="gray">¬´Le proph√®te n'est pas soumis aux illusions du pass√©, du pr√©sent ou du futur.</font>  <font color="gray"><b>La fixit√© des formes linguistiques d√©termine de telles diff√©rences lin√©aires.</b></font>  <font color="gray">Les proph√®tes tiennent la cl√© du verrou de la langue.</font>  <font color="gray">Pour eux, l'image physique ne reste qu'une image physique et rien de plus.</font> <font color="gray"><br><br></font>  <font color="gray">Leur univers n'a pas les propri√©t√©s d'un univers m√©canique.</font>  <font color="gray">L'observateur assume une s√©quence lin√©aire d'√©v√©nements.</font>  <font color="gray">Cause et effet?</font>  <font color="gray">C'est une question compl√®tement diff√©rente.</font>  <font color="gray">Le Proph√®te prononce des paroles fatidiques.</font>  <font color="gray">Vous voyez un aper√ßu d'un √©v√©nement qui devrait se produire ¬´selon la logique des choses¬ª.</font>  <font color="gray">Mais le proph√®te lib√®re instantan√©ment l'√©nergie d'un pouvoir miraculeux infini.</font>  <font color="gray">L'univers subit un changement spirituel. ¬ª</font>  <font color="gray">- <i>Dieu l'empereur de Dune</i></font> </blockquote><br>  Un exemple de NLP (Natural Language Processing) est la fonction de pr√©diction du mot suivant sur le clavier d'un smartphone.  Des milliards de personnes l'utilisent des centaines de fois par jour. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ca4/d48/a13/ca4d48a133d58fe3c4c11e0933ea218e.png"></div><br><br>  La pr√©diction du mot suivant est une t√¢che appropri√©e pour <i>un mod√®le de langage</i> .  Elle peut prendre une liste de mots (disons deux mots) et essayer de pr√©dire ce qui suit. <br><br>  Dans la capture d'√©cran ci-dessus, le mod√®le a pris ces deux mots verts ( <code>thou shalt</code> ) et a renvoy√© une liste d'options (tr√®s probablement pour le mot <code>not</code> ): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5a7/0fc/492/5a70fc49208b501202ed188f24ad1f2c.png"></div><br><br>  On peut imaginer le mod√®le comme une bo√Æte noire: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/164/72f/a83/16472fa83e5eadf58f4bb05b50075654.png"></div><br><br>  Mais en pratique, le mod√®le produit plus d'un mot.  Il d√©rive une estimation de la probabilit√© de pratiquement tous les mots connus (le "dictionnaire" du mod√®le varie de plusieurs milliers √† plus d'un million de mots).  L'application clavier trouve ensuite les mots ayant les scores les plus √©lev√©s et les montre √† l'utilisateur. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/7a7/eda/ad6/7a7edaad67dd51240d90426de0b198c2.png"></div><br>  <i><font color="gray">Un mod√®le de langage neuronal donne la probabilit√© de tous les mots connus.</font></i>  <i><font color="gray">Nous indiquons la probabilit√© en pourcentage, mais dans le vecteur r√©sultant, 40% seront repr√©sent√©s comme 0,4</font></i> <br><br>  Apr√®s l'entra√Ænement, les premiers mod√®les neuronaux ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bengio 2003</a> ) ont calcul√© le pronostic en trois √©tapes: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/27b/082/4f8/27b0824f81962e2863d6d4dcccabfdd2.png"></div><br><br>  La premi√®re √©tape pour nous est la plus pertinente, alors que nous discutons des investissements.  √Ä la suite de la formation, une matrice est cr√©√©e avec les pi√®ces jointes de tous les mots de notre dictionnaire.  Pour obtenir le r√©sultat, nous recherchons simplement les plongements des mots d'entr√©e et ex√©cutons la pr√©diction: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1d1/34b/5ac/1d134b5ac32406ea363944887ce5fc53.png"></div><br><br>  Examinons maintenant le processus d'apprentissage et d√©couvrons comment cette matrice d'investissements est cr√©√©e. <br><br><h1>  Formation sur le mod√®le linguistique </h1><br><blockquote>  <font color="gray">¬´Le processus ne peut pas √™tre compris en y mettant fin.</font>  <font color="gray">La compr√©hension doit avancer avec le processus, fusionner avec son flux et couler avec lui ¬ª- <i>Dune</i></font> </blockquote><br>  Les mod√®les de langage ont un √©norme avantage sur la plupart des autres mod√®les d'apprentissage automatique: ils peuvent √™tre form√©s sur des textes que nous avons en abondance.  Pensez √† tous les livres, articles, documents Wikip√©dia et autres formes de donn√©es textuelles dont nous disposons.  Comparez avec d'autres mod√®les d'apprentissage automatique qui n√©cessitent un travail manuel et des donn√©es sp√©cialement collect√©es. <br><br><blockquote>  <b>¬´Vous devez apprendre le mot par son entreprise¬ª - J. R. Furs</b> </blockquote><br>  Les pi√®ces jointes des mots sont calcul√©es en fonction des mots environnants, qui apparaissent le plus souvent √† proximit√©.  La m√©canique est la suivante: <br><br><ol><li>  Nous obtenons beaucoup de donn√©es textuelles (disons, tous les articles Wikipedia) <br></li><li>  D√©finissez une fen√™tre (par exemple, de trois mots) qui glisse dans le texte. <br></li><li>  Une fen√™tre coulissante g√©n√®re des mod√®les pour l'apprentissage de notre mod√®le. </li></ol><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a31/fc4/626/a31fc4626de165a21c2c91844b21e7ab.png"></div><br><br>  Lorsque cette fen√™tre glisse sur le texte, nous g√©n√©rons (en fait) un ensemble de donn√©es, que nous utilisons ensuite pour former le mod√®le.  Pour comprendre, voyons comment une fen√™tre coulissante g√®re cette phrase: <br><br><blockquote>  <b>¬´Puissiez-vous ne pas construire une machine dot√©e de la ressemblance de l'esprit humain¬ª - <i>Dune</i></b> </blockquote><br>  Lorsque nous commen√ßons, la fen√™tre se trouve sur les trois premiers mots de la phrase: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/81c/c51/a04/81cc51a0478e1655c8f3f85641cf1e4e.png"></div><br><br>  Nous prenons les deux premiers mots pour les signes, et le troisi√®me mot pour l'√©tiquette: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/097/981/086/0979810868ca398fdcad3066294055f5.png"></div><br>  <i><font color="gray">Nous avons g√©n√©r√© le premier √©chantillon dans un ensemble de donn√©es qui peut ensuite √™tre utilis√© pour enseigner un mod√®le de langage</font></i> <br><br>  Ensuite, nous d√©pla√ßons la fen√™tre √† la position suivante et cr√©ons un deuxi√®me √©chantillon: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/98c/0b3/f98/98c0b3f98ebf4790890fd2f66cf86ce9.png"></div><br><br>  Et tr√®s bient√¥t, nous accumulons un plus grand ensemble de donn√©es: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4e7/3ce/50d/4e73ce50d863e1cbfde92a3b595dbaa3.png"></div><br><br>  En pratique, les mod√®les sont g√©n√©ralement form√©s directement au processus de d√©placement d'une fen√™tre coulissante.  Mais logiquement, la phase de ¬´g√©n√©ration des ensembles de donn√©es¬ª est distincte de la phase de formation.  En plus des approches de r√©seau de neurones, la m√©thode N-gram √©tait souvent utilis√©e plus t√¥t pour enseigner les mod√®les de langage (voir le troisi√®me chapitre du livre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´Speech and Language Processing¬ª</a> ).  Pour voir la diff√©rence lors du passage de N-grammes √† des mod√®les neuronaux dans des produits r√©els, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">voici un article de 2015 sur le blog Swiftkey</a> , le d√©veloppeur de mon clavier Android pr√©f√©r√©, qui pr√©sente son mod√®le de langage neuronal et le compare avec le mod√®le N-gram pr√©c√©dent.  J'aime cet exemple car il montre comment les propri√©t√©s algorithmiques des investissements peuvent √™tre d√©crites dans un langage marketing. <br><br><h1>  Nous regardons dans les deux sens </h1><br><blockquote>  <font color="gray">¬´Un paradoxe est un signe que nous devons essayer de r√©fl√©chir √† ce qui se cache derri√®re.</font>  <font color="gray">Si le paradoxe vous inqui√®te, cela signifie que vous vous efforcez de l'absolu.</font>  <font color="gray">Les relativistes consid√®rent le paradoxe simplement comme une pens√©e int√©ressante, peut-√™tre dr√¥le, parfois effrayante, mais une pens√©e tr√®s instructive. ¬ª</font>  <font color="gray"><i>Dieu empereur de Dune</i></font> </blockquote><br>  Sur la base de ce qui pr√©c√®de, comblez le vide: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/680/613/871/680613871307e53415ab86fab022276a.png"></div><br><br>  Comme contexte, il y a cinq mots pr√©c√©dents (et une r√©f√©rence ant√©rieure √† ¬´bus¬ª).  Je suis s√ªr que la plupart d'entre vous ont devin√© qu'il devrait y avoir un "bus".  Mais si je vous donne un autre mot apr√®s l'espace, cela changera-t-il votre r√©ponse? <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/45f/1fa/af0/45f1faaf0cdd4f57ac1699d87861934a.png"></div><br><br>  Cela change compl√®tement la situation: maintenant le mot manquant est tr√®s probablement ¬´rouge¬ª.  De toute √©vidence, les mots ont une valeur informative √† la fois avant et apr√®s un espace.  Il s'av√®re que la comptabilit√© dans les deux sens (gauche et droite) permet de calculer de meilleurs investissements.  Voyons comment configurer la formation du mod√®le dans une telle situation. <br><br><h1>  Sauter le gramme </h1><br><blockquote>  <font color="gray">"Quand un choix absolument indubitable est inconnu, l'intellect a la chance de travailler avec des donn√©es limit√©es dans l'ar√®ne, o√π les erreurs sont non seulement possibles mais aussi n√©cessaires."</font>  <font color="gray">- <i>Capitul Dunes</i></font> </blockquote><br>  En plus de deux mots avant la cible, vous pouvez prendre en compte deux autres mots apr√®s celle-ci. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e2b/1f6/1a1/e2b1f61a179e7d6835b47c7149a47486.png"></div><br><br>  Ensuite, l'ensemble de donn√©es pour la formation du mod√®le ressemblera √† ceci: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6ff/729/ed4/6ff729ed4ce86722dc9c3aa689614195.png"></div><br><br>  Il s'agit de l'architecture CBOW (Continuous Bag of Words) et est d√©crite dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un des documents word2vec</a> [pdf].  Il existe une autre architecture, qui montre √©galement d'excellents r√©sultats, mais est arrang√©e un peu diff√©remment: elle essaie de deviner les mots voisins par le mot courant.  Une fen√™tre coulissante ressemble √† ceci: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/dc9/72d/baa/dc972dbaa78b592ba91b76e950ec56e0.png"></div><br>  <i><font color="gray">Dans la fente verte est le mot d'entr√©e, et chaque champ rose repr√©sente une sortie possible</font></i> <br><br>  Les rectangles roses ont des nuances diff√©rentes car cette fen√™tre coulissante cr√©e en fait quatre mod√®les distincts dans notre jeu de donn√©es d'entra√Ænement: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/709/8ac/dde/7098acddea8266d1efd5663ed98e6303.png"></div><br><br>  Cette m√©thode est appel√©e architecture <b>skip-gram</b> .  Vous pouvez visualiser une fen√™tre coulissante comme suit: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ee2/1d8/508/ee21d850835bde9e3f14250d267d88b1.png"></div><br><br>  Les quatre exemples suivants sont ajout√©s √† l'ensemble de donn√©es de formation: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a40/871/f1c/a40871f1c1c7b48723d3737c05fc6284.png"></div><br><br>  Ensuite, nous d√©pla√ßons la fen√™tre √† la position suivante: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/14a/429/c7b/14a429c7b2ae6ba7383d6d39be9e3031.png"></div><br><br>  Ce qui g√©n√®re quatre autres exemples: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e9b/b3c/89a/e9bb3c89a00306b3fd18eb86d8f2160b.png"></div><br><br>  Bient√¥t, nous aurons beaucoup plus d'√©chantillons: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6bb/749/096/6bb749096d3329712a7c00727b4d3cff.png"></div><br><br><h1>  Revue d'apprentissage </h1><br><blockquote>  <font color="gray">¬´Muad'Dib √©tait un apprenant rapide parce qu'il apprenait principalement √† apprendre.</font>  <font color="gray">Mais la toute premi√®re le√ßon a √©t√© l'assimilation de la croyance qu'il peut apprendre, et c'est la base de tout.</font>  <font color="gray">C'est incroyable combien de personnes ne croient pas qu'elles peuvent apprendre et apprendre, et combien de personnes pensent que l'apprentissage est tr√®s difficile. "</font>  <font color="gray">- <i>Dune</i></font> </blockquote><br>  Maintenant que nous avons l'ensemble skip-gram, nous l'utilisons pour former le mod√®le neuronal de base du langage qui pr√©dit un mot voisin. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/944/fb7/70d/944fb770d3aff38f1befa40dfaa7402a.png"></div><br><br>  Commen√ßons par le premier √©chantillon de notre ensemble de donn√©es.  Nous prenons le signe et l'envoyons au mod√®le non form√© avec la demande de pr√©dire le mot suivant. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/abb/5cb/9a3/abb5cb9a38d29f1a54176206637131dc.png"></div><br><br>  Le mod√®le passe par trois √©tapes et affiche un vecteur de pr√©diction (avec probabilit√© pour chaque mot du dictionnaire).  Le mod√®le n'√©tant pas entra√Æn√©, √† ce stade, ses pr√©visions sont probablement incorrectes.  Mais ce n‚Äôest rien.  Nous savons quel mot elle pr√©dit - c'est la cellule r√©sultante dans la ligne que nous utilisons actuellement pour former le mod√®le: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8af/4fd/c3d/8af4fdc3d3cc86ec1c81fdb3d2715529.png"></div><br>  <i><font color="gray">Un ¬´vecteur cible¬ª est un vecteur dans lequel le mot cible a une probabilit√© de 1, et tous les autres mots ont une probabilit√© de 0</font></i> <br><br>  √Ä quel point le mod√®le √©tait-il mauvais?  Soustrayez le vecteur de pr√©vision de la cible et obtenez le vecteur d'erreur: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e6d/b3e/395/e6db3e39593e9c8639d94ef4caccde58.png"></div><br><br>  Ce vecteur d'erreur peut maintenant √™tre utilis√© pour mettre √† jour le mod√®le, donc la prochaine fois, il est plus susceptible de donner un r√©sultat pr√©cis sur les m√™mes donn√©es d'entr√©e. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/7d3/6c0/476/7d36c047604b937c907a4ef38ceaaeb7.png"></div><br><br>  Ici se termine la premi√®re √©tape de la formation.  Nous continuons √† faire de m√™me avec l'√©chantillon suivant dans l'ensemble de donn√©es, puis avec le suivant, jusqu'√† ce que nous examinions tous les √©chantillons.  C'est la fin de la premi√®re √®re d'apprentissage.  Nous r√©p√©tons tout et maintes et maintes fois pendant plusieurs √©poques, et en cons√©quence, nous obtenons un mod√®le form√©: vous pouvez en extraire la matrice d'investissement et l'utiliser dans toutes les applications. <br><br>  Bien que nous ayons beaucoup appris, mais pour bien comprendre comment word2vec apprend vraiment, quelques id√©es cl√©s manquent. <br><br><h1>  S√©lection n√©gative </h1><br><blockquote>  <font color="gray">¬´Essayer de comprendre Muad'Dib sans comprendre ses ennemis mortels - les Harkonnenov - revient √† essayer de comprendre la V√©rit√© sans comprendre ce qu'est le mensonge.</font>  <font color="gray">C'est une tentative de conna√Ætre la Lumi√®re sans conna√Ætre l'Obscurit√©.</font>  <font color="gray">C'est impossible. "</font>  <font color="gray">- <i>Dune</i></font> </blockquote><br>  Rappelez-vous les trois √©tapes comment un mod√®le neuronal calcule une pr√©vision: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8dd/fe1/4ca/8ddfe14ca387bd4d16c77eb9de8ce98f.png"></div><br><br>  La troisi√®me √©tape est tr√®s co√ªteuse d'un point de vue informatique, surtout si vous le faites pour chaque √©chantillon de l'ensemble de donn√©es (des dizaines de millions de fois).  Il est n√©cessaire d'augmenter en quelque sorte la productivit√©. <br><br>  Une fa√ßon consiste √† diviser l'objectif en deux √©tapes: <br><br><ol><li>  Cr√©ez des pi√®ces jointes de mots de haute qualit√© (sans pr√©dire le mot suivant). <br></li><li>  Utilisez ces investissements de haute qualit√© pour enseigner le mod√®le linguistique (pour les pr√©visions). </li></ol><br>  Cet article se concentrera sur la premi√®re √©tape.  Pour augmenter la productivit√©, vous pouvez vous √©loigner de la pr√©diction d'un mot voisin ... <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/77d/0a8/c17/77d0a8c17587248a0f790155809798fe.png"></div><br><br>  ... et passez √† un mod√®le qui prend les mots d'entr√©e et de sortie et calcule la probabilit√© de leur proximit√© (de 0 √† 1). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/220/0e3/e06/2200e3e063f3119099d1615e59538d2a.png"></div><br><br>  Une transition aussi simple remplace le r√©seau neuronal par un mod√®le de r√©gression logistique - ainsi, les calculs deviennent beaucoup plus simples et plus rapides. <br><br>  En m√™me temps, nous devons affiner la structure de notre ensemble de donn√©es: l'√©tiquette est maintenant une nouvelle colonne avec des valeurs 0 ou 1. Dans notre tableau, les unit√©s sont partout, car nous y avons ajout√© des voisins. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/dc2/d1e/874/dc2d1e87438b2492dc9b6e4b1c72162e.png"></div><br><br>  Un tel mod√®le est calcul√© √† une vitesse incroyable: des millions d'√©chantillons en quelques minutes.  Mais vous devez combler une lacune.  Si tous nos exemples sont positifs (objectif: 1), alors un mod√®le d√©licat peut se former qui renvoie toujours 1, d√©montrant une pr√©cision de 100%, mais il n'apprend rien et g√©n√®re des investissements ind√©sirables. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1ba/aa2/2d0/1baaa22d0b0c06be5398f896fa7a4c4b.png"></div><br><br>  Pour r√©soudre ce probl√®me, vous devez entrer <i>des mod√®les n√©gatifs</i> dans l'ensemble de donn√©es - des mots qui ne sont certainement pas voisins.  Pour eux, le mod√®le doit retourner 0. Maintenant, le mod√®le devra travailler dur, mais les calculs vont toujours √† grande vitesse. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f4c/194/0d8/f4c1940d80c5203620196907a1478431.png"></div><br>  <i><font color="gray">Pour chaque √©chantillon du jeu de donn√©es, ajoutez des exemples n√©gatifs √©tiquet√©s 0</font></i> <br><br>  Mais que pr√©senter comme mots de sortie?  Choisissez les mots arbitrairement: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/84e/b22/06f/84eb2206f26b053f1ea8ec4e1b76c5b6.png"></div><br><br>  Cette id√©e est n√©e sous l'influence de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la</a> m√©thode de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">comparaison</a> du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bruit</a> [pdf].  Nous faisons correspondre le signal r√©el (exemples positifs de mots voisins) avec du bruit (mots s√©lectionn√©s au hasard qui ne sont pas voisins).  Cela fournit un excellent compromis entre performances et performances statistiques. <br><br><h1>  √âchantillon n√©gatif de saut de gramme (SGNS) </h1><br>  Nous avons examin√© deux concepts centraux de word2vec: ensemble, ils sont appel√©s ¬´skip-gram avec √©chantillonnage n√©gatif¬ª. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/873/720/fae/873720fae559ce7d6020be66ccb6c397.png"></div><br><br><h1>  Learning word2vec </h1><br><blockquote>  <font color="gray">¬´Une machine ne peut pas pr√©voir tous les probl√®mes importants pour une personne vivante.</font>  <font color="gray">Il y a une grande diff√©rence entre un espace discret et un continuum continu.</font>  <font color="gray">Nous vivons dans un espace et les machines existent dans un autre. ¬ª</font>  <font color="gray">- <i>Dieu l'empereur de Dune</i></font> </blockquote><br>  Apr√®s avoir examin√© les id√©es de base du saut de gramme et de l'√©chantillonnage n√©gatif, nous pouvons proc√©der √† un examen plus approfondi du processus d'apprentissage word2vec. <br><br>  Tout d'abord, nous pr√©-traitons le texte sur lequel nous formons le mod√®le.  D√©finissez la taille du dictionnaire (nous l'appellerons <code>vocab_size</code> ), disons, dans 10 000 pi√®ces jointes et les param√®tres des mots dans le dictionnaire. <br><br>  Au d√©but de la formation, nous cr√©ons deux matrices: <code>Embedding</code> et <code>Context</code> .  Les pi√®ces jointes de chaque mot sont stock√©es dans ces matrices dans notre dictionnaire (donc <code>vocab_size</code> est l'un de leurs param√®tres).  Le deuxi√®me param√®tre est la dimension de la pi√®ce jointe (g√©n√©ralement <code>embedding_size</code> d√©fini sur 300, mais nous avons examin√© pr√©c√©demment un exemple avec 50 dimensions). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1b7/8f8/018/1b78f8018d20fd36d0c5aef37d87a249.png"></div><br><br>  Tout d'abord, nous initialisons ces matrices avec des valeurs al√©atoires.  Ensuite, nous commen√ßons le processus d'apprentissage.  √Ä chaque √©tape, nous prenons un exemple positif et les n√©gatifs qui lui sont associ√©s.  Voici notre premier groupe: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2d2/261/806/2d22618069aa9e3f8a820cb431c6c014.png"></div><br><br>  Nous avons maintenant quatre mots: le mot d'entr√©e <code>not</code> et les mots de sortie / contextuels <code>thou</code> (voisin r√©el), <code>aaron</code> et <code>taco</code> (exemples n√©gatifs).  Nous commen√ßons la recherche de leurs pi√®ces jointes dans les matrices <code>Embedding</code> (pour le mot d'entr√©e) et <code>Context</code> (pour les mots de contexte), bien que les deux matrices contiennent des pi√®ces jointes pour tous les mots de notre dictionnaire. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/23e/ff0/691/23eff069128db956ce358ae758c0b8bb.png"></div><br><br>  Ensuite, nous calculons le produit scalaire de la pi√®ce jointe d'entr√©e avec chacune des pi√®ces jointes contextuelles.  Dans chaque cas, un nombre est obtenu qui indique la similitude des donn√©es d'entr√©e et des pi√®ces jointes contextuelles. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/615/319/e4a/615319e4accc7235c28fc8c76dca09f6.png"></div><br><br>  Il nous faut maintenant un moyen de transformer ces estimations en une sorte de vraisemblance: toutes doivent √™tre des nombres positifs entre 0 et 1. C'est une excellente t√¢che pour les √©quations logistiques <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sigmo√Ødes</a> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/98b/125/8b2/98b1258b21744917c993e617e0844ad8.png"></div><br><br>  Le r√©sultat du calcul sigmo√Øde peut √™tre consid√©r√© comme la sortie du mod√®le pour ces √©chantillons.  Comme vous pouvez le voir, <code>taco</code> le score le plus √©lev√©, tandis que <code>aaron</code> toujours le score le plus bas, avant et apr√®s sigmo√Øde. <br><br>  Lorsque le mod√®le non form√© a fait une pr√©vision et a un v√©ritable objectif cible pour la comparaison, calculons le nombre d'erreurs dans la pr√©vision du mod√®le.  Pour ce faire, il suffit de soustraire le score sigmo√Øde des √©tiquettes cibles. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d49/458/333/d49458333c28225c596014df3c6fcedb.png"></div><br>  <i><font color="gray"><code>error</code> = <code>target</code> - <code>sigmoid_scores</code></font></i> <br><br>  C'est l√† que commence la phase ¬´d'apprentissage¬ª du terme ¬´apprentissage automatique¬ª.  Nous pouvons maintenant utiliser cette estimation d'erreur pour ajuster les investissements <code>not</code> , <code>thou</code> , <code>aaron</code> et <code>taco</code> , afin que la prochaine fois, le r√©sultat soit plus proche des estimations cibles. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a5d/e51/cd3/a5de51cd3a86a1ed0784a709cb979bdc.png"></div><br><br>  Ceci termine une √©tape de la formation.  Nous avons un peu am√©lior√© l'attachement de quelques mots ( <code>not</code> , <code>thou</code> , <code>aaron</code> et <code>taco</code> ).  Nous passons maintenant √† l'√©tape suivante (le prochain √©chantillon positif et les √©chantillons n√©gatifs qui lui sont associ√©s) et r√©p√©tons le processus. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/637/2ab/c3a/6372abc3a3f6b623d5b2cbab02953030.png"></div><br><br>  Les pi√®ces jointes continuent de s'am√©liorer √† mesure que nous parcourons plusieurs fois l'ensemble des donn√©es.  Vous pouvez ensuite arr√™ter le processus, mettre de c√¥t√© la matrice de <code>Context</code> et utiliser la matrice d' <code>Embeddings</code> int√©gr√©e pour la t√¢che suivante. <br><br><h1>  Taille de la fen√™tre et nombre d'√©chantillons n√©gatifs </h1><br>  Dans le processus d'apprentissage de word2vec, deux hyperparam√®tres cl√©s sont la taille de la fen√™tre et le nombre d'√©chantillons n√©gatifs. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9fe/437/447/9fe4374479f547c1b324c7471cd61cbd.png"></div><br><br>  Diff√©rentes tailles de fen√™tres conviennent √† diff√©rentes t√¢ches.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Il a √©t√© remarqu√©</a> que des tailles de fen√™tre plus petites (2‚Äì15) g√©n√®rent <i>des</i> pi√®ces jointes <i>interchangeables</i> avec des index similaires (notez que les antonymes sont souvent interchangeables lorsque vous regardez les mots environnants: par exemple, les mots ¬´bon¬ª et ¬´mauvais¬ª sont souvent mentionn√©s dans des contextes similaires).  Des tailles de fen√™tre plus grandes (15‚Äì50 ou m√™me plus) g√©n√®rent <i>des</i> pi√®ces jointes <i>associ√©es</i> avec des indices similaires.  En pratique, vous devez souvent fournir des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">annotations</a> pour les similitudes s√©mantiques utiles dans votre t√¢che.  Dans Gensim, la taille de fen√™tre par d√©faut est 5 (deux mots gauche et droit, en plus du mot d'entr√©e lui-m√™me). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4f4/b0a/45a/4f4b0a45a8552d6c19c7c9459302ac48.png"></div><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le nombre d'√©chantillons n√©gatifs est un autre facteur dans le processus d'apprentissage. </font><font style="vertical-align: inherit;">Le document original recommande 5-20. </font><font style="vertical-align: inherit;">Il indique √©galement que 2 √† 5 √©chantillons semblent suffisants lorsque vous disposez d'un ensemble de donn√©es suffisamment volumineux. </font><font style="vertical-align: inherit;">Dans Gensim, la valeur par d√©faut est 5 motifs n√©gatifs.</font></font><br><br><h1>  Conclusion </h1><br><blockquote> <font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Si votre comportement d√©passe vos normes, alors vous √™tes une personne vivante, pas un automate" - </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">God-Emperor of Dune</font></font></i></font> </blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">J'esp√®re que vous comprenez maintenant l'int√©gration des mots et l'essence de l'algorithme word2vec. </font><font style="vertical-align: inherit;">J'esp√®re √©galement que maintenant vous comprendrez mieux les articles qui mentionnent le concept de "saut de gramme avec √©chantillonnage n√©gatif" (SGNS), comme dans les syst√®mes de recommandation susmentionn√©s.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> R√©f√©rences et lectures compl√©mentaires </font></font></h1><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬´Repr√©sentations distribu√©es des mots et des phrases et leur composition¬ª</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> [pdf]</font></font></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´      ¬ª</a> [pdf] </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´   ¬ª</a> [pdf] </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´   ¬ª</a>      ‚Äî    NLP. Word2vec    . </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´      ¬ª</a> by <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a> ‚Äî      . </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a>        Word2vec.        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´ word2vec¬ª</a> </li><li>   ?   : <ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> word2vec  Python</a>  Gensim </li><li>  <a href="">   C</a> ,    <a href="">       </a> </li></ul></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">    </a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´  ¬ª</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> 2</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´¬ª</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr446530/">https://habr.com/ru/post/fr446530/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr446514/index.html">Gmail a 15 ans</a></li>
<li><a href="../fr446516/index.html">Visualisation du temps de renaissance de Roshan</a></li>
<li><a href="../fr446518/index.html">Pare-feu d'applications Web</a></li>
<li><a href="../fr446520/index.html">Comment tout a commenc√©: l'histoire des drones volants</a></li>
<li><a href="../fr446522/index.html">Swift 5.1 - quoi de neuf?</a></li>
<li><a href="../fr446532/index.html">Upwork introduit des frais pour le droit d'√©crire √† un client potentiel</a></li>
<li><a href="../fr446534/index.html">Sortie de Visual Studio 2019</a></li>
<li><a href="../fr446536/index.html">Files d'attente et JMeter: √©change avec Publisher et abonn√©</a></li>
<li><a href="../fr446538/index.html">PhotoGuru est pass√© du ¬´c√¥t√© obscur¬ª au ¬´plus sage¬ª</a></li>
<li><a href="../fr446544/index.html">Microsoft √©tend le programme Azure IP Advantage avec de nouveaux avantages IP pour les innovateurs et les startups Azure IoT</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏌️ 💹 👩‍🎤 Fazemos uma classificação das cidades russas pela qualidade da estrada 🤳🏻 👨🏼‍💻 👩🏿‍🌾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mais uma vez, dirigindo um carro pela minha cidade natal e percorrendo outro poço, pensei: existiam estradas “boas” em todo o país e decidi que deverí...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Fazemos uma classificação das cidades russas pela qualidade da estrada</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/437542/"><img src="https://habrastorage.org/webt/qg/pm/pf/qgpmpfivqp5xqw2c8-qvxjp4-dq.jpeg"><br><br>  Mais uma vez, dirigindo um carro pela minha cidade natal e percorrendo outro poço, pensei: existiam estradas “boas” em todo o país e decidi que deveríamos avaliar objetivamente a situação com a qualidade das estradas em nosso país. <br><a name="habracut"></a><br><h2>  Formalização de tarefas </h2><br>  Na Rússia, os requisitos para a qualidade das estradas estão descritos no GOST R 50597-2017 “Estradas e estradas.  Requisitos para o estado operacional aceitáveis ​​sob as condições de garantir a segurança rodoviária.  Métodos de controle ".  Este documento define os requisitos para cobrir a faixa de rodagem, estradas, faixas divisórias, calçadas, passarelas para pedestres, etc., além de estabelecer os tipos de danos. <br><br>  Como a tarefa de determinar todos os parâmetros das estradas é bastante extensa, decidi reduzi-lo para mim e me concentrar apenas no problema de determinar defeitos na cobertura da estrada.  No GOST R 50597-2017, os seguintes defeitos no revestimento da pista são distinguidos: <br><br><ul><li>  buracos </li><li>  intervalos </li><li>  rebaixamentos </li><li>  turnos </li><li>  pentes </li><li>  rastrear </li><li>  pasta de transpiração </li></ul><br>  Eu decidi resolver esses defeitos. <br><br><h2>  Coleta de dados </h2><br>  Onde posso obter fotografias que retratam seções suficientemente grandes da estrada e mesmo com referência à geolocalização?  A resposta veio em strass - panoramas nos mapas do Yandex (ou Google); no entanto, depois de um pouco de pesquisa, encontrei várias outras opções alternativas: <br><br><ul><li>  emissão de mecanismos de pesquisa de imagens para solicitações relevantes; </li><li>  fotos em sites para recebimento de reclamações (Rosyama, cidadão irritado, virtude etc.) </li><li>  O Opendatascience solicitou um projeto para detectar defeitos na estrada com um conjunto de dados marcado - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github.com/sekilab/RoadDamageDetector</a> </li></ul><br>  Infelizmente, uma análise dessas opções mostrou que elas não são muito adequadas para mim: emitir mecanismos de pesquisa com muito ruído (muitas fotos que não são estradas, várias renderizações etc.), fotos de sites para receber reclamações contêm apenas fotos com grandes violações da superfície do asfalto , há muito poucas fotos com leves violações de cobertura e sem violações nesses sites. O conjunto de dados do projeto RoadDamageDetector é coletado no Japão e não contém amostras com grandes violações de cobertura, bem como estradas sem cobertura. <br><br>  Como as opções alternativas não são adequadas, usaremos os panoramas Yandex (excluí a opção do panorama do Google, pois o serviço é apresentado em menos cidades da Rússia e é atualizado com menos frequência).  Ele decidiu coletar dados em cidades com uma população de mais de 100 mil pessoas, bem como em centros federais.  Fiz uma lista de nomes de cidades - havia 176 delas, mais tarde acontece que apenas 149 delas têm panoramas.  Não vou me aprofundar nos recursos dos blocos de análise, direi que no final consegui 149 pastas (uma para cada cidade) nas quais havia um total de 1,7 milhões de fotos.  Por exemplo, para Novokuznetsk, a pasta era assim: <br><br><img src="https://habrastorage.org/webt/aw/fa/73/awfa73gw128fyrvl8au2b_brjb8.png"><br><br>  Pelo número de fotos baixadas, as cidades foram distribuídas da seguinte forma: <br><br><div class="spoiler">  <b class="spoiler_title">Quadro</b> <div class="spoiler_text"><table><tbody><tr><th>  Cidade <br></th><th>  Número de fotos, peças <br></th></tr><tr><td>  Moscovo <br><br></td><td>  86048 <br><br></td></tr><tr><td>  São Petersburgo <br><br></td><td>  41376 <br><br></td></tr><tr><td>  Saransk <br><br></td><td>  18880 <br><br></td></tr><tr><td>  Podolsk <br><br></td><td>  18560 <br><br></td></tr><tr><td>  Krasnogorsk <br><br></td><td>  18208 <br><br></td></tr><tr><td>  Lyubertsy <br><br></td><td>  17760 <br><br></td></tr><tr><td>  Kaliningrado <br><br></td><td>  16928 <br><br></td></tr><tr><td>  Kolomna <br><br></td><td>  16832 <br><br></td></tr><tr><td>  Mytishchi <br><br></td><td>  16192 <br><br></td></tr><tr><td>  Vladivostok <br><br></td><td>  16096 <br><br></td></tr><tr><td>  Balashikha <br><br></td><td>  15968 <br><br></td></tr><tr><td>  Petrozavodsk <br><br></td><td>  15968 <br><br></td></tr><tr><td>  Ekaterinburg <br><br></td><td>  15808 <br><br></td></tr><tr><td>  Veliky Novgorod <br><br></td><td>  15744 <br><br></td></tr><tr><td>  Naberezhnye Chelny <br><br></td><td>  15680 <br><br></td></tr><tr><td>  Krasnodar <br><br></td><td>  15520 <br><br></td></tr><tr><td>  Nizhny Novgorod <br><br></td><td>  15488 <br><br></td></tr><tr><td>  Khimki <br><br></td><td>  15296 <br><br></td></tr><tr><td>  Tula <br><br></td><td>  15296 <br><br></td></tr><tr><td>  Novosibirsk <br><br></td><td>  15264 <br><br></td></tr><tr><td>  Tver <br><br></td><td>  15200 <br><br></td></tr><tr><td>  Miass <br><br></td><td>  15104 <br><br></td></tr><tr><td>  Ivanovo <br><br></td><td>  15072 <br><br></td></tr><tr><td>  Vologda <br><br></td><td>  15008 <br><br></td></tr><tr><td>  Zhukovsky <br><br></td><td>  14976 <br><br></td></tr><tr><td>  Kostroma <br><br></td><td>  14912 <br><br></td></tr><tr><td>  Samara <br><br></td><td>  14880 <br><br></td></tr><tr><td>  Korolev <br><br></td><td>  14784 <br><br></td></tr><tr><td>  Kaluga <br><br></td><td>  14720 <br><br></td></tr><tr><td>  Cherepovets <br><br></td><td>  14720 <br><br></td></tr><tr><td>  Sebastopol <br><br></td><td>  14688 <br><br></td></tr><tr><td>  Pushkino <br><br></td><td>  14528 <br><br></td></tr><tr><td>  Yaroslavl <br><br></td><td>  14464 <br><br></td></tr><tr><td>  Ulyanovsk <br><br></td><td>  14400 <br><br></td></tr><tr><td>  Rostov do Don <br><br></td><td>  14368 <br><br></td></tr><tr><td>  Domodedovo <br><br></td><td>  14304 <br><br></td></tr><tr><td>  Kamensk-Uralsky <br><br></td><td>  14208 <br><br></td></tr><tr><td>  Pskov <br><br></td><td>  14144 <br><br></td></tr><tr><td>  Yoshkar-Ola <br><br></td><td>  14080 <br><br></td></tr><tr><td>  Kerch <br><br></td><td>  14080 <br><br></td></tr><tr><td>  Murmansk <br><br></td><td>  13920 <br><br></td></tr><tr><td>  Togliatti <br><br></td><td>  13920 <br><br></td></tr><tr><td>  Vladimir <br><br></td><td>  13792 <br><br></td></tr><tr><td>  Águia <br><br></td><td>  13792 <br><br></td></tr><tr><td>  Syktyvkar <br><br></td><td>  13728 <br><br></td></tr><tr><td>  Dolgoprudny <br><br></td><td>  13696 <br><br></td></tr><tr><td>  Khanty-Mansiysk <br><br></td><td>  13664 <br><br></td></tr><tr><td>  Kazan <br><br></td><td>  13600 <br><br></td></tr><tr><td>  Engels <br><br></td><td>  13440 <br><br></td></tr><tr><td>  Arkhangelsk <br><br></td><td>  13280 <br><br></td></tr><tr><td>  Bryansk <br><br></td><td>  13216 <br><br></td></tr><tr><td>  Omsk <br><br></td><td>  13120 <br><br></td></tr><tr><td>  Syzran <br><br></td><td>  13088 <br><br></td></tr><tr><td>  Krasnoyarsk <br><br></td><td>  13056 <br><br></td></tr><tr><td>  Shchelkovo <br><br></td><td>  12928 <br><br></td></tr><tr><td>  Penza <br><br></td><td>  12864 <br><br></td></tr><tr><td>  Chelyabinsk <br><br></td><td>  12768 <br><br></td></tr><tr><td>  Cheboksary <br><br></td><td>  12768 <br><br></td></tr><tr><td>  Nizhny Tagil <br><br></td><td>  12672 <br><br></td></tr><tr><td>  Stavropol <br><br></td><td>  12672 <br><br></td></tr><tr><td>  Ramenskoye <br><br></td><td>  12640 <br><br></td></tr><tr><td>  Irkutsk <br><br></td><td>  12608 <br><br></td></tr><tr><td>  Angarsk <br><br></td><td>  12608 <br><br></td></tr><tr><td>  Tyumen <br><br></td><td>  12512 <br><br></td></tr><tr><td>  Odintsovo <br><br></td><td>  12512 <br><br></td></tr><tr><td>  Ufa <br><br></td><td>  12512 <br><br></td></tr><tr><td>  Magadan <br><br></td><td>  12512 <br><br></td></tr><tr><td>  Perm <br><br></td><td>  12448 <br><br></td></tr><tr><td>  Kirov <br><br></td><td>  12256 <br><br></td></tr><tr><td>  Nizhnekamsk <br><br></td><td>  12224 <br><br></td></tr><tr><td>  Makhachkala <br><br></td><td>  12096 <br><br></td></tr><tr><td>  Nizhnevartovsk <br><br></td><td>  11936 <br><br></td></tr><tr><td>  Kursk <br><br></td><td>  11904 <br><br></td></tr><tr><td>  Sochi <br><br></td><td>  11872 <br><br></td></tr><tr><td>  Tambov <br><br></td><td>  11840 <br><br></td></tr><tr><td>  Pyatigorsk <br><br></td><td>  11808 <br><br></td></tr><tr><td>  Volgodonsk <br><br></td><td>  11712 <br><br></td></tr><tr><td>  Ryazan <br><br></td><td>  11680 <br><br></td></tr><tr><td>  Saratov <br><br></td><td>  11616 <br><br></td></tr><tr><td>  Dzerzhinsk <br><br></td><td>  11456 <br><br></td></tr><tr><td>  Orenburg <br><br></td><td>  11456 <br><br></td></tr><tr><td>  Monte <br><br></td><td>  11424 <br><br></td></tr><tr><td>  Volgogrado <br><br></td><td>  11264 <br><br></td></tr><tr><td>  Izhevsk <br><br></td><td>  11168 <br><br></td></tr><tr><td>  Crisóstomo <br><br></td><td>  11136 <br><br></td></tr><tr><td>  Lipetsk <br><br></td><td>  11072 <br><br></td></tr><tr><td>  Kislovodsk <br><br></td><td>  11072 <br><br></td></tr><tr><td>  Surgut <br><br></td><td>  11040 <br><br></td></tr><tr><td>  Magnitogorsk <br><br></td><td>  10912 <br><br></td></tr><tr><td>  Smolensk <br><br></td><td>  10784 <br><br></td></tr><tr><td>  Khabarovsk <br><br></td><td>  10752 <br><br></td></tr><tr><td>  Kopeysk <br><br></td><td>  10688 <br><br></td></tr><tr><td>  Maykop <br><br></td><td>  10656 <br><br></td></tr><tr><td>  Petropavlovsk-Kamchatsky <br><br></td><td>  10624 <br><br></td></tr><tr><td>  Taganrog <br><br></td><td>  10560 <br><br></td></tr><tr><td>  Barnaul <br><br></td><td>  10528 <br><br></td></tr><tr><td>  Sergiev Posad <br><br></td><td>  10368 <br><br></td></tr><tr><td>  Elista <br><br></td><td>  10304 <br><br></td></tr><tr><td>  Sterlitamak <br><br></td><td>  9920 <br><br></td></tr><tr><td>  Simferopol <br><br></td><td>  9824 <br><br></td></tr><tr><td>  Tomsk <br><br></td><td>  9760 <br><br></td></tr><tr><td>  Orekhovo-Zuevo <br><br></td><td>  9728 <br><br></td></tr><tr><td>  Astracã <br><br></td><td>  9664 <br><br></td></tr><tr><td>  Evpatoria <br><br></td><td>  9568 <br><br></td></tr><tr><td>  Noginsk <br><br></td><td>  9344 <br><br></td></tr><tr><td>  Chita <br><br></td><td>  9216 <br><br></td></tr><tr><td>  Belgorod <br><br></td><td>  9120 <br><br></td></tr><tr><td>  Biysk <br><br></td><td>  8928 <br><br></td></tr><tr><td>  Rybinsk <br><br></td><td>  8896 <br><br></td></tr><tr><td>  Severodvinsk <br><br></td><td>  8832 <br><br></td></tr><tr><td>  Voronezh <br><br></td><td>  8768 <br><br></td></tr><tr><td>  Blagoveshchensk <br><br></td><td>  8672 <br><br></td></tr><tr><td>  Novorossiysk <br><br></td><td>  8608 <br><br></td></tr><tr><td>  Ulan-Ude <br><br></td><td>  8576 <br><br></td></tr><tr><td>  Serpukhov <br><br></td><td>  8320 <br><br></td></tr><tr><td>  Komsomolsk-on-Amur <br><br></td><td>  8192 <br><br></td></tr><tr><td>  Abakan <br><br></td><td>  8128 <br><br></td></tr><tr><td>  Norilsk <br><br></td><td>  8096 <br><br></td></tr><tr><td>  Yuzhno-Sakhalinsk <br><br></td><td>  8032 <br><br></td></tr><tr><td>  Obninsk <br><br></td><td>  7904 <br><br></td></tr><tr><td>  Essentuki <br><br></td><td>  7712 <br><br></td></tr><tr><td>  Bataysk <br><br></td><td>  7648 <br><br></td></tr><tr><td>  Volzhsky <br><br></td><td>  7584 <br><br></td></tr><tr><td>  Novocherkassk <br><br></td><td>  7488 <br><br></td></tr><tr><td>  Berdsk <br><br></td><td>  7456 <br><br></td></tr><tr><td>  Arzamas <br><br></td><td>  7424 <br><br></td></tr><tr><td>  Pervouralsk <br><br></td><td>  7392 <br><br></td></tr><tr><td>  Kemerovo <br><br></td><td>  7104 <br><br></td></tr><tr><td>  Elektrostal <br><br></td><td>  6720 <br><br></td></tr><tr><td>  Derbent <br><br></td><td>  6592 <br><br></td></tr><tr><td>  Yakutsk <br><br></td><td>  6528 <br><br></td></tr><tr><td>  Murom <br><br></td><td>  6240 <br><br></td></tr><tr><td>  Nefteyugansk <br><br></td><td>  5792 <br><br></td></tr><tr><td>  Reutov <br><br></td><td>  5696 <br><br></td></tr><tr><td>  Birobidzhan <br><br></td><td>  5440 <br><br></td></tr><tr><td>  Novokuybyshevsk <br><br></td><td>  5248 <br><br></td></tr><tr><td>  Salekhard <br><br></td><td>  5184 <br><br></td></tr><tr><td>  Novokuznetsk <br><br></td><td>  5152 <br><br></td></tr><tr><td>  Novy Urengoy <br><br></td><td>  4736 <br><br></td></tr><tr><td>  Noyabrsk <br><br></td><td>  4416 <br><br></td></tr><tr><td>  Novocheboksarsk <br><br></td><td>  4352 <br><br></td></tr><tr><td>  Yelets <br><br></td><td>  3968 <br><br></td></tr><tr><td>  Kaspiysk <br><br></td><td>  3936 <br><br></td></tr><tr><td>  Stary Oskol <br><br></td><td>  3840 <br><br></td></tr><tr><td>  Artyom <br><br></td><td>  3744 <br><br></td></tr><tr><td>  Zheleznogorsk <br><br></td><td>  3584 <br><br></td></tr><tr><td>  Salavat <br><br></td><td>  3584 <br><br></td></tr><tr><td>  Prokopyevsk <br><br></td><td>  2816 <br><br></td></tr><tr><td>  Gorno-Altaysk <br><br></td><td>  2464 <br><br></td></tr></tbody></table><br></div></div><br><h2>  Preparando um conjunto de dados para treinamento </h2><br>  E assim, o conjunto de dados é montado, como agora, tendo uma foto da seção da estrada e dos objetos anexos, descobre a qualidade do asfalto mostrado nele?  Decidi cortar um pedaço da foto medindo 350 * 244 pixels no centro da foto original, logo abaixo do meio.  Em seguida, reduza a peça cortada horizontalmente para um tamanho de 244 pixels.  A imagem resultante (tamanho 244 * 244) será a entrada para o codificador convolucional: <br><br><img src="https://habrastorage.org/webt/ya/tt/s8/yatts8qbzq9ddnxql_cydrmfeug.png"><br><br>  Para entender melhor com quais dados eu ligo, as primeiras 2000 fotos que eu mesmo marquei, o restante das fotos foram marcadas pelos funcionários da Yandex.Tolki.  Antes deles, fiz uma pergunta com a seguinte redação. <br><br>  Indique qual superfície da estrada você vê na foto: <br><br><ol><li>  Solo / entulho </li><li>  Pedras de pavimentação, azulejo, pavimento </li><li>  Trilhos, trilhos de trem </li><li>  Água, poças grandes </li><li>  Asfalto </li><li>  Não há estrada na foto / Objetos estranhos / A cobertura não é visível devido a carros </li></ol><br>  Se o artista escolheu "Asphalt", apareceu um menu que oferecia a avaliação de sua qualidade: <br><br><ol><li>  Excelente cobertura </li><li>  Ligeiras rachaduras / buracos únicos rasos </li><li>  Rachaduras grandes / rachaduras na grade / pequenos buracos </li><li>  Caldeirões Grandes / Caldeirões Profundos / Revestimento Destruído </li></ol><br>  Como as execuções de teste das tarefas mostraram, os executores do Y. Toloki não diferem na integridade do trabalho - eles clicam acidentalmente nos campos com o mouse e consideram a tarefa concluída.  Eu tive que adicionar perguntas de controle (havia 46 fotografias na tarefa, 12 das quais eram de controle) e permitir aceitação tardia.  Como questões de controle, usei as fotos que me marcou.  Automatizei a aceitação atrasada - Y. Toloka permite que você carregue os resultados do trabalho em um arquivo CSV e carregue os resultados da verificação de respostas.  A verificação das respostas funcionou da seguinte maneira - se a tarefa contiver mais de 5% de respostas incorretas para controlar as perguntas, ela será considerada não realizada.  Além disso, se o contratado indicou uma resposta que é logicamente próxima da verdadeira, sua resposta é considerada correta. <br>  Como resultado, recebi cerca de 30 mil fotos marcadas, que decidi distribuir em três aulas para treinamento: <br><br><ul><li>  “Bom” - fotos rotuladas como “Asfalto: excelente revestimento” e “Asfalto: pequenas rachaduras simples” </li><li>  “Médio” - fotos rotuladas como “Pedras de pavimentação, ladrilhos, calçadas”, “Trilhos, trilhos” e “Asfalto: grandes rachaduras / rachaduras na grade / pequenos buracos” </li><li>  “Grande” - fotos rotuladas como “Solo / pedra britada”, “Água, poças grandes” e “Asfalto: um grande número de buracos / buracos profundos / pavimento destruído” </li><li>  As fotos marcadas com “Não há estrada na foto / Objetos estranhos / A cobertura não é visível devido aos carros” eram muito poucas (22 peças). Excluí-as de outros trabalhos </li></ul><br><h2>  Desenvolvimento e treinamento do classificador </h2><br>  Assim, como os dados são coletados e rotulados, prosseguimos para o desenvolvimento do classificador.  Normalmente, para as tarefas de classificação de imagens, especialmente quando o treinamento é feito em pequenos conjuntos de dados, é usado um codificador convolucional pronto para a saída à qual um novo classificador está conectado.  Decidi usar um classificador simples sem uma camada oculta, uma camada de entrada do tamanho 128 e uma camada de saída do tamanho 3. Decidi usar imediatamente várias opções prontas, treinadas no ImageNet como codificadores: <br><br><ul><li>  Xception </li><li>  Resnet </li><li>  Iniciação </li><li>  Vgg16 </li><li>  Densenet121 </li><li>  Mobilenet </li></ul><br>  Aqui está a função que cria o modelo Keras com o codificador fornecido: <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(typeModel)</span></span></span><span class="hljs-function">:</span></span> conv_base = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"nasnet"</span></span>): conv_base = keras.applications.nasnet.NASNetMobile(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"xception"</span></span>): conv_base = keras.applications.xception.Xception(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"resnet"</span></span>): conv_base = keras.applications.resnet50.ResNet50(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"inception"</span></span>): conv_base = keras.applications.inception_v3.InceptionV3(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"densenet121"</span></span>): conv_base = keras.applications.densenet.DenseNet121(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"mobilenet"</span></span>): conv_base = keras.applications.mobilenet_v2.MobileNetV2(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(typeModel == <span class="hljs-string"><span class="hljs-string">"vgg16"</span></span>): conv_base = keras.applications.vgg16.VGG16(include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>) conv_base.trainable = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> model = Sequential() model.add(conv_base) model.add(Flatten()) model.add(Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, kernel_regularizer=regularizers.l2(<span class="hljs-number"><span class="hljs-number">0.0002</span></span>))) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)) model.compile(optimizer=keras.optimizers.Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br>  Para o treinamento, usei um gerador com aumento (uma vez que as possibilidades de aumento incorporadas ao Keras me pareciam insuficientes, usei a biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Augmentor</a> ): <br><br><ul><li>  Encostas </li><li>  Distorção aleatória </li><li>  Turns </li><li>  Troca de cores </li><li>  Turnos </li><li>  Alterar contraste e brilho </li><li>  Adicionando ruído aleatório </li><li>  Colheita </li></ul><br>  Após o aprimoramento, as fotos ficaram assim: <br><br><img src="https://habrastorage.org/webt/yc/qy/uh/ycqyuh1no4h57-or062y3epc4yy.png"><br><br>  Código do gerador: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_datagen</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> train_dir=<span class="hljs-string"><span class="hljs-string">'~/data/train_img'</span></span> test_dir=<span class="hljs-string"><span class="hljs-string">'~/data/test_img'</span></span> testDataGen = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span> / <span class="hljs-number"><span class="hljs-number">255</span></span>) train_generator = datagen.flow_from_directory( train_dir, target_size=img_size, batch_size=<span class="hljs-number"><span class="hljs-number">16</span></span>, class_mode=<span class="hljs-string"><span class="hljs-string">'categorical'</span></span>) p = Augmentor.Pipeline(train_dir) p.skew(probability=<span class="hljs-number"><span class="hljs-number">0.9</span></span>) p.random_distortion(probability=<span class="hljs-number"><span class="hljs-number">0.9</span></span>,grid_width=<span class="hljs-number"><span class="hljs-number">3</span></span>,grid_height=<span class="hljs-number"><span class="hljs-number">3</span></span>,magnitude=<span class="hljs-number"><span class="hljs-number">8</span></span>) p.rotate(probability=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, max_left_rotation=<span class="hljs-number"><span class="hljs-number">5</span></span>, max_right_rotation=<span class="hljs-number"><span class="hljs-number">5</span></span>) p.random_color(probability=<span class="hljs-number"><span class="hljs-number">0.7</span></span>, min_factor=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, max_factor=<span class="hljs-number"><span class="hljs-number">1</span></span>) p.flip_left_right(probability=<span class="hljs-number"><span class="hljs-number">0.7</span></span>) p.random_brightness(probability=<span class="hljs-number"><span class="hljs-number">0.7</span></span>, min_factor=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, max_factor=<span class="hljs-number"><span class="hljs-number">1.2</span></span>) p.random_contrast(probability=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, min_factor=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, max_factor=<span class="hljs-number"><span class="hljs-number">1</span></span>) p.random_erasing(probability=<span class="hljs-number"><span class="hljs-number">1</span></span>,rectangle_area=<span class="hljs-number"><span class="hljs-number">0.2</span></span>) p.crop_by_size(probability=<span class="hljs-number"><span class="hljs-number">1</span></span>, width=<span class="hljs-number"><span class="hljs-number">244</span></span>, height=<span class="hljs-number"><span class="hljs-number">244</span></span>, centre=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) train_generator = keras_generator(p,batch_size=<span class="hljs-number"><span class="hljs-number">16</span></span>) test_generator = testDataGen.flow_from_directory( test_dir, target_size=img_size, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, class_mode=<span class="hljs-string"><span class="hljs-string">'categorical'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (train_generator, test_generator)</code> </pre> <br>  O código mostra que o aumento não é usado para dados de teste. <br><br>  Com um gerador sintonizado, você pode começar a treinar o modelo, nós o realizaremos em duas etapas: primeiro, apenas treine nosso classificador e, em seguida, completamente o modelo inteiro. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">evalModelstep1</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(typeModel)</span></span></span><span class="hljs-function">:</span></span> K.clear_session() gc.collect() model=createModel(typeModel) traiGen,testGen=getDatagen() model.fit_generator(generator=traiGen, epochs=<span class="hljs-number"><span class="hljs-number">4</span></span>, steps_per_epoch=<span class="hljs-number"><span class="hljs-number">30000</span></span>/<span class="hljs-number"><span class="hljs-number">16</span></span>, validation_steps=len(testGen), validation_data=testGen, ) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">evalModelstep2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model)</span></span></span><span class="hljs-function">:</span></span> early_stopping_callback = EarlyStopping(monitor=<span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, patience=<span class="hljs-number"><span class="hljs-number">3</span></span>) model.layers[<span class="hljs-number"><span class="hljs-number">0</span></span>].trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span> model.trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span> model.compile(optimizer=keras.optimizers.Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-5</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) traiGen,testGen=getDatagen() model.fit_generator(generator=traiGen, epochs=<span class="hljs-number"><span class="hljs-number">25</span></span>, steps_per_epoch=<span class="hljs-number"><span class="hljs-number">30000</span></span>/<span class="hljs-number"><span class="hljs-number">16</span></span>, validation_steps=len(testGen), validation_data=testGen, callbacks=[early_stopping_callback] ) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">full_fit</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model_names=[ <span class="hljs-string"><span class="hljs-string">"xception"</span></span>, <span class="hljs-string"><span class="hljs-string">"resnet"</span></span>, <span class="hljs-string"><span class="hljs-string">"inception"</span></span>, <span class="hljs-string"><span class="hljs-string">"vgg16"</span></span>, <span class="hljs-string"><span class="hljs-string">"densenet121"</span></span>, <span class="hljs-string"><span class="hljs-string">"mobilenet"</span></span> ] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> model_name <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> model_names: print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(model_name) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) print(<span class="hljs-string"><span class="hljs-string">"#########################################"</span></span>) model = evalModelstep1(model_name) model = evalModelstep2(model) model.save(<span class="hljs-string"><span class="hljs-string">"~/data/models/model_new_"</span></span>+str(model_name)+<span class="hljs-string"><span class="hljs-string">".h5"</span></span>)</code> </pre><br>  Ligue para full_fit () e aguarde.  Estamos esperando por um longo tempo. <br><br>  Como resultado, teremos seis modelos treinados, verificaremos a precisão desses modelos em uma parte separada dos dados rotulados; recebi o seguinte: <br><br><table><tbody><tr><td><p>  Nome do modelo </p><br></td><td><p>  % De precisão </p><br></td></tr><tr><td><p>  Xception </p><br></td><td><p>  87,3 </p><br></td></tr><tr><td><p>  Resnet </p><br></td><td><p>  90,8 </p><br></td></tr><tr><td><p>  Iniciação </p><br></td><td><p>  90,2 </p><br></td></tr><tr><td><p>  Vgg16 </p><br></td><td><p>  89,2 </p><br></td></tr><tr><td><p>  Densenet121 </p><br></td><td><p>  90,6 </p><br></td></tr><tr><td><p>  Mobilenet </p><br></td><td><p>  86,5 </p><br></td></tr></tbody></table><br>  Em geral, não muito, mas com uma amostra de treinamento tão pequena, não se pode esperar mais.  Para aumentar um pouco a precisão, combinei as saídas dos modelos calculando a média: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_meta_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model_names=[ <span class="hljs-string"><span class="hljs-string">"xception"</span></span>, <span class="hljs-string"><span class="hljs-string">"resnet"</span></span>, <span class="hljs-string"><span class="hljs-string">"inception"</span></span>, <span class="hljs-string"><span class="hljs-string">"vgg16"</span></span>, <span class="hljs-string"><span class="hljs-string">"densenet121"</span></span>, <span class="hljs-string"><span class="hljs-string">"mobilenet"</span></span> ] model_input = Input(shape=(<span class="hljs-number"><span class="hljs-number">244</span></span>,<span class="hljs-number"><span class="hljs-number">244</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) submodels=[] i=<span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> model_name <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> model_names: filename= <span class="hljs-string"><span class="hljs-string">"~/data/models/model_new_"</span></span>+str(model_name)+<span class="hljs-string"><span class="hljs-string">".h5"</span></span> submodel = keras.models.load_model(filename) submodel.name = model_name+<span class="hljs-string"><span class="hljs-string">"_"</span></span>+str(i) i+=<span class="hljs-number"><span class="hljs-number">1</span></span> submodels.append(submodel(model_input)) out=average(submodels) model = Model(inputs = model_input,outputs=out) model.compile(optimizer=keras.optimizers.Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br>  A precisão resultante foi de 91,3%.  Neste resultado, eu decidi parar. <br><br><h2>  Usando Classificador </h2><br>  Finalmente, o classificador está pronto e pode ser colocado em ação!  Preparo os dados de entrada e executo o classificador - um pouco mais de um dia e 1,7 milhão de fotos foram processadas.  Agora, a parte divertida são os resultados.  Traga imediatamente a primeira e a última dez cidades no número relativo de estradas com boa cobertura: <br><br><img src="https://habrastorage.org/webt/mf/vl/xu/mfvlxuvjesvy2leqhplfnik4mm8.png"><br><br><div class="spoiler">  <b class="spoiler_title">Tabela completa (imagem clicável)</b> <div class="spoiler_text"> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/9d8/4fd/38c/9d84fd38c07014be4f68499489ce19bc.png"></a> <br></div></div><br><br>  E aqui está a classificação da qualidade da estrada por sujeitos federais: <br><br><img src="https://habrastorage.org/webt/ih/kq/xq/ihkqxqskkfcfib90gc68ivmxo2i.png"><br><br><div class="spoiler">  <b class="spoiler_title">Tabela completa</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/md/6j/-m/md6j-mv6jt27zsxgu8wkd2pimmy.png"><br></div></div><br>  Classificação por distritos federais: <br><br><img src="https://habrastorage.org/webt/ro/qq/ry/roqqryu12toajz6cgeals3vzuxc.png"><br><br>  Distribuição da qualidade das estradas na Rússia como um todo: <br><br><img src="https://habrastorage.org/webt/ow/rt/h1/owrth1ro6yu3svxdpwiyfedzeby.png"><br><br>  Bem, isso é tudo, todos podem tirar conclusões pessoalmente. <br><br>  Por fim, darei as melhores fotos de cada categoria (que receberam o valor máximo em sua classe): <br><br><div class="spoiler">  <b class="spoiler_title">Imagem</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/k9/yf/dl/k9yfdlmiuynquyqhoxjuowvzcsu.jpeg"><br></div></div><br><br>  PS Nos comentários, apontou com razão a falta de estatísticas sobre os anos de recebimento das fotografias.  Eu corrijo e dou uma mesa: <br><table><tbody><tr><td><p>  Ano </p><br></td><td><p>  Número de fotos, peças </p><br></td></tr><tr><td>  2008 </td><td>  37. </td></tr><tr><td>  2009 </td><td>  13 </td></tr><tr><td>  2010 </td><td>  157030 </td></tr><tr><td>  2011 </td><td>  60724 </td></tr><tr><td>  2012 </td><td>  42387 </td></tr><tr><td>  2013 </td><td>  12148 <br><br></td></tr><tr><td>  2014 </td><td>  141021 <br><br></td></tr><tr><td>  2015 </td><td>  46143 <br><br></td></tr><tr><td>  2016 </td><td>  410385 <br><br></td></tr><tr><td>  2017 </td><td>  324279 <br><br></td></tr><tr><td>  2018 </td><td>  581961 <br><br></td></tr></tbody></table></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt437542/">https://habr.com/ru/post/pt437542/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt437532/index.html">A indústria robomóvel está finalmente se tornando mais realista</a></li>
<li><a href="../pt437534/index.html">Como a retenção de retenção é implementada no aplicativo no ar</a></li>
<li><a href="../pt437536/index.html">Melhor angular do mundo da semana - Resumo nº 1 (18 de janeiro a 25 de janeiro)</a></li>
<li><a href="../pt437538/index.html">Rede neural AlphaStar venceu os profissionais StarCraft II com uma pontuação de 10-1</a></li>
<li><a href="../pt437540/index.html">Como gerenciar conflitos de equipe</a></li>
<li><a href="../pt437544/index.html">Qual é a diferença entre monitores de livros eletrônicos e smartphones e tablets?</a></li>
<li><a href="../pt437546/index.html">Máquina Linux em um domínio do Windows AD usando sssd e krb5</a></li>
<li><a href="../pt437548/index.html">Não apenas o uBlock Origin sofrerá com novas APIs no Chromium, mas também outras extensões</a></li>
<li><a href="../pt437550/index.html">Leitura de fim de semana: 10 materiais de vinil - da produção à audição e cuidados em casa</a></li>
<li><a href="../pt437552/index.html">Excursão à produção do Promobot. Entrevista com CTO</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
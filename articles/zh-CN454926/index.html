<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌇 🚶🏻 🧠 您对word2vec的了解都不是真的 🐤 ⚓️ 👧🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="原始科学文章和无数博客文章中对word2vec作为否定样本Skip-gram体系结构的经典解释如下： 



while(1) { 1. vf = vector of focus word 2. vc = vector of focus word 3. train such that (vc . v...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>您对word2vec的了解都不是真的</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454926/"> 原始科学文章和无数博客文章中对word2vec作为否定样本Skip-gram体系结构的经典解释如下： <br><br><pre><code class="plaintext hljs">while(1) { 1. vf = vector of focus word 2. vc = vector of focus word 3. train such that (vc . vf = 1) 4. for(0 &lt;= i &lt;= negative samples): vneg = vector of word *not* in context train such that (vf . vneg = 0) }</code> </pre> <br> 的确，如果您用谷歌搜索[word2vec skipgram]，我们将看到： <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Wikipedia页面，从高层次描述了算法</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">具有相同解释的Tensorflow页面</a> <br></li><li> 转到<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Data Science博客，其中描述了相同的算法</a> ，然后继续进行下去。 </li></ul><br>  <b>但是所有这些实现都是错误的</b> 。 <br><a name="habracut"></a><br>  C语言中word2vec的原始实现工作原理不同，并且<i>根本不同</i> 。 那些专业地使用word2vec中的单词嵌入来实现系统的人员，可以执行以下任一操作： <br><br><ol><li> 直接调用C的原始实现。 <br></li><li> 使用<code>gensim</code>实现，该实现从源C进行<i>音译</i> ，直到变量名称匹配。 </li></ol><br> 实际上， <code>gensim</code>是<i>我所知道</i>的<i>唯一真正的C实现</i> 。 <br><br><h3>  C实现 </h3><br>  C实现实际上<i>为每个单词</i>支持<i>两个向量</i> 。 这个词的一个向量是焦点，第二个向量是上下文。  （似乎很熟悉？对，GloVe开发人员从word2vec借用了一个想法，而没有提到这个事实！） <br><br> 用C代码实现的能力异常出色： <br><br><ul><li>  <code>syn0</code>数组包含单词的向量嵌入（如果单词作为焦点单词出现）。 这是一个<b>随机初始化</b> 。 <br><br><pre> <code class="cpp hljs">https:<span class="hljs-comment"><span class="hljs-comment">//github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L369 for (a = 0; a &lt; vocab_size; a++) for (b = 0; b &lt; layer1_size; b++) { next_random = next_random * (unsigned long long)25214903917 + 11; syn0[a * layer1_size + b] = (((next_random &amp; 0xFFFF) / (real)65536) - 0.5) / layer1_size; }</span></span></code> </pre> </li><li> 当它作为上下文单词出现时，另一个<code>syn1neg</code>数组包含单词的向量。 这里<b>初始化为零</b> 。 <br></li><li> 在训练过程中（Skip-gram，否定样本，尽管其他情况大致相同），我们首先选择焦点词。 在培训过程中，无论是正面还是负面的例子，都将保留它。 在对正样本和负样本进行训练后，聚焦向量的梯度会累积在缓冲区中并应用于聚焦词。 <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (negative &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (d = <span class="hljs-number"><span class="hljs-number">0</span></span>; d &lt; negative + <span class="hljs-number"><span class="hljs-number">1</span></span>; d++) { <span class="hljs-comment"><span class="hljs-comment">// if we are performing negative sampling, in the 1st iteration, // pick a word from the context and set the dot product target to 1 if (d == 0) { target = word; label = 1; } else { // for all other iterations, pick a word randomly and set the dot //product target to 0 next_random = next_random * (unsigned long long)25214903917 + 11; target = table[(next_random &gt;&gt; 16) % table_size]; if (target == 0) target = next_random % (vocab_size - 1) + 1; if (target == word) continue; label = 0; } l2 = target * layer1_size; f = 0; // find dot product of original vector with negative sample vector // store in f for (c = 0; c &lt; layer1_size; c++) f += syn0[c + l1] * syn1neg[c + l2]; // set g = sigmoid(f) (roughly, the actual formula is slightly more complex) if (f &gt; MAX_EXP) g = (label - 1) * alpha; else if (f &lt; -MAX_EXP) g = (label - 0) * alpha; else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))]) * alpha; // 1. update the vector syn1neg, // 2. DO NOT UPDATE syn0 // 3. STORE THE syn0 gradient in a temporary buffer neu1e for (c = 0; c &lt; layer1_size; c++) neu1e[c] += g * syn1neg[c + l2]; for (c = 0; c &lt; layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1]; } // Finally, after all samples, update syn1 from neu1e https://github.com/tmikolov/word2vec/blob/20c129af10659f7c50e86e3be406df663beff438/word2vec.c#L541 // Learn weights input -&gt; hidden for (c = 0; c &lt; layer1_size; c++) syn0[c + l1] += neu1e[c];</span></span></code> </pre> </li></ul><br><h3> 为什么随机和零初始化？ </h3><br> 再一次，由于原始文章<i>和Internet上的任何地方</i>都没有对此进行解释，所以我只能推测。 <br><br> 假设是，当否定样本来自整个文本并且不按频率加权时，您可以选择<i>任何单词</i> ，并且通常选择一个其<i>向量根本没有经过训练</i>的单词。 如果此向量具有含义，则它将随机移动真正重要的单词。 <br><br> 底线是将所有否定示例设置为零，以便<i>仅出现或多或少出现的向量</i>会影响另一个向量的表示。 <br><br> 这实际上很棘手，而且我从未想过初始化策略有多重要。 <br><br><h3> 我为什么要写这个 </h3><br> 我花了两个月的时间来尝试复制word2vec，如原始的科学出版物和互联网上无数的文章所述，但是失败了。 尽管我已尽力而为，但我无法达到与word2vec相同的结果。 <br><br> 我无法想象该出版物的作者实际上制造了一种行不通的算法，而实现却完全不同。 <br><br> 最后，我决定研究来源。 三天以来，我确信自己误解了代码，因为实际上互联网上的每个人都在谈论另一种实现。 <br><br> 我不知道为什么Internet上的原始出版物和文章没有对word2vec的<i>真正</i>机制说什么，所以我决定自己发布此信息。 <br><br> 这也解释了GloVe的根本选择，即为否定语境设置单独的向量-他们只是做了word2vec所做的，但是告诉了人们:)。 <br><br> 这是科学诀窍吗？ 我不知道，这是一个难题。 但是说实话，我非常生气。 可能，我将永远无法再认真对待机器学习中的算法解释：下次，我将<i>立即</i>查看源代码。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN454926/">https://habr.com/ru/post/zh-CN454926/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN454914/index.html">我们使用Yii2。 我们正在编写另一个CMS或尝试以最小的开销显着加快开发速度</a></li>
<li><a href="../zh-CN454916/index.html">用于实现RL算法的神经网络体系结构，能够设置同时运行的动作</a></li>
<li><a href="../zh-CN454918/index.html">如何在12小时内将两个零售商的支持结合起来</a></li>
<li><a href="../zh-CN454922/index.html">《 PD法》后关于外国客户及其在俄罗斯工作特征的故事</a></li>
<li><a href="../zh-CN454924/index.html">Veeam Backup for Microsoft Office 365 v3中的身份验证设置</a></li>
<li><a href="../zh-CN454928/index.html">在RDP会话上绕过Windows锁定屏幕的方法</a></li>
<li><a href="../zh-CN454930/index.html">V8中的垃圾收集：新的Orinoco GC如何工作</a></li>
<li><a href="../zh-CN454932/index.html">投资和软件：5个用于在交易所进行交易的交易终端</a></li>
<li><a href="../zh-CN454938/index.html">开发自己的内核以嵌入基于FPGA的处理器系统</a></li>
<li><a href="../zh-CN454940/index.html">旅游健康保险：详细说明</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
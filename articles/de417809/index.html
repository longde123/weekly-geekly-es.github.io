<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õ∏Ô∏è ü§∑ üï∑Ô∏è KI, praktischer Kurs. Moderne tiefe neuronale Netzwerkarchitekturen zur Bildklassifizierung üîè üë® üí§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In einem fr√ºheren Artikel, √úberblick √ºber neuronale Netze zur Bildklassifizierung , haben wir uns mit den Grundkonzepten von Faltungs-Neuronalen Netze...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>KI, praktischer Kurs. Moderne tiefe neuronale Netzwerkarchitekturen zur Bildklassifizierung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/417809/"><img src="https://habrastorage.org/webt/sz/-n/ep/sz-neph-gqvvjim1l0dreihnxlu.png"><br><br>  In einem fr√ºheren Artikel, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√úberblick √ºber neuronale Netze zur Bildklassifizierung</a> , haben wir uns mit den Grundkonzepten von Faltungs-Neuronalen Netzen sowie den zugrunde liegenden Ideen vertraut gemacht.  In diesem Artikel werden einige tiefe neuronale Netzwerkarchitekturen mit gro√üer Verarbeitungsleistung betrachtet - wie AlexNet, ZFNet, VGG, GoogLeNet und ResNet - und die Hauptvorteile jeder dieser Architekturen zusammengefasst.  Die Struktur des Artikels basiert auf einem Blogeintrag <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Grundlegende Konzepte von Faltungs-Neuronalen Netzen, Teil 3</a> . <br><a name="habracut"></a><br>  Derzeit ist die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ImageNet</a> Challenge der Hauptanreiz f√ºr die Entwicklung von Maschinenerkennungssystemen und die Bildklassifizierung.  Die Kampagne ist ein Wettbewerb f√ºr die Arbeit mit Daten, bei dem den Teilnehmern ein gro√üer Datensatz (mehr als eine Million Bilder) zur Verf√ºgung gestellt wird.  Die Aufgabe des Wettbewerbs besteht darin, einen Algorithmus zu entwickeln, mit dem Sie die erforderlichen Bilder in Objekte in 1000 Kategorien - wie Hunde, Katzen, Autos und andere - mit einer minimalen Anzahl von Fehlern einteilen k√∂nnen. <br><br>  Gem√§√ü den offiziellen Regeln des Wettbewerbs m√ºssen die Algorithmen eine Liste von nicht mehr als f√ºnf Kategorien von Objekten in absteigender Reihenfolge des Vertrauens f√ºr jede Kategorie von Bildern bereitstellen.  Die Bildmarkierungsqualit√§t wird anhand des Etiketts bewertet, das am besten mit der Grundwahrheitseigenschaft des Bildes √ºbereinstimmt.  Die Idee ist, dem Algorithmus zu erm√∂glichen, mehrere Objekte im Bild zu identifizieren und keine Strafpunkte zu sammeln, falls eines der erkannten Objekte tats√§chlich im Bild vorhanden war, aber nicht in der Grundwahrheitseigenschaft enthalten war. <br><br>  Im ersten Jahr des Wettbewerbs erhielten die Teilnehmer vorab ausgew√§hlte Bildattribute f√ºr das Training des Modells.  Dies k√∂nnen beispielsweise Zeichen des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SIFT-</a> Algorithmus sein, der unter Verwendung einer Vektorquantisierung verarbeitet wird und zur Verwendung in der Wortbeutelmethode oder zur Darstellung als r√§umliche Pyramide geeignet ist.  2012 gab es jedoch einen echten Durchbruch in diesem Bereich: Eine Gruppe von Wissenschaftlern der University of Toronto hat gezeigt, dass ein tiefes neuronales Netzwerk im Vergleich zu herk√∂mmlichen Modellen f√ºr maschinelles Lernen, die auf der Grundlage von Vektoren aus zuvor ausgew√§hlten Bildeigenschaften erstellt wurden, signifikant h√∂here Ergebnisse erzielen kann.  In den folgenden Abschnitten werden die erste 2012 vorgeschlagene innovative Architektur sowie die Architekturen betrachtet, die bis 2015 folgen. <br><br><img src="https://habrastorage.org/webt/b1/yc/0j/b1yc0jlxh6r5g9xmpvsfocbxmxo.png"><br>  <i>Diagramm der √Ñnderungen der Anzahl der Fehler (in Prozent) bei der Klassifizierung von ImageNet * -Bildern f√ºr die f√ºnf f√ºhrenden Kategorien.</i>  <i>Bild aus der Pr√§sentation von Kaiming He, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deep Residual Learning for Image Recognition</a></i> <br><br><h3>  <font color="#0071c5">Alexnet</font> </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die AlexNet-</a> Architektur wurde 2012 von einer Gruppe von Wissenschaftlern (A. Krizhevsky, I. Sutskever und J. Hinton) von der University of Toronto vorgeschlagen.  Dies war eine innovative Arbeit, in der die Autoren (zu dieser Zeit) erstmals tiefe Faltungsnetzwerke mit einer Gesamttiefe von acht Schichten (f√ºnf Faltungsschichten und drei vollst√§ndig verbundene Schichten) verwendeten. <br><br><img src="https://habrastorage.org/webt/fm/wq/lm/fmwqlmznjszot3yzk1zfejfab6w.png"><br>  <i>Architektur AlexNet</i> <br><br>  Die Netzwerkarchitektur besteht aus folgenden Schichten: <br><br><ul><li>  [Faltungsschicht + Maximalwertauswahl + Normalisierung] x 2 </li><li>  [Faltungsschicht] x 3 </li><li>  [Auswahl des Maximalwerts] </li><li>  [Volle Schicht] x 3 </li></ul><br>  Ein solches Schema mag etwas seltsam aussehen, da der Lernprozess aufgrund seiner hohen Rechenkomplexit√§t zwischen den beiden GPUs aufgeteilt wurde.  Diese Arbeitsteilung zwischen GPUs erfordert eine manuelle Trennung des Modells in vertikale Bl√∂cke, die miteinander interagieren. <br><br>  Die Architektur von AlexNet hat die Anzahl der Fehler in den f√ºnf f√ºhrenden Kategorien auf 16,4 Prozent reduziert - fast die H√§lfte im Vergleich zu fr√ºheren fortgeschrittenen Entwicklungen!  Ebenfalls im Rahmen dieser Architektur wurde eine solche Aktivierungsfunktion als lineare Gleichrichtereinheit ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ReLU</a> ) eingef√ºhrt, die derzeit der Industriestandard ist.  Das Folgende ist eine kurze Zusammenfassung anderer Hauptmerkmale der AlexNet-Architektur und ihres Lernprozesses: <br><br><ul><li>  Intensive Datenerweiterung </li><li>  Ausschlussmethode </li><li>  Optimierung mit SGD-Moment (siehe Optimierungsleitfaden ‚Äû√úbersicht √ºber Algorithmen zur Optimierung des Gradientenabfalls‚Äú) </li><li>  Manuelle Einstellung der Lerngeschwindigkeit (Reduzierung dieses Koeffizienten um 10 bei Stabilisierung der Genauigkeit) </li><li>  Das endg√ºltige Modell ist eine Sammlung von sieben Faltungs-Neuronalen Netzen </li><li>  Die Schulung wurde auf zwei NVIDIA * GeForce GTX * 580-Grafikprozessoren mit jeweils insgesamt 3 GB Videospeicher durchgef√ºhrt. </li></ul><br><h3>  <font color="#0071c5">Zfnet</font> </h3><br>  Die von den Forschern M. Zeiler und R. Fergus von der New York University vorgeschlagene <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ZFNet-</a> Netzwerkarchitektur ist nahezu identisch mit der AlexNet-Architektur.  Die einzigen signifikanten Unterschiede zwischen ihnen sind wie folgt: <br><br><ul><li>  Filtergr√∂√üe und Schritt in der ersten Faltungsschicht (in AlexNet betr√§gt die Filtergr√∂√üe 11 √ó 11 und der Schritt 4; in ZFNet - 7 √ó 7 bzw. 2) </li><li>  Die Anzahl der Filter in sauberen Faltungsschichten (3, 4, 5). </li></ul><br><img src="https://habrastorage.org/webt/gj/ji/wz/gjjiwzynwfzcnsrw3_vzgilojoo.png"><br>  <i>ZFNet-Architektur</i> <br><br>  Dank der ZFNet-Architektur sank die Anzahl der Fehler in den f√ºnf f√ºhrenden Kategorien auf 11,4 Prozent.  M√∂glicherweise spielt dabei die genaue Abstimmung der Hyperparameter (Gr√∂√üe und Anzahl der Filter, Paketgr√∂√üe, Lerngeschwindigkeit usw.) die Hauptrolle.  Es ist jedoch auch wahrscheinlich, dass die Ideen der ZFNet-Architektur einen sehr wichtigen Beitrag zur Entwicklung von Faltungs-Neuronalen Netzen geleistet haben.  Ziller und Fergus schlugen ein System zur Visualisierung von Kernen, Gewichten und einer verborgenen Ansicht von Bildern mit dem Namen DeconvNet vor.  Dank ihr wurde ein besseres Verst√§ndnis und eine Weiterentwicklung der Faltungs-Neuronalen Netze m√∂glich. <br><br><h3>  <font color="#0071c5">VGG Net</font> </h3><br>  2014 schlugen K. Simonyan und E. Zisserman von der Universit√§t Oxford eine Architektur namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VGG vor</a> .  Die Hauptidee dieser Struktur ist es <i>, die Filter so einfach wie m√∂glich</i> zu <i>halten</i> .  Daher werden alle Faltungsoperationen unter Verwendung eines Filters der Gr√∂√üe 3 und eines Schritts der Gr√∂√üe 1 ausgef√ºhrt, und alle Unterabtastungsoperationen werden unter Verwendung eines Filters der Gr√∂√üe 2 und eines Schritts der Gr√∂√üe 2 durchgef√ºhrt. Dies ist jedoch nicht alles.  Zusammen mit der Einfachheit der Faltungsmodule ist das Netzwerk erheblich gewachsen - jetzt hat es 19 Schichten!  Die wichtigste Idee, die zuerst in dieser Arbeit vorgeschlagen wurde, besteht darin <i>, Faltungsschichten ohne Unterabtastungsschichten aufzuerlegen</i> .  Die zugrunde liegende Idee ist, dass eine solche √úberlagerung immer noch ein ausreichend gro√ües Empfangsfeld liefert (zum Beispiel haben drei √ºberlagerte Faltungsschichten mit einer Gr√∂√üe von 3 √ó 3 in Schritten von 1 ein Empfangsfeld √§hnlich einer Faltungsschicht mit einer Gr√∂√üe von 7 √ó 7). Die Anzahl der Parameter ist jedoch erheblich geringer als in Netzwerken mit gro√üen Filtern (dient als Regularisierer).  Zus√§tzlich wird es m√∂glich, zus√§tzliche nichtlineare Transformationen einzuf√ºhren. <br><br>  Im Wesentlichen haben die Autoren gezeigt, dass Sie selbst mit sehr einfachen Bausteinen im ImageNet-Wettbewerb qualitativ hochwertige Ergebnisse erzielen k√∂nnen.  Die Anzahl der Fehler f√ºr die f√ºnf f√ºhrenden Kategorien wurde auf 7,3 Prozent reduziert. <br><br><img src="https://habrastorage.org/webt/x7/rk/yj/x7rkyjkvxchmnso5gd56gf83eec.png"><br>  <i>VGG-Architektur.</i>  <i>Bitte beachten Sie, dass die Anzahl der Filter umgekehrt proportional zur r√§umlichen Gr√∂√üe des Bildes ist.</i> <br><br><h3>  <font color="#0071c5">GoogleNet</font> </h3><br>  Bisher bestand die gesamte Architekturentwicklung darin, Filter zu vereinfachen und die Tiefe des Netzwerks zu erh√∂hen.  2014 schlug C. Szegedy zusammen mit anderen Teilnehmern einen v√∂llig anderen Ansatz vor und schuf die damals komplexeste Architektur namens GoogLeNet. <br><br><img src="https://habrastorage.org/webt/dl/rg/c7/dlrgc7gmujh1atkvisnx5onluim.png"><br>  <i>GoogLeNet-Architektur.</i>  <i>Es verwendet das Inception-Modul, das in der Abbildung gr√ºn hervorgehoben ist.</i>  <i>Der Netzwerkaufbau basiert auf diesen Modulen</i> <br><br>  Eine der wichtigsten Errungenschaften dieser Arbeit ist das sogenannte Inception-Modul, das in der folgenden Abbildung dargestellt ist.  Netzwerke anderer Architekturen verarbeiten Eingabedaten nacheinander, Schicht f√ºr Schicht, w√§hrend unter Verwendung des Inception-Moduls <i>Eingabedaten parallel verarbeitet werden</i> .  Auf diese Weise k√∂nnen Sie die Ausgabe beschleunigen und die <i>Gesamtzahl der Parameter</i> minimieren. <br><br><img src="https://habrastorage.org/webt/uo/ny/0t/uony0thmws6rtd5jyloaqxs5swe.png"><br>  <i>Inception-Modul.</i>  <i>Beachten Sie, dass das Modul mehrere parallele Zweige verwendet, die unterschiedliche Eigenschaften basierend auf denselben Eingabedaten berechnen und dann die Ergebnisse kombinieren</i> <br><br>  Ein weiterer interessanter Trick, der im Inception-Modul verwendet wird, ist die Verwendung von Faltungsschichten der Gr√∂√üe 1 √ó 1. Dies mag sinnlos erscheinen, bis wir uns daran erinnern, dass der Filter die gesamte Dimension der Tiefe abdeckt.  Somit ist eine 1 √ó 1-Faltung ein einfacher Weg, um die Dimension einer Eigenschaftskarte zu reduzieren.  Diese Art von Faltungsschichten wurde erstmals <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von</a> M. Lin et al. In <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Network</a> eingef√ºhrt. Eine umfassende und verst√§ndliche Erkl√§rung findet sich auch im Blog-Beitrag <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Convolution [1 √ó 1] - N√ºtzlichkeit entgegen der Intuition</a> von A. Prakash. <br><br>  Letztendlich reduzierte diese Architektur die Anzahl der Fehler f√ºr die f√ºnf f√ºhrenden Kategorien um ein weiteres halbes Prozent - auf einen Wert von 6,7 Prozent. <br><br><h3>  <font color="#0071c5">Resnet</font> </h3><br>  Im Jahr 2015 kam eine Gruppe von Forschern (Cuming Hee und andere) von Microsoft Research Asia auf eine Idee, die derzeit von den meisten Mitgliedern der Community als eine der wichtigsten Phasen bei der Entwicklung von Deep Learning angesehen wird. <br><br>  Eines der Hauptprobleme tiefer neuronaler Netze ist das Problem eines verschwindenden Gradienten.  Kurz gesagt, dies ist ein technisches Problem, das auftritt, wenn die Fehlerr√ºckausbreitungsmethode f√ºr den Gradientenberechnungsalgorithmus verwendet wird.  Bei der Arbeit mit der R√ºck√ºbertragung von Fehlern wird eine Kettenregel verwendet.  Wenn der Gradient am Ende des Netzwerks einen kleinen Wert hat, kann er au√üerdem einen unendlich kleinen Wert annehmen, wenn er den Anfang des Netzwerks erreicht.  Dies kann zu v√∂llig anderen Problemen f√ºhren, einschlie√ülich der grunds√§tzlichen Unm√∂glichkeit, das Netzwerk zu lernen (weitere Informationen finden Sie im Blogeintrag von R. Kapur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Das Problem eines verblassenden Gradienten</a> ). <br><br>  Um dieses Problem zu l√∂sen, schlugen Caiming Hee und seine Gruppe die folgende Idee vor: Dem Netzwerk zu erm√∂glichen, die Restzuordnung (ein Element, das der Eingabe hinzugef√ºgt werden sollte) anstelle der Anzeige selbst zu untersuchen.  Technisch erfolgt dies √ºber die in der Abbildung gezeigte Bypass-Verbindung. <br><br><img src="https://habrastorage.org/webt/0r/tc/qs/0rtcqsfuosnmqzprsvgdiho2i_o.png"><br>  <i>Schematische Darstellung des Restblocks: Die Eingangsdaten werden √ºber eine verk√ºrzte Verbindung unter Umgehung der Konvertierungsschichten √ºbertragen und zum Ergebnis addiert.</i>  <i>Bitte beachten Sie, dass eine ‚Äûidentische‚Äú Verbindung dem Netzwerk keine zus√§tzlichen Parameter hinzuf√ºgt, weshalb ihre Struktur nicht kompliziert ist</i> <br><br>  Diese Idee ist √§u√üerst einfach, aber gleichzeitig √§u√üerst effektiv.  Es l√∂st das Problem des verschwindenden Gradienten und erm√∂glicht es ihm, sich ohne √Ñnderungen von den oberen zu den unteren Schichten durch "identische" Verbindungen zu bewegen.  Dank dieser Idee k√∂nnen Sie sehr tiefe, extrem tiefe Netzwerke trainieren. <br><br>  Das Netzwerk, das 2015 die ImageNet Challenge gewann, enthielt 152 Ebenen (die Autoren konnten das Netzwerk mit 1001 Ebenen trainieren, aber es lieferte ungef√§hr das gleiche Ergebnis, sodass sie nicht mehr damit arbeiteten).  Dar√ºber hinaus konnte mit dieser Idee die Anzahl der Fehler f√ºr die f√ºnf f√ºhrenden Kategorien buchst√§blich um die H√§lfte reduziert werden - auf einen Wert von 3,6 Prozent.  Laut einer Studie √ºber das, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">was ich im ImageNet-Wettbewerb von</a> A. Karpathy <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im Wettbewerb mit einem Faltungsnetzwerk</a> gelernt habe, betr√§gt die menschliche Leistung f√ºr diese Aufgabe ungef√§hr 5 Prozent.  Dies bedeutet, dass die ResNet-Architektur zumindest bei dieser Bildklassifizierungsaufgabe die menschlichen Ergebnisse √ºbertreffen kann. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de417809/">https://habr.com/ru/post/de417809/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de417793/index.html">Vergessen Sie die Megastrukturen von Au√üerirdischen: Neue Beobachtungen erkl√§ren das Verhalten des Sterns Tabby nur Staub</a></li>
<li><a href="../de417795/index.html">Meine Besessenheit mit Videospielen in meiner Jugend ist keine "Spielst√∂rung"</a></li>
<li><a href="../de417797/index.html">4 Gr√ºnde, warum NASA-Projekte Fristen brechen und das Budget aufbl√§hen</a></li>
<li><a href="../de417801/index.html">Wie ich nach der Blockierung von Telegram nach Israel gezogen bin</a></li>
<li><a href="../de417803/index.html">Batch-Fotoverarbeitung in Blender</a></li>
<li><a href="../de417813/index.html">Zabbix - √úberwachung von OSPF-Nachbarn mithilfe von SNMPv3-TRAPs, Schmerz und Verzweiflung</a></li>
<li><a href="../de417821/index.html">Network Digest: 20 Expertenmaterialien zu Protokollen, Standards und Informationssicherheit</a></li>
<li><a href="../de417823/index.html">Neue Generation: Das weltweit erste kommerzielle 5G-Netzwerk wurde gestartet</a></li>
<li><a href="../de417825/index.html">"Grenzen erweitern": Der 6-GHz-Bereich wird den Anforderungen von Wi-Fi angepasst</a></li>
<li><a href="../de417827/index.html">Kostenloses WLAN: Das deutsche Gericht hebt die Strafen f√ºr Kaffeeh√§user f√ºr Urheberrechtsverletzungen von Kunden auf</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙏 🙇🏿 😥 Analyse des performances des machines virtuelles dans VMware vSphere. Partie 2: Mémoire ✡️ 🧗 👨🏿‍🤝‍👨🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Partie 1. À propos du CPU 
 Partie 3. À propos du stockage 

 Dans cet article, nous parlerons des compteurs de performances RAM dans vSphere. 
 Il se...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analyse des performances des machines virtuelles dans VMware vSphere. Partie 2: Mémoire</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dataline/blog/455820/"><img src="https://habrastorage.org/webt/el/am/7y/elam7yyhc6vrowmmrt5ofxgj-r0.png"><br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 1. À propos du CPU</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 3. À propos du stockage</a> <br><br>  Dans cet article, nous parlerons des compteurs de performances RAM dans vSphere. <br>  Il semble que la mémoire soit de plus en plus sans ambiguïté qu'avec le processeur: s'il y a des problèmes de performances sur la VM, il est difficile de ne pas les remarquer.  Mais s'ils apparaissent, les traiter est beaucoup plus difficile.  Mais tout d'abord. <a name="habracut"></a><br><br><h3>  Un peu de théorie </h3><br>  La RAM des machines virtuelles est extraite de la mémoire du serveur sur lequel les VM s'exécutent.  C'est assez évident :).  Si la RAM du serveur n'est pas suffisante pour tout le monde, ESXi commence à appliquer des techniques de récupération de mémoire.  Sinon, les systèmes d'exploitation VM se bloqueraient avec des erreurs d'accès à la RAM. <br><br>  Quelles techniques utiliser ESXi décide en fonction de la charge de RAM: <br><div class="scrollable-table"><table><tbody><tr><td>  <b>État de la mémoire</b> <br></td><td>  <b>La frontière</b> <br></td><td>  <b>Actions</b> <br></td></tr><tr><td> Élevé <br></td><td>  400% de minFree <br></td><td>  Après avoir atteint la limite supérieure, les grandes pages de mémoire sont divisées en petites (TPS fonctionne en mode standard). <br></td></tr><tr><td>  Clair <br></td><td>  100% de minFree <br></td><td>  Les grandes pages de mémoire sont divisées en petits, TPS fonctionne de force. <br></td></tr><tr><td>  Doux <br></td><td>  64% de minFree <br></td><td>  TPS + ballon <br></td></tr><tr><td>  Dur <br></td><td>  32% de minFree <br></td><td>  TPS + Compress + Swap <br></td></tr><tr><td>  Faible <br></td><td>  16% de minFree <br></td><td>  Compresser + Swap + Block <br></td></tr></tbody></table></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Source</a> <br><br>  minFree est la RAM nécessaire au fonctionnement de l'hyperviseur. <br><br>  Avant ESXi 4.1 inclus, minFree était fixé par défaut - 6% de la RAM du serveur (le pourcentage pouvait être modifié via l'option Mem.MinFreePct sur ESXi).  Dans les versions ultérieures, en raison de l'augmentation des volumes de mémoire sur les serveurs minFree, il a commencé à être calculé en fonction de la taille de la mémoire de l'hôte, et non en tant que valeur de pourcentage fixe. <br><br>  La valeur minFree (par défaut) est calculée comme suit: <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Pourcentage de mémoire réservé pour minFree</b> <br></td><td>  <b>Plage de mémoire</b> <br></td></tr><tr><td>  6% <br></td><td>  0-4 Go <br></td></tr><tr><td>  4% <br></td><td>  4-12 Go <br></td></tr><tr><td>  2% <br></td><td>  12-28 Go <br></td></tr><tr><td>  1% <br></td><td>  Mémoire restante <br></td></tr></tbody></table></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Source</a> <br><br>  Par exemple, pour un serveur avec 128 Go de RAM, la valeur MinFree serait: <br>  MinFree = 245,76 + 327,68 + 327,68 + 1024 = 1925,12 Mo = 1,88 Go <br>  La valeur réelle peut différer de quelques centaines de Mo, cela dépend du serveur et de la RAM. <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Pourcentage de mémoire réservé pour minFree</b> <br></td><td>  <b>Plage de mémoire</b> <br></td><td>  <b>Valeur pour 128 Go</b> <br></td></tr><tr><td>  6% <br></td><td>  0-4 Go <br></td><td>  245,76 Mo <br></td></tr><tr><td>  4% <br></td><td>  4-12 Go <br></td><td>  327,68 Mo <br></td></tr><tr><td>  2% <br></td><td>  12-28 Go <br></td><td>  327,68 Mo <br></td></tr><tr><td>  1% <br></td><td>  Mémoire restante (100 Go) <br></td><td>  1024 Mo <br></td></tr></tbody></table></div><br><br>  En règle générale, pour les peuplements productifs, seul Elevé peut être considéré comme normal.  Pour les bancs d'essai et de développement, des conditions claires / douces peuvent être acceptables.  S'il reste moins de 64% MinFree de RAM sur l'hôte, les machines virtuelles exécutées sur celui-ci rencontreront certainement des problèmes de performances. <br><br>  Dans chaque état, certaines techniques de récupération de mémoire sont appliquées à partir de TPS, ce qui n'affecte pratiquement pas les performances de la machine virtuelle, se terminant par Swapping.  Je vais vous en dire plus à leur sujet. <br><br>  <b>Partage de page transparent (TPS).</b>  TPS est, en gros, la déduplication des pages de RAM des machines virtuelles sur un serveur. <br><br>  ESXi recherche des pages identiques de RAM de machine virtuelle, compte et compare la somme de hachage des pages et supprime les pages en double, en les remplaçant par des liens vers la même page dans la mémoire physique du serveur.  En conséquence, la consommation de mémoire physique est réduite, et une certaine réabonnement de la mémoire peut être obtenue avec peu ou pas de perte de performances. <br><br><img src="https://habrastorage.org/webt/ul/fz/1i/ulfz1i0bomyhsarceziylov-o6i.jpeg"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Source</a> <br><br>  Ce mécanisme ne fonctionne que pour les pages de 4 ko (petites pages).  Pages de 2 Mo de taille (grandes pages) l'hyperviseur n'essaie même pas de dédupliquer: la chance de trouver des pages identiques de cette taille n'est pas grande. <br><br>  Par défaut, ESXi alloue de la mémoire aux grandes pages.  La division de grandes pages en petites pages commence lorsque le seuil de l'état Haut est atteint et est forcée lorsque l'état Effacer est atteint (voir le tableau des états de l'hyperviseur). <br><br>  Si vous voulez que TPS commence à fonctionner sans attendre que la RAM hôte se remplisse, dans Advanced Options ESXi, vous devez définir la valeur <i>«Mem.AllocGuestLargePage»</i> sur 0 (la valeur par défaut est 1).  Ensuite, l'allocation de grandes pages de mémoire pour les machines virtuelles sera désactivée. <br><br>  Depuis décembre 2014, dans toutes les versions d'ESXi, le TPS entre les VM a été désactivé par défaut, car une vulnérabilité a été trouvée qui permet théoriquement d'accéder à la RAM d'une autre VM à partir d'une VM.  Détails ici.  Informations sur la mise en œuvre pratique de l'exploitation de la vulnérabilité TPS que je n'ai pas rencontrées. <br><br>  La politique TPS est contrôlée via l'option avancée <i>«Mem.ShareForceSalting»</i> sur ESXi: <br>  0 - TPS inter-VM.  TPS fonctionne pour les pages de différentes VM; <br>  1 - TPS pour VM avec la même valeur «sched.mem.pshare.salt» dans VMX; <br>  2 (par défaut) - TPS intra-VM.  TPS fonctionne pour les pages à l'intérieur d'une machine virtuelle. <br><br>  Il est certainement judicieux de désactiver les grandes pages et d'activer Inter-VM TPS sur les bancs de test.  Il peut également être utilisé pour des stands avec un grand nombre de VM du même type.  Par exemple, sur les supports avec VDI, les économies de mémoire physique peuvent atteindre des dizaines de pour cent. <br><br>  <b>Ballon de mémoire.</b>  La montgolfière n'est plus une technique aussi inoffensive et transparente pour le système d'exploitation VM que TPS.  Mais avec une utilisation appropriée avec Ballooning, vous pouvez vivre et même travailler. <br><br>  Avec Vmware Tools, un pilote spécial est installé sur la machine virtuelle, appelé Balloon Driver (alias vmmemctl).  Lorsque l'hyperviseur commence à manquer de mémoire physique et passe à l'état Soft, ESXi demande à la machine virtuelle de renvoyer la RAM inutilisée via ce pilote de ballon.  Le pilote, à son tour, fonctionne au niveau du système d'exploitation et lui demande de la mémoire libre.  L'hyperviseur voit quelles pages de mémoire physique Balloon Driver a prises, prend la mémoire de la machine virtuelle et la retourne à l'hôte.  Il n'y a aucun problème avec le fonctionnement du système d'exploitation, car au niveau du système d'exploitation, la mémoire est occupée par le pilote de ballon.  Par défaut, Balloon Driver peut occuper jusqu'à 65% de la mémoire de la machine virtuelle. <br><br>  Si VMware Tools n'est pas installé sur la machine virtuelle ou si la bulle est désactivée (je ne le recommande pas, mais il y a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">KB</a> :), l'hyperviseur bascule immédiatement vers des méthodes plus strictes de suppression de mémoire.  Conclusion: assurez-vous que VMware Tools sur la machine virtuelle l'est. <br><br><img src="https://habrastorage.org/webt/ey/pm/s1/eypms1ugdkmhr0r4odhga1locao.png"><br>  <i>Le fonctionnement de Balloon Driver peut être vérifié à partir du système d'exploitation via VMware Tools</i> . <br><br>  <b>Compression mémoire</b>  Cette technique est utilisée lorsque ESXi atteint Hard.  Comme son nom l'indique, ESXi essaie de compresser 4 Ko de pages RAM en 2 Ko et ainsi libérer de l'espace dans la mémoire physique du serveur.  Cette technique augmente considérablement le temps d'accès au contenu des pages de la mémoire RAM de la VM, car la page doit d'abord être nettoyée.  Parfois, toutes les pages ne peuvent pas être compressées et le processus lui-même prend un certain temps.  Par conséquent, cette technique n'est pas très efficace en pratique. <br><br>  <b>Échange de mémoire.</b>  Après une courte phase, la compression de mémoire ESXi est presque inévitablement (si les machines virtuelles ne sont pas allées sur d'autres hôtes ou ne se sont pas arrêtées) passe au Swapping.  Et s'il reste très peu de mémoire (état bas), l'hyperviseur arrête également d'allouer des pages de mémoire de machine virtuelle, ce qui peut provoquer des problèmes dans les machines virtuelles invitées. <br><br>  Voici comment fonctionne le swapping.  Lorsque vous allumez la machine virtuelle, un fichier avec l'extension .vswp est créé pour elle.  En taille, elle est égale à la RAM non réservée de la VM: c'est la différence entre la mémoire configurée et la mémoire réservée.  Lorsque vous travaillez avec Swapping, ESXi décharge les pages de mémoire de la machine virtuelle dans ce fichier et commence à travailler avec lui au lieu de la mémoire physique du serveur.  Bien sûr, une telle mémoire "RAM" est plus lente de plusieurs ordres de grandeur que la mémoire réelle, même si .vswp est en stockage rapide. <br><br>  Contrairement à Ballooning, lorsque des pages inutilisées sont sélectionnées à partir d'une machine virtuelle, les pages qui sont activement utilisées par le système d'exploitation ou les applications à l'intérieur de la machine virtuelle peuvent aller sur le disque pendant l'échange.  Par conséquent, les performances de la machine virtuelle diminuent jusqu'à ce qu'elle se bloque.  La VM fonctionne officiellement et au moins elle peut être correctement désactivée du système d'exploitation.  Si vous serez patient;) <br><br>  Si les machines virtuelles sont passées à Swap, il s'agit d'une situation anormale qu'il vaut mieux éviter si possible. <br><br><h3>  Compteurs de performances de base de la mémoire de la machine virtuelle </h3><br>  Nous sommes donc arrivés à l'essentiel.  Pour surveiller l'état de la mémoire dans la machine virtuelle, les compteurs suivants sont disponibles: <br><br>  <b>Actif</b> - indique la quantité de RAM (kilo-octets) à laquelle la machine virtuelle a accédé au cours de la période de mesure précédente. <br><br>  <b>L'utilisation</b> est identique à Active, mais en pourcentage de la mémoire de la VM configurée.  Il est calculé à l'aide de la formule suivante: taille de mémoire active ÷ machine virtuelle configurée. <br>  Une utilisation élevée et active, respectivement, ne sont pas toujours révélatrices de problèmes de performances des machines virtuelles.  Si une machine virtuelle utilise de manière agressive la mémoire (au moins y accède), cela ne signifie pas qu'il n'y a pas assez de mémoire.  C'est plutôt l'occasion de voir ce qui se passe dans le système d'exploitation. <br>  Il existe une alarme standard sur l'utilisation de la mémoire pour les machines virtuelles: <br><br><img src="https://habrastorage.org/webt/8u/ca/n8/8ucan84mevajwvlnr-4ov9boyro.png"><br><br>  <b>Partagé</b> - la quantité de RAM dans une machine virtuelle dédupliquée à l'aide de TPS (à l'intérieur d'une machine virtuelle ou entre machines virtuelles). <br><br>  <b>Accordé</b> - la quantité de mémoire physique de l'hôte (kilo-octets) qui a été donnée à la machine virtuelle.  Comprend partagé. <br><br>  <b>Consommé</b> (accordé - partagé) - la quantité de mémoire physique (kilo-octets) que la machine virtuelle consomme de l'hôte.  N'inclut pas Shared. <br><br>  Si une partie de la mémoire de la machine virtuelle n'est pas allouée à partir de la mémoire physique de l'hôte, mais du fichier d'échange ou que la mémoire a été prise à partir de la machine virtuelle via le pilote de ballon, ce montant n'est pas pris en compte dans Accordé et Consommé. <br>  Les valeurs élevées de Accordé et Consommé sont parfaitement normales.  Le système d'exploitation retire progressivement la mémoire de l'hyperviseur et ne rend pas.  Au fil du temps, avec une machine virtuelle fonctionnant activement, les valeurs de ces compteurs approchent la quantité de mémoire configurée et y restent. <br><br>  <b>Zéro</b> - la quantité de RAM dans la machine virtuelle (kilo-octets), qui contient des zéros.  Cette mémoire est considérée comme un hyperviseur libre et peut être donnée à d'autres machines virtuelles.  Après que l'OS invité l'ait reçu, il a écrit quelque chose dans la mémoire nulle, il va à Consumed et ne revient pas. <br><br>  <b>Surcharge réservée</b> - la quantité de RAM dans la VM, (Ko) réservée par l'hyperviseur pour que la VM fonctionne.  C'est une petite quantité, mais elle doit être disponible sur l'hôte, sinon la VM ne démarrera pas. <br><br>  <b>Ballon</b> - la quantité de RAM (Ko) saisie sur la machine virtuelle à l'aide du pilote de ballon. <br><br>  <b>Compressé</b> - la quantité de RAM (Ko) qui a pu être compressée. <br><br>  <b>Swapped</b> - la quantité de RAM (Ko) qui, par manque de mémoire physique sur le serveur, s'est déplacée sur le disque. <br>  Les compteurs de ballons et autres techniques de récupération de mémoire sont nuls. <br><br>  Voici à quoi ressemble le graphique avec les compteurs de mémoire d'une machine virtuelle fonctionnant normalement avec 150 Go de RAM. <br><br><img src="https://habrastorage.org/webt/0l/pp/w3/0lppw3nz9iqzcnuergtxiseb67s.png"><br><br>  Sur le graphique ci-dessous, la machine virtuelle a des problèmes évidents.  Le graphique montre que pour cette machine virtuelle, toutes les techniques décrites pour travailler avec la RAM ont été utilisées.  Le ballon pour cette machine virtuelle est beaucoup plus grand que consommé.  En fait, la VM est probablement morte que vivante. <br><br><img src="https://habrastorage.org/webt/f4/ic/xk/f4icxkpxpykxua_gp-sirlzuu_u.png"><br><br><h3>  ESXTOP </h3><br>  Comme avec le CPU, si vous voulez évaluer rapidement la situation sur l'hôte, ainsi que sa dynamique avec un intervalle allant jusqu'à 2 secondes, cela vaut la peine d'utiliser ESXTOP. <br><br>  L'écran de mémoire ESXTOP est appelé avec la touche «m» et ressemble à ceci (champs B, D, H, J, K, L, O sélectionnés): <br><br><img src="https://habrastorage.org/webt/rm/wj/4k/rmwj4krvvizdtcizkrid0zjuml8.png"><br><br>  Les paramètres suivants nous intéresseront: <br><br>  <b>Mem overcommit avg</b> - la valeur moyenne d'un sur-abonnement mémoire sur un hôte pendant 1, 5 et 15 minutes.  Si au-dessus de zéro, c'est l'occasion de voir ce qui se passe, mais pas toujours un indicateur de la présence de problèmes. <br><br>  Dans les lignes <b>PMEM / MB</b> et <b>VMKMEM / MB</b> - informations sur la mémoire physique du serveur et la mémoire disponible pour VMkernel.  De l'intéressant ici, vous pouvez voir la valeur minfree (en Mo), l'état de l'hôte de la mémoire (dans notre cas, élevé). <br><br>  Dans la ligne <b>NUMA / MB,</b> vous pouvez voir la répartition de la RAM par NUMA-nœuds (sockets).  Dans cet exemple, la répartition est inégale, ce qui en principe n'est pas très bon. <br><br>  Voici un résumé des statistiques du serveur pour les techniques de récupération de mémoire: <br><br>  <b>PSHARE / MB</b> est les statistiques TPS; <br><br>  <b>SWAP / MB</b> - statistiques sur l'utilisation de Swap; <br><br>  <b>ZIP / MB</b> - statistiques de compression des pages mémoire; <br><br>  <b>MEMCTL / MB</b> - Statistiques d'utilisation du pilote de ballon. <br><br>  Pour les machines virtuelles individuelles, nous pouvons être intéressés par les informations suivantes.  J'ai caché les noms des VM pour ne pas embarrasser le public :).  Si la métrique ESXTOP est la même que le compteur dans vSphere, je cite le compteur correspondant. <br><br>  <b>MEMSZ</b> est la quantité de mémoire configurée sur la machine virtuelle (Mo). <br>  MEMSZ = GRANT + MCTLSZ + SWCUR + intact. <br><br>  <b>SUBVENTION</b> - Accordée en Mo. <br><br>  <b>TCHD</b> - Actif en Mo. <br><br>  <b>MCTL?</b>  - est installé sur VM Balloon Driver. <br><br>  <b>MCTLSZ</b> - Ballon en MB. <br><br>  <b>MCTLGT</b> est la quantité de RAM (Mo) qu'ESXi souhaite supprimer de la machine virtuelle via le pilote de ballon (cible Memctl). <br><br>  <b>MCTLMAX</b> - la quantité maximale de RAM (Mo) qu'ESXi peut supprimer de la machine virtuelle via le pilote de ballon. <br><br>  <b>SWCUR</b> - la quantité actuelle de RAM (Mo) donnée à la machine virtuelle à partir du fichier d'échange. <br><br>  <b>SWGT</b> - la quantité de RAM (Mo) qu'ESXi veut donner aux VM à partir d'un fichier Swap (Swap Target). <br><br>  Également via ESXTOP, vous pouvez voir des informations plus détaillées sur la topologie NUMA VM.  Pour ce faire, sélectionnez les champs D, G: <br><br><img src="https://habrastorage.org/webt/ff/7y/zd/ff7yzdsjedyntnpj4duwv0c731m.png"><br><br>  <b>NHN</b> - nœuds NUMA sur lesquels se trouve la machine virtuelle.  Ici, vous pouvez immédiatement remarquer un vm large qui ne tient pas sur un nœud NUMA. <br><br>  <b>NRMEM</b> - combien de mégaoctets de mémoire la VM prend du nœud NUMA distant. <br><br>  <b>NLMEM</b> - combien de mégaoctets de mémoire la VM prend du nœud NUMA local. <br><br>  <b>N% L</b> - pourcentage de mémoire VM sur le nœud NUMA local (si moins de 80%, des problèmes de performances peuvent survenir). <br><br><h3>  Mémoire sur l'hyperviseur </h3><br>  Si les compteurs CPU sur l'hyperviseur ne sont généralement pas d'un intérêt particulier, alors la situation est inverse avec la mémoire.  Une utilisation élevée de la mémoire sur la machine virtuelle n'indique pas toujours un problème de performances, mais une utilisation élevée de la mémoire sur l'hyperviseur démarre simplement le technicien de gestion de la mémoire et provoque des problèmes avec les performances de la machine virtuelle.  Les alarmes d'utilisation de la mémoire hôte doivent être surveillées et les machines virtuelles ne doivent pas entrer dans Swap. <br><br><img src="https://habrastorage.org/webt/h2/x_/59/h2x_59kddpe84yzudcq03fq1rmc.png"><br><br><img src="https://habrastorage.org/webt/oc/w7/c9/ocw7c9vmbrqogjhmtpbotng4-6y.png"><br><br><h3>  Annuler </h3><br>  Si la machine virtuelle entre dans Swap, ses performances sont considérablement réduites.  Les traces de montgolfière et de compression disparaissent rapidement après l'apparition de RAM libre sur l'hôte, mais la machine virtuelle n'est pas pressée de revenir de Swap à la RAM du serveur. <br>  Avant ESXi 6.0, le seul moyen fiable et rapide de retirer les machines virtuelles de Swap était de redémarrer (plus précisément, d'activer / désactiver le conteneur).  À partir d'ESXi 6.0, un moyen pas si officiel, mais fonctionnel et fiable pour sortir les machines virtuelles de Swap est apparu.  Lors d'une des conférences, j'ai réussi à parler avec l'un des ingénieurs VMware responsable du Planificateur de CPU.  Il a confirmé que la méthode fonctionne et est assez sûre.  D'après notre expérience, aucun problème avec lui n'a également été constaté. <br><br>  Duncan Epping a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">décrit</a> les commandes réelles de sortie des machines virtuelles à partir de Swap.  Je ne répéterai pas la description détaillée, donne juste un exemple de son utilisation.  Comme on peut le voir sur la capture d'écran, un certain temps après l'exécution des commandes Swap spécifiées sur la machine virtuelle disparaît. <br><br><img src="https://habrastorage.org/webt/e5/lm/7e/e5lm7e0e6i_yxrrlm7dfwixptv0.png"><br><br><h3>  Conseils pour gérer la RAM sur ESXi </h3><br>  En conclusion, je vais vous donner quelques conseils pour vous aider à éviter les problèmes de performances des VM dus à la RAM: <br><br><ul><li>  Évitez de sursouscrire en RAM dans les clusters productifs.  Il est toujours conseillé d'avoir environ 20-30% de mémoire libre dans le cluster, afin que DRS (et l'administrateur) ait de la marge de manœuvre, et que les machines virtuelles ne passent pas à Swap pendant la migration.  N'oubliez pas non plus la marge de tolérance aux pannes.  Il est désagréable lorsque, lorsqu'un serveur tombe en panne et que la machine virtuelle est redémarrée à l'aide de HA, certaines machines passent également à Swap. </li><li>  Dans les infrastructures hautement consolidées, essayez de NE PAS créer de machines virtuelles avec plus de la moitié de la mémoire hôte.  Ceci, encore une fois, aidera DRS à distribuer les machines virtuelles entre les serveurs de cluster sans aucun problème.  Cette règle, bien sûr, n'est pas universelle :). </li><li>  Attention à l'alarme d'utilisation de la mémoire de l'hôte. </li><li>  N'oubliez pas de mettre VMware Tools sur la machine virtuelle et de ne pas désactiver la montgolfière. </li><li>  Pensez à activer Inter-VM TPS et à désactiver les grandes pages dans les environnements VDI et de test. </li><li>  Si la machine virtuelle rencontre des problèmes de performances, vérifiez si elle utilise de la mémoire à partir d'un nœud NUMA distant. </li><li>  Retirez les machines virtuelles de Swap le plus rapidement possible!  Entre autres choses, si la VM est en Swap, pour des raisons évidentes, le système de stockage en souffre. </li></ul><br>  C'est tout pour la RAM.  Vous trouverez ci-dessous des articles connexes pour ceux qui souhaitent approfondir les détails.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le prochain article</a> sera consacré à l'histoire. <br><br><div class="spoiler">  <b class="spoiler_title">Liens utiles</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://www.yellow-bricks.com/2015/03/02/what-happens-at-which-vsphere-memory-state/</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://www.yellow-bricks.com/2013/06/14/how-does-mem-minfreepct-work-with-vsphere-5-0-and-up/</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.vladan.fr/vmware-transparent-page-sharing-tps-explained/</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://www.yellow-bricks.com/2016/06/02/memory-pages-swapped-can-unswap/</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://kb.vmware.com/s/article/1002586</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.vladan.fr/what-is-vmware-memory-ballooning/</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://kb.vmware.com/s/article/2080735</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://kb.vmware.com/s/article/2017642</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://labs.vmware.com/vmtj/vmware-esx-memory-resource-management-swap</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://blogs.vmware.com/vsphere/2013/10/understanding-vsphere-active-memory.html</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.vmware.com/support/developer/converter-sdk/conv51_apireference/memory_counters.html</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://docs.vmware.com/en/VMware-vSphere/6.5/vsphere-esxi-vcenter-server-65-monitoring-performance-guide.pdf</a> <br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr455820/">https://habr.com/ru/post/fr455820/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr455802/index.html">Comment assembler l'Olympic par le biais de newsletters par e-mail. Case Black Star</a></li>
<li><a href="../fr455806/index.html">Naissance et mort d'un album: nous comprenons comment les formats musicaux ont changé au cours des 100 dernières années</a></li>
<li><a href="../fr455808/index.html">Obtenez des extraits du registre sur le site Web de FTS en utilisant python</a></li>
<li><a href="../fr455812/index.html">Construire une architecture de microservices sur Golang et gRPC, partie 2 (docker)</a></li>
<li><a href="../fr455816/index.html">Comment créer une action sympa pour Google Assistant. Lifehacks de Just AI</a></li>
<li><a href="../fr455826/index.html">Arrosage automatique télécommandé</a></li>
<li><a href="../fr455828/index.html">Les scientifiques ont découvert de nouvelles formes de synchronisation exotiques</a></li>
<li><a href="../fr455830/index.html">Un regard sur Passer par les yeux d'un développeur .NET. Semaine # 1</a></li>
<li><a href="../fr455832/index.html">Historique d'une seule enquête SQL</a></li>
<li><a href="../fr455834/index.html">Benchmarks pour les serveurs Linux: 5 outils ouverts</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
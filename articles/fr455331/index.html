<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåò üëò ü§üüèø Comment les ordinateurs ont appris √† reconna√Ætre incroyablement bien les images ‚òÅÔ∏è üèÇüèº üì≠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="D'importants travaux scientifiques de 2012 ont transform√© le domaine des logiciels de reconnaissance d'images 


 Aujourd'hui, je peux, par exemple, o...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment les ordinateurs ont appris √† reconna√Ætre incroyablement bien les images</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455331/"><h3>  D'importants travaux scientifiques de 2012 ont transform√© le domaine des logiciels de reconnaissance d'images </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/0d6/b8d/67e/0d6b8d67e771c94acab7f0ed50a54ba4.jpg"><br><br>  Aujourd'hui, je peux, par exemple, ouvrir Google Photos, √©crire ¬´plage¬ª et voir un tas de mes photos des diff√©rentes plages que j'ai visit√©es au cours de la derni√®re d√©cennie.  Et je n'ai jamais sign√© mes photos - Google reconna√Æt les plages sur celles-ci en fonction de leur contenu.  Cette fonctionnalit√© apparemment ennuyeuse est bas√©e sur une technologie appel√©e ¬´r√©seau neuronal convolutionnel profond¬ª, qui permet aux programmes de comprendre les images √† l'aide d'une m√©thode complexe qui n'√©tait pas disponible pour les technologies des g√©n√©rations pr√©c√©dentes. <br><br>  Ces derni√®res ann√©es, les chercheurs ont d√©couvert que la pr√©cision des logiciels s'am√©liore √† mesure qu'ils construisent des r√©seaux neuronaux (NS) plus profonds et les forment sur des ensembles de donn√©es de plus en plus grands.  Cela a cr√©√© un besoin insatiable de puissance de calcul et a enrichi les fabricants de GPU tels que Nvidia et AMD.  Il y a quelques ann√©es, Google a d√©velopp√© ses propres puces sp√©ciales pour l'Assembl√©e nationale, tandis que d'autres entreprises tentent de la suivre. <br><a name="habracut"></a><br>  Chez Tesla, par exemple, Andrei Karpati, un expert du deep learning, a √©t√© nomm√© √† la t√™te du projet Autopilot.  Maintenant, le constructeur automobile d√©veloppe sa propre puce pour acc√©l√©rer le travail de la NS dans les futures versions du pilote automatique.  Ou prenez Apple: les puces A11 et A12, centrales des derniers iPhones, ont un " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">processeur neuronal</a> " Neural Engine qui acc√©l√®re le NS et permet aux applications de reconnaissance d'image et de voix de mieux fonctionner. <br><br>  Les experts que j'ai interview√©s pour cet article suivent le d√©but du boom de l'apprentissage en profondeur pour un travail sp√©cifique: AlexNet, du nom de l'auteur principal, Alex Krizhevsky.  ¬´Je crois que 2012 a √©t√© une ann√©e marquante lorsque le travail d'AlexNet est sorti¬ª, a d√©clar√© Sean Gerrish, expert en d√©fense et auteur du livre ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">How Smart Cars Think</a> ¬ª. <br><br>  Jusqu'en 2012, les r√©seaux de neurones profonds (GNS) √©taient un peu un remous dans le monde de la r√©gion de Moscou.  Mais Krizhevsky et ses coll√®gues de l'Universit√© de Toronto ont ensuite particip√© au prestigieux concours de reconnaissance d'image, et leur programme a d√©pass√© de fa√ßon spectaculaire en pr√©cision tout ce qui a √©t√© d√©velopp√© avant lui.  Presque instantan√©ment, STS est devenu la technologie de pointe en mati√®re de reconnaissance d'image.  D'autres chercheurs utilisant cette technologie ont rapidement d√©montr√© de nouvelles am√©liorations de la pr√©cision de reconnaissance. <br><br>  Dans cet article, nous allons approfondir l'apprentissage en profondeur.  Je vais expliquer ce qu'est NS, comment ils sont form√©s et pourquoi ils ont besoin de telles ressources informatiques.  Et puis je vais expliquer pourquoi un certain type de NS - les r√©seaux de convolution profonde - comprennent si bien les images.  Ne vous inqui√©tez pas, il y aura beaucoup de photos. <br><br><h2>  Un exemple simple avec un neurone </h2><br>  Le concept de ¬´r√©seau neuronal¬ª peut vous sembler vague, alors commen√ßons par un exemple simple.  Supposons que vous vouliez que l'Assembl√©e nationale d√©cide de conduire une voiture en fonction des feux de circulation verts, jaunes et rouges.  NS peut r√©soudre ce probl√®me avec un seul neurone. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c00/2d0/dda/c002d0dda45d5fef70ab7a156ad8e7cd.png"><br><br>  Un neurone re√ßoit des donn√©es d'entr√©e (1 - activ√©, 0 - d√©sactiv√©), multiplie par le poids appropri√© et additionne toutes les valeurs des poids.  Ensuite, le neurone ajoute un d√©calage qui d√©finit la valeur de seuil pour "l'activation" du neurone.  Dans ce cas, si la sortie est positive, nous pensons que le neurone s'est activ√© - et vice versa.  Le neurone √©quivaut √† l'in√©galit√© "vert - rouge - 0,5&gt; 0".  Si cela s'av√®re vrai - c'est-√†-dire que le vert est allum√© et que le rouge n'est pas allum√© - alors la voiture devrait partir. <br><br>  Dans la vraie NS, les neurones artificiels font un autre pas.  En additionnant une entr√©e pond√©r√©e et en ajoutant un d√©calage, le neurone utilise une fonction d'activation non lin√©aire.  Souvent utilis√©e est une sigmo√Øde, une fonction en forme de S, donnant toujours une valeur de 0 √† 1. <br><br>  L'utilisation de la fonction d'activation ne changera pas le r√©sultat de notre mod√®le de feu de signalisation simple (nous avons juste besoin d'utiliser une valeur de seuil de 0,5, pas de 0).  Mais la non-lin√©arit√© des fonctions d'activation est n√©cessaire pour que les NS mod√©lisent des fonctions plus complexes.  Sans la fonction d'activation, chaque NS arbitrairement complexe est r√©duit √† une combinaison lin√©aire de donn√©es d'entr√©e.  Une fonction lin√©aire ne peut pas simuler des ph√©nom√®nes complexes dans le monde r√©el.  La fonction d'activation non lin√©aire permet au NS d'approximer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">n'importe quelle fonction math√©matique</a> . <br><br><h2>  Exemple de r√©seau </h2><br>  Bien s√ªr, il existe de nombreuses fa√ßons d'approximer une fonction.  NS se d√©marque par le fait que nous savons les ¬´former¬ª √† l'aide d'une petite alg√®bre, d'un tas de donn√©es et d'une mer de puissance de calcul.  Au lieu que le programmeur d√©veloppe directement NS pour une t√¢che sp√©cifique, nous pouvons cr√©er un logiciel qui commence par un NS assez g√©n√©ral, √©tudie un tas d'exemples balis√©s, puis modifie le NS afin qu'il donne l'√©tiquette correcte pour autant d'exemples que possible.  On s'attend √† ce que la NS finale r√©sume les donn√©es et produise les √©tiquettes correctes pour les exemples qui n'√©taient pas auparavant dans la base de donn√©es. <br><br>  Le processus menant √† cet objectif a commenc√© bien avant AlexNet.  En 1986, un trio de chercheurs a publi√© un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ouvrage de r√©f√©rence</a> sur la r√©tropropagation, une technologie qui a contribu√© √† faire de l'apprentissage math√©matique de SN complexes une r√©alit√©. <br><br>  Pour imaginer comment fonctionne la r√©tropropagation, regardons une simple NS d√©crite par Michael Nielsen dans son excellent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">manuel GO en ligne</a> .  Le but du r√©seau est de traiter l'image d'un nombre manuscrit dans une r√©solution de 28x28 pixels et de d√©terminer correctement si le nombre 0, 1, 2, etc. est √©crit. <br><br>  Chaque image est de 28 * 28 = 784 quantit√©s d'entr√©e, dont chacune est un nombre r√©el de 0 √† 1, indiquant combien le pixel est clair ou sombre.  Nielsen a cr√©√© l'AN de ce type: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fbf/85e/fe1/fbf85efe11ae6dc62ccd0257e2325229.png"><br><br>  Chaque cercle au centre et dans la colonne de droite est un neurone similaire √† celui que nous avons examin√© dans la section pr√©c√©dente.  Chaque neurone prend une moyenne pond√©r√©e de l'entr√©e, ajoute un d√©calage et applique une fonction d'activation.  Les cercles de gauche ne sont pas des neurones, ils repr√©sentent les donn√©es d'entr√©e du r√©seau.  Et bien que l'image ne montre que 8 cercles d'entr√©e, en fait, il y en a 784 - un pour chaque pixel. <br><br>  Chacun des 10 neurones de droite doit ¬´d√©clencher¬ª son propre num√©ro: le premier doit s'allumer lorsqu'un 0 manuscrit est entr√© (et seulement dans ce cas), le second lorsque le r√©seau voit un 1 manuscrit (et seulement lui), et ainsi de suite. <br><br>  Chaque neurone per√ßoit l'entr√©e de chaque neurone de la couche pr√©c√©dente.  Ainsi, chacun des 15 neurones du milieu re√ßoit 784 valeurs d'entr√©e.  Chacun de ces 15 neurones a un param√®tre de poids pour chacune des 784 valeurs d'entr√©e.  Cela signifie que seule cette couche a 15 * 784 = 11 760 param√®tres de poids.  De m√™me, la couche de sortie contient 10 neurones, chacun recevant une entr√©e des 15 neurones de la couche interm√©diaire, ce qui ajoute 15 * 10 = 150 param√®tres de poids suppl√©mentaires.  De plus, le r√©seau poss√®de 25 variables de d√©placement - une pour chacun des 25 neurones. <br><br><h2>  Formation au r√©seau de neurones </h2><br>  Le but de la formation est d'affiner ces 11 935 param√®tres afin de maximiser la probabilit√© que le neurone de sortie souhait√© - et seulement lui - soit activ√© lorsque les r√©seaux donnent une image d'un chiffre manuscrit.  Nous pouvons le faire avec l'ensemble d'images bien connu MNIST, o√π il y a 60 000 images marqu√©es avec une r√©solution de 28x28 pixels. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/16d/dab/2ee/16ddab2ee3bcd9e22d96f267e473a2f4.png"><br>  <i>160 images sur 60 000 de l'ensemble MNIST</i> <br><br>  Nielsen montre comment former un r√©seau en utilisant 74 lignes de code Python standard - sans aucune biblioth√®que pour MO.  L'apprentissage commence par le choix de valeurs al√©atoires pour chacun de ces 11 935 param√®tres, poids et d√©calages.  Ensuite, le programme passe par des exemples d'images, en passant par deux √©tapes avec chacune d'elles: <br><ol><li>  L'√©tape de propagation directe calcule la sortie du r√©seau sur la base de l'image d'entr√©e et des param√®tres actuels. </li><li>  L'√©tape de r√©tropropagation calcule l'√©cart du r√©sultat par rapport aux donn√©es de sortie correctes et modifie les param√®tres du r√©seau afin d'am√©liorer l√©g√®rement son efficacit√© dans cette image. </li></ol><br><br>  Un exemple.  Disons que le r√©seau a re√ßu l'image suivante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e22/129/af7/e22129af76f6376aaa204ae02164a790.png"><br><br>  S'il est bien calibr√©, alors la broche ¬´7¬ª devrait aller √† 1, et les neuf autres conclusions devraient aller √† 0. Mais, disons qu'√† la place, le r√©seau √† la sortie ¬´0¬ª donne une valeur de 0,8.  C'est trop!  L'algorithme d'apprentissage modifie les poids d'entr√©e du neurone responsable de ¬´0¬ª afin qu'il se rapproche de 0 lors du prochain traitement de cette image. <br><br>  Pour cela, l'algorithme de r√©tropropagation calcule un gradient d'erreur pour chaque poids d'entr√©e.  Il s'agit d'une mesure de la fa√ßon dont l'erreur de sortie changera pour un changement donn√© de poids d'entr√©e.  Ensuite, l'algorithme utilise le gradient pour d√©cider de la quantit√© √† modifier pour chaque poids d'entr√©e - plus le gradient est grand, plus le changement est fort. <br><br>  En d'autres termes, le processus de formation ¬´forme¬ª les neurones de la couche de sortie √† pr√™ter moins d'attention aux entr√©es (neurones de la couche interm√©diaire) qui les poussent √† la mauvaise r√©ponse, et plus aux entr√©es qui poussent dans la bonne direction. <br><br>  L'algorithme r√©p√®te cette √©tape pour tous les autres neurones de sortie.  Il r√©duit les poids d'entr√©e pour les neurones "1", "2", "3", "4", "5", "6", "8" et "9" (mais pas "7") afin d'abaisser la valeur de ceux-ci neurones de sortie.  Plus la valeur de sortie est √©lev√©e, plus le gradient de l'erreur de sortie est important par rapport au poids d'entr√©e - et plus son poids diminue. <br><br>  Et vice versa, l'algorithme augmente le poids des donn√©es d'entr√©e pour la sortie "7", ce qui fait que le neurone produira une valeur plus √©lev√©e la prochaine fois qu'on lui donnera cette image.  Encore une fois, les entr√©es avec des valeurs plus √©lev√©es augmenteront davantage les poids, ce qui fera que le neurone de sortie ¬´7¬ª accordera plus d'attention √† ces entr√©es la prochaine fois. <br><br>  Ensuite, l'algorithme devrait effectuer les m√™mes calculs pour la couche interm√©diaire: modifiez chaque poids d'entr√©e dans une direction qui r√©duira les erreurs de r√©seau - encore une fois, en rapprochant la sortie ¬´7¬ª de 1, et le reste √† 0. Mais chaque neurone interm√©diaire a une connexion avec tous les 10 jours de cong√©, ce qui complique les choses sous deux aspects. <br><br>  Premi√®rement, le gradient d'erreur pour chaque neurone moyen d√©pend non seulement de la valeur d'entr√©e, mais √©galement des gradients d'erreur dans la couche suivante.  L'algorithme est appel√© r√©tropropagation car les gradients d'erreur des couches ult√©rieures du r√©seau se propagent dans la direction oppos√©e et sont utilis√©s pour calculer les gradients dans les couches pr√©c√©dentes. <br><br>  De plus, chaque neurone interm√©diaire est une entr√©e pour les dix jours de cong√©.  Par cons√©quent, l'algorithme d'apprentissage doit calculer le gradient d'erreur, qui refl√®te la fa√ßon dont un changement dans un certain poids d'entr√©e affecte l'erreur moyenne pour toutes les sorties. <br><br>  La r√©tropropagation est un algorithme de mont√©e d'une colline: chaque passe rapproche les valeurs de sortie des valeurs correctes pour une image donn√©e, mais seulement d'un peu.  Plus l'algorithme examine d'exemples, plus il grimpe la colline vers l'ensemble optimal de param√®tres qui classent correctement le nombre maximal d'exemples d'entra√Ænement.  Pour atteindre une grande pr√©cision, des milliers d'exemples sont n√©cessaires, et l'algorithme peut avoir besoin de parcourir chaque image dans cet ensemble des dizaines de fois avant que son efficacit√© ne cesse de cro√Ætre. <br><br>  Nielsen montre comment impl√©menter ces 74 lignes en python.  √âtonnamment, un r√©seau form√© avec un programme aussi simple peut reconna√Ætre plus de 95% des num√©ros manuscrits de la base de donn√©es MNIST.  Gr√¢ce √† des am√©liorations suppl√©mentaires, un simple r√©seau √† deux couches peut reconna√Ætre plus de 98% des nombres. <br><br><h2>  Perc√©e AlexNet </h2><br>  Vous pourriez penser que le d√©veloppement du th√®me de la r√©tropropagation √©tait cens√© avoir lieu dans les ann√©es 1980 et donner lieu √† des progr√®s rapides au sein du minist√®re de la D√©fense bas√© sur l'Assembl√©e nationale - mais cela ne s'est pas produit.  Dans les ann√©es 1990 et au d√©but des ann√©es 2000, certaines personnes travaillaient sur cette technologie, mais l'int√©r√™t pour l'Assembl√©e nationale n'a pris de l'ampleur qu'au d√©but des ann√©es 2010. <br><br>  Cela peut √™tre retrac√© au <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">concours ImageNet</a> , un concours annuel de MO organis√© par Stanford Fay Fay Lee, un sp√©cialiste des TI.  Chaque ann√©e, les concurrents re√ßoivent le m√™me ensemble de plus d'un million d'images pour la formation, chacune √©tant manuellement √©tiquet√©e dans des cat√©gories de plus de 1000 - de ¬´camion de pompier¬ª et ¬´champignon¬ª √† ¬´gu√©pard¬ª.  Le logiciel des participants est jug√© sur la possibilit√© de classer d'autres images qui n'√©taient pas dans l'ensemble.  Un programme peut donner quelques suppositions, et son travail est consid√©r√© comme r√©ussi si au moins l'une des cinq premi√®res suppositions correspond √† la note donn√©e par une personne. <br><br>  La comp√©tition a commenc√© en 2010 et les NS profondes n'y ont pas jou√© un grand r√¥le au cours des deux premi√®res ann√©es.  Les meilleures √©quipes ont utilis√© diff√©rentes techniques de MO et ont obtenu des r√©sultats assez moyens.  En 2010, l'√©quipe a gagn√© avec un pourcentage d'erreurs √©gal √† 28. En 2011 - avec une erreur de 25%. <br><br>  Et puis est venu 2012.  Une √©quipe de l'Universit√© de Toronto a fait une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">offre</a> - plus tard surnomm√©e AlexNet en l'honneur de l'auteur principal, Alex Krizhevsky - et a laiss√© les rivaux loin derri√®re.  √Ä l'aide de NS profonds, l'√©quipe a atteint un taux d'erreur de 16%.  Pour le concurrent le plus proche, ce chiffre √©tait de 26. <br><br>  Le NS d√©crit dans l'article pour la reconnaissance de l'√©criture manuscrite a deux couches, 25 neurones et pr√®s de 12 000 param√®tres.  AlexNet √©tait beaucoup plus grand et plus complexe: huit couches entra√Æn√©es, 650 000 neurones et 60 millions de param√®tres. <br><br>  Une puissance de traitement √©norme est requise pour former des NS de cette taille, et AlexNet a √©t√© con√ßu pour tirer parti de la parall√©lisation massive disponible avec les GPU modernes.  Les chercheurs ont compris comment diviser le travail de formation du r√©seau en deux GPU, ce qui a doubl√© la puissance.  Et pourtant, malgr√© l'optimisation serr√©e, la formation r√©seau a pris 5-6 jours sur le mat√©riel disponible en 2012 (sur une paire de Nvidia GTX 580 avec 3 Go de m√©moire). <br><br>  Il est utile d'√©tudier des exemples des r√©sultats d'AlexNet pour comprendre la gravit√© de cette perc√©e.  Voici une image d'un article scientifique qui montre des exemples d'images et les cinq premi√®res suppositions du r√©seau par leur classification: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d36/1ee/3b6/d361ee3b61cc19de787edda63d6e1e65.png"><br><br>  AlexNet a pu reconna√Ætre la tique dans la premi√®re image, bien qu'il n'y ait qu'une petite forme dans le coin.  Le logiciel a non seulement correctement identifi√© le l√©opard, mais a √©galement donn√© d'autres options proches - un jaguar, un gu√©pard, un l√©opard des neiges, un Mau √©gyptien.  AlexNet a √©tiquet√© la photo de charme comme "agaric".  Juste "champignon" √©tait la deuxi√®me version du r√©seau. <br><br>  Les "erreurs" d'AlexNet sont √©galement impressionnantes.  Elle a marqu√© la photo avec un Dalmatien debout derri√®re un tas de cerises comme ¬´Dalmatien¬ª, bien que l'√©tiquette officielle soit ¬´cerise¬ª.  AlexNet a reconnu qu'il y avait une sorte de baie sur la photo - parmi les cinq premi√®res options √©taient ¬´raisins¬ª et ¬´sureau¬ª - il n'a tout simplement pas reconnu la cerise.  Sur une photo d'un l√©murien de Madagascar assis sur un arbre, AlexNet a donn√© une liste de petits mammif√®res vivant sur des arbres.  Je pense que beaucoup de gens (y compris moi-m√™me) auraient mis la mauvaise signature ici. <br><br>  La qualit√© du travail √©tait impressionnante et a d√©montr√© que le logiciel est capable de reconna√Ætre des objets ordinaires dans un large √©ventail d'orientations et d'environnements.  Le GNS est rapidement devenu la technique la plus populaire pour la reconnaissance d'image, et depuis lors, le monde de MO ne l'a pas abandonn√©e. <br><br>  ¬´Dans le sillage du succ√®s de la m√©thode bas√©e sur GO 2012, la plupart des concurrents de 2013 sont pass√©s √† des r√©seaux neuronaux convolutionnels profonds¬ª, ont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©crit les</a> sponsors d'ImageNet.  Au cours des ann√©es suivantes, cette tendance s'est poursuivie et les gagnants ont ensuite travaill√© sur la base de technologies de base, appliqu√©es pour la premi√®re fois par l'√©quipe AlexNet.  En 2017, les concurrents, utilisant des NS plus profondes, ont s√©rieusement r√©duit le taux d'erreur √† moins de trois.  Compte tenu de la complexit√© de la t√¢che, les ordinateurs ont dans une certaine mesure appris √† la r√©soudre mieux que de nombreuses personnes. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/433/872/5e1/4338725e10f14ecf679878fb267394c9.png"><br>  <i>Le pourcentage d'erreurs dans la classification des images au cours des diff√©rentes ann√©es</i> <br><br><h2>  R√©seaux de convolution: un concept </h2><br>  Techniquement, AlexNet √©tait un NS convolutionnel.  Dans cette section, j'expliquerai ce que fait le r√©seau neuronal convolutif (SNA), et pourquoi cette technologie est devenue d'une importance cruciale pour les algorithmes de reconnaissance de formes modernes. <br><br>  Le r√©seau simple discut√© pr√©c√©demment pour la reconnaissance de l'√©criture manuscrite √©tait compl√®tement connect√©: chaque neurone de la premi√®re couche √©tait une entr√©e pour chaque neurone de la deuxi√®me couche.  Une telle structure fonctionne assez bien sur des t√¢ches simples avec reconnaissance des nombres dans les images 28x28 pixels.  Mais cela ne se modifie pas bien. <br><br>  Dans la base de donn√©es de chiffres manuscrits du MNIST, tous les caract√®res sont centr√©s.  Cela simplifie consid√©rablement l'apprentissage, car, disons, les sept auront toujours plusieurs pixels sombres en haut et √† droite, et le coin inf√©rieur gauche est toujours blanc.  Z√©ro aura presque toujours une tache blanche au milieu et des pixels sombres sur les bords.  Un r√©seau simple et enti√®rement connect√© peut reconna√Ætre de tels mod√®les assez facilement. <br><br>  Mais supposons que vous vouliez cr√©er un NS capable de reconna√Ætre des nombres qui peuvent √™tre situ√©s n'importe o√π sur une image plus grande.  Un r√©seau enti√®rement connect√© ne fonctionnera pas aussi bien avec cette t√¢che, car il n'a pas de moyen efficace de reconna√Ætre des fonctionnalit√©s similaires dans des formulaires situ√©s dans diff√©rentes parties de l'image.  Si, dans votre jeu de donn√©es d'entra√Ænement, la plupart des sept sont situ√©s dans le coin sup√©rieur gauche, votre r√©seau reconna√Ætra mieux les sept dans le coin sup√©rieur gauche que dans toute autre partie de l'image. <br><br>  Th√©oriquement, ce probl√®me peut √™tre r√©solu en s'assurant que votre jeu poss√®de de nombreux exemples de chaque chiffre dans chacune des positions possibles.  Mais en pratique, ce sera un √©norme gaspillage de ressources.  Avec l'augmentation de la taille de l'image et de la profondeur du r√©seau, le nombre de liens - et le nombre de param√®tres de poids - augmentera de mani√®re explosive.  Vous aurez besoin de beaucoup plus d'images d'entra√Ænement (et de puissance de calcul) pour obtenir une pr√©cision ad√©quate. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lorsqu'un r√©seau de neurones apprend √† reconna√Ætre une forme situ√©e √† un endroit d'une image, il doit √™tre capable d'appliquer ces connaissances pour reconna√Ætre la m√™me forme dans d'autres parties de l'image. SNA fournit une solution √©l√©gante √† ce probl√®me. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"C'est comme si vous preniez un pochoir et le fixiez √† tous les endroits de l'image", a d√©clar√© le chercheur en IA Jai Teng. - Vous avez un pochoir avec une photo d'un chien, et vous le fixez d'abord dans le coin sup√©rieur droit de l'image pour voir s'il y a un chien l√†-bas? Sinon, vous d√©placez un peu le pochoir. Et donc pour l'image enti√®re. Peu importe o√π est l'image du chien. Le pochoir correspondra √† elle. Vous n'avez pas besoin que chaque partie du r√©seau apprenne sa propre classification des chiens. ¬ª</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Imaginez que nous prenions une grande image et la divisions en carr√©s de 28 x 28 pixels. </font><font style="vertical-align: inherit;">Ensuite, nous pourrons alimenter chaque carr√© d'un r√©seau enti√®rement connect√© qui reconna√Æt l'√©criture que nous avons √©tudi√©e auparavant. </font><font style="vertical-align: inherit;">Si la sortie "7" est d√©clench√©e dans au moins un des carr√©s, ce sera un signe qu'il y a un sept dans l'image enti√®re. </font><font style="vertical-align: inherit;">C'est exactement ce que font les r√©seaux convolutifs.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fonctionnement des r√©seaux convolutionnels dans AlexNet </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans les r√©seaux convolutifs, ces ¬´pochoirs¬ª sont appel√©s d√©tecteurs de caract√©ristiques et la zone qu'ils √©tudient est connue sous le nom de champ r√©cepteur. Les vrais d√©tecteurs de caract√©ristiques fonctionnent avec des champs beaucoup plus petits qu'un carr√© avec un c√¥t√© de 28 pixels. Dans AlexNet, les d√©tecteurs de caract√©ristiques de la premi√®re couche convolutive fonctionnaient avec un champ r√©cepteur de 11 x 11 pixels. Dans les couches suivantes, les champs r√©cepteurs avaient une largeur de 3 √† 5 unit√©s. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Au cours de la travers√©e, le d√©tecteur de signes de l'image d'entr√©e produit une carte des signes: un r√©seau bidimensionnel, sur lequel on note la force d'activation du d√©tecteur dans diff√©rentes parties de l'image. Les couches convolutives ont g√©n√©ralement plus d'un d√©tecteur, et chacune d'elles scanne l'image √† la recherche de motifs diff√©rents. AlexNet avait 96 d√©tecteurs de fonctionnalit√©s sur la premi√®re couche, distribuant 96 cartes de fonctionnalit√©s.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/94f/1a0/c3d/94f1a0c3deacf7903606f4ecaf040b20.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour mieux comprendre cela, consid√©rez une repr√©sentation visuelle des mod√®les √©tudi√©s par chacun des 96 d√©tecteurs de premi√®re couche AlexNet apr√®s avoir form√© le r√©seau. Il existe des d√©tecteurs √† la recherche de lignes horizontales ou verticales, de transitions du clair au sombre, de motifs d'√©checs et de nombreuses autres formes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une image en couleur est g√©n√©ralement repr√©sent√©e comme une carte de pixels avec trois nombres pour chaque pixel: la valeur du rouge, du vert et du bleu. La premi√®re couche d'AlexNet prend cette vue et la transforme en vue utilisant 96 nombres. Chaque ¬´pixel¬ª de cette image a 96 valeurs, une pour chaque d√©tecteur de caract√©ristiques. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans cet exemple, la premi√®re des 96 valeurs indique si un point de l'image correspond √† ce mod√®le:</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/260/3fa/933/2603fa9332cbf509d9afd9dc1870e53a.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La deuxi√®me valeur indique si un point d'image co√Øncide avec un tel motif: </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a0b/736/b01/a0b736b01ab683e1dfbd229e29904500.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La troisi√®me valeur indique si un point d'image co√Øncide avec un tel motif: </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/bd9/a72/09c/bd9a7209cb808f24e18d54327974a0e7.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et ainsi de suite pour 93 d√©tecteurs d'entit√©s dans la premi√®re couche AlexNet. La premi√®re couche produit une nouvelle repr√©sentation de l'image, o√π chaque pixel est un vecteur en 96 dimensions (j'expliquerai plus tard que cette repr√©sentation est r√©duite de 4 fois). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il s'agit de la premi√®re couche d'AlexNet. Ensuite, il y a quatre autres couches convolutives, chacune prenant la sortie de la pr√©c√©dente comme entr√©e.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comme nous l'avons vu, la premi√®re couche r√©v√®le des motifs de base, tels que des lignes horizontales et verticales, des transitions de la lumi√®re √† l'obscurit√© et des courbes. Le deuxi√®me niveau les utilise comme √©l√©ment de base pour reconna√Ætre des formes l√©g√®rement plus complexes. Par exemple, la deuxi√®me couche pourrait avoir un d√©tecteur d'entit√©s qui trouve des cercles en utilisant une combinaison des sorties des d√©tecteurs d'entit√©s de la premi√®re couche qui trouvent des courbes. La troisi√®me couche trouve des formes encore plus complexes en combinant les fonctionnalit√©s de la deuxi√®me couche. Les quatri√®me et cinqui√®me trouvent des motifs encore plus complexes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les chercheurs Matthew Zeiler et Rob Fergus ont publi√© un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">excellent travail</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> en 2014 </font><font style="vertical-align: inherit;">, qui fournit des moyens tr√®s utiles pour visualiser les mod√®les reconnus par un r√©seau neuronal √† cinq couches similaire √† ImageNet.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans le diaporama suivant tir√© de leur travail, chaque image, sauf la premi√®re, a deux moiti√©s. Sur la droite, vous verrez des exemples de vignettes qui ont fortement activ√© un d√©tecteur de fonction particulier. Ils sont collect√©s en neuf - et chaque groupe correspond √† son propre d√©tecteur. √Ä gauche, une carte montrant exactement quels pixels de cette miniature sont les plus responsables de la correspondance. Cela est particuli√®rement √©vident sur la cinqui√®me couche, car il existe des d√©tecteurs de caract√©ristiques qui r√©agissent fortement aux chiens, aux logos, aux roues, etc. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a2c/beb/74e/a2cbeb74e2f71a9b1b84fbea587294b2.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La premi√®re couche - motifs et formes simples. La </font></font></i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/701/ebd/501/701ebd5013d881b6892c66c3fb63d77f.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">deuxi√®me couche - de petites structures commencent √† appara√Ætre. Les </font></font></i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/34d/283/91a/34d28391a4bb2d0804e15d12992208ba.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">d√©tecteurs d'entit√©s sur la troisi√®me couche peuvent reconna√Ætre des formes plus complexes, telles que des roues de voiture, des nids d'abeilles et m√™me des silhouettes de personnes</font></font></i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/41a/ee2/cb6/41aee2cb61324edc33313a0b01c874b5.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La quatri√®me couche est capable de distinguer des formes complexes, telles que les visages de chiens ou les pattes d'oiseaux. </font></font></i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/04b/96a/baa/04b96abaa00cf8ed2dcb994d56a5af3f.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La cinqui√®me couche peut reconna√Ætre des formes tr√®s complexes.</font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> En regardant les images, vous pouvez voir comment chaque couche suivante est capable de reconna√Ætre des motifs de plus en plus complexes. La premi√®re couche reconna√Æt des motifs simples qui ne ressemblent √† rien. Le second reconna√Æt les textures et les formes simples. Par la troisi√®me couche, des formes reconnaissables telles que des roues et des sph√®res rouge-orange (tomates, coccinelles, autre chose) deviennent visibles.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans la premi√®re couche, le c√¥t√© du champ r√©cepteur est de 11 et dans les derniers, de trois √† cinq. Mais rappelez-vous que les calques ult√©rieurs reconnaissent les cartes d'entit√©s g√©n√©r√©es par les calques ant√©rieurs, de sorte que chacun de leurs ¬´pixels¬ª d√©signe plusieurs pixels de l'image d'origine. Par cons√©quent, le champ r√©cepteur de chaque couche comprend une partie plus grande de la premi√®re image que les couches pr√©c√©dentes. C'est en partie la raison pour laquelle les miniatures dans les calques ult√©rieurs semblent plus complexes que dans les pr√©c√©dentes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La cinqui√®me, derni√®re couche du r√©seau est capable de reconna√Ætre une gamme impressionnante d'√©l√©ments. Par exemple, regardez cette image que j'ai s√©lectionn√©e dans le coin sup√©rieur droit de l'image correspondant au cinqui√®me calque:</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/e82/3fb/895/e823fb8956c1b12d92b32607c41837ec.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les neuf images sur la droite peuvent ne pas se ressembler. Mais si vous regardez les neuf cartes thermiques sur la gauche, vous verrez que ce d√©tecteur de fonctionnalit√© ne se concentre pas sur les objets au premier plan des photos. Au lieu de cela, il se concentre sur l'herbe √† l'arri√®re-plan de chacun d'eux! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De toute √©vidence, un d√©tecteur d'herbe est utile si l'une des cat√©gories que vous essayez d'identifier est ¬´herbe¬ª, mais il peut √™tre utile pour de nombreuses autres cat√©gories. Apr√®s cinq couches convolutives, AlexNet a trois couches compl√®tement connect√©es, comme notre r√©seau pour la reconnaissance de l'√©criture manuscrite. Ces couches examinent chacune des cartes d'entit√©s √©mises par cinq couches convolutives, essayant de classer l'image dans l'une des 1000 cat√©gories possibles.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Donc, s'il y a de l'herbe en arri√®re-plan, alors avec une forte probabilit√©, il y aura un animal sauvage dans l'image. </font><font style="vertical-align: inherit;">En revanche, s'il y a de l'herbe √† l'arri√®re-plan, il est moins probable qu'il s'agisse d'une image de mobilier dans la maison. </font><font style="vertical-align: inherit;">Ces d√©tecteurs de caract√©ristiques de la cinqui√®me couche et d'autres fournissent une tonne d'informations sur le contenu probable de la photo. </font><font style="vertical-align: inherit;">Les derni√®res couches du r√©seau synth√©tisent ces informations afin de fournir une estimation factuelle de ce qui est g√©n√©ralement repr√©sent√© sur l'image.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ce qui rend les couches convolutives diff√©rentes: les poids d'entr√©e communs </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons vu que les d√©tecteurs de caract√©ristiques sur les couches convolutives montrent une reconnaissance de formes impressionnante, mais jusqu'√† pr√©sent, je n'ai pas expliqu√© comment les r√©seaux convolutifs fonctionnent r√©ellement. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La couche convolutionnelle (SS) est constitu√©e de neurones. Ils, comme tous les neurones, prennent une moyenne pond√©r√©e √† l'entr√©e et utilisent la fonction d'activation. Les param√®tres sont entra√Æn√©s √† l'aide de techniques de r√©tropropagation. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais, contrairement aux NS pr√©c√©dents, le SS n'est pas enti√®rement connect√©. Chaque neurone re√ßoit l'entr√©e d'une petite fraction des neurones de la couche pr√©c√©dente. Et, surtout, les neurones de r√©seau convolutionnels ont des poids d'entr√©e communs.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Examinons plus en d√©tail le premier neurone du premier AlexNet SS. Le champ r√©cepteur de cette couche mesure 11x11 pixels, de sorte que le premier neurone examine un carr√© de 11x11 pixels dans un coin de l'image. Ce neurone re√ßoit une entr√©e de ces 121 pixels, et chaque pixel a trois valeurs - rouge, vert et bleu. Par cons√©quent, en g√©n√©ral, le neurone a 363 param√®tres d'entr√©e. Comme tout neurone, celui-ci prend une moyenne pond√©r√©e de 363 param√®tres, et leur applique une fonction d'activation. Et, comme les param√®tres d'entr√©e sont 363, les param√®tres de poids ont √©galement besoin de 363.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le deuxi√®me neurone de la premi√®re couche est similaire au premier. Il √©tudie √©galement les carr√©s de 11x11 pixels, mais son champ r√©cepteur est d√©cal√© de quatre pixels par rapport au premier. Les deux champs ont un chevauchement de 7 pixels, de sorte que le r√©seau ne perd pas de vue les motifs int√©ressants qui sont tomb√©s √† la jonction de deux carr√©s. Le deuxi√®me neurone prend √©galement 363 param√®tres d√©crivant le carr√© 11x11, multiplie chacun d'eux en poids, ajoute et applique la fonction d'activation. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais au lieu d'utiliser un ensemble distinct de 363 poids, le deuxi√®me neurone utilise les m√™mes poids que le premier. Le pixel sup√©rieur gauche du premier neurone utilise les m√™mes poids que le pixel sup√©rieur gauche du second. Par cons√©quent, les deux neurones recherchent le m√™me sch√©ma; leurs champs r√©cepteurs sont simplement d√©cal√©s de 4 pixels les uns par rapport aux autres.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Naturellement, il y a plus de deux neurones: dans le r√©seau 55x55, il y a 3025 neurones. Chacun d'eux utilise le m√™me ensemble de 363 poids que les deux premiers. Ensemble, tous les neurones forment un d√©tecteur de caract√©ristiques qui "scanne" l'image pour le motif souhait√©, qui peut √™tre situ√© n'importe o√π. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">N'oubliez pas que la premi√®re couche AlexNet poss√®de 96 d√©tecteurs de caract√©ristiques. Les 3025 neurones que je viens de mentionner constituent l'un de ces 96 d√©tecteurs. Chacun des 95 restants est un groupe distinct de 3025 neurones. Chaque groupe de 3025 neurones utilise un ensemble commun de 363 poids - cependant, pour chacun des 95 groupes, il poss√®de le sien.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les HF sont form√©s en utilisant la m√™me r√©tropropagation que celle utilis√©e pour les r√©seaux enti√®rement connect√©s, mais la structure convolutionnelle rend le processus d'apprentissage plus efficace et efficient. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"L'utilisation de la convolution aide vraiment - les param√®tres peuvent √™tre r√©utilis√©s", a d√©clar√© Sean Gerrish, un expert en d√©fense et autorisation. </font><font style="vertical-align: inherit;">Cela r√©duit consid√©rablement le nombre de poids d'entr√©e que le r√©seau doit apprendre, ce qui lui permet de produire de meilleurs r√©sultats avec moins d'exemples de formation. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'apprentissage d'une partie de l'image permet une meilleure reconnaissance du m√™me motif dans d'autres parties de l'image. </font><font style="vertical-align: inherit;">Cela permet au r√©seau d'atteindre des performances √©lev√©es sur un nombre beaucoup plus faible d'exemples de formation.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Les gens ont rapidement r√©alis√© la puissance des r√©seaux convolutionnels profonds. </font></font></h2><br>  Le travail d'AlexNet est devenu une sensation dans la communaut√© universitaire de la r√©gion de Moscou, mais son importance a √©t√© rapidement comprise dans l'industrie informatique.  Google √©tait particuli√®rement int√©ress√© par elle. <br><br>  En 2013, Google a acquis une startup fond√©e par les auteurs AlexNet.  La soci√©t√© a utilis√© cette technologie pour ajouter une nouvelle fonction de recherche de photos √† Google Photos.  "Nous avons pris la recherche avanc√©e et l'avons mise en service un peu plus de six mois plus tard", a √©crit Chuck Rosenberg de Google. <br><br>  Pendant ce temps, en 2013, il a √©t√© d√©crit comment Google utilise GSS pour reconna√Ætre les adresses des photos de Google Street View.  ¬´Notre syst√®me nous a aid√©s √† extraire pr√®s de 100 millions d'adresses physiques de ces images¬ª, ont √©crit les auteurs. <br><br>  Les chercheurs ont d√©couvert que l'efficacit√© de la NS augmente avec la profondeur.  "Nous avons constat√© que l'efficacit√© de cette approche augmente avec la profondeur du SCN, et la plus profonde des architectures que nous avons form√©es donne les meilleurs r√©sultats", a √©crit l'√©quipe de Google Street View.  ¬´Nos exp√©riences sugg√®rent que des architectures plus profondes peuvent produire une plus grande pr√©cision, mais avec un ralentissement de l'efficacit√©.¬ª <br><br>  Ainsi, apr√®s AlexNet, les r√©seaux ont commenc√© √† s'approfondir.  L'√©quipe Google a fait une offre au concours en 2014 - deux ans seulement apr√®s la victoire d'AlexNet en 2012. Elle √©tait √©galement bas√©e sur un SNA profond, mais Goolge a utilis√© un r√©seau beaucoup plus profond de 22 couches pour atteindre un taux d'erreur de 6,7% - il s'agit d'une am√©lioration majeure par rapport aux 16% d'AlexNet. <br><br>  Mais en m√™me temps, les r√©seaux plus profonds ne fonctionnaient mieux qu'avec des ensembles de donn√©es de formation plus importants.  Par cons√©quent, Gerrish affirme que l'ensemble de donn√©es ImageNet et la concurrence ont jou√© un r√¥le majeur dans le succ√®s du SCN.  Rappelons qu'au concours ImageNet, les participants re√ßoivent un million d'images et sont invit√©s √† les trier en 1 000 cat√©gories. <br><br>  "Si vous avez un million d'images pour la formation, alors chaque classe comprend 1 000 images", a d√©clar√© Gerrish.  Sans un si grand ensemble de donn√©es, at-il dit, "vous auriez trop d'options pour former le r√©seau". <br><br>  Ces derni√®res ann√©es, les experts se concentrent de plus en plus sur la collecte d'une √©norme quantit√© de donn√©es pour former des r√©seaux plus profonds et plus pr√©cis.  C'est pourquoi les entreprises d√©veloppant des voitures robotis√©es se concentrent sur la circulation sur les routes publiques - des images et des vid√©os de ces voyages sont envoy√©es au si√®ge social et utilis√©es pour former les entreprises NS. <br><br><h2>  Boom du Deep Learning </h2><br>  La d√©couverte du fait que des r√©seaux plus profonds et des ensembles de donn√©es plus importants peuvent am√©liorer les performances de NS a cr√©√© une soif insatiable de puissance de calcul toujours plus grande.  L'une des principales composantes du succ√®s d'AlexNet √©tait l'id√©e que la formation matricielle est utilis√©e dans la formation NS, qui peut √™tre effectu√©e efficacement sur des GPU bien parall√©lisables. <br><br>  "Les NS sont bien parall√©lis√©s", a d√©clar√© Jai Ten, un chercheur de MO.  Les cartes graphiques - fournissant une puissance de traitement parall√®le √©norme pour les jeux vid√©o - se sont av√©r√©es utiles pour les NS. <br><br>  "La partie centrale du travail du GPU, la multiplication tr√®s rapide de la matrice, s'est av√©r√©e √™tre la partie centrale du travail de l'Assembl√©e nationale", a d√©clar√© Ten. <br><br>  Tout cela a √©t√© un succ√®s pour les principaux fabricants de GPU, Nvidia et AMD.  Les deux soci√©t√©s ont d√©velopp√© de nouvelles puces sp√©cialement adapt√©es aux besoins de l'application MO, et maintenant les applications AI sont responsables d'une partie importante des ventes de GPU de ces soci√©t√©s. <br><br>  En 2016, Google a annonc√© la cr√©ation d'une puce sp√©ciale, la Tensor Processing Unit (TPU), con√ßue pour fonctionner √† l'Assembl√©e nationale.  "Bien que Google envisageait la possibilit√© de cr√©er des circuits int√©gr√©s √† usage sp√©cial (ASIC) en 2006, cette situation est devenue urgente en 2013", a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©crit</a> un repr√©sentant de l'entreprise l'ann√©e derni√®re.  ¬´C'est alors que nous avons r√©alis√© que les besoins croissants de l'Assembl√©e nationale en mati√®re de puissance de calcul pourraient nous obliger √† doubler le nombre de centres de donn√©es dont nous disposons.¬ª <br><br>  Au d√©but, seuls les propres services de Google avaient acc√®s aux TPU, mais plus tard, la soci√©t√© a permis √† tout le monde d'utiliser cette technologie via une plate-forme de cloud computing. <br><br>  Bien s√ªr, Google n'est pas la seule entreprise √† travailler sur des puces IA.  Quelques exemples: dans les derni√®res versions des puces iPhone, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">il existe un</a> ¬´noyau neuronal¬ª optimis√© pour les op√©rations avec le NS.  Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©veloppe</a> sa propre gamme de puces optimis√©es pour GO.  Tesla a r√©cemment <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">annonc√©</a> le rejet des puces de Nvidia au profit de ses propres puces NS.  On dit √©galement qu'Amazon <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">travaille</a> sur ses puces AI. <br><br><h2>  Pourquoi les r√©seaux de neurones profonds sont difficiles √† comprendre </h2><br>  J'ai expliqu√© comment fonctionnent les r√©seaux de neurones, mais je n'ai pas expliqu√© pourquoi ils fonctionnent si bien.  On ne sait pas exactement comment l'immense quantit√© de calculs matriciels permet √† un syst√®me informatique de distinguer un jaguar d'un gu√©pard, et du sureau de groseille. <br><br>  La qualit√© la plus remarquable de l'Assembl√©e nationale est peut-√™tre le contraire.  La convolution permet au NS de comprendre la c√©sure - ils peuvent dire si l'image du coin sup√©rieur droit de l'image est similaire √† l'image du coin sup√©rieur gauche d'une autre image. <br><br>  Mais en m√™me temps, le SCN n'a aucune id√©e de la g√©om√©trie.  Ils ne peuvent pas reconna√Ætre la similitude des deux images si elles sont tourn√©es √† 45 degr√©s ou doubl√©es.  SNA n'essaie pas de comprendre la structure tridimensionnelle des objets et ne peut pas prendre en compte diff√©rentes conditions d'√©clairage. <br><br>  Mais en m√™me temps, les NS peuvent reconna√Ætre des photos de chiens prises de face et de c√¥t√©, et peu importe si le chien occupe une petite partie de l'image, ou une grande.  Comment font-ils?  Il s'av√®re que s'il y a suffisamment de donn√©es, une approche statistique avec d√©nombrement direct peut faire face √† la t√¢che.  Le SCN n'est pas con√ßu pour ¬´imaginer¬ª √† quoi ressemblerait une image particuli√®re sous un angle diff√©rent ou dans des conditions diff√©rentes, mais avec un nombre suffisant d'exemples √©tiquet√©s, il peut apprendre toutes les variations possibles de l'image par simple r√©p√©tition. <br><br>  Il est prouv√© que le syst√®me visuel des personnes fonctionne de mani√®re similaire.  Regardez quelques images - √©tudiez d'abord attentivement la premi√®re, puis ouvrez la seconde. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d43/861/b2d/d43861b2ddeebcec572cab31c9ddb81a.png"><br>  <i>Premi√®re photo</i> <br><br><div class="spoiler">  <b class="spoiler_title">Deuxi√®me photo</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/529/451/bde/529451bde2016793fd9cfe4ec092b46a.png"><br></div></div><br><br>  Le cr√©ateur de l'image a pris la photo de quelqu'un et a tourn√© les yeux et la bouche √† l'envers.  L'image semble relativement normale lorsque vous la regardez √† l'envers, car le syst√®me visuel humain est habitu√© √† voir les yeux et la bouche dans cette position.  Mais si vous regardez l'image dans la bonne orientation, vous pouvez imm√©diatement voir que le visage est √©trangement d√©form√©. <br><br>  Cela sugg√®re que le syst√®me visuel humain est bas√© sur les m√™mes techniques de reconnaissance de formes brutes que le NS.  Si nous regardons quelque chose qui est presque toujours visible dans une seule orientation - l'≈ìil humain - nous pouvons le reconna√Ætre beaucoup mieux dans son orientation normale. <br><br>  Les NS reconnaissent bien les images en utilisant tout le contexte disponible sur celles-ci.  Par exemple, les voitures roulent g√©n√©ralement sur les routes.  Les robes sont g√©n√©ralement port√©es sur le corps d'une femme ou suspendues dans un placard.  Les avions sont g√©n√©ralement abattus contre le ciel ou ils gouvernent sur la piste.  Personne n'enseigne sp√©cifiquement aux NS ces corr√©lations, mais avec un nombre suffisant d'exemples √©tiquet√©s, le r√©seau lui-m√™me peut les apprendre. <br><br>  En 2015, des chercheurs de Google ont tent√© de mieux comprendre les NS, en les ¬´faisant reculer¬ª.  Au lieu d'utiliser des images pour la formation des NS, ils ont utilis√© des NS form√©s pour changer les images.  Par exemple, ils ont commenc√© avec une image contenant du bruit al√©atoire, puis l'ont progressivement modifi√©e pour qu'elle active fortement l'un des neurones de sortie de la NS - en fait, ils ont demand√© √† la NS de ¬´dessiner¬ª l'une des cat√©gories qu'il a appris √† reconna√Ætre.  Dans un cas int√©ressant, ils ont forc√© la NS √† g√©n√©rer des images qui activent la NS, entra√Æn√©s √† reconna√Ætre les halt√®res. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ece/817/a18/ece817a18e8c2fc63281cb0a1773ac91.png"><br><br>  "Bien s√ªr, il y a des halt√®res ici, mais pas une seule image des halt√®res ne semble compl√®te sans la pr√©sence d'un corps musculaire muscl√© les soulevant", ont √©crit des chercheurs de Google. <br><br>  √Ä premi√®re vue, cela semble √©trange, mais en r√©alit√©, il n'est pas si diff√©rent de ce que font les gens.  Si nous voyons un petit objet flou sur l'image, nous cherchons un indice dans son environnement pour comprendre ce qui peut s'y passer.  Les gens, √©videmment, parlent des images diff√©remment, en utilisant une compr√©hension conceptuelle complexe du monde qui les entoure.  Mais en fin de compte, le STS reconna√Æt bien les images, car elles tirent pleinement parti du contexte entier repr√©sent√© sur elles, et ce n'est pas tr√®s diff√©rent de la fa√ßon dont les gens le font. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr455331/">https://habr.com/ru/post/fr455331/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr455316/index.html">Nous modifions la pile Bluetooth pour am√©liorer le son des casques sans codecs AAC, aptX et LDAC</a></li>
<li><a href="../fr455318/index.html">Quels sont les domaines d'application de l'impression 3D?</a></li>
<li><a href="../fr455321/index.html">Domotique √† faire soi-m√™me</a></li>
<li><a href="../fr455325/index.html">Portage d'applications de bureau sur .NET Core</a></li>
<li><a href="../fr455329/index.html">Annonce de l'extension des outils Azure IoT Edge (pr√©version)</a></li>
<li><a href="../fr455333/index.html">Qui a mis Python dans la mise √† jour de Windows 10 de mai 2019?</a></li>
<li><a href="../fr455335/index.html">Petty Petty Joy # 3: Po√©sie</a></li>
<li><a href="../fr455337/index.html">Qui a ajout√© Python √† la derni√®re mise √† jour de Windows?</a></li>
<li><a href="../fr455339/index.html">Creuser des tombes, SQL Server, des ann√©es d'externalisation et votre premier projet</a></li>
<li><a href="../fr455341/index.html">Que sait-on de la certification ITIL 4</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíã üë©üèº‚Äçüè´ ‚ôäÔ∏è Eigenes Fahrrad zum Synchronisieren von MariaDB und Sphinx üë®‚Äçüè´ üë®üèæ‚Äçüè´ üè¢</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Am 28. Februar hielt ich eine Pr√§sentation beim SphinxSearch-Treffen , das in unserem B√ºro stattfand. Er sprach dar√ºber, wie wir aus der regelm√§√üigen ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Eigenes Fahrrad zum Synchronisieren von MariaDB und Sphinx</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/superjob/blog/447526/"><p><img src="https://habrastorage.org/webt/t0/1g/vk/t01gvkcn0zx47xuioqcvfz5bqoc.png"></p><br><p>  Am 28. Februar hielt ich eine Pr√§sentation beim <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SphinxSearch-Treffen</a> , das in unserem B√ºro stattfand.  Er sprach dar√ºber, wie wir aus der regelm√§√üigen Neuerstellung von Indizes f√ºr die Volltextsuche und dem Senden von Aktualisierungen des Codes ‚Äûan Ort und Stelle‚Äú an Bahnzeitindizes und der automatischen Synchronisierung des Status des Index und der MariaDB-Datenbank hervorgegangen sind.  Eine Videoaufzeichnung meines Berichts ist √ºber den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a> verf√ºgbar. F√ºr diejenigen, die lieber lesen als das Video ansehen, habe ich diesen Artikel geschrieben. </p><a name="habracut"></a><br><p>  Ich werde damit beginnen, wie unsere Suche arrangiert wurde und warum wir das alles begonnen haben. </p><br><p>  Unsere Suche wurde nach einem v√∂llig Standardschema organisiert. </p><br><p>  Vom Front-End kommen Benutzeranforderungen an den in PHP geschriebenen Anwendungsserver, und dieser kommuniziert wiederum mit der Datenbank (wir haben MariaDB).  Wenn wir eine Suche durchf√ºhren m√ºssen, wendet sich der Anwendungsserver an den Balancer (wir haben Haproxy), der ihn mit einem der Server verbindet, auf denen searchd ausgef√ºhrt wird. Dieser Server f√ºhrt bereits eine Suche durch und gibt das Ergebnis zur√ºck. </p><br><p>  Daten aus der Datenbank fallen auf ganz traditionelle Weise in den Index: Gem√§√ü dem Zeitplan erstellen wir den Index alle paar Minuten mit den Dokumenten neu, die vor relativ kurzer Zeit aktualisiert wurden, und erstellen den Index mit den sogenannten "archivierten" Dokumenten (dh mit denen, mit denen Lange ist nichts passiert).  Es sind einige Computer f√ºr die Indizierung zugewiesen. Dort wird nach einem Zeitplan ein Skript ausgef√ºhrt, das zuerst den Index erstellt, die Indexdateien dann auf besondere Weise umbenennt und dann in einem separaten Ordner ablegt.  Und auf jedem der Server mit searchd wird rsync einmal pro Minute gestartet, wodurch die Dateien aus diesem Ordner in den Ordner searchd indexes kopiert werden. Wenn dann etwas kopiert wurde, wird die Anforderung RELOAD INDEX ausgef√ºhrt. </p><br><p>  F√ºr einige √Ñnderungen bei Lebensl√§ufen und offenen Stellen war es jedoch erforderlich, dass sie den Index so schnell wie m√∂glich ‚Äûerreichen‚Äú.  Wenn beispielsweise eine √∂ffentlich zug√§ngliche Stelle aus der Ver√∂ffentlichung entfernt wird, ist aus Sicht des Benutzers zu erwarten, dass sie innerhalb weniger Sekunden nicht mehr aus dem Problem verschwindet.  Daher werden diese √Ñnderungen direkt √ºber searchd mithilfe von UPDATE-Abfragen gesendet.  Damit diese √Ñnderungen auf alle Kopien von Indizes auf allen unseren Servern angewendet werden, wird f√ºr jede Suche ein verteilter Index eingerichtet, der Aktualisierungen der Attribute an alle Suchinstanzen sendet.  Der Anwendungsserver stellt weiterhin eine Verbindung zum Balancer her und sendet eine Anforderung zum Aktualisieren des verteilten Index.  Daher muss er weder die Liste der Server mit searchd im Voraus kennen, noch wird er genau wissen, zu welchem ‚Äã‚ÄãServer mit searchd. </p><br><p>  Das alles hat ziemlich gut funktioniert, aber es gab Probleme. </p><br><ol><li>  Die durchschnittliche Verz√∂gerung zwischen der Erstellung eines Dokuments (dies ist ein Lebenslauf oder eine freie Stelle f√ºr uns) und seiner Aufnahme in den Index war direkt proportional zu ihrer Anzahl in unserer Datenbank. </li><li> Da wir den verteilten Index zum Verteilen von Attributaktualisierungen verwendet haben, konnten wir nicht garantieren, dass diese Aktualisierungen auf alle Kopien des Index angewendet wurden. </li><li> Die ‚Äûdringenden‚Äú √Ñnderungen, die w√§hrend der Neuerstellung des Index aufgetreten sind, gingen bei der Ausf√ºhrung des Befehls <code>RELOAD INDEX</code> verloren (einfach, weil sie noch nicht im neu erstellten Index enthalten waren) und wurden erst nach der n√§chsten Neuindizierung in den Index aufgenommen. <img src="https://habrastorage.org/webt/rz/t6/v3/rzt6v3lfrnyayc3-texs56vlh48.png"></li><li>  Die Skripte zum Aktualisieren von Indizes auf Servern mit searchd wurden unabh√§ngig voneinander ausgef√ºhrt, es gab keine Synchronisation zwischen ihnen.  Aus diesem Grund kann die Verz√∂gerung zwischen der Aktualisierung des Index auf verschiedenen Servern mehrere Minuten betragen. </li><li>  Wenn etwas im Zusammenhang mit der Suche getestet werden musste, musste der Index nach jeder √Ñnderung neu erstellt werden. </li></ol><br><p>  Jedes dieser Probleme war f√ºr sich genommen keine grundlegende √úberarbeitung der Suchinfrastruktur wert, aber zusammengenommen haben sie das Leben sp√ºrbar verdorben. </p><br><p>  Wir haben uns entschlossen, die oben genannten Probleme mithilfe von Sphinx-Echtzeitindizes zu l√∂sen.  Dar√ºber hinaus hat uns der √úbergang zu RT-Indizes nicht gereicht.  Um Datenrennen endg√ºltig loszuwerden, musste sichergestellt werden, dass alle Aktualisierungen von der Anwendung auf den Index denselben Kanal durchlaufen haben.  Au√üerdem mussten die √Ñnderungen, die w√§hrend der Neuerstellung des Index an der Datenbank vorgenommen wurden, irgendwo gespeichert werden (schlie√ülich ist es manchmal erforderlich, ihn neu zu erstellen, aber die Prozedur erfolgt nicht sofort). </p><br><p>  Wir haben beschlossen, die Verbindung √ºber das MySQL-Replikationsprotokoll als Daten√ºbertragungskanal herzustellen, und im MySQL-Binlog k√∂nnen die √Ñnderungen gespeichert werden, w√§hrend der Index neu erstellt wird.  Mit dieser L√∂sung konnten wir das Schreiben in Sphinx aus dem Anwendungscode entfernen.  Und da wir zu diesem Zeitpunkt bereits eine zeilenbasierte Replikation mit einer globalen Transaktions-ID verwendet hatten, konnte der Wechsel zwischen Datenbankreplikaten ganz einfach durchgef√ºhrt werden. </p><br><p>  Die Idee, eine direkte Verbindung zur Datenbank herzustellen, um von dort √Ñnderungen f√ºr das Senden an den Index zu erhalten, ist nat√ºrlich nicht neu: 2016 haben Kollegen von Avito <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">eine Pr√§sentation gehalten,</a> in der sie ausf√ºhrlich beschrieben haben, wie sie das Problem der Synchronisierung von Daten in Sphinx mit der Hauptdatenbank gel√∂st haben.  Wir haben uns entschlossen, ihre Erfahrung zu nutzen und ein √§hnliches System f√ºr uns zu entwickeln, mit dem Unterschied, dass wir nicht PostgreSQL, sondern MariaDB und den alten Sphinx-Zweig (n√§mlich Version 2.3.2) haben. </p><br><p>  Wir haben einen Dienst erstellt, der √Ñnderungen in MariaDB abonniert und den Index in Sphinx aktualisiert.  Seine Aufgaben sind wie folgt: </p><br><ul><li>  Verbindung zum MariaDB-Server √ºber das Replikationsprotokoll und Empfangen von Ereignissen aus dem Binlog; </li><li>  Verfolgen der aktuellen Binlog-Position und der Nummer der zuletzt abgeschlossenen Transaktion; </li><li>  Filtern von Binlog-Ereignissen; </li><li>  herauszufinden, welche Dokumente im Index hinzugef√ºgt, gel√∂scht oder aktualisiert werden m√ºssen und f√ºr aktualisierte Dokumente - welche Felder m√ºssen aktualisiert werden; </li><li>  Anfrage nach fehlenden Daten von MariaDB; </li><li>  Generierung und Ausf√ºhrung von Indexaktualisierungsanforderungen; </li><li>  Erstellen Sie den Index bei Bedarf neu. </li></ul><br><p>  Wir haben eine Verbindung mithilfe des Replikationsprotokolls mithilfe der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">go-mysql-</a> Bibliothek hergestellt.  Sie ist daf√ºr verantwortlich, eine Verbindung mit MariaDB herzustellen, Replikationsereignisse zu lesen und an einen Handler weiterzuleiten.  Dieser Handler startet in Goroutine, die von der Bibliothek gesteuert wird, aber wir schreiben den Handlercode selbst.  Im Handlercode werden Ereignisse mit einer Liste von Tabellen √ºberpr√ºft, die uns interessieren, und die √Ñnderungen an diesen Tabellen werden zur Verarbeitung gesendet.  Unser Handler speichert auch den Transaktionsstatus.  Dies liegt daran, dass die Ereignisse im Replikationsprotokoll in der richtigen Reihenfolge sind: GTID (Beginn der Transaktion) -&gt; ROW (√Ñnderung der Daten) -&gt; XID (Ende der Transaktion) und nur die erste von ihnen enth√§lt Informationen zur Transaktionsnummer.  Es ist f√ºr uns bequemer, die Transaktionsnummer zusammen mit ihrem Abschluss zu √ºbertragen, um Informationen dar√ºber zu speichern, auf welche Position im Binlog die √Ñnderungen angewendet wurden. Dazu m√ºssen wir uns die Nummer der aktuellen Transaktion zwischen ihrem Beginn und ihrem Abschluss merken. </p><br><pre> <code class="plaintext hljs">MySQL [(none)]&gt; describe sync_state; +-----------------+--------+ | Field | Type | +-----------------+--------+ | id | bigint | | dummy_field | field | | binlog_position | uint | | binlog_name | string | | gtid | string | | flavor | string | +-----------------+--------+</code> </pre> <br><p>  Wir speichern die Nummer der zuletzt abgeschlossenen Transaktion in einem speziellen Index aus einem Dokument auf jedem Server mit searchd.  Zu Beginn des Dienstes √ºberpr√ºfen wir, ob die Indizes initialisiert sind und die erwartete Struktur aufweisen sowie ob die gespeicherte Position auf allen Servern vorhanden und auf allen Servern gleich ist.  Wenn diese √úberpr√ºfungen erfolgreich waren und wir das Binlog von der gespeicherten Position aus lesen konnten, beginnen wir mit dem Synchronisierungsvorgang.  Wenn die √úberpr√ºfungen fehlschlagen oder das Binlog nicht von der gespeicherten Position aus gelesen werden konnte, setzen wir die gespeicherte Position auf die aktuelle Position des MariaDB-Servers zur√ºck und erstellen den Index neu. </p><br><p>  Die Verarbeitung von Replikationsereignissen beginnt mit der Bestimmung, welche Dokumente von einer bestimmten √Ñnderung in der Datenbank betroffen sind.  Zu diesem Zweck haben wir in der Konfiguration unseres Dienstes so etwas wie das Routing f√ºr Zeilen√§nderungsereignisse in den f√ºr uns interessanten Tabellen durchgef√ºhrt, dh eine Reihe von Regeln, um zu bestimmen, wie √Ñnderungen in der Datenbank indiziert werden sollen. </p><br><pre> <code class="plaintext hljs">[[ingest]] table = "vacancy" id_field = "id" index = "vacancy" [ingest.column_map] user_id = ["user_id"] edited_at = ["date_edited"] profession = ["profession"] latitude = ["latitude_deg", "latitude_rad"] longitude = ["longitude_deg", "longitude_rad"] [[ingest]] table = "vacancy_language" id_field = "vacancy_id" index = "vacancy" [ingest.column_map] language_id = ["languages"] level = ["languages"] [[ingest]] table = "vacancy_metro_station" id_field = "vacancy_id" index = "vacancy" [ingest.column_map] metro_station_id = ["metro"]</code> </pre> <br><p>  Mit diesem <code>vacancy_metro_station</code> sollten sich beispielsweise √Ñnderungen an den <code>vacancy_metro_station</code> <code>vacancy</code> , " <code>vacancy_language</code> und " <code>vacancy_metro_station</code> im <code>vacancy_metro_station</code> .  Die <code>vacancy_id</code> kann im Feld <code>id</code> f√ºr die <code>vacancy_id</code> und im Feld <code>vacancy_id</code> f√ºr die beiden anderen Tabellen angegeben werden.  Das Feld <code>column_map</code> ist eine Tabelle zur Abh√§ngigkeit von Indexfeldern von den Feldern verschiedener Datenbanktabellen. </p><br><p>  Wenn wir die Liste der von den √Ñnderungen betroffenen Dokumente erhalten haben, m√ºssen wir sie im Index aktualisieren, jedoch nicht sofort.  Zuerst akkumulieren wir √Ñnderungen f√ºr jedes Dokument und senden die √Ñnderungen an den Index, sobald eine kurze Zeit (wir haben 100 Millisekunden) nach der letzten √Ñnderung dieses Dokuments verstrichen sind. </p><br><p>  Wir haben uns dazu entschlossen, um viele unn√∂tige Indexaktualisierungen zu vermeiden, da in vielen F√§llen eine einzelne logische √Ñnderung an einem Dokument mithilfe mehrerer SQL-Abfragen erfolgt, die sich auf verschiedene Tabellen auswirken und manchmal in v√∂llig unterschiedlichen Transaktionen ausgef√ºhrt werden. </p><br><p>  Ich werde ein einfaches Beispiel geben.  Angenommen, ein Benutzer hat eine freie Stelle bearbeitet.  Der Code, der f√ºr das Speichern von √Ñnderungen verantwortlich ist, wird der Einfachheit halber h√§ufig folgenderma√üen geschrieben: </p><br><pre> <code class="plaintext hljs">BEGIN; UPDATE vacancy SET edited_at = NOW() WHERE id = 123; DELETE FROM vacancy_language WHERE vacancy_id = 123; INSERT INTO vacancy_language (vacancy_id, language_id, level) VALUES (123, 1, "fluent"), (123, 2, "technical"); DELETE FROM vacancy_metro_station WHERE vacancy_id = 123; INSERT INTO vacancy_metro_station (vacancy_id, metro_station_id) VALUES (123, 55); ... COMMIT;</code> </pre> <br><p>  Mit anderen Worten, zuerst werden alle alten Datens√§tze aus den verkn√ºpften Tabellen gel√∂scht und dann neue eingef√ºgt.  Gleichzeitig werden im Binlog weiterhin Eintr√§ge zu diesen L√∂schungen und Einf√ºgungen vorhanden sein, auch wenn sich im Dokument nichts ge√§ndert hat. </p><br><p>  Um nur das zu aktualisieren, was ben√∂tigt wird, haben wir Folgendes getan: Sortieren Sie die ge√§nderten Zeilen so, dass f√ºr jedes Index-Dokument-Paar alle √Ñnderungen in chronologischer Reihenfolge abgerufen werden k√∂nnen.  Anschlie√üend k√∂nnen wir sie nacheinander anwenden, um festzustellen, welche Felder in welchen Tabellen sich letztendlich ge√§ndert haben und welche nicht. Anschlie√üend k√∂nnen wir mithilfe der <code>column_map</code> eine Liste der Felder und <code>column_map</code> , die f√ºr jedes betroffene Dokument aktualisiert werden m√ºssen.  Dar√ºber hinaus k√∂nnen Ereignisse, die sich auf ein Dokument beziehen, nicht nacheinander eintreffen, sondern als ‚Äûanders‚Äú, wenn sie in verschiedenen Transaktionen ausgef√ºhrt werden.  Wenn wir jedoch feststellen k√∂nnen, welche Dokumente sich ge√§ndert haben, hat dies keine Auswirkungen. </p><br><p>  Gleichzeitig konnten wir mit diesem Ansatz nur die Attribute des Index aktualisieren, wenn keine √Ñnderungen in den Textfeldern vorgenommen wurden, und das Senden von √Ñnderungen an Sphinx kombinieren. </p><br><p>  Jetzt k√∂nnen wir herausfinden, welche Dokumente im Index aktualisiert werden m√ºssen. </p><br><p>  In vielen F√§llen reichen die Daten aus dem Binlog nicht aus, um eine Anforderung zum Aktualisieren des Index zu erstellen. Daher erhalten wir die fehlenden Daten von demselben Server, von dem aus wir das Binlog lesen.  Hierzu gibt es in der Konfiguration unseres Dienstes eine Anforderungsvorlage zum Empfangen von Daten. </p><br><pre> <code class="plaintext hljs">[data_source.vacancy] #               #   -      id     parts = 4 query = """ SELECT vacancy.id AS `:id`, vacancy.profession AS `profession_text:field`, GROUP_CONCAT(DISTINCT vacancy_language.language_id) AS `languages:attr_multi`, GROUP_CONCAT(DISTINCT vacancy_metro_station.metro_station_id) AS `metro:attr_multi` FROM vacancy LEFT JOIN vacancy_language ON vacancy_language.vacancy_id = vacancy.id LEFT JOIN vacancy_metro_station ON vacancy_metro_station.vacancy_id = vacancy.id GROUP BY vacancy.id """</code> </pre> <br><p>  In dieser Vorlage sind alle Felder mit speziellen Aliasnamen gekennzeichnet: <code>[___]:___</code> . <br>  Es wird sowohl bei der Erstellung einer Anfrage zum Empfang der fehlenden Daten als auch bei der Erstellung des Index verwendet (dazu sp√§ter mehr). </p><br><p>  Wir bilden eine Anfrage dieser Art: </p><br><pre> <code class="plaintext hljs">SELECT vacancy.id AS `id`, vacancy.profession AS `profession_text`, GROUP_CONCAT(DISTINCT vacancy_language.language_id) AS `languages`, GROUP_CONCAT(DISTINCT vacancy_metro_station.metro_station_id) AS `metro` FROM vacancy LEFT JOIN vacancy_language ON vacancy_language.vacancy_id = vacancy.id LEFT JOIN vacancy_metro_station ON vacancy_metro_station.vacancy_id = vacancy.id WHERE vacancy.id IN (&lt; id ,   &gt;) GROUP BY vacancy.id</code> </pre> <br><p>  Dann pr√ºfen wir f√ºr jedes Dokument, ob es das Ergebnis dieser Anfrage ist.  Wenn nicht, bedeutet dies, dass es aus der Haupttabelle gel√∂scht wurde und daher auch aus dem Index gel√∂scht werden kann (wir f√ºhren die <code>DELETE</code> Abfrage f√ºr dieses Dokument aus).  Wenn dies der Fall ist, pr√ºfen Sie, ob die Textfelder f√ºr dieses Dokument aktualisiert werden m√ºssen.  Wenn Textfelder nicht aktualisiert werden m√ºssen, f√ºhren wir eine <code>UPDATE</code> Abfrage f√ºr dieses Dokument durch, andernfalls <code>REPLACE</code> . </p><br><p>  Es ist anzumerken, dass die Logik, die Position beizubehalten, von der aus Sie bei Fehlern mit dem Lesen des Binlogs beginnen k√∂nnen, kompliziert sein musste, da jetzt eine Situation m√∂glich ist, in der nicht alle aus dem Binlog gelesenen √Ñnderungen angewendet werden. </p><br><p>  Damit das erneute Lesen des binlog ordnungsgem√§√ü funktioniert, haben wir Folgendes ausgef√ºhrt: Speichern Sie f√ºr jedes Zeilen√§nderungsereignis in der Datenbank die ID der zuletzt abgeschlossenen Transaktion zum Zeitpunkt des Auftretens dieses Ereignisses.  Nachdem Sie die √Ñnderungen an Sphinx gesendet haben, aktualisieren wir die Transaktionsnummer, von der aus Sie sicher mit dem Lesen beginnen k√∂nnen, wie folgt.  Wenn wir nicht alle akkumulierten √Ñnderungen verarbeitet haben (weil einige Dokumente nicht in der Warteschlange "aufgesp√ºrt" wurden), nehmen wir die Nummer der fr√ºhesten Transaktion von denen, die sich auf die √Ñnderungen beziehen, die wir noch nicht angewendet haben.  Und wenn es passiert ist, dass wir alle akkumulierten √Ñnderungen angewendet haben, nehmen wir einfach die Nummer der zuletzt abgeschlossenen Transaktion. </p><br><p>  Was als Ergebnis geschah, war f√ºr uns in Ordnung, aber es gab noch einen ziemlich wichtigen Punkt: Damit die Leistung des Echtzeitindex √ºber die Zeit auf einem akzeptablen Niveau bleiben konnte, mussten Gr√∂√üe und Anzahl der ‚ÄûChunks‚Äú dieses Index klein bleiben.  Zu diesem <code>FLUSH RAMCHUNK</code> Sphinx √ºber eine <code>FLUSH RAMCHUNK</code> Anforderung, die einen neuen Festplattenblock erstellt, und eine <code>OPTIMIZE INDEX</code> Anforderung, mit der alle Festplattenbl√∂cke zu einem zusammengef√ºhrt werden.  Anfangs dachten wir, wir w√ºrden es nur regelm√§√üig durchf√ºhren und das ist alles.  Leider stellte sich heraus, dass <code>OPTIMIZE INDEX</code> in Version 2.3.2 nicht funktioniert (n√§mlich mit einer relativ hohen Wahrscheinlichkeit zu einem R√ºckgang der Suche f√ºhrt).  Aus diesem Grund haben wir uns nur einmal am Tag entschlossen, den Index vollst√§ndig neu zu erstellen, zumal wir dies von Zeit zu Zeit noch tun m√ºssen (z. B. wenn sich das Indexschema oder die Tokenizer-Einstellungen √§ndern). </p><br><p>  Das Verfahren zum Wiederherstellen des Index erfolgt in mehreren Schritten. </p><br><ol><li><p>  Wir generieren eine Konfiguration f√ºr den Indexer </p><br><p>  Wie oben erw√§hnt, befindet sich in der Dienstkonfiguration eine SQL-Abfragevorlage.  Es wird auch verwendet, um die Indexer-Konfiguration zu bilden. <br>  In der Konfiguration sind auch andere Einstellungen zum Erstellen des Index erforderlich (Tokenizer-Einstellungen, W√∂rterb√ºcher, verschiedene Einschr√§nkungen des Ressourcenverbrauchs). </p><br></li><li><p>  Speichern Sie die aktuelle Position von MariaDB </p><br><p>  Von dieser Position aus beginnen wir mit dem Lesen des Binlogs, nachdem der neue Index auf allen Servern mit searchd verf√ºgbar ist. </p><br></li><li><p>  Wir starten den Indexer </p><br><p>  <code>indexer --config tmp.vacancy.indexer.0.conf --all</code> Befehle des Formularindexers <code>indexer --config tmp.vacancy.indexer.0.conf --all</code> und warten auf deren Abschluss.  Wenn der Index in Teile unterteilt ist, beginnen wir au√üerdem mit der parallelen Konstruktion aller Teile. </p><br></li><li><p>  Wir laden Indexdateien auf Server </p><br><p>  Das Herunterladen auf jeden Server erfolgt ebenfalls parallel, aber wir warten nat√ºrlich, bis alle Dateien auf alle Server hochgeladen wurden.  Zum Herunterladen von Dateien in der Dienstkonfiguration gibt es einen Abschnitt mit einer Befehlsvorlage zum Herunterladen von Dateien. </p><br><pre> <code class="plaintext hljs">[index_uploader] executable = "rsync" arguments = [ "--files-from=-", "--log-file=&lt;&lt;.DataDir&gt;&gt;/rsync.&lt;&lt;.Host&gt;&gt;.log", "--no-relative", "--times", "--delay-updates", ".", "rsync://&lt;&lt;.Host&gt;&gt;/index/vacancy/", ]</code> </pre> <br><p>  F√ºr jeden Server ersetzen wir einfach seinen Namen in der Host-Variablen und f√ºhren den resultierenden Befehl aus.  Wir verwenden rsync zum Herunterladen, aber im Prinzip funktioniert jedes Programm oder Skript, das eine Liste von Dateien in stdin akzeptiert und diese Dateien in den Ordner herunterl√§dt, in dem searchd Indexdateien erwartet. </p><br></li><li><p>  Wir stoppen die Synchronisation </p><br><p>  Wir h√∂ren auf, das Binlog zu lesen, stoppen die Goroutine, die f√ºr die Anh√§ufung von √Ñnderungen verantwortlich ist. </p><br></li><li><p>  Ersetzen Sie den alten Index durch einen neuen </p><br><p>  F√ºr jeden Server mit searchd f√ºhren wir sequentielle Abfragen durch. <code>RELOAD INDEX vacancy_plain</code> , <code>TRUNCATE INDEX vacancy_plain</code> , <code>ATTACH INDEX vacancy_plain TO vacancy</code> .  Wenn der Index in Teile unterteilt ist, f√ºhren wir diese Abfragen f√ºr jedes Teil nacheinander aus.  Wenn wir uns in einer Produktionsumgebung befinden, entfernen wir vor dem Ausf√ºhren dieser Abfragen auf einem Server die Last √ºber den Balancer (damit niemand SELECT-Abfragen an die Indizes zwischen <code>TRUNCATE</code> und <code>ATTACH</code> ) und sobald <code>ATTACH</code> die letzte <code>ATTACH</code> Anforderung abgeschlossen ist, geben wir die Last an diesen Server zur√ºck. </p><br></li><li><p>  Wiederaufnahme der Synchronisation von einer gespeicherten Position </p><br><p>  Sobald wir alle Echtzeitindizes durch neu erstellte ersetzen, setzen wir das Lesen aus dem Binlog fort und synchronisieren Ereignisse aus dem Binlog, beginnend an der Position, die wir vor Beginn der Indizierung gespeichert haben. </p><br></li></ol><br><p>  Hier ist ein Beispiel eines Diagramms der Verz√∂gerung des Index vom MariaDB-Server. </p><br><p><img src="https://habrastorage.org/webt/xs/pq/56/xspq56osyygn1fxx6h5x_oczgpy.png" alt="Ruckstand nach neuindizierung"></p><br><p>  Hier k√∂nnen Sie sehen, dass der Status des Index nach der Neuerstellung zwar rechtzeitig zur√ºckkehrt, dies jedoch sehr kurz geschieht. </p><br><p>  Jetzt, da alles mehr oder weniger fertig ist, ist es Zeit f√ºr die Ver√∂ffentlichung.  Wir haben es nach und nach gemacht.  Zuerst haben wir einen Echtzeitindex auf einige Server gegossen, und der Rest zu dieser Zeit funktionierte genauso.  Gleichzeitig unterschied sich die Struktur der Indizes auf den ‚Äûneuen‚Äú Servern nicht von den alten, sodass unsere PHP-Anwendung weiterhin eine Verbindung zum Balancer herstellen konnte, ohne sich Gedanken dar√ºber zu machen, ob die Anforderung in einem Echtzeitindex oder in einem einfachen Index verarbeitet werden w√ºrde. </p><br><p><img src="https://habrastorage.org/webt/sy/xz/lx/syxzlx_tfmg0-mze5vr1ngt3_tg.png" alt="Verteilungsschema f√ºr √úbergangsaktuelle Beschr√§nkungen"></p><br><p>  Attributaktualisierungen, √ºber die ich zuvor gesprochen habe, wurden ebenfalls nach dem alten Schema gesendet, mit dem Unterschied, dass der verteilte Index auf allen Servern so konfiguriert wurde, dass UPDATE-Abfragen nur an Server mit einfachen Indizes gesendet werden.  Wenn die UPDATE-Anforderung von der Anwendung den Server mit Echtzeitindizes erreicht, f√ºhrt sie diese Anforderung nicht zu Hause aus, sondern sendet sie an die auf die alte Weise konfigurierten Server. </p><br><p>  Wie wir gehofft hatten, hat sich nach der Ver√∂ffentlichung herausgestellt, dass sich die Verz√∂gerung zwischen der √Ñnderung eines Lebenslaufs oder einer Vakanz in der Datenbank und der Eingabe der entsprechenden √Ñnderungen in den Index erheblich verringert. </p><br><p>  Nach dem Wechsel zu einem Echtzeitindex musste der Index nach jeder √Ñnderung auf den Testservern nicht neu erstellt werden.  Und so wurde es m√∂glich, End-to-End-Autotests unter Beteiligung der Suche relativ kosteng√ºnstig zu schreiben.  Da wir die √Ñnderungen aus dem Binlog jedoch asynchron verarbeiten (aus Sicht der Clients, die in die Datenbank schreiben), mussten wir warten m√ºssen, bis die √Ñnderungen bez√ºglich des am Autotest teilnehmenden Dokuments von unserem Service verarbeitet und an searchd gesendet wurden . </p><br><p>  Zu diesem Zweck haben wir in unserem Service einen Endpunkt erstellt, der genau das tut, dh wartet, bis alle √Ñnderungen auf die angegebene Transaktionsnummer angewendet wurden.  Zu diesem <code>@@gtid_current_pos</code> wir unmittelbar nach den erforderlichen √Ñnderungen an der Datenbank bei MariaDB <code>@@gtid_current_pos</code> und √ºbertragen sie an den Endpunkt unseres Dienstes.  Wenn wir zu diesem Zeitpunkt bereits alle Transaktionen auf diese Position angewendet haben, antwortet der Service sofort, dass wir fortfahren k√∂nnen.  Wenn nicht, erstellen wir in der Goroutine, die f√ºr die Anwendung der √Ñnderungen verantwortlich ist, ein Abonnement f√ºr diese GTID. Sobald sie (oder eine darauf folgende) angewendet wird, k√∂nnen wir dem Client auch erlauben, den Autotest fortzusetzen. </p><br><p>  Im PHP-Code sieht es ungef√§hr so ‚Äã‚Äãaus: </p><br><pre> <code class="plaintext hljs">&lt;?php declare(strict_types=1); use GuzzleHttp\ClientInterface; use GuzzleHttp\RequestOptions; use PDO; class RiverClient { private const REQUEST_METHOD = 'post'; /** * @var ClientInterface */ private $httpClient; public function __construct(ClientInterface $httpClient) { $this-&gt;httpClient = $httpClient; } public function waitForSync(PDO $mysqlConnection, PDO $sphinxConnection, string $riverAddr): void { $masterGTID = $mysqlConnection-&gt;query('SELECT @@gtid_current_pos')-&gt;fetchColumn(); $this-&gt;httpClient-&gt;request( self::REQUEST_METHOD, "http://{$riverAddr}/wait", [RequestOptions::FORM_PARAMS =&gt; ['gtid' =&gt; $masterGTID]] ); } }</code> </pre> <br><h2 id="rezultaty">  Ergebnisse </h2><br><p>  Infolgedessen konnten wir die Verz√∂gerung zwischen der Aktualisierung von MariaDB und Sphinx erheblich reduzieren. </p><br><p><img src="https://habrastorage.org/webt/lc/rs/rl/lcrsrlzpcw8bzhuptg5s42p6wou.png" alt="Einfache Indexverz√∂gerung aus der Datenbank"></p><br><p><img src="https://habrastorage.org/webt/7h/ik/ic/7hikichzuaqyszagbenen-9drhk.png" alt="RT-Index-Verantwortliche von der Datenbank"></p><br><p>  Wir sind auch viel sicherer geworden, dass alle Updates alle unsere Sphinx-Server p√ºnktlich erreichen. </p><br><p>  Dar√ºber hinaus sind Suchtests (sowohl manuell als auch automatisch) viel angenehmer geworden. </p><br><p>  Leider wurde uns dies nicht kostenlos zur Verf√ºgung gestellt: Die Performance des Echtzeitindex im Vergleich zum einfachen Index erwies sich als etwas schlechter. </p><br><p>  Die Verteilung der Verarbeitungszeit von Suchanfragen in Abh√§ngigkeit von der Zeit f√ºr einen einfachen Index ist unten dargestellt. </p><br><p><img src="https://habrastorage.org/webt/op/ro/gm/oprogmvvdykt244nlbmzeldufhu.png" alt="M√ºssen f√ºr die Ausf√ºhrung von Abfragen - einfach"></p><br><p>  Und hier ist das gleiche Diagramm f√ºr den Echtzeitindex. </p><br><p><img src="https://habrastorage.org/webt/07/ii/ce/07iicewkxbb0qvsrrob6dbwoa2i.png" alt="M√ºssen f√ºr die Ausf√ºhrung von Abfragen - zentrale"></p><br><p>  Sie k√∂nnen sehen, dass der Anteil der "schnellen" Anfragen leicht zur√ºckgegangen ist, w√§hrend der Anteil der "langsamen" Anfragen gestiegen ist. </p><br><h2 id="vmesto-zaklyucheniya">  Anstelle einer Schlussfolgerung </h2><br><p>  Es bleibt zu sagen, dass wir den Code des in diesem Artikel beschriebenen Dienstes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√∂ffentlich zug√§nglich gemacht haben</a> .  Leider gibt es noch keine detaillierte Dokumentation, aber wenn Sie m√∂chten, k√∂nnen Sie ein Beispiel f√ºr die Verwendung dieses Dienstes √ºber <code>docker-compose</code> ausf√ºhren. </p><br><h2 id="ssylki">  Referenzen </h2><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Video-</a> und Berichtsfolien </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Videobericht von Andrey Smirnov und Vyacheslav Kryukov √ºber Highload ++</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Go-MySQL-Bibliothek</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Servicecode mit Verwendungsbeispiel</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de447526/">https://habr.com/ru/post/de447526/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de447512/index.html">Und wer hat das getan? Automatisieren Sie das Audit der Informationssicherheit</a></li>
<li><a href="../de447514/index.html">7 Interessante Startups im IoT</a></li>
<li><a href="../de447516/index.html">Wie wir CAD COMPASS-3D ‚Üí Teil 2 √ºbertaktet haben</a></li>
<li><a href="../de447520/index.html">Auto Tiering-Funktionen im Qsan XCubeSAN-Speicher</a></li>
<li><a href="../de447522/index.html">Welche n√ºtzlichen Dinge k√∂nnen aus den Protokollen einer Windows-basierten Workstation abgerufen werden?</a></li>
<li><a href="../de447528/index.html">Wer ist f√ºr die Qualit√§t verantwortlich?</a></li>
<li><a href="../de447530/index.html">OceanLotus: Malvari-Update f√ºr macOS</a></li>
<li><a href="../de447532/index.html">Splunk Universal Forwarder im Docker als Systemprotokollsammler</a></li>
<li><a href="../de447534/index.html">Kosmonaut Aleksandr Laveykin √ºber den besten Weltraumfilm, G-Force von 20 g und sanfte Landung</a></li>
<li><a href="../de447536/index.html">Implementieren Sie IdM. Vorbereitung zur Umsetzung durch den Kunden</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
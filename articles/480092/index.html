<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💧 🏽 💻 Cómo resolver el problema del reconocimiento de audio en GO 👇 🔽 🏉</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recientemente, BI.ZONE participó en la conferencia HighLoad ++. Está claro que llegamos allí no solo para mirar los stands de otras personas, sino que...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cómo resolver el problema del reconocimiento de audio en GO</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/bizone/blog/480092/">  Recientemente, BI.ZONE participó en la conferencia HighLoad ++.  Está claro que llegamos allí no solo para mirar los stands de otras personas, sino que trajimos algo interesante.  Los empleados de diferentes departamentos de la compañía prepararon tareas para los invitados a la conferencia, cuya solución ofrecimos premios.  Una de las tareas de Golang estaba dedicada al reconocimiento de sonido.  Le pedimos a su autor que hablara de ella. <br><br><h2>  Declaración del problema. </h2><br>  En nuestra tarea, necesitamos indexar un cierto número de pistas y aprender a buscar en la base de datos la composición original por su muestra.  En este caso, la muestra puede ser ruidosa, grabada en un micrófono defectuoso, puede tener una frecuencia diferente.  La mayor parte del código ya ha sido escrito para el participante, solo necesita implementar la función de huella digital, que elimina la huella digital de la pista. <br><a name="habracut"></a><br><h2>  Como grabar un sonido </h2><br>  Está claro que cualquier pista es una onda mecánica que tiene una naturaleza analógica.  Las ondas en física tienen dos características: frecuencia y amplitud.  Con respecto a las ondas de sonido, por simplicidad, podemos suponer que la amplitud es el volumen y la frecuencia es el tono, aunque en realidad los sonidos altos parecen ser más fuertes para una persona con la misma amplitud. <br><br>  Es decir, desde el punto de vista de la física, cada composición se describe mediante una función continua, lo que significa que cualquier pieza arbitrariamente pequeña de la canción contendrá una cantidad infinita de información (aunque si esto es algún tipo de post-punk, entonces probablemente habrá un poco de información en las pistas menos)  Debido a esto, la señal analógica no se puede guardar; tendrá que lidiar con su digitalización.  El enfoque principal para la digitalización de señales analógicas es la modulación de código de pulso, que se discutirá en esta sección.  PCM consta de tres etapas: discretización, cuantización y codificación.  Analicemos brevemente lo que sucede en cada uno de ellos. <br><br><h3>  Discreción </h3><br>  Entonces, tenemos una función de amplitud versus tiempo.  Si alguien tiene una pregunta, dónde está la frecuencia, entonces está oculta detrás de las curvas del gráfico de función.  Todavía no es visible, pero luego la sacaremos.  Como estamos hablando de una señal analógica, la función es continua y se define en el conjunto completo de argumentos posibles (cualquier número real desde cero hasta el final de la pista).  Es decir, conocemos el valor de la función en cualquier momento, y tenemos muchos momentos.  Obviamente no necesitamos tanto, así que solo tome un subconjunto discreto.  Para hacer esto, guardaremos el valor de la señal en un pequeño intervalo fijo.  Debe ser lo suficientemente pequeño para que no escuchemos la diferencia de oído, pero lo suficientemente grande como para no ahorrar demasiado, porque esto tampoco es deseable. <br><br>  De hecho, cuando se digitaliza, no se establece el intervalo, sino la frecuencia, que se denomina "frecuencia de muestreo".  Dependiendo de las tareas, la frecuencia de muestreo puede ser de 8 kHz en teléfonos a varios miles de kHz en equipos de audio profesionales.  La música para escuchar normalmente fuera de los estudios de grabación generalmente se almacena a una frecuencia de 44,1 kHz o 48 kHz. <br><br><h3>  Cuantización </h3><br>  Gracias a la discretización, ahora tenemos un montón de puntos en lugar de un gráfico de función continua, pero aún no podemos trabajar con él, necesitamos estropear aún más el sonido.  La función inicial de la amplitud frente al tiempo comparó la amplitud del continuo con el tiempo del continuo.  Con el tiempo, lo descubrimos, y ahora tenemos que encontrar algo con una amplitud, porque sus valores actuales están dispersos en el conjunto de números reales demasiado caóticos para que podamos salvarlos sin problemas.  Por ejemplo, entre ellos, seguro, hay algunos irracionales que no podemos guardar de ninguna manera sin redondear. <br><br>  La cuantización es un proceso durante el cual redondeamos las amplitudes a valores de un conjunto preseleccionado.  Por supuesto, queremos que el número de amplitudes sea una potencia de dos.  Para pistas de audio ordinarias, se utiliza la cuantización de 16 bits, es decir, el número de amplitudes será 65 536 (de 2 a 16 grados).  La grabación de sonido profesional se puede realizar con mayor precisión, pero pocas personas pueden distinguir la cuantización de 16 bits de la de 24 bits.  Entonces, tomamos el poder de dos, tomamos un montón de amplitudes enteras y las llamamos niveles de cuantización.  Entonces será posible decir que la señal se cuantifica en más de 65 536 niveles (suena autoritativamente, ¿verdad?).  Cada amplitud se redondea a uno de los niveles, lo que en última instancia le permite almacenar su valor en 16 bits, y al oído tal grabación es indistinguible del sonido continuo analógico. <br><br>  Como ilustración, puede ver la imagen a continuación o generar sus propias imágenes en Python (el código es aún más bajo).  La parte superior derecha de la ilustración muestra cinco niveles de cuantización.  Es decir, la pista tendrá solo cinco niveles de volumen. <br><br><img src="https://habrastorage.org/webt/9c/44/ma/9c44marhas3olwvom6w5lhjcxx4.png" alt="imagen"><br>  <i>Algunos ejemplos</i> <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> m <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">f</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> m.sin(x) q = <span class="hljs-number"><span class="hljs-number">1</span></span>/<span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-comment"><span class="hljs-comment">#      k = 0 #      1/2  1/4 vf = np.vectorize(f) orig_f = vf(np.arange(0, 4 * m.pi, 0.001)) quanted_f = q * np.round(orig_f/q + k) plt.plot(orig_f) plt.plot(quanted_f)</span></span></code> </pre> <br><h3>  Codificación </h3><br>  En la etapa de codificación, guardamos los resultados de los pasos anteriores en una forma comprensible.  Todas las acciones antes de esto generalmente son realizadas por equipos especializados, pero queremos tener un archivo en la computadora o una matriz en la memoria donde habrá amplitudes.  En consecuencia, en esta etapa, las señales del equipo se convierten en una serie de números, que llamaremos PCM (modulación de código de pulso) en el futuro.  Sus índices son tiempo condicional (índice de intervalo después del muestreo), y las amplitudes se almacenan en él, redondeadas a enteros en la etapa de cuantificación. <br><br><h2>  Transformada de Fourier </h2><br>  Inicialmente, teníamos una onda mecánica y un deseo de digitalizarla, pero ahora tenemos una señal digitalizada y un deseo de obtener frecuencias de ella.  Lo deseado se puede lograr usando la transformada de Fourier.  Por si acaso, volveré a contar su valor aplicado en este problema.  La transformación de Fourier le permite tomar cualquier función y descomponerla en la suma de senos y cosenos.  Estamos interesados ​​en esto, porque las sinusoides y las ondas de coseno son vibraciones, y el sonido se trata de vibraciones.  Es decir, utilizando la transformación de Fourier, puede obtener los componentes de una oscilación compleja, averiguar su amplitud y frecuencia, simplemente observando qué coeficientes están frente a los argumentos seno y seno (o coseno).  Por ejemplo, existe tal ola. <br><br><img src="https://habrastorage.org/webt/jo/l2/cn/jol2cnvs7nfgyxwrbvbxr3jesvi.png" alt="imagen"><br>  <i>La ola</i> <br><br>  De hecho, sabemos que está definido por la función 10sin (3x) + sin (x) + 4sin (4x) + 20sin (2x), pero esto es ahora, y la onda de sonido real consiste en una miríada de términos, y nos gustaría poder trabaja con eso.  Entonces, <a href="http://www.siarion.net/rus/free/fourierscope/">ejecutemos</a> esta función a través de la transformada de Fourier usando el programa <a href="http://www.siarion.net/rus/free/fourierscope/">FourierScope</a> y observemos el espectro de amplitud. <br><br><img src="https://habrastorage.org/webt/wa/i0/xe/wai0xeqihurjmrbsul2p01dotja.png" alt="imagen"><br>  <i>Espectro de amplitud</i> <br><br>  Así es como se ven los cuatro senos.  Es fácil ver que el gráfico corresponde a los coeficientes de los senos y sus argumentos. <br><br>  Debería aclararse que, de hecho, fue una demostración del poder no de la transformación de Fourier en sí, sino de su versión discreta, adecuada para señales que pasaron por la modulación de código de pulso con todas sus discretizaciones y cuantizaciones.  Sería superfluo presentar un algoritmo para la transformada discreta de Fourier, por lo que debemos estar de acuerdo en el hecho de que existe algo llamado DFT, así como su modificación, la transformada rápida de Fourier (FFT).  En este caso, el sentido aplicado de la FFT es el siguiente: el algoritmo recibe una pieza de PCM en la entrada y proporciona una matriz que contiene las amplitudes, y los intervalos de frecuencia son los índices.  Es una cuestión de intervalos de frecuencia, no solo frecuencias, ya que la conversión es discreta.  En esencia, era ingenuo esperar que se pueda aumentar la señal en todo el artículo y luego obtener frecuencias sin problemas e inexactitudes.  De hecho, el bin de frecuencia es un conjunto de frecuencias que la FFT no puede distinguir entre sí. <br><br>  Vale la pena señalar que las FFT a menudo se escriben incorrectamente al reescribir un algoritmo de libros y artículos.  A continuación se muestra un código más correcto para trabajar con FFT, que es exactamente lo que esperábamos de los participantes en su solución. <br><br><pre> <code class="plaintext hljs">import "github.com/mjibson/go-dsp/fft" ... blocksCount := len(pcm) / fftWindowSize for i := 0; i &lt; blocksCount; i++ { complexArray := fft.FFTReal(pcm[i*fftWindowSize : i*fftWindowSize+fftWindowSize]) // use complexArray... }</code> </pre><br>  La tecnología moderna le permite escribir una transformación rápida de Fourier en solo unas pocas líneas.  FFT se usa para segmentos de tamaño fftWindowSize y devuelve una matriz de números complejos, que usaremos en el futuro para tomar huellas digitales. <br><br>  En general, la transformación de Fourier es el lugar más delgado en todo el problema.  Primero, el tamaño del contenedor es $ \ frac {frecuencia \ muestreo} {size \ window} $.  En consecuencia, puede ampliar la ventana y obtener más frecuencias, lo cual es bueno, pero, por supuesto, tiene consecuencias negativas.  El aumento en el tamaño de la ventana lleva al hecho de que analizamos PCM a grandes intervalos y perdemos sonidos de corta duración.  En diferentes circunstancias, esto puede empeorar repetidamente el programa si los sonidos cortos son parte de la composición, o puede mejorar si solo son ruidos.  O tal vez no afecte nada en absoluto.  En una situación tan difícil, el programador debe actuar con decisión: tome un buen número, como $ 2 ^ 9 $ o $ 2 ^ {10} $, y trate de no molestarse con las complejidades donde esto no es necesario.  Suficiente para resolver el problema, pero en una aplicación seria todavía tiene que usar alguna ventana de Hamming y mucho más para pensar. <br><br><h2>  Huella digital </h2><br>  La tarea es aprender a tener un hash que se pueda asignar a una pista y que sea insensible a los cambios, teniendo las frecuencias y amplitudes de la composición.  Pueden ser muy diferentes: un poco de ruido, un cambio de todas las frecuencias, reproducir otra canción en paralelo, etc.  También debe tener en cuenta que la base de datos puede contener simultáneamente muchas pistas similares que deben distinguirse entre sí.  O tal vez todas las pistas serán diferentes, y el problema no será establecer cuál es la más adecuada, sino comprender que ninguna es adecuada.  En general, hay un cierto margen para la creatividad. <br><br>  Puede tomar una impresión de diferentes maneras.  Digamos que haga un hash en forma de una lista de varios indicadores diferentes.  Entre ellos puede estar, por ejemplo, el número promedio de cruces de señal cero, BPM, valores de frecuencia promedio.  Lo hice en versiones anteriores de <a href="https://github.com/metabrainz">Musicbrainz</a> , y los problemas de este enfoque están escritos <a href="https://wiki.musicbrainz.org/Fingerprinting">aquí</a> .  Y puede considerar conceptos más abstractos, como ritmo, analizar la pista utilizando el algoritmo EM ( <a href="https://ieeexplore.ieee.org/document/1203279">artículo</a> ).  En general, completa libertad de expresión.  Desafortunadamente, la mayoría de los algoritmos propuestos, aparentemente, no tienen una implementación pública, por lo que simplemente tomarlos y compararlos no funcionará. <br><br>  La implementación principal se describe en <a href="https://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf">este</a> artículo.  Es especialmente bueno que pueda implementar este algoritmo en varias líneas.  Por ejemplo, en el artículo original, se propone dividir las frecuencias en 6 intervalos, encontrar la amplitud máxima en cada uno, tomar el promedio de los seis y guardar los contenedores que son más altos que el promedio, pero son posibles muchas otras implementaciones. <br><br><pre> <code class="plaintext hljs">var freqBins = [...]int16{40, 80, 120, 180, 300} func getKeyPoints(frame []freq_domain) int { highScores := make([]float64, len(freqBins)) recordPoints := make([]uint, len(freqBins)) for bin := freqBins[0]; bin &lt; freqBins[len(freqBins)-1]; bin++ { magnitude := frame[bin] binIdx := 0 for freqBins[binIdx] &lt; bin { binIdx++ } if magnitude &gt; highScores[binIdx] { highScores[binIdx] = magnitude recordPoints[binIdx] = (uint)(bin) } } return hash(recordPoints) }</code> </pre><br>  La función anterior implementa el algoritmo de huellas digitales.  Al final, se pasa una matriz de frecuencias (o más bien, bins) a la función hash (), que debería convertir una matriz de varios números en un número.  Puede hacerlo de cualquier manera adecuada, incluso puede intentar usar md5 (aunque esta es una mala idea). <br><br><h2>  Acerca de las pruebas </h2><br>  <b>Se prepararon varios casos de prueba:</b> <br><br><ol><li>  Prueba previa normal con una pista.  El original y la muestra coincidieron completamente. </li><li>  Otra prueba previa con dos pistas.  Los originales coincidieron con las muestras. </li><li>  Se indexa un número ligeramente mayor de pistas, todas se buscan alternativamente. </li><li>  Se carga una gran cantidad de pistas, se buscan, pero después de la disminución de la resolución. </li><li>  Las pistas se indexan después del muestreo descendente, se buscan las originales. </li><li>  Indexado varias pistas similares, buscando una similar, pero no en la base de datos. </li><li>  Se indexan varias pistas, se buscan, pero con ruido. </li></ol><br><br><h2>  Algunos enlaces interesantes </h2><br>  <a href="https://metacpan.org/pod/Audio::Ofa::Util">https://metacpan.org/pod/Audio::Ofa::Util</a> <br>  <a href="https://www.researchgate.net/publication/228347102_A_Review_of_Audio_Fingerprinting">https://www.researchgate.net/publication/228347102_A_Review_of_Audio_Fingerprinting</a> <br>  <a href="http://www.freshmeat.net/projects/songprint">http://www.freshmeat.net/projects/songprint</a> <br>  <a href="https://link.springer.com/article/10.1007/s11265-005-4152-2">https://link.springer.com/article/10.1007/s11265-005-4152-2</a> <br>  <a href="https://github.com/acoustid/chromaprint">https://github.com/acoustid/chromaprint</a> <br>  <a href="https://laplacian.wordpress.com/2009/01/10/how-shazam-works/">https://laplacian.wordpress.com/2009/01/10/how-shazam-works/</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/480092/">https://habr.com/ru/post/480092/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../480080/index.html">¿Qué necesitas en las aplicaciones para tomar notas?</a></li>
<li><a href="../480082/index.html">Uso de particiones en MySQL para Zabbix con una gran cantidad de objetos de monitoreo</a></li>
<li><a href="../480086/index.html">Cómo cumplir con los requisitos de 152-FZ, proteger los datos personales de nuestros clientes y no pisar nuestro rastrillo</a></li>
<li><a href="../480088/index.html">DevOps: OK, pero ¿qué hacer? Cómo reducir el trabajo manual y lograr el resultado deseado</a></li>
<li><a href="../480090/index.html">El código abierto lo es todo</a></li>
<li><a href="../480096/index.html">Fin de la infancia: derechos de autor en obras creadas por inteligencia artificial (IA)</a></li>
<li><a href="../480098/index.html">JH Rainwater "Cómo pastar gatos": en el otro lado del desarrollo</a></li>
<li><a href="../480100/index.html">Principiantes Sobre SEO</a></li>
<li><a href="../480102/index.html">Resumen de gestión de productos de noviembre</a></li>
<li><a href="../480104/index.html">9 trucos HTML útiles</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
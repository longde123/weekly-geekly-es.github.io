<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚ÄçüöÄ üòü üíº ClickHouse Product Analytics VKontakte üë©‚Äçüë©‚Äçüë¶‚Äçüë¶ üë®üèø‚Äçüåæ üòî</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En d√©veloppant n'importe quel produit, qu'il s'agisse d'un service vid√©o ou d'une bande, d'histoires ou d'articles, je veux pouvoir mesurer le "bonheu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>ClickHouse Product Analytics VKontakte</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/vk/blog/445284/"><img src="https://habrastorage.org/webt/0f/oi/nf/0foinfaynjgjrh11h6w55fr5510.jpeg"><br><br>  En d√©veloppant n'importe quel produit, qu'il s'agisse d'un service vid√©o ou d'une bande, d'histoires ou d'articles, je veux pouvoir mesurer le "bonheur" conditionnel de l'utilisateur.  Pour comprendre si nous apportons des changements meilleurs ou pires, pour ajuster la direction du d√©veloppement du produit, en fonction non pas de l'intuition et de nos propres sentiments, mais des m√©triques et des chiffres auxquels vous pouvez croire. <br><br>  Dans cet article, je vais vous expliquer comment nous avons r√©ussi √† lancer des statistiques et des analyses de produits sur un service avec une audience mensuelle de 97 millions de dollars, tout en obtenant des requ√™tes analytiques extr√™mement performantes.  Nous parlerons de ClickHouse, des moteurs utilis√©s et des fonctionnalit√©s des requ√™tes.  Je vais d√©crire une approche de l'agr√©gation de donn√©es, qui nous permet d'obtenir des m√©triques complexes en une fraction de seconde, et parler de la conversion et des tests de donn√©es. <br><br>  Maintenant, nous avons environ 6 milliards d'√©v√©nements alimentaires par jour, dans un avenir proche, nous atteindrons 20 √† 25 milliards.  Et puis - pas √† un rythme aussi rapide, nous atteindrons 40 √† 50 milliards d'ici la fin de l'ann√©e, lorsque nous d√©crirons tous les √©v√©nements alimentaires qui nous int√©ressent. <br><br>  <b>1 rangs en jeu.</b>  <b>√âcoul√©: 0,287 s.</b>  <b>59,85 milliards de lignes trait√©es, 59,85 Go (208,16 milliards de lignes / s., 208,16 Go / s.)</b> <br><br>  D√©tails sous la coupe. <br><a name="habracut"></a><br><h1>  Pr√©face </h1><br>  Les outils analytiques √©taient VKontakte avant.  Des utilisateurs uniques ont √©t√© pris en compte, il a √©t√© possible de construire des plannings d'√©v√©nements par tranches et ainsi de tomber dans les profondeurs du service.  Il s'agissait cependant de tranches fixes d'avance, de donn√©es agr√©g√©es, de HLL pour les uniques, d'une certaine rigidit√© et incapacit√© √† r√©pondre rapidement √† des questions un peu plus compliqu√©es que "combien?" <br><br>  Bien s√ªr, il y avait, il y a et aura hadoop, il a √©galement √©t√© √©crit, √©crit et sera √©crit beaucoup, beaucoup de journaux d'utilisation des services.  Malheureusement, hdfs n'a √©t√© utilis√© que par certaines √©quipes pour impl√©menter leurs propres t√¢ches.  Encore plus tristement, hdfs ne concerne pas les requ√™tes analytiques rapides: il y avait des questions dans de nombreux domaines, dont les r√©ponses devaient √™tre trouv√©es dans le code, et non dans la documentation accessible √† tous. <br><br>  Nous sommes arriv√©s √† la conclusion qu'il n'est plus possible de vivre comme √ßa.  Chaque √©quipe doit disposer de donn√©es, les requ√™tes doivent √™tre rapides et les donn√©es elles-m√™mes doivent √™tre pr√©cises et riches en param√®tres utiles. <br><br>  Par cons√©quent, nous avons formul√© des exigences claires pour le nouveau syst√®me de statistiques / analytiques: <br><br><ul><li>  les requ√™tes analytiques doivent √™tre rapides; </li><li>  les donn√©es sont assez pr√©cises, id√©alement ce sont des √©v√©nements d'interaction utilisateur bruts avec le service; </li><li>  la structure des √©v√©nements doit √™tre d√©crite, comprise et accessible; </li><li>  stockage fiable des donn√©es, garantie de livraison unique; </li><li>  il est possible de compter les uniques, l'audience (quotidienne, hebdomadaire, mensuelle), les mesures de r√©tention, le temps pass√© par l'utilisateur dans le service, les actions quantifi√©es sur les mesures uniques et autres par l'ensemble de tranches; </li><li>  les tests, la conversion des donn√©es et la visualisation sont en cours. </li></ul><br><h1>  Dans la cuisine </h1><br>  L'exp√©rience a sugg√©r√© que nous avions besoin de deux bases de donn√©es: une lente, o√π nous agr√©gerions et enrichirions les donn√©es, et une rapide, o√π nous pourrions travailler avec ces donn√©es et construire des graphiques par-dessus.  C'est l'une des approches les plus courantes, dans laquelle dans une base de donn√©es lente, par exemple, dans hdfs, diff√©rentes projections sont construites - sur des uniques et sur le nombre d'√©v√©nements par tranches pendant une certaine p√©riode de temps. <br><br>  Par une chaude journ√©e de septembre, en discutant autour d'une tasse de th√© dans la cuisine donnant sur la cath√©drale de Kazan, nous avons eu l'id√©e d'essayer ClickHouse comme base rapide - √† cette √©poque, nous l'utilisions d√©j√† pour stocker des journaux techniques.  De nombreux doutes √©taient li√©s principalement √† la vitesse et √† la fiabilit√©: les tests de performances d√©clar√©s semblaient irr√©alistes et les nouvelles versions de la base de donn√©es interrompaient p√©riodiquement les fonctionnalit√©s existantes.  Par cons√©quent, la proposition √©tait simple - √† essayer. <br><br><h1>  Premiers √©chantillons </h1><br>  Nous avons d√©ploy√© un cluster de deux machines avec cette configuration: <br>  2xE5-2620 v4 (32 c≈ìurs au total), 256 Go de RAM, 28 places (raid10 avec ext4). <br><br>  Au d√©part, c'√©tait proche de la mise en page, mais nous sommes pass√©s √† loin.  ClickHouse poss√®de de nombreux moteurs de table diff√©rents, mais les principaux sont de la famille MergeTree.  Nous avons choisi ReplicatedReplacingMergeTree avec √† peu pr√®s les param√®tres suivants: <br><br><pre><code class="sql hljs">PARTITION BY dt ORDER BY (toStartOfHour(time), cityHash64(user_id), event_microsec, event_id) SAMPLE BY cityHash64(user_id) SETTINGS index_granularity = 8192;</code> </pre> <br>  <b>R√©pliqu√©</b> - signifie que la table est r√©pliqu√©e, ce qui r√©sout l'une de nos exigences de fiabilit√©. <br><br>  <b>Remplacement</b> - le tableau prend en charge la d√©duplication par la cl√© primaire: par d√©faut, la cl√© primaire correspond √† la cl√© de tri, donc la section ORDER BY vous indique simplement quelle est la cl√© primaire. <br><br>  <b>SAMPLE BY</b> - Je voulais √©galement essayer d'√©chantillonner: sample renvoie un √©chantillon uniform√©ment pseudo-al√©atoire. <br><br>  <b>index_granularity = 8192</b> est le nombre magique de lignes de donn√©es entre les empattements d'index (oui, c'est rare), qui est utilis√© par d√©faut.  Nous ne l'avons pas chang√©. <br><br>  Le partitionnement a √©t√© effectu√© le jour (bien que par d√©faut - par mois).  De nombreuses demandes de donn√©es √©taient cens√©es √™tre intrajournali√®res - par exemple, cr√©er un graphique minute des vues vid√©o pour un jour donn√©. <br><br>  Ensuite, nous avons pris un morceau de journaux techniques et rempli la table avec environ un milliard de lignes.  Excellente compression, regroupement par type de colonne Int *, comptage de valeurs uniques - tout a fonctionn√© incroyablement vite! <br><br>  En parlant de vitesse, je veux dire que pas une seule requ√™te n'a dur√© plus de 500 ms, et la plupart d'entre elles tiennent dans 50-100 ms.  Et cela se fait sur deux machines - et, en fait, une seule a √©t√© impliqu√©e dans les calculs. <br><br>  Nous avons examin√© tout cela et imagin√© qu'au lieu de la colonne UInt8, il y aurait un identifiant du pays, et la colonne Int8 serait remplac√©e par des donn√©es, par exemple, sur l'√¢ge de l'utilisateur.  Et ils ont r√©alis√© que ClickHouse nous convenait parfaitement, si tout √©tait fait correctement. <br><br><h1>  Saisie forte des donn√©es </h1><br>  L'avantage de ClickHouse commence exactement lorsque le sch√©ma de donn√©es correct est form√©.  Exemple: plateforme String - mauvaise, plateforme Int8 + dictionnaire - bonne, LowCardinality (String) - pratique et bonne (je parlerai de LowCardinality un peu plus tard). <br><br>  Nous avons cr√©√© une classe de g√©n√©rateur sp√©ciale en php, qui, sur demande, cr√©e des classes wrapper sur des √©v√©nements bas√©s sur des tables dans ClickHouse, et un point d'entr√©e unique pour la journalisation.  Je vais expliquer l'exemple du sch√©ma qui s'est av√©r√©: <br><br><ol><li>  L'analyste / ing√©nieur / d√©veloppeur de donn√©es d√©crit la documentation: quels champs, valeurs possibles, √©v√©nements doivent √™tre enregistr√©s. </li><li>  Un tableau est cr√©√© dans ClickHouse conform√©ment √† la structure de donn√©es du paragraphe pr√©c√©dent. </li><li>  Des classes d'habillage pour les √©v√©nements bas√©s sur une table sont g√©n√©r√©es. </li><li>  L'√©quipe produit impl√©mente le remplissage des champs d'un objet de cette classe, l'envoi. </li></ol><br>  Changer le sch√©ma au niveau php et le type de donn√©es enregistr√©es ne fonctionnera pas sans d'abord changer la table dans ClickHouse.  Et cela, √† son tour, ne peut se faire sans coordination avec l'√©quipe, modifications de la documentation et description des √©v√©nements. <br><br>  Pour chaque √©v√©nement, vous pouvez d√©finir deux param√®tres qui contr√¥lent respectivement le pourcentage d'√©v√©nements envoy√©s √† ClickHouse et hadoop.  Les param√®tres sont n√©cessaires principalement pour un roulement progressif avec la possibilit√© de r√©duire la journalisation en cas de probl√®me.  Avant hadoop, les donn√©es sont livr√©es de mani√®re standard √† l'aide de Kafka.  Et dans ClickHouse, ils volent √† travers un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sch√©ma avec KittenHouse</a> en mode persistant, ce qui garantit au moins une livraison d'√©v√©nement unique. <br><br>  L'√©v√©nement est remis √† la table tampon dans le fragment souhait√©, sur la base du reste de la division du hachage de user_id par le nombre de fragments dans le cluster.  Ensuite, la table tampon vide les donn√©es dans le ReplicatedReplacingMergeTree local.  Et au-dessus des tables locales, une table distribu√©e est extraite avec le moteur distribu√©, qui vous permet d'acc√©der aux donn√©es de tous les fragments. <br><br><h1>  D√©normalisation </h1><br>  ClickHouse est un SGBD en colonnes.  Il ne s'agit pas de formulaires normaux, ce qui signifie qu'il vaut mieux avoir toutes les informations sur l'√©v√©nement que de se joindre.  Il y a aussi Join, mais si la bonne table ne tient pas en m√©moire, la douleur commence.  Par cons√©quent, nous avons pris une d√©cision ferme: toutes les informations qui nous int√©ressent doivent √™tre stock√©es dans l'√©v√©nement lui-m√™me.  Par exemple, le sexe, l'√¢ge de l'utilisateur, le pays, la ville, l'anniversaire - toutes ces informations publiques peuvent √™tre utiles pour l'analyse d'audience, ainsi que toutes les informations utiles sur l'objet d'interaction.  Si, par exemple, nous parlons de vid√©o, il s'agit de video_id, video_owner_id, la date de mise en ligne de la vid√©o, la dur√©e, la qualit√© au moment de l'√©v√©nement, la qualit√© maximale, etc. <br><br>  Au total, dans chaque table, nous avons de 50 √† 200 colonnes, tandis que dans toutes les tables, il y a des champs de service.  Par exemple, le journal des erreurs est error_log - en fait, nous appelons une erreur hors de port√©e du type.  Au cas o√π des valeurs √©tranges d√©passeraient la taille du type dans le champ avec l'√¢ge. <br><br><h2>  Type LowCardinality (T) </h2><br>  ClickHouse a la possibilit√© d'utiliser des dictionnaires externes.  Ils sont stock√©s en m√©moire, mis √† jour p√©riodiquement, peuvent √™tre efficacement utilis√©s dans divers sc√©narios, y compris comme des ouvrages de r√©f√©rence classiques.  Par exemple, vous souhaitez enregistrer le syst√®me d'exploitation et vous avez deux alternatives: une cha√Æne ou un nombre + un r√©pertoire.  Bien s√ªr, sur de grandes quantit√©s de donn√©es et pour les requ√™tes analytiques hautes performances, il est logique d'√©crire un nombre et d'obtenir une repr√©sentation sous forme de cha√Æne √† partir du dictionnaire lorsque vous avez besoin: <br><br><pre> <code class="sql hljs">dictGetString('os', 'os_name', toUInt64(os_id))</code> </pre> <br>  Mais il existe un moyen beaucoup plus pratique - d'utiliser le type LowCardinality (String), qui cr√©e automatiquement un dictionnaire.  La performance avec LowCardinality sous la condition de faible cardinalit√© de l'ensemble de valeurs est radicalement plus √©lev√©e qu'avec String. <br><br>  Par exemple, nous utilisons LowCardinality (String) pour les types d'√©v√©nements 'play', 'pause', 'rewind'.  Ou pour la plateforme: 'web', 'android', 'iphone': <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> vk_platform, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt = yesterday() <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> vk_platform Elapsed: <span class="hljs-number"><span class="hljs-number">0.145</span></span> sec. Processed <span class="hljs-number"><span class="hljs-number">1.98</span></span> billion <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>, <span class="hljs-number"><span class="hljs-number">5.96</span></span> GB (<span class="hljs-number"><span class="hljs-number">13.65</span></span> billion <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>/s., <span class="hljs-number"><span class="hljs-number">41.04</span></span> GB/s.)</code> </pre> <br>  La fonctionnalit√© est encore exp√©rimentale, donc pour l'utiliser, vous devez effectuer: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> allow_experimental_low_cardinality_type = <span class="hljs-number"><span class="hljs-number">1</span></span>;</code> </pre> <br>  Mais on a le sentiment qu‚Äôapr√®s un certain temps, elle ne sera plus sous le d√©cor. <br><br><h1>  Agr√©gation de donn√©es VKontakte </h1><br>  Puisqu'il y a beaucoup de colonnes et qu'il y a beaucoup d'√©v√©nements, le d√©sir naturel est de couper les ¬´vieilles¬ª partitions, mais d'abord - d'assembler les unit√©s.  Parfois, il est n√©cessaire d'analyser les √©v√©nements bruts (il y a un mois ou un an), afin de ne pas couper les donn√©es en hdfs - tout analyste peut contacter le parquet souhait√© pour n'importe quelle date. <br><br>  En r√®gle g√©n√©rale, lors de l'agr√©gation dans un intervalle de temps, nous nous appuyons toujours sur le fait que le nombre de lignes par unit√© de temps est √©gal au produit de la puissance de coupure.  Cela impose des restrictions: les pays commencent √† se regrouper en groupes tels que `` Russie '', `` Asie '', `` Europe '', `` Le reste du monde '', et les √¢ges - √† intervalles pour r√©duire la dimension √† un million de lignes conditionnelles par date. <br><br><h2>  Agr√©gation par <b>dt, user_id</b> </h2><br>  Mais nous avons un ClickHouse r√©actif!  Pouvons-nous acc√©l√©rer √† 50-100 millions de lignes √† une date? <br>  Des tests rapides ont montr√© que nous pouvions, et √† ce moment une id√©e simple a surgi - laisser l'utilisateur dans la machine.  √Ä savoir, pour agr√©ger non pas par ¬´date, tranches¬ª √† l'aide d'outils spark, mais par ¬´date, utilisateur¬ª signifie par ClickHouse, tout en faisant une ¬´transposition¬ª des donn√©es. <br><br>  Avec cette approche, nous stockons les utilisateurs dans des donn√©es agr√©g√©es, ce qui signifie que nous pouvons toujours prendre en compte les indicateurs d'audience, la r√©tention et les mesures de fr√©quence.  Nous pouvons connecter des unit√©s, en comptant les audiences communes de plusieurs services jusqu'√† l'audience VKontakte enti√®re.  Tout cela peut √™tre fait par n'importe quelle tranche qui est pr√©sente dans le tableau pour le m√™me temps conditionnellement. <br><br>  Je vais illustrer avec un exemple: <br><br><img src="https://habrastorage.org/webt/1n/zq/23/1nzq23ia7micv91mecw0kqzxgrm.jpeg"><br><br>  Apr√®s agr√©gation (beaucoup plus de colonnes √† droite): <br><br><img src="https://habrastorage.org/webt/nx/ol/xl/nxolxl2vmnnlsxlx6svuaklh9go.jpeg"><br><br>  Dans ce cas, l'agr√©gation se produit pr√©cis√©ment par (dt, user_id).  Pour les champs contenant des informations utilisateur, avec une telle agr√©gation, vous pouvez utiliser les fonctions any, anyHeavy (s√©lectionne une valeur fr√©quente).  Vous pouvez, par exemple, collecter anyHeavy (plateforme) dans un agr√©gat pour savoir quelle plateforme l'utilisateur utilise pour la plupart √† partir d'√©v√©nements vid√©o.  Si vous le souhaitez, vous pouvez utiliser groupUniqArray (plateforme) et stocker un tableau de toutes les plateformes √† partir desquelles l'utilisateur a d√©clench√© l'√©v√©nement.  Si cela ne suffit pas, vous pouvez cr√©er des colonnes distinctes pour la plateforme et stocker, par exemple, le nombre de vid√©os uniques visionn√©es √† la moiti√© √† partir d'une plateforme sp√©cifique: <br><br><pre> <code class="sql hljs">uniqCombinedIf(cityHash64(video_owner_id, video_id), (platform = 'android') AND (event = '50p')) as uniq_videos_50p_android</code> </pre> <br>  Avec cette approche, on obtient un agr√©gat assez large dans lequel chaque ligne est un utilisateur unique, et chaque colonne contient des informations soit sur l'utilisateur, soit sur son interaction avec le service. <br><br>  Il s'av√®re que pour calculer la DAU d'un service, il suffit d'ex√©cuter une telle demande au-dessus de son agr√©gat: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> dt, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> DAU <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> dt Elapsed: <span class="hljs-number"><span class="hljs-number">0.078</span></span> sec.</code> </pre> <br>  Ou calculez combien de jours les utilisateurs ont √©t√© dans le service pour la semaine: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> days_in_service, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uniques <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> uniqUpTo(<span class="hljs-number"><span class="hljs-number">7</span></span>)(dt) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg2 <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt &gt; (yesterday() - <span class="hljs-number"><span class="hljs-number">7</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> user_id ) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span> <span class="hljs-number"><span class="hljs-number">7</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">2.922</span></span> sec.</code> </pre> <br>  Nous pouvons acc√©l√©rer par √©chantillonnage, tout en perdant presque toute pr√©cision: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> days_in_service, <span class="hljs-number"><span class="hljs-number">10</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uniques <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> uniqUpTo(<span class="hljs-number"><span class="hljs-number">7</span></span>)(dt) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg2 <span class="hljs-keyword"><span class="hljs-keyword">SAMPLE</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> / <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt &gt; (yesterday() - <span class="hljs-number"><span class="hljs-number">7</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> user_id ) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span> <span class="hljs-number"><span class="hljs-number">7</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.454</span></span> sec.</code> </pre> <br>  Il convient de noter tout de suite que l'√©chantillonnage n'est pas bas√© sur le pourcentage d'√©v√©nements, mais sur le pourcentage d'utilisateurs - et en cons√©quence, il devient un outil incroyablement puissant. <br><br>  Ou la m√™me chose pendant 4 semaines avec 1/100 d'√©chantillonnage - environ 1% de r√©sultats moins pr√©cis sont obtenus. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> days_in_service, <span class="hljs-number"><span class="hljs-number">100</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uniques <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> uniqUpTo(<span class="hljs-number"><span class="hljs-number">7</span></span>)(dt) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg2 <span class="hljs-keyword"><span class="hljs-keyword">SAMPLE</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt &gt; (yesterday() - <span class="hljs-number"><span class="hljs-number">28</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> user_id ) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span> <span class="hljs-number"><span class="hljs-number">28</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.287</span></span> sec.</code> </pre> <br><h2>  Agr√©gation d'autre part </h2><br>  Lors de l'agr√©gation par (dt, user_id), nous ne perdons pas l'utilisateur, nous ne manquons pas d'informations sur son interaction avec le service, mais, bien s√ªr, nous perdons les m√©triques sur un objet d'interaction sp√©cifique.  Mais vous ne pouvez pas perdre cela non plus - construisons l'unit√© en <br>  (dt, video_owner_id, video_id), en adh√©rant aux m√™mes id√©es.  Nous conservons autant que possible les informations sur la vid√©o, nous ne manquons pas de donn√©es sur l'interaction de la vid√©o avec l'utilisateur et nous manquons compl√®tement les informations sur l'utilisateur sp√©cifique. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> starts <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg3 <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> (dt = yesterday()) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> (video_id = ...) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> (video_owner_id = ...) <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.030</span></span> sec</code> </pre> <br>  Ou le top 10 des vid√©os vues hier: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> video_id, video_owner_id, watches <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> video_agg_video_d1 <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt = yesterday() <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> watches <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIMIT</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.035</span></span> sec.</code> </pre> <br>  En cons√©quence, nous avons un sch√©ma d'agr√©gats de la forme: <br><br><ul><li>  agr√©gation par ¬´date, utilisateur¬ª dans le produit; </li><li>  agr√©gation par ¬´date, objet d'interaction¬ª au sein du produit; </li><li>  parfois d'autres projections surgissent. </li></ul><br><h1>  Azkaban et TeamCity </h1><br>  Enfin, quelques mots sur l'infrastructure.  Notre collecte d'agr√©gats commence la nuit, en commen√ßant par OPTIMISER sur chacune des tables avec des donn√©es brutes pour d√©clencher une fusion de donn√©es extraordinaire dans ReplicatedReplacingMergeTree.  L'op√©ration peut durer assez longtemps, cependant, il est n√©cessaire de retirer les prises, si elles se produisent.  Il convient de noter que, jusqu'√† pr√©sent, je n'ai jamais rencontr√© de doublons, mais rien ne garantit qu'ils n'appara√Ætront pas √† l'avenir. <br><br>  L'√©tape suivante est la cr√©ation d'agr√©gats.  Ce sont des scripts bash dans lesquels les √©v√©nements suivants se produisent: <br><br><ul><li>  nous obtenons d'abord le nombre de fragments et un h√¥te du fragment: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> shard_num, <span class="hljs-keyword"><span class="hljs-keyword">any</span></span>(host_name) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> host <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> system.clusters <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> shard_num</code> </pre> </li><li>  puis le script ex√©cute s√©quentiellement pour chaque fragment (clickhouse-client -h $ host) une requ√™te du formulaire (pour les agr√©gats par utilisateurs): <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">SAMPLE</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>/$shards_count <span class="hljs-keyword"><span class="hljs-keyword">OFFSET</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>/$shard_num</code> </pre> </li></ul><br>  Ce n'est pas enti√®rement optimal et peut g√©n√©rer de nombreuses interactions r√©seau entre les h√¥tes.  Cependant, lors de l'ajout de nouveaux fragments, tout continue √† fonctionner, la localit√© des donn√©es pour les unit√©s est conserv√©e, nous avons donc d√©cid√© de ne pas trop nous en pr√©occuper. <br><br>  Nous avons Azkaban comme planificateur de t√¢ches.  Je ne dirais pas que c'est un outil super pratique, mais il fait parfaitement face √† sa t√¢che, y compris lorsqu'il s'agit de construire des pipelines l√©g√®rement plus complexes et lorsqu'un script doit attendre que plusieurs autres se terminent. <br><br>  Le temps total consacr√© √† la conversion des √©v√©nements existants en agr√©gats est de 15 minutes. <br><br><h2>  Test </h2><br>  Chaque matin, nous effectuons des tests automatis√©s qui r√©pondent aux questions concernant les donn√©es brutes, ainsi que la disponibilit√© et la qualit√© des agr√©gats: ¬´V√©rifiez que pour hier il n'y avait pas plus d'un demi pour cent de donn√©es en moins ou des donn√©es uniques sur les donn√©es brutes ou dans les agr√©gats par rapport au m√™me jour il y a une semaine. " <br><br>  Technologiquement, ce sont des tests unitaires ordinaires utilisant JUnit et impl√©mentant le pilote jdbc pour ClickHouse.  L'ex√©cution de tous les tests est lanc√©e dans TeamCity et prend environ 30 secondes dans 1 thread, et en cas d'√©checs, nous recevons des notifications VKontakte de notre merveilleux bot TeamCity. <br><br><h1>  Conclusion </h1><br>  Utilisez uniquement des versions stables de ClickHouse et vos cheveux seront doux et soyeux.  Il convient d'ajouter que <b><i>ClickHouse ne ralentit pas</i></b> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr445284/">https://habr.com/ru/post/fr445284/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr445272/index.html">JavaScript est le meilleur langage de programmation pour les d√©butants. C'est vrai ou pas?</a></li>
<li><a href="../fr445274/index.html">Lorsque "Zo√´"! == "Zo√´", ou pourquoi vous devez normaliser les cha√Ænes Unicode</a></li>
<li><a href="../fr445276/index.html">Guide d'utilisation complet</a></li>
<li><a href="../fr445278/index.html">Comment cr√©er un jeu si vous n'√™tes jamais artiste</a></li>
<li><a href="../fr445280/index.html">Rentabilit√© des sites et des services</a></li>
<li><a href="../fr445286/index.html">Repose-pieds pour le cerveau: Hedera Hashgraph Distributed Registry Platform</a></li>
<li><a href="../fr445288/index.html">Tous vos pr√™ts √† la consommation et vos donn√©es personnelles ¬´en un seul endroit¬ª ...</a></li>
<li><a href="../fr445290/index.html">Comment mettre en ≈ìuvre des processus unifi√©s prenant en compte toutes les fonctionnalit√©s de l'entreprise?</a></li>
<li><a href="../fr445292/index.html">Ce qu'on ne m'a jamais dit sur CSS</a></li>
<li><a href="../fr445294/index.html">Et encore une fois sur le deuxi√®me moniteur de la tablette ...</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
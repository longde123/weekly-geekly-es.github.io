<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚Äçüöí ‚öõÔ∏è üîë Clasificaci√≥n de la cobertura del suelo utilizando eo-learn. Parte 3 üî≠ üë®üèø üë®üèø‚Äçüíº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cuando necesita mejores resultados que satisfactorios 


 Parte 1 
 Parte 2 





 La transici√≥n de la zona de invierno a verano se compone de im√°gene...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Clasificaci√≥n de la cobertura del suelo utilizando eo-learn. Parte 3</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/453354/"><p>  Cuando necesita mejores resultados que satisfactorios </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 1</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 2</a> </p><br><p><img src="https://habrastorage.org/webt/c0/ls/b2/c0lsb2it_c9qwggm74kdk3uglw4.png"></p><br><p> <em>La transici√≥n de la zona de invierno a verano se compone de im√°genes Sentinel-2.</em>  <em>Puede notar algunas diferencias en los tipos de cobertura en la nieve, que se describi√≥ en un art√≠culo anterior.</em> </p><a name="habracut"></a><br><h2 id="predislovie">  Pr√≥logo </h2><br><p> Las √∫ltimas dos semanas han sido muy dif√≠ciles.  Publicamos la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">primera</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">segunda</a> parte de nuestros art√≠culos sobre la clasificaci√≥n de la cobertura en todo el pa√≠s utilizando el marco <code>eo-learn</code> .  <code>eo-learn</code> es una biblioteca de c√≥digo abierto para crear una capa entre la recepci√≥n y el procesamiento de im√°genes satelitales y el aprendizaje autom√°tico.  En art√≠culos anteriores en los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ejemplos,</a> indicamos solo un peque√±o subconjunto de los datos y mostramos los resultados solo en un peque√±o porcentaje del √°rea de inter√©s completa (AOI - √°rea de inter√©s).  S√© que esto parece al menos no muy impresionante, y quiz√°s muy grosero de nuestra parte.  Todo este tiempo has sido atormentado por preguntas sobre c√≥mo puedes usar este conocimiento y transferirlo al <em>siguiente</em> nivel. </p><br><p>  ¬°No se preocupe, para eso es el tercer art√≠culo de esta serie!  Toma una taza de caf√© y toma asiento ... </p><br><h2 id="all-our-data-are-belong-to-you">  ¬°Todos nuestros datos te pertenecen! </h2><br><p>  Ya estas sentado  Tal vez deje el caf√© sobre la mesa por otro segundo, porque ahora escuchar√° las mejores noticias de hoy ... <br>  En Sinergise decidimos publicar el conjunto de datos completo para Eslovenia para 2017.  Gratis  ¬°Puede acceder libremente a 200 GB de datos en forma de ~ 300 fragmentos de EOPatch, cada uno aproximadamente en el tama√±o de 1000x1000, en una resoluci√≥n de 10 m!  Puede leer m√°s sobre el formato EOPatch en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">√∫ltima publicaci√≥n</a> sobre <code>eo-learn</code> , pero de hecho es un contenedor de datos <em>geo-temporales</em> EO (Observaci√≥n de la Tierra) y no EO: por ejemplo, im√°genes de sat√©lite, m√°scaras, mapas, etc. </p><br><p><img src="https://habrastorage.org/webt/dc/nt/gy/dcntgywsu4la7pdpwegv5m6eskc.png"><br>  <em>Estructura EOPatch</em> ) </p><br><p>  No pirateamos cuando descargamos estos datos.  ¬°Cada EOPatch contiene im√°genes de Sentinel-2 L1C, su m√°scara <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">s2cloudless</a> correspondiente y el mapa oficial de cobertura del suelo en formato r√°ster! </p><br><p>  Los datos se almacenan en AWS S3 en: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://eo-learn.sentinel-hub.com/</a> </p><br><p>  Deserializar un objeto EOPatch es bastante simple: </p><br><pre> <code class="python hljs">EOPatch.load(<span class="hljs-string"><span class="hljs-string">'path_to_eopatches/eopatch-0x6/'</span></span>)</code> </pre> <br><p>  Como resultado, obtienes un objeto de la siguiente estructura: </p><br><pre> <code class="python hljs">EOPatch( data: { BANDS: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>), dtype=float32) } mask: { CLM: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=uint8) IS_DATA: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=uint8) IS_VALID: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=bool) } mask_timeless: { LULC: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=uint8) VALID_COUNT: numpy.ndarray(shape=(<span class="hljs-number"><span class="hljs-number">1010</span></span>, <span class="hljs-number"><span class="hljs-number">999</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=int64) } meta_info: { maxcc: <span class="hljs-number"><span class="hljs-number">0.8</span></span> service_type: <span class="hljs-string"><span class="hljs-string">'wcs'</span></span> size_x: <span class="hljs-string"><span class="hljs-string">'10m'</span></span> size_y: <span class="hljs-string"><span class="hljs-string">'10m'</span></span> time_difference: datetime.timedelta(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">86399</span></span>) time_interval: (datetime.datetime(<span class="hljs-number"><span class="hljs-number">2017</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>), datetime.datetime(<span class="hljs-number"><span class="hljs-number">2017</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">31</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)) } bbox: BBox(((<span class="hljs-number"><span class="hljs-number">370230.5261411405</span></span>, <span class="hljs-number"><span class="hljs-number">5085303.344972428</span></span>), (<span class="hljs-number"><span class="hljs-number">380225.31836121203</span></span>, <span class="hljs-number"><span class="hljs-number">5095400.767924464</span></span>)), crs=EPSG:<span class="hljs-number"><span class="hljs-number">32633</span></span>) timestamp: [datetime.datetime(<span class="hljs-number"><span class="hljs-number">2017</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>), ..., datetime.datetime(<span class="hljs-number"><span class="hljs-number">2017</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">25</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)], length=<span class="hljs-number"><span class="hljs-number">80</span></span> )</code> </pre> <br><p>  El acceso a los diversos atributos de EOPatch es el siguiente: </p><br><pre> <code class="python hljs">eopatch.timestamp eopatch.mask[<span class="hljs-string"><span class="hljs-string">'LULC'</span></span>] eopatch.data[<span class="hljs-string"><span class="hljs-string">'CLM'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] eopatch.data[<span class="hljs-string"><span class="hljs-string">'BANDS'</span></span>][<span class="hljs-number"><span class="hljs-number">5</span></span>][..., [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]]</code> </pre> <br><h3 id="eoexecute-order-66">  EO Ejecutar orden 66 </h3><br><p>  Genial, los datos se est√°n cargando.  Mientras esperamos la finalizaci√≥n de este proceso, echemos un vistazo a las capacidades de una clase que a√∫n no se ha discutido en estos art√≠culos: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><code>EOExecutor</code></a> .  Este m√≥dulo se dedica a la ejecuci√≥n y monitoreo de la tuber√≠a y permite el uso de subprocesos m√∫ltiples sin esfuerzos innecesarios.  No m√°s b√∫squedas en Stack Overflow sobre c√≥mo paralelizar la tuber√≠a correctamente o c√≥mo hacer que la barra de progreso funcione en este modo: ¬°ya hemos hecho todo por usted! </p><br><p>  Adem√°s, maneja los errores que ocurren y puede generar un breve resumen del proceso de ejecuci√≥n.  Este √∫ltimo es el momento m√°s importante para estar seguro de la repetibilidad de sus resultados en el futuro, para que el usuario no tenga que pasar un tiempo de trabajo precioso buscando los par√°metros que utiliz√≥ el jueves pasado a las 9 a.m. despu√©s de una noche de juerga (no mezcle alcohol y programaci√≥n) vale la pena!).  ¬°Esta clase tambi√©n puede generar un buen gr√°fico de dependencia para la tuber√≠a, que puede mostrarle a su jefe! </p><br><p><img src="https://habrastorage.org/webt/_o/x7/0q/_ox70q41_uiebqp7opyqbeu0nx0.png"><br>  <em>Gr√°fico de dependencia de canalizaci√≥n generado por <code>eo-learn</code></em> </p><br><h3 id="eksperimenty-s-mashinnym-obucheniem">  Experimentos de aprendizaje autom√°tico </h3><br><p>  Como se prometi√≥, este art√≠culo est√° destinado principalmente a estudiar diferentes modelos con <code>eo-learn</code> utilizando los datos que proporcionamos.  A continuaci√≥n, hemos preparado dos experimentos en los que estudiamos el efecto de las nubes y diferentes algoritmos de remuestreo durante la interpolaci√≥n temporal sobre el resultado final.  Despu√©s de todo esto, comenzaremos a trabajar con redes de convoluci√≥n (CNN) y compararemos los resultados de dos enfoques: el an√°lisis p√≠xel por p√≠xel del √°rbol de decisi√≥n y el aprendizaje profundo utilizando redes neuronales convolucionales. </p><br><p>  Lamentablemente, no se puede dar una respuesta inequ√≠voca sobre las decisiones que se deben tomar durante los experimentos.  Puede estudiar el √°rea tem√°tica m√°s profundamente y hacer suposiciones para decidir si el juego vale la pena, pero en √∫ltima instancia, el trabajo se reducir√° a prueba y error. </p><br><h3 id="igraem-s-oblakami">  Jugar con las nubes </h3><br><p>  Las nubes son un gran dolor en el mundo de EO, especialmente cuando se trata de algoritmos de aprendizaje autom√°tico, donde desea determinarlos y eliminarlos del conjunto de datos para la interpolaci√≥n basada en valores perdidos.  Pero, ¬øqu√© tan grande es el beneficio de este procedimiento?  ¬øVale la pena?  Ru√üwurm y K√∂rner, en su <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo Clasificaci√≥n de la cobertura de la tierra</a> multitemporal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">con codificadores secuenciales recurrentes,</a> incluso demostraron que para el aprendizaje profundo, el proceso de filtrado de nubes probablemente no tenga ninguna importancia, ya que el clasificador mismo puede detectar nubes e ignorarlas. </p><br><p><img src="https://habrastorage.org/webt/gz/c8/zs/gzc8zsp0nrdjtgbewqqysxulaiu.png"><br>  Activaci√≥n de la capa de entrada (arriba) y la capa de modulaci√≥n (abajo) en la secuencia de im√°genes de un fragmento espec√≠fico para una red neuronal.  Puede notar que este fragmento de red aprendi√≥ a crear m√°scaras de nube y filtrar los resultados obtenidos.  (P√°gina 9 en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://www.researchgate.net/publication/322975904_Multi-Temporal_Land_Cover_Classification_with_Sequential_Recurrent_Encoders</a> ) </p><br><p>  Recordamos brevemente la estructura del paso de filtrado de datos (para m√°s detalles, consulte [art√≠culo anterior] ()).  Despu√©s de tomar instant√°neas de Sentinel-2, comenzamos a filtrar instant√°neas en la nube.  Todas las im√°genes en las que el n√∫mero de p√≠xeles no nublados no supere el 80% est√°n sujetas a selecci√≥n (los valores de umbral pueden diferir para diferentes √°reas de inter√©s).  Despu√©s de eso, para obtener valores de p√≠xeles en d√≠as arbitrarios, se usan m√°scaras de nubes para no tener en cuenta dichos datos. </p><br><p>  En total, cuatro comportamientos son posibles: </p><br><ol><li>  <strong>con</strong> filtro de imagen, m√°scaras de nubes <strong>dadas</strong> </li><li>  <strong>sin</strong> filtro de instant√°neas, <strong>con</strong> m√°scaras de nube <strong>dadas</strong> </li><li>  <strong>con</strong> filtro de imagen, excluyendo m√°scaras de nubes </li><li>  <strong>sin</strong> filtro de imagen, <strong>sin incluir</strong> m√°scaras de nube </li></ol><br><p><img src="https://habrastorage.org/webt/rd/3i/ne/rd3ineypd8f0akhs41yve8mtgso.png"><br>  <em>Visualizaci√≥n visual de la pila de im√°genes del sat√©lite Sentinel-2.</em>  <em>Los p√≠xeles transparentes a la izquierda significan p√≠xeles faltantes debido a la capa de nubes.</em>  <em>La pila central muestra los valores de p√≠xeles despu√©s de filtrar im√°genes e interpolarlas con una m√°scara de nubes (Caso 4), y la pila de la derecha muestra el resultado de la interpolaci√≥n en el caso sin filtrar im√°genes y sin m√°scaras de nubes (1).</em>  <em>(Nota: aparentemente, el art√≠culo contiene un error tipogr√°fico, y significaba lo contrario: el caso 1 en el centro y el 4 a la derecha).</em> </p><br><p>  En el √∫ltimo art√≠culo, ya realizamos una variaci√≥n del caso 1 y mostramos los resultados, por lo que los utilizaremos para comparar.  Preparar otros transportadores y entrenar el modelo parece una tarea simple: solo necesita asegurarse de que estamos comparando los valores correctos.  Para hacer esto, solo tome el mismo conjunto de p√≠xeles para entrenar y validar el modelo. </p><br><p>  Los resultados se muestran en la tabla a continuaci√≥n.  ¬°Puede ver que, en general, la influencia de las nubes en el resultado del modelo es bastante baja!  Esto puede deberse al hecho de que la tarjeta de referencia es de muy buena calidad y el modelo puede ignorar la mayor√≠a de las im√°genes.  En cualquier caso, este comportamiento no puede garantizarse para ning√∫n AOI, ¬°as√≠ que t√≥mate tu tiempo para eliminar este paso de tus modelos! </p><br><div class="scrollable-table"><table><thead><tr><th>  Modelo </th><th>  Precisi√≥n [%] </th><th>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">F_1</a> [%] </th></tr></thead><tbody><tr><td>  Sin filtros, sin m√°scara. </td><td>  92,8 </td><td>  92,6 </td></tr><tr><td>  Sin filtros, con m√°scara. </td><td>  94,2 </td><td>  93,9 </td></tr><tr><td>  Con filtro, sin mascarilla </td><td>  94,0 </td><td>  93,8 </td></tr><tr><td>  Con filtro, con mascarilla </td><td>  94,4 </td><td>  94,1 </td></tr></tbody></table></div><br><h3 id="vliyanie-raznyh-podhodov-k-resemplingu">  El impacto de diferentes enfoques de remuestreo </h3><br><p>  La elecci√≥n de las opciones de remuestreo temporal no es obvia.  Por un lado, necesitamos una matriz detallada de im√°genes que muestren bien los detalles de las im√°genes de origen; queremos incluir el n√∫mero de im√°genes m√°s cercano posible a los datos de origen.  Por otro lado, estamos limitados por los recursos inform√°ticos.  La reducci√≥n del paso de remuestreo duplica el n√∫mero de fotogramas despu√©s de la interpolaci√≥n y, por lo tanto, aumenta el n√∫mero de atributos que se utilizan en el entrenamiento.  ¬øVale esa mejora el costo de los recursos?  Esto es lo que tenemos que descubrir. </p><br><p>  Para este experimento, utilizaremos la variaci√≥n 1 del paso anterior.  Despu√©s de la interpolaci√≥n, volvemos a muestrear con las siguientes variaciones: </p><br><ol><li>  Muestreo uniforme con un intervalo de 16 d√≠as. </li><li>  Muestreo uniforme con un intervalo de 8 d√≠as. </li><li>  La elecci√≥n de las "mejores" fechas, el n√∫mero coincide con el caso 2. </li></ol><br><p>  La muestra en el caso 3 se basa en el mayor n√∫mero de fechas comunes para todos los EOPatch en el AOI seleccionado <br><img src="https://habrastorage.org/webt/xg/qa/9w/xgqa9w17-oe4dbtxca22yejwhzo.png"><br>  <em>El gr√°fico muestra el n√∫mero de fragmentos de EOPatch que contienen datos para cada d√≠a de 2017 (azul).</em>  <em>Las l√≠neas rojas muestran las fechas √≥ptimas para el remuestreo, que se basan en las fechas de las im√°genes de Sentinel-2 para el AOI 2017 dado.</em> </p><br><p>  Mirando la tabla a continuaci√≥n, puede ver que los resultados no son muy impresionantes, como en la experiencia pasada.  Para los casos 2 y 3, la cantidad de tiempo invertido se duplica, pero la diferencia con el enfoque inicial es inferior al 1%.  Dichas mejoras son demasiado discretas para un uso pr√°ctico, por lo que podemos considerar el intervalo de 16 d√≠as adecuado para la tarea. </p><br><div class="scrollable-table"><table><thead><tr><th>  Modelo </th><th>  Precisi√≥n [%] </th><th>  F_1 [%] </th></tr></thead><tbody><tr><td>  Uniformemente cada 16 d√≠as </td><td>  94,4 </td><td>  94,1 </td></tr><tr><td>  Uniformemente cada 8 d√≠as </td><td>  94,5 </td><td>  94,3 </td></tr><tr><td>  Elegir las mejores fechas </td><td>  94,6 </td><td>  94,4 </td></tr></tbody></table></div><br><p>  <em>Resultados de precisi√≥n general y F1 ponderada para diferentes tuber√≠as con un cambio en el enfoque de remuestreo.</em> </p><br><h2 id="glubokoe-obuchenie-ispolzuem-svyortochnuyu-neyronnuyu-set-cnn">  Aprendizaje profundo: uso de la red neuronal convolucional (CNN) </h2><br><p>  El aprendizaje profundo se ha convertido en el enfoque est√°ndar para muchas tareas, como la visi√≥n por computadora, el procesamiento de palabras en lenguaje natural y el procesamiento de se√±ales.  Esto se debe a su capacidad para extraer patrones de entradas multidimensionales complejas.  Los enfoques cl√°sicos de aprendizaje autom√°tico (como los √°rboles de decisi√≥n) se han utilizado en muchas tareas de geodatos temporales.  Las redes convolucionales, por otro lado, se utilizaron para analizar la correlaci√≥n espacial entre im√°genes adyacentes.  B√°sicamente, su uso se limit√≥ a trabajar con im√°genes individuales. </p><br><p>  Quer√≠amos estudiar la arquitectura de los modelos de aprendizaje profundo e intentar elegir uno que sea capaz de analizar los aspectos espaciales y temporales de los datos satelitales al mismo tiempo. </p><br><p>  Para hacer esto, utilizamos Netvork temporal totalmente convolucional, TFCN, o m√°s bien, la extensi√≥n temporal a U-Net, implementada en TensorFlow.  M√°s espec√≠ficamente, la arquitectura utiliza correlaciones espacio-temporales para mejorar el resultado.  Una ventaja adicional es que la estructura de red le permite representar mejor las relaciones espaciales a diferentes escalas gracias al proceso de codificaci√≥n / decodificaci√≥n en U-net.  Como en los modelos cl√°sicos, en la salida obtenemos una matriz bidimensional de etiquetas, que compararemos con la verdad. </p><br><p><img src="https://habrastorage.org/webt/p0/jl/mg/p0jlmgxi9euwvodwonx4zrmezsw.png"></p><br><p>  Utilizamos el modelo entrenado para predecir las marcas en el conjunto de prueba, y los valores obtenidos se verificaron con la verdad.  En general, la precisi√≥n fue del 84,4% y F1 fue del 85,4%. </p><br><p><img src="https://habrastorage.org/webt/ol/z2/zj/olz2zjp3waghaak9hnirzcwa258.png"></p><br><p>  <em>Comparaci√≥n de diferentes predicciones para nuestra tarea.</em>  <em>Imagen visual (arriba a la izquierda), mapa de referencia real (arriba a la derecha), predicci√≥n del modelo LightGBM (abajo a la izquierda) y predicci√≥n de U-net (abajo a la derecha)</em> </p><br><p>  Estos resultados muestran solo el trabajo inicial en este prototipo, que no est√° altamente optimizado para la tarea actual.  A pesar de esto, los resultados concuerdan con algunas estad√≠sticas obtenidas en la regi√≥n.  Para liberar el potencial de una red neuronal, es necesario optimizar la arquitectura (conjunto de atributos, profundidad de red, n√∫mero de convoluciones), as√≠ como establecer hiperpar√°metros (velocidad de aprendizaje, n√∫mero de eras, ponderaci√≥n de clase).  Esperamos profundizar a√∫n m√°s en este tema (ja, ja) a√∫n m√°s, y planeamos distribuir nuestro c√≥digo cuando est√© en una forma aceptable. </p><br><h3 id="drugie-eksperimenty">  Otros experimentos </h3><br><p>  Puede encontrar <em>muchas</em> formas de mejorar sus resultados actuales, pero no podemos resolverlas ni probarlas todas.  ¬°Es en ese momento que apareces en la escena!  ¬°Muestre lo que puede hacer con este conjunto de datos y ay√∫denos a mejorar los resultados! </p><br><p>  Por ejemplo, en el futuro cercano, uno de nuestros colegas participar√° en la clasificaci√≥n de la cobertura basada en la pila temporal de im√°genes <em>individuales</em> utilizando redes de convoluci√≥n.  La idea es que algunas superficies, por ejemplo, las artificiales, se pueden distinguir sin caracter√≠sticas temporales, bastante espaciales.  ¬°Estaremos encantados de escribir un art√≠culo separado cuando este trabajo conduzca a resultados! </p><br><h3 id="ot-perevodchika">  Del traductor </h3><br><p>  Desafortunadamente, la siguiente parte de esta serie de art√≠culos no sali√≥, lo que significa que los autores no mostraron ejemplos de c√≥digo fuente con la construcci√≥n de U-Net.  Como alternativa, puedo ofrecer las siguientes fuentes: </p><br><ol><li>  <em>U-Net: redes convolucionales para la segmentaci√≥n de im√°genes biom√©dicas - Olaf Ronneberger, Philipp Fischer, Thomas Brox</em> es uno de los art√≠culos b√°sicos sobre arquitectura U-Net que no involucra datos temporales. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://eo-learn.readthedocs.io/en/latest/examples/land-cover-map/SI_LULC_pipeline.html</a> : la p√°gina de documentaci√≥n de eo-learn, donde (posiblemente) se encuentra una versi√≥n m√°s reciente de tuber√≠as de 1.2 partes. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://github.com/divamgupta/image-segmentation-keras</a> - Un repositorio con varias redes implementadas usando keras.  Tengo algunas preguntas sobre las implementaciones (son ligeramente diferentes de las descritas en los art√≠culos originales), pero en general, las soluciones se adaptan f√°cilmente para fines personales y funcionan bastante bien. </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/453354/">https://habr.com/ru/post/453354/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../453342/index.html">Mitos sobre empleados remotos que nos destruimos</a></li>
<li><a href="../453346/index.html">Tecnolog√≠as de almacenamiento y protecci√≥n de datos: el tercer d√≠a en VMware EMPOWER 2019</a></li>
<li><a href="../453348/index.html">¬øQu√© hay dentro de asyncio?</a></li>
<li><a href="../453350/index.html">Transmisi√≥n abierta de la sala principal de RIT ++ 2019</a></li>
<li><a href="../453352/index.html">C√≥mo los drones entregan medicamentos vitales en Ghana</a></li>
<li><a href="../453356/index.html">Tendencias actuales y recomendaciones sobre aglomeraci√≥n de grandes instituciones financieras</a></li>
<li><a href="../453360/index.html">Ciudad sin atascos</a></li>
<li><a href="../453362/index.html">HabraConf # 1: hacia atr√°s para backend</a></li>
<li><a href="../453364/index.html">Una historia de lanzamiento que afect√≥ todo</a></li>
<li><a href="../453366/index.html">C√≥mo usar comas en ingl√©s: 15 reglas y ejemplos de error</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåé üöò üò∏ O livro "C ++. A pr√°tica da programa√ß√£o multithread " üë¶üèº üèµÔ∏è üëàüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Oi, habrozhiteli! A linguagem C ++ √© escolhida quando voc√™ precisa criar aplicativos realmente r√°pidos. E o processamento competitivo de alta qualidad...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>O livro "C ++. A pr√°tica da programa√ß√£o multithread "</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/484818/"> <a href="https://habr.com/ru/company/piter/blog/484818/"><img src="https://habrastorage.org/webt/cr/ym/3u/crym3urkeecjcfe-nsvq0nrw59y.jpeg" align="left" alt="imagem"></a>  Oi, habrozhiteli!  A linguagem C ++ √© escolhida quando voc√™ precisa criar aplicativos realmente r√°pidos.  E o processamento competitivo de alta qualidade os tornar√° ainda mais r√°pidos.  Os novos recursos do C ++ 17 permitem que voc√™ use todo o poder da programa√ß√£o multithread para resolver facilmente os problemas de processamento gr√°fico, aprendizado de m√°quina, etc. Anthony Williams, especialista em processamento competitivo, considera exemplos e descreve tarefas pr√°ticas, al√©m de compartilhar segredos que ser√£o √∫teis para todos os envolvidos. incluindo os desenvolvedores mais experientes. <br><br>  No livro ‚Ä¢ Uma vis√£o geral completa dos recursos do C ++ 17.  ‚Ä¢ Controle de lan√ßamento e fluxo.  ‚Ä¢ Sincroniza√ß√£o de opera√ß√µes competitivas.  ‚Ä¢ Desenvolvimento de c√≥digo competitivo.  ‚Ä¢ Depurando aplicativos multithread.  O livro √© adequado para desenvolvedores de n√≠vel m√©dio usando C e C ++.  Experi√™ncia de programa√ß√£o competitiva n√£o √© necess√°ria. <br><a name="habracut"></a><br><h3>  Desenvolvimento de C√≥digo Competitivo </h3><br><h3>  8.1  Maneiras de distribuir trabalho entre threads </h3><br>  Imagine que voc√™ precisa construir uma casa.  Para fazer isso, voc√™ ter√° que cavar um po√ßo de funda√ß√£o, preencher a pr√≥pria funda√ß√£o, erguer paredes, instalar canos e fia√ß√£o el√©trica, etc. Teoricamente, com habilidades suficientes, tudo pode ser feito de forma independente, mas provavelmente levar√° muito tempo e voc√™ precisar√° mudar de um trabalho para outro. outro.  Mas voc√™ pode contratar assistentes.  Em seguida, ser√° necess√°rio escolher quantos assistentes contratar e decidir o que eles devem ser capazes.  Voc√™ pode, por exemplo, contratar dois trabalhadores e trabalhar com eles.  Ent√£o voc√™ ainda precisa mudar de um trabalho para outro, mas agora as coisas v√£o mais r√°pido, pois haver√° mais artistas. <br><br>  Voc√™ pode escolher outra op√ß√£o - contratar uma equipe de especialistas, como pedreiro, carpinteiro, eletricista e encanador.  Cada um deles trabalhar√° em sua pr√≥pria especialidade; portanto, at√© que o encanador tenha uma frente de trabalho, ele ficar√° ocioso.  E, no entanto, as coisas v√£o mais r√°pido do que antes, pois h√° mais trabalhadores e, embora o eletricista conduza a fia√ß√£o na cozinha, o encanador pode ir ao banheiro.  Por√©m, quando n√£o h√° trabalho para um especialista espec√≠fico, √© obtido mais tempo de inatividade.  No entanto, pode-se notar que, mesmo com o tempo de inatividade em considera√ß√£o, o trabalho se move mais rapidamente quando especialistas chegam ao trabalho, em vez de uma equipe de trabalhadores.  Os especialistas n√£o precisam mudar constantemente as ferramentas e, com certeza, cada um deles executar√° sua tarefa mais rapidamente do que o trabalhador.  Se isso realmente ser√° assim, depende das circunst√¢ncias espec√≠ficas: tudo √© aprendido na pr√°tica. <br><br>  Mesmo se voc√™ envolver especialistas, ainda precisar√° escolher um n√∫mero diferente de trabalhadores de v√°rias especialidades.  Talvez fa√ßa sentido contratar, por exemplo, mais pedreiros do que eletricistas.  Al√©m disso, a composi√ß√£o da sua equipe e a efic√°cia geral do seu trabalho podem mudar se voc√™ precisar construir v√°rias casas ao mesmo tempo.  Mesmo se houver pouco trabalho para um encanador em uma √∫nica casa, ao construir v√°rias casas ao mesmo tempo, ela poder√° ser utilizada durante todo o dia.  Al√©m disso, se voc√™ n√£o precisar pagar a especialistas por tempo de inatividade, poder√° recrutar uma equipe maior, mesmo que o n√∫mero de pessoas trabalhando simultaneamente n√£o seja alterado. <br><br>  Mas pare de falar sobre a constru√ß√£o.  O que tudo isso tem a ver com threads?  E voc√™ pode aplicar considera√ß√µes semelhantes a eles.  Voc√™ deve decidir quantos threads usar e quais tarefas eles devem executar.  Precisamos de encadeamentos universais que executam o trabalho necess√°rio em um momento espec√≠fico ou encadeamentos especializados que est√£o bem adaptados a apenas uma coisa?  Ou talvez valha a pena combinar os dois?  Essas decis√µes devem ser tomadas independentemente das raz√µes para paralelizar o programa, e o desempenho e a clareza do c√≥digo dependem significativamente de qu√£o bem-sucedidos eles s√£o.  Portanto, √© t√£o importante imaginar quais op√ß√µes est√£o dispon√≠veis para tomar uma decis√£o competente ao desenvolver a estrutura do aplicativo.  Nesta se√ß√£o, consideraremos v√°rios m√©todos para distribuir tarefas, come√ßando com a distribui√ß√£o de dados entre os threads at√© que qualquer outro trabalho seja conclu√≠do. <br><br><h3>  8.1.1  Distribui√ß√£o de dados entre threads antes do processamento </h3><br>  Os mais f√°ceis de paralelizar s√£o algoritmos simples, como std :: for_each, que executam opera√ß√µes em cada elemento de um conjunto de dados.  Para paralelizar esse algoritmo, voc√™ pode atribuir cada elemento a um dos encadeamentos de processamento.  No futuro, ao considerar problemas de desempenho, ficar√° claro que a melhor op√ß√£o de distribui√ß√£o para obter o desempenho ideal depende das caracter√≠sticas da estrutura de dados. <br><br>  Ao distribuir dados, o caso mais simples √© quando os primeiros N elementos s√£o atribu√≠dos a um fluxo, os pr√≥ximos N elementos a outro, e assim por diante (Fig. 8.1), mas outros esquemas podem ser usados.  Independentemente do m√©todo de distribui√ß√£o de dados, cada thread processa apenas os elementos atribu√≠dos a ele, sem interagir com outros threads at√© concluir o processamento. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ie/ex/rm/ieexrmf49u6qerfqmuhtcgpbgpe.png" alt="imagem"></div><br>  A estrutura deve ser familiar para todos que lidam com programa√ß√£o na Message Passing Interface (MPI, <a href="http://www.mpi-forum.org/">www.mpi-forum.org</a> ) ou OpenMP (http://www.openmp.org/): a tarefa √© dividida em v√°rias tarefas executadas em paralelo, os fluxos de trabalho os executam independentemente um do outro e os resultados s√£o coletados no est√°gio final das informa√ß√µes.  Essa abordagem foi usada no exemplo com a fun√ß√£o acumular da se√ß√£o 2.4: as tarefas paralelas e o est√°gio de redu√ß√£o s√£o acumula√ß√£o.  Para um algoritmo for_each simples, a etapa final est√° faltando, pois n√£o h√° nada a reduzir. <br><br>  O fato de um mix ser definido como a ess√™ncia do est√°gio final desempenha um papel muito importante: uma implementa√ß√£o elementar semelhante √† mostrada na Listagem 2.9 executar√° esse mix como um est√°gio sequencial final.  Mas geralmente esse est√°gio tamb√©m √© paralelo: a acumula√ß√£o √© uma opera√ß√£o de redu√ß√£o; portanto, o c√≥digo na Listagem 2.9 pode ser alterado para obter uma chamada recursiva do mesmo c√≥digo quando, por exemplo, o n√∫mero de encadeamentos √© maior que o n√∫mero m√≠nimo de elementos processados ‚Äã‚Äãpelo encadeamento.  Voc√™ tamb√©m pode for√ßar fluxos de trabalho a executar etapas de rollup assim que cada um deles concluir sua tarefa, em vez de iniciar novos threads a cada vez. <br><br>  Por toda a sua efic√°cia, essa t√©cnica n√£o √© vers√°til.  √Äs vezes, os dados n√£o podem ser precisamente divididos com anteced√™ncia, pois a composi√ß√£o de cada parte √© conhecida apenas durante o processamento.  Em particular, isso √© evidente ao usar algoritmos recursivos como o Quicksort, portanto eles exigem uma abordagem diferente. <br><br><h3>  8.1.2  Distribui√ß√£o recursiva de dados </h3><br>  O algoritmo Quicksort possui dois est√°gios principais: dividir os dados em duas partes - tudo o que chega a um dos elementos (refer√™ncia) e tudo depois na ordem de classifica√ß√£o final, e classifica√ß√£o recursiva dessas duas metades.  √â imposs√≠vel paralelizar isso pela divis√£o preliminar dos dados, pois √© poss√≠vel determinar em qual "metade" eles se enquadram apenas durante o processamento dos elementos.  Se voc√™ pretende paralelizar esse algoritmo, precisar√° usar a pr√≥pria ess√™ncia da recurs√£o.  Em cada n√≠vel de recurs√£o, mais e mais chamadas para a fun√ß√£o quick_sort s√£o realizadas, pois √© necess√°rio classificar as que s√£o maiores que a refer√™ncia e as que s√£o menores que ela.  Essas chamadas recursivas s√£o independentes uma da outra porque se referem a conjuntos separados de elementos.  Por esse motivo, eles s√£o os primeiros candidatos √† competitividade.  Esta distribui√ß√£o recursiva √© mostrada na Fig.  8.2 <br><br>  Essa implementa√ß√£o j√° foi atendida no Cap√≠tulo 4. Em vez de fazer duas chamadas recursivas para as metades maiores e menores, usamos a fun√ß√£o std :: async (), que executa tarefas ass√≠ncronas para a metade menor a cada etapa.  Devido ao uso de std :: async (), a Biblioteca de Threads C ++ precisou decidir quando iniciar a tarefa em um novo thread e quando - no modo s√≠ncrono. <br><br>  H√° uma circunst√¢ncia importante: ao classificar um grande conjunto de dados, iniciar um novo encadeamento para cada recurs√£o levar√° a um r√°pido aumento no n√∫mero de encadeamentos.  Ao examinar problemas de desempenho, ser√° mostrado que muitos threads podem diminuir a velocidade do aplicativo.  Al√©m disso, com um grande conjunto de fluxos de dados pode simplesmente n√£o ser suficiente.  A pr√≥pria id√©ia de dividir a tarefa inteira em um modo t√£o recursivo parece muito bem-sucedida; voc√™ s√≥ precisa monitorar cuidadosamente o n√∫mero de threads.  Em casos simples, a fun√ß√£o std :: async () lida com isso, mas existem outras op√ß√µes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rz/ji/l3/rzjil3fye0-nfj2quxo75cvxon4.png" alt="imagem"></div><br>  Uma delas √© usar a fun√ß√£o std :: thread :: hardware_concurrency () para selecionar o n√∫mero de threads, como foi feito na vers√£o paralela da fun√ß√£o acumulate () da Listagem 2.9.  Em vez de iniciar um novo encadeamento para cada chamada recursiva, voc√™ pode colocar o fragmento a ser classificado em uma pilha segura de encadeamentos, por exemplo, como discutido nos cap√≠tulos 6 e 7. Se o encadeamento n√£o tiver nada a fazer ou terminar de processar todos os seus fragmentos ou aguardar o fragmento classificado, ele poder√° pegue um fragmento da pilha e classifique-o. <br><br>  A Listagem 8.1 mostra uma implementa√ß√£o simples dessa tecnologia.  Como na maioria dos outros exemplos, ele apenas demonstra a inten√ß√£o e n√£o √© um c√≥digo pronto para uso pr√°tico.  Se voc√™ usa o compilador C ++ 17 e sua biblioteca suporta, voc√™ deve usar os algoritmos paralelos fornecidos pela biblioteca padr√£o de acordo com as descri√ß√µes fornecidas no cap√≠tulo 10. <br><br>  Listagem 8.1.  Um algoritmo Quicksort paralelo que usa uma pilha de fragmentos aguardando classifica√ß√£o <br><br><img src="https://habrastorage.org/webt/ko/nb/h6/konbh6b_q40lp0uz-gxyunwws3g.png" alt="imagem"><br><img src="https://habrastorage.org/webt/5s/md/52/5smd5279wgwzktq4thil54lidqy.png" alt="imagem"><br><img src="https://habrastorage.org/webt/ro/js/kt/rojsktncuxgmls2wtndzt9ywhqy.png" alt="imagem"><br><br>  Aqui, a fun√ß√£o parallel_quick_sort <b>(19)</b> coloca a maior parte das responsabilidades funcionais na classe classificador <b>(1)</b> , que fornece uma maneira f√°cil de agrupar a pilha de fragmentos n√£o classificados <b>(2)</b> e v√°rios encadeamentos <b>(3)</b> .  O trabalho principal √© realizado na fun√ß√£o do componente do_sort <b>(9)</b> , que √© ocupada pelo particionamento de dados usual <b>(10)</b> .  Dessa vez, em vez de iniciar um novo encadeamento para cada fragmento, ele empurra esse fragmento na pilha (11) e inicia um novo encadeamento apenas se houver um recurso de processador livre (12).  Como um fragmento com valores menores que o da refer√™ncia pode ser processado por outro fluxo, devemos aguardar sua prontid√£o <b>(13)</b> .  Para que o tempo n√£o seja desperdi√ßado (caso tenhamos um √∫nico thread ou todos os outros threads j√° estejam ocupados), √© feita uma tentativa de processar fragmentos da pilha durante esse per√≠odo de espera <b>(14)</b> .  A fun√ß√£o try_sort_chunk recupera um fragmento da pilha <b>(7)</b> , classifica-o <b>(8)</b> e salva os resultados na promessa de promessa para que eles possam receber o fluxo que colocou esse fragmento na pilha <b>(15)</b> . <br><br>  Agora, os threads iniciados est√£o em um loop e tentam classificar fragmentos da pilha <b>(17)</b> se o sinalizador end_of_data <b>(16)</b> n√£o estiver definido.  Entre as verifica√ß√µes, eles entregam o recurso de computa√ß√£o a outros encadeamentos, para que possam enviar trabalho adicional para a pilha.  O trabalho do c√≥digo em termos de ordem desses encadeamentos depende do destruidor da sua classe classificadora <b>(4)</b> .  Quando todos os dados s√£o classificados, a fun√ß√£o do_sort retornar√° o controle (mesmo mantendo a atividade dos threads de trabalho), o thread principal retornar√° de parallel_quick_sort <b>(20)</b> e destruir√° o objeto classificador.  Ele definir√° o sinalizador end_of_data <b>(5)</b> e aguardar√° o t√©rmino do trabalho <b>(6)</b> .A defini√ß√£o do sinalizador interromper√° o loop na fun√ß√£o de threads (16). <br><br>  Com essa abordagem, o problema do n√∫mero ilimitado de threads inerentes √† fun√ß√£o spawn_task que lan√ßou o novo thread desaparecer√° e a depend√™ncia da biblioteca de threads C ++, que seleciona o n√∫mero de threads para voc√™, como ocorre ao usar std :: async (), desaparecer√°.  Em vez disso, para impedir a altern√¢ncia de tarefas com muita frequ√™ncia, o n√∫mero de threads √© limitado pelo valor retornado pela fun√ß√£o std :: thread :: hardware_concurrency ().  Mas surge outro problema: gerenciar esses fluxos e trocar dados entre eles complica bastante o c√≥digo.  Al√©m disso, apesar de os threads processarem elementos de dados individuais, todos eles acessam a pilha, adicionando novos fragmentos a ela e levando fragmentos para processamento.  Uma concorr√™ncia t√£o intensa pode reduzir o desempenho, mesmo que uma pilha sem bloqueio (portanto, sem bloqueio) seja usada, e as raz√µes para isso ser√£o consideradas em breve. <br><br>  Essa abordagem √© uma vers√£o especial do conjunto de encadeamentos - um conjunto de encadeamentos, cada um dos quais recebe trabalho da lista de trabalhos adiados, o executa e depois passa para a lista para um novo.  Alguns problemas em potencial inerentes ao conjunto de encadeamentos (incluindo a concorr√™ncia ao acessar a lista de obras) e as formas de resolv√™-los s√£o discutidos no Cap√≠tulo 9. Ao escalonar o aplicativo criado para que ele seja executado em v√°rios processadores, discutiremos este cap√≠tulo um pouco mais adiante (consulte 8.2.1). <br><br>  Ao distribuir dados antes do processamento e no modo recursivo, presume-se que eles sejam corrigidos com anteced√™ncia e que esteja em andamento uma pesquisa para sua distribui√ß√£o.  Mas isso nem sempre acontece: se os dados s√£o criados no modo din√¢mico ou prov√™m de uma fonte externa, essa abordagem n√£o funciona.  Nesse caso, pode ser mais razo√°vel distribuir o trabalho de acordo com o tipo de tarefa e n√£o com base nos pr√≥prios dados. <br><br><h3>  8.1.3  Distribui√ß√£o do trabalho por tipo de tarefa </h3><br>  A distribui√ß√£o do trabalho entre os segmentos, atribuindo cada um deles (antecipadamente ou recursivamente durante o processamento de dados) diferentes peda√ßos de dados, em qualquer caso, baseia-se no pressuposto de que os segmentos far√£o o mesmo trabalho em cada peda√ßo.  Uma distribui√ß√£o alternativa de trabalho √© a especializa√ß√£o de fluxos, onde cada um executa uma tarefa separada, pois encanadores e eletricistas realizam tarefas diferentes na constru√ß√£o de uma casa.  Os fluxos podem trabalhar com dados diferentes ou com os mesmos dados, mas, no √∫ltimo caso, eles fazem isso para prop√≥sitos diferentes. <br><br>  Essa divis√£o peculiar do trabalho surge como resultado da separa√ß√£o de tarefas com a ajuda da concorr√™ncia: cada segmento tem uma tarefa separada, que √© executada independentemente de outros fluxos.  √Äs vezes, outros encadeamentos podem entregar dados ao fluxo ou produzir eventos aos quais devem responder, mas, em geral, cada fluxo se concentra no desempenho de alta qualidade de uma √∫nica tarefa.  Esse √© um bom design b√°sico, no qual cada parte do c√≥digo deve ser respons√°vel por uma coisa. <br><br><h3>  Distribui√ß√£o do trabalho por tipo de tarefa, a fim de compartilhar responsabilidades </h3><br>  Um aplicativo de thread √∫nico precisa lidar com conflitos relacionados ao princ√≠pio de responsabilidade √∫nica, quando h√° v√°rias tarefas que devem ser executadas continuamente por um certo tempo, ou o aplicativo deve lidar com o processamento de eventos de entrada em tempo h√°bil (por exemplo, um usu√°rio pressiona uma tecla ou os dados chegam pela rede) na presen√ßa de outras tarefas inacabadas.  Em um ambiente de computa√ß√£o de thread √∫nico, √© necess√°rio criar independentemente o c√≥digo que executa parte da tarefa A, parte da tarefa B, verifica se a tecla foi pressionada e se n√£o h√° pacotes de rede e, em seguida, retorna ciclicamente para a pr√≥xima parte da tarefa A. Isso complica o c√≥digo a ser executado tarefas A devido √† necessidade de manter seu estado e retornar periodicamente o controle ao loop principal.  Se voc√™ adicionar muitas tarefas ao ciclo, o trabalho poder√° diminuir significativamente e o usu√°rio provavelmente notar√° uma rea√ß√£o lenta ao pressionamento de teclas.  Estou certo de que todos observaram as manifesta√ß√µes extremas de uma situa√ß√£o semelhante em certos aplicativos: voc√™ define uma tarefa para o aplicativo e a interface n√£o reage a nada at√© que seja conclu√≠da. <br><br>  Aqui os fluxos entram no palco.  Se voc√™ executar cada tarefa em um encadeamento separado, o sistema operacional poder√° fazer isso em vez de voc√™.  No c√≥digo da tarefa A, voc√™ pode se concentrar em concluir a tarefa sem se preocupar em manter o estado e retornar ao loop principal, ou sobre quanto tempo passar√° antes que isso aconte√ßa.  Ou seja, o sistema operacional salvar√° automaticamente o estado e passar√° para a tarefa B ou C no momento certo e, se o sistema no qual o programa ser√° executado tiver v√°rios n√∫cleos ou processadores, ser√° poss√≠vel executar simultaneamente as tarefas A e B. O c√≥digo para processar pressionamentos de tecla ou recibos pacotes de rede agora podem ser executados em tempo h√°bil, e todos se beneficiar√£o: o usu√°rio receber√° uma resposta adequada do programa e voc√™, como desenvolvedor, receber√° c√≥digo simplificado, pois cada fluxo pode ser direcionado  executar opera√ß√µes diretamente relacionadas √†s suas fun√ß√µes, sem mistur√°-las com o fluxo de controle e a intera√ß√£o do usu√°rio. <br><br>  Uma imagem ideal est√° surgindo.  Mas tudo pode acontecer dessa maneira?  Como sempre, tudo depende das circunst√¢ncias espec√≠ficas.  Se a independ√™ncia total for respeitada e os fluxos n√£o precisarem trocar dados entre si, √© exatamente isso que acontecer√°.  Infelizmente, uma situa√ß√£o semelhante √© observada muito raramente.  Freq√ºentemente, as a√ß√µes necess√°rias para o usu√°rio t√™m a forma de tarefas em segundo plano convenientes e precisam notificar o usu√°rio sobre a tarefa, atualizando a interface do usu√°rio de alguma forma.  Ou o usu√°rio pode precisar interromper a tarefa; portanto, a interface do usu√°rio precisar√° enviar uma mensagem para a tarefa em segundo plano, fazendo com que ela pare de executar.  Nos dois casos, √© necess√°rio considerar cuidadosamente o design e a sincroniza√ß√£o adequada, mas as tarefas executadas permanecer√£o fragmentadas.  O thread da interface do usu√°rio ainda controla essa interface, mas pode ser atribu√≠do para executar uma atualiza√ß√£o a pedido de outros threads.  O encadeamento que implementa a tarefa em segundo plano ainda se concentra nas opera√ß√µes necess√°rias para conclu√≠-la; tamb√©m acontece que um dos encadeamentos em segundo plano permite que a tarefa interrompa o outro encadeamento.  Nos dois casos, os fluxos n√£o se importam de onde a solicita√ß√£o vem, √© importante apenas para eles que se destina a eles e est√° diretamente relacionada √†s suas responsabilidades. <br><br>  Existem dois perigos s√©rios no compartilhamento de responsabilidades entre v√°rios threads.  Primeiro, pode acontecer que responsabilidades inadequadas sejam distribu√≠das.  Um sinal disso √© o excesso de dados compartilhados pelos fluxos ou o fato de que diferentes fluxos precisam esperar um pelo outro.          .      .        , , ,    ,             .   ,        ,     ‚Äî   , ,        . <br><br>                .             ,     ,         . <br><br><h3>      </h3><br>                 ,            .      : ,     ,         . <br><br>            ‚Äî        .   ,     ,      .   ,     ,       ,           . <br><br>      ,    8.1.1,   ,           . ,                  . <br><br>     ,        :    ,       . ,        20          ,      3 .      ,         .  ,   ,    ,  ,   12       ,  24  ‚Äî   . .  20     .      .         .       , ,  ,   ,   12 . ,   12       ,        .      ,  :  ,   ,     ,  ,       ,        .      3         12 . <br><br>      ,    9 ,         .            . ,  ,      .          25   ,    ‚Äî  .  ,       ,    : ,   100   ,  ,    1 ,    100 ,    1     100 .     ,  ,        .       ,     ,  , . <br><br>       ,    ,     ,   ,      . <br><br><h3> 8.2. ,      </h3><br>            ,  ,      .        ,  ,     .     ,       16      ,     . <br><br>    ,        ‚Äî   ,    ,    (      ),      .          ,    :      ? <br><br><h3> 8.2.1.     ? </h3><br>  ( )     ,          .   ,    ,        ,          .     ,     .      ,     . ,         ,         (   )       .     ,   ,      ,            . <br><br>     16-       16  :          16 .    ,        16 .   ,    ,         (   ).    ,    16    ,      ,           ,      1.       (oversubscription). <br><br>          ,       ,    C++11 (Standard Thread Library)   std::thread::hardware_concurrency().             . <br><br>   std::thread::hardware_concurrency()    :       -  ,   ,        .   ,        ,  std::thread::hardware_concurrency(),     .  std::async()    ,           .           . <br><br>      ,    ,    ,      .              ‚Äî   ,   ,     . ,     ,   ,       ,          C++.   ,     std::async(),       ,   ,    .       ,     .   ,      ,      std::thread::hardware_concurrency(),     .      ,      ,  ,    . <br><br>       ,                 .          ,     ,      ,    ,        . <br><br>         ,        ‚Äî          . <br><br>  ¬ªMais informa√ß√µes sobre o livro podem ser encontradas no <a href="https://www.piter.com/collection/new/product/c-praktika-mnogopotochnogo-programmirovaniya%3F_gs_cttl%3D120%255E_%255Eamp%255E_%255Egs_direct_link%3D1%255E_%255Eamp%255E_%255Egsaid%3D82744%255E_%255Eamp%255E_%255Egsmid%3D29789%255E_%255Eamp%255E_%255Egstid%3Dc">site do editor</a> <br>  ¬ª <a href="https://storage.piter.com/upload/contents/978544610831/978544610831_X.pdf">Conte√∫do</a> <br>  ¬ª <a href="https://storage.piter.com/upload/contents/978544610831/978544610831_p.pdf">Trecho</a> <br><br>    25%   ‚Äî <b>C++</b> <br><br>  Ap√≥s o pagamento da vers√£o impressa do livro, um livro eletr√¥nico √© enviado por e-mail. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt484818/">https://habr.com/ru/post/pt484818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt484804/index.html">O que criptografar em um sistema corporativo? E por que isso?</a></li>
<li><a href="../pt484806/index.html">Diferen√ßa entre cPanel e Plesk Obsidian</a></li>
<li><a href="../pt484812/index.html">Minha experi√™ncia com o Plesk</a></li>
<li><a href="../pt484814/index.html">6. Introdu√ß√£o ao Fortinet v6.0. Filtragem da Web e controle de aplicativos</a></li>
<li><a href="../pt484816/index.html">Usando ganchos de opera√ß√µes para fazer backup de arquivos no macOS em tempo real</a></li>
<li><a href="../pt484820/index.html">FAQ.Net - um programa gratuito de anota√ß√µes para Windows com um design atualizado</a></li>
<li><a href="../pt484822/index.html">Blazor: como evitar que um componente fique doente ou duas abordagens para separar o c√≥digo da marca√ß√£o</a></li>
<li><a href="../pt484824/index.html">A guerra por apagar as luzes</a></li>
<li><a href="../pt484826/index.html">A intelig√™ncia artificial piora ainda mais os rem√©dios ruins</a></li>
<li><a href="../pt484834/index.html">Como construir uma estrat√©gia corporativa para treinamento e desenvolvimento</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
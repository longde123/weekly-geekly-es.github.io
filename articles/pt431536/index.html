<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∞ üìÉ üë©üèæ‚Äçüé® Ceph. Anatomia do desastre üòÖ üö´ üå≤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ceph √© um armazenamento de objeto projetado para ajudar a criar um cluster de failover. Ainda assim, falhas acontecem. Todo mundo que trabalha com Cep...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ceph. Anatomia do desastre</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/431536/">  Ceph √© um armazenamento de objeto projetado para ajudar a criar um cluster de failover.  Ainda assim, falhas acontecem.  Todo mundo que trabalha com Ceph conhece a lenda sobre CloudMouse ou Rosreestr.  Infelizmente, n√£o √© habitual compartilhar experi√™ncias negativas conosco, as causas das falhas s√£o mais frequentemente escondidas e n√£o permitem que as gera√ß√µes futuras aprendam com os erros dos outros. <br><br>  Bem, vamos configurar um cluster de teste, mas pr√≥ximo ao real, e analisar o desastre por ossos.  Mediremos todos os rebaixamentos de desempenho, encontraremos vazamentos de mem√≥ria e analisaremos o processo de recupera√ß√£o de servi√ßos.  E tudo isso sob a lideran√ßa de Artemy Kapitula, que passou quase um ano estudando as armadilhas, fez com que o desempenho do cluster falhasse em zero e a lat√™ncia n√£o saltasse para valores indecentes.  E eu tenho um gr√°fico vermelho, que √© muito melhor. <br><img src="https://habrastorage.org/webt/c8/nr/1a/c8nr1akew1kjleodu5trq_ow3oy.png"><br><br>  A seguir, voc√™ encontrar√° uma vers√£o em v√≠deo e texto de um dos melhores relat√≥rios do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">DevOpsConf Russia</a> 2018. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/_fWYUl2QsoI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><a name="habracut"></a><br>  <strong>Sobre o palestrante:</strong> Artemy Kapitula, arquiteto de sistemas RCNTEC.  A empresa oferece solu√ß√µes de telefonia IP (colabora√ß√£o, organiza√ß√£o de um escrit√≥rio remoto, sistemas de armazenamento definidos por software e sistemas de gerenciamento / distribui√ß√£o de energia).  A empresa trabalha principalmente no setor empresarial, portanto, n√£o √© muito conhecida no mercado de DevOps.  No entanto, alguma experi√™ncia foi acumulada com o Ceph, que em muitos projetos √© usado como elemento b√°sico da infraestrutura de armazenamento. <br><br>  <strong>O Ceph √© um reposit√≥rio definido por software com muitos componentes de software.</strong> <br><img src="https://habrastorage.org/webt/dw/ow/hm/dwowhmqvjfugd0u-ljhhz3fy2ji.png"><br><br>  No diagrama: <br><br><ul><li>  O n√≠vel superior √© a rede interna do cluster atrav√©s da qual o pr√≥prio cluster se comunica; </li><li>  O n√≠vel mais baixo - atualmente Ceph - √© um conjunto de daemons internos do Ceph (MON, MDS e OSD) que armazenam dados. </li></ul><br>  Como regra, todos os dados s√£o replicados.No diagrama, eu selecionei deliberadamente tr√™s grupos, cada um com tr√™s OSDs, e cada um desses grupos geralmente cont√©m uma r√©plica de dados.  Como resultado, os dados s√£o armazenados em tr√™s c√≥pias. <br><br>  Uma rede de cluster de n√≠vel superior √© a rede atrav√©s da qual os clientes Ceph acessam dados.  Por meio dele, os clientes se comunicam com o monitor, com o MDS (quem precisa dele) e com o OSD.  Cada cliente trabalha com cada OSD e com cada monitor independentemente.  Portanto, o <strong>sistema √© desprovido de um √∫nico ponto de falha</strong> , o que √© muito agrad√°vel. <br><br><h2>  Clientes <br></h2><br>  ‚óè clientes S3 <br><br>  S3 √© uma API para HTTP.  Os clientes S3 trabalham com HTTP e se conectam aos componentes Ceph Rados Gateway (RGW).  Eles quase sempre se comunicam com um componente atrav√©s de uma rede dedicada.  Essa rede (eu chamei de rede S3) usa apenas HTTP, as exce√ß√µes s√£o raras. <br><br>  ‚óè Hipervisor com m√°quinas virtuais <br><br>  Esse grupo de clientes √© frequentemente usado.  Eles trabalham com monitores e com OSD, dos quais recebem informa√ß√µes gerais sobre o status do cluster e a distribui√ß√£o de dados.  Para dados, esses clientes v√£o diretamente para os daemons OSD por meio da rede p√∫blica do cluster. <br><br>  ‚óè clientes RBD <br><br>  Tamb√©m existem hosts f√≠sicos de metais BR, que geralmente s√£o Linux.  Eles s√£o clientes RBD e obt√™m acesso √†s imagens armazenadas em um cluster Ceph (imagens de disco da m√°quina virtual). <br><br>  ‚óè clientes CephFS <br><br>  O quarto grupo de clientes, que muitos ainda n√£o t√™m, mas t√™m um interesse crescente, s√£o clientes do sistema de arquivos em cluster do CephFS.  O sistema de cluster CephFS pode ser montado simultaneamente a partir de muitos n√≥s, e todos os n√≥s obt√™m acesso aos mesmos dados, trabalhando com cada OSD.  Ou seja, n√£o h√° Gateways como tal (Samba, NFS e outros).  O problema √© que esse cliente pode ser apenas Linux e uma vers√£o bastante moderna. <br><img src="https://habrastorage.org/webt/fw/nm/xc/fwnmxcaiig0yy6tkofrljqri3ck.png"><br><br>  Nossa empresa trabalha no mercado corporativo, e l√° a bola √© governada por ESXi, HyperV e outros.  Por conseguinte, o cluster Ceph, que √© de alguma forma usado no setor corporativo, √© necess√°rio para apoiar as t√©cnicas apropriadas.  Isso n√£o foi suficiente para n√≥s na Ceph, por isso tivemos que refinar e expandir o cluster da Ceph com nossos componentes, construindo algo mais do que a Ceph, nossa pr√≥pria plataforma para armazenar dados. <br><br>  Al√©m disso, os clientes do setor corporativo n√£o est√£o no Linux, mas a maioria deles Windows, ocasionalmente Mac OS, n√£o pode acessar o cluster Ceph.  Eles precisam passar por algum tipo de gateways, que nesse caso se tornam gargalos. <br><br>  Tivemos que adicionar todos esses componentes e obtivemos um cluster um pouco maior. <br><img src="https://habrastorage.org/webt/p2/tg/j2/p2tgj2qtpzrzsnst5bophkclywi.png"><br><br>  Temos dois componentes centrais: o <strong>grupo SCSI Gateways</strong> , que fornece acesso aos dados em um cluster Ceph por meio do FibreChannel ou iSCSI.  Esses componentes s√£o usados ‚Äã‚Äãpara conectar o HyperV e ESXi a um cluster Ceph.  Os clientes PROXMOX ainda trabalham √† sua maneira - atrav√©s do RBD. <br><br>  N√£o permitimos que os clientes de arquivos entrem diretamente na rede do cluster; v√°rios Gateways tolerantes a falhas s√£o alocados para eles.  Cada Gateway fornece acesso ao sistema de cluster de arquivos via NFS, AFP ou SMB.  Assim, quase qualquer cliente, seja Linux, FreeBSD ou n√£o apenas um cliente, servidor (OS X, Windows), obt√©m acesso ao CephFS. <br><br>  Para gerenciar tudo isso, tivemos que desenvolver nossa pr√≥pria orquestra Ceph e todos os nossos componentes, que s√£o numerosos l√°.  Mas falar sobre isso agora n√£o faz sentido, pois esse √© o nosso desenvolvimento.  A maioria provavelmente estar√° interessada no pr√≥prio Ceph "nu". <br><br>  O Ceph √© usado muito onde, e ocasionalmente ocorrem falhas.  Certamente todo mundo que trabalha com Ceph conhece a lenda sobre o CloudMouse.  Esta √© uma terr√≠vel lenda urbana, mas nem tudo √© t√£o ruim quanto parece.  H√° um novo conto de fadas sobre Rosreestr.  Ceph estava girando em todos os lugares, e em todo lugar estava falhando.  Em algum lugar que terminou fatalmente, em algum lugar conseguiu eliminar rapidamente as consequ√™ncias. <br><br>  Infelizmente, n√£o √© habitual compartilharmos experi√™ncias negativas, todos est√£o tentando esconder as informa√ß√µes relevantes.  As empresas estrangeiras s√£o um pouco mais abertas, em particular, a DigitalOcean (um conhecido fornecedor que distribui m√°quinas virtuais) tamb√©m sofreu uma falha no Ceph por quase um dia, era 1¬∫ de abril - um dia maravilhoso!  Eles postaram alguns dos relat√≥rios, um pequeno log abaixo. <br><img src="https://habrastorage.org/webt/qo/sb/ds/qosbdsczlkvzh-zqsfvid86er5u.png"><br><br>  Os problemas come√ßaram √†s 7 da manh√£, √†s 11 eles entenderam o que estava acontecendo e come√ßaram a eliminar o fracasso.  Para fazer isso, eles alocaram dois comandos: um, por algum motivo, rodou nos servidores e instalou mem√≥ria nele; o segundo, por algum motivo, iniciou manualmente um servidor ap√≥s o outro e monitorou cuidadosamente todos os servidores.  Porque  Estamos todos acostumados a tudo ativado com um clique. <br><br>  <em>O que basicamente acontece em um sistema distribu√≠do quando ele √© efetivamente constru√≠do e funciona quase no limite de seus recursos?</em> <br><br>  Para responder a essa pergunta, precisamos examinar como o cluster Ceph funciona e como ocorre a falha. <br><img src="https://habrastorage.org/webt/ln/ks/rd/lnksrda1mb-lmfbymyacym1f8aw.png"><br><br><h2>  Cen√°rio de falha do Ceph <br></h2><br>  No in√≠cio, o cluster funciona bem, tudo est√° indo bem.  Ent√£o, algo acontece, ap√≥s o qual os daemons OSD, onde os dados s√£o armazenados, perdem contato com os componentes centrais do cluster (monitores).  Nesse ponto, ocorre um tempo limite e todo o cluster recebe uma aposta.  O cluster permanece por um tempo at√© perceber que algo est√° errado com ele e depois corrigir o conhecimento interno.  Depois disso, o atendimento ao cliente √© restaurado at√© certo ponto e o cluster est√° novamente trabalhando em um modo degradado.  E o engra√ßado √© que funciona mais r√°pido do que no modo normal - esse √© um fato incr√≠vel. <br><br>  Ent√£o eliminamos o fracasso.  Suponhamos que perdemos energia, o rack foi completamente cortado.  Eletricistas vieram correndo, todos restauraram, forneceram energia, os servidores foram ligados e <strong>a divers√£o come√ßou</strong> . <br><br><blockquote>  Todo mundo est√° acostumado ao fato de que, quando um servidor falha, tudo fica ruim e, quando ligamos o servidor, tudo fica bom.  Tudo est√° completamente errado aqui. <br></blockquote><br>  O cluster praticamente para, realiza a sincroniza√ß√£o prim√°ria e inicia uma recupera√ß√£o lenta e suave, retornando gradualmente ao modo normal. <br><img src="https://habrastorage.org/webt/ml/r_/i3/mlr_i3llw-lsdaybp4vbedxeuhi.png"><br><br>  Acima est√° um gr√°fico do desempenho do cluster Ceph √† medida que uma falha se desenvolve.  Observe que aqui os mesmos intervalos de que falamos s√£o muito claramente tra√ßados: <br><br><ul><li>  Opera√ß√£o normal at√© aproximadamente 70 segundos; </li><li>  Falha por um minuto a cerca de 130 segundos; </li><li>  Um plat√¥ que √© notavelmente mais alto que a opera√ß√£o normal √© o trabalho de aglomerados degradados; </li><li>  Em seguida, ativamos o n√≥ ausente - este √© um cluster de treinamento, existem apenas 3 servidores e 15 SSDs.  Iniciamos o servidor em torno de 260 segundos. </li><li>  O servidor ligado, entrou no cluster - IOPS'y caiu. </li></ul><br>  Vamos tentar descobrir o que realmente aconteceu l√°.  A primeira coisa que nos interessa √© uma queda no in√≠cio do gr√°fico. <br><br><h3>  Falha no OSD <br></h3><br>  Considere um exemplo de um cluster com tr√™s racks, v√°rios n√≥s em cada um.  Se o rack esquerdo falhar, todos os daemons OSD (n√£o os hosts!) Ping-se com mensagens Ceph em um determinado intervalo.  Se houver uma perda de v√°rias mensagens, uma mensagem ser√° enviada ao monitor: "Eu, OSD tal e tal, n√£o posso alcan√ßar OSD tal e tal". <br><img src="https://habrastorage.org/webt/zh/1s/ge/zh1sge1ljlclxjmgfygxpyyyc8i.png"><br><br>  Ao mesmo tempo, as mensagens geralmente s√£o agrupadas por host, ou seja, se duas mensagens de OSDs diferentes chegam ao mesmo host, elas s√£o combinadas em uma mensagem.  Portanto, se o OSD 11 e o OSD 12 reportarem que n√£o podem alcan√ßar o OSD 1, isso ser√° interpretado como o Host 11 reclamou do OSD 1. Quando o OSD 21 e o OSD 22 foram relatados, ele √© interpretado como o Host 21 insatisfeito com o OSD 1. Ap√≥s o qual o monitor considera que o OSD 1 est√° no estado inativo e notifica todos os membros do cluster (alterando o mapa OSD), o trabalho continua no modo degradado. <br><img src="https://habrastorage.org/webt/uu/-c/1w/uu-c1wnwflbqk6ueyumhohtlvjy.png"><br><br>  Ent√£o, aqui est√° o nosso cluster e o rack com falha (Host 5 e Host 6).  Ativamos o Host 5 e o Host 6, conforme o poder apareceu, e ... <br><br><h3>  Comportamento interno do Ceph <br></h3><br>  E agora a parte mais interessante √© que estamos iniciando a <strong>sincroniza√ß√£o de dados inicial</strong> .  Como existem muitas r√©plicas, elas devem ser s√≠ncronas e estar na mesma vers√£o.  No processo de iniciar o OSD, inicie: <br><br><ul><li>  O OSD l√™ as vers√µes dispon√≠veis, o hist√≥rico dispon√≠vel (pg_log - para determinar as vers√µes atuais dos objetos). </li><li>  Depois disso, ele determina em qual OSD est√£o as vers√µes mais recentes de objetos degradados (missing_loc) e quais est√£o atrasadas. </li><li>  Onde as vers√µes anteriores s√£o armazenadas, a sincroniza√ß√£o √© necess√°ria e novas vers√µes podem ser usadas como refer√™ncia para leitura e grava√ß√£o de dados. </li></ul><br>  √â usada uma hist√≥ria que √© coletada de todos os OSDs, e essa hist√≥ria pode ser bastante;  √© determinada a localiza√ß√£o real do conjunto de objetos no cluster em que as vers√µes correspondentes est√£o localizadas.  Quantos objetos est√£o no cluster, quantos registros s√£o obtidos, se o cluster permaneceu por muito tempo no modo degradado, a hist√≥ria √© longa. <br><br>  <strong>Para compara√ß√£o: o</strong> tamanho t√≠pico de um objeto quando trabalhamos com uma imagem RBD √© de 4 MB.  Quando trabalhamos no apagamento codificado - 1MB.  Se tivermos um disco de 10 TB, obteremos um milh√£o de objetos de megabyte no disco.  Se tivermos 10 discos no servidor, j√° existem 10 milh√µes de objetos, se 32 discos (estamos construindo um cluster eficaz, temos uma aloca√ß√£o restrita), ent√£o 32 milh√µes de objetos devem ser mantidos na mem√≥ria.  Al√©m disso, de fato, as informa√ß√µes sobre cada objeto s√£o armazenadas em v√°rias c√≥pias, porque cada c√≥pia indica que, neste local, est√° nesta vers√£o e nesta - nesta. <br><br>  Acontece uma enorme quantidade de dados, localizada na RAM: <br><br><ul><li>  quanto mais objetos, maior o hist√≥rico de missing_loc; </li><li>  quanto mais PG - mais pg_log e mapa OSD; </li></ul><br>  al√©m disso: <br><br><ul><li>  quanto maior o tamanho do disco; </li><li>  quanto maior a densidade (o n√∫mero de discos em cada servidor); </li><li>  quanto maior a carga no cluster e mais r√°pido o cluster; </li><li>  quanto mais o OSD estiver inativo (no estado Off-line); </li></ul><br>  em outras palavras, quanto <strong>mais √≠ngreme o cluster que constru√≠mos, e quanto mais a parte do cluster n√£o respondeu, mais RAM seria necess√°ria na inicializa√ß√£o</strong> . <br><br><h2>  Otimiza√ß√µes extremas s√£o a raiz de todo mal <br></h2><br><blockquote>  <em>"... e o OOM preto chega aos meninos e meninas maus √† noite e mata todos os processos, √† esquerda e √† direita"</em> <br><br>  Cidade sysadmin legend <br></blockquote><br>  Portanto, a RAM exige muito, o consumo de mem√≥ria est√° aumentando (come√ßamos imediatamente em um ter√ßo do cluster) e o sistema, em teoria, pode entrar no SWAP, se voc√™ o criou naturalmente.  Acho que muitas pessoas pensam que o SWAP √© ruim e n√£o o criam: "Por que?  Temos muita mem√≥ria!  Mas esta √© a abordagem errada. <br><br>  Se o arquivo SWAP n√£o tiver sido criado com anteced√™ncia, uma vez que foi decidido que o Linux funcionaria com mais efici√™ncia, mais cedo ou mais tarde ocorrer√° com falta de mem√≥ria (OOM-killer), e n√£o com o fato de matar quem comeu toda a mem√≥ria, aquele que teve primeiro azar.  Sabemos o que √© uma localiza√ß√£o otimista - pedimos uma mem√≥ria, eles prometem isso para n√≥s, dizemos: ‚ÄúAgora nos d√™ uma‚Äù, em resposta: ‚ÄúMas n√£o!‚Äù  - e sem mem√≥ria. <br><br>  Este √© um trabalho normal do Linux, a menos que configurado na √°rea de mem√≥ria virtual. <br><br>  O processo fica sem mem√≥ria e cai de forma r√°pida e implac√°vel.  Al√©m disso, nenhum outro processo que ele morreu n√£o conhece.  Ele n√£o teve tempo de notificar ningu√©m de nada, eles simplesmente o demitiram. <br><br>  Ent√£o o processo, √© claro, ser√° reiniciado - n√≥s temos systemd, e tamb√©m lan√ßa, se necess√°rio, OSDs que ca√≠ram.  OSDs ca√≠dos come√ßam e ... uma rea√ß√£o em cadeia come√ßa. <br><img src="https://habrastorage.org/webt/9p/s8/4z/9ps84zkjtmuamxyllkcgffsgxkq.png"><br><br>  No nosso caso, come√ßamos o OSD 8 e o OSD 9, eles come√ßaram a esmagar tudo, mas sem sorte OSD 0 e OSD 5. Um assassino sem mem√≥ria voou para eles e os encerrou.  Eles recome√ßaram - eles leram seus dados, come√ßaram a sincronizar e esmagar o resto.  Mais tr√™s azarados (OSD 9, OSD 4 e OSD 7).  Estes tr√™s reiniciados, come√ßaram a pressionar todo o cluster, o pr√≥ximo pacote teve azar. <br><br>  <strong>O aglomerado come√ßa a desmoronar literalmente diante de nossos olhos</strong> .  A degrada√ß√£o ocorre muito rapidamente, e esse "muito r√°pido" √© geralmente expresso em minutos, no m√°ximo dezenas de minutos.  Se voc√™ tiver 30 n√≥s (10 n√≥s por rack) e cort√°-lo devido a uma falha de energia - ap√≥s 6 minutos, metade do cluster fica. <br><br>  Ent√£o, temos algo parecido com o seguinte. <br><img src="https://habrastorage.org/webt/1b/hq/bu/1bhqburpjt74vwnpbgqn5ehdhh0.png"><br><br>  Em quase todos os servidores, temos um OSD com falha.  E se em cada servidor, ou seja, em cada dom√≠nio de falha que temos para o OSD com falha, a <strong>maioria dos nossos dados fica inacess√≠vel</strong> .  Qualquer solicita√ß√£o √© bloqueada - por escrito, por leitura - n√£o faz diferen√ßa.  Isso √© tudo!  Nos levantamos. <br><br>  O que fazer em tal situa√ß√£o?  Mais precisamente, o <strong>que tinha que ser feito</strong> ? <br><br>  <strong>Resposta:</strong> N√£o inicie o cluster imediatamente, ou seja, todo o rack, mas levante cuidadosamente um dem√¥nio cada. <br><br>  Mas n√≥s n√£o sab√≠amos disso.  Come√ßamos imediatamente e conseguimos o que conseguimos.  Nesse caso, lan√ßamos um dos quatro daemons (8, 9, 10, 11), o consumo de mem√≥ria aumentar√° em cerca de 20%.  Como regra, temos um salto.  Em seguida, o consumo de mem√≥ria come√ßa a diminuir, porque algumas das estruturas usadas para armazenar informa√ß√µes sobre como o cluster degradado est√£o saindo.  Ou seja, parte dos grupos de canais retornou ao seu estado normal e tudo o que √© necess√°rio para manter o estado degradado √© liberado - <strong>em teoria, ele √© liberado</strong> . <br><br>  Vamos ver um exemplo.  O c√≥digo C √† esquerda e √† direita √© quase id√™ntico, a diferen√ßa est√° apenas nas constantes. <br><img src="https://habrastorage.org/webt/sy/1j/u0/sy1ju0rfqjg507jxvk_4wax9_o4.png"><br><br>  Estes dois exemplos solicitam uma quantidade diferente de mem√≥ria do sistema: <br><br><ul><li>  esquerda - 2048 pe√ßas de 1 MB cada; </li><li>  √† direita - 2097152 pe√ßas de 1 Kbyte. </li></ul><br>  Ent√£o os dois exemplos esperam que n√≥s os fotografemos no topo.  E depois de pressionar ENTER, eles liberam mem√≥ria - tudo, exceto a √∫ltima pe√ßa.  Isso √© muito importante - a √∫ltima pe√ßa permanece.  E novamente eles est√£o esperando por n√≥s para fotograf√°-los. <br><br>  Abaixo est√° o que realmente aconteceu. <br><img src="https://habrastorage.org/webt/zx/ah/ug/zxahugrdasantcktho7dbu-tnes.png"><br><br><ul><li>  Primeiro, os dois processos iniciaram e consumiram a mem√≥ria.  Parece a verdade - 2 GB RSS. </li><li>  Pressione ENTER e fique surpreso.  O primeiro programa que se destacou em grandes peda√ßos retornou mem√≥ria.  Mas o segundo programa n√£o retornou. </li></ul><br>  A resposta para o porqu√™ disso aconteceu est√° no malloc do Linux. <br><br>  Se solicitarmos mem√≥ria em grandes peda√ßos, ela ser√° emitida usando o mecanismo mmap an√¥nimo, fornecido ao espa√ßo de endere√ßo do processador, de onde a mem√≥ria √© ent√£o cortada para n√≥s.  Quando liberamos (), a mem√≥ria √© liberada e as p√°ginas s√£o retornadas ao cache de p√°ginas (sistema). <br><br>  Se alocamos mem√≥ria em peda√ßos pequenos, fazemos sbrk ().  sbrk () desloca o ponteiro para o final do heap; em teoria, o final deslocado pode ser retornado retornando p√°ginas de mem√≥ria ao sistema se a mem√≥ria n√£o for usada. <br><br>  Agora olhe para a ilustra√ß√£o.  T√≠nhamos muitos registros no hist√≥rico da localiza√ß√£o de objetos degradados e, em seguida, veio a sess√£o do usu√°rio - um objeto de longa dura√ß√£o.  Sincronizamos e todas as estruturas extras foram embora, mas o objeto de longa dura√ß√£o permaneceu e n√£o podemos mover o sbrk () de volta. <br><img src="https://habrastorage.org/webt/06/wf/eg/06wfegwyvu0ibae8xjlwizrwteo.png"><br><br>  Ainda temos muito espa√ßo n√£o utilizado que pode ser liberado se tivermos SWAP.  Mas somos inteligentes - desativamos o SWAP. <br><br>  Obviamente, ser√° usada uma parte da mem√≥ria desde o in√≠cio do heap, mas essa √© apenas uma parte, e um restante muito significativo ser√° mantido ocupado. <br><br>  O que fazer em tal situa√ß√£o?  A resposta est√° abaixo. <br><br><h3>  Lan√ßamento controlado <br></h3><br><ul><li>  Iniciamos um daemon OSD. </li><li>  Esperamos enquanto est√° sincronizado, verificamos os or√ßamentos de mem√≥ria. </li><li>  Se entendermos que sobreviveremos ao in√≠cio do pr√≥ximo dem√¥nio, iniciaremos o pr√≥ximo. </li><li>  Caso contr√°rio, reinicie rapidamente o daemon que ocupou mais mem√≥ria.  Ele conseguiu ficar inativo por um curto per√≠odo de tempo, ele n√£o tem muita hist√≥ria, falta de locs e outras coisas, ent√£o ele come menos mem√≥ria, o or√ßamento da mem√≥ria aumentar√° um pouco. </li><li>  Corremos pelo cluster, controlamos e aumentamos gradualmente tudo. </li><li>  Verificamos se √© poss√≠vel prosseguir para o pr√≥ximo OSD, v√° para ele. </li></ul><br>  O DigitalOcean realmente conseguiu isso: <br>  <em>"Nossa equipe do Datacenter realiza aumentos de mem√≥ria, enquanto outra equipe continua lentamente a criar n√≥s enquanto gerencia manualmente o or√ßamento de mem√≥ria de cada host".</em> <br><img src="https://habrastorage.org/webt/nr/yg/a1/nryga17av_ez5yj0mt3lm5grkk0.png"><br><br>  Vamos voltar √† nossa configura√ß√£o e situa√ß√£o atual.  Agora, temos um cluster em colapso ap√≥s uma rea√ß√£o em cadeia do killer de falta de mem√≥ria.  Proibimos o rein√≠cio autom√°tico do OSD no dom√≠nio vermelho e, um a um, iniciamos n√≥s a partir dos dom√≠nios azuis.  Porque <strong>nossa primeira tarefa √© sempre restaurar o servi√ßo</strong> , sem entender por que isso aconteceu.  N√≥s entenderemos mais tarde, quando restaurarmos o servi√ßo.  Em opera√ß√£o, esse √© sempre o caso. <br><br>  Trazemos o cluster para o estado de destino para restaurar o servi√ßo e, em seguida, come√ßamos a executar um OSD ap√≥s o outro, de acordo com nossa metodologia.  Observamos o primeiro, se necess√°rio, reinicie os outros para ajustar o or√ßamento da mem√≥ria, o pr√≥ximo - 9, 10, 11 - e o cluster parece estar sincronizado e pronto para iniciar a manuten√ß√£o. <br><br>  O problema √© como a <strong>manuten√ß√£o de grava√ß√£o</strong> √© realizada <strong>no Ceph</strong> . <br><img src="https://habrastorage.org/webt/hl/rp/ek/hlrpekm0rvjgrjwl11zgdklwecc.png"><br><br>  Temos tr√™s r√©plicas: um OSD principal e dois escravos.  Esclareceremos que o mestre / escravo em cada Grupo de Coloca√ß√£o tem o seu, mas cada um tem um mestre e dois escravos. <br><br>  A opera√ß√£o de grava√ß√£o ou leitura cai no mestre.  Ao ler, se o mestre tiver a vers√£o correta, ele a entregar√° ao cliente.  A grava√ß√£o √© um pouco mais complicada, a grava√ß√£o deve ser repetida em todas as r√©plicas.  Assim, quando o cliente grava 64 KB no OSD 0, os mesmos 64 KB do nosso exemplo v√£o para o OSD 5 e OSD 8. <br><br>  Mas o fato √© que nosso OSD 8 est√° muito degradado, porque reiniciamos muitos processos. <br><img src="https://habrastorage.org/webt/es/_z/fr/es_zfrsvdaq8a7f_rgn7hcakpi4.png"><br><br>  Como no Ceph qualquer mudan√ßa √© uma transi√ß√£o de vers√£o para vers√£o, no OSD 0 e OSD 5, teremos uma nova vers√£o, no OSD 8 - a antiga.  ,   ,    ( 64 )    OSD 8   ‚Äî   4  ( ).     4   OSD 0,   OSD 8,  ,    .       ,      64 . <br><br>    ‚Äî  . <br><img src="https://habrastorage.org/webt/ch/uc/l_/chucl_b0vhoi-jvuhl3xokm26qg.png"><br><br>   : <br><br><ul><li>    4   1 ,  1000 /  1 . </li><li>   4  ( )  22 ,  45 /. </li></ul><br> ,      ,       ,        ,         . <br><br>      ‚Äî     . <br><img src="https://habrastorage.org/webt/it/0p/34/it0p34kbqfs3u9hvyhmextflvqc.png"><br><br>    4   22 ,  22 ,   1    4   .   45          SSD,       1  ‚Äî <strong>   45 </strong> . <br><br>       ,    . <br><br><h2>    <br></h2><br><br><ul><li>   <strong> </strong> ,    ‚Äî (45+1) / 2 = <strong>23 .</strong> </li><li>   <strong>75% </strong> ,  (45 * 3 + 1) / 4 = <strong>34 </strong> . </li><li>  90% ‚Äî(45 * 9 + 1) / 10 = 41  ‚Äî  40  ,   . </li></ul><br>     Ceph,      .                 ,     ,    ,     . <br><br>      Ceph       . <br><img src="https://habrastorage.org/webt/ng/jj/od/ngjjodzmfd4n6kes71g4n6pg7os.png"><br><br><ol><li>     ‚Äî   :  , ,  ,  ,    . <br></li><li>  ‚Äî latency.   latency  ,   .      100%    (    ,          ). Latency  60     ,       . <br></li></ol><br><img src="https://habrastorage.org/webt/z3/pb/ob/z3pbobkev0bfszscnwgprpop3xe.png"><br><br>       ,       .  10 ,   1 200 /,    300      ,    ,   .  10 SSD ‚Äî   300   ,   ‚Äî ,  - 300   . <br><br><blockquote>    ,     . <br></blockquote><br>  ,     .       900 / (  SSD).     2 500   128    ( , ESXi  HyperV     128 ).      degraded,   225   .     file store,   object store,         ( ),    110   ,     - . <br><br> SSD  110    ‚Äî ! <br><br> <strong>   ?</strong> <br><br> <strong> 1:</strong>     ‚Äî <b>   </b> . <br><img src="https://habrastorage.org/webt/ls/ib/rh/lsibrhcfnucjiox9f8gzxbk1cc8.png"><br><br>    :   ;   PG; <br>       . <br><br>    : <br><br><ul><li>    ,  45  ‚Äî   . </li><li>     (     . ),   14 . </li><li>    ,  8  (  10% PG). </li></ul><br>   <strong>  ,  </strong> ,       , ,  ,     . <br><br> <strong> 2:</strong>   ‚Äî <b>  </b> (order, objectsize)  . <br><br>     , , ,   4   2  1 .      ,     ,   .  : <br><br><ul><li>     ; </li><li>     (latency)     . </li></ul><br>     : <br><br><ul><li>    ; </li><li>     ; </li><li>   ‚Äî        .     4 ,   . </li></ul><br>        (32  ) ‚Äî      ! <br><br> <strong> 3:</strong>    ‚Äî  <b> Ceph</b> . <br><br>     ,   -,  <strong> Ceph</strong> .                  ,      ,      .     . <br><img src="https://habrastorage.org/webt/c8/nr/1a/c8nr1akew1kjleodu5trq_ow3oy.png"><br><br>     ,   ‚Äî Latency.  ‚Äî  ,  ‚Äî . Latency      30% ,       ,      . <br><br>  Community     ,     preproduction .     ,     .      ,   . <br><br><h1>  Conclus√£o <br></h1><br>      -  ,     .        ,   Ceph    - ,  ,    . <br><br> ‚óè <strong>   -  </strong> . <br>     ,     .  ,  <strong>     </strong> .       .  ,         ,    production.  ,       ,     ,    DigitalOcean  ,   .   ,  ,    ,  . <br><br>   ,        ,        .    ,  : ¬´    !  ?!¬ª     ,  ,     .   ,      : ,   ,    down time. <br><br> ‚óè <strong>    (OSD).</strong> <br>  ,       ,     ‚Äî     , ,  -      ,   . <strong>     OSD ‚Äî    ‚Äî   </strong> .    ,     . <br><br> ‚óè <strong>  .</strong> <br>        OSD       . <strong>   ,   </strong> .  ,     ,     ,   . <br><br> ‚óè <strong>  RAM   OSD.</strong> <br><br> ‚óè <strong>  SWAP.</strong> <br>   SWAP    Ceph' ,    Linux' .         . <br><br> ‚óè <strong>    .</strong> <br>         100%,    10%. ,    ,      ,   . <br><br> ‚óè <strong>        RBD      Rados Getway.</strong> <br>  ,         . <strong>   SWAP ‚Äî    .</strong> ,    SWAP  ‚Äî    , ,  ,    ,     . <br><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Este artigo √© uma transcri√ß√£o do melhor relat√≥rio do DevOpsConf Russia. </font><font style="vertical-align: inherit;">Em breve, abriremos o v√≠deo e publicaremos uma vers√£o em texto de como os t√≥picos s√£o interessantes. </font><font style="vertical-align: inherit;">Inscreva-se aqui no </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">youtube</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ou no </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">boletim informativo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> se voc√™ n√£o perder esses materiais √∫teis e esteja ciente das not√≠cias do DevOps.</font></font><br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt431536/">https://habr.com/ru/post/pt431536/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt431526/index.html">Influ√™ncia corrupta: como a Stasi defendeu a Alemanha Oriental dos videogames</a></li>
<li><a href="../pt431528/index.html">Escritor e g√™nio matem√°tico misterioso promovem solu√ß√£o do problema de permuta√ß√£o</a></li>
<li><a href="../pt431530/index.html">Li√ß√£o aberta "Design de materiais Android: vis√£o geral da atualiza√ß√£o"</a></li>
<li><a href="../pt431532/index.html">Memristores constitu√≠dos por partes de 2 nm de espessura</a></li>
<li><a href="../pt431534/index.html">Identidades de problemas entre desenvolvedores</a></li>
<li><a href="../pt431538/index.html">Case Rate & Goods e Mobio: aumento gradual em todos os indicadores</a></li>
<li><a href="../pt431540/index.html">Pacotes e gerenciadores de pacotes para k8s</a></li>
<li><a href="../pt431542/index.html">Desenvolvimento e manuten√ß√£o eficazes de pap√©is Ansible</a></li>
<li><a href="../pt431544/index.html">Leve DevOps para as massas</a></li>
<li><a href="../pt431546/index.html">Por que estamos dizendo OK?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
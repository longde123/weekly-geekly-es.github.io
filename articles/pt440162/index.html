<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏻‍🎓 👼🏻 👓 Um exemplo de uma rede neural simples em C / C ++ 🤵🏿 👎🏾 🧔🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Olá pessoal. 

 Eu decidi compartilhar uma solução simples e espaçosa na minha opinião de uma rede neural em C ++. 

 Por que essa informação deve ser...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Um exemplo de uma rede neural simples em C / C ++</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440162/">  Olá pessoal. <br><br>  Eu decidi compartilhar uma solução simples e espaçosa na minha opinião de uma rede neural em C ++. <br><br>  <b>Por que essa informação deve ser interessante?</b> <br><br>  <b>Resposta:</b> Tentei programar o trabalho do perceptron multicamada em um conjunto mínimo, para que ele pudesse ser configurado como eu gosto em apenas algumas linhas de código, e a implementação dos algoritmos básicos para trabalhar em “C” permitirá transferir facilmente as linguagens orientadas para “C” (em e para qualquer outro) <b><u>sem usar bibliotecas de terceiros!</u></b> <br><br><h4>  Por favor, dê uma olhada no que veio dele </h4><br>  Não vou falar sobre o <b>objetivo das redes neurais</b> , espero que você não tenha sido banido do <b>Google</b> e encontre as informações de seu interesse (objetivo, recursos, aplicativos e assim por diante). <br><br>  Você encontrará o <b>código fonte</b> no final do artigo, mas por enquanto, em ordem. <br><br><h3>  Vamos começar a análise </h3><br><h4>  1) Arquitetura e detalhes técnicos </h4><br>  - <b>perceptron multicamada</b> com a capacidade de configurar qualquer número de camadas com uma determinada largura.  Abaixo é apresentado <br><br><div class="spoiler">  <b class="spoiler_title">exemplo de configuração</b> <div class="spoiler_text">  <b>myNeuero.cpp</b> <br><br><pre><code class="cpp hljs">inputNeurons = <span class="hljs-number"><span class="hljs-number">100</span></span>; <span class="hljs-comment"><span class="hljs-comment">//   outputNeurons =2; //   nlCount = 4; //  (    3,      1 list = (nnLay*) malloc((nlCount)*sizeof(nnLay)); inputs = (float*) malloc((inputNeurons)*sizeof(float)); targets = (float*) malloc((outputNeurons)*sizeof(float)); list[0].setIO(100,20); //  INPUTS/OUTPUTS    list[1].setIO(20,6); // -//- list[2].setIO(6,3); // -//- list[3].setIO(3,2); // -//-  </span></span></code> </pre> <br></div></div><br>  Observe que a configuração da largura da entrada e saída de cada camada é realizada de acordo com uma determinada regra - a entrada da camada atual = a saída da anterior.  Uma exceção é a camada de entrada. <br><br>  Portanto, você tem a oportunidade de definir qualquer configuração manualmente ou de acordo com uma regra especificada antes de compilar ou após a compilação para ler dados dos arquivos de origem. <a name="habracut"></a><br><br>  - implementação do mecanismo de <b>propagação traseira de erros</b> com a capacidade de definir a velocidade de aprendizado <br><br>  <b>myNeuero.h</b> <br><br><pre> <code class="cpp hljs"> <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> learnRate 0.1</span></span></code> </pre> <br>  - instalação de <b>pesos iniciais</b> <br><br>  <b>myNeuero.h</b> <br><br><pre> <code class="cpp hljs"> <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> randWeight (( ((float)qrand() / (float)RAND_MAX) - 0.5)* pow(out,-0.5))</span></span></code> </pre> <br>  <b>Nota</b> : se houver mais de três camadas (nlCount&gt; 4), é necessário aumentar o pow (saída, -0,5) para que, quando o sinal passa diretamente, sua energia não se reduz a 0. Exemplo de pow (saída, -0,2) <br><br>  - a <b>base do código em C.</b> Os algoritmos básicos e o armazenamento dos coeficientes de ponderação são implementados como uma estrutura em C; todo o resto é a concha da função de chamada dessa estrutura; também é um reflexo de qualquer uma das camadas tiradas separadamente. <br><br><div class="spoiler">  <b class="spoiler_title">Estrutura de camada</b> <div class="spoiler_text">  <b>myNeuero.h</b> <br><br><pre> <code class="cpp hljs"> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">nnLay</span></span></span><span class="hljs-class">{</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> in; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> out; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>** matrix; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>* hidden; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>* errors; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getInCount</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{<span class="hljs-keyword"><span class="hljs-keyword">return</span></span> in;} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutCount</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{<span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out;} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> **</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{<span class="hljs-keyword"><span class="hljs-keyword">return</span></span> matrix;} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">updMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *enteredVal)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ou =<span class="hljs-number"><span class="hljs-number">0</span></span>; ou &lt; out; ou++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> hid =<span class="hljs-number"><span class="hljs-number">0</span></span>; hid &lt; in; hid++) { matrix[hid][ou] += (learnRate * errors[ou] * enteredVal[hid]); } matrix[in][ou] += (learnRate * errors[ou]); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setIO</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> inputs, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> outputs)</span></span></span><span class="hljs-function"> </span></span>{ in=inputs; out=outputs; hidden = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((out)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); matrix = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>**) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((in+<span class="hljs-number"><span class="hljs-number">1</span></span>)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> inp =<span class="hljs-number"><span class="hljs-number">0</span></span>; inp &lt; in+<span class="hljs-number"><span class="hljs-number">1</span></span>; inp++) { matrix[inp] = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>(out*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> inp =<span class="hljs-number"><span class="hljs-number">0</span></span>; inp &lt; in+<span class="hljs-number"><span class="hljs-number">1</span></span>; inp++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> outp =<span class="hljs-number"><span class="hljs-number">0</span></span>; outp &lt; out; outp++) { matrix[inp][outp] = randWeight; } } } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">makeHidden</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *inputs)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> hid =<span class="hljs-number"><span class="hljs-number">0</span></span>; hid &lt; out; hid++) { <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> tmpS = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> inp =<span class="hljs-number"><span class="hljs-number">0</span></span>; inp &lt; in; inp++) { tmpS += inputs[inp] * matrix[inp][hid]; } tmpS += matrix[in][hid]; hidden[hid] = sigmoida(tmpS); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function">* </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getHidden</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> hidden; }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calcOutError</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *targets)</span></span></span><span class="hljs-function"> </span></span>{ errors = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((out)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ou =<span class="hljs-number"><span class="hljs-number">0</span></span>; ou &lt; out; ou++) { errors[ou] = (targets[ou] - hidden[ou]) * sigmoidasDerivate(hidden[ou]); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calcHidError</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *targets,</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> **outWeights,</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> inS, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> outS)</span></span></span><span class="hljs-function"> </span></span>{ errors = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((inS)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> hid =<span class="hljs-number"><span class="hljs-number">0</span></span>; hid &lt; inS; hid++) { errors[hid] = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ou =<span class="hljs-number"><span class="hljs-number">0</span></span>; ou &lt; outS; ou++) { errors[hid] += targets[ou] * outWeights[hid][ou]; } errors[hid] *= sigmoidasDerivate(hidden[hid]); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function">* </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getErrors</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> errors; }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sigmoida</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> val)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (<span class="hljs-number"><span class="hljs-number">1.0</span></span> / (<span class="hljs-number"><span class="hljs-number">1.0</span></span> + <span class="hljs-built_in"><span class="hljs-built_in">exp</span></span>(-val))); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sigmoidasDerivate</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> val)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (val * (<span class="hljs-number"><span class="hljs-number">1.0</span></span> - val)); }; };</code> </pre><br></div></div><br><h4>  2) Aplicação </h4><br>  Testando o projeto com o conjunto mnist foi bem-sucedido, conseguimos obter uma probabilidade condicional de reconhecimento de manuscrito de 0,9795 (nlCount = 4, learnRate = 0,03 e várias épocas).  O principal objetivo do teste era testar o desempenho da rede neural com a qual ela lidava. <br><br>  Abaixo, consideramos o trabalho sobre a <b>"tarefa condicional"</b> . <br><br>  <b>Dados de origem:</b> <br><br>  -2 vetores de entrada aleatórios de 100 valores <br>  rede neural com geração aleatória de pesos <br>  -2 estabelecer metas <br><br>  <b>O código</b> na função main () <br><br><pre> <code class="cpp hljs">{ <span class="hljs-comment"><span class="hljs-comment">//!!!________    qDebug()   std::cout  std::cerr myNeuro *bb = new myNeuro(); //----------------------------------INPUTS----GENERATOR------------- /!  2    qsrand((QTime::currentTime().second())); float *abc = new float[100]; for(int i=0; i&lt;100;i++) { abc[i] =(qrand()%98)*0.01+0.01; } float *cba = new float[100]; for(int i=0; i&lt;100;i++) { cba[i] =(qrand()%98)*0.01+0.01; } //---------------------------------TARGETS----GENERATOR------------- //  2   float *tar1 = new float[2]; tar1[0] =0.01; tar1[1] =0.99; float *tar2 = new float[2]; tar2[0] =0.99; tar2[1] =0.01; //--------------------------------NN---------WORKING--------------- //    bb-&gt;query(abc); qDebug()&lt;&lt;"_________________________________"; bb-&gt;query(cba); //  int i=0; while(i&lt;100000) { bb-&gt;train(abc,tar1); bb-&gt;train(cba,tar2); i++; } //   (   ) qDebug()&lt;&lt;"___________________RESULT_____________"; bb-&gt;query(abc); qDebug()&lt;&lt;"______"; bb-&gt;query(cba); }</span></span></code> </pre> <br>  <b>O resultado da rede neural</b> <br><br><img src="https://habrastorage.org/webt/gt/oe/vc/gtoevca428fe3i7wmvkkupaayq0.png" alt="imagem"><br><br><h3>  <b>Sumário</b> </h3><br>  Como você pode ver, chamar a função de consulta (entradas) antes do treinamento para cada um dos vetores não nos permite julgar suas diferenças.  Além disso, chamando a função train (input, target), para treinamento com o objetivo de organizar coeficientes de peso para que a rede neural possa subsequentemente distinguir entre vetores de entrada. <br><br>  Após concluir o treinamento, observamos que a tentativa de mapear o vetor “abc” para “tar1” e “cba” para “tar2” falhou. <br><br>  <b>Você tem a oportunidade, usando o código-fonte, de testar independentemente o desempenho e experimentar a configuração!</b> <br><br>  PS: este código foi escrito a partir do QtCreator, espero que você possa substituir facilmente a saída, deixar seus comentários e comentários. <br><br>  PPS: se alguém estiver interessado em uma análise detalhada do trabalho de struct nnLay {} write, haverá uma nova postagem. <br><br>  PPPS: Espero que alguém possa usar o código orientado a "C" para portar para outras ferramentas. <br><br><div class="spoiler">  <b class="spoiler_title">Código fonte</b> <div class="spoiler_text">  <b>main.cpp</b> <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCoreApplication&gt; #include &lt;QDebug&gt; #include &lt;QTime&gt; #include "myneuro.h" int main(int argc, char *argv[]) { QCoreApplication a(argc, argv); myNeuro *bb = new myNeuro(); //----------------------------------INPUTS----GENERATOR------------- qsrand((QTime::currentTime().second())); float *abc = new float[100]; for(int i=0; i&lt;100;i++) { abc[i] =(qrand()%98)*0.01+0.01; } float *cba = new float[100]; for(int i=0; i&lt;100;i++) { cba[i] =(qrand()%98)*0.01+0.01; } //---------------------------------TARGETS----GENERATOR------------- float *tar1 = new float[2]; tar1[0] =0.01; tar1[1] =0.99; float *tar2 = new float[2]; tar2[0] =0.99; tar2[1] =0.01; //--------------------------------NN---------WORKING--------------- bb-&gt;query(abc); qDebug()&lt;&lt;"_________________________________"; bb-&gt;query(cba); int i=0; while(i&lt;100000) { bb-&gt;train(abc,tar1); bb-&gt;train(cba,tar2); i++; } qDebug()&lt;&lt;"___________________RESULT_____________"; bb-&gt;query(abc); qDebug()&lt;&lt;"______"; bb-&gt;query(cba); qDebug()&lt;&lt;"_______________THE____END_______________"; return a.exec(); }</span></span></span></span></code> </pre><br>  <b>myNeuro.cpp</b> <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"myneuro.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QDebug&gt; myNeuro::myNeuro() { //-------- inputNeurons = 100; outputNeurons =2; nlCount = 4; list = (nnLay*) malloc((nlCount)*sizeof(nnLay)); inputs = (float*) malloc((inputNeurons)*sizeof(float)); targets = (float*) malloc((outputNeurons)*sizeof(float)); list[0].setIO(100,20); list[1].setIO(20,6); list[2].setIO(6,3); list[3].setIO(3,2); //----------------- // inputNeurons = 100; // outputNeurons =2; // nlCount = 2; // list = (nnLay*) malloc((nlCount)*sizeof(nnLay)); // inputs = (float*) malloc((inputNeurons)*sizeof(float)); // targets = (float*) malloc((outputNeurons)*sizeof(float)); // list[0].setIO(100,10); // list[1].setIO(10,2); } void myNeuro::feedForwarding(bool ok) { list[0].makeHidden(inputs); for (int i =1; i&lt;nlCount; i++) list[i].makeHidden(list[i-1].getHidden()); if (!ok) { qDebug()&lt;&lt;"Feed Forward: "; for(int out =0; out &lt; outputNeurons; out++) { qDebug()&lt;&lt;list[nlCount-1].hidden[out]; } return; } else { // printArray(list[3].getErrors(),list[3].getOutCount()); backPropagate(); } } void myNeuro::backPropagate() { //-------------------------------ERRORS-----CALC--------- list[nlCount-1].calcOutError(targets); for (int i =nlCount-2; i&gt;=0; i--) list[i].calcHidError(list[i+1].getErrors(),list[i+1].getMatrix(), list[i+1].getInCount(),list[i+1].getOutCount()); //-------------------------------UPD-----WEIGHT--------- for (int i =nlCount-1; i&gt;0; i--) list[i].updMatrix(list[i-1].getHidden()); list[0].updMatrix(inputs); } void myNeuro::train(float *in, float *targ) { inputs = in; targets = targ; feedForwarding(true); } void myNeuro::query(float *in) { inputs=in; feedForwarding(false); } void myNeuro::printArray(float *arr, int s) { qDebug()&lt;&lt;"__"; for(int inp =0; inp &lt; s; inp++) { qDebug()&lt;&lt;arr[inp]; } }</span></span></span></span></code> </pre> <br>  <b>myNeuro.h</b> <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">ifndef</span></span></span><span class="hljs-meta"> MYNEURO_H #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> MYNEURO_H #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;iostream&gt; #include &lt;math.h&gt; #include &lt;QtGlobal&gt; #include &lt;QDebug&gt; #define learnRate 0.1 #define randWeight (( ((float)qrand() / (float)RAND_MAX) - 0.5)* pow(out,-0.5)) class myNeuro { public: myNeuro(); struct nnLay{ int in; int out; float** matrix; float* hidden; float* errors; int getInCount(){return in;} int getOutCount(){return out;} float **getMatrix(){return matrix;} void updMatrix(float *enteredVal) { for(int ou =0; ou &lt; out; ou++) { for(int hid =0; hid &lt; in; hid++) { matrix[hid][ou] += (learnRate * errors[ou] * enteredVal[hid]); } matrix[in][ou] += (learnRate * errors[ou]); } }; void setIO(int inputs, int outputs) { in=inputs; out=outputs; hidden = (float*) malloc((out)*sizeof(float)); matrix = (float**) malloc((in+1)*sizeof(float)); for(int inp =0; inp &lt; in+1; inp++) { matrix[inp] = (float*) malloc(out*sizeof(float)); } for(int inp =0; inp &lt; in+1; inp++) { for(int outp =0; outp &lt; out; outp++) { matrix[inp][outp] = randWeight; } } } void makeHidden(float *inputs) { for(int hid =0; hid &lt; out; hid++) { float tmpS = 0.0; for(int inp =0; inp &lt; in; inp++) { tmpS += inputs[inp] * matrix[inp][hid]; } tmpS += matrix[in][hid]; hidden[hid] = sigmoida(tmpS); } }; float* getHidden() { return hidden; }; void calcOutError(float *targets) { errors = (float*) malloc((out)*sizeof(float)); for(int ou =0; ou &lt; out; ou++) { errors[ou] = (targets[ou] - hidden[ou]) * sigmoidasDerivate(hidden[ou]); } }; void calcHidError(float *targets,float **outWeights,int inS, int outS) { errors = (float*) malloc((inS)*sizeof(float)); for(int hid =0; hid &lt; inS; hid++) { errors[hid] = 0.0; for(int ou =0; ou &lt; outS; ou++) { errors[hid] += targets[ou] * outWeights[hid][ou]; } errors[hid] *= sigmoidasDerivate(hidden[hid]); } }; float* getErrors() { return errors; }; float sigmoida(float val) { return (1.0 / (1.0 + exp(-val))); } float sigmoidasDerivate(float val) { return (val * (1.0 - val)); }; }; void feedForwarding(bool ok); void backPropagate(); void train(float *in, float *targ); void query(float *in); void printArray(float *arr,int s); private: struct nnLay *list; int inputNeurons; int outputNeurons; int nlCount; float *inputs; float *targets; }; #endif // MYNEURO_H</span></span></span></span></code> </pre> <br></div></div><br><br><h3>  <b>UPD:</b> </h3>  As fontes para checar o mnist são: <div class="spoiler">  <b class="spoiler_title">o link</b> <div class="spoiler_text">  1) Projeto <br>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Github.com/mamkin-itshnik/simple-neuro-network</a> " <br>  Há também uma descrição gráfica do trabalho.  Resumidamente, ao pesquisar dados de teste na rede, você recebe o valor de cada um dos neurônios de saída (10 neurônios correspondem a números de 0 a 9).  Para tomar uma decisão sobre a figura representada, você precisa conhecer o índice do neurônio máximo.  Dígito = índice + 1 (não esqueça de onde são numerados os números nas matrizes)) <br>  2) MNIST <br>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Www.kaggle.com/oddrationale/mnist-in-csv</a> ” (se você precisar usar um conjunto de dados menor, basta limitar o contador while ao ler o arquivo CSV do PS: existe um exemplo para o git) <br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt440162/">https://habr.com/ru/post/pt440162/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt440148/index.html">Realidade virtual - vida paralela com suas correntes</a></li>
<li><a href="../pt440152/index.html">DIY linear Lehmann ou como clonar um alemão puro-sangue com um bom resultado</a></li>
<li><a href="../pt440154/index.html">Como o Spore foi criado: entrevistas com desenvolvedores</a></li>
<li><a href="../pt440156/index.html">Como organizar o desenvolvimento distribuído, se isso não for possível</a></li>
<li><a href="../pt440158/index.html">Estatísticas de vendas de veículos elétricos e híbridos recarregáveis ​​em 2018 (nos EUA e no mundo)</a></li>
<li><a href="../pt440164/index.html">A monetização dos dados do usuário se tornará uma tendência em 2019?</a></li>
<li><a href="../pt440166/index.html">Compactação de ponteiro Java</a></li>
<li><a href="../pt440168/index.html">Relatórios de vídeo do FunTech ML-meetup</a></li>
<li><a href="../pt440170/index.html">Análise de incidentes relacionados a ataques cibernéticos em projetos de blockchain</a></li>
<li><a href="../pt440172/index.html">CQRS: o princípio de "dividir e conquistar" a serviço de um programador</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
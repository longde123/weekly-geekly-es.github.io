<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏽‍✈️ 👨🏼‍🍳 👨‍👩‍👧 使用Neural Compute Stick和OpenVINO在Raspberry Pi上启动神经网络检测器 👨🏽‍🏫 🤜🏽 🤘🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="随着神经网络的普及和发展，越来越需要在嵌入式和低功耗设备，机器人和无人机上使用它们。 神经计算棒设备与英特尔OpenVINO框架相结合，使我们能够通过对神经网络进行大量计算来解决此问题。 因此，您几乎可以实时在诸如Raspberry Pi的低功耗设备上启动神经网络分类器或检测器，而不会大大增加能耗。...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>使用Neural Compute Stick和OpenVINO在Raspberry Pi上启动神经网络检测器</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436744/"> 随着神经网络的普及和发展，越来越需要在嵌入式和低功耗设备，机器人和无人机上使用它们。 神经计算棒设备与英特尔OpenVINO框架相结合，使我们能够通过对神经网络进行大量计算来解决此问题。 因此，您几乎可以实时在诸如Raspberry Pi的低功耗设备上启动神经网络分类器或检测器，而不会大大增加能耗。 在本文中，我将向您展示如何使用OpenVINO框架（C ++）和Neural Compute Stick在Raspberry Pi上启动简单的面部检测系统。 <br><br> 像往常一样，所有代码都可以在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">GitHub上获得</a> 。 <br><br><img src="https://habrastorage.org/webt/qu/b_/tj/qub_tj1u6ztw9irfy9ivtaaidcc.jpeg"><br><a name="habracut"></a><br><h3> 关于神经计算棒和OpenVINO的一些知识 </h3><br>  2017年夏天，英特尔发布了<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">神经计算棒</a> （NCS）设备，旨在在低功率设备上运行神经网络，几个月后就可以购买和测试了，我做到了。  NCS是一个小型计算模块，带有蓝色外壳（也用作散热器），通过USB连接到主设备。 内部还有Intel Myriad <abbr title="视觉处理单元">VPU</abbr> ，它本质上是12核并行处理器，针对神经网络中经常发生的操作进行了改进。  NCS不适合训练神经网络，但是在已经训练的神经网络中的推理速度与GPU上的速度相当。  NCS中的所有计算都是对16位浮点数执行的，这可以提高速度。  NCS只需1瓦的电源即可运行，也就是说，在5 V时，USB连接器上消耗的电流高达200 mA-甚至比Raspberry Pi的摄像头（250 mA）还小。 <br><br><img src="https://habrastorage.org/webt/8d/u8/ov/8du8ov7hj1-f3vk8sjbenkyupvm.png"><br><br> 为了与第一个NCS配合使用，使用了<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">神经计算SDK</a> （NCSDK）：它包括用于将<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Caffe</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TensorFlow</a>格式的神经网络编译为NCS格式的工具，用于测量其性能的工具以及用于推理的Python和C ++ API。 <br><br> 然后发布了新版本的NCS框架： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">NCSDK2</a> 。  API进行了很多更改，尽管对我来说有些更改很奇怪，但还是有一些有用的创新。 特别是，添加了从float 32位到float 16位到C ++的自动转换（以前，拐杖必须以Numpy的代码形式插入）。 还出现了图像队列及其处理结果。 <br><br> 英特尔于2018年5月发布了<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">OpenVINO</a> （以前称为英特尔计算机视觉SDK）。 该框架旨在在各种设备上高效启动神经网络：英特尔处理器和图形卡， <abbr title="现场可编程门阵列">FPGA</abbr>以及神经计算棒。 <br><br>  2018年11月，发布了新版本的加速器： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Neural Compute Stick 2</a> 。 该设备的计算能力得到了提高：在现场的描述中，他们承诺将加速到8倍，但是，我无法测试该设备的新版本。 通过将内核数从12增加到16，以及添加针对神经网络进行了优化的新计算设备来实现加速。 没错，我没有找到有关功耗信息的信息。 <br><br>  NCS的第二个版本已经与NCSDK或NCSDK2不兼容：除两个版本的NCS之外，OpenVINO能够与许多其他设备一起使用，已经通过了授权。  OpenVINO本身具有强大的功能，并包括以下组件： <br><br><ol><li> 模型优化器：Python脚本，使您可以将神经网络从流行的深度学习框架转换为通用的OpenVINO格式。 支持的框架列表： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Caffe</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TensorFlow</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">MXNET</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Kaldi</a> （语音识别框架）， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ONNX</a> （用于表示神经网络的开放格式）。 </li><li> 推理引擎：用于特定神经网络推理的C ++和Python API，从特定的推理设备中抽象出来。 对于CPU，GPU，FPGA和NCS，API代码看起来几乎相同。 </li><li> 一组用于不同设备的插件。 插件是动态库，它们在主程序的代码中显式加载。 我们对NCS插件最感兴趣。 </li><li> 一组通用OpenVINO格式的预训练模型（完整列表在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此处</a> ）。 令人印象深刻的高质量神经网络集合：面部，行人，物体的检测器； 识别面部的方向，面部的特殊点，人体姿势； 超分辨率 和其他。 值得注意的是，NCS / FPGA / GPU并非全部支持它们。 </li><li>  Model Downloader：另一个脚本，可简化通过网络以OpenVINO格式下载模型的过程（尽管没有它也可以轻松完成）。 </li><li> 针对英特尔硬件优化的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">OpenCV</a>计算机视觉<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">库</a> 。 </li><li> 计算机视觉库<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">OpenVX</a> 。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">面向深度神经网络的</a>英特尔<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">计算库</a> 。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">深度神经网络的</a>英特尔<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">数学内核库</a> 。 </li><li> 用于优化用于FPGA的神经网络的工具（可选）。 </li><li> 文档和示例程序。 </li></ol><br> 在之前的文章中，我讨论了如何在NCS上运行YOLO面部检测器<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">（第一篇文章）</a> ，以及如何训练您的SSD面部检测器并在Raspberry Pi和NCS上运行它<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">（第二篇文章）</a> 。 在这些文章中，我使用了NCSDK和NCSDK2。 在本文中，我将告诉您如何执行类似的操作，但是使用OpenVINO，我将对不同的面部检测器和两个用于启动它们的框架进行较小的比较，并指出一些陷阱。 我用C ++编写，因为我相信通过这种方式可以实现更好的性能，这对于Raspberry Pi而言非常重要。 <br><br><h3> 安装OpenVINO </h3><br> 尽管有一些细微之处，但这并不是最困难的任务。 在撰写本文时，OpenVINO仅支持Ubuntu 16.04 LTS，CentOS 7.4和Windows10。我已经安装了Ubuntu 18，并且需要<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">小拐杖</a>来安装它。 我还想将OpenVINO与NCSDK2进行比较，后者的安装也存在问题：特别是，它收紧了Caffe和TensorFlow的版本，并且可能会稍微破坏环境设置。 最后，我决定遵循简单的方法，将两个框架都安装到具有Ubuntu 16的虚拟机中（我使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">VirtualBox</a> ）。 <br><br> 值得注意的是，为了将NCS成功连接到虚拟机，您需要安装VirtualBox guest虚拟机附加组件并启用USB 3.0支持。 我还为USB设备添加了通用过滤器，因此可以无问题地连接NCS（尽管在虚拟机的设置中仍必须连接网络摄像头）。 要安装和编译OpenVINO，您需要有一个Intel帐户，选择一个框架选项（支持或不支持FPGA），然后按照<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">说明进行操作</a> 。  NCSDK甚至更简单：它<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">从GitHub</a>引导（不要忘记为新版本的框架选择ncsdk2分支），然后需要<code>make install</code> 。 <br><br> 在虚拟机中运行NCSDK2时遇到的唯一问题是以下形式的错误： <br><br><pre> <code class="plaintext hljs">E: [ 0] dispatcherEventReceive:236 dispatcherEventReceive() Read failed -1 E: [ 0] eventReader:254 Failed to receive event, the device may have reset</code> </pre><br> 它发生在程序正确执行的结尾，并且（似乎）没有任何影响。 显然，这是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">与VM相关</a>的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">小错误</a> （不应在Raspberry上出现）。 <br><br>  Raspberry Pi上的安装有很大不同。 首先，确保已安装Raspbian Stretch：这两个框架都只能在此OS上正常工作。  NCSDK2需要<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在仅API模式下</a>进行<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">编译</a> ，否则它将尝试安装Caffe和TensorFlow，这不太可能会使您的Raspberry满意。 就OpenVINO而言，已经有<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Raspberry</a>的已<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">组装版本</a> ，您只需解压缩并配置环境变量即可。 在此版本中，只有C ++和Python API以及OpenCV库，所有其他工具均不可用。 这意味着对于这两个框架，必须在装有Ubuntu的计算机上预先转换模型。 我的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">面部检测演示</a>可在Raspberry和台式机上运行，​​因此我只是将转换后的神经网络文件添加到GitHub存储库中，以使其更易于与Raspberry同步。 我有一个Raspberry Pi 2模型B，但应该与其他模型一起使用。 <br><br> 关于Raspberry Pi和Neural Compute Stick的交互作用还有另一个细微之处：如果在笔记本电脑中，仅将NCS插入最近的USB 3.0端口就足够了，那么对于Raspberry，您将不得不找到一条USB电缆，否则NSC会用它的身体挡住其余三个USB连接器。 还值得记住的是，Raspberry具有所有USB 2.0版本，因此由于通信延迟，推理速度会降低（详细比较将在以后进行）。 但是，如果要将两个或多个NCS连接到Raspberry，最有可能必须找到具有附加电源的USB集线器。 <br><br><h3>  OpenVINO代码是什么样的 </h3><br> 相当笨重。 从加载插件开始到推断本身结束，有很多不同的操作可以做，这就是为什么我为检测器编写了一个包装类的原因。 完整的代码可以在GitHub上查看，但是这里我只列出了要点。 让我们按顺序开始： <br><br> 我们需要的所有功能的定义都在<code>InferenceEngine</code>名称空间的<code>inference_engine.hpp</code>文件中。 <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;inference_engine.hpp&gt; using namespace InferenceEngine;</span></span></span></span></code> </pre><br> 始终需要以下变量。 我们需要<code>inputName</code>和<code>outputName</code>以便处理神经网络的输入和输出。 一般来说，神经网络可以有很多输入和输出，但是在我们的探测器中，一次只能有一个。 变量<code>net</code>是网络本身， <code>request</code>是指向最后一个推理请求的指针， <code>inputBlob</code>是指向神经网络的输入数据数组的指针。 其余变量说明一切。 <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">string</span></span> inputName; <span class="hljs-built_in"><span class="hljs-built_in">string</span></span> outputName; ExecutableNetwork net; InferRequest::Ptr request; Blob::Ptr inputBlob; <span class="hljs-comment"><span class="hljs-comment">//input shape int netInputWidth; int netInputHeight; int netInputChannels; //output shape int maxNumDetectedFaces; //return code StatusCode ncsCode;</span></span></code> </pre><br> 现在下载必要的插件-我们需要一个负责NCS和NCS2的插件，可以通过名称“ MYRIAD”获得。 让我提醒您，在OpenVINO的上下文中，插件只是一个通过显式请求连接的动态库。  <code>PluginDispatcher</code>函数的参数是要在其中查找插件的目录列表。 如果根据说明设置环境变量，则空行就足够了。 作为参考，这些插件位于<code>[OpenVINO_install_dir]/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64/</code> <br><br><pre> <code class="cpp hljs">InferencePlugin plugin = PluginDispatcher({<span class="hljs-string"><span class="hljs-string">""</span></span>}).getPluginByDevice(<span class="hljs-string"><span class="hljs-string">"MYRIAD"</span></span>);</code> </pre><br> 现在创建一个用于加载神经网络的对象，考虑其描述并设置批处理的大小（同时处理的图像数）。  OpenVINO格式的神经网络由两个文件定义：带有描述结构的.xml和带有权重的.bin。 尽管我们将使用OpenVINO的现成探测器，但稍后我们将创建自己的探测器。 这里<code>std::string filename</code>是不带扩展名的文件的名称。 您还需要记住，NCS仅支持1的批量大小。 <br><br><pre> <code class="cpp hljs">CNNNetReader netReader; netReader.ReadNetwork(filename+<span class="hljs-string"><span class="hljs-string">".xml"</span></span>); netReader.ReadWeights(filename+<span class="hljs-string"><span class="hljs-string">".bin"</span></span>); netReader.getNetwork().setBatchSize(<span class="hljs-number"><span class="hljs-number">1</span></span>);</code> </pre><br> 然后发生以下情况： <br><br><ol><li> 要进入神经网络，请将数据类型设置为unsigned char 8 bit。 这意味着我们可以使用来自相机的格式输入图像，而InferenceEngine将负责转换（NCS以16位浮点格式执行计算）。 据我了解，这将在Raspberry Pi上加快速度-转换是在NCS上完成的，因此通过USB传输数据的延迟较小。 </li><li> 我们获得输入和输出名称，以便以后可以访问它们。 </li><li> 我们得到输出的描述（这是从输出名称到数据块指针的映射）。 我们得到一个指向第一个（单个）输出的数据块的指针。 </li><li> 我们得到它的大小：1 x 1 x最大检测数x检测描述的长度（7）。 关于检测描述的格式-稍后。 </li><li> 将输出格式设置为浮点32位。 同样，从float 16位进行的转换将处理InferenceEngine。 </li></ol><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//we can set input type to unsigned char: conversion will be performed on device netReader.getNetwork().getInputsInfo().begin()-&gt;second-&gt;setPrecision(Precision::U8); //get input and output names and their info structures inputName = netReader.getNetwork().getInputsInfo().begin()-&gt;first; outputName = netReader.getNetwork().getOutputsInfo().begin()-&gt;first; OutputsDataMap outputInfo(netReader.getNetwork().getOutputsInfo()); InputsDataMap inputInfo(netReader.getNetwork().getInputsInfo()); DataPtr &amp;outputData = (outputInfo.begin()-&gt;second); //get output shape: (1 x 1 x maxNumDetectedFaces x faceDescriptionLength(7)) const SizeVector outputDims = outputData-&gt;getTensorDesc().getDims(); maxNumDetectedFaces = outputDims[2]; //set input type to float32: calculations are all in float16, conversion is performed on device outputData-&gt;setPrecision(Precision::FP32);</span></span></code> </pre><br> 现在最重要的一点是：将神经网络加载到插件中（即在NCS中）。 显然，正在编译为所需格式。 如果程序在此功能上崩溃，则神经网络可能不适合该设备。 <br><br><pre> <code class="cpp hljs">net = plugin.LoadNetwork(netReader.getNetwork(), {});</code> </pre><br> 最后-我们将进行试验推断并获得输入大小（也许可以更优雅地完成）。 首先，我们打开一个推理请求，然后从中获得指向输入数据块的链接，并且我们已经从中请求了大小。 <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//perform single inference to get input shape (a hack) request = net.CreateInferRequestPtr(); //open inference request //we need the blob size: (batch(1) x channels(3) x H x W) inputBlob = request-&gt;GetBlob(inputName); SizeVector blobSize = inputBlob-&gt;getTensorDesc().getDims(); netInputWidth = blobSize[3]; netInputHeight = blobSize[2]; netInputChannels = blobSize[1]; request-&gt;Infer(); //close request</span></span></code> </pre><br> 让我们尝试将图片上传到NCS。 同样，我们创建一个推理请求，从中获取指向数据块的指针，然后从那里获取指向数组本身的指针。 接下来，只需复制图像中的数据（此处已将其缩小为所需的大小）。 值得注意的是，在<code>cv::Mat</code>和<code>inputBlob</code>测量结果以不同的顺序存储（在OpenCV中，通道索引的更改速度快于所有索引，在OpenVINO中，通道索引的更改速度慢于所有索引），因此memcpy是必不可少的。 然后我们开始异步推断。 <br><br> 为什么要异步？ 这将优化资源分配。 当NCS考虑神经网络时，您可以处理下一帧-这将导致Raspberry Pi上的明显加速。 <br><br><pre> <code class="cpp hljs">cv::Mat data; ... <span class="hljs-comment"><span class="hljs-comment">//get image somehow //create request, get data blob request = net.CreateInferRequestPtr(); inputBlob = request-&gt;GetBlob(inputName); unsigned char* blobData = inputBlob-&gt;buffer().as&lt;unsigned char*&gt;(); //copy from resized frame to network input int wh = netInputHeight*netInputWidth; for (int c = 0; c &lt; netInputChannels; c++) for (int h = 0; h &lt; wh; h++) blobData[c * wh + h] = data.data[netInputChannels*h + c]; //start asynchronous inference request-&gt;StartAsync();</span></span></code> </pre><br> 如果您对神经网络非常熟悉，那么您可能会想知道我们在什么点上缩放神经网络的输入像素的值（例如，将 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> [0,1] </script>  ） 事实是，在OpenVINO模型中，这种转换已包含在神经网络的描述中，并且当使用检测器时，我们将执行类似的操作。 并且由于到Open的转换和输入缩放都是由OpenVINO执行的，因此我们只需要调整图像大小即可。 <br><br> 现在（完成一些有用的工作之后），我们将完成推理请求。 在执行结果到来之前，程序将被阻止。 我们得到一个指向结果的指针。 <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> * output; ncsCode = request-&gt;Wait(IInferRequest::WaitMode::RESULT_READY); output = request-&gt;GetBlob(outputName)-&gt;buffer().as&lt;<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*&gt;();</code> </pre><br> 现在是时候考虑NCS以哪种格式返回检测器的结果了。 值得注意的是，格式与使用NCSDK时的格式略有不同。 一般而言，检测器输出是四维的，并且具有一个维度（1 x 1 x最大检测次数x 7），我们可以假定这是一个大小数组（ <code>maxNumDetectedFaces</code> x 7）。 <br><br>  <code>maxNumDetectedFaces</code>参数在神经网络的描述中设置，并且很容易更改，例如，在Caffe格式的网络的.prototxt描述中。 之前我们是从代表检测器的对象中获得的。 此参数与包括所有受支持的NCS检测器的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">SSD</a>检测器<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">（单发检测器）</a>类别的详细信息有关。  SSD始终为每个图像考虑相同（且非常大）的边界框，在过滤掉具有低置信度等级的检测并使用非最大抑制去除重叠帧后，它们通常保持100-200最佳。 这正是参数所负责的。 <br><br> 一种检测的描述中的七个值如下： <br><br><ol><li> 在其中检测到对象的批次中的图像编号（在我们的情况下，它应该为零）； </li><li> 对象类（0-背景，从1-其他类开始，仅返回具有正类的检测）； </li><li> 对检测存在的信心（在范围内 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-2"> [0,1] </script>  ）; </li><li> 边界框左上角的标准化x坐标（在范围内 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-3"> [0,1] </script>  ）; </li><li> 类似地-y坐标； </li><li> 标准化边框宽度（在范围内 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-4"> [0,1] </script>  ）; </li><li> 同样-高度 </li></ol><br><div class="spoiler">  <b class="spoiler_title">从检测器输出中提取边界框的代码</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_detection_boxes</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params">* predictions, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> numPred, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> w, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> h, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> thresh, </span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">std</span></span></span></span><span class="hljs-function"><span class="hljs-params">::</span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">vector</span></span></span></span><span class="hljs-function"><span class="hljs-params">&lt;</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params">&gt;&amp; probs, </span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">std</span></span></span></span><span class="hljs-function"><span class="hljs-params">::</span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">vector</span></span></span></span><span class="hljs-function"><span class="hljs-params">&lt;cv::Rect&gt;&amp; boxes)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> score = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> cls = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> id = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-comment"><span class="hljs-comment">//predictions holds numPred*7 values //data format: image_id, detection_class, detection_confidence, //box_normed_x, box_normed_y, box_normed_w, box_normed_h for (int i=0; i&lt;numPred; i++) { score = predictions[i*7+2]; cls = predictions[i*7+1]; id = predictions[i*7 ]; if (id&gt;=0 &amp;&amp; score&gt;thresh &amp;&amp; cls&lt;=1) { probs.push_back(score); boxes.push_back(Rect(predictions[i*7+3]*w, predictions[i*7+4]*h, (predictions[i*7+5]-predictions[i*7+3])*w, (predictions[i*7+6]-predictions[i*7+4])*h)); } } }</span></span></code> </pre><br> 我们从检测器本身学习<code>numPred</code> ，并且<code>w,h</code>用于可视化的图像大小。 <br></div></div><br> 现在讨论实时推理的一般方案。 首先，我们初始化神经网络和摄像头，对原始帧启动<code>cv::Mat</code> ，对减小到所需大小的帧启动<code>cv::Mat</code> 。 我们用零填充我们的框架-这将增加您的信心，即神经网络一经发现就不会发现任何东西。 然后我们开始推理周期： <br><br><ul><li> 我们使用异步请求将当前帧加载到神经网络中-NCS已经开始工作，这时我们就有机会使有用的工作成为主处理器。 </li><li> 我们在前一帧上显示所有先前的检测结果，并绘制一个帧（如果需要）。 </li><li> 我们从相机获得一个新的帧，将其压缩到所需的大小。 对于Raspberry，我建议使用最简单的调整大小算法-在OpenCV中，这是“最近邻居”插值。 这不会影响检测器性能的质量，但是会增加速度。 我还镜像了框架，以便于可视化（可选）。 </li><li> 现在是时候通过完成推理请求来使用NCS获得结果了。 该程序将阻塞，直到收到结果为止。 </li><li> 我们处理新的检测，选择帧。 </li><li> 其余的：计算击键，计数帧等。 </li></ul><br><h3> 如何编译 </h3><br> 在InferenceEngine示例中，我不喜欢笨拙的CMake文件，因此决定将所有内容紧凑地重写到我的Makefile中： <br><br><pre> <code class="bash hljs">g++ $(RPI_ARCH) \ -I/usr/include -I. \ -I$(OPENVINO_PATH)/deployment_tools/inference_engine/include \ -I$(OPENVINO_PATH_RPI)/deployment_tools/inference_engine/include \ -L/usr/lib/x86_64-linux-gnu \ -L/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/lib \ -L$(OPENVINO_PATH)/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64 \ -L$(OPENVINO_PATH_RPI)/deployment_tools/inference_engine/lib/raspbian_9/armv7l \ vino.cpp wrapper/vino_wrapper.cpp \ -o demo -std=c++11 \ `pkg-config opencv --cflags --libs` \ -ldl -linference_engine $(RPI_LIBS)</code> </pre><br> 由于一些技巧，该团队将同时在Ubuntu和Raspbian上工作。 我已经为Raspberry和Ubuntu计算机指定了搜索标头和动态库的路径。 在这些库中，除了OpenCV外，还必须连接<code>libinference_engine</code>和<code>libinference_engine</code>一个用于动态链接其他库的库，这是加载插件所必需的。 同时，不需要指定<code>libmyriadPlugin</code>本身。 除其他外，对于Raspberry，我还连接了<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Raspicam</a>库以使用相机（这是<code>$(RPI_LIBS)</code> ）。 我还必须使用C ++ 11标准。 <br><br> 另外，值得注意的是，在Raspberry上编译时，需要<code>-march=armv7-a</code>标志（这是<code>$(RPI_ARCH)</code> ）。 如果不指定它，则程序将编译，但将因无提示段错误而崩溃。 您还可以使用<code>-O3</code>添加优化，这将提高速度。 <br><br><h3> 什么是探测器 </h3><br>  NCS仅支持盒子中的Caffe SSD检测器，尽管有一些肮脏的技巧，但我设法<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">从Darknet格式</a>运行了<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">YOLO</a> 。  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">单发检测器（SSD）</a>是轻型神经网络中的一种流行架构，借助不同的编码器（或骨干网络），您可以相当灵活地改变速度和质量的比率。 <br><br> 我将尝试使用不同的面部检测器： <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">从此处</a>获取的YOLO首先转换为Caffe格式，然后转换为NCS格式（仅适用于NCSDK）。 图片448 x 448。 </li><li> 我的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Mobilenet</a> + SSD检测器，关于培训的内容，我在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">上一期出版物中</a>曾谈到<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">过</a> 。 我仍然有这个检测器的裁剪版本，它只能看到小脸，同时速度更快一些。 我将在NCSDK和OpenVINO上检查我的探测器的完整版本。 图片300 x 300。 </li><li> 来自OpenVINO的Detector face-detection-adas-0001：MobileNet + SSD。 图片384 x 672。 </li><li>  OpenVINO人脸检测零售-0004检测器：轻巧的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">SqueezeNet</a> + SSD。 图片300 x 300。 </li></ul><br> 对于OpenVINO的探测器，Caffe格式或NCSDK格式都没有标尺，因此我只能在OpenVINO中启动它们。 <br><br><h3> 将您的探测器转换为OpenVINO格式 </h3><br> 我有两个Caffe格式的文件：带有网络描述的.prototxt和带有权重的.caffemodel。 我需要从文件中获取两个文件，格式为OpenVINO：.xml和.bin，分别带有说明和权重。 为此，请使用OpenVINO（又称“模型优化器”）中的mo.py脚本： <br><br><pre> <code class="bash hljs">mo.py \ --framework caffe \ --input_proto models/face/ssd-face.prototxt \ --input_model models/face/ssd-face.caffemodel \ --output_dir models/face \ --model_name ssd-vino-custom \ --mean_values [127.5,127.5,127.5] \ --scale_values [127.5,127.5,127.5] \ --data_type FP16</code> </pre><br>  <code>output_dir</code>指定将在其中创建新文件的目录， <code>model_name</code>是没有扩展名的新文件的名称， <code>data_type (FP16/FP32)</code>是神经网络中的平衡类型（NCS仅支持FP16）。  <code>mean_values, scale_values</code>设置在将图像发布到神经网络之前对图像进行预处理的平均值和比例。 具体的转换如下所示： <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#xFF08;</mo></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x50CF;</mo></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x7D20;</mo></mrow><msub><mtext>&amp;#xA0;</mtext><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x503C;</mo></mrow></msub><mo>&amp;#x2212;</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x5747;</mo></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x503C;</mo></mrow><msub><mtext>&amp;#xA0;</mtext><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x503C;</mo></mrow></msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#xFF09;</mo></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>/</mo></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x6BD4;</mo></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x4F8B;</mo></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x5C3A;</mo></mrow><msub><mtext>&amp;#xA0;</mtext><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x503C;</mo></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="27.88ex" height="2.78ex" viewBox="0 -832 12004 1197.1" role="img" focusable="false" style="vertical-align: -0.848ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">（</text><g transform="translate(829,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">像</text></g><g transform="translate(1659,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">素</text></g><g transform="translate(2489,0)"><g transform="translate(250,-170)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(36.68) matrix(1 0 0 -1 0 0)">值</text></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-2212" x="3649" y="0"></use><g transform="translate(4649,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">均</text></g><g transform="translate(5479,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">值</text></g><g transform="translate(6309,0)"><g transform="translate(250,-170)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(36.68) matrix(1 0 0 -1 0 0)">值</text></g></g><g transform="translate(7246,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">）</text></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-2F" x="8076" y="0"></use><g transform="translate(8577,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">比</text></g><g transform="translate(9407,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">例</text></g><g transform="translate(10237,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">尺</text></g><g transform="translate(11067,0)"><g transform="translate(250,-170)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(36.68) matrix(1 0 0 -1 0 0)">值</text></g></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow class="MJX-TeXAtom-ORD"><mo>（</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mo>像</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mo>素</mo></mrow><msub><mtext>&nbsp;</mtext><mrow class="MJX-TeXAtom-ORD"><mo>值</mo></mrow></msub><mo>−</mo><mrow class="MJX-TeXAtom-ORD"><mo>均</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mo>值</mo></mrow><msub><mtext>&nbsp;</mtext><mrow class="MJX-TeXAtom-ORD"><mo>值</mo></mrow></msub><mrow class="MJX-TeXAtom-ORD"><mo>）</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mo>比</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mo>例</mo></mrow><mrow class="MJX-TeXAtom-ORD"><mo>尺</mo></mrow><msub><mtext>&nbsp;</mtext><mrow class="MJX-TeXAtom-ORD"><mo>值</mo></mrow></msub></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-5">（像素\ _值-均值\ _值）/比例尺\ _值</script></p><br><br> 在这种情况下，值将从范围转换 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0.255</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.59ex" height="2.66ex" viewBox="0 -832 2837.5 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-5B" x="0" y="0"></use><g transform="translate(278,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-30"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-2E" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-32" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-35" x="1279" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-35" x="1780" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-5D" x="2559" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0.255</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-6"> [0.255] </script> 在范围内 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhiKelC_ZuKOAp7Xgq06d-y-tXGjZg#MJMAIN-5D" x="1724" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-7"> [0,1] </script>  。 通常，此脚本具有很多参数，其中某些参数特定于各个框架，建议您阅读该脚本的手册。 <br><br>  Raspberry的OpenVINO发行版没有现成的模型，但是下载起来非常简单。 <br><br><div class="spoiler">  <b class="spoiler_title">例如，像这样。</b> <div class="spoiler_text"><pre> <code class="bash hljs"> wget --no-check-certificate \ https://download.01.org/openvinotoolkit/2018_R4/open_model_zoo/face-detection-retail-0004/FP16/face-detection-retail-0004.xml \ -O ./models/face/vino.xml; \ wget --no-check-certificate \ https://download.01.org/openvinotoolkit/2018_R4/open_model_zoo/face-detection-retail-0004/FP16/face-detection-retail-0004.bin \ -O ./models/face/vino.bin</code> </pre><br></div></div><br><h3> 检测器和框架的比较 </h3><br> 我使用了三个比较选项：1）具有Ubuntu 16.04，Core i7处理器，USB 3.0连接器的NCS +虚拟机；  2）NCS +同一台机器，USB 3.0连接器+ USB 2.0电缆（与设备交换时会有更多延迟）；  3）NCS + Raspberry Pi 2 B型，Raspbian Stretch，USB 2.0连接器+ USB 2.0电缆。 <br><br> 我使用OpenVINO和NCSDK2来启动我的检测器，OpenVINO的检测器仅使用其本机框架，YOLO仅使用NCSDK2（很可能也可以在OpenVINO上运行）。 <br><br> 不同探测器的FPS表如下所示（数字为近似值）： <br><br><table><tbody><tr><th> 型号 </th><th>  USB 3.0 </th><th>  USB 2.0 </th><th> 树莓派 </th></tr><tr><td> 带有NCSDK2的定制SSD </td><td>  10.8 </td><td>  9.3 </td><td>  7.2 </td></tr><tr><td> 带有NCSDK2的自定义远程SSD </td><td>  11.8 </td><td>  10.0 </td><td>  7.3 </td></tr><tr><td> 带有NCSDK2的YOLO v2 </td><td>  5.3 </td><td>  4.6 </td><td>  3.6 </td></tr><tr><td> 具有OpenVINO的定制SSD </td><td>  10.6 </td><td>  9.9 </td><td>  7.9 </td></tr><tr><td>  OpenVINO人脸检测零售0004 </td><td>  15.6 </td><td>  14.2 </td><td>  9.3 </td></tr><tr><td>  OpenVINO人脸检测adas-0001 </td><td>  5.8 </td><td>  5.5 </td><td>  3.9 </td></tr></tbody></table><br><br>  <em>注意：性能是针对整个演示程序进行测量的，包括框架的处理和可视化。</em> <br><br>  YOLO是最慢，最不稳定的。 它通常会跳过检测，因此无法与照明的框架一起使用。 <br><br> 我训练过的探测器的工作速度是它的两倍，对帧失真的抵抗力更强，甚至可以探测到小的脸。 但是，它有时仍会跳过检测，有时会检测到错误的检测。 如果从中切下最后几层，它会变得更快一些，但将不再看到大的面孔。 使用USB 2.0时，通过OpenVINO启动的同一检测器会变得更快一些，质量在视觉上不会改变。 <br><br> 当然，OpenVINO探测器远胜于YOLO和我的探测器。  （如果OpenVINO当时以当前形式存在，我什至不会开始训练我的探测器）。 零售-0004模型明显更快，同时几乎不会错过任何人，但是我设法使它傻了一点（尽管对这些检测的信心很低）： <br><br><img src="https://habrastorage.org/webt/uj/ap/nl/ujapnlbjzkipljlzklgyvjzked4.png"><br>  <em>自然情报对人造物的竞争性攻击</em> <br><br>  adas-0001检测器速度较慢，但​​适用于大图像，应更准确。 我没有注意到差异，但是我检查了相当简单的框架。 <br><br><h4> 结论 </h4><br> 通常，在像Raspberry Pi这样的低功耗设备上，您可以使用神经网络，甚至几乎是实时的，这一点非常好。  OpenVINO在许多不同的设备上为神经网络的推理提供了非常广泛的功能-比我在本文中描述的范围要广得多。<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 我认为神经计算棒和OpenVINO在我的机器人研究中将非常有用。 </font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN436744/">https://habr.com/ru/post/zh-CN436744/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN436724/index.html">创造养成习惯的产品</a></li>
<li><a href="../zh-CN436726/index.html">用户报告称，由于聪明地窃取了Electrum钱包，导致比特币损失</a></li>
<li><a href="../zh-CN436738/index.html">再次预测，第2部分</a></li>
<li><a href="../zh-CN436740/index.html">自己的研究，开源能告诉我们什么？</a></li>
<li><a href="../zh-CN436742/index.html">直到2019年的Android机器人技术：真实的故事； 分5部分； 第一部分</a></li>
<li><a href="../zh-CN436746/index.html">如何通过改善性能来降低性能</a></li>
<li><a href="../zh-CN436748/index.html">从零开始开发六脚架（第3部分）-运动学</a></li>
<li><a href="../zh-CN436750/index.html">2018年俄罗斯YouTube趋势分析</a></li>
<li><a href="../zh-CN436752/index.html">蛋糕是骗人的</a></li>
<li><a href="../zh-CN436754/index.html">Q2VKPT：完全重写的Quake II，具有逼真的照明</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
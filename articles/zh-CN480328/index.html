<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤽 🎙️ ☔️ 如何交朋友PyTorch和C ++。 使用TorchScript 👩🏻‍🤝‍👨🏿 👩🏻‍🚀 💤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="大约一年前，PyTorch开发人员引入了TorchScript社区，该工具可让您通过几次可嵌入C ++系统的鼠标单击来从python的管道中创建可转让的解决方案。 下面，我分享使用它的经验，并尝试描述这条道路上遇到的陷阱。 我将特别注意Windows上该项目的实施，因为尽管ML的研究通常是在Ubun...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>如何交朋友PyTorch和C ++。 使用TorchScript</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/480328/"><p>大约一年前，PyTorch开发人员引入了<strong>TorchScript</strong>社区，该工具可让您通过几次可嵌入C ++系统的鼠标单击来从python的管道中创建可转让的解决方案。 下面，我分享使用它的经验，并尝试描述这条道路上遇到的陷阱。 我将特别注意Windows上该项目的实施，因为尽管ML的研究通常是在Ubuntu上完成的，但是最终的解决方案通常（突然！）在“ Windows”下是必需的。 </p><br><p> 可以<a href="https://github.com/IlyaOvodov/TorchScriptTutorial">在GitHub上</a>的<a href="https://github.com/IlyaOvodov/TorchScriptTutorial">存储库中</a>找到用于导出模型和使用该模型的C ++项目的示例代码。 </p><br><p> <a href="https://habr.com/ru/company/ods/blog/480328/"><img src="https://habrastorage.org/webt/3k/u1/ub/3ku1ubmzigl3j016ezncczdonqm.jpeg"></a> </p><a name="habracut"></a><br><a name="continue"></a><br><p>  PyTorch开发人员并未上当。 借助新工具，您可以在几个工作日内以更快的速度将PyTorch中的研究项目转换为嵌入C ++系统中的代码。 </p><br><p>  TorchScript出现在PyTorch 1.0版中，并且继续发展和变化。 如果一年前的第一个版本充满了漏洞并且更具实验性，那么至少在第二点上的当前版本1.3会明显不同：您不能再将其称为实验性的，它非常适合实际使用。 我会专注于她。 </p><br><p>  TorchScript的核心是其自己的类似Python的语言的独立（无Python）编译器，以及将以Python和PyTorch编写的程序转换为Python的工具，用于保存和加载生成的模块的方法以及用于在C ++中使用它们的库。 要工作，您必须向项目中添加几个DLL，总重约为70MB（对于Windows）才能在CPU上工作，而对于GPU版本则需要300MB。  TorchScript支持PyTorch的大多数功能以及python语言的主要功能。 但是第三方库，例如OpenCV或NumPy，将不得不被遗忘。 幸运的是，NumPy的许多功能在PyTorch中都有一个类似物。 </p><br><h2 id="konvertiruem-payplayn-na-pytorch-model-na-torchscript"> 在TorchScript上将管道转换为PyTorch模型 </h2><br><p>  TorchScript提供了两种将Python代码转换为其内部格式的方法：跟踪和脚本编制（跟踪和脚本编制）。 为什么两个？ 不，很明显，当然，两个比一个要好... </p><br><p><img src="https://habrastorage.org/webt/lh/xp/ww/lhxpwwynynljq2_sxj35jhpp9yc.jpeg"></p><br><p> 但是，就这些方法而言，与众所周知的格言一样，结果是左右偏差：两者都更糟。 好吧，世界并不完美。 仅在特定情况下，您需要选择更合适的一种。 </p><br><p> 跟踪方法非常简单。 采集数据样本（通常由随机数初始化），然后将其发送给我们感兴趣的类的函数或方法，然后PyTorch以与训练神经网络通常相同的方式构造和存储计算图。 瞧-脚本已经准备好： </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torchvision model = torchvision.models.resnet34(pretrained = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) model.eval() sample = torch.rand(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>) scripted_model = torch.jit.trace(model, sample)</code> </pre> <br><p> 上面的示例生成ScriptModule类的对象。 可以保存 </p><br><pre> <code class="python hljs">scripted_model.save(<span class="hljs-string"><span class="hljs-string">'my_script.pth'</span></span>)</code> </pre> <br><p> 然后将其加载<a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">到C ++程序</a> （在<a href="https://habr.com/ru/company/ods/blog/480328/">下面进行</a>更多介绍）或Python代码而不是原始对象中： </p><br><div class="spoiler">  <b class="spoiler_title">使用已保存的模型的示例Python代码</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.transforms <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Compose, ToTensor, Normalize transforms = Compose([ToTensor(), Normalize(mean=[<span class="hljs-number"><span class="hljs-number">0.485</span></span>, <span class="hljs-number"><span class="hljs-number">0.456</span></span>, <span class="hljs-number"><span class="hljs-number">0.406</span></span>], std=[<span class="hljs-number"><span class="hljs-number">0.229</span></span>, <span class="hljs-number"><span class="hljs-number">0.224</span></span>, <span class="hljs-number"><span class="hljs-number">0.225</span></span>])]) img = cv2.resize(cv2.imread(<span class="hljs-string"><span class="hljs-string">'pics/cat.jpg'</span></span>), (<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>)) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) x = transforms(img).unsqueeze(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-comment"><span class="hljs-comment"># add batch dimension scripted_model = torch.jit.load('my_script.pth') y = scripted_model(x) print(y[0].argmax(), y[0][y[0].argmax()])</span></span></code> </pre> <br><pre> <code class="plaintext hljs">tensor(282) tensor(12.8130, grad_fn=&lt;SelectBackward&gt;)</code> </pre> </div></div><br><p> 生成的<code>ScriptModule</code>可以出现在<code>nn.Module</code>常用的任何位置。 </p><br><p> 以描述的方式，您可以跟踪<code>nn.Module</code>类和函数的实例（在后一种情况下，将<code>torch._C.Function</code>类的实例）。 </p><br><p> 这种方法（跟踪）具有一个重要的优点：这样，您几乎可以转换任何不使用外部库的Python代码。 但是有一个同样重要的缺点：对于任何分支，仅会记住在测试数据上执行的那个分支： </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_abs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt;= <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> -x my_abs_traced = torch.jit.trace(my_abs, torch.tensor(<span class="hljs-number"><span class="hljs-number">0</span></span>)) print(my_abs_traced(torch.tensor(<span class="hljs-number"><span class="hljs-number">1</span></span>)), my_abs_traced(torch.tensor(<span class="hljs-number"><span class="hljs-number">-1</span></span>)))</code> </pre> <br><pre> <code class="plaintext hljs">c:\miniconda3\lib\site-packages\ipykernel_launcher.py:2: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs! tensor(1) tensor(-1)</code> </pre> <br><p> 糟糕！ 这似乎不是我们想要的，对吗？ 最好至少发出一条警告消息（TracerWarning）。 值得关注此类消息。 </p><br><p> 这是我们的第二种方法-脚本： </p><br><pre> <code class="python hljs">my_abs_script = torch.jit.script(my_abs) print(my_abs_script(torch.tensor(<span class="hljs-number"><span class="hljs-number">1</span></span>)), my_abs_script(torch.tensor(<span class="hljs-number"><span class="hljs-number">-1</span></span>)))</code> </pre> <br><pre> <code class="plaintext hljs">tensor(1) tensor(1)</code> </pre> <br><p> 万岁，收到了预期的结果！ 脚本递归分析Python代码，并将其转换为自己语言的代码。 在输出中，我们还获得<code>ScriptModule</code>类（对于模块）或<code>torch._C.Function</code> （对于函数）。 似乎就是幸福！ 但是出现了另一个问题：与Python不同，TorchScript的内部语言是强类型的。 每个变量的类型由第一个赋值确定，默认情况下，函数参数的类型为<code>Tensor</code> 。 因此，例如，一个熟悉的模式 </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> y = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: y = x <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y my_func = torch.jit.script(my_func)</code> </pre> <br><p> 跟踪将失败。 </p><br><div class="spoiler">  <b class="spoiler_title">跟踪错误看起来像这样</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">RuntimeError Traceback (most recent call last) &lt;ipython-input-9-25414183a687&gt; in &lt;module&gt;() ----&gt; 1 my_func = torch.jit.script(my_func) d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in script(obj, optimize, _frames_up, _rcb) 1224 if _rcb is None: 1225 _rcb = _gen_rcb(obj, _frames_up) -&gt; 1226 fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj)) 1227 # Forward docstrings 1228 fn.__doc__ = obj.__doc__ RuntimeError: Variable 'y' previously has type None but is now being assigned to a value of type Tensor : at &lt;ipython-input-8-75677614fca6&gt;:4:8 def my_func(x): y = None if x.max() &gt; 0: y = x ~ &lt;--- HERE return y</code> </pre> </div></div><br><p> 值得注意的是，尽管在<code>torch.jit.script</code>时发生错误，但在脚本代码中也指出了导致该错误的位置。 </p><br><p> 常数后的偶数点开始起作用： </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: y = <span class="hljs-number"><span class="hljs-number">1.25</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: y = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y my_func = torch.jit.script(my_func)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">会给出一个错误</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">RuntimeError Traceback (most recent call last) &lt;ipython-input-10-0a5f18586763&gt; in &lt;module&gt;() 5 y = 0 6 return y ----&gt; 7 my_func = torch.jit.script(my_func) d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in script(obj, optimize, _frames_up, _rcb) 1224 if _rcb is None: 1225 _rcb = _gen_rcb(obj, _frames_up) -&gt; 1226 fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj)) 1227 # Forward docstrings 1228 fn.__doc__ = obj.__doc__ d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in _rcb(name) 1240 # closure rcb fails 1241 result = closure_rcb(name) -&gt; 1242 if result: 1243 return result 1244 return stack_rcb(name) RuntimeError: bool value of Tensor with more than one value is ambiguous</code> </pre> </div></div><br><p> 因为必须写的不是<code>0</code> ，而是<code>0.</code>所以两个分支的类型是相同的！ 您知道，使用python宠坏了！ </p><br><p> 这只是您需要对python代码进行更改的列表的开头，以便可以将其成功转换为TorchScript模块。 稍后，我将更详细地列出最典型的情况。 原则上，这里没有火箭科学，您的代码可以相应地更正。 但是大多数情况下，我不想修复第三方模块，包括<code>torchvision</code>标准模块，并且通常它们通常不适合编写脚本。 </p><br><p> 幸运的是，两种技术可以结合使用：正在编写脚本的正在编写脚本，正在未编写脚本的正在跟踪： </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> super(MyModule, self).__init__() self.resnet = torchvision.models.resnet34(pretrained = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment">#       torch.jit.script(my_module) #    -   resnet34. #     self.resnet  ScriptModule. self.resnet.eval() # NB:     !  -  ! self.resnet = torch.jit.trace(self.resnet, torch.rand((1,3,224,224), dtype=torch.float)) def forward(self, x): if x.shape[2] &lt; 224 or x.shape[3] &lt; 224: return torch.tensor(0) else: return self.resnet(x) my_module = MyModule() my_module = torch.jit.script(my_module)</span></span></code> </pre> <br><p> 在上面的示例中，跟踪用于包含一个模块，该模块在没有足够跟踪且需要脚本的模块中无法编写脚本。 情况相反。 例如，如果我们需要将模型上传到ONNX，则使用跟踪。 但是跟踪模型可能包含TorchScript函数，因此可以在其中实现需要分支和循环的逻辑！ 在<a href="https://pytorch.org/docs/stable/onnx.html">torch.onnx</a>的<a href="https://pytorch.org/docs/stable/onnx.html">官方文档中</a>给出了一个示例。 </p><br><p>  <a href="https://pytorch.org/docs/stable/jit.html">官方文档</a>和<code>torch.jit</code>中更详细地介绍了PyTorch提供的用于创建TorchScript模块的功能。 特别是，我没有提到以调试器形式使用<code>torch.jit.trace</code>和<code>torch.jit.script</code>的便捷方法，这涉及到调试脚本代码的特殊性。 这以及更多内容在文档中。 </p><br><h2 id="anchorcppanchorvklyuchaem-model-v-proekt-na-c"><a name="cpp"></a> 我们将模型包含在C ++项目中 </h2><br><p> 不幸的是， <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">官方文档</a>仅限于“添加使用<code>torch.ones</code>生成的2张量”形式的示例。 我准备了<a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">一个更接近现实的项目</a>示例， <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">该项目</a>将图像从OpenCV发送到神经网络，并以响应张量，变量元组和带有分割结果的图像的形式接收结果。 </p><br><p> 为了使该示例生效，您需要使用ResNet34保存分类脚本，并使用DeepLabV3进行分段。 要准备这些脚本，您需要运行<a href="https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/prepare_scripts.ipynb">此jupyter notepad</a> 。 </p><br><p> 我们需要<code>torchlib</code>库。 您可以通过几种方式获得它： </p><br><ol><li> 如果您已经使用<code>pip install</code> PyTorch，则可以在Python目录中找到它： <code>&lt;Miniconda3&gt;\Lib\site-packages\torch</code> </li><li> 如果您有从源代码编译的PyTorch，则它位于： <code>&lt;My Pytorch repo&gt;\build\lib.win-amd64-3.6\torch</code> ; </li><li> 最后，您可以通过选择Language = C ++从<a href="https://pytorch.org/">pytorch.org</a>单独下载该<a href="https://pytorch.org/">库</a> ，并解压缩存档。 </li></ol><br><p>  C ++代码非常简单。 有必要： </p><br><ol><li> 包含头文件 <br><pre> <code class="plaintext hljs">#include &lt;torch/script.h&gt;</code> </pre> </li><li> 下载型号 <br><pre> <code class="plaintext hljs">torch::jit::script::Module module = torch::jit::load("../resnet34_infer.pth");</code> </pre> </li><li> 准备数据 <br><pre> <code class="plaintext hljs">torch::Tensor tensor = torch::from_blob(img.data, { img.rows, img.cols, 3 }, torch::kByte);</code> </pre> </li><li> 呼叫<code>forward</code>功能并获得结果 <br><pre> <code class="plaintext hljs">auto output = module.forward( { tensor } )</code> </pre> </li><li> 从结果中获取数据。 如何执行此操作取决于神经网络返回的内容。 顺便说一句，在一般情况下，它也不仅可以接受一张图片，因此最好看一下整个<a href="">示例的源代码</a> ，有不同的选择。 例如，要从float类型的一维张量获取数据： <br><pre> <code class="plaintext hljs">float* data = static_cast&lt;float*&gt;(output.toTensor().data_ptr());</code> </pre> </li><li> 还有另一种微妙之处。 不要忘记在代码中插入<code>with torch.no_grad()</code>的类似物<code>with torch.no_grad()</code>在计算和存储不需要的梯度时浪费资源。 不幸的是，该命令不能包含在脚本中，因此您必须将其添加到C ++代码中： <br><pre> <code class="plaintext hljs">torch::NoGradGuard no_grad;</code> </pre> </li></ol><br><p>  <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">官方指南中</a>介绍了如何使用CMake构建项目。 但是那里没有公开Visual Studio中项目的主题，因此我将对其进行详细描述。 您将必须手动调整项目设置： </p><br><ol><li> 我在Visual Studio 2017上进行了测试。我不能说其他版本。 </li><li> 必须安装v14.11工具集v141（在VS安装程序中选中<code>"VC++ 2017 version 15.4 v14.11 toolset"</code> ）。 </li><li> 该平台必须为<code>x64</code> 。 </li><li> 在<code>General → Platform Toolset</code> <code>v141(Visual Studio 2017)</code> <code>General → Platform Toolset</code>选择<code>v141(Visual Studio 2017)</code> </li><li> 在<code>C/C++ → General → Additional Include Directories</code>添加<code>&lt;libtorch dir&gt;\include</code> </li><li> 在<code>Linker → General → Additional Library Directories</code>添加<code>&lt;libtorch dir&gt;\lib</code> </li><li> 在<code>Linker → Input → Additional Dependencies</code>项中添加<code>torch.lib; c10.lib</code>  <code>torch.lib; c10.lib</code> 。 在Internet上，他们写道可能仍然需要<code>caffe2.lib</code> ，并且对于GPU和<code>&lt;libtorch dir&gt;\lib</code> ，但在当前版本中，添加这两个库对我来说已经足够。 也许这是过时的信息。 </li><li> 他们还写道，您需要设置<code>C/C++ → Language → Conformance Mode</code> = <code>No</code> ，但是我没有看到区别。 </li></ol><br><p> 另外，不应在项目中声明<code>__cplusplus</code>变量。 尝试添加<a href="https://docs.microsoft.com/ru-ru/cpp/build/reference/zc-cplusplus%3Fview%3Dvs-2017"><code>  /Zc:__cplusplus</code></a>将在<code>ivalue.h</code>文件中导致编译错误。 </p><br><p> 在<a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">附件项目中，</a>路径设置（不仅包括TorchLib的路径设置，还包括OpenCV和CUDA的路径设置）都在<a href="https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/cpp_proj/cpp_proj.props">props文件</a>中取出，在进行组装之前，您需要根据本地配置在此处注册它们。 实际上，仅此而已。 </p><br><h2 id="anchortipsanchorchto-eschyo-sleduet-imet-v-vidu"><a name="tips"></a> 还有什么要记住的 </h2><br><p> 如果所描述的过程对您来说似乎太简单了，那么您的直觉并不会欺骗您。 为了将用Python编写的PyTorch模型转换为TorchScript，需要考虑许多细微差别。 我将在下面列出我必须面对的内容。 我已经提到过一些，但是我重复一遍将所有内容收集在一个地方。 </p><br><p><img src="https://habrastorage.org/webt/iv/xy/q-/ivxyq-lqqw8s1aqd_cy4t4uwj5i.jpeg"></p><br><ul><li> 默认情况下，传递给函数的变量类型为Tensor。 如果在某些情况下（非常频繁），这是不可接受的，则必须使用MyPy样式类型注释手动声明类型，如下所示： </li></ul><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calc_letter_statistics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, cls_preds: List[Tensor], cls_thresh: float)</span></span></span><span class="hljs-function">-&gt;Tuple[int, Tuple[Tensor, Tensor, Tensor]]</span></span></code> </pre> <br><p> 左右： </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calc_letter_statistics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, cls_preds, cls_thresh)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># type: (List[Tensor], float)-&gt;Tuple[int, Tuple[Tensor, Tensor, Tensor]]</span></span></code> </pre> <br><ul><li> 变量是强类型的，并且如果未明确指定，则类型由第一个赋值确定。 形式<code>x=[]; for ...: x.append(y)</code>熟悉的构造<code>x=[]; for ...: x.append(y)</code>  <code>x=[]; for ...: x.append(y)</code>必须进行编辑，因为 在分配<code>[]</code>编译器无法确定列表中的类型。 因此，您必须明确指定类型，例如： </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> typing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> List x: List[float] = []</code> </pre> <br><p> 或（另一个“例如”） </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tensor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> typing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dict, Tuple, List x: Dict[int: Tuple[float, List[Tensor], List[List[int]]]] = {}</code> </pre> <br><ul><li> 在上面的示例中，由于这些名称被缝在TorchScript代码中，因此需要导入这些名称。 替代的看似合法的方法 </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> typing x: typing.List[torch.Tensor] = []</code> </pre> <br><p> 会导致<em>输入类型未知的构造函数</em> 。编写脚本时出现<em>列表</em>错误 </p><br><ul><li> 您必须分开的另一个熟悉的设计： </li></ul><br><pre> <code class="python hljs">x = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p> 有两种选择。 或两次分配张量（尺寸不同的事实并不可怕）： </p><br><pre> <code class="python hljs">x = torch.tensor(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p> 并且不要忘记寻找更换后会破裂的东西。 或者尝试诚实地写： </p><br><pre> <code class="python hljs">x: Optional[Tensor] = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p> 但是如果在预期的张量处进一步使用<code>x</code> ，我们很可能会得到一个错误： <em>期望参数'x'的类型为'Tensor'，但找到的类型为'Optional [Tensor]'。</em> </p><br><ul><li><p> 别忘了在第一次分配期间写<code>x=0.</code> 如果变量<code>x</code>必须为<code>float</code>类型，则代替通常的<code>x=0</code>等。 </p><br></li><li><p> 如果在某个地方我们通过<code>x = torch.Tensor(...)</code>使用了张量的老式初始化，则您必须将其<code>x = torch.Tensor(...)</code> ，并用带有小写字母<code>x = torch.tensor(...)</code>的较新版本替换它。 否则，它将在脚本编写过程中飞行： <em>未知的内置操作：aten :: Tensor。</em>  <em>以下是一些建议：aten ::张量</em> 。 看来他们甚至可以解释问题所在，并且很清楚需要做什么。 但是，很显然您是否已经知道正确的答案。 </p><br></li><li><p> 该代码在调用<code>torch.jit.script</code>的模块的上下文中编写脚本。 因此，如果在脚本化类或函数的肠道中某处（例如，使用<code>math.pow</code> ，则必须将<code>import math</code>添加到编译模块中。 而且最好在声明该类的脚本上编写脚本：使用<code>@torch.jit.script</code>装饰器，或在其旁边声明一个使ScriptModule脱离其功能的附加函数。 否则，当我们尝试从其中显然进行了<code>math</code>导入的模块中编译类时，会收到<em>未定义值的数学</em>错误消息。 </p><br></li><li><p> 如果在某处您具有<code>my_tensor[my_tensor &lt; 10] = 0</code>或类似形式的构造，则在编写脚本时会收到一个神秘的错误： </p><br><pre> <code class="plaintext hljs">*aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -&gt; (Tensor(a!)):* *Expected a value of type 'Tensor' for argument 'values' but instead found type 'int'.* *aten::index_put_(Tensor(a!) self, Tensor[] indices, Tensor values, bool accumulate=False) -&gt; (Tensor(a!)):* *Expected a value of type 'List[Tensor]' for argument 'indices' but instead found type 'List[Optional[Tensor]]'.*</code> </pre> <br><p> 您需要用张量替换数字： <code>my_tensor[my_tensor &lt; 10] = torch.tensor(0.).to(my_tensor.device)</code> 。 并且不要忘记a）关于<code>my_tensor</code>类型与创建的张量（在这种情况下为float）的对应关系，以及b）关于<code>.to(my_tensor.device)</code> 。 如果您忘记了第二个，所有内容都将被编写脚本，但是已经在使用GPU的过程中，您将感到不安，这看起来像是<em>CUDA错误的</em>字眼<em>：遇到了非法的内存访问</em> ，而没有指出发生错误的地方！ </p><br></li><li><p> 不要忘记默认情况下<code>nn.Module</code>以及相应的torchvision模型是在“训练模式”下创建的（您不会相信，但事实证明<a href="https://fooobar.com/questions/16769103/error-when-converting-pytorch-model-to-torchscript/25666033">确实存在这种模式</a> ）。 在这种情况下，将使用Dropout和火车模式下的其他技巧，这些技巧可能会中断跟踪或在执行时导致结果不足。 切记在编写脚本或跟踪之前调用<code>model.eval()</code> 。 </p><br></li><li><p> 对于函数和普通类，您需要为nn.Module-一个实例编写类型脚本 </p><br></li><li><p> 尝试使用脚本方法访问全局变量 </p><br></li></ul><br><pre> <code class="python hljs">cls_thresh = <span class="hljs-number"><span class="hljs-number">0.3</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> ... x = r &lt; cls_thresh ...</code> </pre> <br><p> 将导致形式<em>为'float'的python值</em>形式的脚本错误， <em>不能用作value</em> 。 必须在构造函数中使变量成为属性： </p><br><pre> <code class="python hljs">cls_thresh = <span class="hljs-number"><span class="hljs-number">0.3</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> ... self.cls_thresh = cls_thresh ... x = r &lt; self.cls_thresh ...</code> </pre> <br><ul><li> 如果将class属性用作slice参数，则会产生另一个微妙的问题： </li></ul><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FPN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, block, num_blocks, num_layers =</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> ... self.num_layers = num_layers <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x)</span></span></span><span class="hljs-function">:</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (p3, p4, p5, p6, p7)[:self.num_layers]</code> </pre> <br><p> 导致脚本错误的<em>元组切片索引必须是整数常量</em> 。 有必要指出num_layers属性是恒定的，并且不会改变： </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FPN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> num_layers: torch.jit.Final[int] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, block, num_blocks, num_layers =</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> ...</code> </pre> <br><ul><li> 在某些情况下，张量通常可以正常拟合，您需要显式传递数字： </li></ul><br><pre> <code class="python hljs">xx1 = x1.clamp(min=x1[i])</code> </pre> <br><p> 在脚本中<em><code>Expected a value of type 'Optional[number]' for argument 'min' but instead found type 'Tensor'.</code></em>时，抛出错误<em><code>Expected a value of type 'Optional[number]' for argument 'min' but instead found type 'Tensor'.</code></em>  。 好吧，从错误消息中可以很清楚地知道该怎么做： </p><br><pre> <code class="python hljs">xx1 = x1.clamp(min=x1[i].item())</code> </pre> <br><p> 跟踪时出现上述问题。 由于它们的存在，通常无法在TorchScript中简单地编译现成的解决方案，并且您必须长时间按摩源代码（如果源代码适合于编辑），或者使用跟踪。 但是痕迹有其细微差别： </p><br><ul><li> 表单的构造在跟踪中不起作用 </li></ul><br><pre> <code class="plaintext hljs">tensor_a.to(tensor_b.device)</code> </pre> <br><p> 张量加载到的设备在跟踪时是固定的，在执行期间不会更改。 通过将张量声明为<code>nn.Module</code>类型的<code>nn.Module</code>成员，可以部分克服此问题。 然后，在加载模型时，它将启动到<code>torch.jit.load</code>函数中指定的设备上。 </p><br><h2 id="epilog"> 结语 </h2><br><p> 当然，以上所有都会产生问题。 但是，TorchScript允许您将模型本身以及提供预处理和后处理的Python代码作为一个整体组合并发送到解决方案。 是的，尽管存在上述困难，但准备解决方案进行编译所需的时间却比创建解决方案的成本少得多，但是PyTorch在这里提供了巨大的优势，因此值得一试。 </p><br><p><img src="https://habrastorage.org/webt/v0/3m/qt/v03mqtayxdfh5be4ut3nrr0c86q.jpeg"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN480328/">https://habr.com/ru/post/zh-CN480328/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN480316/index.html">如何将Wi-Fi模块的消耗减少十倍或更多倍</a></li>
<li><a href="../zh-CN480318/index.html">莫斯科＃3开发人员即将到来的免费活动（12月16日至24日）</a></li>
<li><a href="../zh-CN480320/index.html">俄罗斯ONYX十年-此期间技术，读者和市场的变化</a></li>
<li><a href="../zh-CN480324/index.html">CPython中的字符串类型实现</a></li>
<li><a href="../zh-CN480326/index.html">F5 Networks Corporation向其客户发送信函，告知他们有关NGINX的当前情况</a></li>
<li><a href="../zh-CN480330/index.html">理想的员工评估工具</a></li>
<li><a href="../zh-CN480332/index.html">分析莫斯科市杜马市2019区块链投票的数据</a></li>
<li><a href="../zh-CN480334/index.html">QtQML /快速关联面板</a></li>
<li><a href="../zh-CN480338/index.html">3D游戏渲染的工作原理：栅格化和光线跟踪</a></li>
<li><a href="../zh-CN480340/index.html">我反对一个无能的经理，然后他被提拔</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
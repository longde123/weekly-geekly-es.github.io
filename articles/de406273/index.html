<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👎🏿 🙇🏻 🎮 Elon Musk ist gegen autonome tödliche Waffen 🚵🏾 👨🏻 👈</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Der Unternehmer Ilon Musk, der viele bekannte Technologieunternehmen leitet, ist bekannt für seine Sicht auf die Gefahren künstlicher Intelligenz. Nat...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Elon Musk ist gegen autonome tödliche Waffen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/madrobots/blog/406273/"><img src="https://habrastorage.org/getpro/geektimes/post_images/e41/3ed/64f/e413ed64f4eb4be13252fda1bdbc7393.jpg" alt="Bild"><br><br>  Der Unternehmer Ilon Musk, der viele bekannte Technologieunternehmen leitet, ist bekannt für seine Sicht auf die Gefahren künstlicher Intelligenz.  Natürlich ist er nicht nur wegen dieser Meinung berühmt.  Seit 2014 ist er jedoch gegen die Schaffung einer starken Form der KI.  Dann erklärte er zum ersten Mal öffentlich, dass künstliche Intelligenz gefährlich sein könnte.  Stephen Hawking und viele andere Wissenschaftler, Zukunftsforscher und IT-Spezialisten stimmen ihm zu.  Es wird angenommen, dass die gesamte Menschheit der technologischen Singularität zum Opfer fallen könnte. <br><br>  Das Gefährlichste ist laut Mask die Tendenz, eine autonome "intelligente" Waffe zu schaffen.  Laut dem Unternehmer ist das Risiko des Auftretens von „Killerrobotern“ sehr hoch, daher ist es notwendig, dieses Problem mit aller Sorgfalt zu behandeln.  "Die dritte Rüstungsrevolution" ist bereits nahe, Experten sind überzeugt, und autonome "Killerroboter" sind eine Art Büchse der Pandora.  Es bleibt nur sehr wenig Zeit, um das Problem zu lösen. <br><a name="habracut"></a><br>  Vor ungefähr einer Woche unterzeichnete Musk zusammen mit 115 prominenten Experten aus verschiedenen Bereichen der Wissenschaft und Technologie einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offenen Brief</a> , dessen Autoren die Vereinten Nationen auffordern, dieses Problem so schnell wie möglich anzugehen. <br><br>  Der Brief wurde auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener">Internationalen Gemeinsamen Konferenz für Künstliche Intelligenz (IJCAI 2017)</a> in Melbourne unterzeichnet.  Übrigens unter den Unterzeichnern - und dem Gründer von DeepMind Mustafa Suleiman sowie Jerome Monce, dem Leiter von Aldebaran Robotics, der den Pepper-Roboter entwickelt hat.  Wenn die Leiter der Unternehmen an der Spitze des technologischen Fortschritts diesen Brief unterschreiben, ist das Problem wahrscheinlich wirklich eine Überlegung wert. <br><br>  In dem Brief heißt es insbesondere, dass sich KI und Robotik so schnell entwickeln, dass die Möglichkeit eines Krieges mit autonomen Waffen, einschließlich Robotern, wahrscheinlicher wird.  Darüber hinaus ist dies eine Frage der kommenden Jahre und überhaupt nicht der Jahrzehnte, wie zuvor angenommen.  Jetzt muss darüber nachgedacht werden, wie Technologie das Schicksal der Menschheit beeinflussen kann.  Und zuallererst sollten die Staats- und Regierungschefs, in denen sich die Technologie so aktiv wie möglich entwickelt, darüber nachdenken. <br><br>  Hinzu kommt die Gefahr, dass solche Technologien in die Hände von Terroristen und Autokraten fallen, die ohne Reue tödliche Werkzeuge gegen gewöhnliche Menschen senden.  Selbst wenn dies vermieden werden kann, besteht weiterhin die Gefahr von Hacking-Systemen, und es ist völlig ungleich Null.  Hacker haben wiederholt bewiesen, dass fast alles gehackt werden kann, egal wie gut dieses „Alles“ geschützt ist. <br><br>  Es gibt bereits Entwicklungen tödlicher Waffen, die autonom oder halbautonom arbeiten.  Dies ist unter anderem ein solches Gerät. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/cd4/234/3c7/cd42343c7db18851b990f953a73b9aaa.jpg"><br><br>  Das Foto soll nur zeigen, wie Waffen in zukünftigen Kriegen mit Robotern ausgerüstet werden können.  Aber schon jetzt fliegen Drohnen in den Himmel und können im automatischen Modus arbeiten.  Und die Schiffe sind mit automatischen Kanonen ausgestattet, die eine mögliche Bedrohung unabhängig verfolgen. <br><br>  Die Regierungen verschiedener Länder stimmen aus verschiedenen Gründen nicht mit dem Standpunkt von Wissenschaftlern und Technologen überein.  Das Wichtigste - für Staaten autonome Waffen - ist von Vorteil.  Es kann die Wirksamkeit des Grenzschutzes erhöhen oder die Zahl der Todesfälle von Soldaten bei lokalen oder regionalen Konflikten verringern.  2015 lehnte die britische Regierung das Verbot autonomer tödlicher Waffen ab.  Darüber hinaus ist die Entwicklung derartiger Waffen hier sehr aktiv. <br><br>  Der Standpunkt von Wissenschaftlern, die sich gegen autonome „Killerroboter“ aussprechen, wird durch die Aussage des Gründers von Element AI, Joshua Benggio, gut veranschaulicht: „Ich habe einen offenen Brief unterschrieben, da der Einsatz von KI in autonomen Waffensystemen meinem Verständnis von Ethik widerspricht, was zu einer sehr gefährlichen Eskalation führen kann. Auswirkungen auf den gesamten Umfang der KI-Entwicklung.  Die Situation sollte unter die Kontrolle der internationalen Gemeinschaft gestellt werden, genau wie dies bei anderen Waffentypen (biologisch, chemisch, nuklear) der Fall war. “ <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/530/6e8/516/5306e851693ea33b96f7d6f8c6c49f0c.jpg"><br><br>  "Die Schaffung tödlicher autonomer Waffen ermöglicht es uns, Kriege auf ein beispielloses Ausmaß auszudehnen, das selbst schwer vorstellbar ist", heißt es in dem Brief.  Und wahrscheinlich haben die Autoren des Briefes wirklich Recht. <br><br><hr><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/files/d29/4c3/07d/d294c307dde04335ac3f425e73b36a7a.gif"></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/files/7fa/417/fe3/7fa417fe3d464fa5aa186b1ab30da53a.gif"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de406273/">https://habr.com/ru/post/de406273/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de406263/index.html">Kobalt 60 zu Hause und bei der Arbeit</a></li>
<li><a href="../de406265/index.html">Sisyphusarbeit</a></li>
<li><a href="../de406267/index.html">Generative neuronale Fälschungen: Wie maschinelles Lernen die Wahrnehmung der Welt verändert</a></li>
<li><a href="../de406269/index.html">Fliegen Sie in Ur-Suppe</a></li>
<li><a href="../de406271/index.html">Movidius Myriad X - Zentrum für Wahrnehmung und Analyse</a></li>
<li><a href="../de406275/index.html">Alan Turings verlorene Briefe wurden in der Speisekammer der Universität von Manchester gefunden</a></li>
<li><a href="../de406279/index.html">Wie funktioniert das Higgs-Feld: 3) Wie erscheint das Higgs-Teilchen?</a></li>
<li><a href="../de406281/index.html">Black Magic Blue Tablets (wir machen das Programm Black Magic Probe aus dem Modul basierend auf STM32F103)</a></li>
<li><a href="../de406283/index.html">Wie die Träne angeordnet ist und wie sie funktioniert und was passiert, wenn das Auge trocknet</a></li>
<li><a href="../de406285/index.html">Es ist einfach, die Überwachung eines Dieselgenerators zu wählen! .. Oder nicht?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
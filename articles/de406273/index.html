<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘ğŸ¿ ğŸ™‡ğŸ» ğŸ® Elon Musk ist gegen autonome tÃ¶dliche Waffen ğŸšµğŸ¾ ğŸ‘¨ğŸ» ğŸ‘ˆ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Der Unternehmer Ilon Musk, der viele bekannte Technologieunternehmen leitet, ist bekannt fÃ¼r seine Sicht auf die Gefahren kÃ¼nstlicher Intelligenz. Nat...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Elon Musk ist gegen autonome tÃ¶dliche Waffen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/madrobots/blog/406273/"><img src="https://habrastorage.org/getpro/geektimes/post_images/e41/3ed/64f/e413ed64f4eb4be13252fda1bdbc7393.jpg" alt="Bild"><br><br>  Der Unternehmer Ilon Musk, der viele bekannte Technologieunternehmen leitet, ist bekannt fÃ¼r seine Sicht auf die Gefahren kÃ¼nstlicher Intelligenz.  NatÃ¼rlich ist er nicht nur wegen dieser Meinung berÃ¼hmt.  Seit 2014 ist er jedoch gegen die Schaffung einer starken Form der KI.  Dann erklÃ¤rte er zum ersten Mal Ã¶ffentlich, dass kÃ¼nstliche Intelligenz gefÃ¤hrlich sein kÃ¶nnte.  Stephen Hawking und viele andere Wissenschaftler, Zukunftsforscher und IT-Spezialisten stimmen ihm zu.  Es wird angenommen, dass die gesamte Menschheit der technologischen SingularitÃ¤t zum Opfer fallen kÃ¶nnte. <br><br>  Das GefÃ¤hrlichste ist laut Mask die Tendenz, eine autonome "intelligente" Waffe zu schaffen.  Laut dem Unternehmer ist das Risiko des Auftretens von â€Killerroboternâ€œ sehr hoch, daher ist es notwendig, dieses Problem mit aller Sorgfalt zu behandeln.  "Die dritte RÃ¼stungsrevolution" ist bereits nahe, Experten sind Ã¼berzeugt, und autonome "Killerroboter" sind eine Art BÃ¼chse der Pandora.  Es bleibt nur sehr wenig Zeit, um das Problem zu lÃ¶sen. <br><a name="habracut"></a><br>  Vor ungefÃ¤hr einer Woche unterzeichnete Musk zusammen mit 115 prominenten Experten aus verschiedenen Bereichen der Wissenschaft und Technologie einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offenen Brief</a> , dessen Autoren die Vereinten Nationen auffordern, dieses Problem so schnell wie mÃ¶glich anzugehen. <br><br>  Der Brief wurde auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener">Internationalen Gemeinsamen Konferenz fÃ¼r KÃ¼nstliche Intelligenz (IJCAI 2017)</a> in Melbourne unterzeichnet.  Ãœbrigens unter den Unterzeichnern - und dem GrÃ¼nder von DeepMind Mustafa Suleiman sowie Jerome Monce, dem Leiter von Aldebaran Robotics, der den Pepper-Roboter entwickelt hat.  Wenn die Leiter der Unternehmen an der Spitze des technologischen Fortschritts diesen Brief unterschreiben, ist das Problem wahrscheinlich wirklich eine Ãœberlegung wert. <br><br>  In dem Brief heiÃŸt es insbesondere, dass sich KI und Robotik so schnell entwickeln, dass die MÃ¶glichkeit eines Krieges mit autonomen Waffen, einschlieÃŸlich Robotern, wahrscheinlicher wird.  DarÃ¼ber hinaus ist dies eine Frage der kommenden Jahre und Ã¼berhaupt nicht der Jahrzehnte, wie zuvor angenommen.  Jetzt muss darÃ¼ber nachgedacht werden, wie Technologie das Schicksal der Menschheit beeinflussen kann.  Und zuallererst sollten die Staats- und Regierungschefs, in denen sich die Technologie so aktiv wie mÃ¶glich entwickelt, darÃ¼ber nachdenken. <br><br>  Hinzu kommt die Gefahr, dass solche Technologien in die HÃ¤nde von Terroristen und Autokraten fallen, die ohne Reue tÃ¶dliche Werkzeuge gegen gewÃ¶hnliche Menschen senden.  Selbst wenn dies vermieden werden kann, besteht weiterhin die Gefahr von Hacking-Systemen, und es ist vÃ¶llig ungleich Null.  Hacker haben wiederholt bewiesen, dass fast alles gehackt werden kann, egal wie gut dieses â€Allesâ€œ geschÃ¼tzt ist. <br><br>  Es gibt bereits Entwicklungen tÃ¶dlicher Waffen, die autonom oder halbautonom arbeiten.  Dies ist unter anderem ein solches GerÃ¤t. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/cd4/234/3c7/cd42343c7db18851b990f953a73b9aaa.jpg"><br><br>  Das Foto soll nur zeigen, wie Waffen in zukÃ¼nftigen Kriegen mit Robotern ausgerÃ¼stet werden kÃ¶nnen.  Aber schon jetzt fliegen Drohnen in den Himmel und kÃ¶nnen im automatischen Modus arbeiten.  Und die Schiffe sind mit automatischen Kanonen ausgestattet, die eine mÃ¶gliche Bedrohung unabhÃ¤ngig verfolgen. <br><br>  Die Regierungen verschiedener LÃ¤nder stimmen aus verschiedenen GrÃ¼nden nicht mit dem Standpunkt von Wissenschaftlern und Technologen Ã¼berein.  Das Wichtigste - fÃ¼r Staaten autonome Waffen - ist von Vorteil.  Es kann die Wirksamkeit des Grenzschutzes erhÃ¶hen oder die Zahl der TodesfÃ¤lle von Soldaten bei lokalen oder regionalen Konflikten verringern.  2015 lehnte die britische Regierung das Verbot autonomer tÃ¶dlicher Waffen ab.  DarÃ¼ber hinaus ist die Entwicklung derartiger Waffen hier sehr aktiv. <br><br>  Der Standpunkt von Wissenschaftlern, die sich gegen autonome â€Killerroboterâ€œ aussprechen, wird durch die Aussage des GrÃ¼nders von Element AI, Joshua Benggio, gut veranschaulicht: â€Ich habe einen offenen Brief unterschrieben, da der Einsatz von KI in autonomen Waffensystemen meinem VerstÃ¤ndnis von Ethik widerspricht, was zu einer sehr gefÃ¤hrlichen Eskalation fÃ¼hren kann. Auswirkungen auf den gesamten Umfang der KI-Entwicklung.  Die Situation sollte unter die Kontrolle der internationalen Gemeinschaft gestellt werden, genau wie dies bei anderen Waffentypen (biologisch, chemisch, nuklear) der Fall war. â€œ <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/530/6e8/516/5306e851693ea33b96f7d6f8c6c49f0c.jpg"><br><br>  "Die Schaffung tÃ¶dlicher autonomer Waffen ermÃ¶glicht es uns, Kriege auf ein beispielloses AusmaÃŸ auszudehnen, das selbst schwer vorstellbar ist", heiÃŸt es in dem Brief.  Und wahrscheinlich haben die Autoren des Briefes wirklich Recht. <br><br><hr><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/files/d29/4c3/07d/d294c307dde04335ac3f425e73b36a7a.gif"></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/files/7fa/417/fe3/7fa417fe3d464fa5aa186b1ab30da53a.gif"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de406273/">https://habr.com/ru/post/de406273/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de406263/index.html">Kobalt 60 zu Hause und bei der Arbeit</a></li>
<li><a href="../de406265/index.html">Sisyphusarbeit</a></li>
<li><a href="../de406267/index.html">Generative neuronale FÃ¤lschungen: Wie maschinelles Lernen die Wahrnehmung der Welt verÃ¤ndert</a></li>
<li><a href="../de406269/index.html">Fliegen Sie in Ur-Suppe</a></li>
<li><a href="../de406271/index.html">Movidius Myriad X - Zentrum fÃ¼r Wahrnehmung und Analyse</a></li>
<li><a href="../de406275/index.html">Alan Turings verlorene Briefe wurden in der Speisekammer der UniversitÃ¤t von Manchester gefunden</a></li>
<li><a href="../de406279/index.html">Wie funktioniert das Higgs-Feld: 3) Wie erscheint das Higgs-Teilchen?</a></li>
<li><a href="../de406281/index.html">Black Magic Blue Tablets (wir machen das Programm Black Magic Probe aus dem Modul basierend auf STM32F103)</a></li>
<li><a href="../de406283/index.html">Wie die TrÃ¤ne angeordnet ist und wie sie funktioniert und was passiert, wenn das Auge trocknet</a></li>
<li><a href="../de406285/index.html">Es ist einfach, die Ãœberwachung eines Dieselgenerators zu wÃ¤hlen! .. Oder nicht?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
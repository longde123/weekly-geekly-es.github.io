<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💮 🍥 📦 Les réseaux de neurones sans professeur sont traduits de langues pour lesquelles il n'y a pas de corpus parallèle de textes 💚 🐉 🏬</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La traduction automatique à l'aide de réseaux de neurones a parcouru un long chemin depuis le moment de la première recherche scientifique sur ce suje...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Les réseaux de neurones sans professeur sont traduits de langues pour lesquelles il n'y a pas de corpus parallèle de textes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/408541/"><img src="https://habrastorage.org/webt/0-/tl/ze/0-tlzebusmsbrgkbzz61wrymo9s.png"><br><br>  La traduction automatique à l'aide de réseaux de neurones a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">parcouru un long chemin</a> depuis le moment de la première recherche scientifique sur ce sujet jusqu'au moment où Google a annoncé le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">transfert complet du service Google Translate au deep learning</a> . <br><br>  Comme vous le savez, la base du traducteur neuronal est le mécanisme des réseaux neuronaux récurrents bidirectionnels, basé sur des calculs matriciels, qui vous permet de construire des modèles probabilistes beaucoup plus complexes que les traducteurs automatiques statistiques.  Cependant, on a toujours cru que la traduction neuronale, comme la traduction statistique, nécessitait des textes bilingues parallèles pour la formation.  Un réseau de neurones est en cours de formation sur ces bâtiments, prenant une traduction humaine comme référence. <br><br>  Comme il s'est avéré maintenant, les réseaux de neurones sont capables de maîtriser une nouvelle langue pour la traduction même sans corpus parallèle de textes!  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deux</a> ouvrages sur ce sujet ont été publiés sur le site de préimpression arXiv.org. <br><a name="habracut"></a><br>  «Imaginez que vous donnez à une personne beaucoup de livres chinois et beaucoup de livres arabes - il n'y a pas de livres identiques parmi eux - et cette personne apprend à traduire du chinois vers l'arabe.  Cela semble impossible, non?  Mais nous avons montré qu'un ordinateur en est capable », <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">explique</a> Mikel Artetxe, informaticien à l'Université du Pays Basque à Saint-Sébastien (Espagne). <br><br>  La plupart des réseaux de neurones de traduction automatique sont enseignés «avec un professeur», dont le rôle est précisément le corpus parallèle de textes traduits par l'homme.  Dans le processus d'apprentissage, grosso modo, le réseau neuronal fait une hypothèse, vérifie par rapport à la norme, effectue les réglages nécessaires dans ses systèmes, puis apprend davantage.  Le problème est que pour certaines langues dans le monde il n'y a pas un grand nombre de textes parallèles, donc ils ne sont pas disponibles pour les réseaux neuronaux de traduction automatique traditionnels. <br><br>  Deux nouveaux modèles proposent une nouvelle approche: enseigner un réseau de neurones de traduction automatique <b>sans professeur</b> .  Le système lui-même essaie de constituer une sorte de corpus parallèle de textes, regroupant les mots les uns autour des autres.  Le fait est que dans la plupart des langues du monde, il y a les mêmes significations, qui correspondent simplement à des mots différents.  Ainsi, toutes ces significations sont regroupées en grappes identiques, c'est-à-dire que les mêmes significations de mots sont regroupées autour des mêmes significations de mots, presque indépendamment de la langue (voir l'article " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Google Translate Neural Network a compilé une base unifiée de la signification des mots humains</a> ") . <br><br><img src="https://habrastorage.org/files/d13/72d/6f7/d1372d6f7b8c41e2a4988e7f5fcad3ea.png"><br>  <i><font color="gray">Le «langage universel» du réseau neuronal Google Neural Machine Translation (GNMT).</font></i>  <i><font color="gray">Des groupes de significations de chaque mot sont affichés dans différentes couleurs sur l'illustration de gauche, les significations inférieures sont les significations de mots obtenues pour lui à partir de différentes langues humaines: anglais, coréen et japonais</font></i> <br><br>  Après avoir compilé un gigantesque «atlas» pour chaque langue, le système essaie de superposer un tel atlas sur une autre - et voilà, vous êtes prêt à avoir une sorte de corpus de texte parallèle! <br><br>  Vous pouvez comparer les modèles des deux architectures d'apprentissage sans enseignant proposées. <br><br><img src="https://habrastorage.org/webt/uu/jw/u7/uujwu7yophvszhccgutsvr7tdxq.png"><br>  <i><font color="gray">L'architecture du système proposé.</font></i>  <i><font color="gray">Pour chaque phrase du langage L1, le système apprend l'alternance de deux étapes: 1) <b>débruitage</b> , qui optimise la probabilité de coder une version bruyante de la phrase avec un codeur commun et sa reconstruction par le décodeur L1;</font></i>  <i><font color="gray">2) rétrotraduction, lorsqu'une phrase est traduite en mode de sortie (c'est-à-dire codée par un codeur commun et décodée par le décodeur L2), puis la probabilité de coder cette phrase traduite avec un codeur commun et de restaurer la phrase originale par le décodeur L1 est optimisée.</font></i>  <i><font color="gray">Illustration: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article scientifique de</a> Mikel Artetks et al.</font></i> <br><br><img src="https://habrastorage.org/webt/7l/en/y3/7leny37dml5fdxwr9exn3kyu-_s.png"><br>  <i><font color="gray">L'architecture proposée et les objectifs d'apprentissage du système (à partir du deuxième travail scientifique).</font></i>  <i><font color="gray">L'architecture est un modèle de traduction de phrases, où l'encodeur et le décodeur fonctionnent dans deux langues, selon l'identifiant de la langue d'entrée, qui permute les tables de recherche.</font></i>  <i><font color="gray">Ci-dessus (auto-codage): le modèle apprend à effectuer une réduction du bruit dans chaque domaine.</font></i>  <i><font color="gray">Ci-dessous (traduction): comme précédemment, plus nous encodons à partir d'une autre langue, en utilisant comme entrée la traduction produite par le modèle dans l'itération précédente (rectangle bleu).</font></i>  <i><font color="gray">Les ellipses vertes indiquent les termes de la fonction de perte.</font></i>  <i><font color="gray">Illustration: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article scientifique de</a> Guillaume Lampl et al.</font></i> <br><br>  Les deux articles scientifiques utilisent une technique sensiblement similaire avec de légères différences.  Mais dans les deux cas, la traduction s'effectue à travers un «langage» intermédiaire ou, mieux, une dimension ou un espace intermédiaire.  Jusqu'à présent, les réseaux de neurones sans enseignant ne montrent pas une qualité de traduction très élevée, mais les auteurs disent qu'il est facile de s'améliorer si vous utilisez un peu d'aide d'un enseignant, tout à l'heure pour la pureté de l'expérience qu'ils n'ont pas faite. <br><br>  A noter que le deuxième travail scientifique a été publié par des chercheurs de la division Facebook AI. <br><br>  Les travaux sont présentés pour la Conférence internationale sur les représentations d'apprentissage 2018.  Aucun article n'a encore été publié dans la presse scientifique. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr408541/">https://habr.com/ru/post/fr408541/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr408531/index.html">Cela inquiète depuis longtemps: pourquoi le nez coule du froid</a></li>
<li><a href="../fr408533/index.html">Qui, sinon SpaceX? Guide complet des sociétés spatiales privées</a></li>
<li><a href="../fr408535/index.html">Une centaine de crypto-monnaies décrites en quatre mots maximum</a></li>
<li><a href="../fr408537/index.html">Extraterrestres, post-apocalypse, Jésus et les contrebandiers de l'espace: les livres de science-fiction les plus intéressants de 2017</a></li>
<li><a href="../fr408539/index.html">Le premier président d'astronaute au monde</a></li>
<li><a href="../fr408543/index.html">Ils ont essayé de mesurer le niveau de bonheur avec une montre intelligente.</a></li>
<li><a href="../fr408545/index.html">Je ne suis pas un monstre</a></li>
<li><a href="../fr408547/index.html">10 consoles qui n'ont jamais vu le monde</a></li>
<li><a href="../fr408549/index.html">L'IoT en ville: aujourd'hui et demain</a></li>
<li><a href="../fr408551/index.html">Examen du nouveau stylo 3D Tiger3D K-One à petit budget</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
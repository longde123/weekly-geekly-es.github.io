<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüé® üê∏ üë¶üèø Restaurando fotos usando redes neurais üèø üì∑ üë©üèø‚Äçüöí</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√° pessoal, trabalho como programador de pesquisa na equipe de vis√£o computacional do Mail.ru Group. Para o Dia da Vit√≥ria deste ano, decidimos fazer...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Restaurando fotos usando redes neurais</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/453872/"><img src="https://habrastorage.org/getpro/habr/post_images/333/44a/c78/33344ac788b63200841180799417f934.jpg"><br><br>  Ol√° pessoal, trabalho como programador de pesquisa na equipe de vis√£o computacional do Mail.ru Group.  Para o Dia da Vit√≥ria deste ano, decidimos fazer um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">projeto para a restaura√ß√£o de fotografias militares</a> .  O que √© restaura√ß√£o de fotos?  Consiste em tr√™s etapas: <br><br><ul><li>  encontramos todos os defeitos da imagem: rupturas, arranh√µes, buracos; <br></li><li>  pinte os defeitos encontrados com base nos valores de pixel ao seu redor; <br></li><li>  colorir a imagem. <br></li></ul><br>  Neste artigo, analisarei cada um dos est√°gios da restaura√ß√£o em detalhes e mostrarei como e para onde levamos os dados, quais redes aprendemos, o que fizemos e em que etapas pisamos. <br><a name="habracut"></a><br><h1>  Pesquisa de defeitos </h1><br>  Queremos encontrar todos os pixels relacionados a defeitos na foto carregada.  Primeiro, precisamos entender que tipo de fotografias dos anos de guerra as pessoas enviar√£o.  Nos voltamos para os organizadores do projeto Immortal Regiment, que compartilharam dados conosco.  Depois de analis√°-los, percebemos que as pessoas frequentemente enviam retratos, √∫nicos ou em grupo, com um n√∫mero moderado ou grande de defeitos. <br><br>  Ent√£o foi necess√°rio coletar uma amostra de treinamento.  A amostra de treinamento para a tarefa de segmenta√ß√£o √© uma imagem e uma m√°scara na qual todos os defeitos s√£o marcados.  A maneira mais f√°cil √© dar fotos aos marcadores.  Obviamente, as pessoas s√£o boas em encontrar defeitos, mas o problema √© que a marca√ß√£o √© um processo muito longo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d5d/a19/892/d5da1989220f10bcaac3944d27d64276.png"><br><br>  Pode levar de uma hora a um dia √∫til inteiro para marcar os pixels relacionados aos defeitos em uma foto, por isso √© dif√≠cil coletar uma amostra de mais de 100 fotos em poucas semanas.  Portanto, tentamos de alguma forma complementar nossos dados e escrevemos defeitos: tiramos uma foto limpa, aplicamos defeitos artificiais e obtivemos uma m√°scara nos mostrando quais partes espec√≠ficas da imagem estavam danificadas.  A parte principal de nossa amostra de treinamento foi de 79 fotos marcadas manualmente, das quais 11 foram transferidas para a amostra de teste. <br><br>  A abordagem mais popular para o problema de segmenta√ß√£o: leve o Unet com um codificador pr√©-treinado e minimize a quantidade <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi><mi>c</mi><mi>e</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.854ex" height="2.057ex" viewBox="0 -780.1 1659.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-42" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-63" x="759" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-65" x="1193" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi><mi>c</mi><mi>e</mi></math></span></span><script type="math/tex" id="MathJax-Element-1"> Bce </script>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">entropia cruzada bin√°ria</a> ) e <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi><mi>I</mi><mi>C</mi><mi>E</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.638ex" height="2.057ex" viewBox="0 -780.1 2858 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-44" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-49" x="828" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-43" x="1333" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-45" x="2093" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>D</mi><mi>I</mi><mi>C</mi><mi>E</mi></math></span></span><script type="math/tex" id="MathJax-Element-2"> DICE </script>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">S√∏rensen - coeficiente de dados</a> ). <br><br>  Que problemas surgem com essa abordagem no problema de segmenta√ß√£o de defeitos? <br><br><ul><li>  Mesmo que pare√ßa que h√° muitos defeitos na foto, que ela est√° muito suja e muito esfarrapada pelo tempo, a √°rea ocupada por defeitos ainda √© muito menor que a parte n√£o danificada da imagem.  Para resolver esse problema, voc√™ pode aumentar o peso da classe positiva em <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi><mi>c</mi><mi>e</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.854ex" height="2.057ex" viewBox="0 -780.1 1659.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-42" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-63" x="759" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-65" x="1193" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi><mi>c</mi><mi>e</mi></math></span></span><script type="math/tex" id="MathJax-Element-3"> Bce </script>  , e o peso ideal ser√° a propor√ß√£o entre o n√∫mero de todos os pixels puros e o n√∫mero de pixels pertencentes aos defeitos. <br></li><li>  O segundo problema √© que, se usarmos o Unet imediatamente com um codificador pr√©-treinado, por exemplo Albunet-18, perderemos muitas informa√ß√µes posicionais.  A primeira camada de Albunet-18 consiste em uma convolu√ß√£o com um n√∫cleo de 5 e passo igual a dois.  Isso permite que a rede trabalhe rapidamente.  Sacrificamos o tempo de opera√ß√£o da rede para melhor localiza√ß√£o de defeitos: removemos o pool m√°ximo ap√≥s a primeira camada, reduzimos o passo para 1 e reduzimos o n√∫cleo de convolu√ß√£o para 3. <br></li><li>  Se trabalharmos com imagens pequenas, por exemplo, compactando uma imagem para 256 x 256 ou 512 x 512, pequenos defeitos simplesmente desaparecer√£o devido √† interpola√ß√£o.  Portanto, voc√™ precisa trabalhar com uma imagem grande.  Agora, na produ√ß√£o, estamos segmentando defeitos em fotografias de 1024 x 1024. Portanto, era necess√°rio treinar a rede neural em grandes quantidades de imagens grandes.  E por isso, h√° problemas com o tamanho pequeno do lote em uma placa de v√≠deo. <br></li><li>  Durante o treinamento, temos cerca de 20 fotos colocadas em um cart√£o.  Por esse motivo, a estimativa da m√©dia e da varia√ß√£o nas camadas BatchNorm √© imprecisa.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O BatchNorm no local</a> nos ajuda a resolver esse problema, que primeiro economiza mem√≥ria e, em segundo lugar, possui uma vers√£o do BatchNorm Sincronizado, que sincroniza as estat√≠sticas entre todos os cart√µes.  Agora, consideramos a m√©dia e a varia√ß√£o n√£o em 20 fotos em um cart√£o, mas em 80 fotos em 4 cart√µes.  Isso melhora a converg√™ncia de rede. <br></li></ul><br>  No final, aumentando o peso <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>B</mi><mi>c</mi><mi>e</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.854ex" height="2.057ex" viewBox="0 -780.1 1659.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-42" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-63" x="759" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-65" x="1193" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi><mi>c</mi><mi>e</mi></math></span></span><script type="math/tex" id="MathJax-Element-4"> Bce </script>  Alterando a arquitetura e usando o In-place BatchNorm, come√ßamos a procurar defeitos na foto.  Mas, de maneira barata, voc√™ pode se sair ainda melhor adicionando o aumento do tempo de teste.  Podemos executar a rede uma vez na imagem de entrada, espelh√°-la e executar a rede novamente, isso pode nos ajudar a encontrar pequenos defeitos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c75/95b/702/c7595b702dcb921dac612b0218ce13e4.png"><br><br>  Como resultado, nossa rede convergiu em quatro GeForce 1080Ti em 18 horas.  A infer√™ncia leva 290 ms.  Acontece por tempo suficiente, mas √© uma taxa pelo fato de estarmos procurando por pequenos defeitos.  Valida√ß√£o <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi><mi>I</mi><mi>C</mi><mi>E</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.638ex" height="2.057ex" viewBox="0 -780.1 2858 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-44" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-49" x="828" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-43" x="1333" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-45" x="2093" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>D</mi><mi>I</mi><mi>C</mi><mi>E</mi></math></span></span><script type="math/tex" id="MathJax-Element-5"> DICE </script>  igual a 0,35, e <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>R</mi><mi>O</mi><mi>C</mi><mi>A</mi><mi>U</mi><mi>C</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.596ex" height="2.057ex" viewBox="0 -780.1 4562 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-52" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-4F" x="759" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-43" x="1523" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-41" x="2283" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-55" x="3034" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/mailru/blog/453872/&amp;usg=ALkJrhiZ9n-eqNV3K2jf2eeFFTAC-ByBGA#MJMATHI-43" x="3801" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>R</mi><mi>O</mi><mi>C</mi><mi>A</mi><mi>U</mi><mi>C</mi></math></span></span><script type="math/tex" id="MathJax-Element-6"> ROCAUC </script>  - 0,93. <br><br><h1>  Restaura√ß√£o de fragmentos </h1><br>  A Unet nos ajudou a resolver esse problema novamente.  Na entrada, demos a ele a imagem original e uma m√°scara na qual marcamos espa√ßos limpos com unidades e os pixels que queremos pintar com zeros.  Coletamos os dados da seguinte maneira: tiramos da Internet um grande conjunto de dados com imagens, por exemplo, o OpenImagesV4, e adicionamos defeitos artificialmente semelhantes em forma aos encontrados na vida real.  E depois disso, eles treinaram a rede para reparar as pe√ßas ausentes. <br><br>  Como podemos modificar o Unet para esta tarefa? <br><br>  Voc√™ pode usar Convolu√ß√£o Parcial em vez da convolu√ß√£o usual.  A ideia dela √© que, quando reduzimos uma regi√£o de uma imagem com um kernel, n√£o levamos em conta os valores de pixel relacionados aos defeitos.  Isso ajuda a tornar a pintura mais precisa.  Um exemplo de um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo da NVIDIA</a> .  Na imagem central, eles usaram Unet com a convolu√ß√£o usual e, √† direita - com Convolu√ß√£o Parcial: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5a5/280/a4b/5a5280a4be71695d16ab08af876c5d23.png"><br><br>  Treinamos a rede por 5 dias.  No √∫ltimo dia, congelamos o BatchNorm, o que ajudou a tornar menos percept√≠veis as bordas da parte pintada da imagem. <br><br>  A rede processa uma imagem de 512 x 512 em 50 ms.  A valida√ß√£o PSNR √© 26.4.  No entanto, as m√©tricas n√£o podem ser confi√°veis ‚Äã‚Äãincondicionalmente nesta tarefa.  Portanto, primeiro executamos v√°rios bons modelos em nossos dados, anonimizamos os resultados e depois votamos nos que mais gostamos.  Ent√£o escolhemos o modelo final. <br><br>  Mencionei que adicionamos defeitos artificialmente para limpar imagens.  Ao treinar, voc√™ precisa monitorar cuidadosamente o tamanho m√°ximo dos defeitos sobrepostos, porque, com defeitos muito grandes que a rede nunca viu no processo de aprendizado, ela fantasiar√° muito e fornecer√° um resultado absolutamente inaplic√°vel.  Portanto, se voc√™ precisar pintar sobre grandes defeitos, aplique tamb√©m grandes defeitos durante o treinamento. <br><br>  Aqui est√° um exemplo do algoritmo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/abd/6cb/c8c/abd6cbc8c05396042bf83c00516b630e.png"><br><br><h1>  Colora√ß√£o </h1><br>  N√≥s segmentamos os defeitos e os pintamos, o terceiro passo √© a reconstru√ß√£o da cor.  Deixe-me lembr√°-lo de que, entre as fotografias do "Regimento Imortal", existem muitos retratos individuais ou em grupo.  E quer√≠amos que nossa rede funcionasse bem com eles.  Decidimos fazer nossa pr√≥pria colora√ß√£o, porque nenhum dos servi√ßos conhecidos por n√≥s retrata retratos de maneira r√°pida e eficaz. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/015/bce/bf1/015bcebf15ef1ee069fdf08f16e00542.png"><br><br>  O GitHub tem um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">reposit√≥rio</a> popular para colorir fotos.  Em m√©dia, ele faz bem esse trabalho, mas ele tem v√°rios problemas.  Por exemplo, ele gosta de pintar roupas de azul.  Portanto, tamb√©m a rejeitamos. <br><br>  Ent√£o, decidimos fazer uma rede neural para colorir.  A id√©ia mais √≥bvia: tire uma imagem em preto e branco e preveja tr√™s canais, vermelho, verde e azul.  Mas, de um modo geral, podemos simplificar nosso trabalho.  Podemos trabalhar n√£o com a representa√ß√£o RGB da cor, mas com a representa√ß√£o YCbCr.  O componente Y √© o brilho (luma).  A imagem em preto e branco baixada √© o canal Y, vamos reutiliz√°-la.  Restava prever Cb e Cr: Cb √© a diferen√ßa na cor azul e brilho, e Cr √© a diferen√ßa na cor vermelha e brilho. <br><br><img src="https://habrastorage.org/webt/k8/ke/l_/k8kel_xrjco6euolh8ypkchjm8g.jpeg"><br><br>  Por que escolhemos a visualiza√ß√£o YCbCr?  O olho humano √© mais suscet√≠vel a mudan√ßas no brilho do que a mudan√ßas de cor.  Portanto, reutilizamos o componente Y (brilho), algo ao qual o olho √© inicialmente bem receptivo, e prevemos Cb e Cr, nos quais podemos cometer um pouco mais de erro, j√° que as pessoas percebem menos cores "falsas".  Esse recurso come√ßou a ser usado ativamente no in√≠cio da televis√£o em cores, quando a largura de banda do canal n√£o era suficiente para transmitir todas as cores na √≠ntegra.  A imagem foi transferida para YCbCr, transferida para o componente Y inalterada e Cb e Cr foram compactados duas vezes. <br><br><h1>  Como montar a linha de base </h1><br>  Voc√™ pode novamente usar o Unet com um codificador pr√©-treinado e minimizar a perda de L1 entre o CbCr real e o previsto.  Queremos retratos em cores, portanto, al√©m das fotos do OpenImages, precisamos adicionar fotos espec√≠ficas √† nossa tarefa. <br><br>  Onde posso obter fotografias coloridas de pessoas em uniforme militar?  Existem pessoas na Internet que pintam fotografias antigas como hobby ou por encomenda.  Eles fazem isso com muito cuidado, tentando cumprir totalmente todas as nuances.  Pintando o uniforme, dragonas, medalhas, eles recorrem a materiais de arquivo, para que o resultado de seu trabalho seja confi√°vel.  No total, foram utilizadas 200 fotografias pintadas √† m√£o.  A segunda fonte de dados √∫til √© o site do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Ex√©rcito Vermelho</a> dos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Trabalhadores e Camponeses</a> .  Um de seus criadores foi fotografado em quase todas as variantes poss√≠veis de um uniforme militar durante a Grande Guerra Patri√≥tica. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f72/999/7d9/f729997d9fd02755fd95967ff09d27ca.png"><br><br>  Em algumas fotografias, ele repetiu as poses de pessoas de famosas fotografias de arquivo.  √â especialmente bom que ele tenha filmado em um fundo branco. Isso nos permitiu aumentar muito bem os dados, adicionando v√°rios objetos naturais ao fundo.  Tamb√©m usamos retratos modernos comuns de pessoas, complementando-os com ins√≠gnias e outros atributos de roupas de guerra. <br><br>  N√≥s treinamos o AlbuNet-50 - este √© o Unet, no qual o AlbuNet-50 √© usado como um codificador.  A rede come√ßou a dar resultados adequados: a pele √© rosada, os olhos s√£o azul acinzentados, as al√ßas s√£o amareladas.  Mas o problema √© que ela pintou as figuras com manchas.  Isso se deve ao fato de que, do ponto de vista do erro L1, √†s vezes √© mais lucrativo n√£o fazer nada do que tentar prever alguma cor. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/435/4a9/63c/4354a963c4cd2789c434002e44fdda26.png"><br>  <i>Estamos comparando nosso resultado com uma foto de Ground Truth - colora√ß√£o manual do artista sob o apelido <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Klimbim</a></i> <br><br>  Como resolver este problema?  Precisamos de um discriminador: uma rede neural, para a qual forneceremos imagens √† entrada, e dir√° qu√£o realista essa imagem parece.  Abaixo, uma fotografia √© pintada √† m√£o e a segunda por uma rede neural.  Qual voc√™ acha? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/253/86a/abd/25386aabd9080c14daf71b60d9968453.png"><br><br><div class="spoiler">  <b class="spoiler_title">A resposta</b> <div class="spoiler_text">  A foto esquerda √© pintada manualmente. <br></div></div><br>  Como discriminador, usamos o discriminador do artigo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Self-Attention GAN</a> .  Trata-se de uma pequena rede convolucional, nas √∫ltimas camadas, na qual est√° embutida a chamada Auto-Aten√ß√£o.  Ele permite que voc√™ "preste aten√ß√£o" aos detalhes da imagem.  Tamb√©m usamos normaliza√ß√£o espectral.  A explica√ß√£o exata e a motiva√ß√£o podem ser encontradas no artigo.  N√≥s treinamos uma rede com uma combina√ß√£o de perda de L1 e o erro retornado pelo discriminador.  Agora a rede pinta os detalhes da imagem melhor e o fundo √© mais consistente.  Outro exemplo: √† esquerda √© o resultado da rede treinada apenas com perda L1, √† direita - com perda L1 e um erro discriminador. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aa4/724/ada/aa4724ada4e0bbdc52dbcaadd5bb3fdc.png"><br><br>  Em quatro Geforce 1080Ti, o treinamento levou dois dias.  A rede funcionou em 30 ms na imagem 512 x 512. A valida√ß√£o MSE foi 34.4.  Como no problema da pintura, as m√©tricas n√£o podem ser totalmente confi√°veis.  Portanto, selecionamos 6 modelos que tinham as melhores m√©tricas para valida√ß√£o e votamos cegamente no melhor modelo. <br><br>  Depois de lan√ßar o modelo em produ√ß√£o, continuamos os experimentos e chegamos √† conclus√£o de que √© melhor minimizar a perda de L1 por pixel, mas a perda de percep√ß√£o.  Para calcul√°-lo, √© necess√°rio executar a previs√£o de rede e a foto de origem atrav√©s da rede VGG-16, pegar os mapas de atributos nas camadas inferiores e compar√°-los de acordo com o MSE.  Essa abordagem pinta mais √°reas e ajuda a obter uma imagem mais colorida. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/db9/303/509/db93035094c4906cf82c246151432cbc.jpg"><br><br><h1>  Conclus√µes e Conclus√£o </h1><br>  Unet √© um modelo legal.  No primeiro problema de segmenta√ß√£o, encontramos um problema no treinamento e no trabalho com imagens de alta resolu√ß√£o; portanto, usamos o In-Place BatchNorm.  Na segunda tarefa (Pintura), em vez da convolu√ß√£o usual, usamos Convolu√ß√£o Parcial, que ajudou a obter melhores resultados.  No problema de colora√ß√£o da Unet, adicionamos uma pequena rede de discriminadores que multou o gerador por uma imagem com apar√™ncia irreal e usou perda perceptiva. <br><br>  A segunda conclus√£o √© que os acessadores s√£o importantes.  E n√£o apenas na etapa de marcar as figuras antes do treinamento, mas tamb√©m na valida√ß√£o do resultado final, porque em problemas de defeitos ou colora√ß√£o da pintura, voc√™ ainda precisa validar o resultado com a ajuda de uma pessoa.  Damos ao usu√°rio tr√™s fotos: a original com os defeitos removidos, colorida com os defeitos removidos e apenas a foto colorida, caso o algoritmo de pesquisa e pintura de defeitos esteja errado. <br><br>  Tiramos algumas fotos do projeto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">√Ålbum Militar</a> e as processamos com nossas redes neurais.  Aqui est√£o os resultados obtidos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a51/ade/15e/a51ade15e9cee54ec8269dc1e22df0af.jpg"><br><br>  E <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> voc√™ pode v√™-los na resolu√ß√£o original e em cada est√°gio do processamento. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt453872/">https://habr.com/ru/post/pt453872/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt453862/index.html">Por que voc√™ deve usar o pathlib</a></li>
<li><a href="../pt453864/index.html">Usar um mouse e teclado em consoles √© trapa√ßa?</a></li>
<li><a href="../pt453866/index.html">Solicita√ß√£o de API com ganchos de rea√ß√£o, HOC ou prop de renderiza√ß√£o</a></li>
<li><a href="../pt453868/index.html">Mini interruptor sens√≠vel ao toque com painel de vidro no nRF52832</a></li>
<li><a href="../pt453870/index.html">Escrevemos o proxy reverso socks5 no PowerShell.</a></li>
<li><a href="../pt453874/index.html">Da roleta russa ao LOTO seguro: como proteger o pessoal do data center</a></li>
<li><a href="../pt453876/index.html">Como no Yandex.Practicum, o front-end desync venceu: um n√∫mero acrob√°tico com Redux-Saga, postMessage e Jupyter</a></li>
<li><a href="../pt453882/index.html">Um √≥timo guia sobre a profiss√£o de arquiteto de solu√ß√µes (+ lista de links √∫teis)</a></li>
<li><a href="../pt453884/index.html">Substitui√ß√£o da c√¢mera HYIP ou DSLR?</a></li>
<li><a href="../pt453886/index.html">Trabalhos do programa</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∏ üôéüèø üë≤ NVIDIA. Revelando os segredos da arquitetura de GPU de Turing de √∫ltima gera√ß√£o: rastreamento de raio duplo, GDDR6 e muito mais ü§πüèæ ü§±üèø üëèüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Na apresenta√ß√£o do NVIDIA SIGGRAPH 2018, o CEO da empresa, Jensen Juan, revelou oficialmente a t√£o aguardada arquitetura de GPU Turing (e rumores e es...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NVIDIA. Revelando os segredos da arquitetura de GPU de Turing de √∫ltima gera√ß√£o: rastreamento de raio duplo, GDDR6 e muito mais</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/422773/">  Na apresenta√ß√£o do NVIDIA SIGGRAPH 2018, o CEO da empresa, Jensen Juan, revelou oficialmente a t√£o aguardada arquitetura de GPU Turing (e rumores e especula√ß√µes).  A pr√≥xima gera√ß√£o de GPUs NVIDIA, Turing, incluir√° v√°rios novos recursos e visitar√° o mundo ainda este ano.  Embora a visualiza√ß√£o profissional (ProViz) tenha sido o foco dos an√∫ncios de hoje, esperamos que a nova arquitetura seja usada em outros produtos NVIDIA futuros.  A an√°lise de hoje n√£o √© apenas uma lista de todos os recursos de Turing. <br><br><img src="https://habrastorage.org/webt/7c/7l/qd/7c7lqd7hpvnms_v0fcexsts94-m.jpeg"><br><a name="habracut"></a><br><h3>  Renderiza√ß√£o h√≠brida e redes neurais: n√∫cleos RT e tensor </h3><br>  Ent√£o, o que h√° de t√£o especial e novo na arquitetura de Turing?  O letreiro, pelo menos para a comunidade NVIDIA ProViz, foi projetado para renderiza√ß√£o h√≠brida, que combina o tra√ßado de raios com a rasteriza√ß√£o tradicional. <br><br><img src="https://habrastorage.org/webt/zz/lq/is/zzlqisnubeefbyyqueijnvgumaa.jpeg"><br><br>  Mudan√ßa importante: a NVIDIA incluiu ainda mais equipamentos de rastreamento de raios em Turing para oferecer o rastreamento de raios acelerado por hardware mais r√°pido.  A novidade da arquitetura Turing √© a unidade de computa√ß√£o RT Core especializada, como a NVIDIA a chama, atualmente n√£o h√° informa√ß√µes suficientes sobre ela, sabe-se apenas que sua fun√ß√£o √© o suporte ao tra√ßado de raios.  Essas unidades de processador aceleram a verifica√ß√£o da interse√ß√£o de raios e tri√¢ngulos, bem como manipulam BVH (hierarquias de volumes delimitadores). <br><br>  A NVIDIA alega que os componentes Turing mais r√°pidos podem contar com 10 bilh√µes de raios (Giga) por segundo, o que representa uma melhoria de 25 vezes no desempenho do rastreamento de raios em compara√ß√£o com o Pascal n√£o acelerado. <br><br>  A arquitetura de Turing inclui n√∫cleos tensoriais Volta que foram refor√ßados.  N√∫cleos tensores s√£o um aspecto importante de v√°rias iniciativas da NVIDIA.  Juntamente com a acelera√ß√£o do rastreamento de raios, uma ferramenta importante na ‚Äúbolsa m√°gica‚Äù da NVIDIA √© reduzir o n√∫mero de raios necess√°rios na cena usando a redu√ß√£o de ru√≠do de AI para limpar a imagem. Aqui os n√∫cleos dos tensores se saem melhor.  Obviamente, essa n√£o √© a √∫nica √°rea em que s√£o boas - todas as redes neurais e imp√©rios de IA da NVIDIA s√£o constru√≠dos sobre elas. <br><br>  Turing √© caracterizado pelo suporte a uma faixa mais ampla de precis√£o, o que significa a possibilidade de acelera√ß√£o significativa em cargas de trabalho que n√£o possuem requisitos de alta precis√£o.  Al√©m do modo de precis√£o Volta FP16, os n√∫cleos tensores de Turing suportam INT8 e at√© INT4.  Isso √© 2 e 4 vezes mais r√°pido que o FP16, respectivamente.  Embora a NVIDIA n√£o queira entrar em detalhes na apresenta√ß√£o, sugiro que eles implementem algo semelhante ao empacotamento de dados, usado para opera√ß√µes de baixa precis√£o nos n√∫cleos CUDA.  Apesar da precis√£o reduzida da rede neural (o retorno √© reduzido - de acordo com o INT4, obtemos apenas 16 (!) Valores) - existem alguns modelos que realmente precisam desse baixo n√≠vel de precis√£o.  Como resultado, os modos de precis√£o reduzida mostrar√£o uma boa taxa de transfer√™ncia, especialmente nas tarefas de sa√≠da, o que sem d√∫vida agradar√° alguns usu√°rios. <br><br>  Voltando √† renderiza√ß√£o h√≠brida em geral, √© interessante que, apesar dessas grandes acelera√ß√µes individuais, a promessa geral da NVIDIA de ganhos de desempenho pare√ßa um pouco mais modesta.  Embora a empresa prometa aumentar a produtividade em 6 vezes em compara√ß√£o com Pascal, √© hora de perguntar quais pe√ßas s√£o aceleradas e em compara√ß√£o com quais.  O tempo dir√°. <br><br>  Enquanto isso, para fazer melhor uso dos n√∫cleos tensores fora do tra√ßado de raios e das tarefas de aprendizado profundo com foco restrito, a NVIDIA implementar√° um SDK, NVIDIA NGX, que integrar√° redes neurais ao processamento de imagens.  A NVIDIA espera o uso de redes neurais e n√∫cleos tensores para processamento adicional de imagem e v√≠deo, incluindo m√©todos como o pr√≥ximo Deep-Anti-Aliasing (DLAA). <br><br><h3>  Turing SM: n√∫cleos INT dedicados, cache √∫nico, sombreamento de taxa vari√°vel </h3><br>  Juntamente com os kernels RT e tensor, a pr√≥pria arquitetura Turing Streaming Multiprocessor (SM) introduz novos truques.  Em particular, uma das altera√ß√µes mais recentes de Volta foi herdada, como resultado dos n√∫cleos de n√∫mero inteiro alocados em seus pr√≥prios blocos e n√£o fazem parte dos n√∫cleos de ponto flutuante da CUDA.  A vantagem √© a gera√ß√£o mais r√°pida de endere√ßos e o desempenho do Fused Multiply Add (FMA). <br><br>  Quanto √† ALU (ainda estou aguardando a confirma√ß√£o de Turing) - suporte para opera√ß√µes mais r√°pidas com baixa precis√£o (por exemplo, FP16 r√°pido).  Em Volta, isso √© implementado como opera√ß√µes do FP16 em dupla frequ√™ncia em rela√ß√£o ao FP32, e opera√ß√µes INT8 em velocidade 4x.  Os kernels tensores j√° suportam esse conceito; portanto, seria l√≥gico transferi-lo para os kernels CUDA. <br>  O FP16 r√°pido, a tecnologia Rapid Packed Math e outras maneiras de agrupar v√°rias pequenas opera√ß√µes em uma grande opera√ß√£o s√£o todos os principais componentes para melhorar o desempenho da GPU no momento em que a Lei de Moore est√° diminuindo. <br><br>  Usando tipos de dados grandes (exatos) somente quando necess√°rio, eles podem ser empacotados juntos para realizar mais trabalhos no mesmo per√≠odo.  Isso √© importante principalmente para a sa√≠da de redes neurais, bem como para o desenvolvimento de jogos.  O fato √© que nem todos os programas de sombreador precisam da precis√£o do FP32, e a redu√ß√£o da precis√£o pode melhorar o desempenho e reduzir a largura de banda da mem√≥ria √∫til e o uso do arquivo de registro. <br><br>  O Turing SM inclui algo que a NVIDIA chama de ‚Äúarquitetura de cache unificado‚Äù.  Como ainda estou esperando diagramas SMID oficiais da NVIDIA, n√£o est√° claro se essa √© a mesma unifica√ß√£o que vimos em Volta - onde o cache L1 foi combinado com mem√≥ria compartilhada - ou a NVIDIA deu um passo adiante.  De qualquer forma, a NVIDIA alega que agora ofereceu o dobro da largura de banda em rela√ß√£o √† "gera√ß√£o anterior", mas n√£o est√° claro se significa "Pascal" ou "Volta" (a √∫ltima √© mais prov√°vel). <br><br>  Finalmente, profundamente oculto no comunicado √† imprensa de Turing, foi mencionada a possibilidade de suporte a sombreamento de taxa vari√°vel.  Essa √© uma tecnologia de renderiza√ß√£o gr√°fica relativamente nova e em evolu√ß√£o, sobre a qual h√° pouca informa√ß√£o (especialmente sobre como exatamente ela √© implementada pela NVIDIA).  Mas, em um n√≠vel muito alto de abstra√ß√£o, soa como ‚Äúa tecnologia de pr√≥xima gera√ß√£o da NVIDIA que permite aplicar sombreamento com diferentes resolu√ß√µes, o que permite aos desenvolvedores exibir diferentes √°reas da tela em diferentes resolu√ß√µes efetivas para concentrar a qualidade (e o tempo de renderiza√ß√£o) nas √°reas onde √© mais necess√°rio‚Äù . <br><br><h3>  Feed the Beast: Suporte para GDDR6 </h3><br>  Como a mem√≥ria usada pelas GPUs √© desenvolvida por empresas de terceiros, n√£o h√° segredos.  A JEDEC e sua grande Samsung, SK Hynix e Micron, com tr√™s membros, est√£o desenvolvendo a mem√≥ria GDDR6 como sucessora de GDDR5 e GDDR5X.  A NVIDIA confirmou que Turing o apoiar√°.  Dependendo do fabricante, a GDDR6 de primeira gera√ß√£o √© anunciada como tendo uma largura de banda de mem√≥ria de at√© 16 Gb / s por barramento, que √© o dobro das placas NVIDIA GDDR5 de √∫ltima gera√ß√£o e 40% mais r√°pida que as placas NVIDIA GDDR5X mais recentes. <br><br><img src="https://habrastorage.org/webt/ts/ln/ty/tslntydaj3sl-jayd7jr8wbg57w.png"><br><br>  Comparado ao GDDR5X, o GDDR6 n√£o parece um grande avan√ßo, pois muitas das inova√ß√µes do GDDR6 j√° foram aplicadas ao GDDR5X.  As mudan√ßas fundamentais aqui incluem tens√µes operacionais mais baixas (1,35 v) e a mem√≥ria interna agora est√° dividida: dois canais de mem√≥ria por microcircuito.  Para um chip de 32 bits padr√£o - dois canais de mem√≥ria de 16 bits, no total, temos 16 desses canais em um cart√£o de 256 bits.  Embora isso, por sua vez, diga que h√° um n√∫mero muito grande de canais, as GPUs obter√£o o m√°ximo benef√≠cio da inova√ß√£o, porque historicamente s√£o os dispositivos mais "paralelos". <br><br><img src="https://habrastorage.org/webt/u-/45/om/u-45om2tovq4lcaqzdvb3acmpyw.jpeg"><br><br>  A NVIDIA, por sua vez, confirmou que as primeiras placas Turing Quadro usar√£o GDDR6 a 14 Gb / s.  Ao mesmo tempo, a NVIDIA tamb√©m confirmou o uso da mem√≥ria da Samsung, especialmente para seus avan√ßados dispositivos de 16 gigabytes.  Isso √© importante porque significa que uma GPU NVIDIA t√≠pica de 256 bits pode ser equipada com 8 m√≥dulos padr√£o e obter 16 GB de capacidade total de mem√≥ria, ou at√© 32 GB se usar o modo clamshell (permite endere√ßar 32 GB de mem√≥ria em 256 bits padr√£o √¥nibus). <br><br><h3>  Todos os tipos de detalhes: NVLink, VirtualLink e 8K HEVC </h3><br>  J√° terminando com uma revis√£o da arquitetura Turing, a NVIDIA confirmou casualmente o suporte para alguns dos novos recursos externos de E / S.  O suporte ao NVLink estar√° presente em pelo menos v√°rios produtos da Turing.  Lembre-se de que a NVIDIA a utiliza nas tr√™s novas placas Quadro.  A NVIDIA oferece uma configura√ß√£o de GPU bidirecional. <br><br>  Um ponto importante (antes que uma parte do nosso p√∫blico-alvo dos jogos seja aprofundada na leitura): a presen√ßa do NVLink no equipamento de Turing n√£o significa que ele ser√° usado nas placas de v√≠deo do consumidor.  Talvez tudo se limite apenas aos cart√µes Quadro e Tesla. <br><br><img src="https://habrastorage.org/webt/hz/ug/kh/hzugkh-qnznywnylpygk2f7u1eq.png"><br><br>  Com a adi√ß√£o do suporte do VirtualLink, os jogadores e usu√°rios do ProViz ter√£o o que esperar da VR.  Um modo alternativo USB Type-C foi anunciado no m√™s passado e suporta transfer√™ncia de dados de 15 W + pot√™ncia e 10 Gb / s, gra√ßas √†s bandas USB 3.1 Gen 2 e 4 DisplayPort HBR3 em um cabo.  Em outras palavras, esta √© uma conex√£o DisplayPort 1.4 com dados e energia adicionais.  Isso permite que a placa de v√≠deo controle diretamente o fone de ouvido VR.  O padr√£o √© suportado pela NVIDIA, AMD, Oculus, Valve e Microsoft, portanto, os produtos Turing ser√£o os primeiros de um n√∫mero de produtos que suportar√£o o novo padr√£o. <br><br>  Embora a NVIDIA mal tenha abordado o assunto, sabemos que a unidade codificadora de v√≠deo NVENC foi atualizada em Turing.  A mais recente itera√ß√£o NVENC adiciona suporte especial √† codifica√ß√£o HEKC 8K.  Enquanto isso, a NVIDIA conseguiu melhorar a qualidade do seu codificador, permitindo obter a mesma qualidade de antes, com uma taxa de bits de v√≠deo 25% menor. <br><br><h3>  Indicadores de desempenho </h3><br>  Juntamente com as especifica√ß√µes de hardware anunciadas, a NVIDIA mostra v√°rios n√∫meros do desempenho do equipamento Turing.  Note-se que aqui sabemos muito, muito pouco.  Aparentemente, os componentes s√£o baseados nos SKUs de Turing total e parcialmente inclu√≠dos, com 4608 n√∫cleos CUDA e 576 n√∫cleos tensores.  As frequ√™ncias n√£o foram divulgadas, no entanto, como esses n√∫meros s√£o perfilados para o hardware Quadro, √© prov√°vel que vejamos velocidades de clock mais baixas do que em qualquer equipamento de consumo. <br><br><img src="https://habrastorage.org/webt/x9/10/zm/x910zmkfvkgbmxvjizsumjqjefi.jpeg"><br><br><img src="https://habrastorage.org/webt/65/95/4z/65954zsmzwtbffhmn6boyiioazi.png"><br><br>  Juntamente com os 10GigaRays / s acima mencionados para n√∫cleos RT, o desempenho dos n√∫cleos de tensores NVIDIA √© de 500 trilh√µes de opera√ß√µes de tensores por segundo (500T TOPs).  Para refer√™ncia, a NVIDIA frequentemente menciona a GPU GV100 como capaz de fornecer no m√°ximo 120T TOP, mas isso n√£o √© a mesma coisa.  Em particular, enquanto o GV100 √© mencionado no processamento de opera√ß√µes do FP16, o desempenho de Turing √© citado com uma precis√£o extremamente baixa INT4, que √© apenas um quarto do tamanho do FP16 e, portanto, aumenta a taxa de transfer√™ncia quatro vezes.  Se normalizarmos a precis√£o, os n√∫cleos de tensores de Turing parecem n√£o ter a melhor taxa de transfer√™ncia por n√∫cleo, mas oferecem mais op√ß√µes de precis√£o do que Volta.  De qualquer forma, 576 n√∫cleos tensor neste chip o equiparam quase ao mesmo n√≠vel do GV100, que possui 640 n√∫cleos. <br><br>  Em rela√ß√£o aos n√∫cleos CUDA, a NVIDIA alega que a GPU Turing pode oferecer desempenho de 16 TFLOPS.  Isso est√° um pouco √† frente dos 15 TFLOPS de desempenho com a precis√£o √∫nica do Tesla V100, ou ainda mais √† frente dos 13,8 TFLOPS do Titan V. Se voc√™ est√° procurando informa√ß√µes mais amig√°veis ‚Äã‚Äãao consumidor, isso √© cerca de 32% mais que o Titan Xp.  Depois de esbo√ßar alguns c√°lculos aproximados no papel, podemos assumir a velocidade do clock da GPU de cerca de 1730 MHz, j√° que no n√≠vel SM n√£o houve altera√ß√µes adicionais que alterariam as f√≥rmulas tradicionais de desempenho da ALU. <br><br>  Enquanto isso, a NVIDIA anunciou que as placas Quadro vir√£o com mem√≥ria GDDR6 operando a 14 Gb / s.  E observando as duas melhores SKUs Quadro que oferecem 48 GB e 24 GB GDDR6, respectivamente, quase vemos o barramento de mem√≥ria de 384 bits nesta GPU Turing.  Por n√∫meros, isso equivale a 672 GB / s de largura de banda de mem√≥ria para os dois cart√µes Quadro topo de linha. <br><br>  Caso contr√°rio, com uma mudan√ßa na arquitetura, √© dif√≠cil fazer muitas compara√ß√µes √∫teis de desempenho, especialmente ao comparar com o Pascal.  Pelo que vimos com Volta, o desempenho geral da NVIDIA melhorou, especialmente em cargas de trabalho de computa√ß√£o bem projetadas.  Assim, uma melhoria de aproximadamente 33% no desempenho do papel em compara√ß√£o com o Quadro P6000 pode muito bem ser algo muito maior. <br><br>  Vou mencionar o tamanho do cristal da nova GPU.  Localizado em 754 mm2, n√£o √© apenas grande, √© enorme.  Comparado a outras GPUs, apenas o NVIDIA GV100 √© o segundo em tamanho, que atualmente permanece o carro-chefe da NVIDIA.  Mas com 18,6 bilh√µes de transistores, √© f√°cil ver por que o chip resultante deve ser t√£o grande.  Aparentemente, a NVIDIA tem grandes planos para esta GPU, que no final ser√° capaz de justificar a presen√ßa de dois grandes processadores gr√°ficos em sua pilha de produtos. <br><br>  A NVIDIA, por sua vez, n√£o indicou um n√∫mero de modelo espec√≠fico para esta GPU - seja uma GPU tradicional da classe 102 ou mesmo da classe 100.  Gostaria de saber se veremos uma modifica√ß√£o desse tipo de GPU para um produto de consumo de uma forma ou de outra;  √© t√£o grande que a NVIDIA pode querer mant√™-lo por suas GPUs Quadro e Tesla mais lucrativas. <br><br><h3>  Lan√ßado no quarto trimestre de 2018, se n√£o antes </h3><br>  Concluindo, direi que, juntamente com o an√∫ncio da arquitetura Turing, a NVIDIA anunciou que as 4 primeiras placas Quadro baseadas em GPUs Turing - Quadro RTX 8000, RTX 6000 e RTX 5000 come√ßar√£o a ser distribu√≠das no quarto trimestre deste ano.  Como a pr√≥pria natureza deste an√∫ncio √© um pouco invertida - geralmente a NVIDIA anuncia os componentes do consumidor pela primeira vez - eu n√£o aplicaria a mesma linha do tempo aos cart√µes do consumidor que n√£o possuem requisitos de valida√ß√£o t√£o rigorosos.  Veremos o equipamento de Turing no quarto trimestre deste ano, se n√£o antes.  Quem quiser comprar a Quadro pode come√ßar a economizar agora: o melhor dos novos cart√µes Quadro RTX 8000 custar√° cerca de US $ 10.000. <br><br>  Finalmente, para os consumidores com o Tesla da NVIDIA, o lan√ßamento do Turing deixa Volta no limbo.  A NVIDIA n√£o nos disse se Turing acabaria se expandindo para o espa√ßo de ponta de Tesla - substituindo o GV100 - ou se seu melhor processador Volta continuaria sendo o mestre de seu dom√≠nio por s√©culos.  No entanto, como os outros cart√µes da Tesla at√© agora foram baseados em Pascal, eles s√£o os primeiros candidatos a Turing em 2019. <br><br>  Obrigado por ficar conosco.  Voc√™ gosta dos nossos artigos?  Deseja ver materiais mais interessantes?  Ajude-nos fazendo um pedido ou recomendando a seus amigos, um <b>desconto de 30% para os usu√°rios da Habr em um an√°logo exclusivo de servidores b√°sicos que inventamos para voc√™:</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Toda a verdade sobre o VPS (KVM) E5-2650 v4 (6 n√∫cleos) 10GB DDR4 240GB SSD 1Gbps de US $ 20 ou como dividir o servidor?</a>  (as op√ß√µes est√£o dispon√≠veis com RAID1 e RAID10, at√© 24 n√∫cleos e at√© 40GB DDR4). <br><br>  <b>VPS (KVM) E5-2650 v4 (6 n√∫cleos) 10GB DDR4 240GB SSD de 1Gbps at√© dezembro de gra√ßa</b> quando pagar por um per√≠odo de seis meses, voc√™ pode fazer o pedido <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br>  <b>Dell R730xd 2 vezes mais barato?</b>  Somente n√≥s temos <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">2 TVs Intel Dodeca-Core Xeon E5-2650v4 128GB DDR4 6x480GB SSD 1Gbps 100 a partir de US $ 249</a> na Holanda e nos EUA!</b>  Leia sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Como criar um pr√©dio de infraestrutura.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">classe usando servidores Dell R730xd E5-2650 v4 custando 9.000 euros por um centavo?</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt422773/">https://habr.com/ru/post/pt422773/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt422763/index.html">Eventos digitais em Moscou, de 10 a 16 de setembro</a></li>
<li><a href="../pt422765/index.html">OpenID Connect 1.0 nos dedos</a></li>
<li><a href="../pt422767/index.html">Confer√™ncia DEFCON 16. Fedor, InSecure.org Hacker. NMAP Scan Online</a></li>
<li><a href="../pt422769/index.html">Vencedores do Startup Battlefield TechCrunch Disrupt San Francisco 2018</a></li>
<li><a href="../pt422771/index.html">As regras do design, atingindo um novo n√≠vel e design thinking</a></li>
<li><a href="../pt422775/index.html">Confer√™ncia DEFCON 22. Andrew "Zoz" Brooks. N√£o estrague tudo! Parte 1</a></li>
<li><a href="../pt422777/index.html">Uma introdu√ß√£o simples √† ALU para redes neurais: explica√ß√£o, significado f√≠sico e implementa√ß√£o</a></li>
<li><a href="../pt422781/index.html">Resumo da Fintech: SWIFT continuar√° trabalhando na Federa√ß√£o Russa, o VISA permitir√° a transfer√™ncia de fundos por n√∫mero de telefone, biometria cara</a></li>
<li><a href="../pt422783/index.html">Melhor, mais r√°pido, mais poderoso: componentes com estilo v4</a></li>
<li><a href="../pt422785/index.html">Digitaliza√ß√£o de f√°brica: um olhar pela frente</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
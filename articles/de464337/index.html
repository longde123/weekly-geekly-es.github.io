<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëø ‚ôâÔ∏è üçÅ So umgehen Sie Captcha: Neuronales Netzwerk auf Tensorflow, Keras, Python v numerisch verrauschtes Captcha üóûÔ∏è üõÄüèª üíØ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Captcha-Thema ist nicht neu, auch f√ºr Habr. Die Captcha-Algorithmen √§ndern sich jedoch ebenso wie die Algorithmen zu ihrer L√∂sung. Daher wird vorg...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>So umgehen Sie Captcha: Neuronales Netzwerk auf Tensorflow, Keras, Python v numerisch verrauschtes Captcha</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/464337/">  Das Captcha-Thema ist nicht neu, auch f√ºr Habr.  Die Captcha-Algorithmen √§ndern sich jedoch ebenso wie die Algorithmen zu ihrer L√∂sung.  Daher wird vorgeschlagen, sich an die alte zu erinnern und die folgende Version von Captcha zu betreiben: <br><br><img src="https://habrastorage.org/webt/x6/h7/tn/x6h7tnn4a3slc9th4nbup6sumdm.jpeg"><br><br>  Verstehen Sie dabei die Arbeit eines einfachen neuronalen Netzwerks in der Praxis und verbessern Sie auch dessen Ergebnisse. <br><a name="habracut"></a><br>  Machen Sie sofort einen Vorbehalt, dass wir nicht in Gedanken dar√ºber eintauchen, wie das Neuron funktioniert und was damit zu tun ist. Der Artikel behauptet nicht, wissenschaftlich zu sein, sondern bietet nur ein kleines Tutorial. <br><br><h3>  Vom Herd aus tanzen.  Anstatt mitzumachen </h3><br>  Vielleicht werden die Worte von jemandem wiederholt, aber die meisten B√ºcher √ºber Deep Learning beginnen wirklich damit, dass dem Leser vorbereitete Daten angeboten werden, mit denen er zu arbeiten beginnt.  Irgendwie MNIST - 60.000 handschriftliche Ziffern, CIFAR-10 usw.  Nach dem Lesen kommt eine Person vorbereitet heraus ... f√ºr diese Datens√§tze.  Es ist v√∂llig unklar, wie Sie Ihre Daten verwenden und vor allem, wie Sie beim Aufbau Ihres eigenen neuronalen Netzwerks etwas verbessern k√∂nnen. <br><br>  Aus diesem Grund war der Artikel auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">pyimagesearch.com</a> √ºber die Arbeit mit Ihren eigenen Daten sowie deren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√úbersetzung</a> sehr n√ºtzlich. <br><br>  Aber wie sie sagen, ist Rettich-Meerrettich nicht s√º√üer: Selbst mit der √úbersetzung des gekauten Artikels √ºber Keras gibt es viele blinde Flecken.  Auch hier wird ein vorbereiteter Datensatz nur f√ºr Katzen, Hunde und Pandas angeboten.  M√ºssen die L√ºcken selbst ausf√ºllen. <br>  Dieser Artikel und Code werden jedoch als Grundlage verwendet. <br><br><h3>  Wir sammeln Daten √ºber Captcha </h3><br>  Hier gibt es nichts Neues.  Wir brauchen Captcha-Proben, wie  Das Netzwerk wird unter unserer Anleitung von ihnen lernen.  Sie k√∂nnen das Captcha selbst abbauen oder hier ein wenig nehmen - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">29.000 Captchas</a> .  Jetzt m√ºssen Sie die Zahlen aus jedem Captcha herausschneiden.  Es ist nicht notwendig, alle 29.000 Captcha zu schneiden, zumal 1 Captcha 5 Ziffern ergibt.  500 Captcha werden mehr als genug sein. <br><br>  Wie schneide ich?  In Photoshop ist dies m√∂glich, aber es ist besser, ein besseres Messer zu haben. <br><br>  Also hier ist der Python Messer Code - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Download</a> .  (F√ºr Windows. Erstellen Sie zuerst die Ordner C: \ 1 \ test und C: \ 1 \ test-out.) <br>  Die Ausgabe ist ein Dump mit Zahlen von 1 bis 9 (das Captcha enth√§lt keine Nullen). <br>  Als n√§chstes m√ºssen Sie diese Blockierung von den Zahlen in Ordner von 1 bis 9 analysieren und durch die entsprechende Nummer in jeden Ordner einf√ºgen.  So lala Beruf.  Aber an einem Tag k√∂nnen Sie bis zu 1000 Ziffern erkennen. <br><br>  Wenn es bei der Auswahl einer Nummer zweifelhaft ist, welche der Nummern es ist, ist es besser, dieses Beispiel zu l√∂schen.  Und es ist in Ordnung, wenn die Zahlen verrauscht sind oder unvollst√§ndig in den "Frame" eingegeben werden: <br><br><img src="https://habrastorage.org/webt/bi/qi/um/biqiumw_hjgkfbgzt4abq4pqiby.jpeg"><br><br><img src="https://habrastorage.org/webt/ec/xc/pu/ecxcpugnhuys1puccmahjitsfwe.jpeg"><br><br><img src="https://habrastorage.org/webt/3o/fe/wl/3ofewllm6jxduh7rsj3ginfbrrm.jpeg"><br><br>  Sie m√ºssen 200 Proben jeder Ziffer in jedem Ordner sammeln.  Sie k√∂nnen diese Arbeit an Dienste von Drittanbietern delegieren. Es ist jedoch besser, alles selbst zu erledigen, damit Sie sp√§ter nicht nach falsch √ºbereinstimmenden Nummern suchen. <br><br><h3>  Neuronales Netz.  Test </h3><br>  <i>Tyat, tyat, unsere Netze zogen den Toten</i> <br><br>  Bevor Sie mit Ihren eigenen Daten arbeiten, lesen Sie den obigen Artikel und f√ºhren Sie den Code aus, um zu verstehen, dass alle Komponenten (Keras, Tensorflow usw.) installiert sind und ordnungsgem√§√ü funktionieren. <br><br>  Wir werden ein einfaches Netzwerk verwenden, dessen Startsyntax aus der Befehlszeile (!) Stammt: <br><br><pre><code class="bash hljs">python train_simple_nn.py --dataset animals --model output/simple_nn.model --label-bin output/simple_nn_lb.pickle --plot output/simple_nn_plot.png</code> </pre> <br>  * Tensorflow kann schreiben, wenn Fehler in eigenen Dateien und veraltete Methoden bearbeitet werden. Sie k√∂nnen sie von Hand beheben oder einfach ignorieren. <br><br>  Die Hauptsache ist, dass nach dem Ausarbeiten des Programms zwei Dateien im Projektprojektordner angezeigt werden: simple_nn_lb.pickle und simple_nn.model, und das Bild des Tieres mit einer Beschriftungs- und Erkennungsrate wird angezeigt, zum Beispiel: <br><br><img src="https://habrastorage.org/webt/p3/vn/mv/p3vnmvdsxkgpx3cqpi94tvmwd5i.png"><br><br><h3>  Neuronales Netz - eigene Daten </h3><br>  Nachdem der Netzwerkzustandstest √ºberpr√ºft wurde, k√∂nnen Sie Ihre eigenen Daten verbinden und mit dem Training des Netzwerks beginnen. <br><br>  Legen Sie in den Ordner dat Ordner Ordner mit Nummern ab, die ausgew√§hlte Stichproben f√ºr jede Ziffer enthalten. <br>  Der Einfachheit halber legen wir den Dat-Ordner im Projektordner ab (z. B. neben dem Tierordner). <br>  Die Syntax zum Starten des Netzwerklernens lautet nun: <br><br><pre> <code class="bash hljs">python train_simple_nn.py --dataset dat --model output/simple_nn.model --label-bin output/simple_nn_lb.pickle --plot output/simple_nn_plot.png</code> </pre> <br>  Es ist jedoch zu fr√ºh, um mit dem Training zu beginnen. <br><br>  Sie m√ºssen die Datei train_simple_nn.py reparieren. <br><br>  1. Ganz am Ende der Datei: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#model.summary() score = model.evaluate(testX, testY, verbose=1) print("\nTest score:", score[0]) print('Test accuracy:', score[1])</span></span></code> </pre> <br>  Dadurch werden Informationen hinzugef√ºgt. <br><br>  2. <br><br><pre> <code class="python hljs">image = cv2.resize(image, (<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)).flatten()</code> </pre> <br>  wechseln zu <br><br><pre> <code class="python hljs">image = cv2.resize(image, (<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">37</span></span>)).flatten()</code> </pre>  Hier √§ndern wir die Gr√∂√üe des Eingabebildes.  Warum genau diese Gr√∂√üe?  Weil die meisten gehackten Ziffern entweder diese Gr√∂√üe haben oder darauf reduziert sind.  Wenn Sie auf 32 x 32 Pixel skalieren, wird das Bild verzerrt.  Ja und warum? <br><br>  Dar√ºber hinaus versuchen wir diese √Ñnderung: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: image = cv2.resize(image, (<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">37</span></span>)).flatten() <span class="hljs-keyword"><span class="hljs-keyword">except</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span></code> </pre> <br>  Weil  Das Programm kann einige Bilder und Probleme nicht verarbeiten. Keine, daher werden sie √ºbersprungen. <br><br>  3. Nun das Wichtigste.  Wo es einen Kommentar im Code gibt <blockquote>  Definieren Sie die Architektur 3072-1024-512-3 mit Keras </blockquote><br>  Die Netzwerkarchitektur im Artikel ist als 3072-1024-512-3 definiert.  Dies bedeutet, dass das Netzwerk 3072 (32 Pixel * 32 Pixel * 3) am Eingang empf√§ngt, dann Schicht 1024, Schicht 512 und am Ausgang 3 Optionen - eine Katze, ein Hund oder ein Panda. <br><br>  In unserem Fall ist die Eingabe 1776 (16 Pixel * 37 Pixel * 3), dann Schicht 1024, Schicht 512, bei der Ausgabe von 9 Varianten von Zahlen. <br><br>  Deshalb unser Code: <br><br><pre> <code class="python hljs">model.add(Dense(<span class="hljs-number"><span class="hljs-number">1024</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">1776</span></span>,), activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>))model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>))</code> </pre><br>  * 9 Ausg√§nge m√ºssen nicht zus√§tzlich angegeben werden, da  Das Programm selbst bestimmt die Anzahl der Exits anhand der Anzahl der Ordner im Dataset. <br><br><h3>  Wir starten </h3><br><pre> <code class="bash hljs">python train_simple_nn.py --dataset dat --model output/simple_nn.model --label-bin output/simple_nn_lb.pickle --plot output/simple_nn_plot.png</code> </pre> <br>  Da die Bilder mit Zahlen klein sind, lernt das Netzwerk auch bei schwacher Hardware sehr schnell (5-10 Minuten) und verwendet nur die CPU. <br><br>  Nachdem Sie das Programm in der Befehlszeile ausgef√ºhrt haben, sehen Sie sich die Ergebnisse an: <br><br><img src="https://habrastorage.org/webt/ul/wn/hq/ulwnhqojm6nydi91td23u6vkpew.png"><br><br>  Dies bedeutet, dass am Trainingssatz eine Wiedergabetreue von 82,19%, bei der Kontrolle von 75,6% und beim Test von 75,59% erreicht wurde. <br><br>  Wir m√ºssen uns gr√∂√ütenteils auf den letzteren Indikator konzentrieren.  Warum die anderen auch wichtig sind, wird sp√§ter erkl√§rt. <br><br>  Sehen wir uns auch den grafischen Teil der Arbeit des neuronalen Netzwerks an.  Es befindet sich im Ausgabeordner des Projekts simple_nn_plot.png: <br><br><img src="https://habrastorage.org/webt/c5/bm/fx/c5bmfxpm_1ce3vfunweiunp6gge.png"><br><br><h3>  Schneller, h√∂her, st√§rker.  Ergebnisse verbessern </h3><br>  Ein bisschen √ºber das Einrichten eines neuronalen Netzwerks, siehe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br>  Die authentische Option lautet wie folgt. <br><br>  Epochen hinzuf√ºgen. <br>  Im Code √§ndern wir <br><br><pre> <code class="python hljs">EPOCHS = <span class="hljs-number"><span class="hljs-number">75</span></span></code> </pre> <br>  auf <br><br><pre> <code class="python hljs">EPOCHS = <span class="hljs-number"><span class="hljs-number">200</span></span></code> </pre> <br>  Erh√∂hen Sie die "H√§ufigkeit", mit der das Netzwerk geschult wird. <br><br>  Ergebnis: <br><br><img src="https://habrastorage.org/webt/ud/oj/ht/udojhtyznrjf2imm9fqilahpg8e.png"><br><br>  Somit 93,5%, 92,6%, 92,6%. <br><br>  In Bildern: <br><br><img src="https://habrastorage.org/webt/v3/4z/fc/v34zfcx1t39ulua8_j7jgbdt9dk.png"><br><br>  Hier f√§llt auf, dass sich die blauen und roten Linien nach der 130. √Ñra voneinander zu l√∂sen beginnen und dies besagt, dass eine weitere Erh√∂hung der Anzahl der Epochen nicht funktionieren wird.  √úberpr√ºfen Sie dies heraus. <br><br>  Im Code √§ndern wir <br><br><pre> <code class="python hljs">EPOCHS = <span class="hljs-number"><span class="hljs-number">200</span></span></code> </pre> <br>  auf <br><br><pre> <code class="python hljs">EPOCHS = <span class="hljs-number"><span class="hljs-number">500</span></span></code> </pre> <br>  und wieder weglaufen. <br><br>  Ergebnis: <br><br><img src="https://habrastorage.org/webt/dz/dw/cd/dzdwcdeiebyebam67qi02xjozu4.png"><br><br>  Also haben wir: <br>  99%, 95,5%, 95,5%. <br><br>  Und in der Grafik: <br><br><img src="https://habrastorage.org/webt/qb/y2/vm/qby2vmydwtig4l626qzikq5qln0.png"><br><br>  Nun, die Zunahme der Anzahl der Epochen ist eindeutig ins Netz gegangen.  Dieses Ergebnis ist jedoch irref√ºhrend. <br><br>  Lassen Sie uns den Netzwerkbetrieb anhand eines realen Beispiels √ºberpr√ºfen. <br><br>  Zu diesem Zweck befindet sich das Predict.py-Skript im Projektordner.  Vor dem Start vorbereiten. <br><br>  Im Bilderordner des Projekts legen wir die Dateien mit den Bildern von Zahlen aus Captcha ab, auf die das Netzwerk zuvor im Lernprozess nicht gesto√üen war.  Das hei√üt,  Es ist notwendig, Ziffern zu nehmen, die nicht aus dem Datendatensatz dat stammen. <br><br>  In der Datei selbst legen wir zwei Zeilen f√ºr die Standardbildgr√∂√üe fest: <br><br><pre> <code class="python hljs">ap.add_argument(<span class="hljs-string"><span class="hljs-string">"-w"</span></span>, <span class="hljs-string"><span class="hljs-string">"--width"</span></span>, type=int, default=<span class="hljs-number"><span class="hljs-number">16</span></span>, help=<span class="hljs-string"><span class="hljs-string">"target spatial dimension width"</span></span>) ap.add_argument(<span class="hljs-string"><span class="hljs-string">"-e"</span></span>, <span class="hljs-string"><span class="hljs-string">"--height"</span></span>, type=int, default=<span class="hljs-number"><span class="hljs-number">37</span></span>, help=<span class="hljs-string"><span class="hljs-string">"target spatial dimension height"</span></span>)</code> </pre> <br>  F√ºhren Sie √ºber die Befehlszeile aus: <br><br><pre> <code class="bash hljs">python predict.py --image images/1.jpg --model output/simple_nn.model --label-bin output/simple_nn_lb.pickle --flatten 1</code> </pre> <br><br>  Und wir sehen das Ergebnis: <br><br><img src="https://habrastorage.org/webt/qp/f-/nz/qpf-nzzqpqoaccbynu5idkpwhoo.png"><br><br>  Noch ein Bild: <br><br><img src="https://habrastorage.org/webt/l9/hv/7r/l9hv7robn9u3pljp3llpoughsbi.png"><br><br>  Es funktioniert jedoch nicht mit allen verrauschten Zahlen: <br><br><img src="https://habrastorage.org/webt/p4/d3/me/p4d3me0oclkrhw9ntnlg4kailfq.png"><br><br>  Was kann man hier machen? <br><br><ol><li>  Erh√∂hen Sie die Anzahl der Kopien von Nummern in den Ordnern f√ºr das Training. </li><li>  Probieren Sie andere Methoden aus. </li></ol><br><h3>  Probieren wir andere Methoden aus </h3><br>  Wie Sie der letzten Grafik entnehmen k√∂nnen, weichen die blauen und roten Linien in der 130. √Ñra voneinander ab.  Dies bedeutet, dass das Lernen nach der 130. √Ñra unwirksam ist.  Wir korrigieren das Ergebnis in der 130. Epoche: 89,3%, 88%, 88% und pr√ºfen, ob andere Methoden zur Verbesserung der Netzwerkarbeit funktionieren. <br><br>  <b>Reduzieren Sie die Lerngeschwindigkeit.</b> <br><br><pre> <code class="python hljs">INIT_LR = <span class="hljs-number"><span class="hljs-number">0.01</span></span></code> </pre>  auf <pre> <code class="python hljs">INIT_LR = <span class="hljs-number"><span class="hljs-number">0.001</span></span></code> </pre> <br>  Ergebnis: <br>  41%, 39%, 39% <br><br>  Nun, von. <br><br>  <b>F√ºgen Sie eine zus√§tzliche versteckte Ebene hinzu.</b> <br><br><pre> <code class="python hljs">model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>))</code> </pre>  auf <pre> <code class="python hljs">model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">258</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>))</code> </pre> <br>  Ergebnis: <br>  56%, 62%, 62% <br><br>  Besser, aber nein. <br><br>  Wenn Sie jedoch die Anzahl der Epochen auf 250 erh√∂hen: <br>  84%, 83%, 83% <br><br>  Gleichzeitig l√∂sen sich die roten und blauen Linien nach der 130. √Ñra nicht mehr voneinander: <br><br><img src="https://habrastorage.org/webt/tn/d0/vs/tnd0vsxo6wb-tdn7_x-cxqt5vuu.png"><br><br>  <b>Speichern Sie 250 Epochen und wenden Sie die Ausd√ºnnung an</b> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers.core <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dropout</code> </pre> <br>  F√ºgen Sie eine Ausd√ºnnung zwischen den Schichten ein: <br><br><pre> <code class="python hljs">model.add(Dense(<span class="hljs-number"><span class="hljs-number">1024</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">1776</span></span>,), activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">258</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>))</code> </pre> <br>  Ergebnis: <br>  53%, 65%, 65% <br><br>  Der erste Wert ist niedriger als der Rest. Dies zeigt an, dass das Netzwerk nicht lernt.  Zu diesem Zweck wird empfohlen, die Anzahl der Epochen zu erh√∂hen. <br><br><pre> <code class="python hljs">model.add(Dense(<span class="hljs-number"><span class="hljs-number">1024</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">1776</span></span>,), activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>))</code> </pre><br>  Ergebnis: <br>  88%, 92%, 92% <br><br>  Mit 1 zus√§tzlichen Schicht, Ausd√ºnnung und 500 Epochen: <br><br><pre> <code class="python hljs">model.add(Dense(<span class="hljs-number"><span class="hljs-number">1024</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">1776</span></span>,), activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">258</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>))</code> </pre> <br>  Ergebnis: <br>  92,4%, 92,6%, 92,58% <br><br>  Trotz eines geringeren Prozentsatzes im Vergleich zu einer einfachen Erh√∂hung der Epochen auf 500 sieht die Grafik gleichm√§√üiger aus: <br><br><img src="https://habrastorage.org/webt/9m/-r/p7/9m-rp7ohvgfrhodwotg-e7c0lew.png"><br><br>  Und das Netzwerk verarbeitet Bilder, die zuvor ausgefallen sind: <br><br><img src="https://habrastorage.org/webt/ik/ih/4z/ikih4zdiifii2jdrvqcjnqyxv5o.png"><br><br>  Jetzt werden wir alles in einer Datei sammeln, die das Bild mit dem Captcha an der Eingabe in 5 Ziffern schneidet, jede Ziffer durch das neuronale Netzwerk f√ºhrt und das Ergebnis an den Python-Interpreter ausgibt. <br><br>  Hier ist es einfacher.  F√ºgen Sie in der Datei, die uns die Zahlen aus dem Captcha herausschneidet, die Datei hinzu, die sich mit Vorhersagen befasst. <br><br>  Jetzt schneidet das Programm nicht nur das Captcha in 5 Teile, sondern zeigt auch alle erkannten Zahlen im Interpreter an: <br><br><img src="https://habrastorage.org/webt/yo/xu/c7/yoxuc7nvgnx0zzctehu0jyxxn8k.png"><br><br>  Auch hier muss ber√ºcksichtigt werden, dass das Programm nicht 100% des Ergebnisses liefert und h√§ufig eine der 5 Ziffern falsch ist.  Dies ist jedoch ein gutes Ergebnis, wenn man bedenkt, dass das Trainingsset nur 170 bis 200 Exemplare pro Nummer enth√§lt. <br><br>  Die Captcha-Erkennung dauert auf einem Computer mit mittlerer Leistung 3-5 Sekunden. <br><br>  Wie sonst k√∂nnen Sie versuchen, das Netzwerk zu verbessern? Sie k√∂nnen im Buch "Keras Library - ein Deep-Learning-Tool" A. Dzhulli, S. Pala lesen. <br><br>  Das letzte Skript, das das Captcha schneidet und erkennt, ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br>  Es beginnt ohne Parameter. <br>  Recycelte Skripte zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Trainieren</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Testen des</a> Netzwerks. <br>  Captcha f√ºr den Test, auch mit falsch positiven Ergebnissen - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br>  Das Modell f√ºr die Arbeit ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br>  Die Nummern in Ordnern sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de464337/">https://habr.com/ru/post/de464337/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de464325/index.html">Wie Scrumban das Beste aus Kanban- und Scrum-Methoden vereint</a></li>
<li><a href="../de464327/index.html">Vergleich der Speichernutzung verschiedener Toolkit-GUIs</a></li>
<li><a href="../de464331/index.html">Nutzlose Vorteile: Synthese von UV-absorbierenden Chemikalien aus Cashewn√ºssen</a></li>
<li><a href="../de464333/index.html">Verfolgung des Lebenszyklus von Benutzern ohne Zange und Isolierband</a></li>
<li><a href="../de464335/index.html">Unit-Tests in DBMS - wie wir es in Sportmaster machen, Teil eins</a></li>
<li><a href="../de464345/index.html">5 Gr√ºnde, ein IT-Startup in Deutschland zu er√∂ffnen</a></li>
<li><a href="../de464347/index.html">Abh√§ngigkeitsinjektions-, JavaScript- und ES6-Module</a></li>
<li><a href="../de464351/index.html">PoE IP-Kameras, spezielle Anforderungen und st√∂rungsfreier Betrieb - alles zusammen</a></li>
<li><a href="../de464353/index.html">1C: ERP VS 1C: KA 2.0. Was sollten Lebensmittelhersteller w√§hlen?</a></li>
<li><a href="../de464355/index.html">Wie ein Frame in Shadow Fight 3 gerendert wird</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👿 ♉️ 🍁 So umgehen Sie Captcha: Neuronales Netzwerk auf Tensorflow, Keras, Python v numerisch verrauschtes Captcha 🗞️ 🛀🏻 💯</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Captcha-Thema ist nicht neu, auch für Habr. Die Captcha-Algorithmen ändern sich jedoch ebenso wie die Algorithmen zu ihrer Lösung. Daher wird vorg...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>So umgehen Sie Captcha: Neuronales Netzwerk auf Tensorflow, Keras, Python v numerisch verrauschtes Captcha</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/464337/">  Das Captcha-Thema ist nicht neu, auch für Habr.  Die Captcha-Algorithmen ändern sich jedoch ebenso wie die Algorithmen zu ihrer Lösung.  Daher wird vorgeschlagen, sich an die alte zu erinnern und die folgende Version von Captcha zu betreiben: <br><br><img src="https://habrastorage.org/webt/x6/h7/tn/x6h7tnn4a3slc9th4nbup6sumdm.jpeg"><br><br>  Verstehen Sie dabei die Arbeit eines einfachen neuronalen Netzwerks in der Praxis und verbessern Sie auch dessen Ergebnisse. <br><a name="habracut"></a><br>  Machen Sie sofort einen Vorbehalt, dass wir nicht in Gedanken darüber eintauchen, wie das Neuron funktioniert und was damit zu tun ist. Der Artikel behauptet nicht, wissenschaftlich zu sein, sondern bietet nur ein kleines Tutorial. <br><br><h3>  Vom Herd aus tanzen.  Anstatt mitzumachen </h3><br>  Vielleicht werden die Worte von jemandem wiederholt, aber die meisten Bücher über Deep Learning beginnen wirklich damit, dass dem Leser vorbereitete Daten angeboten werden, mit denen er zu arbeiten beginnt.  Irgendwie MNIST - 60.000 handschriftliche Ziffern, CIFAR-10 usw.  Nach dem Lesen kommt eine Person vorbereitet heraus ... für diese Datensätze.  Es ist völlig unklar, wie Sie Ihre Daten verwenden und vor allem, wie Sie beim Aufbau Ihres eigenen neuronalen Netzwerks etwas verbessern können. <br><br>  Aus diesem Grund war der Artikel auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">pyimagesearch.com</a> über die Arbeit mit Ihren eigenen Daten sowie deren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Übersetzung</a> sehr nützlich. <br><br>  Aber wie sie sagen, ist Rettich-Meerrettich nicht süßer: Selbst mit der Übersetzung des gekauten Artikels über Keras gibt es viele blinde Flecken.  Auch hier wird ein vorbereiteter Datensatz nur für Katzen, Hunde und Pandas angeboten.  Müssen die Lücken selbst ausfüllen. <br>  Dieser Artikel und Code werden jedoch als Grundlage verwendet. <br><br><h3>  Wir sammeln Daten über Captcha </h3><br>  Hier gibt es nichts Neues.  Wir brauchen Captcha-Proben, wie  Das Netzwerk wird unter unserer Anleitung von ihnen lernen.  Sie können das Captcha selbst abbauen oder hier ein wenig nehmen - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">29.000 Captchas</a> .  Jetzt müssen Sie die Zahlen aus jedem Captcha herausschneiden.  Es ist nicht notwendig, alle 29.000 Captcha zu schneiden, zumal 1 Captcha 5 Ziffern ergibt.  500 Captcha werden mehr als genug sein. <br><br>  Wie schneide ich?  In Photoshop ist dies möglich, aber es ist besser, ein besseres Messer zu haben. <br><br>  Also hier ist der Python Messer Code - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Download</a> .  (Für Windows. Erstellen Sie zuerst die Ordner C: \ 1 \ test und C: \ 1 \ test-out.) <br>  Die Ausgabe ist ein Dump mit Zahlen von 1 bis 9 (das Captcha enthält keine Nullen). <br>  Als nächstes müssen Sie diese Blockierung von den Zahlen in Ordner von 1 bis 9 analysieren und durch die entsprechende Nummer in jeden Ordner einfügen.  So lala Beruf.  Aber an einem Tag können Sie bis zu 1000 Ziffern erkennen. <br><br>  Wenn es bei der Auswahl einer Nummer zweifelhaft ist, welche der Nummern es ist, ist es besser, dieses Beispiel zu löschen.  Und es ist in Ordnung, wenn die Zahlen verrauscht sind oder unvollständig in den "Frame" eingegeben werden: <br><br><img src="https://habrastorage.org/webt/bi/qi/um/biqiumw_hjgkfbgzt4abq4pqiby.jpeg"><br><br><img src="https://habrastorage.org/webt/ec/xc/pu/ecxcpugnhuys1puccmahjitsfwe.jpeg"><br><br><img src="https://habrastorage.org/webt/3o/fe/wl/3ofewllm6jxduh7rsj3ginfbrrm.jpeg"><br><br>  Sie müssen 200 Proben jeder Ziffer in jedem Ordner sammeln.  Sie können diese Arbeit an Dienste von Drittanbietern delegieren. Es ist jedoch besser, alles selbst zu erledigen, damit Sie später nicht nach falsch übereinstimmenden Nummern suchen. <br><br><h3>  Neuronales Netz.  Test </h3><br>  <i>Tyat, tyat, unsere Netze zogen den Toten</i> <br><br>  Bevor Sie mit Ihren eigenen Daten arbeiten, lesen Sie den obigen Artikel und führen Sie den Code aus, um zu verstehen, dass alle Komponenten (Keras, Tensorflow usw.) installiert sind und ordnungsgemäß funktionieren. <br><br>  Wir werden ein einfaches Netzwerk verwenden, dessen Startsyntax aus der Befehlszeile (!) Stammt: <br><br><pre><code class="bash hljs">python train_simple_nn.py --dataset animals --model output/simple_nn.model --label-bin output/simple_nn_lb.pickle --plot output/simple_nn_plot.png</code> </pre> <br>  * Tensorflow kann schreiben, wenn Fehler in eigenen Dateien und veraltete Methoden bearbeitet werden. Sie können sie von Hand beheben oder einfach ignorieren. <br><br>  Die Hauptsache ist, dass nach dem Ausarbeiten des Programms zwei Dateien im Projektprojektordner angezeigt werden: simple_nn_lb.pickle und simple_nn.model, und das Bild des Tieres mit einer Beschriftungs- und Erkennungsrate wird angezeigt, zum Beispiel: <br><br><img src="https://habrastorage.org/webt/p3/vn/mv/p3vnmvdsxkgpx3cqpi94tvmwd5i.png"><br><br><h3>  Neuronales Netz - eigene Daten </h3><br>  Nachdem der Netzwerkzustandstest überprüft wurde, können Sie Ihre eigenen Daten verbinden und mit dem Training des Netzwerks beginnen. <br><br>  Legen Sie in den Ordner dat Ordner Ordner mit Nummern ab, die ausgewählte Stichproben für jede Ziffer enthalten. <br>  Der Einfachheit halber legen wir den Dat-Ordner im Projektordner ab (z. B. neben dem Tierordner). <br>  Die Syntax zum Starten des Netzwerklernens lautet nun: <br><br><pre> <code class="bash hljs">python train_simple_nn.py --dataset dat --model output/simple_nn.model --label-bin output/simple_nn_lb.pickle --plot output/simple_nn_plot.png</code> </pre> <br>  Es ist jedoch zu früh, um mit dem Training zu beginnen. <br><br>  Sie müssen die Datei train_simple_nn.py reparieren. <br><br>  1. Ganz am Ende der Datei: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#model.summary() score = model.evaluate(testX, testY, verbose=1) print("\nTest score:", score[0]) print('Test accuracy:', score[1])</span></span></code> </pre> <br>  Dadurch werden Informationen hinzugefügt. <br><br>  2. <br><br><pre> <code class="python hljs">image = cv2.resize(image, (<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)).flatten()</code> </pre> <br>  wechseln zu <br><br><pre> <code class="python hljs">image = cv2.resize(image, (<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">37</span></span>)).flatten()</code> </pre>  Hier ändern wir die Größe des Eingabebildes.  Warum genau diese Größe?  Weil die meisten gehackten Ziffern entweder diese Größe haben oder darauf reduziert sind.  Wenn Sie auf 32 x 32 Pixel skalieren, wird das Bild verzerrt.  Ja und warum? <br><br>  Darüber hinaus versuchen wir diese Änderung: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: image = cv2.resize(image, (<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">37</span></span>)).flatten() <span class="hljs-keyword"><span class="hljs-keyword">except</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span></code> </pre> <br>  Weil  Das Programm kann einige Bilder und Probleme nicht verarbeiten. Keine, daher werden sie übersprungen. <br><br>  3. Nun das Wichtigste.  Wo es einen Kommentar im Code gibt <blockquote>  Definieren Sie die Architektur 3072-1024-512-3 mit Keras </blockquote><br>  Die Netzwerkarchitektur im Artikel ist als 3072-1024-512-3 definiert.  Dies bedeutet, dass das Netzwerk 3072 (32 Pixel * 32 Pixel * 3) am Eingang empfängt, dann Schicht 1024, Schicht 512 und am Ausgang 3 Optionen - eine Katze, ein Hund oder ein Panda. <br><br>  In unserem Fall ist die Eingabe 1776 (16 Pixel * 37 Pixel * 3), dann Schicht 1024, Schicht 512, bei der Ausgabe von 9 Varianten von Zahlen. <br><br>  Deshalb unser Code: <br><br><pre> <code class="python hljs">model.add(Dense(<span class="hljs-number"><span class="hljs-number">1024</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">1776</span></span>,), activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>))model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>))</code> </pre><br>  * 9 Ausgänge müssen nicht zusätzlich angegeben werden, da  Das Programm selbst bestimmt die Anzahl der Exits anhand der Anzahl der Ordner im Dataset. <br><br><h3>  Wir starten </h3><br><pre> <code class="bash hljs">python train_simple_nn.py --dataset dat --model output/simple_nn.model --label-bin output/simple_nn_lb.pickle --plot output/simple_nn_plot.png</code> </pre> <br>  Da die Bilder mit Zahlen klein sind, lernt das Netzwerk auch bei schwacher Hardware sehr schnell (5-10 Minuten) und verwendet nur die CPU. <br><br>  Nachdem Sie das Programm in der Befehlszeile ausgeführt haben, sehen Sie sich die Ergebnisse an: <br><br><img src="https://habrastorage.org/webt/ul/wn/hq/ulwnhqojm6nydi91td23u6vkpew.png"><br><br>  Dies bedeutet, dass am Trainingssatz eine Wiedergabetreue von 82,19%, bei der Kontrolle von 75,6% und beim Test von 75,59% erreicht wurde. <br><br>  Wir müssen uns größtenteils auf den letzteren Indikator konzentrieren.  Warum die anderen auch wichtig sind, wird später erklärt. <br><br>  Sehen wir uns auch den grafischen Teil der Arbeit des neuronalen Netzwerks an.  Es befindet sich im Ausgabeordner des Projekts simple_nn_plot.png: <br><br><img src="https://habrastorage.org/webt/c5/bm/fx/c5bmfxpm_1ce3vfunweiunp6gge.png"><br><br><h3>  Schneller, höher, stärker.  Ergebnisse verbessern </h3><br>  Ein bisschen über das Einrichten eines neuronalen Netzwerks, siehe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br>  Die authentische Option lautet wie folgt. <br><br>  Epochen hinzufügen. <br>  Im Code ändern wir <br><br><pre> <code class="python hljs">EPOCHS = <span class="hljs-number"><span class="hljs-number">75</span></span></code> </pre> <br>  auf <br><br><pre> <code class="python hljs">EPOCHS = <span class="hljs-number"><span class="hljs-number">200</span></span></code> </pre> <br>  Erhöhen Sie die "Häufigkeit", mit der das Netzwerk geschult wird. <br><br>  Ergebnis: <br><br><img src="https://habrastorage.org/webt/ud/oj/ht/udojhtyznrjf2imm9fqilahpg8e.png"><br><br>  Somit 93,5%, 92,6%, 92,6%. <br><br>  In Bildern: <br><br><img src="https://habrastorage.org/webt/v3/4z/fc/v34zfcx1t39ulua8_j7jgbdt9dk.png"><br><br>  Hier fällt auf, dass sich die blauen und roten Linien nach der 130. Ära voneinander zu lösen beginnen und dies besagt, dass eine weitere Erhöhung der Anzahl der Epochen nicht funktionieren wird.  Überprüfen Sie dies heraus. <br><br>  Im Code ändern wir <br><br><pre> <code class="python hljs">EPOCHS = <span class="hljs-number"><span class="hljs-number">200</span></span></code> </pre> <br>  auf <br><br><pre> <code class="python hljs">EPOCHS = <span class="hljs-number"><span class="hljs-number">500</span></span></code> </pre> <br>  und wieder weglaufen. <br><br>  Ergebnis: <br><br><img src="https://habrastorage.org/webt/dz/dw/cd/dzdwcdeiebyebam67qi02xjozu4.png"><br><br>  Also haben wir: <br>  99%, 95,5%, 95,5%. <br><br>  Und in der Grafik: <br><br><img src="https://habrastorage.org/webt/qb/y2/vm/qby2vmydwtig4l626qzikq5qln0.png"><br><br>  Nun, die Zunahme der Anzahl der Epochen ist eindeutig ins Netz gegangen.  Dieses Ergebnis ist jedoch irreführend. <br><br>  Lassen Sie uns den Netzwerkbetrieb anhand eines realen Beispiels überprüfen. <br><br>  Zu diesem Zweck befindet sich das Predict.py-Skript im Projektordner.  Vor dem Start vorbereiten. <br><br>  Im Bilderordner des Projekts legen wir die Dateien mit den Bildern von Zahlen aus Captcha ab, auf die das Netzwerk zuvor im Lernprozess nicht gestoßen war.  Das heißt,  Es ist notwendig, Ziffern zu nehmen, die nicht aus dem Datendatensatz dat stammen. <br><br>  In der Datei selbst legen wir zwei Zeilen für die Standardbildgröße fest: <br><br><pre> <code class="python hljs">ap.add_argument(<span class="hljs-string"><span class="hljs-string">"-w"</span></span>, <span class="hljs-string"><span class="hljs-string">"--width"</span></span>, type=int, default=<span class="hljs-number"><span class="hljs-number">16</span></span>, help=<span class="hljs-string"><span class="hljs-string">"target spatial dimension width"</span></span>) ap.add_argument(<span class="hljs-string"><span class="hljs-string">"-e"</span></span>, <span class="hljs-string"><span class="hljs-string">"--height"</span></span>, type=int, default=<span class="hljs-number"><span class="hljs-number">37</span></span>, help=<span class="hljs-string"><span class="hljs-string">"target spatial dimension height"</span></span>)</code> </pre> <br>  Führen Sie über die Befehlszeile aus: <br><br><pre> <code class="bash hljs">python predict.py --image images/1.jpg --model output/simple_nn.model --label-bin output/simple_nn_lb.pickle --flatten 1</code> </pre> <br><br>  Und wir sehen das Ergebnis: <br><br><img src="https://habrastorage.org/webt/qp/f-/nz/qpf-nzzqpqoaccbynu5idkpwhoo.png"><br><br>  Noch ein Bild: <br><br><img src="https://habrastorage.org/webt/l9/hv/7r/l9hv7robn9u3pljp3llpoughsbi.png"><br><br>  Es funktioniert jedoch nicht mit allen verrauschten Zahlen: <br><br><img src="https://habrastorage.org/webt/p4/d3/me/p4d3me0oclkrhw9ntnlg4kailfq.png"><br><br>  Was kann man hier machen? <br><br><ol><li>  Erhöhen Sie die Anzahl der Kopien von Nummern in den Ordnern für das Training. </li><li>  Probieren Sie andere Methoden aus. </li></ol><br><h3>  Probieren wir andere Methoden aus </h3><br>  Wie Sie der letzten Grafik entnehmen können, weichen die blauen und roten Linien in der 130. Ära voneinander ab.  Dies bedeutet, dass das Lernen nach der 130. Ära unwirksam ist.  Wir korrigieren das Ergebnis in der 130. Epoche: 89,3%, 88%, 88% und prüfen, ob andere Methoden zur Verbesserung der Netzwerkarbeit funktionieren. <br><br>  <b>Reduzieren Sie die Lerngeschwindigkeit.</b> <br><br><pre> <code class="python hljs">INIT_LR = <span class="hljs-number"><span class="hljs-number">0.01</span></span></code> </pre>  auf <pre> <code class="python hljs">INIT_LR = <span class="hljs-number"><span class="hljs-number">0.001</span></span></code> </pre> <br>  Ergebnis: <br>  41%, 39%, 39% <br><br>  Nun, von. <br><br>  <b>Fügen Sie eine zusätzliche versteckte Ebene hinzu.</b> <br><br><pre> <code class="python hljs">model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>))</code> </pre>  auf <pre> <code class="python hljs">model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">258</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>))</code> </pre> <br>  Ergebnis: <br>  56%, 62%, 62% <br><br>  Besser, aber nein. <br><br>  Wenn Sie jedoch die Anzahl der Epochen auf 250 erhöhen: <br>  84%, 83%, 83% <br><br>  Gleichzeitig lösen sich die roten und blauen Linien nach der 130. Ära nicht mehr voneinander: <br><br><img src="https://habrastorage.org/webt/tn/d0/vs/tnd0vsxo6wb-tdn7_x-cxqt5vuu.png"><br><br>  <b>Speichern Sie 250 Epochen und wenden Sie die Ausdünnung an</b> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers.core <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dropout</code> </pre> <br>  Fügen Sie eine Ausdünnung zwischen den Schichten ein: <br><br><pre> <code class="python hljs">model.add(Dense(<span class="hljs-number"><span class="hljs-number">1024</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">1776</span></span>,), activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">258</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>))</code> </pre> <br>  Ergebnis: <br>  53%, 65%, 65% <br><br>  Der erste Wert ist niedriger als der Rest. Dies zeigt an, dass das Netzwerk nicht lernt.  Zu diesem Zweck wird empfohlen, die Anzahl der Epochen zu erhöhen. <br><br><pre> <code class="python hljs">model.add(Dense(<span class="hljs-number"><span class="hljs-number">1024</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">1776</span></span>,), activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>))</code> </pre><br>  Ergebnis: <br>  88%, 92%, 92% <br><br>  Mit 1 zusätzlichen Schicht, Ausdünnung und 500 Epochen: <br><br><pre> <code class="python hljs">model.add(Dense(<span class="hljs-number"><span class="hljs-number">1024</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">1776</span></span>,), activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">258</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"sigmoid"</span></span>))</code> </pre> <br>  Ergebnis: <br>  92,4%, 92,6%, 92,58% <br><br>  Trotz eines geringeren Prozentsatzes im Vergleich zu einer einfachen Erhöhung der Epochen auf 500 sieht die Grafik gleichmäßiger aus: <br><br><img src="https://habrastorage.org/webt/9m/-r/p7/9m-rp7ohvgfrhodwotg-e7c0lew.png"><br><br>  Und das Netzwerk verarbeitet Bilder, die zuvor ausgefallen sind: <br><br><img src="https://habrastorage.org/webt/ik/ih/4z/ikih4zdiifii2jdrvqcjnqyxv5o.png"><br><br>  Jetzt werden wir alles in einer Datei sammeln, die das Bild mit dem Captcha an der Eingabe in 5 Ziffern schneidet, jede Ziffer durch das neuronale Netzwerk führt und das Ergebnis an den Python-Interpreter ausgibt. <br><br>  Hier ist es einfacher.  Fügen Sie in der Datei, die uns die Zahlen aus dem Captcha herausschneidet, die Datei hinzu, die sich mit Vorhersagen befasst. <br><br>  Jetzt schneidet das Programm nicht nur das Captcha in 5 Teile, sondern zeigt auch alle erkannten Zahlen im Interpreter an: <br><br><img src="https://habrastorage.org/webt/yo/xu/c7/yoxuc7nvgnx0zzctehu0jyxxn8k.png"><br><br>  Auch hier muss berücksichtigt werden, dass das Programm nicht 100% des Ergebnisses liefert und häufig eine der 5 Ziffern falsch ist.  Dies ist jedoch ein gutes Ergebnis, wenn man bedenkt, dass das Trainingsset nur 170 bis 200 Exemplare pro Nummer enthält. <br><br>  Die Captcha-Erkennung dauert auf einem Computer mit mittlerer Leistung 3-5 Sekunden. <br><br>  Wie sonst können Sie versuchen, das Netzwerk zu verbessern? Sie können im Buch "Keras Library - ein Deep-Learning-Tool" A. Dzhulli, S. Pala lesen. <br><br>  Das letzte Skript, das das Captcha schneidet und erkennt, ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br>  Es beginnt ohne Parameter. <br>  Recycelte Skripte zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Trainieren</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Testen des</a> Netzwerks. <br>  Captcha für den Test, auch mit falsch positiven Ergebnissen - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br>  Das Modell für die Arbeit ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br>  Die Nummern in Ordnern sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de464337/">https://habr.com/ru/post/de464337/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de464325/index.html">Wie Scrumban das Beste aus Kanban- und Scrum-Methoden vereint</a></li>
<li><a href="../de464327/index.html">Vergleich der Speichernutzung verschiedener Toolkit-GUIs</a></li>
<li><a href="../de464331/index.html">Nutzlose Vorteile: Synthese von UV-absorbierenden Chemikalien aus Cashewnüssen</a></li>
<li><a href="../de464333/index.html">Verfolgung des Lebenszyklus von Benutzern ohne Zange und Isolierband</a></li>
<li><a href="../de464335/index.html">Unit-Tests in DBMS - wie wir es in Sportmaster machen, Teil eins</a></li>
<li><a href="../de464345/index.html">5 Gründe, ein IT-Startup in Deutschland zu eröffnen</a></li>
<li><a href="../de464347/index.html">Abhängigkeitsinjektions-, JavaScript- und ES6-Module</a></li>
<li><a href="../de464351/index.html">PoE IP-Kameras, spezielle Anforderungen und störungsfreier Betrieb - alles zusammen</a></li>
<li><a href="../de464353/index.html">1C: ERP VS 1C: KA 2.0. Was sollten Lebensmittelhersteller wählen?</a></li>
<li><a href="../de464355/index.html">Wie ein Frame in Shadow Fight 3 gerendert wird</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
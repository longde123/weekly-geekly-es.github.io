<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸŒŸ ğŸŒ„ ğŸ”¯ Alihkan Tinder ke Kubernetes ğŸŒ· ğŸ‘©ğŸ»â€ğŸ« ğŸ‘²ğŸ¼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Catatan perev. : Karyawan Tinder baru-baru ini membagikan beberapa detail teknis tentang migrasi infrastruktur mereka ke Kubernetes. Proses ini memaka...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Alihkan Tinder ke Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/440278/">  <i><b>Catatan</b></i>  <i><b>perev.</b></i>  <i>: Karyawan Tinder baru-baru ini membagikan beberapa detail teknis tentang migrasi infrastruktur mereka ke Kubernetes.</i>  <i>Proses ini memakan waktu hampir dua tahun dan menghasilkan peluncuran platform K8 yang sangat besar yang terdiri dari 200 layanan yang di-host di 48 ribu kontainer.</i>  <i>Kesulitan apa yang menarik yang dihadapi oleh insinyur Tinder dan hasil apa yang mereka peroleh - baca dalam terjemahan ini.</i> <br><br><img src="https://habrastorage.org/webt/uq/og/xd/uqogxdavfghsshnu8hvlszhubpe.png"><a name="habracut"></a><br><br><h2>  Mengapa </h2><br>  Hampir dua tahun lalu, Tinder memutuskan untuk beralih platformnya ke Kubernetes.  Kubernetes akan memungkinkan tim Tinder untuk kemas dan beralih ke operasi dengan upaya minimal melalui <i>penyebaran abadi</i> .  Dalam hal ini, perakitan aplikasi, penyebarannya, dan infrastrukturnya sendiri akan ditentukan secara unik oleh kode. <br><br>  Kami juga mencari solusi untuk masalah skalabilitas dan stabilitas.  Ketika penskalaan menjadi kritis, kami sering harus menunggu beberapa menit untuk meluncurkan instance EC2 baru.  Karenanya, ide untuk meluncurkan kontainer dan mulai melayani lalu lintas dalam hitungan detik, bukan menit, menjadi sangat menarik bagi kami. <br><br>  Prosesnya tidak mudah.  Selama migrasi, pada awal 2019, cluster Kubernetes mencapai massa kritis dan kami mulai menghadapi berbagai masalah karena jumlah lalu lintas, ukuran cluster, dan DNS.  Dalam perjalanan ini, kami memecahkan banyak masalah menarik terkait dengan transfer 200 layanan dan pemeliharaan cluster Kubernetes, yang terdiri dari 1000 node, 15.000 pod, dan 48.000 kontainer yang berfungsi. <br><br><h2>  Bagaimana? </h2><br>  Sejak Januari 2018, kami telah melalui berbagai tahap migrasi.  Kami mulai dengan membuat wadah semua layanan kami dan menempatkannya di lingkungan pengujian Kubernetes.  Pada bulan Oktober, proses transfer metodis dari semua layanan yang ada ke Kubernetes dimulai.  Pada bulan Maret tahun berikutnya, "relokasi" selesai dan sekarang platform Tinder berjalan secara eksklusif di Kubernetes. <br><br><h3>  Buat gambar untuk Kubernetes </h3><br>  Kami memiliki lebih dari 30 repositori kode sumber untuk layanan microser yang berjalan di kluster Kubernetes.  Kode dalam repositori ini ditulis dalam bahasa yang berbeda (misalnya, Node.js, Java, Scala, Go) dengan banyak lingkungan runtime untuk bahasa yang sama. <br><br>  Sistem build dirancang untuk memberikan "konteks pembangunan" yang sepenuhnya dapat disesuaikan untuk setiap layanan Microsoft.  Biasanya terdiri dari Dockerfile dan daftar perintah shell.  Konten mereka sepenuhnya dapat disesuaikan, dan pada saat yang sama, semua konteks build ini ditulis sesuai dengan format standar.  Standarisasi konteks pembangunan memungkinkan sistem pembangunan tunggal untuk menangani semua layanan microser. <br><br><img src="https://habrastorage.org/webt/qg/he/8h/qghe8hvhjmsnpwuivvebqk1ne04.png"><br>  <i>Gambar 1-1.</i>  <i>Proses pembangunan terstandarisasi melalui pembangun-kontainer (Builder)</i> <br><br>  Untuk mencapai konsistensi maksimum antara runtime, proses build yang sama digunakan selama pengembangan dan pengujian.  Kami menghadapi masalah yang sangat menarik: kami harus mengembangkan cara untuk menjamin konsistensi lingkungan perakitan di seluruh platform.  Untuk melakukan ini, semua proses perakitan dilakukan di dalam wadah <i>Builder</i> khusus. <br><br>  Implementasinya membutuhkan teknik-teknik canggih untuk bekerja dengan Docker.  Builder mewarisi ID pengguna lokal dan rahasia (seperti kunci SSH, kredensial AWS, dll.) Yang diperlukan untuk mengakses repositori pribadi Tinder.  Itu me-mount direktori lokal yang mengandung sumber untuk menyimpan artefak perakitan secara alami.  Pendekatan ini meningkatkan kinerja dengan menghilangkan kebutuhan untuk menyalin artefak perakitan antara wadah Builder dan tuan rumah.  Artefak rakitan yang disimpan dapat digunakan kembali tanpa konfigurasi tambahan. <br><br>  Untuk beberapa layanan, kami harus membuat wadah lain agar sesuai dengan lingkungan kompilasi dengan runtime (misalnya, selama proses instalasi, perpustakaan bcrypt Node.js menghasilkan artefak biner khusus platform).  Selama kompilasi, persyaratan dapat bervariasi untuk berbagai layanan, dan Dockerfile akhir dikompilasi dengan cepat. <br><br><h3>  Arsitektur dan Migrasi Cluster Kubernetes </h3><br><h4>  Manajemen ukuran cluster </h4><br>  Kami memutuskan untuk menggunakan <b>kube-aws</b> untuk menyebarkan kluster secara otomatis pada instance Amazon EC2.  Pada awalnya, semuanya bekerja dalam satu kumpulan node yang sama.  Kami dengan cepat menyadari perlunya memisahkan beban kerja berdasarkan ukuran dan jenis contoh untuk penggunaan sumber daya yang lebih efisien.  Logikanya adalah bahwa peluncuran beberapa pod multi-threaded yang dimuat ternyata lebih dapat diprediksi kinerjanya daripada koeksistensi mereka dengan sejumlah besar pod single-threaded. <br><br>  Sebagai hasilnya, kami memutuskan: <br><br><ul><li>  <i>m5.4xlarge</i> - untuk pemantauan (Prometheus); </li><li>  <i>c5.4xlarge</i> - untuk beban kerja Node.js (beban kerja berulir tunggal); </li><li>  <i>c5.2xlarge</i> - untuk Java dan Go (beban kerja multi-utas); </li><li>  <i>c5.4xlarge</i> - untuk panel kontrol (3 node). </li></ul><br><h4>  Migrasi </h4><br>  Salah satu langkah persiapan untuk bermigrasi dari infrastruktur lama ke Kubernetes adalah mengarahkan kembali interaksi langsung yang ada antara layanan ke penyeimbang beban baru (ELB, Elastic Load Balancers).  Mereka dibuat pada subnet virtual private cloud (VPC) tertentu.  Subnet ini terhubung ke Kubernetes VPC.  Ini memungkinkan kami untuk memigrasikan modul secara bertahap, tidak dengan mempertimbangkan urutan dependensi layanan tertentu. <br><br>  Titik akhir ini dibuat menggunakan set data DNS tertimbang dengan CNAME menunjuk ke setiap ELB baru.  Untuk beralih, kami menambahkan catatan baru yang menunjuk ke layanan Kubernetes baru ELB dengan bobot 0. Kemudian kami mengatur Time To Live (TTL) dari recordset ke 0. Setelah itu, bobot lama dan baru perlahan-lahan disesuaikan, dan akhirnya 100% beban dikirim. ke server baru.  Setelah sakelar selesai, nilai TTL kembali ke level yang lebih memadai. <br><br>  Modul Java kami yang ada menangani DNS TTL rendah, tetapi aplikasi Node tidak.  Salah satu insinyur menulis ulang bagian dari kode kumpulan koneksi, membungkusnya dengan manajer yang memperbarui kumpulan setiap 60 detik.  Pendekatan yang dipilih bekerja dengan sangat baik dan tanpa penurunan kinerja yang nyata. <br><br><h2>  Pelajaran </h2><br><h3>  Pembatasan perangkat jaringan </h3><br>  Pada dini hari 8 Januari 2019, platform Tinder tiba-tiba jatuh.  Menanggapi peningkatan latensi platform yang tidak terkait sebelumnya di pagi hari, jumlah pod dan node dalam cluster meningkat.  Ini menyebabkan habisnya cache ARP di semua node kami. <br><br>  Ada tiga opsi Linux yang terkait dengan cache ARP: <br><br><img src="https://habrastorage.org/webt/fq/bp/av/fqbpavle6xhk1ryeup0nd-lrqm0.png"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sumber</a> ) <br><br>  <b>gc_thresh3</b> adalah batas yang sulit.  Penampilan dalam log entri dari bentuk "tetangga tabel melimpah" berarti bahwa bahkan setelah pengumpulan sampah sinkron (GC) dalam cache ARP, tidak ada cukup ruang untuk menyimpan catatan tetangga.  Dalam hal ini, kernel hanya menjatuhkan paket sepenuhnya. <br><br>  Kami menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Flannel</a> sebagai <i>fabric jaringan</i> di Kubernetes.  Paket dikirimkan melalui VXLAN.  VXLAN adalah terowongan L2, terangkat melalui jaringan L3.  Teknologi ini menggunakan enkapsulasi MAC-in-UDP (Alamat MAC-di-Pengguna Protokol) dan memungkinkan Anda untuk memperluas segmen jaringan tingkat 2.  Protokol transport dalam jaringan fisik pusat data adalah IP plus UDP. <br><br> <a href=""><img src="https://habrastorage.org/webt/ad/vn/pl/advnplfowrh7mi-6otctfhzm2xs.png"></a> <br>  <i>Gambar 2â€“1.</i>  <i>Bagan Flanel ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sumber</a> )</i> <br><br><img src="https://habrastorage.org/webt/nz/ti/xz/nztixz_5aer3xofz2drri5uafb8.jpeg"><br>  <i>Gambar 2â€“2.</i>  <i>Paket VXLAN ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sumber</a> )</i> <br><br>  Setiap simpul kerja Kubernet mengalokasikan ruang alamat virtual dengan mask / 24 dari blok yang lebih besar / 9.  Untuk setiap node, ini <a href="">berarti</a> satu entri dalam tabel routing, satu entri dalam tabel ARP (pada antarmuka <i>flannel.1</i> ) dan satu entri dalam tabel switching (FDB).  Mereka ditambahkan ketika simpul kerja pertama kali dimulai atau ketika setiap simpul baru terdeteksi. <br><br>  Selain itu, koneksi node-pod (atau pod-pod) akhirnya melewati antarmuka <b>eth0</b> (seperti yang ditunjukkan pada diagram Flannel di atas).  Ini menghasilkan entri tambahan dalam tabel ARP untuk setiap sumber dan tujuan node yang sesuai. <br><br>  Di lingkungan kita, jenis komunikasi ini sangat umum.  Untuk objek jenis layanan di Kubernetes, sebuah ELB dibuat dan Kubernet mendaftar setiap node di ELB.  ELB tidak tahu apa-apa tentang polong dan simpul yang dipilih mungkin bukan tujuan akhir dari paket.  Faktanya adalah bahwa ketika sebuah node menerima paket dari ELB, ia menganggapnya mempertimbangkan aturan <b>iptables</b> akun untuk layanan tertentu dan secara acak memilih pod pada node lain. <br><br>  Pada saat kegagalan, cluster memiliki 605 node.  Untuk alasan yang disebutkan di atas, ini sudah cukup untuk mengatasi nilai <b>gc_thresh3 default</b> .  Ketika ini terjadi, tidak hanya paket-paket yang mulai dibuang, tetapi seluruh ruang alamat virtual Flannel dengan mask / 24 menghilang dari tabel ARP.  Komunikasi node-pod dan kueri DNS terputus (DNS dihosting di sebuah cluster; lihat bagian lain artikel ini untuk detailnya). <br><br>  Untuk mengatasi masalah ini, tingkatkan nilai <b>gc_thresh1</b> , <b>gc_thresh2</b> dan <b>gc_thresh3</b> dan restart Flannel untuk mendaftar ulang jaringan yang hilang. <br><br><h4>  Penskalaan DNS yang Tidak Terduga </h4><br>  Selama proses migrasi, kami secara aktif menggunakan DNS untuk mengelola lalu lintas dan secara bertahap mentransfer layanan dari infrastruktur lama ke Kubernetes.  Kami menetapkan nilai TTL yang relatif rendah untuk Recordset terkait di Route53.  Ketika infrastruktur lama berjalan pada instance EC2, konfigurasi resolver kami menunjuk ke Amazon DNS.  Kami menerima begitu saja dan dampak TTL rendah pada layanan Amazon kami (seperti DynamoDB) hampir tanpa disadari. <br><br>  Karena layanan dimigrasikan ke Kubernetes, kami menemukan bahwa DNS menangani 250.000 kueri per detik.  Akibatnya, aplikasi mulai mengalami waktu tunggu yang konstan dan serius untuk permintaan DNS.  Ini terjadi meskipun ada upaya luar biasa untuk mengoptimalkan dan mengalihkan penyedia DNS ke CoreDNS (yang mencapai 1000 pod berjalan pada 120 core pada beban puncak). <br><br>  Menjelajahi penyebab dan solusi lain yang mungkin, kami menemukan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sebuah artikel yang</a> menggambarkan kondisi ras yang memengaruhi kerangka penyaringan paket <b>netfilter</b> di Linux.  Timeout yang kami amati, bersama dengan peningkatan <b>insert_failed</b> counter di antarmuka Flannel, sesuai dengan kesimpulan artikel. <br><br>  Masalahnya muncul pada tahap Terjemahan Sumber dan Tujuan Alamat Jaringan (SNAT dan DNAT) dan entri selanjutnya ke tabel <b>conntrack</b> .  Salah satu solusi yang dibahas dalam perusahaan dan diusulkan oleh komunitas adalah transfer DNS ke node kerja itu sendiri.  Dalam hal ini: <br><br><ul><li>  SNAT tidak diperlukan karena lalu lintas tetap berada di dalam node.  Tidak perlu dialihkan melalui antarmuka <b>eth0</b> . </li><li>  DNAT tidak diperlukan, karena IP tujuan adalah lokal untuk host, dan bukan pod yang dipilih secara acak sesuai dengan aturan <b>iptables</b> . </li></ul><br>  Kami memutuskan untuk tetap berpegang pada pendekatan ini.  CoreDNS digunakan sebagai DaemonSet di Kubernetes dan kami mengimplementasikan server DNS lokal host di <b>resolv.conf dari</b> setiap pod dengan mengkonfigurasi <b>flag --cluster-dns</b> dari perintah <b>kubelet</b> .  Solusi ini terbukti efektif untuk batas waktu DNS. <br><br>  Namun, kami masih mengamati hilangnya paket dan peningkatan penghitung <b>insert_failed</b> di antarmuka Flannel.  Situasi ini berlanjut setelah pengenalan solusinya, karena kami dapat mengecualikan SNAT dan / atau DNAT hanya untuk lalu lintas DNS.  Kondisi balapan bertahan untuk jenis lalu lintas lainnya.  Untungnya, sebagian besar paket kami adalah TCP, dan ketika masalah terjadi, mereka hanya dikirim ulang.  Kami masih berusaha menemukan solusi yang cocok untuk semua jenis lalu lintas. <br><br><h4>  Menggunakan Utusan untuk Penyeimbangan Beban yang Lebih Baik </h4><br>  Ketika kami memigrasi layanan backend ke Kubernetes, kami mulai menderita dari beban yang tidak seimbang antara pod.  Kami menemukan bahwa karena HTTP Keepalive, koneksi ELB tergantung pada pod siap pakai pertama dari setiap penyebaran peluncuran.  Dengan demikian, sebagian besar lalu lintas melewati sebagian kecil dari pod yang tersedia.  Solusi pertama yang kami uji adalah mengatur parameter MaxSurge ke 100% pada penerapan baru untuk kasus terburuk.  Efeknya tidak signifikan dan tidak menjanjikan dalam hal penyebaran yang lebih besar. <br><br>  Solusi lain yang kami gunakan adalah meningkatkan permintaan sumber daya secara artifisial untuk layanan misi-kritis.  Dalam hal ini, pod yang berdekatan akan memiliki lebih banyak ruang untuk bermanuver daripada pod berat lainnya.  Dalam jangka panjang, itu juga tidak akan berhasil karena pemborosan sumber daya.  Selain itu, aplikasi Node kami adalah single-threaded dan, karenanya, hanya dapat menggunakan satu inti.  Satu-satunya solusi nyata adalah menggunakan load balancing yang lebih baik. <br><br>  Kami sudah lama ingin sepenuhnya menghargai <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Utusan</a> .  Situasi saat ini memungkinkan kami untuk menyebarkannya dengan cara yang sangat terbatas dan mendapatkan hasil langsung.  Utusan adalah sumber terbuka, proksi tingkat tujuh kinerja tinggi yang dirancang untuk aplikasi SOA besar.  Ia mampu menerapkan teknik penyeimbangan beban tingkat lanjut, termasuk percobaan ulang otomatis, pemutus sirkuit, dan batas kecepatan global.  <i>( <b>Catatan terjemahan</b> : Untuk lebih jelasnya, lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel terbaru</a> tentang Istio - service mesh, yang didasarkan pada Utusan.)</i> <br><br>  Kami datang dengan konfigurasi berikut: minta sespan utusan untuk setiap pod dan satu rute, dan cluster - sambungkan ke kontainer secara lokal dengan port.  Untuk meminimalkan potensi cascading dan menjaga radius kecil "kerusakan", kami menggunakan taman pod proxy-depan Utusan, satu untuk setiap Zona Ketersediaan (AZ) untuk setiap layanan.  Mereka beralih ke mekanisme penemuan layanan sederhana yang ditulis oleh salah satu insinyur kami, yang hanya mengembalikan daftar pod di setiap AZ untuk layanan yang diberikan. <br><br>  Kemudian bagian depan layanan Utusan menggunakan mekanisme penemuan layanan ini dengan satu cluster hulu dan rute.  Kami menetapkan batas waktu yang memadai, meningkatkan semua pengaturan pemutus sirkuit, dan menambahkan konfigurasi coba ulang minimal untuk membantu dengan kegagalan tunggal dan memastikan penyebaran yang mulus.  Sebelum masing-masing utusan depan layanan ini, kami menempatkan TCP ELB.  Bahkan jika keepalive dari lapisan proxy utama kami tergantung pada beberapa pod Utusan, mereka masih dapat menangani beban lebih baik dan diatur untuk menyeimbangkan melalui setidaknya_meminta di backend. <br><br>  Untuk penyebaran, kami menggunakan kait preStop pada pod aplikasi dan pod sespan.  Kait memulai kesalahan dalam memeriksa status titik akhir admin yang terletak di wadah sespan, dan "tidur" untuk sementara waktu untuk memungkinkan koneksi aktif untuk menyelesaikan. <br><br>  Salah satu alasan mengapa kami dapat maju dengan cepat dalam menyelesaikan masalah adalah terkait dengan metrik terperinci yang kami dapat dengan mudah diintegrasikan ke dalam instalasi standar Prometheus.  Dengan mereka menjadi mungkin untuk melihat apa yang terjadi ketika kami memilih parameter konfigurasi dan mendistribusikan kembali traffic. <br><br>  Hasilnya langsung dan jelas.  Kami mulai dengan layanan yang paling tidak seimbang, dan saat ini sudah berfungsi sebelum 12 layanan paling penting di cluster.  Tahun ini kami berencana untuk pindah ke jala servis penuh dengan penemuan layanan yang lebih canggih, pemutus sirkuit, deteksi outlier, pembatasan kecepatan dan pelacakan. <br><br> <a href=""><img src="https://habrastorage.org/webt/gy/yg/6s/gyyg6s_l8nlpbktislqy9jp9fma.png" alt="gambar"></a> <br>  <i>Gambar 3â€“1.</i>  <i>Konvergensi CPU dari satu layanan selama transisi ke Utusan</i> <br><br><img src="https://habrastorage.org/webt/lf/iw/pn/lfiwpneg1uvaruk85ghgcbhoghy.png"><br><br><img src="https://habrastorage.org/webt/ud/ug/8m/udug8mekxc36ql2vohzl-snp3vu.png"><br><br><h2>  Hasil akhir </h2><br>  Berkat pengalaman dan penelitian tambahan kami, kami telah membangun tim infrastruktur yang kuat dengan keterampilan yang baik dalam mendesain, menyebarkan dan mengoperasikan kluster Kubernet besar.  Sekarang semua insinyur Tinder memiliki pengetahuan dan pengalaman tentang cara mengemas kontainer dan menyebarkan aplikasi di Kubernetes. <br><br>  Ketika kebutuhan untuk kapasitas tambahan muncul pada infrastruktur lama, kami harus menunggu beberapa menit untuk meluncurkan instance EC2 baru.  Sekarang wadah mulai dan mulai memproses lalu lintas selama beberapa detik, bukan menit.  Menjadwalkan banyak wadah pada satu instance EC2 juga memberikan peningkatan konsentrasi horisontal.  Akibatnya, pada tahun 2019, kami memperkirakan penurunan biaya EC2 yang signifikan dibandingkan tahun lalu. <br><br>  Butuh waktu hampir dua tahun untuk bermigrasi, tetapi kami menyelesaikannya pada Maret 2019.  Saat ini, platform Tinder berjalan secara eksklusif pada kluster Kubernetes, yang terdiri dari 200 layanan, 1000 node, 15.000 pod, dan 48.000 container yang berjalan.  Infrastruktur tidak lagi menjadi tanggung jawab tim operasi.  Semua teknisi kami berbagi tanggung jawab ini dan mengendalikan proses membangun dan menggunakan aplikasi mereka hanya menggunakan kode. <br><br><h2>  PS dari penerjemah </h2><br>  Baca juga seri artikel kami di blog kami: <br><br><ul><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kisah sukses Kubernetes dalam produksi.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 1: <b>4.200 perapian dan TessMaster di eBay</b></a> . " </li><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kisah sukses Kubernetes dalam produksi.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 2: <b>Setuju dan SAP</b></a> . " </li><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kisah sukses Kubernetes dalam produksi.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 3: <b>GitHub</b></a> . " </li><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kisah sukses Kubernetes dalam produksi.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 4: <b>SoundCloud (penulis Prometheus)</b></a> . " </li><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kisah sukses Kubernetes dalam produksi.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 5: <b>Bank Digital Monzo.</b></a> " </li><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kisah sukses Kubernetes dalam produksi.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 6: <b>BlaBlaCar</b></a> . " </li><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kisah sukses Kubernetes dalam produksi.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 7: <b>BlackRock</b></a> . " </li><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kisah sukses Kubernetes dalam produksi.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 8: <b>Huawei</b></a> . " </li><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kisah sukses Kubernetes dalam produksi.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 9: <b>Cluster CERN dan 210 K8.</b></a> â€ </li><li>  â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kisah sukses Kubernetes dalam produksi.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagian 10: <b>Reddit</b></a> . " </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id440278/">https://habr.com/ru/post/id440278/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id440268/index.html">Pengalihan suara: mekanisme untuk menghasilkan klik ultrasonik di ngengat malam hari sebagai perlindungan terhadap kelelawar</a></li>
<li><a href="../id440270/index.html">Kami mempertimbangkan jadwal shift dalam pikiran</a></li>
<li><a href="../id440272/index.html">Mobile Opera telah mendapat VPN gratis</a></li>
<li><a href="../id440274/index.html">Membangun Layanan Mata Uang Pribadi Menggunakan Exonum</a></li>
<li><a href="../id440276/index.html">Front end dan debugging ujung belakang</a></li>
<li><a href="../id440280/index.html">Ulasan Perangkat Lunak Bebas Android</a></li>
<li><a href="../id440282/index.html">Kerangka kerja web Python tercepat di 2019</a></li>
<li><a href="../id440284/index.html">Tampilan segar menampilkan dialog di Android</a></li>
<li><a href="../id440286/index.html">Perlin noise, pembuatan konten prosedural, dan ruang yang menarik</a></li>
<li><a href="../id440288/index.html">Keamanan IOT. Masalah 1. Jam tangan pintar, pelacak kebugaran, dan timbangan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
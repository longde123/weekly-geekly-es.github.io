<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõèÔ∏è üå≠ üó∫Ô∏è ¬´Entra√Ænement de renforcement profond. AlphaGo et autres technologies ": l'annonce du livre üë®‚Äçüë©‚Äçüë¶ üöØ üë©‚Äç‚ù§Ô∏è‚Äçüë©</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour √† tous! 

 Nous avons l'un des meilleurs livres sur la formation de renforcement disponible en pr√©commande, initialement appel√© " Deep Reinfor...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>¬´Entra√Ænement de renforcement profond. AlphaGo et autres technologies ": l'annonce du livre</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/474276/">  Bonjour √† tous! <br><br>  Nous avons l'un des meilleurs livres sur la formation de renforcement disponible en pr√©commande, initialement appel√© " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deep Reinforcement Learning Hands-on</a> " par Maxim Lapan.  Voici la couverture de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">traduction russe</a> : <br><br><img src="https://habrastorage.org/webt/av/ig/n-/avign-oqnxjpgpptv7irkkwsope.jpeg"><br><br>  Afin que vous puissiez appr√©cier le r√©sum√© du livre, nous vous proposons une traduction de la critique r√©dig√©e par l'auteur √† la sortie de l'original. <br><a name="habracut"></a><br><br>  Salut <br><br>  Je suis un passionn√© autodidacte qui aime l'apprentissage en profondeur.  Par cons√©quent, lorsque des repr√©sentants de la maison d'√©dition Packt m'ont contact√© et m'ont sugg√©r√© d'√©crire un livre pratique sur l'√©tat actuel de l'apprentissage en profondeur avec renforcement, j'avais un peu peur, mais apr√®s quelques h√©sitations, j'ai accept√©, en supposant avec optimisme: "Oh, il y aura une exp√©rience int√©ressante." <br>  Je ne dirai pas que ce travail m'a √©t√© donn√© comme une promenade facile, bien s√ªr que non.  Vous n'avez pas de jours de cong√©, pas de temps libre, une peur constante de "geler la stupidit√©" et la poursuite des d√©lais pour chaque chapitre (deux semaines par chapitre et exemple de code).  Cependant, en g√©n√©ral, tout s'est pass√© de mani√®re positive et tr√®s int√©ressante. <br><br>  Avant de d√©crire bri√®vement le contenu de chaque chapitre, d√©crivons l' <i>id√©e de l'ensemble du livre</i> . <br>  Lorsque j'ai commenc√© √† exp√©rimenter en RL il y a plus de quatre ans, j'avais √† ma disposition les sources d'informations suivantes: <br><br><ul><li>  Sutton and Barto Book of <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Reinforcement Learning: An Introduction</a> </li><li>  Articles scientifiques sur <a href="">arxiv.org</a> </li><li>  Le parcours de David Silver. </li></ul><br><br>  Peut-√™tre qu'il y avait autre chose, mais ce sont les sources d'information les plus importantes.  Tous sont tr√®s loin de la pratique: <br><br><ul><li>  Le livre de Sutton et Barto, √©galement connu sous le nom de ¬´Le livre RL¬ª, ne fournit que les fondements th√©oriques de cette discipline. </li><li>  Les articles li√©s √† RL sont publi√©s presque quotidiennement, mais contiennent encore rarement des liens vers un code sp√©cifique.  Uniquement des formules et des algorithmes.  Si vous √™tes chanceux, des hyper param√®tres seront indiqu√©s. </li><li>  Le cours David Silver a √©t√© enseign√© √† l'University College London (UCL) en 2015.  Il donne un tr√®s bon aper√ßu des m√©thodes qui existaient √† l'√©poque, leur permettant d'√™tre ma√Ætris√©es intuitivement, cependant, ici, la th√©orie l'emporte √† nouveau sur la pratique. </li></ul><br><br>  Dans le m√™me temps, j'√©tais profond√©ment accro √† l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article DeepMind</a> ("Un r√©seau de neurones peut apprendre √† jouer aux jeux Atari en pixels! WOW!"), Et j'ai senti que cette th√©orie s√®che cache une √©norme valeur pratique.  J'ai donc pass√© beaucoup de temps √† √©tudier la th√©orie, √† mettre en ≈ìuvre diverses m√©thodes et √† les d√©boguer.  Comme vous l'avez probablement devin√©, cela n'a pas √©t√© facile: vous pouvez passer quelques semaines √† perfectionner la m√©thode, puis d√©couvrir que votre impl√©mentation est incorrecte (ou pire encore, vous avez mal compris la formule).  Je ne consid√®re pas une telle formation comme une perte de temps - au contraire, je pense que c'est la fa√ßon la plus correcte d'apprendre quelque chose.  Cependant, cela prend beaucoup de temps. <br><br>  Deux ans plus tard, lorsque j'ai commenc√© √† travailler sur le texte, mon objectif principal √©tait le suivant: donner des informations pratiques approfondies sur les m√©thodes de RL √† un lecteur qui ne conna√Æt que cette discipline fascinante - comme je l'ai d√©j√† fait. <br><br>  Maintenant, parlons un peu du livre.  Il se concentre principalement sur la pratique, et j'ai essay√© de minimiser le volume de la th√©orie et des formules.  Il contient des formules cl√©s, mais aucune preuve n'est donn√©e.  Fondamentalement, j'essaie de donner une compr√©hension intuitive de ce qui se passe, sans rechercher la rigueur maximale de pr√©sentation. <br><br>  Dans le m√™me temps, il est suppos√© que le lecteur poss√®de des connaissances de base de l'apprentissage en profondeur et des statistiques.  Il y a un chapitre dans le livre avec une vue d'ensemble de la biblioth√®que PyTorch (puisque tous les exemples sont donn√©s en utilisant PyTorch), mais ce chapitre ne peut pas √™tre consid√©r√© comme une source d'information auto-suffisante sur les r√©seaux de neurones.  Si vous n'avez jamais entendu parler des fonctions de perte et d'activation auparavant, commencez par consulter d'autres livres, aujourd'hui il y en a beaucoup.  (Remarque: par exemple, le livre " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deep learning</a> "). <br><br>  Dans mon livre, vous trouverez de nombreux exemples de complexit√© variable, √† commencer par les plus simples (la m√©thode <code>CrossEntropy</code> dans l'environnement <code>CartPole</code> contient ~ 100 lignes en python), se terminant par des projets assez importants, par exemple, apprendre AlphGo Zero ou un agent RL pour le commerce sur l'√©change.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Un exemple de code est enti√®rement t√©l√©charg√© sur GitHub</a> , il y a plus de 14k lignes de code en Python. <br><br>  Le livre se compose de 18 chapitres couvrant les aspects les plus importants de l'apprentissage profond moderne avec renforcement: <br><br><ul><li>  <b>Le chapitre 1</b> : fournit des informations introductives sur le paradigme de l'apprentissage renforc√©, montre en quoi il diff√®re de l'apprentissage avec et sans enseignant.  Nous consid√©rons ici le mod√®le math√©matique central li√© √† l'apprentissage par renforcement: les processus d√©cisionnels de Markov: (MPPR).  La connaissance du MPNR s'est faite √©tape par √©tape: je parle des cha√Ænes de Markov, qui sont transform√©es en processus de renforcement de Markov (avec l'ajout d'une composante de renforcement) et, enfin, en processus de d√©cision Markov √† part enti√®re, o√π les actions de l'agent sont √©galement prises en compte dans le tableau d'ensemble. </li><li>  <b>Chapitre 2</b> : parle d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenAI Gym</a> , une API g√©n√©ralis√©e pour RL, con√ßue pour fonctionner dans une vari√©t√© d'environnements, y compris Atari, r√©soudre des probl√®mes classiques, tels que CartPole, des t√¢ches d'apprentissage continu, etc. </li><li>  <b>Chapitre 3</b> : donne un aper√ßu rapide de l'API PyTorch.  Ce chapitre n'a pas √©t√© con√ßu comme un guide complet de DL, mais il jette les bases de la compr√©hension de chapitres suppl√©mentaires.  Si vous utilisez d'autres outils pour r√©soudre des probl√®mes d'apprentissage profond, il devrait servir de bonne introduction au beau mod√®le PyTorch, afin qu'il vous soit plus facile de comprendre les exemples des chapitres suivants.  √Ä la fin de ce chapitre, nous enseignerons un GAN simple qui g√©n√©rera et distinguera les captures d'√©cran Atari de diff√©rents jeux. </li><li>  <b>Chapitre 4</b> : examine l'une des m√©thodes les plus simples et les plus puissantes: CrossEntropy.  Dans ce chapitre, nous vous apprendrons le premier r√©seau capable de r√©soudre des probl√®mes dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">environnement CartPole</a> . </li><li>  <b>Chapitre 5</b> : Ce chapitre commence la <b>deuxi√®me partie du livre</b> sur l'algorithme d'it√©ration pour les valeurs.  Le chapitre 5 pr√©sente une m√©thode simple de formation sur un tableur √† l'aide de l'√©quation de Bellman pour r√©soudre des probl√®mes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dans l'environnement FrozenLake</a> . </li><li>  <b>Chapitre 6</b> : Ce chapitre vous pr√©sente les DQN qui jouent au jeu Atari.  L'architecture de l'agent est exactement la m√™me que dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">c√©l√®bre article DeepMind</a> . </li><li>  <b>Chapitre 7</b> : pr√©sente plusieurs extensions DQN modernes pour am√©liorer la stabilit√© et les performances du DQN sous-jacent.  Dans ce chapitre, les m√©thodes de l'article ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Rainbow: Combiner les am√©liorations dans Deep RL</a> ¬ª;  toutes ces m√©thodes sont impl√©ment√©es dans le chapitre, et j'explique les id√©es qui les sous-tendent.  Ces m√©thodes sont les suivantes: DQN en N √©tapes, DQN double, r√©seaux bruyants, tampon de lecture prioritaire, r√©seaux en duel et r√©seaux de cat√©gorie.  √Ä la fin du chapitre, toutes les m√©thodes sont combin√©es dans un exemple de code commun, exactement comme cela a √©t√© fait dans ¬´l'article arc-en-ciel¬ª. </li><li>  <b>Le chapitre 8</b> : d√©crit le premier projet de taille moyenne, illustrant le c√¥t√© pratique du RL dans la r√©solution de probl√®mes du monde r√©el.  Dans ce chapitre, √† l'aide du DQN, un agent est form√© pour effectuer des op√©rations sur l'√©change. </li><li>  <b>Chapitre 9</b> : Ce chapitre commence la <b>troisi√®me partie du</b> livre sur les techniques de gradient politique.  On y d√©couvre de telles m√©thodes, leurs forces et leurs faiblesses par rapport aux m√©thodes de d√©nombrement par valeurs d√©j√† envisag√©es ci-dessus.  La premi√®re m√©thode de cette famille est appel√©e RENFORCEMENT. </li><li>  <b>Le chapitre 10</b> : d√©crit comment traiter l'un des probl√®mes les plus graves de RL: la variabilit√© du gradient des politiques.  Apr√®s avoir exp√©riment√© les niveaux de PG de base, vous vous familiariserez avec la m√©thode acteur-critique. </li><li>  <b>Chapitre 11</b> : explique comment parall√©liser la m√©thode acteur-critique sur du mat√©riel moderne. </li><li>  <b>Chapitre 12</b> : un deuxi√®me exemple pratique qui d√©crit comment r√©soudre les probl√®mes associ√©s au traitement du langage naturel.  Dans ce chapitre, nous enseignons √† un chatbot simple √† utiliser les m√©thodes RL sur le mat√©riau de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bo√Æte de dialogue cin√©ma Cornell</a> . </li><li>  <b>Chapitre 13</b> : un autre exemple pratique sur l'automatisation Web: MiniWoB est utilis√© comme plateforme.  Malheureusement, OpenAI a refus√© d'utiliser MiniWoB, il est donc difficile de trouver des informations √† ce sujet ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">voici</a> quelques grains).  Mais l'id√©e de MiniWoB est brillante, donc dans ce chapitre je montre comment configurer et former l'agent pour r√©soudre certains des probl√®mes qui lui sont associ√©s. </li><li>  <b>Chapitre 14</b> : la derni√®re, <b>quatri√®me partie du</b> livre, consacr√©e aux m√©thodes et techniques plus avanc√©es, commence par elle.  Le chapitre 14 se concentre sur les t√¢ches de gestion continue et d√©crit les m√©thodes A3C, DDPG et D4PG pour r√©soudre les probl√®mes dans certains environnements PyBullet. </li><li>  <b>Chapitre 15</b> : parle davantage des probl√®mes de gestion continue et vous pr√©sente le ph√©nom√®ne de la r√©gion de confiance en utilisant TRPO, PPO et ACKTR comme exemples. </li><li>  <b>Chapitre 16</b> : consacr√© aux m√©thodes p√©dagogiques avec renforcement sans gradients (travail sur le principe de la ¬´bo√Æte noire¬ª);  ils sont positionn√©s comme des alternatives plus √©volutives pour les m√©thodes DQN et PG.  Des strat√©gies √©volutives et des algorithmes g√©n√©tiques sont appliqu√©s ici pour r√©soudre plusieurs probl√®mes de contr√¥le continu. </li><li>  <b>Le chapitre 17</b> : examine les approches RL bas√©es sur un mod√®le et d√©crit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la tentative de DeepMind de</a> combler l'√©cart entre les m√©thodes bas√©es sur un mod√®le et non bas√©es sur un mod√®le.  Ce chapitre impl√©mente l'agent I2A pour Breakout. </li><li>  <b>Chapitre 18</b> : Le dernier chapitre du livre traite de la m√©thode AlphaGo Zero utilis√©e lors de la lecture de Connect4.  Ensuite, l'agent fini est utilis√© dans le cadre du bot de t√©l√©gramme pour v√©rifier les r√©sultats. </li></ul><br><br><br>  C'est tout!  J'esp√®re que vous appr√©cierez le livre. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr474276/">https://habr.com/ru/post/fr474276/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr474252/index.html">Animation r√©aliste de personnages dans des jeux utilisant l'IA</a></li>
<li><a href="../fr474254/index.html">Faire un effet collant cool pour un curseur sur React</a></li>
<li><a href="../fr474256/index.html">L'id√©e de trouver des gens dans la for√™t</a></li>
<li><a href="../fr474268/index.html">Reconnaissance des circuits num√©riques. D√©clenchement de comptage asynchrone</a></li>
<li><a href="../fr474274/index.html">Graphique des connaissances. Pluralit√©, temporalit√©, approche de l'activit√©</a></li>
<li><a href="../fr474278/index.html">Python v3.x: comment augmenter la vitesse du d√©corateur sans inscription et sms</a></li>
<li><a href="../fr474280/index.html">Vous voulez un SGBD de premi√®re main? Une r√©union ouverte √† Nijni Novgorod - √† venir</a></li>
<li><a href="../fr474282/index.html">Explication du Datacenter TCP</a></li>
<li><a href="../fr474284/index.html">Non seulement les futures et les options: quels autres instruments financiers secondaires existent sur les bourses et pas seulement</a></li>
<li><a href="../fr474286/index.html">Analyse d√©taill√©e de la m√©thode simplex</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
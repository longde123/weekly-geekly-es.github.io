<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèΩ‚Äçüîß üë©üèæ‚Äçüéì üöå Pourquoi les TPU sont-ils si bons pour l'apprentissage en profondeur? üöÑ ‚ú¥Ô∏è üòñ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Processeur tenseur de 3e g√©n√©ration 

 Le processeur Google Tensor est un circuit int√©gr√© √† usage sp√©cial ( ASIC ) d√©velopp√© √† partir de z√©ro par Goog...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pourquoi les TPU sont-ils si bons pour l'apprentissage en profondeur?</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/422317/"><img src="https://habrastorage.org/webt/hc/p7/cd/hcp7cda1npc6ylbq16nwwcsyxd4.jpeg"><br>  <i>Processeur tenseur de 3e g√©n√©ration</i> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le processeur Google Tensor</a> est un circuit int√©gr√© √† usage sp√©cial ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ASIC</a> ) d√©velopp√© √† partir de z√©ro par Google pour effectuer des t√¢ches d'apprentissage automatique.  Il travaille sur plusieurs produits Google majeurs, notamment Translate, Photos, Search Assistant et Gmail.  Cloud TPU offre les avantages de l'√©volutivit√© et de la facilit√© d'utilisation √† tous les d√©veloppeurs et scientifiques des donn√©es qui lancent des mod√®les d'apprentissage automatique de pointe dans Google Cloud.  Lors de Google Next '18, nous avons annonc√© que Cloud TPU v2 est d√©sormais disponible pour tous les utilisateurs, y compris <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">les comptes d'essai gratuits</a> , et Cloud TPU v3 est disponible pour les tests alpha. <br><a name="habracut"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/f34/b73/cee/f34b73ceecf379f47dd446f0cc8b1a7c.jpg"><br><br>  Mais beaucoup de gens demandent - quelle est la diff√©rence entre CPU, GPU et TPU?  Nous avons r√©alis√© un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">site de d√©monstration</a> o√π <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">se</a> trouvent la pr√©sentation et l'animation qui r√©pondent √† cette question.  Dans cet article, je voudrais m'attarder sur certaines caract√©ristiques du contenu de ce site. <br><br><h2>  Comment fonctionnent les r√©seaux de neurones? </h2><br>  Avant de commencer √† comparer le CPU, le GPU et le TPU, voyons quels types de calculs sont n√©cessaires pour l'apprentissage automatique - et en particulier, pour les r√©seaux de neurones. <br><br>  Imaginez, par exemple, que nous utilisons un r√©seau neuronal monocouche pour reconna√Ætre les nombres manuscrits, comme le montre le diagramme suivant: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2d6/bf4/585/2d6bf4585be28678f66652fd77ecb2f8.png"><br><br>  Si l'image est une grille de 28x28 pixels en √©chelle de gris, elle peut √™tre convertie en un vecteur de 784 valeurs (mesures).  Un neurone qui reconna√Æt le nombre 8 prend ces valeurs et les multiplie par les valeurs des param√®tres (lignes rouges dans le diagramme). <br><br>  Le param√®tre fonctionne comme un filtre, extrayant les caract√©ristiques des donn√©es qui indiquent la similitude de l'image et de la forme 8: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/020/141/559/0201415596ab1132ba07a3b430a2fa34.gif"><br><br>  C'est l'explication la plus simple de la classification des donn√©es par les r√©seaux de neurones.  Multiplication des donn√©es avec les param√®tres qui leur correspondent (coloration des points) et leur addition (somme des points √† droite).  Le r√©sultat le plus √©lev√© indique la meilleure correspondance entre les donn√©es saisies et le param√®tre correspondant, qui, tr√®s probablement, sera la bonne r√©ponse. <br><br>  En termes simples, les r√©seaux de neurones doivent effectuer un grand nombre de multiplications et d'ajouts de donn√©es et de param√®tres.  Nous les organisons souvent sous forme de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">multiplication matricielle</a> , que vous pourriez rencontrer en alg√®bre √† l'√©cole.  Par cons√©quent, le probl√®me est d'effectuer un grand nombre de multiplications matricielles aussi rapidement que possible, en d√©pensant le moins d'√©nergie possible. <br><br><h2>  Comment fonctionne un CPU? </h2><br>  Comment le CPU aborde-t-il cette t√¢che?  Le CPU est un processeur polyvalent bas√© sur l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">architecture von Neumann</a> .  Cela signifie que le CPU fonctionne avec le logiciel et la m√©moire comme suit: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/963/029/620/96302962031a0a23ecf34b868d194161.gif"><br><br>  Le principal avantage du CPU est sa flexibilit√©.  Gr√¢ce √† l'architecture von Neumann, vous pouvez t√©l√©charger des logiciels compl√®tement diff√©rents pour des millions de fins diff√©rentes.  Le CPU peut √™tre utilis√© pour le traitement de texte, le contr√¥le du moteur de fus√©e, les transactions bancaires, la classification d'images √† l'aide d'un r√©seau de neurones. <br><br>  Mais comme le CPU est si flexible, l'√©quipement ne sait pas toujours √† l'avance quelle sera la prochaine op√©ration jusqu'√† ce qu'il lise la prochaine instruction du logiciel.  Le CPU a besoin de stocker les r√©sultats de chaque calcul dans la m√©moire situ√©e √† l'int√©rieur du CPU (les soi-disant registres, ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cache L1</a> ).  L'acc√®s √† cette m√©moire devient un inconv√©nient de l'architecture CPU, connue sous le nom de goulot d'√©tranglement de l'architecture von Neumann.  Et bien qu'une √©norme quantit√© de calculs pour les r√©seaux de neurones rend les √©tapes futures pr√©visibles, chaque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">p√©riph√©rique logique arithm√©tique du</a> CPU (ALU, un composant qui stocke et contr√¥le les multiplicateurs et les additionneurs) effectue des op√©rations s√©quentiellement, acc√©dant √† la m√©moire √† chaque fois, ce qui limite le d√©bit global et consomme une quantit√© importante d'√©nergie . <br><br><h2>  Comment fonctionne le GPU </h2><br>  Pour augmenter le d√©bit par rapport au CPU, le GPU utilise une strat√©gie simple: pourquoi ne pas int√©grer des milliers d'ALU dans le processeur?  Le GPU moderne contient environ 2500 √† 5000 ALU sur le processeur, ce qui permet d'effectuer des milliers de multiplications et d'ajouts √† la fois. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fbb/bcb/17b/fbbbcb17b7732e20d2658d5e76023beb.gif"><br><br>  Une telle architecture fonctionne bien avec des applications n√©cessitant une parall√©lisation massive, comme par exemple la multiplication matricielle dans un r√©seau neuronal.  Avec une charge de formation typique d'apprentissage en profondeur (GO), le d√©bit dans ce cas augmente d'un ordre de grandeur par rapport au CPU.  Par cons√©quent, le GPU est aujourd'hui l'architecture de processeur la plus populaire pour GO. <br><br>  Mais le GPU reste un processeur polyvalent qui doit prendre en charge un million d'applications et de logiciels diff√©rents.  Et cela nous ram√®ne au probl√®me fondamental du goulot d'√©tranglement de l'architecture von Neumann.  Pour chaque calcul en milliers d'ALU, GPU, il est n√©cessaire de se r√©f√©rer aux registres ou √† la m√©moire partag√©e afin de lire et sauvegarder les r√©sultats de calcul interm√©diaires.  √âtant donn√© que le GPU effectue plus de calcul parall√®le sur des milliers de ses ALU, il d√©pense √©galement proportionnellement plus d'√©nergie pour acc√©der √† la m√©moire et occupe une grande surface. <br><br><h2>  Comment fonctionne le TPU? </h2><br>  Lorsque nous avons d√©velopp√© TPU chez Google, nous avons construit une architecture con√ßue pour une t√¢che sp√©cifique.  Au lieu de d√©velopper un processeur polyvalent, nous avons d√©velopp√© un processeur matriciel sp√©cialis√© pour travailler avec les r√©seaux de neurones.  Le TPU ne pourra pas fonctionner avec un traitement de texte, contr√¥ler des moteurs de fus√©e ou effectuer des transactions bancaires, mais il peut traiter un grand nombre de multiplications et d'ajouts pour les r√©seaux de neurones √† une vitesse incroyable, tout en consommant beaucoup moins d'√©nergie et en s'adaptant √† un volume physique plus petit. <br><br>  La principale chose qui lui permet de le faire est l'√©limination radicale du goulot d'√©tranglement de l'architecture von Neumann.  √âtant donn√© que la t√¢che principale du TPU est le traitement matriciel, les d√©veloppeurs de circuits connaissaient toutes les √©tapes de calcul n√©cessaires.  Par cons√©quent, ils ont pu placer des milliers de multiplicateurs et d'additionneurs et les connecter physiquement, formant une grande matrice physique.  C'est ce qu'on appelle l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">architecture de r√©seau en pipeline</a> .  Dans le cas de Cloud TPU v2, deux matrices de pipeline de 128 x 128 sont utilis√©es, ce qui donne au total 32 768 ALU pour des valeurs √† virgule flottante 16 bits sur un processeur. <br><br>  Voyons comment un tableau en pipeline effectue des calculs pour un r√©seau de neurones.  Tout d'abord, le TPU charge les param√®tres de la m√©moire dans une matrice de multiplicateurs et d'additionneurs. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9ec/de3/fc6/9ecde3fc6d69116db89aacd83bdf15e5.gif"><br><br>  Le TPU charge ensuite les donn√©es de la m√©moire.  √Ä la fin de chaque multiplication, le r√©sultat est transmis aux facteurs suivants, tout en effectuant des ajouts.  Par cons√©quent, la sortie sera la somme de toutes les multiplications des donn√©es et des param√®tres.  Tout au long du processus de calcul volum√©trique et de transfert de donn√©es, l'acc√®s √† la m√©moire est totalement inutile. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/04a/ef8/b31/04aef8b31b8eb550ba093df4eb811d58.gif"><br><br>  Par cons√©quent, TPU d√©montre un d√©bit sup√©rieur lors du calcul pour les r√©seaux de neurones, consommant beaucoup moins d'√©nergie et occupant moins d'espace. <br><br><h2>  Avantage: 5 fois moins cher </h2><br>  Quels sont les avantages de l'architecture TPU?  Co√ªt.  Voici le co√ªt de Cloud TPU v2 pour ao√ªt 2018, au moment de la r√©daction: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e2f/340/d86/e2f340d861ef00ac9ceac0e7d6dc5f24.png"><br>  Co√ªt de travail normal et TPU pour diff√©rentes r√©gions de Google Cloud <br><br>  L'Universit√© de Stanford distribue un ensemble de tests <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DAWNBench</a> qui mesurent les performances des syst√®mes d'apprentissage en profondeur.  Vous pouvez y voir diff√©rentes combinaisons de t√¢ches, mod√®les et plates-formes informatiques, ainsi que les r√©sultats des tests correspondants. <br><br>  Au moment de la fin du concours en avril 2018, le co√ªt minimum de formation sur les processeurs avec une architecture autre que TPU √©tait de 72,40 $ (pour la formation ResNet-50 avec une pr√©cision de 93% sur ImageNet sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des instances ponctuelles</a> ).  Avec Cloud TPU v2, cette formation peut √™tre effectu√©e pour 12,87 $.  C'est moins de 1/5 du co√ªt.  Telle est la puissance de l'architecture con√ßue sp√©cifiquement pour les r√©seaux de neurones. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr422317/">https://habr.com/ru/post/fr422317/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr422303/index.html">Meilleur constructeur SQL - utilisez jOOQ sur Android</a></li>
<li><a href="../fr422305/index.html">R√©partition du nombre de travailleurs russes par salaire sur la base d'une grande enqu√™te en ligne sur une plateforme non sp√©cialis√©e</a></li>
<li><a href="../fr422309/index.html">Comment prot√©ger les donn√©es dans les r√©seaux de neurones cloud - une nouvelle m√©thode de cryptage est propos√©e</a></li>
<li><a href="../fr422311/index.html">Int√©ressant et utilit√© de python. 2e partie</a></li>
<li><a href="../fr422315/index.html">Comment survivre √† un chasseur d'insectes: lutte quotidienne pour le revenu</a></li>
<li><a href="../fr422319/index.html">Pour la premi√®re fois, l'√©quipe russe est entr√©e dans le plus grand acc√©l√©rateur scientifique IndieBio</a></li>
<li><a href="../fr422321/index.html">Optimisation du travail avec des prototypes dans les moteurs JavaScript</a></li>
<li><a href="../fr422323/index.html">Hackers: Russie et Chine</a></li>
<li><a href="../fr422325/index.html">DevDay √† propos des tests: D√©tendez-vous. Testez-le facilement</a></li>
<li><a href="../fr422327/index.html">Calendrier du projet vs backlog: bataille sans chance</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
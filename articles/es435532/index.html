<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üò∫ üíö üíπ Tornado vs Aiohttp: un viaje a la naturaleza de los marcos asincr√≥nicos üö¢ ‚õàÔ∏è üë®‚Äçüé®</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola Soy Dima, y ‚Äã‚Äãhe estado sentada en Python desde hace bastante tiempo. Hoy quiero mostrarles las diferencias entre dos marcos asincr√≥nicos: Tornad...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tornado vs Aiohttp: un viaje a la naturaleza de los marcos asincr√≥nicos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/avito/blog/435532/">  Hola  Soy Dima, y ‚Äã‚Äãhe estado sentada en Python desde hace bastante tiempo.  Hoy quiero mostrarles las diferencias entre dos marcos asincr√≥nicos: Tornado y Aiohttp.  Contar√© la historia de la elecci√≥n entre los marcos en nuestro proyecto, c√≥mo difieren las corutinas en Tornado y AsyncIO, mostrar√© puntos de referencia y dar√© algunos consejos √∫tiles sobre c√≥mo entrar en la naturaleza de los marcos y salir con √©xito de all√≠. <br><br><img src="https://habrastorage.org/webt/df/uz/jm/dfuzjmbmzyoqjfd87asllltamtk.png"><br><a name="habracut"></a><br>  Como saben, Avito es un servicio de publicidad bastante grande.  Tenemos muchos datos y cargas, 35 millones de usuarios cada mes y 45 millones de anuncios activos diariamente.  Trabajo como asesor t√©cnico de un grupo de desarrollo de recomendaciones.  Mi equipo escribe microservicios, ahora tenemos unos veinte.  Se est√° acumulando una carga en todo esto, como 5k RPS. <br><br><h2>  Elegir un marco asincr√≥nico </h2><br>  Primero te dir√© c√≥mo terminamos donde estamos ahora.  En 2015, necesit√°bamos elegir un marco asincr√≥nico, porque sab√≠amos: <br><br><ul><li>  que tiene que hacer muchas solicitudes a otros microservicios: http, json, rpc; </li><li>  que necesitar√° recopilar datos de diferentes fuentes todo el tiempo: Redis, Postgres, MongoDB. </li></ul><br>  Por lo tanto, tenemos muchas tareas de red, y la aplicaci√≥n est√° ocupada principalmente con entrada / salida.  La versi√≥n actual de python en ese momento era 3.4, as√≠ncrono y en espera a√∫n no aparec√≠a.  Aiohttp tambi√©n fue - en la versi√≥n 0.x.  El Tornado As√≠ncrono de Facebook apareci√≥ en 2010.  Muchos de los controladores de bases de datos est√°n escritos para √©l que necesitamos.  Tornado mostr√≥ resultados estables en los puntos de referencia.  Luego detuvimos nuestra elecci√≥n en este marco. <br><br>  Tres a√±os despu√©s, entendimos mucho. <br><br>  Primero, Python 3.5 sali√≥ con mec√°nica as√≠ncrona / espera.  Descubrimos cu√°l es la diferencia entre el rendimiento y el rendimiento y c√≥mo Tornado es consistente con esperar (spoiler: no muy bueno). <br>  En segundo lugar, nos encontramos con extra√±os problemas de rendimiento con una gran cantidad de rutina en el programador, incluso cuando la CPU no est√° completamente ocupada. <br>  En tercer lugar, descubrimos que al realizar una gran cantidad de solicitudes http a otros servicios de Tornado, debe ser especialmente amigable con la resoluci√≥n as√≠ncrona de DNS, no respeta los tiempos de espera para establecer una conexi√≥n y enviar la solicitud que especificamos.  Y, en general, el mejor m√©todo para realizar solicitudes http en Tornado es curl, lo cual es bastante extra√±o en s√≠ mismo. <br><br>  En su <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">charla en PyCon Rusia 2018,</a> Andrei Svetlov dijo: ‚ÄúSi quieres escribir alg√∫n tipo de aplicaci√≥n web as√≠ncrona, solo escribe as√≠ncrono, espera.  Event loop, probablemente, no lo necesitar√° en absoluto pronto.  No entre en la naturaleza de los marcos para no confundirse.  No uses primitivas de bajo nivel, y todo estar√° bien contigo ... ".  En los √∫ltimos tres a√±os, lamentablemente, hemos tenido que subir al interior del Tornado con bastante frecuencia, aprender muchas cosas interesantes desde all√≠ y ver trazas gigantes para 30-40 llamadas. <br><br><h2>  Rendimiento vs rendimiento de </h2><br>  Uno de los mayores problemas para entender en Python as√≠ncrono es la diferencia entre rendimiento y rendimiento. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Guido Van Rossum escribi√≥</a> m√°s sobre esto.  Adjunto la traducci√≥n con ligeras abreviaturas. <br><blockquote>  Me han preguntado varias veces por qu√© PEP 3156 insiste en usar el rendimiento desde en lugar del rendimiento, lo que elimina la posibilidad de hacer backport en Python 3.2 o incluso 2.7. <br>  (...) <br>  cada vez que quieres un resultado futuro, usas rendimiento. <br>  Esto se implementa de la siguiente manera.  La funci√≥n que contiene el rendimiento es (obviamente) un generador, por lo que debe haber alg√∫n tipo de c√≥digo iterativo.  Vamos a llamarlo un planificador.  De hecho, el planificador no "itera" en el sentido cl√°sico (con for-loop);  en su lugar, admite dos colecciones futuras. <br><br>  Llamar√© a la primera colecci√≥n una secuencia "ejecutable".  Este es el futuro, cuyos resultados est√°n disponibles.  Si bien esta lista no est√° vac√≠a, el planificador selecciona un elemento y realiza un paso de iteraci√≥n.  Este paso llama al m√©todo generador .send () con el resultado del futuro (que pueden ser datos que se acaban de leer desde el socket);  en el generador, este resultado aparece como el valor de retorno de la expresi√≥n de rendimiento.  Cuando send () devuelve un resultado o se completa, el planificador analiza el resultado (que puede ser StopIteration, otra excepci√≥n o alg√∫n tipo de objeto). <br>  (Si est√° confundido, probablemente deber√≠a leer sobre c√≥mo funcionan los generadores, en particular, el m√©todo .send (). Quiz√°s PEP 342 es un buen punto de partida). <br><br>  (...) <br><br>  La segunda colecci√≥n futura que admite el planificador consiste en el futuro, que todav√≠a est√° esperando E / S.  De alguna manera se pasan a select / poll / shell, etc.  que devuelve la llamada cuando el descriptor de archivo est√° listo para E / S.  La devoluci√≥n de llamada realmente realiza la operaci√≥n de E / S solicitada por futuro, establece el valor futuro resultante al resultado de la operaci√≥n de E / S y mueve el futuro a la cola de ejecuci√≥n. <br><br>  (...) <br><br>  Ahora hemos llegado a lo m√°s interesante.  Supongamos que est√° escribiendo un protocolo complejo.  Dentro de su protocolo, lee bytes de un socket utilizando el m√©todo recv ().  Estos bytes llegan al b√∫fer.  El m√©todo recv () est√° envuelto en un shell as√≠ncrono, que establece la E / S y devuelve el futuro, que se ejecuta cuando se completa la E / S, como expliqu√© anteriormente.  Ahora suponga que alguna otra parte de su c√≥digo desea leer datos del b√∫fer una l√≠nea a la vez.  Suponga que us√≥ el m√©todo readline ().  Si el tama√±o del b√∫fer es mayor que la longitud de l√≠nea promedio, su m√©todo readline () simplemente puede obtener la siguiente l√≠nea del b√∫fer sin bloquear;  pero a veces el b√∫fer no contiene una l√≠nea completa, y readline () a su vez llama a recv () en el z√≥calo. <br><br>  Pregunta: ¬ødeber√≠a readline () regresar futuro o no?  No ser√≠a muy bueno si a veces devolviera una cadena de bytes y, a veces, en el futuro, obligando a la persona que llama a realizar una verificaci√≥n de tipo y rendimiento condicional.  Entonces la respuesta es que readline () siempre debe regresar en el futuro.  Cuando se llama a readline (), comprueba el b√∫fer y, si encuentra al menos una l√≠nea completa all√≠, crea un futuro, establece el resultado futuro de una l√≠nea tomada del b√∫fer y devuelve el futuro.  Si el b√∫fer no tiene una l√≠nea completa, inicia E / S y lo espera, y cuando se completa la E / S, comienza de nuevo. <br><br>  (...) <br><br>  Pero ahora estamos creando muchos futuros que no requieren el bloqueo de E / S, pero que a√∫n fuerzan una llamada al planificador, porque readline () devuelve el futuro, se requiere rendimiento de la persona que llama, y ‚Äã‚Äãeso significa una llamada al planificador. <br>  El planificador puede transferir el control directamente a la rutina si ve que se muestra el futuro, que ya se ha completado, o puede devolver el futuro a la cola de ejecuci√≥n.  Este √∫ltimo ralentizar√° en gran medida el trabajo (siempre que haya m√°s de una rutina ejecutable), ya que no solo se requiere esperar al final de la cola, sino que tambi√©n se pierde la localidad de la memoria (si es que existe). <br><br>  (...) <br><br>  El efecto neto de todo esto es que los autores de rutina necesitan saber sobre el rendimiento futuro y, por lo tanto, existe una mayor barrera psicol√≥gica para reorganizar el c√≥digo complejo en corutinas m√°s legibles, mucho m√°s fuerte que la resistencia existente, porque las llamadas a funciones en Python son bastante lentas.  Y recuerdo de una conversaci√≥n con Glyph que la velocidad es importante en una estructura de E / S as√≠ncrona t√≠pica. <br>  Ahora comparemos esto con el rendimiento de. <br><br>  (...) <br><br>  Es posible que haya escuchado que "rendimiento de S" es m√°s o menos equivalente a "para i en S: rendimiento i".  En el caso m√°s simple, esto es cierto, pero esto no es suficiente para entender la rutina.  Considere lo siguiente (no piense en E / S as√≠ncrona todav√≠a): <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">driver</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(g)</span></span></span><span class="hljs-function">:</span></span> print(next(g)) g.send(<span class="hljs-number"><span class="hljs-number">42</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen1</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> val = <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-string"><span class="hljs-string">'okay'</span></span> print(val) driver(gen1())</code> </pre> <br>  Este c√≥digo imprime dos l√≠neas que contienen "okay" y "42" (y luego produce una StopIteration no controlada, que puede suprimir agregando rendimiento al final de gen1).  Puede ver este c√≥digo en acci√≥n en pythontutor.com en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> . <br><br>  Ahora considere lo siguiente: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> gen1() driver(gen2())</code> </pre><br>  Funciona <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">exactamente de la misma manera</a> .  Ahora piensa.  Como funciona  Aqu√≠ no se puede usar la extensi√≥n de rendimiento simple en el ciclo for, ya que en este caso el c√≥digo devolver√≠a None.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">(Pru√©balo)</a>  Yield-from act√∫a como un "canal transparente" entre driver y gen1.  Es decir, cuando gen1 da el valor "est√° bien", sale de gen2, a trav√©s del rendimiento desde, al controlador, y cuando el controlador env√≠a 42 de vuelta a gen2, este valor se devuelve a trav√©s del rendimiento desde a gen1 nuevamente (donde se convierte en el resultado del rendimiento ) <br><br>  Lo mismo suceder√≠a si el conductor arrojara un error en el generador: el error pasa por el rendimiento desde el generador interno que lo procesa.  Por ejemplo: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">throwing_driver</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(g)</span></span></span><span class="hljs-function">:</span></span> print(next(g)) g.throw(RuntimeError(<span class="hljs-string"><span class="hljs-string">'booh'</span></span>)) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen1</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: val = <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-string"><span class="hljs-string">'okay'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> RuntimeError <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> exc: print(exc) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: print(val) <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> throwing_driver(gen1())</code> </pre><br>  El c√≥digo dar√° "okay" y "bah", as√≠ como el siguiente c√≥digo: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> gen1() <span class="hljs-comment"><span class="hljs-comment"># unchanged throwing_driver(gen2())</span></span></code> </pre> <br>  (Ver aqu√≠: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">goo.gl/8tnjk</a> ) <br><br>  Ahora me gustar√≠a presentar gr√°ficos simples (ASCII) para poder hablar sobre este tipo de c√≥digo.  Utilizo [f1 -&gt; f2 -&gt; ... -&gt; fN) para representar la pila con f1 en la parte inferior (marco de llamada m√°s antiguo) y fN en la parte superior (marco de llamada m√°s reciente), donde cada elemento de la lista es un generador, y -&gt; son rendimientos de .  El primer ejemplo, driver (gen1 ()) no tiene rendimiento de, pero tiene un generador gen1, por lo que se ve as√≠: <br><br><pre> <code class="python hljs">[ gen1 )</code> </pre> <br>  En el segundo ejemplo, gen2 llama a gen1 usando el rendimiento desde, por lo que se ve as√≠: <br><br><pre> <code class="python hljs">[ gen2 -&gt; gen1 )</code> </pre> <br>  Utilizo la notaci√≥n matem√°tica para el intervalo medio abierto [...) para mostrar que se puede agregar otro cuadro a la derecha cuando el generador m√°s a la derecha usa el rendimiento desde para llamar a otro generador, mientras que el extremo izquierdo est√° m√°s o menos fijo.  El final izquierdo es lo que ve el controlador (es decir, el planificador). <br><br>  Ahora estoy listo para volver al ejemplo de readline ().  Podemos reescribir readline () como un generador que llama a read (), otro generador que usa yield-from;  este √∫ltimo, a su vez, llama a recv (), que realiza la entrada / salida real desde el socket.  A nuestra izquierda est√° la aplicaci√≥n, que tambi√©n consideramos como un generador que llama a readline (), nuevamente usando el rendimiento desde.  El esquema es el siguiente: <br><br><pre> <code class="python hljs">[ app -&gt; readline -&gt; read -&gt; recv )</code> </pre> <br>  Ahora el generador recv () establece E / S, lo une al futuro y lo pasa al planificador usando * yield * (¬°no rendimiento-desde!).  El futuro va a la izquierda a lo largo de ambas flechas de rendimiento en el programador (ubicado a la izquierda de "[").  Tenga en cuenta que el planificador no sabe que contiene una pila de generadores;  todo lo que sabe es que contiene el generador m√°s a la izquierda y que acaba de emitir un futuro.  Cuando se completa la E / S, el planificador establece el resultado futuro y lo env√≠a de vuelta al generador;  el resultado se mueve hacia la derecha en ambas flechas desde el generador de recepci√≥n, que recibe los bytes que quer√≠a leer desde el socket como resultado del rendimiento. <br><br>  En otras palabras, el planificador de marco de rendimiento desde maneja las operaciones de E / S al igual que el planificador de marco basado en rendimiento que describ√≠ anteriormente.  * Pero: * no necesita preocuparse por la optimizaci√≥n cuando el futuro ya est√° ejecutado, ya que el programador no participa en la transferencia de control entre readline () y read () o entre read () y recv (), y viceversa.  Por lo tanto, el planificador no participa en absoluto cuando app () llama a readline (), y readline () puede satisfacer la solicitud del b√∫fer (sin llamar a read ()) - la interacci√≥n entre app () y readline () en este caso es procesada completamente por el int√©rprete de bytecode Pit√≥n  El programador puede ser m√°s simple, y el n√∫mero de futuros creados y administrados por el programador es menor, porque no hay futuros que se creen y destruyan con cada llamada de rutina.  El √∫nico futuro que a√∫n se necesita son aquellos que representan la E / S real, por ejemplo, creada por recv (). <br><br>  Si has le√≠do hasta este punto, mereces una recompensa.  Omit√≠ muchos detalles de implementaci√≥n, pero la ilustraci√≥n anterior refleja esencialmente la imagen correctamente. <br><br>  Otra cosa que me gustar√≠a se√±alar.  * Puede * hacer que parte del c√≥digo use el rendimiento de, y la otra parte use el rendimiento.  Pero el rendimiento requiere que cada eslab√≥n de la cadena tenga un futuro, no solo una rutina.  Dado que existen varias ventajas al usar el rendimiento desde, quiero que el usuario no tenga que recordar cu√°ndo usar el rendimiento, y cuando el rendimiento desde, es m√°s f√°cil usar siempre el rendimiento desde.  Una soluci√≥n simple incluso permite que recv () utilice el rendimiento desde para pasar E / S futuras al planificador: el m√©todo __iter__ es en realidad el generador que emite el futuro. <br><br>  (...) <br><br>  Y una cosa m√°s.  ¬øQu√© valor produce el rendimiento del rendimiento?  Resulta que este es el valor de retorno del generador * externo *. <br><br>  (...) <br><br>  Por lo tanto, mientras las flechas unen los cuadros izquierdo y derecho al objetivo * que rinde *, tambi√©n pasan los valores de retorno habituales de la manera habitual, un cuadro de pila a la vez.  Las excepciones se mueven de la misma manera;  por supuesto, en cada nivel, se requiere try / except para atraparlos. <br></blockquote>  Resulta que el rendimiento es m√°s o menos lo mismo que esperar. <br><br><h2>  rendimiento de vs as√≠ncrono </h2><br><table><tbody><tr><td><p>  def coro () ^ </p><p>  y = rendimiento de a </p></td><td>  async def async_coro (): <p>  y = espera un </p></td></tr><tr><td>  0 load_global </td><td>  0 load_global </td></tr><tr><td>  2 get_yield_from_iter </td><td><p>  2 get_awaitable </p></td></tr><tr><td>  4 load_const </td><td><p>  4 load_const </p></td></tr><tr><td>  6 rendimiento_de </td><td>  6 rendimiento_de </td></tr><tr><td>  8 store_fast </td><td><p>  8 store_fast </p></td></tr><tr><td>  10 load_const </td><td>  10 load_const <br></td></tr><tr><td>  12 return_value </td><td>  12 return_value </td></tr></tbody></table><br><br>  Las dos corutinas de las viejas y nuevas escuelas tienen solo una peque√±a diferencia: obtener rendimiento de iter frente a esperar. <br><br>  ¬øPor qu√© es todo esto?  Tornado usa un rendimiento simple.  Antes de la versi√≥n 5, conecta toda esta cadena de llamadas a trav√©s del rendimiento, que es poco compatible con el nuevo paradigma de rendimiento / espera fresco. <br><br><h2>  El punto de referencia asincr√≥nico m√°s simple </h2><br>  Es dif√≠cil encontrar un marco realmente bueno, eligi√©ndolo solo de acuerdo con pruebas sint√©ticas.  En la vida real, muchas cosas pueden salir mal. <br><br>  Tom√© Aiohttp versi√≥n 3.4.4, Tornado 5.1.1, uvloop 0.11, tom√© el procesador del servidor Intel Xeon, CPU E5 v4, 3.6 GHz, y con Python 3.6.5 comenc√© a verificar la competitividad de los servidores web. <br><br>  El problema t√≠pico que resolvemos con la ayuda de microservicios, y que funciona en modo as√≠ncrono, se ve as√≠.  Recibiremos solicitudes.  Para cada uno de ellos haremos una solicitud a alg√∫n microservicio, obtendremos datos de all√≠, luego iremos a otros dos o tres microservicios, tambi√©n de forma as√≠ncrona, luego escribiremos los datos en alg√∫n lugar de la base de datos y devolveremos el resultado.  Resulta muchos puntos donde esperaremos. <br><br>  Llevamos a cabo una operaci√≥n m√°s simple.  Encendemos el servidor, lo hacemos dormir 50 ms.  Crea una rutina y compl√©tala.  No tendremos un RPS muy grande (puede que no sea un orden de magnitud similar a lo que se ve en los puntos de referencia completamente sint√©ticos) con un retraso aceptable debido al hecho de que mucha corutina girar√° simult√°neamente en un servidor competitivo. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@tornado.gen.coroutine def old_school_work(): yield tornado.gen.sleep(SLEEP_TIME) async def work(): await tornado.gen.sleep(SLEEP_TIME)</span></span></code> </pre> <br>  Cargar: OBTENER solicitudes http.  Duraci√≥n - 300s, 1s - calentamiento, 5 repeticiones de la carga. <br><br><img src="https://habrastorage.org/webt/ep/mq/fw/epmqfwh6bv_vyfu8tymtelvohos.png"><br><br>  <i>Resultados en percentiles del tiempo de respuesta del servicio.</i> <br><br><div class="spoiler">  <b class="spoiler_title">¬øQu√© son los percentiles?</b> <div class="spoiler_text">  Tienes una gran cantidad de n√∫meros.  El percentil 95 X significa que el 95% de los valores en esta muestra son menores que X. Con una probabilidad del 5%, su n√∫mero ser√° mayor que X. <br></div></div><br>  Vemos que Aiohttp hizo un buen trabajo a 1000 RPS en una prueba tan simple.  Todo hasta ahora sin <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">uvloop</a> . <br><br>  Compare Tornado con las rutinas de las escuelas antiguas (rendimiento) y nuevas (as√≠ncronas).  Los autores recomiendan usar as√≠ncrono.  Podemos asegurarnos de que sean mucho m√°s r√°pidos. <br><br>  A las 1200 RPS, Tornado, incluso con las nuevas corutinas de la escuela, ya est√° comenzando a rendirse, y Tornado con las corutinas de la vieja escuela est√° completamente impresionado.  Si dormimos durante 50 ms, y el microservicio es responsable de 80 ms, esto no entra en ninguna puerta. <br><br>  La nueva escuela de Tornado a 1,500 RPS se ha rendido por completo, mientras que Aiohttp a√∫n est√° lejos del l√≠mite de 3,000 RPS.  Lo m√°s interesante est√° por venir. <br><br><h2>  Pyflame, perfilando un microservicio en funcionamiento </h2><br>  Veamos qu√© est√° pasando en este momento con el procesador. <br><br><img src="https://habrastorage.org/webt/mw/-6/c-/mw-6c-vzw_kk-flygqeig93qohe.png"><br><br>  Cuando descubrimos c√≥mo funcionan los microservicios asincr√≥nicos de Python en la producci√≥n, tratamos de entender en qu√© se topaba todo.  En la mayor√≠a de los casos, el problema estaba en la CPU o en los descriptores.  Hay una gran herramienta de creaci√≥n de perfiles creada en Uber, el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">generador de</a> perfiles <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Pyflame</a> , que se basa en la llamada al sistema ptrace. <br><br>  Comenzamos alg√∫n servicio en el contenedor y comenzamos a lanzar una carga de combate sobre √©l.  A menudo, esta no es una tarea muy trivial: crear tal carga que est√° en batalla, porque a menudo sucede que ejecutas pruebas sint√©ticas en pruebas de carga, mira y todo funciona bien.  Empujas la carga de combate sobre √©l, y aqu√≠ el microservicio comienza a disminuir. <br><br>  Durante la operaci√≥n, este generador de perfiles hace instant√°neas de la pila de llamadas por nosotros.  No puede cambiar el servicio en absoluto, solo ejecute pyflame cerca.  Recopilar√° un rastro de la pila una vez en un cierto per√≠odo de tiempo, y luego har√° una visualizaci√≥n genial.  Este generador de perfiles proporciona muy poca sobrecarga, especialmente cuando se compara con cProfile.  Pyflame tambi√©n admite programas multiproceso.  Lanzamos esto directamente en el producto, y el rendimiento no se degrad√≥ mucho. <br><br><img src="https://habrastorage.org/webt/pk/2s/lu/pk2slutzgqe-szo4mbefnk_zoqe.png"><br><br>  Aqu√≠, el eje X es la cantidad de tiempo, el n√∫mero de llamadas, cuando el marco de la pila estaba en la lista de todos los marcos de la pila Python.  Esta es la cantidad aproximada de tiempo de procesador que pasamos en este marco particular de la pila. <br><br>  Como puede ver, aqu√≠ la mayor parte del tiempo en aiohttp pasa a inactivo.  Bien: esto es lo que queremos de un servicio as√≠ncrono para que se ocupe de las llamadas de red la mayor parte del tiempo.  La profundidad de la pila en este caso es de aproximadamente 15 cuadros. <br><br>  En Tornado (segunda imagen) con la misma carga, se gasta mucho menos tiempo en inactivo y la profundidad de la pila en este caso es de aproximadamente 30 fotogramas. <br><br>  Aqu√≠ hay un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace a svg</a> , puede torcerse usted mismo. <br><br><h2>  Punto de referencia asincr√≥nico m√°s complejo </h2><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">work</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#     await asyncio.sleep(SLEEP_TIME) class HardWorkHandler(tornado.web.RequestHandler): timeout_time = datetime.timedelta(seconds=SLEEP_TIME / 2) async def get(self): await work() #     await tornado.gen.multi([work(), work()]) #     try: await tornado.gen.with_timeout(self.timeout_time, work()) except tornado.util.TimeoutError: #     pass</span></span></code> </pre><br>  Espere un tiempo de ejecuci√≥n de 125 ms. <br><br><img src="https://habrastorage.org/webt/i2/u5/3d/i2u53d-v1qhpmgkqiifa6q8rita.png"><br><br>  Tornado con uvloop aguanta mejor.  Pero Aiohttp uvloop ayuda mucho m√°s.  Aiohttp comienza a comportarse mal en 2300-2400 RPS, y con uvloop expande significativamente el rango de carga.  Una l√≠nea de importaci√≥n, y ahora tiene un servicio mucho m√°s productivo. <br><br><h2>  Resumen </h2><br>  Resumir√© lo que quer√≠a transmitirles hoy. <br><br><ul><li>  En primer lugar, lanc√© un determinado punto de referencia artificial, donde hab√≠a una cantidad decente de larga rutina.  En nuestra prueba, Aiohttp se desempe√±√≥ mejor 2.5 veces que Tornado. </li><li>  El segundo hecho.  Uvloop muy bien ayuda a mejorar el rendimiento de Aiohttp (mejor que Tornado). </li><li>  Te cont√© sobre Pyflame, con el que a menudo perfilamos la aplicaci√≥n directamente en producci√≥n. </li><li>  Y tambi√©n hablamos sobre el rendimiento de (espera) versus rendimiento. </li></ul><br>  Como resultado de estos puntos de referencia, nuestro equipo de recomendaciones (y algunos otros) se traslad√≥ casi por completo a Aiohttp con Tornado para microservicios en Python en producci√≥n. <br><br><ul><li>  Para los servicios de combate, el consumo de CPU se redujo en m√°s de 2 veces. </li><li>  Comenzamos a respetar los tiempos de espera para las solicitudes http. </li><li>  Los servicios de latencia cayeron de 2 a 5 veces. </li></ul><br>  Aqu√≠ hay un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace al punto de referencia</a> .  Si est√° interesado, puede repetirlo.  Gracias a todos por su atenci√≥n.  Haga preguntas, tratar√© de responderlas. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es435532/">https://habr.com/ru/post/es435532/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es435520/index.html">Escribimos nuestro lenguaje de programaci√≥n, parte 3: Arquitectura del traductor. An√°lisis de estructuras del lenguaje y expresiones matem√°ticas.</a></li>
<li><a href="../es435522/index.html">Instant√°neas de eventos en Axonframework 3, mejorando el rendimiento</a></li>
<li><a href="../es435526/index.html">Aventuras con un grupo de Kubernetes casero</a></li>
<li><a href="../es435528/index.html">5 razones para el √©xito: por qu√© Amazon se ha convertido en la empresa m√°s cara del mundo</a></li>
<li><a href="../es435530/index.html">Suscripciones pagas: dependencia de la conexi√≥n autom√°tica en un dispositivo m√≥vil</a></li>
<li><a href="../es435534/index.html">Ciencia de datos: libros de nivel b√°sico</a></li>
<li><a href="../es435536/index.html">Robots humanoides: beneficios y problemas de los mecanismos antropom√≥rficos.</a></li>
<li><a href="../es435538/index.html">En 2018, se recibi√≥ m√°s energ√≠a "verde" en Alemania que la electricidad de la combusti√≥n de carb√≥n</a></li>
<li><a href="../es435540/index.html">Nuevas palabras clave en Java</a></li>
<li><a href="../es435542/index.html">Desarrollo del juego y defensa de un diploma o "C√≥mo mat√© a dos p√°jaros con un primer panqueque de piedra"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úåÔ∏è üßùüèæ ü§ê Apache NiFi: de quoi s'agit-il et un bref aper√ßu des fonctionnalit√©s üèì üë≤üèæ ü§õüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Aujourd'hui, sur les sites th√©matiques √©trangers sur le Big Data, vous pouvez trouver une mention d'un outil relativement nouveau pour l'√©cosyst√®me Ha...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apache NiFi: de quoi s'agit-il et un bref aper√ßu des fonctionnalit√©s</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/rostelecom/blog/432166/">  Aujourd'hui, sur les sites th√©matiques √©trangers sur le Big Data, vous pouvez trouver une mention d'un outil relativement nouveau pour l'√©cosyst√®me Hadoop comme Apache NiFi.  Il s'agit d'un outil ETL open source moderne.  Architecture distribu√©e pour un chargement parall√®le et un traitement des donn√©es rapides, un grand nombre de plug-ins pour les sources et les transformations, le versionnage des configurations ne sont qu'une partie de ses avantages.  Avec toute sa puissance, NiFi reste assez simple √† utiliser. <br><br><img src="https://habrastorage.org/webt/9b/zs/ri/9bzsrib2emb_rcdq1cj-d8nubbe.png" alt="image"><br><br>  Chez Rostelecom, nous nous effor√ßons de d√©velopper le travail avec Hadoop, nous avons donc d√©j√† essay√© et √©valu√© les avantages d'Apache NiFi par rapport √† d'autres solutions.  Dans cet article, je vais vous dire comment cet outil nous a attir√© et comment nous l'utilisons. <br><a name="habracut"></a><br><h2>  Contexte </h2><br>  Il n'y a pas si longtemps, nous √©tions confront√©s au choix d'une solution pour charger des donn√©es de sources externes dans un cluster Hadoop.  Pendant longtemps, nous avons utilis√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apache Flume</a> pour r√©soudre de tels probl√®mes.  Il n'y a eu aucune plainte concernant Flume dans son ensemble, √† l'exception de quelques points qui ne nous convenaient pas. <br><br>  <i>La premi√®re</i> chose que nous, en tant qu'administrateurs, n'aimions pas, c'est que l'√©criture de la configuration Flume pour effectuer le prochain t√©l√©chargement trivial ne pouvait pas √™tre confi√©e √† un d√©veloppeur ou √† un analyste qui n'√©tait pas plong√© dans les subtilit√©s de cet outil.  La connexion de chaque nouvelle source a n√©cessit√© une intervention obligatoire de l'√©quipe d'administration. <br>  <i>Le deuxi√®me point</i> √©tait la tol√©rance aux pannes et la mise √† l'√©chelle.  Pour les t√©l√©chargements lourds, par exemple via syslog, il √©tait n√©cessaire de configurer plusieurs agents Flume et de d√©finir un √©quilibreur devant eux.  Tout cela devait alors √™tre en quelque sorte surveill√© et restaur√© en cas de panne. <br>  <i>Troisi√®mement</i> , Flume n'a pas permis de t√©l√©charger des donn√©es √† partir de divers SGBD et de travailler avec certains autres protocoles pr√™ts √† l'emploi.  Bien s√ªr, dans les vastes √©tendues du r√©seau, vous pouvez trouver des moyens de faire fonctionner Flume avec Oracle ou SFTP, mais prendre en charge de tels v√©los n'est pas du tout agr√©able.  Pour charger des donn√©es √† partir du m√™me Oracle, nous avons d√ª utiliser un autre outil - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apache Sqoop</a> . <br>  Franchement, par nature, je suis une personne paresseuse et je ne voulais pas du tout soutenir le zoo des solutions.  Et je n'aimais pas que tout ce travail soit fait par moi-m√™me. <br><br>  Il existe, bien s√ªr, des solutions assez puissantes sur le march√© des outils ETL qui peuvent fonctionner avec Hadoop.  Il s'agit notamment d'Informatica, IBM Datastage, SAS et Pentaho Data Integration.  Ce sont ceux qui sont le plus souvent entendus par les coll√®gues de l'atelier et ceux qui me viennent √† l'esprit en premier.  Soit dit en passant, nous utilisons IBM DataStage for ETL sur des solutions de la classe Data Warehouse.  Mais il est arriv√© historiquement que notre √©quipe n'ait pas pu utiliser DataStage pour les t√©l√©chargements dans Hadoop.  Encore une fois, nous n'avions pas besoin de toute la puissance des solutions de ce niveau pour effectuer des conversions et des t√©l√©chargements de donn√©es assez simples.  Ce qu'il nous fallait, c'√©tait une solution avec une bonne dynamique de d√©veloppement, capable de travailler avec de nombreux protocoles et une interface pratique et intuitive que non seulement un administrateur qui comprenait toutes ses subtilit√©s √©tait capable de g√©rer, mais aussi un d√©veloppeur avec un analyste, qui sont souvent pour nous clients des donn√©es elles-m√™mes. <br><br>  Comme vous pouvez le voir dans le titre, nous avons r√©solu les probl√®mes ci-dessus avec Apache NiFi. <br><br><h2>  Qu'est-ce que Apache NiFi </h2><br>  Le nom NiFi vient de ¬´Niagara Files¬ª.  Le projet a √©t√© d√©velopp√© par la US National Security Agency pendant huit ans, et en novembre 2014, son code source a √©t√© ouvert et transf√©r√© √† l'Apache Software Foundation dans le cadre du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">programme de transfert de technologie</a> de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">NSA</a> . <br><br>  NiFi est un outil ETL / ELT open source qui peut fonctionner avec de nombreux syst√®mes, et pas seulement avec les classes Big Data et Data Warehouse.  En voici quelques-uns: HDFS, Hive, HBase, Solr, Cassandra, MongoDB, ElastcSearch, Kafka, RabbitMQ, Syslog, HTTPS, SFTP.  Vous pouvez voir la liste compl√®te dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation</a> officielle. <br><br>  Le travail avec un SGBD sp√©cifique est impl√©ment√© en ajoutant le pilote JDBC appropri√©.  Il existe une API pour √©crire votre module en tant que r√©cepteur ou convertisseur de donn√©es suppl√©mentaire.  Des exemples peuvent √™tre trouv√©s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br><h2>  Caract√©ristiques cl√©s </h2><br>  NiFi utilise une interface Web pour cr√©er DataFlow.  Un analyste qui a r√©cemment commenc√© √† travailler avec Hadoop, un d√©veloppeur et un administrateur barbu s'en occupera.  Les deux derniers peuvent interagir non seulement avec des ¬´rectangles et des fl√®ches¬ª, mais aussi avec l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">API REST</a> pour collecter des statistiques, surveiller et g√©rer les composants DataFlow. <br><br><img src="https://habrastorage.org/webt/zw/dx/iq/zwdxiqh9ovilvva4tak-stj5jpc.png" alt="image"><br>  <i>Gestion bas√©e sur le Web NiFi</i> <br><br>  Ci-dessous, je vais montrer quelques exemples DataFlow pour effectuer certaines op√©rations courantes. <br><br><img src="https://habrastorage.org/webt/jz/cw/v_/jzcwv_nu7infyyarte3skiwvayi.png" alt="image"><br>  <i>Exemple de t√©l√©chargement de fichiers d'un serveur SFTP vers HDFS</i> <br><br>  Dans cet exemple, le processeur ListSFTP effectue une liste de fichiers sur le serveur distant.  Le r√©sultat de cette liste est utilis√© pour le chargement de fichiers parall√®les par tous les n≈ìuds du cluster par le processeur FetchSFTP.  Apr√®s cela, des attributs sont ajout√©s √† chaque fichier, obtenus en analysant son nom, qui sont ensuite utilis√©s par le processeur PutHDFS lors de l'√©criture du fichier dans le r√©pertoire final. <br><br><img src="https://habrastorage.org/webt/v-/ei/op/v-eiopqny5-jao0kaqlyexduvx0.png" alt="image"><br>  <i>Un exemple de t√©l√©chargement de donn√©es syslog dans Kafka et HDFS</i> <br><br>  Ici, en utilisant le processeur ListenSyslog, nous obtenons le flux de messages d'entr√©e.  Apr√®s cela, des attributs concernant l'heure de leur arriv√©e dans NiFi et le nom du sch√©ma dans le registre de sch√©ma Avro sont ajout√©s √† chaque groupe de messages.  Ensuite, la premi√®re branche est dirig√©e vers l'entr√©e du processeur QueryRecord, qui, sur la base du sch√©ma sp√©cifi√©, lit les donn√©es et les analyse √† l'aide de SQL, puis les envoie √† Kafka.  La deuxi√®me branche est envoy√©e au processeur MergeContent, qui agr√®ge les donn√©es pendant 10 minutes, puis les transmet au processeur suivant pour conversion au format Parquet et enregistrement sur HDFS. <br><br>  Voici un exemple de la fa√ßon dont vous pouvez styliser un DataFlow: <br><img src="https://habrastorage.org/webt/43/kd/2-/43kd2-43rovwudvvoi3sm8hdmuk.png" alt="image"><br>  <i>T√©l√©chargez les donn√©es syslog sur Kafka et HDFS.</i>  <i>Effacement des donn√©es dans Hive</i> <br><br>  Maintenant sur la conversion des donn√©es.  NiFi vous permet d'analyser des donn√©es avec des donn√©es r√©guli√®res, d'ex√©cuter SQL dessus, de filtrer et d'ajouter des champs et de convertir un format de donn√©es en un autre.  Il poss√®de √©galement son propre langage d'expression, riche en divers op√©rateurs et fonctions int√©gr√©es.  Avec lui, vous pouvez ajouter des variables et des attributs aux donn√©es, comparer et calculer des valeurs, les utiliser plus tard dans la formation de divers param√®tres, tels que le chemin pour √©crire dans HDFS ou une requ√™te SQL dans Hive.  Lisez plus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br><img src="https://habrastorage.org/webt/a4/7m/b_/a47mb_i_f2mzkfezluoq6qrt6-0.png" alt="image"><br>  <i>Un exemple d'utilisation de variables et de fonctions dans le processeur UpdateAttribute</i> <br><br>  L'utilisateur peut suivre le chemin complet des donn√©es, observer la modification de leur contenu et de leurs attributs. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a69/e09/44a/a69e0944abb4bb44f3863653994cd891.png"><br>  <i>Visualisation de la cha√Æne DataFlow</i> <br><br><img src="https://habrastorage.org/webt/sc/u3/ih/scu3ihzv1nwydvwfjc4ks9yvfoe.png" alt="image"><br>  <i>Afficher le contenu et les attributs de donn√©es</i> <br><br>  Pour versionner DataFlow, il existe un service de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">registre NiFi</a> distinct.  En le configurant, vous avez la possibilit√© de g√©rer les modifications.  Vous pouvez ex√©cuter des modifications locales, annuler ou t√©l√©charger n'importe quelle version pr√©c√©dente. <br><br><img src="https://habrastorage.org/webt/ci/uz/ge/ciuzgeuazknrhqm5peopzmekiuo.png" alt="image"><br>  <i>Menu de contr√¥le de version</i> <br><br>  En NiFi, vous pouvez contr√¥ler l'acc√®s √† l'interface Web et la s√©paration des droits des utilisateurs.  Les m√©canismes d'authentification suivants sont actuellement pris en charge: <br><br><ul><li>  Bas√© sur un certificat <br></li><li>  Bas√© sur le nom d'utilisateur et le mot de passe via LDAP et Kerberos <br></li><li>  Via <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apache Knox</a> <br></li><li>  Via <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenID Connect</a> <br></li></ul><br>  L'utilisation simultan√©e de plusieurs m√©canismes √† la fois n'est pas prise en charge.  Pour autoriser les utilisateurs du syst√®me, FileUserGroupProvider et LdapUserGroupProvider sont utilis√©s.  En savoir plus √† ce sujet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Comme je l'ai dit, NiFi peut fonctionner en mode cluster.  Cela offre une tol√©rance aux pannes et permet une mise √† l'√©chelle horizontale de la charge.  Il n'y a pas de n≈ìud ma√Ætre fixe statiquement.  Au lieu de cela, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apache Zookeeper</a> s√©lectionne un n≈ìud comme coordinateur et un comme principal.  Le coordinateur re√ßoit des informations sur leur √©tat des autres n≈ìuds et est responsable de leur connexion et d√©connexion du cluster. <br>  Le n≈ìud principal est utilis√© pour d√©marrer des processeurs isol√©s, qui ne doivent pas s'ex√©cuter sur tous les n≈ìuds simultan√©ment. <br><br><img src="https://habrastorage.org/webt/1w/io/mv/1wiomvdhjbh_ewwa73dgl-yjitg.png" alt="image"><br>  <i>Fonctionnement NiFi dans un cluster</i> <br><br><img src="https://habrastorage.org/webt/du/ty/ea/dutyeaditjnc6bq_qgta6xcexrk.png" alt="image"><br>  <i>Distribution de charge par n≈ìuds de cluster en utilisant le processeur PutHDFS comme exemple</i> <br><br><h2>  Une br√®ve description de l'architecture et des composants NiFi </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/d68/920/1de/d689201de4c392c562e807fc279cd2ab.png"><br>  <i>Architecture d'instance NiFi</i> <br><br>  NiFi est bas√© sur le concept de ¬´Flow Based Programming¬ª ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">FBP</a> ).  Voici les concepts et composants de base que chaque utilisateur rencontre: <br><br>  <b>FlowFile</b> - une entit√© qui repr√©sente un objet avec un contenu de z√©ro ou plusieurs octets et ses attributs correspondants.  Cela peut √™tre soit les donn√©es elles-m√™mes (par exemple, le flux de messages Kafka), soit le r√©sultat du processeur (PutSQL, par exemple), qui ne contient pas de donn√©es en tant que telles, mais uniquement les attributs g√©n√©r√©s √† la suite de la requ√™te.  Les attributs sont des m√©tadonn√©es FlowFile. <br><br>  <b>Le processeur FlowFile</b> est exactement l'essence qui fait le travail de base en NiFi.  Un processeur, en r√®gle g√©n√©rale, a une ou plusieurs fonctions pour travailler avec FlowFile: cr√©ation, lecture / √©criture et modification de contenu, lecture / √©criture / modification d'attributs, routage.  Par exemple, le processeur ListenSyslog re√ßoit des donn√©es √† l'aide du protocole syslog, cr√©ant des FlowFiles avec les attributs syslog.version, syslog.hostname, syslog.sender et autres.  Le processeur RouteOnAttribute lit les attributs du FlowFile d'entr√©e et d√©cide de le rediriger vers la connexion appropri√©e avec un autre processeur, en fonction des valeurs des attributs. <br><br>  <b>Connexion</b> - fournit une connexion et un transfert FlowFile entre divers processeurs et certaines autres entit√©s NiFi.  La connexion place le FlowFile dans une file d'attente, puis le transmet le long de la cha√Æne.  Vous pouvez configurer la fa√ßon dont les FlowFiles sont s√©lectionn√©s dans la file d'attente, leur dur√©e de vie, le nombre maximal et la taille maximale de tous les objets de la file d'attente. <br><br>  <b>Groupe de processus</b> - un ensemble de processeurs, leurs connexions et d'autres √©l√©ments DataFlow.  C'est un m√©canisme pour organiser de nombreux composants en une seule structure logique.  Aide √† simplifier la compr√©hension de DataFlow.  Les ports d'entr√©e / sortie sont utilis√©s pour recevoir et envoyer des donn√©es √† partir de groupes de processus.  En savoir plus sur leur utilisation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  <b>Le r√©f√©rentiel FlowFile</b> est l'endroit o√π NiFi stocke toutes les informations qu'il conna√Æt sur chaque FlowFile existant dans le syst√®me. <br><br>  <b>R√©f√©rentiel de contenu</b> - le r√©f√©rentiel dans lequel se trouve le contenu de tous les FlowFiles, c'est-√†-dire  les donn√©es transmises elles-m√™mes. <br><br>  <b>R√©f√©rentiel de provenance</b> - Contient une histoire sur chaque FlowFile.  Chaque fois qu'un √©v√©nement se produit avec FlowFile (cr√©ation, modification, etc.), les informations correspondantes sont entr√©es dans ce r√©f√©rentiel. <br><br>  <b>Serveur Web</b> - fournit une interface Web et une API REST. <br><br><h2>  Conclusion </h2><br>  Avec NiFi, Rostelecom a pu am√©liorer le m√©canisme de livraison des donn√©es √† Data Lake sur Hadoop.  En g√©n√©ral, l'ensemble du processus est devenu plus pratique et plus fiable.  Aujourd'hui, je peux affirmer avec confiance que NiFi est id√©al pour le t√©l√©chargement sur Hadoop.  Nous n'avons aucun probl√®me dans son fonctionnement. <br><br>  Soit dit en passant, NiFi fait partie de la distribution de flux de donn√©es Hortonworks et est activement d√©velopp√© par Hortonworks lui-m√™me.  Il a √©galement un sous-projet Apache MiNiFi int√©ressant, qui vous permet de collecter des donn√©es √† partir de divers appareils et de les int√©grer dans DataFlow √† l'int√©rieur de NiFi. <br><br><h2>  Informations suppl√©mentaires sur NiFi </h2><br><ul><li>  Page de documentation officielle du projet <br></li><li>  Une collection d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">articles int√©ressants</a> sur NiFi de l'un des participants au projet <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Blog sur l'</a> un des d√©veloppeurs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">NiFi</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Articles</a> Hortonworks <br></li></ul><br>  C‚Äôest peut-√™tre tout.  Merci √† tous pour votre attention.  √âcrivez dans les commentaires si vous avez des questions.  Je leur r√©pondrai avec plaisir. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr432166/">https://habr.com/ru/post/fr432166/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr432154/index.html">L'acc√®s conditionnel comme m√©canisme de contr√¥le d'acc√®s</a></li>
<li><a href="../fr432156/index.html">Nouveau 2GIS - connectez-vous aux tests publics</a></li>
<li><a href="../fr432158/index.html">Utiliser JIRA et Confluence dans un grand projet</a></li>
<li><a href="../fr432160/index.html">Vid√©o d'Android Kolesa Mobile: sur le d√©veloppement modulaire, l'interface utilisateur pilot√©e par le backend et l'int√©gration continue</a></li>
<li><a href="../fr432162/index.html">¬´Nous essayons de raconter des histoires r√©elles¬ª: √† propos du programme Heisenbug 2018 Moscou</a></li>
<li><a href="../fr432168/index.html">Les autorit√©s chinoises collectent des informations sur les v√©hicules √©lectriques des citoyens du pays</a></li>
<li><a href="../fr432170/index.html">Transportez un centre de donn√©es en 14 400 secondes</a></li>
<li><a href="../fr432172/index.html">Invitation dangereuse ou Fonctionnement de la charge de combat pour un e-mail de phishing</a></li>
<li><a href="../fr432174/index.html">Comment d√©velopper avec comp√©tence et efficacit√© un produit logiciel</a></li>
<li><a href="../fr432176/index.html">Comment nous avons doubl√© la vitesse de travail avec Float en Mono</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
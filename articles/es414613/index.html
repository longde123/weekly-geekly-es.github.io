<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•¢ üê¥ ü§πüèæ Competencia de riesgo de incumplimiento crediticio de Kaggle Home - An√°lisis de datos y modelos predictivos simples üë®üèΩ‚Äçüöí üëµüèæ üññüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En el festival de datos 2 en Minsk, Vladimir Iglovikov, ingeniero de visi√≥n artificial en Lyft, coment√≥ perfectamente que la mejor manera de aprender ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Competencia de riesgo de incumplimiento crediticio de Kaggle Home - An√°lisis de datos y modelos predictivos simples</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414613/">  En el festival de datos 2 en Minsk, Vladimir Iglovikov, ingeniero de visi√≥n artificial en Lyft, coment√≥ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">perfectamente</a> que la mejor manera de aprender Data Science es participar en competiciones, ejecutar soluciones de otras personas, combinarlas, lograr resultados y mostrar su trabajo.  En realidad, dentro del marco de este paradigma, decid√≠ echar un vistazo m√°s de cerca a la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">competencia de</a> evaluaci√≥n de riesgo de cr√©dito de Home Credit y explicar (a los principiantes, cient√≠ficos y ante todo a m√≠ mismo) c√≥mo analizar adecuadamente dichos conjuntos de datos y construir modelos para ellos. <br><br><img src="https://habrastorage.org/webt/iv/ji/-t/ivji-tusvam8d05dqef8wjbmbye.png"><br><a name="habracut"></a><br>  (foto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de aqu√≠</a> ) <br><br><img src="https://habrastorage.org/webt/xc/er/pe/xcerpefrjvrblmubhxyeljevcie.png" width="250" align="right">  Home Credit Group es un grupo de organizaciones de cr√©dito bancarias y no bancarias que realiza operaciones en 11 pa√≠ses (incluida Rusia como Home Credit and Finance Bank LLC).  El prop√≥sito de la competencia es crear una metodolog√≠a para evaluar la solvencia de los prestatarios que no tienen un historial crediticio.  Lo que parece bastante noble: los prestatarios de esta categor√≠a a menudo no pueden obtener ning√∫n cr√©dito del banco y se ven obligados a recurrir a estafadores y micropr√©stamos.  Es interesante que el cliente no establezca requisitos de transparencia e interpretabilidad del modelo (como suele ser el caso con los bancos), puede usar cualquier cosa, incluso una red neuronal. <br><br>  La muestra de capacitaci√≥n consta de m√°s de 300 mil registros, hay muchos signos: 122, entre ellos hay muchos categ√≥ricos (no num√©ricos).  Las se√±ales describen al prestatario con suficiente detalle, hasta el material del que est√°n hechas las paredes de su casa.  Parte de los datos est√°n contenidos en 6 tablas adicionales (datos de la agencia de cr√©dito, saldo de tarjetas de cr√©dito y pr√©stamos anteriores), estos datos tambi√©n deben procesarse de alguna manera y cargarse en los principales. <br><br>  La competencia parece una tarea de clasificaci√≥n est√°ndar (1 en el campo OBJETIVO significa cualquier dificultad con los pagos, 0 significa que no hay dificultades).  Sin embargo, no se debe predecir 0/1, sino la probabilidad de problemas (que, por cierto, puede resolverse f√°cilmente mediante los m√©todos de predicci√≥n de probabilidad predic_proba que tienen todos los modelos complejos). <br><br>  A primera vista, el conjunto de datos es bastante est√°ndar para las tareas de aprendizaje autom√°tico, los organizadores ofrecieron un gran premio de $ 70k, como resultado, m√°s de 2,600 equipos participan en la competencia hoy, y la batalla es en mil√©simas de un por ciento.  Sin embargo, por otro lado, tal popularidad significa que el conjunto de datos se ha estudiado de arriba abajo y muchos n√∫cleos se han creado con buena EDA (An√°lisis de datos exploratorios: investigaci√≥n y an√°lisis de datos en la red, incluidos gr√°ficos), Ingenier√≠a de caracter√≠sticas (trabajo con atributos) y con modelos interesantes.  (Kernel es un ejemplo de trabajo con un conjunto de datos que cualquiera puede dise√±ar para mostrar su trabajo a otros kugglers). <br><br>  Los granos merecen atenci√≥n: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">EDA con una descripci√≥n detallada para principiantes y modelos simples</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Deep EDA con Plotly Package + Bureau Data Upload</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Buen EDA con paquete Seaborn</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">An√°lisis comparativo de los prestatarios problem√°ticos y morosos</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LightGBM de 15 l√≠neas en tres se√±ales con una velocidad final de 0.714</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">An√°lisis de signos seg√∫n bur√≥s de cr√©dito.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Procesamiento de agregar.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">mesas + LightGBM</a> </li></ul><br>  Para trabajar con datos, generalmente se recomienda el siguiente plan, que intentaremos seguir. <br><br><ol><li>  Comprender el problema y familiarizarse con los datos </li><li>  Limpieza y formateo de datos </li><li>  EDA </li><li>  Modelo base </li><li>  Mejora modelo </li><li>  Interpretaci√≥n del modelo </li></ol><br>  En este caso, debe tener en cuenta el hecho de que los datos son bastante extensos y no se pueden dominar de inmediato, tiene sentido actuar por etapas. <br><br>  Comencemos importando las bibliotecas que necesitamos en el an√°lisis para trabajar con datos en forma de tablas, construir gr√°ficos y trabajar con matrices. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns %matplotlib inline</code> </pre> <br>  Descargue los datos.  Veamos que tenemos todos.  Esta ubicaci√≥n en el directorio "../input/", por cierto, est√° conectada con el requisito de colocar sus n√∫cleos en Kaggle. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os PATH=<span class="hljs-string"><span class="hljs-string">"../input/"</span></span> print(os.listdir(PATH))</code> </pre> <br> <code>['application_test.csv', 'application_train.csv', 'bureau.csv', 'bureau_balance.csv', 'credit_card_balance.csv', 'HomeCredit_columns_description.csv', 'installments_payments.csv', 'POS_CASH_balance.csv', 'previous_application.csv']</code> <br> <br>  Hay 8 tablas con datos (sin contar la tabla HomeCredit_columns_description.csv, que contiene una descripci√≥n de los campos), que se interconectan de la siguiente manera: <br><br><img src="https://habrastorage.org/webt/vn/yr/84/vnyr84vhzozgnfinu2to2tyhlp8.png"><br><br>  application_train / application_test: datos maestros, el prestatario se identifica por el campo SK_ID_CURR <br>  bur√≥: Datos sobre pr√©stamos anteriores de otras instituciones de cr√©dito de un bur√≥ de cr√©dito <br>  bureau_balance: datos mensuales sobre pr√©stamos anteriores de la oficina.  Cada l√≠nea es el mes de usar el pr√©stamo <br>  previous_application: Solicitudes anteriores para pr√©stamos en Home Credit, cada una tiene un campo √∫nico SK_ID_PREV <br>  POS_CASH_BALANCE: Datos mensuales sobre pr√©stamos en Home Credit con la emisi√≥n de efectivo y pr√©stamos para la compra de bienes. <br>  credit_card_balance: datos mensuales del saldo de la tarjeta de cr√©dito en Home Credit <br>  cuotas_pago: Historial de pagos de pr√©stamos anteriores en Home Credit. <br><br>  Centr√©monos primero en la fuente de datos principal y veamos qu√© informaci√≥n se puede extraer de ella y qu√© modelos construir.  Descargue los datos b√°sicos. <br><br><ul><li>  app_train = pd.read_csv (PATH + 'application_train.csv',) </li><li>  app_test = pd.read_csv (PATH + 'application_test.csv',) </li><li>  print ("formato del conjunto de entrenamiento:", app_train.shape) </li><li>  print ("formato de muestra de prueba:", app_test.shape) </li><li>  formato de muestra de entrenamiento: (307511, 122) </li><li>  formato de muestra de prueba: (48744, 121) </li></ul><br>  En total, tenemos 307 mil registros y 122 signos en la muestra de capacitaci√≥n y 49 mil registros y 121 signos en la prueba.  La discrepancia se debe obviamente al hecho de que no hay un atributo objetivo TARGET en la muestra de prueba, y lo predeciremos. <br><br>  Echemos un vistazo m√°s de cerca a los datos. <br><br><pre> <code class="python hljs">pd.set_option(<span class="hljs-string"><span class="hljs-string">'display.max_columns'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) <span class="hljs-comment"><span class="hljs-comment">#  pandas     app_train.head()</span></span></code> </pre> <br><br><img src="https://habrastorage.org/webt/xo/yc/rg/xoycrgiodfhonfrjbt50ncthrls.png"><br>  (se muestran las primeras 8 columnas) <br><br>  Es bastante dif√≠cil ver datos en este formato.  Veamos la lista de columnas: <br><br> <code>app_train.info(max_cols=122) <br> &lt;class 'pandas.core.frame.DataFrame'&gt; <br> RangeIndex: 307511 entries, 0 to 307510 <br> Data columns (total 122 columns): <br> SK_ID_CURR 307511 non-null int64 <br> TARGET 307511 non-null int64 <br> NAME_CONTRACT_TYPE 307511 non-null object <br> CODE_GENDER 307511 non-null object <br> FLAG_OWN_CAR 307511 non-null object <br> FLAG_OWN_REALTY 307511 non-null object <br> CNT_CHILDREN 307511 non-null int64 <br> AMT_INCOME_TOTAL 307511 non-null float64 <br> AMT_CREDIT 307511 non-null float64 <br> AMT_ANNUITY 307499 non-null float64 <br> AMT_GOODS_PRICE 307233 non-null float64 <br> NAME_TYPE_SUITE 306219 non-null object <br> NAME_INCOME_TYPE 307511 non-null object <br> NAME_EDUCATION_TYPE 307511 non-null object <br> NAME_FAMILY_STATUS 307511 non-null object <br> NAME_HOUSING_TYPE 307511 non-null object <br> REGION_POPULATION_RELATIVE 307511 non-null float64 <br> DAYS_BIRTH 307511 non-null int64 <br> DAYS_EMPLOYED 307511 non-null int64 <br> DAYS_REGISTRATION 307511 non-null float64 <br> DAYS_ID_PUBLISH 307511 non-null int64 <br> OWN_CAR_AGE 104582 non-null float64 <br> FLAG_MOBIL 307511 non-null int64 <br> FLAG_EMP_PHONE 307511 non-null int64 <br> FLAG_WORK_PHONE 307511 non-null int64 <br> FLAG_CONT_MOBILE 307511 non-null int64 <br> FLAG_PHONE 307511 non-null int64 <br> FLAG_EMAIL 307511 non-null int64 <br> OCCUPATION_TYPE 211120 non-null object <br> CNT_FAM_MEMBERS 307509 non-null float64 <br> REGION_RATING_CLIENT 307511 non-null int64 <br> REGION_RATING_CLIENT_W_CITY 307511 non-null int64 <br> WEEKDAY_APPR_PROCESS_START 307511 non-null object <br> HOUR_APPR_PROCESS_START 307511 non-null int64 <br> REG_REGION_NOT_LIVE_REGION 307511 non-null int64 <br> REG_REGION_NOT_WORK_REGION 307511 non-null int64 <br> LIVE_REGION_NOT_WORK_REGION 307511 non-null int64 <br> REG_CITY_NOT_LIVE_CITY 307511 non-null int64 <br> REG_CITY_NOT_WORK_CITY 307511 non-null int64 <br> LIVE_CITY_NOT_WORK_CITY 307511 non-null int64 <br> ORGANIZATION_TYPE 307511 non-null object <br> EXT_SOURCE_1 134133 non-null float64 <br> EXT_SOURCE_2 306851 non-null float64 <br> EXT_SOURCE_3 246546 non-null float64 <br> APARTMENTS_AVG 151450 non-null float64 <br> BASEMENTAREA_AVG 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_AVG 157504 non-null float64 <br> YEARS_BUILD_AVG 103023 non-null float64 <br> COMMONAREA_AVG 92646 non-null float64 <br> ELEVATORS_AVG 143620 non-null float64 <br> ENTRANCES_AVG 152683 non-null float64 <br> FLOORSMAX_AVG 154491 non-null float64 <br> FLOORSMIN_AVG 98869 non-null float64 <br> LANDAREA_AVG 124921 non-null float64 <br> LIVINGAPARTMENTS_AVG 97312 non-null float64 <br> LIVINGAREA_AVG 153161 non-null float64 <br> NONLIVINGAPARTMENTS_AVG 93997 non-null float64 <br> NONLIVINGAREA_AVG 137829 non-null float64 <br> APARTMENTS_MODE 151450 non-null float64 <br> BASEMENTAREA_MODE 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_MODE 157504 non-null float64 <br> YEARS_BUILD_MODE 103023 non-null float64 <br> COMMONAREA_MODE 92646 non-null float64 <br> ELEVATORS_MODE 143620 non-null float64 <br> ENTRANCES_MODE 152683 non-null float64 <br> FLOORSMAX_MODE 154491 non-null float64 <br> FLOORSMIN_MODE 98869 non-null float64 <br> LANDAREA_MODE 124921 non-null float64 <br> LIVINGAPARTMENTS_MODE 97312 non-null float64 <br> LIVINGAREA_MODE 153161 non-null float64 <br> NONLIVINGAPARTMENTS_MODE 93997 non-null float64 <br> NONLIVINGAREA_MODE 137829 non-null float64 <br> APARTMENTS_MEDI 151450 non-null float64 <br> BASEMENTAREA_MEDI 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_MEDI 157504 non-null float64 <br> YEARS_BUILD_MEDI 103023 non-null float64 <br> COMMONAREA_MEDI 92646 non-null float64 <br> ELEVATORS_MEDI 143620 non-null float64 <br> ENTRANCES_MEDI 152683 non-null float64 <br> FLOORSMAX_MEDI 154491 non-null float64 <br> FLOORSMIN_MEDI 98869 non-null float64 <br> LANDAREA_MEDI 124921 non-null float64 <br> LIVINGAPARTMENTS_MEDI 97312 non-null float64 <br> LIVINGAREA_MEDI 153161 non-null float64 <br> NONLIVINGAPARTMENTS_MEDI 93997 non-null float64 <br> NONLIVINGAREA_MEDI 137829 non-null float64 <br> FONDKAPREMONT_MODE 97216 non-null object <br> HOUSETYPE_MODE 153214 non-null object <br> TOTALAREA_MODE 159080 non-null float64 <br> WALLSMATERIAL_MODE 151170 non-null object <br> EMERGENCYSTATE_MODE 161756 non-null object <br> OBS_30_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DEF_30_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> OBS_60_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DEF_60_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DAYS_LAST_PHONE_CHANGE 307510 non-null float64 <br> FLAG_DOCUMENT_2 307511 non-null int64 <br> FLAG_DOCUMENT_3 307511 non-null int64 <br> FLAG_DOCUMENT_4 307511 non-null int64 <br> FLAG_DOCUMENT_5 307511 non-null int64 <br> FLAG_DOCUMENT_6 307511 non-null int64 <br> FLAG_DOCUMENT_7 307511 non-null int64 <br> FLAG_DOCUMENT_8 307511 non-null int64 <br> FLAG_DOCUMENT_9 307511 non-null int64 <br> FLAG_DOCUMENT_10 307511 non-null int64 <br> FLAG_DOCUMENT_11 307511 non-null int64 <br> FLAG_DOCUMENT_12 307511 non-null int64 <br> FLAG_DOCUMENT_13 307511 non-null int64 <br> FLAG_DOCUMENT_14 307511 non-null int64 <br> FLAG_DOCUMENT_15 307511 non-null int64 <br> FLAG_DOCUMENT_16 307511 non-null int64 <br> FLAG_DOCUMENT_17 307511 non-null int64 <br> FLAG_DOCUMENT_18 307511 non-null int64 <br> FLAG_DOCUMENT_19 307511 non-null int64 <br> FLAG_DOCUMENT_20 307511 non-null int64 <br> FLAG_DOCUMENT_21 307511 non-null int64 <br> AMT_REQ_CREDIT_BUREAU_HOUR 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_DAY 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_WEEK 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_MON 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_QRT 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_YEAR 265992 non-null float64 <br> dtypes: float64(65), int64(41), object(16) <br> memory usage: 286.2+ MB</code> <br> <br>  Recupere anotaciones detalladas por campo en el archivo HomeCredit_columns_description.  Como puede ver en la informaci√≥n, parte de los datos est√° incompleta y parte es categ√≥rica, se muestran como objeto.  La mayor√≠a de los modelos no funcionan con dichos datos, tendremos que hacer algo con ellos.  Sobre esto, el an√°lisis inicial puede considerarse completado, iremos directamente a EDA <br><br><h2>  An√°lisis exploratorio de datos o miner√≠a de datos primarios </h2><br>  En el proceso EDA, contamos las estad√≠sticas b√°sicas y dibujamos gr√°ficos para encontrar tendencias, anomal√≠as, patrones y relaciones dentro de los datos.  El objetivo de EDA es averiguar qu√© pueden decir los datos.  Por lo general, el an√°lisis va de arriba a abajo, desde una visi√≥n general hasta el estudio de zonas individuales que llaman la atenci√≥n y pueden ser de inter√©s.  Posteriormente, estos hallazgos pueden usarse en la construcci√≥n del modelo, la selecci√≥n de caracter√≠sticas para √©l y en su interpretaci√≥n. <br><br><h3>  Distribuci√≥n Variable Objetivo </h3><br><pre> <code class="python hljs">app_train.TARGET.value_counts()</code> </pre> <br> <code>0 282686 <br> 1 24825 <br> Name: TARGET, dtype: int64</code> <br> <br><pre> <code class="python hljs">plt.style.use(<span class="hljs-string"><span class="hljs-string">'fivethirtyeight'</span></span>) plt.rcParams[<span class="hljs-string"><span class="hljs-string">"figure.figsize"</span></span>] = [<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>]‚Äã plt.hist(app_train.TARGET) plt.show()</code> </pre> <br><img src="https://habrastorage.org/webt/xm/rd/ch/xmrdchcab8eqbwt2p1pie4jmaeu.png"><br><br>  Perm√≠tame recordarle que 1 significa problemas de cualquier tipo con un retorno, 0 significa que no hay problemas.  Como puede ver, principalmente los prestatarios no tienen problemas con el pago, la parte problem√°tica es de aproximadamente el 8%.  Esto significa que las clases no est√°n equilibradas y esto debe tenerse en cuenta al construir el modelo. <br><br><h3>  Investigaci√≥n de datos faltantes </h3><br>  Hemos visto que la falta de datos es bastante sustancial.  Veamos con m√°s detalle d√≥nde y qu√© falta. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      def missing_values_table(df): #   mis_val = df.isnull().sum() #    mis_val_percent = 100 * df.isnull().sum() / len(df) #    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1) #   mis_val_table_ren_columns = mis_val_table.rename( columns = {0 : 'Missing Values', 1 : '% of Total Values'}) #    mis_val_table_ren_columns = mis_val_table_ren_columns[ mis_val_table_ren_columns.iloc[:,1] != 0].sort_values( '% of Total Values', ascending=False).round(1) #  print ("   " + str(df.shape[1]) + " .\n" " " + str(mis_val_table_ren_columns.shape[0]) + "    .") #     return mis_val_table_ren_columns missing_values = missing_values_table(app_train) missing_values.head(10)</span></span></code> </pre> <br><br> <code>   122 . <br>  67    .</code> <br> <img src="https://habrastorage.org/webt/oa/jm/tp/oajmtpuvkymt4asczwqmhqziria.png"><br><br>  En formato gr√°fico: <br><br><pre> <code class="python hljs">plt.style.use(<span class="hljs-string"><span class="hljs-string">'seaborn-talk'</span></span>)‚Äã fig = plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">18</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>)) miss_train = pd.DataFrame((app_train.isnull().sum())*<span class="hljs-number"><span class="hljs-number">100</span></span>/app_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]).reset_index() miss_test = pd.DataFrame((app_test.isnull().sum())*<span class="hljs-number"><span class="hljs-number">100</span></span>/app_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]).reset_index() miss_train[<span class="hljs-string"><span class="hljs-string">"type"</span></span>] = <span class="hljs-string"><span class="hljs-string">""</span></span> miss_test[<span class="hljs-string"><span class="hljs-string">"type"</span></span>] = <span class="hljs-string"><span class="hljs-string">""</span></span> missing = pd.concat([miss_train,miss_test],axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) ax = sns.pointplot(<span class="hljs-string"><span class="hljs-string">"index"</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,data=missing,hue=<span class="hljs-string"><span class="hljs-string">"type"</span></span>) plt.xticks(rotation =<span class="hljs-number"><span class="hljs-number">90</span></span>,fontsize =<span class="hljs-number"><span class="hljs-number">7</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">"    "</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">"  %"</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">""</span></span>)</code> </pre> <br><br><img src="https://habrastorage.org/webt/iv/fc/ib/ivfcibv85aaktlxybl8bps2vurw.png"><br><br>  Hay muchas respuestas a la pregunta "qu√© hacer con todo esto".  Puede llenarlo con ceros, puede usar valores medios, simplemente puede eliminar l√≠neas sin la informaci√≥n necesaria.  Todo depende del modelo que planeemos usar, ya que algunos de ellos hacen frente perfectamente a los valores perdidos.  Mientras recordamos este hecho y dejamos todo como est√°. <br><br><h3>  Tipos de columna y codificaci√≥n categ√≥rica </h3><br>  Como recordamos  parte de las columnas es de tipo objeto, es decir, no tiene un valor num√©rico, pero refleja alguna categor√≠a.  Miremos estas columnas m√°s de cerca. <br><br><pre> <code class="python hljs">app_train.dtypes.value_counts()</code> </pre> <br> <code>float64 65 <br> int64 41 <br> object 16 <br> dtype: int64</code> <br> <br><pre> <code class="python hljs">app_train.select_dtypes(include=[object]).apply(pd.Series.nunique, axis = <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br> <code>NAME_CONTRACT_TYPE 2 <br> CODE_GENDER 3 <br> FLAG_OWN_CAR 2 <br> FLAG_OWN_REALTY 2 <br> NAME_TYPE_SUITE 7 <br> NAME_INCOME_TYPE 8 <br> NAME_EDUCATION_TYPE 5 <br> NAME_FAMILY_STATUS 6 <br> NAME_HOUSING_TYPE 6 <br> OCCUPATION_TYPE 18 <br> WEEKDAY_APPR_PROCESS_START 7 <br> ORGANIZATION_TYPE 58 <br> FONDKAPREMONT_MODE 4 <br> HOUSETYPE_MODE 3 <br> WALLSMATERIAL_MODE 7 <br> EMERGENCYSTATE_MODE 2 <br> dtype: int64</code> <br> <br>  Tenemos 16 columnas, cada una con 2 a 58 opciones de valor diferentes.  En general, los modelos de aprendizaje autom√°tico no pueden hacer nada con tales columnas (excepto algunas, como LightGBM o CatBoost).  Como planeamos probar diferentes modelos en el conjunto de datos, es necesario hacer algo con esto.  B√°sicamente hay dos enfoques: <br><br><ul><li>  Codificaci√≥n de etiquetas: a las categor√≠as se les asignan d√≠gitos 0, 1, 2, etc., y se escriben en la misma columna </li><li>  One-Hot-encoding: una columna se descompone en varias seg√∫n el n√∫mero de opciones y estas columnas indican qu√© opci√≥n tiene este registro. </li></ul><br>  Entre los m√°s populares, vale la pena se√±alar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la codificaci√≥n media del objetivo</a> (gracias por aclarar los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">rrangeorangepants</a> ). <br><br>  Hay un peque√±o problema con la codificaci√≥n de etiquetas: asigna valores num√©ricos que no tienen nada que ver con la realidad.  Por ejemplo, si estamos tratando con un valor num√©rico, entonces el ingreso del prestatario de 100,000 es definitivamente mayor y mejor que el ingreso de 20,000. Pero podemos decir que, por ejemplo, una ciudad es mejor que otra porque a una se le asigna el valor 100 y la otra 200 ? <br><br>  La codificaci√≥n One-Hot, por otro lado, es m√°s segura, pero puede producir columnas "adicionales".  Por ejemplo, si codificamos el mismo g√©nero usando One-Hot, obtenemos dos columnas, "g√©nero masculino" y "g√©nero femenino", aunque una ser√≠a suficiente, "¬øes masculino". <br><br>  Para un buen conjunto de datos, ser√≠a necesario codificar signos con baja variabilidad utilizando Label Encoding y todo lo dem√°s: One-Hot, pero por simplicidad codificamos todo de acuerdo con One-Hot.  Pr√°cticamente no afectar√° la velocidad de c√°lculo y el resultado.  El proceso de codificaci√≥n de pandas en s√≠ mismo es muy simple. <br><br><pre> <code class="python hljs">app_train = pd.get_dummies(app_train) app_test = pd.get_dummies(app_test)‚Äã print(<span class="hljs-string"><span class="hljs-string">'Training Features shape: '</span></span>, app_train.shape) print(<span class="hljs-string"><span class="hljs-string">'Testing Features shape: '</span></span>, app_test.shape)</code> </pre> <br> <code>Training Features shape: (307511, 246) <br> Testing Features shape: (48744, 242)</code> <br> <br>  Como el n√∫mero de opciones en las columnas de selecci√≥n no es igual, el n√∫mero de columnas ahora no coincide.  Se requiere alineaci√≥n: debe eliminar las columnas del conjunto de entrenamiento que no est√°n en el conjunto de prueba.  Esto hace que el m√©todo de alineaci√≥n, necesite especificar axis = 1 (para columnas). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># ,           . train_labels = app_train['TARGET']‚Äã #  -   .     app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)‚Äã print('  : ', app_train.shape) print('  : ', app_test.shape)‚Äã # Add target back in to the data app_train['TARGET'] = train_labels</span></span></code> </pre> <br> <code>  : (307511, 242) <br>   : (48744, 242)</code> <br> <br><h3>  Correlaci√≥n de datos </h3><br>  Una buena manera de comprender los datos es calcular los coeficientes de correlaci√≥n de Pearson para los datos relativos al atributo objetivo.  Este no es el mejor m√©todo para mostrar la relevancia de las caracter√≠sticas, pero es simple y le permite tener una idea de los datos.  Los coeficientes se pueden interpretar de la siguiente manera: <br><br><ul><li>  00-.19 "muy d√©bil" </li><li>  20-.39 "d√©bil" </li><li>  40-.59 "promedio" </li><li>  60-.79 fuerte </li><li>  80-1.0 "muy fuerte" </li></ul><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    correlations = app_train.corr()['TARGET'].sort_values()‚Äã #  print('  : \n', correlations.tail(15)) print('\n  : \n', correlations.head(15))</span></span></code> </pre> <br> <code>  : <br> DAYS_REGISTRATION 0.041975 <br> OCCUPATION_TYPE_Laborers 0.043019 <br> FLAG_DOCUMENT_3 0.044346 <br> REG_CITY_NOT_LIVE_CITY 0.044395 <br> FLAG_EMP_PHONE 0.045982 <br> NAME_EDUCATION_TYPE_Secondary / secondary special 0.049824 <br> REG_CITY_NOT_WORK_CITY 0.050994 <br> DAYS_ID_PUBLISH 0.051457 <br> CODE_GENDER_M 0.054713 <br> DAYS_LAST_PHONE_CHANGE 0.055218 <br> NAME_INCOME_TYPE_Working 0.057481 <br> REGION_RATING_CLIENT 0.058899 <br> REGION_RATING_CLIENT_W_CITY 0.060893 <br> DAYS_BIRTH 0.078239 <br> TARGET 1.000000 <br> Name: TARGET, dtype: float64 <br> <br>   : <br> EXT_SOURCE_3 -0.178919 <br> EXT_SOURCE_2 -0.160472 <br> EXT_SOURCE_1 -0.155317 <br> NAME_EDUCATION_TYPE_Higher education -0.056593 <br> CODE_GENDER_F -0.054704 <br> NAME_INCOME_TYPE_Pensioner -0.046209 <br> ORGANIZATION_TYPE_XNA -0.045987 <br> DAYS_EMPLOYED -0.044932 <br> FLOORSMAX_AVG -0.044003 <br> FLOORSMAX_MEDI -0.043768 <br> FLOORSMAX_MODE -0.043226 <br> EMERGENCYSTATE_MODE_No -0.042201 <br> HOUSETYPE_MODE_block of flats -0.040594 <br> AMT_GOODS_PRICE -0.039645 <br> REGION_POPULATION_RELATIVE -0.037227 <br> Name: TARGET, dtype: float64</code> <br> <br>  Por lo tanto, todos los datos se correlacionan d√©bilmente con el objetivo (excepto el objetivo en s√≠, que, por supuesto, es igual a s√≠ mismo).  Sin embargo, la edad y algunas "fuentes de datos externas" se distinguen de los datos.  Estos son probablemente algunos datos adicionales de otras organizaciones de cr√©dito.  Es curioso que aunque el objetivo se declare independiente de dichos datos al tomar una decisi√≥n de cr√©dito, de hecho nos basaremos principalmente en ellos. <br><br><h3>  Edad </h3><br>  Est√° claro que cuanto mayor es el cliente, mayor es la probabilidad de un retorno (hasta cierto l√≠mite, por supuesto).  Pero por alguna raz√≥n, la edad se indica en d√≠as negativos antes de que se emita un pr√©stamo, por lo tanto, se correlaciona positivamente con la falta de reembolso (lo que parece algo extra√±o).  Lo llevamos a un valor positivo y observamos la correlaci√≥n. <br><br><pre> <code class="python hljs">app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>] = abs(app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>]) app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>].corr(app_train[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>])</code> </pre> <br> <code>-0.078239308309827088</code> <br> <br>  Echemos un vistazo m√°s de cerca a la variable.  Comencemos con el histograma. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     ,  25  plt.hist(app_train['DAYS_BIRTH'] / 365, edgecolor = 'k', bins = 25) plt.title('Age of Client'); plt.xlabel('Age (years)'); plt.ylabel('Count');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/v2/zq/1q/v2zq1qolo8rc5wx0tyao4ucygxc.png"><br><br>  El histograma de distribuci√≥n en s√≠ puede ser un poco √∫til, excepto que no vemos valores at√≠picos especiales y todo parece m√°s o menos cre√≠ble.  Para mostrar el efecto de la influencia de la edad en el resultado, podemos construir un gr√°fico de estimaci√≥n de la densidad del n√∫cleo (KDE): la distribuci√≥n de la densidad nuclear, pintada con los colores del atributo objetivo.  Muestra la distribuci√≥n de una variable y puede interpretarse como un histograma suavizado (calculado como un n√∫cleo gaussiano para cada punto, que luego se promedia para suavizar). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365, label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365, label = 'target == 1')‚Äã #  plt.xlabel('Age (years)'); plt.ylabel('Density'); plt.title('Distribution of Ages');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/st/xs/e1/stxse1wipiaqcf0a7trlm0lwz0g.png"><br><br>  Como puede verse, la proporci√≥n de impagos es mayor para los j√≥venes y disminuye a medida que aumenta la edad.  Esta no es una raz√≥n para rechazar siempre el cr√©dito a los j√≥venes, tal "recomendaci√≥n" solo conducir√° a la p√©rdida de ingresos y al mercado para el banco.  Esta es una ocasi√≥n para pensar en un monitoreo m√°s exhaustivo de dichos pr√©stamos, evaluaciones y, posiblemente, incluso alg√∫n tipo de educaci√≥n financiera para j√≥venes prestatarios. <br><br><h3>  Fuentes externas </h3><br>  Echemos un vistazo m√°s de cerca a las "fuentes de datos externas" EXT_SOURCE y su correlaci√≥n. <br><br><pre> <code class="python hljs">ext_data = app_train[[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_1'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_2'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_3'</span></span>, <span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>]] ext_data_corrs = ext_data.corr() ext_data_corrs</code> </pre> <br><img src="https://habrastorage.org/webt/5k/ba/fe/5kbafej-y0vvcexlt6iebcjvjbs.png"><br><br>  Tambi√©n es conveniente mostrar la correlaci√≥n usando el mapa de calor <br><br><pre> <code class="python hljs">sns.heatmap(ext_data_corrs, cmap = plt.cm.RdYlBu_r, vmin = <span class="hljs-number"><span class="hljs-number">-0.25</span></span>, annot = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, vmax = <span class="hljs-number"><span class="hljs-number">0.6</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'Correlation Heatmap'</span></span>);</code> </pre> <br><img src="https://habrastorage.org/webt/e6/wj/vw/e6wjvwnetgs2y-i65_4okda-6t8.png"><br><br>  Como puede ver, todas las fuentes muestran una correlaci√≥n negativa con el objetivo.  Veamos la distribuci√≥n de KDE para cada fuente. <br><br><pre> <code class="python hljs">plt.figure(figsize = (<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment">#    for i, source in enumerate(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']): #  plt.subplot(3, 1, i + 1) #    sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, source], label = 'target == 0') #    sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, source], label = 'target == 1') #  plt.title('Distribution of %s by Target Value' % source) plt.xlabel('%s' % source); plt.ylabel('Density'); plt.tight_layout(h_pad = 2.5)</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/lf/ig/xm/lfigxmxlck1s4w2uyygfudghajm.png"><br><br>  La imagen es similar a la distribuci√≥n por edad: con un aumento en el indicador, aumenta la probabilidad de un pr√©stamo.  La tercera fuente es la m√°s poderosa a este respecto.  Aunque en t√©rminos absolutos la correlaci√≥n con la variable objetivo todav√≠a est√° en la categor√≠a "muy baja", las fuentes de datos externas y la edad ser√°n de la mayor importancia en la construcci√≥n del modelo. <br><br><h3>  Horario par </h3><br>  Para comprender mejor la relaci√≥n de estas variables, puede construir un gr√°fico de pares, en √©l podemos ver la relaci√≥n de cada par y un histograma de la distribuci√≥n a lo largo de la diagonal.  Por encima de la diagonal, puede mostrar el diagrama de dispersi√≥n, y debajo - 2d KDE. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       age_data = app_train[['TARGET', 'DAYS_BIRTH']] age_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / 365‚Äã #     plot_data = ext_data.drop(labels = ['DAYS_BIRTH'], axis=1).copy()‚Äã #   plot_data['YEARS_BIRTH'] = age_data['YEARS_BIRTH']‚Äã #         100 .  plot_data = plot_data.dropna().loc[:100000, :]‚Äã #     def corr_func(x, y, **kwargs): r = np.corrcoef(x, y)[0][1] ax = plt.gca() ax.annotate("r = {:.2f}".format(r), xy=(.2, .8), xycoords=ax.transAxes, size = 20)‚Äã #   pairgrid object grid = sns.PairGrid(data = plot_data, size = 3, diag_sharey=False, hue = 'TARGET', vars = [x for x in list(plot_data.columns) if x != 'TARGET'])‚Äã #  -  grid.map_upper(plt.scatter, alpha = 0.2)‚Äã #  -  grid.map_diag(sns.kdeplot)‚Äã #  -   grid.map_lower(sns.kdeplot, cmap = plt.cm.OrRd_r);‚Äã plt.suptitle('Ext Source and Age Features Pairs Plot', size = 32, y = 1.05);</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/wu/bm/ut/wubmutz04p4kwsmmk34gbuoq71g.png"><br><br>  Los pr√©stamos reembolsables se muestran en azul, no reembolsables en rojo.  Interpretar todo esto es bastante dif√≠cil, pero una buena impresi√≥n en una camiseta o una imagen en un museo de arte moderno puede salir de esta imagen. <br><br><h3>  Examen de otros signos. </h3><br>  Consideremos con m√°s detalle otras caracter√≠sticas y su dependencia de la variable objetivo.  Como hay muchos categ√≥ricos (y ya logramos codificarlos), nuevamente necesitamos los datos iniciales.  Llamemos un poco diferente para evitar confusiones <br><br><pre> <code class="python hljs">application_train = pd.read_csv(PATH+<span class="hljs-string"><span class="hljs-string">"application_train.csv"</span></span>) application_test = pd.read_csv(PATH+<span class="hljs-string"><span class="hljs-string">"application_test.csv"</span></span>)</code> </pre> <br>  Tambi√©n necesitaremos un par de funciones para mostrar bellamente las distribuciones y su influencia en la variable objetivo.  Muchas gracias <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">a</a> ellos por el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">autor de</a> este <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">n√∫cleo.</a> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_stats</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(feature,label_rotation=False,horizontal_layout=True)</span></span></span><span class="hljs-function">:</span></span> temp = application_train[feature].value_counts() df1 = pd.DataFrame({feature: temp.index,<span class="hljs-string"><span class="hljs-string">' '</span></span>: temp.values})‚Äã <span class="hljs-comment"><span class="hljs-comment">#   target=1   cat_perc = application_train[[feature, 'TARGET']].groupby([feature],as_index=False).mean() cat_perc.sort_values(by='TARGET', ascending=False, inplace=True) if(horizontal_layout): fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6)) else: fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12,14)) sns.set_color_codes("pastel") s = sns.barplot(ax=ax1, x = feature, y=" ",data=df1) if(label_rotation): s.set_xticklabels(s.get_xticklabels(),rotation=90) s = sns.barplot(ax=ax2, x = feature, y='TARGET', order=cat_perc[feature], data=cat_perc) if(label_rotation): s.set_xticklabels(s.get_xticklabels(),rotation=90) plt.ylabel(' ', fontsize=10) plt.tick_params(axis='both', which='major', labelsize=10)‚Äã plt.show();</span></span></code> </pre> <br>  Por lo tanto, consideraremos los principales signos de los clientes. <br><br><h3>  Tipo de pr√©stamo </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_TYPE'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/gf/xr/hd/gfxrhdfhqe7zyvlvwjmtgg-opam.png"><br><br>  Curiosamente, los pr√©stamos renovables (probablemente sobregiros o algo as√≠) representan menos del 10% del n√∫mero total de pr√©stamos.  Al mismo tiempo, el porcentaje de no retorno entre ellos es mucho mayor.  Una buena raz√≥n para revisar la metodolog√≠a de trabajo con estos pr√©stamos, y tal vez incluso abandonarlos. <br><br><h3>  Sexo del cliente </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CODE_GENDER'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/fj/vu/eu/fjvueuchpemqvpmijfzsslyiy5m.png"><br><br>  Hay casi el doble de clientes femeninas que hombres, y los hombres muestran un riesgo mucho mayor. <br><br><h3>  Propiedad de autom√≥viles y propiedades </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'FLAG_OWN_CAR'</span></span>) plot_stats(<span class="hljs-string"><span class="hljs-string">'FLAG_OWN_REALTY'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/l4/iv/u4/l4ivu4-yhdkdma8yjrnhj07evdq.png"><br><img src="https://habrastorage.org/webt/fg/qn/2-/fgqn2-3qqhjvkbovec9zm_qkfgo.png"><br><br>  Los clientes con el autom√≥vil son la mitad de "sin caballo".  El riesgo es casi el mismo, los clientes con la m√°quina pagan un poco mejor. <br><br>  Para el sector inmobiliario, lo contrario es cierto: hay la mitad de los clientes sin √©l.  El riesgo para los propietarios tambi√©n es ligeramente menor. <br><br><h3>  Estado civil </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_FAMILY_STATUS'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/7u/qt/t1/7uqtt10kghqs01w-_y_1e6vx2jw.png"><br><br>  Si bien la mayor√≠a de los clientes est√°n casados, los m√°s riesgosos son los clientes civiles y solteros.  Los viudos muestran un riesgo m√≠nimo. <br><br><h3>  Numero de ni√±os </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CNT_CHILDREN'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/5s/ux/o8/5suxo8vh8yl68pnxqf4vm7c-ixa.png"><br><br>  La mayor√≠a de los clientes no tienen hijos.  Al mismo tiempo, los clientes con 9 y 11 ni√±os muestran un no reembolso completo <br><br><pre> <code class="python hljs">application_train.CNT_CHILDREN.value_counts()</code> </pre> <br> <code>0 215371 <br> 1 61119 <br> 2 26749 <br> 3 3717 <br> 4 429 <br> 5 84 <br> 6 21 <br> 7 7 <br> 14 3 <br> 19 2 <br> 12 2 <br> 10 2 <br> 9 2 <br> 8 2 <br> 11 1 <br> Name: CNT_CHILDREN, dtype: int64</code> <br> <br>  Como muestra el c√°lculo de los valores, estos datos son estad√≠sticamente insignificantes: solo 1-2 clientes de ambas categor√≠as.  Sin embargo, los tres entraron en incumplimiento, al igual que la mitad de los clientes con 6 hijos. <br><br><h3>  Numero de miembros de la familia </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CNT_FAM_MEMBERS'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/bw/tg/sc/bwtgsctk9vk_y8tcx9bv9fraogu.png"><br><br>  La situaci√≥n es similar: cuantas menos bocas, mayor ser√° el rendimiento. <br><br><h3>  Tipo de ingreso </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_INCOME_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/ow/la/kf/owlakfzs7cqh74msyjw9ngeq8h4.png"><br><br>  Es probable que las madres solteras y los desempleados sean interrumpidos en la etapa de solicitud; hay muy pocos de ellos en la muestra.  Pero los problemas se muestran de manera estable. <br><br><h3>  Tipo de actividad </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'OCCUPATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/pw/m4/eu/pwm4eui3y46rrd0380w5jnkqiug.png"><br><br><pre> <code class="python hljs">application_train.OCCUPATION_TYPE.value_counts()</code> </pre> <br> <code>Laborers 55186 <br> Sales staff 32102 <br> Core staff 27570 <br> Managers 21371 <br> Drivers 18603 <br> High skill tech staff 11380 <br> Accountants 9813 <br> Medicine staff 8537 <br> Security staff 6721 <br> Cooking staff 5946 <br> Cleaning staff 4653 <br> Private service staff 2652 <br> Low-skill Laborers 2093 <br> Waiters/barmen staff 1348 <br> Secretaries 1305 <br> Realty agents 751 <br> HR staff 563 <br> IT staff 526 <br> Name: OCCUPATION_TYPE, dtype: int64</code> <br> <br>  Es de inter√©s para los conductores y los oficiales de seguridad que son bastante numerosos y enfrentan problemas con m√°s frecuencia que otras categor√≠as. <br><br><h3>  Educacion </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_EDUCATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/dh/g9/-t/dhg9-t4wl5oaaultg0m4ujq4ky0.png"><br><br>  Cuanto mayor es la educaci√≥n, mejor es la recurrencia, obviamente. <br><br><h3>  Tipo de organizaci√≥n: empleador </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'ORGANIZATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/nm/eq/p-/nmeqp-rvrmowwpqhkjzvygeah20.png"><br><br>  El mayor porcentaje de no retorno se observa en Transporte: tipo 3 (16%), Industria: tipo 13 (13.5%), Industria: tipo 8 (12.5%) y Restaurante (hasta 12%). <br><br><h3>  Asignaci√≥n de pr√©stamos </h3><br>  Considere la distribuci√≥n de los montos de los pr√©stamos y su impacto en el reembolso <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>)) plt.title(<span class="hljs-string"><span class="hljs-string">" AMT_CREDIT"</span></span>) ax = sns.distplot(app_train[<span class="hljs-string"><span class="hljs-string">"AMT_CREDIT"</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/x1/8k/qg/x18kqghr1tue4io96l_keuqcr94.png"><br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'AMT_CREDIT'], label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'AMT_CREDIT'], label = 'target == 1')‚Äã #  plt.xlabel(' '); plt.ylabel(''); plt.title(' ');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/_3/fu/cj/_3fucjn19lmxvjjaamrrlwumh5m.png"><br><br>  Como muestra el gr√°fico de densidad, las cantidades s√≥lidas se devuelven con mayor frecuencia <br><br><h3>  Distribuci√≥n de la densidad </h3><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>)) plt.title(<span class="hljs-string"><span class="hljs-string">" REGION_POPULATION_RELATIVE"</span></span>) ax = sns.distplot(app_train[<span class="hljs-string"><span class="hljs-string">"REGION_POPULATION_RELATIVE"</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/26/3h/os/263hoss0mbvvq2p0ewagrw5v-sm.png"><br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'REGION_POPULATION_RELATIVE'], label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'REGION_POPULATION_RELATIVE'], label = 'target == 1')‚Äã #  plt.xlabel(''); plt.ylabel(' '); plt.title(' ');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/fs/ez/82/fsez82q5fbqdkiqizkxjralpm-8.png"><br><br>  Los clientes de regiones m√°s pobladas tienden a pagar mejor los pr√©stamos. <br><br>  Por lo tanto, tenemos una idea de las principales caracter√≠sticas del conjunto de datos y su influencia en el resultado.  No haremos nada espec√≠ficamente con los enumerados en este art√≠culo, pero pueden resultar muy importantes en el trabajo futuro. <br><br><h2>  Ingenier√≠a de caracter√≠sticas - Conversi√≥n de caracter√≠sticas </h2><br>  Las competiciones en Kaggle se ganan mediante la transformaci√≥n de los signos: gana el que pueda crear los signos m√°s √∫tiles a partir de los datos.  Al menos para los datos estructurados, los modelos ganadores ahora son b√°sicamente diferentes opciones de aumento de gradiente.  La mayor√≠a de las veces, es m√°s eficiente pasar tiempo convirtiendo atributos que configurando hiperpar√°metros o seleccionando modelos.  Un modelo todav√≠a puede aprender solo de los datos que se le han transferido.  Asegurarse de que los datos sean relevantes para la tarea es la responsabilidad principal de la fecha del Cient√≠fico. <br><br>  El proceso de transformaci√≥n de caracter√≠sticas puede incluir la creaci√≥n de nuevos datos disponibles, la selecci√≥n de los m√°s importantes disponibles, etc.  Esta vez intentaremos con signos polin√≥micos. <br><br><h3>  Signos polinomiales </h3><br>  El m√©todo polin√≥mico de construcci√≥n de caracter√≠sticas es que simplemente creamos caracter√≠sticas que son el grado de caracter√≠sticas disponibles y sus productos.  En algunos casos, tales caracter√≠sticas construidas pueden tener una correlaci√≥n m√°s fuerte con la variable objetivo que sus "padres".  Aunque tales m√©todos se usan a menudo en modelos estad√≠sticos, son mucho menos comunes en el aprendizaje autom√°tico.  Sin embargo  nada nos impide probarlos, especialmente dado que Scikit-Learn tiene una clase espec√≠ficamente para estos fines, PolynomialFeatures, que crea caracter√≠sticas polin√≥micas y sus productos, solo necesita especificar las caracter√≠sticas originales en s√≠ mismas y el grado m√°ximo en el que deben elevarse.  Utilizamos los efectos m√°s potentes sobre el resultado de 4 atributos y el grado 3 para no complicar demasiado el modelo y evitar el sobreajuste (sobreentrenamiento del modelo, su ajuste excesivo a la muestra de entrenamiento). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       poly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']] poly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]‚Äã #    from sklearn.preprocessing import Imputer imputer = Imputer(strategy = 'median')‚Äã poly_target = poly_features['TARGET']‚Äã poly_features = poly_features.drop('TARGET', axis=1)‚Äã poly_features = imputer.fit_transform(poly_features) poly_features_test = imputer.transform(poly_features_test) from sklearn.preprocessing import PolynomialFeatures #     3 poly_transformer = PolynomialFeatures(degree = 3) #    poly_transformer.fit(poly_features) #   poly_features = poly_transformer.transform(poly_features) poly_features_test = poly_transformer.transform(poly_features_test) print('  : ', poly_features.shape)</span></span></code> </pre> <br> <code>  : (307511, 35) <br>        get_feature_names</code> <br> <br><pre> <code class="python hljs">poly_transformer.get_feature_names(input_features = [<span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_1'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_2'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_3'</span></span>, <span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>])[:<span class="hljs-number"><span class="hljs-number">15</span></span>]</code> </pre> <br> <code>['1', <br> 'EXT_SOURCE_1', <br> 'EXT_SOURCE_2', <br> 'EXT_SOURCE_3', <br> 'DAYS_BIRTH', <br> 'EXT_SOURCE_1^2', <br> 'EXT_SOURCE_1 EXT_SOURCE_2', <br> 'EXT_SOURCE_1 EXT_SOURCE_3', <br> 'EXT_SOURCE_1 DAYS_BIRTH', <br> 'EXT_SOURCE_2^2', <br> 'EXT_SOURCE_2 EXT_SOURCE_3', <br> 'EXT_SOURCE_2 DAYS_BIRTH', <br> 'EXT_SOURCE_3^2', <br> 'EXT_SOURCE_3 DAYS_BIRTH', <br> 'DAYS_BIRTH^2']</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un total de 35 caracter√≠sticas polin√≥micas y derivadas. </font><font style="vertical-align: inherit;">Verifique su correlaci√≥n con el objetivo.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     poly_features = pd.DataFrame(poly_features, columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']))‚Äã #   poly_features['TARGET'] = poly_target‚Äã #   poly_corrs = poly_features.corr()['TARGET'].sort_values()‚Äã #      print(poly_corrs.head(10)) print(poly_corrs.tail(5))</span></span></code> </pre> <br> <code>EXT_SOURCE_2 EXT_SOURCE_3 -0.193939 <br> EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3 -0.189605 <br> EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH -0.181283 <br> EXT_SOURCE_2^2 EXT_SOURCE_3 -0.176428 <br> EXT_SOURCE_2 EXT_SOURCE_3^2 -0.172282 <br> EXT_SOURCE_1 EXT_SOURCE_2 -0.166625 <br> EXT_SOURCE_1 EXT_SOURCE_3 -0.164065 <br> EXT_SOURCE_2 -0.160295 <br> EXT_SOURCE_2 DAYS_BIRTH -0.156873 <br> EXT_SOURCE_1 EXT_SOURCE_2^2 -0.156867 <br> Name: TARGET, dtype: float64 <br> DAYS_BIRTH -0.078239 <br> DAYS_BIRTH^2 -0.076672 <br> DAYS_BIRTH^3 -0.074273 <br> TARGET 1.000000 <br> 1 NaN <br> Name: TARGET, dtype: float64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entonces, algunos signos muestran una correlaci√≥n m√°s alta que la original. </font><font style="vertical-align: inherit;">Tiene sentido intentar aprender con ellos y sin ellos (como mucho m√°s en el aprendizaje autom√°tico, esto se puede determinar experimentalmente). </font><font style="vertical-align: inherit;">Para hacer esto, cree una copia de los marcos de datos y agregue nuevas caracter√≠sticas all√≠.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      poly_features_test = pd.DataFrame(poly_features_test, columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']))‚Äã #    poly_features['SK_ID_CURR'] = app_train['SK_ID_CURR'] app_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')‚Äã #    poly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR'] app_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')‚Äã #   app_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)‚Äã #   print('    : ', app_train_poly.shape) print('    : ', app_test_poly.shape)</span></span></code> </pre> <br> <code>    : (307511, 277) <br>     : (48744, 277)</code> <br> <br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Entrenamiento modelo </font></font></h2><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Nivel b√°sico </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En los c√°lculos, debe comenzar desde un nivel b√°sico del modelo, por debajo del cual ya no es posible caer. </font><font style="vertical-align: inherit;">En nuestro caso, esto podr√≠a ser 0.5 para todos los clientes de prueba; esto muestra que no tenemos idea de si el cliente pagar√° el pr√©stamo o no. </font><font style="vertical-align: inherit;">En nuestro caso, ya se ha realizado un trabajo preliminar y se pueden utilizar modelos m√°s complejos.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Regresi√≥n log√≠stica </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para calcular la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">regresi√≥n log√≠stica,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> necesitamos tomar tablas con caracter√≠sticas categ√≥ricas codificadas, completar los datos faltantes y normalizarlos (llevarlos a valores de 0 a 1). </font><font style="vertical-align: inherit;">Todo esto ejecuta el siguiente c√≥digo:</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MinMaxScaler, Imputer‚Äã <span class="hljs-comment"><span class="hljs-comment">#      if 'TARGET' in app_train: train = app_train.drop(labels = ['TARGET'], axis=1) else: train = app_train.copy() features = list(train.columns)‚Äã #    test = app_test.copy()‚Äã #     imputer = Imputer(strategy = 'median')‚Äã #  scaler = MinMaxScaler(feature_range = (0, 1))‚Äã #    imputer.fit(train)‚Äã #      train = imputer.transform(train) test = imputer.transform(app_test)‚Äã #      scaler.fit(train) train = scaler.transform(train) test = scaler.transform(test)‚Äã print('  : ', train.shape) print('  : ', test.shape)</span></span></code> </pre> <br> <code>  : (307511, 242) <br>   : (48744, 242)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Utilizamos la regresi√≥n log√≠stica de Scikit-Learn como primer modelo. </font><font style="vertical-align: inherit;">Tomemos el modelo de deflaci√≥n con una correcci√≥n: bajamos el par√°metro de regularizaci√≥n C para evitar el sobreajuste. </font><font style="vertical-align: inherit;">La sintaxis es normal: creamos un modelo, lo entrenamos y predecimos la probabilidad usando predict_proba (necesitamos probabilidad, no 0/1)</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LogisticRegression‚Äã <span class="hljs-comment"><span class="hljs-comment">#   log_reg = LogisticRegression(C = 0.0001)‚Äã #   log_reg.fit(train, train_labels) LogisticRegression(C=0.0001, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='liblinear', tol=0.0001, verbose=0, warm_start=False)      .  prdict_proba     mx 2,  m -  ,   -  0,  -  1.    ( ). log_reg_pred = log_reg.predict_proba(test)[:, 1]</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ahora puede crear un archivo para cargar en Kaggle. </font><font style="vertical-align: inherit;">Cree un marco de datos a partir de la identificaci√≥n del cliente y la probabilidad de no devoluci√≥n y c√°rguelo.</font></font><br><br><pre> <code class="python hljs">submit = app_test[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]] submit[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>] = log_reg_pred‚Äã submit.head()</code> </pre> <br> <code>SK_ID_CURR TARGET <br> 0 100001 0.087954 <br> 1 100005 0.163151 <br> 2 100013 0.109923 <br> 3 100028 0.077124 <br> 4 100038 0.151694</code> <br> <br><pre> <code class="python hljs">submit.to_csv(<span class="hljs-string"><span class="hljs-string">'log_reg_baseline.csv'</span></span>, index = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Entonces, el resultado de nuestro trabajo tit√°nico: 0.673, con el mejor resultado para hoy es 0.802.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modelo mejorado - Bosque aleatorio </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Logreg no se muestra muy bien, intentemos usar un modelo mejorado: un bosque aleatorio. </font><font style="vertical-align: inherit;">Este es un modelo mucho m√°s poderoso que puede construir cientos de √°rboles y producir un resultado mucho m√°s preciso. </font><font style="vertical-align: inherit;">Usamos 100 √°rboles. </font><font style="vertical-align: inherit;">El esquema de trabajar con el modelo es el mismo, completamente est√°ndar: cargar el clasificador, entrenamiento. </font><font style="vertical-align: inherit;">predicci√≥n</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier‚Äã <span class="hljs-comment"><span class="hljs-comment">#   random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50)‚Äã #     random_forest.fit(train, train_labels)‚Äã #     predictions = random_forest.predict_proba(test)[:, 1]‚Äã #     submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #  submit.to_csv('random_forest_baseline.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El resultado aleatorio del bosque es ligeramente mejor - 0.683</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modelo de entrenamiento con caracter√≠sticas polin√≥micas. </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ahora que tenemos un modelo. </font><font style="vertical-align: inherit;">que hace al menos algo: es hora de probar nuestros signos polin√≥micos. </font><font style="vertical-align: inherit;">Hagamos lo mismo con ellos y comparemos el resultado.</font></font><br><br><pre> <code class="python hljs">poly_features_names = list(app_train_poly.columns)‚Äã <span class="hljs-comment"><span class="hljs-comment">#         imputer = Imputer(strategy = 'median')‚Äã poly_features = imputer.fit_transform(app_train_poly) poly_features_test = imputer.transform(app_test_poly)‚Äã #  scaler = MinMaxScaler(feature_range = (0, 1))‚Äã poly_features = scaler.fit_transform(poly_features) poly_features_test = scaler.transform(poly_features_test)‚Äã random_forest_poly = RandomForestClassifier(n_estimators = 100, random_state = 50) #     random_forest_poly.fit(poly_features, train_labels)‚Äã #  predictions = random_forest_poly.predict_proba(poly_features_test)[:, 1]‚Äã #    submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #   submit.to_csv('random_forest_baseline_engineered.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El resultado de un bosque aleatorio con caracter√≠sticas polin√≥micas ha empeorado: 0.633. </font><font style="vertical-align: inherit;">Lo que pone en tela de juicio la necesidad de su uso.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Aumento de gradiente </font></font></h3><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El aumento de gradiente</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> es un "modelo serio" para el aprendizaje autom√°tico. </font><font style="vertical-align: inherit;">Casi todas las √∫ltimas competiciones son "arrastradas" exactamente. </font><font style="vertical-align: inherit;">Vamos a construir un modelo simple y probar su rendimiento.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LGBMClassifier‚Äã clf = LGBMClassifier() clf.fit(train, train_labels)‚Äã predictions = clf.predict_proba(test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]‚Äã <span class="hljs-comment"><span class="hljs-comment">#    submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #   submit.to_csv('lightgbm_baseline.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El resultado de LightGBM es 0.735, lo que deja atr√°s a todos los dem√°s modelos.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Interpretaci√≥n del modelo: importancia de los atributos </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La forma m√°s f√°cil de interpretar un modelo es observar la importancia de las caracter√≠sticas (que no todos los modelos pueden hacer). </font><font style="vertical-align: inherit;">Como nuestro clasificador proces√≥ la matriz, tomar√° algo de trabajo volver a configurar los nombres de las columnas de acuerdo con las columnas de esta matriz.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      def show_feature_importances(model, features): plt.figure(figsize = (12, 8)) #          results = pd.DataFrame({'feature': features, 'importance': model.feature_importances_}) results = results.sort_values('importance', ascending = False) #  print(results.head(10)) print('\n     0.01 = ', np.sum(results['importance'] &gt; 0.01)) #  results.head(20).plot(x = 'feature', y = 'importance', kind = 'barh', color = 'red', edgecolor = 'k', title = 'Feature Importances'); return results #         feature_importances = show_feature_importances(clf, features)</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como era de esperar, la m√°s importante modelar todas las mismas caracter√≠sticas 4. </font><font style="vertical-align: inherit;">La importancia de los atributos no es el mejor m√©todo de interpretaci√≥n del modelo, pero le permite comprender los principales factores que utiliza el modelo para las predicciones.</font></font><code>feature importance <br> 28 EXT_SOURCE_1 310 <br> 30 EXT_SOURCE_3 282 <br> 29 EXT_SOURCE_2 271 <br> 7 DAYS_BIRTH 192 <br> 3 AMT_CREDIT 161 <br> 4 AMT_ANNUITY 142 <br> 5 AMT_GOODS_PRICE 129 <br> 8 DAYS_EMPLOYED 127 <br> 10 DAYS_ID_PUBLISH 102 <br> 9 DAYS_REGISTRATION 69 <br> <br>     0.01 = 158</code> <br> <br><img src="https://habrastorage.org/webt/uc/pi/ox/ucpiox1dno_vps4lsuk0lmxk7si.png"><br><br><font style="vertical-align: inherit;"></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Agregar datos de otras tablas </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ahora consideraremos cuidadosamente tablas adicionales y qu√© se puede hacer con ellas. </font><font style="vertical-align: inherit;">Inmediatamente comience a preparar mesas para m√°s capacitaci√≥n. </font><font style="vertical-align: inherit;">Pero primero, elimine las tablas voluminosas pasadas de la memoria, borre la memoria utilizando el recolector de basura e importe las bibliotecas necesarias para un an√°lisis posterior.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gc‚Äã <span class="hljs-comment"><span class="hljs-comment">#del app_train, app_test, train_labels, application_train, application_test, poly_features, poly_features_test‚Äã gc.collect() import pandas as pd import numpy as np‚Äã from sklearn.preprocessing import MinMaxScaler, LabelEncoder from sklearn.model_selection import train_test_split, KFold from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix from sklearn.feature_selection import VarianceThreshold‚Äã from lightgbm import LGBMClassifier</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Importar datos, eliminar inmediatamente la columna de destino en una columna separada </font></font><br><br><pre> <code class="python hljs">data = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/application_train.csv'</span></span>) test = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/application_test.csv'</span></span>) prev = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/previous_application.csv'</span></span>) buro = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/bureau.csv'</span></span>) buro_balance = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/bureau_balance.csv'</span></span>) credit_card = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/credit_card_balance.csv'</span></span>) POS_CASH = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/POS_CASH_balance.csv'</span></span>) payments = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/installments_payments.csv'</span></span>)‚Äã <span class="hljs-comment"><span class="hljs-comment">#Separate target variable y = data['TARGET'] del data['TARGET']</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Codifique inmediatamente caracter√≠sticas categ√≥ricas. </font><font style="vertical-align: inherit;">Ya hicimos esto antes, codificamos las muestras de entrenamiento y prueba por separado, y luego alineamos los datos. </font><font style="vertical-align: inherit;">Intentemos un enfoque ligeramente diferente: encontraremos todos estos signos categ√≥ricos, combinaremos los marcos de datos, codificaremos de la lista de los encontrados y luego dividiremos nuevamente las muestras en entrenamiento y pruebas.</font></font><br><br><pre> <code class="python hljs">categorical_features = [col <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> data[col].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>]‚Äã one_hot_df = pd.concat([data,test]) one_hot_df = pd.get_dummies(one_hot_df, columns=categorical_features)‚Äã data = one_hot_df.iloc[:data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>],:] test = one_hot_df.iloc[data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]:,]‚Äã <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, data.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, test.shape)</code> </pre> <br> <code>   (307511, 245) <br>    (48744, 245)</code> <br> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Datos de la agencia de cr√©dito sobre el saldo mensual del pr√©stamo. </font></font></h3><br><pre> <code class="python hljs">buro_balance.head()</code> </pre> <br><img src="https://habrastorage.org/webt/pa/im/0s/paim0sea2cdjnvm7lok--vi8oke.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MONTHS_BALANCE: el n√∫mero de meses antes de la fecha de solicitud de un pr√©stamo. </font><font style="vertical-align: inherit;">Eche un vistazo m√°s de cerca a los "estados"</font></font><br><br><pre> <code class="python hljs">buro_balance.STATUS.value_counts()</code> </pre> <br> <code>C 13646993 <br> 0 7499507 <br> X 5810482 <br> 1 242347 <br> 5 62406 <br> 2 23419 <br> 3 8924 <br> 4 5847 <br> Name: STATUS, dtype: int64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Los estados significan lo siguiente: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - cerrado, es decir, pr√©stamo pagado. </font><font style="vertical-align: inherit;">X es un estado desconocido. </font><font style="vertical-align: inherit;">0 - pr√©stamo actual, sin morosidad. </font><font style="vertical-align: inherit;">1 - retraso de 1 a 30 d√≠as, 2 - retraso de 31 a 60 d√≠as, y as√≠ sucesivamente hasta el estado 5 - el pr√©stamo se vende a un tercero o se cancela. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aqu√≠, por ejemplo, se pueden distinguir los siguientes signos: buro_grouped_size - el n√∫mero de entradas en la base de datos buro_grouped_max - el saldo m√°ximo del pr√©stamo buro_grouped_min - el saldo m√≠nimo del pr√©stamo </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y todos estos estados de pr√©stamo pueden codificarse (utilizamos el m√©todo de desapilar, y luego adjuntamos los datos recibidos a la tabla buro, ya que SK_ID_BUREAU es lo mismo aqu√≠ y all√°.</font></font><br><br><pre> <code class="python hljs">buro_grouped_size = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].size() buro_grouped_max = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].max() buro_grouped_min = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].min()‚Äã buro_counts = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'STATUS'</span></span>].value_counts(normalize = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) buro_counts_unstacked = buro_counts.unstack(<span class="hljs-string"><span class="hljs-string">'STATUS'</span></span>) buro_counts_unstacked.columns = [<span class="hljs-string"><span class="hljs-string">'STATUS_0'</span></span>, <span class="hljs-string"><span class="hljs-string">'STATUS_1'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_2'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_3'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_4'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_5'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_C'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_X'</span></span>,] buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_COUNT'</span></span>] = buro_grouped_size buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_MIN'</span></span>] = buro_grouped_min buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_MAX'</span></span>] = buro_grouped_max‚Äã buro = buro.join(buro_counts_unstacked, how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> buro_balance gc.collect()</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Informaci√≥n general sobre oficinas de cr√©dito. </font></font></h3><br><pre> <code class="python hljs">buro.head()</code> </pre> <br><img src="https://habrastorage.org/webt/00/7q/dz/007qdzakfbvd5qiizsxqwxvoari.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(se muestran las primeras 7 columnas) Hay </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">bastantes datos que, en general, puede intentar codificar simplemente con One-Hot-Encoding, agrupar por SK_ID_CURR, promedio y, de la misma manera, prepararse para unirse a la tabla principal</font></font><br><br><pre> <code class="python hljs">buro_cat_features = [bcol <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> bcol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> buro.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> buro[bcol].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>] buro = pd.get_dummies(buro, columns=buro_cat_features) avg_buro = buro.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() avg_buro[<span class="hljs-string"><span class="hljs-string">'buro_count'</span></span>] = buro[[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>, <span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).count()[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_buro[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> buro gc.collect()</code> </pre> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Datos sobre solicitudes anteriores </font></font></h3><br><pre> <code class="python hljs">prev.head()</code> </pre> <br><img src="https://habrastorage.org/webt/nx/sv/z-/nxsvz-simhdingy0zqgnwg9xxpi.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Del mismo modo, codificamos caracter√≠sticas categ√≥ricas, promediamos y combinamos sobre la ID actual. </font></font><br><br><pre> <code class="python hljs">prev_cat_features = [pcol <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> pcol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> prev.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> prev[pcol].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>] prev = pd.get_dummies(prev, columns=prev_cat_features) avg_prev = prev.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() cnt_prev = prev[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).count() avg_prev[<span class="hljs-string"><span class="hljs-string">'nb_app'</span></span>] = cnt_prev[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_prev[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> prev gc.collect()</code> </pre> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Saldo de tarjeta de cr√©dito </font></font></h3><br><pre> <code class="python hljs">POS_CASH.head()</code> </pre> <br><img src="https://habrastorage.org/webt/aq/25/er/aq25erq2wzuknck85ina4twk2g8.png"><br><br><pre> <code class="python hljs">POS_CASH.NAME_CONTRACT_STATUS.value_counts()</code> </pre> <br> <code>Active 9151119 <br> Completed 744883 <br> Signed 87260 <br> Demand 7065 <br> Returned to the store 5461 <br> Approved 4917 <br> Amortized debt 636 <br> Canceled 15 <br> XNA 2 <br> Name: NAME_CONTRACT_STATUS, dtype: int64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Codificamos caracter√≠sticas categ√≥ricas y preparamos una tabla para combinar </font></font><br><br><pre> <code class="python hljs">le = LabelEncoder() POS_CASH[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] = le.fit_transform(POS_CASH[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>].astype(str)) nunique_status = POS_CASH[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).nunique() nunique_status2 = POS_CASH[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() POS_CASH[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS'</span></span>] = nunique_status[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] POS_CASH[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS2'</span></span>] = nunique_status2[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] POS_CASH.drop([<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Datos de la tarjeta </font></font></h3><br><pre> <code class="python hljs">credit_card.head()</code> </pre> <br><img src="https://habrastorage.org/webt/q5/wj/pj/q5wjpj8s-vak-svacdtlhqrwlus.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(primeras 7 columnas) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Trabajo similar</font></font><br><br><pre> <code class="python hljs">credit_card[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] = le.fit_transform(credit_card[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>].astype(str)) nunique_status = credit_card[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).nunique() nunique_status2 = credit_card[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() credit_card[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS'</span></span>] = nunique_status[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] credit_card[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS2'</span></span>] = nunique_status2[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] credit_card.drop([<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Datos de pago </font></font></h3><br><pre> <code class="python hljs">payments.head()</code> </pre> <br><img src="https://habrastorage.org/webt/ay/fy/3y/ayfy3yp5tzdxsffurkrgjd4udwu.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(se muestran las primeras 7 columnas) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Creemos tres tablas, con valores promedio, m√≠nimo y m√°ximo de esta tabla.</font></font><br><br><pre> <code class="python hljs">avg_payments = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() avg_payments2 = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() avg_payments3 = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).min() <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_payments[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> payments gc.collect()</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tabla de uni√≥n </font></font></h3><br><pre> <code class="python hljs">data = data.merge(right=avg_prev.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_prev.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_buro.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_buro.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(POS_CASH.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(POS_CASH.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(credit_card.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(credit_card.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments2.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments2.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments3.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments3.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_prev, avg_buro, POS_CASH, credit_card, avg_payments, avg_payments2, avg_payments3 gc.collect() <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, data.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, test.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, y.shape)</code> </pre> <br> <code>   (307511, 504) <br>    (48744, 504) <br>    (307511,)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬°Y, en realidad, golpearemos esta tabla duplicada con un aumento de gradiente! </font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LGBMClassifier‚Äã clf2 = LGBMClassifier() clf2.fit(data, y)‚Äã predictions = clf2.predict_proba(test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]‚Äã <span class="hljs-comment"><span class="hljs-comment">#    submission = test[['SK_ID_CURR']] submission['TARGET'] = predictions‚Äã #   submission.to_csv('lightgbm_full.csv', index = False)</span></span></code> </pre> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El resultado es 0.770. </font></font></b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OK, finalmente, intentemos una t√©cnica m√°s compleja con plegado en pliegues, validaci√≥n cruzada y elecci√≥n de la mejor iteraci√≥n.</font></font><br><br><pre> <code class="python hljs">folds = KFold(n_splits=<span class="hljs-number"><span class="hljs-number">5</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">546789</span></span>) oof_preds = np.zeros(data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) sub_preds = np.zeros(test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>])‚Äã feature_importance_df = pd.DataFrame()‚Äã feats = [f <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> [<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]]‚Äã <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n_fold, (trn_idx, val_idx) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(folds.split(data)): trn_x, trn_y = data[feats].iloc[trn_idx], y.iloc[trn_idx] val_x, val_y = data[feats].iloc[val_idx], y.iloc[val_idx] clf = LGBMClassifier( n_estimators=<span class="hljs-number"><span class="hljs-number">10000</span></span>, learning_rate=<span class="hljs-number"><span class="hljs-number">0.03</span></span>, num_leaves=<span class="hljs-number"><span class="hljs-number">34</span></span>, colsample_bytree=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, subsample=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, max_depth=<span class="hljs-number"><span class="hljs-number">8</span></span>, reg_alpha=<span class="hljs-number"><span class="hljs-number">.1</span></span>, reg_lambda=<span class="hljs-number"><span class="hljs-number">.1</span></span>, min_split_gain=<span class="hljs-number"><span class="hljs-number">.01</span></span>, min_child_weight=<span class="hljs-number"><span class="hljs-number">375</span></span>, silent=<span class="hljs-number"><span class="hljs-number">-1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">-1</span></span>, ) clf.fit(trn_x, trn_y, eval_set= [(trn_x, trn_y), (val_x, val_y)], eval_metric=<span class="hljs-string"><span class="hljs-string">'auc'</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">100</span></span>, early_stopping_rounds=<span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-comment"><span class="hljs-comment">#30 ) oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1] sub_preds += clf.predict_proba(test[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits fold_importance_df = pd.DataFrame() fold_importance_df["feature"] = feats fold_importance_df["importance"] = clf.feature_importances_ fold_importance_df["fold"] = n_fold + 1 feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0) print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx]))) del clf, trn_x, trn_y, val_x, val_y gc.collect()‚Äã print('Full AUC score %.6f' % roc_auc_score(y, oof_preds))‚Äã test['TARGET'] = sub_preds‚Äã test[['SK_ID_CURR', 'TARGET']].to_csv('submission_cross.csv', index=False)</span></span></code> </pre> <br> <code>Full AUC score 0.785845</code> <br> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scor final en kaggle 0.783</font></font></b> <br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> A donde ir ahora </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Definitivamente continuar trabajando con signos. Explore los datos, seleccione algunos de los signos, comb√≠nelos, adjunte tablas adicionales de una manera diferente. Puede experimentar con hiperpar√°metros Mogheli, muchas direcciones. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Espero que esta peque√±a compilaci√≥n le haya mostrado m√©todos modernos de investigaci√≥n de datos y preparaci√≥n de modelos predictivos. ¬°Aprenda datasaens, participe en concursos, sea genial! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y nuevamente enlaces a los n√∫cleos que me ayudaron a preparar este art√≠culo. El art√≠culo tambi√©n se publica en forma de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">computadora port√°til en Github</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , puede descargarlo, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">conjunto de datos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> y ejecutar y experimentar. </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Will Koehrsen. Comience aqu√≠: una introducci√≥n suave </font></font></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sban. HomeCreditRisk: Amplia l√≠nea de base EDA + [0.772]</font></font></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Gabriel Preda. Home Credit Default Risk Extensive EDA</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Pavan Raj. Loan repayers v/s Loan defaulters ‚Äî HOME CREDIT</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lem Lordje Ko. 15 lines: Just EXT_SOURCE_x</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Shanth. HOME CREDIT ‚Äî BUREAU DATA ‚Äî FEATURE ENGINEERING</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dmitriy Kisil. Good_fun_with_LigthGBM</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es414613/">https://habr.com/ru/post/es414613/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es414597/index.html">Preg√∫ntele a Ethan: ¬øQu√© tan cerca pueden unirse las civilizaciones alien√≠genas?</a></li>
<li><a href="../es414601/index.html">Cuando las monta√±as eran altas y las computadoras port√°tiles grandes: un poco m√°s de historia de TI</a></li>
<li><a href="../es414605/index.html">Mini imperios</a></li>
<li><a href="../es414609/index.html">¬øPuede 2018 PWA (Progressive Web Apps) ser una competencia digna para las aplicaciones nativas?</a></li>
<li><a href="../es414611/index.html">Mi historia de crear una aplicaci√≥n motivadora (iOS y Android) para una hija con una hija en Unity y C #</a></li>
<li><a href="../es414615/index.html">Olv√≠date del RGPD: la reforma de los derechos de autor de la UE podr√≠a cambiar completamente la web</a></li>
<li><a href="../es414619/index.html">Hogwarts rojos. Serie 8. Vela</a></li>
<li><a href="../es414621/index.html">El sistema rob√≥tico acelera el muestreo y las pruebas de sangre</a></li>
<li><a href="../es414625/index.html">Data Center World: ¬øvale la pena el viaje?</a></li>
<li><a href="../es414627/index.html">Desarrollo seguro en PHDays 8: Resultados de la reuni√≥n comunitaria PDUG</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
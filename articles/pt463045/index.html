<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏼 😡 👩🏼‍🎓 Detecta automaticamente emoções em conversas de texto usando redes neurais 👩🏽‍🏭 🙋🏻 ⏲️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Uma das principais tarefas dos sistemas de diálogo não é apenas fornecer as informações de que o usuário precisa, mas também gerar o maior número poss...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Detecta automaticamente emoções em conversas de texto usando redes neurais</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/463045/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t6/sr/jr/t6srjrmjjmm6qn8gpld9emy4txu.gif"></div><br>  Uma das principais tarefas dos sistemas de diálogo não é apenas fornecer as informações de que o usuário precisa, mas também gerar o maior número possível de respostas humanas.  E o reconhecimento das emoções do interlocutor não é mais apenas um recurso interessante, é uma necessidade vital.  Neste artigo, examinaremos a <b>arquitetura de uma rede neural recorrente para determinar emoções em conversas de texto</b> , que participou da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tarefa 3</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SemEval-2019 "EmoContext"</a> , a competição anual em linguística de computação.  A tarefa era classificar emoções (“feliz”, “triste”, “zangada” e “outras pessoas”) em uma conversa de três observações, na qual participaram um bot de bate-papo e uma pessoa. <br><br>  Na primeira parte do artigo, consideraremos a tarefa definida no EmoContext e os dados fornecidos pelos organizadores.  Na segunda e terceira partes, analisamos o processamento preliminar do texto e os modos de representação vetorial das palavras.  Na quarta parte, descrevemos a arquitetura LSTM que usamos na competição.  O código é escrito em Python usando a biblioteca Keras. <br><a name="habracut"></a><br><h2>  1. Dados de treinamento </h2><br>  A faixa “EmoContext” no SemEval-2019 foi dedicada à definição de emoções nas conversas em texto, levando em consideração o contexto da correspondência.  O contexto, neste caso, são várias observações consecutivas dos participantes do diálogo.  Há dois participantes na conversa: um usuário anônimo (ele possui a primeira e a terceira réplica) e um bot de bate-papo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Ruuh</a> (ele possui a segunda réplica).  Com base em três réplicas, é necessário determinar qual emoção o usuário experimentou ao escrever uma resposta para o chatbot (Tabela 1).  No total, a marcação do conjunto de dados continha quatro emoções: “feliz”, “triste”, “zangada” ou “outras” (Tabela 1).  Uma descrição detalhada é apresentada aqui: ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chatterjee et al., 2019</a> ). <br><br>  <i>Tabela 1. Exemplos do conjunto de dados EmoContext ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chatterjee et al., 2019</a> )</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Usuário (Estágio 1) </th><th>  Robô interativo (estágio 1) </th><th>  Usuário (Estágio 2) </th><th>  Classe verdadeira </th></tr><tr><td>  Acabei de me qualificar para o estágio Nabard </td><td>  WOOT!  Essa é uma ótima notícia.  Parabéns! </td><td>  Comecei a chorar </td><td>  Felicidade </td></tr><tr><td>  Como você ousa dar um tapa no meu filho </td><td>  Se você estragar o meu carro, eu também farei isso </td><td>  Apenas tente fazer isso uma vez </td><td>  Raiva </td></tr><tr><td>  Eu fui machucado por você mais </td><td>  Você não quis dizer isso. </td><td>  diga que me ama </td><td>  Tristeza </td></tr><tr><td>  Eu vou fazer a noite </td><td>  Tudo bem.  Mantenha-me informado. </td><td>  Não dando WhatsApp não. </td><td>  Outros </td></tr></tbody></table></div><br>  Durante a competição, os organizadores forneceram vários conjuntos de dados.  O conjunto de dados de treinamento (Trem) consistiu em 30.160 textos marcados manualmente.  Nesses textos, havia aproximadamente 5.000 objetos pertencentes às classes “feliz”, “triste” e “zangado”, além de 15.000 textos da classe “outros” (Tabela 2). <br><br>  Os organizadores também forneceram conjuntos de dados para desenvolvimento (Dev) e testes (Teste), nos quais, diferentemente do conjunto de dados de treinamento, a distribuição por classe de emoções correspondia à vida real: cerca de 4% para cada uma das classes “feliz”, “triste” e “ bravo ", e o resto é da classe" outros ".  Dados fornecidos pela Microsoft, você pode baixá-lo no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">grupo oficial no LinkedIn</a> . <br><br>  <i>Tabela 2. Distribuição dos rótulos das classes de emoções no conjunto de dados ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chatterjee et al., 2019</a> ).</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Datacet </th><th>  Felicidade </th><th>  Tristeza </th><th>  Raiva </th><th>  Outros </th><th> Total </th></tr><tr><td>  Treinamento <br></td><td>  14,07% <br></td><td>  18,11% <br></td><td>  18,26% <br></td><td>  49,56% <br></td><td>  30 160 <br></td></tr><tr><td>  Desenvolver <br></td><td>  5,15% <br></td><td>  4,54% <br></td><td>  5,45% <br></td><td>  84,86% <br></td><td>  2755 <br></td></tr><tr><td>  Teste <br></td><td>  5,16% <br></td><td>  4,54% <br></td><td>  5,41% <br></td><td>  84,90% <br></td><td>  5509 <br></td></tr><tr><td>  Remoto <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  0% <br></td><td>  900 mil <br></td></tr></tbody></table></div><br>  Além desses dados, coletamos 900 mil mensagens em inglês do Twitter para criar um conjunto de dados Distant (300 mil tweets para cada emoção).  Ao criá-lo, seguimos a estratégia de Go et al.  (2009), no âmbito do qual as mensagens foram simplesmente associadas à presença de palavras relacionadas a emoções, como #angry, #annoyed, #happy, #sad, #surprised e assim por diante.  A lista de termos é baseada nos termos do SemEval-2018 AIT DISC ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Duppada et al., 2018</a> ). <br><br>  A principal métrica de qualidade da competição EmoContext é a medida F1 média para as três classes de emoções, ou seja, para as classes "feliz", "triste" e "zangada". <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocessData</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataFilePath, mode)</span></span></span><span class="hljs-function">:</span></span> conversations = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(dataFilePath, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> finput: finput.readline() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> finput: line = line.strip().split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>): line[i] = tokenize(line[i]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: labels.append(emotion2label[line[<span class="hljs-number"><span class="hljs-number">4</span></span>]]) conv = line[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conversations.append(conv) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations), np.array(labels) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations) texts_train, labels_train = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/train.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_dev, labels_dev = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/dev.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_test, labels_test = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/test.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>)</code> </pre> <br><h2>  2. Pré-processamento de texto </h2><br>  Antes do treinamento, processamos previamente os textos usando a ferramenta Ekphrasis (Baziotis et al., 2017).  Ajuda a corrigir a ortografia, normalizar palavras, segmento e também determinar quais tokens devem ser descartados, normalizados ou anotados usando tags especiais.  Na fase de pré-processamento, fizemos o seguinte: <br><br><ul><li>  URLs e correio, data e hora, apelidos, porcentagens, moedas e números foram substituídos pelas tags correspondentes. </li><li>  Termos em maiúsculas repetidos, censurados e alongados, acompanhados por rótulos apropriados. </li><li>  Palavras alongadas foram corrigidas automaticamente. </li></ul><br>  Além disso, o Ênfase contém um tokenizador que pode identificar a maioria dos emojis, emoticons e expressões complexas, além de datas, horas, moedas e acrônimos. <br><br>  <i>Tabela 3. Exemplos de pré-processamento de texto.</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Texto fonte </th><th>  Texto pré-processado </th></tr><tr><td>  Eu sinto você ... estou quebrando em milhões de pedaços <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td><td>  &lt;allcaps&gt; eu sinto você &lt;/allcaps&gt;.  &lt;repetido&gt; estou quebrando em milhões de pedaços <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td></tr><tr><td>  cansado e eu também senti sua falta :‑( </td><td>  cansado e eu também senti sua falta &lt;sad&gt; </td></tr><tr><td>  você deve ouvir isso: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">www.youtube.com/watch?v=99myH1orbs4</a> </td><td>  você deve ouvir &lt;elongated&gt; o seguinte: &lt;url&gt; </td></tr><tr><td>  Meu apartamento cuida disso.  Meu aluguel é de cerca de US $ 650. </td><td>  meu apartamento cuida disso.  meu aluguel é em torno de &lt;dinheiro&gt;. </td></tr></tbody></table></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.preprocessor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TextPreProcessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.tokenizer <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SocialTokenizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.dicts.emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io label2emotion = {<span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-string"><span class="hljs-string">"happy"</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-string"><span class="hljs-string">"sad"</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>: <span class="hljs-string"><span class="hljs-string">"angry"</span></span>} emotion2label = {<span class="hljs-string"><span class="hljs-string">"others"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"happy"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"sad"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"angry"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>} emoticons_additional = { <span class="hljs-string"><span class="hljs-string">'(^・^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑c'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'=‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‑)"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑('</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‑)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':\\/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'d=&lt;'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‑]'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'(^ ^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'angru'</span></span>: <span class="hljs-string"><span class="hljs-string">'angry'</span></span>, <span class="hljs-string"><span class="hljs-string">"d‑':"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‑("</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":‑["</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'( ? )'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'x‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, } text_processor = TextPreProcessor( <span class="hljs-comment"><span class="hljs-comment"># terms that will be normalized normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'number'], # terms that will be annotated annotate={"hashtag", "allcaps", "elongated", "repeated", 'emphasis', 'censored'}, fix_html=True, # fix HTML tokens # corpus from which the word statistics are going to be used # for word segmentation segmenter="twitter", # corpus from which the word statistics are going to be used # for spell correction corrector="twitter", unpack_hashtags=True, # perform word segmentation on hashtags unpack_contractions=True, # Unpack contractions (can't -&gt; can not) spell_correct_elong=True, # spell correction for elongated words # select a tokenizer. You can use SocialTokenizer, or pass your own # the tokenizer, should take as input a string and return a list of tokens tokenizer=SocialTokenizer(lowercase=True).tokenize, # list of dictionaries, for replacing tokens extracted from the text, # with other expressions. You can pass more than one dictionaries. dicts=[emoticons, emoticons_additional] ) def tokenize(text): text = " ".join(text_processor.pre_process_doc(text)) return text</span></span></code> </pre><br><h2>  3. Representação vetorial de palavras </h2><br>  A representação vetorial tornou-se parte integrante da maioria das abordagens para a criação de sistemas de PNL usando aprendizado profundo.  Para determinar os modelos de mapeamento vetorial mais adequados, experimentamos o Word2Vec ( <a href="">Mikolov et al., 2013</a> ), GloVe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pennington et al., 2014</a> ) e FastText ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Joulin et al., 2017</a> ), bem como os vetores DataStories pré-treinados ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Baziotis et al. 2017</a> ).  O Word2Vec localiza relacionamentos entre palavras, assumindo que palavras semanticamente relacionadas são encontradas em contextos semelhantes.  O Word2Vec tenta prever a palavra de destino (arquitetura CBOW) ou o contexto (arquitetura Skip-Gram), ou seja, minimizar a função de perda e o GloVe calcula vetores de palavras, reduzindo a dimensão da matriz de adjacência.  A lógica do FastText é semelhante à lógica do Word2Vec, exceto que ele usa n-gramas simbólicos para criar vetores de palavras e, como resultado, pode resolver o problema de palavras desconhecidas. <br><br>  Para todos os modelos mencionados, usamos os parâmetros de treinamento padrão fornecidos pelos autores.  Nós treinamos um modelo LSTM simples (dim = 64) com base em cada uma dessas representações vetoriais e comparamos a eficiência da classificação usando validação cruzada.  O melhor resultado nas medidas F1 foi mostrado por vetores pré-treinados do DataStories. <br><br>  Para enriquecer o mapeamento vetorial selecionado com a coloração emocional das palavras, decidimos ajustar os vetores usando o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">conjunto de dados</a> Distant automaticamente identificado ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Deriu et al., 2017</a> ).  Usamos o conjunto de dados Distant para treinar uma rede LSTM simples para classificar mensagens "más", "tristes" e "felizes".  A camada de incorporação foi congelada durante a primeira iteração do treinamento, a fim de evitar fortes mudanças nos pesos dos vetores e, nas cinco iterações seguintes, a camada foi descongelada.  Após o treinamento, os vetores "atrasados" foram salvos para uso posterior na rede neural e também <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">compartilhados</a> . <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(file)</span></span></span><span class="hljs-function">:</span></span> embeddingsIndex = {} dim = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(file, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: values = line.split() word = values[<span class="hljs-number"><span class="hljs-number">0</span></span>] embeddingVector = np.asarray(values[<span class="hljs-number"><span class="hljs-number">1</span></span>:], dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) embeddingsIndex[word] = embeddingVector dim = len(embeddingVector) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingsIndex, dim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddingMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(wordIndex, embeddings, dim)</span></span></span><span class="hljs-function">:</span></span> embeddingMatrix = np.zeros((len(wordIndex) + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word, i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> wordIndex.items(): embeddingMatrix[i] = embeddings.get(word) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingMatrix <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tokenizer embeddings, dim = getEmbeddings(<span class="hljs-string"><span class="hljs-string">'emosense.300d.txt'</span></span>) tokenizer = Tokenizer(filters=<span class="hljs-string"><span class="hljs-string">''</span></span>) tokenizer.fit_on_texts([<span class="hljs-string"><span class="hljs-string">' '</span></span>.join(list(embeddings.keys()))]) wordIndex = tokenizer.word_index print(<span class="hljs-string"><span class="hljs-string">"Found %s unique tokens."</span></span> % len(wordIndex)) embeddings_matrix = getEmbeddingMatrix(wordIndex, embeddings, dim)</code> </pre><br><h2>  4. Arquitetura de rede neural </h2><br>  Redes Neurais Recorrentes (RNNs) são uma família de redes neurais especializadas no processamento de uma série de eventos.  Diferentemente das redes neurais tradicionais, as RNNs são projetadas para trabalhar com sequências usando balanços internos.  Para isso, o gráfico computacional RNN contém ciclos que refletem a influência de informações anteriores da sequência de eventos no atual.  Redes neurais LSTM (Long Short-Term Memory) foram introduzidas como uma extensão da RNN em 1997 ( <a href="">Hochreiter e Schmidhuber, 1997</a> ).  As células de recorrência LSTM são conectadas para evitar problemas de explosão e desbotamento.  Os LSTMs tradicionais preservam apenas as informações passadas enquanto processam a sequência em uma direção.  Os LSTMs bidirecionais que operam em ambas as direções combinam a saída de duas camadas ocultas de LSTM que transmitem informações em direções opostas - uma no decorrer do tempo e a outra contra - recebendo simultaneamente dados de estados passados ​​e futuros ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Schuster e Paliwal, 1997</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bdf/d46/a41/bdfd46a41a20ba916382a57bb7c17e19.png"><br>  <i>Figura 1: Versão reduzida da arquitetura.</i>  <i>O módulo LSTM usa os mesmos pesos para o primeiro e o terceiro estágios.</i> <br><br>  Uma representação simplificada da abordagem descrita é apresentada na Figura 1. A arquitetura da rede neural consiste em uma camada de incorporação e dois módulos LTSM bidirecionais (dim = 64).  O primeiro módulo LTSM analisa as palavras do primeiro usuário (isto é, a primeira e a terceira réplica da conversa) e o segundo módulo analisa as palavras do segundo usuário (segunda réplica).  No primeiro estágio, as palavras de cada usuário usando representações vetoriais pré-treinadas são inseridas no módulo bidirecional LTSM correspondente.  Em seguida, os três mapas de recursos resultantes são combinados em um vetor de recurso plano e depois transferidos para uma camada oculta totalmente conectada (dim = 30), que analisa as interações entre os recursos extraídos.  Finalmente, essas características são processadas na camada de saída usando a função de ativação softmax para determinar o rótulo da classe final.  Para reduzir o sobreajuste, após as camadas da representação vetorial, foram adicionadas camadas de regularização com ruído gaussiano e camadas de abandono a cada módulo LTSM (p = 0,2) e uma camada totalmente conectada oculta (p = 0,1) ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Srivastava et al., 2014</a> ) <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Embedding, Concatenate, Activation, \ Dropout, LSTM, Bidirectional, GlobalMaxPooling1D, GaussianNoise <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(embeddings_matrix, sequence_length, lstm_dim, hidden_layer_dim, num_classes, noise=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout_lstm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> turn1_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn2_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn3_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) embedding_dim = embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] embeddingLayer = Embedding(embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], embedding_dim, weights=[embeddings_matrix], input_length=sequence_length, trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) turn1_branch = embeddingLayer(turn1_input) turn2_branch = embeddingLayer(turn2_input) turn3_branch = embeddingLayer(turn3_input) turn1_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn1_branch) turn2_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn2_branch) turn3_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn3_branch) lstm1 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) lstm2 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) turn1_branch = lstm1(turn1_branch) turn2_branch = lstm2(turn2_branch) turn3_branch = lstm1(turn3_branch) x = Concatenate(axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)([turn1_branch, turn2_branch, turn3_branch]) x = Dropout(dropout)(x) x = Dense(hidden_layer_dim, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) output = Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[turn1_input, turn2_input, turn3_input], outputs=output) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model model = buildModel(embeddings_matrix, MAX_SEQUENCE_LENGTH, lstm_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_layer_dim=<span class="hljs-number"><span class="hljs-number">30</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><h2>  5. Resultados </h2><br>  Na busca pela arquitetura ideal, experimentamos não apenas o número de neurônios nas camadas, funções de ativação e parâmetros de regularização, mas também a arquitetura da própria rede neural.  Isso é descrito com mais detalhes no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalho original</a> . <br><br>  A arquitetura descrita na seção anterior mostrou os melhores resultados ao treinar no conjunto de dados Train e validar no conjunto de dados Dev, por isso foi usado na fase final da competição.  No último conjunto de dados de teste, o modelo mostrou uma medida F1 micro-média de 72,59%, e o resultado máximo alcançado entre todos os participantes foi de 79,59%.  No entanto, nosso resultado foi muito superior ao valor basal de 58,68% estabelecido pelos organizadores. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O código fonte da representação de modelo e vetor de palavras</a> está disponível no GitHub. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A versão completa do artigo</a> e o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalho com a descrição da tarefa</a> estão no site da ACL Anthology. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O conjunto de dados de treinamento</a> pode ser baixado do grupo oficial do LinkedIn. <br><br>  Citação: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inproceedings{smetanin-2019-emosense, title = "{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations", author = "Smetanin, Sergey", booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation", year = "2019", address = "Minneapolis, Minnesota, USA", publisher = "Association for Computational Linguistics", url = "https://www.aclweb.org/anthology/S19-2034", pages = "210--214", }</span></span></code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt463045/">https://habr.com/ru/post/pt463045/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt463031/index.html">Viva e aprenda. Parte 3. Educação continuada ou a idade do eterno aluno</a></li>
<li><a href="../pt463035/index.html">Notícias do mundo do OpenStreetMap nº 471 (23.07.2019-29.07.2019)</a></li>
<li><a href="../pt463037/index.html">À procura de inspiração ou Como sair de F</a></li>
<li><a href="../pt463039/index.html">Aspirador de manicure do tipo faça você mesmo</a></li>
<li><a href="../pt463041/index.html">Definido ou Indefinido? Nuances da criação de matrizes em JavaScript</a></li>
<li><a href="../pt463055/index.html">Sobre administradores, devops, confusão sem fim e transformação de DevOps na empresa</a></li>
<li><a href="../pt463057/index.html">Direitos personalizados da estrutura 2 do Yii</a></li>
<li><a href="../pt463059/index.html">Três vidas em TI e não apenas</a></li>
<li><a href="../pt463061/index.html">Regras para preparar layouts em Figma</a></li>
<li><a href="../pt463063/index.html">Lidamos com interfaces no Go</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
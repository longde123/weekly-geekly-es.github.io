<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèº üò° üë©üèº‚Äçüéì Detecta automaticamente emo√ß√µes em conversas de texto usando redes neurais üë©üèΩ‚Äçüè≠ üôãüèª ‚è≤Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Uma das principais tarefas dos sistemas de di√°logo n√£o √© apenas fornecer as informa√ß√µes de que o usu√°rio precisa, mas tamb√©m gerar o maior n√∫mero poss...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Detecta automaticamente emo√ß√µes em conversas de texto usando redes neurais</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/463045/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t6/sr/jr/t6srjrmjjmm6qn8gpld9emy4txu.gif"></div><br>  Uma das principais tarefas dos sistemas de di√°logo n√£o √© apenas fornecer as informa√ß√µes de que o usu√°rio precisa, mas tamb√©m gerar o maior n√∫mero poss√≠vel de respostas humanas.  E o reconhecimento das emo√ß√µes do interlocutor n√£o √© mais apenas um recurso interessante, √© uma necessidade vital.  Neste artigo, examinaremos a <b>arquitetura de uma rede neural recorrente para determinar emo√ß√µes em conversas de texto</b> , que participou da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tarefa 3</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SemEval-2019 "EmoContext"</a> , a competi√ß√£o anual em lingu√≠stica de computa√ß√£o.  A tarefa era classificar emo√ß√µes (‚Äúfeliz‚Äù, ‚Äútriste‚Äù, ‚Äúzangada‚Äù e ‚Äúoutras pessoas‚Äù) em uma conversa de tr√™s observa√ß√µes, na qual participaram um bot de bate-papo e uma pessoa. <br><br>  Na primeira parte do artigo, consideraremos a tarefa definida no EmoContext e os dados fornecidos pelos organizadores.  Na segunda e terceira partes, analisamos o processamento preliminar do texto e os modos de representa√ß√£o vetorial das palavras.  Na quarta parte, descrevemos a arquitetura LSTM que usamos na competi√ß√£o.  O c√≥digo √© escrito em Python usando a biblioteca Keras. <br><a name="habracut"></a><br><h2>  1. Dados de treinamento </h2><br>  A faixa ‚ÄúEmoContext‚Äù no SemEval-2019 foi dedicada √† defini√ß√£o de emo√ß√µes nas conversas em texto, levando em considera√ß√£o o contexto da correspond√™ncia.  O contexto, neste caso, s√£o v√°rias observa√ß√µes consecutivas dos participantes do di√°logo.  H√° dois participantes na conversa: um usu√°rio an√¥nimo (ele possui a primeira e a terceira r√©plica) e um bot de bate-papo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Ruuh</a> (ele possui a segunda r√©plica).  Com base em tr√™s r√©plicas, √© necess√°rio determinar qual emo√ß√£o o usu√°rio experimentou ao escrever uma resposta para o chatbot (Tabela 1).  No total, a marca√ß√£o do conjunto de dados continha quatro emo√ß√µes: ‚Äúfeliz‚Äù, ‚Äútriste‚Äù, ‚Äúzangada‚Äù ou ‚Äúoutras‚Äù (Tabela 1).  Uma descri√ß√£o detalhada √© apresentada aqui: ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chatterjee et al., 2019</a> ). <br><br>  <i>Tabela 1. Exemplos do conjunto de dados EmoContext ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chatterjee et al., 2019</a> )</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Usu√°rio (Est√°gio 1) </th><th>  Rob√¥ interativo (est√°gio 1) </th><th>  Usu√°rio (Est√°gio 2) </th><th>  Classe verdadeira </th></tr><tr><td>  Acabei de me qualificar para o est√°gio Nabard </td><td>  WOOT!  Essa √© uma √≥tima not√≠cia.  Parab√©ns! </td><td>  Comecei a chorar </td><td>  Felicidade </td></tr><tr><td>  Como voc√™ ousa dar um tapa no meu filho </td><td>  Se voc√™ estragar o meu carro, eu tamb√©m farei isso </td><td>  Apenas tente fazer isso uma vez </td><td>  Raiva </td></tr><tr><td>  Eu fui machucado por voc√™ mais </td><td>  Voc√™ n√£o quis dizer isso. </td><td>  diga que me ama </td><td>  Tristeza </td></tr><tr><td>  Eu vou fazer a noite </td><td>  Tudo bem.  Mantenha-me informado. </td><td>  N√£o dando WhatsApp n√£o. </td><td>  Outros </td></tr></tbody></table></div><br>  Durante a competi√ß√£o, os organizadores forneceram v√°rios conjuntos de dados.  O conjunto de dados de treinamento (Trem) consistiu em 30.160 textos marcados manualmente.  Nesses textos, havia aproximadamente 5.000 objetos pertencentes √†s classes ‚Äúfeliz‚Äù, ‚Äútriste‚Äù e ‚Äúzangado‚Äù, al√©m de 15.000 textos da classe ‚Äúoutros‚Äù (Tabela 2). <br><br>  Os organizadores tamb√©m forneceram conjuntos de dados para desenvolvimento (Dev) e testes (Teste), nos quais, diferentemente do conjunto de dados de treinamento, a distribui√ß√£o por classe de emo√ß√µes correspondia √† vida real: cerca de 4% para cada uma das classes ‚Äúfeliz‚Äù, ‚Äútriste‚Äù e ‚Äú bravo ", e o resto √© da classe" outros ".  Dados fornecidos pela Microsoft, voc√™ pode baix√°-lo no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">grupo oficial no LinkedIn</a> . <br><br>  <i>Tabela 2. Distribui√ß√£o dos r√≥tulos das classes de emo√ß√µes no conjunto de dados ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Chatterjee et al., 2019</a> ).</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Datacet </th><th>  Felicidade </th><th>  Tristeza </th><th>  Raiva </th><th>  Outros </th><th> Total </th></tr><tr><td>  Treinamento <br></td><td>  14,07% <br></td><td>  18,11% <br></td><td>  18,26% <br></td><td>  49,56% <br></td><td>  30 160 <br></td></tr><tr><td>  Desenvolver <br></td><td>  5,15% <br></td><td>  4,54% <br></td><td>  5,45% <br></td><td>  84,86% <br></td><td>  2755 <br></td></tr><tr><td>  Teste <br></td><td>  5,16% <br></td><td>  4,54% <br></td><td>  5,41% <br></td><td>  84,90% <br></td><td>  5509 <br></td></tr><tr><td>  Remoto <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  0% <br></td><td>  900 mil <br></td></tr></tbody></table></div><br>  Al√©m desses dados, coletamos 900 mil mensagens em ingl√™s do Twitter para criar um conjunto de dados Distant (300 mil tweets para cada emo√ß√£o).  Ao cri√°-lo, seguimos a estrat√©gia de Go et al.  (2009), no √¢mbito do qual as mensagens foram simplesmente associadas √† presen√ßa de palavras relacionadas a emo√ß√µes, como #angry, #annoyed, #happy, #sad, #surprised e assim por diante.  A lista de termos √© baseada nos termos do SemEval-2018 AIT DISC ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Duppada et al., 2018</a> ). <br><br>  A principal m√©trica de qualidade da competi√ß√£o EmoContext √© a medida F1 m√©dia para as tr√™s classes de emo√ß√µes, ou seja, para as classes "feliz", "triste" e "zangada". <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocessData</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataFilePath, mode)</span></span></span><span class="hljs-function">:</span></span> conversations = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(dataFilePath, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> finput: finput.readline() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> finput: line = line.strip().split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>): line[i] = tokenize(line[i]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: labels.append(emotion2label[line[<span class="hljs-number"><span class="hljs-number">4</span></span>]]) conv = line[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conversations.append(conv) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations), np.array(labels) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations) texts_train, labels_train = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/train.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_dev, labels_dev = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/dev.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_test, labels_test = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/test.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>)</code> </pre> <br><h2>  2. Pr√©-processamento de texto </h2><br>  Antes do treinamento, processamos previamente os textos usando a ferramenta Ekphrasis (Baziotis et al., 2017).  Ajuda a corrigir a ortografia, normalizar palavras, segmento e tamb√©m determinar quais tokens devem ser descartados, normalizados ou anotados usando tags especiais.  Na fase de pr√©-processamento, fizemos o seguinte: <br><br><ul><li>  URLs e correio, data e hora, apelidos, porcentagens, moedas e n√∫meros foram substitu√≠dos pelas tags correspondentes. </li><li>  Termos em mai√∫sculas repetidos, censurados e alongados, acompanhados por r√≥tulos apropriados. </li><li>  Palavras alongadas foram corrigidas automaticamente. </li></ul><br>  Al√©m disso, o √änfase cont√©m um tokenizador que pode identificar a maioria dos emojis, emoticons e express√µes complexas, al√©m de datas, horas, moedas e acr√¥nimos. <br><br>  <i>Tabela 3. Exemplos de pr√©-processamento de texto.</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Texto fonte </th><th>  Texto pr√©-processado </th></tr><tr><td>  Eu sinto voc√™ ... estou quebrando em milh√µes de peda√ßos <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td><td>  &lt;allcaps&gt; eu sinto voc√™ &lt;/allcaps&gt;.  &lt;repetido&gt; estou quebrando em milh√µes de peda√ßos <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td></tr><tr><td>  cansado e eu tamb√©m senti sua falta :‚Äë( </td><td>  cansado e eu tamb√©m senti sua falta &lt;sad&gt; </td></tr><tr><td>  voc√™ deve ouvir isso: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">www.youtube.com/watch?v=99myH1orbs4</a> </td><td>  voc√™ deve ouvir &lt;elongated&gt; o seguinte: &lt;url&gt; </td></tr><tr><td>  Meu apartamento cuida disso.  Meu aluguel √© de cerca de US $ 650. </td><td>  meu apartamento cuida disso.  meu aluguel √© em torno de &lt;dinheiro&gt;. </td></tr></tbody></table></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.preprocessor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TextPreProcessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.tokenizer <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SocialTokenizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.dicts.emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io label2emotion = {<span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-string"><span class="hljs-string">"happy"</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-string"><span class="hljs-string">"sad"</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>: <span class="hljs-string"><span class="hljs-string">"angry"</span></span>} emotion2label = {<span class="hljs-string"><span class="hljs-string">"others"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"happy"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"sad"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"angry"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>} emoticons_additional = { <span class="hljs-string"><span class="hljs-string">'(^„Éª^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëc'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'=‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë)"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë('</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':\\/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'d=&lt;'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë]'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'(^ ^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'angru'</span></span>: <span class="hljs-string"><span class="hljs-string">'angry'</span></span>, <span class="hljs-string"><span class="hljs-string">"d‚Äë':"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë("</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":‚Äë["</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'( ? )'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'x‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, } text_processor = TextPreProcessor( <span class="hljs-comment"><span class="hljs-comment"># terms that will be normalized normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'number'], # terms that will be annotated annotate={"hashtag", "allcaps", "elongated", "repeated", 'emphasis', 'censored'}, fix_html=True, # fix HTML tokens # corpus from which the word statistics are going to be used # for word segmentation segmenter="twitter", # corpus from which the word statistics are going to be used # for spell correction corrector="twitter", unpack_hashtags=True, # perform word segmentation on hashtags unpack_contractions=True, # Unpack contractions (can't -&gt; can not) spell_correct_elong=True, # spell correction for elongated words # select a tokenizer. You can use SocialTokenizer, or pass your own # the tokenizer, should take as input a string and return a list of tokens tokenizer=SocialTokenizer(lowercase=True).tokenize, # list of dictionaries, for replacing tokens extracted from the text, # with other expressions. You can pass more than one dictionaries. dicts=[emoticons, emoticons_additional] ) def tokenize(text): text = " ".join(text_processor.pre_process_doc(text)) return text</span></span></code> </pre><br><h2>  3. Representa√ß√£o vetorial de palavras </h2><br>  A representa√ß√£o vetorial tornou-se parte integrante da maioria das abordagens para a cria√ß√£o de sistemas de PNL usando aprendizado profundo.  Para determinar os modelos de mapeamento vetorial mais adequados, experimentamos o Word2Vec ( <a href="">Mikolov et al., 2013</a> ), GloVe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pennington et al., 2014</a> ) e FastText ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Joulin et al., 2017</a> ), bem como os vetores DataStories pr√©-treinados ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Baziotis et al. 2017</a> ).  O Word2Vec localiza relacionamentos entre palavras, assumindo que palavras semanticamente relacionadas s√£o encontradas em contextos semelhantes.  O Word2Vec tenta prever a palavra de destino (arquitetura CBOW) ou o contexto (arquitetura Skip-Gram), ou seja, minimizar a fun√ß√£o de perda e o GloVe calcula vetores de palavras, reduzindo a dimens√£o da matriz de adjac√™ncia.  A l√≥gica do FastText √© semelhante √† l√≥gica do Word2Vec, exceto que ele usa n-gramas simb√≥licos para criar vetores de palavras e, como resultado, pode resolver o problema de palavras desconhecidas. <br><br>  Para todos os modelos mencionados, usamos os par√¢metros de treinamento padr√£o fornecidos pelos autores.  N√≥s treinamos um modelo LSTM simples (dim = 64) com base em cada uma dessas representa√ß√µes vetoriais e comparamos a efici√™ncia da classifica√ß√£o usando valida√ß√£o cruzada.  O melhor resultado nas medidas F1 foi mostrado por vetores pr√©-treinados do DataStories. <br><br>  Para enriquecer o mapeamento vetorial selecionado com a colora√ß√£o emocional das palavras, decidimos ajustar os vetores usando o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">conjunto de dados</a> Distant automaticamente identificado ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Deriu et al., 2017</a> ).  Usamos o conjunto de dados Distant para treinar uma rede LSTM simples para classificar mensagens "m√°s", "tristes" e "felizes".  A camada de incorpora√ß√£o foi congelada durante a primeira itera√ß√£o do treinamento, a fim de evitar fortes mudan√ßas nos pesos dos vetores e, nas cinco itera√ß√µes seguintes, a camada foi descongelada.  Ap√≥s o treinamento, os vetores "atrasados" foram salvos para uso posterior na rede neural e tamb√©m <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">compartilhados</a> . <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(file)</span></span></span><span class="hljs-function">:</span></span> embeddingsIndex = {} dim = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(file, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: values = line.split() word = values[<span class="hljs-number"><span class="hljs-number">0</span></span>] embeddingVector = np.asarray(values[<span class="hljs-number"><span class="hljs-number">1</span></span>:], dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) embeddingsIndex[word] = embeddingVector dim = len(embeddingVector) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingsIndex, dim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddingMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(wordIndex, embeddings, dim)</span></span></span><span class="hljs-function">:</span></span> embeddingMatrix = np.zeros((len(wordIndex) + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word, i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> wordIndex.items(): embeddingMatrix[i] = embeddings.get(word) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingMatrix <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tokenizer embeddings, dim = getEmbeddings(<span class="hljs-string"><span class="hljs-string">'emosense.300d.txt'</span></span>) tokenizer = Tokenizer(filters=<span class="hljs-string"><span class="hljs-string">''</span></span>) tokenizer.fit_on_texts([<span class="hljs-string"><span class="hljs-string">' '</span></span>.join(list(embeddings.keys()))]) wordIndex = tokenizer.word_index print(<span class="hljs-string"><span class="hljs-string">"Found %s unique tokens."</span></span> % len(wordIndex)) embeddings_matrix = getEmbeddingMatrix(wordIndex, embeddings, dim)</code> </pre><br><h2>  4. Arquitetura de rede neural </h2><br>  Redes Neurais Recorrentes (RNNs) s√£o uma fam√≠lia de redes neurais especializadas no processamento de uma s√©rie de eventos.  Diferentemente das redes neurais tradicionais, as RNNs s√£o projetadas para trabalhar com sequ√™ncias usando balan√ßos internos.  Para isso, o gr√°fico computacional RNN cont√©m ciclos que refletem a influ√™ncia de informa√ß√µes anteriores da sequ√™ncia de eventos no atual.  Redes neurais LSTM (Long Short-Term Memory) foram introduzidas como uma extens√£o da RNN em 1997 ( <a href="">Hochreiter e Schmidhuber, 1997</a> ).  As c√©lulas de recorr√™ncia LSTM s√£o conectadas para evitar problemas de explos√£o e desbotamento.  Os LSTMs tradicionais preservam apenas as informa√ß√µes passadas enquanto processam a sequ√™ncia em uma dire√ß√£o.  Os LSTMs bidirecionais que operam em ambas as dire√ß√µes combinam a sa√≠da de duas camadas ocultas de LSTM que transmitem informa√ß√µes em dire√ß√µes opostas - uma no decorrer do tempo e a outra contra - recebendo simultaneamente dados de estados passados ‚Äã‚Äãe futuros ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Schuster e Paliwal, 1997</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bdf/d46/a41/bdfd46a41a20ba916382a57bb7c17e19.png"><br>  <i>Figura 1: Vers√£o reduzida da arquitetura.</i>  <i>O m√≥dulo LSTM usa os mesmos pesos para o primeiro e o terceiro est√°gios.</i> <br><br>  Uma representa√ß√£o simplificada da abordagem descrita √© apresentada na Figura 1. A arquitetura da rede neural consiste em uma camada de incorpora√ß√£o e dois m√≥dulos LTSM bidirecionais (dim = 64).  O primeiro m√≥dulo LTSM analisa as palavras do primeiro usu√°rio (isto √©, a primeira e a terceira r√©plica da conversa) e o segundo m√≥dulo analisa as palavras do segundo usu√°rio (segunda r√©plica).  No primeiro est√°gio, as palavras de cada usu√°rio usando representa√ß√µes vetoriais pr√©-treinadas s√£o inseridas no m√≥dulo bidirecional LTSM correspondente.  Em seguida, os tr√™s mapas de recursos resultantes s√£o combinados em um vetor de recurso plano e depois transferidos para uma camada oculta totalmente conectada (dim = 30), que analisa as intera√ß√µes entre os recursos extra√≠dos.  Finalmente, essas caracter√≠sticas s√£o processadas na camada de sa√≠da usando a fun√ß√£o de ativa√ß√£o softmax para determinar o r√≥tulo da classe final.  Para reduzir o sobreajuste, ap√≥s as camadas da representa√ß√£o vetorial, foram adicionadas camadas de regulariza√ß√£o com ru√≠do gaussiano e camadas de abandono a cada m√≥dulo LTSM (p = 0,2) e uma camada totalmente conectada oculta (p = 0,1) ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Srivastava et al., 2014</a> ) <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Embedding, Concatenate, Activation, \ Dropout, LSTM, Bidirectional, GlobalMaxPooling1D, GaussianNoise <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(embeddings_matrix, sequence_length, lstm_dim, hidden_layer_dim, num_classes, noise=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout_lstm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> turn1_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn2_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn3_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) embedding_dim = embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] embeddingLayer = Embedding(embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], embedding_dim, weights=[embeddings_matrix], input_length=sequence_length, trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) turn1_branch = embeddingLayer(turn1_input) turn2_branch = embeddingLayer(turn2_input) turn3_branch = embeddingLayer(turn3_input) turn1_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn1_branch) turn2_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn2_branch) turn3_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn3_branch) lstm1 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) lstm2 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) turn1_branch = lstm1(turn1_branch) turn2_branch = lstm2(turn2_branch) turn3_branch = lstm1(turn3_branch) x = Concatenate(axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)([turn1_branch, turn2_branch, turn3_branch]) x = Dropout(dropout)(x) x = Dense(hidden_layer_dim, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) output = Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[turn1_input, turn2_input, turn3_input], outputs=output) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model model = buildModel(embeddings_matrix, MAX_SEQUENCE_LENGTH, lstm_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_layer_dim=<span class="hljs-number"><span class="hljs-number">30</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><h2>  5. Resultados </h2><br>  Na busca pela arquitetura ideal, experimentamos n√£o apenas o n√∫mero de neur√¥nios nas camadas, fun√ß√µes de ativa√ß√£o e par√¢metros de regulariza√ß√£o, mas tamb√©m a arquitetura da pr√≥pria rede neural.  Isso √© descrito com mais detalhes no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalho original</a> . <br><br>  A arquitetura descrita na se√ß√£o anterior mostrou os melhores resultados ao treinar no conjunto de dados Train e validar no conjunto de dados Dev, por isso foi usado na fase final da competi√ß√£o.  No √∫ltimo conjunto de dados de teste, o modelo mostrou uma medida F1 micro-m√©dia de 72,59%, e o resultado m√°ximo alcan√ßado entre todos os participantes foi de 79,59%.  No entanto, nosso resultado foi muito superior ao valor basal de 58,68% estabelecido pelos organizadores. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O c√≥digo fonte da representa√ß√£o de modelo e vetor de palavras</a> est√° dispon√≠vel no GitHub. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A vers√£o completa do artigo</a> e o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalho com a descri√ß√£o da tarefa</a> est√£o no site da ACL Anthology. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O conjunto de dados de treinamento</a> pode ser baixado do grupo oficial do LinkedIn. <br><br>  Cita√ß√£o: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inproceedings{smetanin-2019-emosense, title = "{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations", author = "Smetanin, Sergey", booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation", year = "2019", address = "Minneapolis, Minnesota, USA", publisher = "Association for Computational Linguistics", url = "https://www.aclweb.org/anthology/S19-2034", pages = "210--214", }</span></span></code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt463045/">https://habr.com/ru/post/pt463045/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt463031/index.html">Viva e aprenda. Parte 3. Educa√ß√£o continuada ou a idade do eterno aluno</a></li>
<li><a href="../pt463035/index.html">Not√≠cias do mundo do OpenStreetMap n¬∫ 471 (23.07.2019-29.07.2019)</a></li>
<li><a href="../pt463037/index.html">√Ä procura de inspira√ß√£o ou Como sair de F</a></li>
<li><a href="../pt463039/index.html">Aspirador de manicure do tipo fa√ßa voc√™ mesmo</a></li>
<li><a href="../pt463041/index.html">Definido ou Indefinido? Nuances da cria√ß√£o de matrizes em JavaScript</a></li>
<li><a href="../pt463055/index.html">Sobre administradores, devops, confus√£o sem fim e transforma√ß√£o de DevOps na empresa</a></li>
<li><a href="../pt463057/index.html">Direitos personalizados da estrutura 2 do Yii</a></li>
<li><a href="../pt463059/index.html">Tr√™s vidas em TI e n√£o apenas</a></li>
<li><a href="../pt463061/index.html">Regras para preparar layouts em Figma</a></li>
<li><a href="../pt463063/index.html">Lidamos com interfaces no Go</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧖🏿 👨🏾‍🏫 👰🏻 Kiat & trik Kubernetes: alokasi simpul dan banyak aplikasi web 🎪 📀 👩</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Melanjutkan artikel kami dengan instruksi praktis tentang cara membuat hidup lebih mudah dalam pekerjaan sehari-hari dengan Kubernetes, kami berbicara...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kiat & trik Kubernetes: alokasi simpul dan banyak aplikasi web</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/432748/"><img src="https://habrastorage.org/webt/7r/gv/ix/7rgvixbeoe0vyfkw__obak6ow_y.jpeg"><br><br>  Melanjutkan artikel kami dengan instruksi praktis tentang cara membuat hidup lebih mudah dalam pekerjaan sehari-hari dengan Kubernetes, kami berbicara tentang dua cerita dari dunia operasi: alokasi node individu untuk tugas-tugas tertentu dan konfigurasi php-fpm (atau server aplikasi lain) untuk beban berat.  Seperti sebelumnya, solusi yang dijelaskan di sini tidak mengklaim sebagai yang ideal, tetapi ditawarkan sebagai titik awal untuk kasus spesifik Anda dan dasar untuk refleksi.  Pertanyaan dan perbaikan dalam komentar dipersilahkan! <a name="habracut"></a><br><br><h2>  1. Alokasi masing-masing node untuk tugas tertentu </h2><br>  Kami meningkatkan cluster Kubernetes di server virtual, cloud, atau server bare metal.  Jika Anda menginstal semua perangkat lunak sistem dan aplikasi klien pada node yang sama, kemungkinan akan ada masalah: <br><br><ul><li>  aplikasi klien tiba-tiba akan mulai "bocor" dari memori, meskipun batasnya sangat tinggi; </li><li>  permintaan satu kali yang kompleks untuk loghouse, Prometheus atau Ingress * mengarah ke OOM, akibatnya aplikasi klien menderita; </li><li>  kebocoran memori karena bug dalam perangkat lunak sistem membunuh aplikasi klien, meskipun komponen mungkin tidak terhubung secara logis satu sama lain. </li></ul><br>  <i>* Di antara hal-hal lain, itu relevan untuk versi Ingress yang lebih lama, ketika karena banyaknya koneksi websocket dan pemuatan ulang nginx yang terus-menerus, muncul "proses nginx gantung", yang berjumlah ribuan dan menghabiskan banyak sumber daya.</i> <br><br>  Kasus sebenarnya adalah dengan pemasangan Prometheus dengan sejumlah besar metrik, di mana ketika melihat dasbor "berat", di mana sejumlah besar wadah aplikasi disajikan, dari masing-masing grafik yang diambil, konsumsi memori dengan cepat tumbuh hingga ~ 15 GB.  Akibatnya, pembunuh OOM dapat "datang" pada sistem host dan mulai membunuh layanan lain, yang pada gilirannya menyebabkan "perilaku aplikasi yang tidak dapat dipahami dalam cluster".  Dan karena beban CPU yang tinggi pada aplikasi klien, mudah untuk mendapatkan waktu pemrosesan kueri Ingress yang tidak stabil ... <br><br>  Solusi dengan cepat muncul dengan sendirinya: perlu mengalokasikan masing-masing mesin untuk tugas yang berbeda.  Kami telah mengidentifikasi 3 jenis utama kelompok tugas: <br><br><ol><li>  <b>Front</b> , tempat kami hanya memasukkan Ingress, untuk memastikan bahwa tidak ada layanan lain yang dapat memengaruhi waktu pemrosesan permintaan; </li><li>  <b>Node sistem</b> tempat kami menyebarkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">VPN</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">loghouse</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Prometheus</a> , Dashboard, CoreDNS, dll.; </li><li>  <b>Node untuk aplikasi</b> - pada kenyataannya, di mana aplikasi klien diluncurkan.  Mereka juga dapat dialokasikan untuk lingkungan atau fungsi: dev, prod, perf, ... </li></ol><br><h3>  Solusi </h3><br>  Bagaimana kita menerapkan ini?  Sangat sederhana: dua mekanisme Kubernet asli.  Yang pertama adalah <b>nodeSelector</b> untuk memilih node yang diinginkan di mana aplikasi harus pergi, yang didasarkan pada label yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dipasang</a> pada setiap node. <br><br>  Katakanlah kita memiliki simpul <code>kube-system-1</code> .  Kami menambahkan label tambahan untuk itu: <br><br><pre> <code class="bash hljs">$ kubectl label node kube-system-1 node-role/monitoring=</code> </pre> <br>  ... dan dalam <code>Deployment</code> , yang harus diluncurkan ke simpul ini, kami menulis: <br><br><pre> <code class="plaintext hljs">nodeSelector: node-role/monitoring: ""</code> </pre> <br>  Mekanisme kedua adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><b>noda dan toleransi</b></a> .  Dengan bantuannya, kami secara eksplisit menunjukkan bahwa pada mesin ini hanya wadah yang dapat diluncurkan yang memiliki toleransi terhadap noda ini. <br><br>  Misalnya, ada mesin <code>kube-frontend-1</code> di mana kita hanya akan menggulung Ingress.  Tambahkan noda ke simpul ini: <br><br><pre> <code class="bash hljs">$ kubectl taint node kube-frontend-1 node-role/frontend=<span class="hljs-string"><span class="hljs-string">""</span></span>:NoExecute</code> </pre> <br>  ... dan di <code>Deployment</code> kami membuat toleransi: <br><br><pre> <code class="plaintext hljs">tolerations: - effect: NoExecute key: node-role/frontend</code> </pre> <br>  Dalam kasus kops, masing-masing grup instance dapat dibuat untuk kebutuhan yang sama: <br><br><pre> <code class="bash hljs">$ kops create ig --name cluster_name IG_NAME</code> </pre> <br>  ... dan Anda mendapatkan sesuatu seperti grup contoh ini config in kops: <br><br><pre> <code class="plaintext hljs">apiVersion: kops/v1alpha2 kind: InstanceGroup metadata: creationTimestamp: 2017-12-07T09:24:49Z labels: dedicated: monitoring kops.k8s.io/cluster: k-dev.k8s name: monitoring spec: image: kope.io/k8s-1.8-debian-jessie-amd64-hvm-ebs-2018-01-14 machineType: m4.4xlarge maxSize: 2 minSize: 2 nodeLabels: dedicated: monitoring role: Node subnets: - eu-central-1c taints: - dedicated=monitoring:NoSchedule</code> </pre> <br>  Dengan demikian, simpul dari grup instance ini akan secara otomatis menambahkan label dan noda tambahan. <br><br><h2>  2. Mengkonfigurasi php-fpm untuk beban berat </h2><br>  Ada berbagai macam server yang digunakan untuk menjalankan aplikasi web: php-fpm, gunicorn dan sejenisnya.  Penggunaannya dalam Kubernetes berarti bahwa ada beberapa hal yang harus selalu Anda pikirkan: <br><br><ul><li>  Kita <b>perlu</b> memahami kira-kira <b>berapa banyak pekerja</b> yang bersedia kita alokasikan dalam php-fpm di setiap wadah.  Misalnya, kami dapat mengalokasikan 10 pekerja untuk memproses permintaan yang masuk, mengalokasikan lebih sedikit sumber daya untuk pod dan skala menggunakan jumlah pod - ini adalah praktik yang baik.  Contoh lain adalah mengalokasikan 500 pekerja untuk setiap pod dan memiliki 2-3 pod seperti itu dalam produksi ... tapi ini ide yang sangat buruk. </li><li>  <b>Tes hidup / kesiapan</b> diperlukan untuk memverifikasi operasi yang benar dari masing-masing pod dan jika pod macet karena masalah jaringan atau karena akses database (mungkin ada pilihan dan alasan Anda).  Dalam situasi seperti itu, Anda harus membuat ulang pod yang bermasalah. </li><li>  Penting untuk secara eksplisit mendaftarkan <b>permintaan dan membatasi sumber daya</b> untuk setiap wadah sehingga aplikasi tidak "mengalir" dan tidak mulai membahayakan semua layanan di server ini. </li></ul><br><h3>  Solusi </h3><br>  Sayangnya, <b>tidak ada peluru perak</b> yang membantu Anda segera memahami berapa banyak sumber daya (CPU, RAM) aplikasi mungkin perlu.  Pilihan yang memungkinkan adalah mengawasi konsumsi sumber daya dan setiap kali memilih nilai optimal.  Untuk menghindari kill'ov OOM yang tidak dapat dibenarkan dan pembatasan CPU, yang sangat memengaruhi layanan, Anda dapat menawarkan: <br><br><ul><li>  tambahkan tes liness / readiness yang benar sehingga kita dapat mengatakan dengan pasti bahwa wadah ini berfungsi dengan benar.  Kemungkinan besar itu akan menjadi halaman layanan yang memeriksa ketersediaan semua elemen infrastruktur (diperlukan untuk aplikasi untuk bekerja di pod) dan mengembalikan 200 kode respons OK; </li><li>  pilih dengan benar jumlah pekerja yang akan memproses permintaan, dan sebarkan dengan benar. </li></ul><br>  Sebagai contoh, kami memiliki 10 pod yang terdiri dari dua kontainer: nginx (untuk mengirim statika dan permintaan proxy ke backend) dan php-fpm (sebenarnya backend, yang memproses halaman dinamis).  Kumpulan php-fpm dikonfigurasikan untuk jumlah pekerja statis (10).  Dengan demikian, dalam satuan waktu, kami dapat memproses 100 permintaan aktif ke backend.  Biarkan setiap permintaan diproses oleh PHP dalam 1 detik. <br><br>  Apa yang terjadi jika 1 permintaan lagi tiba di satu pod tertentu, di mana 10 permintaan sedang diproses secara aktif sekarang?  PHP tidak akan dapat memprosesnya dan Ingress akan mengirimkannya untuk mencoba lagi ke pod berikutnya jika permintaan GET.  Jika ada permintaan POST, itu akan mengembalikan kesalahan. <br><br>  Dan jika kita memperhitungkan bahwa selama pemrosesan semua 10 permintaan, cek dari kubelet (penyelidikan lives) akan tiba, itu akan gagal dan Kubernetes akan mulai berpikir bahwa ada sesuatu yang salah dengan wadah ini, dan akan membunuhnya.  Dalam hal ini, semua permintaan yang diproses saat ini akan berakhir dengan kesalahan (!) Dan pada saat restart wadah itu akan jatuh tidak seimbang, yang akan memerlukan peningkatan permintaan untuk semua backend lainnya. <br><br><h4>  Jelas </h4><br>  Misalkan kita memiliki 2 pod yang masing-masing memiliki 10 pekerja php-fpm dikonfigurasi.  Berikut adalah grafik yang menampilkan informasi selama "downtime", yaitu  ketika satu-satunya yang meminta php-fpm adalah eksportir php-fpm (kami masing-masing memiliki satu pekerja aktif): <br><br><img src="https://habrastorage.org/webt/zo/hw/ea/zohwea7nsfbofpgvhixp7edc-qk.png"><br><br>  Sekarang mulai boot dengan concurrency 19: <br><br><img src="https://habrastorage.org/webt/my/ba/hp/mybahpcgbfoqzzazbwtzu9dc46a.png"><br><br>  Sekarang mari kita coba untuk membuat konkurensi lebih tinggi dari yang dapat kita tangani (20) ... katakanlah 23. Kemudian semua pekerja php-fpm sibuk memproses permintaan klien: <br><br><img src="https://habrastorage.org/webt/tq/v6/f1/tqv6f1fopruyz8_zittdan1pkho.png"><br><br>  Vorkers tidak lagi cukup untuk memproses sampel liveness, jadi kami melihat gambar ini di dashboard Kubernetes (atau <code>describe pod</code> ): <br><br><img src="https://habrastorage.org/webt/7z/qo/fw/7zqofwlbjcmxl0qkz2g2rkerece.png"><br><br>  Sekarang, ketika salah satu pod reboot, <b>efek longsoran terjadi</b> : permintaan mulai jatuh pada pod kedua, yang juga tidak dapat memprosesnya, karena itu kami menerima sejumlah besar kesalahan dari klien.  Setelah kumpulan semua wadah penuh, meningkatkan layanan menjadi bermasalah - ini hanya dimungkinkan dengan peningkatan tajam dalam jumlah polong atau pekerja. <br><br><h4>  Opsi pertama </h4><br>  Dalam sebuah wadah dengan PHP, Anda bisa mengonfigurasi 2 kumpulan fpm: satu untuk memproses permintaan klien, yang lain untuk memeriksa “survivability” kontainer.  Kemudian pada wadah nginx Anda perlu melakukan konfigurasi serupa: <br><br><pre> <code class="plaintext hljs"> upstream backend { server 127.0.0.1:9000 max_fails=0; } upstream backend-status { server 127.0.0.1:9001 max_fails=0; }</code> </pre> <br>  Yang tersisa adalah mengirim sampel liveness untuk diproses ke hulu yang disebut <code>backend-status</code> . <br><br>  Sekarang setelah penyelidikan liveness diproses secara terpisah, kesalahan masih akan terjadi pada beberapa klien, tetapi setidaknya tidak ada masalah yang terkait dengan me-restart pod dan memutus seluruh klien.  Dengan demikian, kami akan sangat mengurangi jumlah kesalahan, bahkan jika backend kami tidak dapat mengatasi beban saat ini. <br><br>  Opsi ini, tentu saja, lebih baik daripada tidak sama sekali, tetapi juga buruk karena sesuatu dapat terjadi pada kumpulan utama, yang kita tidak akan tahu tentang menggunakan tes liveness. <br><br><h4>  Opsi kedua </h4><br>  Anda juga dapat menggunakan modul nginx yang tidak terlalu populer yang disebut <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">nginx-limit-upstream</a> .  Kemudian di PHP kita akan menentukan 11 pekerja, dan dalam wadah dengan nginx kita akan membuat konfigurasi yang sama: <br><br><pre> <code class="plaintext hljs"> limit_upstream_zone limit 32m; upstream backend { server 127.0.0.1:9000 max_fails=0; limit_upstream_conn limit=10 zone=limit backlog=10 timeout=5s; } upstream backend-status { server 127.0.0.1:9000 max_fails=0; }</code> </pre> <br>  Pada level frontend, nginx akan membatasi jumlah permintaan yang akan dikirim ke backend (10).  Hal yang menarik adalah bahwa backlog khusus dibuat: jika permintaan ke-11 untuk nginx berasal dari klien, dan nginx melihat bahwa kumpulan php-fpm sedang sibuk, maka permintaan ini ditempatkan di backlog selama 5 detik.  Jika, selama waktu ini, php-fpm tidak dibebaskan, maka baru Ingress yang akan bertindak, yang akan mencoba kembali permintaan ke pod lain.  Ini memperhalus gambar, karena kita akan selalu memiliki 1 pekerja PHP gratis untuk memproses sampel liveness - kita dapat menghindari efek longsoran salju. <br><br><h4>  Pikiran lain </h4><br>  Untuk opsi yang lebih fleksibel dan indah untuk memecahkan masalah ini, ada baiknya mencari ke arah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Utusan</a> dan analognya. <br><br>  Secara umum, agar Prometheus memiliki pekerjaan yang jelas bagi para pekerja, yang pada gilirannya akan membantu menemukan masalah dengan cepat (dan memberi tahu tentang itu), saya sangat menyarankan agar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">eksportir</a> siap pakai untuk mengkonversi data dari perangkat lunak ke format Prometheus. <br><br><h2>  PS </h2><br>  Lainnya dari siklus tips &amp; trik K8: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Halaman kesalahan yang dipersonalisasi di NGINX Ingress</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Transfer sumber daya yang bekerja di sebuah cluster ke manajemen Helm 2</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Akses ke situs dev</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Mempercepat bootstrap dari database besar.</a> " </li></ul><br>  Baca juga di blog kami: <br><br><ul><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Seberapa Ketersediaan Tinggi di Kubernetes Disediakan</a> ”; </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Monitoring and Kubernetes</a> ” <i>(ulasan dan laporan video)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pengalaman kami dengan Kubernetes dalam proyek-proyek kecil</a> " <i>(laporan video, yang mencakup pengantar perangkat teknis Kubernetes)</i> . </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id432748/">https://habr.com/ru/post/id432748/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id432736/index.html">Devops, JUnit5 dan pengujian layanan mikro: pandangan subyektif pada Moscow Heisenbag</a></li>
<li><a href="../id432740/index.html">"CMS" berdasarkan Google Spreadsheets untuk situs statis</a></li>
<li><a href="../id432742/index.html">Tekanan waktu perusahaan</a></li>
<li><a href="../id432744/index.html">DWDM: solusinya lebih murah daripada operator dengan 30-50% (kelas Perusahaan)</a></li>
<li><a href="../id432746/index.html">Selama tiga hari dalam perawatan intensif atau apa yang salah dengan bagian Work-Life Balance di Mobius'18?</a></li>
<li><a href="../id432750/index.html">Kegembiraan Haxe. Sebuah novel dengan bahasa pemrograman yang terabaikan</a></li>
<li><a href="../id432752/index.html">Bukit atau benteng semut? Saya sedang membangun rumah untuk harga sebuah apartemen. 3 bagian. Catu daya</a></li>
<li><a href="../id432754/index.html">Penyimpanan data In-Memory dan On-Disk akan dibawa ke publik</a></li>
<li><a href="../id432756/index.html">Kami menerapkan dukungan aksesibilitas tanpa mengubah komponen visual dari aplikasi seluler</a></li>
<li><a href="../id432760/index.html">Tampilan produk vektor, atau penggunaan model Word2Vec lainnya</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
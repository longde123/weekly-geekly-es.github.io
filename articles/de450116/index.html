<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïß üéá üîõ Betriebssysteme: Drei einfache Teile. Teil 5: Planung: Mehrstufige Feedback-Warteschlange (√úbersetzung) üîµ ‚ÜôÔ∏è üåë</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Einf√ºhrung in Betriebssysteme 
 Hallo Habr! Ich m√∂chte Sie auf eine Reihe von Artikel√ºbersetzungen einer meiner Meinung nach interessanten Literatur a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Betriebssysteme: Drei einfache Teile. Teil 5: Planung: Mehrstufige Feedback-Warteschlange (√úbersetzung)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/450116/"><h1>  Einf√ºhrung in Betriebssysteme </h1><br>  Hallo Habr!  Ich m√∂chte Sie auf eine Reihe von Artikel√ºbersetzungen einer meiner Meinung nach interessanten Literatur aufmerksam machen - OSTEP.  Dieser Artikel beschreibt ziemlich ausf√ºhrlich die Arbeit von Unix-√§hnlichen Betriebssystemen, n√§mlich die Arbeit mit Prozessen, verschiedenen Schedulern, Speicher und anderen √§hnlichen Komponenten, aus denen das moderne Betriebssystem besteht.  Das Original aller Materialien k√∂nnen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier sehen</a> .  Bitte beachten Sie, dass die √úbersetzung unprofessionell (ziemlich frei) durchgef√ºhrt wurde, aber ich hoffe, dass ich die allgemeine Bedeutung beibehalten habe. <br><br>  Laborarbeiten zu diesem Thema finden Sie hier: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das Original</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das Original</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">meine pers√∂nliche Anpassung</a> </li></ul><br>  Andere Teile: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 1: Intro</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 2: Abstraktion: der Prozess</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 3: Einf√ºhrung in die Prozess-API</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 4: Einf√ºhrung in den Scheduler</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 5: MLFQ Scheduler</a> </li></ul><br>  Und du kannst meinen Kanal im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Telegramm</a> ansehen =) <br><a name="habracut"></a><br><h2>  Planung: Mehrstufige Feedback-Warteschlange </h2><br>  In diesem Vortrag werden wir √ºber die Probleme bei der Entwicklung eines der bekanntesten Ans√§tze sprechen <br>  Planung namens <b>Multi-Level Feedback Queue</b> (MLFQ).  Der MLFQ-Scheduler wurde erstmals 1962 von Fernando J. Corbat√≥ in einem System namens Compatible Time-Sharing System (CTSS) beschrieben.  Diese Arbeiten (einschlie√ülich sp√§terer Arbeiten zu Multics) wurden anschlie√üend beim Turing Award eingereicht.  Der Scheduler wurde anschlie√üend verbessert und erhielt ein Aussehen, das bereits in einigen modernen Systemen zu finden ist. <br><br>  Der MLFQ-Algorithmus versucht, zwei grundlegende Querschnittsprobleme zu l√∂sen. <br>  <b>Zun√§chst</b> versucht er, die Bearbeitungszeit zu optimieren, die, wie wir in der vorherigen Vorlesung untersucht haben, optimiert wird, indem am Anfang der Warteschlange der k√ºrzesten Aufgaben begonnen wird.  Das Betriebssystem wei√ü jedoch nicht, wie lange dieser oder jener Prozess funktionieren wird, und dies ist das notwendige Wissen f√ºr den Betrieb der SJF- und STCF-Algorithmen.  <b>Zweitens</b> versucht MLFQ, das System auf Benutzer (z. B. diejenigen, die auf dem Bildschirm sitzen und starren, w√§hrend sie auf den Abschluss der Aufgabe warten) zu reagieren und so die Antwortzeit zu minimieren.  Leider reduzieren Algorithmen wie RR die Antwortzeit, haben jedoch einen sehr schlechten Einfluss auf die Durchlaufzeitmetriken.  Daher unser Problem: Wie kann man einen Scheduler entwerfen, der unseren Anforderungen entspricht und gleichzeitig nichts √ºber die Art des Prozesses im Allgemeinen wei√ü?  Wie kann der Planer die Merkmale der von ihm gestarteten Aufgaben kennenlernen und so bessere Planungsentscheidungen treffen? <br><br>  <u>Das Wesentliche des Problems: Wie kann man die Formulierung von Aufgaben ohne perfektes Wissen planen?</u>  <u>Wie kann ein Scheduler entwickelt werden, der gleichzeitig die Antwortzeit f√ºr interaktive Aufgaben minimiert und gleichzeitig die Bearbeitungszeit minimiert, ohne die Zeit f√ºr die Ausf√ºhrung der Aufgabe zu kennen?</u> <br><br>  Hinweis: Aus fr√ºheren Ereignissen lernen <br><br>  Die MLFQ-Aufstellung ist ein gro√üartiges Beispiel f√ºr ein System, das aus vergangenen Ereignissen lernt, um die Zukunft vorherzusagen.  √Ñhnliche Ans√§tze finden sich h√§ufig im Betriebssystem (und in vielen anderen Bereichen der Informatik, einschlie√ülich Hardware-Vorhersagezweigen und Caching-Algorithmen).  √Ñhnliche Reisen funktionieren, wenn Aufgaben Verhaltensphasen haben und daher vorhersehbar sind. <br><br>  Bei einer solchen Technik sollte man jedoch vorsichtig sein, da sich Vorhersagen sehr leicht als falsch herausstellen und das System dazu veranlassen k√∂nnen, schlechtere Entscheidungen zu treffen, als dies ohne Wissen √ºberhaupt der Fall w√§re. <br><br><h3>  MLFQ: Grundregeln </h3><br>  Beachten Sie die Grundregeln des MLFQ-Algorithmus.  Obwohl es mehrere Implementierungen dieses Algorithmus gibt, sind die grundlegenden Ans√§tze √§hnlich. <br><br>  In der Implementierung, die wir betrachten werden, wird es in MLFQ mehrere separate Warteschlangen geben, von denen jede eine andere Priorit√§t hat.  Eine zur Ausf√ºhrung bereitstehende Aufgabe befindet sich jederzeit in einer Warteschlange.  MLFQ verwendet Priorit√§ten, um zu entscheiden, welche Aufgabe ausgef√ºhrt werden soll, d. H.  Eine Aufgabe mit einer h√∂heren Priorit√§t (eine Aufgabe aus der Warteschlange mit einer h√∂heren Priorit√§t) wird zuerst gestartet. <br><br>  Zweifellos kann sich mehr als eine Aufgabe in einer bestimmten Warteschlange befinden, sodass sie dieselbe Priorit√§t haben.  In diesem Fall wird die RR-Engine verwendet, um den Start unter diesen Aufgaben zu planen. <br><br>  Somit kommen wir zu zwei Grundregeln f√ºr MLFQ: <br><br><ul><li>  Regel 1: Wenn Priorit√§t (A)&gt; Priorit√§t (B), wird Aufgabe A gestartet (B nicht). </li><li>  Regel 2: Wenn Priorit√§t (A) = Priorit√§t (B), werden A &amp; B mit RR gestartet </li></ul><br>  Auf dieser Grundlage sind die Schl√ºsselelemente f√ºr die MLFQ-Planung Priorit√§ten.  Anstatt f√ºr jede Aufgabe eine feste Priorit√§t festzulegen, √§ndert MLFQ seine Priorit√§t abh√§ngig vom beobachteten Verhalten. <br><br>  Wenn beispielsweise eine Aufgabe die Arbeit an der CPU st√§ndig beendet, w√§hrend sie auf Tastatureingaben wartet, beh√§lt MLFQ die Priorit√§t des Prozesses auf einem hohen Niveau bei, da der interaktive Prozess auf diese Weise funktionieren sollte.  Wenn im Gegenteil die Aufgabe die CPU √ºber einen langen Zeitraum st√§ndig und intensiv nutzt, verringert MLFQ ihre Priorit√§t.  Daher wird MLFQ das Verhalten von Prozessen zum Zeitpunkt ihres Betriebs untersuchen und das Verhalten verwenden. <br><br>  Lassen Sie uns ein Beispiel zeichnen, wie die Warteschlangen zu einem bestimmten Zeitpunkt aussehen k√∂nnten, und dann erhalten wir so etwas: <br><br><img src="https://habrastorage.org/webt/4x/ad/rr/4xadrrwfmrtn3mg-se6wgith9gm.png" alt="Bild"><br><br>  In diesem Schema befinden sich 2 Prozesse A und B in der Warteschlange mit der h√∂chsten Priorit√§t.  Prozess C befindet sich irgendwo in der Mitte und Prozess D befindet sich ganz am Ende der Warteschlange.  Gem√§√ü den obigen Beschreibungen des MLFQ-Algorithmus f√ºhrt der Scheduler Aufgaben nur mit der h√∂chsten Priorit√§t gem√§√ü RR aus, und die Aufgaben C, D sind arbeitslos. <br><br>  Ein statischer Schnappschuss liefert nat√ºrlich kein vollst√§ndiges Bild der Funktionsweise von MLFQ. <br>  Es ist wichtig, genau zu verstehen, wie sich das Bild im Laufe der Zeit √§ndert. <br><br><h4>  Versuch 1: So √§ndern Sie die Priorit√§t </h4><br>  Zu diesem Zeitpunkt m√ºssen Sie entscheiden, wie MLFQ die Priorit√§tsstufe der Aufgabe (und damit die Position der Aufgabe in der Warteschlange) w√§hrend ihres Lebenszyklus √§ndert.  Dazu m√ºssen Sie den Workflow ber√ºcksichtigen: eine Reihe interaktiver Aufgaben mit einer kurzen Laufzeit (und damit h√§ufigen CPU-Freigabe) und mehreren langen Aufgaben, die die CPU w√§hrend ihrer gesamten Arbeitszeit nutzen, w√§hrend die Antwortzeit f√ºr solche Aufgaben nicht wichtig ist.  Und so k√∂nnen Sie den ersten Versuch unternehmen, den MLFQ-Algorithmus mit den folgenden Regeln zu implementieren: <br><br><ul><li>  Regel 3: Wenn eine Aufgabe in das System eingeht, wird sie mit der h√∂chsten in die Warteschlange gestellt </li><li>  Priorit√§t. </li><li>  Regel 4a: Wenn eine Aufgabe das gesamte ihr zugewiesene Zeitfenster verwendet, ist es </li><li>  Priorit√§t sinkt. </li><li>  Regel 4b: Wenn die Task die CPU vor Ablauf ihres Zeitfensters freigibt, dann sie </li><li>  bleibt mit der gleichen Priorit√§t. </li></ul><br>  <b>Beispiel 1: Eine einzelne Aufgabe mit langer Laufzeit</b> <br><br>  Wie Sie in diesem Beispiel sehen k√∂nnen, hat die Aufgabe bei der Zulassung die h√∂chste Priorit√§t.  Nach einem Zeitfenster von 10 ms wird der Prozess vom Scheduler vorrangig abgesenkt.  Nach dem n√§chsten Zeitfenster f√§llt die Aufgabe schlie√ülich auf die niedrigste Priorit√§t im System, wo sie verbleibt. <br><br><img src="https://habrastorage.org/webt/jl/wi/fg/jlwifg8osgxds9bpyftx2aoa9pa.png"><br><br>  <b>Beispiel 2: Sie haben eine kurze Aufgabe angesprochen</b> <br><br>  Schauen wir uns nun ein Beispiel an, wie MLFQ versuchen wird, SJF n√§her zu kommen.  In diesem Beispiel gibt es zwei Aufgaben: A, eine lang laufende Aufgabe, die st√§ndig die CPU beansprucht, und B, eine kurze interaktive Aufgabe.  Angenommen, A hat bereits einige Zeit gearbeitet, als Aufgabe B eintrifft. <br><br><img src="https://habrastorage.org/webt/hq/dp/ou/hqdpouigzrlqbjbhwnvgv9e8mxc.png"><br><br>  In diesem Diagramm sind die Ergebnisse des Skripts sichtbar.  Aufgabe A befindet sich wie jede Aufgabe, die eine CPU verwendet, ganz unten.  Aufgabe B erreicht T = 100 und wird mit der h√∂chsten Priorit√§t in die Warteschlange gestellt.  Da die Zeit ihrer Arbeit kurz ist, endet sie, bevor sie die letzte Stufe erreicht. <br><br>  Anhand dieses Beispiels sollte man das Hauptziel des Algorithmus verstehen: Da der Algorithmus keine lange oder kurze Aufgabe kennt, geht er zun√§chst davon aus, dass die Aufgabe kurz ist, und gibt ihr die h√∂chste Priorit√§t.  Wenn es sich um eine wirklich kurze Aufgabe handelt, wird sie schnell erledigt. Wenn es sich um eine lange Aufgabe handelt, wird sie sich langsam in der Priorit√§t nach unten bewegen und bald beweisen, dass es sich um eine wirklich lange Aufgabe handelt, f√ºr die keine Antwort erforderlich ist. <br><br>  <b>Beispiel 3: Was ist mit E / A?</b> <br><br>  Schauen Sie sich nun das E / A-Beispiel an.  Wie in Regel 4b angegeben, bleibt ein Prozess auf derselben Priorit√§tsstufe, wenn er einen Prozessor freigibt, ohne seine Prozessorzeit vollst√§ndig zu nutzen.  Die Absicht dieser Regel ist recht einfach: Wenn eine interaktive Aufgabe viele E / A-Vorg√§nge ausf√ºhrt, z. B. darauf wartet, dass ein Benutzer eine Taste oder eine Maus dr√ºckt, gibt eine solche Aufgabe den Prozessor vor dem zugewiesenen Fenster frei.  Wir m√∂chten eine solche Aufgabe nicht vorrangig weglassen, und daher bleibt sie auf dem gleichen Niveau. <br><br><img src="https://habrastorage.org/webt/md/oa/f_/mdoaf_yf81n7xvy-j_bdo6hvbmm.png"><br><br>  Dieses Beispiel zeigt, wie der Algorithmus mit solchen Prozessen arbeitet - eine interaktive Aufgabe B, die vor dem Ausf√ºhren des E / A-Prozesses nur 1 ms lang eine CPU ben√∂tigt, und eine lange Aufgabe A, die die CPU st√§ndig nutzt. <br><br>  MLFQ h√§lt Prozess B mit der h√∂chsten Priorit√§t, da er die ganze Zeit fortgesetzt wird. <br>  Geben Sie die CPU frei.  Wenn B eine interaktive Aufgabe ist, hat der Algorithmus sein Ziel erreicht, interaktive Aufgaben schnell zu starten. <br><br>  <b>Probleme mit dem aktuellen MLFQ-Algorithmus</b> <br><br>  In den vorherigen Beispielen haben wir die Basisversion von MLFQ erstellt.  Und es scheint, dass er seine Arbeit gut und ehrlich macht, indem er die Prozessorzeit ehrlich auf lange Aufgaben verteilt und es kurzen Aufgaben oder Aufgaben, die intensiv auf E / A zugreifen, erm√∂glicht, schnell zu arbeiten.  Leider enth√§lt dieser Ansatz mehrere schwerwiegende Probleme. <br><br>  <b>Erstens</b> das Problem des Hungers: Wenn es viele interaktive Aufgaben im System gibt, verbrauchen sie die gesamte Prozessorzeit und somit kann keine einzige lange Aufgabe ausgef√ºhrt werden (sie hungern). <br><br>  <b>Zweitens</b> k√∂nnten intelligente Benutzer ihre Programme so schreiben <br>  Trick den Planer.  Der Trick besteht darin, etwas zu tun <br>  Scheduler, um dem Prozess mehr Prozessorzeit zu geben.  Algorithmus das <br>  oben beschrieben ist ziemlich anf√§llig f√ºr solche Angriffe: bevor das Zeitfenster praktisch ist <br>  beendet m√ºssen Sie eine E / A-Operation ausf√ºhren (f√ºr einige, egal welche Datei) <br>  und damit die CPU freigeben.  Dieses Verhalten erm√∂glicht es Ihnen, im selben zu bleiben <br>  die Warteschlange selbst und wieder einen gr√∂√üeren Prozentsatz der CPU-Zeit erhalten.  Wenn fertig <br>  Dies ist korrekt (z. B. 99% der Fensterzeit vor dem Freigeben der CPU). <br>  Eine solche Aufgabe kann den Prozessor einfach monopolisieren. <br><br>  Schlie√ülich kann ein Programm sein Verhalten im Laufe der Zeit √§ndern.  Diese Aufgaben <br>  Wer die CPU benutzt hat, kann interaktiv werden.  In unserem Beispiel √§hnlich <br>  Aufgaben werden vom Planer nicht richtig behandelt, wie andere es tun w√ºrden <br>  (anf√§ngliche) interaktive Aufgaben. <br><br>  <u>Frage an das Publikum: Welche Angriffe auf den Planer k√∂nnten in der modernen Welt erfolgen?</u> <u><br></u> <br><h4>  Versuch 2: Priorit√§t erh√∂hen </h4><br><br>  Versuchen wir, die Regeln zu √§ndern und herauszufinden, ob wir Probleme mit vermeiden k√∂nnen <br>  Fasten.  Was k√∂nnten wir tun, um dies sicherzustellen? <br>  CPU-Aufgaben erhalten ihre Zeit (auch wenn nicht lange). <br>  Als einfache L√∂sung f√ºr das Problem k√∂nnen Sie regelm√§√üig anbieten <br>  Erh√∂hen Sie die Priorit√§t aller dieser Aufgaben im System.  Es gibt viele M√∂glichkeiten. <br>  Um dies zu erreichen, versuchen wir, als Beispiel etwas Einfaches zu implementieren: √ºbersetzen <br>  Alle Aufgaben gleichzeitig mit h√∂chster Priorit√§t, daher die neue Regel: <br><ul><li>  <b>Regel 5</b> : <b>√úbertragen Sie</b> nach einer bestimmten Zeitspanne von S alle Aufgaben im System auf die h√∂chste Priorit√§t. </li></ul><br>  Unsere neue Regel l√∂st zwei Probleme gleichzeitig.  Erstens die Prozesse <br>  garantiert nicht verhungern: Aufgaben mit der h√∂chsten Priorit√§t werden geteilt <br>  Prozessorzeit nach dem RR-Algorithmus und damit alle Prozesse empfangen <br>  Prozessorzeit.  Zweitens, wenn es einen Prozess gibt, der zuvor verwendet wurde <br>  Nur der Prozessor wird interaktiv, dann bleibt er im Einklang mit dem h√∂heren <br>  Priorit√§t nach einmal erh√§lt eine Priorit√§tserh√∂hung auf die h√∂chste. <br>  Betrachten Sie ein Beispiel.  Betrachten Sie in diesem Szenario einen Prozess mit <br><img src="https://habrastorage.org/webt/cx/te/ll/cxtellydeep0hkgrqfiypt-zqq4.png"><br><br>  CPU und zwei interaktive, kurze Prozesse.  Links in der Abbildung zeigt die Abbildung das Verhalten, ohne die Priorit√§t zu erh√∂hen, und daher beginnt die lange Aufgabe zu verhungern, nachdem zwei interaktive Aufgaben im System angekommen sind.  In der Abbildung rechts wird alle 50 ms die Priorit√§t erh√∂ht, sodass alle Prozesse garantiert Prozessorzeit erhalten und regelm√§√üig gestartet werden.  In diesem Fall werden 50 ms als Beispiel genommen, in Wirklichkeit ist diese Zahl etwas gr√∂√üer. <br>  Offensichtlich f√ºhrt die Hinzuf√ºgung von Zeit f√ºr eine periodische Erh√∂hung von S zu <br>  logische Frage: Welcher Wert sollte gesetzt werden?  Einer der Geehrten <br>  Systemingenieure John Ousterhout nannte √§hnliche Gr√∂√üen in Systemen wie voo-doo <br>  konstant, weil sie irgendwie schwarze Magie f√ºr richtig forderten <br>  ausstellen.  Und leider hat S so ein Aroma.  Wenn Sie den Wert auch einstellen <br>  gro√üe - lange Aufgaben werden anfangen zu verhungern.  Und wenn Sie den Wert zu niedrig einstellen, <br>  Interaktive Aufgaben erhalten keine ordnungsgem√§√üe Prozessorzeit. <br><br><h4>  Versuch 3: Beste Buchhaltung </h4><br><br>  Jetzt haben wir noch ein Problem, das gel√∂st werden muss: wie nicht <br>  unseren Planer betr√ºgen lassen?  Schuld an dieser Gelegenheit sind <br>  Regeln 4a, 4b, die es der Aufgabe erm√∂glichen, die Priorit√§t beizubehalten und den Prozessor freizugeben <br>  vor Ablauf der zugewiesenen Zeit.  Wie gehe ich damit um? <br>  Die L√∂sung in diesem Fall kann als die beste Abrechnung der CPU-Zeit auf jedem angesehen werden <br>  MLFQ-Level.  Anstatt die Zeit zu vergessen, die das Programm verwendet hat <br>  Prozessor f√ºr den zugewiesenen Zeitraum sollten Sie ihn ber√ºcksichtigen und speichern.  Nachdem <br>  Der Prozess hat Zeit daf√ºr aufgewendet, sollte auf den n√§chsten reduziert werden <br>  Priorit√§tsstufe.  Egal wie der Prozess seine Zeit nutzt - wie <br>  st√§ndig auf dem Prozessor oder so viele Anrufe rechnen.  Auf diese Weise, <br>  Regel 4 sollte wie folgt umgeschrieben werden: <br><br><ul><li>  <b>Regel 4</b> : Nachdem die Aufgabe die ihr in der aktuellen Warteschlange <b>zugewiesene</b> Zeit <b>aufgebraucht</b> hat (unabh√§ngig davon, wie oft sie die CPU freigegeben hat), nimmt die Priorit√§t einer solchen Aufgabe ab (sie bewegt sich in der Warteschlange nach unten). </li></ul><br>  Schauen wir uns ein Beispiel an: <br><img src="https://habrastorage.org/webt/je/rs/kw/jerskwy36cewrg6auapm-dal7iu.png">  "" <br><br>  Die Abbildung zeigt, was passiert, wenn Sie versuchen, den Scheduler zu t√§uschen, wie <br>  Wenn es mit den vorherigen Regeln 4a, 4b w√§re, erhalten wir das Ergebnis auf der linken Seite.  Frohes neues <br>  Die Regel ist das Ergebnis auf der rechten Seite.  Vor dem Schutz kann jeder Prozess E / A bis zum Abschluss aufrufen und <br>  dominieren somit die CPU nach Aktivierung des Schutzes, unabh√§ngig vom Verhalten <br>  I / O, es wird immer noch auf der ganzen Linie fallen und wird daher nicht unehrlich sein <br>  CPU-Ressourcen in Besitz nehmen. <br><br><h4>  Verbesserung des MLFQ und anderer Probleme </h4><br>  Mit den oben genannten Verbesserungen treten neue Probleme auf: eines der Hauptprobleme <br>  Fragen - wie man einen solchen Scheduler parametriert?  Das hei√üt,  Wie viel sollte sein <br>  platzt?  Wie gro√ü sollte das Programmfenster in der Warteschlange sein?  Wie <br>  Die Programmpriorit√§t sollte h√§ufig erh√∂ht werden, um Hunger zu vermeiden <br>  √Ñnderungen im Programmverhalten ber√ºcksichtigen?  Auf diese Fragen ist es nicht einfach <br>  Antwort und nur Experimente mit Lasten und nachfolgender Konfiguration <br>  Der Planer kann zu einem zufriedenstellenden Gleichgewicht f√ºhren. <br><br>  Bei den meisten MLFQ-Implementierungen k√∂nnen Sie beispielsweise unterschiedliche Zuweisungen vornehmen <br>  Zeitintervalle zu verschiedenen Warteschlangen.  Warteschlangen mit hoher Priorit√§t normalerweise <br>  kurze Intervalle werden zugewiesen.  Diese Warteschlangen bestehen aus interaktiven Aufgaben. <br>  Das Umschalten ist sehr empfindlich und sollte 10 oder weniger dauern <br>  ms  Im Gegensatz dazu bestehen Warteschlangen mit niedriger Priorit√§t aus langen Aufgaben <br>  CPU  In diesem Fall passen lange Zeitintervalle sehr gut (100 ms). <br><img src="https://habrastorage.org/webt/p4/1j/-d/p41j-d9spzwfok9w7xmkcewqgrq.png"><br><br>  In diesem Beispiel gab es zwei Aufgaben, die in der Warteschlange 20 mit hoher Priorit√§t ausgef√ºhrt wurden <br>  ms, 10 ms lang durch Windows unterbrochen.  40 ms in der mittleren Warteschlange (Fenster bei 20 ms) und in der niedrigen Priorit√§t <br>  Das Zeitfenster f√ºr die Warteschlange betrug 40 ms, in dem die Aufgaben ihre Arbeit erledigten. <br><br>  Die Solaris OS MLFQ-Implementierung ist eine Klasse von Time-Sharing-Schedulern. <br>  Der Scheduler bietet eine Reihe von Tabellen, die genau bestimmen, wie es sein soll <br>  √Ñndern Sie die Priorit√§t des Prozesses √ºber seine Lebensdauer, was sollte die Gr√∂√üe sein <br>  das ausgew√§hlte Fenster und wie oft Sie die Priorit√§ten der Aufgabe erh√∂hen m√ºssen.  Admin <br>  Systeme k√∂nnen mit dieser Tabelle interagieren und den Scheduler verhalten <br>  anders.  Standardm√§√üig enth√§lt diese Tabelle 60 inkrementelle Warteschlangen. <br>  Fenstergr√∂√üe von 20 ms (hohe Priorit√§t) bis zu mehreren hundert ms (niedrigste Priorit√§t) und <br>  auch mit einem Schub aller Aufgaben einmal pro Sekunde. <br><br>  Andere MLFQ-Planer verwenden keine Tabelle oder eine bestimmte <br>  die Regeln, die in dieser Vorlesung beschrieben werden, im Gegenteil, sie berechnen Priorit√§ten mit <br>  mathematische Formeln.  So verwendet beispielsweise der Scheduler in FreeBSD die Formel f√ºr <br>  Berechnen der aktuellen Priorit√§t einer Aufgabe basierend auf dem Umfang des Prozesses <br>  gebrauchte CPU.  Dar√ºber hinaus nimmt die Nutzung der CPU mit der Zeit ab und so weiter <br>  Somit erfolgt die Priorit√§tserh√∂hung etwas anders als oben beschrieben.  Ist das so <br>  Zerfallsalgorithmen genannt.  Seit Version 7.1 verwendet FreeBSD den ULE-Scheduler. <br><br>  Schlie√ülich haben viele Planer andere Funktionen.  Zum Beispiel einige <br>  Planer reservieren die h√∂chsten Ebenen f√ºr das Betriebssystem und so weiter <br>  Auf diese Weise kann kein Benutzerprozess die h√∂chste Priorit√§t erhalten <br>  System.  Bei einigen Systemen k√∂nnen Sie Tipps geben, um zu helfen. <br>  der Scheduler, um Priorit√§ten richtig zu setzen.  Zum Beispiel mit dem Befehl <b>nice</b> <br>  Sie k√∂nnen die Priorit√§t der Aufgabe erh√∂hen oder verringern und damit oder erh√∂hen <br>  Reduzieren Sie die Wahrscheinlichkeit, dass das Programm Prozessorzeit ben√∂tigt. <br><h3>  MLFQ: Zusammenfassung </h3><br>  Wir haben einen Planungsansatz namens MLFQ beschrieben.  Sein Name <br>  im Prinzip der Arbeit abgeschlossen - es hat mehrere Warteschlangen und verwendet Feedback <br>    . <br>     : <br><ul><li> <b>Rule1</b> :  () &gt; (),     (  ) </li><li> <b>Rule2</b> :  () = (),     RR </li><li> <b>Rule3</b> :     ,       . </li><li> <b>Rule4</b> :            (       CPU)     (   ). </li><li> <b>Rule5</b> :     S        . </li></ul><br> MLFQ     ‚Äî       <br>   ,        <br>  .          ‚Äî      (SJF, STCF)    , <br>  CPU .   ,  BSD   , <br> Solaris, Windows, Mac        <br> MLFQ    . <br><h4>  : </h4><br><ol><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">manpages.debian.org/stretch/manpages/sched.7.en.html</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">en.wikipedia.org/wiki/Scheduling_</a> (computing) </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">pages.lip6.fr/Julia.Lawall/atc18-bouron.pdf</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.usenix.org/legacy/event/bsdcon03/tech/full_papers/roberson/roberson.pdf</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">chebykin.org/freebsd-process-scheduling</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de450116/">https://habr.com/ru/post/de450116/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de450104/index.html">Sehr schwierig und sehr interessant: IT-Communities auf TechTrain</a></li>
<li><a href="../de450106/index.html">Das Projekt der Organisation von Bau und Wiederaufbau unter beengten Verh√§ltnissen auf der SPDS-Baustelle</a></li>
<li><a href="../de450110/index.html">Geschmacksmuster: Teil zwei (Beispiele von Microsoft, Snapchat, Samsung, Netflix, Airbnb, Tinder)</a></li>
<li><a href="../de450112/index.html">Eh, was ist mit den Koffern passiert ?! Am Beispiel eines Kinderkofferscooters ZINC</a></li>
<li><a href="../de450114/index.html">√úber das, was wir dank Ihres Ratschlags in EWM implementiert haben</a></li>
<li><a href="../de450118/index.html">Streamen Sie den Bildschirm √ºber das Netzwerk auf mehrere Ger√§te</a></li>
<li><a href="../de450120/index.html">Suchen Sie nach √§hnlichen Bildern und analysieren Sie einen einzelnen Algorithmus</a></li>
<li><a href="../de450122/index.html">Startup Digest: Genetics (Januar - M√§rz 2019)</a></li>
<li><a href="../de450124/index.html">Konfigurieren von OsmAnd-Karten der Strava-Heatmap-Ebene</a></li>
<li><a href="../de450126/index.html">Die Hintert√ºr und der Buhtrap-Verschl√ºsseler wurden mit Yandex.Direct verteilt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
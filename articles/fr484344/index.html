<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôÜüèº ‚öæÔ∏è üë®üèª‚Äçüî¨ Trois niveaux d'autoscaling dans Kubernetes: comment les utiliser efficacement üíù üëÜüèæ üöö</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pour ma√Ætriser pleinement Kubernetes, vous devez conna√Ætre les diff√©rentes fa√ßons de faire √©voluer les ressources du cluster: selon les d√©veloppeurs d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Trois niveaux d'autoscaling dans Kubernetes: comment les utiliser efficacement</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/484344/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/ns/da/j-/nsdaj-fipddnizqrkx4z2rzvyc0.png"></div><br>  Pour ma√Ætriser pleinement Kubernetes, vous devez conna√Ætre les diff√©rentes fa√ßons de faire <a href="https://speakerdeck.com/thockin/everything-you-ever-wanted-to-know-about-resource-scheduling-dot-dot-dot-almost">√©voluer les</a> ressources du cluster: selon <a href="https://speakerdeck.com/thockin/everything-you-ever-wanted-to-know-about-resource-scheduling-dot-dot-dot-almost">les d√©veloppeurs du syst√®me</a> , c'est l'une des principales t√¢ches de Kubernetes.  Nous avons pr√©par√© un examen de haut niveau des m√©canismes de mise √† l'√©chelle automatique horizontale et verticale et de redimensionnement de cluster, ainsi que des recommandations sur la fa√ßon de les utiliser efficacement. <br><br>  Un article de <a href="https://www.magalix.com/blog/kubernetes-autoscaling-101">Kubernetes Autoscaling 101: Cluster Autoscaler, Horizontal Autoscaler et Vertical Pod Autoscaler a √©t√©</a> traduit par une √©quipe qui a impl√©ment√© l' <a href="https://mcs.mail.ru/containers/">autoscaling</a> dans <a href="https://mcs.mail.ru/containers/">Kubernetes aaS √† partir de Mail.ru.</a> <br><a name="habracut"></a><br><h2>  Pourquoi est-il important de penser √† la mise √† l'√©chelle </h2><br>  <a href="https://mcs.mail.ru/blog/kubernetes-for-much-stuff">Kubernetes</a> est un outil de gestion et d'orchestration des ressources.  Bien s√ªr, il est agr√©able de bricoler avec des fonctions de d√©ploiement, de surveillance et de gestion des pods sympas (le module pod est un groupe de conteneurs qui sont lanc√©s en r√©ponse √† une demande). <br><br>  Cependant, vous devriez penser √† ces probl√®mes: <br><br><ol><li>  Comment faire √©voluer les modules et les applications? <br></li><li>  Comment maintenir les conteneurs op√©rationnels et efficaces? <br></li><li>  Comment r√©pondre aux changements constants du code et des charges de travail des utilisateurs? <br></li></ol><br>  La configuration des clusters Kubernetes pour √©quilibrer les ressources et les performances peut √™tre difficile; cela n√©cessite une connaissance approfondie des composants internes de Kubernetes.  La charge de travail de votre application ou de vos services peut varier au cours de la journ√©e, voire d'une heure, l'√©quilibrage est donc mieux repr√©sent√© comme un processus continu. <br><br><h2>  Niveaux de mise √† l'√©chelle automatique de Kubernetes </h2><br>  Une mise √† l'√©chelle automatique efficace n√©cessite une coordination entre deux niveaux: <br><br><ol><li>  Niveau du pod, y compris horizontal (horizontal Pod Autoscaler, HPA) et vertical auto-scaling (Vertical Pod Autoscaler, VPA).  Cela met √† l'√©chelle les ressources disponibles pour vos conteneurs. <br></li><li>  Le niveau de cluster, contr√¥l√© par le syst√®me Cluster Autoscaler (CA), augmente ou diminue le nombre de n≈ìuds au sein du cluster. <br></li></ol><br><h2>  Module de mise √† l'√©chelle automatique horizontale (HPA) </h2><br>  Comme son nom l'indique, HPA met √† l'√©chelle le nombre de r√©pliques de pod.  Comme d√©clencheur pour changer le nombre de r√©pliques, la plupart des devops utilisent le CPU et la charge m√©moire.  Cependant, vous pouvez faire √©voluer le syst√®me en fonction de <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">m√©triques personnalis√©es</a> , de leur <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">combinaison</a> ou m√™me <a href="https://cloud.google.com/kubernetes-engine/docs/tutorials/external-metrics-autoscaling">de m√©triques externes</a> . <br><br>  Flux de travail HPA de haut niveau: <br><br><ol><li>  HPA v√©rifie en permanence les valeurs m√©triques sp√©cifi√©es lors de l'installation avec un intervalle par d√©faut de 30 secondes. <br></li><li>  HPA essaie d'augmenter le nombre de modules si le seuil sp√©cifi√© est atteint. <br></li><li>  HPA met √† jour le nombre de r√©pliques dans le contr√¥leur de d√©ploiement / r√©plication. <br></li><li>  Le contr√¥leur de d√©ploiement / r√©plication d√©ploie ensuite tous les modules compl√©mentaires requis. <br></li></ol><br><img src="https://habrastorage.org/getpro/habr/post_images/879/338/b0e/879338b0e99aa2b652ab1406e9677319.jpg"><br>  <i>HPA lance le processus de d√©ploiement de module lorsque le seuil de m√©triques est atteint</i> <br><br>  Lorsque vous utilisez HPA, tenez compte des √©l√©ments suivants: <br><br><ul><li>  L'intervalle de validation HPA par d√©faut est de 30 secondes.  Il est d√©fini avec l'indicateur de <i>p√©riode horizontale-pod-autoscaler-sync-period</i> dans le gestionnaire de contr√¥leur. <br></li><li>  L'erreur relative par d√©faut est de 10%. <br></li><li>  Apr√®s la derni√®re augmentation du nombre de modules, HPA s'attend √† ce que les mesures se stabilisent dans les trois minutes.  Cet intervalle est d√©fini par l'indicateur de <i>d√©lai horizontal-autoscaler-upscale-delay</i> . <br></li><li>  Apr√®s la derni√®re r√©duction du nombre de modules, le HPA pr√©voit de se stabiliser pendant cinq minutes.  Cet intervalle est d√©fini avec l'indicateur de <i>d√©lai horizontal-autoscaler-downscale-delay</i> . <br></li><li> HPA fonctionne mieux avec les objets de d√©ploiement, pas avec les contr√¥leurs de r√©plication.  La mise √† l'√©chelle automatique horizontale n'est pas compatible avec les mises √† jour continues, qui manipulent directement les contr√¥leurs de r√©plication.  Lors du d√©ploiement, le nombre de r√©pliques d√©pend directement des objets de d√©ploiement. <br></li></ul><br><h2>  Autoscaling vertical des pods </h2><br>  Vertical Auto Scale (VPA) alloue plus (ou moins) de temps processeur ou m√©moire aux pods existants.  Il convient aux pods avec ou sans √©tat sans √©tat, mais il est principalement destin√© aux services avec √©tat.  Cependant, vous pouvez appliquer l'APV pour les modules sans √©tat si vous devez ajuster automatiquement la quantit√© de ressources initialement allou√©es. <br><br>  VPA r√©pond √©galement aux √©v√©nements OOM (m√©moire insuffisante, m√©moire insuffisante).  Pour modifier la dur√©e du processeur et la taille de la m√©moire, des red√©marrages du pod sont n√©cessaires.  Lors du red√©marrage, l'APV respecte le <a href="https://kubernetes.io/docs/concepts/workloads/pods/disruptions/">budget de distribution des pods (PDB</a> ) pour garantir le nombre minimum de modules. <br><br>  Vous pouvez d√©finir la quantit√© minimale et maximale de ressources pour chaque module.  Ainsi, vous pouvez limiter la quantit√© maximale de m√©moire allou√©e √† une limite de 8 Go.  Cela est utile si les n≈ìuds actuels ne peuvent tout simplement pas allouer plus de 8 Go de m√©moire par conteneur.  Les sp√©cifications d√©taill√©es et les m√©canismes de fonctionnement sont d√©crits dans le <a href="">wiki officiel de l'APV</a> . <br><br>  De plus, VPA a une fonction de recommandation int√©ressante (VPA Recommender).  Il suit l'utilisation des ressources et les √©v√©nements OOM de tous les modules pour offrir de nouvelles valeurs de m√©moire et de temps processeur bas√©es sur un algorithme intelligent prenant en compte les m√©triques historiques.  Il existe √©galement une API qui prend un descripteur de module et renvoie les valeurs de ressource propos√©es. <br><br>  Il convient de noter que VPA Recommender ne surveille pas la "limite" des ressources.  Cela peut amener le module √† monopoliser les ressources au sein des n≈ìuds.  Il est pr√©f√©rable de d√©finir une valeur limite au niveau de l'espace de noms pour √©viter un √©norme gaspillage de m√©moire ou de temps processeur. <br><br>  Sch√©ma de haut niveau de l'APV: <br><br><ol><li>  Le VPA v√©rifie en continu les valeurs m√©triques sp√©cifi√©es lors de l'installation avec un intervalle par d√©faut de 10 secondes. <br></li><li>  Si le seuil sp√©cifi√© est atteint, l'APV tente de modifier la quantit√© allou√©e de ressources. <br></li><li>  VPA met √† jour la quantit√© de ressources dans le contr√¥leur de d√©ploiement / r√©plication. <br></li><li>  Lorsque vous red√©marrez les modules, toutes les nouvelles ressources sont appliqu√©es aux instances cr√©√©es. <br></li></ol><br><img src="https://habrastorage.org/getpro/habr/post_images/738/82e/e90/73882ee906b515bcf4c9a8ab42a742b6.jpg"><br>  <i>VPA ajoute la quantit√© requise de ressources</i> <br><br>  Tenez compte des points suivants lorsque vous utilisez VPA: <br><br><ul><li>  La mise √† l'√©chelle n√©cessite un red√©marrage obligatoire du module.  Cela est n√©cessaire pour √©viter un fonctionnement instable apr√®s avoir effectu√© des modifications.  Pour des raisons de fiabilit√©, les modules sont red√©marr√©s et r√©partis entre les n≈ìuds en fonction des ressources nouvellement allou√©es. <br></li><li>  VPA et HPA ne sont pas encore compatibles entre eux et ne peuvent pas fonctionner sur les m√™mes pods.  Si vous utilisez les deux m√©canismes de mise √† l'√©chelle dans le m√™me cluster, assurez-vous que les param√®tres ne permettront pas leur activation sur les m√™mes objets. <br></li><li>  VPA configure les requ√™tes de conteneur pour les ressources en fonction uniquement de l'utilisation pass√©e et actuelle.  Il ne fixe pas de limites √† l'utilisation des ressources.  Il peut y avoir des probl√®mes avec un fonctionnement incorrect des applications qui commenceront √† saisir de plus en plus de ressources, cela entra√Ænera la d√©sactivation de ce pod par Kubernetes. <br></li><li>  L'APV est encore √† un stade pr√©coce de d√©veloppement.  Soyez pr√™t √† ce que, dans un proche avenir, le syst√®me puisse subir quelques modifications.  Vous pouvez en savoir plus sur les <a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler">limitations connues</a> et <a href="">les plans de d√©veloppement</a> .  Ainsi, dans les plans de mise en ≈ìuvre du travail conjoint de VPA et HPA, ainsi que le d√©ploiement de modules ainsi qu'une politique de mise √† l'√©chelle verticale pour eux (par exemple, une √©tiquette sp√©ciale `` n√©cessite VPA ''). <br></li></ul><br><h2>  Mise √† l'√©chelle automatique du cluster Kubernetes </h2><br>  Cluster Autoscaler (CA) modifie le nombre de n≈ìuds en fonction du nombre de pods en attente.  Le syst√®me v√©rifie p√©riodiquement les modules en attente - et augmente la taille du cluster si davantage de ressources sont n√©cessaires et si le cluster ne d√©passe pas les limites √©tablies.  L'autorit√© de certification interagit avec le fournisseur de services cloud, lui demande des n≈ìuds suppl√©mentaires ou lib√®re les n≈ìuds inactifs.  La premi√®re version publique de CA a √©t√© introduite dans Kubernetes 1.8. <br><br>  Sch√©ma de fonctionnement de haut niveau CA: <br><br><ol><li>  L'autorit√© de certification recherche les modules en √©tat de veille avec un intervalle par d√©faut de 10 secondes. <br></li><li>  Si un ou plusieurs modules sont en √©tat de veille en raison des ressources insuffisantes disponibles dans le cluster pour leur distribution, il essaie de pr√©parer un ou plusieurs n≈ìuds suppl√©mentaires. <br></li><li>  Lorsque le fournisseur de services cloud alloue le n≈ìud requis, il rejoint le cluster et est pr√™t √† servir les modules pod. <br></li><li>  Kubernetes Scheduler distribue les modules en attente √† un nouvel h√¥te.  Si apr√®s cela, certains modules restent toujours en √©tat de veille, le processus se r√©p√®te et de nouveaux n≈ìuds sont ajout√©s au cluster. <br></li></ol><br><img src="https://habrastorage.org/getpro/habr/post_images/13a/65b/ac3/13a65bac364aca04c83fc6fe1a59c60f.jpg"><br>  <i>Allocation automatique des n≈ìuds de cluster dans le cloud</i> <br><br>  Tenez compte des √©l√©ments suivants lorsque vous utilisez CA: <br><br><ul><li>  CA garantit que tous les modules du cluster ont un emplacement pour s'ex√©cuter, quelle que soit la charge du processeur.  De plus, il essaie de s'assurer qu'il n'y a pas de n≈ìuds inutiles dans le cluster. <br></li><li>  L'AC enregistre le besoin de mise √† l'√©chelle apr√®s environ 30 secondes. <br></li><li>  Une fois que le n≈ìud est devenu inutile, CA attend par d√©faut 10 minutes avant de mettre le syst√®me √† l'√©chelle. <br></li><li>  Dans le syst√®me de mise √† l'√©chelle automatique, il y a le concept d'agrandisseurs.  Ce sont diff√©rentes strat√©gies pour choisir un groupe de n≈ìuds auxquels de nouveaux seront ajout√©s. <br></li><li>  Utilisez de mani√®re responsable l'option <i>cluster-autoscaler.kubernetes.io/safe-to-evict (true)</i> .  Si vous installez plusieurs pods ou si beaucoup d'entre eux sont dispers√©s sur tous les n≈ìuds, vous perdrez consid√©rablement la possibilit√© de r√©duire la taille du cluster. <br></li><li>  Utilisez <a href="https://kubernetes.io/docs/concepts/workloads/pods/disruptions/">PodDisruptionBudgets</a> pour emp√™cher la suppression des pods, car la partie de votre application peut √©chouer compl√®tement. <br></li></ul><br><h2>  Comment les syst√®mes de mise √† l'√©chelle automatique de Kubernetes interagissent </h2><br>  Pour une harmonie parfaite, la mise √† l'√©chelle automatique doit √™tre appliqu√©e √† la fois au niveau du pod (HPA / VPA) et au niveau du cluster.  Ils interagissent relativement simplement les uns avec les autres: <br><br><ol><li>  HPA ou VPA met √† jour les r√©pliques de pods ou les ressources allou√©es aux pods existants. <br></li><li>  S'il n'y a pas suffisamment de n≈ìuds pour la mise √† l'√©chelle planifi√©e, l'autorit√© de certification constate la pr√©sence de pods √† l'√©tat inactif. <br></li><li>  CA alloue de nouveaux n≈ìuds. <br></li><li>  Les modules sont distribu√©s √† de nouveaux n≈ìuds. <br></li></ol><br><img src="https://habrastorage.org/getpro/habr/post_images/20a/8c0/bef/20a8c0befe51c509efc2354c43aeaf13.jpg"><br>  <i>Syst√®me de mise √† l'√©chelle collaborative Kubernetes</i> <br><br><h2>  Erreurs courantes de mise √† l'√©chelle automatique de Kubernetes </h2><br>  Les d√©veloppeurs rencontrent plusieurs probl√®mes typiques lorsqu'ils essaient d'appliquer la mise √† l'√©chelle automatique. <br><br>  HPA et VPA d√©pendent des m√©triques et de certaines donn√©es historiques.  Si des ressources insuffisantes sont allou√©es, les modules seront r√©duits et ne pourront pas g√©n√©rer de m√©triques.  Dans ce cas, la mise √† l'√©chelle automatique n'aura jamais lieu. <br><br>  L'op√©ration de mise √† l'√©chelle elle-m√™me est sensible au temps.  Nous voulons que les modules et le cluster √©voluent rapidement - avant que les utilisateurs ne remarquent des probl√®mes ou des √©checs.  Par cons√©quent, le temps de mise √† l'√©chelle moyen des modules et du cluster doit √™tre pris en compte. <br><br>  Sc√©nario id√©al - 4 minutes: <br><br><ol><li>  30 secondes  Mise √† jour des mesures cibles: 30 √† 60 secondes. <br></li><li>  30 secondes  HPA v√©rifie les valeurs m√©triques: 30 secondes. <br></li><li>  Moins de 2 secondes.  Les modules pod sont cr√©√©s et passent en √©tat de veille: 1 seconde. <br></li><li>  Moins de 2 secondes.  L'autorit√© de certification voit les modules en attente et envoie des appels pour pr√©parer les n≈ìuds: 1 seconde. <br></li><li>  3 minutes  Le fournisseur de cloud alloue des n≈ìuds.  Les K8 attendent jusqu'√† ce qu'ils soient pr√™ts: jusqu'√† 10 minutes (d√©pend de plusieurs facteurs). <br></li></ol><br>  Pire (plus r√©aliste) sc√©nario - 12 minutes: <br><br><ol><li>  30 secondes  Mise √† jour des m√©triques cibles. <br></li><li>  30 secondes  HPA valide les valeurs m√©triques. <br></li><li>  Moins de 2 secondes.  Les modules pod sont cr√©√©s et passent en √©tat de veille. <br></li><li>  Moins de 2 secondes.  CA voit les modules en attente et envoie des appels pour pr√©parer les n≈ìuds. <br></li><li>  10 minutes  Le fournisseur de cloud alloue des n≈ìuds.  Les K8 attendent jusqu'√† ce qu'ils soient pr√™ts.  Le temps d'attente d√©pend de plusieurs facteurs, comme le retard du fournisseur, le retard de l'OS, le travail des outils auxiliaires. <br></li></ol><br>  Ne confondez pas les m√©canismes de mise √† l'√©chelle des fournisseurs de cloud avec notre autorit√© de certification.  Ce dernier fonctionne √† l'int√©rieur du cluster Kubernetes, tandis que le m√©canisme du fournisseur de cloud fonctionne sur la base de l'allocation des n≈ìuds.  Il ne sait pas ce qui se passe avec vos pods ou votre application.  Ces syst√®mes fonctionnent en parall√®le. <br><br><h2>  Comment g√©rer la mise √† l'√©chelle dans Kubernetes </h2><br><ol><li>  Kubernetes est un outil de gestion et d'orchestration des ressources.  Les op√©rations de pod de cluster et de gestion des ressources sont une √©tape cl√© dans le d√©veloppement de Kubernetes. <br></li><li>  D√©couvrez la logique d'√©volutivit√© des pods pour HPA et VPA. <br></li><li>  L'AC ne doit √™tre utilis√© que si vous comprenez bien les besoins de vos dosettes et conteneurs. <br></li><li>  Pour une configuration de cluster optimale, vous devez comprendre comment les diff√©rents syst√®mes de mise √† l'√©chelle fonctionnent ensemble. <br></li><li>  Lors de l'√©valuation des temps de mise √† l'√©chelle, gardez √† l'esprit les pires et les meilleurs sc√©narios. <br></li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr484344/">https://habr.com/ru/post/fr484344/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr484332/index.html">Concentrez-vous sur la gestion des t√¢ches. Comment nous faisons notre syst√®me de gestion</a></li>
<li><a href="../fr484336/index.html">R√®gles de travail avec les tableaux dynamiques et les classes de collection personnalis√©es</a></li>
<li><a href="../fr484338/index.html">Projet Neon de Samsung: banquiers num√©riques, h√¥tes de t√©l√©vision, compagnons</a></li>
<li><a href="../fr484340/index.html">Java Digest du 17 janvier. Les deux premi√®res semaines de la nouvelle ann√©e</a></li>
<li><a href="../fr484342/index.html">Bo√Æte √† outils bas√©e sur Eclipse et GTK +, pour ¬´Toradex Colibri T20 (Linux)¬ª</a></li>
<li><a href="../fr484356/index.html">Un projet int√©ressant dans une √©quipe sympathique, ou combien co√ªte le bon employ√©?</a></li>
<li><a href="../fr484358/index.html">Gestion de portefeuille en R</a></li>
<li><a href="../fr484364/index.html">√Ä 26 ans, Yana Harlan dirige le d√©veloppement d'un moteur spatial. L'ann√©e prochaine, ils pr√©voient de le lancer.</a></li>
<li><a href="../fr484368/index.html">Comment j'ai fait un moteur de recherche pour Telegram</a></li>
<li><a href="../fr484370/index.html">Slurm SRE - apprenez √† assurer le bonheur des utilisateurs</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßöüèø üë©üèΩ‚Äçü§ù‚Äçüë®üèæ ‚ö∞Ô∏è Le livre "Apache Kafka. Traitement des flux et analyse des donn√©es ¬ª ü¶â üöá üéûÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pendant le travail de toute application d'entreprise, des donn√©es sont g√©n√©r√©es: ce sont des fichiers journaux, des m√©triques, des informations sur l'...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le livre "Apache Kafka. Traitement des flux et analyse des donn√©es ¬ª</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/421519/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/t6/ej/tx/t6ejtxboknf_ha_u7radv1gzrls.jpeg" align="left" alt="image"></a>  Pendant le travail de toute application d'entreprise, des donn√©es sont g√©n√©r√©es: ce sont des fichiers journaux, des m√©triques, des informations sur l'activit√© des utilisateurs, des messages sortants, etc. Une manipulation correcte de toutes ces donn√©es n'est pas moins importante que les donn√©es elles-m√™mes.  Si vous √™tes un architecte, un d√©veloppeur ou un ing√©nieur dipl√¥m√© qui souhaite r√©soudre de tels probl√®mes, mais qui n'est pas encore familier avec Apache Kafka, alors, dans ce merveilleux livre, vous apprendrez √† travailler avec cette plate-forme de streaming gratuite qui vous permet de traiter les files d'attente de donn√©es en temps r√©el. <br><br><h3>  √Ä qui s'adresse ce livre? </h3><br>  ¬´Apache Kafka.  Stream processing and data analysis ¬ªa √©t√© √©crit pour les d√©veloppeurs qui utilisent l'API Kafka dans leur travail, ainsi que les ing√©nieurs de processus (√©galement appel√©s SRE, DevOps ou administrateurs syst√®me) qui sont impliqu√©s dans l'installation, la configuration, la configuration et la surveillance de son fonctionnement pendant l'exploitation industrielle.  Nous n'avons pas non plus oubli√© les architectes de donn√©es et les ing√©nieurs analytiques - ceux qui sont responsables de la conception et de la cr√©ation de l'ensemble de l'infrastructure de donn√©es de l'entreprise.  Certains chapitres, en particulier 3, 4 et 11, sont destin√©s aux d√©veloppeurs Java.  Pour les comprendre, il est important que le lecteur soit familiaris√© avec les bases du langage de programmation Java, y compris les probl√®mes tels que la gestion des exceptions et la concurrence. <br><a name="habracut"></a><br>  D'autres chapitres, en particulier 2, 8, 9 et 10, supposent que le lecteur a une exp√©rience avec Linux et est familier avec la configuration du r√©seau et du stockage Linux.  Le reste du livre et les architectures logicielles de Kafka sont discut√©s en termes plus g√©n√©raux, donc aucune connaissance particuli√®re n'est requise des lecteurs. <br><br>  Une autre cat√©gorie de personnes susceptibles d'√™tre int√©ress√©es par ce livre sont les gestionnaires et les architectes qui travaillent non pas directement avec Kafka, mais avec ceux qui y travaillent.  Il est tout aussi important qu‚Äôils comprennent quelles sont les garanties de la plate-forme et quels compromis leurs subordonn√©s et coll√®gues devront faire lors de la cr√©ation de syst√®mes bas√©s sur Kafka.  Ce livre sera utile aux gestionnaires qui souhaitent former leurs employ√©s √† travailler avec Kafka ou √† s'assurer que l'√©quipe de d√©veloppement poss√®de les informations n√©cessaires. <br><br><h3>  Chapitre 2. Installer Kafka </h3><br>  Apache Kafka est une application Java qui peut s'ex√©cuter sur de nombreux syst√®mes d'exploitation, y compris Windows, MacOS, Linux et autres. Dans ce chapitre, nous nous concentrerons sur l'installation de Kafka sur Linux, car c'est la plate-forme qui est le plus souvent install√©e sur ce syst√®me d'exploitation.  Linux est √©galement le syst√®me d'exploitation recommand√© pour le d√©ploiement Kafka √† usage g√©n√©ral.  Pour plus d'informations sur l'installation de Kafka sur Windows et MacOS, voir l'annexe A. <br><br>  <b>Installer Java</b> <br><br>  Avant d'installer ZooKeeper ou Kafka, vous devez installer et configurer l'environnement Java.  Il est recommand√© d'utiliser Java 8, et il peut s'agir d'une version, soit incluse dans votre syst√®me d'exploitation, soit t√©l√©charg√©e directement sur java.com.  Bien que ZooKeeper et Kafka fonctionnent avec Java Runtime Edition, il est plus pratique d'utiliser le kit de d√©veloppement Java (JDK) complet lors du d√©veloppement d'utilitaires et d'applications.  Ces √©tapes d'installation supposent que JDK version 8.0.51 est install√© dans le r√©pertoire /usr/java/jdk1.8.0_51. <br><br>  <b>Installez ZooKeeper</b> <br><br>  Apache Kafka utilise ZooKeeper pour stocker des m√©tadonn√©es sur le cluster Kafka, ainsi que des d√©tails sur les clients consommateurs (Fig. 2.1).  Bien que ZooKeeper puisse √©galement √™tre lanc√© √† l'aide de scripts inclus dans la distribution Kafka, l'installation de la version compl√®te du r√©f√©rentiel ZooKeeper √† partir de la distribution est tr√®s simple. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/a-/ye/ed/a-yeeda4ysojxtp4kcwlnmufwlc.png" alt="image"></div><br>  Kafka a √©t√© soigneusement test√© avec la version stable 3.4.6 du r√©f√©rentiel ZooKeeper, qui peut √™tre t√©l√©charg√©e depuis apache.org. <br><br>  <b>Serveur autonome</b> <br><br>  L'exemple suivant illustre l'installation de ZooKeeper avec les param√®tres de base dans le r√©pertoire / usr / local / zookeeper et l'enregistrement des donn√©es dans le r√©pertoire / var / lib / zookeeper: <br><br><pre><code class="hljs delphi"># tar -zxf zookeeper-<span class="hljs-number"><span class="hljs-number">3.4</span></span>.<span class="hljs-number"><span class="hljs-number">6</span></span>.tar.gz # mv zookeeper-<span class="hljs-number"><span class="hljs-number">3.4</span></span>.<span class="hljs-number"><span class="hljs-number">6</span></span> /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper # mkdir -p /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/zookeeper # cat &gt; /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/conf/zoo.cfg &lt;&lt; EOF &gt; tickTime=<span class="hljs-number"><span class="hljs-number">2000</span></span> &gt; dataDir=/<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/zookeeper &gt; clientPort=<span class="hljs-number"><span class="hljs-number">2181</span></span> &gt; EOF # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/zkServer.sh start JMX enabled by <span class="hljs-keyword"><span class="hljs-keyword">default</span></span> Using config: /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/../conf/zoo.cfg Starting zookeeper ... STARTED # <span class="hljs-keyword"><span class="hljs-keyword">export</span></span> JAVA_HOME=/usr/java/jdk1.<span class="hljs-number"><span class="hljs-number">8.0</span></span>_51 # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/zkServer.sh start JMX enabled by <span class="hljs-keyword"><span class="hljs-keyword">default</span></span> Using config: /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/../conf/zoo.cfg Starting zookeeper ... STARTED #</code> </pre> <br>  Vous pouvez maintenant v√©rifier que ZooKeeper est cens√© fonctionner hors ligne en se connectant au port client et en envoyant la commande srvr √† quatre lettres: <br><br><pre> <code class="hljs pgsql"># telnet localhost <span class="hljs-number"><span class="hljs-number">2181</span></span> Trying ::<span class="hljs-number"><span class="hljs-number">1.</span></span>.. Connected <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> localhost. <span class="hljs-keyword"><span class="hljs-keyword">Escape</span></span> <span class="hljs-type"><span class="hljs-type">character</span></span> <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-string"><span class="hljs-string">'^]'</span></span>. srvr Zookeeper <span class="hljs-keyword"><span class="hljs-keyword">version</span></span>: <span class="hljs-number"><span class="hljs-number">3.4</span></span><span class="hljs-number"><span class="hljs-number">.6</span></span><span class="hljs-number"><span class="hljs-number">-1569965</span></span>, built <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> <span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">20</span></span>/<span class="hljs-number"><span class="hljs-number">2014</span></span> <span class="hljs-number"><span class="hljs-number">09</span></span>:<span class="hljs-number"><span class="hljs-number">09</span></span> GMT Latency min/avg/max: <span class="hljs-number"><span class="hljs-number">0</span></span>/<span class="hljs-number"><span class="hljs-number">0</span></span>/<span class="hljs-number"><span class="hljs-number">0</span></span> Received: <span class="hljs-number"><span class="hljs-number">1</span></span> Sent: <span class="hljs-number"><span class="hljs-number">0</span></span> Connections: <span class="hljs-number"><span class="hljs-number">1</span></span> Outstanding: <span class="hljs-number"><span class="hljs-number">0</span></span> Zxid: <span class="hljs-number"><span class="hljs-number">0x0</span></span> Mode: standalone Node count: <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Connection</span></span> closed <span class="hljs-keyword"><span class="hljs-keyword">by</span></span> <span class="hljs-keyword"><span class="hljs-keyword">foreign</span></span> host. #</code> </pre> <br>  <b>ZooKeeper Ensemble</b> <br><br>  Le cluster ZooKeeper est appel√© un ensemble.  En raison de la nature de l'algorithme lui-m√™me, il est recommand√© que l'ensemble comprenne un nombre impair de serveurs, par exemple 3, 5, etc., car pour que ZooKeeper puisse r√©pondre aux demandes, la majorit√© des membres de l'ensemble doivent fonctionner (quorum).  Cela signifie qu'un ensemble de trois n≈ìuds peut fonctionner avec un n≈ìud inactif.  Si l'ensemble a trois n≈ìuds, il peut y en avoir deux. <br><br>  Pour configurer le fonctionnement des serveurs ZooKeeper dans l'ensemble, ils doivent avoir une configuration unique avec une liste de tous les serveurs, et chaque serveur du r√©pertoire de donn√©es doit avoir un fichier myid avec l'identifiant de ce serveur.  Si les h√¥tes de l'ensemble sont nomm√©s zoo1.example.com, zoo2.example.com et zoo3.example.com, le fichier de configuration peut ressembler √† ceci: <br><br><pre> <code class="hljs pgsql">tickTime=<span class="hljs-number"><span class="hljs-number">2000</span></span> dataDir=/var/lib/zookeeper clientPort=<span class="hljs-number"><span class="hljs-number">2181</span></span> initLimit=<span class="hljs-number"><span class="hljs-number">20</span></span> syncLimit=<span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-keyword"><span class="hljs-keyword">server</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>=zoo1.example.com:<span class="hljs-number"><span class="hljs-number">2888</span></span>:<span class="hljs-number"><span class="hljs-number">3888</span></span> <span class="hljs-keyword"><span class="hljs-keyword">server</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span>=zoo2.example.com:<span class="hljs-number"><span class="hljs-number">2888</span></span>:<span class="hljs-number"><span class="hljs-number">3888</span></span> <span class="hljs-keyword"><span class="hljs-keyword">server</span></span><span class="hljs-number"><span class="hljs-number">.3</span></span>=zoo3.example.com:<span class="hljs-number"><span class="hljs-number">2888</span></span>:<span class="hljs-number"><span class="hljs-number">3888</span></span></code> </pre> <br>  Dans cette configuration, initLimit est la dur√©e pendant laquelle les n≈ìuds esclaves peuvent se connecter au ma√Ætre.  La valeur syncLimit limite le d√©calage des n≈ìuds esclaves par rapport au ma√Ætre.  Les deux valeurs sont sp√©cifi√©es en unit√©s tickTime, c'est-√†-dire initLimit = 20 ¬∑ 2000 ms = 40 s.  La configuration r√©pertorie √©galement tous les serveurs d'ensemble.  Ils sont au format server.X = hostname: peerPort: leaderPort avec les param√®tres suivants: <br><br><ul><li>  X est l'identifiant du serveur.  Ce doit √™tre un entier, mais le compte peut ne pas √™tre de z√©ro et ne pas √™tre s√©quentiel; </li><li>  nom d'h√¥te - nom d'h√¥te ou adresse IP du serveur; </li><li>  peerPort - Port TCP par lequel les serveurs d'ensemble communiquent entre eux; </li><li>  leaderPort - Port TCP par lequel l'h√¥te est s√©lectionn√©. </li></ul><br>  Il suffit que les clients puissent se connecter √† l'ensemble via le port clientPort, mais les membres de l'ensemble doivent pouvoir √©changer des messages entre eux sur les trois ports. <br><br>  En plus d'un fichier de configuration unique, chaque serveur du r√©pertoire dataDir doit avoir un fichier myid.  Il doit contenir l'identifiant du serveur correspondant √† celui donn√© dans le fichier de configuration.  Apr√®s avoir termin√© ces √©tapes, vous pouvez d√©marrer les serveurs et ils interagiront les uns avec les autres dans l'ensemble. <br><br><h3>  Installation de Kafka Broker </h3><br>  Apr√®s avoir termin√© la configuration de Java et ZooKeeper, vous pouvez proc√©der √† l'installation d'Apache Kafka.  La derni√®re version d'Apache Kafka peut √™tre t√©l√©charg√©e sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">kafka.apache.org/downloads.html</a> . <br><br>  Dans l'exemple suivant, installez la plate-forme Kafka dans le r√©pertoire / usr / local / kafka, configurez-la pour utiliser le serveur ZooKeeper pr√©c√©demment lanc√© et enregistrez les segments du journal des messages dans le r√©pertoire / tmp / kafka-logs: <br><br><pre> <code class="hljs pgsql"># tar -zxf kafka_2<span class="hljs-number"><span class="hljs-number">.11</span></span><span class="hljs-number"><span class="hljs-number">-0.9</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>.tgz # mv kafka_2<span class="hljs-number"><span class="hljs-number">.11</span></span><span class="hljs-number"><span class="hljs-number">-0.9</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span> /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka # mkdir /tmp/kafka-logs # export JAVA_HOME=/usr/java/jdk1<span class="hljs-number"><span class="hljs-number">.8</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>_51 # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>-<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>.sh -daemon /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/config/<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>.properties #</code> </pre> <br>  Apr√®s avoir lanc√© le courtier Kafka, vous pouvez tester son fonctionnement en effectuant des op√©rations simples avec le cluster, notamment en cr√©ant une rubrique de test, en g√©n√©rant des messages et en les consommant. <br><br>  Cr√©ation et v√©rification de threads: <br><br><pre> <code class="hljs objectivec"><span class="hljs-meta"><span class="hljs-meta"># /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test Created topic </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"test"</span></span></span><span class="hljs-meta">. # /usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test Topic:test PartitionCount:1 ReplicationFactor:1 Configs: Topic: test Partition: 0 Leader: 0 Replicas: 0 Isr: 0 #</span></span></code> </pre> <br>  G√©n√©ration de messages pour le sujet de test: <br><br><pre> <code class="hljs delphi"># /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-console-producer.sh --broker-list localhost:<span class="hljs-number"><span class="hljs-number">9092</span></span> --topic test Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> ^D #</code> </pre> <br>  Consommation de messages du sujet de test: <br><br><pre> <code class="hljs delphi"># /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-console-consumer.sh --zookeeper localhost:<span class="hljs-number"><span class="hljs-number">2181</span></span> --topic test --from-beginning Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> ^C Consumed <span class="hljs-number"><span class="hljs-number">2</span></span> messages #</code> </pre> <br><h3>  Configuration du courtier </h3><br>  L'exemple de configuration de courtier fourni avec la distribution Kafka est tout √† fait appropri√© pour une version d'essai d'un serveur autonome, mais pour la plupart des installations, ce ne sera pas suffisant.  Il existe de nombreuses options de configuration de Kafka qui r√©gissent tous les aspects de l'installation et de la configuration.  Vous pouvez laisser les valeurs par d√©faut pour bon nombre d'entre elles, car elles se rapportent aux nuances de la configuration d'un courtier Kafka qui ne s'appliquent pas tant que vous ne travaillez pas avec un sc√©nario sp√©cifique n√©cessitant leur utilisation. <br><br><h3>  Param√®tres de base du courtier </h3><br>  Il existe plusieurs param√®tres du courtier Kafka que vous devez prendre en compte lors du d√©ploiement de la plate-forme dans n'importe quel environnement, √† l'exception d'un courtier autonome sur un serveur distinct.  Ces param√®tres se rapportent aux param√®tres principaux du courtier et la plupart d'entre eux doivent √™tre modifi√©s pour que le courtier puisse travailler en cluster avec d'autres courtiers. <br><br>  <b>broker.id</b> <br><br>  Chaque courtier Kafka doit avoir un identifiant entier sp√©cifi√© par le param√®tre broker.id.  Par d√©faut, cette valeur est 0, mais peut √™tre n'importe quel nombre.  L'essentiel est qu'il ne se r√©p√®te pas au sein du m√™me cluster Kafka.  Le choix du num√©ro peut √™tre arbitraire et, si n√©cessaire, pour la commodit√© de la maintenance, il peut √™tre transf√©r√© d'un courtier √† un autre.  Il est souhaitable que ce num√©ro soit en quelque sorte connect√© √† l'h√¥te, la correspondance des identifiants de courtier avec les h√¥tes avec suivi sera plus transparente.  Par exemple, si vos noms d'h√¥tes contiennent des nombres uniques (par exemple, host1.example.com, host2.example.com, etc.), ces nombres seraient un bon choix pour les valeurs broker.id. <br><br>  <b>port</b> <br><br>  Un fichier de configuration typique d√©marre Kafka avec un √©couteur sur le port TCP 9092. Ce port peut √™tre chang√© en tout autre disponible en changeant le port du param√®tre de configuration.  Gardez √† l'esprit que lorsque vous choisissez un port avec un nombre inf√©rieur √† 1024, Kafka doit √™tre ex√©cut√© en tant que root.  Il n'est pas recommand√© d'ex√©cuter Kafka en tant que root. <br><br>  <b>zookeeper.connect</b> <br><br>  Le chemin utilis√© par ZooKeeper pour stocker les m√©tadonn√©es du courtier est d√©fini √† l'aide du param√®tre de configuration zookeeper.connect.  Dans l'exemple de configuration, ZooKeeper s'ex√©cute sur le port 2181 sur l'h√¥te local, qui est indiqu√© comme localhost: 2181.  Le format de ce param√®tre est une liste de lignes s√©par√©es par un point-virgule de la forme nom d'h√¥te: port / chemin, y compris: <br><br><ul><li>  nom d'h√¥te - nom d'h√¥te ou adresse IP du serveur ZooKeeper; </li><li>  port - num√©ro de port client pour le serveur; </li><li>  / path - un chemin ZooKeeper facultatif utilis√© comme nouveau chemin racine (chroot) du cluster Kafka.  S'il n'est pas sp√©cifi√©, le chemin racine est utilis√©. </li></ul><br>  Si le chemin de chroot sp√©cifi√© n'existe pas, il sera cr√©√© au d√©marrage du courtier. <br><br>  <b>log.dirs</b> <br><br>  Kafka enregistre tous les messages sur le disque dur et ces segments du journal sont stock√©s dans les r√©pertoires sp√©cifi√©s dans le param√®tre log.dirs.  Il s'agit d'une liste de chemins s√©par√©s par des virgules dans le syst√®me local.  Si plusieurs chemins sont sp√©cifi√©s, le courtier y enregistrera des sections selon le principe du moins utilis√©, avec conservation des segments de journal d'une section le long d'un chemin.  Notez que le courtier placera la nouvelle section dans le r√©pertoire dans lequel au moins les partitions sont actuellement stock√©es, et non le moindre espace est utilis√©, de sorte que la distribution uniforme des donn√©es entre les sections n'est pas garantie. <br><br>  <b>num.recovery.threads.per.data.dir</b> <br><br>  Kafka utilise un pool de threads personnalis√© pour traiter les segments de journal.  Actuellement, il est appliqu√©: <br><br><ul><li>  pendant le d√©marrage normal - pour ouvrir les segments de journal de chaque section; </li><li>  commencer apr√®s un √©chec - pour v√©rifier et tronquer les segments de journal de chaque section; </li><li>  Stop - pour fermer doucement les segments de journal. </li></ul><br>  Par d√©faut, un seul thread est utilis√© par r√©pertoire de journaux.  √âtant donn√© que cela ne se produit qu'au d√©marrage et √† l'arr√™t, il est logique d'en utiliser davantage afin de parall√©liser les op√©rations.  Lors de la r√©cup√©ration d'un arr√™t incorrect, les avantages de l'utilisation de cette approche peuvent atteindre plusieurs heures si le courtier avec un grand nombre de partitions est red√©marr√©!  N'oubliez pas que la valeur de ce param√®tre est d√©termin√©e en fonction d'un r√©pertoire de journaux √† partir du num√©ro sp√©cifi√© √† l'aide de log.dirs.  En d'autres termes, si la valeur du param√®tre num.recovery.threads.per.data.dir est 8 et que trois chemins d'acc√®s sont sp√©cifi√©s dans log.dirs, le nombre total de threads est de 24. <br><br>  <b>auto.create.topics.enable</b> <br><br>  Selon la configuration par d√©faut de Kafka, le courtier doit cr√©er automatiquement un th√®me lorsque: <br><br><ul><li>  le fabricant commence √† √©crire dans la ligne d'objet; </li><li>  le consommateur commence √† lire le sujet du message; </li><li>  tout client demande des m√©tadonn√©es de rubrique. </li></ul><br>  Dans de nombreux cas, ce comportement peut √™tre ind√©sirable, notamment en raison du fait qu'il n'y a aucun moyen de v√©rifier l'existence d'un sujet √† l'aide du protocole Kafka sans provoquer sa cr√©ation.  Si vous contr√¥lez la cr√©ation de cela explicitement, manuellement ou via le syst√®me d'initialisation, vous pouvez d√©finir le param√®tre auto.create.topics.enable sur false. <br><br><h3>  Param√®tres de th√®me par d√©faut </h3><br>  La configuration du serveur Kafka d√©finit de nombreux param√®tres par d√©faut pour les th√®mes cr√©√©s.  Certains de ces param√®tres, notamment le nombre de sections et les param√®tres d'enregistrement des messages, peuvent √™tre d√©finis s√©par√©ment pour chaque rubrique √† l'aide des outils d'administration (abord√©s au chapitre 9).  Les valeurs par d√©faut dans la configuration du serveur doivent √™tre d√©finies √©gales aux valeurs de r√©f√©rence qui conviennent √† la plupart des rubriques de cluster. <br><br>  <b>num.partitions</b> <br><br>  Le param√®tre num.partitions d√©termine avec combien de sections un nouveau sujet est cr√©√©, principalement lorsque la cr√©ation automatique par th√®mes est activ√©e (ce qui est le comportement par d√©faut).  La valeur par d√©faut de ce param√®tre est 1. Gardez √† l'esprit que le nombre de sections pour un sujet ne peut √™tre augment√©, mais pas r√©duit.  Cela signifie que s'il n√©cessite moins de partitions que ce qui est indiqu√© dans num.partitions, vous devrez le cr√©er soigneusement manuellement (cela est expliqu√© au chapitre 9). <br><br>  Comme indiqu√© au chapitre 1, les sections sont un moyen de mettre √† l'√©chelle des sujets dans un cluster Kafka, il est donc important que vous en ayez autant que n√©cessaire pour √©quilibrer la charge des messages sur l'ensemble du cluster √† mesure que des courtiers sont ajout√©s.  De nombreux utilisateurs pr√©f√®rent que le nombre de partitions soit √©gal ou le nombre de courtiers dans le cluster.  Cela permet de r√©partir uniform√©ment les sections entre les courtiers, ce qui conduira √† une r√©partition uniforme de la charge entre les messages.  Cependant, ce n'est pas une exigence obligatoire, car la pr√©sence de plusieurs rubriques vous permet d'√©quilibrer la charge. <br><br>  <b>log.retention.ms</b> <br><br>  Le plus souvent, le stockage des messages √† Kafka est limit√© dans le temps.  La valeur par d√©faut est sp√©cifi√©e dans le fichier de configuration √† l'aide du param√®tre log.retention.hours et est √©gale √† 168 heures ou 1 semaine.  Cependant, vous pouvez utiliser deux autres param√®tres - log.retention.minutes et log.retention.ms.  Ces trois param√®tres d√©terminent la m√™me chose - la p√©riode de temps apr√®s laquelle les messages sont supprim√©s.  Mais il est recommand√© d'utiliser le param√®tre log.retention.ms, car si plusieurs param√®tres sont sp√©cifi√©s, la priorit√© appartient √† la plus petite unit√© de mesure, donc la valeur de log.retention.ms sera toujours utilis√©e. <br><br>  <b>log.retention.bytes</b> <br><br>  Une autre fa√ßon de limiter la validit√© des messages est bas√©e sur la taille totale (en octets) des messages stock√©s.  La valeur est d√©finie √† l'aide du param√®tre log.retention.bytes et est appliqu√©e s√©par√©ment.  Cela signifie que dans le cas d'un sujet de huit sections et √©gal √† 1 Go de la valeur de log.retention.bytes, la quantit√© maximale de donn√©es stock√©es pour ce sujet sera de 8 Go.  Notez que la quantit√© de stockage d√©pend des sections individuelles et non du sujet.  Cela signifie que si le nombre de sections de la rubrique augmente, la quantit√© maximale de donn√©es enregistr√©es lors de l'utilisation de log.retention.bytes augmentera √©galement. <br><br>  <b>log.segment.bytes</b> <br><br>  Les param√®tres de journalisation mentionn√©s concernent des segments de journal et non des messages individuels.  Au fur et √† mesure que les messages sont g√©n√©r√©s par le courtier Kafka, ils sont ajout√©s √† la fin du segment de journal actuel de la section correspondante.  Lorsque le segment de journal atteint la taille sp√©cifi√©e par le param√®tre log.segment.bytes et est √©gal √† 1 Go par d√©faut, ce segment se ferme et un nouveau s'ouvre.  Apr√®s la fermeture, le segment de journal peut √™tre retir√©.  Plus la taille des segments de journal est petite, plus vous devez souvent fermer des fichiers et en cr√©er de nouveaux, ce qui r√©duit l'efficacit√© globale des √©critures sur disque. <br><br>  Le dimensionnement des segments de journal est important lorsque les sujets sont caract√©ris√©s par une faible fr√©quence de g√©n√©ration de messages.  Par exemple, si une rubrique ne re√ßoit que 100 Mo de messages par jour et que le param√®tre log.segment.bytes est d√©fini sur la valeur par d√©faut, il faut 10 jours pour remplir un segment.  Et comme les messages ne peuvent pas √™tre d√©clar√©s invalides tant que le segment de journal n'est pas ferm√©, alors avec la valeur de 604,8 millions (1 semaine) du param√®tre log.retention.ms, les messages peuvent s'accumuler en 17 jours avant que le segment de journal ferm√© ne soit retir√© de la circulation.  En effet, lorsque vous fermez un segment avec des messages qui se sont accumul√©s sur 10 jours, vous devez le stocker pendant 7 jours suppl√©mentaires avant de pouvoir le retirer conform√©ment aux r√®gles temporaires adopt√©es, car le segment ne peut pas √™tre supprim√© avant l'expiration du dernier message qu'il contient. . <br><br>  <b>log.segment.ms</b> <br><br>  Une autre fa√ßon de contr√¥ler la fermeture des segments de journal consiste √† utiliser le param√®tre log.segment.ms, qui sp√©cifie la dur√©e apr√®s laquelle le segment de journal est ferm√©.  Comme les param√®tres log.retention.bytes et log.retention.ms, les param√®tres log.segment.bytes et log.segment.ms ne s'excluent pas mutuellement.  Kafka ferme le segment de journal lorsque le temps est √©coul√© ou que la taille limite sp√©cifi√©e est atteinte, selon lequel de ces √©v√©nements se produit en premier.  Par d√©faut, la valeur du param√®tre log.segment.ms n'est pas d√©finie, de sorte que la fermeture des segments de journal est d√©termin√©e par leur taille. <br><br>  <b>message.max.bytes</b> <br><br>  Le courtier Kafka permet d'utiliser le param√®tre message.max.bytes pour limiter la taille maximale des messages g√©n√©r√©s.  La valeur par d√©faut de ce param√®tre est 1 000 000 (1 Mo).  Un fabricant qui essaie d'envoyer un message plus volumineux recevra une notification d'erreur du courtier, mais le message ne sera pas accept√©.  Comme dans le cas de toutes les autres tailles en octets sp√©cifi√©es dans les param√®tres du courtier, nous parlons de la taille du message compress√©, afin que les fabricants puissent envoyer des messages, dont la taille non compress√©e est beaucoup plus grande s'ils peuvent √™tre compress√©s dans les limites sp√©cifi√©es par message.max.bytes . <br><br>  L'augmentation de la taille du message peut s√©rieusement affecter les performances.  Une taille de message plus importante signifie que les threads de courtier qui traitent les connexions et les demandes r√©seau prendront plus de temps pour chaque demande.  Les messages plus volumineux augmentent √©galement la quantit√© de donn√©es √©crites sur le disque, ce qui affecte le d√©bit d'E / S. <br><br><h3>  S√©lection du mat√©riel </h3><br>  Choisir le bon mat√©riel pour le courtier Kafka est plus un art qu'une science.  La plate-forme Kafka elle-m√™me n'a pas d'exigences mat√©rielles strictes; elle fonctionnera sans probl√®me sur n'importe quel syst√®me.  Mais si nous parlons de performances, elles sont influenc√©es par plusieurs facteurs: capacit√© et d√©bit des disques, RAM, r√©seau et CPU. <br><br>  Vous devez d'abord d√©cider quels types de performances sont les plus importants pour votre syst√®me, apr√®s quoi vous pouvez choisir la configuration mat√©rielle optimale qui correspond au budget. <br><br><h3>  D√©bit du disque </h3><br>  Le d√©bit des disques du courtier, qui sont utilis√©s pour stocker des segments de journal, affecte directement les performances des clients de fabrication.  Les messages Kafka doivent √™tre enregistr√©s dans un stockage local qui confirme leur enregistrement.  Ce n'est qu'alors que l'op√©ration d'envoi peut √™tre consid√©r√©e comme r√©ussie.  Cela signifie que plus les op√©rations d'√©criture sur le disque sont rapides, moins le d√©lai de g√©n√©ration des messages sera long. <br><br>  L'action √©vidente en cas de probl√®mes avec la bande passante des disques est d'utiliser des disques durs avec des plaques tournantes (HDD) ou des disques SSD.  Les SSD ont des temps de recherche / d'acc√®s inf√©rieurs et des performances sup√©rieures.  Les disques durs sont plus √©conomiques et ont une capacit√© relative plus √©lev√©e.  Les performances des disques durs peuvent √™tre am√©lior√©es en raison de leur plus grand nombre dans le courtier, ou en utilisant plusieurs r√©pertoires de donn√©es, ou en installant des disques dans une matrice de disques ind√©pendants avec redondance (matrice redondante de disques ind√©pendants, RAID).  D'autres facteurs influencent le d√©bit, par exemple, la technologie de fabrication d'un disque dur (par exemple, SAS ou SATA), ainsi que les caract√©ristiques du contr√¥leur de disque dur. <br><br><h3>  Capacit√© disque </h3><br>  La capacit√© est un autre aspect du stockage.  La quantit√© d'espace disque requise est d√©termin√©e par le nombre de messages qui doivent √™tre stock√©s en m√™me temps.  Si le courtier doit recevoir 1 To de trafic par jour, alors avec un stockage de 7 jours, il aura besoin d'un stockage disponible pour des segments de journal d'au moins 7 To.  Vous devez √©galement envisager un d√©passement d'au moins 10% pour les autres fichiers, sans compter la m√©moire tampon pour les √©ventuelles fluctuations du trafic ou sa croissance dans le temps. <br><br>  La capacit√© de stockage est l'un des facteurs √† prendre en compte pour d√©terminer la taille optimale du cluster Kafka et d√©cider de son expansion.  Le trafic total du cluster peut √™tre √©quilibr√© par plusieurs sections pour chaque rubrique, ce qui vous permet d'utiliser des courtiers suppl√©mentaires pour augmenter la capacit√© disponible dans les cas o√π la densit√© de donn√©es par courtier n'est pas suffisante.  La d√©cision sur la quantit√© d'espace disque n√©cessaire est √©galement d√©termin√©e par la strat√©gie de r√©plication s√©lectionn√©e pour le cluster (discut√©e plus en d√©tail au chapitre 6). <br><br><h3>  La m√©moire </h3><br>  Dans le mode de fonctionnement normal, le consommateur Kafka lit √† partir de la fin de la section, et le consommateur rattrape constamment le temps perdu et seulement l√©g√®rement derri√®re les fabricants, voire pas du tout.            ,      ,         . ,         ,    -. <br><br>   Kafka     JVM      .  ,   X        X   ,      5 .             Kafka        .      Kafka  ,      ,       ,     Kafka. <br><br><h3>     </h3><br>   ,    Kafka,     .    (    )    .     Kafka (   )       .    1       ,       ,      .       ,     (.  6)    (   8).          ,     . <br><br><h3>  CPU </h3><br>     ,      ,           .             .  Kafka, ,              .            .    Kafka  '   .            . <br><br><h3> Kafka    </h3><br> Kafka      , , Amazon Web Services (AWS). AWS     ,     CPU,     .              Kafka.       ,      .                /      SSD.         (, AWS Elastic Block Store).            CPU   . <br>    ,     AWS      m4  r3.    m4    ,        ,      .      r3      SSD-,        .            i2  d2. <br><br><h3>  Kafka </h3><br>   Kafka         ,             (. 2.2).     ‚Äî      .    ‚Äî            .         Kafka        .         Kafka.           6. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vo/c-/cc/voc-cc5ywmwoh4ttiidnzt1gdk4.png" alt="image"></div><br><br><h3>    ? </h3><br>   Kafka   .    ‚Äî              .     10  ,      2 ,     ‚Äî  .  ,          100 % (    ) (.  6).  ,              . <br><br>   ,   , ‚Äî     . ,                        (         ).        80 %   ,    ,             .     ,      ,   .        ,     ,          . <br><br><h3>   </h3><br>               Kafka.  ‚Äî          zookeeper.connect.    ZooKeeper     .  ‚Äî           broker.id.       broker.id    ,            .      ,    ,      ,    . <br><br><h3>     </h3><br>     Linux      ,       ,           Kafka.          ,    ,        .       /etc/sysctl.conf,        Linux,       . <br><br><h3>   </h3><br>     Linux     .           ,    ¬´¬ª  ,        Kafka. <br>     ,  ,    ,    ()  . ,      ,       Kafka.  , Kafka     ,         ,       . <br><br>      ‚Äî        .  ‚Äî   ,      -   .            .      vm.swappiness  ,  1.      ( ) ,            .     ,   . <br><br>  ,      ¬´¬ª ,      ,   .   Kafka       /.         :        (, SSD),       NVRAM   (, RAID).       ¬´¬ª ,         .       vm.dirty_background_ratio ,     ( 10).       ( ),         5.       0,                           . <br><br>   ¬´¬ª ,               ,      vm.dirty_ratio  ,     ‚Äî 20 (        ).       ,      60  80.               ,       /       .       vm.dirty_ratio       Kafka,     . <br><br>          ¬´¬ª      Kafka        .        /proc/vmstat: <br><br><pre> <code class="hljs objectivec"><span class="hljs-meta"><span class="hljs-meta"># cat /proc/vmstat | egrep </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"dirty|writeback"</span></span></span><span class="hljs-meta"> nr_dirty 3875 nr_writeback 29 nr_writeback_temp 0 #</span></span></code> </pre> <br><h3>  Conduire </h3><br>         ,    RAID-    ,           .     ,        EXT4 (fourth extended file system ‚Äî    )  XFS (Extents File System ‚Äî     ). EXT4   ,       .       ,     (5),       .  EXT4     ,            .    XFS     ,   ,   EXT4.  XFS    Kafka  ,        ,    .         ,       /. <br><br>     ,        ,     noatime.      /:   (ctime),    (mtime)       (atime).     atime     .        .  atime    ,   ,      ,         (      realtime). Kafka     atime,      .   noatime       /,        ctime  mtime. <br><br><h3>     </h3><br>       Linux ‚Äî     ,    ,             .     Kafka     ,    -    .     (   ) ,         .          .              net.core.wmem_default  net.core.rmem_default ,      2 097 152 (2 ).   ,           ,       . <br><br>              TCP    net.ipv4.tcp_wmem  net.ipv4.tcp_rmem.        ,   ,       .    ‚Äî 4096 65536 2048000 ‚Äî ,     4 ,    ‚Äî 64 ,   ‚Äî 2 .      ,      net.core.wmem_max  net.core.rmem_max.        Kafka           . <br><br>      .     TCP    1  net.ipv4.tcp_window_scaling,               .   net.ipv4.tcp_max_syn_backlog ,     1024,     .   net.core.netdev_max_backlog,     1000,       ,       ,    ,       . <br><br><h3>   </h3><br>      Kafka      ,             . <br><br><h3>    </h3><br>     Java      ,           ,   .  ,     Java 7     Garbage First (G1). G1                    .         ,       ,           . <br><br>         G1   .       . <br><br><ul><li> MaxGCPauseMillis.         .     ‚Äî   G1    .      200 .  ,  G1       ,    ,    , ,      200 . </li><li> InitiatingHeapOccupancyPercent.        ,       .     45.  ,  G1       ,    45 % ,       (Eden),    . </li></ul><br>  Kafka         ,         .               64   ,  Kafka     5 .       20  MaxGCPauseMillis.    InitiatingHeapOccupancyPercent   35,       ,     . <br><br>   Kafka       G1,            .       .       : <br><br><pre> <code class="hljs pgsql"># export JAVA_HOME=/usr/java/jdk1<span class="hljs-number"><span class="hljs-number">.8</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>_51 # export KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=true" # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>-<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>.sh -daemon /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/config/<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>.properties #</code> </pre> <br><h3>   </h3><br>          Kafka      ,                 .             -    ,     .         Kafka (.  6),         .        Kafka,       . <br><br>  Kafka             ,  ,                     (    , , AWS),           ,            .          .  ,   ¬´¬ª             (.    6). <br><br>  :    Kafka      ,   ,       ,     .             (     )                   .               , ,     . <br><br><h3>    ZooKeeper </h3><br> Kafka  ZooKeeper     ,   .   ZooKeeper              Kafka.     ,      ZooKeeper    Kafka  .      ZooKeeper      Kafka (     ZooKeeper   ,      ). <br><br>      ZooKeeper     .        ZooKeeper,  Kafka,      .    ZooKeeper  ,        ZooKeeper        .       ‚Äî 1 ,               .        ZooKeeper,      ,     .   ZooKeeper      ,     .  ,      Kafka   Kafka        ZooKeeper. <br><br>         Kafka,       ,    . Kafka         ZooKeeper,          .              ZooKeeper,     .        ,            , ,     .    ,            ,   . <br><br><h3>  R√©sum√© </h3><br>       ,     Apache Kafka. ,       ,         . ,   Kafka,         Kafka.             Kafka ( 3),       ( 4). <br><br>  ¬ªPlus d'informations sur le livre sont disponibles sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le site Web de l'√©diteur</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Contenu</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Extrait</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><br></a> <br>    20%   ‚Äî <b>Apache Kafka</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr421519/">https://habr.com/ru/post/fr421519/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr421501/index.html">Hacker a trouv√© un moyen de suivre les visiteurs des sites concurrents</a></li>
<li><a href="../fr421503/index.html">Comment r√©diger des instructions pour √™tre compris</a></li>
<li><a href="../fr421505/index.html">Mini hacks de vie pour travailler avec Yandex.Direct</a></li>
<li><a href="../fr421507/index.html">Quels √©taient les soudeurs pour l'optique</a></li>
<li><a href="../fr421513/index.html">Introduction en douceur de la m√™l√©e par les d√©veloppeurs eux-m√™mes (nous r√©solvons les contradictions, mettons en place l'√©quipe, √©vitons les conflits)</a></li>
<li><a href="../fr421521/index.html">Monstres apr√®s les vacances: AMD Threadripper 2990WX 32-Core et 2950X 16-Core (partie 3 - tests)</a></li>
<li><a href="../fr421523/index.html">Unity: apprendre √† conna√Ætre les objets scriptables</a></li>
<li><a href="../fr421525/index.html">Un peu sur les diff√©rences entre les h√©bergeurs russes et √©trangers</a></li>
<li><a href="../fr421527/index.html">Lancement de la diffusion du projet "Serveur dans les nuages"</a></li>
<li><a href="../fr421529/index.html">Netflix, Uber, Google et vous au MBLT DEV 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤘🏿 📵 👷 使用变分优化的神经网络简化 🦒 🕳️ 🚺</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="哈Ha 今天，我想提出变分优化的主题，并介绍如何将其应用于修剪神经网络中非信息通道的任务（修剪）。 使用它，可以相对轻松地提高神经网络的“发射率”，而无需改动其体系结构。 


 减少机器学习算法中冗余元素的想法并不是什么新鲜事。 实际上，它早于深度学习的概念：决定性树的树枝被切割，现在在神经网络中...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>使用变分优化的神经网络简化</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/413939/"> 哈Ha 今天，我想提出<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">变分优化</a>的主题，并介绍如何将其应用于修剪神经网络中非信息通道的任务（修剪）。 使用它，可以相对轻松地提高神经网络的“发射率”，而无需改动其体系结构。 <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ie/h7/hk/ieh7hkwe2y3kclwhb1l148ag_sa.jpeg"></div><br><a name="habracut"></a><br> 减少机器学习算法中冗余元素的想法并不是什么新鲜事。 实际上，它早于深度学习的概念：决定性树的树枝被切割，现在在神经网络中权重才更早。 <br><br> 基本思想很简单：我们在网络中找到无用权重的子集并将其归零。 没有详尽的搜索，很难说出哪些权重真正参与了预测，哪些权重只是假装的，但这不是必需的。 各种正则化方法，最佳脑损伤和其他算法都可以正常工作。 为什么要去掉所有的砝码？ 事实证明，这提高了网络的泛化能力：通常，不重要的权重要么只是将噪声引入预测中，要么针对训练数据集的迹象（即再训练的伪像）进行了专门的锐化。 从这个意义上讲，可以将连接的减少与网络训练期间断开随机神经元（丢失）的方法进行比较。 此外，如果网络有很多零，它将占用档案中较少的空间，并且在某些体系结构上能够更快地读取。 <br><br> 听起来不错，但更有趣的是，不丢掉单独的权重，而是丢掉完全连接的层或通道中的神经元。 在这种情况下，可以更清楚地观察到网络压缩和预测加速的效果。 但这比破坏单个体重更复杂：如果尝试进行“最佳脑部伤害”，而不是一个连接，而是整个捆绑，结果可能不会很令人印象深刻。 为了能够无痛地移除神经元，有必要将其制作成没有任何有用的连接。 为此，您需要以某种方式诱导“强”神经元变强，而“弱”神经元变弱。 这项任务已经为我们所熟悉：实际上，我们迫使网络变得稀疏，并对权重分组施加一些限制。 <br><img src="https://habrastorage.org/webt/ca/-a/6i/ca-a6irrotqnolbkudgrwbs9-b8.png"><br> 请注意，要删除一个神经元或卷积通道，您需要修改两个权重矩阵。 我不会区分卷积通道和神经元：它们的作用是相同的，只是去除的特定权重和移位方法不同。 <br><br><h3> 简单方法：组L1正则化 </h3><br> 首先，我将向您介绍从网络中删除多余神经元的最简单有效的方法-组LASSO-regularization。 通常，它用于使网络中无用的权重保持接近零。 它简单地归纳为逐个案例的情况。 与常规正则化不同，我们不直接对权重或图层激活进行正则化，这个想法有些棘手。  [通道修剪，用于加速非常深的神经网络； 何益辉等；  2017] <br><img src="https://habrastorage.org/webt/sv/ch/ye/svchyedbpgcgy5pqef0w2e6kc9e.png"><br> 考虑具有权重向量的特殊蒙版层 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2">M</span><span class="MJXp-mo" id="MJXp-Span-3" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mrow" id="MJXp-Span-4"><span class="MJXp-mo" id="MJXp-Span-5" style="margin-left: 0.278em; margin-right: 0.278em;">（</span></span><span class="MJXp-mtext" id="MJXp-Span-6">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-7">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-8">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-9">t</span><span class="MJXp-msubsup" id="MJXp-Span-10"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-11" style="margin-right: 0.05em;">a</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-12" style="vertical-align: -0.4em;">1</span></span><span class="MJXp-mrow" id="MJXp-Span-13"><span class="MJXp-mo" id="MJXp-Span-14" style="margin-left: 0.278em; margin-right: 0.278em;">，</span></span><span class="MJXp-mtext" id="MJXp-Span-15">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-16">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-17">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-18">t</span><span class="MJXp-msubsup" id="MJXp-Span-19"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-20" style="margin-right: 0.05em;">a</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-21" style="vertical-align: -0.4em;">2</span></span><span class="MJXp-mrow" id="MJXp-Span-22"><span class="MJXp-mo" id="MJXp-Span-23" style="margin-left: 0.278em; margin-right: 0.278em;">，</span></span><span class="MJXp-mtext" id="MJXp-Span-24" style="color: red;">\点</span><span class="MJXp-mrow" id="MJXp-Span-25"><span class="MJXp-mo" id="MJXp-Span-26" style="margin-left: 0.278em; margin-right: 0.278em;">，</span></span><span class="MJXp-mtext" id="MJXp-Span-27">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-28">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-29">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-30">t</span><span class="MJXp-msubsup" id="MJXp-Span-31"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-32" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-33" style="vertical-align: -0.4em;">n</span></span><span class="MJXp-mrow" id="MJXp-Span-34"><span class="MJXp-mo" id="MJXp-Span-35" style="margin-left: 0.278em; margin-right: 0.278em;">）</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="35.79ex" height="2.66ex" viewBox="0 -832 15409.4 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-4D" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMAIN-3D" x="1329" y="0"></use><g transform="translate(2385,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">（</text></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-62" x="3465" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-65" x="3895" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-74" x="4361" y="0"></use><g transform="translate(4723,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMAIN-31" x="748" y="-213"></use></g><g transform="translate(5706,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">，</text></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-62" x="6786" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-65" x="7215" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-74" x="7682" y="0"></use><g transform="translate(8043,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMAIN-32" x="748" y="-213"></use></g><g transform="translate(9027,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">，</text></g><g fill="red" stroke="red" transform="translate(9857,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMAIN-5C"></use><g transform="translate(500,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">点</text></g></g><g transform="translate(11187,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">，</text></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-62" x="12267" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-65" x="12697" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-74" x="13163" y="0"></use><g transform="translate(13525,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-6E" x="748" y="-213"></use></g><g transform="translate(14579,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">）</text></g></g></svg></span><script type="math/tex" id="MathJax-Element-1"> M =（\ beta_1，\ beta_2，\点，\ beta_n）</script>  。 他的结论只是零散的工作 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-36"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-37">M</span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.442ex" height="2.057ex" viewBox="0 -780.1 1051.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-4D" x="0" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-2"> M </script> 根据上一层的结论，他没有激活功能。 我们将掩膜层放置在每一层之后的通道中，将要丢弃的通道放置在这些层中，并对这些层中的权重进行L1正则化。 因此，面膜的重量 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-38"><span class="MJXp-mtext" id="MJXp-Span-39">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-40">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-41">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-42">t</span><span class="MJXp-msubsup" id="MJXp-Span-43"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-44" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-45" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.531ex" height="2.419ex" viewBox="0 -780.1 2381.3 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-65" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-74" x="1146" y="0"></use><g transform="translate(1507,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-69" x="748" y="-213"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-3"> \ beta_i </script> 乘以该层的第i个输出就暗含了对该结论所依赖的所有权重的限制。 如果在这些权重中，说一半有用，则 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-46"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-47">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-49">t</span><span class="MJXp-msubsup" id="MJXp-Span-50"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-51" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-52" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.95ex" height="2.419ex" viewBox="0 -780.1 2131.3 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-62" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-65" x="429" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-74" x="896" y="0"></use><g transform="translate(1257,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-69" x="748" y="-213"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-4"> beta_i </script> 将保持更接近统一，这个结论将能够很好地传递信息。 但是，如果只有一个或根本没有， <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-53"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-54">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-55">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-56">t</span><span class="MJXp-msubsup" id="MJXp-Span-57"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-58" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-59" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.95ex" height="2.419ex" viewBox="0 -780.1 2131.3 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-62" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-65" x="429" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-74" x="896" y="0"></use><g transform="translate(1257,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-69" x="748" y="-213"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-5"> beta_i </script> 它会降为零，这将重置神经元的输出，并且实际上将重置此结论所依赖的所有权重（在激活函数等于零时为零的情况下）。 请注意，以这种方式，如果合法的权重较大或法律上的强烈回应，则该网络所受到的负面强化就会减少。 整个神经元的有用性至关重要。 <br><br> 原来这个公式： <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ox/on/fi/oxonfibtmtq9lye1otygkyxcw-4.png"></div><br> 哪里 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-60"><span class="MJXp-mtext" id="MJXp-Span-61">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-62">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-63">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-64">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-65">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-66">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-67">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.987ex" height="2.057ex" viewBox="0 -780.1 3439 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-6C" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-61" x="548" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-6D" x="1078" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-62" x="1956" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-64" x="2386" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-61" x="2909" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-6"> \ lambda </script>  -损失'网络和稀疏'的加权常数。 看起来像通常的L1正则化公式，只有第二项包含掩蔽层的向量，而不包含网络的权重。 <br><br> 经过网络训练后，我们遍历了神经元及其掩盖值。 如果 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-68"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-69">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-70">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-71">t</span><span class="MJXp-msubsup" id="MJXp-Span-72"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-73" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-74" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.95ex" height="2.419ex" viewBox="0 -780.1 2131.3 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-62" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-65" x="429" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-74" x="896" y="0"></use><g transform="translate(1257,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-69" x="748" y="-213"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-7"> beta_i </script> 超过某个阈值，然后将神经元权重乘以 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-75"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-76">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-77">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-78">t</span><span class="MJXp-msubsup" id="MJXp-Span-79"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-81" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.95ex" height="2.419ex" viewBox="0 -780.1 2131.3 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-62" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-65" x="429" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-74" x="896" y="0"></use><g transform="translate(1257,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-69" x="748" y="-213"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-8"> beta_i </script> 如果更少，则从传入和传出权重的矩阵中删除与神经元相对应的元素（如图中稍高一些）。 此后，可以删除掩码并完成网络。 <br><br> 在组LASSO的应用中，有一些微妙之处： <br><ol><li> 正常正则化。 连同掩码权重的正则化，L1 / L2正则化应应用于所有其他网络权重。 如果不这样做，在不饱和激活函数（ReLu，ELu）的情况下，掩盖重量的减少将很容易通过增加重量来补偿，并且无效效果将不起作用。 是的，对于普通的乙状结肠，这可以使您以积极的反馈更好地开始这一过程： <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-82"><span class="MJXp-msubsup" id="MJXp-Span-83"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-84" style="margin-right: 0.05em;">M</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-85" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.054ex" height="2.419ex" viewBox="0 -780.1 1314.8 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-4D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/413939/&amp;usg=ALkJrhh6qGU2VUsluQqQEAGr_NOnHoCsyg#MJMATHI-69" x="1372" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-9"> M_i </script> 无关紧要的输出变小，这就是为什么优化器必须更认真地考虑每个特定权重的原因，这会使输出变得更无用的信息，这就是为什么 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-86"><span class="MJXp-msubsup" id="MJXp-Span-87"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-88" style="margin-right: 0.05em;">M</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-89" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-10"> M_i </script> 减少更多，依此类推。 </li><li> 文章的作者还建议对层的重量施加球形限制 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-90"><span class="MJXp-mrow" id="MJXp-Span-91"><span class="MJXp-mo" id="MJXp-Span-92" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-msubsup" id="MJXp-Span-93"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-94" style="margin-right: 0.05em;">W</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-95" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-msubsup" id="MJXp-Span-96"><span class="MJXp-mrow" id="MJXp-Span-97" style="margin-right: 0.05em;"><span class="MJXp-mo" id="MJXp-Span-98" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mn MJXp-script" id="MJXp-Span-99" style="vertical-align: -0.4em;">2</span></span><span class="MJXp-mo" id="MJXp-Span-100" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-101">1</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-11-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-11"> | W_i | _2 = 1 </script>  。 这可能应该有助于从弱神经元到强神经元的平衡“流动”，但是我没有注意到有太大的区别。 </li><li> 推拉训练。 本文的作者建议交替训练神经网络的正常权重和掩盖权重。 它比一次教所有内容要长，但结果似乎好一点吗？ </li><li> 固定掩模后，不要忘记对网络进行长时间微调（微调），这一点非常重要。 </li><li> 仔细监控您的口罩的站立状态：激活功能之前或之后。 当参数为零（例如，S型）时，激活可能不等于零，可能会遇到问题。 </li><li> 修剪对batchnorm不友好，其原因与丢弃对它不友好的原因相同：从规范化的角度来看，当数据包中有32个值时，其中32个值为零，而当数据包中有20个值是非常不同的情况时。 撕掉归零余额后，batchnorm层学习到的分布不再有效。 您需要在所有batchnorm层之后插入修剪层，或以某种方式修改后者。 </li><li> 将信道减少应用于分支体系结构和残差网络（ResNet）也存在困难。 在合并分支过程中修剪了多余的神经元后，尺寸可能会不一致。 这很容易通过引入缓冲层来解决，在缓冲层中我们不会拒绝神经元。 此外，如果网络分支承载的信息量不同，则设置不同的值是有意义的。 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-102"><span class="MJXp-mtext" id="MJXp-Span-103">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-104">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-105">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-106">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-107">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-108">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-109">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-12"> \ lambda </script> 这样就不会发现修剪只切除了信息最少的分支中的所有神经元。 但是，如果所有神经元都被切除，那不是那么重要的分支吗？ </li><li> 在问题的原始陈述中，对非零通道的数量进行了严格限制，但在我看来，仅更改初始损失的权重参数和掩蔽权重的L1损失就足够了，然后让优化器确定要保留多少个通道。 </li><li> 捕获口罩。 这不是原始文章中的内容，但是在我看来，这是提高收敛性的良好实用机制。 当遮罩的值达到某个预定的较低值时，我们将其重置，并禁止更改遮罩的这一部分。 因此，在模型训练期间，较弱的权重已完全停止对预测做出贡献，并且不会在相应的量中引入任何杂散值。 从理论上讲，这可能会阻止潜在有用的渠道恢复服务，但是我认为这实际上并没有发生。 </li></ol><br><h3> 困难的方法：L0正则化 </h3><br> 但是我们不是在寻找简单的方法，对吗？ <br><br> 使用L1正则化的信道拒绝并不完全公平。 它允许通道在“强响应”-“弱响应”-“零响应”的范围内移动。 仅当掩膜权重足够接近零时，我们才使用捕获掩膜丢弃通道。 这样的运动极大地扭曲了画面，并在训练过程中改变了其他通道：在前一个神经元完全关闭时，他们必须学会如何系统地给出较弱的响应时才能做些什么，然后才能学习该做什么。 <br><br> 让我提醒您，理想情况下，我们希望从网络中选择信息最少的频道，继续学习没有它的网络，删除下一​​个信息最少的频道，再次调整网络，依此类推。  las，以这种表述，即使对于相对简单的网络，该任务在计算上也是难以承受的。 而且，这种方法不会给通道带来第二次机会-一旦远端神经元无法再次恢复操作。 让我们稍微改变一下任务：我们有时会移除神经元，有时会留下它。 此外，如果神经元整体上有用，那么它通常会被保留，但如果它没有用，反之亦然。 为此，我们将使用与L1正则化相同的掩膜层（并非没有理由引入它们！）。 只有它们的权重不会在吸引子为零的情况下沿整个实轴移动，而是集中在0和1周围。不是说它变得简单得多，而是至少解决了神经元分类去除的问题。 <br><br> 网络培训师的本能表明，通过穷举搜索来解决问题是不值得的，但是您需要将当前运行层中活跃神经元的数量添加到损失函数中。 但是，这样的损耗项将是逐步恒定的，并且梯度下降无法使用它。 有必要以某种方式教导学习算法，尽管没有梯度，但要定期排除一些神经元。 <br><br> 我们有一种临时去除神经元的方法：我们可以对蒙版层应用一个滤除。 在训练期间 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-110"><span class="MJXp-mtext" id="MJXp-Span-111">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-112">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-113">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-114">t</span><span class="MJXp-msubsup" id="MJXp-Span-115"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-116" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-117" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-118" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-119">1</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-13-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-13"> \ beta_i = 1 </script> 很有可能 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-120"><span class="MJXp-mtext" id="MJXp-Span-121">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-122">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-123">i</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-14-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-14"> \ pi </script> 和 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-124"><span class="MJXp-mtext" id="MJXp-Span-125">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-126">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-127">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-128">t</span><span class="MJXp-msubsup" id="MJXp-Span-129"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-130" style="margin-right: 0.05em;">a</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-131" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-132" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-133">0</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-15-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-15"> \ beta_i = 0 </script> 很有可能 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-134"><span class="MJXp-mn" id="MJXp-Span-135">1</span><span class="MJXp-mo" id="MJXp-Span-136" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mtext" id="MJXp-Span-137">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-138">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-139">i</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-16-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-16"> 1-\ pi </script>  。 现在，在损失函数中，您可以将总和 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-140"><span class="MJXp-mtext" id="MJXp-Span-141">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-142">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-143">i</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-17-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-17"> \ pi </script> 这是一个实数。 在这里，我们面临另一个障碍：分布是离散的，尚不清楚反向传播是如何工作的。 通常，这里有特殊的优化算法可以为我们提供帮助（请参阅REINFORCE），但是我们将采用不同的方法。 <br><br> 然后是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">变分优化</a>开始<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">起作用</a>的时刻：我们可以通过连续的1来近似掩蔽层中零和一的离散分布，并使用常规的反向传播算法优化后者的参数。 这就是[通过L0正则化学习稀疏神经网络；  Christos Louizos等；  2017]。 <br><br> 连续分布的作用将由坚硬的混凝土分布来发挥[混凝土分布：离散随机变量的连续松弛； 克里斯·麦迪逊；  2017]，这是一个近似于伯努利分布的对数中的棘手事情： <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nj/ti/wf/njtiwf-b8htnm5pcukvpqbzy1_i.png"></div><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-144"><span class="MJXp-mtext" id="MJXp-Span-145">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-146">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-147">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-148">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-149">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-150">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-18-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-18"> \ alpha </script>  -相对于中心的偏移分布，以及 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-151"><span class="MJXp-mtext" id="MJXp-Span-152">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-153">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-154">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-155">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-156">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-19-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-19"> \ beta </script>  -温度。 在 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-157"><span class="MJXp-mtext" id="MJXp-Span-158">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-159">B</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-160">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-161">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-162">a</span><span class="MJXp-mtext" id="MJXp-Span-163">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-164">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-165">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-166">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-167">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-168">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-169">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-170">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-171">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-172">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-173">w</span><span class="MJXp-mn" id="MJXp-Span-174">0</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-20-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-20"> \ Beta \ rightarrow 0 </script> 分布越来越接近真实伯努利分布，但失去了可微性。 在 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-175"><span class="MJXp-mn" id="MJXp-Span-176">0</span><span class="MJXp-mo" id="MJXp-Span-177" style="margin-left: 0.333em; margin-right: 0.333em;">&lt;</span><span class="MJXp-mtext" id="MJXp-Span-178">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-179">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-180">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-181">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-182">a</span><span class="MJXp-mo" id="MJXp-Span-183" style="margin-left: 0.333em; margin-right: 0.333em;">&lt;</span><span class="MJXp-mn" id="MJXp-Span-184">1</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-21-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-21"> 0 <\ beta <1 </script> 分布密度是凹的（这是我们感兴趣的情况）， <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-185"><span class="MJXp-mtext" id="MJXp-Span-186">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-187">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-188">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-189">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-190">a</span><span class="MJXp-mo" id="MJXp-Span-191" style="margin-left: 0.333em; margin-right: 0.333em;">&gt;</span><span class="MJXp-mn" id="MJXp-Span-192">1</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-22-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-22"> \ beta> 1 </script>  -凸 我们通过刚性S形传递此分布，以便它可以以有限的非零概率熟练地给出 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-193"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-194">z</span><span class="MJXp-mo" id="MJXp-Span-195" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-196">0</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-23-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-23"> z = 0 </script> 和 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-197"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-198">z</span><span class="MJXp-mo" id="MJXp-Span-199" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-200">1</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-24-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-24"> z = 1 </script>  ，并且在区间（0，1）上具有连续的可微分密度。 修剪完成后，我们查看分布朝哪个方向移动并替换随机变量 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-201"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-202">z</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-25-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-25"> z </script> 到特定的掩码值 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-203"><span class="MJXp-mtext" id="MJXp-Span-204">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-205">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-206">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-207">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-208">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-26-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-26"> \ beta </script> 我们把已经确定的模型带到了条件上。 <br><br> 为了感觉更好的分布，我将给出一些针对不同参数的密度示例： <br><div class="spoiler">  <b class="spoiler_title">分布密度</b> <div class="spoiler_text"><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-209"><span class="MJXp-mtext" id="MJXp-Span-210">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-211"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-212"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-213"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">p </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-214"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">h </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-215"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a </font></font></span><span class="MJXp-mo" id="MJXp-Span-216" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">= </font></font></span><span class="MJXp-mn" id="MJXp-Span-217"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0.0 </font></font></span><span class="MJXp-mrow" id="MJXp-Span-218"><span class="MJXp-mo" id="MJXp-Span-219" style="margin-left: 0.278em; margin-right: 0.278em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font></span></span><font style="vertical-align: inherit;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-221"><font style="vertical-align: inherit;"> b </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-222"><font style="vertical-align: inherit;">e </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-223"><font style="vertical-align: inherit;">t </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-224"><font style="vertical-align: inherit;">a </font></span><span class="MJXp-mo" id="MJXp-Span-225" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;">= </font></span><span class="MJXp-mn" id="MJXp-Span-226"><font style="vertical-align: inherit;">0.8</font></span></font><span class="MJXp-mtext" id="MJXp-Span-220">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-221"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-222"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-223"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-224"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-225" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mn" id="MJXp-Span-226"><font style="vertical-align: inherit;"></font></span></span></span><script type="math/tex" id="MathJax-Element-27"> \ alpha = 0.0，\ beta = 0.8 </script>  ： <br><img src="https://habrastorage.org/webt/6l/wt/ga/6lwtgav6fe0ajijoctaxxtv-d6m.png"><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-227"><span class="MJXp-mtext" id="MJXp-Span-228">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-229"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-230"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-231"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">p </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-232"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">h </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-233"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a </font></font></span><span class="MJXp-mo" id="MJXp-Span-234" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">= </font></font></span><span class="MJXp-mn" id="MJXp-Span-235"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1.0 </font></font></span><span class="MJXp-mrow" id="MJXp-Span-236"><span class="MJXp-mo" id="MJXp-Span-237" style="margin-left: 0.278em; margin-right: 0.278em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font></span></span><font style="vertical-align: inherit;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-239"><font style="vertical-align: inherit;"> b </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-240"><font style="vertical-align: inherit;">e </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-241"><font style="vertical-align: inherit;">t </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-242"><font style="vertical-align: inherit;">a </font></span><span class="MJXp-mo" id="MJXp-Span-243" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;">= </font></span><span class="MJXp-mn" id="MJXp-Span-244"><font style="vertical-align: inherit;">0.8</font></span></font><span class="MJXp-mtext" id="MJXp-Span-238">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-239"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-240"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-241"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-242"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-243" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mn" id="MJXp-Span-244"><font style="vertical-align: inherit;"></font></span></span></span><script type="math/tex" id="MathJax-Element-28"> \ alpha = 1.0，\ beta = 0.8 </script>  ： <br><img src="https://habrastorage.org/webt/ro/xr/ni/roxrni40bi9ilebvcjxyw5tw-cg.png"><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-245"><span class="MJXp-mtext" id="MJXp-Span-246">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-247"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-248"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-249"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">p </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-250"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">h </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-251"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a </font></font></span><span class="MJXp-mo" id="MJXp-Span-252" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">= </font></font></span><span class="MJXp-mn" id="MJXp-Span-253"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2.0 </font></font></span><span class="MJXp-mrow" id="MJXp-Span-254"><span class="MJXp-mo" id="MJXp-Span-255" style="margin-left: 0.278em; margin-right: 0.278em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font></span></span><font style="vertical-align: inherit;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-257"><font style="vertical-align: inherit;"> b </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-258"><font style="vertical-align: inherit;">e </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-259"><font style="vertical-align: inherit;">t </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-260"><font style="vertical-align: inherit;">a </font></span><span class="MJXp-mo" id="MJXp-Span-261" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;">= </font></span><span class="MJXp-mn" id="MJXp-Span-262"><font style="vertical-align: inherit;">0.8</font></span></font><span class="MJXp-mtext" id="MJXp-Span-256">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-257"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-258"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-259"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-260"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-261" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mn" id="MJXp-Span-262"><font style="vertical-align: inherit;"></font></span></span></span><script type="math/tex" id="MathJax-Element-29"> \ alpha = 2.0，\ beta = 0.8 </script>  ： <br><img src="https://habrastorage.org/webt/vv/ly/fb/vvlyfbuux9ytl778kyx6lhhtoee.png"><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-263"><span class="MJXp-mtext" id="MJXp-Span-264">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-265">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-266">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-267">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-268">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-269">a</span><span class="MJXp-mo" id="MJXp-Span-270" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-271">0.0</span><span class="MJXp-mrow" id="MJXp-Span-272"><span class="MJXp-mo" id="MJXp-Span-273" style="margin-left: 0.278em; margin-right: 0.278em;">，</span></span><span class="MJXp-mtext" id="MJXp-Span-274">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-275">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-276">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-277">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-278">a</span><span class="MJXp-mo" id="MJXp-Span-279" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-280">0.5</span></span></span><script type="math/tex" id="MathJax-Element-30"> \ alpha = 0.0，\ beta = 0.5 </script>  ： <br><img src="https://habrastorage.org/webt/v_/gs/xm/v_gsxm3cmpxm3frhsozqf4r8vbw.png"><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-281"><span class="MJXp-mtext" id="MJXp-Span-282">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-283">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-284">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-285">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-286">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-287">a</span><span class="MJXp-mo" id="MJXp-Span-288" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-289">1.0</span><span class="MJXp-mrow" id="MJXp-Span-290"><span class="MJXp-mo" id="MJXp-Span-291" style="margin-left: 0.278em; margin-right: 0.278em;">，</span></span><span class="MJXp-mtext" id="MJXp-Span-292">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-293">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-294">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-295">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-296">a</span><span class="MJXp-mo" id="MJXp-Span-297" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-298">0.5</span></span></span><script type="math/tex" id="MathJax-Element-31"> \ alpha = 1.0，\ beta = 0.5 </script>  ： <br><img src="https://habrastorage.org/webt/xs/1q/3t/xs1q3t19w75qvfdnx1f3p6fmlri.png"><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-299"><span class="MJXp-mtext" id="MJXp-Span-300">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-301">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-302">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-303">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-304">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-305">a</span><span class="MJXp-mo" id="MJXp-Span-306" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-307">2.0</span><span class="MJXp-mrow" id="MJXp-Span-308"><span class="MJXp-mo" id="MJXp-Span-309" style="margin-left: 0.278em; margin-right: 0.278em;">，</span></span><span class="MJXp-mtext" id="MJXp-Span-310">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-311">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-312">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-313">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-314">a</span><span class="MJXp-mo" id="MJXp-Span-315" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-316">0.5</span></span></span><script type="math/tex" id="MathJax-Element-32"> \ alpha = 2.0，\ beta = 0.5 </script>  ： <br><img src="https://habrastorage.org/webt/tc/fd/-7/tcfd-7wts42f2afefiyjeuhu6oc.png"><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-317"><span class="MJXp-mtext" id="MJXp-Span-318">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-319">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-320">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-321">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-322">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-323">a</span><span class="MJXp-mo" id="MJXp-Span-324" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-325">2.0</span><span class="MJXp-mrow" id="MJXp-Span-326"><span class="MJXp-mo" id="MJXp-Span-327" style="margin-left: 0.278em; margin-right: 0.278em;">，</span></span><span class="MJXp-mtext" id="MJXp-Span-328">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-329">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-330">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-331">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-332">a</span><span class="MJXp-mo" id="MJXp-Span-333" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-334">0.1</span></span></span><script type="math/tex" id="MathJax-Element-33"> \ alpha = 2.0，\ beta = 0.1 </script>  ： <br><img src="https://habrastorage.org/webt/bx/fd/vq/bxfdvqygmsuoghhodr4o30q1sta.png"><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-335"><span class="MJXp-mtext" id="MJXp-Span-336">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-337">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-338">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-339">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-340">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-341">a</span><span class="MJXp-mo" id="MJXp-Span-342" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-343">2.0</span><span class="MJXp-mrow" id="MJXp-Span-344"><span class="MJXp-mo" id="MJXp-Span-345" style="margin-left: 0.278em; margin-right: 0.278em;">，</span></span><span class="MJXp-mtext" id="MJXp-Span-346">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-347">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-348">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-349">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-350">a</span><span class="MJXp-mo" id="MJXp-Span-351" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-352">2.0</span></span></span><script type="math/tex" id="MathJax-Element-34"> \ alpha = 2.0，\ beta = 2.0 </script>  ： <br><img src="https://habrastorage.org/webt/qa/vc/gi/qavcgiip2fdeesih47og_3fwrxe.png"><br></div></div><br> 从本质上讲，我们有一个“智能”辍学层，可以了解应该更频繁地抛弃哪些结论。 但是我们到底在优化什么呢？ 在损失中，应将分布密度的积分放在非零区域（简单地说，在训练过程中蒙版最终变为非零的概率）： <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/er/7w/k-/er7wk-_hmqlzik9y7xhser1cmbi.png"></div><br> 下列功能已添加到推挽式训练，正则正则化和有关L1正则化一章中提到的其他实现细节中： <br><ul><li> 再一次：我们的“智能”辍学层以某种明显的概率重置了输出，有些则保留了它的原样，此外，取决于 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-353"><span class="MJXp-mtext" id="MJXp-Span-354">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-355">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-356">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-357">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-358">a</span><span class="MJXp-mrow" id="MJXp-Span-359"><span class="MJXp-mo" id="MJXp-Span-360" style="margin-left: 0.278em; margin-right: 0.278em;">，</span></span><span class="MJXp-mtext" id="MJXp-Span-361">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-362">x</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-363">i</span><span class="MJXp-mrow" id="MJXp-Span-364"><span class="MJXp-mo" id="MJXp-Span-365" style="margin-left: 0.278em; margin-right: 0.278em;">，</span></span><span class="MJXp-mtext" id="MJXp-Span-366">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-367">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-368">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-369">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-370">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-371">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-35-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-35"> \ beta，\ xi，\ gamma </script> 输出将被一个0到1的随机数相乘。最后一部分对我们的最终目标来说是寄生的，而不是有用的，但是没有任何形式-反向传播回传是必需的。 </li><li> 一般而言 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-372"><span class="MJXp-mtext" id="MJXp-Span-373">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-374">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-375">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-376">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-377">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-378">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-36-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-36"> \ alpha </script> 和 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-379"><span class="MJXp-mtext" id="MJXp-Span-380">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-381">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-382">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-383">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-384">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-37-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-37"> \ beta </script>  -训练参数，但是在我的实验中，我觉得如果你问一点 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-385"><span class="MJXp-mtext" id="MJXp-Span-386">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-387">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-388">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-389">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-390">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-38-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-38"> \ beta </script>  （0.05），并且在学习过程中仍会线性减少，算法的收敛性要好于您诚实地学习算法。 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-391"><span class="MJXp-mtext" id="MJXp-Span-392">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-393">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-394">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-395">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-396">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-397">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-39-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-39"> \ alpha </script> 最好设置足够大 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-398"><span class="MJXp-mtext" id="MJXp-Span-399">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-400">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-401">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-402">g</span><span class="MJXp-mrow" id="MJXp-Span-403"><span class="MJXp-mtext" id="MJXp-Span-404">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-405">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-406">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-407">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-408">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-409">a</span></span><span class="MJXp-mtext" id="MJXp-Span-410" style="color: red;">\约</span><span class="MJXp-mn" id="MJXp-Span-411">2.5</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-40-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-40"> \ log {\ alpha} \约2.5 </script> 这样一来，最初保存的神经元多于丢弃的神经元，但其大小不足以使损失的乙状结肠饱和。 </li><li> 如果替换为公式 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-412"><span class="MJXp-mtext" id="MJXp-Span-413" style="color: red;">\日</span><span class="MJXp-mrow" id="MJXp-Span-414"><span class="MJXp-mo" id="MJXp-Span-415" style="margin-left: 0.278em; margin-right: 0.278em;">志</span></span><span class="MJXp-mrow" id="MJXp-Span-416"><span class="MJXp-mtext" id="MJXp-Span-417">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-418">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-419">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-420">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-421">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-422">a</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-41-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-41"> \日志{\ alpha} </script> 只是 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-423"><span class="MJXp-mtext" id="MJXp-Span-424">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-425">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-426">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-427">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-428">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-429">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-42-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-42"> \ alpha </script> 好像网络在训练期间融合得更好，并且不太可能碰到NaN。 通过这种操作，一定不能忘记更改损失函数和初始化中的项。 </li><li> 另外，如果您作弊并用损失较大的硬质合金代替损失中的普通乙状结肠， <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-430"><span class="MJXp-mtext" id="MJXp-Span-431">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-432">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-433">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-434">g</span><span class="MJXp-mrow" id="MJXp-Span-435"><span class="MJXp-mtext" id="MJXp-Span-436">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-437">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-438">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-439">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-440">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-441">a</span></span><span class="MJXp-mtext" id="MJXp-Span-442">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-443">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-444">n</span><span class="MJXp-mo" id="MJXp-Span-445" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mo" id="MJXp-Span-446" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mn" id="MJXp-Span-447">4</span><span class="MJXp-mrow" id="MJXp-Span-448"><span class="MJXp-mo" id="MJXp-Span-449" style="margin-left: 0.278em; margin-right: 0.278em;">，</span></span><span class="MJXp-mn" id="MJXp-Span-450">4</span><span class="MJXp-mo" id="MJXp-Span-451" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-43-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-43"> \ log {\ alpha} \ in [-4，4] </script>  ，正规化将更好地融合并发挥更大的作用。 </li><li> 到 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-452"><span class="MJXp-mtext" id="MJXp-Span-453">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-454">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-455">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-456">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-457">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-458">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-44-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-44"> \ alpha </script> 和 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-459"><span class="MJXp-mtext" id="MJXp-Span-460">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-461">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-462">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-463">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-464">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-45-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-45"> \ beta </script> 您还可以应用正则化来进一步增加稀疏性。 </li><li> 训练后，您应该对结果进行二值化，并使用确定的掩码持续训练网络，直到val精度达到常数为止。 这篇文章提供了一个更准确的公式，通过该公式可以在验证过程中确定神经元的输出或将网络释放为释放状态，但是看来在训练结束时 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-465"><span class="MJXp-mtext" id="MJXp-Span-466">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-467">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-468">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-469">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-470">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-471">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-46-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-46"> \ alpha </script> 事实证明，这种极化足以使简单的启发式方法起作用： <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-472"><span class="MJXp-mtext" id="MJXp-Span-473">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-474">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-475">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-476">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-477">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-478">a</span><span class="MJXp-mo" id="MJXp-Span-479" style="margin-left: 0.333em; margin-right: 0.333em;">&lt;</span><span class="MJXp-mn" id="MJXp-Span-480">0</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-47-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-47"> \ alpha <0 </script>  -遮罩0， <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-481"><span class="MJXp-mtext" id="MJXp-Span-482">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-483">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-484">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-485">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-486">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-487">a</span><span class="MJXp-mtext" id="MJXp-Span-488">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-489">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-490">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-491">q</span><span class="MJXp-mn" id="MJXp-Span-492">0</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-48-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-48"> \ alpha \ geq 0 </script>  -遮罩1（但这不准确）。 使用确定性蒙版后，您将看到质量的飞跃。 不要忘记我们来到这里是零权重，并且在某个权重阈值以下，您仍然需要将掩蔽权重替换为零。 </li><li>  L0方法的另一个优点-屏蔽层开始像辍学一样工作，这为网络带来了强大的正则化效果。 但这是一把双刃剑：如果您开始训练太少， <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-493"><span class="MJXp-mtext" id="MJXp-Span-494">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-495">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-496">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-497">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-498">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-499">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-49-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-49"> \ alpha </script> 可能会破坏预先训练的网络结构。 </li></ul><br><h3> 实验 </h3><br> 对于实验，请使用CIFAR-10数据集和一个相对简单的网络（由四个卷积层组成），然后是两个完全连接的层：Conv2D，Mask，Conv2D，Mask，Pool2D，Conv2D，Mask，Conv2D，Mask，Pool2D，Flatten，Dropout（p = 0.5） ，密集，蒙版，密集（登录）。 人们认为修剪的算法在较厚的网络上可以更好地工作，但是在这里我遇到了一个纯粹的技术问题，即缺乏计算能力。 作为优化器，使用了学习率= 0.0015和批量大小= 32的Adam。此外，还使用了常规的L1（0.00005）和L2（0.00025）正则化。 没有应用图像增强。 该网络在收敛之前经过了200个时期的训练，之后被保留下来，并对其应用了神经元减少算法。 <br><br> 除了应用上述算法进行修剪外，我们还设置了一个琐碎的参考点以确保算法完全可以完成某些工作。 让我们尝试扔掉每一层的第一层 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-500"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-501">k</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-50-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-50"> k </script> 神经元并结束生成的网络。 <br><br> 该图显示了在使用不同正则化功率常数进行的一系列实验之后，比较L1和L0通道缩减算法的结果。  x轴<i>表示</i>应用算法后<i>重量</i>减少的百分比。 在Y轴上，验证样本中切割网络的精度。 中间的蓝色条表示尚未切断神经元的网络的近似质量。 绿线代表一种简单的L1掩模学习算法。 红线是L0修剪。 紫线-第一次移除 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-502"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-503">k</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-51-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-51"> k </script> 渠道。 黑色三角形-训练最初权重较小的网络。 <br><img src="https://habrastorage.org/webt/wh/ne/yo/whneyoap30b6vj9qty4msc1lyk8.png"><br>  CIFAR-100的另一个示例，它具有近似相同的体系结构和相似的训练参数，且网络稍长且较宽： <br><img src="https://habrastorage.org/webt/_c/kv/cv/_ckvcvybcmnn-rewibzy-us4s-o.png"><br> 在图中可以清楚地看到，简单的L1算法可以应付狡猾的变分优化，并且在低压缩值下甚至可以提高网络质量。 通过其他数据集和网络体系结构的一次性实验也证实了该结果。 这是绝对预期的结果，当我开始进行网络还原实验时就可以依靠它。 老实说  igh <br><br> 好吧，老实说，我有些惊讶，并尝试使用算法和网络：不同的体系结构，网络超参数，精确的公式，具体的硬分布，初始值 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-504"><span class="MJXp-mtext" id="MJXp-Span-505">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-506">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-507">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-508">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-509">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-510">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-52-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-52"> \ alpha </script> 和 <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-511"><span class="MJXp-mtext" id="MJXp-Span-512">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-513"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">b </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-514"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-515"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-516"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a</font></font></span></span></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，中间调整的时期数。 L0规范化在理论上看起来很酷，但是在实践中，获取超参数更加困难，而且需要更长的时间，因此，我建议您在没有其他实验和文件处理的情况下使用它。请不要考虑花费在阅读本文上的时间：L0修剪看起来确实非常可信，我想说我宁愿将算法错误地应用于某个地方，也没有收到承诺的收益。此外，变分优化是更高级的约简算法的基础（例如，使用变分</font><font style="vertical-align: inherit;">信息瓶颈</font><font style="vertical-align: inherit;">压缩神经网络</font><font style="vertical-align: inherit;">，2018年）。</font><font style="vertical-align: inherit;">通常，可以得出以下结论：</font></font><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-53-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-53"> \ beta </script><font style="vertical-align: inherit;"></font><br><font style="vertical-align: inherit;"></font><br><br><font style="vertical-align: inherit;"></font><br><ol><li>       .           30-50% .      «» ,    .                   [The Lottery Ticket Hypothesis: Training Pruned Neural Networks, J. Frankle and M. Carbin, 2018] (  ,   ,        ,    ). </li><li>           ,     .             .     ,      ? </li><li>         ,        .             60-90%   .               <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-517"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-518">k</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-54-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-54"> k </script>   &lt;7%,        . </li><li>  ,      (&lt;60%)      :         ,  ! </li><li>  L1  L0               (APoZ),      , ..    ,     <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-519"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-520">k</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-55-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-55"> k </script> . </li><li>       ,          .  ,   ,   ,    ,        .         ,   ,           .       pruning'    ,     .     -  ,       . </li></ol><br><br><h3>       </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">还记得我在博文开头写过的话，即完成修剪算法之后，您可以“完全切断多余的网络部分”吗？因此，切断多余的网络绝非易事。 Tensorflow和其他库构建了一个计算图，并且在已经运行时不能轻易更改它。您必须使用计算出的蒙版保存网络，从中删除必要权重的列表，根据需要转置权重，删除置零的组，转置回去，并根据输出的张量集创建新网络。生成的网络应具有与原始网络相同的布局，但它将具有较少的神经元。在创建初始和最终网络的功能方面，要保持相同的网络方案会让人头疼，尤其是当它们不是线性的而是分支的时。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">为了方便遮罩，您可能必须创建自己的图层。这很容易，但是要小心，向哪些集合添加掩膜选项。容易出错，并且不小心训练了频道缩减参数以及所有其他比例。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">应当指出，架构不是很深的网络的权重的很大一部分通常集中在从卷积部分到完全连接的部分的过渡上。这是由于以下事实：最后一个卷积层被弄平了，其结果是在其中形成了神经元的（通道数）*（宽度）*（高度），并且下一个权重矩阵非常宽。这些重量不太可能减少。此外，不应该这样做，否则网络的最后一层将被“盲目”到某些地方发现的功能。在这种情况下，请尝试减小最终通道数，并使用maxpool'ing甚至使用完全卷积或完全完全连接的体系结构。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">谢谢大家的关注，如果有人有兴趣在CIFAR-10和CIFAR-100上重复实验，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">该代码可以在github上获取</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">祝您工作愉快！</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN413939/">https://habr.com/ru/post/zh-CN413939/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN413929/index.html">Sochi。Camera：总体上完全从头开始创建项目的功能，而无需实施标准和示例</a></li>
<li><a href="../zh-CN413931/index.html">Linux内核4.17发行版：您需要了解的内容</a></li>
<li><a href="../zh-CN413933/index.html">[案例]我们如何为波音747进行机库布局</a></li>
<li><a href="../zh-CN413935/index.html">您对bash的了解程度如何？</a></li>
<li><a href="../zh-CN413937/index.html">程序员对就业的误解</a></li>
<li><a href="../zh-CN413941/index.html">在经历了来自AI领域的公司和初创公司的大量采访后我学到了什么</a></li>
<li><a href="../zh-CN413943/index.html">早期宇宙4.均匀膨胀宇宙的运动学</a></li>
<li><a href="../zh-CN413945/index.html">比听起来容易。 第4-5章</a></li>
<li><a href="../zh-CN413947/index.html">在Sailfish OS的VKontakte客户端中使用Long Poll服务器实现工作</a></li>
<li><a href="../zh-CN413949/index.html">为什么我们还在看纸质书？</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
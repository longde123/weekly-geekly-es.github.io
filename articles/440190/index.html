<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•© üë©üèæ‚Äçüç≥ ‚ôàÔ∏è Conocimiento de la red neuronal m√°s simple y su implementaci√≥n paso a paso. üÜë üò∑ üè∞</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Una vez me encontr√© con un libro llamado "Crea tu red neuronal" , escrito por Tarik Rashid . A diferencia de muchos otros libros sobre redes neuronale...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Conocimiento de la red neuronal m√°s simple y su implementaci√≥n paso a paso.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440190/"> Una vez me encontr√© con un libro llamado <b>"Crea tu red neuronal"</b> , escrito por <b>Tarik Rashid</b> .  A diferencia de muchos otros libros sobre redes neuronales, en este se present√≥ todo en un lenguaje simple, con un n√∫mero suficiente de ejemplos y consejos. <br><br>  Inspirado en este libro, quiero revisarlo paso a paso, es decir, su parte pr√°ctica, <b>escribir el c√≥digo para una red neuronal simple</b> . <br>  Este art√≠culo es para aquellos que desean participar en redes neuronales y aprendizaje autom√°tico, pero hasta ahora tienen dificultades para comprender esta incre√≠ble √°rea de la ciencia.  El <b>esqueleto</b> m√°s simple <b>del</b> c√≥digo de una red neuronal se describir√° a continuaci√≥n, de modo que muchos entiendan el principio m√°s simple de construcci√≥n e interacci√≥n de todo lo que consiste esta red neuronal. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/055/9ca/080/0559ca080954e91fdfed1b451fcbfebe.jpg" alt="imagen"><br><a name="habracut"></a><br><br>  Las teor√≠as sobre el aprendizaje autom√°tico y las redes neuronales en el Habr√© son suficientes.  Pero si alguien lo necesita, dejar√© algunos enlaces al final del art√≠culo.  Y ahora, comenzaremos a escribir c√≥digo directamente, y escribiremos en <b>Python</b> , recomiendo usar <u><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Jupyter-Notebook</a></u> al escribir c√≥digo <br><br><h2>  Paso 1. Inicializaci√≥n de la red </h2><br>  Primero, por supuesto, necesitamos inicializar todos los componentes activos de nuestra red <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># numpy ‚Äî    Python,        import numpy #  scipy.special , -scipy    , ,  ,      ,       ,   - " " import scipy.special #,      import matplotlib.pyplot #     class neuralNetwork: #     def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate): #     ,   ,   ,  ) #     ,  ,   self.inodes = inputnodes self.hnodes = hiddennodes self.onodes = outputnodes #    , wih -       ,    who-       self.wih = numpy.random.rand(self.hnodes, self.inodes) self.who = numpy.random.rand(self.onodes, self.hnodes) #   -  ,  ,  ,    ,     ,     ,  ,  ,   self.lr = learningrate #  -   self.activation_function = lambda x: scipy.special.expit(x)</span></span></code> </pre> <br><h2>  Sigmoide </h2><br>  Esta funci√≥n pertenece a la clase de funciones continuas, toma un n√∫mero <b>real arbitrario (es decir, <b>no necesariamente</b> un n√∫mero entero)</b> en la entrada <b>y proporciona un n√∫mero real en el rango de 0 a 1 en la salida</b> . <br><br>  En particular, <b>los n√∫meros negativos</b> grandes (m√≥dulo) <b>se convierten en cero</b> , <b>y los</b> <b>n√∫meros</b> <b>positivos grandes</b> <b>se convierten</b> <b>en uno</b> . <br><br>  Su salida se interpreta bien <b>como el nivel de activaci√≥n de la</b> neurona: desde la <b>ausencia de activaci√≥n</b> (0) hasta la <b>activaci√≥n</b> completamente <b>saturada</b> (1). <br><br>  El sigmoide se expresa mediante la f√≥rmula: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eee/fc0/ace/eeefc0acea96c33eedbb8befdaf28fa7.png" alt="imagen"><br><br>  El gr√°fico de la funci√≥n sigmoidea de acuerdo con la figura siguiente: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/688/227/a86/688227a8673b5e82494c8aa01536c3ef.png" alt="imagen"><br><br>  La funci√≥n sigmoidea es: <br><br><ul><li>  continuo </li><li>  aumentando mon√≥tonamente; </li><li>  diferenciable </li></ul><br>  En este c√≥digo, el sigmoide est√° presente, como puede ver, bajo el nombre <b>expit (x)</b> <br><br><h2>  Un poco sobre c√≥mo se ve un nodo en una red neuronal </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/32e/7ad/4b4/32e7ad4b4fac123e73d88c44a8acb8ca.png" alt="imagen"><br><br>  La imagen muestra m√°s ese nodo, solo que generalmente se presenta en forma de c√≠rculo, no de rect√°ngulo.  Como vemos, dentro de un rect√°ngulo (bien, o un c√≠rculo), todo esto es abstracto, hay 2 funciones: <br><br>  La primera funci√≥n se dedica al hecho de que recibe toda la informaci√≥n, teniendo en cuenta los pesos, los datos y, a veces, incluso teniendo en cuenta la neurona de desplazamiento (una neurona especial que simplemente permite que los gr√°ficos se muevan y no se mezclen en un mont√≥n feo, eso es todo) <br><br>  La segunda funci√≥n toma como par√°metro el mismo valor que la primera funci√≥n sumada, y esta segunda funci√≥n se llama funci√≥n de activaci√≥n.  En nuestro caso, un <b>sigmoide</b> <br><br>  <b>Continuamos</b> : <br><br><h2>  Parte 2. Entrenamiento de redes neuronales </h2><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs_list, targets_list)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#       inputs = numpy.array(inputs_list, ndmin=2).T #     input targets = numpy.array(targets_list, ndmin=2).T #  targets #      hidden_inputs = numpy.dot(self.wih, inputs) #  ,       .    ,       hidden_inputs (1 ),        -   (2 ) hidden_outputs = self.activation_function(hidden_inputs) #    ()  final_inputs = numpy.dot(self.who, hidden_outputs) #  ,     final_outputs = self.activation_function(final_inputs) #   ( - ) output_errors = targets - final_outputs #      ,    &lt;b&gt;  &lt;/b&gt;,   &lt;b&gt;       &lt;/b&gt;(      ) hidden_errors = numpy.dot(self.who.T, output_errors) #        ( ,      ) self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs)) #       (       ) self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))</span></span></code> </pre><br>  <b>Y ahora estamos llegando al final</b> <br><br><h2>  Parte 3. Interrogaci√≥n de una red neuronal </h2><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  ,      def query(self, inputs_list): #         inputs = numpy.array(inputs_list, ndmin=2).T #      hidden_inputs = numpy.dot(self.wih, inputs) #  ,     hidden_outputs = self.activation_function(hidden_inputs) #      final_inputs = numpy.dot(self.who, hidden_outputs) #     ,     final_outputs = self.activation_function(final_inputs) return final_outputs</span></span></code> </pre> <br><h2>  Lo llevamos al final </h2><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     ,  ,  (  &lt;b&gt;&lt;/b&gt;-    , ,   input_nodes = 3 hidden_nodes = 3 output_nodes = 3 #    -   , ... 0.3! learning_rate = 0.3 #   (n    neuralNetwork ,      __init__ ,        n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)</span></span></code> </pre> <br><h2>  PS </h2><br>  Arriba se present√≥ un modelo computacionalmente m√°s simple de una red neuronal.  Pero no se mostr√≥ ninguna aplicaci√≥n espec√≠fica. <br><br>  Si lo desea, puede ir m√°s all√° al agregar la capacidad de reconocer texto escrito a mano en el c√≥digo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MNIST</a> , para esto puede descubrir completamente (y simplemente divertirse) con este <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">archivo jupyter</a> , mi tarea fue demostrar el c√≥digo y, si es posible, masticar en la red y para que respuestas <br><br><h2>  PPS </h2><br>  A continuaci√≥n encontrar√° enlaces √∫tiles: <br><br>  1. Enlace a Github Tarik <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">-&gt;</a> <br>  2.Su libro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">-&gt;</a> <br>  3.Teor√≠a del aprendizaje de m√°quinas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">-&gt;</a> <br>  4.Teor√≠a del aprendizaje de m√°quinas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">-&gt;</a> <br>  5.Teor√≠a del aprendizaje de m√°quinas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">-&gt;</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/440190/">https://habr.com/ru/post/440190/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../440178/index.html">Eliminar la recursividad en Python</a></li>
<li><a href="../440180/index.html">Concurso de programaci√≥n Q #: Concurso de codificaci√≥n Q # de Microsoft</a></li>
<li><a href="../440182/index.html">IBM Watson Studio: una plataforma de desarrollo de aplicaciones de IA basada en la nube</a></li>
<li><a href="../440184/index.html">¬øPor qu√© usamos GraphQL en 8base?</a></li>
<li><a href="../440188/index.html">Alcanzando las estrellas: Dominando a los operadores de Ansible para la gesti√≥n de aplicaciones en Kubernetes</a></li>
<li><a href="../440192/index.html">¬øC√≥mo hacemos radio corporativa para nuestro</a></li>
<li><a href="../440196/index.html">Secretos de la mente y las matem√°ticas</a></li>
<li><a href="../440198/index.html">Nuevas impresoras 3D DWS para profesionales</a></li>
<li><a href="../440200/index.html">Hablemos sobre el registro</a></li>
<li><a href="../440202/index.html">Controles proactivos de OWASP: lista de requisitos previos para desarrolladores de software</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
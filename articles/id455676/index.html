<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤛🏾 🕦 🥜 Apakah gelembung pembelajaran mesin meledak, atau awal fajar baru 💮 💓 🛂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Baru-baru ini, sebuah artikel telah dirilis yang menunjukkan tren pembelajaran mesin yang bagus dalam beberapa tahun terakhir. Singkatnya: jumlah star...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apakah gelembung pembelajaran mesin meledak, atau awal fajar baru</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/recognitor/blog/455676/">  Baru-baru ini, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sebuah artikel</a> telah dirilis yang menunjukkan tren pembelajaran mesin yang bagus dalam beberapa tahun terakhir.  Singkatnya: jumlah startup di bidang pembelajaran mesin telah menurun tajam dalam dua tahun terakhir. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1c6/466/4fc/1c64664fcaf125f2104e67547b533e41.png" alt="gambar"></div><br>  Baiklah apa.  Mari kita analisis "apakah gelembung itu pecah", "bagaimana melanjutkan hidup" dan berbicara tentang dari mana keributan itu berasal. <br><a name="habracut"></a><br>  Pertama, mari kita bicara tentang apa yang menjadi pendorong kurva ini.  Dari mana asalnya.  Mungkin semua orang akan mengingat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kemenangan</a> pembelajaran mesin pada 2012 di kontes ImageNet.  Bagaimanapun, ini adalah acara global pertama!  Namun kenyataannya tidak demikian.  Dan pertumbuhan kurva dimulai sedikit lebih awal.  Saya akan memecahnya menjadi beberapa poin. <br><br><ol><li>  2008 adalah munculnya istilah "data besar."  Produk nyata mulai <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">muncul</a> pada 2010.  Data besar terkait langsung dengan pembelajaran mesin.  Tanpa data besar, operasi stabil dari algoritma yang ada pada saat itu tidak mungkin.  Dan ini bukan jaringan saraf.  Hingga 2012, jaringan saraf adalah banyak minoritas marginal.  Tetapi kemudian algoritma yang benar-benar berbeda mulai bekerja, yang telah ada selama bertahun-tahun, atau bahkan beberapa dekade: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">SVM</a> (1963, 1993), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Random Forest</a> (1995), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">AdaBoost</a> (2003), ... Permulaan tahun-tahun tersebut terutama terkait dengan pemrosesan otomatis data terstruktur : kantor tiket, pengguna, iklan, banyak lagi. <br><br>  Turunan dari gelombang pertama ini adalah serangkaian kerangka kerja seperti XGBoost, CatBoost, LightGBM, dll. <br></li><li>  Pada 2011-2012, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">jaringan saraf convolutional</a> memenangkan serangkaian kontes pengenalan gambar.  Penggunaan sebenarnya agak tertunda.  Saya akan mengatakan bahwa startup dan solusi yang sangat berarti mulai muncul pada tahun 2014.  Butuh dua tahun untuk mencerna bahwa neuron masih bekerja, untuk membuat kerangka kerja yang nyaman yang dapat dipasang dan dijalankan dalam jumlah waktu yang wajar, untuk mengembangkan metode yang akan menstabilkan dan mempercepat waktu konvergensi. <br><br>  Jaringan konvolusional memungkinkan untuk menyelesaikan masalah penglihatan mesin: klasifikasi gambar dan objek dalam gambar, deteksi objek, pengenalan objek dan orang, peningkatan gambar, dll., Dll. </li><li>  2015-2017 tahun.  Boom algoritma dan proyek terkait dengan jaringan berulang atau analognya (LSTM, GRU, TransformerNet, dll.).  Algoritme ucapan-ke-teks yang berfungsi dengan baik dan sistem terjemahan mesin telah muncul.  Sebagian, mereka didasarkan pada jaringan konvolusional untuk menyoroti fitur dasar.  Sebagian karena fakta bahwa mereka belajar mengumpulkan kumpulan data yang sangat besar dan bagus. </li></ol><br><img src="https://habrastorage.org/webt/_c/bj/f2/_cbjf2doqjypuqwfwh1d8_vx92a.png"><br><br>  "Apakah gelembungnya pecah?"  Apakah Hype terlalu panas?  Apakah mereka mati seperti blockchain? " <br>  Baiklah kalau begitu!  Besok Siri akan berhenti bekerja di ponsel Anda, dan lusa Tesla tidak akan membedakan belokan dari kanguru. <br><br>  Jaringan saraf sudah bekerja.  Mereka ada di puluhan perangkat.  Mereka benar-benar memungkinkan Anda untuk menghasilkan, mengubah pasar dan dunia di sekitar Anda.  Hype terlihat sedikit berbeda: <br><br><img src="https://habrastorage.org/webt/zl/7m/ph/zl7mphh3m3rzprgxpbaopha3gwy.png"><br><br>  Hanya saja jaringan saraf tidak lagi menjadi sesuatu yang baru.  Ya, banyak orang memiliki harapan tinggi.  Tetapi sejumlah besar perusahaan telah belajar untuk menggunakan neuron mereka dan membuat produk berdasarkan pada mereka.  Neuron memberikan fungsionalitas baru, dapat mengurangi pekerjaan, mengurangi harga layanan: <br><br><ul><li>  Perusahaan manufaktur mengintegrasikan algoritma untuk analisis penolakan pada konveyor. </li><li>  Peternakan ternak membeli sistem untuk mengendalikan sapi. </li><li>  Pemanen otomatis. </li><li>  Pusat Panggilan Otomatis. </li><li>  Filter di Snapchat.  ( <s>Yah, setidaknya sesuatu yang masuk akal!</s> ) </li></ul><br>  Tetapi yang utama, dan bukan yang paling jelas: "Tidak ada lagi ide baru, atau mereka tidak akan membawa modal instan."  Jaringan saraf telah memecahkan banyak masalah.  Dan mereka akan memutuskan lebih banyak lagi.  Semua ide nyata yang - banyak melahirkan startup.  Tapi semua yang ada di permukaan sudah dikumpulkan.  Selama dua tahun terakhir, saya belum menemukan satu ide baru untuk penggunaan jaringan saraf.  Bukan satu pendekatan baru (well, ok, ada beberapa masalah dengan GAN). <br><br>  Dan setiap startup berikutnya semakin rumit.  Tidak perlu lagi dua orang yang melatih neuron pada data terbuka.  Ini membutuhkan programmer, server, tim penulis, dukungan kompleks, dll. <br><br>  Akibatnya, ada lebih sedikit startup.  Tetapi produksinya lebih.  Perlu melampirkan pengenalan plat nomor?  Ada ratusan profesional dengan pengalaman yang relevan di pasar.  Anda dapat merekrut dan dalam beberapa bulan karyawan Anda akan membuat sistem.  Atau beli yang sudah jadi.  Tetapi melakukan startup baru? .. Kegilaan! <br><br>  Kami perlu membuat sistem untuk melacak pengunjung - mengapa membayar banyak lisensi, ketika Anda bisa melakukannya sendiri selama 3-4 bulan, pertajam untuk bisnis Anda. <br><br>  Sekarang jaringan saraf berjalan dengan cara yang sama seperti puluhan teknologi lainnya. <br><br>  Ingat bagaimana konsep "pengembang situs" telah berubah sejak 1995?  Sementara pasar tidak jenuh dengan spesialis.  Hanya ada sedikit profesional.  Tapi saya bisa bertaruh bahwa dalam 5-10 tahun tidak akan ada banyak perbedaan antara seorang programmer Java dan pengembang jaringan saraf.  Dan itu dan spesialis itu akan cukup di pasar. <br><br>  Hanya akan ada kelas tugas yang diselesaikan oleh neuron.  Ada tugas - menyewa spesialis. <br><br>  <b>"Lalu apa?</b>  <b>Di mana kecerdasan buatan yang dijanjikan? "</b> <br><br>  Dan di sini ada neponyatchka kecil tapi menarik :) <br><br>  Tumpukan teknologi yang ada saat ini, tampaknya, masih tidak akan menuntun kita ke kecerdasan buatan.  Ide-ide, kebaruan mereka, sebagian besar telah melelahkan diri mereka sendiri.  Mari kita bicara tentang apa yang memegang tingkat perkembangan saat ini. <br><br><h3>  Keterbatasan </h3><br>  Mari kita mulai dengan drone otomatis.  Tampaknya dipahami bahwa dimungkinkan untuk membuat mobil yang sepenuhnya otonom dengan teknologi saat ini.  Tetapi setelah berapa tahun ini akan terjadi tidak jelas.  Tesla percaya bahwa ini akan terjadi dalam beberapa tahun - <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Ucp0TTmvqOE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Ada banyak <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">spesialis</a> lain yang menilai ini berusia 5-10 tahun. <br><br>  Kemungkinan besar, menurut saya, setelah 15 tahun, infrastruktur kota itu sendiri akan berubah sehingga munculnya mobil otonom menjadi tak terhindarkan, akan menjadi kelanjutannya.  Namun ini tidak bisa dianggap kecerdasan.  Tesla modern adalah saluran pipa yang sangat kompleks untuk memfilter data, mencari mereka dan melatih kembali.  Ini adalah aturan, aturan, aturan, pengumpulan data, dan filter di atasnya (di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> saya menulis lebih banyak tentang itu, atau melihat dari titik <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ini</a> ). <br><br><h3>  Masalah pertama </h3><br>  Dan di sinilah kita melihat <b>masalah mendasar pertama</b> .  Data besar.  Inilah yang menghasilkan gelombang saat ini dari jaringan saraf dan pembelajaran mesin.  Sekarang, untuk melakukan sesuatu yang kompleks dan otomatis, Anda memerlukan banyak data.  Bukan hanya banyak, tetapi sangat, sangat banyak.  Kami membutuhkan algoritma otomatis untuk pengumpulan, markup, penggunaannya.  Kami ingin membuat mobil melihat truk melawan matahari - kita harus terlebih dahulu mengumpulkan jumlah yang cukup.  Kami ingin mobil tidak menjadi gila dengan sepeda yang dikencangkan ke bagasi - lebih banyak sampel. <br><br>  Apalagi satu contoh saja tidak cukup.  Ratusan?  Ribuan <br><br><img src="https://habrastorage.org/webt/hl/tm/ip/hltmipml3fq_m-md4ansomrxjmk.jpeg"><br><br><h3>  Masalah kedua </h3><br>  <b>Masalah kedua</b> adalah visualisasi dari apa yang dipahami jaringan saraf kita.  Ini adalah tugas yang sangat sepele.  Sampai sekarang, hanya sedikit orang yang mengerti bagaimana memvisualisasikan ini.  Artikel-artikel ini sangat baru, ini hanya beberapa contoh, bahkan yang jauh: <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Visualisasi</a> fiksasi pada tekstur.  Ini menunjukkan dengan baik apa yang cenderung terjadi dalam siklus + apa yang dia rasakan sebagai informasi awal. <br><br><img src="https://habrastorage.org/webt/d7/wb/5f/d7wb5fbpcbugnrcma1qrnn9vyc0.png" alt="gambar"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Visualisasi</a> redaman selama <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">terjemahan</a> .  Sungguh, redaman seringkali dapat digunakan secara tepat untuk menunjukkan apa yang menyebabkan reaksi jaringan semacam itu.  Saya bertemu hal-hal seperti itu untuk debug dan untuk solusi produk.  Ada banyak artikel tentang topik ini.  Tetapi semakin kompleks data, semakin sulit untuk memahami bagaimana mencapai visualisasi berkelanjutan. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/154/93f/988/15493f988978760639233843c9c28c91.png" alt="gambar"><br><br>  Yah dan ya, perangkat lama yang bagus dari "lihat apa yang ada di dalam kotak di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">filter</a> ."  Foto-foto ini populer sekitar 3-4 tahun yang lalu, tetapi semua orang dengan cepat menyadari bahwa gambar-gambar itu indah, tetapi tidak ada banyak artinya di dalamnya. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f68/78c/a4a/f6878ca4a732ef4890e1ad9d8a369896.jpg" alt="gambar"><br><br>  Saya tidak menyebutkan lusinan lotion lain, metode, retas, studi tentang cara menampilkan bagian dalam jaringan.  Apakah alat ini berfungsi?  Apakah mereka membantu Anda dengan cepat memahami apa masalahnya dan men-debug jaringan? .. Tarik keluar persen terakhir?  Nah, kira-kira seperti ini: <br><br><img width="600" src="https://habrastorage.org/webt/eo/p0/i6/eop0i67mupthvfm86dwn139kkha.jpeg"><br><br>  Anda dapat menonton kontes apa pun di Kaggle.  Dan deskripsi tentang bagaimana orang membuat keputusan akhir.  Kami tiba model mulenov 100-500-800 dan berhasil! <br><br>  Tentu saja, saya melebih-lebihkan.  Tetapi pendekatan ini tidak memberikan jawaban yang cepat dan langsung. <br><br>  Memiliki pengalaman yang cukup, setelah menyodok pilihan yang berbeda, Anda dapat mengeluarkan putusan tentang mengapa sistem Anda membuat keputusan semacam itu.  Tetapi memperbaiki perilaku sistem akan sulit.  Masukkan kruk, pindahkan ambang, tambahkan dataset, ambil jaringan backend lainnya. <br><br><h3>  Masalah ketiga </h3><br>  <b>Masalah mendasar ketiga</b> adalah bahwa grid tidak mengajarkan logika, tetapi statistik.  Secara statistik <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">orang</a> ini: <br><br><img src="https://habrastorage.org/webt/wa/lg/6h/walg6hlyvy_cvd7i6oojypaa0lc.png" alt="gambar"><br><br>  Secara logis - tidak terlalu mirip.  Jaringan saraf tidak mempelajari sesuatu yang rumit jika tidak dipaksa.  Mereka selalu mempelajari gejala yang paling sederhana.  Punya mata, hidung, kepala?  Jadi wajah ini!  Atau berikan contoh di mana mata tidak akan berarti wajah.  Dan lagi, jutaan contoh. <br><br><h3>  Ada banyak ruang di bawah </h3><br>  Saya akan mengatakan bahwa ketiga masalah global inilah yang saat ini membatasi pengembangan jaringan saraf dan pembelajaran mesin.  Dan di mana masalah ini tidak terbatas sudah digunakan secara aktif. <br><br>  <b>Apakah ini akhirnya?</b>  <b>Jaringan saraf bangun?</b> <br><br>  Tidak dikenal  Tapi, tentu saja, semua orang berharap tidak. <br><br>  Ada banyak pendekatan dan arahan untuk memecahkan masalah mendasar yang telah saya bahas di atas.  Namun sejauh ini, tidak satu pun dari pendekatan ini yang memungkinkan kami untuk melakukan sesuatu yang secara fundamental baru, untuk menyelesaikan sesuatu yang belum terselesaikan.  Sejauh ini, semua proyek mendasar dilakukan berdasarkan pendekatan stabil (Tesla), atau tetap menguji proyek lembaga atau perusahaan (Google Brain, OpenAI). <br><br>  Secara kasar, arah utama adalah penciptaan beberapa representasi data input tingkat tinggi.  Dalam arti tertentu, "memori."  Contoh paling sederhana dari memori adalah berbagai representasi "Embedding" dari gambar.  Sebagai contoh, semua sistem pengenalan wajah.  Jaringan belajar untuk mendapatkan dari wajah ide stabil tertentu yang tidak bergantung pada rotasi, pencahayaan, resolusi.  Bahkan, jaringan meminimalkan metrik "wajah yang berbeda - jauh" dan "identik - dekat". <br><br><img src="https://habrastorage.org/webt/8z/re/sp/8zrespvq6y2unwlyuaeovq3fj58.png"><br><br>  Pelatihan semacam itu membutuhkan puluhan dan ratusan ribu contoh.  Tetapi hasilnya membawa beberapa dasar "Pembelajaran Satu Kali".  Sekarang kita tidak perlu ratusan wajah untuk mengingat seseorang.  Hanya satu wajah, dan hanya itu - kita akan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mencari tahu</a> ! <br>  Hanya di sinilah masalahnya ... Grid hanya dapat mempelajari objek yang cukup sederhana.  Ketika mencoba untuk membedakan bukan wajah, tetapi, misalnya, "orang dengan pakaian" ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tugas identifikasi ulang</a> ), kualitas gagal oleh banyak urutan besarnya.  Dan jaringan tidak bisa lagi belajar perubahan sudut yang cukup jelas. <br><br>  Dan belajar dari jutaan contoh juga merupakan hiburan yang begitu-begitu saja. <br><br>  Ada pekerjaan untuk mengurangi pemilu secara signifikan.  Misalnya, Anda dapat segera mengingat salah satu karya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Google OneShot</a> <b>Learning</b> pertama: <br><br><img src="https://habrastorage.org/webt/dv/h5/zt/dvh5zte1ggsunwya3tm40zqwiec.png"><br><br>  Ada banyak karya seperti itu, misalnya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">1</a> atau <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">2</a> atau <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">3</a> . <br><br>  Ada satu minus - biasanya pelatihan bekerja dengan baik pada beberapa contoh sederhana, "contoh MNIST'ovskie".  Dan dalam transisi ke tugas-tugas kompleks - Anda memerlukan basis besar, model objek, atau semacam sihir. <br>  Secara umum, bekerja pada pelatihan One-Shot adalah topik yang sangat menarik.  Anda menemukan banyak ide.  Tetapi untuk sebagian besar, dua masalah yang saya daftarkan (pra-pelatihan pada dataset besar / ketidakstabilan pada data yang kompleks) sangat menghambat pembelajaran. <br><br>  Di sisi lain, GAN - jaringan yang kompetitif secara generatif - mendekati Embedding.  Anda mungkin membaca banyak artikel tentang topik ini di Habré.  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">3</a> ) <br>  Fitur GAN adalah pembentukan beberapa ruang keadaan internal (pada dasarnya Embedding yang sama), yang memungkinkan Anda untuk menggambar.  Bisa jadi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">orang</a> , bisa ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">aksi</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e25/77f/f6d/e2577ff6d435046c44f861ab5d3ce2b3.jpg" alt="gambar"><br><br>  Masalah GAN adalah bahwa semakin kompleks objek yang dihasilkan, semakin sulit untuk menggambarkannya dalam logika "generator-diskriminator".  Akibatnya, dari aplikasi nyata GAN, yang hanya terdengar DeepFake, yang, sekali lagi, memanipulasi representasi individu (yang ada basis besar). <br><br>  Saya telah menemui sangat sedikit aplikasi berguna lainnya.  Biasanya semacam peluit palsu dengan menggambar gambar. <br><br>  Dan lagi.  Tidak ada yang memiliki pemahaman tentang bagaimana ini akan memungkinkan kita untuk bergerak menuju masa depan yang lebih cerah.  Representasi logika / ruang dalam jaringan saraf adalah baik.  Tetapi kita membutuhkan banyak contoh, kita tidak mengerti bagaimana neuron ini mewakili dirinya sendiri, kita tidak mengerti bagaimana membuat neuron mengingat beberapa ide yang sangat rumit. <br><br>  <b>Pembelajaran penguatan</b> adalah pendekatan yang sama sekali berbeda.  Tentunya Anda ingat bagaimana Google mengalahkan semua orang di Go.  Kemenangan terbaru di Starcraft dan Dota.  Tapi di sini semuanya jauh dari begitu cerah dan menjanjikan.  Hal terbaik tentang RL dan kompleksitasnya adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel ini</a> . <br><br>  Untuk meringkas secara singkat apa yang penulis tulis: <br><br><ul><li>  Model di luar kotak tidak cocok / bekerja dengan buruk dalam banyak kasus </li><li>  Tugas praktis lebih mudah diselesaikan dengan cara lain.  Boston Dynamics tidak menggunakan RL karena kompleksitasnya / ketidakpastiannya / kompleksitas komputasinya </li><li>  Agar RL berfungsi, Anda memerlukan fungsi yang kompleks.  Seringkali sulit untuk membuat / menulis. </li><li>  Sulit untuk melatih model.  Kita harus menghabiskan banyak waktu untuk berayun dan keluar dari optima lokal </li><li>  Akibatnya, sulit untuk mengulang model, ketidakstabilan model pada perubahan sekecil apa pun </li><li>  Ini sering melebihi batas pada beberapa pola kiri, hingga generator nomor acak </li></ul><br>  Poin kuncinya adalah bahwa RL belum berfungsi dalam produksi.  Google memiliki beberapa jenis eksperimen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">2</a> ).  Tapi saya belum melihat satu sistem kelontong. <br><br>  <b>Memori</b>  Kelemahan dari semua yang dijelaskan di atas tidak terstruktur.  Salah satu pendekatan untuk mencoba merapikan semua ini adalah menyediakan jaringan saraf dengan akses ke memori terpisah.  Sehingga dia dapat merekam dan menulis ulang hasil langkahnya di sana.  Maka jaringan saraf dapat ditentukan oleh keadaan memori saat ini.  Ini sangat mirip dengan prosesor dan komputer klasik. <br><br>  Artikel paling terkenal dan populer adalah dari DeepMind: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b66/f0d/3a9/b66f0d3a9da550ad89e677eb4453a6bf.png" alt="gambar"><br><br>  Tampaknya ini dia, kunci untuk memahami kecerdasan?  Melainkan, tidak.  Sistem masih membutuhkan sejumlah besar data untuk pelatihan.  Dan itu bekerja terutama dengan data tabel terstruktur.  Pada saat yang sama, ketika Facebook <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">memecahkan</a> masalah yang sama, mereka pergi sepanjang jalan "melihat memori, hanya membuat neuron lebih rumit, tetapi lebih banyak contoh - dan itu akan belajar sendiri." <br><br>  <b>Penguraian</b> .  Cara lain untuk menciptakan memori yang bermakna adalah dengan mengambil embeddings yang sama, tetapi ketika belajar memperkenalkan kriteria tambahan yang memungkinkan mereka untuk menyoroti "makna" di dalamnya.  Sebagai contoh, kami ingin melatih jaringan saraf untuk membedakan antara perilaku seseorang di toko.  Jika kita mengikuti jalur standar, kita harus membuat selusin jaringan.  Seseorang mencari seseorang, yang kedua menentukan apa yang dia lakukan, yang ketiga adalah usianya, yang keempat adalah jenis kelamin.  Logika yang terpisah melihat bagian toko di mana ia melakukan / mempelajarinya.  Yang ketiga menentukan lintasannya, dll. <br><br>  Atau, jika ada banyak data, maka mungkin untuk melatih satu jaringan untuk semua jenis hasil (jelas bahwa array data seperti itu tidak dapat diketik). <br><br>  Pendekatan disenthelment memberi tahu kita - dan mari kita latih jaringan sehingga ia dapat dengan sendirinya membedakan antar konsep.  Agar dia membentuk embedding dalam video, di mana satu area akan menentukan tindakan, satu - posisi di lantai tepat waktu, satu - ketinggian orang, dan lainnya - jenis kelaminnya.  Pada saat yang sama, selama pelatihan, saya ingin hampir tidak pernah menyarankan konsep-konsep kunci seperti itu ke jaringan, tetapi agar itu sendiri mengidentifikasi dan mengelompokkan area.  Ada beberapa artikel semacam itu (beberapa di antaranya adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">3</a> ) dan secara umum cukup teoretis. <br><br>  Tetapi arah ini, setidaknya secara teoritis, harus mencakup masalah yang terdaftar di awal. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/314/bd2/7ab/314bd27abc46e22c8c64430c6b6b9211.gif" alt="gambar"><br><br>  Dekomposisi gambar sesuai dengan parameter “warna dinding / warna lantai / bentuk objek / warna objek / dll.” <br><br><img src="https://habrastorage.org/webt/km/md/fb/kmmdfbtnliixqj3d5szfofcqe7q.jpeg"><br><br>  Dekomposisi wajah sesuai dengan parameter “ukuran, alis, orientasi, warna kulit, dll.” <br><br><h3>  Lainnya </h3><br>  Ada banyak petunjuk lain yang tidak terlalu global yang memungkinkan kita untuk mengurangi basis, bekerja dengan data yang lebih heterogen, dll. <br><br>  <b>Perhatian</b> .  Mungkin tidak masuk akal untuk mengisolasi ini sebagai metode terpisah.  Hanya sebuah pendekatan yang memperkuat orang lain.  Banyak artikel yang ditujukan kepadanya ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">3</a> ).  Arti Perhatian adalah untuk memperkuat respons jaringan terhadap benda-benda penting selama pelatihan.  Seringkali oleh beberapa penunjukan target eksternal, atau jaringan eksternal kecil. <br><br>  <b>Simulasi 3D</b> .  Jika Anda membuat mesin 3D yang baik, Anda sering dapat menutup 90% dari data pelatihan dengan itu (saya bahkan melihat contoh di mana hampir 99% dari data ditutup dengan mesin yang baik).  Ada banyak ide dan peretasan tentang cara membuat jaringan yang terlatih pada mesin 3D bekerja pada data nyata (Penyetelan halus, transfer gaya, dll.).  Tetapi sering membuat mesin yang bagus beberapa kali lipat lebih sulit daripada mengumpulkan data.  Contoh saat membuat mesin: <br>  Pelatihan robot ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">google</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">braingarden</a> ) <br>  Belajar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mengenali</a> barang di toko (tetapi dalam dua proyek yang kami lakukan, kami dengan tenang menghilangkan ini). <br>  Pelatihan di Tesla (sekali lagi, video yang ada di atas). <br><br><h2>  Kesimpulan </h2><br>  Seluruh artikel dalam arti tertentu kesimpulan.  Mungkin pesan utama yang ingin saya lakukan adalah "freebie selesai, neuron tidak memberikan solusi yang lebih sederhana."  Sekarang kita harus bekerja keras untuk membangun solusi yang kompleks.  Atau bekerja keras melakukan laporan ilmiah yang rumit. <br><br>  Secara umum, topik ini masih bisa diperdebatkan.  Mungkin pembaca punya contoh lebih menarik? </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id455676/">https://habr.com/ru/post/id455676/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id455658/index.html">Legendaris Intel Core i7-2600K: menguji Sandy Bridge pada 2019 (bagian 3)</a></li>
<li><a href="../id455662/index.html">Tampilan mekanis besar dengan mekanisme cam sebagai decoder</a></li>
<li><a href="../id455666/index.html">Membangun Penjualan Outbound di Perusahaan Layanan TI</a></li>
<li><a href="../id455668/index.html">Kami menulis di bawah FPGA tanpa HDL. Perbandingan alat pengembangan tingkat tinggi</a></li>
<li><a href="../id455670/index.html">Bagaimana printer 3D mencetak tulang, pembuluh darah, dan organ</a></li>
<li><a href="../id455678/index.html">Di jalan Sergey Pavlovich Korolev. Proyek berawak Rusia modern. Bagian 1. "Federasi"</a></li>
<li><a href="../id455682/index.html">Berapa banyak yang Anda habiskan untuk infrastruktur? Dan bagaimana cara menghemat ini?</a></li>
<li><a href="../id455684/index.html">Mengapa kami melakukan hackathon untuk penguji</a></li>
<li><a href="../id455686/index.html">Bagaimana Memilih Alat Manajemen Proyek Terbaik Jika Anda Seorang Milenial?</a></li>
<li><a href="../id455692/index.html">ASZP: restyling atau teater dimulai dengan gantungan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
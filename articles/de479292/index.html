<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§≤üèΩ üë®üèΩ‚Äçü§ù‚Äçüë®üèº üö´ Wie man ein neuronales Netzwerk lehrt, um die Spielphysik zu reproduzieren üßòüèΩ üé∂ üîú</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In fast jedem modernen Computerspiel ist das Vorhandensein einer physischen Engine eine Grundvoraussetzung. Im Wind flatternde Fahnen und Hasen, die v...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie man ein neuronales Netzwerk lehrt, um die Spielphysik zu reproduzieren</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pixonic/blog/479292/"> In fast jedem modernen Computerspiel ist das Vorhandensein einer physischen Engine eine Grundvoraussetzung.  Im Wind flatternde Fahnen und Hasen, die von Kugeln bombardiert werden - all dies erfordert eine ordnungsgem√§√üe Ausf√ºhrung.  Und nat√ºrlich, auch wenn nicht alle Helden Regenm√§ntel tragen ... aber diejenigen, die das tragen, brauchen wirklich eine angemessene Simulation von flatterndem Stoff. <br><br><img src="https://habrastorage.org/webt/5-/tq/jb/5-tqjb5ugkqhg77mf9vr1lfzz9o.png"><br><br>  Eine vollst√§ndige physikalische Modellierung solcher Wechselwirkungen wird jedoch h√§ufig unm√∂glich, da sie um Gr√∂√üenordnungen langsamer ist als f√ºr Echtzeitspiele erforderlich.  Dieser Artikel bietet eine neue Modellierungsmethode, mit der physikalische Simulationen um das 300- bis 5000-fache beschleunigt werden k√∂nnen.  Ziel ist es, ein neuronales Netzwerk zu unterrichten, um physikalische Kr√§fte zu simulieren. <br><a name="habracut"></a><br>  Fortschritte bei der Entwicklung physikalischer Motoren werden sowohl von der wachsenden Rechenleistung technischer Ger√§te als auch von der Entwicklung schneller und stabiler Modellierungsmethoden bestimmt.  Zu diesen Methoden geh√∂rt beispielsweise die Modellierung durch Aufteilung des Raums in Teilr√§ume und datengesteuerte Ans√§tze - das hei√üt, basierend auf Daten.  Erstere arbeiten nur in einem reduzierten oder komprimierten Unterraum, in dem nur wenige Verformungsformen ber√ºcksichtigt werden.  Dies kann bei gro√üen Projekten zu einem deutlichen Anstieg der technischen Anforderungen f√ºhren.  Datengesteuerte Ans√§tze verwenden den Systemspeicher und die darin gespeicherten vorberechneten Daten, wodurch diese Anforderungen reduziert werden. <br><br>  Hier betrachten wir einen Ansatz, der beide Methoden kombiniert: Auf diese Weise sollen die St√§rken beider genutzt werden.  Eine solche Methode kann auf zwei Arten interpretiert werden: entweder als Subraummodellierungsmethode, die von einem neuronalen Netzwerk parametrisiert wird, oder als DD-Methode, die auf Subraummodellierung basiert, um ein komprimiertes simuliertes Medium zu erstellen. <br><br>  Das Wesentliche dabei ist: Zuerst sammeln wir mit <abbr title="Maya nCloth - integriertes Toolkit f√ºr die Erstellung hochrealistischer Computergrafiken Autodesk Maya, mit dem Sie realistische Stoffe und andere verformbare Materialien erstellen k√∂nnen.">Maya nCloth</abbr> hochpr√§zise Simulationsdaten und berechnen dann den linearen Unterraum mit <abbr title="Die Hauptkomponentenanalyse (PCA) ist eine der Hauptmethoden, um die Dimensionalit√§t von Daten zu reduzieren und gleichzeitig die geringste Informationsmenge zu verlieren. Aus mathematischer Sicht handelt es sich bei dieser Methode um eine orthogonale lineare Transformation, bei der Daten aus dem urspr√ºnglichen Merkmalsraum auf einen neuen Raum mit einer niedrigeren Dimension abgebildet werden. In diesem Fall ist die erste Achse des neuen Koordinatensystems so konstruiert, dass die Streuung der Daten maximal ist. Die zweite Achse ist orthogonal zur ersten Achse konstruiert, so dass die Varianz der Daten entlang dieser Achse auch das Maximum des verbleibenden M√∂glichen ist und so weiter. Die Bedeutung des Verfahrens liegt also darin, dass jeder Hauptkomponente ein bestimmter Bruchteil der Gesamtvarianz des urspr√ºnglichen Datensatzes zugeordnet ist. Die Varianz, die ein Ma√ü f√ºr die Variabilit√§t von Daten ist, kann wiederum den Grad ihres Informationsgehalts widerspiegeln.">der Hauptkomponentenmethode (PCA)</abbr> .  Im n√§chsten Schritt verwenden wir maschinelles Lernen auf der Grundlage des klassischen neuronalen Netzwerkmodells und unserer neuen Methodik. Anschlie√üend f√ºhren wir das trainierte Modell in einen interaktiven Algorithmus mit mehreren Optimierungen ein, z. B. einen effizienten Dekomprimierungsalgorithmus durch eine GPU und eine Methode zur Approximation von Vertexnormalen. <br><br><img src="https://habrastorage.org/webt/6n/_a/1u/6n_a1urmdl9_nqjackk2iwmvuag.png"><br>  <i>Abbildung 1. Das Strukturdiagramm der Methode</i> <br><br><h3>  Trainingsdaten </h3><br>  Im Allgemeinen ist die einzige Eingabe f√ºr diese Methode der rohe Zeitstempel der rahmenweisen Positionen der Scheitelpunkte des Objekts.  Als n√§chstes beschreiben wir den Prozess der Erfassung solcher Daten. <br><br>  Wir f√ºhren die Simulation in Maya nCloth durch und erfassen Daten mit einer Geschwindigkeit von 60 Bildern pro Sekunde. Je nach Stabilit√§t der Simulation werden 5 oder 20 Unterschritte und 10 oder 25 begrenzende Iterationen ausgef√ºhrt.  Nehmen Sie f√ºr Stoffe ein T-Shirt-Modell mit einer leichten Gewichtszunahme des Materials und seiner Best√§ndigkeit gegen Dehnung und f√ºr verformbare Objekte Hartgummi mit verringerter Reibung.  Wir f√ºhren externe Kollisionen durch, indem wir Dreiecke mit externer Geometrie kollidieren, Selbstkollisionen - Scheitelpunkte mit Scheitelpunkten f√ºr Stoff und Dreiecke mit Dreiecken f√ºr Gummi.  In allen F√§llen verwenden wir eine ziemlich gro√üe Dicke der Kollision - in der Gr√∂√üenordnung von 5 cm -, um die Stabilit√§t des Modells zu gew√§hrleisten und ein Einklemmen und Rei√üen des Gewebes zu verhindern. <br><br>  <i>Tabelle 1. Parameter der modellierten Objekte</i> <br><img src="https://habrastorage.org/webt/dw/ag/tf/dwagtfbbptnhiioq-2gutci9ung.png"><br><br>  F√ºr verschiedene Arten der Interaktion einfacher Objekte (z. B. Kugeln) erzeugen wir ihre Bewegung auf zuf√§llige Weise, indem wir zuf√§llige Koordinaten zu zuf√§lligen Zeiten beschneiden.  Um die Interaktion von Gewebe mit einem Charakter zu simulieren, verwenden wir eine Motion-Capture-Datenbank mit 6,5 √ó 10 <sup>5</sup> Bildern, die eine gro√üe Animation darstellen.  Nach Abschluss der Simulation √ºberpr√ºfen wir das Ergebnis und schlie√üen Frames mit instabilem oder schlechtem Verhalten aus.  F√ºr die Szene mit dem Rock entfernen wir die H√§nde des Charakters, da sie sich h√§ufig mit der Geometrie des Beingeflechts schneiden und jetzt unbedeutend sind. <br><br><img src="https://habrastorage.org/webt/0r/aa/ug/0raaugw5jdlmj9aqrzac7uj14-e.gif"><br>  <i>Abbildung 2. Die ersten beiden Szenen aus der Tabelle</i> <br><br>  Normalerweise ben√∂tigen wir 10 <sup>5</sup> -10 <sup>6</sup> Frames mit Trainingsdaten.  Nach unserer Erfahrung reichen in den meisten F√§llen 10 <sup>5</sup> Frames zum Testen aus, w√§hrend die besten Ergebnisse mit 10 <sup>6</sup> Frames erzielt werden. <br><br><h3>  Schulung </h3><br>  Als n√§chstes werden wir √ºber den Prozess des maschinellen Lernens sprechen: √ºber die Parametrisierung in unserem neuronalen Netzwerk, √ºber die Netzwerkarchitektur und direkt √ºber die Technik selbst. <br><br><h4>  Parametrierung </h4><br>  Um einen Trainingsdatensatz zu erhalten, sammeln wir die Koordinaten der Eckpunkte in jedem Rahmen <i>t</i> zu einem Vektor <i>x <sub>t</sub></i> und kombinieren diese rahmenweisen Vektoren dann zu einer gro√üen Matrix X. Diese Matrix beschreibt die Zust√§nde des modellierten Objekts.  Au√üerdem m√ºssen wir eine Vorstellung vom Zustand der externen Objekte in jedem Frame haben.  F√ºr einfache Objekte (z. B. B√§lle) k√∂nnen Sie ihre dreidimensionalen Koordinaten verwenden, w√§hrend der Zustand komplexer Modelle (Zeichen) durch die Position jedes Gelenks relativ zum Referenzpunkt beschrieben wird: Bei einem Rock ist eine solche St√ºtze das H√ºftgelenk, bei einem Mantel der Hals.  Bei Objekten mit einem sich bewegenden Bezugssystem sollte die Position der Erde relativ dazu ber√ºcksichtigt werden: Dann kennt unser System die Richtung der Schwerkraft sowie deren lineare Geschwindigkeit, Beschleunigung, Rotationsgeschwindigkeit und Rotationsbeschleunigung.  Bei der Flagge ber√ºcksichtigen wir die Geschwindigkeit und Richtung des Windes.  Als Ergebnis erhalten wir f√ºr jedes Objekt einen gro√üen Vektor, der den Zustand des externen Objekts beschreibt, und alle diese Vektoren werden auch in der Matrix Y kombiniert. <br><br>  Nun wenden wir die PCA sowohl auf die Matrix X als auch auf die Matrix Y an und verwenden die resultierenden Transformationsmatrizen Z und W, um das Unterraumbild zu konstruieren.  Wenn die PCA-Prozedur zu viel Speicher ben√∂tigt, probieren Sie zuerst unsere Daten aus. <br><br>  Die PCA-Komprimierung f√ºhrt unweigerlich zu Detailverlusten, insbesondere bei Objekten mit vielen potenziellen Bedingungen, wie z. B. d√ºnnen Stofffalten.  Wenn der Unterraum jedoch aus 256 Basisvektoren besteht, hilft dies normalerweise, die meisten Details zu erhalten.  Im Folgenden finden Sie Animationen der Standardphysik des Mantels und der Modelle mit 256, 128 bzw. 64 Basisvektoren. <br><br><img src="https://habrastorage.org/webt/yt/gg/7a/ytgg7aiprksj0qtezlvbpy2qcs4.gif"><br>  <i>Abbildung 3. Vergleich des Kontrollmodells (Standard) mit den Modellen unserer Methode in R√§umen mit unterschiedlichen Bema√üungsgrundlagen</i> <br><br><h4>  Quelle und erweitertes Modell </h4><br>  Es war notwendig, ein Modell zu entwickeln, das den Zustand von Modellvektoren in zuk√ºnftigen Frames vorhersagen kann.  Und da die modellierten Objekte normalerweise durch Tr√§gheit mit einer Tendenz zu einem bestimmten mittleren Ruhezustand gekennzeichnet sind (nach dem PCA-Verfahren nimmt das Objekt einen solchen Zustand bei Nullwerten an), w√§re ein gutes Anfangsmodell der Ausdruck, der durch die Linie 9 des Algorithmus in 4 dargestellt wird. Hier sind Œ± und Œ≤ die Modellparameter, ‚äô ist ein explodiertes Produkt.  Die Werte dieser Parameter werden aus den Quellendaten erhalten, indem die <abbr title="Die Methode der kleinsten Quadrate ist eine mathematische Methode zur L√∂sung verschiedener Probleme, die auf der Minimierung der Summe der quadrierten Abweichungen einiger Funktionen von den gew√ºnschten Variablen basiert.">lineare Gleichung</abbr> der <abbr title="Die Methode der kleinsten Quadrate ist eine mathematische Methode zur L√∂sung verschiedener Probleme, die auf der Minimierung der Summe der quadrierten Abweichungen einiger Funktionen von den gew√ºnschten Variablen basiert.">kleinsten Quadrate</abbr> individuell f√ºr Œ± und Œ≤ gel√∂st wird: <br><br><img src="https://habrastorage.org/webt/4g/ml/d1/4gmld1lrufdu-hdusjpuerfmb6w.png"><br><br>  Hier ist ‚Ä† die <abbr title="A + wird als pseudoinverse Matrix f√ºr eine Matrix A bezeichnet, wenn sie die folgenden Kriterien erf√ºllt: A A + A = A; A + A A + = A +; (A A +) * = A A +; (A + A) * = A + A.">pseudoinverse Transformation der Matrix</abbr> . <br><br>  Da eine solche Vorhersage nur eine sehr grobe Ann√§herung ist und den Einfluss externer Objekte w nicht ber√ºcksichtigt, ist sie offensichtlich nicht in der Lage, die Trainingsdaten genau zu modellieren.  Daher trainieren wir das neuronale Netz Œ¶, um die Resteffekte des Modells gem√§√ü der 11. Zeile des Algorithmus zu approximieren.  Hier parametrisieren wir mit der Aktivierungsfunktion <abbr title="Die Aktivierungsfunktion bestimmt den Ausgabewert eines Neurons in Abh√§ngigkeit vom Ergebnis einer gewichteten Summe von Eingaben und einem Schwellenwert. Die Aktivierungsfunktion ReLu gibt x zur√ºck, wenn x positiv ist, und ansonsten 0.">ReLU</abbr> ein standardm√§√üiges <abbr title="Die Aktivierungsfunktion bestimmt den Ausgabewert eines Neurons in Abh√§ngigkeit vom Ergebnis einer gewichteten Summe von Eingaben und einem Schwellenwert. Die Aktivierungsfunktion ReLu gibt x zur√ºck, wenn x positiv ist, und ansonsten 0.">direktverteilendes</abbr> <abbr title="Ein neuronales Vorw√§rtskopplungsnetz ist ein neuronales Netz, in dem sich ein Signal streng von der Eingangsschicht zur Ausgangsschicht ausbreitet und sich nicht in die entgegengesetzte Richtung ausbreitet.">neuronales Netzwerk</abbr> mit 10 Schichten f√ºr jede Schicht (mit Ausnahme der Ausgabe).  Mit Ausnahme der Eingabe- und Ausgabeebene setzen wir die Anzahl der ausgeblendeten Einheiten auf jeder verbleibenden Ebene auf eineinhalb der Gr√∂√üe der PCA-Daten, was zu einem guten Kompromiss zwischen dem belegten Speicherplatz auf der Festplatte und der Leistung f√ºhrte. <br><br><img src="https://habrastorage.org/webt/re/7_/ii/re7_iisbng_s83ibdfmcn32idf8.png"><br>  <i>Abbildung 4. Lernalgorithmus f√ºr neuronale Netze</i> <br><br><h3>  Neuronales Netz-Training </h3><br>  Eine Standardmethode zum Trainieren eines neuronalen Netzwerks besteht darin, den gesamten Datensatz zu durchlaufen und das Netzwerk zu trainieren, um Vorhersagen f√ºr jeden Frame zu treffen.  Ein solcher Ansatz f√ºhrt nat√ºrlich zu einem geringen Lernfehler, aber die R√ºckkopplung in einer solchen Vorhersage f√ºhrt zu einem instabilen Verhalten des Ergebnisses.  Um eine stabile Langzeitvorhersage zu gew√§hrleisten, verwendet unser Algorithmus daher die <abbr title="Die Ausbreitung von Fehlern in R√ºckw√§rtsrichtung ist eine M√∂glichkeit, ein neuronales Netzwerk zu trainieren. Das Training mit diesem Algorithmus umfasst zwei Durchg√§nge durch alle Schichten des Netzwerks: direkt und umgekehrt. Bei einem direkten Durchlauf wird der Eingabevektor der Eingabeschicht des neuronalen Netzwerks zugef√ºhrt, wonach er sich von Schicht zu Schicht durch das Netzwerk ausbreitet. Infolgedessen wird ein Satz von Ausgangssignalen erzeugt, bei denen es sich um die tats√§chliche Antwort des Netzwerks auf ein bestimmtes Eingangsbild handelt. W√§hrend eines direkten Durchgangs werden alle synaptischen Nettogewichte festgelegt. W√§hrend der Umkehrung werden sie gem√§√ü der Fehlerkorrekturregel konfiguriert: Die tats√§chliche Netzwerkleistung wird von der gew√ºnschten abgezogen, wodurch ein Fehlersignal erzeugt wird. Dieses Signal breitet sich anschlie√üend in der Richtung entgegengesetzt zur Richtung der synaptischen Verbindungen durch das Netzwerk aus. Die synaptischen Gewichte werden angepasst, um die Netzwerkleistung auf den gew√ºnschten Wert zu maximieren.">Methode der R√ºck√ºbertragung von Fehlern</abbr> w√§hrend des gesamten Integrationsvorgangs. <br><br>  Im Allgemeinen funktioniert das so: Aus einem kleinen Fenster mit Trainingsdaten <i>z</i> und <i>w</i> nehmen wir die ersten beiden Frames <i>z <sub>0</sub></i> und <i>z <sub>1</sub></i> und f√ºgen ihnen ein kleines Rauschen <i>r <sub>0</sub></i> , <i>r <sub>1 hinzu</sub></i> , um den Lernpfad geringf√ºgig zu st√∂ren.  Um die n√§chsten Frames vorherzusagen, f√ºhren wir den Algorithmus mehrmals aus und kehren bei jedem neuen Zeitschritt zu den vorherigen Ergebnissen der Vorhersagen zur√ºck.  Sobald wir eine Vorhersage der gesamten Flugbahn erhalten, berechnen wir den durchschnittlichen Koordinatenfehler und √ºbergeben ihn dann an den AmsGrad-Optimierer unter Verwendung der mit TensorFlow berechneten automatischen Ableitungen. <br><br>  Wir werden diesen Algorithmus an Mini-Samples von 16 Frames mit √ºberlappenden Fenstern von 32 Frames f√ºr 100 Epochen oder bis zur Konvergenz des Trainings wiederholen.  Wir verwenden die Lernrate von 0,0001, den D√§mpfungskoeffizienten der Lernrate von 0,999 und die aus den ersten drei Komponenten des PCA-Raums berechnete Standardabweichung des Rauschens.  Diese Schulung dauert je nach Komplexit√§t der Installation und Gr√∂√üe der PCA-Daten 10 bis 48 Stunden. <br><br><img src="https://habrastorage.org/webt/k4/fe/in/k4feinopgrygcqm6p3dkrjk1pcu.gif"><br>  <i>Abbildung 5. Visueller Vergleich des Referenzrocks und desjenigen, den unser neuronales Netzwerk zu bauen gelernt hat</i> <br><br><h3>  Systemimplementierung </h3><br>  Wir werden die Implementierung unserer Methode in einer interaktiven Umgebung detailliert beschreiben, einschlie√ülich der Bewertung eines neuronalen Netzwerks, der Berechnung der Normalen zu den Oberfl√§chen von Objekten zum Rendern und des Umgangs mit sichtbaren Schnittpunkten. <br><br><h4>  Rendering-App </h4><br>  Wir rendern die resultierenden Modelle in einer einfachen interaktiven 3D-Anwendung, die in C ++ und DirectX geschrieben wurde: Wir implementieren erneut die Vorprozesse und neuronalen Netzwerkoperationen in Single-Threaded-C ++ - Code und laden die bin√§ren Netzwerkgewichtungen, die w√§hrend unseres Trainingsprozesses erhalten wurden.  Dann wenden wir einige einfache Optimierungen f√ºr die Netzwerksch√§tzung an, insbesondere die Wiederverwendung von Speicherpuffern und sp√§rlichen Vektor-Matrix-Daten, die aufgrund des Vorhandenseins von Null verborgenen Einheiten m√∂glich werden, die dank der ReLU-Aktivierungsfunktion erhalten werden. <br><br><h4>  GPU-Dekomprimierung </h4><br>  Senden Sie komprimierte z-Statusdaten an die GPU und dekomprimieren Sie sie f√ºr das weitere Rendern.  Zu diesem Zweck verwenden wir einen einfachen Berechnungsshader, der f√ºr jeden Scheitelpunkt des Objekts das Punktprodukt des Vektors z und der ersten drei Zeilen der Matrix U <sup>T</sup> berechnet, die den Koordinaten dieses Scheitelpunkts entsprechen, und anschlie√üend den Durchschnittswert <i>x <sub>¬µ</sub></i> addiert.  Dieser Ansatz hat zwei Vorteile gegen√ºber der <abbr title="Die naive Methode ist eine einfache probabilistische Methode, die auf der Anwendung des Bayes-Theorems mit strengen (naiven) Annahmen √ºber die Unabh√§ngigkeit basiert. Abh√§ngig von der genauen Art des Wahrscheinlichkeitsmodells k√∂nnen naive Bayes-Klassifikatoren sehr effektiv trainiert werden. In vielen praktischen Anwendungen wird die Maximum-Likelihood-Methode verwendet, um Parameter f√ºr naive Bayes'sche Modelle abzusch√§tzen.">naiven</abbr> Dekomprimierungsmethode.  Erstens beschleunigt die Parallelit√§t der GPU die Berechnung des Modellzustandsvektors erheblich, was bis zu 1 ms dauern kann.  Zweitens wird die Daten√ºbertragungszeit zwischen der Zentrale und der GPU um eine Gr√∂√üenordnung verk√ºrzt, was insbesondere f√ºr Plattformen wichtig ist, auf denen die √úbertragung des gesamten Zustands des gesamten Objekts zu langsam ist. <br><br><h4>  Vertex-Normalvorhersage </h4><br>  W√§hrend des Renderns reicht es nicht aus, nur auf die Koordinaten der Scheitelpunkte zuzugreifen, sondern es werden auch Informationen √ºber die Verformungen ihrer Normalen ben√∂tigt.  In der Regel lassen Sie in einer physischen Engine diese Berechnung entweder weg oder f√ºhren eine naive Frame-f√ºr-Frame-Neuberechnung von Normalen mit anschlie√üender Umverteilung auf benachbarte Scheitelpunkte durch.  Dies kann sich als ineffizient herausstellen, da die grundlegende Implementierung des Zentralprozessors zus√§tzlich zu den Kosten f√ºr Dekomprimierung und Daten√ºbertragung weitere 150 Œºs f√ºr ein solches Verfahren erfordert.  Und obwohl diese Berechnung auf der GPU durchgef√ºhrt werden kann, gestaltet sich die Implementierung aufgrund der Notwendigkeit von Paralleloperationen schwieriger. <br><br>  Stattdessen f√ºhren wir auf dem GPU-Shader eine lineare Regression des Zustands des Unterraums zu normalen Vollzustandsvektoren durch.  Wenn wir die Werte der Normalen der Eckpunkte in jedem Frame kennen, berechnen wir die Matrix Q, die die Darstellung des Unterraums auf den Normalen der Eckpunkte am besten darstellt. <br><br>  Da die Vorhersage von Normalen in unserer Methode noch nie zuvor vorgestellt wurde, gibt es keine Garantie daf√ºr, dass dieser Ansatz korrekt ist, aber in der Praxis hat er sich als wirklich gut erwiesen, wie aus der folgenden Abbildung ersichtlich ist. <br><br><img src="https://habrastorage.org/webt/ex/mn/ef/exmnefvyrkox7j-mcl7brp2vyog.png"><br>  <i>Abbildung 6. Vergleich der mit unserer Methode berechneten Modelle und der Referenz (Grundwahrheit) sowie der Differenz zwischen ihnen</i> <br><br><h4>  Kreuzungskampf </h4><br>  Unser neuronales Netzwerk lernt, Kollisionen effizient auszuf√ºhren. Aufgrund von Ungenauigkeiten bei Vorhersagen und Fehlern, die durch die Komprimierung des Unterraums verursacht werden, k√∂nnen jedoch Schnittpunkte zwischen externen und simulierten Objekten auftreten.  Da wir die Berechnung des vollst√§ndigen Zustands der Szene auf den Anfang des Renderns verschieben, gibt es dar√ºber hinaus keine M√∂glichkeit, diese Probleme im Voraus effektiv zu l√∂sen.  Um eine hohe Leistung aufrechtzuerhalten, m√ºssen diese √úberschneidungen beim Rendern entfernt werden. <br><br>  Wir haben daf√ºr eine einfache und effektive L√∂sung gefunden, die darin besteht, dass sich √ºberschneidende Scheitelpunkte auf die Oberfl√§che der Grundelemente projiziert werden, aus denen wir den Charakter bilden.  Diese Projektion ist auf der GPU mit demselben Computer-Shader einfach durchzuf√ºhren, mit dem die Fabric dekomprimiert und die normale Schattierung berechnet wird. <br><br>  Zun√§chst komponieren wir ein Zeichen aus Proxy-Objekten, die mit Scheitelpunkten mit unterschiedlichen Anfangs- und Endradien verbunden sind, und √ºbertragen anschlie√üend Informationen √ºber die Koordinaten und Radien dieser Objekte an den Computing-Shader.  √úberpr√ºfen Sie erneut die Koordinaten jedes Scheitelpunkts auf Schnittpunkte mit dem entsprechenden Proxy-Objekt und projizieren Sie diesen Scheitelpunkt, falls dies der Fall ist, auf die Oberfl√§che des Proxy-Objekts.  Wir korrigieren also nur die Position des Scheitelpunkts, ohne die Normale selbst zu ber√ºhren, um die Schattierung nicht zu besch√§digen. <br><br>  Bei diesem Ansatz werden kleine sichtbare √úberschneidungen von Objekten entfernt, vorausgesetzt, die Fehler der Scheitelpunktverschiebung sind nicht so gro√ü, dass sich die Projektion auf der gegen√ºberliegenden Seite des entsprechenden Proxy-Objekts befindet. <br><br><img src="https://habrastorage.org/webt/ef/9q/al/ef9qal2u48v_kwy6q8pqdspe9qi.png"><br>  <i>Abbildung 7. Zeichenmodell bestehend aus Proxy-Objekten und den Ergebnissen der Beseitigung sichtbarer √úberschneidungen mithilfe unserer Methode: Vorher und Nachher</i> <br><br><h3>  Ergebnisermittlung </h3><br>  Unsere Testszenen umfassen also: <br><br><ul><li> ,     ; </li><li> ,    ,    ; </li><li> ,   ; </li><li>      ,  ; </li><li> ,    ; </li><li> ,    . </li></ul><br>        ,   . <br><br>    -         16 ,         120  240   . <br><br><img src="https://habrastorage.org/webt/m8/ls/dz/m8lsdz-6i0bgaghswhtf8luequg.gif"><br> <i> 8.   16 . Party time!</i> <br><br><h4>    </h4><br> ,       , ,        ,       . <br><br>   ,          PCA.   ,        ,             ,   . <br><br><img src="https://habrastorage.org/webt/0o/mb/js/0ombjsge3myljg4b2ieuzr0seic.png"><br> <i> 9.   ,    ,  ‚Äì </i> <br><br><h4>  Ausf√ºhrung </h4><br>          ‚Äï     ,     .         ,     .        300-5000      ,   .           ,   <abbr title=" -   ‚Äî       ,       (Projective Dynamics)       ."> -   (HRPD)</abbr> , <abbr title="   (Long short-term memory) ‚Äî      ,     .      ,                 .  LSTM      ,   (gates) ¬´¬ª.">   (LSTM)</abbr>  <abbr title="    ‚Äî    LSTM-.            ¬´ ¬ª (update gate).  ,       .       ,   LSTM-.">   (GRU)</abbr> . <br><br>      ,          .        Intel Xeon E5-1650 3.5 GHz    GeForce GTX 1080 Titan. <br><br> <i> 2.    </i> <br><img src="https://habrastorage.org/webt/io/ax/rw/ioaxrwaeedpn506pzo7sv857as4.png"><br><br><h3>      </h3><br> ,         ,   .      ,                  . <br><br>    data-driven ,     . ,   ,         ,           ,    ,       .  ,      ,        ‚Äï ,       . <br><br>     ,      ,         ,         . <br><br>         ,      .      data-driven ,     ‚Äï ,       .        ,   ,    ,      .        , ,            ,       . <br><br>       ,         .        . <br><br>       , , ,      .   ,   , ‚Äï    ,       . -,         ,   ,    -      .                . <br><br> ,       ,       ,     ,     .    ,     ,      ,      , ‚Äï         ,       ,     .        . <br><br>        <a href="https://www.youtube.com/watch%3Fv%3DatcKO15YVD8"></a> . <br><br><img src="https://habrastorage.org/webt/1i/hx/uf/1ihxuf4flcfzfps0xuw6sk9p8ts.gif"><br> <i> 10.  vs : choose your fighter</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de479292/">https://habr.com/ru/post/de479292/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de479282/index.html">Wenn die Daten nicht in den Speicher passen. Einfachste Methoden</a></li>
<li><a href="../de479284/index.html">Das Haus, das der Roboter gebaut hat</a></li>
<li><a href="../de479286/index.html">Schreiben einer einfachen Webanwendung mit Spring MVC, Spring Data JPA und Hibernate</a></li>
<li><a href="../de479288/index.html">Warum Service Desk implementieren und wie Sie eine L√∂sung f√ºr Ihr Unternehmen ausw√§hlen</a></li>
<li><a href="../de479290/index.html">Algorithmen zum Suchen des Volumens und des Massenschwerpunkts eines Polyeders</a></li>
<li><a href="../de479294/index.html">GitLab 12.5 wurde mit der Erstellung von EKS-Clustern und dem Environment Panel ver√∂ffentlicht</a></li>
<li><a href="../de479296/index.html">Wie ich aufh√∂rte zu hassen und mich in die Entwicklung verliebte</a></li>
<li><a href="../de479298/index.html">PostgreSQL-Antimuster: CTE x CTE</a></li>
<li><a href="../de479300/index.html">√ñkologie und Rechenzentren. Wie in Russland und im Ausland "gr√ºne Daten"</a></li>
<li><a href="../de479302/index.html">Grundlagen zu Unity Shader-Diagrammen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
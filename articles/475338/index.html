<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíÄ üç∑ üëßüèΩ Si no tiene Python, pero hay un modelo Keras y Java üï° üéè üë©üèæ‚Äçüåæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos! En la construcci√≥n de modelos ML, Python hoy ocupa una posici√≥n de liderazgo y es ampliamente popular entre la comunidad de especialista...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Si no tiene Python, pero hay un modelo Keras y Java</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/naumen/blog/475338/">  Hola a todos!  En la construcci√≥n de modelos ML, Python hoy ocupa una posici√≥n de liderazgo y es ampliamente popular entre la comunidad de especialistas en Data Science [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1</a> ]. <br><br>  Como la mayor√≠a de los desarrolladores, Python nos atrae con su simplicidad y sintaxis concisa.  Lo usamos para resolver problemas de aprendizaje autom√°tico utilizando redes neuronales artificiales.  Sin embargo, en la pr√°ctica, el lenguaje de desarrollo de productos no siempre es Python, y esto nos obliga a resolver problemas de integraci√≥n adicionales. <br><br>  En este art√≠culo hablar√© sobre las soluciones a las que llegamos cuando necesit√°bamos asociar el modelo Keras de Python con Java. <br><br>  A qu√© prestamos atenci√≥n: <br><br><ul><li>  Incluye paquetes de modelos Keras y Java; </li><li>  Prepararse para trabajar con el marco DeepLearning4j (DL4J para abreviar); </li><li>  Importar un modelo de Keras en DL4J (cuidadosamente, la secci√≥n contiene m√∫ltiples ideas): c√≥mo registrar capas, qu√© limitaciones tiene el m√≥dulo de importaci√≥n, c√≥mo verificar los resultados de su trabajo. </li></ul><br>  ¬øPor qu√© leer? <br><br><ul><li>  Para ahorrar tiempo al principio, si enfrentar√° la tarea de una integraci√≥n similar; </li><li>  Para saber si nuestra soluci√≥n es adecuada para usted y si puede reutilizar nuestra experiencia. </li></ul><a name="habracut"></a><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2m/2k/xj/2m2kxjbwgahv1gx0wejstn2qpjw.png" alt="imagen alt"></div><br>  Caracter√≠stica integral sobre la importancia de los marcos de aprendizaje profundo [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> ]. <br><br>  Puede encontrar un resumen de los marcos de aprendizaje profundo m√°s populares aqu√≠ [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">3</a> ] y aqu√≠ [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">4</a> ]. <br><br>  Como puede ver, la mayor√≠a de estos marcos se basan en Python y C ++: usan C ++ como el n√∫cleo para acelerar las operaciones b√°sicas y altamente cargadas, y Python como la interfaz de interacci√≥n para acelerar el desarrollo. <br><br>  De hecho, muchos lenguajes de desarrollo son mucho m√°s extensos.  Java es el l√≠der en desarrollo de productos para grandes empresas y organizaciones.  Algunos marcos populares para redes neuronales tienen puertos para Java en forma de carpetas JNI / JNA, pero en este caso existe la necesidad de construir un proyecto para cada arquitectura y la ventaja de Java en el tema del desenfoque multiplataforma.  Este matiz puede ser extremadamente importante en soluciones replicadas. <br><br>  Otro enfoque alternativo es usar Jython para compilar en Java bytecode;  pero hay un inconveniente aqu√≠: soporte solo para la segunda versi√≥n de Python, as√≠ como la capacidad limitada de usar bibliotecas de Python de terceros. <br><br>  Para simplificar el desarrollo de soluciones de redes neuronales en Java, se est√° desarrollando el marco DeepLearning4j (DL4J para abreviar).  DL4 adem√°s de la API de Java ofrece un conjunto de modelos previamente entrenados [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">5</a> ].  En general, esta herramienta de desarrollo es dif√≠cil de competir con TensorFlow.  TensorFlow supera a DL4J con documentaci√≥n m√°s detallada y una serie de ejemplos, capacidades t√©cnicas, tama√±os de comunidad y desarrollo acelerado.  Sin embargo, la tendencia a la que se adhiere Skymind es bastante prometedora.  Los competidores significativos en Java para esta herramienta a√∫n no son visibles. <br><br>  La biblioteca DL4J es una de las pocas (si no la √∫nica) que permite importar modelos Keras, y ampl√≠a su funcionalidad con las capas familiares de Keras [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">6</a> ].  La biblioteca DL4J contiene un directorio con ejemplos de la implementaci√≥n de modelos ML de redes neuronales (ejemplo dl4j).  En nuestro caso, las sutilezas de implementar estos modelos en Java no son tan interesantes.  Se prestar√° m√°s atenci√≥n a la importaci√≥n del modelo entrenado Keras / TF a Java utilizando m√©todos DL4J. <br><br><h1>  Empezando </h1><br>  Antes de comenzar, debe instalar los programas necesarios: <br><br><ol><li>  Java versi√≥n 1.7 (versi√≥n de 64 bits) y superior. </li><li>  Sistema de construcci√≥n del proyecto Apache Maven. </li><li>  IDE para elegir: Intellij IDEA, Eclipse, Netbeans.  Los desarrolladores recomiendan la primera opci√≥n y, adem√°s, se analizan los ejemplos de capacitaci√≥n disponibles. </li><li>  Git (para clonar un proyecto en tu PC). </li></ol><br>  Puede encontrar una descripci√≥n detallada con un ejemplo de lanzamiento aqu√≠ [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">7</a> ] o en el video [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">8</a> ]. <br><br>  Para importar el modelo, los desarrolladores de DL4J sugieren usar el <em>m√≥dulo de</em> importaci√≥n <em>KerasModelImport</em> (apareci√≥ en octubre de 2016).  El funcional del m√≥dulo es compatible con ambas arquitecturas de modelos de Keras: es secuencial (anal√≥gico en java clase MultiLayerNetwork) y funcional (anal√≥gico en java clase ComputationGraph).  El modelo se importa como un todo en formato HDF5, o 2 archivos separados: el peso del modelo con la extensi√≥n h5 y el archivo json que contiene la arquitectura de red neuronal. <br><br>  Para un inicio r√°pido, los desarrolladores de DL4J prepararon un an√°lisis paso a paso de un ejemplo simple en el conjunto de datos de iris de Fisher para un modelo de tipo secuencial [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">9</a> ].  Se consider√≥ otro ejemplo de capacitaci√≥n desde la perspectiva de importar modelos de dos maneras (1: en formato HDF5 completo; 2: en archivos separados: pesos de modelo (extensi√≥n h5) y arquitectura (extensi√≥n json)), seguido de una comparaci√≥n de los resultados de los modelos Python y Java [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">10</a> ].  Esto concluye la discusi√≥n de las capacidades pr√°cticas del m√≥dulo de importaci√≥n. <br><br>  Tambi√©n hay TF en Java, pero est√° en un estado experimental y los desarrolladores no dan ninguna garant√≠a de su funcionamiento estable [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">11</a> ].  Hay problemas con el control de versiones, y TF en Java tiene una API incompleta, por lo que esta opci√≥n no se considerar√° aqu√≠. <br><br><h1>  Caracter√≠sticas del modelo original Keras / TF: </h1><br>  Importar una red neuronal es sencillo.  Con m√°s detalle en el c√≥digo analizaremos un ejemplo de integraci√≥n de una red neuronal con una arquitectura m√°s complicada. <br><br>  No debe entrar en los aspectos pr√°cticos de este modelo, es indicativo desde el punto de vista de la contabilidad de las capas (en particular, el registro de capas Lambda), algunas sutilezas y limitaciones del m√≥dulo de importaci√≥n, as√≠ como DL4J en su conjunto.  En la pr√°ctica, los matices observados pueden requerir ajustes en la arquitectura de la red o abandonar por completo el enfoque de lanzar el modelo a trav√©s de DL4J. <br><br>  Caracter√≠sticas del modelo: <br><br>  <b>1.</b> Tipo de modelo: funcional (red con ramificaci√≥n); <br><br>  <b>2.</b> Los par√°metros de entrenamiento (el tama√±o del lote, el n√∫mero de eras) se seleccionan peque√±os: el tama√±o del lote - 100, el n√∫mero de eras - 10, los pasos por era - 10; <br><br>  <b>3.</b> 13 capas, un resumen de las capas se muestra en la figura: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/85/of/hn/85ofhnioy_usez2msaeqpt2whja.png" alt="imagen alt"></div><br><div class="spoiler">  <b class="spoiler_title">Descripci√≥n de capa corta</b> <div class="spoiler_text"><ol><li>  input_1: capa de entrada, acepta un tensor bidimensional (representado por una matriz); </li><li>  lambda_1: la capa de usuario, en nuestro caso, hace que el relleno en TF del tensor tenga los mismos valores num√©ricos; </li><li>  incrustaci√≥n_1: crea la incrustaci√≥n (representaci√≥n vectorial) para la secuencia de entrada de datos de texto (convierte el tensor 2-D en 3-D); </li><li>  conv1d_1: capa convolucional 1-D; </li><li>  lstm_2: capa LSTM (va despu√©s de incrustar la capa_1 (No. 3)); </li><li>  lstm_1 - capa LSTM (va despu√©s de la capa conv1d (No. 4)); </li><li>  lambda_2 es ‚Äã‚Äãla capa de usuario donde el tensor se trunca despu√©s de la capa lstm_2 (No. 5) (la operaci√≥n opuesta al relleno en la capa lambda_1 (No. 2)); </li><li>  lambda_3 es la capa de usuario donde el tensor se trunca despu√©s de las capas lstm_1 (No. 6) y conv1d_1 (No. 4) (la operaci√≥n opuesta al relleno en la capa lambda_1 (No. 2)); </li><li>  concatenate_1: uni√≥n de capas truncadas (No. 7) y (No. 8); </li><li>  dense_1: una capa totalmente conectada de 8 neuronas y una funci√≥n de activaci√≥n lineal exponencial "elu"; </li><li>  batch_normalization_1: capa de normalizaci√≥n; </li><li>  dense_2 - capa completamente conectada de 1 neurona y funci√≥n de activaci√≥n sigmoidea "sigmoidea"; </li><li>  lambda_4: una capa de usuario donde se realiza la compresi√≥n de la capa anterior (compresi√≥n en TF). </li></ol></div></div><br>  <b>4.</b> Funci√≥n de p√©rdida - binary_crossentropy <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo>&amp;#x2212;</mo><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>N</mi></mrow><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>N</mi></mrow></msubsup><mo stretchy=&quot;false&quot;>(</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo><mo>+</mo><mo stretchy=&quot;false&quot;>(</mo><mn>1</mn><mo>&amp;#x2212;</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo><mtext>&amp;#xA0;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><mn>1</mn><mo>&amp;#x2212;</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="75.468ex" height="2.901ex" viewBox="0 -883.9 32492.9 1249" role="img" focusable="false" style="vertical-align: -0.848ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6C" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6F" x="298" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-73" x="784" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-73" x="1253" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-3D" x="2000" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-2212" x="3057" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-66" x="4085" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-72" x="4636" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-61" x="5087" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-63" x="5617" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-31" x="6050" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-4E" x="6551" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-73" x="7689" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-75" x="8159" y="0"></use><g transform="translate(8731,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-4E" x="1242" y="488"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-31" x="1242" y="-435"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-28" x="10338" y="0"></use><g transform="translate(10727,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-72" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-75" x="812" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-65" x="1385" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-63" x="12877" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-64" x="13311" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6F" x="13834" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-74" x="14320" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6C" x="14681" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6F" x="14980" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-67" x="15465" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-28" x="15946" y="0"></use><g transform="translate(16335,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-70" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-72" x="503" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-65" x="955" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-64" x="1421" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-29" x="18301" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-2B" x="18913" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-28" x="19914" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-31" x="20303" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-2212" x="21026" y="0"></use><g transform="translate(22027,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-72" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-75" x="812" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-65" x="1385" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-29" x="23927" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-63" x="24566" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-64" x="25000" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6F" x="25523" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-74" x="26009" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6C" x="26370" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6F" x="26669" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-67" x="27154" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-28" x="27635" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-31" x="28024" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-2212" x="28747" y="0"></use><g transform="translate(29748,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-70" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-72" x="503" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-65" x="955" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-64" x="1421" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-29" x="31713" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-29" x="32103" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo>‚àí</mo><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mn>1</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>N</mi></mrow><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class="MJX-TeXAtom-ORD"><mn>1</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>N</mi></mrow></msubsup><mo stretchy="false">(</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mtext>&nbsp;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>‚àí</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mo stretchy="false">)</mo><mtext>&nbsp;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>1</mn><mo>‚àí</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> loss = - \ frac {1} {N} \ sum_ {1} ^ {N} (y_ {true} \ cdot log (y_ {pred}) + (1-y_ {true}) \ cdot log (1- y_ {pred})) </script></p><br><br>  <b>5.</b> M√©trica de calidad del modelo - media arm√≥nica (medida F) <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>F</mi><mo>=</mo><mn>2</mn><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="53.569ex" height="2.419ex" viewBox="0 -780.1 23064.5 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-46" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-3D" x="1027" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-32" x="2083" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-66" x="2834" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-72" x="3384" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-61" x="3836" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-63" x="4365" y="0"></use><g transform="translate(4799,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-50" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-72" x="751" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-65" x="1203" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-63" x="1669" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-69" x="2103" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-73" x="2448" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-69" x="2918" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6F" x="3263" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6E" x="3749" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-74" x="4599" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-69" x="4961" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6D" x="5306" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-65" x="6185" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-73" x="6651" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-52" x="7121" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-65" x="7880" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-63" x="8347" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-61" x="8780" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6C" x="9310" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6C" x="9608" y="0"></use></g><g transform="translate(14706,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-50" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-72" x="751" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-65" x="1203" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-63" x="1669" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-69" x="2103" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-73" x="2448" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-69" x="2918" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6F" x="3263" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6E" x="3749" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMAIN-2B" x="4571" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-52" x="5572" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-65" x="6331" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-63" x="6798" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-61" x="7231" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6C" x="7761" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhi9quqMpo-thM8DeFkVXKzZVDWGXA#MJMATHI-6C" x="8059" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>F</mi><mo>=</mo><mn>2</mn><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mtext>&nbsp;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> F = 2 \ frac {Precision \ times Recall} {Precision + Recall} </script></p><br>  En nuestro caso, el tema de las m√©tricas de calidad no es tan importante como la exactitud de la importaci√≥n.  La exactitud de la importaci√≥n est√° determinada por la coincidencia de los resultados en los modelos NN de Python y Java que funcionan en el modo de inferencia. <br><br><h1>  Importar modelos Keras en DL4J: </h1><br>  Versiones utilizadas: Tensorflow 1.5.0 y Keras 2.2.5.  En nuestro caso, el modelo de Python fue cargado en su conjunto por el archivo HDF5. <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># saving model model1.save('model1_functional.h5')</span></span></code> </pre> <br>  Al importar un modelo en DL4J, el m√≥dulo de importaci√≥n no proporciona m√©todos API para pasar par√°metros adicionales: el nombre del m√≥dulo de tensorflow (desde donde se importaron las funciones al construir el modelo). <br><br>  En t√©rminos generales, DL4J solo funciona con las funciones de Keras, se proporciona una lista exhaustiva en la secci√≥n de importaci√≥n de Keras [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">6</a> ], por lo que si se cre√≥ un modelo en Keras utilizando m√©todos de TF (como en nuestro caso), el m√≥dulo de importaci√≥n no podr√° identificarlos. <br><br><h3>  Pautas generales para importar un modelo </h3><br>  Obviamente, trabajar con el modelo Keras implica su entrenamiento repetido.  Con este fin, para ahorrar tiempo, se establecieron los par√°metros de entrenamiento (1 √©poca) y 1 paso por √©poca (pasos_por_epoca). <br><br>  Cuando importa por primera vez un modelo, en particular con capas personalizadas √∫nicas y combinaciones de capas raras, el √©xito es poco probable.  Por lo tanto, se recomienda llevar a cabo el proceso de importaci√≥n de forma iterativa: reduzca el n√∫mero de capas del modelo Keras hasta que pueda importar y ejecutar el modelo en Java sin errores.  Luego, agregue una capa a la vez al modelo Keras e importe el modelo resultante a Java, resolviendo los errores que ocurren. <br><br><h3>  Uso de la funci√≥n de p√©rdida de TF </h3><br>  Para demostrar que, al importar a Java, la funci√≥n de p√©rdida del modelo entrenado debe ser de Keras, utilizamos log_loss de tensorflow (como la m√°s similar a la funci√≥n custom_loss).  Recibimos el siguiente error en la consola: <br><br><pre> <code class="java hljs">Exception in thread <span class="hljs-string"><span class="hljs-string">"main"</span></span> org.deeplearning4j.nn.modelimport.keras.exceptions.UnsupportedKerasConfigurationException: Unknown Keras loss function log_loss.</code> </pre> <br><h3>  Sustituci√≥n de m√©todos TF con Keras </h3><br>  En nuestro caso, las funciones del m√≥dulo TF se usan 2 veces y en todos los casos se encuentran solo en capas lambda. <br><br>  Las capas Lambda son capas personalizadas que se utilizan para agregar una funci√≥n arbitraria. <br><br>  Nuestro modelo tiene solo 4 capas lambda.  El hecho es que en Java es necesario registrar estas capas lambda manualmente a trav√©s de KerasLayer.registerLambdaLayer (de lo contrario, obtendremos un error [ <a href="">12</a> ]).  En este caso, la funci√≥n definida dentro de la capa lambda deber√≠a ser una funci√≥n de las bibliotecas Java correspondientes.  En Java no hay ejemplos de registro de estas capas, as√≠ como documentaci√≥n exhaustiva para esto;  Un ejemplo est√° aqu√≠ [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">13</a> ].  Consideraciones generales fueron tomadas de los ejemplos [ <a href="">14</a> , <a href="">15</a> ]. <br><br>  Considere secuencialmente registrar todas las capas lambda del modelo en Java: <br><br>  1) Capa Lambda para agregar constantes al tensor (matriz) un n√∫mero finito de veces a lo largo de las direcciones dadas (en nuestro caso, izquierda y derecha): <br><br>  La entrada de esta capa est√° conectada a la entrada del modelo. <br><br>  1.1) Capa de Python: <br><br><pre> <code class="python hljs">padding = keras.layers.Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: tf.pad(x, paddings=[[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>], [<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]], constant_values=<span class="hljs-number"><span class="hljs-number">1</span></span>))(embedding)</code> </pre> <br>  Para mayor claridad, las funciones de esta capa funcionan, sustituimos expl√≠citamente los valores num√©ricos en las capas de Python. <br><br><div class="spoiler">  <b class="spoiler_title">Tabla con un ejemplo de un tensor arbitrario 2x2</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><td>  Fue 2x2 </td><td>  Se ha convertido en 2x22 </td></tr><tr><td>  [[ <strong>1</strong> , <strong>2</strong> ], <br>  [ <strong>3</strong> , <strong>4</strong> ]] </td><td>  [[37, 37, 37, 37, 37, 37, 37, 37, 37, 37, <strong>1</strong> , <strong>2</strong> , 37, 37, 37, 37, 37, 37, 37, 37, 37, 37], <br>  [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, <strong>3</strong> , <strong>4</strong> , 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]] </td></tr></tbody></table></div><br></div></div><br>  1.2) Capa de Java: <br><br><pre> <code class="java hljs">KerasLayer.registerLambdaLayer(<span class="hljs-string"><span class="hljs-string">"lambda_1"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SameDiffLambdaLayer() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> SDVariable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">defineLayer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(SameDiff sameDiff, SDVariable sdVariable)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sameDiff.nn().pad(sdVariable, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[][]{ { <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span> }, { <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span> }}, <span class="hljs-number"><span class="hljs-number">1</span></span>); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> InputType </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutputType</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> layerIndex, InputType inputType)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> InputType.feedForward(<span class="hljs-number"><span class="hljs-number">20</span></span>); } });</code> </pre> <br>  En todas las capas lambda registradas en Java, se redefinen 2 funciones: <br>  La primera funci√≥n "definelayer" es responsable del m√©todo utilizado (en absoluto un hecho obvio: este m√©todo solo se puede utilizar desde el backend nn ());  getOutputType es responsable de la salida de la capa registrada, el argumento es un par√°metro num√©rico (aqu√≠ 20, pero generalmente se permite cualquier valor entero).  Parece inconsistente, pero funciona as√≠. <br><br>  2) Capa Lambda para recortar el tensor (matriz) a lo largo de las direcciones dadas (en nuestro caso, izquierda y derecha): <br><br>  En este caso, la capa LSTM ingresa la entrada de la capa lambda. <br><br>  2.1) Capa de Python: <br><br><pre> <code class="python hljs">slicing_lstm = keras.layers.Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:, <span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">-10</span></span>])(lstm)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Tabla con un ejemplo de un tensor arbitrario 2x22x5</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><td>  Fue 2x22x5 </td><td>  Se ha convertido en 2x2x5 </td></tr><tr><td>  [[[1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1 , 2,3,4,5], [1,2,3,4,5], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [1,2 , 3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3 , 4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4 , 5], [1,2,3,4,5]], <br><br>  [[1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [ 1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1, 2,3,4,5], [1,2,3,4,5], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [1,2, 3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3, 4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4, 5], [1,2,3,4,5]]] </td><td>  [[[ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ]], <br>  [[ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ]]] </td></tr></tbody></table></div><br></div></div><br>  2.2) Capa de Java: <br><br><pre> <code class="java hljs">KerasLayer.registerLambdaLayer(<span class="hljs-string"><span class="hljs-string">"lambda_2"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SameDiffLambdaLayer() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> SDVariable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">defineLayer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(SameDiff sameDiff, SDVariable sdVariable)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sameDiff.stridedSlice(sdVariable, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span> }, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">0</span></span>], (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">1</span></span>], (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">2</span></span>]-<span class="hljs-number"><span class="hljs-number">10</span></span>}, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span> }); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> InputType </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutputType</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> layerIndex, InputType inputType)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> InputType.recurrent(<span class="hljs-number"><span class="hljs-number">60</span></span>); } });</code> </pre> <br>  En el caso de esta capa, el par√°metro InputType cambi√≥ de feedforward (20) a recurrente (60).  En el argumento recurrente, el n√∫mero puede ser cualquier n√∫mero entero (distinto de cero), pero su suma con el argumento recurrente de la siguiente capa lambda debe dar 160 (es decir, en la siguiente capa, el argumento debe ser 100).  El n√∫mero 160 se debe al hecho de que el tensor con la dimensi√≥n (Ninguno, Ninguno, 160) debe recibirse en la entrada concatenada_1 de la capa. <br><br>  Los primeros 2 argumentos son variables, dependiendo del tama√±o de la cadena de entrada. <br><br>  3) Capa Lambda para recortar el tensor (matriz) a lo largo de las direcciones dadas (en nuestro caso, izquierda y derecha): <br><br>  La entrada de esta capa es la capa LSTM, frente a la cual est√° la capa conv1_d <br><br>  3.1) Capa de Python: <br><br><pre> <code class="python hljs">slicing_convolution = keras.layers.Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,<span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">-10</span></span>])(lstm_conv)</code> </pre> <br>  Esta operaci√≥n es completamente id√©ntica a la operaci√≥n en el p√°rrafo 2.1. <br><br>  3.2) capa de Java: <br><br><pre> <code class="java hljs">KerasLayer.registerLambdaLayer(<span class="hljs-string"><span class="hljs-string">"lambda_3"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SameDiffLambdaLayer() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> SDVariable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">defineLayer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(SameDiff sameDiff, SDVariable sdVariable)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sameDiff.stridedSlice(sdVariable, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span> }, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">0</span></span>], (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">1</span></span>], (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">2</span></span>]-<span class="hljs-number"><span class="hljs-number">10</span></span>}, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span> }); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> InputType </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutputType</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> layerIndex, InputType inputType)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> InputType.recurrent(<span class="hljs-number"><span class="hljs-number">100</span></span>); } });</code> </pre> <br>  Esta capa lambda repite la capa lambda anterior con la excepci√≥n del par√°metro recurrente (100).  Por qu√© se toma "100" se observa en la descripci√≥n de la capa anterior. <br><br>  En los puntos 2 y 3, las capas lambda se ubican despu√©s de las capas LSTM, por lo que se utiliza el tipo recurrente.  Pero si antes de la capa lambda no hab√≠a LSTM, sino conv1d_1, entonces todav√≠a es necesario establecer recurrente (parece inconsistente, pero funciona as√≠). <br><br>  4) Capa Lambda para comprimir la capa anterior: <br><br>  La entrada de esta capa es una capa totalmente conectada. <br><br>  4.1) Capa de Python: <br><br><pre> <code class="python hljs"> squeeze = keras.layers.Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: tf.squeeze( x, axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>))(dense)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Tabla con un ejemplo de un tensor arbitrario 2x4x1</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><td>  Fue 2x4x1 </td><td>  Se convirti√≥ en 2x4 </td></tr><tr><td>  [[[ <strong>[1], [2], [3], [4]]</strong> , <br><br>  [ <strong>[1], [2], [3], [4]</strong> ]] </td><td>  [[ <strong>1, 2, 3, 4</strong> ], <br>  [ <strong>1, 2, 3, 4</strong> ]] </td></tr></tbody></table></div><br></div></div><br>  4.2) Capa de Java: <br><br><pre> <code class="java hljs">KerasLayer.registerLambdaLayer(<span class="hljs-string"><span class="hljs-string">"lambda_4"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SameDiffLambdaLayer() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> SDVariable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">defineLayer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(SameDiff sameDiff, SDVariable sdVariable)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sameDiff.squeeze(sdVariable, -<span class="hljs-number"><span class="hljs-number">1</span></span>); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> InputType </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutputType</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> layerIndex, InputType inputType)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> InputType.feedForward(<span class="hljs-number"><span class="hljs-number">15</span></span>); } });</code> </pre> <br>  La entrada de esta capa recibe una capa completamente conectada, InputType para esta capa feedForward (15), el par√°metro 15 no afecta el modelo (se permite cualquier valor entero). <br><br><h3>  Descargar modelo importado </h3><br>  El modelo se carga a trav√©s del m√≥dulo ComputationGraph: <br><br><pre> <code class="java hljs">ComputationGraph model = org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasModelAndWeights(<span class="hljs-string"><span class="hljs-string">"/home/user/Models/model1_functional.h5"</span></span>);</code> </pre> <br><h3>  Salida de datos a la consola Java </h3><br>  En Java, en particular en DL4J, los tensores se escriben como matrices de la biblioteca Nd4j de alto rendimiento, que puede considerarse un an√°logo de la biblioteca Numpy en Python. <br><br>  Digamos que nuestra cadena de entrada consta de 4 caracteres.  Los s√≠mbolos se representan como enteros (como √≠ndices), por ejemplo, de acuerdo con alguna numeraci√≥n.  Se crea una matriz de la dimensi√≥n correspondiente (4) para ellos. <br><br>  Por ejemplo, tenemos 4 caracteres codificados por √≠ndice: 1, 3, 4, 8. <br><br>  C√≥digo en Java: <br><br><pre> <code class="java hljs">INDArray myArray = Nd4j.zeros(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">4</span></span>); <span class="hljs-comment"><span class="hljs-comment">// one row 4 column array myArray.putScalar(0,0,1); myArray.putScalar(0,1,3); myArray.putScalar(0,2,4); myArray.putScalar(0,3,8); INDArray output = model.outputSingle(myArray); System.out.println(output);</span></span></code> </pre> <br>  La consola mostrar√° las probabilidades para cada elemento de entrada. <br><br><h3>  Modelos importados </h3><br>  La arquitectura de la red neuronal original y los pesos se importan sin errores.  Tanto los modelos de red neuronal Keras como Java en modo de inferencia est√°n de acuerdo con los resultados. <br><br>  Modelo de Python: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/om/sk/oe/omskoecug43s_gop5osadysm21m.png" alt="imagen alt"></div><br>  Modelo Java: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/es/qc/px/esqcpxwnhjdgrhqapedjukmvfec.png" alt="imagen alt"></div><br>  En realidad, importar modelos no es tan simple.  A continuaci√≥n destacaremos brevemente algunos puntos que en algunos casos pueden ser cr√≠ticos. <br><br>  1) La capa de normalizaci√≥n del parche no funciona despu√©s de las capas recursivas.  El problema ha estado abierto en GitHub durante casi un a√±o [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">16</a> ].  Por ejemplo, si agrega esta capa al modelo (despu√©s de la capa de contacto), obtenemos el siguiente error: <br><br><pre> <code class="java hljs">Exception in thread <span class="hljs-string"><span class="hljs-string">"main"</span></span> java.lang.IllegalStateException: Invalid input type: Batch norm layer expected input of type CNN, CNN Flat or FF, <span class="hljs-function"><span class="hljs-function">got </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">InputTypeRecurrent</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">160</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">for</span></span></span><span class="hljs-function"> layer index -1, layer name </span></span>= batch_normalization_1</code> </pre> <br>  En la pr√°ctica, el modelo se neg√≥ a funcionar, citando un error similar cuando se agreg√≥ la capa de normalizaci√≥n despu√©s de conve1d.  Despu√©s de una capa totalmente conectada, la adici√≥n funciona a la perfecci√≥n. <br><br>  2) Despu√©s de una capa completamente conectada, al configurar la capa Flatten se produce un error.  Un error similar se menciona en Stackoverflow [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://stackoverflow.com/questions/55753493/problem-opening-a-keras-model-in-java-with-deeplearning4j-">17</a> ].  Durante seis meses, no hay comentarios. <br><br>  Definitivamente, estas no son todas las restricciones que puede encontrar al trabajar con DL4J. <br>  El tiempo de funcionamiento final del modelo est√° aqu√≠ [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">18</a> ]. <br><br><h1>  Conclusi√≥n </h1><br>  En conclusi√≥n, se puede observar que los modelos Keras entrenados importados sin dolor en DL4J solo pueden ser para casos simples (por supuesto, si no tiene esa experiencia y, de hecho, un buen dominio de Java). <br><br>  Cuantas menos capas de usuario, m√°s f√°cil ser√° importar el modelo, pero si la arquitectura de la red es compleja, tendr√° que pasar mucho tiempo transfiri√©ndola a DL4J. <br><br>  El soporte documental del m√≥dulo de importaci√≥n desarrollado, el n√∫mero de ejemplos relacionados, parec√≠a bastante h√∫medo.  En cada etapa, surgen nuevas preguntas: c√≥mo registrar las capas de Lambda, el significado de los par√°metros, etc. <br><br>  Dada la velocidad de la complejidad de las arquitecturas de redes neuronales y la interacci√≥n entre capas, la complejidad de las capas, DL4J a√∫n no se ha desarrollado activamente para alcanzar el nivel de los marcos de gama alta para trabajar con redes neuronales artificiales. <br><br>  En cualquier caso, los muchachos son dignos de respeto por su trabajo y me gustar√≠a ver que el desarrollo de esta √°rea contin√∫e. <br><br>  <strong>Referencias</strong> <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Los 5 mejores lenguajes de programaci√≥n para el campo de la inteligencia artificial</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Deep Learning Framework Power Scores 2018</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Comparaci√≥n de software de aprendizaje profundo</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Los 9 marcos principales en el mundo de la inteligencia artificial</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aprendizaje profundo 4j.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Modelos disponibles</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aprendizaje profundo 4j.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Importaci√≥n del modelo Keras.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Funciones compatibles</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Deeplearning4j.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Inicio r√°pido</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lecci√≥n 0: Comenzando con DeepLearning4j</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Deeplearing4j: importaci√≥n del modelo Keras</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Conferencia 7 |</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Importar modelo Keras</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Instalar TensorFlow para Java</a> </li><li>  <a href="">Usando capas de Keras</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">DeepLearning4j: Clase KerasLayer</a> </li><li>  <a href="">DeepLearning4j: SameDiffLambdaLayer.java</a> </li><li>  <a href="">DeepLearning4j: KerasLambdaTest.java</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">DeepLearning4j: BatchNorm con RecurrentInputType</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://stackoverflow.com/questions/55753493/problem-opening-a-keras-model-in-java-with-deeplearning4j-">StackOverFlow: Problema al abrir un modelo de Keras en Java con deeplearning4j (https://deeplearning4j.org/)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GitHub: c√≥digo completo para el modelo en cuesti√≥n</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Skymind: Comparaci√≥n de marcos de AI</a> </li></ol><br></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/475338/">https://habr.com/ru/post/475338/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../475324/index.html">Programaci√≥n funcional desde el punto de vista de EcmaScript. Composici√≥n, Curry, Aplicaci√≥n Parcial</a></li>
<li><a href="../475326/index.html">C√≥mo los estafadores hacen esto. Herramientas de enga√±o</a></li>
<li><a href="../475328/index.html">Operaci√≥n TA505, cuarta parte. Gemelos</a></li>
<li><a href="../475330/index.html">Concurso de complementos de la plataforma Miro con un premio de $ 21,000</a></li>
<li><a href="../475336/index.html">C√≥mo dejar de fumar correctamente (instrucci√≥n)</a></li>
<li><a href="../475342/index.html">Andrey Sebrant (Yandex): negocios en la era de la inteligencia artificial</a></li>
<li><a href="../475346/index.html">Mientras el ej√©rcito de los Estados Unidos trata de leer las mentes</a></li>
<li><a href="../475354/index.html">Feliz d√≠a del especialista en seguridad</a></li>
<li><a href="../475358/index.html">An√°lisis salarial en el sector de TI de Armenia m√°s vacantes abiertas en las empresas de TI TOP10</a></li>
<li><a href="../475366/index.html">Droidcon London 2019: nuevas tendencias y los informes m√°s interesantes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨‍🏭 ✈️ 👷 Cluster Kubernetes dalam layanan VPC 👉🏾 🥪 🐳</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kami telah menambahkan kemampuan untuk meluncurkan Kubernetes dengan nyaman di layanan Virtual Private Cloud dalam mode pengujian beta awal. 


 Fungs...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cluster Kubernetes dalam layanan VPC</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/416951/"><img src="https://habrastorage.org/webt/bc/b6/cy/bcb6cykv49fwewsnhfr-7ny-0uc.png"><br><p><br>  Kami telah menambahkan kemampuan untuk meluncurkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener noreferrer">Kubernetes</a> dengan nyaman di layanan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener noreferrer">Virtual Private Cloud</a> dalam mode pengujian beta awal. </p><br><p>  Fungsionalitas ini akan berguna bagi pengguna yang membutuhkan manajemen yang mudah dari sejumlah besar aplikasi yang berjalan sebagai wadah.  Kubernetes menawarkan alat untuk penskalaan, penyembuhan sendiri, penyeimbangan beban untuk kontainer yang berjalan di dalam sebuah cluster. </p><br><p>  Karena layanan <strong>Virtual Private Cloud</strong> didasarkan pada OpenStack, kami menggunakan salah satu komponennya - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener noreferrer">OpenStack Magnum</a> .  Hal ini memungkinkan Anda untuk dengan cepat membuat cluster Kubernetes pribadi dengan jumlah node yang diinginkan. </p><br><p>  Saat ini, setiap pengguna layanan kami dapat membuat beberapa cluster independen dalam proyek mereka.  Sebagai node cluster, mesin virtual akan digunakan, konfigurasi yang dapat dipilih dan diubah. </p><br><p>  Pada artikel ini, kita akan berbicara tentang objek utama dari cluster Kubernetes dan menggunakan contoh-contoh untuk melihat proses membuat sebuah cluster menggunakan OpenStack Magnum. </p><a name="habracut"></a><br><h2>  Buat dan kelola kluster Kubernetes </h2><br><p>  Saat ini, pembuatan cluster Kubernetes hanya dimungkinkan melalui utilitas konsol atau <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener noreferrer">API OpenStack</a> di zona ketersediaan <strong>ru-1a</strong> dan <strong>ru-1b</strong> (St. Petersburg). </p><br><p>  Untuk memulai, Anda perlu: </p><br><ul><li>  Buat yang baru atau gunakan proyek <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener noreferrer">VPC yang</a> ada; </li><li>  Buat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener noreferrer">pengguna dengan kunci SSH</a> ; </li><li>  Tambahkan pengguna ke proyek yang dibuat pada halaman <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener noreferrer">manajemen</a> proyek; </li><li>  Pergi ke proyek dan dapatkan file akses pada tab <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener noreferrer">Access</a> ; </li><li>  Instal klien konsol <strong>openstack</strong> dengan <strong>pustaka python-magnumclient</strong> ; </li><li>  Instal klien konsol <strong>kubectl</strong> . </li></ul><br><p>  Untuk menginstal klien konsol <strong>openstack</strong> , <strong>Anda</strong> dapat menggunakan petunjuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener noreferrer">pada tautan</a> , namun, harus diingat bahwa untuk klien ini Anda juga perlu menginstal pustaka <strong>python-magnumclient</strong> untuk mendukung pembuatan kluster Kubernetes. </p><br><p>  Seperangkat perintah lengkap untuk menginstal klien openstack dengan plug-in yang diperlukan untuk sistem operasi keluarga Ubuntu / Debian: </p><br><pre><code class="bash hljs">$ sudo apt update $ sudo apt -y install curl python-pip python-dev python3-dev git libxml2-dev libxslt1-dev python-openssl python3-openssl python-pyasn1 libffi-dev libssl-dev build-essential $ sudo pip install -UI pbr setuptools pytz $ sudo pip install -UI git+https://github.com/openstack/python-openstackclient $ sudo pip install -UI git+https://github.com/openstack/python-magnumclient</code> </pre> <br><p>  Seperangkat perintah lengkap untuk menginstal klien openstack dengan plug-in yang diperlukan untuk sistem operasi keluarga Fedora / CentOS: </p><br><pre> <code class="bash hljs">$ sudo yum -y install python-pip gcc libffi-devel python-devel libxslt-devel openssl-devel git libffi-devel $ sudo pip install -UI pbr setuptools pytz $ sudo pip install -UI git+https://github.com/openstack/python-openstackclient $ sudo pip install -UI git+https://github.com/openstack/python-magnumclient</code> </pre> <br><p>  Untuk mengelola objek Kubernetes, Anda memerlukan klien konsol <strong>kubectl</strong> .  Metode pemasangan untuk berbagai sistem operasi dijelaskan dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener noreferrer">dokumentasi resmi</a> . </p><br><p>  Untuk membuat cluster, Anda harus membuat atau menggunakan yang sudah ada: </p><br><ul><li>  <strong>Templat</strong> klaster; </li><li>  Seperangkat parameter untuk CPU dan RAM mesin virtual ( <strong>rasa</strong> ). </li></ul><br><p>  Anda bisa membuat templat klaster dan menambahkan rasa sendiri, atau menggunakan templat publik yang dibuat sebelumnya. </p><br><p>  Anda juga perlu menentukan zona ketersediaan, jenis disk untuk kluster Anda, dan jumlah node.  Perlu mempertimbangkan bahwa di kita belum mendukung kemungkinan membuat satu cluster di beberapa zona.  Anda dapat memilih semua jenis drive jaringan (cepat, universal atau dasar). <br>  Anda dapat mempelajari lebih lanjut tentang jenis drive dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener noreferrer">basis pengetahuan</a> kami. </p><br><p>  Jumlah node dapat berbeda untuk peran <strong>master</strong> dan untuk <strong>minion</strong> .  Pada node yang menjalankan peran utama, elemen kontrol kluster akan diluncurkan - <strong>controller-manager</strong> , <strong>scheduler</strong> , <strong>api</strong> .  Di node lain, <strong>kubelet</strong> , layanan <strong>proxy kubus</strong> dan semua wadah aplikasi akan diluncurkan.  Anda dapat mempelajari lebih lanjut tentang komponen yang berjalan di node cluster dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener noreferrer">dokumentasi resmi</a> . </p><br><p>  Untuk mengakses node melalui SSH, Anda harus menggunakan kunci SSH yang dibuat sebelumnya.  Perintah sampel akan menggunakan kunci yang disebut <strong>uji ssh</strong> . </p><br><p>  Kami akan menggunakan templat dan citarasa gugusan publik, jenis cakram cepat, dan zona ketersediaan <strong>ru-1b</strong> . <br>  Di cluster kami, 2 node master dan 3 node minion awalnya akan diluncurkan. </p><br><p>  Untuk memverifikasi parameter ini, kami menggunakan perintah openstackclient dan file akses yang diunduh ( <strong>rc.sh</strong> ): </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#          . $ source rc.sh #  ,         $ openstack flavor show BL1.2-4096 -c ram -c vcpus +-------+-------+ | Field | Value | +-------+-------+ | ram | 4096 | | vcpus | 2 | +-------+-------+ #       ru-1b $ openstack volume type show fast.ru-1b -c name +-------+------------+ | Field | Value | +-------+------------+ | name | fast.ru-1b | +-------+------------+ #    Kubernetes $ openstack coe cluster template list -c name +---------------------------------------+ | name | +---------------------------------------+ | kubernetes-nofloatingips-ru-1b-v1.9.3 | | kubernetes-nofloatingips-ru-1b-v1.9.6 | | kubernetes-nofloatingips-ru-1b-v1.9.9 | | kubernetes-floatingips-ru-1b-v1.9.3 | | kubernetes-floatingips-ru-1b-v1.9.6 | | kubernetes-floatingips-ru-1b-v1.9.9 | | kubernetes-nofloatingips-ru-1a-v1.9.3 | | kubernetes-nofloatingips-ru-1a-v1.9.6 | | kubernetes-nofloatingips-ru-1a-v1.9.9 | | kubernetes-floatingips-ru-1a-v1.9.3 | | kubernetes-floatingips-ru-1a-v1.9.6 | | kubernetes-floatingips-ru-1a-v1.9.9 | +---------------------------------------+</span></span></code> </pre> <br><p>  Sebagai contoh, kita akan memilih templat klaster kedua, alamat apung yang dapat diakses publik untuk masing-masing simpul tidak akan dibuat darinya.  Kami tidak akan membutuhkannya. </p><br><pre> <code class="plaintext hljs">#   Kubernetes   test-cluster #   keypair   ,   $ openstack coe cluster create \ --cluster-template kubernetes-nofloatingips-ru-1b-v1.9.9 \ --master-count 2 \ --node-count 3 \ --keypair ssh-test \ --master-flavor BL1.2-4096 \ --flavor BL1.2-4096 \ test-cluster</code> </pre> <br><p>  <em>Harap dicatat bahwa kami telah memilih konfigurasi yang sama untuk node yang berbeda (parameter master-flavour dan flavour), Anda dapat memilih set konfigurasi yang berbeda tergantung pada persyaratan cluster.</em>  <em>Perubahan mereka mungkin setelah penciptaannya.</em> </p><br><p>  Juga patut dipertimbangkan bahwa ketika membuat sebuah cluster dengan beberapa node master, penyeimbang beban akan secara otomatis dibuat untuk mengakses API Kubernetes. </p><br><p>  Setelah beberapa menit, kluster Kubernetes akan muncul di proyek Anda.  Di panel kontrol proyek, Anda akan melihat mesin virtual, disk, dan objek jaringan. </p><br><p>  Anda dapat memeriksa status cluster Anda melalui openstackclient: </p><br><pre> <code class="bash hljs">openstack coe cluster list -c name -c status +--------------+--------------------+ | name | status | +--------------+--------------------+ | <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster | CREATE_IN_PROGRESS | +--------------+--------------------+</code> </pre> <br><p>  Setelah cluster memasuki status CREATE_COMPLETE, Anda dapat mengelola objeknya melalui utilitas kubectl dengan mengunduh file konfigurasi menggunakan perintah berikut: </p><br><pre> <code class="bash hljs">$ mkdir -p ~/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster $ openstack coe cluster config <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster --dir ~/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster</code> </pre> <br><p>  Setelah itu, Anda bisa bekerja dengan cluster menggunakan utilitas kubectl: </p><br><pre> <code class="bash hljs">$ <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> KUBECONFIG=~/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster/config $ kubectl get pods --all-namespaces -o=custom-columns=NAME:.metadata.name,STATUS:.status.phase NAME STATUS coredns-785dcf9c58-6gnfp Running heapster-6846cdc674-rm4k6 Running kube-dns-autoscaler-6b94f7bbf8-x5clt Running kubernetes-dashboard-747575c864-wlg6p Running monitoring-grafana-84b4596dd7-zf5rx Running monitoring-influxdb-c8486fc95-bqqb6 Running node-exporter-test-cluster-robvp4cvwpt7-minion-0 Running</code> </pre> <br><p>  Jika perlu, Anda bisa menambah atau mengurangi jumlah node minion di cluster melalui openstackclient dengan meneruskan nilai node_count baru: </p><br><pre> <code class="bash hljs">$ openstack coe cluster update <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster replace node_count=4</code> </pre> <br><h2>  Objek Cluster Kubernet Kunci </h2><br><h3>  Polong </h3><br><p>  Meskipun Kubernetes mengelola satu set wadah, entitas dasar yang dikelola Kubernetes bukanlah wadah, melainkan <strong>Pod</strong> . </p><br><p>  Pod adalah seperangkat ruang nama kernel Linux dan pengaturan tumpukan jaringan yang memungkinkan Anda untuk merakit satu set wadah menjadi satu kesatuan. <br>  Lebih sering daripada tidak, satu wadah dengan aplikasi diluncurkan di dalam satu Pod terpisah. <br>  Jika perlu, Anda dapat menjalankan beberapa kontainer di dalam satu Pod, ini dapat berguna ketika Anda perlu memberikan akses dari satu kontainer ke yang lain melalui antarmuka jaringan localhost, atau karena alasan lain jalankan beberapa kontainer pada host yang sama. <br>  Semua kontainer yang berjalan di Pod yang sama akan memiliki satu nama host, alamat IP, tabel perutean dan disk. </p><br><p>  Perlu dicatat bahwa ketika melakukan penskalaan jumlah instance aplikasi Anda di dalam Kubernetes, Anda perlu menambah jumlah Pod, dan bukan jumlah kontainer dalam satu Pod tertentu. <br>  Lebih detail dalam dokumentasi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener noreferrer">Pods</a> resmi. </p><br><p>  Sebagai contoh, mari kita buat Pod paling sederhana dengan Nginx menggunakan deskripsi dalam format yaml: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-basic.yaml apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80</span></span></code> </pre> <br><p>  Untuk membuat Pod, kita bisa menggunakan utilitas <strong>kubectl</strong> . <br>  Kami menambahkan semua contoh yang disajikan dalam artikel ke <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener noreferrer">grup Github</a> kami, sehingga Anda tidak dapat membuat file di komputer Anda, tetapi menggunakan url file dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener noreferrer">repositori</a> publik: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/pods/nginx-basic.yaml</code> </pre> <br><p>  Setelah pembuatan, kami dapat meminta informasi lengkap tentang status Pod menggunakan perintah uraian kubectl: </p><br><pre> <code class="bash hljs">$ kubectl describe pod nginx Name: nginx Namespace: default Node: <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0/10.0.0.5 Start Time: Sun, 17 Jun 2018 12:29:03 +0000 Labels: &lt;none&gt; Annotations: &lt;none&gt; Status: Running IP: 10.100.88.9 Containers: nginx: Container ID: docker://6ca6383b66686c05c61c1f690737110e0f8994eda393f44a7ebfbbf2b2026267 Image: library/nginx:1.14-alpine Image ID: docker-pullable://docker.io/nginx@sha256:944b79ca7dbe456ce72e73e70816c1990e39967c8f010349a388c00b77ec519c Port: 80/TCP Host Port: 0/TCP State: Running Started: Sun, 17 Jun 2018 12:29:16 +0000 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-rp5ls (ro) Conditions: Type Status Initialized True Ready True PodScheduled True Volumes: default-token-rp5ls: Type: Secret (a volume populated by a Secret) SecretName: default-token-rp5ls Optional: <span class="hljs-literal"><span class="hljs-literal">false</span></span> QoS Class: BestEffort Node-Selectors: &lt;none&gt; Tolerations: &lt;none&gt; Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 52s default-scheduler Successfully assigned nginx to <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Normal SuccessfulMountVolume 51s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 MountVolume.SetUp succeeded <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> volume <span class="hljs-string"><span class="hljs-string">"default-token-rp5ls"</span></span> Normal Pulling 50s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 pulling image <span class="hljs-string"><span class="hljs-string">"library/nginx:1.14-alpine"</span></span> Normal Pulled 39s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Successfully pulled image <span class="hljs-string"><span class="hljs-string">"library/nginx:1.14-alpine"</span></span> Normal Created 39s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Created container Normal Started 39s kubelet, <span class="hljs-built_in"><span class="hljs-built_in">test</span></span>-cluster-nd5c5y6lsfxb-minion-0 Started container</code> </pre> <br><p>  Seperti yang Anda lihat, Pod dimulai pada node bernama test-cluster-nd5c5y6lsfxb-minion-0 dan menerima alamat IP internal 10.100.88.9. </p><br><p>  Dari bagian Acara, Anda dapat melihat acara peluncuran utama - memilih simpul untuk meluncurkan dan mengunduh gambar. </p><br><p>  Kita dapat masuk ke Pod dan memeriksa status proses di dalam wadah: </p><br><pre> <code class="bash hljs">$ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> -it nginx sh ps aux PID USER TIME COMMAND 1 root 0:00 nginx: master process nginx -g daemon off; 7 nginx 0:00 nginx: worker process 20 root 0:00 sh 24 root 0:00 ps aux <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> <br><p>  Harus diingat bahwa alamat IP 10.100.88.9 tidak akan tersedia untuk aplikasi lain di dalam dan di luar kelompok Kubernetes, akses ke Nginx yang sedang berjalan hanya akan dimungkinkan dari dalam Pod itu sendiri: </p><br><pre> <code class="bash hljs">$ ping -c 1 10.100.88.9 PING 10.100.88.9 (10.100.88.9): 56 data bytes --- 10.100.88.9 ping statistics --- 1 packets transmitted, 0 packets received, 100% packet loss $ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> nginx -- ping -c1 10.100.88.9 PING 10.100.88.9 (10.100.88.9): 56 data bytes 64 bytes from 10.100.88.9: seq=0 ttl=64 time=0.075 ms --- 10.100.88.9 ping statistics --- 1 packets transmitted, 1 packets received, 0% packet loss round-trip min/avg/max = 0.075/0.075/0.075 ms</code> </pre> <br><p>  Selain fakta bahwa alamat IP yang ditentukan hanya dapat diakses dari wadah, itu juga tidak permanen.  Ini berarti bahwa jika Pod ini dibuat ulang, ia bisa mendapatkan alamat IP yang berbeda. </p><br><p>  Untuk mengatasi masalah ini, Anda dapat menggunakan objek yang disebut Layanan. </p><br><h3>  Layanan </h3><br><p>  Layanan memungkinkan Anda untuk menetapkan alamat IP permanen untuk Pods, menyediakannya akses dari jaringan eksternal dan menyeimbangkan permintaan antara Pods. <br>  Anda dapat mempelajari lebih lanjut tentang Layanan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener noreferrer">dokumentasi resmi</a> . </p><br><p>  Misalnya, kita perlu menghapus Pod yang sedang berjalan: </p><br><pre> <code class="bash hljs">$ kubectl delete pod nginx</code> </pre> <br><p>  Tambahkan ke deskripsi label Pod a (Label), yang diperlukan untuk Layanan: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-labeled.yaml apiVersion: v1 kind: Pod metadata: name: nginx labels: app: webservice spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80</span></span></code> </pre> <br><p>  Kami juga akan memerlukan deskripsi Layanan: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-nodeport.yaml apiVersion: v1 kind: Service metadata: name: nginx-nodeport labels: app: webservice spec: type: NodePort ports: - port: 80 nodePort: 30001 protocol: TCP selector: app: webservice</span></span></code> </pre> <br><p>  Buat Pod dan Layanan: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/pods/nginx-labeled.yaml \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/services/nginx-nodeport.yaml</code> </pre> <br><p>  Karena Layanan yang dibuat adalah tipe NodePort, maka port 30001 yang ditunjukkan oleh kami pada semua antarmuka jaringan akan dibuka pada semua node cluster. <br>  Ini berarti bahwa jika kita menambahkan alamat IP eksternal ke sembarang simpul, kita dapat mengakses Pod yang sedang berjalan dengan Nginx dari jaringan eksternal. </p><br><p>  Agar tidak menggunakan alamat eksternal node cluster untuk mengakses Layanan, kita bisa menggunakan tipe LoadBalancer alih-alih NodePort. <br>  Kami akan membutuhkan deskripsi layanan yang baru: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-loadbalancer.yaml apiVersion: v1 kind: Service metadata: name: nginx-loadbalancer labels: app: webservice spec: type: LoadBalancer ports: - port: 80 protocol: TCP selector: app: webservice</span></span></code> </pre> <br><p>  Hapus layanan saat ini dan terapkan deskripsi baru: </p><br><pre> <code class="bash hljs">$ kubectl delete service nginx-service $ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/services/nginx-loadbalancer.yaml</code> </pre> <br><p>  Setelah memulai layanan, Nginx akan tersedia pada port TCP 80 dari jaringan eksternal, dan tidak perlu untuk menetapkan dan menggunakan alamat eksternal untuk node cluster.  Layanan tipe LoadBalancer akan secara otomatis mengalokasikan alamat eksternal baru untuk proyek VPC Anda dan mulai menggunakannya. </p><br><p>  Anda bisa mendapatkan informasi tentang alamat eksternal yang disorot menggunakan kubectl: </p><br><pre> <code class="bash hljs">$ kubectl get service nginx-service -o=custom-columns=IP:status.loadBalancer.ingress[0].ip IP xxx.xxx.xxx.xxx</code> </pre> <br><p>  Dalam contoh kami, hanya satu Pod yang diluncurkan dengan Nginx.  Untuk mengatur skala aplikasi ke lebih banyak Pod, kita bisa menggunakan Penempatan. </p><br><h3>  Penugasan </h3><br><p>  Penempatan adalah inti dari kluster Kubernetes, yang memungkinkan Anda untuk menskala Pods dan dengan mudah memperbarui atau memutar kembali versi untuk sejumlah besar Pods. <br>  Alih-alih Penerapan, Anda juga dapat menggunakan objek ReplicaSet, tetapi kami tidak akan menyentuhnya dalam contoh kami. <br>  Anda dapat mempelajari lebih lanjut tentang Penerapan dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener noreferrer">dokumentasi resmi</a> . </p><br><p>  Kami lagi perlu menghapus Pod (kami tidak perlu menghapus Layanan): </p><br><pre> <code class="bash hljs">$ kubectl delete pod nginx</code> </pre> <br><p>  Tambahkan deskripsi Penerapan berikut: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-1.14.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 10 selector: matchLabels: app: webservice minReadySeconds: 10 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 maxSurge: 1 template: metadata: labels: app: webservice spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80</span></span></code> </pre> <br><p>  Buat Penempatan yang ditentukan: </p><br><pre> <code class="bash hljs">$ kubectl create -f \ https://raw.githubusercontent.com/selectel/kubernetes-examples/master/deployments/nginx-1.14.yaml</code> </pre> <br><p>  Kami memilih 10 untuk parameter replika, jadi 10 Pods dengan aplikasi Nginx akan dibuat di cluster kami: </p><br><pre> <code class="bash hljs">$ kubectl get pods --selector app=webservice NAME READY STATUS RESTARTS AGE nginx-deployment-54bfdc4489-42rrb 1/1 Running 0 4m nginx-deployment-54bfdc4489-5lvtc 1/1 Running 0 4m nginx-deployment-54bfdc4489-g7rk2 1/1 Running 0 4m nginx-deployment-54bfdc4489-h5rxp 1/1 Running 0 4m nginx-deployment-54bfdc4489-l9l2d 1/1 Running 0 4m nginx-deployment-54bfdc4489-pjpvg 1/1 Running 0 4m nginx-deployment-54bfdc4489-q8dnp 1/1 Running 0 4m nginx-deployment-54bfdc4489-s4wzf 1/1 Running 0 4m nginx-deployment-54bfdc4489-tfxf9 1/1 Running 0 4m nginx-deployment-54bfdc4489-xjzb5 1/1 Running 0 4m</code> </pre> <br><p>  Anda dapat mengakses aplikasi yang sedang berjalan dari jaringan eksternal menggunakan Layanan yang dibuat di bagian sebelumnya.  Layanan akan secara otomatis menyeimbangkan permintaan dari jaringan eksternal antara 10 instance Nginx. </p><br><p>  Jika perlu, kami dapat memperbarui versi Nginx.  Perbarui deskripsi Penerapan dengan mengubah versi gambar dari 1,14-alpine ke 1,15-alpine: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-1.15.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 10 selector: matchLabels: app: webservice minReadySeconds: 10 strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 1 maxSurge: 1 template: metadata: labels: app: webservice spec: containers: - name: nginx image: library/nginx:1.15-alpine # &lt;-- changed ports: - containerPort: 80</span></span></code> </pre> <br><p>  Untuk memulai proses memperbarui Pod, kami menggunakan perintah kubectl.  Perhatikan argumen --record, ini berguna bagi kita untuk kemunduran nyaman berikutnya dari versi Nginx: </p><br><pre> <code class="bash hljs">$ kubectl apply -f \ https://raw.githubusercontent.com/selectel/kubernetes-examples/master/deployments/nginx-1.15.yaml \ --record</code> </pre> <br><p>  Anda dapat memantau kemajuan pembaruan menggunakan perintah berikut: </p><br><pre> <code class="bash hljs">$ kubectl rollout status deployment nginx-deployment Waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> rollout to finish: 4 out of 10 new replicas have been updated...</code> </pre> <br><p>  Kubernetes akan menunggu 10 detik setelah pembaruan yang berhasil dari satu Pod, karena kami menetapkan nilai 10 untuk parameter minReadySeconds dalam deskripsi Penerapan. </p><br><p>  Setelah pembaruan selesai, semua Pods for Deployment akan masuk ke status aktif: </p><br><pre> <code class="bash hljs">$ kubectl get deployment --selector app=webservice NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 10 10 10 10 23m</code> </pre> <br><p>  Kita dapat memutar kembali versi aplikasi jika terjadi kesalahan.  Untuk melakukan ini, kita perlu memilih revisi Penempatan yang diinginkan: </p><br><pre> <code class="bash hljs">$ kubectl rollout <span class="hljs-built_in"><span class="hljs-built_in">history</span></span> deployment nginx-deployment deployments <span class="hljs-string"><span class="hljs-string">"nginx-deployment"</span></span> REVISION CHANGE-CAUSE 1 &lt;none&gt; 2 kubectl apply --filename=https://raw.githubusercontent.com/selectel/kubernetes-examples/master/deployments/nginx-1.15.yaml --record=<span class="hljs-literal"><span class="hljs-literal">true</span></span></code> </pre> <br><p>  Ada 2 revisi dalam output perintah - yang pertama adalah penciptaan Penerapan asli, yang kedua adalah pembaruan.  Karena kami menggunakan argumen --record saat memperbarui, kami melihat perintah yang membuat revisi kedua Penerapan. </p><br><p>  Untuk memutar kembali versi, gunakan perintah berikut: </p><br><pre> <code class="bash hljs">$ kubectl rollout undo deployment nginx-deployment --to-revision=1</code> </pre> <br><p>  Demikian pula dengan pembaruan, kita dapat memantau kemunduran versi menggunakan perintah: </p><br><pre> <code class="bash hljs">$ kubectl rollout status deployment nginx-deployment Waiting <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> rollout to finish: 6 out of 10 new replicas have been updated…</code> </pre> <br><p>  Dalam semua contoh kami, kami menggunakan wadah tanpa penyimpanan data yang persisten.  Di bagian selanjutnya kita akan memperbaikinya. </p><br><h2>  Penyimpanan data </h2><br><p>  Secara default, semua data dari kontainer yang berjalan di dalam Pods bersifat sementara dan akan hilang ketika Pods crash. </p><br><p>  Anda bisa menggunakan objek PersistentVolumeClaim untuk menjalankan Pods dengan gudang data yang persisten. </p><br><p>  Membuat objek seperti itu di cluster sangat sederhana - cukup tambahkan deskripsinya, mirip dengan cara kami membuat Pod, Layanan, atau Penempatan di bagian sebelumnya. </p><br><p>  Informasi lebih lanjut dapat ditemukan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener noreferrer">dokumentasi resmi</a> . </p><br><p>  Contoh deskripsi PersistentVolumeClaim membuat disk 10GB: </p><br><pre> <code class="bash hljs">apiVersion: v1 kind: PersistentVolumeClaim metadata: name: my-pv-claim spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi</code> </pre> <br><p>  Kita dapat menghubungkannya sebagai disk ke Pod kami dengan memperbarui deskripsi Pod dengan Nginx yang dibuat sebelumnya: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># nginx-with-volume.yaml apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: library/nginx:1.14-alpine ports: - containerPort: 80 volumeMounts: - mountPath: "/var/www/html" name: data volumes: - name: data persistentVolumeClaim: claimName: my-pv-claim</span></span></code> </pre> <br><p>  Namun, agar disk dapat dibuat, Anda harus menentukan properti disk yang dibuat dalam bentuk StorageClass.  Dalam layanan "Virtual Private Cloud", Anda dapat menggunakan drive jaringan tipe cepat, universal, dan dasar sebagai penyimpanan permanen data Pod Kubernetes. </p><br><p>  Misalnya, untuk membuat StorageClass yang memungkinkan Anda untuk menggunakan disk cepat di zona ketersediaan ru-1b, Anda memerlukan deskripsi berikut: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># fast.ru-1b.yaml kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: fast.ru-1b annotations: storageclass.beta.kubernetes.io/is-default-class: "true" provisioner: kubernetes.io/cinder parameters: type: fast.ru-1b availability: ru-1b</span></span></code> </pre> <br><p>  Sebelum membuat objek yang ditentukan, hapus Penempatan yang dibuat sebelumnya: </p><br><pre> <code class="bash hljs">$ kubectl delete deployment nginx-deployment</code> </pre> <br><p>  Pertama-tama, mari kita buat StorageClass, jadi itu akan menjadi kelas default, dan PersistentVolumeClaim yang dibuat nanti akan menggunakannya: </p><br><pre> <code class="bash hljs">$ kubectl create -f \ https://raw.githubusercontent.com/selectel/kubernetes-examples/master/storageclasses/fast.ru-1b.yaml</code> </pre> <br><p>  Buat PersistentVolumeClaim dan Pod: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/persistentvolumeclaims/my-pv-claim.yaml \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/pods/nginx-with-volume.yaml</code> </pre> <br><p>  Setelah itu, disk akan secara otomatis dibuat di proyek Anda yang akan terhubung ke salah satu node minion dari cluster.  Ketika jatuh, disk akan secara otomatis beralih ke node lain. </p><br><p>  Kita dapat melihat disk di dalam wadah dengan Nginx: </p><br><pre> <code class="bash hljs">$ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> -it nginx sh mount | grep <span class="hljs-string"><span class="hljs-string">"/var/www/html"</span></span> /dev/sdc on /var/www/html <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> ext4 (rw,seclabel,relatime,data=ordered) <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> <br><p>  Anda dapat menghubungkan drive ke Deployment.  Contoh yang sesuai dapat ditemukan dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener noreferrer">dokumentasi resmi</a> . </p><br><h2>  Panel Kontrol Kubernetes </h2><br><p>  Anda bisa menggunakan dasbor bawaan Kubernetes itu sendiri untuk melihat status objek cluster dan manajemennya. </p><br><p>  Untuk mengakses semua fitur panel, Anda harus membuat akun dengan peran administrator di cluster Anda. </p><br><p>  Untuk melakukan ini, kami memerlukan deskripsi akun: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># admin-user.yaml apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kube-system</span></span></code> </pre> <br><p>  Dan deskripsi peran: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># cluster-admin.yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kube-system</span></span></code> </pre> <br><p>  Buat objek yang ditentukan: </p><br><pre> <code class="bash hljs">$ kubectl create \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/accounts/admin-user.yaml \ -f https://raw.githubusercontent.com/selectel/kubernetes-examples/master/clusterrolebindings/cluster-admin.yaml</code> </pre> <br><p>  Selanjutnya, Anda perlu mengetahui nilai token yang dihasilkan untuk akun ini. <br>  Untuk melakukan ini, temukan objek Rahasia yang sesuai di kluster: </p><br><pre> <code class="bash hljs">$ kubectl get secret --namespace=kube-system | grep <span class="hljs-string"><span class="hljs-string">"admin-user-token"</span></span> admin-user-token-bkfhb kubernetes.io/service-account-token 3 22m</code> </pre> <br><p>  Dan lihat nilai token dari Secret yang ditemukan dengan nama admin-user-token-bkfhb: </p><br><pre> <code class="bash hljs">$ kubectl describe secret admin-user-token-bkfhb --namespace=kube-system | grep <span class="hljs-string"><span class="hljs-string">"token:"</span></span> token: XXXXXX...</code> </pre> <br><p>  Sebagai tanggapan, Anda akan menerima nilai token, simpan, itu akan berguna bagi kami di masa depan. <br>  Untuk detail kontrol akses untuk objek Kubernetes, lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener noreferrer">dokumentasi resmi</a> . </p><br><p>  Jika Anda membuat kluster dari templat publik, Pod dan Layanan sudah ada di dalamnya untuk memastikan pengoperasian panel: </p><br><pre> <code class="bash hljs">$ kubectl get svc kubernetes-dashboard --namespace=kube-system 206ms Tue Jun 19 14:35:19 2018 NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes-dashboard ClusterIP 10.254.122.245 &lt;none&gt; 443/TCP 2d $ kubectl get pod --namespace=kube-system --selector k8s-app=kubernetes-dashboard 119ms Tue Jun 19 14:36:48 2018 NAME READY STATUS RESTARTS AGE kubernetes-dashboard-747575c864-jpxvt 1/1 Running 0 2d</code> </pre> <br><p>  Karena Layanan adalah dari jenis ClusterIP, itu akan tersedia hanya dari dalam cluster itu sendiri. <br>  Anda dapat mengakses panel dari komputer Anda yang bekerja dengan file konfigurasi cluster menggunakan perintah kubectl: </p><br><pre> <code class="bash hljs">$ kubectl proxy Starting to serve on 127.0.0.1:8001</code> </pre> <br><p>  Uji proxy dengan membuka alamat yang ditentukan di browser: </p><br><img src="https://habrastorage.org/webt/lc/zm/k1/lczmk1ud4tjatfu3lthvkrcu66e.png"><br><p>  Jika Anda melihat jawaban yang mirip dengan tangkapan layar, maka Anda dapat pergi ke layar panel kontrol menggunakan alamat berikut: </p><br><pre> <code class="bash hljs">http://127.0.0.1:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</code> </pre> <br><p>  Melihat itu, Anda akan melihat layar login di panel: </p><br><img src="https://habrastorage.org/webt/60/fj/p5/60fjp5-2xjyn_p5mz-jh_ozwzxe.png"><br><p>  Anda harus menentukan token yang diterima sebelumnya.  Setelah masuk, Anda dapat menggunakan panel kontrol: </p><br><img src="https://habrastorage.org/webt/38/ry/dr/38rydrraxndpo0hyqhnm-k1nb_k.png"><br><p>  Anda dapat mengetahui tentang semua fitur panel kontrol dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="nofollow noopener noreferrer">dokumentasi resmi</a> . </p><br><h2>  Memantau Objek Kubernetes </h2><br><p>  Jika Anda menggunakan templat klaster publik, Anda akan secara otomatis menjalankan komponen untuk mengumpulkan dan menampilkan metrik - Prometheus dan Grafana. </p><br><p>  Mirip dengan panel kontrol, ClusterIP diinstal sebagai tipe Layanan, akses ke sana hanya mungkin dari dalam cluster atau melalui proxy kubectl.  Anda dapat mengakses Grafana dari komputer kerja Anda di alamat berikut: </p><br><pre> <code class="bash hljs">http://127.0.0.1:8001/api/v1/proxy/namespaces/kube-system/services/monitoring-grafana:80</code> </pre> <br><img src="https://habrastorage.org/webt/p3/7e/go/p37egoksdoz8bvp8tsq2fgpsuru.png"><br><h2>  Kesimpulan </h2><br><p>  Pada artikel ini, kami memeriksa objek Kubernetes yang paling umum digunakan dan melihat contoh memulai dan mengelola cluster menggunakan OpenStack Magnum. </p><br><p>  Dalam waktu dekat, dimungkinkan untuk menggunakan rilis Kubernet terbaru, dan manajemen klaster akan tersedia melalui <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">panel kontrol</a> . </p><br><p>  Kami akan senang jika Anda menggunakan layanan kami dalam mode pengujian dan memberikan umpan balik. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id416951/">https://habr.com/ru/post/id416951/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id416941/index.html">Teori kebahagiaan. Pengantar Merphology</a></li>
<li><a href="../id416943/index.html">Bahan yang berguna untuk merancang antarmuka suara</a></li>
<li><a href="../id416945/index.html">Seperti yang kami lakukan BelAZ. Bagian 1 - Setrika</a></li>
<li><a href="../id416947/index.html">Mainkan game sebelum Olimpiade: eSports menjadi resmi</a></li>
<li><a href="../id416949/index.html">Peningkatan skala besar Mr. Steven untuk menginstal jaringan perburuan empat kali lipat lebih besar telah selesai</a></li>
<li><a href="../id416953/index.html">Buat shader air kartun untuk web. Bagian 1</a></li>
<li><a href="../id416955/index.html">Trik kecil dengan Elasticsearch</a></li>
<li><a href="../id416957/index.html">Mesin laser mana yang harus dibeli? Ulasan Mesin Laser Raylogic 11G yang Andal</a></li>
<li><a href="../id416959/index.html">Apple Memperkenalkan Fitur Anti-Pencurian iOS Baru</a></li>
<li><a href="../id416961/index.html">Resolusi konflik otomatis menggunakan transformasi operasional</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
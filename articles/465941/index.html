<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèæ‚Äçüé§ ü§∏üèΩ üë®‚Äçüë®‚Äçüëß S√≠ntesis multiling√ºe del habla con clonaci√≥n üò± üìÖ ‚ôªÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Aunque las redes neuronales comenzaron a usarse para la s√≠ntesis del habla no hace mucho tiempo ( por ejemplo ), ya han logrado superar los enfoques c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>S√≠ntesis multiling√ºe del habla con clonaci√≥n</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/465941/"><p>  Aunque las redes neuronales comenzaron a usarse para la s√≠ntesis del habla no hace mucho tiempo ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">por ejemplo</a> ), ya han logrado superar los enfoques cl√°sicos y cada a√±o experimentan tareas cada vez m√°s nuevas. </p><br><p>  Por ejemplo, hace un par de meses hubo una implementaci√≥n de s√≠ntesis de voz con clonaci√≥n de voz <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Real-Time-Voice-Cloning</a> .  Intentemos averiguar en qu√© consiste y realizar nuestro modelo de fonema multiling√ºe (ruso-ingl√©s). </p><br><h2 id="stroenie">  Edificio </h2><br><p><img src="https://habrastorage.org/webt/4b/k7/e_/4bk7e_qeb-qw-clbaxsqs14f7cg.png"></p><br><p>  Nuestro modelo consistir√° en cuatro redes neuronales.  El primero convertir√° el texto en fonemas (g2p), el segundo convertir√° el discurso que queremos clonar en un vector de signos (n√∫meros).  El tercero sintetizar√° los espectrogramas Mel basados ‚Äã‚Äãen las salidas de los dos primeros.  Y finalmente, el cuarto recibir√° sonido de espectrogramas. </p><a name="habracut"></a><br><h2 id="nabory-dannyh">  Conjuntos de datos </h2><br><p>  Este modelo necesita mucho discurso.  A continuaci√≥n se presentan las bases que ayudar√°n con esto. </p><br><div class="scrollable-table"><table><thead><tr><th>  Nombre </th><th>  Idioma </th><th>  Enlace </th><th>  Comentarios </th><th>  Mi enlace </th><th>  Comentarios </th></tr></thead><tbody><tr><td>  Diccionario de fonemas </td><td>  En ru </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">En</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ru</a> </td><td></td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> </td><td>  Diccionario combinado de fonemas ruso e ingl√©s </td></tr><tr><td>  Libripepeech </td><td>  En </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> </td><td>  300 votos, 360 horas de puro discurso </td><td></td><td></td></tr><tr><td>  VoxCeleb </td><td>  En </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> </td><td>  7000 votos, muchas horas de mal sonido </td><td></td><td></td></tr><tr><td>  M-AILABS </td><td>  Ru </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> </td><td>  3 votos, 46 horas de puro discurso </td><td></td><td></td></tr><tr><td>  open_tts, open_stt </td><td>  Ru </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">open_tts</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">open_stt</a> </td><td>  muchas voces, muchas horas de mal sonido </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> </td><td>  Limpi√© 4 horas de discurso de un orador.  Anotaci√≥n corregida, dividida en segmentos de hasta 7 segundos. </td></tr><tr><td>  Voxforge + audiolibro </td><td>  Ru </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> </td><td>  muchos votos, 25h de diferente calidad </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> </td><td>  Seleccionados buenos archivos.  Se rompi√≥ en segmentos.  Se agregaron audiolibros de Internet.  Result√≥ 200 altavoces en un par de minutos por cada </td></tr><tr><td>  RUSLAN </td><td>  Ru </td><td>  <a href="">enlace</a> </td><td>  Una voz, 40 horas de puro discurso. </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> </td><td>  Recodificado a 16kHz </td></tr><tr><td>  Mozilla </td><td>  Ru </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> </td><td>  50 votos, 30 horas de calidad normal </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> </td><td>  Recodificado a 16kHz, dispers√≥ a diferentes usuarios en carpetas </td></tr><tr><td>  Soltero ruso </td><td>  Ru </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> </td><td>  Una voz, 9 horas de puro discurso. </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> </td><td></td></tr></tbody></table></div><br><h2 id="obrabotka-teksta">  Procesamiento de textos </h2><br><p>  La primera tarea ser√° el procesamiento de texto.  Imagine el texto en la forma en que se expresar√° m√°s.  Representaremos n√∫meros en palabras y abriremos abreviaturas.  Lea m√°s en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo sobre s√≠ntesis</a> .  Esta es una tarea dif√≠cil, as√≠ que supongamos que ya hemos procesado el texto (se ha procesado en las bases de datos anteriores). </p><br><p>  La siguiente pregunta que debe hacerse es si se debe usar la grabaci√≥n de grafema o fonema.  Para una voz monof√≥nica y monoling√ºe, tambi√©n es adecuado un modelo de letra.  Si desea trabajar con un modelo multiling√ºe de varias voces, le aconsejo que use la transcripci√≥n (Google <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tambi√©n</a> ). </p><br><h3 id="g2p">  G2p </h3><br><p>  Para el idioma ruso, hay una implementaci√≥n llamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">russian_g2p</a> .  Se basa en las reglas del idioma ruso y se adapta bien a la tarea, pero tiene desventajas.  No todas las palabras subrayan, y tampoco es adecuado para un modelo multiling√ºe.  Por lo tanto, tome el diccionario creado para ella, agregue el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">diccionario para el idioma ingl√©s</a> y alimente la red neuronal (por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> ) </p><br><p>  Antes de entrenar la red, vale la pena considerar qu√© sonidos de diferentes idiomas suenan similares, y puede seleccionar un car√°cter para ellos, y para lo cual es imposible.  Cuantos m√°s sonidos haya, m√°s dif√≠cil ser√° aprender el modelo, y si hay muy pocos, el modelo tendr√° un acento.  Recuerde enfatizar caracteres individuales con vocales estresadas.  Para el idioma ingl√©s, el estr√©s secundario juega un papel peque√±o, y no lo distinguir√≠a. </p><br><h2 id="kodirovanie-spikerov">  Codificaci√≥n de altavoces </h2><br><p>  La red es similar a la tarea de identificar a un usuario por voz.  En la salida, diferentes usuarios obtienen diferentes vectores con n√∫meros.  Sugiero usar la implementaci√≥n de CorentinJ, que se basa en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> .  El modelo es un LSTM de tres capas con 768 nodos, seguido de una capa totalmente conectada de 256 neuronas, lo que da un vector de 256 n√∫meros. </p><br><p>  La experiencia ha demostrado que una red capacitada en ingl√©s habla bien con ruso.  Esto simplifica enormemente la vida, ya que la capacitaci√≥n requiere muchos datos.  Recomiendo tomar un modelo ya entrenado y volver a entrenar en ingl√©s de VoxCeleb y LibriSpeech, as√≠ como todos los discursos en ruso que encuentre.  El codificador no necesita una anotaci√≥n de texto de fragmentos de voz. </p><br><h3 id="trenirovka">  Entrenamiento </h3><br><ol><li> Ejecute <code>python encoder_preprocess.py &lt;datasets_root&gt;</code> para procesar los datos </li><li>  Ejecute "visdom" en una terminal separada. </li><li>  Ejecute <code>python encoder_train.py my_run &lt;datasets_root&gt;</code> para entrenar el codificador </li></ol><br><h2 id="sintez">  S√≠ntesis </h2><br><p>  Pasemos a la s√≠ntesis.  Los modelos que conozco no obtienen sonido directamente del texto, porque es dif√≠cil (demasiados datos).  Primero, el texto produce sonido en forma espectral, y solo entonces la cuarta red se traducir√° en una voz familiar.  Por lo tanto, primero entendemos c√≥mo la forma espectral est√° asociada con la voz.  Es m√°s f√°cil descubrir el problema inverso de c√≥mo obtener un espectrograma del sonido. </p><br><p>  El sonido se divide en segmentos de 25 ms en incrementos de 10 ms (el valor predeterminado en la mayor√≠a de los modelos).  Luego, usando la transformada de Fourier para cada pieza, se calcula el espectro (oscilaciones arm√≥nicas, cuya suma da la se√±al original) y se presenta en forma de gr√°fico, donde la franja vertical es el espectro de un segmento (en frecuencia), y en horizontal: una secuencia de segmentos (en el tiempo).  Este gr√°fico se llama espectrograma.  Si la frecuencia se codifica de forma no lineal (las frecuencias m√°s bajas son mejores que las superiores), entonces la escala vertical cambiar√° (necesaria para reducir los datos), entonces este gr√°fico se llama espectrograma Mel.  As√≠ es como funciona la audici√≥n humana, que escuchamos una ligera desviaci√≥n en las frecuencias m√°s bajas mejor que en las m√°s altas, por lo tanto, la calidad del sonido no sufrir√° </p><br><p><img src="https://habrastorage.org/webt/dx/mv/fs/dxmvfst1objf8dmdglu7rlbhaiq.jpeg"></p><br><p>  Hay varias implementaciones de s√≠ntesis de espectrograma buenas, como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tacotron 2</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Deepvoice 3</a> .  Cada uno de estos modelos tiene sus propias implementaciones, por ejemplo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">3</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">4</a> .  Usaremos (como CorentinJ) el modelo Tacotron de Rayhane-mamah. </p><br><p><img src="https://habrastorage.org/webt/u9/jm/h0/u9jmh0ldgpelp8qoouinbx9ptfi.png"></p><br><p>  Tacotron se basa en la red seq2seq con un mecanismo de atenci√≥n.  Lee los detalles en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> . </p><br><h3 id="trenirovka-1">  Entrenamiento </h3><br><p>  No olvide editar utils / symbols.py si sintetiza no solo el habla inglesa, hparams.p, sino tambi√©n preprocess.py. </p><br><p>  La s√≠ntesis requiere una gran cantidad de sonido limpio y bien marcado de diferentes altavoces.  Aqu√≠ un idioma extranjero no ayudar√°. </p><br><ol><li>  Ejecute <code>python synthesizer_preprocess_audio.py &lt;datasets_root&gt;</code> para crear sonido procesado y espectrogramas </li><li>  Ejecute <code>python synthesizer_preprocess_embeds.py &lt;datasets_root&gt;</code> para codificar el sonido (obtenga los signos de una voz) </li><li>  Ejecute <code>python synthesizer_train.py my_run &lt;datasets_root&gt;</code> para entrenar el sintetizador </li></ol><br><h2 id="vokoder">  Vocoder </h2><br><p>  Ahora solo queda convertir los espectrogramas en sonido.  Para esto, la √∫ltima red es el vocoder.  Surge la pregunta, si los espectrogramas se obtienen del sonido usando la transformada de Fourier, ¬øes posible obtener sonido nuevamente usando la transformaci√≥n inversa?  La respuesta es s√≠ y no.  Las oscilaciones arm√≥nicas que componen la se√±al original contienen amplitud y fase, y nuestros espectrogramas contienen informaci√≥n solo sobre la amplitud (en aras de reducir los par√°metros y trabajar con espectrogramas), por lo que si hacemos la transformaci√≥n inversa de Fourier, obtendremos un mal sonido. </p><br><p>  Para resolver este problema, inventaron un algoritmo r√°pido de Griffin-Lim.  √âl hace la transformada inversa de Fourier del espectrograma, obteniendo un sonido "malo".  Luego realiza una conversi√≥n directa de este sonido y recibe un espectro que ya contiene una peque√±a informaci√≥n sobre la fase, y la amplitud no cambia en el proceso.  Luego, la transformaci√≥n inversa se toma nuevamente y se obtiene un sonido m√°s limpio.  Desafortunadamente, la calidad de la voz generada por tal algoritmo deja mucho que desear. </p><br><p>  Fue reemplazado por vocoders neuronales como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">WaveNet</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">WaveRNN</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">WaveGlow</a> y otros.  CorentinJ us√≥ el modelo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">WaveRNN</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">fatchord</a> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/2fe/b25/464/2feb25464260ad8a96c983bb85340fee.gif" alt="imagen"></p><br><p>  Para el preprocesamiento de datos, se utilizan dos enfoques.  Obtenga espectrogramas del sonido (usando la transformaci√≥n de Fourier) o del texto (usando el modelo de s√≠ntesis).  Google recomienda un segundo enfoque. </p><br><h3 id="trenirovka-2">  Entrenamiento </h3><br><ol><li>  Ejecute <code>python vocoder_preprocess.py &lt;datasets_root&gt;</code> para sintetizar espectrogramas </li><li>  Ejecute <code>python vocoder_train.py &lt;datasets_root&gt;</code> para vocoder </li></ol><br><h2 id="itogo">  Total </h2><br><p>  Tenemos un modelo de s√≠ntesis de voz multiling√ºe que puede clonar una voz. <br>  Ejecute toolbox: <code>python demo_toolbox.py -d &lt;datasets_root&gt;</code> <br>  Se pueden escuchar ejemplos aqu√≠ </p><br><div class="oembed">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://soundcloud.com/fn5va3vghrkh/sets/multi-tacotron</a> </div><br><h4 id="sovety-i-vyvody">  Consejos y conclusiones </h4><br><ul><li>  Necesita muchos datos (&gt; 1000 votos,&gt; 1000 horas) </li><li>  La velocidad de operaci√≥n es comparable con el tiempo real solo en la s√≠ntesis de al menos 4 oraciones </li><li>  Para el codificador, use el modelo pre-entrenado para el idioma ingl√©s, ligeramente reentrenamiento.  Ella esta bien </li><li>  Un sintetizador entrenado en datos "limpios" funciona mejor, pero clona peor que uno que entren√≥ en un volumen mayor, pero datos sucios </li><li>  El modelo funciona bien solo con los datos sobre los que estudi√© </li></ul><br><p>  Puede sintetizar su voz en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">l√≠nea usando colab</a> , o ver mi implementaci√≥n en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">github</a> y descargar mis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pesos</a> . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/465941/">https://habr.com/ru/post/465941/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../465921/index.html">De cyberpunk a DevSecOps: 7 libros para los cuales el ingeniero DevSecOps todav√≠a vale la pena aprender ingl√©s</a></li>
<li><a href="../465923/index.html">3 errores que pueden costar la vida de tu startup</a></li>
<li><a href="../465927/index.html">Cuente Scoring de la Fer o un estudio sobre calificaci√≥n crediticia como parte de la ampliaci√≥n de los horizontes. Parte 3</a></li>
<li><a href="../465929/index.html">Infraestructura A / B experimenta en la gran b√∫squeda. Informe Yandex</a></li>
<li><a href="../465937/index.html">Technostream: una nueva selecci√≥n de videos de capacitaci√≥n para el inicio del a√±o escolar</a></li>
<li><a href="../465943/index.html">La startup Unicorn Bolt celebrar√° un campeonato para desarrolladores con un premio de 350 mil rublos y la posibilidad de reubicarse en Europa</a></li>
<li><a href="../465945/index.html">Acerca de la instalaci√≥n y uso de LineageOS 16, F-Droid</a></li>
<li><a href="../465947/index.html">Entrenamiento Cisco 200-125 CCNA v3.0. D√≠a 30. Arquitectura de red Cisco y resoluci√≥n de problemas</a></li>
<li><a href="../465949/index.html">Aplicaciones para libros electr√≥nicos en el sistema operativo Android. Parte 5. Almacenamiento en la nube y jugadores</a></li>
<li><a href="../465951/index.html">Todos necesitamos mesa de ayuda</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
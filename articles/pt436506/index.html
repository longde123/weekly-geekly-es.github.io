<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëπ üè• üë®‚Äçüç≥ Como criar um racista de IA sem muito esfor√ßo „äôÔ∏è üåä üë©üèª‚Äçüî¨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Uma li√ß√£o de advert√™ncia. 

 Vamos fazer um classificador de tonalidade! 

 A an√°lise de sentimentos (an√°lise de sentimentos) √© uma tarefa muito comum...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como criar um racista de IA sem muito esfor√ßo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436506/"> Uma li√ß√£o de advert√™ncia. <br><br>  <b>Vamos fazer um classificador de tonalidade!</b> <br><br>  A an√°lise de sentimentos (an√°lise de sentimentos) √© uma tarefa muito comum no processamento de linguagem natural (PNL), e isso n√£o √© surpreendente.  √â importante que uma empresa entenda o que as pessoas est√£o dizendo: positivas ou negativas.  Essa an√°lise √© usada para monitorar redes sociais, feedback dos clientes e at√© mesmo na negocia√ß√£o algor√≠tmica de a√ß√µes (como resultado, os bots <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">compram a√ß√µes da Berkshire Hathaway depois de postarem cr√≠ticas positivas sobre o papel de Anne Hathaway no √∫ltimo filme</a> ). <br><br>  √Äs vezes, o m√©todo de an√°lise √© muito simplificado, mas √© uma das maneiras mais f√°ceis de obter resultados mensur√°veis.  Basta enviar o texto - e o resultado √© positivo e negativo.  N√£o h√° necessidade de lidar com a √°rvore de an√°lise, criar um gr√°fico ou outra representa√ß√£o complexa. <br><a name="habracut"></a><br>  √â isso que faremos.  Seguiremos o caminho de menor resist√™ncia e tornaremos o classificador mais simples, que provavelmente parece muito familiar para todos os envolvidos em desenvolvimentos relevantes no campo da PNL.  Por exemplo, esse modelo pode ser encontrado no artigo <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Deep Averaging Networks</a></i> (Iyyer et al., 2015).  N√£o estamos tentando desafiar seus resultados ou criticar o modelo;  simplesmente fornecemos um m√©todo bem conhecido de representa√ß√£o vetorial de palavras. <br><br>  Plano de trabalho: <br><br><ul><li>  Introduzir uma <b>representa√ß√£o vetorial</b> t√≠pica <b>de palavras</b> para trabalhar com significados (significados). </li><li>  Introduzir <b>conjuntos de dados de treinamento e teste</b> com listas padr√£o de palavras positivas e negativas. </li><li>  <b>Treine</b> o <b>classificador de</b> descida de gradiente para reconhecer outras palavras positivas e negativas com base em sua representa√ß√£o vetorial. </li><li>  Use este classificador para calcular <b>classifica√ß√µes de tonalidade</b> para frases de texto. </li><li>  <b>Para ver o monstro</b> que criamos. </li></ul><br>  E ent√£o veremos "como criar um racista de IA sem esfor√ßos especiais".  Obviamente, voc√™ n√£o pode deixar o sistema de uma forma t√£o monstruosa, ent√£o vamos: <br><br><ul><li>  <b>Avaliar o problema</b> estatisticamente, para que seja poss√≠vel medir o progresso conforme ele √© resolvido. </li><li>  <b>Melhore os dados</b> para obter um modelo sem√¢ntico mais preciso e menos racista. </li></ul><br><h1>  Depend√™ncias de software </h1><br>  Este tutorial foi escrito em Python e baseia-se em uma pilha t√≠pica de aprendizado de m√°quina Python: <code>numpy</code> e <code>scipy</code> para computa√ß√£o num√©rica, <code>pandas</code> para gerenciamento de dados e <code>scikit-learn</code> para aprendizado de m√°quina.  No final, tamb√©m <code>seaborn</code> <code>matplotlib</code> e <code>seaborn</code> para criar diagramas. <br><br>  Em princ√≠pio, o <code>scikit-learn</code> pode ser substitu√≠do por TensorFlow ou Keras, ou algo assim: eles tamb√©m s√£o capazes de treinar o classificador em descidas gradientes.  Mas n√£o precisamos de suas abstra√ß√µes, porque aqui o treinamento ocorre em um est√°gio. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> statsmodels.formula.api <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SGDClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> accuracy_score <span class="hljs-comment"><span class="hljs-comment">#     %matplotlib inline seaborn.set_context('notebook', rc={'figure.figsize': (10, 6)}, font_scale=1.5)</span></span></code> </pre> <br><h1>  Etapa 1. Representa√ß√£o vetorial de palavras </h1><br>  As representa√ß√µes vetoriais s√£o frequentemente usadas quando h√° entrada de texto.  As palavras se tornam vetores no espa√ßo multidimensional, onde vetores adjacentes representam significados semelhantes.  Usando representa√ß√µes vetoriais, voc√™ pode comparar as palavras pelo significado (aproximadamente) e n√£o apenas pelas correspond√™ncias exatas. <br><br>  O aprendizado bem-sucedido requer centenas de gigabytes de texto.  Felizmente, v√°rias equipes de pesquisa j√° fizeram esse trabalho e forneceram modelos pr√©-treinados de representa√ß√µes vetoriais dispon√≠veis para download. <br><br>  Os dois conjuntos de dados mais conhecidos para o idioma ingl√™s s√£o <b>word2vec</b> (treinado nos textos do Google Not√≠cias) e <b>GloVe</b> (nas p√°ginas da web de rastreamento comum).  Qualquer um deles dar√° um resultado semelhante, mas usaremos o modelo GloVe porque ele tem uma fonte de dados mais transparente. <br><br>  O GloVe vem em tr√™s tamanhos: 6 bilh√µes, 42 bilh√µes e 840 bilh√µes.O modelo mais recente √© o mais poderoso, mas requer recursos de processamento significativos.  A vers√£o de 42 bilh√µes √© muito boa, e o dicion√°rio √© bem aparado para 1 milh√£o de palavras.  Estamos no caminho de menor resist√™ncia, ent√£o pegue a vers√£o de 42 bilh√µes. <br><br><blockquote>  <b>- Por que √© t√£o importante usar um modelo "conhecido"?</b> <br><br>  "Estou feliz que voc√™ perguntou sobre isso, interlocutor hipot√©tico!"  Em cada etapa, tentamos fazer algo extremamente t√≠pico, e o melhor modelo para a representa√ß√£o vetorial de palavras por algum motivo ainda n√£o foi determinado.  Espero que este artigo desperte o desejo de usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">modelos modernos de alta qualidade</a> , especialmente aqueles que levam em conta um erro algor√≠tmico e tentam corrigi-lo.  No entanto, mais sobre isso mais tarde. </blockquote><br>  Fa√ßa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o download</a> do arquivo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">glove.42B.300d.zip no site da GloVe</a> e extraia o arquivo <code>data/glove.42B.300d.txt</code> .  Em seguida, definimos uma fun√ß√£o para ler vetores em um formato simples. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_embeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""  DataFrame      ,   word2vec, GloVe, fastText  ConceptNet Numberbatch.            . """</span></span> labels = [] rows = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(infile): items = line.rstrip().split(<span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(items) == <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-comment"><span class="hljs-comment"># This is a header row giving the shape of the matrix continue labels.append(items[0]) values = np.array([float(x) for x in items[1:]], 'f') rows.append(values) arr = np.vstack(rows) return pd.DataFrame(arr, index=labels, dtype='f') embeddings = load_embeddings('data/glove.42B.300d.txt') embeddings.shape</span></span></code> </pre> <br> <code>(1917494, 300)</code> <br> <h1>  Etapa 2. Dicion√°rio de tonalidade padr√£o-ouro </h1><br>  Agora precisamos de informa√ß√µes sobre quais palavras s√£o consideradas positivas e quais s√£o negativas.  Existem muitos dicion√°rios, mas usaremos um dicion√°rio muito simples (Hu e Liu, 2004), que √© usado no artigo da <i>Deep Averaging Networks</i> . <br><br>  Fa√ßa o download do dicion√°rio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no site</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Bing Liu</a> e extraia os dados em <code>data/positive-words.txt</code> e <code>data/negative-words.txt</code> . <br><br>  Em seguida, determinamos como ler esses arquivos e os atribu√≠mos como <code>neg_words</code> e <code>neg_words</code> : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_lexicon</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""       (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html)      Latin-1.      ,    - .    ,    ';'   ,   . """</span></span> lexicon = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(filename, encoding=<span class="hljs-string"><span class="hljs-string">'latin-1'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> infile: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> infile: line = line.rstrip() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> line.startswith(<span class="hljs-string"><span class="hljs-string">';'</span></span>): lexicon.append(line) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> lexicon pos_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/positive-words.txt'</span></span>) neg_words = load_lexicon(<span class="hljs-string"><span class="hljs-string">'data/negative-words.txt'</span></span>)</code> </pre> <br><h1>  Etapa 3. Treinamos o modelo para prever a tonalidade </h1><br>  Com base nos vetores de palavras positivas e negativas, usamos o comando Pandas <code>.loc[]</code> para procurar representa√ß√µes vetoriais de todas as palavras. <br><br>  Algumas palavras est√£o faltando no dicion√°rio GloVe.  Na maioria das vezes, esses s√£o erros de digita√ß√£o, como "fantasiar".  Aqui vemos um monte de <code>NaN</code> , que indica a aus√™ncia de um vetor, e os <code>.dropna()</code> com o comando <code>.dropna()</code> . <br><br> <code>pos_vectors = embeddings.loc[pos_words].dropna() <br> neg_vectors = embeddings.loc[neg_words].dropna()</code> <br> <br>  Agora, criamos matrizes de dados na entrada (representa√ß√µes vetoriais) e na sa√≠da (1 para palavras positivas e -1 para negativa).  Tamb√©m verificamos que os vetores est√£o anexados √†s palavras para que possamos interpretar os resultados. <br><br> <code>vectors = pd.concat([pos_vectors, neg_vectors]) <br> targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index]) <br> labels = list(pos_vectors.index) + list(neg_vectors.index)</code> <br> <br><blockquote>  <b>- Espere.</b>  <b>Algumas palavras n√£o s√£o positivas nem negativas, s√£o neutras.</b>  <b>Uma terceira classe n√£o deveria ser criada para palavras neutras?</b> <br><br>  "Eu acho que ele teria sido √∫til."  Mais tarde, veremos quais problemas surgem devido √† atribui√ß√£o de tonalidade a palavras neutras.  Se pudermos identificar com seguran√ßa palavras neutras, √© bem poss√≠vel aumentar a complexidade do classificador para tr√™s categorias.  Mas voc√™ precisa encontrar um dicion√°rio de palavras neutras, porque no dicion√°rio de Liu existem apenas palavras positivas e negativas. <br><br>  Ent√£o, tentei minha vers√£o com 800 exemplos de palavras e aumentei o peso para prever palavras neutras.  Mas os resultados finais n√£o foram muito diferentes do que voc√™ ver√° agora. <br><br>  <b>- Como esta lista distingue palavras positivas e negativas?</b>  <b>Isso n√£o depende do contexto?</b> <br><br>  Boa pergunta.  A an√°lise das chaves gerais n√£o √© t√£o simples quanto parece.  A fronteira √© bastante arbitr√°ria em alguns lugares.  Nesta lista, a palavra "insolente" √© marcada como "ruim" e "ambiciosa" como "boa".  "Comic" √© ruim e "engra√ßado" √© bom.  Um "reembolso" √© bom, embora geralmente seja mencionado em um contexto ruim quando voc√™ deve dinheiro a algu√©m ou deve a algu√©m. <br><br>  Todo mundo entende que a tonalidade √© determinada pelo contexto, mas em um modelo simples, voc√™ precisa ignorar o contexto e esperar que a tonalidade m√©dia seja adivinhada corretamente. </blockquote><br>  Usando a fun√ß√£o <code>train_test_split</code> , dividimos simultaneamente os vetores de entrada, valores de sa√≠da e r√≥tulos em dados de treinamento e teste, deixando 10% para o teste. <br><br><pre> <code class="python hljs">train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Agora crie um classificador e passe vetores atrav√©s de itera√ß√µes.  Usamos a fun√ß√£o de perda log√≠stica para que o classificador final possa deduzir a probabilidade de a palavra ser positiva ou negativa. <br><br><pre> <code class="python hljs">model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) SGDClassifier(alpha=<span class="hljs-number"><span class="hljs-number">0.0001</span></span>, average=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, class_weight=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, epsilon=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, eta0=<span class="hljs-number"><span class="hljs-number">0.0</span></span>, fit_intercept=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, l1_ratio=<span class="hljs-number"><span class="hljs-number">0.15</span></span>, learning_rate=<span class="hljs-string"><span class="hljs-string">'optimal'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_jobs=<span class="hljs-number"><span class="hljs-number">1</span></span>, penalty=<span class="hljs-string"><span class="hljs-string">'l2'</span></span>, power_t=<span class="hljs-number"><span class="hljs-number">0.5</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, warm_start=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  Avaliamos o classificador em vetores de teste.  Mostra uma precis√£o de 95%.  Nada mal. <br><br> <code>accuracy_score(model.predict(test_vectors), test_targets) <br> 0.95022624434389136</code> <br> <br>  Definimos a fun√ß√£o de previs√£o de tonalidade para certas palavras e, em seguida, a usamos para alguns exemplos de dados de teste. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vecs_to_sentiment</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(vecs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># predict_log_proba  log-    predictions = model.predict_log_proba(vecs) #        #  log-    . return predictions[:, 1] - predictions[:, 0] def words_to_sentiment(words): vecs = embeddings.loc[words].dropna() log_odds = vecs_to_sentiment(vecs) return pd.DataFrame({'sentiment': log_odds}, index=vecs.index) #  20      words_to_sentiment(test_labels).ix[:20]</span></span></code> </pre> <br><table border="1" width="350"><thead><tr><th></th><th>  tonalidade </th></tr></thead><tbody><tr><th>  inquieta√ß√£o </th><td>  -9.931679 </td></tr><tr><th>  interromper </th><td>  -9.634706 </td></tr><tr><th>  firmemente </th><td>  1.466919 </td></tr><tr><th>  imagin√°rio </th><td>  -2,989215 </td></tr><tr><th>  tributa√ß√£o </th><td>  0.468522 </td></tr><tr><th>  mundialmente famoso </th><td>  6.908561 </td></tr><tr><th>  barato </th><td>  9.237223 </td></tr><tr><th>  desapontamento </th><td>  -8.737182 </td></tr><tr><th>  totalit√°rio </th><td>  -10.851580 </td></tr><tr><th>  beligerante </th><td>  -8,328674 </td></tr><tr><th>  congela </th><td>  -8,456981 </td></tr><tr><th>  pecado </th><td>  -7.839670 </td></tr><tr><th>  fr√°gil </th><td>  -4,018289 </td></tr><tr><th>  enganado </th><td>  -4,309344 </td></tr><tr><th>  n√£o resolvido </th><td>  -2,816172 </td></tr><tr><th>  habilmente </th><td>  2.339609 </td></tr><tr><th>  demoniza </th><td>  -2.102152 </td></tr><tr><th>  despreocupado </th><td>  8.747150 </td></tr><tr><th>  impopular </th><td>  -7,887475 </td></tr><tr><th>  simpatizar </th><td>  1.790899 </td></tr></tbody></table><br>  √â visto que o classificador est√° funcionando.  Ele aprendeu a generalizar a tonalidade em palavras fora dos dados de treinamento. <br><br><h1>  Etapa 4. Obtenha uma pontua√ß√£o de tonalidade para o texto. </h1><br>  Existem v√°rias maneiras de adicionar vetores a uma estimativa geral.  Novamente, seguimos o caminho de menor resist√™ncia, portanto, basta pegar o valor m√©dio. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re TOKEN_RE = re.compile(<span class="hljs-string"><span class="hljs-string">r"\w.*?\b"</span></span>) <span class="hljs-comment"><span class="hljs-comment"># regex  ,     (\w)   #   (.+?)    (\b).   #       . def text_to_sentiment(text): tokens = [token.casefold() for token in TOKEN_RE.findall(text)] sentiments = words_to_sentiment(tokens) return sentiments['sentiment'].mean()</span></span></code> </pre> <br>  H√° muito a ser solicitado para otimiza√ß√£o: <br><br><ul><li>  Introduzir uma rela√ß√£o inversa entre a palavra peso e sua frequ√™ncia, para que as mesmas preposi√ß√µes n√£o afetem muito a tonalidade. </li><li>  Configura√ß√£o para que frases curtas n√£o terminem com valores extremos de tonalidade. </li><li>  Frases de contabilidade. </li><li>  Um algoritmo de segmenta√ß√£o de palavras mais confi√°vel que ap√≥strofos n√£o s√£o interrompidos. </li><li>  Contabilizando negativos como "n√£o satisfeito". </li></ul><br>  Mas tudo requer c√≥digo adicional e n√£o altera fundamentalmente os resultados.  Pelo menos agora voc√™ pode comparar aproximadamente ofertas diferentes: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is pretty cool"</span></span>) <span class="hljs-number"><span class="hljs-number">3.889968926086298</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"this example is okay"</span></span>) <span class="hljs-number"><span class="hljs-number">2.7997773492425186</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"meh, this example sucks"</span></span>) <span class="hljs-number"><span class="hljs-number">-1.1774475917460698</span></span></code> </pre> <br><h1>  Passo 5. Veja o monstro que criamos </h1><br>  Nem toda frase tem uma tonalidade pronunciada.  Vamos ver o que acontece com frases neutras: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Italian food"</span></span>) <span class="hljs-number"><span class="hljs-number">2.0429166109408983</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Chinese food"</span></span>) <span class="hljs-number"><span class="hljs-number">1.4094033658140972</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"Let's go get Mexican food"</span></span>) <span class="hljs-number"><span class="hljs-number">0.38801985560121732</span></span></code> </pre> <br>  Eu j√° encontrei esse fen√¥meno ao analisar resenhas de restaurantes, levando em considera√ß√£o representa√ß√µes vetoriais de palavras.  Por nenhuma raz√£o aparente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">, todos os restaurantes mexicanos t√™m uma pontua√ß√£o geral mais baixa</a> . <br><br>  As representa√ß√µes vetoriais capturam diferen√ßas sem√¢nticas sutis no contexto.  Portanto, eles refletem os preconceitos da nossa sociedade. <br><br>  Aqui est√£o algumas outras sugest√µes neutras: <br><br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Emily"</span></span>) <span class="hljs-number"><span class="hljs-number">2.2286179364745311</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Heather"</span></span>) <span class="hljs-number"><span class="hljs-number">1.3976291151079159</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Yvette"</span></span>) <span class="hljs-number"><span class="hljs-number">0.98463802132985556</span></span></code> </pre> <br><pre> <code class="python hljs">text_to_sentiment(<span class="hljs-string"><span class="hljs-string">"My name is Shaniqua"</span></span>) <span class="hljs-number"><span class="hljs-number">-0.47048131775890656</span></span></code> </pre> <br>  Bem, droga ... <br><br>  O sistema associado aos nomes das pessoas sentimentos completamente diferentes.  Voc√™ pode ver esses e muitos outros exemplos e ver que a tonalidade √© geralmente mais alta para nomes estereotipicamente brancos e menor para nomes estereotipados pretos. <br><br>  Este teste foi usado por Caliscan, Bryson e Narayanan em seu trabalho de pesquisa publicado na revista <i>Science</i> em abril de 2017.  Prova que a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sem√¢ntica do corpus da linguagem cont√©m os preconceitos da sociedade</a> .  Vamos usar esse m√©todo. <br><br><h1>  Etapa 6. Avaliando o problema </h1><br>  Queremos entender como evitar esses erros.  Vamos passar mais dados pelo classificador e medir estatisticamente seu ‚Äúvi√©s‚Äù. <br><br>  Aqui temos quatro listas de nomes que refletem diferentes origens √©tnicas, principalmente nos EUA.  Os dois primeiros s√£o listas de nomes predominantemente ‚Äúbrancos‚Äù e ‚Äúnegros‚Äù, adaptados com base em um artigo de Kaliskan et al. Tamb√©m adicionei nomes espanh√≥is e mu√ßulmanos do √°rabe e do urdu. <br><br>  Esses dados s√£o usados ‚Äã‚Äãpara verificar o vi√©s do algoritmo durante o processo de constru√ß√£o do ConceptNet: ele pode ser encontrado no m√≥dulo <code>conceptnet5.vectors.evaluation.bias</code> .  Existe uma id√©ia de expandir o dicion√°rio para outros grupos √©tnicos, levando em considera√ß√£o n√£o apenas nomes, mas tamb√©m sobrenomes. <br><br>  Aqui est√£o as listagens: <br><br><pre> <code class="python hljs">NAMES_BY_ETHNICITY = { <span class="hljs-comment"><span class="hljs-comment">#           . 'White': [ 'Adam', 'Chip', 'Harry', 'Josh', 'Roger', 'Alan', 'Frank', 'Ian', 'Justin', 'Ryan', 'Andrew', 'Fred', 'Jack', 'Matthew', 'Stephen', 'Brad', 'Greg', 'Jed', 'Paul', 'Todd', 'Brandon', 'Hank', 'Jonathan', 'Peter', 'Wilbur', 'Amanda', 'Courtney', 'Heather', 'Melanie', 'Sara', 'Amber', 'Crystal', 'Katie', 'Meredith', 'Shannon', 'Betsy', 'Donna', 'Kristin', 'Nancy', 'Stephanie', 'Bobbie-Sue', 'Ellen', 'Lauren', 'Peggy', 'Sue-Ellen', 'Colleen', 'Emily', 'Megan', 'Rachel', 'Wendy' ], 'Black': [ 'Alonzo', 'Jamel', 'Lerone', 'Percell', 'Theo', 'Alphonse', 'Jerome', 'Leroy', 'Rasaan', 'Torrance', 'Darnell', 'Lamar', 'Lionel', 'Rashaun', 'Tyree', 'Deion', 'Lamont', 'Malik', 'Terrence', 'Tyrone', 'Everol', 'Lavon', 'Marcellus', 'Terryl', 'Wardell', 'Aiesha', 'Lashelle', 'Nichelle', 'Shereen', 'Temeka', 'Ebony', 'Latisha', 'Shaniqua', 'Tameisha', 'Teretha', 'Jasmine', 'Latonya', 'Shanise', 'Tanisha', 'Tia', 'Lakisha', 'Latoya', 'Sharise', 'Tashika', 'Yolanda', 'Lashandra', 'Malika', 'Shavonn', 'Tawanda', 'Yvette' ], #         . 'Hispanic': [ 'Juan', 'Jos√©', 'Miguel', 'Lu√≠s', 'Jorge', 'Santiago', 'Mat√≠as', 'Sebasti√°n', 'Mateo', 'Nicol√°s', 'Alejandro', 'Samuel', 'Diego', 'Daniel', 'Tom√°s', 'Juana', 'Ana', 'Luisa', 'Mar√≠a', 'Elena', 'Sof√≠a', 'Isabella', 'Valentina', 'Camila', 'Valeria', 'Ximena', 'Luciana', 'Mariana', 'Victoria', 'Martina' ], #       # ,   .     . # #          # -   .    #   ,    . # #       . 'Arab/Muslim': [ 'Mohammed', 'Omar', 'Ahmed', 'Ali', 'Youssef', 'Abdullah', 'Yasin', 'Hamza', 'Ayaan', 'Syed', 'Rishaan', 'Samar', 'Ahmad', 'Zikri', 'Rayyan', 'Mariam', 'Jana', 'Malak', 'Salma', 'Nour', 'Lian', 'Fatima', 'Ayesha', 'Zahra', 'Sana', 'Zara', 'Alya', 'Shaista', 'Zoya', 'Yasmin' ] }</span></span></code> </pre> <br>  Usando Pandas, compilaremos uma tabela de nomes, sua origem √©tnica predominante e classifica√ß√µes de tonalidade: <br><br><pre> <code class="plaintext hljs">def name_sentiment_table(): frames = [] for group, name_list in sorted(NAMES_BY_ETHNICITY.items()): lower_names = [name.lower() for name in name_list] sentiments = words_to_sentiment(lower_names) sentiments['group'] = group frames.append(sentiments) #           return pd.concat(frames) name_sentiments = name_sentiment_table()</code> </pre> <br>  Dados de exemplo: <br><br> <code>name_sentiments.ix[::25]</code> <br> <table border="1" width="350"><thead><tr><th></th><th>  tonalidade </th><th>  o grupo </th></tr></thead><tbody><tr><th>  mohammed </th><td>  0.834974 </td><td>  √Årabe / mu√ßulmano </td></tr><tr><th>  alya </th><td>  3.916803 </td><td>  √Årabe / mu√ßulmano </td></tr><tr><th>  terryl </th><td>  -2,858010 </td><td>  Preto </td></tr><tr><th>  jos√© </th><td>  0.432956 </td><td>  Hisp√¢nico </td></tr><tr><th>  luciana </th><td>  1.086073 </td><td>  Hisp√¢nico </td></tr><tr><th>  hank </th><td>  0,391858 </td><td>  Branco </td></tr><tr><th>  megan </th><td>  2.158679 </td><td>  Branco </td></tr></tbody></table><br>  Faremos um gr√°fico da distribui√ß√£o da tonalidade para cada nome. <br><br><pre> <code class="python hljs">plot = seaborn.swarmplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments) plot.set_ylim([<span class="hljs-number"><span class="hljs-number">-10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>])</code> </pre> <br> <code>(-10, 10)</code> <br> <br><img src="https://habrastorage.org/webt/qv/y7/ge/qvy7gel8rrvm5txo-nou6g0i0re.png"><br><br>  Ou como um histograma com intervalos de confian√ßa para a m√©dia de 95%. <br><br><pre> <code class="python hljs">plot = seaborn.barplot(x=<span class="hljs-string"><span class="hljs-string">'group'</span></span>, y=<span class="hljs-string"><span class="hljs-string">'sentiment'</span></span>, data=name_sentiments, capsize=<span class="hljs-number"><span class="hljs-number">.1</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/uv/ib/n6/uvibn6olthaxt6cxbd96szehq94.png"><br><br>  Por fim, execute o pacote de estat√≠sticas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">statsmodels</a> s√©rio.  Ele mostrar√° o qu√£o grande √© o vi√©s do algoritmo (junto com v√°rias outras estat√≠sticas). <br><br><br>  <font color="gray">Resultados da regress√£o OLS</font> <br><table><tbody><tr><th>  Dep.  Vari√°vel: </th><td>  sentimento </td><th>  R-quadrado: </th><td>  0,208 </td></tr><tr><th>  Modelo: </th><td>  OLS </td><th>  Adj.  R-quadrado: </th><td>  0,192 </td></tr><tr><th>  M√©todo: </th><td>  M√≠nimos quadrados </td><th>  Estat√≠stica F: </th><td>  13/04 </td></tr><tr><th>  Data: </th><td>  Qui, 13 Jul 2017 </td><th>  Prob (estat√≠stica F): </th><td>  1.31e-07 </td></tr><tr><th>  Hora: </th><td>  11:31:17 </td><th>  Probabilidade de log: </th><td>  -356,78 </td></tr><tr><th>  N√£o.  Observa√ß√µes: </th><td>  153 </td><th>  AIC: </th><td>  721,6 </td></tr><tr><th>  Df Residuals: </th><td>  149 </td><th>  BIC: </th><td>  733,7 </td></tr><tr><th>  Modelo Df: </th><td>  3 </td><th></th><td></td></tr><tr><th>  Tipo de covari√¢ncia: </th><td>  antiferrugem </td><th></th><td></td></tr></tbody></table><br>  Estat√≠stica F √© a raz√£o de varia√ß√£o entre os grupos para a varia√ß√£o dentro dos grupos, que pode ser tomada como uma avalia√ß√£o geral do vi√©s. <br><br>  Imediatamente abaixo est√° indicada a probabilidade de vermos a estat√≠stica F m√°xima com a hip√≥tese nula: ou seja, na aus√™ncia de uma diferen√ßa entre as op√ß√µes comparadas.  A probabilidade √© muito, muito baixa.  Em um artigo cient√≠fico, chamar√≠amos o resultado de "muito estatisticamente significativo". <br><br>  Precisamos melhorar o valor F.  Quanto menor, melhor. <br><br> <code>ols_model.fvalue <br> 13.041597745167659</code> <br> <br><h1>  Etapa 7. Tentando outros dados. </h1><br>  Agora temos a oportunidade de medir numericamente o vi√©s prejudicial do modelo.  Vamos tentar ajust√°-lo.  Para fazer isso, voc√™ precisa repetir v√°rias coisas que costumavam ser apenas etapas separadas em um bloco de notas Python. <br><br>  Se eu escrevesse um c√≥digo bom e suportado, n√£o usaria vari√°veis ‚Äã‚Äãglobais, como <code>model</code> e <code>embeddings</code> .  Mas o c√≥digo atual do espaguete permite que voc√™ examine melhor cada etapa e entenda o que est√° acontecendo.  Reutilizamos parte do c√≥digo e pelo menos definimos uma fun√ß√£o para repetir algumas etapas: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">retrain_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(new_embs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""      . """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> model, embeddings, name_sentiments embeddings = new_embs pos_vectors = embeddings.loc[pos_words].dropna() neg_vectors = embeddings.loc[neg_words].dropna() vectors = pd.concat([pos_vectors, neg_vectors]) targets = np.array([<span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> pos_vectors.index] + [<span class="hljs-number"><span class="hljs-number">-1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> entry <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> neg_vectors.index]) labels = list(pos_vectors.index) + list(neg_vectors.index) train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \ train_test_split(vectors, targets, labels, test_size=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>) model = SGDClassifier(loss=<span class="hljs-string"><span class="hljs-string">'log'</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>, n_iter=<span class="hljs-number"><span class="hljs-number">100</span></span>) model.fit(train_vectors, train_targets) accuracy = accuracy_score(model.predict(test_vectors), test_targets) print(<span class="hljs-string"><span class="hljs-string">"Accuracy of sentiment: {:.2%}"</span></span>.format(accuracy)) name_sentiments = name_sentiment_table() ols_model = statsmodels.formula.api.ols(<span class="hljs-string"><span class="hljs-string">'sentiment ~ group'</span></span>, data=name_sentiments).fit() print(<span class="hljs-string"><span class="hljs-string">"F-value of bias: {:.3f}"</span></span>.format(ols_model.fvalue)) print(<span class="hljs-string"><span class="hljs-string">"Probability given null hypothesis: {:.3}"</span></span>.format(ols_model.f_pvalue)) <span class="hljs-comment"><span class="hljs-comment">#        Y plot = seaborn.swarmplot(x='group', y='sentiment', data=name_sentiments) plot.set_ylim([-10, 10])</span></span></code> </pre> <br><h3>  Tentamos word2vec </h3><br>  Pode-se supor que apenas o GloVe tenha o problema.  Provavelmente existem muitos sites duvidosos no banco de dados do Common Crawl e pelo menos 20 c√≥pias do Dicion√°rio Urbano de g√≠rias de rua.  Talvez em uma base diferente seja melhor: e a boa e velha word2vec treinada no Google Not√≠cias? <br><br>  Parece que a fonte mais autorizada para dados do word2vec √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">esse arquivo no Google Drive</a> .  Fa√ßa o download e salve-o como <code>data/word2vec-googlenews-300.bin.gz</code> . <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   ConceptNet   word2vec   Pandas     from conceptnet5.vectors.formats import load_word2vec_bin w2v = load_word2vec_bin('data/word2vec-googlenews-300.bin.gz', nrows=2000000) #  word2vec    w2v.index = [label.casefold() for label in w2v.index] #  ,    w2v = w2v.reset_index().drop_duplicates(subset='index', keep='first').set_index('index') retrain_model(w2v)</span></span></code> </pre> <br> <code>Accuracy of sentiment: 94.30% <br> F-value of bias: 15.573 <br> Probability given null hypothesis: 7.43e-09</code> <br> <br>  Portanto, o word2vec acabou sendo ainda pior com um valor F superior a 15. <br><br>  Em princ√≠pio, era tolice esperar que as <i>not√≠cias</i> fossem melhor protegidas contra preconceitos. <br><br><h3>  Tentando ConceptNet Numberbatch </h3><br>  Finalmente, posso falar sobre meu pr√≥prio projeto sobre a representa√ß√£o vetorial de palavras. <br><br>  O ConceptNet com o recurso de apresenta√ß√£o vetorial √© o gr√°fico de conhecimento em que estou trabalhando.  Normaliza as representa√ß√µes vetoriais na fase de treinamento, identificando e removendo algumas fontes de racismo algor√≠tmico e sexismo.  Esse m√©todo de corre√ß√£o de vi√©s √© baseado em um artigo cient√≠fico de Bulukbashi et al., <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">‚ÄúDebiasing Word Embeddings‚Äù</a> e √© generalizado para eliminar v√°rios tipos de vi√©s ao mesmo tempo.  At√© onde eu sei, este √© o √∫nico sistema sem√¢ntico em que existe algo assim. <br><br>  Periodicamente, exportamos vetores pr√©-computados do ConceptNet - esses lan√ßamentos s√£o chamados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ConceptNet Numberbatch</a> .  Em abril de 2017, o primeiro lan√ßamento com corre√ß√£o de vi√©s foi lan√ßado, portanto, carregaremos os vetores no idioma ingl√™s e treinaremos novamente nosso modelo. <br><br>  <code><a href="">numberbatch-en-17.04b.txt.gz</a></code> , salvamos no diret√≥rio <code>data/</code> e treinamos novamente o modelo: <br><br><pre> <code class="python hljs">retrain_model(load_embeddings(<span class="hljs-string"><span class="hljs-string">'data/numberbatch-en-17.04b.txt'</span></span>))</code> </pre> <br> <code>Accuracy of sentiment: 97.46% <br> F-value of bias: 3.805 <br> Probability given null hypothesis: 0.0118</code> <br> <br><img src="https://habrastorage.org/webt/5d/iu/uq/5diuuqrst8bca5-m7fljox--pro.png"><br><br>  Ent√£o, o ConceptNet Numberbatch resolveu completamente o problema?  Chega de racismo algor√≠tmico?  <b>N√£o.</b> <br><br>  O racismo se tornou muito menos?  <b>Definitivamente</b> . <br><br>  Os intervalos principais para grupos √©tnicos se sobrep√µem muito mais do que nos vetores GloVe ou word2vec.  Comparado ao GloVe, o valor de F diminuiu mais de tr√™s vezes e comparado ao word2vec - mais de quatro vezes.  E, em geral, vemos diferen√ßas muito menores na tonalidade ao comparar nomes diferentes: deve ser assim, porque os nomes realmente n√£o devem afetar o resultado da an√°lise. <br><br>  Mas uma ligeira correla√ß√£o permaneceu.  Talvez eu possa pegar esses dados e par√¢metros de treinamento que o problema parece estar resolvido.  Mas essa ser√° uma op√ß√£o ruim, porque <i>, de fato, o</i> problema permanece, porque no ConceptNet n√£o identificamos e compensamos todas as causas do racismo algor√≠tmico.  Mas este √© um bom come√ßo. <br><br><h3>  Sem armadilhas </h3><br>  Observe que, com a mudan√ßa para o ConceptNet Numberbatch, a precis√£o da previs√£o de tonalidade melhorou. <br><br>  Algu√©m pode ter sugerido que a corre√ß√£o do racismo algor√≠tmico pioraria os resultados de alguma outra maneira.  Mas n√£o.  Voc√™ pode ter dados melhores e menos racistas.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Os dados est√£o realmente melhorando com essa corre√ß√£o. </font><font style="vertical-align: inherit;">O racismo word2vec e GloVe adquirido de pessoas n√£o tem nada a ver com a precis√£o do algoritmo.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Outras abordagens </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Obviamente, essa √© apenas uma maneira de analisar a tonalidade. Alguns detalhes podem ser implementados de maneira diferente. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Em vez disso, ou al√©m de alterar a base do vetor, voc√™ pode tentar corrigir esse problema diretamente na sa√≠da. Por exemplo, geralmente elimine a avalia√ß√£o da tonalidade para nomes e grupos de pessoas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Em geral, existe uma op√ß√£o para recusar calcular a tonalidade de todas as palavras e calcul√°-la apenas para palavras da lista. Esta √© talvez a forma mais comum de an√°lise de sentimentos - sem aprendizado de m√°quina. Os resultados n√£o ter√£o mais vi√©s do que o autor da lista. Mas recusar o aprendizado de m√°quina significa reduzir o recall (recall), e a √∫nica maneira de adaptar o modelo a um conjunto de dados √© editar manualmente a lista.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como uma abordagem h√≠brida, voc√™ pode criar um grande n√∫mero de estimativas de tonalidade estimadas para palavras e instruir uma pessoa a edit√°-las pacientemente, fazer uma lista de palavras de exce√ß√£o com tonalidade zero. </font><font style="vertical-align: inherit;">Mas este √© um trabalho extra. </font><font style="vertical-align: inherit;">Por outro lado, voc√™ realmente ver√° como o modelo funciona. </font><font style="vertical-align: inherit;">Eu acho que, em qualquer caso, isso deve ser buscado.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt436506/">https://habr.com/ru/post/pt436506/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt436496/index.html">PVS-Studio para Java</a></li>
<li><a href="../pt436498/index.html">Software AG: N√£o apenas ARIS</a></li>
<li><a href="../pt436500/index.html">Como o quadro de Rise of the Tomb Raider √© renderizado</a></li>
<li><a href="../pt436502/index.html">Pampers de assinatura ou como vender mais para os mesmos clientes</a></li>
<li><a href="../pt436504/index.html">Sistema no pacote ou O que h√° sob a cobertura do pacote de chips?</a></li>
<li><a href="../pt436508/index.html">US $ 10 milh√µes em investimentos e elogios de Wozniak - criando um computador educacional para crian√ßas</a></li>
<li><a href="../pt436510/index.html">Dados principais em detalhes</a></li>
<li><a href="../pt436512/index.html">Como encontramos lan√ßamentos problem√°ticos com o Graphite e o Moira. Experimente o Yandex.Money</a></li>
<li><a href="../pt436514/index.html">Criando hist√≥rias para Instagram a partir do PHP</a></li>
<li><a href="../pt436518/index.html">Haiku Œ≤1 - torne o / b / OS √≥timo novamente</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
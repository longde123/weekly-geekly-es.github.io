<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòµ üë®üèΩ‚Äçüç≥ üé∑ Nous segmentons 600 millions d'utilisateurs en temps r√©el chaque jour ü§ì üöí ‚è™</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Chaque jour, les utilisateurs engagent des millions d'activit√©s en ligne. Le projet FACETz DMP doit structurer ces donn√©es et les segmenter pour ident...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nous segmentons 600 millions d'utilisateurs en temps r√©el chaque jour</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/jugru/blog/421125/">  Chaque jour, les utilisateurs engagent des millions d'activit√©s en ligne.  Le projet FACETz DMP doit structurer ces donn√©es et les segmenter pour identifier les pr√©f√©rences des utilisateurs.  Dans l'article, nous expliquerons comment l'√©quipe a segment√© un public de 600 millions de personnes, trait√© 5 milliards d'√©v√©nements par jour et travaill√© avec des statistiques √† l'aide de Kafka et HBase. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/5Ybt_k53CIE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Le mat√©riel est bas√© sur une transcription d'un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rapport par Artyom Marinov</a> , sp√©cialiste du Big Data chez Directual, de la conf√©rence SmartData 2017. <br><a name="habracut"></a><br>  Je m'appelle Artyom Marinov, je veux parler de la fa√ßon dont nous avons repens√© l'architecture du projet FACETz DMP lorsque je travaillais chez Data Centric Alliance.  Pourquoi nous l'avons fait, √† quoi cela a conduit, dans quelle direction nous sommes all√©s et quels probl√®mes nous avons rencontr√©s. <br><br>  DMP (Data Management Platform) est une plateforme de collecte, de traitement et d'agr√©gation de donn√©es utilisateur.  Les donn√©es sont beaucoup de choses diff√©rentes.  La plateforme compte environ 600 millions d'utilisateurs.  Ce sont des millions de cookies qui vont sur Internet et font divers √©v√©nements.  En g√©n√©ral, une journ√©e ressemble en moyenne √† quelque chose comme ceci: nous voyons environ 5,5 milliards d'√©v√©nements par jour, ils sont en quelque sorte r√©partis sur la journ√©e et, au pic, ils atteignent environ 100 000 √©v√©nements par seconde. <img src="https://habrastorage.org/getpro/habr/post_images/f66/f4d/915/f66f4d9154b1ddad3c3bb8af7e5ba860.png">  Les √©v√©nements sont diff√©rents signaux utilisateur.  Par exemple, une visite sur un site: nous voyons √† partir de quel navigateur l'utilisateur va, son agent utilisateur et tout ce que nous pouvons extraire.  Parfois, nous voyons comment et pour quelles requ√™tes de recherche il est venu sur le site.  Il peut √©galement s'agir de diverses donn√©es du monde hors ligne, par exemple, ce qu'il paie avec des coupons de r√©duction, etc. <br><br>  Nous devons enregistrer ces donn√©es et marquer l'utilisateur dans les soi-disant groupes de segments d'audience.  Par exemple, les segments peuvent √™tre une ¬´femme¬ª qui ¬´aime les chats¬ª et qui recherche un ¬´service de voiture¬ª, elle ¬´a une voiture de plus de trois ans¬ª. <br><br>  Pourquoi segmenter un utilisateur?  Il existe de nombreuses applications pour cela, par exemple la publicit√©.  Divers r√©seaux publicitaires peuvent optimiser les algorithmes de diffusion d'annonces.  Si vous faites la publicit√© de votre service de voiture, vous pouvez mettre en place une campagne de telle sorte que seules les personnes qui ont une vieille voiture affichent des informations, √† l'exclusion des propri√©taires de nouvelles.  Vous pouvez modifier dynamiquement le contenu du site, vous pouvez utiliser les donn√©es pour la notation - il existe de nombreuses applications. <br><br>  Les donn√©es sont obtenues √† partir de nombreux endroits compl√®tement diff√©rents.  Il peut s'agir de param√®tres de pixels directs - c'est-√†-dire que si le client veut analyser son public, il place le pixel sur le site, une image invisible qui est t√©l√©charg√©e depuis notre serveur.  L'essentiel est que nous voyons la visite de l'utilisateur sur ce site: vous pouvez l'enregistrer, commencer √† analyser et comprendre le portrait de l'utilisateur, toutes ces informations sont √† la disposition de notre client. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ad9/ebf/849/ad9ebf84913e17fb9e84a947b256a810.png"><br>  Les donn√©es peuvent √™tre obtenues aupr√®s de diff√©rents partenaires qui voient beaucoup de donn√©es et souhaitent les mon√©tiser de diff√©rentes mani√®res.  Les partenaires peuvent fournir des donn√©es en temps r√©el et effectuer des t√©l√©chargements p√©riodiques sous forme de fichiers. <br><br>  Exigences cl√©s: <br><br><ul><li>  √âvolutivit√© horizontale; </li><li>  √âvaluation du volume de l'audience; </li><li>  Commodit√© du suivi et du d√©veloppement; </li><li>  Bonne vitesse de r√©action aux √©v√©nements. </li></ul><br>  L'une des principales exigences du syst√®me est l'√©volutivit√© horizontale.  Il y a un tel moment que lorsque vous d√©veloppez un portail ou une boutique en ligne, vous pouvez estimer le nombre de vos utilisateurs (comment il va cro√Ætre, comment cela va changer) et comprendre approximativement combien de ressources sont n√©cessaires, et comment la boutique va vivre et se d√©velopper au fil du temps. <br><br>  Lorsque vous d√©veloppez une plate-forme similaire √† DMP, vous devez √™tre pr√©par√© au fait que tout grand site - l'Amazonie conditionnelle - peut y mettre votre pixel, et vous devrez travailler avec le trafic de l'ensemble de ce site, alors que vous ne devriez pas tomber, et les indicateurs les syst√®mes ne devraient pas en quelque sorte changer de cela. <br><br>  Il est √©galement tr√®s important de pouvoir comprendre le volume d'une certaine audience afin qu'un annonceur potentiel ou quelqu'un d'autre puisse √©laborer un plan m√©dia.  Par exemple, une personne vient √† vous et vous demande de savoir combien de femmes enceintes de Novossibirsk recherchent un pr√™t hypoth√©caire afin d'√©valuer s'il est logique de les cibler ou non. <br><br>  Du point de vue du d√©veloppement, vous devez pouvoir surveiller froidement tout ce qui se passe dans votre syst√®me, d√©boguer une partie du trafic r√©el, etc. <br><br>  L'une des exigences syst√®me les plus importantes est une bonne vitesse de r√©action aux √©v√©nements.  Plus les syst√®mes r√©pondent rapidement aux √©v√©nements, mieux c'est, c'est √©vident.  Si vous cherchez des billets de th√©√¢tre, alors si vous voyez une sorte d'offre de r√©duction apr√®s une journ√©e, deux jours ou m√™me une heure - cela peut ne pas √™tre pertinent, car vous pourriez d√©j√† acheter des billets ou aller √† une repr√©sentation.  Lorsque vous cherchez une perceuse - vous la recherchez, trouvez, achetez, accrochez une √©tag√®re, et apr√®s quelques jours, le bombardement commence: "Achetez une perceuse!". <br><br><h3>  Comme avant </h3><br>  L'article dans son ensemble porte sur le recyclage de l'architecture.  Je voudrais vous dire quel √©tait notre point de d√©part, comment tout fonctionnait avant les changements. <br><br>  Toutes les donn√©es que nous avions, qu'il s'agisse d'un flux de donn√©es direct ou de journaux, √©taient stock√©es sur un stockage de fichiers distribu√© HDFS.  Ensuite, il y avait un certain processus qui √©tait p√©riodiquement lanc√©, prenait tous les fichiers non trait√©s de HDFS et les convertissait en demandes d'enrichissement de donn√©es dans HBase (¬´demandes PUT¬ª). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3c6/902/3eb/3c69023eb0fc851d8acc327a7b57fb22.png"><br><br><h3>  Comment stockons-nous les donn√©es dans HBase </h3><br>  Il s'agit d'une base de donn√©es chronologique en colonnes.  Elle a le concept d'une cl√© de ligne - c'est la cl√© sous laquelle vous stockez vos donn√©es.  Nous utilisons l'ID utilisateur comme cl√©, l'ID utilisateur, que nous g√©n√©rons lorsque nous voyons l'utilisateur pour la premi√®re fois.  √Ä l'int√©rieur de chaque cl√©, les donn√©es sont divis√©es en famille de colonnes - entit√©s au niveau desquelles vous pouvez g√©rer les m√©ta-informations de vos donn√©es.  Par exemple, vous pouvez stocker un millier de versions d'enregistrements pour les ¬´donn√©es¬ª de la famille de colonnes et les stocker pendant deux mois, et pour la famille de colonnes ¬´brutes¬ª - un an, en option. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/89f/fb5/46e/89ffb546efcad40cd08d140df54ac6a4.png"><br>  Au sein de la famille de colonnes, il existe de nombreux qualificateurs de colonne (colonne ci-apr√®s).  Nous utilisons divers attributs utilisateur comme colonne.  Il peut s'agir de l'URL vers laquelle il est all√©, de l'adresse IP, de la requ√™te de recherche.  Et surtout, beaucoup d'informations sont stock√©es dans chaque colonne.  √Ä l'int√©rieur de l'URL de la colonne, il peut √™tre indiqu√© que l'utilisateur est all√© sur smartdataconf.ru, puis sur d'autres sites.  Et l'horodatage est utilis√© comme version - vous voyez un historique ordonn√© des visites des utilisateurs.  Dans notre cas, nous pouvons d√©terminer que l'utilisateur est venu sur le site Web de smartdataconf avec le mot-cl√© ¬´conf√©rence¬ª, car il a le m√™me horodatage. <br><br><h3>  Travailler avec HBase </h3><br>  Il existe plusieurs options pour travailler avec HBase.  Il peut s'agir de demandes PUT (demande de changement de donn√©es), de demande GET ("donnez-moi toutes les donn√©es sur l'utilisateur Vasya", etc.).  Vous pouvez ex√©cuter des requ√™tes SCAN - analyse s√©quentielle multithread de toutes les donn√©es dans HBase.  Nous l'avons utilis√© plus t√¥t pour baliser dans les segments d'audience. <br><br>  Il y avait une t√¢che appel√©e Analytics Engine, qui s'ex√©cutait une fois par jour et analysait HBase dans plusieurs threads.  Pour chaque utilisateur, elle a extrait toute l'histoire de HBase et l'a ex√©cut√©e √† travers un ensemble de scripts analytiques. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fba/b4c/674/fbab4c674fabf2f07e0dc8553e8b6cfc.png"><br>  Qu'est-ce qu'un script analytique?  Il s'agit d'une sorte de bo√Æte noire (classe java), qui re√ßoit toutes les donn√©es utilisateur en entr√©e et donne un ensemble de segments qu'il consid√®re comme appropri√© en sortie.  Nous donnons tout au script que nous voyons - IP, visites, UserAgent, etc., et sur la sortie les scripts donnent: ¬´c'est une femme, aime les chats, n'aime pas les chiens¬ª. <br><br>  Ces donn√©es ont √©t√© transmises aux partenaires, des statistiques ont √©t√© prises en compte.  Il √©tait important pour nous de comprendre combien de femmes en g√©n√©ral, combien d'hommes, combien de gens aiment les chats, combien ont ou n'ont pas de voiture, etc. <br><br>  Nous avons stock√© des statistiques dans MongoDB et √©crit en incr√©mentant un compteur de segment sp√©cifique pour chaque jour.  Nous avions un graphique du volume de chaque segment pour chaque jour. <br><br>  Ce syst√®me √©tait bon pour l'√©poque.  Il permettait de se redimensionner horizontalement, de grandir, permettait d'estimer le volume de l'audience, mais il avait un certain nombre d'inconv√©nients. <br><br>  Il n'√©tait pas toujours possible de comprendre ce qui se passait dans le syst√®me, de consulter les journaux.  Pendant que nous √©tions √† l'h√©bergeur pr√©c√©dent, la t√¢che a souvent √©chou√© pour diverses raisons.  Il y avait un cluster Hadoop de 20+ serveurs, une fois par jour, l'un des serveurs se bloquait de mani√®re stable.  Cela a conduit au fait que la t√¢che pouvait partiellement tomber et ne pas calculer les donn√©es.  Il fallait avoir le temps de le red√©marrer et, √©tant donn√© qu'il fonctionnait pendant plusieurs heures, il y avait un certain nombre de nuances. <br><br>  La chose la plus fondamentale que l'architecture existante ne remplissait pas √©tait que le temps de r√©action √† l'√©v√©nement √©tait trop long.  Il y a m√™me une histoire √† ce sujet.  Il y avait une entreprise qui accordait des microcr√©dits √† la population des r√©gions et nous nous sommes associ√©s √† elle.  Leur client vient sur le site, remplit une demande de microcr√©dit, l'entreprise doit donner une r√©ponse en 15 minutes: sont-ils pr√™ts √† accorder ou non un pr√™t.  Si vous √™tes pr√™t, ils ont imm√©diatement transf√©r√© de l'argent sur la carte. <br><br>  Tout fonctionnait plut√¥t bien.  Le client a d√©cid√© de v√©rifier comment cela se passe g√©n√©ralement: il a pris un ordinateur portable s√©par√©, install√© un syst√®me propre, visit√© de nombreuses pages sur Internet et s'est rendu sur son site.  Ils voient qu'il y a une demande, et en r√©ponse, nous disons qu'il n'y a pas encore de donn√©es.  Le client demande: "Pourquoi n'y a-t-il pas de donn√©es?" <br><br>  Nous expliquons: il y a un certain d√©calage avant que l'utilisateur n'agisse.  Les donn√©es sont envoy√©es √† HBase, trait√©es et ce n'est qu'alors que le client re√ßoit le r√©sultat.  Il semblerait que si l'utilisateur n'a pas vu la publicit√© - tout est en ordre, il ne se passera rien de mal.  Mais dans cette situation, l'utilisateur pourrait ne pas obtenir de pr√™t en raison du d√©calage. <br><br>  Ce n'est pas un cas isol√© et il a fallu passer √† un syst√®me temps r√©el.  Que voulons-nous d'elle? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ad8/103/d08/ad8103d08bb70410bcc51c8fdd99b3f5.png"><br>  Nous voulons √©crire des donn√©es dans HBase d√®s que nous les voyons.  Nous avons vu une visite, enrichi tout ce que nous savons et envoy√© √† Storage.  D√®s que les donn√©es du stockage ont chang√©, vous devez ex√©cuter imm√©diatement l'ensemble complet des scripts analytiques dont nous disposons.  Nous voulons la commodit√© de la surveillance et du d√©veloppement, la possibilit√© d'√©crire de nouveaux scripts, de les d√©boguer en morceaux de trafic r√©el.  Nous voulons comprendre ce que le syst√®me est actuellement occup√©. <br><br>  La premi√®re chose avec laquelle nous avons commenc√© est de r√©soudre le deuxi√®me probl√®me: segmenter l'utilisateur imm√©diatement apr√®s avoir modifi√© les donn√©es le concernant dans HBase.  Initialement, nous avions des n≈ìuds de travail (des t√¢ches de r√©duction de carte ont √©t√© lanc√©es sur eux) situ√©s au m√™me endroit que HBase.  Dans un certain nombre de cas, c'√©tait tr√®s bien - les calculs sont effectu√©s √† c√¥t√© des donn√©es, les t√¢ches fonctionnent assez rapidement, peu de trafic passe par le r√©seau.  Il est clair que la t√¢che consomme certaines ressources, car elle ex√©cute des scripts analytiques complexes. <br><br>  Lorsque nous allons travailler en temps r√©el, la nature de la charge sur HBase change.  Nous passons √† des lectures al√©atoires au lieu de lectures s√©quentielles.  Il est important que la charge sur HBase soit attendue - nous ne pouvons pas permettre √† quelqu'un d'ex√©cuter la t√¢che sur le cluster Hadoop et de g√¢cher les performances de HBase. <br><br>  La premi√®re chose que nous avons faite a √©t√© de d√©placer HBase sur des serveurs s√©par√©s.  A √©galement modifi√© BlockCache et BloomFilter.  Ensuite, nous avons fait un bon travail sur la fa√ßon de stocker les donn√©es dans HBase.  Ils ont √† peu pr√®s retravaill√© le syst√®me dont j'ai parl√© au d√©but et ont r√©colt√© les donn√©es elles-m√™mes. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/191/f68/3c9/191f683c9cddf8d90f43cafc5c1163a3.png"><br>  De l'√©vidence: nous avons stock√© IP sous forme de cha√Æne et sommes devenus longs en nombre.  Certaines donn√©es ont √©t√© class√©es, effectu√©es des choses de vocabulaire, etc.  L'essentiel est qu'√† cause de cela, nous avons pu secouer HBase environ deux fois - de 10 To √† 5 To.  HBase a un m√©canisme similaire aux d√©clencheurs dans une base de donn√©es r√©guli√®re.  Il s'agit d'un m√©canisme de coprocesseur.  Nous avons √©crit un coprocesseur qui, lorsqu'un utilisateur passe √† HBase, envoie l'ID utilisateur √† Kafka. <br><br>  L'ID utilisateur est dans Kafka.  En outre, il existe un certain ¬´segmentateur¬ª de services.  Il lit le flux d'identifiants utilisateur et ex√©cute sur eux tous les m√™mes scripts qu'avant, demandant des donn√©es √† HBase.  Le processus a √©t√© lanc√© sur 10% du trafic, nous avons regard√© comment cela fonctionne.  Tout √©tait plut√¥t bien. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8c1/589/928/8c15899287c8a623bb63df3f85ba84e6.png"><br>  Ensuite, nous avons commenc√© √† augmenter la charge et avons constat√© un certain nombre de probl√®mes.  La premi√®re chose que nous avons vue est que le service fonctionne, se segmente, puis tombe de Kafka, se connecte et recommence √† fonctionner.  Plusieurs services - ils s'entraident.  Puis le suivant tombe, un autre et ainsi de suite en cercle.  Dans le m√™me temps, la gamme d'utilisateurs pour la segmentation n'est presque pas ratiss√©e. <br><br>  Cela √©tait d√ª √† la particularit√© du m√©canisme de battement de c≈ìur dans Kafka, alors c'√©tait toujours la version 0.8.  Le battement de c≈ìur, c'est quand les consommateurs disent au courtier s'ils sont vivants ou non, dans notre cas, rapporte le segmentateur.  La chose suivante s'est produite: nous avons re√ßu un assez gros paquet de donn√©es, envoy√© pour traitement.  Pendant un certain temps, cela a fonctionn√©, pendant que cela a fonctionn√© - aucun battement de c≈ìur n'a √©t√© envoy√©.  Les courtiers ont cru que le consommateur √©tait mort et l'ont d√©sactiv√©. <br><br>  Le consommateur a travaill√© jusqu'au bout, gaspillant de pr√©cieux processeurs, a essay√© de dire que le pack de donn√©es avait √©t√© √©labor√© et que le suivant pouvait √™tre pris, mais il a √©t√© refus√© parce que l'autre avait emport√© ce avec quoi il travaillait.  Nous l'avons corrig√© en faisant notre battement de chaleur en arri√®re-plan, puis la v√©rit√© est venue d'une nouvelle version de Kafka o√π nous avons r√©solu ce probl√®me. <br><br>  Puis la question s'est pos√©e: sur quel type de mat√©riel nos segmentateurs devraient-ils √™tre install√©s?  La segmentation est un processus gourmand en ressources (li√© au processeur).  Il est important que le service consomme non seulement beaucoup de CPU, mais charge √©galement le r√©seau.  Le trafic atteint d√©sormais 5 Gbit / s.  La question √©tait: o√π mettre les services, sur de nombreux petits serveurs ou un peu gros. <br><br>  √Ä ce moment, nous avons d√©j√† d√©m√©nag√© sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">servers.com</a> sur du bare metal.  Nous avons discut√© avec les gars des serveurs, ils nous ont aid√©s, ont permis de tester le travail de notre solution √† la fois sur un petit nombre de serveurs chers, et sur de nombreux serveurs peu co√ªteux avec des CPU puissants.  Nous avons choisi l'option appropri√©e, en calculant le co√ªt unitaire de traitement d'un √©v√©nement par seconde.  Soit dit en passant, le choix s'est port√© sur un Dell R230 suffisamment puissant et en m√™me temps extr√™mement abordable, ils l'ont lanc√© - tout a fonctionn√©. <br><br>  Il est important qu'apr√®s que le segmentateur ait marqu√© l'utilisateur en segments, le r√©sultat de son analyse revienne √† Kafka, dans un certain sujet R√©sultat de segmentation. <br><br>  De plus, nous pouvons nous connecter ind√©pendamment √† ces donn√©es par diff√©rents consommateurs qui n'interf√©reront pas les uns avec les autres.  Cela nous permet de fournir des donn√©es de mani√®re ind√©pendante √† chaque partenaire, qu'il s'agisse de partenaires externes, DSP interne, Google, statistiques. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1e7/051/526/1e705152621996ed538a6a3910e8db47.png"><br>  Avec les statistiques, il y a aussi un point int√©ressant: plus t√¥t, nous pourrions augmenter la valeur des compteurs dans MongoDB, combien d'utilisateurs √©taient dans un certain segment pour un certain jour.  Maintenant, cela ne peut pas √™tre fait car nous analysons maintenant chaque utilisateur apr√®s avoir termin√© un √©v√©nement, c'est-√†-dire  plusieurs fois par jour. <br><br>  Par cons√©quent, nous avons d√ª r√©soudre le probl√®me du comptage du nombre unique d'utilisateurs dans le flux.  Pour ce faire, nous avons utilis√© la structure de donn√©es HyperLogLog et son impl√©mentation dans Redis.  La structure des donn√©es est probabiliste.  Cela signifie que vous pouvez y ajouter des identifiants utilisateur, les identifiants eux-m√™mes ne seront pas stock√©s, vous pouvez donc stocker des millions d'identifiants uniques dans HyperLogLog extr√™mement compacts, et cela prendra jusqu'√† 12 kilo-octets par cl√©. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2a6/572/614/2a6572614da5ccffd52271292e646e9d.png"><br><br>  Vous ne pouvez pas obtenir les identifiants vous-m√™me, mais vous pouvez conna√Ætre la taille de cet ensemble.  √âtant donn√© que la structure des donn√©es est probabiliste, il y a une erreur.  Par exemple, si vous avez un segment ¬´aime les chats¬ª, faisant une demande pour la taille de ce segment pour un certain jour, vous recevrez 99,2 millions et cela signifiera quelque chose comme ¬´de 99 millions √† 100 millions¬ª. <br><br>  √âgalement dans HyperLogLog, vous pouvez obtenir la taille de l'union de plusieurs ensembles.  Disons que vous avez deux segments: ¬´aime les phoques¬ª et ¬´aime les chiens¬ª.  Disons les 100 premiers millions, le second 1 million. On peut se demander: "Combien d'animaux aiment-ils?"  et obtenez la r√©ponse "environ 101 millions" avec une erreur de 1%.  Il serait int√©ressant de calculer combien les chats et les chiens sont aim√©s en m√™me temps, mais cela est assez difficile. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/380/74d/500/38074d5004513c86015c8d2770047f56.png"><br>  D'une part, vous pouvez conna√Ætre la taille de chaque ensemble, conna√Ætre la taille de l'union, ajouter, soustraire l'un de l'autre et obtenir l'intersection.  Mais du fait que la taille de l'erreur peut √™tre sup√©rieure √† la taille de l'intersection finale, le r√©sultat final peut √™tre de la forme "de -50 √† 50 000". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/08d/3ba/520/08d3ba520f5c91efd84822d63f299c83.png"><br>  Nous avons beaucoup travaill√© sur la fa√ßon d'augmenter les performances lors de l'√©criture de donn√©es dans Redis.  Initialement, nous avons atteint 200 000 op√©rations par seconde.  Mais lorsque chaque utilisateur a plus de 50 segments - enregistrement d'informations sur chaque utilisateur - 50 op√©rations.  Il s'av√®re que notre bande passante est assez limit√©e et, dans cet exemple, nous ne pouvons pas √©crire d'informations sur plus de 4 000 utilisateurs par seconde, c'est plusieurs fois moins que ce dont nous avons besoin. <br><br>  Nous avons cr√©√© une ¬´proc√©dure stock√©e¬ª distincte dans Redis via Lua, nous l'avons charg√©e √† cet endroit et avons commenc√© √† lui passer une cha√Æne avec la liste compl√®te des segments d'un utilisateur.  La proc√©dure √† l'int√©rieur coupera la cha√Æne pass√©e dans les mises √† jour HyperLogLog n√©cessaires et enregistrera les donn√©es, nous avons donc atteint environ 1 million de mises √† jour par seconde. <br><br>  Un peu de hardcore: Redis est un thread unique, vous pouvez l'√©pingler √† un c≈ìur de processeur et une carte r√©seau √† un autre et atteindre 15% de performances suppl√©mentaires, en √©conomisant sur le changement de contexte.  En plus de cela, le point important est que vous ne pouvez pas simplement regrouper la structure de donn√©es, car les op√©rations d'obtention de la puissance des unions d'ensembles ne sont pas regroup√©es <br><br><h3>  Kafka est un excellent outil </h3><br>  Vous voyez que Kafka est notre principal outil de transport dans le syst√®me. <br>  Il a l'essence du "sujet".  C'est l√† que vous √©crivez les donn√©es, mais essentiellement - la file d'attente.  Dans notre cas, il y a plusieurs files d'attente.  L'un d'eux est l'identifiant des utilisateurs qu'il faut segmenter.  Le second est les r√©sultats de segmentation. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f35/eb3/8c2/f35eb38c205fec791ea2f42d41a8c875.png"><br>  Un sujet est un ensemble de partitions.  Il est divis√© en quelques morceaux.  Chaque partition est un fichier sur le disque dur.  Lorsque vos producteurs √©crivent des donn√©es, ils √©crivent des morceaux de texte √† la fin de la partition.  Lorsque vos consommateurs lisent les donn√©es, ils lisent simplement √† partir de ces partitions. <br><br>  L'important est que vous puissiez connecter ind√©pendamment plusieurs groupes de consommateurs, ils consommeront des donn√©es sans interf√©rer les uns avec les autres.  Ceci est d√©termin√© par le nom du groupe de consommateurs et est obtenu comme suit. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/157/5f7/23d/1575f723d77042fd058b9c30bc050247.png"><br>  Il y a une telle chose comme d√©calage, la position o√π le groupe de consommateurs est maintenant situ√© sur chaque partition.  Par exemple, le groupe A consomme le septi√®me message de partition1 et le cinqui√®me de partition2.  Le groupe B, ind√©pendant de A, a un autre d√©calage. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f8a/10f/1a0/f8a10f1a04b8614f6b9a437142b0db7b.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous pouvez faire √©voluer votre groupe de consommateurs horizontalement, ajouter un autre processus ou serveur. Cela se produira une r√©affectation de partition (le courtier Kafka attribuera √† chaque consommateur une liste de partitions pour la consommation) Cela signifie que le premier groupe de consommateurs commencera √† consommer uniquement la partition 1 et le second ne consommera que la partition 2. Si certains consommateurs meurent (par exemple, le battement de foyer ne vient pas), une nouvelle r√©affectation se produit , chaque consommateur re√ßoit une liste de partition √† jour pour traitement.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/56b/40b/bde/56b40bbde5b1890d35f67a481c4a6462.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C'est assez pratique. Tout d'abord, vous pouvez manipuler l'offset pour chaque groupe de consommateurs. Imaginez qu'il existe un partenaire auquel vous transf√©rez des donn√©es de ce sujet avec les r√©sultats de la segmentation. Il √©crit qu'il a accidentellement perdu le dernier jour de donn√©es en raison d'un bogue. Et vous, pour le groupe de consommateurs de ce client, reculez simplement une journ√©e et versez-y toute la journ√©e de donn√©es. Nous pouvons √©galement avoir notre propre groupe de consommateurs, nous connecter au trafic de production, regarder ce qui se passe et d√©boguer sur des donn√©es r√©elles. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ainsi, nous avons r√©alis√© que nous avons commenc√© √† segmenter les utilisateurs lors des changements, nous pouvons connecter ind√©pendamment de nouveaux consommateurs, nous √©crivons des statistiques et nous pouvons les regarder. Vous devez maintenant obtenir les donn√©es √©crites dans HBase imm√©diatement apr√®s leur arriv√©e.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/c4e/eec/d6c/c4eeecd6ce987e902fee723a089ab780.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comment nous l'avons fait. Il y avait autrefois un chargement de donn√©es par lots. Il y avait un chargeur par lots, il traitait les fichiers journaux d'activit√© de l'utilisateur: si l'utilisateur faisait 10 visites, le lot venait pour 10 √©v√©nements, il √©tait enregistr√© dans HBase en une seule op√©ration. Il n'y avait qu'un seul √©v√©nement par segmentation. Maintenant, nous voulons √©crire chaque √©v√©nement s√©par√© dans le stockage. Nous augmenterons consid√©rablement le flux d'√©criture et le flux de lecture. Le nombre d'√©v√©nements par segmentation augmentera √©galement.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/79a/849/910/79a8499101ac2cb58ccf272abb668f6f.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La premi√®re chose que nous avons faite a √©t√© de porter HBase sur le SSD. Par des moyens standard, cela n'est pas particuli√®rement fait. Cela a √©t√© fait en utilisant HDFS. Vous pouvez dire qu'un r√©pertoire sp√©cifique sur HDFS doit se trouver sur un tel groupe de disques. Il y avait un probl√®me cool avec le fait que lorsque nous avons amen√© HBase sur le SSD et l'avons doubl√©, tous les instantan√©s y sont arriv√©s aussi, et nos SSD se sont termin√©s assez rapidement. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ceci est √©galement r√©solu, nous avons commenc√© √† exporter p√©riodiquement des instantan√©s vers un fichier, √† √©crire dans un autre r√©pertoire HDFS et √† supprimer toutes les m√©ta-informations sur les instantan√©s. Si vous devez restaurer - prenez le fichier enregistr√©, importez et restaurez. Cette op√©ration est tr√®s peu fr√©quente, heureusement.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√âgalement sur le SSD, ils ont sorti Write Ahead Log, torsad√© MemStore, activ√© l'option de blocage de cache √† l'√©criture. Il vous permet de les mettre imm√©diatement dans le cache de bloc lors de l'enregistrement des donn√©es. C'est tr√®s pratique car dans notre cas, si nous avons enregistr√© les donn√©es, il est fort probable qu'elles soient imm√©diatement lues. Cela a √©galement donn√© certains avantages. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ensuite, nous avons chang√© toutes nos sources de donn√©es pour √©crire des donn√©es dans Kafka. D√©j√† √† partir de Kafka, nous avons enregistr√© des donn√©es dans HDFS pour maintenir la compatibilit√© descendante, notamment pour que nos analystes puissent travailler avec des donn√©es, ex√©cuter des t√¢ches MapReduce et analyser leurs r√©sultats. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons connect√© un groupe de consommateurs distinct qui √©crit des donn√©es dans HBase. Il s'agit en fait d'un wrapper qui lit √† partir de Kafka et forme les PUT dans HBase.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/d53/267/0b3/d532670b344a70dadf97c5c4674b1596.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons lanc√© deux circuits en parall√®le afin de ne pas rompre la compatibilit√© descendante et de ne pas d√©grader les performances du syst√®me. Un nouveau sch√©ma n'a √©t√© lanc√© que pour un certain pourcentage de trafic. √Ä 10%, tout √©tait plut√¥t cool. Mais √† une plus grande charge, les segmenteurs ne pouvaient pas faire face au flux de segmentation. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/d20/3fa/78c/d203fa78c3d0b80ee7c7a5dce34f558b.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous collectons la m√©trique "combien de messages se trouvaient dans Kafka avant sa lecture." C'est une bonne m√©trique. Initialement, nous avons collect√© la m√©trique "combien de messages bruts sont maintenant", mais elle ne dit rien de sp√©cial. Vous regardez: ¬´J'ai un million de messages bruts¬ª, alors quoi? Pour interpr√©ter ce million, vous devez savoir √† quelle vitesse le segmentateur (consommateur) fonctionne, ce qui n'est pas toujours clair.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Avec cette m√©trique, vous voyez imm√©diatement que les donn√©es sont √©crites dans la file d'attente, extraites de celle-ci, et vous voyez combien elles s'attendent √† √™tre trait√©es. </font><font style="vertical-align: inherit;">Nous avons vu que nous n'avions pas le temps de segmenter, et le message √©tait dans la file d'attente plusieurs heures avant de le lire. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous pourriez simplement ajouter de la capacit√©, mais ce serait trop </font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">cher</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Par cons√©quent, nous avons essay√© d'optimiser.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Auto-mise √† l'√©chelle </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons HBase. L'utilisateur change, son identifiant vole √† Kafka. Le sujet est divis√© en partitions, la partition cible est s√©lectionn√©e par ID utilisateur. Cela signifie que lorsque vous voyez l'utilisateur "Vasya" - il va √† la partition 1. Lorsque vous voyez "Petya" - √† la partition 2. C'est pratique - vous pouvez r√©aliser que vous verrez un consommateur sur une instance de votre service, et le second - de l'autre. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/299/573/aef/299573aefcae8b909623e246d4a2cf80.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons commenc√© √† regarder ce qui se passait. Un comportement utilisateur typique sur Internet consiste √† acc√©der √† un site Web et √† ouvrir plusieurs onglets d'arri√®re-plan. La seconde consiste √† se rendre sur le site et √† faire quelques clics pour acc√©der √† la page de destination.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous regardons la file d'attente de segmentation et voyons ce qui suit: L'utilisateur A a visit√© la page. 5 autres √©v√©nements viennent de cet utilisateur - chacun signifie une ouverture de page. Nous traitons chaque √©v√©nement de l'utilisateur. Mais en fait, les donn√©es de HBase contiennent les 5 visites. Nous traitons les 5 visites pour la premi√®re fois, la deuxi√®me fois, etc. - nous gaspillons les ressources du processeur. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/6df/eba/fbf/6dfebafbf435cfb43e5b71cc7d2016fd.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Par cons√©quent, nous avons commenc√© √† stocker un certain cache local sur chacun des segmenteurs avec la date de la derni√®re analyse de cet utilisateur. Autrement dit, nous l'avons trait√©, √©crit son ID utilisateur et son horodatage dans le cache. Chaque message kafka a √©galement un horodatage - nous le comparons simplement: si l'horodatage dans la file d'attente est inf√©rieur √† la date de la derni√®re segmentation - nous avons d√©j√† analys√© l'utilisateur pour ces donn√©es, et vous pouvez simplement ignorer cet √©v√©nement.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les √©v√©nements utilisateur (Red A) peuvent √™tre diff√©rents et ils ne fonctionnent plus. L'utilisateur peut ouvrir plusieurs onglets d'arri√®re-plan, ouvrir plusieurs liens d'affil√©e, peut-√™tre que le site a plusieurs de nos partenaires √† la fois, chacun envoyant ces donn√©es. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Notre pixel peut voir la visite de l'utilisateur, puis une autre action - nous nous enverrons son casque. Cinq √©v√©nements arrivent, nous traitons le premier A. rouge. Si l'√©v√©nement est arriv√©, il est d√©j√† dans HBase. Nous voyons des √©v√©nements, parcourons un ensemble de scripts. Nous voyons l'√©v√©nement suivant, et l√† tous les m√™mes √©v√©nements, car ils sont d√©j√† enregistr√©s. Nous l'ex√©cutons √† nouveau et enregistrons le cache avec la date, le comparons avec l'horodatage de l'√©v√©nement.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/3f5/a41/48b/3f5a4148b5b8f14067816cda7b7bfade.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gr√¢ce √† cela, le syst√®me a obtenu la propri√©t√© d'auto-√©volutivit√©. L'axe des y est le pourcentage de ce que nous faisons avec les ID utilisateur lorsqu'ils nous parviennent. Vert - le travail que nous avons effectu√© a lanc√© le script de segmentation. Jaune - nous ne l'avons pas fait, car D√©j√† segment√© exactement ces donn√©es. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/902/e54/03d/902e5403d2dc07b5f2a4ceaf57ea3e47.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">On peut voir qu'il y a des ressources la nuit, il y a moins de flux de donn√©es et vous pouvez segmenter chaque deuxi√®me √©v√©nement. Une journ√©e de ressources plus petite et nous ne segmentons que 20% des √©v√©nements. Un saut √† la fin de la journ√©e - le partenaire a t√©l√©charg√© des fichiers de donn√©es que nous n'avions pas vus auparavant, et ils devaient √™tre segment√©s ¬´honn√™tement¬ª.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le syst√®me lui-m√™me s'adapte √† la croissance de la charge. Si nous avons un tr√®s gros partenaire, nous traitons les m√™mes donn√©es mais un peu moins souvent. Dans ce cas, les caract√©ristiques du syst√®me se d√©t√©rioreront le soir, la segmentation sera retard√©e non pas pendant 2-3 secondes, mais pendant une minute. Le matin, ajoutez les serveurs et revenez aux r√©sultats souhait√©s. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ainsi, nous avons √©conomis√© environ 5 fois sur les serveurs. Maintenant, nous travaillons sur 10 serveurs, et cela prendrait donc 50 √† 60.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La petite chose bleue en haut, ce sont les bots. C'est la partie la plus difficile de la segmentation. Ils ont un grand nombre de visites, ils cr√©ent une tr√®s grande charge sur le fer. Nous voyons chaque bot sur un serveur s√©par√©. Nous pouvons y collecter un cache local avec une liste noire de bots. Introduit un simple anti-fraude: si l'utilisateur fait trop de visites pendant un certain temps, alors quelque chose ne va pas avec lui, nous ajoutons √† la liste noire pendant un certain temps. C'est une petite bande bleue, environ 5%. Ils nous ont permis d'√©conomiser 30% suppl√©mentaires sur le processeur. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ainsi, nous avons atteint ce que nous voyons l'ensemble du pipeline de traitement des donn√©es √† chaque √©tape. Nous voyons des mesures de la quantit√© de message dans Kafka. Le soir, quelque chose s'estompe quelque part, le temps de traitement passe √† une minute, puis il est rel√¢ch√© et revient √† la normale.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/58e/fed/411/58efed411c7c5a4348b9280b3c963c16.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous pouvons surveiller comment nos actions avec le syst√®me affectent son d√©bit, nous pouvons voir combien le script s'ex√©cute, o√π il est n√©cessaire d'optimiser et combien peut √™tre enregistr√©. </font><font style="vertical-align: inherit;">Nous pouvons voir la taille des segments, la dynamique de la taille des segments, √©valuer leur association et leur intersection. </font><font style="vertical-align: inherit;">Cela peut √™tre fait pour plus ou moins les m√™mes tailles de segment.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Qu'aimeriez-vous affiner? </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons un cluster Hadoop avec quelques ressources informatiques. Il est occup√© - les analystes y travaillent pendant la journ√©e, mais la nuit, il est pratiquement libre. En g√©n√©ral, nous pouvons conteneuriser et ex√©cuter le segmenteur en tant que processus distinct au sein de notre cluster. Nous voulons stocker plus pr√©cis√©ment les statistiques afin de calculer plus pr√©cis√©ment le volume de l'intersection. Nous avons √©galement besoin d'une optimisation sur le CPU. Cela affecte directement le co√ªt de la d√©cision. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour r√©sumer: Kafka est bon, mais, comme avec toute autre technologie, vous devez comprendre comment cela fonctionne √† l'int√©rieur et ce qui lui arrive. Par exemple, la garantie de priorit√© des messages ne fonctionne qu'√† l'int√©rieur de la partition. Si vous envoyez un message qui va √† diff√©rentes partitions, il n'est pas clair dans quel ordre elles seront trait√©es.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les donn√©es r√©elles sont tr√®s importantes. </font><font style="vertical-align: inherit;">Si nous n'avions pas test√© sur le trafic r√©el, alors nous n'aurions probablement pas vu de probl√®mes avec les bots, avec les sessions utilisateur. </font><font style="vertical-align: inherit;">D√©velopperait quelque chose dans le vide, courrait et se coucherait. </font><font style="vertical-align: inherit;">Il est important de surveiller ce que vous jugez n√©cessaire de surveiller et non de surveiller ce que vous ne pensez pas.</font></font><br><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Minute de publicit√©. </font><font style="vertical-align: inherit;">Si vous avez aim√© ce rapport de la conf√©rence SmartData, veuillez noter que </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SmartData 2018</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> se tiendra √† Saint-P√©tersbourg le 15 octobre, une </font><font style="vertical-align: inherit;">conf√©rence pour ceux qui sont plong√©s dans le monde de l'apprentissage automatique, de l'analyse et du traitement des donn√©es. </font><font style="vertical-align: inherit;">Le programme aura beaucoup de choses int√©ressantes, le site a d√©j√† ses premiers intervenants et rapports.</font></font></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr421125/">https://habr.com/ru/post/fr421125/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr421113/index.html">Pr√©sentation de DJI Mavic 2 Pro / Zoom</a></li>
<li><a href="../fr421115/index.html">Contexte dans une application Android</a></li>
<li><a href="../fr421119/index.html">D√©veloppement SmartTV de r√¢teau sous-marin</a></li>
<li><a href="../fr421121/index.html">Streaming vid√©o via un navigateur √† tr√®s faible latence (et WebRTC!)</a></li>
<li><a href="../fr421123/index.html">R√©sum√© des √©v√©nements informatiques de septembre</a></li>
<li><a href="../fr421127/index.html">Webinaires Skillbox Friday: Design & Developers</a></li>
<li><a href="../fr421129/index.html">Comment r√©duire la r√©vision du code de deux semaines √† plusieurs heures. L'exp√©rience de l'√©quipe Yandex.Market</a></li>
<li><a href="../fr421131/index.html">Vuln√©rabilit√© critique des serveurs 1Cloud</a></li>
<li><a href="../fr421133/index.html">LINKa. Clavier en papier. Boutons extra larges</a></li>
<li><a href="../fr421135/index.html">Au / Ni / MgO: transfert de chaleur √† l'√©chelle nanom√©trique</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💅 🎩 🧕🏽 Vergleich der besten APIs zum Filtern obszöner Inhalte 🙍🏻 💊 👨🏿‍🎓</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vollständiges Testen mehrerer APIs zum Filtern von Bildern verschiedener Kategorien wie Nacktheit, Pornografie und Dissektion. 



 Eine Person verste...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vergleich der besten APIs zum Filtern obszöner Inhalte</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/431628/">  Vollständiges Testen mehrerer APIs zum Filtern von Bildern verschiedener Kategorien wie Nacktheit, Pornografie und Dissektion. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/61a/0bd/57a/61a0bd57a558ed9e069c9da24e8696fc.jpg"><br><br>  Eine Person versteht sofort, dass ein bestimmtes Bild unangemessen ist, dh NSFW (Not Safe For Work).  Aber für künstliche Intelligenz ist nicht alles so klar.  Viele Unternehmen versuchen derzeit, effektive Tools zum automatischen Filtern solcher Inhalte zu entwickeln. <br><a name="habracut"></a><br>  Ich wollte verstehen, wie der aktuelle Stand des Marktes ist.  Vergleichen Sie die Wirksamkeit vorhandener Bildfilter-APIs in den folgenden Kategorien: <br><br><ul><li>  Völlige Nacktheit </li><li>  Suggestive Nacktheit (dh Suggestive Nacktheit - ca. Per.) </li><li>  Pornografie / Geschlechtsverkehr </li><li>  Nachahmung / animierter Porno </li><li>  Zerstückelung (Gore) / Gewalt </li></ul><br>  <b>Tl; DR:</b> Wenn Sie nur die beste API herausfinden möchten, können Sie sofort zum Vergleich am Ende des Artikels gehen. <br><br><h1>  Versuchsbedingungen </h1><br>  <b>Datensatz</b> .  Zur Auswertung habe ich meinen NSFW-Datensatz mit einer gleichen Anzahl von Bildern in jeder NSFW-Unterkategorie gesammelt.  Der Datensatz besteht aus 120 Bildern mit 20 positiven NSFW-Bildern für jede der fünf genannten Kategorien und 20 SFW-Bildern.  Ich habe mich entschieden, das öffentlich verfügbare YACVID 180 nicht zu verwenden, da es hauptsächlich auf der Verwendung von Nacktheit als Maß für den NSFW-Inhalt basiert. <br><br>  Das Sammeln von NSFW-Bildern ist mühsam, es ist eine sehr lange und völlig schmerzhafte Aufgabe, die die geringe Anzahl von Bildern erklärt. <br><br>  <b>Der Datensatz steht hier zum Download <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bereit</a> .</b>  <b><u>[Warnung: enthält expliziten Inhalt]</u></b> <b><br><br></b>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier ist eine</a> Tabelle mit Rohergebnissen für jede API und jedes Bild im Datensatz.</b> <br><br><h1>  Metriken </h1><br>  Jeder der Klassifikatoren wird nach allgemein anerkannten Metriken bewertet: <br><br><h3>  Wirklich positiv: TP </h3><br>  Wenn der Klassifikator etwas NSFW aufruft und es tatsächlich NSFW ist. <br><br><h3>  Richtig negativ: TN </h3><br>  Wenn der Klassifikator etwas SFW aufruft und es tatsächlich SFW ist. <br><br><h3>  Falsch positiv: FP </h3><br>  Wenn der Klassifikator etwas NSFW heißt und dies tatsächlich SFW ist. <br><br><h3>  Falsch Negativ: FN </h3><br>  Wenn der Klassifikator etwas SFW nennt, es aber tatsächlich NSFW war. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/462/ef5/45c/462ef545c6e968b3c54ba38417511dce.png"><br><br><h3>  Genauigkeit </h3><br>  Kann das Modell vertrauenswürdig sein, wenn es eine Prognose erstellt? <br><br><h3>  Genauigkeit </h3><br>  Wenn das Modell sagt, dass das Bild NSFW ist, wie oft ist die richtige Prognose? <br><br><h3>  Rückruf </h3><br>  Wenn alle Proben NSFW sind, wie viel identifiziert es? <br><br><h3>  F1-Punktzahl </h3><br>  Es ist eine Mischung aus Fehler und Rückruf, oft ähnlich der Genauigkeit. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ec7/740/69d/ec774069de39f1d76591109e457f0277.png"></div><br><br>  Die folgenden APIs für die Inhaltsmoderation wurden bewertet: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Amazon-Erkennung</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Google</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Microsoft</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Yahoo</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Algorithmus</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Clarifai</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Deepai</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Imagga</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Nanonets</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Sightengine</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>X-Moderator</em></a> </li></ul><br><h1>  Leistung nach Kategorie </h1><br>  Zuerst habe ich jede API in allen NSFW-Kategorien bewertet. <br><br><h1>  Pornografie / Sex </h1><br>  Die APIs von Google und Sightengine sind hier wirklich gut.  Sie waren die einzigen, die alle pornografischen Bilder richtig erkannten.  Nanonets und Algorithmia liegen mit einer Punktzahl von 90% leicht zurück.  Microsoft und Imagga haben die schlechteste Leistung in dieser Kategorie gezeigt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6d9/faf/a65/6d9fafa658b2f527824eb6ae241fa41e.png"></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/d6e/e79/167/d6ee791670e7dfa0425dee823d1ea08e.png"><br><br>  Bilder, die leicht zu identifizieren sind, sind eindeutig pornografisch.  Alle APIs haben die obigen Bilder korrekt erkannt.  Die meisten von ihnen sagten NSFW mit sehr großem Vertrauen voraus. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a01/ca1/939/a01ca19394689c2cac96803ed7c3de26.png"><br><br>  Schwer zu identifizierende Bilder enthalten teilweise geschlossene oder verschwommene Objekte, was die Arbeit erschwert.  Im schlimmsten Fall haben 11 von 12 Systemen einen Fehler mit dem Bild gemacht.  Die Effektivität bei der Erkennung von Pornografie ist sehr unterschiedlich, abhängig von der Intensität des Pornos und der Sichtbarkeit des Inhalts. <br><br><h1>  Völlige Nacktheit </h1><br>  Die meisten APIs zeigten mit vielen Bildern in dieser Kategorie eine überraschend gute Leistung und zeigten eine Erkennungsrate von 100%.  Selbst die APIs mit der niedrigsten Leistung (Clarifai und Algorithmia) zeigten 90%.  Die Definition von Nacktheit war schon immer Gegenstand von Debatten.  Wie aus den Ergebnissen hervorgeht, versagen Systeme normalerweise in zweifelhaften Fällen, wenn es wahrscheinlich ist, dass das Bild noch SFW ist. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c36/6fc/13f/c366fc13f13bf5565f65f7daf4737909.png"></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/45c/436/44d/45c43644d9fd473d51f4f0ca7b6b4e9a.png"><br><br>  In einfachen Bildern ist explizite Nacktheit deutlich sichtbar.  Jeder wird sie ohne Frage NSFW nennen.  Keine einzige API hat einen Fehler gemacht, und die durchschnittliche Punktzahl betrug 0,99. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/83f/c7b/9cd/83fc7b9cde287f7b712fda75471f35b9.png"><br><br>  Bei kontroversen Bildern waren die APIs falsch.  Vielleicht liegt der Grund darin, dass jeder von ihnen Empfindlichkeitseinstellungen hat. <br><br><h1>  Suggestive Nacktheit </h1><br>  Google gewann erneut mit einer Erkennungsrate von 100%.  Sightengine und Nanonets schnitten mit 95% bzw. 90% besser ab als andere.  Automatisierte Systeme erkennen suggestive Nacktheit fast so leicht wie explizit.  Sie machen einen Fehler in Bildern, die normalerweise wie SFW aussehen, mit nur wenigen Anzeichen von Nacktheit. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/40f/cb1/3ba/40fcb13ba029230b0d414a206758eb1a.png"></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a92/bee/4be/a92bee4be11339ccb569a2d85aa4b977.png"><br><br>  Auch hier wurde bei expliziten NSFW-Bildern keine API verwechselt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a6b/b00/f25/a6bb00f254a26a747a6ce0157f2805a4.png"><br><br>  In suggestiver Nacktheit gingen die APIs auseinander.  Wie in bloßer Nacktheit hatten sie unterschiedliche Toleranzschwellen.  Ich selbst bin mir nicht sicher, ob ich diese SFW-Bilder erkennen soll oder nicht. <br><br><h1>  Nachahmung / animierter Porno </h1><br>  Alle APIs zeigten hier eine außergewöhnlich gute Leistung und fanden 100% Beispiele für die Nachahmung von Pornos.  Die einzige Ausnahme war Imagga, bei der ein Bild fehlte.  Ich frage mich, warum die APIs bei dieser Aufgabe so gut funktionieren.  Anscheinend ist es für Algorithmen einfacher, künstlich erzeugte Bilder zu identifizieren als für natürliche. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/855/a76/266/855a762662284a0e4838897912937e4d.png"></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/331/258/a8c/331258a8c34a1d0fffda26bf69dd1824.png"><br><br>  Alle APIs zeigten hervorragende Ergebnisse und hohe Vertrauensbewertungen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fbf/8cf/83a/fbf8cf83a46e0519d3d509df9fb4701d.png"></div><br><br>  Das einzige Bild, auf dem Imagga sich geirrt hat, kann als kein Porno interpretiert werden, wenn man es lange nicht betrachtet. <br><br><h1>  Präparation </h1><br>  Dies ist eine der schwierigsten Kategorien, da die durchschnittliche Erkennungseffizienz durch die API weniger als 50% betrug.  Clarifai und Sightengine übertrafen die Konkurrenz, indem sie 100% der Bilder in dieser Kategorie korrekt erkannten. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cda/6f8/054/cda6f8054f52cd5e5ca122275aea8311.png"></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/1d4/386/c13/1d4386c13acf272b29576b739008e2b3.png"><br><br>  Die APIs handhabten medizinische Bilder am besten, aber selbst 4 von 12 Systemen machten den Fehler auf dem leichtesten von ihnen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/271/abb/d23/271abbd23e9a356933a5a3a961cdb18b.png"><br><br>  Schwierige Bilder haben nichts gemeinsam.  Die Leute werden diese Bilder jedoch sehr leicht als blutig bezeichnen.  Dies bedeutet wahrscheinlich, dass der Grund für die geringe Effizienz der Mangel an verfügbaren Daten für das Training ist. <br><br><h1>  Sichere Bilder </h1><br>  Bilder, die nicht als NSFW identifiziert werden können, gelten als sicher.  Die Datenerfassung an sich ist schwierig, da diese Bilder in der Nähe von NSFW liegen müssen, um die API zu verstehen.  Man kann argumentieren, ob alle diese Bilder SFW sind oder nicht.  Hier zeigten Sightengine und Google das schlechteste Ergebnis, was ihre hervorragende Leistung in anderen Kategorien erklärt.  Sie nennen einfach alle zweifelhaften NSFW-Bilder.  Auf der anderen Seite hat Imagga hier gute Arbeit geleistet, weil es nichts NSFW nennt.  X-Moderator schnitt ebenfalls sehr gut ab. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9d5/930/9a1/9d59309a1e0a0797d96f7aa99d4ee25f.png"></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/489/e3f/1b1/489e3f1b10bb850cc201cd92ab76cd64.png"><br>  <b>Links zu Originalbildern: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW15</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW12</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW6</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW4</a></b> <br><br>  Auf Bildern, die leicht zu identifizieren sind, werden nur kleine Hautflecken angezeigt, und Menschen können sie leicht als SFW identifizieren.  Nur ein oder zwei Systeme haben sie falsch erkannt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/47b/e0d/00c/47be0d00cc4bcf66e0e300468d579099.png"><br>  <b>Links zu Originalbildern: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW17</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW18</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW10</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW3</a></b> <br><br>  Alle schwer zu identifizierenden SFW-Bilder zeigen größere Bereiche der Haut oder des Anime (Systeme berücksichtigen in der Regel Anime-Pornografie).  Die meisten APIs zählten großflächige Bilder als SFW.  Die Frage ist, ist das SFW? <br><br><h1>  Allgemeiner Vergleich </h1><br>  Wenn wir die Wirksamkeit der API in allen NSFW-Kategorien sowie ihre Wirksamkeit bei der korrekten Erkennung von SFW betrachten, können wir den Schluss ziehen, dass das beste F1-Ergebnis und die beste durchschnittliche Genauigkeit des Nanonets-Systems: Es funktioniert in allen Kategorien stabil gut.  Das Google-System zeigt in den NSFW-Kategorien ein außergewöhnlich gutes Ergebnis, markiert jedoch zu oft sichere Bilder als NSFW und erhielt daher eine Geldstrafe für die F1-Metrik. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fa1/a3b/d17/fa1a3bd175db605cc97027a9f531da1a.png"></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c5f/2ff/ee9/c5f2ffee941e3d59df38ea602594da6d.png"></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/153/576/32c/15357632cb346d53743f183a95752995.png"></div><br><br><h1>  Von Entwicklern </h1><br>  Ich habe die Top-5-Systeme auf Genauigkeit und F1-Punktzahl verglichen, um Unterschiede in ihrer Leistung zu bewerten.  Je größer die Fläche des Blütenblattdiagramms ist, desto besser. <br><br><h3>  1. Nanonets </h3><br>  Das Nanonets-System belegte in keiner Kategorie den ersten Platz.  Dies ist jedoch die ausgewogenste Lösung.  Der schwächste Punkt, an dem Sie noch arbeiten können, ist die Erkennungsgenauigkeit von SFW.  Er ist zu empfindlich gegenüber exponierten Bereichen des Körpers. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9d7/b93/04f/9d7b9304f0170027f64cb161a505006e.png"></div><br><br><h3>  2. Google </h3><br>  Google ist das beste in den meisten NSFW-Kategorien, aber das schlechteste in der SFW-Erkennung.  Ich möchte darauf hinweisen, dass ich das Beispiel zum Testen mit Google genommen habe, das heißt, sie sollte diese Bilder "kennen".  Dies kann der Grund für eine wirklich gute Leistung in den meisten Kategorien sein. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b25/27a/348/b2527a3486ea533f49db93f28871a5f5.png"></div><br><br><h3>  3. Clarifai </h3><br>  Clarifai ist wirklich hervorragend darin, die Aufteilung zu bestimmen. Vor den meisten anderen APIs ist das System auch gut ausbalanciert und funktioniert in den meisten Kategorien gut.  Aber es fehlt ihr an Genauigkeit bei der Identifizierung von suggestiver Nacktheit und Pornografie. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/760/cd3/f67/760cd3f6718b5455262636fbf5a5f048.png"></div><br><br><h3>  4. X-Moderator </h3><br>  X-Moderator ist eine weitere ausgewogene API.  Neben der Dissektion identifiziert er die meisten anderen Arten von NSFW eindeutig.  100% ige Genauigkeit bei der Bestimmung von SFW, was dieses System von Wettbewerbern unterscheidet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/36b/dad/79c/36bdad79ca6aca4ab821d6ced6c10fef.png"></div><br><br><h3>  5. Sightengine </h3><br>  Wie Google zeigte das Sightengine-System ein nahezu perfektes Ergebnis bei der Identifizierung von NSFW.  Sie erkannte jedoch kein einziges Bild der Präparation. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8fe/231/303/8fe231303a92ca3ec3d1b8b265474f53.png"></div><br><br><h1>  Preise </h1><br>  Ein weiteres Kriterium bei der Auswahl einer API ist der Preis.  Die Preise aller Unternehmen werden unten verglichen.  Die meisten APIs bieten eine kostenlose Testversion mit eingeschränkter Nutzung an.  Yahoo ist die einzige vollständig kostenlose API, die jedoch eigenständig gehostet werden muss. Diese API ist in dieser Tabelle nicht enthalten. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c1b/0c2/74e/c1b0c274ef386df2a58a1ff46ea24875.png"></div><br><br>  <i>Amazon, Microsoft, Nanonets und DeepAI bieten den niedrigsten Preis von 1.000 USD pro Monat für eine Million API-Aufrufe.</i> <br><br><h1>  Was ist die beste API für die Moderation von Inhalten? </h1><br>  Die subjektive Natur des NSFW-Inhalts macht es schwierig, den Gewinner zu bestimmen. <br><br>  <b>Für soziale Medien eines allgemeinen Themas, das sich mehr auf die Verteilung von Inhalten konzentriert und einen ausgewogenen Klassifikator benötigt, würde ich die Nanonets-API mit der höchsten Bewertung von F1 für den Klassifikator bevorzugen.</b> <br><br>  Wenn sich die Anwendung an Kinder richtet, wäre ich sicher und würde die Google-API aufgrund ihrer beispielhaften Wirksamkeit in allen Kategorien von NSFW wählen, selbst wenn einige normale Inhalte verloren gehen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d97/47f/99a/d9747f99ad72f6a43359821477bce7c3.png"></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ba8/59e/729/ba859e7291c0dc6ebf907a97f87d2f64.png"></div><br><br><h1>  Was ist NSFW wirklich? </h1><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/78c/bae/afa/78cbaeafab83b61961daa9b8a0a31dea.jpg"></div><br><br>  Nachdem ich viel Zeit mit diesem Problem verbracht hatte, erkannte ich eine wichtige Sache: Tatsächlich ist die Definition von NSFW sehr vage.  Jede Person hat ihre eigene Definition.  Was als akzeptabel angesehen wird, hängt weitgehend davon ab, was Ihr Service bietet.  Teilweise Nacktheit ist in einer Dating-Anwendung akzeptabel, jedoch nicht in einem Kinderbett.  Und im Gegenteil in einem medizinischen Journal.  Eine wirklich graue Fläche ist suggestive Nacktheit, wo es unmöglich ist, die richtige Antwort zu bekommen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de431628/">https://habr.com/ru/post/de431628/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de431618/index.html">Harry Potter und die Schwierigkeiten der Übersetzung: ROSMAN und MAJAON gegen das Original</a></li>
<li><a href="../de431620/index.html">"Ich wurde Therapeut oder Psychologe" - Vitaliy Fridman über UX-Tests und mobile Schnittstellen</a></li>
<li><a href="../de431622/index.html">Sehen Sie Flutter Live at Wrike 4. Dezember</a></li>
<li><a href="../de431624/index.html">Sie müssen nicht Fehler beseitigen, sondern den Grund für ihr Auftreten: ein Fall von einem Spieleentwickler</a></li>
<li><a href="../de431626/index.html">Microsoft wird US-Soldaten mit VR-Brillen ausstatten</a></li>
<li><a href="../de431630/index.html">Die Lasersicherheit ist klar oder warum Sie nicht in den Laserstrahl schauen sollten</a></li>
<li><a href="../de431636/index.html">So feiern Sie den Tag der Informationssicherheit</a></li>
<li><a href="../de431638/index.html">Wie wir in die Informationssicherheitsabteilung eines großen Unternehmens kamen und dort anfingen zu arbeiten. Tagebuch zweier junger und vielversprechender Spezialisten</a></li>
<li><a href="../de431642/index.html">Imker versus Mikrocontroller oder die Vorteile von Fehlern</a></li>
<li><a href="../de431644/index.html">Gerade mit TM. v4.0</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
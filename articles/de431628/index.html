<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíÖ üé© üßïüèΩ Vergleich der besten APIs zum Filtern obsz√∂ner Inhalte üôçüèª üíä üë®üèø‚Äçüéì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vollst√§ndiges Testen mehrerer APIs zum Filtern von Bildern verschiedener Kategorien wie Nacktheit, Pornografie und Dissektion. 



 Eine Person verste...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vergleich der besten APIs zum Filtern obsz√∂ner Inhalte</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/431628/">  Vollst√§ndiges Testen mehrerer APIs zum Filtern von Bildern verschiedener Kategorien wie Nacktheit, Pornografie und Dissektion. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/61a/0bd/57a/61a0bd57a558ed9e069c9da24e8696fc.jpg"><br><br>  Eine Person versteht sofort, dass ein bestimmtes Bild unangemessen ist, dh NSFW (Not Safe For Work).  Aber f√ºr k√ºnstliche Intelligenz ist nicht alles so klar.  Viele Unternehmen versuchen derzeit, effektive Tools zum automatischen Filtern solcher Inhalte zu entwickeln. <br><a name="habracut"></a><br>  Ich wollte verstehen, wie der aktuelle Stand des Marktes ist.  Vergleichen Sie die Wirksamkeit vorhandener Bildfilter-APIs in den folgenden Kategorien: <br><br><ul><li>  V√∂llige Nacktheit </li><li>  Suggestive Nacktheit (dh Suggestive Nacktheit - ca. Per.) </li><li>  Pornografie / Geschlechtsverkehr </li><li>  Nachahmung / animierter Porno </li><li>  Zerst√ºckelung (Gore) / Gewalt </li></ul><br>  <b>Tl; DR:</b> Wenn Sie nur die beste API herausfinden m√∂chten, k√∂nnen Sie sofort zum Vergleich am Ende des Artikels gehen. <br><br><h1>  Versuchsbedingungen </h1><br>  <b>Datensatz</b> .  Zur Auswertung habe ich meinen NSFW-Datensatz mit einer gleichen Anzahl von Bildern in jeder NSFW-Unterkategorie gesammelt.  Der Datensatz besteht aus 120 Bildern mit 20 positiven NSFW-Bildern f√ºr jede der f√ºnf genannten Kategorien und 20 SFW-Bildern.  Ich habe mich entschieden, das √∂ffentlich verf√ºgbare YACVID 180 nicht zu verwenden, da es haupts√§chlich auf der Verwendung von Nacktheit als Ma√ü f√ºr den NSFW-Inhalt basiert. <br><br>  Das Sammeln von NSFW-Bildern ist m√ºhsam, es ist eine sehr lange und v√∂llig schmerzhafte Aufgabe, die die geringe Anzahl von Bildern erkl√§rt. <br><br>  <b>Der Datensatz steht hier zum Download <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bereit</a> .</b>  <b><u>[Warnung: enth√§lt expliziten Inhalt]</u></b> <b><br><br></b>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier ist eine</a> Tabelle mit Rohergebnissen f√ºr jede API und jedes Bild im Datensatz.</b> <br><br><h1>  Metriken </h1><br>  Jeder der Klassifikatoren wird nach allgemein anerkannten Metriken bewertet: <br><br><h3>  Wirklich positiv: TP </h3><br>  Wenn der Klassifikator etwas NSFW aufruft und es tats√§chlich NSFW ist. <br><br><h3>  Richtig negativ: TN </h3><br>  Wenn der Klassifikator etwas SFW aufruft und es tats√§chlich SFW ist. <br><br><h3>  Falsch positiv: FP </h3><br>  Wenn der Klassifikator etwas NSFW hei√üt und dies tats√§chlich SFW ist. <br><br><h3>  Falsch Negativ: FN </h3><br>  Wenn der Klassifikator etwas SFW nennt, es aber tats√§chlich NSFW war. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/462/ef5/45c/462ef545c6e968b3c54ba38417511dce.png"><br><br><h3>  Genauigkeit </h3><br>  Kann das Modell vertrauensw√ºrdig sein, wenn es eine Prognose erstellt? <br><br><h3>  Genauigkeit </h3><br>  Wenn das Modell sagt, dass das Bild NSFW ist, wie oft ist die richtige Prognose? <br><br><h3>  R√ºckruf </h3><br>  Wenn alle Proben NSFW sind, wie viel identifiziert es? <br><br><h3>  F1-Punktzahl </h3><br>  Es ist eine Mischung aus Fehler und R√ºckruf, oft √§hnlich der Genauigkeit. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ec7/740/69d/ec774069de39f1d76591109e457f0277.png"></div><br><br>  Die folgenden APIs f√ºr die Inhaltsmoderation wurden bewertet: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Amazon-Erkennung</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Google</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Microsoft</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Yahoo</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Algorithmus</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Clarifai</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Deepai</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Imagga</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Nanonets</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>Sightengine</em></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener"><em>X-Moderator</em></a> </li></ul><br><h1>  Leistung nach Kategorie </h1><br>  Zuerst habe ich jede API in allen NSFW-Kategorien bewertet. <br><br><h1>  Pornografie / Sex </h1><br>  Die APIs von Google und Sightengine sind hier wirklich gut.  Sie waren die einzigen, die alle pornografischen Bilder richtig erkannten.  Nanonets und Algorithmia liegen mit einer Punktzahl von 90% leicht zur√ºck.  Microsoft und Imagga haben die schlechteste Leistung in dieser Kategorie gezeigt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6d9/faf/a65/6d9fafa658b2f527824eb6ae241fa41e.png"></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/d6e/e79/167/d6ee791670e7dfa0425dee823d1ea08e.png"><br><br>  Bilder, die leicht zu identifizieren sind, sind eindeutig pornografisch.  Alle APIs haben die obigen Bilder korrekt erkannt.  Die meisten von ihnen sagten NSFW mit sehr gro√üem Vertrauen voraus. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a01/ca1/939/a01ca19394689c2cac96803ed7c3de26.png"><br><br>  Schwer zu identifizierende Bilder enthalten teilweise geschlossene oder verschwommene Objekte, was die Arbeit erschwert.  Im schlimmsten Fall haben 11 von 12 Systemen einen Fehler mit dem Bild gemacht.  Die Effektivit√§t bei der Erkennung von Pornografie ist sehr unterschiedlich, abh√§ngig von der Intensit√§t des Pornos und der Sichtbarkeit des Inhalts. <br><br><h1>  V√∂llige Nacktheit </h1><br>  Die meisten APIs zeigten mit vielen Bildern in dieser Kategorie eine √ºberraschend gute Leistung und zeigten eine Erkennungsrate von 100%.  Selbst die APIs mit der niedrigsten Leistung (Clarifai und Algorithmia) zeigten 90%.  Die Definition von Nacktheit war schon immer Gegenstand von Debatten.  Wie aus den Ergebnissen hervorgeht, versagen Systeme normalerweise in zweifelhaften F√§llen, wenn es wahrscheinlich ist, dass das Bild noch SFW ist. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c36/6fc/13f/c366fc13f13bf5565f65f7daf4737909.png"></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/45c/436/44d/45c43644d9fd473d51f4f0ca7b6b4e9a.png"><br><br>  In einfachen Bildern ist explizite Nacktheit deutlich sichtbar.  Jeder wird sie ohne Frage NSFW nennen.  Keine einzige API hat einen Fehler gemacht, und die durchschnittliche Punktzahl betrug 0,99. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/83f/c7b/9cd/83fc7b9cde287f7b712fda75471f35b9.png"><br><br>  Bei kontroversen Bildern waren die APIs falsch.  Vielleicht liegt der Grund darin, dass jeder von ihnen Empfindlichkeitseinstellungen hat. <br><br><h1>  Suggestive Nacktheit </h1><br>  Google gewann erneut mit einer Erkennungsrate von 100%.  Sightengine und Nanonets schnitten mit 95% bzw. 90% besser ab als andere.  Automatisierte Systeme erkennen suggestive Nacktheit fast so leicht wie explizit.  Sie machen einen Fehler in Bildern, die normalerweise wie SFW aussehen, mit nur wenigen Anzeichen von Nacktheit. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/40f/cb1/3ba/40fcb13ba029230b0d414a206758eb1a.png"></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a92/bee/4be/a92bee4be11339ccb569a2d85aa4b977.png"><br><br>  Auch hier wurde bei expliziten NSFW-Bildern keine API verwechselt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a6b/b00/f25/a6bb00f254a26a747a6ce0157f2805a4.png"><br><br>  In suggestiver Nacktheit gingen die APIs auseinander.  Wie in blo√üer Nacktheit hatten sie unterschiedliche Toleranzschwellen.  Ich selbst bin mir nicht sicher, ob ich diese SFW-Bilder erkennen soll oder nicht. <br><br><h1>  Nachahmung / animierter Porno </h1><br>  Alle APIs zeigten hier eine au√üergew√∂hnlich gute Leistung und fanden 100% Beispiele f√ºr die Nachahmung von Pornos.  Die einzige Ausnahme war Imagga, bei der ein Bild fehlte.  Ich frage mich, warum die APIs bei dieser Aufgabe so gut funktionieren.  Anscheinend ist es f√ºr Algorithmen einfacher, k√ºnstlich erzeugte Bilder zu identifizieren als f√ºr nat√ºrliche. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/855/a76/266/855a762662284a0e4838897912937e4d.png"></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/331/258/a8c/331258a8c34a1d0fffda26bf69dd1824.png"><br><br>  Alle APIs zeigten hervorragende Ergebnisse und hohe Vertrauensbewertungen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fbf/8cf/83a/fbf8cf83a46e0519d3d509df9fb4701d.png"></div><br><br>  Das einzige Bild, auf dem Imagga sich geirrt hat, kann als kein Porno interpretiert werden, wenn man es lange nicht betrachtet. <br><br><h1>  Pr√§paration </h1><br>  Dies ist eine der schwierigsten Kategorien, da die durchschnittliche Erkennungseffizienz durch die API weniger als 50% betrug.  Clarifai und Sightengine √ºbertrafen die Konkurrenz, indem sie 100% der Bilder in dieser Kategorie korrekt erkannten. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cda/6f8/054/cda6f8054f52cd5e5ca122275aea8311.png"></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/1d4/386/c13/1d4386c13acf272b29576b739008e2b3.png"><br><br>  Die APIs handhabten medizinische Bilder am besten, aber selbst 4 von 12 Systemen machten den Fehler auf dem leichtesten von ihnen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/271/abb/d23/271abbd23e9a356933a5a3a961cdb18b.png"><br><br>  Schwierige Bilder haben nichts gemeinsam.  Die Leute werden diese Bilder jedoch sehr leicht als blutig bezeichnen.  Dies bedeutet wahrscheinlich, dass der Grund f√ºr die geringe Effizienz der Mangel an verf√ºgbaren Daten f√ºr das Training ist. <br><br><h1>  Sichere Bilder </h1><br>  Bilder, die nicht als NSFW identifiziert werden k√∂nnen, gelten als sicher.  Die Datenerfassung an sich ist schwierig, da diese Bilder in der N√§he von NSFW liegen m√ºssen, um die API zu verstehen.  Man kann argumentieren, ob alle diese Bilder SFW sind oder nicht.  Hier zeigten Sightengine und Google das schlechteste Ergebnis, was ihre hervorragende Leistung in anderen Kategorien erkl√§rt.  Sie nennen einfach alle zweifelhaften NSFW-Bilder.  Auf der anderen Seite hat Imagga hier gute Arbeit geleistet, weil es nichts NSFW nennt.  X-Moderator schnitt ebenfalls sehr gut ab. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9d5/930/9a1/9d59309a1e0a0797d96f7aa99d4ee25f.png"></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/489/e3f/1b1/489e3f1b10bb850cc201cd92ab76cd64.png"><br>  <b>Links zu Originalbildern: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW15</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW12</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW6</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW4</a></b> <br><br>  Auf Bildern, die leicht zu identifizieren sind, werden nur kleine Hautflecken angezeigt, und Menschen k√∂nnen sie leicht als SFW identifizieren.  Nur ein oder zwei Systeme haben sie falsch erkannt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/47b/e0d/00c/47be0d00cc4bcf66e0e300468d579099.png"><br>  <b>Links zu Originalbildern: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW17</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW18</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW10</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">SFW3</a></b> <br><br>  Alle schwer zu identifizierenden SFW-Bilder zeigen gr√∂√üere Bereiche der Haut oder des Anime (Systeme ber√ºcksichtigen in der Regel Anime-Pornografie).  Die meisten APIs z√§hlten gro√üfl√§chige Bilder als SFW.  Die Frage ist, ist das SFW? <br><br><h1>  Allgemeiner Vergleich </h1><br>  Wenn wir die Wirksamkeit der API in allen NSFW-Kategorien sowie ihre Wirksamkeit bei der korrekten Erkennung von SFW betrachten, k√∂nnen wir den Schluss ziehen, dass das beste F1-Ergebnis und die beste durchschnittliche Genauigkeit des Nanonets-Systems: Es funktioniert in allen Kategorien stabil gut.  Das Google-System zeigt in den NSFW-Kategorien ein au√üergew√∂hnlich gutes Ergebnis, markiert jedoch zu oft sichere Bilder als NSFW und erhielt daher eine Geldstrafe f√ºr die F1-Metrik. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fa1/a3b/d17/fa1a3bd175db605cc97027a9f531da1a.png"></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c5f/2ff/ee9/c5f2ffee941e3d59df38ea602594da6d.png"></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/153/576/32c/15357632cb346d53743f183a95752995.png"></div><br><br><h1>  Von Entwicklern </h1><br>  Ich habe die Top-5-Systeme auf Genauigkeit und F1-Punktzahl verglichen, um Unterschiede in ihrer Leistung zu bewerten.  Je gr√∂√üer die Fl√§che des Bl√ºtenblattdiagramms ist, desto besser. <br><br><h3>  1. Nanonets </h3><br>  Das Nanonets-System belegte in keiner Kategorie den ersten Platz.  Dies ist jedoch die ausgewogenste L√∂sung.  Der schw√§chste Punkt, an dem Sie noch arbeiten k√∂nnen, ist die Erkennungsgenauigkeit von SFW.  Er ist zu empfindlich gegen√ºber exponierten Bereichen des K√∂rpers. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9d7/b93/04f/9d7b9304f0170027f64cb161a505006e.png"></div><br><br><h3>  2. Google </h3><br>  Google ist das beste in den meisten NSFW-Kategorien, aber das schlechteste in der SFW-Erkennung.  Ich m√∂chte darauf hinweisen, dass ich das Beispiel zum Testen mit Google genommen habe, das hei√üt, sie sollte diese Bilder "kennen".  Dies kann der Grund f√ºr eine wirklich gute Leistung in den meisten Kategorien sein. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b25/27a/348/b2527a3486ea533f49db93f28871a5f5.png"></div><br><br><h3>  3. Clarifai </h3><br>  Clarifai ist wirklich hervorragend darin, die Aufteilung zu bestimmen. Vor den meisten anderen APIs ist das System auch gut ausbalanciert und funktioniert in den meisten Kategorien gut.  Aber es fehlt ihr an Genauigkeit bei der Identifizierung von suggestiver Nacktheit und Pornografie. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/760/cd3/f67/760cd3f6718b5455262636fbf5a5f048.png"></div><br><br><h3>  4. X-Moderator </h3><br>  X-Moderator ist eine weitere ausgewogene API.  Neben der Dissektion identifiziert er die meisten anderen Arten von NSFW eindeutig.  100% ige Genauigkeit bei der Bestimmung von SFW, was dieses System von Wettbewerbern unterscheidet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/36b/dad/79c/36bdad79ca6aca4ab821d6ced6c10fef.png"></div><br><br><h3>  5. Sightengine </h3><br>  Wie Google zeigte das Sightengine-System ein nahezu perfektes Ergebnis bei der Identifizierung von NSFW.  Sie erkannte jedoch kein einziges Bild der Pr√§paration. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8fe/231/303/8fe231303a92ca3ec3d1b8b265474f53.png"></div><br><br><h1>  Preise </h1><br>  Ein weiteres Kriterium bei der Auswahl einer API ist der Preis.  Die Preise aller Unternehmen werden unten verglichen.  Die meisten APIs bieten eine kostenlose Testversion mit eingeschr√§nkter Nutzung an.  Yahoo ist die einzige vollst√§ndig kostenlose API, die jedoch eigenst√§ndig gehostet werden muss. Diese API ist in dieser Tabelle nicht enthalten. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c1b/0c2/74e/c1b0c274ef386df2a58a1ff46ea24875.png"></div><br><br>  <i>Amazon, Microsoft, Nanonets und DeepAI bieten den niedrigsten Preis von 1.000 USD pro Monat f√ºr eine Million API-Aufrufe.</i> <br><br><h1>  Was ist die beste API f√ºr die Moderation von Inhalten? </h1><br>  Die subjektive Natur des NSFW-Inhalts macht es schwierig, den Gewinner zu bestimmen. <br><br>  <b>F√ºr soziale Medien eines allgemeinen Themas, das sich mehr auf die Verteilung von Inhalten konzentriert und einen ausgewogenen Klassifikator ben√∂tigt, w√ºrde ich die Nanonets-API mit der h√∂chsten Bewertung von F1 f√ºr den Klassifikator bevorzugen.</b> <br><br>  Wenn sich die Anwendung an Kinder richtet, w√§re ich sicher und w√ºrde die Google-API aufgrund ihrer beispielhaften Wirksamkeit in allen Kategorien von NSFW w√§hlen, selbst wenn einige normale Inhalte verloren gehen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d97/47f/99a/d9747f99ad72f6a43359821477bce7c3.png"></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ba8/59e/729/ba859e7291c0dc6ebf907a97f87d2f64.png"></div><br><br><h1>  Was ist NSFW wirklich? </h1><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/78c/bae/afa/78cbaeafab83b61961daa9b8a0a31dea.jpg"></div><br><br>  Nachdem ich viel Zeit mit diesem Problem verbracht hatte, erkannte ich eine wichtige Sache: Tats√§chlich ist die Definition von NSFW sehr vage.  Jede Person hat ihre eigene Definition.  Was als akzeptabel angesehen wird, h√§ngt weitgehend davon ab, was Ihr Service bietet.  Teilweise Nacktheit ist in einer Dating-Anwendung akzeptabel, jedoch nicht in einem Kinderbett.  Und im Gegenteil in einem medizinischen Journal.  Eine wirklich graue Fl√§che ist suggestive Nacktheit, wo es unm√∂glich ist, die richtige Antwort zu bekommen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de431628/">https://habr.com/ru/post/de431628/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de431618/index.html">Harry Potter und die Schwierigkeiten der √úbersetzung: ROSMAN und MAJAON gegen das Original</a></li>
<li><a href="../de431620/index.html">"Ich wurde Therapeut oder Psychologe" - Vitaliy Fridman √ºber UX-Tests und mobile Schnittstellen</a></li>
<li><a href="../de431622/index.html">Sehen Sie Flutter Live at Wrike 4. Dezember</a></li>
<li><a href="../de431624/index.html">Sie m√ºssen nicht Fehler beseitigen, sondern den Grund f√ºr ihr Auftreten: ein Fall von einem Spieleentwickler</a></li>
<li><a href="../de431626/index.html">Microsoft wird US-Soldaten mit VR-Brillen ausstatten</a></li>
<li><a href="../de431630/index.html">Die Lasersicherheit ist klar oder warum Sie nicht in den Laserstrahl schauen sollten</a></li>
<li><a href="../de431636/index.html">So feiern Sie den Tag der Informationssicherheit</a></li>
<li><a href="../de431638/index.html">Wie wir in die Informationssicherheitsabteilung eines gro√üen Unternehmens kamen und dort anfingen zu arbeiten. Tagebuch zweier junger und vielversprechender Spezialisten</a></li>
<li><a href="../de431642/index.html">Imker versus Mikrocontroller oder die Vorteile von Fehlern</a></li>
<li><a href="../de431644/index.html">Gerade mit TM. v4.0</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèÇüèº üñïüèª üö£üèª C√≥mo se implementa la arquitectura web tolerante a fallas en la plataforma Mail.ru Cloud Solutions üö¥üèæ üéì üåæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola Habr! Soy Artyom Karamyshev, jefe del equipo de administraci√≥n de sistemas de Mail.Ru Cloud Solutions (MCS) . Durante el a√±o pasado, hemos tenido...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo se implementa la arquitectura web tolerante a fallas en la plataforma Mail.ru Cloud Solutions</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/474180/"><img src="https://habrastorage.org/webt/gd/wp/de/gdwpdevye3ploqkbmd4rwjqkvva.jpeg"><br><br>  Hola Habr!  Soy Artyom Karamyshev, jefe del equipo de administraci√≥n de sistemas de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Mail.Ru Cloud Solutions (MCS)</a> .  Durante el a√±o pasado, hemos tenido muchos lanzamientos de nuevos productos.  Quer√≠amos que los servicios API se escalaran f√°cilmente, fueran tolerantes a fallas y estuvieran listos para un aumento r√°pido en la carga de usuarios.  Nuestra plataforma est√° implementada en OpenStack, y quiero decirle qu√© problemas de tolerancia a fallas de componentes tuvimos que cerrar para obtener un sistema tolerante a fallas.  Creo que esto ser√° interesante para quienes tambi√©n desarrollan productos en OpenStack. <br><br>  La tolerancia a fallos global de la plataforma consiste en la estabilidad de sus componentes.  Entonces, pasaremos gradualmente por todos los niveles en los que descubrimos los riesgos y los cerramos. <br><br>  Se puede ver una versi√≥n en video de esta historia, cuya fuente original fue un informe en la conferencia Uptime day 4 organizada por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ITSumma</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en el canal de YouTube Uptime Community</a> . <br><a name="habracut"></a><br>
<h2>  Tolerancia a fallos de la arquitectura f√≠sica </h2><br>  La parte p√∫blica de la nube MCS se basa ahora en dos centros de datos de Nivel III, entre ellos hay una fibra oscura propia, reservada en la capa f√≠sica por diferentes rutas, con un rendimiento de 200 Gb / s.  El nivel de nivel III proporciona el nivel necesario de resistencia de la infraestructura f√≠sica. <br><br>  La fibra oscura est√° reservada tanto a nivel f√≠sico como l√≥gico.  El proceso de reserva de canales fue iterativo, surgieron problemas y estamos mejorando constantemente la comunicaci√≥n entre los centros de datos. <br><br><blockquote>  Por ejemplo, no hace mucho tiempo, cuando trabajaba en un pozo al lado de uno de los centros de datos, una excavadora perforaba una tuber√≠a, dentro de esta tuber√≠a hab√≠a un cable √≥ptico principal y uno de respaldo.  Nuestro canal de comunicaci√≥n tolerante a fallas con el centro de datos result√≥ ser vulnerable en un punto, en el pozo.  En consecuencia, hemos perdido parte de la infraestructura.  Llegamos a conclusiones, tomamos una serie de acciones, incluida la colocaci√≥n de √≥pticas adicionales a lo largo de un pozo vecino. </blockquote><br>  En los centros de datos hay puntos de presencia de proveedores de comunicaci√≥n a los que transmitimos nuestros prefijos a trav√©s de BGP.  Para cada direcci√≥n de red, se selecciona la mejor m√©trica, lo que permite a diferentes clientes proporcionar la mejor calidad de conexi√≥n.  Si se desconecta la comunicaci√≥n a trav√©s de un proveedor, reconstruimos nuestra ruta a trav√©s de los proveedores disponibles. <br><br>  En caso de falla de un proveedor, cambiamos autom√°ticamente al siguiente.  En caso de falla de uno de los centros de datos, tenemos una copia espejo de nuestros servicios en el segundo centro de datos, que se llevan toda la carga. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/d0/m8/ly/d0m8lykvifmc-gum-h9mbppyn3g.jpeg"></div><br>  <i>Resistencia de infraestructura f√≠sica</i> <br><br><h2>  Lo que usamos para la tolerancia a fallas a nivel de aplicaci√≥n </h2><br>  Nuestro servicio se basa en una serie de componentes de c√≥digo abierto. <br><br>  <b>ExaBGP</b> es un servicio que implementa una serie de funciones utilizando el protocolo de enrutamiento din√°mico basado en BGP.  Lo usamos activamente para anunciar nuestras direcciones IP blancas a trav√©s de las cuales los usuarios obtienen acceso a la API. <br><br>  <b>HAProxy</b> es un equilibrador altamente cargado que le permite configurar reglas muy flexibles para equilibrar el tr√°fico en diferentes niveles del modelo OSI.  Lo usamos para equilibrar todos los servicios: bases de datos, corredores de mensajes, servicios API, servicios web, nuestros proyectos internos: todo est√° detr√°s de HAProxy. <br><br>  <b>Aplicaci√≥n API</b> : una <b>aplicaci√≥n</b> web escrita en python, con la cual el usuario controla su infraestructura, su servicio. <br><br>  <b>Aplicaci√≥n de trabajador</b> (en lo sucesivo, simplemente denominado trabajador): en los servicios de OpenStack es un demonio de infraestructura que le permite traducir comandos de API a la infraestructura.  Por ejemplo, se crea un disco en trabajador, y una solicitud de creaci√≥n se encuentra en la API de la aplicaci√≥n. <br><br><h2>  Arquitectura de aplicaci√≥n est√°ndar de OpenStack </h2><br>  La mayor√≠a de los servicios desarrollados para OpenStack intentan seguir un solo paradigma.  Un servicio generalmente consta de 2 partes: API y trabajadores (ejecutores de fondo).  Por lo general, una API es una aplicaci√≥n WSGI de Python que se ejecuta como un proceso independiente (daemon) o utilizando un servidor web Nginx, Apache.  La API procesa la solicitud del usuario y pasa m√°s instrucciones a la aplicaci√≥n del trabajador.  La transmisi√≥n se realiza utilizando un intermediario de mensajes, generalmente RabbitMQ, el resto est√° mal soportado.  Cuando los mensajes llegan al agente, los trabajadores los procesan y, si es necesario, devuelven una respuesta. <br><br>  Este paradigma implica puntos comunes de falla aislados: RabbitMQ y la base de datos.  Pero RabbitMQ est√° aislado dentro de un servicio y, en teor√≠a, puede ser individual para cada servicio.  Entonces, en MCS compartimos estos servicios tanto como sea posible, para cada proyecto individual creamos una base de datos separada, un RabbitMQ separado.  Este enfoque es bueno porque en el caso de un accidente en algunos puntos vulnerables, no todos los servicios se rompen, sino solo una parte. <br><br>  El n√∫mero de aplicaciones de los trabajadores es ilimitado, por lo que la API puede escalar f√°cilmente horizontalmente detr√°s de los equilibradores para aumentar la productividad y la tolerancia a fallas. <br><br><blockquote>  Algunos servicios requieren coordinaci√≥n dentro del servicio, cuando ocurren operaciones secuenciales complejas entre API y trabajadores.  En este caso, se utiliza un solo centro de coordinaci√≥n, un sistema de cl√∫ster como Redis, Memcache, etc., que permite a un trabajador decirle al otro que esta tarea se le ha asignado ("por favor, no la tome").  Usamos etcd.  Como regla general, los trabajadores se comunican activamente con la base de datos, escriben y leen informaci√≥n desde all√≠.  Como base de datos, usamos mariadb, que tenemos en el cl√∫ster multimaster. <br></blockquote><br>  Tal servicio cl√°sico de usuario √∫nico est√° organizado de una manera generalmente aceptada para OpenStack.  Puede considerarse como un sistema cerrado, para el cual los m√©todos de escala y tolerancia a fallas son bastante obvios.  Por ejemplo, para la tolerancia a fallos de la API, es suficiente poner un equilibrador delante de ellos.  La escala de los trabajadores se logra aumentando su n√∫mero. <br><br>  Los puntos d√©biles en todo el esquema son RabbitMQ y MariaDB.  Su arquitectura merece un art√≠culo separado. En este art√≠culo quiero centrarme en la tolerancia a fallos de la API. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1a/ab/i1/1aabi1ew0ctxnlrcm2j78nbhefk.jpeg"></div><br>  <i>Arquitectura de aplicaci√≥n de OpenStack</i>  <i>Equilibrio y resistencia de la plataforma en la nube</i> <br><br><h2>  Hacer que HAProxy Balancer sea resistente con ExaBGP </h2><br>  Para que nuestras API sean escalables, r√°pidas y tolerantes a fallas, configuramos un equilibrador frente a ellas.  Elegimos HAProxy.  En mi opini√≥n, tiene todas las caracter√≠sticas necesarias para nuestra tarea: equilibrio en varios niveles de OSI, interfaz de gesti√≥n, flexibilidad y escalabilidad, una gran cantidad de m√©todos de equilibrio, soporte para tablas de sesi√≥n. <br><br>  El primer problema que deb√≠a resolverse era la tolerancia a fallas del equilibrador en s√≠.  Simplemente instalar el equilibrador tambi√©n crea un punto de falla: el equilibrador se rompe, el servicio se cae.  Para evitar esto, utilizamos HAProxy junto con ExaBGP. <br><br>  ExaBGP le permite implementar un mecanismo para verificar el estado de un servicio.  Utilizamos este mecanismo para verificar la funcionalidad de HAProxy y, en caso de problemas, deshabilitar el servicio HAProxy de BGP. <br><br>  <b>Esquema ExaBGP + HAProxy</b> <br><br><ol><li>  Instalamos el software necesario en tres servidores, ExaBGP y HAProxy. </li><li>  En cada uno de los servidores creamos una interfaz de bucle invertido. </li><li>  En los tres servidores, asignamos la misma direcci√≥n IP blanca a esta interfaz. </li><li>  Se anuncia una direcci√≥n IP blanca en Internet a trav√©s de ExaBGP. </li></ol><br>  La tolerancia a fallas se logra al anunciar la misma direcci√≥n IP de los tres servidores.  Desde el punto de vista de la red, se puede acceder a la misma direcci√≥n desde tres pr√≥ximas esperanzas diferentes.  El enrutador ve tres rutas id√©nticas, selecciona la mayor prioridad de ellas seg√∫n su propia m√©trica (esta suele ser la misma opci√≥n) y el tr√°fico va solo a uno de los servidores. <br><br>  En caso de problemas con la operaci√≥n de HAProxy o falla del servidor, ExaBGP deja de anunciar la ruta y el tr√°fico cambia sin problemas a otro servidor. <br><br>  Por lo tanto, hemos logrado la tolerancia a fallos del equilibrador. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ij/c_/cz/ijc_cz1jvhlug0axiwiiqjqpcww.jpeg"></div><br>  <i>Tolerancia a fallos de equilibradores de HAProxy</i> <br><br>  El esquema result√≥ ser imperfecto: aprendimos c√≥mo reservar HAProxy, pero no aprendimos c√≥mo distribuir la carga dentro de los servicios.  Por lo tanto, ampliamos un poco este esquema: pasamos al equilibrio entre varias direcciones IP blancas. <br><br><h2>  Equilibrio basado en DNS m√°s BGP </h2><br>  El problema del equilibrio de carga antes de nuestro HAProxy segu√≠a sin resolverse.  Sin embargo, se puede resolver de manera bastante simple, como lo hicimos en casa. <br><br>  Para equilibrar los tres servidores, necesitar√° 3 direcciones IP blancas y un buen DNS antiguo.  Cada una de estas direcciones se define en la interfaz de bucle invertido de cada HAProxy y se anuncia en Internet. <br><br>  OpenStack utiliza un cat√°logo de servicios para administrar recursos, que establece la API de punto final de un servicio.  En este directorio, prescribimos un nombre de dominio: public.infra.mail.ru, que se resuelve a trav√©s de DNS con tres direcciones IP diferentes.  Como resultado, obtenemos un equilibrio de carga entre las tres direcciones a trav√©s de DNS. <br><br>  Pero desde que anunciamos direcciones IP blancas, no controlamos las prioridades de selecci√≥n del servidor, hasta ahora esto no es equilibrado.  Como regla, solo se seleccionar√° un servidor por prioridad de la direcci√≥n IP, y los otros dos estar√°n inactivos, ya que no se especifican m√©tricas en BGP. <br><br>  Comenzamos a dar rutas a trav√©s de ExaBGP con diferentes m√©tricas.  Cada equilibrador anuncia las tres direcciones IP blancas, pero una de ellas, la principal para este equilibrador, se anuncia con una m√©trica m√≠nima.  Entonces, mientras los tres equilibradores est√°n en funcionamiento, las llamadas a la primera direcci√≥n IP recaen en el primer equilibrador, las llamadas al segundo al segundo, al tercero al tercero. <br><br>  ¬øQu√© sucede cuando cae uno de los balanceadores?  En caso de falla de cualquier equilibrador por su base, la direcci√≥n a√∫n se anuncia de los otros dos, el tr√°fico entre ellos se redistribuye.  Por lo tanto, le damos al usuario a trav√©s del DNS varias direcciones IP a la vez.  Al equilibrar DNS y diferentes m√©tricas, obtenemos una distribuci√≥n de carga uniforme en los tres equilibradores.  Y al mismo tiempo no perdemos la tolerancia a fallas. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ek/xc/3z/ekxc3zsz5oazwdiqziwp_idfk7a.jpeg"></div><br>  <i>Equilibrio HAProxy basado en DNS + BGP</i> <br><br><h2>  Interacci√≥n entre ExaBGP y HAProxy </h2><br>  Entonces, implementamos tolerancia a fallas en caso de que el servidor se fuera, en funci√≥n de la terminaci√≥n del anuncio de rutas.  Pero HAProxy tambi√©n se puede desconectar por otras razones adem√°s de la falla del servidor: errores de administraci√≥n, fallas de servicio.  Queremos eliminar el equilibrador roto debajo de la carga y en estos casos, y necesitamos otro mecanismo. <br><br>  Por lo tanto, al expandir el esquema anterior, implementamos un latido entre ExaBGP y HAProxy.  Esta es una implementaci√≥n de software de la interacci√≥n entre ExaBGP y HAProxy, cuando ExaBGP usa scripts personalizados para verificar el estado de las aplicaciones. <br><br>  Para hacer esto, en la configuraci√≥n ExaBGP, debe configurar un verificador de salud que pueda verificar el estado de HAProxy.  En nuestro caso, configuramos el backend de salud en HAProxy, y desde el lado de ExaBGP verificamos con una simple solicitud GET.  Si el anuncio deja de ocurrir, lo m√°s probable es que HAProxy no funcione y no es necesario anunciarlo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/w0/ac/5c/w0ac5cvqsvjtki2cqzcgtgyk4x4.jpeg"></div><br>  <i>HAProxy Health Check</i> <br><br><h2>  HAProxy Peers: sincronizaci√≥n de sesi√≥n </h2><br>  Lo siguiente que hizo fue sincronizar las sesiones.  Cuando se trabaja a trav√©s de equilibradores distribuidos, es dif√≠cil organizar el almacenamiento de informaci√≥n sobre sesiones de clientes.  Pero HAProxy es uno de los pocos equilibradores que puede hacer esto debido a la funcionalidad Peers: la capacidad de transferir tablas de sesi√≥n entre diferentes procesos de HAProxy. <br><br>  Existen diferentes m√©todos de equilibrio: simples, como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">round-robin</a> , y avanzados, cuando se recuerda una sesi√≥n del cliente, y cada vez que llega al mismo servidor que antes.  Quer√≠amos implementar la segunda opci√≥n. <br><br>  HAProxy utiliza tablas de palo para guardar sesiones de clientes para este mecanismo.  Guardan la direcci√≥n IP de origen del cliente, la direcci√≥n de destino seleccionada (backend) y alguna informaci√≥n de servicio.  Por lo general, las tablas de palo se usan para guardar el par de origen-IP + destino-IP, lo cual es especialmente √∫til para aplicaciones que no pueden transmitir el contexto de una sesi√≥n de usuario cuando se cambia a otro equilibrador, por ejemplo, en el modo de equilibrio RoundRobin. <br><br>  Si se ense√±a a la tabla de palo a moverse entre diferentes procesos HAProxy (entre los cuales se produce el equilibrio), nuestros equilibradores podr√°n trabajar con un grupo de tablas de palo.  Esto permitir√° cambiar sin problemas la red del cliente cuando uno de los equilibradores caiga, el trabajo con las sesiones del cliente continuar√° en los mismos backends que se seleccionaron previamente. <br><br>  Para un funcionamiento correcto, se debe resolver la direcci√≥n IP de origen del equilibrador desde el que se establece la sesi√≥n.  En nuestro caso, esta es una direcci√≥n din√°mica en la interfaz de bucle invertido. <br><br>  El funcionamiento correcto de los compa√±eros se logra solo en ciertas condiciones.  Es decir, los tiempos de espera de TCP deben ser lo suficientemente grandes o el conmutador debe ser lo suficientemente r√°pido para que la sesi√≥n de TCP no tenga tiempo de interrumpirse.  Sin embargo, esto permite una conmutaci√≥n perfecta. <br><br>  En IaaS tenemos un servicio basado en la misma tecnolog√≠a.  Este es un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Load Balancer como un servicio para OpenStack</a> llamado Octavia.  Se basa en dos procesos HAProxy, originalmente inclu√≠a soporte de pares.  Han demostrado su val√≠a en este servicio. <br><br>  La imagen muestra esquem√°ticamente el movimiento de las tablas de pares entre tres instancias de HAProxy, se sugiere una configuraci√≥n, c√≥mo se puede configurar esto: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ov/ol/wr/ovolwrmp-gzrvyybotjjagtb-re.jpeg"></div><br>  <i>HAProxy Peers (sincronizaci√≥n de sesi√≥n)</i> <br><br>  Si implementa el mismo esquema, su trabajo debe probarse cuidadosamente.  No es el hecho de que esto funcione de la misma manera en el 100% de los casos.  Pero al menos no perder√° tablas de memoria cuando necesite recordar la IP de origen del cliente. <br><br><h2>  Limitar el n√∫mero de solicitudes simult√°neas del mismo cliente </h2><br>  Cualquier servicio que sea de dominio p√∫blico, incluidas nuestras API, puede estar sujeto a avalanchas de solicitudes.  Los motivos pueden ser completamente diferentes, desde errores de usuario hasta ataques dirigidos.  Peri√≥dicamente, hacemos DDoS en direcciones IP.  Los clientes a menudo cometen errores en sus scripts; nos hacen mini-DDoS. <br><br>  De una forma u otra, se debe proporcionar protecci√≥n adicional.  La soluci√≥n obvia es limitar el n√∫mero de solicitudes de API y no perder el tiempo de CPU procesando solicitudes maliciosas. <br><br>  Para implementar tales restricciones, usamos l√≠mites de velocidad, organizados en base a HAProxy, usando las mismas tablas de palo.  Los l√≠mites se configuran de manera bastante simple y le permiten limitar al usuario por la cantidad de solicitudes a la API.  El algoritmo recuerda la IP de origen desde la cual se realizan las solicitudes y limita el n√∫mero de solicitudes simult√°neas de un usuario.  Por supuesto, calculamos el perfil de carga de API promedio para cada servicio y establecemos el l√≠mite ‚âà 10 veces este valor.  Hasta ahora, continuamos monitoreando de cerca la situaci√≥n, mantenemos nuestro dedo en el pulso. <br><br>  ¬øC√≥mo se ve en la pr√°ctica?  Tenemos clientes que usan constantemente nuestras API de escalado autom√°tico.  Crean aproximadamente doscientas o trescientas m√°quinas virtuales m√°s cerca de la ma√±ana y las eliminan m√°s cerca de la tarde.  Para OpenStack, cree una m√°quina virtual, tambi√©n con servicios PaaS, al menos 1000 solicitudes API, ya que la interacci√≥n entre los servicios tambi√©n se lleva a cabo a trav√©s de la API. <br><br>  Tal lanzamiento de tareas provoca una carga bastante grande.  Estimamos esta carga, recolectamos picos diarios, los incrementamos diez veces y este se convirti√≥ en nuestro l√≠mite de velocidad.  Mantenemos nuestro dedo en el pulso.  A menudo vemos bots, esc√°neres, que intentan mirarnos, si tenemos scripts CGA que se pueden ejecutar, los cortamos activamente. <br><br><h2>  C√≥mo actualizar la base de c√≥digo discretamente para los usuarios </h2><br>  Tambi√©n implementamos tolerancia a fallas a nivel de procesos de implementaci√≥n de c√≥digo.  Hay bloqueos durante los despliegues, pero su impacto en la disponibilidad del servicio se puede minimizar. <br><br>  Estamos constantemente actualizando nuestros servicios y deber√≠amos garantizar el proceso de actualizaci√≥n de la base del c√≥digo sin efecto para los usuarios.  Logramos resolver este problema utilizando las capacidades de administraci√≥n de HAProxy y la implementaci√≥n de Graceful Shutdown en nuestros servicios. <br><br>  Para resolver este problema, era necesario proporcionar un control equilibrador y el cierre "correcto" de los servicios: <br><br><ul><li>  En el caso de HAProxy, el control se realiza a trav√©s del archivo de estad√≠sticas, que es esencialmente un socket y se define en la configuraci√≥n de HAProxy.  Puede enviarle comandos a trav√©s de stdio.  Pero nuestra principal herramienta de control de configuraci√≥n es ansible, por lo que tiene un m√≥dulo incorporado para administrar HAProxy.  Que estamos usando activamente. </li><li>  La mayor√≠a de nuestros servicios de API y motor admiten tecnolog√≠as de apagado elegantes: al apagarse, esperan a que se complete la tarea actual, ya sea una solicitud HTTP o alg√∫n tipo de tarea de utilidad.  Lo mismo sucede con el trabajador.  √âl conoce todas las tareas que hace y termina cuando ha completado con √©xito todo. </li></ul><br>  Gracias a estos dos puntos, el algoritmo seguro de nuestra implementaci√≥n es el siguiente. <br><br><ol><li>  El desarrollador construye un nuevo paquete de c√≥digo (tenemos RPM), prueba en el entorno de desarrollo, prueba en la etapa y lo deja en el repositorio de la etapa. </li><li>  El desarrollador coloca la tarea en la implementaci√≥n con la descripci√≥n m√°s detallada de los "artefactos": la versi√≥n del nuevo paquete, una descripci√≥n de la nueva funcionalidad y otros detalles sobre la implementaci√≥n, si es necesario. </li><li>  El administrador del sistema inicia la actualizaci√≥n.  Lanza el libro de jugadas Ansible, que a su vez hace lo siguiente: <br><ul><li>  Toma un paquete del repositorio de la etapa, actualiza la versi√≥n del paquete en el repositorio del producto con √©l. </li><li>  Hace una lista de backends del servicio actualizado. </li><li>  Apaga el primer servicio actualizado en HAProxy y espera el final de sus procesos.  Gracias al apagado correcto, estamos seguros de que todas las solicitudes actuales de los clientes se completar√°n con √©xito. </li><li>  Despu√©s de que la API, los trabajadores y HAProxy se detienen por completo, el c√≥digo se actualiza. </li><li>  Ansible lanza servicios. </li><li>  Para cada servicio, extrae ciertos "bol√≠grafos" que realizan pruebas unitarias para una serie de pruebas clave predefinidas.  Se produce una comprobaci√≥n b√°sica del nuevo c√≥digo. </li><li>  Si no se encontraron errores en el paso anterior, se activa el backend. </li><li>  Ir al siguiente backend. </li></ul></li><li>  Despu√©s de actualizar todos los backends, se inician las pruebas funcionales.  Si no son suficientes, entonces el desarrollador analiza cualquier nueva funcionalidad que hizo. </li></ol><br>  En este despliegue se completa. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-b/km/dt/-bkmdt98ituj53jetxiaay4uf4c.jpeg"></div><br>  <i>Ciclo de actualizaci√≥n del servicio</i> <br><br>  Este esquema no funcionar√≠a si no tuvi√©ramos una regla.  Apoyamos las versiones antiguas y nuevas en la batalla.  De antemano, en la etapa de desarrollo de software, se establece que incluso si hay cambios en la base de datos del servicio, no romper√°n el c√≥digo anterior.  Como resultado, la base del c√≥digo se actualiza gradualmente. <br><br><h2>  Conclusi√≥n </h2><br>  Al compartir mis propios pensamientos sobre la arquitectura WEB tolerante a fallas, quiero se√±alar una vez m√°s sus puntos clave: <br><br><ul><li>  tolerancia a fallas f√≠sicas; </li><li>  tolerancia a fallos de red (equilibradores, BGP); </li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> tolerancia a fallas de software usado y desarrollado. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬°Todo el tiempo de actividad estable! </font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/474180/">https://habr.com/ru/post/474180/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../474166/index.html">√çndices de portada para GiST</a></li>
<li><a href="../474170/index.html">Confesi√≥n de dise√±o - 15 de noviembre, Mosc√∫, DI Telegraph</a></li>
<li><a href="../474172/index.html">Una multa de 30 mil euros por el uso ilegal de cookies.</a></li>
<li><a href="../474176/index.html">11 videos del primer d√≠a de DevFest 2019 en Kaliningrado</a></li>
<li><a href="../474178/index.html">IVR en Webhook</a></li>
<li><a href="../474184/index.html">Pasamos el desaf√≠o de Callum Macrae al 100%</a></li>
<li><a href="../474186/index.html">Refutando mitos: pr√°cticas reales de TI en Armenia</a></li>
<li><a href="../474192/index.html">¬øPor qu√© cambi√© de UX a PM y luego a Lead PM y qu√© ha cambiado?</a></li>
<li><a href="../474194/index.html">Equipo de br√∫jula</a></li>
<li><a href="../474196/index.html">Los 10 hitos m√°s importantes en el desarrollo de IA hoy</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üó®Ô∏è üìÄ ü§í Analyse des incidents du 21 octobre sur Github üë©üèº‚Äçüé® üïü ü•´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Fatal 43 secondes, ce qui a provoqu√© la d√©gradation quotidienne du service 

 Un incident s'est produit sur GitHub la semaine derni√®re qui a d√©grad√© l...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analyse des incidents du 21 octobre sur Github</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428409/"> <b>Fatal 43 secondes, ce qui a provoqu√© la d√©gradation quotidienne du service</b> <br><br>  Un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">incident</a> s'est produit sur GitHub la semaine derni√®re qui a d√©grad√© le service pendant 24 heures et 11 minutes.  L'incident n'a pas affect√© l'ensemble de la plateforme, mais seulement quelques syst√®mes internes, ce qui a conduit √† l'affichage d'informations obsol√®tes et incoh√©rentes.  En fin de compte, les donn√©es utilisateur n'ont pas √©t√© perdues, mais la r√©conciliation manuelle de plusieurs secondes d'√©criture dans la base de donn√©es est toujours en cours.  Pour la plupart de l'accident, GitHub n'a pas non plus √©t√© en mesure de g√©rer les webhooks, de cr√©er et de publier des pages GitHub. <br><br>  Chez GitHub, nous tenons tous √† nous excuser sinc√®rement pour les probl√®mes que vous avez tous rencontr√©s.  Nous connaissons votre confiance en GitHub et sommes fiers de cr√©er des syst√®mes durables qui prennent en charge la haute disponibilit√© de notre plateforme.  Nous vous avons laiss√© tomber cet incident et le regrettons profond√©ment.  Bien que nous ne puissions pas r√©soudre les probl√®mes dus √† la d√©gradation de la plate-forme GitHub pendant longtemps, nous pouvons expliquer les raisons de ce qui s'est pass√©, parler des le√ßons apprises et des mesures qui permettront √† l'entreprise de mieux se prot√©ger contre de telles d√©faillances √† l'avenir. <br><a name="habracut"></a><br><h1>  Contexte </h1><br>  La plupart des services utilisateur GitHub fonctionnent dans nos propres <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">centres de donn√©es</a> .  La topologie du centre de donn√©es est con√ßue pour fournir un r√©seau frontalier fiable et extensible devant plusieurs centres de donn√©es r√©gionaux qui fournissent le travail des syst√®mes informatiques et de stockage de donn√©es.  Malgr√© les niveaux de redondance int√©gr√©s aux composants physiques et logiques du projet, il est toujours possible que les sites ne puissent pas interagir les uns avec les autres pendant un certain temps. <br><br>  Le 21 octobre, √† 22 h 52 UTC, les travaux de r√©paration pr√©vus pour remplacer l'√©quipement optique 100G d√©fectueux ont entra√Æn√© une perte de communication entre le n≈ìud du r√©seau sur la c√¥te est (c√¥te est des √âtats-Unis) et le principal centre de donn√©es sur la c√¥te est.  La connexion entre eux a √©t√© r√©tablie apr√®s 43 secondes, mais cette courte d√©connexion a provoqu√© une cha√Æne d'√©v√©nements qui a entra√Æn√© 24 heures et 11 minutes de d√©gradation du service. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c1e/fd8/71b/c1efd871b9017afe95d9605703ba7734.png"><br>  <i><font color="gray">L'architecture de r√©seau de haut niveau de GitHub, comprenant deux centres de donn√©es physiques, 3 POP et un stockage cloud dans plusieurs r√©gions, connect√©s via l'homologation</font></i> <br><br>  Dans le pass√©, nous avons discut√© de la fa√ßon dont nous utilisons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MySQL pour stocker les m√©tadonn√©es GitHub</a> , ainsi que de notre approche pour fournir une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">haute disponibilit√© pour MySQL</a> .  GitHub g√®re plusieurs clusters MySQL dont la taille varie de centaines de gigaoctets √† pr√®s de cinq t√©raoctets.  Chaque cluster poss√®de des dizaines de r√©plicas en lecture pour stocker des m√©tadonn√©es autres que Git, de sorte que nos applications fournissent des demandes de pool, des probl√®mes, l'authentification, le traitement en arri√®re-plan et des fonctionnalit√©s suppl√©mentaires en dehors du r√©f√©rentiel d'objets Git.  Diff√©rentes donn√©es dans diff√©rentes parties de l'application sont stock√©es dans diff√©rents clusters √† l'aide de la segmentation fonctionnelle. <br><br>  Pour am√©liorer les performances √† grande √©chelle, les applications dirigent les √©critures sur le serveur principal appropri√© pour chaque cluster, mais dans la grande majorit√© des cas, d√©l√®guent les demandes de lecture √† un sous-ensemble de serveurs de r√©plicas.  Nous utilisons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Orchestrator</a> pour g√©rer les topologies de cluster MySQL et basculer automatiquement.  Au cours de ce processus, Orchestrator prend en compte un certain nombre de variables et est assembl√© au-dessus de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Raft</a> pour plus de coh√©rence.  Orchestrator peut potentiellement impl√©menter des topologies que les applications ne prennent pas en charge, vous devez donc vous assurer que votre configuration Orchestrator r√©pond aux attentes au niveau de l'application. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/686/ea1/657/686ea165750913fa41b771482266b887.png"><br>  <i><font color="gray">Dans une topologie typique, toutes les applications lisent localement avec une faible latence.</font></i> <br><br><h1>  Chronique de l'incident </h1><br><h4>  10.21.2018, 22:52 UTC </h4><br>  Au cours de la s√©paration du r√©seau susmentionn√©e, Orchestrator dans le centre de donn√©es principal a commenc√© le processus de d√©s√©lection du leadership selon l'algorithme de consensus Raft.  Le centre de donn√©es de la c√¥te ouest et les n≈ìuds de cloud public Orchestrator sur la c√¥te est ont r√©ussi √† atteindre un consensus - et ont commenc√© √† r√©soudre les √©checs de cluster pour transmettre les enregistrements au centre de donn√©es occidental.  Orchestrator a commenc√© √† cr√©er une topologie de cluster de base de donn√©es dans l'Ouest.  Apr√®s la reconnexion, les applications ont imm√©diatement envoy√© du trafic d'√©criture vers les nouveaux serveurs principaux dans l'ouest am√©ricain. <br><br>  Sur les serveurs de bases de donn√©es du centre de donn√©es oriental, il y avait des enregistrements pour une courte p√©riode qui n'√©taient pas r√©pliqu√©s vers le centre de donn√©es occidental.  √âtant donn√© que les clusters de bases de donn√©es dans les deux centres de donn√©es contenaient d√©sormais des enregistrements qui ne se trouvaient pas dans l'autre centre de donn√©es, nous n'avons pas pu retourner en toute s√©curit√© le serveur principal au centre de donn√©es oriental. <br><br><h4>  10.21.2018, 22:54 UTC </h4><br>  Nos syst√®mes de surveillance internes ont commenc√© √† g√©n√©rer des alertes indiquant de nombreux dysfonctionnements du syst√®me.  √Ä cette √©poque, plusieurs ing√©nieurs ont r√©pondu et travaill√© sur le tri des notifications entrantes.  √Ä 23 h 02, les ing√©nieurs du premier groupe de r√©ponse ont d√©termin√© que les topologies de nombreux clusters de bases de donn√©es √©taient dans un √©tat inattendu.  Lors de l'interrogation de l'API Orchestrator, la topologie de r√©plication de la base de donn√©es √©tait affich√©e, ne contenant que les serveurs du centre de donn√©es occidental. <br><br><h4>  10.21.2018, 23:07 UTC </h4><br>  √Ä ce stade, l'√©quipe d'intervention a d√©cid√© de bloquer manuellement les outils de d√©ploiement interne pour emp√™cher des modifications suppl√©mentaires.  √Ä 23 h 09, le groupe a mis le site en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">jaune</a> .  Cette action a automatiquement attribu√© √† la situation le statut d'incident actif et envoy√© un avertissement au coordinateur d'incident.  √Ä 23h11, le coordinateur a rejoint le travail et deux minutes plus tard a d√©cid√© de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">changer le statut en rouge</a> . <br><br><h4>  10.21.2018, 23:13 UTC </h4><br>  √Ä cette √©poque, il √©tait clair que le probl√®me affectait plusieurs clusters de bases de donn√©es.  D'autres d√©veloppeurs du groupe d'ing√©nierie de la base de donn√©es ont √©t√© impliqu√©s dans les travaux.  Ils ont commenc√© √† examiner l'√©tat actuel pour d√©terminer les actions √† entreprendre pour configurer manuellement la base de donn√©es de la c√¥te est des √âtats-Unis en tant que principale pour chaque cluster et reconstruire la topologie de r√©plication.  Cela n'a pas √©t√© facile, car √† ce stade, le cluster de bases de donn√©es occidentales recevait des enregistrements du niveau application depuis pr√®s de 40 minutes.  De plus, dans la grappe orientale, il y avait plusieurs secondes d'enregistrements qui n'√©taient pas r√©pliqu√©s vers l'ouest et ne permettaient pas la r√©plication de nouveaux enregistrements vers l'est. <br><br>  La protection de la confidentialit√© et de l'int√©grit√© des donn√©es utilisateur est la priorit√© absolue de GitHub.  Par cons√©quent, nous avons d√©cid√© que plus de 30 minutes de donn√©es enregistr√©es dans le centre de donn√©es occidental ne nous laissaient qu'une seule solution √† la situation afin de sauvegarder ces donn√©es: le transfert vers l'avant (√©chec vers l'avant).  Cependant, les applications de l'Est, qui d√©pendent de l'√©criture d'informations dans le cluster MySQL occidental, ne sont actuellement pas en mesure de g√©rer le d√©lai suppl√©mentaire d√ª au transfert de la plupart de leurs appels de base de donn√©es dans les deux sens.  Cette d√©cision entra√Ænera le fait que notre service deviendra inappropri√© pour de nombreux utilisateurs.  Nous pensons que la d√©gradation √† long terme de la qualit√© de service valait la peine d'assurer la coh√©rence des donn√©es de nos utilisateurs. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a66/119/b52/a66119b52dbb23111ddfe47bca1194d8.png"><br>  <i><font color="gray">Dans la mauvaise topologie, la r√©plication d'Ouest en Est est viol√©e et les applications ne peuvent pas lire les donn√©es des r√©plicas actuels, car elles d√©pendent d'une faible latence pour maintenir les performances des transactions</font></i> <br><br><h4>  10.21.2018, 23:19 UTC </h4><br>  Les enqu√™tes sur l'√©tat des clusters de bases de donn√©es ont montr√© qu'il √©tait n√©cessaire d'arr√™ter l'ex√©cution des t√¢ches qui √©crivent des m√©tadonn√©es telles que les requ√™tes push.  Nous avons fait un choix et avons d√©lib√©r√©ment opt√© pour une d√©gradation partielle du service, suspendant les webhooks et l'assemblage des pages GitHub afin de ne pas mettre en p√©ril les donn√©es que nous avons d√©j√† re√ßues des utilisateurs.  En d'autres termes, la strat√©gie √©tait de prioriser: l'int√©grit√© des donn√©es au lieu de la convivialit√© du site et une r√©cup√©ration rapide. <br><br><h4>  22/10/2018, 00:05 UTC </h4><br>  Les ing√©nieurs de l'√©quipe d'intervention ont commenc√© √† d√©velopper un plan pour r√©soudre les incoh√©rences de donn√©es et ont lanc√© des proc√©dures de basculement pour MySQL.  Le plan √©tait de restaurer les fichiers √† partir de la sauvegarde, de synchroniser les r√©plicas sur les deux sites, de revenir √† une topologie de service stable, puis de reprendre les travaux de traitement dans la file d'attente.  Nous avons mis √† jour le statut pour informer les utilisateurs que nous allons effectuer un basculement g√©r√© du syst√®me de stockage interne. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eb4/cb7/a34/eb4cb7a34add07f272b99fc93f161d56.png"><br>  <i><font color="gray">Le plan de r√©cup√©ration impliquait d'aller de l'avant, de restaurer √† partir de sauvegardes, de synchroniser, d'annuler et de travailler sur le d√©lai avant de revenir au statut vert</font></i> <br><br>  Bien que les sauvegardes MySQL soient effectu√©es toutes les quatre heures et stock√©es pendant de nombreuses ann√©es, elles se trouvent dans un stockage cloud distant d'objets blob.  La r√©cup√©ration de plusieurs t√©raoctets √† partir d'une sauvegarde a pris plusieurs heures.  Le transfert des donn√©es du service de sauvegarde √† distance a pris beaucoup de temps.  La plupart du temps a √©t√© consacr√© au d√©ballage, √† la v√©rification de la somme de contr√¥le, √† la pr√©paration et au t√©l√©chargement de fichiers de sauvegarde volumineux sur des serveurs MySQL fra√Æchement pr√©par√©s.  Cette proc√©dure est test√©e quotidiennement, donc tout le monde avait une bonne id√©e du temps que prendrait la r√©cup√©ration.  Cependant, avant cet incident, nous n'avions jamais eu √† reconstruire compl√®tement l'int√©gralit√© du cluster √† partir d'une sauvegarde.  D'autres strat√©gies ont toujours fonctionn√©, comme les r√©pliques diff√©r√©es. <br><br><h4>  22/10/2018, 00:41 UTC </h4><br>  √Ä ce moment, un processus de sauvegarde avait √©t√© lanc√© pour tous les clusters MySQL concern√©s et les ing√©nieurs ont suivi les progr√®s.  Dans le m√™me temps, plusieurs groupes d'ing√©nieurs ont √©tudi√© les moyens d'acc√©l√©rer le transfert et la r√©cup√©ration sans d√©gradation suppl√©mentaire du site ni risque de corruption des donn√©es. <br><br><h4>  22/10/2018, 06:51 UTC </h4><br>  Plusieurs clusters dans le centre de donn√©es oriental ont termin√© la r√©cup√©ration des sauvegardes et ont commenc√© √† r√©pliquer de nouvelles donn√©es de la c√¥te ouest.  Cela a entra√Æn√© un ralentissement du chargement des pages qui ont effectu√© une op√©ration d'√©criture √† travers le pays, mais la lecture des pages de ces clusters de base de donn√©es a retourn√© des r√©sultats r√©els si la demande de lecture tombait sur une r√©plique nouvellement restaur√©e.  D'autres clusters de bases de donn√©es plus importants ont continu√© de se redresser. <br><br>  Nos √©quipes ont identifi√© une m√©thode de r√©cup√©ration directement depuis la c√¥te ouest pour surmonter les limitations de bande passante caus√©es par le d√©marrage √† partir d'un stockage externe.  Il est devenu presque clair √† 100% que la r√©cup√©ration se terminera avec succ√®s, et le temps n√©cessaire pour cr√©er une topologie de r√©plication saine d√©pend du temps n√©cessaire √† la r√©plication de rattrapage.  Cette estimation a √©t√© interpol√©e lin√©airement en fonction de la r√©plication de t√©l√©m√©trie disponible, et la page d'√©tat a √©t√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mise</a> √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">jour</a> pour d√©finir l'attente de deux heures comme temps de r√©cup√©ration estim√©. <br><br><h4>  22/10/2018, 07:46 UTC </h4><br>  GitHub a publi√© un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article de blog informatif</a> .  Nous utilisons nous-m√™mes les pages GitHub, et tous les assemblages ont √©t√© interrompus il y a quelques heures, la publication a donc n√©cessit√© des efforts suppl√©mentaires.  Nous nous excusons pour le retard.  Nous avions l'intention d'envoyer ce message beaucoup plus t√¥t et √† l'avenir, nous fournirons la publication de mises √† jour dans les conditions de ces restrictions. <br><br><h4>  22/10/2018, 11:12 UTC </h4><br>  Toutes les bases de donn√©es primaires sont √† nouveau transf√©r√©es vers l'Est.  Cela a conduit le site √† devenir beaucoup plus r√©actif, car les enregistrements √©taient d√©sormais achemin√©s vers un serveur de base de donn√©es situ√© dans le m√™me centre de donn√©es physique que notre couche d'application.  Bien que cela ait consid√©rablement am√©lior√© les performances, il y avait encore des dizaines de r√©pliques de lecture de la base de donn√©es qui √©taient plusieurs heures derri√®re la copie principale.  Ces r√©pliques diff√©r√©es ont conduit les utilisateurs √† voir des donn√©es incoh√©rentes lors de leurs interactions avec nos services.  Nous r√©partissons la charge de lecture sur un large pool de r√©plicas de lecture, et chaque demande √† nos services a de bonnes chances d'entrer dans la r√©plique de lecture avec un retard de plusieurs heures. <br><br>  En fait, le temps de rattrapage d'une r√©plique en retard est r√©duit de fa√ßon exponentielle et non lin√©aire.  Lorsque les utilisateurs aux √âtats-Unis et en Europe se sont r√©veill√©s, en raison de la charge accrue des enregistrements dans les clusters de bases de donn√©es, le processus de r√©cup√©ration a pris plus de temps que pr√©vu. <br><br><h4>  22/10/2018, 13:15 UTC </h4><br>  Nous approchions de la charge de pointe sur GitHub.com.  L'√©quipe d'intervention a discut√© des prochaines √©tapes.  Il √©tait clair que le retard de r√©plication vers un √©tat coh√©rent augmente, et non diminue.  Plus t√¥t, nous avons commenc√© √† pr√©parer des r√©pliques de lecture MySQL suppl√©mentaires dans le cloud public de la c√¥te Est.  Une fois disponibles, il est devenu plus facile de r√©partir le flux des demandes de lecture entre plusieurs serveurs.  La r√©duction de la charge moyenne des r√©plicas en lecture a acc√©l√©r√© le rattrapage de la r√©plication. <br><br><h4>  22/10/2018, 16:24 UTC </h4><br>  Apr√®s avoir synchronis√© les r√©pliques, nous sommes revenus √† la topologie d'origine, √©liminant les probl√®mes de retard et de disponibilit√©.  Dans le cadre d'une d√©cision consciente sur la priorit√© de l'int√©grit√© des donn√©es par rapport √† une correction rapide de la situation, nous avons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">maintenu le statut rouge du</a> site lorsque nous avons commenc√© √† traiter les donn√©es accumul√©es. <br><br><h4>  22/10/2018, 16:45 UTC </h4><br>  Au stade de la r√©cup√©ration, il √©tait n√©cessaire d'√©quilibrer la charge accrue associ√©e au d√©calage, surchargeant potentiellement nos partenaires de l'√©cosyst√®me de notifications et revenant √† une efficacit√© √† cent pour cent aussi rapidement que possible.  Plus de cinq millions d'√©v√©nements de raccordement et 80 000 demandes de cr√©ation de pages Web sont rest√©s dans la file d'attente. <br><br>  Lorsque nous avons r√©activ√© le traitement de ces donn√©es, nous avons trait√© environ 200 000 t√¢ches utiles avec des webhooks qui d√©passaient le TTL interne et ont √©t√© abandonn√©es.  En apprenant cela, nous avons arr√™t√© le traitement et commenc√© √† augmenter le TTL. <br><br>  Pour √©viter une nouvelle diminution de la fiabilit√© de nos mises √† jour de statut, nous avons laiss√© le statut de d√©gradation jusqu'√† ce que nous ayons fini de traiter l'int√©gralit√© de la quantit√© de donn√©es accumul√©es et de nous assurer que les services sont clairement revenus au niveau normal de performance. <br><br><h4>  22/10/2018, 23h03 UTC </h4><br>  Tous les √©v√©nements de webhook et assemblages de pages incomplets sont trait√©s, et l'int√©grit√© et le bon fonctionnement de tous les syst√®mes sont confirm√©s.  Le statut du site est pass√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">au vert</a> . <br><br><h1>  Actions suppl√©mentaires </h1><br><h4>  R√©solution de l'inad√©quation des donn√©es </h4><br>  Pendant la r√©cup√©ration, nous avons corrig√© les journaux binaires MySQL avec des entr√©es principalement du centre de donn√©es, qui n'√©taient pas r√©pliqu√©es vers le centre de l'Ouest.  Le nombre total de ces entr√©es est relativement faible.  Par exemple, dans l'un des clusters les plus occup√©s, il n'y a que 954 enregistrements dans ces secondes.  Nous analysons actuellement ces journaux et d√©terminons quelles entr√©es peuvent √™tre automatiquement rapproch√©es et lesquelles n√©cessitent une assistance utilisateur.  Plusieurs √©quipes participent √† ce travail, et notre analyse a d√©j√† d√©termin√© la cat√©gorie d'enregistrements que l'utilisateur a ensuite r√©p√©t√©s - et ils ont √©t√© enregistr√©s avec succ√®s.  Comme indiqu√© dans cette analyse, notre objectif principal est de maintenir l'int√©grit√© et la pr√©cision des donn√©es que vous stockez sur GitHub. <br><br><h4>  La communication </h4><br>  En essayant de vous transmettre des informations importantes pendant l'incident, nous avons fait plusieurs estimations publiques du temps de r√©cup√©ration en fonction de la vitesse de traitement des donn√©es accumul√©es.  R√©trospectivement, nos estimations n'ont pas pris en compte toutes les variables.  Nous nous excusons pour la confusion et nous nous efforcerons de fournir des informations plus pr√©cises √† l'avenir. <br><br><h4>  Mesures techniques </h4><br>  Au cours de cette analyse, un certain nombre de mesures techniques ont √©t√© identifi√©es.  L'analyse se poursuit, la liste peut √™tre compl√©t√©e. <br><br><ul><li>  Ajustez la configuration d'Orchestrator pour emp√™cher les bases de donn√©es principales de se d√©placer hors de la r√©gion.  Orchestrator a fonctionn√© selon les param√®tres, bien que la couche application ne prenne pas en charge un tel changement de topologie.  Le choix d'un leader dans une r√©gion est g√©n√©ralement s√ªr, mais l'apparition soudaine d'un retard d√ª √† la circulation √† travers le continent est devenue la principale cause de cet incident.  Il s'agit d'un comportement nouveau et √©mergent du syst√®me, car avant nous ne rencontrions pas la section interne du r√©seau de cette ampleur. </li><li>  Nous avons acc√©l√©r√© la migration vers le nouveau syst√®me de rapport d'√©tat, qui fournira une plate-forme plus appropri√©e pour discuter des incidents actifs avec des formulations plus pr√©cises et claires.  Bien que de nombreuses parties de GitHub aient √©t√© disponibles tout au long de l'incident, nous n'avons pu s√©lectionner que les √©tats vert, jaune et rouge pour l'ensemble du site.  Nous admettons que cela ne donne pas une image pr√©cise: ce qui fonctionne et ce qui ne fonctionne pas.  Le nouveau syst√®me affichera les diff√©rents composants de la plateforme afin que vous connaissiez l'√©tat de chaque service. </li><li>  Quelques semaines avant cet incident, nous avons lanc√© une initiative d'ing√©nierie √† l'√©chelle de l'entreprise pour prendre en charge le trafic GitHub √† partir de plusieurs centres de donn√©es en utilisant l'architecture active / active / active.  L'objectif de ce projet est de prendre en charge la redondance N + 1 au niveau du centre de donn√©es afin de r√©sister √† la d√©faillance d'un centre de donn√©es sans interf√©rence ext√©rieure.  Cela repr√©sente beaucoup de travail et prendra du temps, mais nous pensons que plusieurs centres de donn√©es bien connect√©s dans diff√©rentes r√©gions constitueront un bon compromis.  Le dernier incident a pouss√© cette initiative encore plus loin. </li><li>  Nous prendrons une position plus active dans la v√©rification de nos hypoth√®ses.  GitHub se d√©veloppe rapidement et a accumul√© une quantit√© consid√©rable de complexit√© au cours de la derni√®re d√©cennie.  Il devient de plus en plus difficile de saisir et de transmettre √† la nouvelle g√©n√©ration d'employ√©s le contexte historique des compromis et des d√©cisions prises. </li></ul><br><h4>  Mesures organisationnelles </h4><br>  Cet incident a grandement influenc√© notre compr√©hension de la fiabilit√© du site.  Nous avons appris que resserrer le contr√¥le op√©rationnel ou am√©liorer les temps de r√©ponse ne sont pas des garanties suffisantes de fiabilit√© dans un syst√®me de services aussi complexe que le n√¥tre.  Pour soutenir ces efforts, nous commencerons √©galement une pratique syst√©matique de test des sc√©narios de panne avant qu'ils ne se produisent r√©ellement.  Ce travail comprend un d√©pannage d√©lib√©r√© et l'utilisation d'outils d'ing√©nierie du chaos. <br><br><h1>  Conclusion </h1><br>  Nous savons comment vous comptez sur GitHub dans vos projets et votre entreprise.  Nous nous soucions plus que quiconque de la disponibilit√© de notre service et de la s√©curit√© de vos donn√©es.  L'analyse de cet incident continuera de trouver une occasion de mieux vous servir et de justifier votre confiance. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428409/">https://habr.com/ru/post/fr428409/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428393/index.html">Webinaire "Testez les environnements 2.0 dans le cloud et apprenez √† les cuisiner"</a></li>
<li><a href="../fr428395/index.html">Le livre ¬´Minimum th√©orique pour le Big Data. Tout ce que vous devez savoir sur le Big Data ¬ª</a></li>
<li><a href="../fr428401/index.html">Processus de d√©veloppement √† travers les yeux de l'exploitation. Un regard de l'autre c√¥t√© de la barricade</a></li>
<li><a href="../fr428403/index.html">Le condens√© des √©v√©nements pour les professionnels des RH dans le domaine des TI pour novembre 2018</a></li>
<li><a href="../fr428407/index.html">6 parcelles typiques de la litt√©rature mondiale</a></li>
<li><a href="../fr428411/index.html">Radar technologique: une liste de langages, d'outils et de plateformes qui sont pass√©s entre les mains de Lamoda</a></li>
<li><a href="../fr428413/index.html">Syst√®mes de refroidissement dans les centres de donn√©es Selectel</a></li>
<li><a href="../fr428415/index.html">Pr√©sentation du contr√¥leur cloud TP-Link Omada OC200</a></li>
<li><a href="../fr428417/index.html">Apprentissage automatique dans MatLab / Octave: exemples d'algorithmes pris en charge par les formules</a></li>
<li><a href="../fr428419/index.html">Faites glisser et faites glisser dans RecyclerView. Partie 2: glisser-d√©poser des contr√¥leurs, des grilles et des animations personnalis√©es</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
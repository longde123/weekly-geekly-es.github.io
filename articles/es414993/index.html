<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👐🏼 🍄 💆🏾 Identificación y clasificación de comentarios tóxicos. Conferencia en Yandex 😐 🥣 👋🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Todos los sistemas modernos de moderación utilizan crowdsourcing o aprendizaje automático que ya se ha convertido en un clásico. En el próximo entrena...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Identificación y clasificación de comentarios tóxicos. Conferencia en Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/414993/">  Todos los sistemas modernos de moderación utilizan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">crowdsourcing</a> o aprendizaje automático que ya se ha convertido en un clásico.  En el próximo entrenamiento de ML en Yandex, Konstantin Kotik, Igor Galitsky y Alexey Noskov hablaron sobre su participación en el concurso para la identificación masiva de comentarios ofensivos.  La competencia se llevó a cabo en la plataforma Kaggle. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3mL9iP8g3fA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - Hola a todos!  Mi nombre es Konstantin Kotik, soy científico de datos en la compañía Button of Life, estudiante del departamento de física y de la Escuela de Graduados de Negocios de la Universidad Estatal de Moscú. <br><a name="habracut"></a><br>  Hoy, nuestros colegas, Igor Galitsky y Alexei Noskov, le informarán sobre la competencia del Desafío de clasificación de comentarios tóxicos, en la que nuestro equipo DecisionGuys ocupó el décimo lugar entre 4551 equipos. <br><br>  Una discusión en línea de temas que nos importan puede ser difícil.  Los insultos, la agresión y el acoso que ocurren en línea a menudo obligan a muchas personas a abandonar la búsqueda de varias opiniones apropiadas sobre temas que les interesan, a negarse a expresarse. <br><br>  Muchas plataformas luchan por comunicarse efectivamente en línea, pero esto a menudo lleva a muchas comunidades a simplemente cerrar los comentarios de los usuarios. <br><br>  Un equipo de investigación de Google y otra compañía están trabajando en herramientas para ayudar a mejorar la discusión en línea. <br><br>  Uno de los trucos en los que se centran es explorar comportamientos negativos en línea, como comentarios tóxicos.  Estos son comentarios que pueden ser ofensivos, irrespetuosos o simplemente obligar al usuario a abandonar la discusión. <br><br><img src="https://habrastorage.org/webt/y2/o4/oz/y2o4ozi061ri0lyir_c9szxsmko.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Hasta la fecha, este grupo ha desarrollado una API pública que puede determinar el grado de toxicidad de un comentario, pero sus modelos actuales aún cometen errores.  Y en esta competencia, nosotros, los Kegglers, fuimos desafiados a construir un modelo que fuera capaz de identificar comentarios que contengan amenazas, odio, insultos y similares.  E idealmente, este modelo debía ser mejor que el modelo actual para su API. <br><br>  Tenemos la tarea del procesamiento de texto: identificar y luego clasificar los comentarios.  Como ejemplos de entrenamiento y prueba, se proporcionaron comentarios de las páginas de discusión de Wikipedia.  Hubo alrededor de 160 mil comentarios en el tren, 154 mil en la prueba. <br><br><img src="https://habrastorage.org/webt/u5/ys/we/u5yswe0_sb618cfq9rlilpykuke.jpeg" width="700"><br><br>  La muestra de entrenamiento se marcó de la siguiente manera.  Cada comentario tiene seis etiquetas.  Las etiquetas toman el valor 1 si el comentario contiene este tipo de toxicidad, 0 de lo contrario.  Y puede ser que todas las etiquetas sean cero, un caso de comentario adecuado.  O puede ser que un comentario contenga varios tipos de toxicidad, inmediatamente una amenaza y obscenidad. <br><br>  Debido al hecho de que estamos en el aire, no puedo demostrar ejemplos específicos de estas clases.  Con respecto a la muestra de prueba, para cada comentario fue necesario predecir la probabilidad de cada tipo de toxicidad. <br><br>  La métrica de calidad es el AUC ROC promediado sobre los tipos de toxicidad, es decir, la media aritmética del AUC ROC para cada clase por separado. <br><br><img src="https://habrastorage.org/webt/17/cm/gk/17cmgklewbzg00esfhzii641og4.jpeg" width="700"><br><br>  Aquí está la distribución de objetos por clases en el conjunto de entrenamiento.  Se puede ver que los datos están muy desequilibrados.  Debo decir de inmediato que nuestro equipo calificó en una muestra de métodos para trabajar con datos desequilibrados, por ejemplo, sobremuestreo o submuestreo. <br><br><img src="https://habrastorage.org/webt/og/t6/gy/ogt6gyfkpmslose73rrxl4v_7ci.jpeg" width="700"><br><br>  Cuando construí el modelo, utilicé un preprocesamiento de datos en dos etapas.  La primera etapa es el preprocesamiento básico de los datos, estas son las transformaciones de la vista en la diapositiva, esto está llevando el texto a minúsculas, eliminando enlaces, direcciones IP, números y signos de puntuación. <br><br><img src="https://habrastorage.org/webt/xb/5v/kq/xb5vkq8juiimjekysw3e0we4vgq.jpeg" width="700"><br><br>  Para todos los modelos, se utilizó este preprocesamiento de datos básico.  En la segunda etapa, se llevó a cabo un preprocesamiento parcial de los datos, reemplazando los emoticones con las palabras correspondientes, descifrando abreviaturas, corrigiendo errores tipográficos, llevando los diferentes tipos de tapetes a la misma forma y también eliminando imágenes.  En algunos comentarios, se indicaron enlaces a imágenes, simplemente los eliminamos. <br><br>  Para cada uno de los modelos, se utilizó el preprocesamiento parcial de datos y sus diversos elementos.  Todo esto se hizo para que los modelos base redujeran la correlación cruzada entre los modelos base al construir una composición adicional. <br>  Pasemos a la parte más interesante: construir un modelo. <br><br>  Inmediatamente abandoné el enfoque clásico de la bolsa de palabras.  Debido al hecho de que en este enfoque cada palabra es un atributo separado.  Este enfoque no tiene en cuenta el orden general de las palabras; se supone que las palabras son independientes.  En este enfoque, la generación del texto ocurre de modo que haya cierta distribución en las palabras, una palabra se selecciona aleatoriamente de esta distribución y se inserta en el texto. <br><br>  Por supuesto, hay procesos generativos más complejos, pero la esencia no cambia: este enfoque no tiene en cuenta el orden general de las palabras.  Puede ir a engramas, pero solo se tendrá en cuenta el orden de las palabras en la ventana, y no en general.  Por lo tanto, también entendí a mis compañeros de equipo que necesitaban usar algo más inteligente. <br><br><img src="https://habrastorage.org/webt/7q/1q/2v/7q1q2v5h2q8c8ngog4foqvsabbm.jpeg" width="700"><br><h5>  <sub><sup><a href="">Enlace</a></sup></sub> </h5><br>  Lo primero que se me ocurrió fue usar una representación vectorial con Doc2vec.  Este es Word2vec más un vector que tiene en cuenta la unicidad de un documento en particular.  En el artículo original, este vector se llama como el párrafo id. <br><br>  Luego, de acuerdo con dicha representación vectorial, se estudió la regresión logística, donde cada documento estaba representado por un vector de 10.000 dimensiones.  La evaluación de calidad se realizó en una validación cruzada de diez pliegues, se estratificó y es importante tener en cuenta que la regresión logística se estudió para cada clase, seis problemas de clasificación se resolvieron por separado.  Y al final, el resultado fue una distribución de probabilidad por clase. <br><br>  La regresión logística ha sido entrenada durante mucho tiempo.  Generalmente no encajaba en la RAM.  En las instalaciones de Igor, pasaron un día en algún lugar para obtener el resultado, como en una diapositiva.  Por esta razón, de inmediato nos negamos a usar Doc2vec debido a las altas expectativas, aunque podría mejorarse en 1000 si se hiciera un comentario con preprocesamiento de datos adicional. <br><br><img src="https://habrastorage.org/webt/kt/0i/ks/kt0iksctnlf6kobgk1e0xnkomee.jpeg" width="700"><br><br>  Los más inteligentes que nosotros y los otros competidores usamos fueron redes neuronales recurrentes.  Reciben secuencialmente palabras en la entrada, actualizando su estado oculto después de cada palabra.  Igor y yo usamos la red recurrente GRU para la incorporación de palabras en fastText, que es especial porque resuelve muchos problemas de clasificación binaria independientes.  Predecir la presencia o ausencia de la palabra de contexto de forma independiente. <br><br>  También realizamos una evaluación de calidad en la validación cruzada de diez pliegues, no se estratificó aquí, y aquí la distribución de probabilidad se obtuvo inmediatamente por clase.  Cada problema de clasificación binaria no se resolvió por separado, pero se generó inmediatamente un vector de seis dimensiones.  Fue nuestro uno de los mejores modelos individuales. <br><br>  Usted pregunta, ¿cuál fue el secreto del éxito? <br><br><img src="https://habrastorage.org/webt/aq/ik/nm/aqiknmpv8txoen1uollbhmy3iz8.jpeg" width="700"><br><br>  Consistía en mezclar, había mucho, con apilamiento y redes en el enfoque.  El enfoque de redes debe representarse como un gráfico dirigido. <br><br><img src="https://habrastorage.org/webt/uj/hl/9r/ujhl9rp1pse-y-0euvxutavnrpa.jpeg" width="700"><br><br>  Al comienzo de la competencia, el equipo de DecisionGuys estaba formado por dos personas.  Luego, Pavel Pleskov, en el canal ODS Slack, expresó el deseo de querer formar un equipo con alguien del top 200.  En ese momento estábamos en algún lugar en el lugar 157, y Pavel Pleskov en el lugar 154, en algún lugar del vecindario.  Igor notó su deseo de unirse, y lo invité al equipo.  Entonces Andrey Litvinov se unió a nosotros, luego Pavel invitó al Gran Maestro Alexei Noskov a nuestro equipo.  Igor - Eugene.  Y el último socio de nuestro equipo fue el búlgaro Atanas Atanasov, y este fue el resultado de un conjunto internacional humano. <br><br>  Ahora Igor Galitsky contará cómo enseñó gru, con más detalle hablará sobre las ideas y enfoques de Pavel Pleskov, Andrei Litvinov y Atanas Atanasov. <br><br>  Igor Galitsky: <br>  - Soy científico de datos en Epoch8, y hablaré sobre la mayoría de las arquitecturas que utilizamos. <br><br><img src="https://habrastorage.org/webt/l1/ah/jz/l1ahjzsk3hgrivbmffam4eb_9vy.jpeg" width="700"><br><br>  Todo comenzó con el gruñido didireccional estándar con dos capas, casi todos los equipos lo usaron, y fastText, la función de activación EL, se usó como incrustación. <br><br>  No hay nada especial que decir, arquitectura simple, sin lujos.  ¿Por qué nos dio tan buenos resultados con los que nos mantuvimos en el top 150 durante bastante tiempo?  Tuvimos un buen preprocesamiento del texto.  Era necesario seguir adelante. <br><br><img src="https://habrastorage.org/webt/ni/ny/dx/ninydx6a2wsofsa-qdqncx904ou.jpeg" width="700"><br><br>  Paul tuvo su propio enfoque.  Después de mezclarse con la nuestra, esto dio un aumento significativo.  Antes de eso, teníamos una mezcla de gru y modelo en Doc2vec, dio 61 LB. <br><br><img src="https://habrastorage.org/webt/hq/uk/lg/hquklgojqvgbhidth4gqgv5lctg.jpeg" width="700"><br><br>  Te contaré sobre los enfoques de Atanas Atanasov, él es directamente un entusiasta de cualquier artículo nuevo.  Aquí está gru con atención, todos los parámetros en la diapositiva.  Tenía muchos enfoques realmente geniales, pero hasta el último momento usó su preprocesamiento y todas las ganancias se nivelaron.  Velocidad en el tobogán. <br><br><img src="https://habrastorage.org/webt/1f/3w/_h/1f3w_hiemppymuwtyvt4xjd04so.jpeg" width="700"><br><br>  Luego hubo una atención jerárquica, mostró resultados aún peores, ya que inicialmente era una red para clasificar documentos que constaban de oraciones.  Lo jodió, pero el enfoque no es muy. <br><br><img src="https://habrastorage.org/webt/dp/pn/su/dppnsuijdyfefmos-rmpecohrsu.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Hubo un enfoque interesante, inicialmente podemos obtener características de la oferta desde el principio y desde el final.  Con la ayuda de convolución, capas convolucionales, obtenemos entidades por separado a la izquierda y a la derecha del árbol.  Esto es desde el principio y el final de la oración, luego se fusionan y nuevamente pasan por gru. <br><br><img src="https://habrastorage.org/webt/j7/gp/vr/j7gpvrmt3s3tf04qidvcfobmzvs.jpeg" width="700"><br><br>  También Bi-GRU con bloque de atención.  Este es uno de los mejores en privado fue una red bastante profunda, mostró buenos resultados. <br><br><img src="https://habrastorage.org/webt/d9/tw/_v/d9tw_v7n_nkvuxnxctppb2lvbyo.jpeg" width="700"><br><br>  El siguiente enfoque es resaltar las características tanto como sea posible.  Después de la capa de la red recurrente, hacemos tres capas paralelas más de convolución.  Y aquí tomamos oraciones no tan largas, las redujimos a 250, pero debido a tres convoluciones esto dio un buen resultado. <br><br><img src="https://habrastorage.org/webt/ft/hq/xy/fthqxy5pglwimem_-h46ieewheq.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Fue la red más profunda.  Como dijo Atanas, solo quería enseñar algo grande e interesante.  Una cuadrícula convolucional ordinaria que aprendió de las características del texto, los resultados no son nada especial. <br><br><img src="https://habrastorage.org/webt/pq/d6/eh/pqd6eh0_hxzqvb6hkwkjzkyws1u.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Este es un enfoque nuevo bastante interesante, en 2017 hubo un artículo sobre este tema, se usó para ImageNet y allí nos permitió mejorar el resultado anterior en un 25%.  Su característica principal es que se lanza una pequeña capa paralela al bloque convolucional, que enseña los pesos para cada convolución en este bloque.  Ella dio un enfoque muy bueno, a pesar de cortar las oraciones. <br><br>  El problema es que la longitud máxima de las oraciones en estas tareas alcanzó las 1.500 palabras, hubo comentarios muy grandes.  Otros equipos también pensaron en cómo aprovechar esta gran oferta, cómo encontrarla, porque no todo está muy presionado.  Y muchos dijeron que al final de la oración había un infante muy importante.  Desafortunadamente, en todos estos enfoques, esto no se tuvo en cuenta, porque se tomó el comienzo.  Quizás esto daría un aumento adicional. <br><br><img src="https://habrastorage.org/webt/mn/aq/om/mnaqomuiugd3p8_bpnrphhxrcmm.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Aquí está la arquitectura AC-BLSTM.  La conclusión es que si la división inferior en dos partes, además de la atención, es un tirón inteligente, pero en paralelo todavía es normal, y todo esto se concreta.  También buenos resultados. <br><br><img src="https://habrastorage.org/webt/tw/qa/-c/twqa-cw8om3ingxliha5wrf3brg.jpeg" width="700"><br><br>  Y Atanas su zoológico completo de modelos, entonces fue una mezcla genial.  Además de los modelos en sí, agregué algunas características de texto, generalmente la longitud, la cantidad de letras mayúsculas, la cantidad de palabras malas, la cantidad de caracteres, todo lo demás.  Validación cruzada de cinco pliegues, y obtuve excelentes resultados en LB privado 0.9867. <br><br><img src="https://habrastorage.org/webt/jk/m-/ev/jkm-evezbsayfconwk3cc1uke2s.jpeg" width="700"><br><h5>  <sub><sup><a href="">Enlace</a></sup></sub> </h5><br>  Y el segundo enfoque, enseñó con una inserción diferente, pero los resultados fueron peores.  Casi todos usaban fastText. <br><br>  Quería hablar sobre el enfoque de nuestro otro colega, Andrei, con el sobrenombre de Laol en ODS.  Enseñó muchos granos públicos, los bebió como si estuviera fuera de sí mismo, y esto realmente arrojó resultados muy buenos.  No podría hacer todo esto, pero solo tome un montón de núcleos públicos diferentes, incluso en tf-idf, hay todo tipo de convolucionistas gru. <br><br><img src="https://habrastorage.org/webt/re/gq/cg/regqcgtzm_teedu_brcisgw2hkw.jpeg" width="700"><br><h5>  <sub><sup><a href="">Enlace</a></sup></sub> </h5><br>  Tuvo uno de los mejores enfoques, con los que nos quedamos durante mucho tiempo en el top 15, hasta que Alexey y Atanas se unieron a nosotros, combinó la combinación y el apilamiento de todo esto.  Y también un momento genial, que, según tengo entendido, que ninguno de los equipos utilizó, también hicimos funciones a partir de los resultados de la API de los organizadores.  Sobre esto, dile a Alex. <br><br>  Alexey Noskov: <br>  hola  Te contaré sobre el enfoque que utilicé y cómo lo completamos. <br><br><img src="https://habrastorage.org/webt/st/ol/im/stolimynmwutbmyfpce9qgmcvjg.jpeg" width="700"><br><br>  Todo fue lo suficientemente simple para mí: 10 pliegues de validación cruzada, modelos pre-entrenados en diferentes vectores con diferentes preprocesamientos, para que tuvieran más diversidad en el conjunto, un pequeño aumento y dos ciclos de desarrollo.  El primero, que básicamente funcionó al principio, entrenó a un cierto número de modelos, analizó los errores de validación cruzada, en qué ejemplos comete errores obvios y corrigió el preprocesamiento basado en esto, porque es más claro cómo solucionarlos. <br><br>  Y el segundo enfoque, que se usó más al final, enseñó algunos conjuntos de modelos, examinó las correlaciones, encontró bloques de modelos que están débilmente correlacionados entre sí, fortaleció la parte que consiste en ellos.  Esta es la matriz de correlación de validación cruzada entre mis modelos. <br><br><img src="https://habrastorage.org/webt/lu/e2/ul/lue2ullofbhfzn1v1x0zk92wam4.jpeg" width="700"><br><br>  Se puede ver que tiene una estructura de bloques en algunos lugares, mientras que algunos modelos eran de buena calidad, estaban débilmente correlacionados con los demás, y se obtuvieron muy buenos resultados cuando tomé estos modelos como base, les enseñé varias variaciones diferentes que difieren en diferentes hiperparámetros o preprocesamiento, y luego se agregan al conjunto. <br><br><img src="https://habrastorage.org/webt/r_/m3/5l/r_m35le0i7o8cujs5osoyq8t9h4.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Para aumentar, la idea que fue publicada en el foro por Pavel Ostyakov fue la que más despertó.  Consistió en el hecho de que podemos tomar un comentario, traducirlo a otro idioma y luego volver.  Como resultado de la doble traducción, se obtiene una reformulación, algo se pierde un poco, pero en general se obtiene un texto similar ligeramente diferente, que también se puede clasificar y, por lo tanto, ampliar el conjunto de datos. <br><br>  Y el segundo enfoque, que no ayudó tanto, pero también ayudó, es que puede intentar tomar dos comentarios arbitrarios, generalmente no muy largos, pegarlos y tomar como una etiqueta en el objetivo una combinación de etiquetas o un poco de entusiasmo donde solo hay uno de contenían una etiqueta. <br><br>  Ambos enfoques funcionaron bien si no se aplicaron de antemano a todo el conjunto de conjuntos, sino para cambiar el conjunto de ejemplos a los que se debe aplicar el aumento en cada era.  Cada era en el proceso de formar un lote, elegimos, digamos, el 30% de los ejemplos que se ejecutan a través de traducciones.  Más bien, de antemano, en algún lugar paralelo yace en la memoria, simplemente seleccionamos la versión para la traducción basada en ella y la agregamos al lote durante su entrenamiento. <br><br><img src="https://habrastorage.org/webt/gp/84/92/gp8492suelagjk9stcprkcgdi_y.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Primer enlace</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">segundo enlace</a></sup></sub> </h5><br>  Una diferencia interesante fueron los modelos entrenados en BPE.  Hay una SentencePiece, un tokenizador de Google que le permite dividirse en tokens en los que no habrá UNK en absoluto.  Un diccionario limitado en el que cualquier cadena se divide en algunos tokens.  Si el número de palabras en el texto real es mayor que el tamaño objetivo del diccionario, comienzan a dividirse en pedazos más pequeños, y se obtiene un enfoque intermedio entre el nivel de caracteres y los modelos de nivel de palabra. <br><br>  Allí se utilizan dos algoritmos de construcción principales: BPE y Unigram.  Para el algoritmo BPE, fue bastante fácil encontrar incrustaciones premarcadas en la red, y con un vocabulario fijo, solo tenía un buen vocabulario de 50k, también podía entrenar modelos que dieron bastante bien (inaudible, aprox. Ed.), Un poco peor, de lo habitual en fastText, pero se correlacionaron muy débilmente con todos los demás y dieron un buen impulso. <br><br><img src="https://habrastorage.org/webt/ny/et/hs/nyeths5qlmvbeegudjhpi3jgrpy.jpeg" width="700"><br><br>  Este es un esquema de apilamiento clásico.  Como regla general, durante la mayor parte de la competencia, antes de combinar, solía mezclar simplemente todos mis modelos sin pesas.  Esto dio los mejores resultados.  Pero después de la fusión, pude obtener un esquema un poco más complejo, que al final dio un buen impulso. <br><br><img src="https://habrastorage.org/webt/zg/vu/th/zgvuthkjtwku6kiaaexiagevq7s.jpeg" width="700"><br><br>  Tenía una gran cantidad de modelos.  ¿Solo tirarlos a todos en algún tipo de apilador?  No volvió a funcionar muy bien, volvió a entrenar, pero dado que los modelos eran grupos que estaban muy correlacionados, simplemente los uní en estos grupos, dentro de cada grupo promedié y recibí 5-7 grupos de modelos muy similares, de los cuales como características para El siguiente nivel utilizó valores promediados.  Entrené a LightGBM en esto, probé 20 lanzamientos con varias muestras, cargué un poco de metafuncionalidad similar a lo que hizo Atanas, y al final finalmente comenzó a funcionar, dando un impulso sobre el promedio simple. <br><br><img src="https://habrastorage.org/webt/of/vg/b0/ofvgb0ucc3da92cftyrou5ngvye.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Sobre todo, agregué la API que Andrei encontró y que contiene un conjunto similar de etiquetas.  Los organizadores construyeron modelos para ellos inicialmente.  Como originalmente era diferente, los participantes no lo usaron, era imposible simplemente compararlo con los que necesitábamos predecir.  Pero si se lanzó a un apilamiento que funciona bien como una meta-característica, entonces daría un impulso maravilloso, especialmente en la clase TOXIC, que, aparentemente, fue la más difícil en la tabla de clasificación, y nos permitió saltar a varios lugares al final, literalmente el último día. . <br><br><img src="https://habrastorage.org/webt/g-/ip/8f/g-ip8f1wpu7jq35ilzgcbnuphhk.jpeg" width="700"><br><br>  Dado que descubrimos que el apilamiento y la API funcionaron tan bien para nosotros, antes de las presentaciones finales, teníamos pocas dudas sobre qué tan bien se portaría a privado.  Funcionó muy sospechosamente bien, por lo que elegimos dos presentaciones de acuerdo con el siguiente principio: uno: una combinación de modelos sin una API que se recibió antes de eso, además de apilar con metafísica de la API.  Aquí resultó 0.9880 en público y 0.9874 en privado.  Aquí mis marcas son confusas. <br><br><img src="https://habrastorage.org/webt/cg/d2/4o/cgd24objdrwraciizrqugzuf8t8.jpeg" width="700"><br><br>  Y el segundo es una combinación de modelos sin API, sin usar apilamiento y sin usar LightGBM, porque existía el temor de que esto fuera algún tipo de reentrenamiento menor para el público, y podríamos volar con eso.  Sucedió, no volaron, y como resultado, con el resultado de 0.9876 en privado obtuvimos la décima posición.  Eso es todo. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es414993/">https://habr.com/ru/post/es414993/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es414979/index.html">Concepto de Bitcoin MAST</a></li>
<li><a href="../es414981/index.html">Biblioteca no escrita</a></li>
<li><a href="../es414983/index.html">Alan Kay: ¿Qué hizo que Xerox PARC fuera especial y quién todavía se parece a ellos hoy?</a></li>
<li><a href="../es414989/index.html">Satélite de desechos espaciales lanzado desde la EEI</a></li>
<li><a href="../es414991/index.html">Detección y reconocimiento de objetos de la cámara en ROS utilizando el paquete find_object_2d</a></li>
<li><a href="../es414995/index.html">Notas de aficionados, o The Tale of How the Scala FPGA Developer Configured</a></li>
<li><a href="../es414997/index.html">ML-Blitz: análisis de las tareas de la primera ronda de clasificación</a></li>
<li><a href="../es414999/index.html">Probador 3D de vigilancia y termistor</a></li>
<li><a href="../es415001/index.html">El operador del automóvil robótico Uber, que derribó a un ciclista, vio el espectáculo de Voz en el momento de la colisión.</a></li>
<li><a href="../es415003/index.html">Carga de archivos sin restricciones en Apple.com</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
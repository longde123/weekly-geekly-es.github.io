<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>游녫游낖 游꼓 游눉游 Identificaci칩n y clasificaci칩n de comentarios t칩xicos. Conferencia en Yandex 游땛 游볶 游녦游낖</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Todos los sistemas modernos de moderaci칩n utilizan crowdsourcing o aprendizaje autom치tico que ya se ha convertido en un cl치sico. En el pr칩ximo entrena...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Identificaci칩n y clasificaci칩n de comentarios t칩xicos. Conferencia en Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/414993/">  Todos los sistemas modernos de moderaci칩n utilizan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">crowdsourcing</a> o aprendizaje autom치tico que ya se ha convertido en un cl치sico.  En el pr칩ximo entrenamiento de ML en Yandex, Konstantin Kotik, Igor Galitsky y Alexey Noskov hablaron sobre su participaci칩n en el concurso para la identificaci칩n masiva de comentarios ofensivos.  La competencia se llev칩 a cabo en la plataforma Kaggle. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3mL9iP8g3fA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - Hola a todos!  Mi nombre es Konstantin Kotik, soy cient칤fico de datos en la compa침칤a Button of Life, estudiante del departamento de f칤sica y de la Escuela de Graduados de Negocios de la Universidad Estatal de Mosc칰. <br><a name="habracut"></a><br>  Hoy, nuestros colegas, Igor Galitsky y Alexei Noskov, le informar치n sobre la competencia del Desaf칤o de clasificaci칩n de comentarios t칩xicos, en la que nuestro equipo DecisionGuys ocup칩 el d칠cimo lugar entre 4551 equipos. <br><br>  Una discusi칩n en l칤nea de temas que nos importan puede ser dif칤cil.  Los insultos, la agresi칩n y el acoso que ocurren en l칤nea a menudo obligan a muchas personas a abandonar la b칰squeda de varias opiniones apropiadas sobre temas que les interesan, a negarse a expresarse. <br><br>  Muchas plataformas luchan por comunicarse efectivamente en l칤nea, pero esto a menudo lleva a muchas comunidades a simplemente cerrar los comentarios de los usuarios. <br><br>  Un equipo de investigaci칩n de Google y otra compa침칤a est치n trabajando en herramientas para ayudar a mejorar la discusi칩n en l칤nea. <br><br>  Uno de los trucos en los que se centran es explorar comportamientos negativos en l칤nea, como comentarios t칩xicos.  Estos son comentarios que pueden ser ofensivos, irrespetuosos o simplemente obligar al usuario a abandonar la discusi칩n. <br><br><img src="https://habrastorage.org/webt/y2/o4/oz/y2o4ozi061ri0lyir_c9szxsmko.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Hasta la fecha, este grupo ha desarrollado una API p칰blica que puede determinar el grado de toxicidad de un comentario, pero sus modelos actuales a칰n cometen errores.  Y en esta competencia, nosotros, los Kegglers, fuimos desafiados a construir un modelo que fuera capaz de identificar comentarios que contengan amenazas, odio, insultos y similares.  E idealmente, este modelo deb칤a ser mejor que el modelo actual para su API. <br><br>  Tenemos la tarea del procesamiento de texto: identificar y luego clasificar los comentarios.  Como ejemplos de entrenamiento y prueba, se proporcionaron comentarios de las p치ginas de discusi칩n de Wikipedia.  Hubo alrededor de 160 mil comentarios en el tren, 154 mil en la prueba. <br><br><img src="https://habrastorage.org/webt/u5/ys/we/u5yswe0_sb618cfq9rlilpykuke.jpeg" width="700"><br><br>  La muestra de entrenamiento se marc칩 de la siguiente manera.  Cada comentario tiene seis etiquetas.  Las etiquetas toman el valor 1 si el comentario contiene este tipo de toxicidad, 0 de lo contrario.  Y puede ser que todas las etiquetas sean cero, un caso de comentario adecuado.  O puede ser que un comentario contenga varios tipos de toxicidad, inmediatamente una amenaza y obscenidad. <br><br>  Debido al hecho de que estamos en el aire, no puedo demostrar ejemplos espec칤ficos de estas clases.  Con respecto a la muestra de prueba, para cada comentario fue necesario predecir la probabilidad de cada tipo de toxicidad. <br><br>  La m칠trica de calidad es el AUC ROC promediado sobre los tipos de toxicidad, es decir, la media aritm칠tica del AUC ROC para cada clase por separado. <br><br><img src="https://habrastorage.org/webt/17/cm/gk/17cmgklewbzg00esfhzii641og4.jpeg" width="700"><br><br>  Aqu칤 est치 la distribuci칩n de objetos por clases en el conjunto de entrenamiento.  Se puede ver que los datos est치n muy desequilibrados.  Debo decir de inmediato que nuestro equipo calific칩 en una muestra de m칠todos para trabajar con datos desequilibrados, por ejemplo, sobremuestreo o submuestreo. <br><br><img src="https://habrastorage.org/webt/og/t6/gy/ogt6gyfkpmslose73rrxl4v_7ci.jpeg" width="700"><br><br>  Cuando constru칤 el modelo, utilic칠 un preprocesamiento de datos en dos etapas.  La primera etapa es el preprocesamiento b치sico de los datos, estas son las transformaciones de la vista en la diapositiva, esto est치 llevando el texto a min칰sculas, eliminando enlaces, direcciones IP, n칰meros y signos de puntuaci칩n. <br><br><img src="https://habrastorage.org/webt/xb/5v/kq/xb5vkq8juiimjekysw3e0we4vgq.jpeg" width="700"><br><br>  Para todos los modelos, se utiliz칩 este preprocesamiento de datos b치sico.  En la segunda etapa, se llev칩 a cabo un preprocesamiento parcial de los datos, reemplazando los emoticones con las palabras correspondientes, descifrando abreviaturas, corrigiendo errores tipogr치ficos, llevando los diferentes tipos de tapetes a la misma forma y tambi칠n eliminando im치genes.  En algunos comentarios, se indicaron enlaces a im치genes, simplemente los eliminamos. <br><br>  Para cada uno de los modelos, se utiliz칩 el preprocesamiento parcial de datos y sus diversos elementos.  Todo esto se hizo para que los modelos base redujeran la correlaci칩n cruzada entre los modelos base al construir una composici칩n adicional. <br>  Pasemos a la parte m치s interesante: construir un modelo. <br><br>  Inmediatamente abandon칠 el enfoque cl치sico de la bolsa de palabras.  Debido al hecho de que en este enfoque cada palabra es un atributo separado.  Este enfoque no tiene en cuenta el orden general de las palabras; se supone que las palabras son independientes.  En este enfoque, la generaci칩n del texto ocurre de modo que haya cierta distribuci칩n en las palabras, una palabra se selecciona aleatoriamente de esta distribuci칩n y se inserta en el texto. <br><br>  Por supuesto, hay procesos generativos m치s complejos, pero la esencia no cambia: este enfoque no tiene en cuenta el orden general de las palabras.  Puede ir a engramas, pero solo se tendr치 en cuenta el orden de las palabras en la ventana, y no en general.  Por lo tanto, tambi칠n entend칤 a mis compa침eros de equipo que necesitaban usar algo m치s inteligente. <br><br><img src="https://habrastorage.org/webt/7q/1q/2v/7q1q2v5h2q8c8ngog4foqvsabbm.jpeg" width="700"><br><h5>  <sub><sup><a href="">Enlace</a></sup></sub> </h5><br>  Lo primero que se me ocurri칩 fue usar una representaci칩n vectorial con Doc2vec.  Este es Word2vec m치s un vector que tiene en cuenta la unicidad de un documento en particular.  En el art칤culo original, este vector se llama como el p치rrafo id. <br><br>  Luego, de acuerdo con dicha representaci칩n vectorial, se estudi칩 la regresi칩n log칤stica, donde cada documento estaba representado por un vector de 10.000 dimensiones.  La evaluaci칩n de calidad se realiz칩 en una validaci칩n cruzada de diez pliegues, se estratific칩 y es importante tener en cuenta que la regresi칩n log칤stica se estudi칩 para cada clase, seis problemas de clasificaci칩n se resolvieron por separado.  Y al final, el resultado fue una distribuci칩n de probabilidad por clase. <br><br>  La regresi칩n log칤stica ha sido entrenada durante mucho tiempo.  Generalmente no encajaba en la RAM.  En las instalaciones de Igor, pasaron un d칤a en alg칰n lugar para obtener el resultado, como en una diapositiva.  Por esta raz칩n, de inmediato nos negamos a usar Doc2vec debido a las altas expectativas, aunque podr칤a mejorarse en 1000 si se hiciera un comentario con preprocesamiento de datos adicional. <br><br><img src="https://habrastorage.org/webt/kt/0i/ks/kt0iksctnlf6kobgk1e0xnkomee.jpeg" width="700"><br><br>  Los m치s inteligentes que nosotros y los otros competidores usamos fueron redes neuronales recurrentes.  Reciben secuencialmente palabras en la entrada, actualizando su estado oculto despu칠s de cada palabra.  Igor y yo usamos la red recurrente GRU para la incorporaci칩n de palabras en fastText, que es especial porque resuelve muchos problemas de clasificaci칩n binaria independientes.  Predecir la presencia o ausencia de la palabra de contexto de forma independiente. <br><br>  Tambi칠n realizamos una evaluaci칩n de calidad en la validaci칩n cruzada de diez pliegues, no se estratific칩 aqu칤, y aqu칤 la distribuci칩n de probabilidad se obtuvo inmediatamente por clase.  Cada problema de clasificaci칩n binaria no se resolvi칩 por separado, pero se gener칩 inmediatamente un vector de seis dimensiones.  Fue nuestro uno de los mejores modelos individuales. <br><br>  Usted pregunta, 쯖u치l fue el secreto del 칠xito? <br><br><img src="https://habrastorage.org/webt/aq/ik/nm/aqiknmpv8txoen1uollbhmy3iz8.jpeg" width="700"><br><br>  Consist칤a en mezclar, hab칤a mucho, con apilamiento y redes en el enfoque.  El enfoque de redes debe representarse como un gr치fico dirigido. <br><br><img src="https://habrastorage.org/webt/uj/hl/9r/ujhl9rp1pse-y-0euvxutavnrpa.jpeg" width="700"><br><br>  Al comienzo de la competencia, el equipo de DecisionGuys estaba formado por dos personas.  Luego, Pavel Pleskov, en el canal ODS Slack, expres칩 el deseo de querer formar un equipo con alguien del top 200.  En ese momento est치bamos en alg칰n lugar en el lugar 157, y Pavel Pleskov en el lugar 154, en alg칰n lugar del vecindario.  Igor not칩 su deseo de unirse, y lo invit칠 al equipo.  Entonces Andrey Litvinov se uni칩 a nosotros, luego Pavel invit칩 al Gran Maestro Alexei Noskov a nuestro equipo.  Igor - Eugene.  Y el 칰ltimo socio de nuestro equipo fue el b칰lgaro Atanas Atanasov, y este fue el resultado de un conjunto internacional humano. <br><br>  Ahora Igor Galitsky contar치 c칩mo ense침칩 gru, con m치s detalle hablar치 sobre las ideas y enfoques de Pavel Pleskov, Andrei Litvinov y Atanas Atanasov. <br><br>  Igor Galitsky: <br>  - Soy cient칤fico de datos en Epoch8, y hablar칠 sobre la mayor칤a de las arquitecturas que utilizamos. <br><br><img src="https://habrastorage.org/webt/l1/ah/jz/l1ahjzsk3hgrivbmffam4eb_9vy.jpeg" width="700"><br><br>  Todo comenz칩 con el gru침ido didireccional est치ndar con dos capas, casi todos los equipos lo usaron, y fastText, la funci칩n de activaci칩n EL, se us칩 como incrustaci칩n. <br><br>  No hay nada especial que decir, arquitectura simple, sin lujos.  쯇or qu칠 nos dio tan buenos resultados con los que nos mantuvimos en el top 150 durante bastante tiempo?  Tuvimos un buen preprocesamiento del texto.  Era necesario seguir adelante. <br><br><img src="https://habrastorage.org/webt/ni/ny/dx/ninydx6a2wsofsa-qdqncx904ou.jpeg" width="700"><br><br>  Paul tuvo su propio enfoque.  Despu칠s de mezclarse con la nuestra, esto dio un aumento significativo.  Antes de eso, ten칤amos una mezcla de gru y modelo en Doc2vec, dio 61 LB. <br><br><img src="https://habrastorage.org/webt/hq/uk/lg/hquklgojqvgbhidth4gqgv5lctg.jpeg" width="700"><br><br>  Te contar칠 sobre los enfoques de Atanas Atanasov, 칠l es directamente un entusiasta de cualquier art칤culo nuevo.  Aqu칤 est치 gru con atenci칩n, todos los par치metros en la diapositiva.  Ten칤a muchos enfoques realmente geniales, pero hasta el 칰ltimo momento us칩 su preprocesamiento y todas las ganancias se nivelaron.  Velocidad en el tobog치n. <br><br><img src="https://habrastorage.org/webt/1f/3w/_h/1f3w_hiemppymuwtyvt4xjd04so.jpeg" width="700"><br><br>  Luego hubo una atenci칩n jer치rquica, mostr칩 resultados a칰n peores, ya que inicialmente era una red para clasificar documentos que constaban de oraciones.  Lo jodi칩, pero el enfoque no es muy. <br><br><img src="https://habrastorage.org/webt/dp/pn/su/dppnsuijdyfefmos-rmpecohrsu.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Hubo un enfoque interesante, inicialmente podemos obtener caracter칤sticas de la oferta desde el principio y desde el final.  Con la ayuda de convoluci칩n, capas convolucionales, obtenemos entidades por separado a la izquierda y a la derecha del 치rbol.  Esto es desde el principio y el final de la oraci칩n, luego se fusionan y nuevamente pasan por gru. <br><br><img src="https://habrastorage.org/webt/j7/gp/vr/j7gpvrmt3s3tf04qidvcfobmzvs.jpeg" width="700"><br><br>  Tambi칠n Bi-GRU con bloque de atenci칩n.  Este es uno de los mejores en privado fue una red bastante profunda, mostr칩 buenos resultados. <br><br><img src="https://habrastorage.org/webt/d9/tw/_v/d9tw_v7n_nkvuxnxctppb2lvbyo.jpeg" width="700"><br><br>  El siguiente enfoque es resaltar las caracter칤sticas tanto como sea posible.  Despu칠s de la capa de la red recurrente, hacemos tres capas paralelas m치s de convoluci칩n.  Y aqu칤 tomamos oraciones no tan largas, las redujimos a 250, pero debido a tres convoluciones esto dio un buen resultado. <br><br><img src="https://habrastorage.org/webt/ft/hq/xy/fthqxy5pglwimem_-h46ieewheq.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Fue la red m치s profunda.  Como dijo Atanas, solo quer칤a ense침ar algo grande e interesante.  Una cuadr칤cula convolucional ordinaria que aprendi칩 de las caracter칤sticas del texto, los resultados no son nada especial. <br><br><img src="https://habrastorage.org/webt/pq/d6/eh/pqd6eh0_hxzqvb6hkwkjzkyws1u.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Este es un enfoque nuevo bastante interesante, en 2017 hubo un art칤culo sobre este tema, se us칩 para ImageNet y all칤 nos permiti칩 mejorar el resultado anterior en un 25%.  Su caracter칤stica principal es que se lanza una peque침a capa paralela al bloque convolucional, que ense침a los pesos para cada convoluci칩n en este bloque.  Ella dio un enfoque muy bueno, a pesar de cortar las oraciones. <br><br>  El problema es que la longitud m치xima de las oraciones en estas tareas alcanz칩 las 1.500 palabras, hubo comentarios muy grandes.  Otros equipos tambi칠n pensaron en c칩mo aprovechar esta gran oferta, c칩mo encontrarla, porque no todo est치 muy presionado.  Y muchos dijeron que al final de la oraci칩n hab칤a un infante muy importante.  Desafortunadamente, en todos estos enfoques, esto no se tuvo en cuenta, porque se tom칩 el comienzo.  Quiz치s esto dar칤a un aumento adicional. <br><br><img src="https://habrastorage.org/webt/mn/aq/om/mnaqomuiugd3p8_bpnrphhxrcmm.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Aqu칤 est치 la arquitectura AC-BLSTM.  La conclusi칩n es que si la divisi칩n inferior en dos partes, adem치s de la atenci칩n, es un tir칩n inteligente, pero en paralelo todav칤a es normal, y todo esto se concreta.  Tambi칠n buenos resultados. <br><br><img src="https://habrastorage.org/webt/tw/qa/-c/twqa-cw8om3ingxliha5wrf3brg.jpeg" width="700"><br><br>  Y Atanas su zool칩gico completo de modelos, entonces fue una mezcla genial.  Adem치s de los modelos en s칤, agregu칠 algunas caracter칤sticas de texto, generalmente la longitud, la cantidad de letras may칰sculas, la cantidad de palabras malas, la cantidad de caracteres, todo lo dem치s.  Validaci칩n cruzada de cinco pliegues, y obtuve excelentes resultados en LB privado 0.9867. <br><br><img src="https://habrastorage.org/webt/jk/m-/ev/jkm-evezbsayfconwk3cc1uke2s.jpeg" width="700"><br><h5>  <sub><sup><a href="">Enlace</a></sup></sub> </h5><br>  Y el segundo enfoque, ense침칩 con una inserci칩n diferente, pero los resultados fueron peores.  Casi todos usaban fastText. <br><br>  Quer칤a hablar sobre el enfoque de nuestro otro colega, Andrei, con el sobrenombre de Laol en ODS.  Ense침칩 muchos granos p칰blicos, los bebi칩 como si estuviera fuera de s칤 mismo, y esto realmente arroj칩 resultados muy buenos.  No podr칤a hacer todo esto, pero solo tome un mont칩n de n칰cleos p칰blicos diferentes, incluso en tf-idf, hay todo tipo de convolucionistas gru. <br><br><img src="https://habrastorage.org/webt/re/gq/cg/regqcgtzm_teedu_brcisgw2hkw.jpeg" width="700"><br><h5>  <sub><sup><a href="">Enlace</a></sup></sub> </h5><br>  Tuvo uno de los mejores enfoques, con los que nos quedamos durante mucho tiempo en el top 15, hasta que Alexey y Atanas se unieron a nosotros, combin칩 la combinaci칩n y el apilamiento de todo esto.  Y tambi칠n un momento genial, que, seg칰n tengo entendido, que ninguno de los equipos utiliz칩, tambi칠n hicimos funciones a partir de los resultados de la API de los organizadores.  Sobre esto, dile a Alex. <br><br>  Alexey Noskov: <br>  hola  Te contar칠 sobre el enfoque que utilic칠 y c칩mo lo completamos. <br><br><img src="https://habrastorage.org/webt/st/ol/im/stolimynmwutbmyfpce9qgmcvjg.jpeg" width="700"><br><br>  Todo fue lo suficientemente simple para m칤: 10 pliegues de validaci칩n cruzada, modelos pre-entrenados en diferentes vectores con diferentes preprocesamientos, para que tuvieran m치s diversidad en el conjunto, un peque침o aumento y dos ciclos de desarrollo.  El primero, que b치sicamente funcion칩 al principio, entren칩 a un cierto n칰mero de modelos, analiz칩 los errores de validaci칩n cruzada, en qu칠 ejemplos comete errores obvios y corrigi칩 el preprocesamiento basado en esto, porque es m치s claro c칩mo solucionarlos. <br><br>  Y el segundo enfoque, que se us칩 m치s al final, ense침칩 algunos conjuntos de modelos, examin칩 las correlaciones, encontr칩 bloques de modelos que est치n d칠bilmente correlacionados entre s칤, fortaleci칩 la parte que consiste en ellos.  Esta es la matriz de correlaci칩n de validaci칩n cruzada entre mis modelos. <br><br><img src="https://habrastorage.org/webt/lu/e2/ul/lue2ullofbhfzn1v1x0zk92wam4.jpeg" width="700"><br><br>  Se puede ver que tiene una estructura de bloques en algunos lugares, mientras que algunos modelos eran de buena calidad, estaban d칠bilmente correlacionados con los dem치s, y se obtuvieron muy buenos resultados cuando tom칠 estos modelos como base, les ense침칠 varias variaciones diferentes que difieren en diferentes hiperpar치metros o preprocesamiento, y luego se agregan al conjunto. <br><br><img src="https://habrastorage.org/webt/r_/m3/5l/r_m35le0i7o8cujs5osoyq8t9h4.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Para aumentar, la idea que fue publicada en el foro por Pavel Ostyakov fue la que m치s despert칩.  Consisti칩 en el hecho de que podemos tomar un comentario, traducirlo a otro idioma y luego volver.  Como resultado de la doble traducci칩n, se obtiene una reformulaci칩n, algo se pierde un poco, pero en general se obtiene un texto similar ligeramente diferente, que tambi칠n se puede clasificar y, por lo tanto, ampliar el conjunto de datos. <br><br>  Y el segundo enfoque, que no ayud칩 tanto, pero tambi칠n ayud칩, es que puede intentar tomar dos comentarios arbitrarios, generalmente no muy largos, pegarlos y tomar como una etiqueta en el objetivo una combinaci칩n de etiquetas o un poco de entusiasmo donde solo hay uno de conten칤an una etiqueta. <br><br>  Ambos enfoques funcionaron bien si no se aplicaron de antemano a todo el conjunto de conjuntos, sino para cambiar el conjunto de ejemplos a los que se debe aplicar el aumento en cada era.  Cada era en el proceso de formar un lote, elegimos, digamos, el 30% de los ejemplos que se ejecutan a trav칠s de traducciones.  M치s bien, de antemano, en alg칰n lugar paralelo yace en la memoria, simplemente seleccionamos la versi칩n para la traducci칩n basada en ella y la agregamos al lote durante su entrenamiento. <br><br><img src="https://habrastorage.org/webt/gp/84/92/gp8492suelagjk9stcprkcgdi_y.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Primer enlace</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">segundo enlace</a></sup></sub> </h5><br>  Una diferencia interesante fueron los modelos entrenados en BPE.  Hay una SentencePiece, un tokenizador de Google que le permite dividirse en tokens en los que no habr치 UNK en absoluto.  Un diccionario limitado en el que cualquier cadena se divide en algunos tokens.  Si el n칰mero de palabras en el texto real es mayor que el tama침o objetivo del diccionario, comienzan a dividirse en pedazos m치s peque침os, y se obtiene un enfoque intermedio entre el nivel de caracteres y los modelos de nivel de palabra. <br><br>  All칤 se utilizan dos algoritmos de construcci칩n principales: BPE y Unigram.  Para el algoritmo BPE, fue bastante f치cil encontrar incrustaciones premarcadas en la red, y con un vocabulario fijo, solo ten칤a un buen vocabulario de 50k, tambi칠n pod칤a entrenar modelos que dieron bastante bien (inaudible, aprox. Ed.), Un poco peor, de lo habitual en fastText, pero se correlacionaron muy d칠bilmente con todos los dem치s y dieron un buen impulso. <br><br><img src="https://habrastorage.org/webt/ny/et/hs/nyeths5qlmvbeegudjhpi3jgrpy.jpeg" width="700"><br><br>  Este es un esquema de apilamiento cl치sico.  Como regla general, durante la mayor parte de la competencia, antes de combinar, sol칤a mezclar simplemente todos mis modelos sin pesas.  Esto dio los mejores resultados.  Pero despu칠s de la fusi칩n, pude obtener un esquema un poco m치s complejo, que al final dio un buen impulso. <br><br><img src="https://habrastorage.org/webt/zg/vu/th/zgvuthkjtwku6kiaaexiagevq7s.jpeg" width="700"><br><br>  Ten칤a una gran cantidad de modelos.  쯉olo tirarlos a todos en alg칰n tipo de apilador?  No volvi칩 a funcionar muy bien, volvi칩 a entrenar, pero dado que los modelos eran grupos que estaban muy correlacionados, simplemente los un칤 en estos grupos, dentro de cada grupo promedi칠 y recib칤 5-7 grupos de modelos muy similares, de los cuales como caracter칤sticas para El siguiente nivel utiliz칩 valores promediados.  Entren칠 a LightGBM en esto, prob칠 20 lanzamientos con varias muestras, cargu칠 un poco de metafuncionalidad similar a lo que hizo Atanas, y al final finalmente comenz칩 a funcionar, dando un impulso sobre el promedio simple. <br><br><img src="https://habrastorage.org/webt/of/vg/b0/ofvgb0ucc3da92cftyrou5ngvye.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a></sup></sub> </h5><br>  Sobre todo, agregu칠 la API que Andrei encontr칩 y que contiene un conjunto similar de etiquetas.  Los organizadores construyeron modelos para ellos inicialmente.  Como originalmente era diferente, los participantes no lo usaron, era imposible simplemente compararlo con los que necesit치bamos predecir.  Pero si se lanz칩 a un apilamiento que funciona bien como una meta-caracter칤stica, entonces dar칤a un impulso maravilloso, especialmente en la clase TOXIC, que, aparentemente, fue la m치s dif칤cil en la tabla de clasificaci칩n, y nos permiti칩 saltar a varios lugares al final, literalmente el 칰ltimo d칤a. . <br><br><img src="https://habrastorage.org/webt/g-/ip/8f/g-ip8f1wpu7jq35ilzgcbnuphhk.jpeg" width="700"><br><br>  Dado que descubrimos que el apilamiento y la API funcionaron tan bien para nosotros, antes de las presentaciones finales, ten칤amos pocas dudas sobre qu칠 tan bien se portar칤a a privado.  Funcion칩 muy sospechosamente bien, por lo que elegimos dos presentaciones de acuerdo con el siguiente principio: uno: una combinaci칩n de modelos sin una API que se recibi칩 antes de eso, adem치s de apilar con metaf칤sica de la API.  Aqu칤 result칩 0.9880 en p칰blico y 0.9874 en privado.  Aqu칤 mis marcas son confusas. <br><br><img src="https://habrastorage.org/webt/cg/d2/4o/cgd24objdrwraciizrqugzuf8t8.jpeg" width="700"><br><br>  Y el segundo es una combinaci칩n de modelos sin API, sin usar apilamiento y sin usar LightGBM, porque exist칤a el temor de que esto fuera alg칰n tipo de reentrenamiento menor para el p칰blico, y podr칤amos volar con eso.  Sucedi칩, no volaron, y como resultado, con el resultado de 0.9876 en privado obtuvimos la d칠cima posici칩n.  Eso es todo. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es414993/">https://habr.com/ru/post/es414993/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es414979/index.html">Concepto de Bitcoin MAST</a></li>
<li><a href="../es414981/index.html">Biblioteca no escrita</a></li>
<li><a href="../es414983/index.html">Alan Kay: 쯈u칠 hizo que Xerox PARC fuera especial y qui칠n todav칤a se parece a ellos hoy?</a></li>
<li><a href="../es414989/index.html">Sat칠lite de desechos espaciales lanzado desde la EEI</a></li>
<li><a href="../es414991/index.html">Detecci칩n y reconocimiento de objetos de la c치mara en ROS utilizando el paquete find_object_2d</a></li>
<li><a href="../es414995/index.html">Notas de aficionados, o The Tale of How the Scala FPGA Developer Configured</a></li>
<li><a href="../es414997/index.html">ML-Blitz: an치lisis de las tareas de la primera ronda de clasificaci칩n</a></li>
<li><a href="../es414999/index.html">Probador 3D de vigilancia y termistor</a></li>
<li><a href="../es415001/index.html">El operador del autom칩vil rob칩tico Uber, que derrib칩 a un ciclista, vio el espect치culo de Voz en el momento de la colisi칩n.</a></li>
<li><a href="../es415003/index.html">Carga de archivos sin restricciones en Apple.com</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🥜 🎗️ 🤰 Recherche à 1 To / s ⚽️ 🧚🏻 👨🏻‍💼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="TL; DR: Il y a quatre ans, j'ai quitté Google avec l'idée d'un nouvel outil de surveillance des serveurs. L'idée était de combiner les fonctions habit...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Recherche à 1 To / s</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/445456/"> TL; DR: Il y a quatre ans, j'ai quitté Google avec l'idée d'un nouvel outil de surveillance des serveurs.  L'idée était de combiner les fonctions habituellement isolées de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">collecte</a> et d'analyse de journaux, de collecte de métriques, d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">alertes</a> et d'un tableau de bord en un seul service.  L'un des principes - le service doit être très <i>rapide</i> , offrant aux développeurs un travail facile, interactif et agréable.  Cela nécessite de traiter des ensembles de données de plusieurs gigaoctets en une fraction de seconde, sans dépasser le budget.  Les outils existants pour travailler avec les journaux sont souvent lents et maladroits, nous avons donc été confrontés à une bonne tâche: développer correctement un outil pour donner aux utilisateurs de nouvelles sensations du travail. <br><br>  Cet article décrit comment nous, chez Scalyr, avons résolu ce problème en appliquant les méthodes de la vieille école, l'approche par force brute, en éliminant les couches redondantes et en évitant les structures de données complexes.  Vous pouvez appliquer ces leçons à vos propres tâches d'ingénierie. <br><a name="habracut"></a><br><h1>  La force de la vieille école </h1><br>  L'analyse des journaux commence généralement par une recherche: recherchez tous les messages correspondant à un certain modèle.  Dans Scalyr, ce sont des dizaines ou des centaines de gigaoctets de journaux provenant de nombreux serveurs.  Les approches modernes impliquent généralement la construction d'une structure de données complexe optimisée pour la recherche.  Bien sûr, je l'ai vu sur Google, où ils sont assez bons dans de telles choses.  Mais nous avons opté pour une approche beaucoup plus grossière: le balayage linéaire des journaux.  Et cela a fonctionné - nous fournissons une interface de recherche d'un ordre de grandeur plus rapide que celle des concurrents (voir animation à la fin). <br><br>  L'idée clé est que les processeurs modernes sont vraiment très rapides dans des opérations simples et directes.  Ceci est facilement ignoré dans les systèmes complexes à plusieurs couches qui dépendent de la vitesse d'E / S et des opérations réseau, et de tels systèmes sont très courants aujourd'hui.  Ainsi, nous avons développé une conception qui minimise le nombre de couches et l'excès de déchets.  Avec plusieurs processeurs et serveurs en parallèle, la vitesse de recherche atteint 1 To par seconde. <br><br>  Principales conclusions de cet article: <br><br><ul><li>  La recherche approximative est une approche viable pour résoudre des problèmes réels à grande échelle. <br></li><li>  La force brute est une technique de conception, pas une libération du travail.  Comme toute technique, elle est mieux adaptée à certains problèmes qu'à d'autres et peut être mal ou bien mise en œuvre. <br></li><li>  La force brute est particulièrement bonne pour <i>des</i> performances <i>stables</i> . <br></li><li>  L'utilisation efficace de la force brute nécessite une optimisation du code et l'utilisation en temps opportun de ressources suffisantes.  Il convient si vos serveurs sont soumis à de lourdes charges de travail non utilisateur et que les opérations utilisateur restent une priorité. <br></li><li>  Les performances dépendent de la conception de l'ensemble du système, et pas seulement de l'algorithme de boucle interne. </li></ul><br>  (Cet article décrit comment rechercher des données en mémoire. Dans la plupart des cas, lorsqu'un utilisateur recherche des journaux, les serveurs Scalyr les ont déjà mis en cache. Dans l'article suivant, nous discuterons de la recherche de journaux non mis en cache. Les mêmes principes s'appliquent: code efficace, méthode de force brute avec de gros calculs ressources). <br><br><h1>  Méthode de la force brute </h1><br>  Traditionnellement, une recherche dans un grand ensemble de données se fait à l'aide d'un index de mots clés.  Telle qu'appliquée aux journaux du serveur, cela signifie rechercher chaque mot unique dans le journal.  Pour chaque mot, vous devez faire une liste de toutes les inclusions.  Cela facilite la recherche de tous les messages avec ce mot, par exemple, "erreur", "firefox" ou "transaction_16851951" - il suffit de regarder dans l'index. <br><br>  J'ai utilisé cette approche sur Google et cela a bien fonctionné.  Mais dans Scalyr, nous regardons dans les journaux octet par octet. <br><br>  Pourquoi?  D'un point de vue algorithmique abstrait, les index de mots-clés sont beaucoup plus efficaces qu'une recherche brute.  Cependant, nous ne vendons pas d'algorithmes, nous vendons des performances.  Et les performances ne sont pas seulement des algorithmes, mais aussi de l'ingénierie des systèmes.  Il faut tout considérer: la quantité de données, le type de recherche, le matériel disponible et le contexte logiciel.  Nous avons décidé que pour notre problème particulier, une option comme «grep» est meilleure qu'un indice. <br><br>  Les index sont excellents, mais ils ont des limites.  Un mot est facile à trouver.  Mais trouver des messages en quelques mots, comme «googlebot» et «404», est déjà beaucoup plus compliqué.  La recherche de phrases comme «exception non capturée» nécessite un index plus lourd qui enregistre non seulement tous les messages avec ce mot, mais aussi l'emplacement spécifique du mot. <br><br>  La vraie difficulté vient quand vous ne cherchez pas de mots.  Supposons que vous souhaitiez voir la quantité de trafic provenant des robots.  La première pensée est de rechercher dans les journaux le mot «bot».  Vous trouverez donc quelques bots: Googlebot, Bingbot et bien d'autres.  Mais ici, «bot» n'est pas un mot, mais en fait partie.  Si nous recherchons «bot» dans l'index, nous ne trouverons pas de messages avec le mot «Googlebot».  Si vous vérifiez chaque mot dans l'index, puis recherchez dans l'index les mots-clés trouvés, la recherche ralentira considérablement.  En conséquence, certains programmes pour travailler avec des journaux ne permettent pas de rechercher dans certaines parties d'un mot ou (au mieux) permettent d'utiliser une syntaxe spéciale avec des performances inférieures.  Nous voulons éviter cela. <br><br>  Un autre problème est la ponctuation.  Vous souhaitez trouver toutes les demandes provenant de <code>50.168.29.7</code> ?  Qu'en est-il du débogage des journaux contenant <code>[error]</code> ?  Les index sautent généralement la ponctuation. <br><br>  Enfin, les ingénieurs aiment les outils puissants, et parfois un problème ne peut être résolu qu'avec une expression régulière.  L'index des mots clés n'est pas très approprié pour cela. <br><br>  De plus, les index <i>sont complexes</i> .  Chaque message doit être ajouté à plusieurs listes de mots clés.  Ces listes doivent toujours être conservées dans un format convivial pour la recherche.  Les requêtes contenant des phrases, des fragments de mots ou des expressions régulières doivent être traduites en opérations avec plusieurs listes et les résultats analysés et combinés pour obtenir un ensemble de résultats.  Dans le cadre d'un service multi-utilisateurs à grande échelle, cette complexité crée des problèmes de performances qui ne sont pas visibles lors de l'analyse des algorithmes. <br><br>  Les index de mots-clés prennent également beaucoup d'espace et le stockage est le principal élément de coût dans le système de gestion des journaux. <br><br>  D'un autre côté, une grande puissance de calcul peut être dépensée pour chaque recherche.  Nos utilisateurs apprécient les recherches à grande vitesse pour les requêtes uniques, mais ces requêtes sont relativement rares.  Pour les requêtes de recherche typiques, par exemple, pour le tableau de bord, nous utilisons des techniques spéciales (nous les décrirons dans le prochain article).  Les autres requêtes sont assez rares, vous devez donc rarement en traiter plusieurs à la fois.  Mais cela ne signifie pas que nos serveurs ne sont pas occupés: ils sont occupés par le travail de réception, d'analyse et de compression des nouveaux messages, d'évaluation des alertes, de compression des anciennes données, etc.  Ainsi, nous avons une offre assez importante de processeurs qui peuvent être utilisés pour répondre aux demandes. <br><br><h1>  La force brute fonctionne si vous avez un problème de force brute (et beaucoup de force) </h1><br>  La force brute fonctionne mieux sur des tâches simples avec de petites boucles internes.  Souvent, vous pouvez optimiser la boucle intérieure pour travailler à des vitesses très élevées.  Si le code est complexe, il est beaucoup plus difficile de l'optimiser. <br><br>  Initialement, notre code de recherche avait une boucle interne assez grande.  Nous stockons des messages sur des pages 4K;  chaque page contient des messages (en UTF-8) et des métadonnées pour chaque message.  Les métadonnées sont une structure dans laquelle la longueur de la valeur, l'ID du message interne et d'autres champs sont codés.  La boucle de recherche ressemblait à ceci: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/700/659/eb8/700659eb85e63ee1b7493c995ed8b235.png"><br><br>  Il s'agit d'une option simplifiée par rapport au code réel.  Mais même ici, vous pouvez voir plusieurs placements d'objets, des copies de données et des appels de fonction.  La JVM optimise assez bien les appels de fonction et alloue des objets éphémères, donc ce code a mieux fonctionné que nous ne le méritions.  Pendant les tests, les clients l'ont utilisé avec succès.  Mais à la fin, nous sommes passés à un nouveau niveau. <br><br>  (Vous pouvez vous demander pourquoi nous stockons des messages dans ce format avec des pages 4K, du texte et des métadonnées, plutôt que de travailler directement avec les journaux. Il existe de nombreuses raisons pour lesquelles le moteur Scalyr interne ressemble plus à une base de données distribuée qu'à système de fichiers La recherche de texte est souvent combinée avec des filtres de style SGBD dans les champs après l'analyse des journaux. Nous pouvons rechercher plusieurs milliers de journaux en même temps, et les fichiers texte simples ne conviennent pas à notre contrôle transactionnel, répliqué et distribué  données). <br><br>  Initialement, il semblait qu'un tel code n'était pas très adapté à l'optimisation sous la méthode de la force brute.  Le «vrai travail» dans <code>String.indexOf()</code> ne dominait même pas le profil CPU.  Autrement dit, l'optimisation de cette seule méthode n'apporterait pas d'effet significatif. <br><br>  Il se trouve que nous stockons des métadonnées au début de chaque page, et le texte de tous les messages en UTF-8 est compressé à l'autre extrémité.  Profitant de cela, nous avons réécrit la boucle de recherche sur toute la page à la fois: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cc2/c88/cf3/cc2c88cf34b05cdc752c2a117fde8079.png"><br><br>  Cette version fonctionne directement sur la vue d' <code>raw byte[]</code> et recherche tous les messages à la fois sur la page 4K entière. <br><br>  C'est beaucoup plus facile à optimiser pour la force brute.  Le cycle de recherche interne est appelé simultanément pour la page 4K entière, et non séparément pour chaque message.  Il n'y a pas de copie de données, pas de sélection d'objets.  Et les opérations plus complexes avec des métadonnées sont appelées uniquement avec un résultat positif, et non pour chaque message.  Ainsi, nous avons éliminé une tonne de frais généraux et le reste de la charge est concentré dans un petit cycle de recherche interne, ce qui est bien adapté pour une optimisation supplémentaire. <br><br>  Notre algorithme de recherche actuel est basé sur la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">grande idée de Leonid Volnitsky</a> .  Il est similaire à l'algorithme de Boyer-Moore avec le saut de la longueur de la chaîne de recherche à chaque étape.  La principale différence est qu'il vérifie deux octets à la fois pour minimiser les fausses correspondances. <br><br>  Notre implémentation nécessite la création d'une table de recherche de 64 Ko pour chaque recherche, mais cela n'a aucun sens par rapport aux gigaoctets de données que nous recherchons.  La boucle interne traite plusieurs gigaoctets par seconde sur un seul cœur.  En pratique, les performances stables sont d'environ 1,25 Go par seconde sur chaque cœur, et il y a un potentiel d'amélioration.  Vous pouvez éliminer une partie de la surcharge en dehors de la boucle interne, et nous prévoyons d'expérimenter avec la boucle interne en C au lieu de Java. <br><br><h1>  Appliquer la force </h1><br>  Nous avons discuté du fait que les recherches dans les journaux peuvent être mises en œuvre «à peu près», mais de quel «pouvoir» disposons-nous?  Beaucoup. <br><br>  <b>1 cœur</b> : lorsqu'il est utilisé correctement, un cœur d'un processeur moderne est assez puissant en soi. <br><br>  <b>8 cœurs</b> : nous travaillons actuellement sur des serveurs SSD Amazon hi1.4xlarge et i2.4xlarge, chacun ayant 8 cœurs (16 threads).  Comme mentionné ci-dessus, ces noyaux sont généralement occupés par des opérations en arrière-plan.  Lorsque l'utilisateur effectue une recherche, les opérations d'arrière-plan sont interrompues, libérant les 8 cœurs pour la recherche.  La recherche se termine généralement en une fraction de seconde, après quoi le travail en arrière-plan reprend (le programme du contrôleur garantit qu'un barrage de requêtes de recherche n'interfère pas avec le travail en arrière-plan important). <br><br>  <b>16 cœurs</b> : pour plus de fiabilité, nous organisons les serveurs en groupes maître / esclave.  Chaque maître a un serveur SSD et un subordonné EBS.  Si le serveur principal tombe en panne, le serveur sur le SSD prend immédiatement sa place.  Presque tout le temps, le maître et l'esclave fonctionnent bien, donc chaque bloc de données est consultable sur deux serveurs différents (le serveur EBS esclave a un processeur faible, donc nous ne le considérons pas).  Nous répartissons la tâche entre eux, de sorte que nous avons un total de 16 cœurs disponibles. <br><br>  <b>De nombreux cœurs</b> : dans un avenir proche, nous distribuerons les données entre les serveurs afin qu'ils participent tous au traitement de chaque demande non triviale.  Chaque noyau fonctionnera.  [Remarque: <i>nous avons mis en œuvre le plan et augmenté la vitesse de recherche à 1 To / s, voir la note à la fin de l'article</i> ]. <br><br><h1>  La simplicité assure la fiabilité </h1><br>  Un autre avantage de la force brute est sa performance relativement stable.  En règle générale, la recherche n'est pas trop sensible aux détails de la tâche et de l'ensemble de données (je pense que c'est pourquoi elle est appelée "grossière"). <br><br>  L'index de mots-clés produit parfois des résultats incroyablement rapides, mais dans d'autres cas, ce n'est pas le cas.  Supposons que vous disposiez de 50 Go de journaux dans lesquels le terme «customer_5987235982» apparaît exactement trois fois.  Une recherche par ce terme compte trois emplacements directement à partir de l'index et se termine instantanément.  Mais une recherche générique complexe peut analyser des milliers de mots-clés et prendre beaucoup de temps. <br><br>  D'un autre côté, les recherches par force brute pour n'importe quelle requête sont effectuées à plus ou moins la même vitesse.  La recherche de mots longs est meilleure, mais même la recherche d'un seul caractère est assez rapide. <br><br>  La simplicité de la méthode de la force brute signifie que sa productivité est proche du maximum théorique.  Il existe moins d'options pour une surcharge de disque inattendue, un conflit de verrouillage, des poursuites de pointeur et des milliers d'autres raisons d'échecs.  Je viens de regarder les requêtes faites par les utilisateurs Scalyr la semaine dernière sur notre serveur le plus occupé.  Il y a eu 14 000 demandes.  Exactement huit d'entre eux ont pris plus d'une seconde;  99% effectué en 111 millisecondes (si vous n'avez pas utilisé les outils d'analyse de journal, croyez-moi: <i>c'est rapide</i> ). <br><br>  Des performances stables et fiables sont importantes pour la commodité d'utilisation du service.  S'il ralentit périodiquement, les utilisateurs le percevront comme peu fiable et hésiteront à l'utiliser. <br><br><h1>  Recherche de journaux en action </h1><br>  Voici une petite animation qui montre Scalyr en train de chercher en action.  Nous avons un compte de démonstration où nous importons chaque événement dans chaque référentiel Github public.  Dans cette démo, j'étudie les données de la semaine: environ 600 Mo de logs bruts. <br><br>  La vidéo a été enregistrée en direct, sans préparation particulière, sur mon bureau (à environ 5000 kilomètres du serveur).  Les performances que vous constaterez sont en grande partie dues à l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">optimisation du client web</a> , ainsi qu'au backend rapide et fiable.  Chaque fois qu'il y a une pause sans l'indicateur de «chargement», je la mets en pause pour que vous puissiez lire sur quoi je vais cliquer. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/159/bf8/c90/159bf8c9074eb627d27e7b5876e57740.gif"><br><br><h1>  En conclusion </h1><br>  Lors du traitement de grandes quantités de données, il est important de choisir un bon algorithme, mais «bon» ne signifie pas «fantaisie».  Réfléchissez à la façon dont votre code fonctionnera dans la pratique.  Certains facteurs qui peuvent être d'une grande importance dans le monde réel sortent de l'analyse théorique des algorithmes.  Les algorithmes plus simples sont plus faciles à optimiser et sont plus stables dans les situations limites. <br><br>  Pensez également au contexte dans lequel le code s'exécutera.  Dans notre cas, nous avons besoin de serveurs suffisamment puissants pour gérer les tâches d'arrière-plan.  Les utilisateurs initient relativement rarement une recherche, nous pouvons donc emprunter tout un groupe de serveurs pendant la courte période nécessaire pour terminer chaque recherche. <br><br>  En utilisant la force brute, nous avons implémenté une recherche rapide, fiable et flexible sur un ensemble de journaux.  Nous espérons que ces idées seront utiles pour vos projets. <br><br>  Modifier: le <i>titre et le texte sont passés de «Recherche à 20 Go par seconde» à «Recherche à 1 To par seconde» pour refléter l'augmentation des performances au cours des dernières années.</i>  <i>Cette augmentation de la vitesse est principalement due à un changement dans le type et le nombre de serveurs EC2 que nous élevons aujourd'hui pour servir la clientèle accrue.</i>  <i>Dans un avenir proche, des changements devraient permettre une nouvelle augmentation sensible de l'efficacité au travail, et nous attendons avec impatience l'occasion d'en parler.</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr445456/">https://habr.com/ru/post/fr445456/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr445446/index.html">Comment nous avons utilisé la réplication différée pour la reprise après sinistre avec PostgreSQL</a></li>
<li><a href="../fr445448/index.html">Configuration de la réception automatique des certificats Letsencrypt à l'aide de Docker sous Linux</a></li>
<li><a href="../fr445450/index.html">Extension de navigateur pour toster.ru</a></li>
<li><a href="../fr445452/index.html">Référentiels utiles avec Eloquent?</a></li>
<li><a href="../fr445454/index.html">Afficheur braille Raspberry Pi Zero Inside Handy Tech Active Star 40</a></li>
<li><a href="../fr445458/index.html">Electronic Arts traitera avec 350 employés et «réduira sa présence» en Russie</a></li>
<li><a href="../fr445460/index.html">Interactivité sans gadget</a></li>
<li><a href="../fr445464/index.html">Diminution de la taille de l'échantillon des données expérimentales sans perte d'informations</a></li>
<li><a href="../fr445466/index.html">Félicitations aux champions de la finale régionale Imagine Cup EMEA: Team Finderr du Royaume-Uni! L'équipe russe est troisième</a></li>
<li><a href="../fr445468/index.html">Une équipe russe a pris la troisième place de la compétition Imagine Cup en Europe, en Afrique et au Moyen-Orient</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
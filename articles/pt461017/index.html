<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéì üíß üôÖüèª Novo algoritmo de rastreamento de GPU: rastreamento de caminho do Wavefront üëµüèæ ‚ö´Ô∏è üèÆ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Neste artigo, exploramos o importante conceito usado na plataforma Lighthouse 2., lan√ßada recentemente. O rastreamento de caminho da frente de onda , ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Novo algoritmo de rastreamento de GPU: rastreamento de caminho do Wavefront</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/461017/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/_x/t8/rw/_xt8rwehj6jymumaisqg5ehgkro.png"></div><br>  Neste artigo, exploramos o importante conceito usado na plataforma Lighthouse 2., lan√ßada recentemente. O <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rastreamento de caminho da frente de onda</a> , como √© chamado Lane, Karras e Aila da NVIDIA, ou o rastreamento de caminho de streaming, como foi originalmente chamado na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tese de mestrado de</a> Van Antwerp, desempenha um papel crucial na o desenvolvimento de rastreadores de caminho eficientes na GPU e potencialmente rastreadores de caminho na CPU.  No entanto, √© bastante contra-intuitivo, portanto, para entend√™-lo, √© necess√°rio repensar os algoritmos de rastreamento de raios. <br><a name="habracut"></a><br><h2>  Ocupa√ß√£o </h2><br>  O algoritmo de rastreamento de caminho √© surpreendentemente simples e pode ser descrito em apenas algumas linhas de pseudoc√≥digo: <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">vec3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Trace</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( vec3 O, vec3 D )</span></span></span><span class="hljs-function"> IntersectionData i </span></span>= Scene::Intersect( O, D ) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (i == NoHit) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> vec3( <span class="hljs-number"><span class="hljs-number">0</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// ray left the scene if (i == Light) return i.material.color // lights do not reflect vec3 R, pdf = RandomDirectionOnHemisphere( i.normal ), 1 / 2PI return Trace( i.position, R ) * i.BRDF * dot( i.normal, R ) / pdf</span></span></code> </pre> <br>  A entrada √© o <em>raio prim√°rio que</em> passa da c√¢mera pelo pixel da tela.  Para esse feixe, determinamos a interse√ß√£o mais pr√≥xima da primitiva da cena.  Se n√£o houver interse√ß√µes, o feixe desaparecer√° no vazio.  Caso contr√°rio, se o feixe atingir a fonte de luz, encontramos o caminho da luz entre a fonte e a c√¢mera.  Se encontrarmos outra coisa, realizamos reflex√£o e recurs√£o, esperando que o feixe refletido ainda encontre a fonte de ilumina√ß√£o.  Observe que esse processo se assemelha ao caminho (de retorno) de um f√≥ton refletindo na superf√≠cie de uma cena. <br><br>  As GPUs s√£o projetadas para executar esta tarefa no modo multithread.  A princ√≠pio, pode parecer que o tra√ßado de raios √© ideal para isso.  Portanto, usamos o OpenCL ou CUDA para criar um fluxo para um pixel, cada fluxo executa um algoritmo que realmente funciona conforme o esperado e √© bastante r√°pido: basta ver alguns exemplos com o ShaderToy para entender o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">qu√£o</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">r√°pido o</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rastreamento de raios</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pode</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ser</a> na GPU.  Seja como for, a quest√£o √© diferente: esses tra√ßadores de raios s√£o realmente o <em>mais r√°pido poss√≠vel</em> ? <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ce5/61d/07d/ce561d07daa3437927ab8ad5a6744ec9.jpg"></div><br>  Este algoritmo tem um problema.  O raio prim√°rio pode encontrar a fonte de luz imediatamente, ou ap√≥s uma reflex√£o aleat√≥ria ou ap√≥s cinquenta reflex√µes.  O programador da CPU notar√° um potencial estouro de pilha aqui;  o programador da GPU deve ver <em>o problema de ocupa√ß√£o</em> .  O problema √© causado por recurs√£o condicional da cauda: o caminho pode terminar na fonte de luz ou continuar.  Vamos transferir isso para muitos threads: alguns deles ser√£o interrompidos e a outra parte continuar√° funcionando.  Ap√≥s algumas reflex√µes, teremos v√°rios threads que precisam continuar computando, e a maioria deles aguardar√° o t√©rmino do trabalho desses √∫ltimos threads.  <em>O emprego</em> √© uma medida da parte dos encadeamentos da GPU que fazem um trabalho √∫til. <br><br>  O problema de emprego se aplica ao modelo de execu√ß√£o dos dispositivos SIMT GPU.  Os fluxos s√£o organizados em grupos, por exemplo, na GPU Pascal (classe de equipamento NVidia 10xx) 32 threads s√£o combinados em um <em>warp</em> .  Os threads no warp t√™m um contador de programa comum: eles s√£o executados com uma etapa fixa; portanto, cada instru√ß√£o do programa √© executada por 32 threads simultaneamente.  SIMT significa <em>thread √∫nico de instru√ß√£o √∫nica</em> , que descreve bem o conceito.  Para um processador SIMT, um c√≥digo com condi√ß√µes √© complexo.  Isso √© mostrado claramente na documenta√ß√£o oficial de Volta: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9bb/1c0/cb0/9bb1c0cb0c4916e8a7989edeb466d3dd.jpg"></div><br>  <i>Execu√ß√£o de c√≥digo com condi√ß√µes no SIMT.</i> <br><br>  Quando uma determinada condi√ß√£o √© verdadeira para alguns threads no warp, as ramifica√ß√µes da <em>instru√ß√£o if s√£o</em> serializadas.  Uma alternativa √† abordagem "todos os threads fazem o mesmo" √© "alguns threads est√£o desativados".  No bloco if-then-else, a ocupa√ß√£o m√©dia de warp ser√° de 50%, a menos que todos os threads tenham consist√™ncia em rela√ß√£o √† condi√ß√£o. <br><br>  Infelizmente, c√≥digo com condi√ß√µes no ray tracer n√£o √© t√£o raro.  Raios de sombras s√£o emitidos somente se a fonte de luz n√£o estiver atr√°s do ponto de sombreamento, caminhos diferentes podem colidir com materiais diferentes, a integra√ß√£o com o m√©todo da roleta russa pode destruir ou deixar o caminho vivo e assim por diante.  Acontece que a ocupa√ß√£o est√° se tornando a principal fonte de inefici√™ncia, e n√£o √© t√£o f√°cil evit√°-la sem medidas de emerg√™ncia. <br><br><h2>  Rastreamento de caminho de streaming </h2><br>  O algoritmo de rastreamento do caminho de streaming foi desenvolvido para solucionar a causa raiz do problema ocupado.  O rastreamento de caminho de streaming divide o algoritmo de rastreamento de caminho em quatro etapas: <br><br><ol><li>  <strong>Gerar</strong> </li><li>  <strong>Estender</strong> </li><li>  <strong>Sombra</strong> </li><li>  <strong>Conectar</strong> </li></ol><br>  Cada est√°gio √© implementado como um programa separado.  Portanto, em vez de executar um rastreador de caminho completo como um √∫nico programa de GPU (‚Äúkernel‚Äù, kernel), teremos que trabalhar com <em>quatro</em> n√∫cleos.  Al√©m disso, como veremos em breve, eles s√£o executados em um loop. <br><br>  <b>O est√°gio 1 ("Gerar")</b> √© respons√°vel pela gera√ß√£o de raios prim√°rios.  Este √© um n√∫cleo simples que cria os pontos de partida e as dire√ß√µes dos raios em uma quantidade igual ao n√∫mero de pixels.  A sa√≠da desse est√°gio √© um grande buffer de raios e um contador que informa o est√°gio seguinte do n√∫mero de raios que precisam ser processados.  Para raios prim√°rios, esse valor √© igual √† <em>largura da tela</em> vezes a <em>altura da tela</em> . <br><br>  <strong>O est√°gio 2 ("Renovar")</strong> √© o segundo n√∫cleo.  √â executado somente ap√≥s a conclus√£o do est√°gio 1 para todos os pixels.  O kernel l√™ o buffer gerado na etapa 1 e cruza cada raio com a cena.  A sa√≠da desse est√°gio √© o resultado da interse√ß√£o para cada raio armazenado no buffer. <br><br>  <strong>O est√°gio 3 (‚ÄúSombra‚Äù)</strong> √© executado ap√≥s a conclus√£o do est√°gio 2. Ele recebe o resultado da interse√ß√£o do est√°gio 2 e calcula o modelo de sombreamento para cada caminho.  Esta opera√ß√£o pode ou n√£o gerar novos raios, dependendo se o caminho foi conclu√≠do.  Os caminhos que geram o novo raio (o caminho ‚Äúse estende‚Äù) grava o novo raio (o ‚Äúsegmento do caminho‚Äù) no buffer.  Os caminhos que amostram diretamente as fontes de luz ("amostram explicitamente a ilumina√ß√£o" ou "calculam o pr√≥ximo evento") gravam um feixe de sombra em um segundo buffer. <br><br>  <strong>O est√°gio 4 ("Conectar")</strong> rastreia os raios das sombras gerados no est√°gio 3. √â semelhante ao est√°gio 2, mas com uma diferen√ßa importante: os raios da sombra precisam encontrar <em>qualquer</em> interse√ß√£o, enquanto os raios que se estendem precisam encontrar a interse√ß√£o mais pr√≥xima.  Portanto, um n√∫cleo separado foi criado para isso. <br><br>  Depois de concluir a etapa 4, obtemos um buffer contendo raios que estendem o caminho.  Depois de capturar esses raios, prosseguimos para o est√°gio 2. Continuamos fazendo isso at√© que n√£o haja raios de extens√£o ou at√© atingirmos o n√∫mero m√°ximo de itera√ß√µes. <br><br><h2>  Fontes de inefici√™ncia </h2><br>  Um programador preocupado com o desempenho ver√° muitos momentos perigosos nesse esquema de algoritmos de rastreamento de caminho de streaming: <br><br><ul><li>  Em vez de uma √∫nica chamada do kernel, agora temos <em>tr√™s chamadas por itera√ß√£o</em> , mais um kernel de gera√ß√£o.  N√∫cleos desafiadores significam um certo aumento na carga, portanto isso √© ruim. </li><li>  Cada n√∫cleo l√™ um buffer enorme e grava um buffer enorme. </li><li>  A CPU precisa saber quantos threads gerar para cada n√∫cleo; portanto, a GPU deve informar √† CPU quantos raios foram gerados na etapa 3. Mover informa√ß√µes da GPU para a CPU √© uma m√° ideia e precisa ser feita pelo menos uma vez por itera√ß√£o. </li><li>  Como o est√°gio 3 grava os raios no buffer sem criar espa√ßos em todos os lugares?  Ele n√£o usa um contador at√¥mico para isso? </li><li>  O n√∫mero de caminhos ativos ainda est√° diminuindo. Ent√£o, como esse esquema pode ajudar? </li></ul><br>  Vamos come√ßar com a √∫ltima pergunta: se transferirmos um milh√£o de tarefas para a GPU, ela n√£o gerar√° um milh√£o de threads.  O n√∫mero real de threads executados simultaneamente depende do equipamento, mas no caso geral, dezenas de milhares de threads s√£o executados.  Somente quando a carga cair abaixo desse n√∫mero, perceberemos problemas de emprego causados ‚Äã‚Äãpor um pequeno n√∫mero de tarefas. <br><br>  Outra preocupa√ß√£o √© a E / S em grande escala de buffers.  Essa √© realmente uma dificuldade, mas n√£o t√£o s√©ria quanto voc√™ poderia esperar: o acesso aos dados √© altamente previs√≠vel, especialmente ao gravar em buffers, para que o atraso n√£o cause problemas.  De fato, as GPUs foram desenvolvidas principalmente para esse tipo de processamento de dados. <br><br>  Outro aspecto que as GPUs lidam muito bem s√£o os contadores at√¥micos, o que √© bastante inesperado para programadores que trabalham no mundo da CPU.  O buffer z requer acesso r√°pido e, portanto, a implementa√ß√£o de contadores at√¥micos nas GPUs modernas √© extremamente eficaz.  Na pr√°tica, uma opera√ß√£o de grava√ß√£o at√¥mica √© t√£o cara quanto uma grava√ß√£o n√£o armazenada em cache na mem√≥ria global.  Em muitos casos, o atraso ser√° mascarado pela execu√ß√£o paralela em larga escala na GPU. <br><br>  Duas perguntas permanecem: chamadas do kernel e transfer√™ncia de dados bidirecional para contadores.  O √∫ltimo √© realmente um problema, por isso precisamos de outra altera√ß√£o na arquitetura: <em>threads persistentes</em> . <br><br><h2>  As consequ√™ncias </h2><br>  Antes de nos aprofundarmos nos detalhes, examinaremos as implica√ß√µes do uso do algoritmo de rastreamento de caminho da frente de onda.  Primeiro, digamos sobre buffers.  Precisamos de um buffer para gerar os dados do est√°gio 1, ou seja,  raios prim√°rios.  Para cada viga precisamos: <br><br><ul><li>  Origem do raio: tr√™s valores de flutua√ß√£o, ou seja, 12 bytes </li><li>  Dire√ß√£o do raio: tr√™s valores de flutua√ß√£o, ou seja, 12 bytes </li></ul><br>  Na pr√°tica, √© melhor aumentar o tamanho do buffer.  Se voc√™ armazenar 16 bytes para o in√≠cio e a dire√ß√£o do feixe, a GPU poder√° l√™-los em uma opera√ß√£o de leitura de 128 bits.  Uma alternativa √© uma opera√ß√£o de leitura de 64 bits seguida por uma opera√ß√£o de 32 bits para obter o float3, que √© quase duas vezes mais lento.  Ou seja, para uma tela de 1920 √ó 1080, obtemos: 1920x1080x32 = ~ 64 MB.  Tamb√©m precisamos de um buffer para os resultados da interse√ß√£o criados pelo kernel Extend.  S√£o outros 128 bits por elemento, ou seja, 32 MB.  Al√©m disso, o kernel ‚ÄúShadow‚Äù pode criar extens√µes de caminho de at√© 1920 √ó 1080 (limite superior), e n√£o podemos grav√°-las no buffer do qual lemos.  Isso √© outros 64 MB.  E finalmente, se o nosso rastreador de caminho emitir raios de sombra, esse ser√° outro buffer de 64 MB.  Depois de resumir tudo, obtemos 224 MB de dados, e isso √© apenas para o algoritmo de frente de onda.  Ou cerca de 1 GB em resolu√ß√£o 4K. <br><br>  Aqui precisamos nos acostumar com outro recurso: temos bastante mem√≥ria.  Pode parecer.  esse 1 GB √© muito, e h√° maneiras de reduzir esse n√∫mero, mas se voc√™ abordar isso de forma realista, quando realmente precisarmos rastrear os caminhos em 4K, usar 1 GB em uma GPU com 8 GB ser√° o menor dos nossos problemas. <br><br>  Mais graves que os requisitos de mem√≥ria, as consequ√™ncias ser√£o para o algoritmo de renderiza√ß√£o.  At√© agora, sugeri que precisamos gerar um raio de extens√£o e, possivelmente, um raio de sombra para cada thread no n√∫cleo da sombra.  Mas e se quisermos realizar a oclus√£o ambiental usando 16 raios por pixel?  16 raios AO precisam ser armazenados no buffer, mas, pior ainda, eles aparecer√£o apenas na pr√≥xima itera√ß√£o.  Um problema semelhante surge ao rastrear raios no estilo Whited: emitir um feixe de sombra para v√°rias fontes de luz ou dividir um feixe em uma colis√£o com vidro √© quase imposs√≠vel de se perceber. <br><br>  Por outro lado, o rastreamento do caminho da frente de onda resolve os problemas listados na se√ß√£o Ocupa√ß√£o: <br><br><ul><li>  No est√°gio 1, todos os fluxos sem condi√ß√µes criam raios prim√°rios e os gravam no buffer. </li><li>  No est√°gio 2, todos os fluxos sem condi√ß√µes cruzam os raios com a cena e escrevem os resultados da interse√ß√£o no buffer. </li><li>  Na etapa 3, come√ßamos a calcular os resultados da interse√ß√£o com 100% de ocupa√ß√£o. </li><li>  Na etapa 4, processamos uma lista cont√≠nua de raios de sombra sem espa√ßos. </li></ul><br>  Quando retornamos ao est√°gio 2 com os raios sobreviventes com 2 segmentos de comprimento, novamente temos um buffer de raios compacto que garante o pleno emprego quando o kernel √© iniciado. <br><br>  Al√©m disso, h√° uma vantagem adicional que n√£o deve ser subestimada.  O c√≥digo √© isolado em quatro etapas separadas.  Cada n√∫cleo pode usar todos os recursos GPU dispon√≠veis (cache, mem√≥ria compartilhada, registros) sem levar em conta outros n√∫cleos.  Isso pode permitir que a GPU execute o c√≥digo de interse√ß√£o com a cena em mais threads, porque esse c√≥digo n√£o requer tantos registros quanto o c√≥digo de sombreador.  Quanto mais threads, melhor voc√™ pode ocultar os atrasos. <br><br>  Mascaramento de atraso aprimorado em tempo integral, grava√ß√£o de streaming: todos esses benef√≠cios est√£o diretamente relacionados ao surgimento e √† natureza da plataforma GPU.  Para a GPU, o algoritmo de rastreamento de caminho da frente de onda √© muito natural. <br><br><h2>  Vale a pena? </h2><br>  Obviamente, temos uma pergunta: o emprego otimizado justifica a E / S dos buffers e o custo de chamar n√∫cleos adicionais? <br><br>  A resposta √© sim, mas provar isso n√£o √© t√£o f√°cil. <br><br>  Se voltarmos aos rastreadores de pista com o ShaderToy por um segundo, veremos que a maioria deles usa uma cena simples e codificada.  Substitu√≠-lo por uma cena completa n√£o √© uma tarefa trivial: para milh√µes de primitivas, cruzar o feixe e a cena se torna um problema complexo, cuja solu√ß√£o costuma ser deixada para NVidia ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Optix</a> ), AMD ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Radeon-Rays</a> ) ou Intel ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Embree</a> ).  Nenhuma dessas op√ß√µes pode substituir facilmente a cena codificada no tra√ßador de raios artificial CUDA.  No CUDA, o anal√≥gico mais pr√≥ximo (Optix) requer controle sobre a execu√ß√£o do programa.  A incorpora√ß√£o na CPU permite rastrear feixes individuais a partir do seu pr√≥prio c√≥digo, mas o custo disso √© uma sobrecarga significativa de desempenho: ele prefere rastrear grandes grupos de feixes em vez de feixes individuais. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fb4/2a2/409/fb42a240924ba04871abb70421d16cdf.png"></div><br>  <i>Tela de It's About Time renderizada com Brigade 1.</i> <br><br>  O rastreamento do caminho da frente de onda ser√° mais r√°pido do que sua alternativa (o megakernel, como Lane e colegas o chamam) depende do tempo gasto nos n√∫cleos (cenas grandes e shaders caros reduzem o custo relativo excedido pelo algoritmo de frente de onda), no comprimento m√°ximo do caminho , emprego mega n√∫cleo e diferen√ßas na carga dos registros em quatro etapas.  Em uma vers√£o inicial do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Brigade Path Tracer original,</a> descobrimos que mesmo uma cena simples com uma mistura de superf√≠cies refletivas e Lambert rodando no GTX480 se beneficiava do uso da frente de onda. <br><br><h2>  Rastreamento de caminho de streaming no farol 2 </h2><br>  A plataforma Lighthouse 2 possui dois rastreadores de rastreamento de caminho de frente de onda.  O primeiro utiliza o Optix Prime para a implementa√ß√£o dos est√°gios 2 e 4 (est√°gios da interse√ß√£o de raios e cenas);  no segundo, o Optix √© usado diretamente para implementar essa funcionalidade. <br><br>  Optix Prime √© uma vers√£o simplificada do Optix que lida apenas com a interse√ß√£o de um conjunto de vigas com uma cena composta por tri√¢ngulos.  Diferente da biblioteca Optix completa, ela n√£o suporta c√≥digo de interse√ß√£o personalizado e apenas intercepta tri√¢ngulos.  No entanto, √© exatamente isso que √© necess√°rio para o rastreador de caminho da frente de onda. <br><br>  O rastreador de caminho de frente de onda baseado em Optix Prime √© implementado no <code>rendercore.cpp</code> projeto <code>rendercore.cpp</code> .  A inicializa√ß√£o do Optix Prime inicia na fun√ß√£o <code>Init</code> e usa <code>rtpContextCreate</code> .  A cena √© criada usando <code>rtpModelCreate</code> .  V√°rios buffers de raio s√£o criados na fun√ß√£o <code>rtpBufferDescCreate</code> usando <code>rtpBufferDescCreate</code> .  Observe que, para esses buffers, fornecemos os ponteiros usuais do dispositivo: isso significa que eles podem ser usados ‚Äã‚Äãno Optix e nos n√∫cleos regulares do CUDA. <br><br>  A renderiza√ß√£o come√ßa no m√©todo <code>Render</code> .  Para preencher o buffer de raios prim√°rio, <code>generateEyeRays</code> um n√∫cleo CUDA chamado <code>generateEyeRays</code> .  Depois de preencher o buffer, o Optix Prime √© chamado usando <code>rtpQueryExecute</code> .  Com isso, os resultados da interse√ß√£o s√£o gravados no <code>extensionHitBuffer</code> .  Observe que todos os buffers permanecem na GPU: com exce√ß√£o das chamadas do kernel, n√£o h√° tr√°fego entre a CPU e a GPU.  O est√°gio "Shadow" √© implementado no n√∫cleo de cores CUDA regular.  Sua implementa√ß√£o est√° no <code>pathtracer.cu</code> . <br><br>  Vale ressaltar alguns detalhes de implementa√ß√£o do <code>optixprime_b</code> .  Primeiro, os raios das sombras s√£o tra√ßados fora do ciclo da frente de onda.  Isso est√° correto: um raio de sombra afeta um pixel apenas se n√£o estiver bloqueado, mas em todos os outros casos, seu resultado n√£o √© necess√°rio em nenhum outro lugar.  Ou seja, o feixe de sombra √© <em>descart√°vel</em> , pode ser rastreado a qualquer momento e em qualquer ordem.  No nosso caso, usamos isso agrupando os raios da sombra para que o lote finalmente rastreado seja o maior poss√≠vel.  Isso tem uma conseq√º√™ncia desagrad√°vel: com <em>N</em> itera√ß√µes do algoritmo de frente de onda e <em>raios</em> prim√°rios X, o limite superior do n√∫mero de raios de sombra √© igual a <em>XN</em> . <br><br>  Outro detalhe √© o processamento de v√°rios contadores.  Os est√°gios ‚ÄúRenovar‚Äù e ‚ÄúSombra‚Äù devem saber quantos caminhos est√£o ativos.  Os contadores para isso s√£o atualizados na GPU (atomicamente), o que significa que eles s√£o usados ‚Äã‚Äãna GPU, mesmo sem retornar √† CPU.  Infelizmente, em um dos casos, isso √© imposs√≠vel: a biblioteca Optix Prime precisa saber o n√∫mero de raios rastreados.  Para fazer isso, precisamos retornar as informa√ß√µes dos contadores uma vez que uma itera√ß√£o. <br><br><h2>  Conclus√£o </h2><br>  Este artigo explica o que √© o rastreamento de caminho da frente de onda e por que √© necess√°rio executar efetivamente o rastreamento de caminho na GPU.  Sua implementa√ß√£o pr√°tica √© apresentada na plataforma Lighthouse 2, que √© de c√≥digo aberto e <a href="">dispon√≠vel no Github</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt461017/">https://habr.com/ru/post/pt461017/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt461005/index.html">Teste para a empresa: fazendo as perguntas certas na entrevista</a></li>
<li><a href="../pt461007/index.html">Introdu√ß√£o ao Analisador Est√°tico PVS-Studio para Visual C ++</a></li>
<li><a href="../pt461009/index.html">Como fazer um padr√£o em 10 dias. Parte Dois Chato</a></li>
<li><a href="../pt461013/index.html">Reservando conex√£o √† Internet</a></li>
<li><a href="../pt461015/index.html">Viva e aprenda. Parte 2. Universidade: 5 anos ou 5 corredores?</a></li>
<li><a href="../pt461019/index.html">Como √© a vida dos desenvolvedores no Ir√£</a></li>
<li><a href="../pt461027/index.html">Java REPL voc√™ n√£o ScriptEngine</a></li>
<li><a href="../pt461029/index.html">Um lago de dados de marketing - de tabelas monstruosas a relat√≥rios e visualiza√ß√µes</a></li>
<li><a href="../pt461031/index.html">Conectamos mapas on-line ao navegador no smartphone. Parte 1 - mapas rasterizados padr√£o</a></li>
<li><a href="../pt461033/index.html">De onde vem essa configura√ß√£o? [Debian / Ubuntu]</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
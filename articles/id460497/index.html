<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🍕 🏽 📚 Penggunaan intuitif metode Monte Carlo dengan rantai Markov 🔐 🖤 🌴</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Apakah itu mudah? Saya mencoba 
 Alexey Kuzmin, direktur pengembangan data dan bekerja di DomKlik, dosen Ilmu Data di Netologi, menerjemahkan sebuah a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Penggunaan intuitif metode Monte Carlo dengan rantai Markov</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/netologyru/blog/460497/"><h4>  Apakah itu mudah?  Saya mencoba </h4><br>  <i>Alexey Kuzmin, direktur pengembangan data dan bekerja di DomKlik, dosen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Ilmu Data</a> di Netologi, menerjemahkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sebuah artikel oleh</a> Rahul Agarwal tentang bagaimana metode Monte Carlo bekerja dengan rantai Markov untuk memecahkan masalah dengan ruang negara yang besar.</i> <br><a name="habracut"></a><br>  Semua orang yang terkait dengan Ilmu Data pernah mendengar metode Monte Carlo dengan rantai Markov (MCMC).  Terkadang topik tersebut disentuh ketika mempelajari statistik Bayesian, kadang-kadang ketika bekerja dengan alat-alat seperti Nabi. <br><br>  Tetapi MCMC sulit dimengerti.  Setiap kali saya membaca tentang metode ini, saya perhatikan bahwa esensi MCMC tersembunyi di lapisan dalam kebisingan matematika, dan sulit untuk melihat di balik kebisingan ini.  Saya harus menghabiskan waktu berjam-jam untuk memahami konsep ini. <br><br>  Dalam artikel ini, upaya untuk menjelaskan metode Monte Carlo dengan rantai Markov tersedia, sehingga menjadi jelas untuk apa mereka digunakan.  Saya akan fokus pada beberapa cara lagi untuk menggunakan metode ini di posting saya berikutnya. <br><br>  Jadi mari kita mulai.  MCMC terdiri dari dua istilah: rantai Monte Carlo dan Markov.  Mari kita bicara tentang mereka masing-masing. <br><br><h2>  Monte Carlo </h2><br><img src="https://habrastorage.org/webt/i8/wx/2n/i8wx2nylvemkcfvwp7rxvznjfa0.jpeg"><br><br>  Dalam istilah yang paling sederhana <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">, metode Monte Carlo</a> dapat didefinisikan sebagai simulasi sederhana. <br><br>  Metode Monte Carlo mendapatkan nama mereka dari Kasino Monte Carlo di Monako.  Dalam banyak permainan kartu, Anda perlu mengetahui kemungkinan memenangkan dealer.  Kadang-kadang perhitungan probabilitas ini bisa rumit secara matematis atau sulit dilakukan.  Tetapi kita selalu dapat menjalankan simulasi komputer untuk memainkan seluruh game berkali-kali dan mempertimbangkan probabilitas sebagai jumlah kemenangan dibagi dengan jumlah game yang dimainkan. <br>  Ini semua yang perlu Anda ketahui tentang metode Monte Carlo.  Ya, itu hanya teknik pemodelan sederhana dengan nama mewah. <br><br><h2>  Rantai Markov </h2><br><img src="https://habrastorage.org/webt/7r/my/np/7rmynpvle1yn4xk5tuwqdvkd7mo.jpeg"><br><br>  Karena istilah MCMC terdiri dari dua bagian, Anda masih perlu memahami apa itu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">rantai Markov</a> .  Tetapi sebelum beralih ke rantai Markov, mari kita bicara sedikit tentang properti Markov. <br><br>  Misalkan ada sistem status M-mungkin, dan Anda berpindah dari satu negara ke yang lain.  Jangan biarkan apa pun membingungkan Anda.  Contoh spesifik dari sistem tersebut adalah cuaca, yang berubah dari panas ke dingin menjadi sedang.  Contoh lain adalah pasar saham, yang melompat dari bearish ke keadaan bullish dan stagnan. <br><br>  <i>Properti Markov</i> menunjukkan bahwa untuk proses yang diberikan yang dalam keadaan X <sub>n</sub> pada saat tertentu dalam waktu, probabilitas X <sub>n + 1</sub> = k (di mana k adalah salah satu dari negara-negara M di mana proses dapat berjalan) hanya bergantung pada apa kondisi ini saat ini.  Dan bukan tentang bagaimana mencapai kondisi saat ini. <br>  Dalam istilah matematika, kita dapat menulis ini dalam bentuk rumus berikut: <br><img src="https://habrastorage.org/webt/tw/kq/se/twkqseq2tra2alhiqdyfuyswnla.png"><br>  Untuk kejelasan, Anda tidak peduli tentang urutan kondisi yang diambil pasar untuk menjadi bullish.  Probabilitas bahwa negara berikutnya akan "bearish" hanya ditentukan oleh kenyataan bahwa pasar saat ini dalam keadaan "bullish".  Ini juga masuk akal dalam praktik. <br><br>  Proses dengan properti Markov disebut proses Markov.  Mengapa rantai Markov penting?  Karena distribusi stasionernya. <br><br><h3>  Apa distribusi stasioner? </h3><br>  Saya akan mencoba menjelaskan distribusi stasioner dengan menghitungnya untuk contoh di bawah ini.  Misalkan Anda memiliki proses Markov untuk pasar saham, seperti yang ditunjukkan di bawah ini. <br><img src="https://habrastorage.org/webt/1k/o-/bb/1ko-bbb9hzmv8j9o_an1ocvyurs.png"><br>  Anda memiliki matriks probabilitas transisi yang menentukan probabilitas transisi dari kondisi X <sub>i</sub> ke X <sub>j</sub> . <br><img src="https://habrastorage.org/webt/or/u7/jp/oru7jpnpioj12jbrcw7t4o6sk94.png"><br>  Matriks Probabilitas Transisi, Q <br><br>  Dalam matriks probabilitas transisi Q yang diberikan, probabilitas bahwa keadaan berikutnya adalah "bull", mengingat status "bull" saat ini = 0,9;  probabilitas bahwa keadaan selanjutnya akan "bearish" jika keadaan saat ini adalah "bull" = 0,075.  Dan sebagainya. <br><br>  Baiklah, mari kita mulai dengan kondisi tertentu.  Negara kita akan diatur oleh vektor [banteng, beruang, stagnasi].  Jika kita mulai dengan keadaan "bearish", vektornya akan seperti ini: [0,1,0].  Kita dapat menghitung distribusi probabilitas untuk keadaan berikutnya dengan mengalikan vektor keadaan saat ini dengan matriks probabilitas transisi. <br><img src="https://habrastorage.org/webt/or/jy/85/orjy85onzacwcu2wlgftmugzygk.png"><br>  <b>Perhatikan bahwa probabilitas bertambah hingga 1.</b> <br><br>  Distribusi status berikut dapat ditemukan dengan rumus: <br><img src="https://habrastorage.org/webt/ge/wk/fu/gewkfuf7xziuajc2ox7tn9blfcm.png"><br><br>  Dan sebagainya.  Pada akhirnya, Anda akan mencapai status stasioner di mana kondisi stabil: <br><img src="https://habrastorage.org/webt/iy/5y/65/iy5y65fxgxo4foqpe3fpq2hs-dq.png"><br><br>  Untuk matriks probabilitas transisi Q yang dijelaskan di atas, distribusi stasioner adalah <br><img src="https://habrastorage.org/webt/ae/ut/_8/aeut_8m8wsypenpgkig3onnzwdc.png"><br>  Anda bisa mendapatkan distribusi stasioner dengan kode berikut: <br><br><pre><code class="python hljs">Q = np.matrix([[<span class="hljs-number"><span class="hljs-number">0.9</span></span>,<span class="hljs-number"><span class="hljs-number">0.075</span></span>,<span class="hljs-number"><span class="hljs-number">0.025</span></span>],[<span class="hljs-number"><span class="hljs-number">0.15</span></span>,<span class="hljs-number"><span class="hljs-number">0.8</span></span>,<span class="hljs-number"><span class="hljs-number">0.05</span></span>],[<span class="hljs-number"><span class="hljs-number">0.25</span></span>,<span class="hljs-number"><span class="hljs-number">0.25</span></span>,<span class="hljs-number"><span class="hljs-number">0.5</span></span>]]) init_s = np.matrix([[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span> , <span class="hljs-number"><span class="hljs-number">0</span></span>]]) epsilon =<span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> epsilon&gt;<span class="hljs-number"><span class="hljs-number">10e-9</span></span>:    next_s = np.dot(init_s,Q)    epsilon = np.sqrt(np.sum(np.square(next_s - init_s)))    init_s = next_s print(init_s) ------------------------------------------------------------------ matrix([[<span class="hljs-number"><span class="hljs-number">0.62499998</span></span>, <span class="hljs-number"><span class="hljs-number">0.31250002</span></span>, <span class="hljs-number"><span class="hljs-number">0.0625</span></span>  ]])</code> </pre> <br>  Anda juga dapat memulai dari negara bagian lain - dapatkan distribusi alat tulis yang sama.  Ubah status awal dalam kode jika Anda ingin memastikan ini. <br><br>  Sekarang kita dapat menjawab pertanyaan mengapa distribusi stasioner sangat penting. <br><br>  Distribusi stasioner penting karena dapat digunakan untuk menentukan probabilitas suatu sistem berada dalam keadaan tertentu secara acak. <br><br>  Sebagai contoh kita, kita dapat mengatakan bahwa dalam 62,5% kasus pasar akan berada dalam kondisi "bullish", 31,25% dalam kondisi "bearish" dan stagnasi 6,25%. <br><br>  Secara intuitif, Anda bisa melihat ini sebagai pengembaraan acak di sekitar rantai. <br><br><img src="https://habrastorage.org/webt/i3/e6/xt/i3e6xtqko2iip-janj6dvfbnv4q.png"><br>  Berjalan acak <br><br>  Anda berada pada titik tertentu dan memilih negara berikutnya, mengamati distribusi probabilitas negara berikutnya, dengan mempertimbangkan keadaan saat ini.  Kita dapat mengunjungi beberapa node lebih sering daripada yang lain, berdasarkan probabilitas dari node-node ini. <br><br>  Inilah cara Google memecahkan masalah pencarian di awal Internet.  Masalahnya adalah menyortir halaman, tergantung pada kepentingannya.  Google memecahkan masalah menggunakan algoritma Pagerank.  Algoritma Google Pagerank harus mempertimbangkan status sebagai sebuah halaman, dan probabilitas suatu halaman dalam distribusi stasioner sebagai kepentingan relatifnya. <br><br>  Sekarang kita beralih langsung ke pertimbangan metode MCMC. <br><br><h2>  Apa itu Metode Monte Carlo dengan Rantai Markov (MCMC) </h2><br>  Sebelum menjawab apa MCMC, izinkan saya mengajukan satu pertanyaan.  Kami tahu tentang distribusi beta.  Kita tahu fungsi kerapatan kemungkinannya.  Tetapi bisakah kita mengambil sampel dari distribusi ini?  Bisakah Anda menemukan cara untuk melakukan ini? <br><br><img src="https://habrastorage.org/webt/ks/ai/wd/ksaiwdv7lomes7g55ihqbhxushs.png"><br>  Pikirkan ... <br><br>  MCMC memungkinkan Anda untuk memilih dari distribusi probabilitas apa pun.  Ini sangat penting ketika Anda perlu memilih dari distribusi posterior. <br><img src="https://habrastorage.org/webt/12/kn/-5/12kn-58z9ub6t2ft1lctptwix28.png"><br>  Angka tersebut menunjukkan teorema Bayes. <br><br>  Misalnya, Anda perlu membuat sampel dari distribusi posterior.  Tetapi apakah mudah untuk menghitung komponen posterior bersama dengan konstanta normalisasi (bukti)?  Dalam kebanyakan kasus, Anda dapat menemukannya dalam bentuk produk kemungkinan dan probabilitas apriori.  Tetapi untuk menghitung konstanta normalisasi (p (D)) tidak berfungsi.  Mengapa  Mari kita lihat lebih dekat. <br><br>  Misalkan H hanya mengambil 3 nilai: <br><br>  p (D) = p (H = H1) .p (D | H = H1) + p (H = H2) .p (D | H = H2) + p (H = H3) .p (D | H = H3) <br><br>  Dalam hal ini, p (D) mudah untuk dihitung.  Tetapi bagaimana jika nilai H kontinu?  Apakah mungkin untuk menghitung ini dengan mudah, terutama jika H mengambil nilai yang tak terbatas?  Untuk ini, integral yang kompleks harus dipecahkan. <br><br>  Kami ingin membuat pemilihan acak dari distribusi posterior, tetapi juga ingin menganggap p (D) sebagai konstanta. <br><br>  Wikipedia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menulis</a> : <br><br>  Metode Monte Carlo dengan rantai Markov adalah kelas algoritma untuk pengambilan sampel dari distribusi probabilitas, berdasarkan pada konstruksi rantai Markov, yang sebagai distribusi stasioner memiliki bentuk yang diinginkan.  Status rantai setelah serangkaian langkah kemudian digunakan sebagai pilihan dari distribusi yang diinginkan.  Kualitas pengambilan sampel meningkat dengan meningkatnya jumlah langkah. <br><br>  Mari kita lihat sebuah contoh.  Katakanlah Anda memerlukan sampel dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">distribusi beta</a> .  Kepadatannya: <br><img src="https://habrastorage.org/webt/ag/xh/wj/agxhwjqglfhcz2bl88eu3ov84ja.png"><br><br>  di mana C adalah konstanta normalisasi.  Sebenarnya, ini adalah beberapa fungsi dari α dan β, tapi saya ingin menunjukkan bahwa itu tidak diperlukan untuk sampel dari distribusi beta, jadi kami akan menganggapnya sebagai konstanta. <br><br>  Masalah distribusi beta sangat sulit, jika tidak praktis tidak larut.  Pada kenyataannya, Anda mungkin harus bekerja dengan fungsi distribusi yang lebih kompleks, dan kadang-kadang Anda tidak akan tahu konstanta normalisasi. <br><br>  Metode MCMC membuat hidup lebih mudah dengan menyediakan algoritma yang dapat membuat rantai Markov yang memiliki distribusi beta sebagai distribusi stasioner, mengingat bahwa kita dapat memilih dari distribusi yang seragam (yang relatif sederhana). <br><br>  Jika kita mulai dengan keadaan acak dan beralih ke keadaan berikutnya berdasarkan beberapa algoritma beberapa kali, kita akhirnya akan membuat rantai Markov dengan distribusi beta sebagai distribusi stasioner.  Dan keadaan yang kita temukan dalam waktu yang lama dapat digunakan sebagai sampel dari distribusi beta. <br><br>  Salah satu algoritma MCMC ini adalah algoritma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Metropolis-Hastings.</a> <br><br><h2>  Algoritma Metropolis-Hastings </h2><br><img src="https://habrastorage.org/webt/qq/oj/89/qqoj89il8-rsyd3xo-sqawnrug0.jpeg"><br><br><h3>  Intuisi: </h3><br>  Jadi apa tujuannya? <br><br>  <i>Secara intuitif, kami ingin berjalan di sepanjang permukaan (rantai Markov kami) sedemikian rupa sehingga jumlah waktu yang kami habiskan di setiap lokasi sebanding dengan ketinggian permukaan di tempat itu (kepadatan probabilitas yang diinginkan dari mana kami ingin menentukan pilihan).</i> <i><br><br></i>  <i>Jadi, misalnya, kami ingin menghabiskan waktu dua kali lebih banyak di puncak bukit setinggi 100 meter dari pada bukit tetangga setinggi 50 meter.</i>  <i>Adalah baik bahwa kita dapat melakukan ini bahkan jika kita tidak tahu ketinggian absolut dari titik-titik di permukaan: yang perlu Anda ketahui adalah ketinggian relatif.</i>  <i>Misalnya, jika puncak bukit A dua kali lebih tinggi dari puncak bukit B, maka kami ingin menghabiskan waktu dua kali lebih banyak di A daripada di B.</i> <i><br><br></i>  <i>Ada skema yang lebih kompleks untuk mengusulkan tempat dan aturan baru untuk adopsi mereka, tetapi gagasan utamanya adalah sebagai berikut:</i> <i><br><br></i> <ol><li>  <i>Pilih lokasi "disarankan" baru.</i> </li><li>  <i>Cari tahu seberapa tinggi atau lebih rendah lokasi ini dibandingkan dengan yang sekarang.</i> </li><li>  <i>Tetap di tempat atau pindah ke tempat baru dengan probabilitas sebanding dengan ketinggian tempat.</i> </li></ol> <i><br></i>  <i>Tujuan dari MCMC adalah untuk memilih dari beberapa distribusi probabilitas tanpa harus mengetahui tingginya yang tepat pada titik mana pun (tidak perlu tahu C).</i> <i><br></i>  <i>Jika proses "mengembara" diatur dengan benar, Anda dapat memastikan bahwa proporsionalitas ini (antara waktu yang dihabiskan dan tinggi distribusi) tercapai</i> . <br><br><h3>  Algoritma: </h3><br>  Sekarang mari kita mendefinisikan dan menggambarkan tugas dalam istilah yang lebih formal.  Misalkan s = (s1, s2, ..., sM) menjadi distribusi stasioner yang diinginkan.  Kami ingin membuat rantai Markov dengan distribusi stasioner seperti itu.  Kita mulai dengan rantai Markov yang berubah-ubah dengan M-state dengan matriks transisi P, sehingga pij mewakili probabilitas transisi dari state i ke j. <br><br>  Secara intuitif, kita tahu bagaimana menjelajah rantai Markov, tetapi rantai Markov tidak memiliki distribusi stasioner yang diperlukan.  Rantai ini memiliki beberapa distribusi stasioner (yang tidak kita butuhkan).  Tujuan kami adalah mengubah cara kami menjelajahi rantai Markov sehingga rantai memiliki distribusi stasioner yang diinginkan. <br><br>  Untuk melakukan ini: <br><br><ol><li>  Mulai dengan keadaan awal acak i. </li><li>  Secara acak pilih keadaan diasumsikan baru dengan melihat probabilitas transisi di baris ke-i dari matriks transisi P. </li><li>  Hitung ukuran yang disebut probabilitas keputusan, yang didefinisikan sebagai: aij = min (sj.pji / si.pij, 1). </li><li>  Sekarang lempar koin, yang mendarat di permukaan elang dengan probabilitas aij.  Jika seekor elang jatuh, terimalah tawaran itu, yaitu pergi ke keadaan berikutnya, jika tidak, tolak tawaran itu, yaitu, tetap dalam keadaan saat ini. <br></li><li>  Ulangi berkali-kali. <br></li></ol><br>  Setelah sejumlah besar tes, rantai ini akan bertemu dan memiliki distribusi stasioner.  Kemudian kita dapat menggunakan status rantai sebagai sampel dari distribusi apa pun. <br><br>  Dengan melakukan ini untuk mengambil sampel distribusi beta, satu-satunya waktu Anda harus menggunakan kepadatan probabilitas adalah untuk mencari probabilitas membuat keputusan.  Untuk melakukan ini, bagi sj dengan si (yaitu, konstanta normalisasi C dibatalkan). <br><br><h3>  Seleksi Beta </h3><br><img src="https://habrastorage.org/webt/h9/ac/zw/h9aczwarm4hfwm0pya3hai-rg2e.jpeg"><br><br>  Sekarang kita beralih ke masalah pengambilan sampel dari distribusi beta. <br><br>  Distribusi beta adalah distribusi kontinu pada [0,1] dan dapat memiliki nilai tak hingga pada [0,1].  Misalkan rantai P Markov yang berubah-ubah dengan status tak terbatas pada [0,1] memiliki matriks transisi P sehingga pij = pji = semua elemen dalam matriks. <br><br>  Kita tidak perlu Matrix P, seperti yang akan kita lihat nanti, tetapi saya ingin deskripsi masalahnya sedekat mungkin dengan algoritma yang kami usulkan. <br><br><ul><li>  Mulai dengan keadaan awal acak i diperoleh dari distribusi seragam pada (0,1). </li><li>  Secara acak pilih keadaan diasumsikan baru dengan melihat probabilitas transisi di baris ke-i dari matriks transisi P. Misalkan kita memilih negara lain Unif (0,1) sebagai keadaan diasumsikan j. </li><li>  Hitung ukurannya, yang disebut probabilitas membuat keputusan: </li></ul><br><img src="https://habrastorage.org/webt/lp/jo/-0/lpjo-0phzn3o8zl83oniptticmu.png"><br>  Yang disederhanakan menjadi: <br><img src="https://habrastorage.org/webt/4c/he/pi/4chepi6_1om84fk52t8jquzpmku.png"><br>  Karena pji = pij, dan di mana <br><img src="https://habrastorage.org/webt/pm/qc/y2/pmqcy2hanok1y-mnhbxk49dqbve.png"><br><ul><li>  Sekarang lempar koin.  Dengan probabilitas aij seekor elang akan jatuh.  Jika elang jatuh, maka Anda harus menerima tawaran itu, yaitu, pindah ke negara bagian berikutnya.  Kalau tidak, ada baiknya menolak tawaran itu, yaitu tetap dalam keadaan yang sama. </li><li>  Ulangi tes ini berkali-kali. </li></ul><br><h3>  Kode: </h3><br>  Saatnya beralih dari teori ke praktik.  Kami akan menulis sampel beta kami dengan Python. <br><br><pre> <code class="python hljs">impo rt rand om <span class="hljs-comment"><span class="hljs-comment"># Lets define our Beta Function to generate s for any particular state. We don't care for the normalizing constant here. def beta_s(w,a,b): return w**(a-1)*(1-w)**(b-1) # This Function returns True if the coin with probability P of heads comes heads when flipped. def random_coin(p): unif = random.uniform(0,1) if unif&gt;=p: return False else: return True # This Function runs the MCMC chain for Beta Distribution. def beta_mcmc(N_hops,a,b): states = [] cur = random.uniform(0,1) for i in range(0,N_hops): states.append(cur) next = random.uniform(0,1) ap = min(beta_s(next,a,b)/beta_s(cur,a,b),1) # Calculate the acceptance probability if random_coin(ap): cur = next return states[-1000:] # Returns the last 100 states of the chain</span></span></code> </pre><br>  Bandingkan hasilnya dengan distribusi beta yang sebenarnya. <br><br><pre> <code class="python hljs">impo rt num py <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pylab <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pl <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scipy.special <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> ss %matplotlib inline pl.rcParams[<span class="hljs-string"><span class="hljs-string">'figure.figsize'</span></span>] = (<span class="hljs-number"><span class="hljs-number">17.0</span></span>, <span class="hljs-number"><span class="hljs-number">4.0</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Actual Beta PDF. def beta(a, b, i): e1 = ss.gamma(a + b) e2 = ss.gamma(a) e3 = ss.gamma(b) e4 = i ** (a - 1) e5 = (1 - i) ** (b - 1) return (e1/(e2*e3)) * e4 * e5 # Create a function to plot Actual Beta PDF with the Beta Sampled from MCMC Chain. def plot_beta(a, b): Ly = [] Lx = [] i_list = np.mgrid[0:1:100j] for i in i_list: Lx.append(i) Ly.append(beta(a, b, i)) pl.plot(Lx, Ly, label="Real Distribution: a="+str(a)+", b="+str(b)) pl.hist(beta_mcmc(100000,a,b),normed=True,bins =25, histtype='step',label="Simulated_MCMC: a="+str(a)+", b="+str(b)) pl.legend() pl.show() plot_beta(0.1, 0.1) plot_beta(1, 1) plot_beta(2, 3)</span></span></code> </pre><br><br><img src="https://habrastorage.org/webt/6z/b_/zb/6zb_zbywfexkiagddl4lpusmcko.png"><br><br>  Seperti yang Anda lihat, nilainya sangat mirip dengan distribusi beta.  Dengan demikian, jaringan MCMC telah mencapai kondisi stasioner <br><br>  Dalam kode di atas, kami membuat sampler beta, tetapi konsep yang sama berlaku untuk distribusi lain dari mana kami ingin membuat pilihan. <br><br><h2>  Kesimpulan </h2><br><img src="https://habrastorage.org/webt/5f/oh/h5/5fohh5w_hsavzw3yvbryxewnnkw.png"><br><br>  Itu adalah pos yang bagus.  Selamat jika Anda membacanya sampai akhir. <br><br>  Intinya, metode MCMC bisa rumit, tetapi mereka memberi kita fleksibilitas yang besar.  Anda dapat memilih dari fungsi distribusi apa saja menggunakan pilihan melalui MCMC.  Biasanya, metode ini digunakan untuk mengambil sampel dari distribusi posterior. <br><br>  Anda juga dapat menggunakan MCMC untuk memecahkan masalah dengan ruang keadaan besar.  Misalnya, dalam masalah ransel atau untuk dekripsi.  Saya akan mencoba memberi Anda contoh-contoh yang lebih menarik di posting <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">selanjutnya</a> .  Tetap disini. <br><br><h2>  Dari para editor </h2><br><ul><li>  Tentu saja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">python untuk bekerja dengan data</a> </li><li>  Kursus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pembelajaran Mesin</a> Online </li><li>  Kursus online " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">DATA BESAR dari awal</a> " </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id460497/">https://habr.com/ru/post/id460497/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id460485/index.html">Bagaimana turnamen online dapat mencegah "selesai minggu depan"</a></li>
<li><a href="../id460489/index.html">TOP 11 kesalahan dalam pengembangan BCP</a></li>
<li><a href="../id460491/index.html">Sensor suhu dan kelembaban Arduino dengan pengiriman dan perencanaan (Bagian 1)</a></li>
<li><a href="../id460493/index.html">“Killer apps” untuk PC dari tahun 80-an: VisiCalc dan WordStar</a></li>
<li><a href="../id460495/index.html">Container-to-pipeline: CRI-O sekarang menjadi default di OpenShift Container Platform 4</a></li>
<li><a href="../id460499/index.html">Tiga pemenang Dijkstra Prize: bagaimana Hydra 2019 dan SPTDC 2019 pergi</a></li>
<li><a href="../id460501/index.html">Contoh Implementasi Integrasi Berkelanjutan Menggunakan BuildBot</a></li>
<li><a href="../id460503/index.html">Konfigurasi nirkabel Raspberry PI 3 B +</a></li>
<li><a href="../id460505/index.html">Pikat tiga persilangan, atau Mengapa proyek sangat sulit diselesaikan tepat waktu</a></li>
<li><a href="../id460507/index.html">XEN dan masa depan otomotif: bagaimana hypervisor open-source menjadi pesaing untuk solusi otomotif komersial</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
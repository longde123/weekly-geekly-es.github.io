<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘©ğŸ½â€ğŸ« ğŸ‘©ğŸ¿â€ğŸ¤â€ğŸ‘¨ğŸ» ğŸŒ¾ TCP vs UDP atau masa depan protokol jaringan ğŸŒ ğŸ‘¨â€ğŸ”§ ğŸ‘©ğŸ½â€ğŸ­</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sebelum setiap layanan menghasilkan setidaknya 1 Mb / s lalu lintas Internet, muncul pertanyaan: â€œBagaimana? lebih dari TCP atau lebih dari UDP? " Di ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>TCP vs UDP atau masa depan protokol jaringan</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/461829/">  Sebelum setiap layanan menghasilkan setidaknya 1 Mb / s lalu lintas Internet, muncul pertanyaan: â€œBagaimana?  lebih dari TCP atau lebih dari UDP? "  Di bidang aplikasi, termasuk platform pengiriman, preferensi dan tradisi pengambilan keputusan telah dikembangkan. <br><br>  Secara teori, jika, misalnya, ketika pengembang yang malas tidak mencoba menggunakan ML-nya dengan Python (karena dia hanya mengetahuinya), dunia kemungkinan besar tidak akan pernah dipenuhi dengan cinta seperti itu untuk bahasa "super-Java encoders" yang tercela.  Dan hari ini, kelemahan bahasa ini dalam konteks aplikasi masa lalu tanpa syarat memberikannya keunggulan dalam penyebaran dan peluncuran banyak penambangan A / B. <br><br>  Anda dapat membandingkan banyak: ARM dengan Intel, iOS dan Android, dan Mortal Kombat dengan Ketidakadilan.  Dan mengalami holivar luar angkasa, jadi kembali ke topik pengiriman konten multi-format dalam jumlah besar. <br><br>  Sepuluh tahun yang lalu, semua orang benar-benar yakin UDP adalah sesuatu tentang pengiriman yang tidak dijamin.  Jika Anda memerlukan protokol yang andal, ini TCP.  Dan bertentangan dengan tradisi dalam artikel ini, kita akan membandingkan hal-hal yang tampaknya tak tertandingi seperti TCP dan UDP. <br><br><img src="https://habrastorage.org/webt/p5/tk/9z/p5tk9z_pumv5hmxly_ob3rvdikg.jpeg"><br>  <i>Perhatian, di bawah potongan 99 ilustrasi dan diagram dan semuanya penting.</i> <br><a name="habracut"></a><br>  Perbandingan dilakukan oleh kepala pengembangan platform Video dan Tape di OK <b>Alexander Tobol</b> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" class="user_link">alatobol</a> ).  Layanan Video dan Umpan Berita di jejaring sosial OK - secara eksklusif tentang konten dan pengirimannya ke semua platform klien yang ada dalam kondisi jaringan yang buruk atau luar biasa, dan pertanyaan tentang bagaimana mengirimkannya - melalui TCP atau UDP - sangat penting. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/aXYJlizk3CQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  TCP vs UDP.  Teori minimum </h2><br>  Untuk mendapatkan perbandingan, kita perlu sedikit teori dasar. <br><br><img src="https://habrastorage.org/webt/fd/2q/ko/fd2qkoeptll1vmmm0ptkscrhu9i.jpeg"><br><br>  Apa yang kita ketahui tentang jaringan IP?  Aliran data yang Anda kirim dibagi menjadi beberapa paket, semacam kotak hitam mengirimkan paket-paket ini ke klien.  Klien mengumpulkan paket dan menerima aliran data.  Biasanya ini semua transparan dan tidak perlu memikirkan apa yang ada di level bawah. <br><br><img src="https://habrastorage.org/webt/dj/6r/xm/dj6rxmcr3xayjlmfnblkxet-1le.jpeg"><br><br>  Diagram menunjukkan tumpukan TCP / IP dan UDP / IP.  Di bagian bawah ada paket Ethernet, paket IP, dan selanjutnya di tingkat OS ada TCP dan UDP.  TCP dan UDP dalam tumpukan ini tidak jauh berbeda satu sama lain.  Mereka dienkapsulasi dalam paket IP, dan aplikasi dapat menggunakannya.  Untuk melihat perbedaannya, Anda perlu melihat ke dalam paket TCP dan UDP. <br><br><img src="https://habrastorage.org/webt/mz/pr/lt/mzprltftvytepznp_xufo63xb0g.jpeg"><br><br>  Baik di sana maupun di sana ada porta.  Tetapi <strong>dalam UDP hanya ada checksum</strong> - panjang paket, protokol ini sesederhana mungkin.  Dan dalam TCP, ada banyak data yang secara jelas menunjukkan jendela, pengakuan, urutan, paket, dan sebagainya.  Jelas <strong>TCP lebih kompleks</strong> . <br><br><blockquote>  Berbicara sangat kasar, TCP adalah protokol pengiriman yang andal, dan UDP adalah protokol yang tidak bisa diandalkan. </blockquote><br>  Namun, terlepas dari dugaan tidak dapat diandalkannya UDP, kami akan mencari tahu apakah mungkin untuk mengirimkan data lebih cepat dan lebih dapat diandalkan daripada menggunakan TCP.  Mari kita coba melihat jaringan dari dalam dan memahami cara kerjanya.  Sepanjang jalan, kita akan menyentuh pertanyaan-pertanyaan berikut: <br><br><ul><li>  mengapa membandingkan TCP atau apa yang salah dengannya; </li><li>  dengan apa dan apa yang harus Anda bandingkan TCP; </li><li>  apa yang Google lakukan dan keputusan apa yang diambilnya; </li><li>  apa masa depan protokol jaringan menunggu kita. </li></ul><br>  Artikel ini tidak akan memiliki teori: level dan model OSI, model matematika yang kompleks, meskipun semuanya dapat dihitung melalui mereka.  Kami akan menganalisis secara maksimal bagaimana menyentuh jaringan tidak secara teori, tetapi dengan tangan kita sendiri. <br><br><h2>  Mengapa membandingkan TCP atau apa yang salah dengannya </h2><br>  TCP ditemukan pada 1974, dan 20 tahun kemudian, ketika saya pergi ke sekolah, saya membeli kartu Internet, menghapus kode, dan menelepon ke suatu tempat.  Apalagi, jika Anda menelepon dari 2 malam hingga 7 pagi, maka internet gratis, tetapi sulit untuk dilewati. <br><br>  Lain 20 tahun berlalu, dan pengguna pada jaringan nirkabel seluler mulai menang atas pengguna "kabel", sementara TCP secara konseptual tidak berubah. <br><br><blockquote>  Dunia seluler menang, protokol nirkabel muncul, dan TCP masih tidak berubah. </blockquote><br>  Saat ini, 80% pengguna menggunakan Wi-Fi atau jaringan nirkabel 3G-4G. <br><br><img src="https://habrastorage.org/webt/mw/a9/u4/mwa9u4ew7v6e1uevlbgrvf2jlrw.jpeg"><br><br>  Dalam jaringan nirkabel, ada: <br><br><ul><li>  packet loss - sekitar 0,6% dari paket yang kami kirim hilang di sepanjang jalan; </li><li>  penataan ulang - penataan ulang paket di tempat, dalam kehidupan nyata adalah fenomena yang agak langka, tetapi terjadi pada 0,2% kasus; </li><li>  jitter - ketika paket dikirim secara merata dan tiba dalam antrian dengan penundaan sekitar 50 ms. </li></ul><br>  TCP berhasil menyembunyikan semua fitur transfer data ini di jaringan heterogen dari Anda, dan Anda tidak perlu masuk ke dalamnya. <br><br>  Di bawah ini pada peta adalah laju data TCP rata-rata di Rusia.  Jika Anda menghapus bagian barat, jelas bahwa kecepatan diukur lebih dalam kilobit daripada di megabit. <br><br><img src="https://habrastorage.org/webt/ck/a4/y5/cka4y5puk4gyorr-uaq2xcdtuom.jpeg"><br><br>  Itu, rata-rata, untuk pengguna kami (tidak termasuk bagian barat Rusia): throughput 1,1 Mbps, paket loss 0,6%, RTT (waktu pulang-pergi) sekitar 200 ms. <br><br><h3>  Bagaimana cara menghitung RTT </h3><br>  Ketika saya melihat rata-rata 200 ms, saya berpikir bahwa ada kesalahan dalam statistik, dan memutuskan untuk mengukur RTT ke server kami di MSC dengan cara alternatif menggunakan RIPE Atlas.  Ini adalah sistem untuk mengumpulkan data tentang keadaan Internet.  Probe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">RIPE Atlas</a> tersedia secara gratis. <br><br><img src="https://habrastorage.org/webt/za/rj/3g/zarj3gndghr0wnxs4yqt_odm68a.jpeg"><br><br>  Intinya adalah bahwa Anda menghubungkannya ke Internet di rumah Anda dan mengumpulkan "karma".  Dia bekerja selama berhari-hari, beberapa orang memenuhi beberapa permintaannya.  Kemudian Anda dapat mengatur berbagai tugas sendiri.  Contoh dari tugas seperti itu: secara tidak sengaja mengambil 30 poin di Internet, dan meminta untuk mengukur RTT, yaitu, jalankan perintah ping ke situs web Odnoklassniki. <br><br><img src="https://habrastorage.org/webt/kb/qa/5k/kbqa5k7sgl6wt5modhjfpa2fg00.jpeg"><br><br>  Anehnya, di antara titik-titik acak ada banyak yang memiliki ping dari 200 hingga 300 ms. <br><br>  Secara keseluruhan, <strong>jaringan nirkabel populer dan tidak stabil</strong> (meskipun yang terakhir biasanya diabaikan, karena diyakini bahwa TCP dapat menangani ini): <br><br><ul><li>  Lebih dari 80% pengguna menggunakan internet nirkabel; </li><li>  Parameter jaringan nirkabel berubah secara dinamis tergantung, misalnya, pada kenyataan bahwa pengguna telah berbelok; </li><li>  Jaringan nirkabel memiliki tingkat kehilangan paket, jitter, pemesanan ulang yang tinggi; </li><li>  Memperbaiki saluran asimetris, mengubah alamat IP. </li></ul><br><h3>  Konsumsi Konten Tergantung pada Kecepatan Internet </h3><br>  Ini sangat mudah diverifikasi - ada banyak statistik.  Saya mengambil <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">statistik</a> pada video, yang mengatakan bahwa semakin tinggi kecepatan internet di negara itu, semakin banyak pengguna menonton video. <br><br><img src="https://habrastorage.org/webt/de/6q/_r/de6q_ruks-vpbgoo4yt5vokfkno.jpeg"><br><br>  Menurut statistik ini, Rusia memiliki Internet yang cukup cepat, tetapi menurut data internal kami, kecepatan rata-rata sedikit lebih rendah. <br><br>  Dalam mendukung fakta bahwa kecepatan internet secara keseluruhan tidak mencukupi, dikatakan bahwa semua pencipta aplikasi besar, jejaring sosial, layanan video dan sebagainya mengoptimalkan layanan mereka untuk bekerja di jaringan yang buruk.  Setelah 10 Kb data yang diterima, Anda dapat melihat informasi minimum dalam rekaman, dan pada kecepatan 500 Kb Anda dapat menonton video. <br><br><h3>  Cara mempercepat pemuatan </h3><br>  Dalam proses pengembangan platform Video, kami menyadari bahwa TCP tidak terlalu efektif dalam jaringan nirkabel.  Bagaimana Anda sampai pada kesimpulan ini? <br><br>  Kami memutuskan untuk mempercepat unduhan dan melakukan trik berikutnya. <br><br><img src="https://habrastorage.org/webt/n2/gg/xf/n2ggxfu9tzoskihc7itlm28j7ui.jpeg"><br><br>  Kami mengunduh video dari klien ke server dalam beberapa aliran, yaitu, 40 MB dibagi menjadi 4 bagian dari 10 MB dan dimuat secara paralel.  Kami memulainya di Android dan memuatnya secara paralel lebih cepat daripada dalam satu koneksi ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">demo</a> dalam laporan).  Yang paling menarik adalah ketika kami meluncurkan unduhan paralel ke dalam produksi, kami melihat bahwa di beberapa daerah kecepatan unduhan meningkat 3 kali lipat! <br><br><blockquote>  Empat koneksi TCP sebenarnya dapat mengunggah data ke server 3 kali lebih cepat. </blockquote><br>  Jadi kami meningkatkan kecepatan pengunduhan video dan menyimpulkan bahwa pengunduhan perlu diparalelkan. <br><br><h3>  TCP di jaringan yang tidak stabil </h3><br>  Efek luar biasa dengan paralelisme dapat disentuh.  Cukup dengan mengambil pengukur kecepatan untuk menerima / mengirim data (misalnya, Tes Kecepatan) dan pembentuk lalu lintas (misalnya, kondisioner tautan jaringan, jika Anda memiliki Mac) Kami membatasi jaringan untuk parameter 1 Mbps untuk diunggah dan diunduh dan mulai meningkatkan kehilangan paket. <br><br><img src="https://habrastorage.org/webt/lk/ki/j8/lkkij8appdgsvglvlp1rdt3em7s.jpeg"><br><br>  Tabel menunjukkan RTT dan kerugian.  Dapat dilihat bahwa dalam kasus kehilangan 0%, jaringan digunakan 100%. <br><br>  Dengan iterasi berikutnya, kami meningkatkan packet loss sebesar 5%, dan kami melihat bahwa jaringan hanya digunakan oleh 74%.  Tampaknya baik-baik saja - dengan kehilangan paket 5%, 26% dari jaringan hilang.  Tetapi jika Anda juga meningkatkan ping, maka <strong>kurang dari setengah saluran</strong> akan tetap. <br><br><blockquote>  Jika saluran dengan RTT tinggi dan kehilangan paket besar, maka satu koneksi TCP tidak sepenuhnya memanfaatkan jaringan. </blockquote><br>  Trik lebih lanjut menunjukkan bahwa jika Anda mulai menggunakan koneksi TCP paralel (Anda bisa menjalankan beberapa Tes Kecepatan secara bersamaan), Anda dapat melihat pertumbuhan sebaliknya dari pemanfaatan saluran. <br><br><img src="https://habrastorage.org/webt/co/n7/v_/con7v_t-dxmnrsxe6e0kkakbnwm.jpeg"><br><br>  Dengan peningkatan jumlah koneksi TCP paralel, pemanfaatan jaringan menjadi hampir sama dengan throughput, dikurangi persentase kerugian. <br><br>  Jadi, ternyata: <br><br><ul><li>  Jaringan seluler nirkabel telah menang dan tidak stabil. </li><li>  TCP tidak sepenuhnya memanfaatkan saluran di jaringan yang tidak stabil. </li><li>  Konsumsi konten tergantung pada kecepatan Internet: semakin tinggi kecepatan Internet, semakin banyak pengguna menonton, dan kami sangat mencintai pengguna kami dan ingin mereka menonton lebih banyak. </li></ul><br>  Jelas, Anda perlu pindah ke suatu tempat dan mempertimbangkan alternatif untuk TCP. <br><br><h2>  TCP vs bukan TCP </h2><br>  Bagaimana membandingkan yang hangat?  Ada dua opsi. <br><br>  Opsi pertama - pada level IP ada TCP dan UDP, kita dapat membeli beberapa protokol lain dari atas.  Jelas, jika Anda memulai protokol Anda sendiri secara paralel dengan TCP dan UDP, maka Firewall, Brandmauer, router dan seluruh dunia yang terlibat dalam pengiriman paket tidak akan mengetahuinya.  Akibatnya, Anda harus menunggu selama bertahun-tahun ketika semua peralatan diperbarui dan mulai bekerja dengan protokol baru. <br><br>  Opsi kedua adalah membuat protokol pengiriman data Anda sendiri yang andal di atas UDP yang tidak bisa diandalkan.  Tentunya, Anda bisa menunggu lama sampai Linux, Android dan iOS menambahkan protokol baru ke kernel Anda, jadi Anda perlu memotong protokol menjadi User Space. <br><br>  Solusi ini tampaknya menarik, kita akan menyebutnya protokol UDP buatan sendiri.  Untuk mulai mengembangkannya, Anda tidak perlu sesuatu yang istimewa: cukup buka soket UDP dan kirim datanya. <br><br><img src="https://habrastorage.org/webt/zy/zt/sn/zyztsnsutwgufcqwlhxb6qslhpg.jpeg"><br><br>  Kami akan mengembangkannya, sambil mempelajari cara kerja jaringan. <br><br><h2>  TCP vs UDP buatan sendiri </h2><br>  Nah, dan apa yang harus dibandingkan? <br><br>  Jaringan berbeda: <br><br><ul><li>  Dengan kemacetan, ketika ada banyak paket dan beberapa dari mereka jatuh karena kemacetan saluran atau peralatan. </li><li>  Kecepatan tinggi dengan pulang pergi besar (misalnya, ketika server relatif jauh). </li><li>  Aneh - ketika sepertinya tidak ada yang terjadi pada jaringan, tetapi paket-paket masih menghilang hanya karena titik akses Wi-Fi ada di belakang dinding. </li></ul><br>  Anda selalu dapat menyentuh sendiri profil jaringan: pilih satu atau beberapa profil lain di ponsel Anda dan jalankan Tes Kecepatan. <br><br><img src="https://habrastorage.org/webt/v1/0j/-p/v10j-p8absukvs6s4jn2ntd8qau.jpeg"><br><br>  Selain profil jaringan, Anda juga perlu menentukan profil konsumsi lalu lintas.  Inilah yang kami gunakan: <br><br><img src="https://habrastorage.org/webt/3k/dc/fb/3kdcfbeyhjpduwbumk1n1iz2-c0.jpeg"><br><br>  Karena saya bertanggung jawab atas Video dan Stream, profilnya sesuai: <br><br><ul><li>  Video Profil, saat Anda menghubungkan dan mengalirkan konten ini atau itu.  Kecepatan koneksi meningkat, seperti pada grafik atas.  Persyaratan untuk protokol ini: latensi rendah dan adaptasi bitrate. </li><li>  Opsi tampilan tape: pemuatan data impuls, permintaan latar belakang, waktu henti.  Persyaratan untuk protokol ini: data yang diterima multipleks dan diprioritaskan, prioritas konten pengguna lebih tinggi dari proses latar belakang, ada pembatalan pengunduhan. </li></ul><br>  Tentu saja, Anda perlu membandingkan protokol pada HTTP paling populer. <br><br><h3>  HTTP 1.1 dan HTTP 2.0 </h3><br>  Tumpukan standar 2000-an tampak seperti HTTP 1.1 di atas SSL.  Tumpukan modern adalah HTTP 2.0, TLS 1.3, dan semuanya ada di atas TCP. <br><br><img src="https://habrastorage.org/webt/k9/yp/ng/k9ypngmth9i_4m8pqzx5n-kipf0.jpeg"><br><br>  Perbedaan utama adalah bahwa HTTP 1.1 menggunakan kumpulan koneksi terbatas di browser ke satu domain, sehingga mereka membuat domain terpisah untuk gambar, untuk data, dan sebagainya.  HTTP 2.0 menawarkan satu koneksi multipleks tempat semua data ini dikirimkan. <br><br><img src="https://habrastorage.org/webt/uo/aj/uu/uoajuubf2yfz_femlhzhvq6buty.jpeg"><br><br>  HTTP 1.1 berfungsi seperti ini: membuat permintaan, mendapatkan data, membuat permintaan, mendapatkan data. <br><br><img src="https://habrastorage.org/webt/1y/nv/xd/1ynvxdxpfkluduputf3szhfi75a.jpeg"><br><br>  Biasanya browser atau aplikasi seluler adalah bullet, yaitu koneksi untuk menerima gambar, data dengan API, dan Anda secara bersamaan menjalankan permintaan untuk gambar, untuk API, untuk video, dan sebagainya. <br><br><img src="https://habrastorage.org/webt/cn/ub/kl/cnubklsdxjrcuwpamcckap5_uu8.jpeg"><br><br>  Masalah utamanya adalah kompetisi.  Anda tidak memiliki kendali atas permintaan yang diajukan.  Anda memahami bahwa pengguna tidak lagi membutuhkan gambar yang dibaliknya, tetapi tidak dapat melakukan apa pun. <br><br><blockquote>  Dengan HTTP 1.1, Anda masih mendapatkan apa yang Anda minta, sulit untuk membatalkan unduhan. </blockquote><br>  Satu-satunya soket stopkontak adalah untuk menutup koneksi.  Maka kita akan melihat mengapa ini buruk. <br><br><h3>  Perbedaan dalam HTTP 2.0 </h3><br>  HTTP 2.0 memecahkan masalah ini: <br><br><ul><li>  biner, kompresi tajuk; </li><li>  multiplexing data; </li><li>  prioritisasi; </li><li>  membatalkan pengunduhan; </li><li>  dorongan server </li></ul><br>  Mari kita pertimbangkan poin yang lebih penting bagi kita. <br><br><img src="https://habrastorage.org/webt/tb/nl/ur/tbnlurtfdzcqaxpy6_hgcphtye0.jpeg"><br><br>  Minta gambar dan API.  Gambar segera diberikan, API disiapkan setelah beberapa saat.  API diberikan - gambar diberikan sampai akhir.  Semua ini terjadi secara transparan.  <strong>Konten prioritas tinggi diunduh lebih awal.</strong> <br><br><img src="https://habrastorage.org/webt/gw/ws/wp/gwwswpducmtjv2huz9jprbhwpha.jpeg"><br><br>  <strong>Server push</strong> adalah hal seperti itu ketika Anda meminta sesuatu yang spesifik seperti API, tetapi bahkan dalam memuat gambar klien di-cache yang pasti akan diperlukan untuk melihat, misalnya, rekaman. <br><br>  Ada juga perintah <strong>Reset stream</strong> yang dijalankan oleh browser sendiri jika Anda berpindah antar halaman, dll.  Untuk klien seluler, dengan bantuannya, Anda dapat menolak menerima data tanpa kehilangan koneksi. <br><br>  Dengan demikian, kami akan membandingkan TCP pada yang berbeda: <br><br><ul><li>  Profil jaringan: Wi-Fi, 3G, LTE. </li><li>  Profil konsumsi: streaming (video), multiplexing dan prioritisasi dengan membatalkan unduhan (HTTP / 2) untuk menerima konten rekaman. </li></ul><br><h3>  Model lossless </h3><br>  Mari kita mulai perbandingan dengan jaringan sederhana yang hanya memiliki dua parameter: waktu pulang-pergi dan bandwidth. <br><br>  <b>RTT</b> adalah ping, waktu penyelesaian paket, penerimaan pengakuan, atau waktu gema respons. <br><br>  Untuk mengukur <b>bandwidth</b> - <b>bandwidth</b> jaringan - kami mengirim paket paket dan menghitung jumlah paket yang dikirimkan pada interval waktu tertentu. <br><br><img src="https://habrastorage.org/webt/6r/du/2l/6rdu2lwrhgztjekbwsfgvtuwdec.jpeg"><br><br>  Karena kami bekerja dengan protokol yang andal, tentu saja, ada pengakuan - kami mengirim paket dan menerima konfirmasi tanda terima. <br><br><h3>  Masalah internet lambat </h3><br>  Pada awal pengembangan layanan video kami pada 2013, teman saya pergi ke California dan memutuskan untuk menonton seri baru seri favoritnya di Odnoklassniki.  Dia memiliki RTT 250 ms, Wi-Fi sempurna 400 Mbps di kampus Google, dia ingin melihat seri baru dalam FullHD. <br><br>  Apakah Anda pikir dia bisa menonton video?  Jawabannya tergantung pada konfigurasi buffer send / recv di server kami. <br><br><img src="https://habrastorage.org/webt/qf/sk/qj/qfskqjvyygm-klersirdlmfdreo.jpeg"><br><br>  Karena kami memiliki protokol dengan pengakuan, semua data yang tidak menerima konfirmasi pengiriman disimpan dalam buffer.  Jika buffer pengiriman dibatasi hingga 128 Kb, maka 128 Kb ini kurang dari untuk RTT, kami tidak dapat mengirim.  Jadi, dari jaringan kami 400 Mbit / s, 4 Mbit / s tetap.  Ini tidak cukup untuk menonton video online dalam FullHD. <br><br>  Lalu saya menarik ukuran buffer dan melihat bagaimana kecepatan output dari satu segmen video benar-benar berubah tergantung pada perubahan ukuran buffer.  Segera buat reservasi agar recv buffer disetel secara otomatis, mis.  apa yang dikirim server, klien selalu dapat menerima. <br><br><img src="https://habrastorage.org/webt/vj/yi/ef/vjyiefcatf55inm_ka-0b1vpake.jpeg"><br><br><blockquote>  Resep TCP yang jelas: jika Anda mengirim data berkecepatan tinggi dalam jarak jauh, Anda perlu meningkatkan buffer pengiriman. </blockquote><br>  Segalanya tampak baik-baik saja.  Anda dapat pergi ke layanan fast.com, yang mengukur kecepatan Internet Anda ke server Netflix.  Dari kantor saya mendapat kecepatan 210 Mbps.  Dan kemudian melalui pembentuk jaring saya mengatur kondisi tugas dan pergi ke situs ini lagi.  Magic - Saya mendapat 4 Mbps dengan tepat. <br><br><img src="https://habrastorage.org/webt/xx/sl/nr/xxslnr1m5syfgyludnghfp7d6yw.jpeg"><br><br>  Tidak peduli bagaimana saya memutarnya, Netflix tidak berhasil mendapatkan buffer yang lebih besar dari 128 KB. <br><br><h3>  Ukuran penyangga </h3><br>  Untuk mengetahui ukuran buffer optimal, Anda perlu memahami paket On-the-fly. <br><br><img src="https://habrastorage.org/webt/cl/ym/ws/clymwsmlyixceklwgevvv00izru.jpeg"><br><br>  Ada status jaringan: <br><br><ul><li>  paket 1 dan 2 telah dikirim, konfirmasi telah diterima untuk mereka; </li><li>  paket 3, 4, 5, 6 dikirim, tetapi hasil pengiriman tidak diketahui (paket on-the-fly); </li><li>  paket lain sedang dalam antrian. </li></ul><br><img src="https://habrastorage.org/webt/if/oh/m0/ifohm0lal6uotlodse6vrehnoqc.jpeg"><br><br>  Jika jumlah paket dalam On-the-fly sama dengan ukuran buffer, maka itu tidak cukup besar.  Dalam hal ini, jaringan kelaparan, tidak dimanfaatkan sepenuhnya. <br><br>  Situasi sebaliknya dimungkinkan - buffer terlalu besar.  Dalam hal ini, buffer membengkak.  Kenapa ini buruk? <br><br><img src="https://habrastorage.org/webt/m1/4y/fk/m14yfka8426esfgz8a8xeglxko4.jpeg"><br><br>  Jika kita berbicara tentang multiplexing data dan mengirim beberapa permintaan secara bersamaan, misalnya gambar dalam koneksi dan API yang sama, maka ketika seluruh gambar megabita besar masuk ke buffer, dan kami mencoba memasukkan API prioritas tinggi juga, buffer membengkak.  Anda harus menunggu sangat lama ketika gambar hilang. <br><br>  Solusi sederhana adalah menyesuaikan ukuran buffer secara otomatis.  Sekarang tersedia di banyak klien dan bekerja seperti ini. <br><br><img src="https://habrastorage.org/webt/pm/dj/rj/pmdjrjtekrknmzgogzn6bzkgplq.jpeg"><br><br>  Jika banyak paket dapat dikirim sekarang, buffer meningkat, transfer data semakin cepat, ukuran buffer bertambah, semuanya tampak hebat. <br><br>  Tapi ada masalah.  Jika buffer telah meningkat, itu tidak dapat dikurangi dengan mudah.  Ini adalah tugas yang lebih sulit.  Jika kecepatan melorot, maka terjadi pembengkakan buffer yang sama.  Buffer cukup besar dan penuh, kita harus menunggu sampai semua data dikirim ke klien. <br><br>  Jika kita menulis protokol UDP kita sendiri, maka semuanya sangat sederhana - kita memiliki akses ke buffer. <br><br><img src="https://habrastorage.org/webt/ow/lz/5m/owlz5m0em5dqvtz3ni14pgc3khm.jpeg"><br><br>  Jika TCP dalam situasi seperti itu hanya menambah data sampai akhir, dan Anda tidak dapat melakukan apa pun, maka dalam protokol buatan sendiri Anda dapat memasukkan data, misalnya, meneruskan, segera setelah paket On-the-fly. <br><br>  Dan jika pembatalan datang, dan klien mengatakan bahwa gambar ini tidak lagi diperlukan, ia membutuhkan data API, ia menggulir konten lebih lanjut, Anda dapat membuang semua ini dari buffer dan mengirim yang diperlukan. <br><br>  Bagaimana ini dilakukan?  Diketahui bahwa untuk mengembalikan paket, mengatur pengiriman, menerima ucapan terima kasih, Anda memerlukan beberapa sequence_id dari paket.  Sequence_id kami ditulis hanya untuk paket on-the-fly, yaitu, kami mengeluarkannya hanya ketika kami mengirim paket.  Segala sesuatu yang lain dalam buffer dapat dipindahkan seperti yang kita inginkan hingga paket hilang. <br><br>  <strong>Kesimpulan:</strong> buffer TCP harus dikonfigurasi dengan benar, menangkap keseimbangan agar tidak berbatasan dengan jaringan dan tidak mengembang buffer.  Untuk protokol UDP Anda sendiri, semuanya sederhana - ini dapat dikontrol. <br><br><h3>  Model jaringan lossy </h3><br>  Kami pindah ke tingkat yang lebih tinggi, jaringan menjadi sedikit lebih rumit, paket loss muncul di dalamnya.  Untuk jaringan seluler, ini adalah situasi yang umum.  Beberapa paket yang dikirim tidak mencapai klien.  Algoritme pemulihan transmisi ulang standar berfungsi seperti ini: <br><br><img src="https://habrastorage.org/webt/tg/z7/tv/tgz7tvr6zchscr49onnqepvjvje.jpeg"><br><br>  Mengirim paket, untuk setiap paket menerima pengakuan.   Retransmit timeout (RTO)  RTT     ,   . <br><br>     TCP,    5% ,     50%. <br><br><img src="https://habrastorage.org/webt/ob/vi/qf/obviqfawoiesuiex2yqf_idbvei.jpeg"><br><br>  retransmit,    ,      .    ,  ,   Congestion control. <br><br><h3> Congestion control </h3><br>      flow control,    . <br><br><img src="https://habrastorage.org/webt/bc/3k/g9/bc3kg9sb5k5sppttampxxaeaypu.jpeg"><br><br><ul><li> <b>Flow control</b> â€”      .  ,           ,      .    flow control  recv window,      .  flow control â€”  back pressure  ,    -    . </li><li>  <b>congestion control</b>   .  ,   â€”    . </li></ul><br><img src="https://habrastorage.org/webt/mf/b5/9d/mfb59d5xp1ph_irk_rhkckjpbew.jpeg"><br><br>   ,     :  ,    ,    ,      .        ,     congestion control. <br><br>    TCP window. <br><br><img src="https://habrastorage.org/webt/tj/u0/9s/tju09sic8asow88ehlwsuyfjj6q.jpeg"><br><br>     flow control  congestion control,       . <br><br> : <br><br><ul><li>  TCP window = 1,       :  acknowledgement,     .. </li><li>  TCP window = 4,       ,  acknowledgement   . </li></ul><br>    ,    .  initial window  TCP = 10. <br><br><img src="https://habrastorage.org/webt/ar/jf/ja/arjfjayzxewtfl-iulsna677qa0.jpeg"><br><br>    ,  ,        . <br><br>     ? <br><br><img src="https://habrastorage.org/webt/yj/ck/_t/yjck_tpkuuze0pjmkdb5mhfrlri.jpeg"><br><br><ul><li>    ,    .     ,      . </li><li>      :   , acknowledgements   . </li><li>            -    , acknowledgements      ( ). </li></ul><br>       . <br><br><img src="https://habrastorage.org/webt/jp/6c/di/jp6cdirmtiqosalz9vw-mvkjkei.jpeg"><br><br>   ,    ,   .     :     ,     ..    ,      .   congestion control,  TCP window,    ,    . <br><br><img src="https://habrastorage.org/webt/__/w0/zg/__w0zgqdiycta2u7yla0svmhof4.jpeg"><br><br>     congestion control,   ,   â€”   .      packet loss â€”  ,   .        ,   ,         â€”    ,    . <br><br> ,  TCP , ,   congestion control   loss-.    congestion control  loss delay,     ,   . <br><br><img src="https://habrastorage.org/webt/44/no/5k/44no5kuc601zfx2h8dm_kwoqete.jpeg"><br><br> : <br><br><ul><li> <b>Cubic</b> â€”  Congestion Control  Linux 2.6.        :   â€”  . </li><li> <b>BBR</b> â€”   Congestion Control,    Google  2016 .   . </li></ul><br><h3> BBR Congestion Control </h3><br>   Cubic  BBR   feedback. <br><br><img src="https://habrastorage.org/webt/7u/5z/zr/7u5zzrcv5cr3eyywvi0ui75qxr8.jpeg"><br><br>       ,      â€”   acknowledgement       .   : <br><br><ul><li> BBR ,    ,    ,    . </li><li> Cubic        . </li></ul><br>  Di bawah ini adalah grafik dari penundaan terhadap waktu koneksi, yang menunjukkan apa yang terjadi pada Kontrol Kemacetan yang berbeda. <br><br><img src="https://habrastorage.org/webt/xn/l5/c_/xnl5c_gfgpby_vchj-lt5ftptta.jpeg"><br><br>  BBR pertama kali merasakan waktu pulang-pergi, mengirimkan lebih banyak paket, kemudian menyadari bahwa buffer tersumbat, dan memasuki mode operasi dengan penundaan minimal. <br><br>  Cubic bekerja secara agresif - itu meluap ke seluruh buffer, dan ketika buffer meluap dan kehilangan paket terjadi, cubic mengurangi jendela. <br><br>  Tampaknya dengan bantuan BBR akan mungkin untuk menyelesaikan semua masalah, tetapi ada <strong>jitter</strong> di jaringan - paket kadang-kadang tertunda, kadang-kadang dikelompokkan dalam bundel.  Anda mengirim mereka dengan frekuensi tertentu, dan mereka datang berkelompok.  Lebih buruk lagi, ketika Anda menerima ucapan terima kasih kembali ke paket-paket ini, dan mereka juga entah bagaimana "jitter". <br><br>  Karena saya berjanji bahwa semuanya dapat disentuh dengan tangan, maka kami melakukan ping, misalnya, situs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HighLoad ++</a> , melihat ping dan mempertimbangkan jitter di antara paket-paket. <br><br><img src="https://habrastorage.org/webt/be/pu/fj/bepufjz6mtygfhqppfkeyvi3phq.jpeg"><br><br>  Dapat dilihat bahwa paket datang tidak rata, rata-rata jitter adalah sekitar 50 ms.  Secara alami, BBR mungkin salah. <br><br>  BBR bagus karena membedakan antara: kehilangan kongesti nyata, kehilangan paket karena buffer overflow perangkat, dan kehilangan acak karena buruknya jaringan nirkabel.  Tapi itu tidak berfungsi dengan baik jika jitter tinggi.  Bagaimana saya bisa membantunya? <br><br><h3>  Cara membuat kontrol kemacetan lebih baik </h3><br>  Bahkan, TCP tidak memiliki informasi yang cukup dalam pengakuan, hanya memiliki paket apa yang dilihatnya.  Ada juga pengakuan selektif, yang mengatakan paket mana yang dikonfirmasi, yang belum tiba.  Tetapi informasi ini tidak cukup. <br><br><img src="https://habrastorage.org/webt/fs/9j/gm/fs9jgmfd67brdk7wynu6sqjprk8.jpeg"><br><br>  Jika Anda memiliki kesempatan untuk meningkatkan pengakuan, Anda masih dapat menghemat waktu - tidak hanya mengirim paket-paket ini, tetapi juga tiba di klien.  Itu, pada kenyataannya, di server untuk mengumpulkan klien jitter. <br><br>  Mengapa efektif meningkatkan pengakuan?  Karena jaringan seluler asimetris.  Misalnya, biasanya dengan 3G atau LTE, 70% dari bandwidth dialokasikan untuk mengunduh data dan 30% untuk mengunggah.  Pemancar beralih: unggah - unduh, unggah - unduh, dan Anda tidak memengaruhinya dengan cara apa pun.  Jika Anda tidak membongkar apa pun, maka itu hanya menganggur.  Karena itu, jika Anda memiliki ide menarik, tingkatkan pengakuan, jangan malu-malu - ini bukan masalah. <br><br><img src="https://habrastorage.org/webt/cv/0t/gd/cv0tgdq9vzirpmrvzx4optqe0ik.jpeg"><br><br>  Contoh bagaimana Anda dapat menggunakan pengakuan untuk membagi jitter ke dalam pengiriman dan jitter untuk menerima, dan melacaknya secara terpisah.  Kemudian kita menjadi lebih fleksibel, dan kita mengerti kapan kehilangan kemacetan terjadi, dan ketika kehilangan acak terjadi.  Misalnya, Anda dapat memahami berapa banyak jitter di setiap arah, dan lebih tepatnya mengkonfigurasi jendela. <br><br><img src="https://habrastorage.org/webt/ti/qj/zk/tiqjzkihljlcb2pn2oj-wdlbmkq.jpeg"><br><br><h3>  Kontrol kemacetan mana yang harus dipilih </h3><br>  Teman sekelas adalah jaringan besar dengan banyak lalu lintas berbeda: video, API, gambar.  Dan ada statistik yang mengontrol kemacetan yang lebih baik untuk dipilih. <br><br>  BBR selalu efektif untuk video karena mengurangi penundaan.  Dalam kasus lain, Cubic biasanya digunakan - itu bagus untuk foto.  Tetapi ada opsi lain. <br><br><img src="https://habrastorage.org/webt/9m/ea/gd/9meagdum2m9dvmtn4eeawrmbtay.jpeg"><br><br>  Ada puluhan opsi kontrol kemacetan yang berbeda.  Untuk memilih yang terbaik, Anda dapat mengumpulkan statistik pada klien dan mencoba satu atau lain kontrol kemacetan untuk berbagai jenis profil pemuatan. <br><br>  Misalnya, ini adalah efek memulai BBR pada video. <br><br><img src="https://habrastorage.org/webt/hy/h8/dh/hyh8dhiugrgtyl6vgaozjzitnxq.jpeg"><br><br>  Kami berhasil meningkatkan kedalaman tampilan secara serius.  Google mengatakan mereka memiliki sekitar 10% lebih sedikit buffering pada pemain saat menggunakan BBR. <br><br>  Hebat, tapi bagaimana dengan pelanggan kami? <br><br><img src="https://habrastorage.org/webt/np/m1/uy/npm1uywvt78qoudkof3mkebqrj8.jpeg"><br><br>  Klien agak lambat, mereka semua memiliki Cubic, dan Anda tidak dapat mempengaruhinya.  Tapi tidak apa-apa, kadang-kadang Anda bisa memparalelkan data, dan itu akan baik. <br><br>  <strong>Kesimpulan tentang kontrol kemacetan:</strong> <br><br><ul><li>  BBR selalu bagus untuk video. </li><li>  Dalam kasus lain, jika kami menggunakan protokol UDP kami sendiri, Anda dapat mengambil kendali kemacetan dengan Anda. </li><li>  Dari sudut pandang TCP, Anda hanya dapat menggunakan kontrol kemacetan, yang ada di kernel.  Jika Anda ingin menerapkan kontrol kemacetan Anda ke dalam kernel, Anda harus mematuhi spesifikasi TCP.  Tidak mungkin untuk mengembang pengakuan, untuk membuat perubahan, karena mereka tidak ada di klien. </li></ul><br><blockquote>  Jika Anda membuat protokol UDP, Anda memiliki lebih banyak kebebasan dalam hal kontrol kemacetan. </blockquote><br><h3>  Multiplexing dan Prioritas </h3><br>  Ini adalah tren baru, semua orang melakukannya sekarang.  Ada masalah apa?  Jika kita menggunakan TCP, pasti semua orang (atau hampir semua orang) tahu situasi pemblokiran head-of-line. <br><br><img src="https://habrastorage.org/webt/zv/rt/6t/zvrt6t3igpnzn4vea3lgdw7vb1e.jpeg"><br><br>  Ada beberapa permintaan yang multiplexing melalui koneksi TCP tunggal.  Kami mengirim mereka ke jaringan, tetapi beberapa paket hilang.  Sambungan TCP akan mentransmisikan ulang paket ini, akan mengirimkan kembali dalam waktu dekat dengan RTT atau lebih.  Saat ini, kami tidak akan bisa mendapatkan apa pun, meskipun buffer TCP berisi data dari permintaan lain yang sepenuhnya siap untuk diambil. <br><br><blockquote>  Ternyata multiplexing melalui TCP, jika Anda menggunakan HTTP 2.0, tidak selalu efektif pada jaringan yang buruk. </blockquote><br>  Masalah selanjutnya adalah pembengkakan buffer. <br><br><img src="https://habrastorage.org/webt/fy/zh/rw/fyzhrwlr4mmtdgxwhp-mxfa9k-y.jpeg"><br><br>  Ketika gambar dikirim ke klien, buffer meningkat.  Kami mengirimnya untuk waktu yang lama, dan kemudian permintaan API muncul, dan itu tidak dapat diprioritaskan.  Dalam kasus seperti itu, penentuan prioritas TCP tidak berfungsi. <br><br>  Jadi, jika packet loss terjadi, ada pemblokiran head-of-Line, dan ketika klien memiliki bitrate variabel (dan ini sering terjadi pada klien seluler), efek bufferbloat muncul.  Akibatnya, tidak multiplexing, atau prioritisasi, atau server push, atau segala sesuatu yang lain, karena kami memiliki buffer atau klien mengharapkan sesuatu. <br><br>  Jika kita melakukan multiplexing sendiri, maka kita bisa meletakkan berbagai data di sana. <br><br><img src="https://habrastorage.org/webt/_g/er/5g/_ger5gqpdxllo3-p1eo7ytzupce.jpeg"><br><br>  Ini tidak sulit, cukup tambahkan paket dengan nomor ke buffer.  On-the-fly - jangan menyentuh apa yang sudah dikirim, tetapi apa yang belum terkirim dapat diatur ulang.  Ini terlihat seperti ini. <br><br><img src="https://habrastorage.org/webt/9g/_v/xr/9g_vxrrlkavxucnmocy3kggc-f8.jpeg"><br><br>  Mereka mengirim gambar, memecahnya menjadi paket, datang permintaan API prioritas: mereka memasukkannya, mengirim gambar.  Bahkan jika suatu paket hilang, kita bisa mendapatkan permintaan API yang sudah jadi dari buffer, itu adalah prioritas tinggi dan akan dengan cepat menjangkau klien.  Dalam TCP, menurut definisi, streaming transfer data tidak dimungkinkan. <br><br><h3>  Buat koneksi </h3><br>  Jika kita profil aplikasi kita, kita akan melihat bahwa sebagian besar waktu jaringan menganggur pada awal aplikasi, karena koneksi pertama kali dibuat sebelum API, maka kita mendapatkan data, kemudian koneksi dibuat sebelum gambar, data ini diunduh, dll.  Ini selalu terjadi - jaringan digunakan oleh puncak. <br><br><img src="https://habrastorage.org/webt/14/cn/ck/14cnckztbu1v-otwf__j9dqzahu.jpeg"><br><br>  Untuk mengatasinya, mari kita lihat bagaimana koneksi dibuat. <br><br><img src="https://habrastorage.org/webt/ca/eb/ij/caebijcqzlqj0h5soblnfudqedo.jpeg"><br><br>  Yang pertama adalah menyelesaikan DNS - kami tidak dapat melakukan apa pun dengan ini.  Selanjutnya, buat koneksi TCP, buat koneksi aman, lalu jalankan permintaan dan terima respons.  Yang paling menarik adalah bagian dari pekerjaan yang server lakukan ketika menanggapi permintaan biasanya membutuhkan waktu lebih sedikit daripada membangun koneksi. <br><br>  Sekarang sangat modis untuk mengukur angka latensi untuk memori, untuk disk, untuk hal lain.  Anda dapat mengukurnya untuk jaringan 3G, 4G dan melihat berapa lama yang dibutuhkan untuk membuat koneksi TCP dengan TLS. <br><br><img src="https://habrastorage.org/webt/qe/ux/1p/qeux1p7brp9mvpxeptinhubywmc.jpeg"><br><br>  Dan itu bisa beberapa detik!  Bahkan pada 4G hingga 700 ms juga signifikan.  Tapi TCP tidak bisa hidup dengan mudah selama ini. <br><br>  Koneksi didasarkan pada algoritma <strong>handshake TCP 3-way</strong> dasar.  Lakukan syn, syn + ack, lalu perbaiki permintaan nanti (di sebelah kiri dalam diagram). <br><br><img src="https://habrastorage.org/webt/ty/mj/-a/tymj-amfsa1c4j8sirtaspnvq1o.jpeg"><br><br>  Ada <strong>TCP Fast Open</strong> (kanan).  Jika Anda sudah berjabat tangan dengan server ini, ada cookie, Anda dapat segera mengirim permintaan Anda untuk zero-RTT.  Untuk menggunakan ini, Anda perlu membuat socket, membuat sendto () data pertama, katakan bahwa Anda ingin FASTOPEN. <br><br><img src="https://habrastorage.org/webt/ab/kl/b9/abklb93dq3g__tw2rihxrhagkl8.jpeg"><br><br>  Nginx dapat melakukan semua ini - cukup nyalakan, semuanya akan bekerja (atau nyalakan di kernel). <br><br><h2>  TLS </h2><br>  Mari kita periksa apakah TLS itu buruk. <br><br>  Saya mengatur pembentuk bersih lagi untuk 200 ms, ping google.com dan melihat bahwa RTT = 220 adalah pembentuk RTT + RTT saya.  Lalu saya membuat permintaan melalui HTTP dan HTTPS.  Saya menemukan bahwa melalui HTTP dimungkinkan untuk mendapatkan respons selama RTT, yaitu, TFO berfungsi untuk Google dari komputer saya.  Untuk HTTPS, ini butuh waktu lebih lama. <br><br><img src="https://habrastorage.org/webt/po/hl/kj/pohlkjs39dl7kk3rp5kzbxrwsna.jpeg"><br><br>  Ini adalah overhead TLS yang umum yang membutuhkan pengiriman pesan untuk membuat koneksi yang aman. <br><br><img src="https://habrastorage.org/webt/zf/j2/qn/zfj2qndcohpiok8cqpc82kiun3s.jpeg"><br><br>  Untuk melakukan ini, mereka berpikir untuk kita, menambahkan TLS 1.3.  Juga mudah dimasukkan ke dalam nginx. <br><br><img src="https://habrastorage.org/webt/m5/eo/i0/m5eoi0z5a2rzb4hthqlbjchxhyi.jpeg"><br><br>  Segalanya tampak bekerja.  Tapi mari kita lihat apa yang ada di klien seluler kami yang memanfaatkan semua ini. <br><br><h3>  Ada apa dengan pelanggan </h3><br>  TCP Fast Open adalah hal yang keren.  Menurut statistik. <br><br><img src="https://habrastorage.org/webt/pq/yy/l8/pqyyl89jhtoulpwalg61q8pqbnw.jpeg"><br><br>  Ada banyak artikel yang mengatakan bahwa membangun koneksi dijamin lulus 10% lebih cepat.  Tetapi pada Android 8.1.0 (saya menonton berbagai perangkat) tidak ada yang memiliki TFO.  Di Android 9, saya melihat TFO pada emulator, tetapi tidak pada perangkat nyata.  IOS sedikit lebih baik.  Di sini Anda bisa melihatnya: <br><br><pre><code class="plaintext hljs">sysctl -a | grep fast net.ipv4.tcp_fastopen = 0</code> </pre> <br>  Mengapa ini terjadi?  TCP Fast Open diusulkan kembali pada tahun 2014, sekarang sudah standar, didukung di Linux dan semuanya hebat.  Tetapi ada masalah sehingga jabat tangan TFO mulai berantakan di beberapa jaringan.  Ini karena beberapa penyedia (atau beberapa perangkat) digunakan untuk memeriksa TCP, melakukan optimasi mereka, dan tidak berharap bahwa akan ada jabat tangan TFO.  Oleh karena itu, implementasinya membutuhkan banyak waktu, dan sampai sekarang, klien seluler tidak memasukkannya secara default, setidaknya Android. <br><br>  Dengan TLS 1.3, yang menjanjikan kita pengaturan koneksi zero-RTT bahkan lebih baik.  Saya tidak menemukan perangkat Android yang akan berfungsi.  Oleh karena itu, Facebook membuat perpustakaan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Fizz</a> .  Beberapa bulan yang lalu, itu menjadi tersedia di open source, Anda dapat menyeretnya dengan Anda dan menggunakan TLS 1.3.  Ternyata bahkan keamanan harus diseret, tidak ada yang muncul dalam inti dari ini. <br><br><img src="https://habrastorage.org/webt/07/qm/kf/07qmkfwywo3llz5nrrh04kg3a_o.jpeg"><br><br>  Diagram menunjukkan penggunaan berbagai versi Android oleh klien seluler kami.  V 9.x cukup sedikit - di mana TFO dapat muncul, dan TLS1.3 tidak ditemukan di tempat lain. <br><br>  <strong>Kesimpulan tentang membangun koneksi:</strong> <br><br><ul><li>  TFO tidak tersedia untuk 95% perangkat. </li><li>  TLS1.3 perlu dibawa sendiri. </li><li>  Jika Anda perlu mengulang ini di UDP, maka transfer semua ini ke UDP dan ulangi. </li></ul><br><img src="https://habrastorage.org/webt/n2/tj/v1/n2tjv1g-04l2jfghy_6--uqaqjc.jpeg"><br><br>  Ternyata 97% dari koneksi yang dibuat menggunakan kunci yang ada, yaitu, 97% dibuat untuk nol RTT, dan hanya 3% yang baru.  Kunci disimpan pada perangkat untuk beberapa waktu. <br><br>  TCP tidak dapat menyombongkannya.  Dalam maksimal 5% kasus, jika Anda melakukan semuanya dengan benar, Anda akan bisa mendapatkan nol-RTT nyata yang dibicarakan semua orang sekarang. <br><br><h2>  Perubahan alamat IP </h2><br>  Seringkali, ketika Anda meninggalkan rumah, ponsel Anda beralih dari Wi-Fi ke 4G. <br><br><blockquote>  TCP berfungsi seperti ini: alamat IP telah berubah - koneksi gagal. </blockquote><br><img src="https://habrastorage.org/webt/km/nu/u8/kmnuu8dtr8jeipuzx4bhpfezuwm.jpeg"><br><br>  Jika Anda menulis protokol UDP Anda, ini sangat sederhana, dengan menerapkan ID koneksi (CUID) di setiap paket, Anda dapat mengidentifikasinya, bahkan jika itu berasal dari alamat IP yang berbeda. <br><br><img src="https://habrastorage.org/webt/xu/ga/r_/xugar_l9pbltv6419btnrimfhv8.jpeg"><br><br>  Jelas bahwa Anda perlu memastikan bahwa ia memiliki kunci yang benar, semuanya didekripsi, dll.  Tetapi pada prinsipnya, Anda dapat mulai menanggapi alamat ini, tidak akan ada masalah dengan ini. <br><br><blockquote>  Dalam TCP, Migrasi IP adalah hal yang mustahil. </blockquote><br>  Jika Anda membuat UDP Anda, dan Anda datang ke server yang sama, Anda perlu melakukan sedikit keajaiban, memasukkan CID di setiap paket, dan Anda akan dapat menggunakan koneksi yang telah dibuat saat mengubah alamat IP. <br><br><h2>  Koneksi ulang </h2><br>  Semua orang mengatakan Anda perlu menggunakan kembali koneksi karena koneksi adalah hal yang sangat mahal. <br><br><img src="https://habrastorage.org/webt/8-/lr/ot/8-lrot44ac9mwo6m7ue_ksezk0g.jpeg"><br><br>  Tetapi ada jebakan dalam menggunakan kembali senyawa. <br><br><img src="https://habrastorage.org/webt/_n/aa/z3/_naaz3uac-hwdd7uikndioiupry.jpeg"><br><br>  Kemungkinan besar, banyak orang ingat (jika tidak, lihat di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> ) bahwa tidak semua orang memiliki alamat publik, tetapi ada NAT, yang biasanya menyimpan pemetaan untuk beberapa waktu di router rumah.  Untuk TCP, jelas berapa banyak yang harus disimpan, tetapi untuk UDP tidak jelas.  NAT beroperasi pada batas waktu, jika Anda mengukur batas waktu ini dengan hati-hati, kami mendapatkan bahwa dalam sekitar 15-30 detik lebih dari 50% koneksi akan mulai gagal. <br><br>  Tidak apa-apa - kami akan membuat paket ping-pong selama 15 detik.  Untuk kasus ketika koneksi masih terputus, ada Migrasi IP, yang murah memungkinkan Anda untuk mengubah port pada router. <br><br><img src="https://habrastorage.org/webt/7g/mu/bf/7gmubflfj-yenwqvgiqbkc8toa8.jpeg"><br><br><h2>  Paket mondar-mandir </h2><br>  Ini adalah hal yang sangat penting jika Anda melakukan protokol UDP Anda. <br><br><img src="https://habrastorage.org/webt/cf/d5/97/cfd597jt4v7uopygyyu-dfsx_8s.jpeg"><br><br>  Jika sangat sederhana, semakin lama Anda terus mengirim paket ke jaringan, semakin besar kemungkinan hilangnya paket.  Jika Anda memfilter paket, maka packet loss akan lebih rendah. <br><br>  Ada banyak teori berbeda tentang bagaimana ini bekerja, tetapi saya suka yang ini. <br><br><img src="https://habrastorage.org/webt/75/79/xl/7579xlvo70vmotoqjjp3zmmplr8.jpeg"><br><br>  Ada 3 koneksi yang dibuat sekaligus.  Anda memiliki jendela awal yang disebut - 10 paket yang dibuat pada saat yang sama.  Tentu saja, bandwidth mungkin tidak cukup pada saat ini.  Tetapi jika Anda hati-hati mendistribusikannya, pisahkan, maka semuanya akan baik-baik saja, seperti pada gambar yang tepat. <br><br>  Dengan demikian, jika Anda menetapkan tingkat seragam untuk mengirim paket, menipiskannya, maka probabilitas bahwa akan ada buffer overflow satu kali menjadi lebih rendah.  Ini tidak terbukti, tetapi secara teori ternyata seperti ini. <br><br><img src="https://habrastorage.org/webt/vw/mg/vw/vwmgvw6oyq3v_yaliklp4ilnocm.jpeg"><br><br>  Saat Anda perlu memotong paket (lakukan mondar-mandir): <br><br><ul><li>  Saat Anda membuat jendela. </li><li>  Ketika Anda memperbesar jendela, misalnya, disarankan untuk menambahkan paket sebanyak yang dapat dikirim untuk RTT / 2.  Ini tidak akan menurunkan waktu pengiriman, tetapi mengurangi kehilangan paket. </li><li>  Dalam kasus kehilangan kemacetan, untuk mengurangi jendela Anda perlu mengolesi paket lebih banyak lagi.  4/5 RTT adalah sosok yang dipilih secara empiris. </li></ul><br><h2>  MTU </h2><br>  Saat menulis protokol UDP Anda, pastikan untuk mengingat tentang MTU.  MTU adalah ukuran data yang dapat Anda teruskan. <br><br><img src="https://habrastorage.org/webt/c2/7_/ow/c27_ow36h5amg3d4zkskjph_ama.jpeg"><br><br>  Kami mengirim paket dari server ke klien, misalnya, dengan ukuran 1500. Jika ada router di jalur yang tidak mendukung ukuran MTU ini, itu akan memecahnya.  Satu-satunya masalah fragmentasi adalah bahwa jika satu paket hilang, keduanya akan hilang, dan semua ini harus ditransmisikan ulang.  Oleh karena itu, TCP memiliki algoritma untuk menentukan MTU - PMTU. <br><br><img src="https://habrastorage.org/webt/je/gs/ks/jegskszkwrb3pm2nghgfpplez8o.jpeg"><br><br>  Setiap router melihat MTU antarmuka-nya, mengirimkannya ke satu klien, yang lain mengirimkannya ke kliennya, semua orang tahu berapa banyak MTU yang mereka miliki di klien.  Kemudian fragmentasi dilarang oleh bendera dan paket ukuran MTU dikirim.  Jika saat ini seseorang di dalam jaringan menyadari bahwa ia memiliki lebih sedikit MTU, maka melalui ICMP ia akan berkata: "Maaf, paket itu hilang karena fragmentasi diperlukan" dan menunjukkan ukuran MTU.  Kami akan mengubah ukuran ini dan melanjutkan pengiriman.  Dalam kasus terburuk, overhead kecil kami adalah RTT / 2.  Ini dalam TCP. <br><br><img src="https://habrastorage.org/webt/vl/br/fo/vlbrfo8a7p80neysmtjguosakww.jpeg"><br><br>  Jika di UDP Anda tidak ingin repot dengan ICMP, maka Anda dapat melakukan hal berikut: izinkan fragmentasi saat mengirim data normal.  Yaitu, untuk mengirim paket terfragmentasi - biarkan mereka bekerja.  Dan secara paralel untuk memulai proses yang melarang fragmentasi, pencarian biner akan memilih MTU optimal, yang kemudian akan kita buka.  Ini tidak sepenuhnya efektif, karena pada awalnya MTU akan terasa hangat. <br><br>  Opsi yang lebih rumit adalah melihat distribusi MTU di antara klien seluler. <br><br><img src="https://habrastorage.org/webt/ie/a5/w8/iea5w8h3msrkprfxpgfhb2nkjyu.jpeg"><br><br>  Dari semua klien, kami mengirim paket dengan berbagai ukuran dengan larangan fragmentasi.  Artinya, jika paket tidak mencapai, itu akan turun, dan MTU terkecil harus mencapai 100%.  Tetapi ada paket kecil yang hilang, jadi ada dua slide pada grafik: <br><br><ol><li>  1350 byte - alih-alih 98%, kami mendapatkan pengiriman 95% segera. </li><li>  1500 byte - MTU, setelah itu sudah 80% klien tidak akan menerima paket seperti itu. </li></ol><br><blockquote>  Bahkan, kita dapat mengatakan ini: kita mengabaikan 1-2% dari pelanggan kita, membiarkan mereka hidup dengan paket yang terfragmentasi.  Tetapi kita akan segera mulai dari apa yang kita butuhkan - ini dari 1350. </blockquote><br><h2>  Koreksi kesalahan (SACK, NACK, FEC) </h2><br>  Jika Anda membuat protokol, Anda perlu memperbaiki kesalahan.  Jika paket tidak ada (ini normal untuk jaringan nirkabel), itu perlu dipulihkan. <br><br>  Dalam kasus paling sederhana (lebih detail di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> ), ada relay melalui Retransmit Time Out (RTO).  Jika paket tidak ada, tunggu waktu pengiriman ulang dan kirim lagi. <br><br>  Algoritma selanjutnya adalah <b>Fast retransmit</b> .  Ini semua adalah algoritma TCP, tetapi mereka dapat dengan mudah dipindahkan ke UDP. <br><br><img src="https://habrastorage.org/webt/hm/s1/ee/hms1eey-ntpj2x0piswhxc4e5fa.jpeg"><br><br>  Ketika paket hilang, kami terus mengirim - ada pengiriman paket lain.  Pada saat ini, server mengatakan bahwa ia menerima paket berikutnya, tetapi tidak ada yang sebelumnya.  Untuk melakukan ini, ia membuat pernyataan yang rumit, yang sama dengan nomor paket +1, dan menetapkan flag ack duplikat.  Dia mengirim dup ack demikian, dan pada yang ketiga kita biasanya mengerti bahwa paket telah hilang dan mengirimkannya kembali. <br><br>  Apa lagi yang ingin Anda lakukan berkelas, apa yang tidak ada dalam TCP dan apa yang mereka usulkan untuk dilakukan di UDP adalah <b>Forward Error Correction</b> . <br><br><img src="https://habrastorage.org/webt/ex/_u/gg/ex_uggyt0-4ntdgzy-vn7hvmyzg.jpeg"><br><br>  Tampaknya jika kita tahu bahwa paket mungkin hilang, kita dapat mengambil satu set paket, menambahkan paket XOR ke dalamnya dan memperbaiki masalah tanpa transmisi ulang tambahan segera pada klien saat menerima data.  Tetapi ada masalah jika beberapa paket hilang.  Tampaknya itu bisa diselesaikan melalui perlindungan paritas, Reed-Solomon, dll. <br><br>  Kami mencobanya dengan cara ini, ternyata ternyata paket-paket itu menghilang dalam bundel. <br><br><img src="https://habrastorage.org/webt/fg/qo/jj/fgqojj1gas9pgutyyyzkla_m5ze.jpeg"><br><br>  Kesenjangan paket rata-rata menjadi 6. Ini adalah celah paket yang sangat tidak nyaman - Anda memerlukan banyak kode koreksi kesalahan.  Pada saat yang sama, ada semacam puncak di 11 - saya tidak tahu mengapa, tetapi paket-paket kadang-kadang menghilang dalam paket 11.  Karena celah paket ini, ini tidak berfungsi. <br><br>  Google juga mencoba ini, semua orang memimpikan FEC, tetapi sejauh ini belum ada yang berhasil. <br><br>  Ada opsi lain ketika FEC dapat membantu. <br><br><img src="https://habrastorage.org/webt/d9/tb/tw/d9tbtwafxbt_t08_j9wvarw5icc.jpeg"><br><br>  Selain mentransmisikan kembali melalui Retransmit Time Out, Fast Retransmit, ada juga <strong>probe kehilangan ekor</strong> .  Ini adalah hal seperti itu ketika Anda mengirim data, dan ekornya hilang.  Artinya, Anda mengirim bagian dari data, mengirim paket kelima - sudah tiba.  Kemudian paket-paket mulai menghilang, misalnya, karena jaringan gagal.  Paket hilang, menghilang, dan Anda menerima pemberitahuan hanya untuk paket kelima. <br><br>  Untuk memahami apakah data ini telah mencapai, setelah beberapa saat Anda mulai melakukan TLP (probe kehilangan ekor), tanyakan apakah akhirnya diterima.  Faktanya adalah bahwa transfer data telah berakhir, dan Anda tidak mengirim apa pun, maka Fast Retransmit tidak akan berfungsi.  Untuk mengatasinya, lakukan TLP. <br><br>  Anda dapat menambahkan FEC ke TLP.  Anda dapat melihat semua paket yang tidak datang, menghitung paritasnya dan mengirim TLP dengan beberapa paket paritas. <br><br>  Ini semua keren, sepertinya berhasil.  Tapi ada masalah seperti itu. <br><br><img src="https://habrastorage.org/webt/pt/y5/qm/pty5qmye2nqwrocxnp3fv5-gll4.jpeg"><br><br>  Kami mengumpulkan statistik, dan ternyata 98% kesalahan diperbaiki melalui Fast Retransmit.  Sisanya diperbaiki melalui Retransmit Time Out, dan kurang dari 1% melalui TLP.  Jika Anda memperbaiki sesuatu yang lain FEC, itu akan kurang dari 0,5%. <br><br><blockquote>  TCP tidak mendukung FEC.  Dalam UDP tidak sulit untuk melakukan ini, tetapi dalam kasus umum, algoritma pemulihan TCP standar sudah cukup. </blockquote><br><h2>  Performa </h2><br>  Adalah mungkin untuk tidak merusak kinerja dengan membandingkan TCP dengan UDP. <br><br>  TCP adalah protokol yang sangat lama dengan banyak optimasi yang berbeda, misalnya, LSO (big segment offload) dan zerocopy.  Sekarang untuk UDP semuanya tidak tersedia.  Oleh karena itu, kinerja UDP hanya 20% relatif terhadap TCP dari server yang sama.  Tetapi sudah ada solusi siap pakai ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">UDP GSO</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">zerocopy</a> ) yang memungkinkan Linux mendukung hal ini. <br><br>  Masalah utama yang mendukung pengoptimalan untuk zerocopy dan LSO adalah bahwa pacing hilang. <br><br><img src="https://habrastorage.org/webt/qu/6i/th/qu6ith66mowy_jm9iznjsstsadm.jpeg"><br><br><h2>  Waktu ke pasar atau apa yang membunuh TCP </h2><br>  Baru-baru ini, ketika jaringan nirkabel seluler menjadi populer, banyak standar TCP yang berbeda muncul: TLP, TFO, kontrol Congestion baru, RACK, BBR dan banyak lagi. <br><br><img src="https://habrastorage.org/webt/nq/lx/5a/nqlx5a_sq5zzvi2au81ulptczew.jpeg"><br><br><blockquote>  Tetapi masalah utama adalah banyak dari mereka tidak diimplementasikan, karena TCP dikatakan keras.  Dalam banyak kasus, operator melihat paket TCP dan berharap dapat melihat apa yang mereka harapkan.  Karena itu, sangat sulit untuk berubah. </blockquote><br>  Selain itu, klien seluler diperbarui untuk waktu yang lama, dan kami tidak dapat mengirimkan pembaruan ini.  Jika Anda melihat pembaruan terbaru apa saja yang tersedia di klien, dan apa yang ada di server, Anda dapat mengatakan bahwa hampir tidak ada apa-apa di klien. <br><br><img src="https://habrastorage.org/webt/au/57/iw/au57iwnkvrjzkvrpo2osdo7f49e.jpeg"><br><br>  Oleh karena itu, keputusan untuk menulis protokol di ruang pengguna, setidaknya selama Anda mengakumulasikan semua fitur ini, sepertinya tidak terlalu buruk. <br><br><img src="https://habrastorage.org/webt/6i/o6/po/6io6poew2qopzofy3vbflm3-5a8.jpeg"><br><br>  Dengan TCP, fitur telah bergulir selama bertahun-tahun.  Untuk protokol UDP Anda, Anda dapat memutakhirkan versi secara harfiah dalam satu pembaruan klien dan server.  Tetapi Anda perlu menambahkan versi negosiasi. <br><br><h2>  TCP vs UDP buatan sendiri.  Pertarungan terakhir </h2><br><img src="https://habrastorage.org/webt/fx/q6/ct/fxq6ctnz94vaf7pfr7jmrcbz7lu.jpeg"><br><br><ul><li>  Send / recv buffer: buffer yang dapat diubah dapat dilakukan untuk protokol Anda, akan ada masalah dengan buffer bloat dengan TCP. </li><li>  Kontrol kemacetan bisa Anda gunakan yang sudah ada.  Di UDP mereka ada. </li><li>  Kontrol Congestion yang baru sulit untuk ditambahkan ke TCP, karena Anda perlu memodifikasi pengakuan, Anda tidak bisa melakukan ini pada klien. </li><li>  Multiplexing adalah masalah kritis.  Pemblokiran head-of-line terjadi, ketika Anda kehilangan suatu paket, Anda tidak bisa multiplex ke TCP.  Oleh karena itu, HTTP2.0 over TCP seharusnya tidak memberikan peningkatan yang serius. </li><li>  Kasus ketika Anda bisa mendapatkan pengaturan koneksi untuk 0-RTT di TCP sangat jarang, dari urutan 5%, dan urutan 97% untuk UDP buatan sendiri. </li></ul><br><img src="https://habrastorage.org/webt/4f/_f/oe/4f_foen6zvxf5mexl8p6jfu2izm.jpeg"><br><br><ul><li>  Migrasi IP bukanlah fitur yang begitu penting, tetapi dalam kasus langganan yang rumit dan status penyimpanan di server, itu pasti diperlukan, tetapi tidak diimplementasikan dalam TCP. </li><li>  Nat unbinding tidak mendukung UDP.  Dalam hal ini, UDP sering perlu melakukan paket ping-pong. </li><li>  Paket pacing di UDP sederhana, sementara tidak ada optimasi, di TCP opsi ini tidak berfungsi. </li><li>  MTU dan koreksi kesalahan keduanya sebanding. </li><li>  Kecepatan TCP, tentu saja, lebih cepat daripada UDP sekarang, jika Anda mendistribusikan banyak lalu lintas.  Tetapi beberapa optimasi membutuhkan waktu yang sangat lama untuk dicapai. </li></ul><br>  Jika Anda mengumpulkan semua yang paling penting, maka UDP, lebih mungkin, memiliki lebih banyak pro daripada kontra. <br><br><img src="https://habrastorage.org/webt/p4/7k/ys/p47kysilkuqtb-x-zc0cwhigeoe.jpeg"><br><br>  <b>Pilih UDP!</b> <br><br><h2>  Menguji UDP buatan sendiri pada pengguna </h2><br>  Kami telah mengumpulkan bangku tes. <br><br><img src="https://habrastorage.org/webt/rh/er/ec/rherec8kewip9-ycek5qimdgvuw.jpeg"><br><br>  Ada klien di TCP dan UDP.  Kami menormalkan lalu lintas melalui pembentuk bersih, dikirim ke Internet dan ke server.  Satu layanan REST API, yang kedua dengan UDP.  Dan UDP pergi ke REST API yang sama di dalam pusat data yang sama untuk memeriksa data.  Kami mengumpulkan berbagai profil klien seluler kami dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">meluncurkan tes</a> . <br><br><img src="https://habrastorage.org/webt/sy/rf/nf/syrfnflhcgpr13bngr1y7cv5fle.jpeg"><br><br>  Mengukur rata-rata di atas portal, kami melihat bahwa kami dapat mengurangi waktu memanggil API sebesar 10%, gambar sebesar 7%.  Aktivitas pengguna hanya tumbuh 1%, tapi kami tidak menyerah, kami pikir itu akan lebih baik. <br><br><img src="https://habrastorage.org/webt/o9/wr/bj/o9wrbjk45dk58yjji6t8boe9-xw.jpeg"><br><br>  Dalam hal beban, kami sekarang memiliki sekitar 10 juta pengguna di UDP buatan kami sendiri, lalu lintas hingga 80 Gb / s, 6 juta paket per detik dan 20 server semuanya melayani ini. <br><br><h2>  Daftar periksa UDP <br></h2><br>  Jika Anda akan menulis protokol Anda, Anda perlu daftar periksa: <br><br><ul><li>  Mondar-mandir </li><li>  Penemuan MTU. </li><li>  <strong>Diperlukan perbaikan bug</strong> . </li><li>  Kontrol aliran dan kontrol kemacetan. </li><li>  Secara opsional Anda dapat mendukung Migrasi IP, TLP mudah. </li></ul><br>  Ingatlah bahwa salurannya asimetris, dan saat Anda menerima data dari server, unggahan Anda mungkin menganggur, coba gunakan. <br><br><h2>  QUIC </h2><br>  Tidak jujur â€‹â€‹mengatakan bahwa Google tidak melakukannya. <br><br><img src="https://habrastorage.org/webt/z0/b9/-v/z0b9-v9kmmobln4nv2yado-rble.jpeg"><br><br>  Ada protokol QUIC yang diterapkan Google di bawah HTTP 2.0, yang mendukung banyak hal yang sama. <br><br><h3>  Mengapa QUIC tidak begitu cepat </h3><br>  Ketika QUIC keluar, ada banyak kebencian tentang fakta bahwa Google mengatakan bahwa semuanya bekerja lebih cepat, dan "Saya mengukurnya di rumah menggunakan komputer - kerjanya lebih lambat." <br><br><img src="https://habrastorage.org/webt/db/5a/vd/db5avdtu1zaito8ntcmg-hdvwy8.jpeg"><br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Artikel</a> ini <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">memiliki</a> banyak gambar dan pengukuran. <br><br>  Nah, ternyata kita melakukan semua ini dengan sia-sia, apakah orang mengukur untuk kita?  Ada pengukuran rumah nyata, bahkan dengan contoh kode. <br><br><img src="https://habrastorage.org/webt/id/wr/39/idwr39saesks74hbadevlunieua.jpeg"><br><br>  Bahkan, tidak akan ada peningkatan sampai Anda memaralelkan permintaan, bekerja di jaringan nyata, dan sampai paket hilang dibagi menjadi kehilangan kemacetan dan kehilangan acak.  Kita membutuhkan persaingan nyata dari jaringan nyata. <br><br>  Tetapi ada yang positif, kata mereka, QUIC tidak lebih baik atau lebih buruk.  Dengan demikian, dalam jaringan yang sempurna, QUIC berfungsi dengan baik. <br><br><h2>  Masa depan </h2><br>  Google baru-baru ini menamai HTTP 2.0 di atas QUIC HTTP 3, jangan bingung, karena HTTP 2.0 bisa di atas TCP dan di atas QUIC.  Sekarang HTTP 3. <br><br><img src="https://habrastorage.org/webt/go/ra/z4/goraz4ktgsje7ankwyipapzeow0.jpeg"><br><br>  Ada juga <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Google QUIC</a> - ini QUIC, yang diterapkan di Chrome, dan iQUIC - QUIC standar.  QUIC terstandarisasi tidak diterapkan di mana pun, server iQUIC standar tidak berjabat tangan dengan Google QUIC.  Sekarang mereka berjanji untuk menyelesaikan masalah ini, dan segera akan tersedia. <br><br><h3>  QUIC ada di mana-mana </h3><br>  Jika Anda masih tidak percaya bahwa TCP sudah mati, maka saya akan memberi tahu Anda bahwa ketika Anda menggunakan Chrome, Android, dan segera iOS, dan pergi ke google, youtube dan sebagainya, maka Anda menggunakan QUIC dan UDP ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">prooflink</a> ). <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">QUIC sekarang</a> adalah: <br><br><ul><li>  1,9% dari semua situs web; </li><li>  12% dari semua lalu lintas; </li><li>  30% dari lalu lintas video di jaringan seluler. </li></ul><br>  Bagaimana cara memeriksa bahwa Anda menggunakan QUIC jika Anda tidak percaya?  Buka di Chrome Wireshark.  Saya mencari iQUIC, saya belum menemukannya di mana pun, tetapi GQUIC terjadi. <br><br><img src="https://habrastorage.org/webt/t_/8v/9q/t_8v9qsq9jcgbjkf9vqqr67vw7k.jpeg"><br><br>  Anda juga dapat online di browser Anda dan juga melihat apa yang ada di GQUIC. <br><br><img src="https://habrastorage.org/webt/av/ko/p5/avkop5nphmxm6ee3rqc2hi23wzu.jpeg"><br><br><h3>  Beberapa lagi masa depan </h3><br>  Multipath menunggu kita segera. <br><br><img src="https://habrastorage.org/webt/d8/bi/wo/d8biwobqjbdjqdn8g-wb7gegka0.jpeg"><br><br>  Saat Anda memiliki klien seluler yang memiliki Wi-Fi dan 3G, Anda dapat menggunakan kedua saluran.  Multipath TCP sekarang dalam pengembangan dan akan segera tersedia di kernel Linux.  Jelas, itu tidak akan menjangkau pelanggan segera, saya pikir itu bisa dilakukan pada UDP lebih cepat. <br><br><img src="https://habrastorage.org/webt/pb/7o/yt/pb7oytnkrhutg6qtqlwq0jf3p4o.jpeg"><br><br>  Karena kami melakukan banyak terjemahan masing-masing 3 TB, kami sangat sering menggunakan teknologi seperti distribusi CDN dan p2p, ketika konten yang sama perlu dikirim ke banyak pengguna di seluruh dunia. <br><br>  Di IPv6 ada multicast dengan UDP, yang akan memungkinkan pengiriman paket ke beberapa pengguna yang berlangganan sekaligus.  Oleh karena itu, saya berpikir bahwa teknologi CDN dan p2p tidak akan dibutuhkan dalam waktu dekat jika kami mengirimkan semua konten menggunakan multicast ke IPv6. <br><br><h2>  Kesimpulan </h2><br>  Saya harap Anda mengerti: <br><br><ul><li>  Bagaimana jaringan benar-benar bekerja, dan TCP dapat diulangi melalui UDP dan dilakukan dengan lebih baik. </li><li>  TCP itu tidak terlalu buruk jika Anda mengkonfigurasinya dengan benar, tetapi itu benar-benar menyerah dan hampir tidak lagi berkembang. </li><li>  Jangan percaya pembenci UDP yang mengatakan mereka tidak akan bekerja di ruang pengguna.  Semua masalah ini bisa diselesaikan.  Cobalah - ini adalah masa depan yang dekat. </li><li>  Jika Anda tidak percaya, maka Anda dapat dan harus menyentuh jaringan dengan tangan Anda.  Saya menunjukkan bagaimana hampir semuanya dapat diperiksa. </li></ul><br>  Anda membaca semuanya dan mencari tahu apa selanjutnya? <br><br><ul><li>  Konfigurasikan protokol (TCP, UDP - tidak masalah) untuk situasi (profil jaringan + memuat profil). </li><li>  Gunakan resep TCP yang saya katakan: TFO, kirim / terima penyangga, TLS1.3, CC ... </li><li>  Buat protokol UDP Anda jika Anda memiliki sumber daya. </li><li>  Jika Anda telah melakukan UDP, periksa daftar periksa UDP bahwa Anda telah melakukan semua yang Anda butuhkan.  Lupa omong kosong seperti mondar-mandir, itu tidak akan berhasil. </li></ul><br>  Jika Anda tidak memiliki sumber daya, siapkan infrastruktur Anda untuk QUIC.  Cepat atau lambat dia akan mendatangimu. <br><br><blockquote>  Kami menentukan masa depan.  Kami memutuskan protokol apa yang akan digunakan.  Jika Anda ingin menggunakan QUIC - gunakan, jika Anda ingin UDP atau tetap menggunakan TCP - putuskan sendiri di masa depan. </blockquote><br><h3>  Tautan yang bermanfaat </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Juta panggilan video per hari atau "Hubungi ibu!"</a>  . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kami sedang menulis protokol kami di atas UDP</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Podcast tentang pengoptimalan jaringan</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Meningkatkan kecepatan transfer data di jaringan yang buruk</a> . </li></ul><br><blockquote>  Hingga 7 September, Anda masih dapat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mengirimkan aplikasi</a> untuk Moscow <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HighLoad ++</a> dan membagikan bagaimana Anda mempersiapkan layanan Anda untuk beban tinggi.  Tetapi program ini secara bertahap telah diisi, dari laporan Odnoklassniki telah diterima pada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">arsitektur baru</a> grafik teman, tentang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mengoptimalkan layanan hadiah</a> untuk beban tinggi dan tentang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">apa yang harus dilakukan</a> jika Anda telah mengoptimalkan semuanya dan data tidak mencapai pengguna dengan cukup cepat. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id461829/">https://habr.com/ru/post/id461829/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id461817/index.html">CMake dan C ++ - saudara selamanya</a></li>
<li><a href="../id461819/index.html">Mengapa desain situs web sederhana lebih baik secara ilmiah</a></li>
<li><a href="../id461821/index.html">Imunoterapi baru menghilangkan semua tumor pada wanita dengan kanker payudara metastatik</a></li>
<li><a href="../id461823/index.html">Enhanced Four Rules untuk Desain Perangkat Lunak</a></li>
<li><a href="../id461827/index.html">Pengembangan Aplikasi PHP / Go Hibrid Menggunakan RoadRunner</a></li>
<li><a href="../id461831/index.html">StealthWatch: Penempatan dan Kustomisasi. Bagian 2</a></li>
<li><a href="../id461833/index.html">Jangan tersesat dalam tiga pinus: representasi lingkungan yang egosentris</a></li>
<li><a href="../id461835/index.html">Bagaimana Gantt Charts Menyederhanakan dan Memberdayakan Manajemen Proyek</a></li>
<li><a href="../id461841/index.html">PVS-Studio Melihat ke dalam Mesin Peluru Red Dead Redemption</a></li>
<li><a href="../id461845/index.html">Investasi di bursa sebagai cara untuk menjaga keuangan: 3 metode kerja</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
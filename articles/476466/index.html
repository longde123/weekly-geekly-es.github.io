<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßîüèø ‚ö°Ô∏è üåü El libro "Arquitectos de inteligencia" ü§• üìπ üï¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La Inteligencia Artificial (IA) se est√° moviendo r√°pidamente de la ciencia ficci√≥n a la vida cotidiana. Los dispositivos modernos reconocen el habla h...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>El libro "Arquitectos de inteligencia"</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/476466/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><img src="https://habrastorage.org/webt/mb/12/np/mb12npah994j7jq-gm2outusizg.jpeg" align="left" alt="imagen"></a>  La Inteligencia Artificial (IA) se est√° moviendo r√°pidamente de la ciencia ficci√≥n a la vida cotidiana.  Los dispositivos modernos reconocen el habla humana, pueden responder preguntas y realizar traducciones autom√°ticas.  En una variedad de √°reas, desde conducir un veh√≠culo no tripulado hasta diagnosticar c√°ncer, se utilizan algoritmos de reconocimiento de objetos basados ‚Äã‚Äãen IA que son superiores a las capacidades humanas.  Las grandes compa√±√≠as de medios utilizan el periodismo rob√≥tico para crear art√≠culos similares a los derechos de autor de los datos recopilados.  Obviamente, la IA est√° lista para convertirse en una tecnolog√≠a verdaderamente universal, como la electricidad. <br><br>  ¬øQu√© enfoques y tecnolog√≠as se consideran los m√°s prometedores?  ¬øQu√© grandes descubrimientos son posibles en los pr√≥ximos a√±os?  ¬øEs posible crear una m√°quina verdaderamente pensante o IA comparable a la humana, y qu√© tan pronto?  ¬øQu√© riesgos y amenazas est√°n asociados con la IA y c√≥mo evitarlos?  ¬øLa IA causar√° caos en la econom√≠a y el mercado laboral?  ¬øLas m√°quinas superinteligentes se saldr√°n del control humano y se convertir√°n en una amenaza real? <br><br>  Por supuesto, es imposible predecir el futuro.  Sin embargo, los expertos saben m√°s que nadie sobre el estado actual de la tecnolog√≠a, as√≠ como sobre las innovaciones en el futuro cercano.  Tendr√° reuniones brillantes con personas tan reconocidas como R. Kurzweil, D. Hassabis, J. Hinton, R. Brooks y muchos otros. <br><a name="habracut"></a><br><h3>  Yan Lekun </h3><br>  VICEPRESIDENTE Y FUNDADOR DEL LABORATORIO DE INVESTIGACI√ìN DE AI EN FACEBOOK (FERIA), PROFESOR DE CIENCIAS INFORM√ÅTICAS EN LA UNIVERSIDAD DE NUEVA YORK <br><br>  <i>Junto con Jeffrey Hinton y Joshua Benjio, Ian Lekun es parte de un grupo de investigadores cuyos esfuerzos y perseverancia han llevado a la revoluci√≥n actual en relaci√≥n con las redes neuronales y el aprendizaje profundo.</i>  <i>Mientras trabajaba en Bell Labs, invent√≥ las redes neuronales convolucionales.</i>  <i>Recibi√≥ un diploma de ingeniero el√©ctrico en Par√≠s de ESIEE, y un doctorado en ciencias de la computaci√≥n de la Universidad de Pierre y Marie Curie.</i>  <i>Despu√©s de graduarse, trabaj√≥ en el Laboratorio Jeffrey Hinton de la Universidad de Toronto.</i> <br><br>  <b>Martin Ford: ¬ø</b> La explosi√≥n de inter√©s en el aprendizaje profundo en los √∫ltimos 10 a√±os es una consecuencia de la mejora simult√°nea de las redes neuronales, el aumento de la potencia de las computadoras y la cantidad de datos disponibles? <br><br>  <b>Yang Lekun:</b> S√≠, pero el proceso fue m√°s deliberado.  Apareci√≥ en 1986‚Äì87.  El algoritmo de retropropagaci√≥n permiti√≥ entrenar redes neuronales multicapa.  Esto caus√≥ una ola de inter√©s que dur√≥ hasta 1995. En 2003, Jeffrey Hinton, Joshua Benggio y yo ideamos un plan para renovar el inter√©s de la comunidad en estos m√©todos porque confiaban en su inminente victoria.  Entonces podemos decir que hubo una conspiraci√≥n deliberada. <br><br>  <b>M.F .:</b> ¬øYa entendiste todas las perspectivas?  La IA y el aprendizaje profundo ahora se consideran sin√≥nimos. <br><br>  <b>I. L .:</b> S√≠ y no.  Sab√≠amos que los m√©todos formar√≠an la base de la visi√≥n por computadora, el reconocimiento de voz y posiblemente un par de otras cosas, pero nadie esperaba que se extendieran a la comprensi√≥n del lenguaje natural, la rob√≥tica, el an√°lisis de im√°genes m√©dicas e incluso contribuyeran a la aparici√≥n de veh√≠culos no tripulados.  A principios de la d√©cada de 1990.  Pens√© que el movimiento hacia estas cosas ser√≠a m√°s suave y aparecer√≠an un poco antes.  Est√°bamos esperando la revoluci√≥n que sucedi√≥ alrededor de 2013. <br><br>  <b>M.F .:</b> ¬øY c√≥mo surgi√≥ su inter√©s en la IA y el aprendizaje autom√°tico? <br><br>  <b>Y. L .:</b> Desde la infancia me interesaron la ciencia, la tecnolog√≠a y los problemas globales sobre el origen de la vida, la inteligencia, el origen de la humanidad.  La idea de IA me cautiv√≥.  Pero en la d√©cada de 1960‚Äì70.  nadie hizo esto en Francia, as√≠ que despu√©s de la escuela fui a estudiar como ingeniero. <br><br>  En 1980, me gust√≥ mucho el libro sobre la filosof√≠a del lenguaje y el aprendizaje: el debate entre Jean Piaget y Noam Chomsky ("Lenguaje y aprendizaje: una discusi√≥n entre Jean Piaget y Noam Chomsky"), en el que el creador de la teor√≠a del desarrollo cognitivo y el ling√ºista discutieron la naturaleza y la educaci√≥n. , as√≠ como la aparici√≥n del lenguaje y la inteligencia. <br><br>  Del lado de Piaget, el profesor del MIT Seymour Peypert habl√≥ sobre los or√≠genes del aprendizaje autom√°tico a fines de la d√©cada de 1960.  en realidad contribuy√≥ al cese del trabajo con redes neuronales.  Y ahora, despu√©s de 10 a√±os, ensalz√≥ el llamado perceptr√≥n, un modelo muy simple de aprendizaje autom√°tico que apareci√≥ en la d√©cada de 1950.  y en el que trabaj√≥ en la d√©cada de 1960.  Entonces, por primera vez, conoc√≠ el concepto de aprendizaje autom√°tico y qued√© absolutamente fascinado.  La capacidad de aprender, consideraba una parte integral de la inteligencia. <br><br>  Como estudiante, le√≠ todo lo que pude encontrar sobre aprendizaje autom√°tico e hice varios proyectos sobre este tema.  Result√≥ que en Occidente nadie trabaja con redes neuronales.  Algunos investigadores japoneses trabajaron en lo que m√°s tarde se conoci√≥ como este t√©rmino.  En nuestro pa√≠s, este tema no era de inter√©s para nadie, en parte debido a lo que apareci√≥ a fines de la d√©cada de 1960.  libros de Peypert y Minsky. <br><br>  Comenc√© una investigaci√≥n independiente y en 1987 defend√≠ mi disertaci√≥n doctoral Modeles connexionnistes de l'apprentissage ("Modelos de aprendizaje conexionista").  Mi gerente Maurice Milgram no se ocup√≥ de este tema y me dijo directamente que podr√≠a convertirse oficialmente en mi consultor, pero que no pod√≠a ayudarme t√©cnicamente. <br><br>  A principios de 1980  Descubr√≠ una comunidad de personas que trabajaban en redes neuronales y las contact√©.  Como resultado, en paralelo con David Rumelhart y Jeffrey Hinton, descubr√≠ el m√©todo de propagaci√≥n inversa del error. <br><br>  <b>M.F .:</b> Es decir, a principios de los a√±os ochenta.  En Canad√°, ¬øse han realizado numerosos estudios en esta √°rea? <br><br>  <b>Y. L .:</b> No, todo sucedi√≥ en los Estados Unidos.  En Canad√°, tales estudios a√∫n no se realizaron.  A principios de 1980  Jeffrey Hinton era un empleado de la Universidad de California, San Diego, donde trabaj√≥ con psic√≥logos cognitivos como David Rumelhart y James McClelland.  Como resultado, apareci√≥ un libro explicando la psicolog√≠a con la ayuda de redes neuronales simples y modelos de computadora.  Jeffrey luego se convirti√≥ en profesor asistente en la Universidad Carnegie Mellon.  Solo se mud√≥ a Toronto en 1987. Luego me mud√© a Toronto y trabaj√© en su laboratorio durante un a√±o. <br><br>  M.F .: a principios de los a√±os ochenta.  Era estudiante de inform√°tica y no recuerdo que las redes neuronales se usaran en alg√∫n lugar.  Ahora la situaci√≥n ha cambiado dram√°ticamente. <br><br>  <b>Y. L .:</b> Las redes neuronales no solo est√°n al margen de la ciencia.  En la d√©cada de 1970  y principios de los ochenta.  en realidad fueron anatematizados.  Los art√≠culos fueron rechazados por una menci√≥n de las redes neuronales. <br><br>  El conocido art√≠culo Optimal Perceptual Inference, publicado en 1983 por Jeffrey Hinton y Terry Seinowski.  Para describir en √©l uno de los primeros modelos de aprendizaje profundo y red neuronal, utilizaron palabras de c√≥digo, incluso en el nombre. <br><br>  <b>M.F .:</b> Usted es conocido como el autor de una red neuronal convolucional.  Por favor explique de qu√© se trata? <br><br>  <b>Y. L .:</b> Inicialmente, esta red neuronal fue optimizada para el reconocimiento de objetos en im√°genes.  Pero result√≥ que se puede aplicar a una amplia gama de tareas, como el reconocimiento de voz y la traducci√≥n autom√°tica.  La idea de su creaci√≥n fue servida por las caracter√≠sticas de la corteza visual del cerebro de animales y humanos, estudiadas en los a√±os cincuenta y sesenta.  David Hubel y Thorsten Wiesel, que luego recibi√≥ el Premio Nobel de neurobiolog√≠a. <br><br>  La red convolucional es una forma especial de conectar neuronas que no son una copia exacta de las neuronas biol√≥gicas.  En la primera capa, la capa de convoluci√≥n, cada neurona est√° asociada con un peque√±o n√∫mero de p√≠xeles de imagen y calcula la suma ponderada de sus datos de entrada.  Durante el entrenamiento, los pesos cambian.  Grupos de neuronas ven peque√±as √°reas de la imagen.  Si una neurona detecta una caracter√≠stica espec√≠fica en un √°rea, otra neurona detectar√° exactamente la misma caracter√≠stica en el √°rea adyacente y todas las dem√°s neuronas en las √°reas restantes de la imagen.  La operaci√≥n matem√°tica que las neuronas realizan juntas se llama convoluci√≥n discreta.  De ah√≠ el nombre. <br><br>  Luego viene la capa no lineal, donde cada neurona se activa o desactiva, dependiendo de si la suma ponderada calculada por la capa de convoluci√≥n result√≥ ser mayor o menor que el umbral especificado.  Finalmente, la tercera capa realiza una operaci√≥n de disminuci√≥n de muestras para asegurarse de que un ligero sesgo o deformaci√≥n de la imagen de entrada no cambie en gran medida la salida.  Esto proporciona independencia de las deformaciones de la imagen de entrada. <br><br>  De hecho, una red convolucional es una pila organizada a partir de capas de convoluci√≥n, no linealidad y submuestreo.  Cuando se pliegan, aparecen neuronas que reconocen los objetos.  Por ejemplo, una neurona que se activa cuando el caballo est√° en la imagen, otra neurona para autom√≥viles, una tercera para personas, etc., para todas las categor√≠as que necesita. <br><br>  Adem√°s, lo que hace la red neuronal est√° determinado por la fuerza de las conexiones entre las neuronas, es decir, los pesos.  Y estos pesos no est√°n programados, sino que son el resultado del entrenamiento. <br><br>  La imagen del caballo se muestra en la red y, si no responde "caballo", se le informar√° que esto est√° mal y se le solicitar√° la respuesta correcta.  Despu√©s de eso, utilizando el algoritmo de propagaci√≥n de error de retorno, la red ajusta los pesos de todas las conexiones para que la pr√≥xima vez que se muestre la misma imagen, el resultado est√© m√°s cerca del deseado.  Al mismo tiempo, debes mostrarle miles de im√°genes. <br><br>  <b>M. F .:</b> ¬øEs esto ense√±ar con un maestro?  Seg√∫n tengo entendido, ahora este es el enfoque dominante. <br><br>  <b>Y. L .:</b> Exactamente.  Casi todas las aplicaciones modernas de aprendizaje profundo utilizan la formaci√≥n del profesorado.  La magia es que la red entrenada en su mayor parte da las respuestas correctas incluso para im√°genes que no se hab√≠an mostrado antes.  Pero necesita una gran cantidad de ejemplos. <br><br>  <b>M.F .:</b> ¬øY qu√© se puede esperar en el futuro?  ¬øSer√° posible ense√±ar un auto de ni√±o, que solo necesita mostrar un gato una vez y nombrarlo? <br><br>  <b>I. L .:</b> En realidad, no tienes toda la raz√≥n.  Los primeros entrenamientos convolucionales realmente tienen lugar en millones de im√°genes de varias categor√≠as.  Y luego, si necesita agregar una nueva categor√≠a, por ejemplo, ense√±ar a una computadora a reconocer gatos, unas pocas muestras son suficientes.  Despu√©s de todo, la red ya est√° entrenada para reconocer objetos de casi cualquier tipo.  Las adiciones al entrenamiento se relacionan con un par de capas superiores. <br><br>  <b>MF:</b> Ya se parece a la forma en que estudian los ni√±os. <br><br>  <b>Y. L .:</b> No, desafortunadamente, esto no es para nada as√≠.  Los ni√±os obtienen la mayor parte de la informaci√≥n antes de que alguien les diga: "Este es un gato".  En los primeros meses de vida, los ni√±os aprenden sin una pista sobre el idioma.  Reconocen la estructura del mundo simplemente observando el mundo e interactuando un poco con √©l.  Esta forma de acumular conocimiento no est√° disponible para las m√°quinas.  C√≥mo llamarlo no est√° claro.  Algunos usan el t√©rmino provocativo "ense√±anza sin maestros".  Esto a veces se llama entrenamiento anticipatorio o inductivo.  Yo lo llamo autoestudio.  Cuando se entrena este tipo, no se trata de prepararse para realizar una tarea, simplemente se trata de observar el mundo y c√≥mo funciona. <br><br>  <b>M.F .:</b> ¬øEl aprendizaje reforzado entra en esta categor√≠a? <br><br>  <b>Y. L .:</b> No, esta es una categor√≠a completamente diferente.  De hecho, hay tres categor√≠as principales: aprendizaje reforzado, capacitaci√≥n docente y autoaprendizaje. <br><br>  El entrenamiento con refuerzo se lleva a cabo mediante prueba y error y funciona bien para juegos en los que puedes hacer tantos intentos como quieras.  El buen rendimiento de AlphaGo se logr√≥ despu√©s de que la m√°quina jug√≥ m√°s juegos que toda la humanidad en los √∫ltimos tres mil a√±os.  Para los problemas del mundo real, este enfoque no es pr√°ctico. <br><br>  Una persona puede aprender a conducir un autom√≥vil en 15 horas de entrenamiento sin chocar contra nada.  Si utiliza los m√©todos existentes de entrenamiento con refuerzos, el autom√≥vil, para aprender a conducir sin conductor, tendr√° que caerse de un precipicio 10 mil veces antes de que ella comprenda c√≥mo evitarlo. <br><br>  <b>M.F .:</b> Me parece que este es un argumento a favor del modelado. <br><br>  <b>Y. L .:</b> M√°s bien, es una confirmaci√≥n de que el tipo de entrenamiento que usan las personas es muy diferente del aprendizaje reforzado.  Esto es similar al entrenamiento de refuerzo basado en modelos.  Despu√©s de todo, una persona que conduce un autom√≥vil por primera vez tiene un modelo del mundo y puede predecir las consecuencias de sus acciones.  C√≥mo hacer que la m√°quina estudie de forma independiente los modelos pron√≥sticos es el principal problema sin resolver. <br><br>  <b>M.F .:</b> ¬øDe esto se trata tu trabajo con Facebook? <br><br>  <b>I. L .:</b> S√≠, esta es una de las cosas en las que estamos trabajando.  Tambi√©n entrenamos la m√°quina para observar diferentes fuentes de datos.  Estamos construyendo un modelo del mundo, esperando el reflejo del sentido com√∫n en √©l, para que luego pueda usarse como pron√≥stico. <br><br>  <b>M.F .:</b> Algunas personas piensan que el aprendizaje profundo por s√≠ solo no es suficiente, y en las redes deber√≠a haber inicialmente una estructura responsable de la inteligencia.  Y parece estar convencido de que la inteligencia puede emerger org√°nicamente de redes neuronales relativamente universales. <br><br>  Y. L .: Exageras.  Todos est√°n de acuerdo con la necesidad de la estructura; la pregunta es c√≥mo deber√≠a verse.  Y hablando de personas que creen que deber√≠a haber estructuras que proporcionen un pensamiento l√≥gico y la capacidad de argumentar, probablemente se refiera a Gary Marcus y, posiblemente, a Oren Etzioni.  Discutimos con Gary sobre este tema esta ma√±ana.  Su opini√≥n no es bien recibida en la comunidad, porque, sin hacer la m√°s m√≠nima contribuci√≥n al aprendizaje profundo, escribi√≥ cr√≠ticamente al respecto.  Oren trabaj√≥ en esta √°rea durante alg√∫n tiempo y al mismo tiempo habla mucho m√°s suave. <br><br>  De hecho, la idea de redes convolucionales surgi√≥ como un intento de agregar estructura a las redes neuronales.  La pregunta es: ¬øqu√© permite a la m√°quina manipular caracteres o, por ejemplo, corresponder a las caracter√≠sticas jer√°rquicas del lenguaje? <br><br>  Muchos de mis colegas, incluidos Jeffrey Hinton y Joshua Benggio, est√°n de acuerdo en que tarde o temprano podemos prescindir de las estructuras.  Pueden ser √∫tiles a corto plazo, porque todav√≠a no se ha inventado una forma de autoaprendizaje.  Este punto se puede eludir vinculando todo a la arquitectura.  Pero la microestructura de la corteza, tanto visual como prefrontal, parece completamente homog√©nea. <br><br>  <b>M.F .:</b> ¬øUtiliza el cerebro algo similar al m√©todo de propagaci√≥n de errores? <br><br>  <b>I. L .:</b> Esto es desconocido.  Puede resultar que esta no es la propagaci√≥n inversa en la forma como la conocemos, sino una forma similar de aproximaci√≥n de la estimaci√≥n del gradiente.  Joshua Benggio ha trabajado en formas biol√≥gicamente plausibles de estimaci√≥n de gradiente.  Existe la posibilidad de que el cerebro calcule el gradiente de cualquier funci√≥n objetivo. <br><br>  <b>M.F .:</b> ¬øEn qu√© otras cosas importantes se est√° trabajando en Facebook? <br><br>  <b>Y. L .:</b> Nos dedicamos a una variedad de investigaciones b√°sicas, as√≠ como a problemas de aprendizaje autom√°tico, por lo tanto, nos ocupamos principalmente de la matem√°tica aplicada y la optimizaci√≥n.  Se est√° trabajando en el aprendizaje reforzado y los llamados patrones generativos, que son una forma de autoaprendizaje o aprendizaje anticipado. <br><br>  <b>MF:</b> ¬øFacebook desarrolla sistemas que pueden mantener una conversaci√≥n? <br><br>  <b>Y. L .:</b> He enumerado los temas de investigaci√≥n fundamentales anteriores, pero tambi√©n hay muchas √°reas de su aplicaci√≥n.  Facebook est√° desarrollando activamente desarrollos en el campo de la visi√≥n por computadora, y se puede argumentar que tenemos el mejor grupo de investigaci√≥n del mundo.  Trabajamos mucho en el procesamiento de textos en un lenguaje natural.  Esto incluye traducci√≥n, generalizaci√≥n, categorizaci√≥n (averiguar qu√© tema se est√° discutiendo) y sistemas de di√°logo para asistentes virtuales, sistemas de preguntas y respuestas, etc. <br><br>  <b>M.F .:</b> ¬øCrees que alg√∫n d√≠a habr√° una IA que pueda pasar la prueba de Turing? <br><br>  <b>I. L .:</b> En alg√∫n momento esto suceder√°, pero no considero que la prueba de Turing sea un buen criterio: es f√°cil de enga√±ar y est√° algo desactualizado.  Muchos olvidan o se niegan a creer que el lenguaje es un fen√≥meno secundario en relaci√≥n con la inteligencia. <br><br>  ¬ªSe puede encontrar m√°s informaci√≥n sobre el libro en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el sitio web del editor</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Contenidos</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Extracto</a> <br><br>  Cup√≥n de 25% de descuento para vendedores ambulantes - <b>Intelligence Architects</b> <br><br>  Tras el pago de la versi√≥n en papel del libro, se env√≠a un libro electr√≥nico por correo electr√≥nico. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/476466/">https://habr.com/ru/post/476466/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../476452/index.html">Almacenamiento de valor clave o c√≥mo nuestras aplicaciones se han vuelto m√°s convenientes</a></li>
<li><a href="../476454/index.html">Se acerca el 5G: qu√© empresas garantizar√°n la introducci√≥n de nuevas tecnolog√≠as en 2020</a></li>
<li><a href="../476456/index.html">El sistema de cr√©dito social chino no es, en primer lugar, un sistema de evaluaci√≥n ciudadana, sino un API masivo</a></li>
<li><a href="../476460/index.html">El primer formato de archivo de √©xito en Internet no era MP3, sino MIDI</a></li>
<li><a href="../476464/index.html">Problemas de registro de eventos de seguridad del sistema de Windows</a></li>
<li><a href="../476468/index.html">Nuevo curso gratuito de an√°lisis de texto de redes neuronales en l√≠nea de Samsung</a></li>
<li><a href="../476474/index.html">Devolvemos Keenetic en el soporte KN-1310 del m√≥dem usb</a></li>
<li><a href="../476476/index.html">Mostrar Gmail solo en html</a></li>
<li><a href="../476478/index.html">Etapas de la introducci√≥n de modelos de aprendizaje autom√°tico en grandes empresas</a></li>
<li><a href="../476480/index.html">C√≥mo desarrollar un desarrollador en una ciudad peque√±a y no muy inform√°tica</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
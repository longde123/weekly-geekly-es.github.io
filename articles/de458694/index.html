<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚¨úÔ∏è üë®‚Äç‚úàÔ∏è üí≥ Ist Python GIL wirklich tot? üë®üèº‚ÄçüöÄ üë®üèº‚Äçüè≠ üñïüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo allerseits! Am kommenden Montag beginnen die Kurse in der neuen Gruppe des Python Developer- Kurses. Dies bedeutet, dass wir Zeit haben, ein wei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ist Python GIL wirklich tot?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/458694/">  Hallo allerseits!  Am kommenden Montag beginnen die Kurse in der neuen Gruppe des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Python Developer-</a> Kurses. Dies bedeutet, dass wir Zeit haben, ein weiteres interessantes Material zu ver√∂ffentlichen, das wir jetzt durchf√ºhren werden.  Gute Lekt√ºre. <br><br><img src="https://habrastorage.org/webt/jb/cq/wj/jbcqwjrmctxos6x_uzhptngfd9y.png"><br><br>  Bereits 2003 ver√∂ffentlichte Intel den neuen Pentium 4 ‚ÄûHT‚Äú -Prozessor.  Dieser Prozessor √ºbertaktete auf 3 GHz und unterst√ºtzte die Hyper-Threading-Technologie. <a name="habracut"></a><br><br><img src="https://habrastorage.org/webt/9d/z1/es/9dz1esccmgms80liftaeolcqiui.jpeg"><br><br>  In den folgenden Jahren hatten Intel und AMD Probleme, die beste Desktop-Leistung zu erzielen, indem sie die Busgeschwindigkeit, die L2-Cache-Gr√∂√üe und die Matrixgr√∂√üe erh√∂hten, um die Latenz zu minimieren.  Im Jahr 2004 wurde das HT-Modell mit einer Frequenz von 3 GHz durch das 580 Prescott-Modell mit √úbertaktung auf 4 GHz ersetzt. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/AmwzUrL3vMc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Es schien, dass es nur notwendig war, die Taktfrequenz zu erh√∂hen, aber die neuen Prozessoren litten unter hohem Stromverbrauch und W√§rmeableitung. <br><br>  Liefert Ihr Desktop-Prozessor heute 4 GHz?  Dies ist unwahrscheinlich, da der Weg zur Verbesserung der Leistung letztendlich in der Erh√∂hung der Busgeschwindigkeit und der Erh√∂hung der Anzahl der Kerne liegt.  Im Jahr 2006 ersetzte Intel Core 2 den Pentium 4 und hatte eine viel niedrigere Taktrate. <br><br>  Neben der Ver√∂ffentlichung von Multi-Core-Prozessoren f√ºr ein breites Benutzerpublikum geschah 2006 noch etwas anderes.  Python 2.5 hat endlich das Licht erblickt!  Es kam bereits mit einer Beta-Version des with-Schl√ºsselworts, die Sie alle kennen und lieben. <br><br>  Python 2.5 hatte eine wesentliche Einschr√§nkung bei der Verwendung von Intel Core 2 oder AMD Athlon X2. <br>  Es war eine Gil. <br><br><h2>  Was ist eine GIL? </h2><br>  GIL (Global Interpreter Lock) ist ein boolescher Wert im Python-Interpreter, der durch einen Mutex gesch√ºtzt ist.  Die Sperre wird in der Haupt-CPython-Bytecode-Berechnungsschleife verwendet, um zu bestimmen, welcher Thread gerade Anweisungen ausf√ºhrt. <br><br>  CPython unterst√ºtzt die Verwendung mehrerer Threads in einem einzelnen Interpreter. Threads m√ºssen jedoch den Zugriff auf die GIL anfordern, um Operationen auf niedriger Ebene ausf√ºhren zu k√∂nnen.  Dies bedeutet wiederum, dass Python-Entwickler asynchronen Code und Multithreading verwenden k√∂nnen und sich nicht mehr um das Blockieren von Variablen oder Abst√ºrze auf Prozessorebene w√§hrend Deadlocks k√ºmmern m√ºssen. <br><br>  GIL vereinfacht die Multithread-Python-Programmierung. <br><br><img src="https://habrastorage.org/webt/lg/yz/3h/lgyz3hoq07fkumzp4axuuiqxplk.gif"><br><br>  GIL sagt uns auch, dass CPython zwar Multithread-f√§hig sein kann, jedoch jeweils nur ein Thread ausgef√ºhrt werden kann.  Dies bedeutet, dass Ihr Quad-Core-Prozessor so etwas tut (mit Ausnahme des blauen Bildschirms hoffentlich). <br><br>  Die aktuelle Version von GIL <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wurde 2009 geschrieben</a> , um asynchrone Funktionen zu unterst√ºtzen, und blieb auch nach vielen Versuchen, sie im Prinzip zu entfernen oder die Anforderungen daf√ºr zu √§ndern, unber√ºhrt. <br><br>  Jeder Vorschlag, die GIL zu entfernen, wurde durch die Tatsache gerechtfertigt, dass das globale Sperren des Interpreters die Leistung von Single-Threaded-Code nicht beeintr√§chtigen sollte.  Jeder, der 2003 versucht hat, Hyperthreading zu aktivieren, wird verstehen, wovon <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ich spreche</a> . <br><br><h2>  Gil Verlassenheit in CPython </h2><br>  Wenn Sie den Code in CPython wirklich parallelisieren m√∂chten, m√ºssen Sie mehrere Prozesse verwenden. <br><br>  In CPython 2.6 wurde das <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Multiprozessor-</a></i> Modul zur Standardbibliothek hinzugef√ºgt.  Multiprocessing maskierte die Generierung von Prozessen in CPython (jeder Prozess mit seiner eigenen GIL). <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> multiprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Process <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">f</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'hello'</span></span>, name <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: p = Process(target=f, args=(<span class="hljs-string"><span class="hljs-string">'bob'</span></span>,)) p.start() p.join()</code> </pre> <br><br>  Prozesse werden erstellt, Befehle werden mit kompilierten Modulen und Python-Funktionen an sie gesendet und dann wieder mit dem Hauptprozess verbunden. <br><br>  Multiprocessing unterst√ºtzt auch die Verwendung von Variablen √ºber eine Warteschlange oder einen Kanal.  Sie hat ein Sperrobjekt, mit dem Objekte im Hauptprozess gesperrt und aus anderen Prozessen geschrieben werden. <br><br>  Multiprocessing hat einen gro√üen Nachteil.  Es ist mit einer erheblichen Rechenlast verbunden, die sich sowohl auf die Verarbeitungszeit als auch auf die Speichernutzung auswirkt.  Die CPython-Startzeit betr√§gt auch ohne Site 100-200 ms (weitere Informationen finden Sie unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://hackernoon.com/which-is-the-fastest-version-of-python-2ae7c61a6b2b</a> ). <br><br>  Infolgedessen verf√ºgen Sie m√∂glicherweise √ºber parallelen Code in CPython, m√ºssen jedoch die Arbeit lang laufender Prozesse, die mehrere Objekte gemeinsam nutzen, sorgf√§ltig planen. <br><br>  Eine andere Alternative kann darin bestehen, ein Paket eines Drittanbieters wie Twisted zu verwenden. <br><br><h2>  PEP554 und der Tod von GIL? </h2><br>  Ich m√∂chte Sie daran erinnern, dass Multithreading in CPython einfach ist, in Wirklichkeit jedoch keine Parallelisierung, sondern Multiprocessing parallel ist, jedoch einen erheblichen Overhead mit sich bringt. <br><br>  <i>Was ist, wenn es einen besseren Weg gibt?</i> <br>  Der Schl√ºssel zur Umgehung der GIL liegt im Namen. Die globale Sperrung des Interpreters ist Teil des globalen Status des Interpreters.  CPython-Prozesse k√∂nnen mehrere Interpreter und daher mehrere Sperren haben. Diese Funktion wird jedoch selten verwendet, da der Zugriff nur √ºber die C-API erfolgt. <br><br>  Eine der Funktionen von CPython 3.8 ist PEP554, eine Implementierung von Unterinterpreten und APIs mit einem neuen <code>interpreters</code> in der Standardbibliothek. <br><br>  Auf diese Weise k√∂nnen Sie in einem einzigen Prozess mehrere Interpreter aus Python erstellen.  Eine weitere Neuerung von Python 3.8 ist, dass alle Interpreter ihre eigene GIL haben. <br><br><img src="https://habrastorage.org/webt/bq/nc/m2/bqncm29jhm-ytakgrlkasbfe_6y.png"><br><br>  Da der Status des Interpreters eine im Speicher zugewiesene Region enth√§lt, eine Sammlung aller Zeiger auf Python-Objekte (lokal und global), k√∂nnen Subinterpreter in PEP554 nicht auf die globalen Variablen anderer Interpreter zugreifen. <br><br>  Interpreter, die Objekte gemeinsam nutzen, bestehen wie Multiprocessing darin, sie zu serialisieren und das IPC-Formular (Netzwerk, Festplatte oder gemeinsam genutzter Speicher) zu verwenden.  Es gibt viele M√∂glichkeiten, Objekte in Python zu serialisieren, z. B. das <code>simplexml</code> Modul, das <code>pickle</code> Modul oder standardisierte Methoden wie <code>json</code> oder <code>simplexml</code> .  Jeder von ihnen hat seine Vor- und Nachteile, und alle geben eine Rechenlast. <br><br>  Es w√§re am besten, einen gemeinsamen Speicherplatz zu haben, der durch einen bestimmten Prozess ge√§ndert und gesteuert werden kann.  Somit k√∂nnen Objekte vom Hauptinterpreter gesendet und von einem anderen Interpreter empfangen werden.  Dies ist der verwaltete Speicherplatz f√ºr die Suche nach PyObject-Zeigern, auf die jeder Interpreter zugreifen kann, w√§hrend der Hauptprozess die Sperren verwaltet. <br><br><img src="https://habrastorage.org/webt/be/ww/d8/bewwd8ju-3akmyhs7ujq7xmyliy.png"><br><br>  Eine API daf√ºr wird noch entwickelt, aber sie wird wahrscheinlich ungef√§hr so ‚Äã‚Äãaussehen: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> _xxsubinterpreters <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> interpreters <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> threading <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> textwrap <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tw <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> marshal <span class="hljs-comment"><span class="hljs-comment"># Create a sub-interpreter interpid = interpreters.create() # If you had a function that generated some data arry = list(range(0,100)) # Create a channel channel_id = interpreters.channel_create() # Pre-populate the interpreter with a module interpreters.run_string(interpid, "import marshal; import _xxsubinterpreters as interpreters") # Define a def run(interpid, channel_id): interpreters.run_string(interpid, tw.dedent(""" arry_raw = interpreters.channel_recv(channel_id) arry = marshal.loads(arry_raw) result = [1,2,3,4,5] # where you would do some calculating result_raw = marshal.dumps(result) interpreters.channel_send(channel_id, result_raw) """), shared=dict( channel_id=channel_id ), ) inp = marshal.dumps(arry) interpreters.channel_send(channel_id, inp) # Run inside a thread t = threading.Thread(target=run, args=(interpid, channel_id)) t.start() # Sub interpreter will process. Feel free to do anything else now. output = interpreters.channel_recv(channel_id) interpreters.channel_release(channel_id) output_arry = marshal.loads(output) print(output_arry)</span></span></code> </pre> <br><br>  In diesem Beispiel wird NumPy verwendet.  Das Numpy-Array wird √ºber den Kanal gesendet, es wird mithilfe des <code>marshal</code> serialisiert, und der Subinterpreter verarbeitet die Daten (auf einer separaten GIL), sodass m√∂glicherweise ein Parallelisierungsproblem mit der CPU verbunden ist, das f√ºr Subinterpreter ideal ist. <br><br><h4>  <b>Es sieht ineffizient aus</b> </h4><br>  Das <code>marshal</code> arbeitet sehr schnell, aber nicht so schnell wie das direkte Freigeben von Objekten aus dem Speicher. <br><br>  PEP574 f√ºhrt ein neues <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pickle-</a> Protokoll <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">(v5) ein</a> , das die F√§higkeit unterst√ºtzt, Speicherpuffer getrennt vom Rest des Pickle-Streams zu verarbeiten.  Bei gro√üen Datenobjekten bedeutet das Serialisieren aller Objekte auf einmal und das Deserialisieren von einem Subinterpreter viel Overhead. <br><br>  Die neue API kann (rein hypothetisch) wie folgt implementiert werden: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> _xxsubinterpreters <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> interpreters <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> threading <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> textwrap <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tw <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pickle <span class="hljs-comment"><span class="hljs-comment"># Create a sub-interpreter interpid = interpreters.create() # If you had a function that generated a numpy array arry = [5,4,3,2,1] # Create a channel channel_id = interpreters.channel_create() # Pre-populate the interpreter with a module interpreters.run_string(interpid, "import pickle; import _xxsubinterpreters as interpreters") buffers=[] # Define a def run(interpid, channel_id): interpreters.run_string(interpid, tw.dedent(""" arry_raw = interpreters.channel_recv(channel_id) arry = pickle.loads(arry_raw) print(f"Got: {arry}") result = arry[::-1] result_raw = pickle.dumps(result, protocol=5) interpreters.channel_send(channel_id, result_raw) """), shared=dict( channel_id=channel_id, ), ) input = pickle.dumps(arry, protocol=5, buffer_callback=buffers.append) interpreters.channel_send(channel_id, input) # Run inside a thread t = threading.Thread(target=run, args=(interpid, channel_id)) t.start() # Sub interpreter will process. Feel free to do anything else now. output = interpreters.channel_recv(channel_id) interpreters.channel_release(channel_id) output_arry = pickle.loads(output) print(f"Got back: {output_arry}")</span></span></code> </pre> <br><h4>  <b>Es sieht gemustert aus</b> </h4><br>  Im Wesentlichen basiert dieses Beispiel auf der Verwendung der API von Subinterpretern auf niedriger Ebene.  Wenn Sie die <code>multiprocessing</code> Bibliothek nicht verwendet haben, werden Ihnen einige Probleme bekannt vorkommen.  Es ist nicht so einfach wie die Stream-Verarbeitung. Sie k√∂nnen diese Funktion beispielsweise (vorerst) nicht einfach mit einer solchen Liste von Eingabedaten in separaten Interpreten ausf√ºhren. <br><br>  Sobald dieses PEP mit anderen verschmilzt, werden wir wahrscheinlich mehrere neue APIs in PyPi sehen. <br><br><h3>  Wie viel Overhead hat der Subinterpreter? </h3><br>  <b>Kurze Antwort:</b> Mehr als ein Stream, weniger als ein Prozess. <br>  <b>Lange Antwort: Der</b> Interpreter hat einen eigenen Status, daher muss er Folgendes klonen und initialisieren, obwohl PEP554 die Erstellung von Subinterpreten vereinfacht: <br><br><ul><li>  Module im <code>importlib</code> <code>__main__</code> und <code>importlib</code> ; </li><li>  Der Inhalt des <code>sys</code> ; </li><li>  Eingebaute Funktionen ( <code>print()</code> , <code>assert</code> usw.); </li><li>  Streams; </li><li>  Kernel-Konfiguration. </li></ul><br><br>  Die Kernelkonfiguration kann leicht aus dem Speicher geklont werden, aber das Importieren von Modulen ist nicht so einfach.  Das Importieren von Modulen in Python ist langsam. Wenn das Erstellen eines Subinterpreters das Importieren von Modulen in einen anderen Namespace jedes Mal bedeutet, werden die Vorteile verringert. <br><br><h3>  Was ist mit Asyncio? </h3><br>  Die vorhandene Implementierung der <code>asyncio</code> Ereignisschleife in der Standardbibliothek erstellt <code>asyncio</code> zur Auswertung und <code>asyncio</code> Status im Hauptinterpreter (und teilt daher die GIL). <br><br>  Nach dem Kombinieren von PEP554, wahrscheinlich bereits in Python 3.9, kann eine alternative Implementierung der Ereignisschleife verwendet werden (obwohl dies noch niemand getan hat), die asynchrone Methoden in Subinterpretern parallel ausf√ºhrt. <br><br><h3>  Klingt cool, wickel mich auch ein! </h3><br>  Nun, nicht wirklich. <br>  Da CPython so lange auf demselben Interpreter ausgef√ºhrt wurde, verwenden viele Teile der Codebasis "Laufzeitstatus" anstelle von "Interpreterstatus". Wenn PEP554 jetzt eingef√ºhrt w√ºrde, g√§be es immer noch viele Probleme. <br><br>  Beispielsweise geh√∂rt der Status des Garbage Collector (in Version 3.7 &lt;) zur Laufzeit. <br><br>  Bei √Ñnderungen w√§hrend PyCon-Sprints begann sich der Status des Garbage Collectors auf den Interpreter zu verschieben, sodass jeder Subinterpreter seinen eigenen Garbage Collector hatte (wie es sein sollte). <br><br>  Ein weiteres Problem ist, dass es einige ‚Äûglobale‚Äú Variablen gibt, die in der CPython-Codebasis zusammen mit vielen Erweiterungen in C verblieben sind. Als die Leute pl√∂tzlich anfingen, ihren Code korrekt zu parallelisieren, sahen wir einige Probleme. <br><br>  Ein weiteres Problem besteht darin, dass die Dateideskriptoren zum Prozess geh√∂ren. Wenn Sie also eine Datei zum Schreiben in einem Interpreter ge√∂ffnet haben, kann der Subinterpreter nicht auf diese Datei zugreifen (ohne weitere √Ñnderungen an CPython). <br><br>  Kurz gesagt, es gibt noch viele Probleme, die angegangen werden m√ºssen. <br><br><h2>  Fazit: Ist GIL noch wahr? </h2><br>  GIL wird weiterhin f√ºr Single-Threaded-Anwendungen verwendet.  Selbst wenn Sie PEP554 folgen, wird Ihr Single-Thread-Code daher pl√∂tzlich nicht mehr parallel. <br>  Wenn Sie parallelen Code in Python 3.8 schreiben m√∂chten, treten Parallelisierungsprobleme im Zusammenhang mit dem Prozessor auf, dies ist jedoch auch ein Ticket f√ºr die Zukunft! <br><br><h2>  Wann? </h2><br>  Pickle v5 und Speicherfreigabe f√ºr die Mehrfachverarbeitung werden h√∂chstwahrscheinlich in Python 3.8 (Oktober 2019) verf√ºgbar sein, und Subinterpreter werden zwischen den Versionen 3.8 und 3.9 angezeigt. <br>  Wenn Sie mit den vorgestellten Beispielen herumspielen m√∂chten, habe ich einen separaten Zweig mit dem erforderlichen Code erstellt: <a href="">https://github.com/tonybaloney/cpython/tree/subinterpreters.</a> <br><br>  Was denkst du dar√ºber?  Schreiben Sie Ihre Kommentare und wir sehen uns auf dem Kurs. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458694/">https://habr.com/ru/post/de458694/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458684/index.html">ICANN entfernt Preisschwelle f√ºr .org-Domain - warum die IT-Community dagegen ist und was als n√§chstes passieren wird</a></li>
<li><a href="../de458686/index.html">@ Pythonetc Juni 2019</a></li>
<li><a href="../de458688/index.html">Tipps und Tricks von meinem Telegramm-Kanal @pythonetc, Juni 2019</a></li>
<li><a href="../de458690/index.html">Automatisieren Sie es! Wie wir Integrationstests verbessert haben</a></li>
<li><a href="../de458692/index.html">"Vielleicht" -Monade durch Async / Warten in C # (Keine Aufgaben!)</a></li>
<li><a href="../de458696/index.html">Texturierung oder was Sie wissen m√ºssen, um ein Oberfl√§chenk√ºnstler zu werden. Teil 3. Z√ºchterrechte und Materialien</a></li>
<li><a href="../de458698/index.html">Der Weg des Friedens und der Weg des Krieges in IT-Projekten</a></li>
<li><a href="../de458702/index.html">Schlittenhunde: Was Sie √ºber sie wissen m√ºssen und wie sie gebracht wurden</a></li>
<li><a href="../de458704/index.html">Implementierung eines DLP-Systems am Beispiel des Einzelhandels</a></li>
<li><a href="../de458706/index.html">Gopniks sind jetzt auf ausl√§ndischen M√§rkten oder "Warum ist es so schwierig, einen normalen Programmierer zu finden?"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
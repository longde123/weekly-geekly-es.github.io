<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üóìÔ∏è üßóüèΩ üàπ Perendaman dalam jaringan saraf convolutional. Bagian 5/10 - 18 üï∞Ô∏è üè† üßîüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kursus lengkap dalam bahasa Rusia dapat ditemukan di tautan ini . 
 Kursus bahasa Inggris asli tersedia di tautan ini . 



 Kuliah baru dijadwalkan s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Perendaman dalam jaringan saraf convolutional. Bagian 5/10 - 18</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458170/"><p>  Kursus lengkap dalam bahasa Rusia dapat ditemukan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ini</a> . <br>  Kursus bahasa Inggris asli tersedia di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ini</a> . </p><br><p><img src="https://habrastorage.org/webt/1m/hz/qn/1mhzqnwa288uxjmptqhexriiahc.png"><br>  <i>Kuliah baru dijadwalkan setiap 2-3 hari.</i> </p><a name="habracut"></a><br><h1>  Isi </h1><br><ol><li>  Wawancara dengan Sebastian Trun </li><li>  Pendahuluan </li><li>  Dataset Anjing dan Kucing </li><li>  Gambar berbagai ukuran </li><li>  Gambar berwarna.  Bagian 1 </li><li>  Gambar berwarna.  Bagian 2 </li><li>  Operasi konvolusi pada gambar berwarna </li><li>  Pengoperasian subsampling dengan nilai maksimum dalam gambar berwarna </li><li>  CoLab: kucing dan anjing </li><li>  Softmax dan sigmoid </li><li>  Periksa </li><li>  Ekstensi gambar </li><li>  Pengecualian </li><li>  CoLab: anjing dan kucing.  Pengulangan </li><li>  Teknik lain untuk mencegah pelatihan ulang </li><li>  Latihan: klasifikasi gambar warna </li><li>  Ringkasan </li></ol><br><h1>  Softmax dan Sigmoid </h1><br><p>  Dalam CoLab terakhir kami, kami menggunakan arsitektur jaringan saraf convolutional berikut: </p><br><pre><code class="python hljs">model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">150</span></span>, <span class="hljs-number"><span class="hljs-number">150</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>)), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Flatten(), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>) ])</code> </pre> <br><p>  Harap dicatat bahwa lapisan terakhir kami (classifier kami) terdiri dari lapisan yang sepenuhnya terhubung dengan dua neuron output dan <code>softmax</code> aktivasi <code>softmax</code> : </p><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)</code> </pre> <br><p>  Pendekatan populer lainnya untuk memecahkan masalah klasifikasi biner adalah penggunaan classifier, yang terdiri dari lapisan yang terhubung penuh dengan 1 output neuron dan <code>sigmoid</code> aktivasi <code>sigmoid</code> : </p><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)</code> </pre> <br><p>  Kedua opsi ini akan bekerja dengan baik dalam masalah klasifikasi biner.  Namun, apa yang harus Anda ingat jika Anda memutuskan untuk menggunakan <code>sigmoid</code> aktivasi <code>sigmoid</code> di classifier Anda, Anda juga perlu mengubah fungsi loss di <code>model.compile()</code> dari <code>sparse_categorical_crossentropy</code> ke <code>binary_crossentropy</code> seperti pada contoh di bawah ini: </p><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br><h1>  Validasi </h1><br><p>  Di kelas sebelumnya, kami mempelajari keakuratan jaringan saraf convolutional kami menggunakan metrik <code>accuracy</code> pada dataset uji.  Ketika kami mengembangkan jaringan saraf convolutional untuk mengklasifikasikan gambar dari set data FASHION MNIST, kami memperoleh akurasi 97% pada set data pelatihan dan hanya 92% akurasi pada set data uji.  Semua ini terjadi karena model kami dilatih ulang.  Dengan kata lain, jaringan saraf convolutional kami mulai mengingat set data pelatihan.  Namun, kami dapat belajar tentang pelatihan ulang hanya <em>setelah</em> kami melatih dan menguji model pada data yang tersedia dengan membandingkan akurasi set data pelatihan dan set data uji. </p><br><p>  Untuk menghindari masalah ini, kami sering menggunakan kumpulan data untuk validasi: </p><br><p><img src="https://habrastorage.org/webt/mj/fw/ea/mjfweaqi7ztkkfbmznz1nfnogjq.png"></p><br><p>  Selama pelatihan, jaringan saraf convolutional kami "melihat" hanya set data pelatihan dan membuat keputusan tentang bagaimana mengubah nilai-nilai parameter internal - bobot dan perpindahan.  Setelah setiap iterasi pelatihan, kami memeriksa keadaan model dengan menghitung nilai fungsi kerugian pada set data pelatihan dan pada set data validasi.  Perlu dicatat dan memberikan perhatian khusus pada fakta bahwa data dari set validasi tidak digunakan di mana pun oleh model untuk menyesuaikan nilai parameter internal.  Memeriksa keakuratan model pada set data validasi hanya memberi tahu kami seberapa baik model kami bekerja pada set data yang sama.  Dengan demikian, hasil model pada set data validasi memberi tahu kami seberapa baik model kami telah belajar untuk menggeneralisasi data yang diperoleh dan menerapkan generalisasi ini ke set data baru. </p><br><p>  Idenya adalah karena kita tidak menggunakan set data validasi saat melatih model, maka pengujian model pada set validasi akan memungkinkan kita untuk memahami apakah model dilatih ulang atau tidak. </p><br><p>  Mari kita lihat sebuah contoh. </p><br><p>  Dalam CoLab, yang kami lakukan beberapa poin di atas, kami melatih jaringan saraf kami untuk 15 iterasi. </p><br><pre> <code class="plaintext hljs">Epoch 15/15 10/10 [===] - loss: 1.0124 - acc: 0.7170 20/20 [===] - loss: 0.0528 - acc: 0.9900 - val_loss: 1.0124 - val_acc: 0.7070</code> </pre> <br><p>  Jika kita melihat keakuratan prediksi pada set data pelatihan dan validasi pada iterasi pelatihan kelima belas, kita dapat melihat bahwa kita telah mencapai akurasi tinggi pada set data pelatihan dan indikator yang sangat rendah pada set data validasi - <code>0.9900</code> dibandingkan <code>0.7070</code> . </p><br><p>  Ini adalah tanda pelatihan ulang yang jelas.  Jaringan saraf mengingat set data pelatihan, oleh karena itu ia bekerja dengan akurasi luar biasa pada input data dari itu.  Namun, segera setelah memeriksa akurasi pada dataset validasi yang modelnya tidak ‚Äúlihat‚Äù, hasilnya berkurang secara signifikan. </p><br><p>  Salah satu cara untuk menghindari pelatihan ulang adalah dengan hati-hati mempelajari grafik nilai-nilai fungsi kerugian pada set data pelatihan dan validasi di seluruh semua iterasi pelatihan: </p><br><p><img src="https://habrastorage.org/webt/mo/bb/ml/mobbml4mb5sqt1ugcjjmj69ziau.png"></p><br><p>  Dalam CoLab, kami membangun grafik yang sama dan mendapatkan sesuatu yang mirip dengan grafik di atas dari ketergantungan fungsi kerugian pada iterasi pelatihan. </p><br><p>  Anda mungkin memperhatikan bahwa setelah iterasi pelatihan tertentu, nilai fungsi kerugian dalam set data validasi mulai meningkat, sementara nilai fungsi kerugian dalam set data pelatihan terus menurun. </p><br><p>  Pada akhir iterasi 15 pelatihan, kami melihat bahwa nilai fungsi kerugian pada set data validasi sangat tinggi, dan nilai fungsi kerugian pada set data pelatihan sangat kecil.  Sebenarnya, ini adalah indikator pelatihan jaringan saraf. </p><br><p>  Dengan melihat grafik dengan cermat, Anda dapat memahami bahwa secara harfiah setelah beberapa iterasi pelatihan, jaringan saraf kami mulai hanya menyimpan data pelatihan, yang berarti bahwa kemampuan model untuk menggeneralisasi berkurang, yang mengarah pada penurunan akurasi pada set data validasi. </p><br><p>  Seperti yang mungkin sudah Anda pahami, kumpulan data validasi memungkinkan kami untuk menentukan jumlah iterasi pelatihan yang perlu dilakukan agar jaringan saraf convolutional kami akurat dan, pada saat yang sama, tidak berlatih ulang. </p><br><p>  Pendekatan semacam itu bisa sangat berguna jika kita memiliki pilihan beberapa arsitektur jaringan saraf convolutional: </p><br><p><img src="https://habrastorage.org/webt/ay/5j/lq/ay5jlqtty3bwks_zdjclydfgumq.png"></p><br><p>  Misalnya, jika Anda memutuskan jumlah lapisan dalam jaringan saraf convolutional, Anda dapat membuat beberapa arsitektur jaringan saraf dan kemudian membandingkan keakuratannya menggunakan kumpulan data untuk validasi. </p><br><p>  Arsitektur jaringan saraf, yang memungkinkan Anda untuk mencapai nilai minimum dari fungsi kerugian dan akan menjadi yang terbaik untuk menyelesaikan tugas Anda. </p><br><p>  Pertanyaan selanjutnya yang mungkin Anda miliki adalah mengapa membuat dataset validasi jika kita sudah memiliki dataset uji?  Bisakah kita menggunakan set data uji untuk validasi? </p><br><p>  Masalahnya adalah bahwa meskipun fakta bahwa kami tidak menggunakan dataset validasi dalam proses pelatihan model, kami menggunakan hasil bekerja pada dataset uji untuk meningkatkan akurasi model, yang berarti bahwa dataset uji mempengaruhi bobot dan bias dalam saraf. jaringan. </p><br><p><img src="https://habrastorage.org/webt/ys/7a/ih/ys7aihyxutwvpilqpnsaczev5eo.png"></p><br><p>  Karena alasan inilah kami memerlukan dataset validasi yang belum pernah dilihat oleh model kami untuk memverifikasi kinerjanya secara akurat. </p><br><p>  Kami baru saja mengetahui bagaimana dataset yang divalidasi dapat membantu kami menghindari pelatihan ulang.  Pada bagian berikut, kita akan berbicara tentang ekstensi data (yang disebut augmentasi) dan pemutusan (yang disebut putus) neuron - dua teknik populer yang juga dapat membantu kita menghindari pelatihan ulang. </p><br><h1>  Ekstensi Gambar (augmentasi) </h1><br><p>  Dalam melatih jaringan saraf untuk menentukan objek dari kelas tertentu, kami ingin jaringan saraf kami menemukan objek-objek ini, terlepas dari lokasi dan ukurannya dalam gambar. </p><br><p>  Sebagai contoh, misalkan kita ingin melatih jaringan saraf kita untuk mengenali anjing dalam gambar: </p><br><p><img src="https://habrastorage.org/webt/0y/d2/cu/0yd2cuip0aaef2hi8auegdq6mt8.png"></p><br><p>  Dengan demikian, kami ingin jaringan saraf kami untuk menentukan keberadaan seekor anjing dalam gambar, terlepas dari seberapa besar anjing itu dan di bagian mana dari gambar itu, apakah bagian dari anjing itu terlihat atau seluruh anjing.  Kami ingin memastikan bahwa jaringan saraf kami dapat memproses semua opsi ini selama pelatihan. </p><br><p>  Jika Anda cukup beruntung dan Anda memiliki satu set data pelatihan yang besar, maka kita dapat mengatakan dengan yakin bahwa Anda beruntung dan jaringan saraf Anda tidak mungkin untuk berlatih kembali.  Namun, apa yang terjadi cukup sering, kami harus bekerja dengan rangkaian gambar yang terbatas (data pelatihan), yang, pada gilirannya, akan memimpin jaringan saraf convolutional kami dengan probabilitas tinggi untuk pelatihan ulang dan mengurangi kemampuannya untuk menggeneralisasi dan menghasilkan hasil yang diinginkan pada data yang tidak "melihat" sebelumnya. </p><br><p>  Masalah ini dapat diselesaikan dengan menggunakan teknik yang disebut "ekstensi" (augmentasi gambar).  Perluasan gambar (data) bekerja dengan membuat (menghasilkan) gambar baru untuk pelatihan dengan menerapkan transformasi sewenang-wenang dari set gambar asli dari set pelatihan. </p><br><p>  Misalnya, kita dapat mengambil salah satu gambar sumber dari set data pelatihan kami dan menerapkan beberapa transformasi sewenang-wenang terhadapnya - balikkan dengan derajat X, mirror secara horizontal dan buat peningkatan yang sewenang-wenang. </p><br><p><img src="https://habrastorage.org/webt/nd/ps/fv/ndpsfvldpaymeybswwqkmyspr40.png"></p><br><p>  Dengan menambahkan gambar yang dihasilkan ke set data pelatihan kami, kami yakin bahwa jaringan saraf kami akan "melihat" sejumlah contoh berbeda untuk pelatihan.  Sebagai hasil dari tindakan tersebut, jaringan saraf convolutional kami akan lebih menggeneralisasi dan bekerja pada data yang belum terlihat dan kami akan dapat menghindari pelatihan ulang. </p><br><p>  Pada bagian selanjutnya, kita akan belajar apa itu dropout (shutdown) - teknik lain untuk mencegah overfitting model. </p><br><h1>  Pengecualian (putus) </h1><br><p>  Pada bagian ini, kita akan belajar teknik baru - dropout, yang juga akan membantu kita menghindari pelatihan model yang berlebihan.  Seperti yang sudah kita ketahui dari bagian awal, jaringan saraf mengoptimalkan parameter internal (bobot dan perpindahan) untuk meminimalkan fungsi kerugian. </p><br><p>  Salah satu masalah yang dapat dihadapi saat melatih jaringan saraf adalah nilai-nilai besar di satu bagian dari jaringan saraf dan nilai-nilai kecil di bagian lain dari jaringan saraf. </p><br><p><img src="https://habrastorage.org/webt/op/bb/cf/opbbcfp4z1wl_geilpygynmvdz8.png"></p><br><p>  Akibatnya, ternyata neuron dengan bobot lebih tinggi memainkan peran yang lebih besar dalam proses pembelajaran, sedangkan neuron dengan bobot lebih rendah berhenti menjadi signifikan dan semakin sedikit dapat berubah.  Salah satu cara untuk menghindarinya adalah dengan menggunakan dropout neuron secara sewenang-wenang. </p><br><p>  Shutdown (dropout) - proses shutdown selektif neuron dalam proses pembelajaran. </p><br><p><img src="https://habrastorage.org/webt/8j/7t/0p/8j7t0p91wpjv2qswrxugif3b2e4.png"></p><br><p>  Pematian selektif dari beberapa neuron dalam proses pembelajaran memungkinkan Anda untuk secara aktif melibatkan neuron lain dalam pembelajaran.  Selama pelatihan iterasi, kami sewenang-wenang menonaktifkan beberapa neuron. </p><br><p>  Mari kita lihat sebuah contoh.  Bayangkan bahwa pada iterasi pelatihan pertama, kami mematikan dua neuron yang disorot dalam warna hitam: </p><br><p><img src="https://habrastorage.org/webt/rv/f7/uv/rvf7uvlolq1t38zvhi50mqw7hgg.png"></p><br><p>  Proses propagasi langsung dan propagasi balik terjadi tanpa menggunakan dua neuron yang terisolasi. </p><br><p>  Pada iterasi pelatihan kedua, kami memutuskan untuk tidak menggunakan tiga neuron berikut - matikan: </p><br><p><img src="https://habrastorage.org/webt/lq/dq/k2/lqdqk2gkxaagbvcpgwsybs8i2wq.png"></p><br><p>  Seperti dalam kasus sebelumnya, dalam proses propagasi langsung dan balik, kami tidak menggunakan ketiga neuron ini.  Terakhir, iterasi pelatihan ketiga, kami memutuskan untuk tidak menggunakan dua neuron ini: </p><br><p><img src="https://habrastorage.org/webt/dk/jf/ac/dkjfacty06iu6r6aopxq9by5qs4.png"></p><br><p>  Dan dalam hal ini, kami tidak menggunakan neuron yang terputus dalam proses propagasi langsung dan terbalik.  Dan sebagainya. </p><br><p>  Dengan melatih jaringan saraf kita dengan cara ini kita dapat menghindari pelatihan ulang.  Kita dapat mengatakan bahwa jaringan saraf kita menjadi lebih stabil, karena dengan pendekatan ini, ia tidak dapat bergantung sepenuhnya pada semua neuron untuk menyelesaikan masalah.  Dengan demikian, neuron lain mulai mengambil bagian yang lebih aktif dalam pembentukan nilai output yang dibutuhkan dan juga mulai mengatasi tugas tersebut. </p><br><p>  Dalam praktiknya, pendekatan ini membutuhkan indikasi kemungkinan menghilangkan setiap neuron pada setiap iterasi pelatihan.  Harap dicatat bahwa menunjukkan kemungkinan kita menemukan diri kita dalam situasi di mana beberapa neuron akan lebih sering terputus daripada yang lain, dan beberapa mungkin tidak terputus sama sekali.  Namun, ini bukan masalah, karena proses ini dilakukan berkali-kali dan rata-rata setiap neuron dengan probabilitas yang sama dapat terputus. </p><br><p>  Sekarang mari kita terapkan pengetahuan teoretis yang diperoleh dalam praktik dan sempurnakan klasifikasi gambar kucing dan anjing kita. </p><br><h1>  CoLab: anjing dan kucing.  Pengulangan </h1><br><p>  CoLab dalam bahasa Inggris tersedia di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ini</a> . <br>  CoLab dalam bahasa Rusia tersedia di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan ini</a> . </p><br><h2 id="koshki-vs-sobaki-klassifikaciya-izobrazheniy-s-rasshireniem">  Kucing VS Anjing: klasifikasi gambar dengan ekstensi </h2><br><p>  Dalam tutorial ini, kita akan membahas cara mengategorikan gambar kucing dan anjing.  Kami akan mengembangkan penggolong gambar menggunakan model <code>tf.keras.Sequential</code> , dan menggunakan <code>tf.keras.Sequential</code> untuk memuat data. </p><br><h3 id="idei-kotorye-budut-zatronuty-v-etoy-chasti">  Gagasan yang akan dibahas di bagian ini: </h3><br><p>  Kami akan mendapatkan pengalaman praktis dalam mengembangkan classifier dan mengembangkan pemahaman intuitif konsep-konsep berikut: </p><br><ol><li>  Membangun model aliran data ( <em>jalur input data</em> ) menggunakan kelas <code>tf.keras.preprocessing.image.ImageDataGenerator</code> (Bagaimana cara efisien bekerja dengan data pada disk yang berinteraksi dengan model?) </li><li>  Pelatihan ulang - apa itu dan bagaimana menentukannya? </li><li>  Augmentasi data dan metode putus sekolah adalah teknik utama dalam memerangi pelatihan ulang dalam tugas pengenalan pola yang akan kami terapkan dalam proses pelatihan model kami. </li></ol><br><h4 id="my-budem-sledovat-osnovnomu-podhodu-pri-razrabotke-modeley-mashinnogo-obucheniya">  Kami akan mengikuti pendekatan dasar dalam mengembangkan model pembelajaran mesin: </h4><br><ol><li>  Jelajahi dan pahami data </li><li>  Konfigurasikan aliran input </li><li>  Membangun model </li><li>  Model kereta </li><li>  Model uji </li><li>  Perbaiki Model / Proses Ulangi </li></ol><br><p>  <strong>Sebelum kita mulai ...</strong> </p><br><p>  Sebelum memulai kode di editor, kami sarankan Anda mengatur ulang semua pengaturan di <strong>Runtime -&gt; Reset semua</strong> di menu atas.  Tindakan semacam itu akan membantu menghindari masalah dengan kekurangan memori, jika Anda bekerja secara paralel atau bekerja dengan beberapa editor. </p><br><h1 id="importirovanie-paketov">  Paket impor </h1><br><p>  Mari kita mulai dengan mengimpor paket yang Anda butuhkan: </p><br><ul><li>  <code>os</code> - baca file dan struktur direktori; </li><li>  <code>numpy</code> - untuk beberapa operasi matriks di luar TensorFlow; </li><li>  <code>matplotlib.pyplot</code> - merencanakan dan menampilkan gambar dari dataset uji dan validasi. </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np</code> </pre> <br><p>  Impor <code>TensorFlow</code> : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras.preprocessing.image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ImageDataGenerator</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging logger = tf.get_logger() logger.setLevel(logging.ERROR)</code> </pre> <br><h1 id="zagruzka-dannyh">  Pemuatan data </h1><br><p>  Kami memulai pengembangan classifier kami dengan memuat dataset.  Kumpulan data yang kami gunakan adalah versi yang disaring dari kumpulan data <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Anjing vs Kucing</a> dari layanan Kaggle (pada akhirnya, kumpulan data ini disediakan oleh Microsoft Research). </p><br><p>  Di masa lalu, CoLab dan saya menggunakan dataset dari modul <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">TensorFlow Dataset</a> itu sendiri, yang sangat nyaman untuk bekerja dan pengujian.  Namun, dalam CoLab ini, kita akan menggunakan kelas <code>tf.keras.preprocessing.image.ImageDataGenerator</code> untuk membaca data dari disk.  Oleh karena itu, pertama-tama kita perlu mengunduh kumpulan data Anjing VS Kucing dan unzip. </p><br><pre> <code class="python hljs">_URL = <span class="hljs-string"><span class="hljs-string">'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'</span></span> zip_dir = tf.keras.utils.get_file(<span class="hljs-string"><span class="hljs-string">'cats_and_dogs_filterted.zip'</span></span>, origin=_URL, extract=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><p>  Kumpulan data yang kami unduh memiliki struktur berikut: </p><br><pre> <code class="plaintext hljs">cats_and_dogs_filtered |__ train |______ cats: [cat.0.jpg, cat.1.jpg, cat.2.jpg ...] |______ dogs: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...] |__ validation |______ cats: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ...] |______ dogs: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]</code> </pre> <br><p>  Untuk mendapatkan daftar lengkap direktur, Anda dapat menggunakan perintah berikut: </p><br><pre> <code class="python hljs">zip_dir_base = os.path.dirname(zip_dir) !find $zip_dir_base -type d -<span class="hljs-keyword"><span class="hljs-keyword">print</span></span></code> </pre> <br><p>  Output (saat mulai dari CoLab): </p><br><pre> <code class="plaintext hljs">/root/.keras/datasets /root/.keras/datasets/cats_and_dogs_filtered /root/.keras/datasets/cats_and_dogs_filtered/train /root/.keras/datasets/cats_and_dogs_filtered/train/dogs /root/.keras/datasets/cats_and_dogs_filtered/train/cats /root/.keras/datasets/cats_and_dogs_filtered/validation /root/.keras/datasets/cats_and_dogs_filtered/validation/dogs /root/.keras/datasets/cats_and_dogs_filtered/validation/cats</code> </pre> <br><p>  Sekarang tetapkan jalur yang benar ke direktori dengan set data untuk pelatihan dan validasi ke variabel: </p><br><pre> <code class="python hljs">base_dir = os.path.join(os.path.dirname(zip_dir), <span class="hljs-string"><span class="hljs-string">'cats_and_dogs_filtered'</span></span>) train_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>) validation_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'validation'</span></span>) train_cats_dir = os.path.join(train_dir, <span class="hljs-string"><span class="hljs-string">'cats'</span></span>) train_dogs_dir = os.path.join(train_dir, <span class="hljs-string"><span class="hljs-string">'dogs'</span></span>) validation_cats_dir = os.path.join(validation_dir, <span class="hljs-string"><span class="hljs-string">'cats'</span></span>) validation_dogs_dir = os.path.join(validation_dir, <span class="hljs-string"><span class="hljs-string">'dogs'</span></span>)</code> </pre> <br><h4 id="razbiraemsya-s-dannymi-i-ih-strukturoy">  Memahami data dan strukturnya </h4><br><p>  Mari kita lihat berapa banyak gambar kucing dan anjing yang kita miliki dalam kumpulan data pengujian dan validasi (direktori). </p><br><pre> <code class="python hljs">num_cats_tr = len(os.listdir(train_cats_dir)) num_dogs_tr = len(os.listdir(train_dogs_dir)) num_cats_val = len(os.listdir(validation_cats_dir)) num_dogs_val = len(os.listdir(validation_dogs_dir)) total_train = num_cats_tr + num_dogs_tr total_val = num_cats_val + num_dogs_val</code> </pre> <br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_cats_tr) print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_dogs_tr) print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_cats_val) print(<span class="hljs-string"><span class="hljs-string">'    : '</span></span>, num_dogs_val) print(<span class="hljs-string"><span class="hljs-string">'--'</span></span>) print(<span class="hljs-string"><span class="hljs-string">'     : '</span></span>, total_train) print(<span class="hljs-string"><span class="hljs-string">'     : '</span></span>, total_val)</code> </pre> <br><p>  Kesimpulan: </p><br><pre> <code class="plaintext hljs">    : 1000     : 1000     : 500     : 500 --      : 2000      : 1000</code> </pre> <br><h1 id="ustanovka-parametrov-modeli">  Pengaturan parameter model </h1><br><p>  Untuk kenyamanan, kami akan menempatkan pemasangan variabel yang kami butuhkan untuk pemrosesan data lebih lanjut dan pelatihan model dalam pengumuman terpisah: </p><br><pre> <code class="python hljs">BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-comment"><span class="hljs-comment">#          IMG_SHAPE = 150 #       </span></span></code> </pre> <br><h1 id="rasshirenie-dannyh">  Ekstensi data </h1><br><p>  Pelatihan ulang biasanya terjadi ketika ada beberapa contoh pelatihan dalam dataset kami.  Salah satu cara untuk menghilangkan kekurangan data adalah mengembangkannya ke jumlah instance yang tepat dan variabilitas yang tepat.  Ekstensi data adalah proses menghasilkan data dari instance yang ada dengan menerapkan berbagai transformasi pada set data asli.  Tujuan dari metode ini adalah untuk menambah jumlah instance input unik yang model tidak akan pernah melihat lagi, yang, pada gilirannya, akan memungkinkan model untuk lebih menggeneralisasi data input dan menunjukkan akurasi yang lebih besar pada set data validasi. </p><br><p>  Menggunakan <strong><code>tf.keras</code></strong> kita dapat mengimplementasikan transformasi acak tersebut dan menghasilkan gambar baru melalui kelas <strong><code>ImageDataGenerator</code></strong> .  Ini akan cukup bagi kita untuk lulus dalam bentuk parameter berbagai transformasi yang ingin kita terapkan pada gambar, dan kelas itu sendiri akan mengurus sisanya selama pelatihan model. </p><br><p>  Pertama, mari kita menulis fungsi yang akan menampilkan gambar yang diperoleh sebagai hasil dari transformasi acak.  Kemudian kita akan memeriksa secara lebih rinci transformasi yang digunakan dalam proses perluasan set data asli. </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plotImages</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images_arr)</span></span></span><span class="hljs-function">:</span></span> fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>,<span class="hljs-number"><span class="hljs-number">20</span></span>)) axes = axes.flatten() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> img, ax <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(images_arr, axes): ax.imshow(img) plt.tight_layout() plt.show()</code> </pre> <br><h4 id="perevorachivanie-izobrazheniya-po-gorizontali">  Balikkan gambar secara horizontal </h4><br><p>  Kita dapat mulai dengan konversi sederhana - membalik gambar horizontal.  Mari kita lihat bagaimana transformasi ini akan terlihat diterapkan pada gambar sumber kami.        <code>horizontal_flip=True</code>   <strong>ImageDataGenerator</strong> . </p><br><pre> <code class="python hljs">image_gen = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>, horizontal_flip=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, target_size=(IMG_SHAPE, IMG_SHAPE))</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Found 2000 images belonging to 2 classes.</code> </pre> <br><p>                    .      (  )   . </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><p>  (2  5 ): </p><br><p><img src="https://habrastorage.org/webt/9k/ss/zk/9ksszkjktuykiawts9xldwp8d6e.png"></p><br><h4 id="povorot-izobrazheniy">   </h4><br><p>            .        45. </p><br><pre> <code class="python hljs">image_gen = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>, rotation_range=<span class="hljs-number"><span class="hljs-number">45</span></span>) train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, target_size=(IMG_SHAPE, IMG_SHAPE))</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Found 2000 images belonging to 2 classes.</code> </pre> <br><p>         ‚Äî          5   .      (  )   . </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><p>  (2   5): </p><br><p><img src="https://habrastorage.org/webt/f4/7a/du/f47adubevummwogquqvplmzvy5k.png"></p><br><h4 id="primenenie-uvelicheniya">   </h4><br><p>             ‚Äî    50%. </p><br><pre> <code class="python hljs">image_gen = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>, zoom_range=<span class="hljs-number"><span class="hljs-number">0.5</span></span>) train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, target_size=(IMG_SHAPE, IMG_SHAPE))</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Found 2000 images belonging to 2 classes.</code> </pre> <br><p>   ,      ‚Äî 5      .   (  )       . </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><p>  (2  5 ): </p><br><p><img src="https://habrastorage.org/webt/i6/75/qx/i675qx7wsf8c4woaxoipll-j8cs.png"></p><br><h4 id="obedinyaem-vsyo-vmeste">    </h4><br><p>       ,   ,   ,          <code>ImageDataGenerator</code> . </p><br><p>       ‚Äî   ,   45 ,   ,   ,    . </p><br><pre> <code class="python hljs">image_gen_train = ImageDataGenerator( rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>, rotation_range=<span class="hljs-number"><span class="hljs-number">40</span></span>, width_shift_range=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, height_shift_range=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, shear_range=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, zoom_range=<span class="hljs-number"><span class="hljs-number">0.2</span></span>, horizontal_flip=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, fill_mode=<span class="hljs-string"><span class="hljs-string">'nearest'</span></span> ) train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, target_size=(IMG_SHAPE, IMG_SHAPE), class_mode=<span class="hljs-string"><span class="hljs-string">'binary'</span></span>)</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Found 2000 images belonging to 2 classes.</code> </pre> <br><p>   ,           . </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><p>  (2   5): </p><br><p><img src="https://habrastorage.org/webt/8e/nu/xg/8enuxgydgovr7ppmile7k3arbwg.png"></p><br><h4 id="sozdayom-validacionnyy-nabor-dannyh">     </h4><br><p>  ,       ,       ,            .        ,   ,  . </p><br><pre> <code class="python hljs">image_gen_val = ImageDataGenerator(rescale=<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">255</span></span>) val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE, directory=validation_dir, target_size=(IMG_SHAPE, IMG_SHAPE), class_mode=<span class="hljs-string"><span class="hljs-string">'binary'</span></span>)</code> </pre> <br><h1 id="sozdanie-modeli">   </h1><br><h3 id="opisyvaem-model">   </h3><br><p>    4           . </p><br><p>             0.5.  ,  50%          0.    . </p><br><p>        512     <code>relu</code> .        ‚Äî    ‚Äî  <code>softmax</code> . </p><br><pre> <code class="python hljs">model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(IMG_SHAPE, IMG_SHAPE, <span class="hljs-number"><span class="hljs-number">3</span></span>)), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">128</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>), tf.keras.layers.Flatten(), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>) ])</code> </pre> <br><h4 id="kompilirovanie-modeli">   </h4><br><p>       <code>adam</code> .      <code>sparse_categorical_crossentropy</code> .            ,    <code>accuracy</code>   <code>metrics</code> : </p><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br><h4 id="predstavlenie-modeli">   </h4><br><p>           <strong>summary</strong> : </p><br><pre> <code class="python hljs">model.summary()</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Model: "sequential" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 148, 148, 32) 896 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 74, 74, 32) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 72, 72, 64) 18496 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64) 0 _________________________________________________________________ conv2d_2 (Conv2D) (None, 34, 34, 128) 73856 _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128) 0 _________________________________________________________________ conv2d_3 (Conv2D) (None, 15, 15, 128) 147584 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128) 0 _________________________________________________________________ dropout (Dropout) (None, 7, 7, 128) 0 _________________________________________________________________ flatten (Flatten) (None, 6272) 0 _________________________________________________________________ dense (Dense) (None, 512) 3211776 _________________________________________________________________ dense_1 (Dense) (None, 2) 1026 ================================================================= Total params: 3,453,634 Trainable params: 3,453,634 Non-trainable params: 0 _________________________________________________________________</code> </pre> <br><h4 id="trenirovka-modeli">   </h4><br><p>    ! </p><br><p>         ( <code>ImageDataGenerator</code> )    <code>fit_generator</code>     <code>fit</code> : </p><br><pre> <code class="python hljs">EPOCHS = <span class="hljs-number"><span class="hljs-number">100</span></span> history = model.fit_generator( train_data_gen, steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))), epochs=EPOCHS, validation_data=val_data_gen, validation_steps=int(np.ceil(total_val / float(BATCH_SIZE))) )</code> </pre> <br><h4 id="vizualizaciya-rezultatov-trenirovki">    </h4><br><p>       : </p><br><pre> <code class="plaintext hljs">acc = history.history['acc'] val_acc = history.history['val_acc'] loss = history.history['loss'] val_loss = history.history['val_loss'] epochs_range = range(EPOCHS) plt.figure(figsize=(8,8)) plt.subplot(1, 2, 1) plt.plot(epochs_range, acc, label='  ') plt.plot(epochs_range, val_acc, label='  ') plt.legend(loc='lower right') plt.title('     ') plt.subplot(1, 2, 2) plt.plot(epochs_range, loss, label='  ') plt.plot(epochs_range, val_loss, label='  ') plt.legend(loc='upper right') plt.title('     ') plt.savefig('./foo.png') plt.show()</code> </pre> <br><p> : </p><br><p><img src="https://habrastorage.org/webt/bo/ea/t2/boeat2ibnf3khchazx3lslllj2e.png"></p><br><h1>      </h1><br><p>        ,    : </p><br><ol><li> <strong> </strong> :                      (   ). </li><li> <strong>  (.. augmentation)</strong> :                . </li><li> <strong> /  (.. dropout)</strong> :           (   ,      ). </li></ol><br><p>         ,     .           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="> </a> . </p><br><h1> :    </h1><br><p>  CoLab      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="> </a> . <br> CoLab      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="> </a> . </p><br><p>                .      CoLab        .   CoLab               .   CoLab       ,             . </p><br><p>               CoLab.   CoLab        ,       ,         . </p><br><p> ! </p><br><p>ÔªøÔªø#     tf.keras </p><br><p>   CoLab     .        <code>tf.keras.Sequential</code> ,      <code>ImageDataGenerator</code> . </p><br><h1 id="importirovanie-paketov-1">   </h1><br><p>      . <code>os</code>         , <code>numpy</code>     python-  numpy-     ,  ,   <code>matplotlib.pyplot</code>         . </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> glob <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> shutil <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt</code> </pre> <br><h3 id="todo-importiruem-tensorflow-i-keras-sloi"> TODO:  TensorFlow  Keras- </h3><br><p>         TensorFlow  <code>tf</code>  Keras-  ,         .  ,  <code>ImageDataGenerator</code> -  Keras         . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  </span></span></code> </pre> <br><h1 id="zagruzka-dannyh-1">   </h1><br><p>                ‚Äî   .              . </p><br><p>    . </p><br><pre> <code class="python hljs">_URL = <span class="hljs-string"><span class="hljs-string">"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"</span></span> zip_file = tf.keras.utils.get_file(origin=_URL, fname=<span class="hljs-string"><span class="hljs-string">"flower_photos.tgz"</span></span>, extract=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) base_dir = os.path.join(os.path.dirname(zip_file), <span class="hljs-string"><span class="hljs-string">'flower_photos'</span></span>)</code> </pre> <br><p>  ,    ,  5  : </p><br><ol><li>  </li><li>  </li><li>  </li><li>  </li><li>  </li></ol><br><p>        : </p><br><pre> <code class="python hljs">classes = [<span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>]</code> </pre> <br><p>  ,   ,   : </p><br><pre> <code class="plaintext hljs">flower_photos |__ diasy |__ dandelion |__ roses |__ sunflowers |__ tulips</code> </pre> <br><p>                  .            .   ,    . </p><br><p>    2  <code>train</code>  <code>val</code>      5 - (    ).          ,  80%      ,   20%     .      : </p><br><pre> <code class="plaintext hljs">flower_photos |__ diasy |__ dandelion |__ roses |__ sunflowers |__ tulips |__ train |______ daisy: [1.jpg, 2.jpg, 3.jpg ....] |______ dandelion: [1.jpg, 2.jpg, 3.jpg ....] |______ roses: [1.jpg, 2.jpg, 3.jpg ....] |______ sunflowers: [1.jpg, 2.jpg, 3.jpg ....] |______ tulips: [1.jpg, 2.jpg, 3.jpg ....] |__ val |______ daisy: [507.jpg, 508.jpg, 509.jpg ....] |______ dandelion: [719.jpg, 720.jpg, 721.jpg ....] |______ roses: [514.jpg, 515.jpg, 516.jpg ....] |______ sunflowers: [560.jpg, 561.jpg, 562.jpg .....] |______ tulips: [640.jpg, 641.jpg, 642.jpg ....]</code> </pre> <br><p>       ,     ,   .             . </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> cl <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> classes: img_path = os.path.join(base_dir, cl) images = glob.glob(img_path + <span class="hljs-string"><span class="hljs-string">'/*.jpg'</span></span>) print(<span class="hljs-string"><span class="hljs-string">"{}: {} "</span></span>.format(cl, len(images))) train, val = images[:round(len(images)*<span class="hljs-number"><span class="hljs-number">0.8</span></span>)], images[round(len(images)*<span class="hljs-number"><span class="hljs-number">0.8</span></span>):] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> train: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>, cl)): os.makedirs(os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>, cl)) shutil.move(t, os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>, cl)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> v <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> val: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'val'</span></span>, cl)): os.makedirs(os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'val'</span></span>, cl)) shutil.move(v, os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'val'</span></span>, cl))</code> </pre> <br><p>            : </p><br><pre> <code class="python hljs">train_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'train'</span></span>) val_dir = os.path.join(base_dir, <span class="hljs-string"><span class="hljs-string">'val'</span></span>)</code> </pre> <br><h1 id="rasshirenie-dannyh-1">   </h1><br><p> ,  ,  ,       .       ‚Äî   (.. augmentation)     .                    .    ,    ,         ‚Äî     ,   .          . </p><br><p>  <strong>tf.keras</strong>       ,             ‚Äî <strong>ImageDataGenerator</strong> .                  . </p><br><h2 id="eksperimentiruyte-s-razlichnymi-preobrazovaniyami-izobrazheniy">      </h2><br><p>            .            ‚Äî        ()    <code>batch_size</code> ,            <code>IMG_SHAPE</code> . </p><br><h4 id="todo-ustanovite-kolichestvo-obuchayuschih-blokov-i-razmer-izobrazheniy"> TODO:        </h4><br><p>      100   <code>batch_size</code>   150   <code>IMG_SHAPE</code> : </p><br><pre> <code class="python hljs">batch_size = IMG_SHAPE =</code> </pre> <br><h4 id="todo-primenite-proizvolnyy-gorizontalnyy-perevorot-izobrazheniya"> TODO:      </h4><br><p>      <code>ImageDataGenerator</code>   ,       ,      .     <code>.flow_from_directory</code>          . ,      ,       ,          . </p><br><pre> <code class="python hljs">image_gen = train_data_gen =</code> </pre> <br><p>         5      : </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plotImages</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images_arr)</span></span></span><span class="hljs-function">:</span></span> fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>,<span class="hljs-number"><span class="hljs-number">20</span></span>)) axes = axes.flatten() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> img, ax <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(images_arr, axes): ax.imshow(img) plt.tight_layout() plt.show() augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><h4 id="todo-primenite-proizvolnyy-perevorot-izobrazheniya"> TODO:     </h4><br><p>   ,   <code>ImageDataGenerator</code>          45 .     .flow_from_directory          . ,      ,       ,          . </p><br><pre> <code class="python hljs">image_gen = train_data_gen =</code> </pre> <br><p>         5      : </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><h4 id="todo-primenite-proizvolnoe-uvelichenie-izobrazheniya"> TODO:     </h4><br><p>   ,   ImageDataGenerator          50%.     .flow_from_directory          . ,      ,       ,          . </p><br><pre> <code class="python hljs">image_gen = train_data_gen =</code> </pre> <br><p>         5      : </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><h4 id="todo-obedinyaem-vse-izmeneniya"> TODO:    </h4><br><p>     ,   <code>ImageDataGenerator</code>          : </p><br><ul><li>   45  </li><li>   50% </li><li>   </li><li>     0.15 </li><li>     0.15 </li></ul><br><p>    <code>flow_from_directory</code>          . ,      ,       ,          . </p><br><pre> <code class="python hljs">image_gen_train = train_data_gen =</code> </pre> <br><p>         5      : </p><br><pre> <code class="python hljs">augmented_images = [train_data_gen[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>)] plotImages(augmented_images)</code> </pre> <br><h4 id="todo-sozdayte-generator-izobrazheniy-dlya-validacionnogo-nabora-dannyh"> TODO:        </h4><br><p>         . ,   ,   <code>ImageDataGenerator</code>   ,      .    <code>flow_from_directory</code>          . ,      ,           .      . </p><br><pre> <code class="python hljs">image_gen_val = val_data_gen =</code> </pre> <br><h1 id="todo-sozdayte-svyortochnuyu-neyronnuyu-set"> TODO:     </h1><br><p>       ,     3   ‚Äî        .      16 ,  ‚Äî 32 ,  ‚Äî 64 .      33.          22. </p><br><p>         <code>Flatten</code> ,      512 .           5 ,       <strong>softmax</strong> .        <strong>relu</strong> .  ,   ,       20%. </p><br><pre> <code class="python hljs">model =</code> </pre> <br><h1 id="todo-skompiliruyte-model"> TODO:   </h1><br><p>     ,        <code>adam</code>   <code>sparse_categorical_crossentropy</code>    .                  ,         <code>compile(...)</code> . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  </span></span></code> </pre> <br><h1 id="todo-obuchite-model"> TODO:   </h1><br><p>     ,        <strong>fit_generator</strong>    <strong>fit</strong> ,    .    <strong>fit_generator</strong>       <strong>ImageDataGenerator</strong>          .    80   ,      <strong>fit_generator</strong> -. </p><br><pre> <code class="python hljs">epochs = history =</code> </pre> <br><h1 id="todo-postroyte-grafiki-tochnosti--poter-dlya-obuchayuschego-i-validacionnogo-naborov-dannyh"> TODO:    /        </h1><br><p>     ,            : </p><br><pre> <code class="python hljs">acc = val_acc = loss = val_loss = epochs_range =</code> </pre> <br><h1 id="todo-poeksperimentiruyte-s-razlichnymi-parametrami"> TODO:     </h1><br><p>              (  +  )       512 .             .      . ,            ,       ..        <strong></strong>   ,     <strong>ImageDataGenerator</strong> ‚Äî         .       ,             . </p><br><p>      ? </p><br><h1>  </h1><br><p>                    . </p><br><p>             RGB-  : </p><br><ul><li> <strong> </strong> :      ,                  (   ); </li><li> <strong> </strong> :      3D-; </li><li> <strong>RGB-</strong> :     3  : ,   ; </li><li> <strong></strong> :                  ().               ,          ().         ‚Äî      . </li><li> <strong>   </strong> :                       .            ,          . </li><li> <strong>  </strong> :               .               ,                . </li></ul><br><p>    : </p><br><ul><li> <strong> </strong> :                    ,      . </li><li> <strong> </strong> :                    . </li><li> <strong> ()</strong> :         . </li></ul><br><p>                       .       ,                     .                    . </p><br><p> ‚Ä¶   call-to-action ‚Äî ,     share :) <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">YouTube</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Telegram</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">VKontakte</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id458170/">https://habr.com/ru/post/id458170/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id458154/index.html">Kisah luar biasa tentang asal port USB yang mengubah segalanya</a></li>
<li><a href="../id458156/index.html">Benchmarking PostgreSQL dengan FreeBSD, CentOS, Ubuntu Debian, dan openSUSE</a></li>
<li><a href="../id458158/index.html">Mencari asteroid - proyek Hubble Asteroid Hunter</a></li>
<li><a href="../id458160/index.html">Kunci Prioritas di .NET</a></li>
<li><a href="../id458168/index.html">Juni Machine Learning dan Intelijen Berita Buatan Intisari</a></li>
<li><a href="../id458176/index.html">Penghalang exaflops akan diatasi pada 2021</a></li>
<li><a href="../id458184/index.html">Haxe dan PHP: pengetikan statis, fungsi panah, metaprogramming, dan banyak lagi</a></li>
<li><a href="../id458186/index.html">WAL di PostgreSQL: 1. Buffer cache</a></li>
<li><a href="../id458190/index.html">Saya mengerti, itu berarti saya ada: ulasan tentang Deep Learning in Computer Vision (bagian 2)</a></li>
<li><a href="../id458202/index.html">Lihatlah SObjectizer jika Anda ingin menggunakan Aktor atau CSP dalam proyek C ++ Anda</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª‚Äçü§ù‚Äçüë®üèº üíáüèΩ üò¢ USE, RED, PgBouncer, seine Einstellungen und √úberwachung ü•î üìê ‚úäüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir haben begonnen, die √úberwachung f√ºr PgBouncer in unserem Service zu aktualisieren, und beschlossen, alles ein wenig zu k√§mmen. Um alles fit zu mac...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>USE, RED, PgBouncer, seine Einstellungen und √úberwachung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/okmeter/blog/420429/"><img align="left" width="359" src="https://habrastorage.org/webt/l4/xy/iz/l4xyize9ztzrmf303fot3iylnc8.png" alt="Pgbouncer USE RED"><br><p>  Wir haben begonnen, die √úberwachung f√ºr PgBouncer in unserem Service zu aktualisieren, und beschlossen, alles ein wenig zu k√§mmen.  Um alles fit zu machen, haben wir die bekanntesten Methoden zur Leistungs√ºberwachung verwendet: USE (Utilization, Saturation, Errors) von Brendan Gregg und RED (Requests, Errors, Durations) von Tom Wilkie. </p><br><p>  Unter der Zwischensequenz finden Sie eine Geschichte mit Grafiken dar√ºber, wie pgbouncer funktioniert, welche Konfigurationshandles es hat und wie USE / RED verwendet wird, um die richtigen Metriken f√ºr die √úberwachung auszuw√§hlen. </p><a name="habracut"></a><br><h2 id="snachala-pro-sami-metody">  Zun√§chst zu den Methoden selbst </h2><br><p>  Obwohl diese Methoden ziemlich bekannt sind (√ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sie war es bereits bei Habr√©, wenn auch nicht sehr detailliert</a> ), ist es nicht so, dass sie in der Praxis weit verbreitet sind. </p><br><h3 id="use">  VERWENDUNG </h3><br><blockquote>  Behalten Sie f√ºr jede Ressource die Entsorgung, S√§ttigung und Fehler im Auge. <br>  Brendan Gregg </blockquote><p>  Hier ist eine <strong>Ressource</strong> eine separate physische Komponente - eine CPU, eine Festplatte, ein Bus usw.  Aber nicht nur - die Leistung einiger Softwareressourcen kann mit dieser Methode auch ber√ºcksichtigt werden, insbesondere virtuelle Ressourcen, wie z. B. Container / Gruppen mit Einschr√§nkungen, es ist auch zweckm√§√üig, dies zu ber√ºcksichtigen. </p><br><p> <strong>U - Entsorgung</strong> : entweder ein Prozentsatz der Zeit (ab dem Beobachtungsintervall), in der die Ressource mit n√ºtzlicher Arbeit besch√§ftigt war.  Da beispielsweise das Laden der CPU- oder Festplattenauslastung zu 90% bedeutet, dass 90% der Zeit von etwas N√ºtzlichem beansprucht wurde) oder f√ºr Ressourcen wie Speicher der Prozentsatz des verwendeten Speichers. </p><br><p>  In jedem Fall bedeutet 100% Recycling, dass die Ressource nicht mehr als jetzt genutzt werden kann.  Und entweder bleibt die Arbeit h√§ngen und wartet auf die Ver√∂ffentlichung / geht in die Warteschlange, oder es gibt Fehler.  Diese beiden Szenarien werden durch die entsprechenden zwei verbleibenden USE-Metriken abgedeckt: </p><br><p>  <strong>S - S√§ttigung</strong> , es ist auch S√§ttigung: ein Ma√ü f√ºr die Menge der "zur√ºckgestellten" / in die Warteschlange gestellten Arbeit. </p><br><p>  <strong>E - Fehler</strong> : Wir z√§hlen einfach die Anzahl der Fehler.  Fehler / Ausf√§lle beeintr√§chtigen die Leistung, sind jedoch m√∂glicherweise nicht sofort erkennbar, da gespiegelte Vorg√§nge oder Fehlertoleranzmechanismen mit Sicherungsger√§ten usw. abgerufen werden. </p><br><h3 id="red">  Rot </h3><br><p>  Tom Wilkie (der jetzt bei Grafana Labs arbeitet) war frustriert √ºber die USE-Methodik oder vielmehr √ºber die in einigen F√§llen schlechte Anwendbarkeit und die Inkonsistenz mit der Praxis.  Wie kann man zum Beispiel die S√§ttigung des Ged√§chtnisses messen?  Oder wie man Systembusfehler in der Praxis misst? </p><br><blockquote>  Es stellt sich heraus, dass Linux wirklich Fehlerzahlen meldet. <br>  T. Wilkie </blockquote><p>  Kurz gesagt, um die Leistung und das Verhalten von Mikrodiensten zu √ºberwachen, schlug er eine andere geeignete Methode vor: erneut drei Indikatoren zu messen: </p><br><p>  <strong>R - Rate</strong> : Die Anzahl der Anfragen pro Sekunde. <br>  <strong>E - Fehler</strong> : Wie viele Anfragen haben einen Fehler zur√ºckgegeben. <br>  <strong>D - Dauer</strong> : Zeitaufwand f√ºr die Bearbeitung der Anfrage.  Es ist Latenz, "Latenz" (¬© Sveta Smirnova :), Reaktionszeit usw. </p><br><p>  Im Allgemeinen eignet sich USE besser zur √úberwachung von Ressourcen und RED f√ºr Dienste und deren Arbeitslast / Nutzlast. </p><br><h2 id="pgbouncer">  Pgbouncer </h2><br><p>  Als Dienstleistung hat sie gleichzeitig alle m√∂glichen internen Grenzen und Ressourcen.  Gleiches gilt f√ºr Postgres, auf das Clients √ºber diesen PgBouncer zugreifen.  F√ºr eine vollst√§ndige √úberwachung in dieser Situation sind daher beide Methoden erforderlich. </p><br><p>  Um zu verstehen, wie diese Methoden auf einen T√ºrsteher angewendet werden, m√ºssen Sie die Details seines Ger√§ts verstehen.  Es reicht nicht aus, es als Black-Box zu √ºberwachen - "lebt der pgbouncer-Prozess" oder "ist der Port offen", weil  Im Falle von Problemen gibt dies kein Verst√§ndnis daf√ºr, was genau und wie es kaputt gegangen ist und was zu tun ist. </p><br><p>  Was macht PgBouncer im Allgemeinen aus Sicht des Kunden? </p><br><ol><li>  Client verbindet </li><li>  [Kunde stellt eine Anfrage - erh√§lt eine Antwort] x wie oft er ben√∂tigt </li></ol><br><p>  Hier habe ich ein Diagramm der entsprechenden Client-Zust√§nde aus Sicht von PgBoucer gezeichnet: <br><img src="https://habrastorage.org/webt/zb/mh/ot/zbmhotvidvuxnsbzp04-bqtgqhk.jpeg"></p><br><p> W√§hrend des Anmeldevorgangs kann die Autorisierung sowohl lokal (Dateien, Zertifikate und sogar PAM und hba aus neuen Versionen) als auch remote erfolgen - d. H.  in der Datenbank selbst, zu der die Verbindung versucht wird.  Somit hat der Anmeldestatus einen zus√§tzlichen Unterzustand.  Nennen wir es <code>Executing</code> um anzuzeigen, dass <code>auth_query</code> zu diesem Zeitpunkt in der Datenbank ausgef√ºhrt wird: <br><img src="https://habrastorage.org/webt/e4/ib/pb/e4ibpbf6ef5q9xcdy2fantydkc4.png"></p><br><p>  Diese Clientverbindungen stimmen jedoch tats√§chlich mit den Backend- / Upstream-Verbindungen √ºberein, die PgBouncer innerhalb des Pools √∂ffnet und eine begrenzte Anzahl enth√§lt.  Und sie stellen eine solche Verbindung zum Client nur f√ºr die Zeit her - f√ºr die Dauer der Sitzung, Transaktion oder Anforderung, abh√§ngig von der Art des Poolings (bestimmt durch die Einstellung <code>pool_mode</code> ).  In den meisten F√§llen wird das Transaktionspooling verwendet (wir werden es haupts√§chlich sp√§ter besprechen) - wenn die Verbindung f√ºr eine Transaktion an den Client ausgegeben wird und der Client f√ºr den Rest der Zeit tats√§chlich nicht mit dem Server verbunden ist.  Der "aktive" Zustand des Clients sagt also wenig aus, und wir werden ihn in Substrate unterteilen: <br><img src="https://habrastorage.org/webt/uv/q4/tj/uvq4tjzbbauunpwzhboxc8s3pgu.png"></p><br><p>  Jeder dieser Clients f√§llt in seinen eigenen Verbindungspool, der f√ºr die tats√§chliche Verbindung zu Postgres ausgegeben wird.  Dies ist die Hauptaufgabe von PgBouncer - die Anzahl der Verbindungen zu Postgres zu begrenzen. </p><br><p>  Aufgrund der eingeschr√§nkten Serververbindungen kann es vorkommen, dass der Client die Anforderung direkt erf√ºllen muss, aber derzeit keine freie Verbindung besteht.  Dann wird der Client in die Warteschlange gestellt und seine Verbindung wird in den <code>CL_WAITING</code> .  Daher muss das Zustandsdiagramm erg√§nzt werden: <br><img src="https://habrastorage.org/webt/2v/ny/yu/2vnyyuhlqher6cc5q5izwjtu7te.png"><br>  Da dies passieren kann, wenn sich der Client nur anmeldet und eine Autorisierungsanforderung ausf√ºhren muss, wird auch der <code>CL_WAITING_LOGIN</code> . </p><br><p>  Wenn Sie jetzt von der R√ºckseite - von der Seite der Serververbindungen - <code>SV_LOGIN</code> , befinden sie sich dementsprechend in solchen Zust√§nden: Wenn die Autorisierung unmittelbar nach der Verbindung erfolgt - <code>SV_LOGIN</code> , ausgestellt und (m√∂glicherweise) vom Client verwendet - <code>SV_ACTIVE</code> oder frei - <code>SV_IDLE</code> . </p><br><h2 id="use-dlya-pgbouncer">  VERWENDUNG f√ºr PgBouncer </h2><br><p>  So kommen wir zur (naiven Version) Nutzung eines bestimmten Pools: </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">Pool</span></span> utiliz =    /  </code> </pre> <br><p>  PgBouncer verf√ºgt √ºber eine spezielle pgbouncer-Dienstprogrammdatenbank, in der sich ein <code>SHOW POOLS</code> , der den aktuellen Status der Verbindungen jedes Pools anzeigt: <br><img src="https://habrastorage.org/webt/xz/_o/eb/xz_oebvf-0yahuvdfzrxx3iass0.png"><br>  Es sind 4 Clientverbindungen offen und alle sind <code>cl_active</code> .  Von 5 Serververbindungen - 4 <code>sv_active</code> und eine im neuen Status <code>sv_used</code> . </p><br><div class="spoiler">  <b class="spoiler_title">Was ist sv_used wirklich an den verschiedenen Einstellungen von pgbouncer, die nichts mit der √úberwachung zu tun haben?</b> <div class="spoiler_text"><p>  <code>sv_used</code> bedeutet also nicht "Verbindung wird verwendet", wie Sie vielleicht denken, sondern "Verbindung wurde einmal verwendet und wurde lange nicht mehr verwendet".  Tatsache ist, dass PgBouncer standardm√§√üig Serververbindungen im LIFO-Modus verwendet - d. H.  Zuerst werden neu freigegebene Verbindungen verwendet, dann k√ºrzlich verwendete usw.  allm√§hlich zu lang verwendeten Verbindungen √ºbergehen.  Dementsprechend k√∂nnen Serververbindungen von der Unterseite eines solchen Stapels "schlecht werden".  Und sie sollten vor der Verwendung auf Lebendigkeit √ºberpr√ºft werden, was mit <code>server_check_query</code> erfolgt. W√§hrend sie √ºberpr√ºft werden, wird der Status <code>sv_tested</code> . </p><br><p>  Die Dokumentation besagt, dass LIFO standardm√§√üig als aktiviert ist  dann "bekommt eine kleine Anzahl von Verbindungen die meiste Arbeitslast. Und dies bietet die beste Leistung, wenn es einen Server gibt, der die Datenbank hinter pgbouncer bedient", d.h.  wie im typischsten Fall.  Ich glaube, dass der potenzielle Leistungsschub auf die Einsparungen bei der Switching-Leistung zwischen mehreren Backend-Prozessen zur√ºckzuf√ºhren ist.  Aber es hat nicht zuverl√§ssig geklappt, weil  Dieses Implementierungsdetail besteht seit&gt; 12 Jahren und geht √ºber die Commit-Historie f√ºr Github und die Tiefe meines Interesses hinaus =) </p><br><p>  Es schien also seltsam und <code>server_check_delay</code> mit den aktuellen Realit√§ten, dass der Standardwert der Einstellung <code>server_check_delay</code> , die feststellt, dass der Server nicht zu lange verwendet wurde und √ºberpr√ºft werden sollte, bevor er an den Client √ºbergeben wird, 30 Sekunden betr√§gt.  Dies trotz der Tatsache, dass standardm√§√üig tcp_keepalive gleichzeitig mit den Standardeinstellungen aktiviert ist. Beginnen Sie 2 Stunden nach dem Leerlauf mit der √úberpr√ºfung der Keep-Alive-Verbindung mit Samples. <br>  Es stellt sich heraus, dass in einer Burst / Surge-Situation von Clientverbindungen, die etwas auf dem Server tun m√∂chten, eine zus√§tzliche Verz√∂gerung f√ºr <code>server_check_query</code> eingef√ºhrt <code>server_check_query</code> , die, obwohl " <code>SELECT 1;</code> immer noch ~ 100 Mikrosekunden dauern kann, und wenn <code>server_check_query = ';'</code>  dann k√∂nnen Sie ~ 30 Mikrosekunden sparen =) </p><br><p>  Aber die Annahme, dass die Arbeit in nur wenigen Verbindungen = an mehreren "Haupt" -Back-End-Postgres-Prozessen effizienter ist, scheint mir zweifelhaft.  Der Postgres-Worker-Prozess speichert (Meta-) Informationen zu jeder Tabelle, auf die in diesem Zusammenhang zugegriffen wurde.  Wenn Sie eine gro√üe Anzahl von Tabellen haben, kann dieser Relcache sehr stark wachsen und viel Speicher beanspruchen, bis die Seiten des 0_o-Prozesses ausgetauscht werden.  Um dies zu <code>server_lifetime</code> , verwenden Sie die Einstellung <code>server_lifetime</code> (Standard ist 1 Stunde), mit der die Serververbindung f√ºr die Rotation geschlossen wird.  Andererseits gibt es eine Einstellung f√ºr <code>server_round_robin</code> , mit der der Modus f√ºr die Verwendung von Verbindungen von LIFO zu FIFO <code>server_round_robin</code> wodurch Clientanforderungen auf Serververbindungen gleichm√§√üiger verteilt werden. </p></div></div><br><p>  <code>SHOW POOLS</code> wir <code>SHOW POOLS</code> Metriken von <code>SHOW POOLS</code> (von einem Prometheus-Exporteur) √ºbernehmen, k√∂nnen wir diese Zust√§nde darstellen: </p><br><p><img src="https://habrastorage.org/webt/i8/8f/-x/i88f-xpwo_2hj7z6iq6qbnatsju.png"></p><br><p>  Um zur Verf√ºgung zu stehen, m√ºssen Sie jedoch einige Fragen beantworten: </p><br><ul><li>  Wie gro√ü ist der Pool? </li><li>  Wie wird gez√§hlt, wie viele Verbindungen verwendet werden?  In Witzen oder in der Zeit, im Durchschnitt oder in der Spitze? </li></ul><br><h3 id="razmer-pula">  Poolgr√∂√üe </h3><br><p>  Hier ist alles kompliziert, wie im Leben.  Insgesamt gibt es im pbbouncer bereits f√ºnf Einstellungslimits! </p><br><ul><li>  <code>pool_size</code> kann f√ºr jede Datenbank festgelegt werden.  F√ºr jedes DB / Benutzer-Paar wird ein separater Pool erstellt, d. H.  Von jedem <em>zus√§tzlichen</em> Benutzer aus k√∂nnen Sie weitere <code>pool_size</code> Backends / Postgres-Worker erstellen.  Weil  Wenn <code>pool_size</code> nicht festgelegt ist, f√§llt es in <code>default_pool_size</code> , das standardm√§√üig 20 ist. Es stellt sich heraus, dass jeder Benutzer, der das Recht hat, eine Verbindung zur Datenbank herzustellen (und √ºber pgbouncer arbeitet), m√∂glicherweise 20 Postgres-Prozesse erstellen kann, was nicht viel zu sein scheint.  Wenn Sie jedoch viele verschiedene Benutzer der Datenbanken oder der Datenbanken selbst haben und die Pools nicht bei einem festen Benutzer registriert sind, d. H.  wird im <code>autodb_idle_timeout</code> erstellt (und dann von <code>autodb_idle_timeout</code> gel√∂scht), dann kann dies gef√§hrlich sein =) <br><blockquote>  Es k√∂nnte sich lohnen, <code>default_pool_size</code> klein zu lassen, nur f√ºr jeden Feuerwehrmann. <br></blockquote></li><li>  <code>max_db_connections</code> - wird nur ben√∂tigt, um die Gesamtzahl der Verbindungen zu einer Datenbank zu begrenzen, weil  Andernfalls k√∂nnen sich schlecht verhaltende Clients zu vielen Backend- / Postgres-Prozessen f√ºhren.  Und standardm√§√üig hier - unbegrenzt ¬Ø_ („ÉÑ) _ / ¬Ø <br><blockquote>  Vielleicht sollten Sie die Standardeinstellungen f√ºr <code>max_db_connections</code> √§ndern. Sie k√∂nnen sich beispielsweise auf die <code>max_connections</code> Ihrer Postgres konzentrieren (standardm√§√üig 100).  Aber wenn Sie viele PgBouncer haben ... <br></blockquote></li><li>  <code>reserve_pool_size</code> - Wenn nur <code>pool_size</code> verwendet wird, kann PgBouncer mehrere weitere Verbindungen zur Basis herstellen.  So wie ich es verstehe, wird dies getan, um mit einem Lastanstieg fertig zu werden.  Wir werden darauf zur√ºckkommen. </li><li>  <code>max_user_connections</code> - Dies ist im Gegenteil die Grenze der Verbindungen von einem Benutzer zu allen Datenbanken, d. h.  relevant, wenn Sie mehrere Datenbanken haben und diese unter denselben Benutzern liegen. </li><li>  <code>max_client_conn</code> - Wie viele Clientverbindungen akzeptiert PgBouncer insgesamt?  Standard hat wie √ºblich eine sehr seltsame Bedeutung - 100. Das hei√üt,  Es wird davon ausgegangen, dass mehr als 100 Clients, die pl√∂tzlich abst√ºrzen, nur stillschweigend auf TCP-Ebene <code>reset</code> und <code>reset</code> (nun, in den Protokollen muss ich zugeben, dass dies "keine Verbindungen mehr zul√§ssig (max_client_conn)" ist). <br><blockquote>  Es k√∂nnte sich lohnen, <code>max_client_conn &gt;&gt; SUM ( pool_size' )</code> beispielsweise zehnmal mehr zu machen. <br></blockquote></li></ul><br><p>  Zus√§tzlich zu <code>SHOW POOLS</code> Dienst pseudo-base pgbouncer auch den <code>SHOW DATABASES</code> , der die tats√§chlich auf einen bestimmten Pool angewendeten Grenzwerte anzeigt: <br><img src="https://habrastorage.org/webt/1v/lv/4h/1vlv4hviyhxz1pbh9puc6xxim9o.jpeg"></p><br><h3 id="servernye-soedineniya">  Serververbindungen </h3><br><p>  Noch einmal - wie kann man messen, wie viele Verbindungen verwendet werden? <br>  In Witzen im Durchschnitt / in Spitzenzeiten / in der Zeit? </p><br><p>  In der Praxis ist es ziemlich problematisch, die Verwendung von Pools durch den T√ºrsteher mit weit verbreiteten Werkzeugen zu √ºberwachen, wie z  pgbouncer selbst liefert nur ein kurzes Bild, und da h√§ufig keine Umfrage durchgef√ºhrt wird, besteht immer noch die M√∂glichkeit eines falschen Bildes aufgrund von Stichproben.  Hier ist ein reales Beispiel, bei dem sich das Bild sowohl offener als auch verwendeter Verbindungen grundlegend √§ndert, je nachdem, wann der Exporteur zu Beginn oder am Ende der Minute gearbeitet hat: </p><br><p><img src="https://habrastorage.org/webt/i3/ch/qb/i3chqbtvyp3p6nm0bayw62pf3hq.png"></p><br><p>  Hier sind alle √Ñnderungen beim Laden / Verwenden der Verbindungen nur eine Fiktion, ein Artefakt der Neustarts des Statistiksammlers.  Hier sehen Sie die Verbindungsdiagramme in Postgres w√§hrend dieser Zeit und die Dateideskriptoren des Bouncers und des PG - keine √Ñnderungen: </p><br><p><img src="https://habrastorage.org/webt/n7/bh/4r/n7bh4r_2h21ypaxhtr7njv2u8xa.png"></p><br><p>  Zur√ºck zum Thema Entsorgung.  Wir haben uns f√ºr einen kombinierten Ansatz in unserem Service entschieden - wir <code>SHOW POOLS</code> einmal pro Sekunde und rendern einmal pro Minute sowohl die durchschnittliche als auch die maximale Anzahl von Verbindungen in jeder Klasse: </p><br><p><img src="https://habrastorage.org/webt/ea/v5/ei/eav5eimcl7fofctvc24oaymzsu4.png"></p><br><p>  Wenn wir die Anzahl dieser aktiven Statusverbindungen durch die Gr√∂√üe des Pools dividieren, erhalten wir die durchschnittliche und maximale Auslastung dieses Pools und k√∂nnen benachrichtigen, wenn er nahe bei 100% liegt. </p><br><p>  Dar√ºber hinaus verf√ºgt PgBouncer √ºber einen Befehl <code>SHOW STATS</code> dem Nutzungsstatistiken f√ºr jede Proxy-Datenbank angezeigt werden: <br><img src="https://habrastorage.org/webt/mo/wz/_q/mowz_qavy_zspkljbvnehbj1bpc.png"><br>  Wir interessieren uns am meisten f√ºr die Spalte <code>total_query_time</code> - die Zeit, die alle Verbindungen f√ºr die Ausf√ºhrung von Abfragen in Postgres ben√∂tigen.  Und ab Version 1.8 gibt es auch die Metrik <code>total_xact_time</code> - die Zeit, die f√ºr Transaktionen aufgewendet wird.  Basierend auf diesen Metriken k√∂nnen wir die Auslastung der Serververbindungszeit aufbauen, da dieser Indikator im Gegensatz zu den aus Verbindungszust√§nden berechneten nicht Stichprobenproblemen unterliegt, weil  Diese <code>total_..._time</code> sind kumulativ und bestehen nichts: </p><br><p><img src="https://habrastorage.org/webt/p3/1l/iv/p31liv1gccpj3rxnxav-nbelck0.png"><br>  Vergleichen <br><img src="https://habrastorage.org/webt/yk/rt/gd/ykrtgdu5s8_pcltl3w3mmcuj4oo.png"><br>  Es ist ersichtlich, dass die Stichprobe nicht alle Momente mit einer hohen Auslastung von ~ 100% zeigt, und query_time zeigt. </p><br><h3 id="saturation-i-pgbouncer">  S√§ttigung und PgBouncer </h3><br><p>  Warum m√ºssen Sie die S√§ttigung √ºberwachen, da aufgrund der hohen Auslastung bereits klar ist, dass alles schlecht ist? </p><br><p>  Das Problem ist, dass unabh√§ngig davon, wie Sie die Auslastung messen, selbst akkumulierte Z√§hler keine lokale 100% ige Ressourcennutzung anzeigen k√∂nnen, wenn sie nur in sehr kurzen Intervallen auftritt.  Sie haben beispielsweise alle Kronen oder andere synchrone Prozesse, die gleichzeitig mit dem Befehl Abfragen an die Datenbank durchf√ºhren k√∂nnen.  Wenn diese Anforderungen kurz sind, kann die Auslastung, gemessen auf der Skala von Minuten und sogar Sekunden, gering sein, aber gleichzeitig mussten diese Anforderungen irgendwann in der Schlange auf die Ausf√ºhrung warten.  √Ñhnlich verh√§lt es sich mit einer Situation, in der die CPU nicht zu 100% ausgelastet ist und die durchschnittliche Last hoch ist - wie die Prozessorzeit immer noch vorhanden ist, aber dennoch warten viele Prozesse in der Schlange auf die Ausf√ºhrung. </p><br><p>  Wie kann diese Situation √ºberwacht werden <code>cl_waiting</code> , wir k√∂nnen einfach die Anzahl der Clients im <code>cl_waiting</code> gem√§√ü <code>SHOW POOLS</code> .  In einer normalen Situation gibt es Null und mehr als Null bedeutet einen √úberlauf dieses Pools: </p><br><p><img src="https://habrastorage.org/webt/q1/tg/tj/q1tgtjcqgrqpavfpkf0kyg31hjq.png"></p><br><p>  Es bleibt das Problem, dass <code>SHOW POOLS</code> nur abgetastet werden k√∂nnen, und in einer Situation mit synchronen Kronen oder √Ñhnlichem k√∂nnen wir solche wartenden Clients einfach √ºberspringen und nicht sehen. </p><br><p>  Sie k√∂nnen diesen Trick anwenden. Pgbouncer selbst kann die 100% ige Nutzung des Pools erkennen und den Sicherungspool √∂ffnen.  Daf√ºr sind zwei Einstellungen verantwortlich: <code>reserve_pool_size</code> - wie gesagt f√ºr seine Gr√∂√üe und <code>reserve_pool_timeout</code> - wie viele Sekunden ein Client <code>waiting</code> sollte, bevor er den Sicherungspool verwendet.  Wenn wir also in der Grafik der Serververbindungen sehen, dass die Anzahl der f√ºr Postgres ge√∂ffneten Verbindungen gr√∂√üer als pool_size ist, gab es eine S√§ttigung des Pools wie folgt: <br><img src="https://habrastorage.org/webt/ne/ec/hn/neechnkp9sffd8g3rjov_3jjijm.png"><br>  Offensichtlich macht so etwas wie Kronen einmal pro Stunde viele Anfragen und belegt den Pool vollst√§ndig.  Und obwohl wir nicht den Moment sehen, in dem <code>active</code> Verbindungen das Limit <code>pool_size</code> √ºberschreiten, war pgbouncer dennoch gezwungen, zus√§tzliche Verbindungen zu √∂ffnen. </p><br><p>  Auch in diesem Diagramm sind die Einstellungen f√ºr <code>server_idle_timeout</code> deutlich sichtbar - nach dem <code>server_idle_timeout</code> zu dem das Halten und Schlie√üen nicht verwendeter Verbindungen gestoppt werden muss.  Standardm√§√üig sind dies 10 Minuten, die wir in der Tabelle sehen - nach den <code>active</code> Spitzen genau um 5:00 Uhr, um 6:00 Uhr usw.  (gem√§√ü cron <code>0 * * * *</code> ) h√§ngen die Verbindungen im <code>idle</code> + <code>used</code> weitere 10 Minuten verwendet und schlie√üen. </p><br><p>  Wenn Sie an der Spitze des Fortschritts stehen und PgBouncer in den letzten 9 Monaten aktualisiert haben, finden Sie in der Spalte <code>SHOW STATS</code> <code>total_wait_time</code> die beste S√§ttigung, weil  ber√ºcksichtigt kumulativ die Zeit, die Kunden in einem <code>waiting</code> verbringen.  Zum Beispiel hier - <code>waiting</code> erschien um 16:30: <br><img src="https://habrastorage.org/webt/ck/-q/qt/ck-qqth3dhvsqsw1zzeuvkjg4wa.png"><br>  Und <code>wait_time</code> , die vergleichbar ist und sich eindeutig auf die <code>average query time</code> <code>wait_time</code> auswirkt, kann von 15:15 bis fast 19 Uhr <code>wait_time</code> : <br><img src="https://habrastorage.org/webt/gn/av/bb/gnavbbmcfchzhkt0d0egcybthzc.png"></p><br><p>  Trotzdem ist die √úberwachung des Status von Clientverbindungen immer noch sehr n√ºtzlich, weil  Auf diese Weise k√∂nnen Sie nicht nur feststellen, dass alle Verbindungen zu einer solchen Datenbank hergestellt wurden und die Clients warten m√ºssen, sondern auch, dass <code>SHOW POOLS</code> von Benutzern in separate Pools unterteilt wird und <code>SHOW STATS</code> dies nicht. <code>SHOW STATS</code> k√∂nnen Sie herausfinden, welche Clients alle Verbindungen verwendet haben auf die angegebene Basis - gem√§√ü der Spalte <code>sv_active</code> des entsprechenden Pools.  Oder nach Metrik </p><br><pre> <code class="hljs pgsql">sum_by(<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">database</span></span>, metric(<span class="hljs-type"><span class="hljs-type">name</span></span>="pgbouncer.clients.count", state="active-link")):</code> </pre> <br><p><img src="https://habrastorage.org/webt/k_/0s/lf/k_0slfupzfrdz4npoiz8kbxgpko.png"></p><br><p>  Wir bei okmeter sind noch weiter gegangen und haben eine Aufschl√ºsselung der Verbindungen hinzugef√ºgt, die von den IP-Adressen der Clients verwendet werden, die sie ge√∂ffnet und verwendet haben.  Auf diese Weise k√∂nnen Sie genau verstehen, welche Anwendungsinstanzen sich unterschiedlich verhalten: <br><img src="https://habrastorage.org/webt/dk/fr/5j/dkfr5j_yvxgmm2f0b5dvru4b9nk.png"><br>  Hier sehen wir IPs bestimmter Kubernetes von Herden, mit denen wir uns befassen m√ºssen. </p><br><h3 id="errors">  Fehler </h3><br><p>  Hier gibt es nichts besonders Kniffliges: pgbouncer schreibt Protokolle, in denen Fehler gemeldet werden, wenn das Limit der Clientverbindungen erreicht ist, das Zeitlimit f√ºr die Verbindung zum Server usw.  Wir haben die pgbouncer-Protokolle selbst noch nicht erreicht :( </p><br><h2 id="red-dlya-pgbouncer">  ROT f√ºr PgBouncer </h2><br><p>  W√§hrend sich die NUTZUNG mehr auf die Leistung konzentriert, geht es bei RED im Sinne von Engp√§ssen meiner Meinung nach mehr um die Merkmale des eingehenden und ausgehenden Verkehrs im Allgemeinen und nicht um Engp√§sse.  Das hei√üt, RED beantwortet die Frage: Funktioniert alles einwandfrei? Wenn nicht, hilft USE, das Problem zu verstehen. </p><br><h2 id="requests">  Anforderungen </h2><br><p>  Es scheint, dass f√ºr die SQL-Datenbank und f√ºr den Proxy- / Verbindungsabzieher in einer solchen Datenbank alles recht einfach ist - Clients f√ºhren SQL-Anweisungen aus, bei denen es sich um Anforderungen handelt.  Aus <code>SHOW STATS</code> nehmen wir <code>total_requests</code> und zeichnen seine Zeitableitung </p><br><pre> <code class="hljs lisp">rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"pgbouncer.total_requests"</span></span>, database: <span class="hljs-string"><span class="hljs-string">"*"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/fa/7u/o2/fa7uo2r8b6_4y6z9e2bounudzmw.png"></p><br><p>  Tats√§chlich gibt es jedoch verschiedene Arten des Ziehens, und die h√§ufigsten sind Transaktionen.  Die Arbeitseinheit f√ºr diesen Modus ist eine Transaktion, keine Abfrage.  Dementsprechend bietet Pgbouner ab Version 1.8 bereits zwei weitere Statistiken an: <code>total_query_count</code> anstelle von <code>total_requests</code> und <code>total_xact_count</code> - die Anzahl der abgeschlossenen Transaktionen. </p><br><p>  Jetzt kann die Arbeitslast nicht nur anhand der Anzahl der abgeschlossenen Anforderungen / Transaktionen charakterisiert werden, sondern Sie k√∂nnen beispielsweise die durchschnittliche Anzahl der Anforderungen pro Transaktion in verschiedenen Datenbanken anzeigen und in eine andere aufteilen </p><br><pre> <code class="hljs lisp">rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"total_requests"</span></span>, database=<span class="hljs-string"><span class="hljs-string">"*"</span></span>)) / rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"total_xact"</span></span>, database=<span class="hljs-string"><span class="hljs-string">"*"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/xd/uh/3w/xduh3wsb-bww1tysfwtdhcw-seg.png"></p><br><p>  Hier sehen wir offensichtliche √Ñnderungen im Lastprofil, die der Grund f√ºr die √Ñnderung der Leistung sein k√∂nnen.  Und wenn Sie nur die Rate der Transaktionen oder Anfragen betrachten, sehen Sie dies m√∂glicherweise nicht. </p><br><h2 id="red-errors">  ROTE Fehler </h2><br><p>  Es ist klar, dass sich RED und USE bei der Fehler√ºberwachung √ºberschneiden, aber es scheint mir, dass Fehler in der USE haupts√§chlich Fehler bei der Anforderungsverarbeitung aufgrund einer 100% igen Auslastung betreffen, d. H.  wenn der Dienst sich weigert, mehr Arbeit anzunehmen.  Und Fehler f√ºr RED w√§ren besser, um Fehler aus Sicht des Kunden und der Kundenanforderungen genau zu messen.  Das hei√üt, nicht nur in einer Situation, in der der Pool im PgBouncer voll ist oder ein anderes Limit funktioniert hat, sondern auch, wenn Anforderungszeitlimits wie "Abbruch der Anweisung aufgrund eines Anweisungszeitlimits", Stornierungen und Rollbacks von Transaktionen durch den Client usw. funktioniert haben. e.  √ºbergeordnete, n√§her an der Gesch√§ftslogik liegende Fehlertypen. </p><br><h2 id="durations">  Dauer </h2><br><p>  Auch hier helfen uns <code>SHOW STATS</code> mit kumulativen Z√§hlern <code>total_xact_time</code> , <code>total_query_time</code> und <code>total_wait_time</code> , indem wir sie durch die Anzahl der Anfragen bzw. Transaktionen dividieren. Wir erhalten die durchschnittliche Anforderungszeit, die durchschnittliche Transaktionszeit und die durchschnittliche Wartezeit pro Transaktion.  Ich habe bereits eine Grafik √ºber die erste und dritte gezeigt: <br><img src="https://habrastorage.org/webt/gn/av/bb/gnavbbmcfchzhkt0d0egcybthzc.png"></p><br><p>  Was kannst du sonst noch cool bekommen?  Das bekannte Antimuster bei der Arbeit mit der Datenbank und Postgres, insbesondere wenn die Anwendung eine Transaktion √∂ffnet, eine Anfrage stellt, dann (f√ºr eine lange Zeit) beginnt, ihre Ergebnisse zu verarbeiten, oder noch schlimmer - geht zu einem anderen Dienst / einer anderen Datenbank und stellt dort Anfragen.  W√§hrend dieser ganzen Zeit "h√§ngt" die Transaktion in den ge√∂ffneten Postgres, der Dienst kehrt dann zur√ºck und stellt weitere Anforderungen, Aktualisierungen in der Datenbank und schlie√üt die Transaktion erst dann.  F√ºr Postgres ist dies besonders unangenehm, weil  pg Arbeiter sind teuer.  So k√∂nnen wir √ºberwachen, wann eine solche Anwendung <code>idle in transaction</code> im Postgres selbst inaktiv ist - gem√§√ü der <code>pg_stat_activity</code> in <code>pg_stat_activity</code> , aber es gibt immer noch die gleichen beschriebenen Probleme mit der Stichprobe, weil  <code>pg_stat_activity</code> gibt nur das aktuelle Bild an.  In PgBouncer k√∂nnen wir die Zeit, die Clients in <code>total_query_time</code> Anforderungen <code>total_query_time</code> , von der Zeit subtrahieren, die in Transaktionen <code>total_xact_time</code> verbracht wird - dies ist die Zeit eines solchen Leerlaufs.  Wenn das Ergebnis immer noch durch <code>total_xact_time</code> geteilt wird, wird es normalisiert: Ein Wert von 1 entspricht einer Situation, in der Clients zu 100% <code>idle in transaction</code> <code>total_xact_time</code> sind.  Und mit einer solchen Normalisierung ist es leicht zu verstehen, wie schlimm alles ist: </p><br><p><img src="https://habrastorage.org/webt/t9/kn/io/t9knioh2ckzd_photgqvcq543x4.png"></p><br><p>  <code>total_xact_time - total_query_time</code> zu Duration zur√ºckkehren, kann die Metrik <code>total_xact_time - total_query_time</code> durch die Anzahl der Transaktionen geteilt werden, um zu sehen, wie hoch die durchschnittliche Leerlaufanwendung pro Transaktion ist. </p><br><hr><br><p>  Meiner Meinung nach sind USE / RED-Methoden am n√ºtzlichsten, um zu strukturieren, welche Metriken Sie aufnehmen und warum.  Da wir uns mit der Vollzeit√ºberwachung besch√§ftigen und verschiedene Infrastrukturkomponenten √ºberwachen m√ºssen, helfen uns diese Methoden, die richtigen Metriken zu ermitteln, die richtigen Zeitpl√§ne und Ausl√∂ser f√ºr unsere Kunden zu erstellen. </p><br><p>  <em>Eine gute √úberwachung kann nicht sofort durchgef√ºhrt werden, sondern ist ein iterativer Prozess.</em>  <em>In <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">okmeter.io haben</a> wir nur eine kontinuierliche √úberwachung (es gibt viele Dinge, aber morgen wird es besser und detaillierter sein :)</em> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de420429/">https://habr.com/ru/post/de420429/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de420413/index.html">SQLite und NW.js - Schritt-f√ºr-Schritt-Anleitungen zum Erstellen starker Freundschaften</a></li>
<li><a href="../de420415/index.html">Alles, was Sie √ºber das Testen von Wi-Fi-Adaptern wissen wollten, aber Angst hatten zu fragen</a></li>
<li><a href="../de420419/index.html">L√§ufer f√ºr diejenigen, die Dem√ºtigung m√∂gen oder wie wir PixJam ver√§ndert und modifiziert haben</a></li>
<li><a href="../de420423/index.html">Probleme mit der Schnittstelle zwischen Bodenkreuzung</a></li>
<li><a href="../de420425/index.html">Theorie und Praxis der Verwendung von HBase</a></li>
<li><a href="../de420431/index.html">Mars Praktischer Leitfaden zum Terraforming f√ºr Hausfrauen</a></li>
<li><a href="../de420433/index.html">‚ÄûFreitag-Format‚Äú: Musikalische Stra√üen - was ist das und warum sind sie nicht in Russland?</a></li>
<li><a href="../de420435/index.html">Schnellstart mit ARM Mbed: Entwicklung moderner Mikrocontroller f√ºr Anf√§nger</a></li>
<li><a href="../de420437/index.html">Eine praktische Einf√ºhrung in den Paketmanager f√ºr Kubernetes - Helm</a></li>
<li><a href="../de420439/index.html">Fintech-Digest: Die Investitionen in Fintech beliefen sich auf 57 Milliarden US-Dollar, die Transaktionsgeschwindigkeit steigt und die Kosten sinken</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏻‍🤝‍👨🏼 💇🏽 😢 USE, RED, PgBouncer, seine Einstellungen und Überwachung 🥔 📐 ✊🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir haben begonnen, die Überwachung für PgBouncer in unserem Service zu aktualisieren, und beschlossen, alles ein wenig zu kämmen. Um alles fit zu mac...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>USE, RED, PgBouncer, seine Einstellungen und Überwachung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/okmeter/blog/420429/"><img align="left" width="359" src="https://habrastorage.org/webt/l4/xy/iz/l4xyize9ztzrmf303fot3iylnc8.png" alt="Pgbouncer USE RED"><br><p>  Wir haben begonnen, die Überwachung für PgBouncer in unserem Service zu aktualisieren, und beschlossen, alles ein wenig zu kämmen.  Um alles fit zu machen, haben wir die bekanntesten Methoden zur Leistungsüberwachung verwendet: USE (Utilization, Saturation, Errors) von Brendan Gregg und RED (Requests, Errors, Durations) von Tom Wilkie. </p><br><p>  Unter der Zwischensequenz finden Sie eine Geschichte mit Grafiken darüber, wie pgbouncer funktioniert, welche Konfigurationshandles es hat und wie USE / RED verwendet wird, um die richtigen Metriken für die Überwachung auszuwählen. </p><a name="habracut"></a><br><h2 id="snachala-pro-sami-metody">  Zunächst zu den Methoden selbst </h2><br><p>  Obwohl diese Methoden ziemlich bekannt sind (über <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sie war es bereits bei Habré, wenn auch nicht sehr detailliert</a> ), ist es nicht so, dass sie in der Praxis weit verbreitet sind. </p><br><h3 id="use">  VERWENDUNG </h3><br><blockquote>  Behalten Sie für jede Ressource die Entsorgung, Sättigung und Fehler im Auge. <br>  Brendan Gregg </blockquote><p>  Hier ist eine <strong>Ressource</strong> eine separate physische Komponente - eine CPU, eine Festplatte, ein Bus usw.  Aber nicht nur - die Leistung einiger Softwareressourcen kann mit dieser Methode auch berücksichtigt werden, insbesondere virtuelle Ressourcen, wie z. B. Container / Gruppen mit Einschränkungen, es ist auch zweckmäßig, dies zu berücksichtigen. </p><br><p> <strong>U - Entsorgung</strong> : entweder ein Prozentsatz der Zeit (ab dem Beobachtungsintervall), in der die Ressource mit nützlicher Arbeit beschäftigt war.  Da beispielsweise das Laden der CPU- oder Festplattenauslastung zu 90% bedeutet, dass 90% der Zeit von etwas Nützlichem beansprucht wurde) oder für Ressourcen wie Speicher der Prozentsatz des verwendeten Speichers. </p><br><p>  In jedem Fall bedeutet 100% Recycling, dass die Ressource nicht mehr als jetzt genutzt werden kann.  Und entweder bleibt die Arbeit hängen und wartet auf die Veröffentlichung / geht in die Warteschlange, oder es gibt Fehler.  Diese beiden Szenarien werden durch die entsprechenden zwei verbleibenden USE-Metriken abgedeckt: </p><br><p>  <strong>S - Sättigung</strong> , es ist auch Sättigung: ein Maß für die Menge der "zurückgestellten" / in die Warteschlange gestellten Arbeit. </p><br><p>  <strong>E - Fehler</strong> : Wir zählen einfach die Anzahl der Fehler.  Fehler / Ausfälle beeinträchtigen die Leistung, sind jedoch möglicherweise nicht sofort erkennbar, da gespiegelte Vorgänge oder Fehlertoleranzmechanismen mit Sicherungsgeräten usw. abgerufen werden. </p><br><h3 id="red">  Rot </h3><br><p>  Tom Wilkie (der jetzt bei Grafana Labs arbeitet) war frustriert über die USE-Methodik oder vielmehr über die in einigen Fällen schlechte Anwendbarkeit und die Inkonsistenz mit der Praxis.  Wie kann man zum Beispiel die Sättigung des Gedächtnisses messen?  Oder wie man Systembusfehler in der Praxis misst? </p><br><blockquote>  Es stellt sich heraus, dass Linux wirklich Fehlerzahlen meldet. <br>  T. Wilkie </blockquote><p>  Kurz gesagt, um die Leistung und das Verhalten von Mikrodiensten zu überwachen, schlug er eine andere geeignete Methode vor: erneut drei Indikatoren zu messen: </p><br><p>  <strong>R - Rate</strong> : Die Anzahl der Anfragen pro Sekunde. <br>  <strong>E - Fehler</strong> : Wie viele Anfragen haben einen Fehler zurückgegeben. <br>  <strong>D - Dauer</strong> : Zeitaufwand für die Bearbeitung der Anfrage.  Es ist Latenz, "Latenz" (© Sveta Smirnova :), Reaktionszeit usw. </p><br><p>  Im Allgemeinen eignet sich USE besser zur Überwachung von Ressourcen und RED für Dienste und deren Arbeitslast / Nutzlast. </p><br><h2 id="pgbouncer">  Pgbouncer </h2><br><p>  Als Dienstleistung hat sie gleichzeitig alle möglichen internen Grenzen und Ressourcen.  Gleiches gilt für Postgres, auf das Clients über diesen PgBouncer zugreifen.  Für eine vollständige Überwachung in dieser Situation sind daher beide Methoden erforderlich. </p><br><p>  Um zu verstehen, wie diese Methoden auf einen Türsteher angewendet werden, müssen Sie die Details seines Geräts verstehen.  Es reicht nicht aus, es als Black-Box zu überwachen - "lebt der pgbouncer-Prozess" oder "ist der Port offen", weil  Im Falle von Problemen gibt dies kein Verständnis dafür, was genau und wie es kaputt gegangen ist und was zu tun ist. </p><br><p>  Was macht PgBouncer im Allgemeinen aus Sicht des Kunden? </p><br><ol><li>  Client verbindet </li><li>  [Kunde stellt eine Anfrage - erhält eine Antwort] x wie oft er benötigt </li></ol><br><p>  Hier habe ich ein Diagramm der entsprechenden Client-Zustände aus Sicht von PgBoucer gezeichnet: <br><img src="https://habrastorage.org/webt/zb/mh/ot/zbmhotvidvuxnsbzp04-bqtgqhk.jpeg"></p><br><p> Während des Anmeldevorgangs kann die Autorisierung sowohl lokal (Dateien, Zertifikate und sogar PAM und hba aus neuen Versionen) als auch remote erfolgen - d. H.  in der Datenbank selbst, zu der die Verbindung versucht wird.  Somit hat der Anmeldestatus einen zusätzlichen Unterzustand.  Nennen wir es <code>Executing</code> um anzuzeigen, dass <code>auth_query</code> zu diesem Zeitpunkt in der Datenbank ausgeführt wird: <br><img src="https://habrastorage.org/webt/e4/ib/pb/e4ibpbf6ef5q9xcdy2fantydkc4.png"></p><br><p>  Diese Clientverbindungen stimmen jedoch tatsächlich mit den Backend- / Upstream-Verbindungen überein, die PgBouncer innerhalb des Pools öffnet und eine begrenzte Anzahl enthält.  Und sie stellen eine solche Verbindung zum Client nur für die Zeit her - für die Dauer der Sitzung, Transaktion oder Anforderung, abhängig von der Art des Poolings (bestimmt durch die Einstellung <code>pool_mode</code> ).  In den meisten Fällen wird das Transaktionspooling verwendet (wir werden es hauptsächlich später besprechen) - wenn die Verbindung für eine Transaktion an den Client ausgegeben wird und der Client für den Rest der Zeit tatsächlich nicht mit dem Server verbunden ist.  Der "aktive" Zustand des Clients sagt also wenig aus, und wir werden ihn in Substrate unterteilen: <br><img src="https://habrastorage.org/webt/uv/q4/tj/uvq4tjzbbauunpwzhboxc8s3pgu.png"></p><br><p>  Jeder dieser Clients fällt in seinen eigenen Verbindungspool, der für die tatsächliche Verbindung zu Postgres ausgegeben wird.  Dies ist die Hauptaufgabe von PgBouncer - die Anzahl der Verbindungen zu Postgres zu begrenzen. </p><br><p>  Aufgrund der eingeschränkten Serververbindungen kann es vorkommen, dass der Client die Anforderung direkt erfüllen muss, aber derzeit keine freie Verbindung besteht.  Dann wird der Client in die Warteschlange gestellt und seine Verbindung wird in den <code>CL_WAITING</code> .  Daher muss das Zustandsdiagramm ergänzt werden: <br><img src="https://habrastorage.org/webt/2v/ny/yu/2vnyyuhlqher6cc5q5izwjtu7te.png"><br>  Da dies passieren kann, wenn sich der Client nur anmeldet und eine Autorisierungsanforderung ausführen muss, wird auch der <code>CL_WAITING_LOGIN</code> . </p><br><p>  Wenn Sie jetzt von der Rückseite - von der Seite der Serververbindungen - <code>SV_LOGIN</code> , befinden sie sich dementsprechend in solchen Zuständen: Wenn die Autorisierung unmittelbar nach der Verbindung erfolgt - <code>SV_LOGIN</code> , ausgestellt und (möglicherweise) vom Client verwendet - <code>SV_ACTIVE</code> oder frei - <code>SV_IDLE</code> . </p><br><h2 id="use-dlya-pgbouncer">  VERWENDUNG für PgBouncer </h2><br><p>  So kommen wir zur (naiven Version) Nutzung eines bestimmten Pools: </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">Pool</span></span> utiliz =    /  </code> </pre> <br><p>  PgBouncer verfügt über eine spezielle pgbouncer-Dienstprogrammdatenbank, in der sich ein <code>SHOW POOLS</code> , der den aktuellen Status der Verbindungen jedes Pools anzeigt: <br><img src="https://habrastorage.org/webt/xz/_o/eb/xz_oebvf-0yahuvdfzrxx3iass0.png"><br>  Es sind 4 Clientverbindungen offen und alle sind <code>cl_active</code> .  Von 5 Serververbindungen - 4 <code>sv_active</code> und eine im neuen Status <code>sv_used</code> . </p><br><div class="spoiler">  <b class="spoiler_title">Was ist sv_used wirklich an den verschiedenen Einstellungen von pgbouncer, die nichts mit der Überwachung zu tun haben?</b> <div class="spoiler_text"><p>  <code>sv_used</code> bedeutet also nicht "Verbindung wird verwendet", wie Sie vielleicht denken, sondern "Verbindung wurde einmal verwendet und wurde lange nicht mehr verwendet".  Tatsache ist, dass PgBouncer standardmäßig Serververbindungen im LIFO-Modus verwendet - d. H.  Zuerst werden neu freigegebene Verbindungen verwendet, dann kürzlich verwendete usw.  allmählich zu lang verwendeten Verbindungen übergehen.  Dementsprechend können Serververbindungen von der Unterseite eines solchen Stapels "schlecht werden".  Und sie sollten vor der Verwendung auf Lebendigkeit überprüft werden, was mit <code>server_check_query</code> erfolgt. Während sie überprüft werden, wird der Status <code>sv_tested</code> . </p><br><p>  Die Dokumentation besagt, dass LIFO standardmäßig als aktiviert ist  dann "bekommt eine kleine Anzahl von Verbindungen die meiste Arbeitslast. Und dies bietet die beste Leistung, wenn es einen Server gibt, der die Datenbank hinter pgbouncer bedient", d.h.  wie im typischsten Fall.  Ich glaube, dass der potenzielle Leistungsschub auf die Einsparungen bei der Switching-Leistung zwischen mehreren Backend-Prozessen zurückzuführen ist.  Aber es hat nicht zuverlässig geklappt, weil  Dieses Implementierungsdetail besteht seit&gt; 12 Jahren und geht über die Commit-Historie für Github und die Tiefe meines Interesses hinaus =) </p><br><p>  Es schien also seltsam und <code>server_check_delay</code> mit den aktuellen Realitäten, dass der Standardwert der Einstellung <code>server_check_delay</code> , die feststellt, dass der Server nicht zu lange verwendet wurde und überprüft werden sollte, bevor er an den Client übergeben wird, 30 Sekunden beträgt.  Dies trotz der Tatsache, dass standardmäßig tcp_keepalive gleichzeitig mit den Standardeinstellungen aktiviert ist. Beginnen Sie 2 Stunden nach dem Leerlauf mit der Überprüfung der Keep-Alive-Verbindung mit Samples. <br>  Es stellt sich heraus, dass in einer Burst / Surge-Situation von Clientverbindungen, die etwas auf dem Server tun möchten, eine zusätzliche Verzögerung für <code>server_check_query</code> eingeführt <code>server_check_query</code> , die, obwohl " <code>SELECT 1;</code> immer noch ~ 100 Mikrosekunden dauern kann, und wenn <code>server_check_query = ';'</code>  dann können Sie ~ 30 Mikrosekunden sparen =) </p><br><p>  Aber die Annahme, dass die Arbeit in nur wenigen Verbindungen = an mehreren "Haupt" -Back-End-Postgres-Prozessen effizienter ist, scheint mir zweifelhaft.  Der Postgres-Worker-Prozess speichert (Meta-) Informationen zu jeder Tabelle, auf die in diesem Zusammenhang zugegriffen wurde.  Wenn Sie eine große Anzahl von Tabellen haben, kann dieser Relcache sehr stark wachsen und viel Speicher beanspruchen, bis die Seiten des 0_o-Prozesses ausgetauscht werden.  Um dies zu <code>server_lifetime</code> , verwenden Sie die Einstellung <code>server_lifetime</code> (Standard ist 1 Stunde), mit der die Serververbindung für die Rotation geschlossen wird.  Andererseits gibt es eine Einstellung für <code>server_round_robin</code> , mit der der Modus für die Verwendung von Verbindungen von LIFO zu FIFO <code>server_round_robin</code> wodurch Clientanforderungen auf Serververbindungen gleichmäßiger verteilt werden. </p></div></div><br><p>  <code>SHOW POOLS</code> wir <code>SHOW POOLS</code> Metriken von <code>SHOW POOLS</code> (von einem Prometheus-Exporteur) übernehmen, können wir diese Zustände darstellen: </p><br><p><img src="https://habrastorage.org/webt/i8/8f/-x/i88f-xpwo_2hj7z6iq6qbnatsju.png"></p><br><p>  Um zur Verfügung zu stehen, müssen Sie jedoch einige Fragen beantworten: </p><br><ul><li>  Wie groß ist der Pool? </li><li>  Wie wird gezählt, wie viele Verbindungen verwendet werden?  In Witzen oder in der Zeit, im Durchschnitt oder in der Spitze? </li></ul><br><h3 id="razmer-pula">  Poolgröße </h3><br><p>  Hier ist alles kompliziert, wie im Leben.  Insgesamt gibt es im pbbouncer bereits fünf Einstellungslimits! </p><br><ul><li>  <code>pool_size</code> kann für jede Datenbank festgelegt werden.  Für jedes DB / Benutzer-Paar wird ein separater Pool erstellt, d. H.  Von jedem <em>zusätzlichen</em> Benutzer aus können Sie weitere <code>pool_size</code> Backends / Postgres-Worker erstellen.  Weil  Wenn <code>pool_size</code> nicht festgelegt ist, fällt es in <code>default_pool_size</code> , das standardmäßig 20 ist. Es stellt sich heraus, dass jeder Benutzer, der das Recht hat, eine Verbindung zur Datenbank herzustellen (und über pgbouncer arbeitet), möglicherweise 20 Postgres-Prozesse erstellen kann, was nicht viel zu sein scheint.  Wenn Sie jedoch viele verschiedene Benutzer der Datenbanken oder der Datenbanken selbst haben und die Pools nicht bei einem festen Benutzer registriert sind, d. H.  wird im <code>autodb_idle_timeout</code> erstellt (und dann von <code>autodb_idle_timeout</code> gelöscht), dann kann dies gefährlich sein =) <br><blockquote>  Es könnte sich lohnen, <code>default_pool_size</code> klein zu lassen, nur für jeden Feuerwehrmann. <br></blockquote></li><li>  <code>max_db_connections</code> - wird nur benötigt, um die Gesamtzahl der Verbindungen zu einer Datenbank zu begrenzen, weil  Andernfalls können sich schlecht verhaltende Clients zu vielen Backend- / Postgres-Prozessen führen.  Und standardmäßig hier - unbegrenzt ¯_ (ツ) _ / ¯ <br><blockquote>  Vielleicht sollten Sie die Standardeinstellungen für <code>max_db_connections</code> ändern. Sie können sich beispielsweise auf die <code>max_connections</code> Ihrer Postgres konzentrieren (standardmäßig 100).  Aber wenn Sie viele PgBouncer haben ... <br></blockquote></li><li>  <code>reserve_pool_size</code> - Wenn nur <code>pool_size</code> verwendet wird, kann PgBouncer mehrere weitere Verbindungen zur Basis herstellen.  So wie ich es verstehe, wird dies getan, um mit einem Lastanstieg fertig zu werden.  Wir werden darauf zurückkommen. </li><li>  <code>max_user_connections</code> - Dies ist im Gegenteil die Grenze der Verbindungen von einem Benutzer zu allen Datenbanken, d. h.  relevant, wenn Sie mehrere Datenbanken haben und diese unter denselben Benutzern liegen. </li><li>  <code>max_client_conn</code> - Wie viele Clientverbindungen akzeptiert PgBouncer insgesamt?  Standard hat wie üblich eine sehr seltsame Bedeutung - 100. Das heißt,  Es wird davon ausgegangen, dass mehr als 100 Clients, die plötzlich abstürzen, nur stillschweigend auf TCP-Ebene <code>reset</code> und <code>reset</code> (nun, in den Protokollen muss ich zugeben, dass dies "keine Verbindungen mehr zulässig (max_client_conn)" ist). <br><blockquote>  Es könnte sich lohnen, <code>max_client_conn &gt;&gt; SUM ( pool_size' )</code> beispielsweise zehnmal mehr zu machen. <br></blockquote></li></ul><br><p>  Zusätzlich zu <code>SHOW POOLS</code> Dienst pseudo-base pgbouncer auch den <code>SHOW DATABASES</code> , der die tatsächlich auf einen bestimmten Pool angewendeten Grenzwerte anzeigt: <br><img src="https://habrastorage.org/webt/1v/lv/4h/1vlv4hviyhxz1pbh9puc6xxim9o.jpeg"></p><br><h3 id="servernye-soedineniya">  Serververbindungen </h3><br><p>  Noch einmal - wie kann man messen, wie viele Verbindungen verwendet werden? <br>  In Witzen im Durchschnitt / in Spitzenzeiten / in der Zeit? </p><br><p>  In der Praxis ist es ziemlich problematisch, die Verwendung von Pools durch den Türsteher mit weit verbreiteten Werkzeugen zu überwachen, wie z  pgbouncer selbst liefert nur ein kurzes Bild, und da häufig keine Umfrage durchgeführt wird, besteht immer noch die Möglichkeit eines falschen Bildes aufgrund von Stichproben.  Hier ist ein reales Beispiel, bei dem sich das Bild sowohl offener als auch verwendeter Verbindungen grundlegend ändert, je nachdem, wann der Exporteur zu Beginn oder am Ende der Minute gearbeitet hat: </p><br><p><img src="https://habrastorage.org/webt/i3/ch/qb/i3chqbtvyp3p6nm0bayw62pf3hq.png"></p><br><p>  Hier sind alle Änderungen beim Laden / Verwenden der Verbindungen nur eine Fiktion, ein Artefakt der Neustarts des Statistiksammlers.  Hier sehen Sie die Verbindungsdiagramme in Postgres während dieser Zeit und die Dateideskriptoren des Bouncers und des PG - keine Änderungen: </p><br><p><img src="https://habrastorage.org/webt/n7/bh/4r/n7bh4r_2h21ypaxhtr7njv2u8xa.png"></p><br><p>  Zurück zum Thema Entsorgung.  Wir haben uns für einen kombinierten Ansatz in unserem Service entschieden - wir <code>SHOW POOLS</code> einmal pro Sekunde und rendern einmal pro Minute sowohl die durchschnittliche als auch die maximale Anzahl von Verbindungen in jeder Klasse: </p><br><p><img src="https://habrastorage.org/webt/ea/v5/ei/eav5eimcl7fofctvc24oaymzsu4.png"></p><br><p>  Wenn wir die Anzahl dieser aktiven Statusverbindungen durch die Größe des Pools dividieren, erhalten wir die durchschnittliche und maximale Auslastung dieses Pools und können benachrichtigen, wenn er nahe bei 100% liegt. </p><br><p>  Darüber hinaus verfügt PgBouncer über einen Befehl <code>SHOW STATS</code> dem Nutzungsstatistiken für jede Proxy-Datenbank angezeigt werden: <br><img src="https://habrastorage.org/webt/mo/wz/_q/mowz_qavy_zspkljbvnehbj1bpc.png"><br>  Wir interessieren uns am meisten für die Spalte <code>total_query_time</code> - die Zeit, die alle Verbindungen für die Ausführung von Abfragen in Postgres benötigen.  Und ab Version 1.8 gibt es auch die Metrik <code>total_xact_time</code> - die Zeit, die für Transaktionen aufgewendet wird.  Basierend auf diesen Metriken können wir die Auslastung der Serververbindungszeit aufbauen, da dieser Indikator im Gegensatz zu den aus Verbindungszuständen berechneten nicht Stichprobenproblemen unterliegt, weil  Diese <code>total_..._time</code> sind kumulativ und bestehen nichts: </p><br><p><img src="https://habrastorage.org/webt/p3/1l/iv/p31liv1gccpj3rxnxav-nbelck0.png"><br>  Vergleichen <br><img src="https://habrastorage.org/webt/yk/rt/gd/ykrtgdu5s8_pcltl3w3mmcuj4oo.png"><br>  Es ist ersichtlich, dass die Stichprobe nicht alle Momente mit einer hohen Auslastung von ~ 100% zeigt, und query_time zeigt. </p><br><h3 id="saturation-i-pgbouncer">  Sättigung und PgBouncer </h3><br><p>  Warum müssen Sie die Sättigung überwachen, da aufgrund der hohen Auslastung bereits klar ist, dass alles schlecht ist? </p><br><p>  Das Problem ist, dass unabhängig davon, wie Sie die Auslastung messen, selbst akkumulierte Zähler keine lokale 100% ige Ressourcennutzung anzeigen können, wenn sie nur in sehr kurzen Intervallen auftritt.  Sie haben beispielsweise alle Kronen oder andere synchrone Prozesse, die gleichzeitig mit dem Befehl Abfragen an die Datenbank durchführen können.  Wenn diese Anforderungen kurz sind, kann die Auslastung, gemessen auf der Skala von Minuten und sogar Sekunden, gering sein, aber gleichzeitig mussten diese Anforderungen irgendwann in der Schlange auf die Ausführung warten.  Ähnlich verhält es sich mit einer Situation, in der die CPU nicht zu 100% ausgelastet ist und die durchschnittliche Last hoch ist - wie die Prozessorzeit immer noch vorhanden ist, aber dennoch warten viele Prozesse in der Schlange auf die Ausführung. </p><br><p>  Wie kann diese Situation überwacht werden <code>cl_waiting</code> , wir können einfach die Anzahl der Clients im <code>cl_waiting</code> gemäß <code>SHOW POOLS</code> .  In einer normalen Situation gibt es Null und mehr als Null bedeutet einen Überlauf dieses Pools: </p><br><p><img src="https://habrastorage.org/webt/q1/tg/tj/q1tgtjcqgrqpavfpkf0kyg31hjq.png"></p><br><p>  Es bleibt das Problem, dass <code>SHOW POOLS</code> nur abgetastet werden können, und in einer Situation mit synchronen Kronen oder Ähnlichem können wir solche wartenden Clients einfach überspringen und nicht sehen. </p><br><p>  Sie können diesen Trick anwenden. Pgbouncer selbst kann die 100% ige Nutzung des Pools erkennen und den Sicherungspool öffnen.  Dafür sind zwei Einstellungen verantwortlich: <code>reserve_pool_size</code> - wie gesagt für seine Größe und <code>reserve_pool_timeout</code> - wie viele Sekunden ein Client <code>waiting</code> sollte, bevor er den Sicherungspool verwendet.  Wenn wir also in der Grafik der Serververbindungen sehen, dass die Anzahl der für Postgres geöffneten Verbindungen größer als pool_size ist, gab es eine Sättigung des Pools wie folgt: <br><img src="https://habrastorage.org/webt/ne/ec/hn/neechnkp9sffd8g3rjov_3jjijm.png"><br>  Offensichtlich macht so etwas wie Kronen einmal pro Stunde viele Anfragen und belegt den Pool vollständig.  Und obwohl wir nicht den Moment sehen, in dem <code>active</code> Verbindungen das Limit <code>pool_size</code> überschreiten, war pgbouncer dennoch gezwungen, zusätzliche Verbindungen zu öffnen. </p><br><p>  Auch in diesem Diagramm sind die Einstellungen für <code>server_idle_timeout</code> deutlich sichtbar - nach dem <code>server_idle_timeout</code> zu dem das Halten und Schließen nicht verwendeter Verbindungen gestoppt werden muss.  Standardmäßig sind dies 10 Minuten, die wir in der Tabelle sehen - nach den <code>active</code> Spitzen genau um 5:00 Uhr, um 6:00 Uhr usw.  (gemäß cron <code>0 * * * *</code> ) hängen die Verbindungen im <code>idle</code> + <code>used</code> weitere 10 Minuten verwendet und schließen. </p><br><p>  Wenn Sie an der Spitze des Fortschritts stehen und PgBouncer in den letzten 9 Monaten aktualisiert haben, finden Sie in der Spalte <code>SHOW STATS</code> <code>total_wait_time</code> die beste Sättigung, weil  berücksichtigt kumulativ die Zeit, die Kunden in einem <code>waiting</code> verbringen.  Zum Beispiel hier - <code>waiting</code> erschien um 16:30: <br><img src="https://habrastorage.org/webt/ck/-q/qt/ck-qqth3dhvsqsw1zzeuvkjg4wa.png"><br>  Und <code>wait_time</code> , die vergleichbar ist und sich eindeutig auf die <code>average query time</code> <code>wait_time</code> auswirkt, kann von 15:15 bis fast 19 Uhr <code>wait_time</code> : <br><img src="https://habrastorage.org/webt/gn/av/bb/gnavbbmcfchzhkt0d0egcybthzc.png"></p><br><p>  Trotzdem ist die Überwachung des Status von Clientverbindungen immer noch sehr nützlich, weil  Auf diese Weise können Sie nicht nur feststellen, dass alle Verbindungen zu einer solchen Datenbank hergestellt wurden und die Clients warten müssen, sondern auch, dass <code>SHOW POOLS</code> von Benutzern in separate Pools unterteilt wird und <code>SHOW STATS</code> dies nicht. <code>SHOW STATS</code> können Sie herausfinden, welche Clients alle Verbindungen verwendet haben auf die angegebene Basis - gemäß der Spalte <code>sv_active</code> des entsprechenden Pools.  Oder nach Metrik </p><br><pre> <code class="hljs pgsql">sum_by(<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">database</span></span>, metric(<span class="hljs-type"><span class="hljs-type">name</span></span>="pgbouncer.clients.count", state="active-link")):</code> </pre> <br><p><img src="https://habrastorage.org/webt/k_/0s/lf/k_0slfupzfrdz4npoiz8kbxgpko.png"></p><br><p>  Wir bei okmeter sind noch weiter gegangen und haben eine Aufschlüsselung der Verbindungen hinzugefügt, die von den IP-Adressen der Clients verwendet werden, die sie geöffnet und verwendet haben.  Auf diese Weise können Sie genau verstehen, welche Anwendungsinstanzen sich unterschiedlich verhalten: <br><img src="https://habrastorage.org/webt/dk/fr/5j/dkfr5j_yvxgmm2f0b5dvru4b9nk.png"><br>  Hier sehen wir IPs bestimmter Kubernetes von Herden, mit denen wir uns befassen müssen. </p><br><h3 id="errors">  Fehler </h3><br><p>  Hier gibt es nichts besonders Kniffliges: pgbouncer schreibt Protokolle, in denen Fehler gemeldet werden, wenn das Limit der Clientverbindungen erreicht ist, das Zeitlimit für die Verbindung zum Server usw.  Wir haben die pgbouncer-Protokolle selbst noch nicht erreicht :( </p><br><h2 id="red-dlya-pgbouncer">  ROT für PgBouncer </h2><br><p>  Während sich die NUTZUNG mehr auf die Leistung konzentriert, geht es bei RED im Sinne von Engpässen meiner Meinung nach mehr um die Merkmale des eingehenden und ausgehenden Verkehrs im Allgemeinen und nicht um Engpässe.  Das heißt, RED beantwortet die Frage: Funktioniert alles einwandfrei? Wenn nicht, hilft USE, das Problem zu verstehen. </p><br><h2 id="requests">  Anforderungen </h2><br><p>  Es scheint, dass für die SQL-Datenbank und für den Proxy- / Verbindungsabzieher in einer solchen Datenbank alles recht einfach ist - Clients führen SQL-Anweisungen aus, bei denen es sich um Anforderungen handelt.  Aus <code>SHOW STATS</code> nehmen wir <code>total_requests</code> und zeichnen seine Zeitableitung </p><br><pre> <code class="hljs lisp">rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"pgbouncer.total_requests"</span></span>, database: <span class="hljs-string"><span class="hljs-string">"*"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/fa/7u/o2/fa7uo2r8b6_4y6z9e2bounudzmw.png"></p><br><p>  Tatsächlich gibt es jedoch verschiedene Arten des Ziehens, und die häufigsten sind Transaktionen.  Die Arbeitseinheit für diesen Modus ist eine Transaktion, keine Abfrage.  Dementsprechend bietet Pgbouner ab Version 1.8 bereits zwei weitere Statistiken an: <code>total_query_count</code> anstelle von <code>total_requests</code> und <code>total_xact_count</code> - die Anzahl der abgeschlossenen Transaktionen. </p><br><p>  Jetzt kann die Arbeitslast nicht nur anhand der Anzahl der abgeschlossenen Anforderungen / Transaktionen charakterisiert werden, sondern Sie können beispielsweise die durchschnittliche Anzahl der Anforderungen pro Transaktion in verschiedenen Datenbanken anzeigen und in eine andere aufteilen </p><br><pre> <code class="hljs lisp">rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"total_requests"</span></span>, database=<span class="hljs-string"><span class="hljs-string">"*"</span></span>)) / rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"total_xact"</span></span>, database=<span class="hljs-string"><span class="hljs-string">"*"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/xd/uh/3w/xduh3wsb-bww1tysfwtdhcw-seg.png"></p><br><p>  Hier sehen wir offensichtliche Änderungen im Lastprofil, die der Grund für die Änderung der Leistung sein können.  Und wenn Sie nur die Rate der Transaktionen oder Anfragen betrachten, sehen Sie dies möglicherweise nicht. </p><br><h2 id="red-errors">  ROTE Fehler </h2><br><p>  Es ist klar, dass sich RED und USE bei der Fehlerüberwachung überschneiden, aber es scheint mir, dass Fehler in der USE hauptsächlich Fehler bei der Anforderungsverarbeitung aufgrund einer 100% igen Auslastung betreffen, d. H.  wenn der Dienst sich weigert, mehr Arbeit anzunehmen.  Und Fehler für RED wären besser, um Fehler aus Sicht des Kunden und der Kundenanforderungen genau zu messen.  Das heißt, nicht nur in einer Situation, in der der Pool im PgBouncer voll ist oder ein anderes Limit funktioniert hat, sondern auch, wenn Anforderungszeitlimits wie "Abbruch der Anweisung aufgrund eines Anweisungszeitlimits", Stornierungen und Rollbacks von Transaktionen durch den Client usw. funktioniert haben. e.  übergeordnete, näher an der Geschäftslogik liegende Fehlertypen. </p><br><h2 id="durations">  Dauer </h2><br><p>  Auch hier helfen uns <code>SHOW STATS</code> mit kumulativen Zählern <code>total_xact_time</code> , <code>total_query_time</code> und <code>total_wait_time</code> , indem wir sie durch die Anzahl der Anfragen bzw. Transaktionen dividieren. Wir erhalten die durchschnittliche Anforderungszeit, die durchschnittliche Transaktionszeit und die durchschnittliche Wartezeit pro Transaktion.  Ich habe bereits eine Grafik über die erste und dritte gezeigt: <br><img src="https://habrastorage.org/webt/gn/av/bb/gnavbbmcfchzhkt0d0egcybthzc.png"></p><br><p>  Was kannst du sonst noch cool bekommen?  Das bekannte Antimuster bei der Arbeit mit der Datenbank und Postgres, insbesondere wenn die Anwendung eine Transaktion öffnet, eine Anfrage stellt, dann (für eine lange Zeit) beginnt, ihre Ergebnisse zu verarbeiten, oder noch schlimmer - geht zu einem anderen Dienst / einer anderen Datenbank und stellt dort Anfragen.  Während dieser ganzen Zeit "hängt" die Transaktion in den geöffneten Postgres, der Dienst kehrt dann zurück und stellt weitere Anforderungen, Aktualisierungen in der Datenbank und schließt die Transaktion erst dann.  Für Postgres ist dies besonders unangenehm, weil  pg Arbeiter sind teuer.  So können wir überwachen, wann eine solche Anwendung <code>idle in transaction</code> im Postgres selbst inaktiv ist - gemäß der <code>pg_stat_activity</code> in <code>pg_stat_activity</code> , aber es gibt immer noch die gleichen beschriebenen Probleme mit der Stichprobe, weil  <code>pg_stat_activity</code> gibt nur das aktuelle Bild an.  In PgBouncer können wir die Zeit, die Clients in <code>total_query_time</code> Anforderungen <code>total_query_time</code> , von der Zeit subtrahieren, die in Transaktionen <code>total_xact_time</code> verbracht wird - dies ist die Zeit eines solchen Leerlaufs.  Wenn das Ergebnis immer noch durch <code>total_xact_time</code> geteilt wird, wird es normalisiert: Ein Wert von 1 entspricht einer Situation, in der Clients zu 100% <code>idle in transaction</code> <code>total_xact_time</code> sind.  Und mit einer solchen Normalisierung ist es leicht zu verstehen, wie schlimm alles ist: </p><br><p><img src="https://habrastorage.org/webt/t9/kn/io/t9knioh2ckzd_photgqvcq543x4.png"></p><br><p>  <code>total_xact_time - total_query_time</code> zu Duration zurückkehren, kann die Metrik <code>total_xact_time - total_query_time</code> durch die Anzahl der Transaktionen geteilt werden, um zu sehen, wie hoch die durchschnittliche Leerlaufanwendung pro Transaktion ist. </p><br><hr><br><p>  Meiner Meinung nach sind USE / RED-Methoden am nützlichsten, um zu strukturieren, welche Metriken Sie aufnehmen und warum.  Da wir uns mit der Vollzeitüberwachung beschäftigen und verschiedene Infrastrukturkomponenten überwachen müssen, helfen uns diese Methoden, die richtigen Metriken zu ermitteln, die richtigen Zeitpläne und Auslöser für unsere Kunden zu erstellen. </p><br><p>  <em>Eine gute Überwachung kann nicht sofort durchgeführt werden, sondern ist ein iterativer Prozess.</em>  <em>In <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">okmeter.io haben</a> wir nur eine kontinuierliche Überwachung (es gibt viele Dinge, aber morgen wird es besser und detaillierter sein :)</em> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de420429/">https://habr.com/ru/post/de420429/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de420413/index.html">SQLite und NW.js - Schritt-für-Schritt-Anleitungen zum Erstellen starker Freundschaften</a></li>
<li><a href="../de420415/index.html">Alles, was Sie über das Testen von Wi-Fi-Adaptern wissen wollten, aber Angst hatten zu fragen</a></li>
<li><a href="../de420419/index.html">Läufer für diejenigen, die Demütigung mögen oder wie wir PixJam verändert und modifiziert haben</a></li>
<li><a href="../de420423/index.html">Probleme mit der Schnittstelle zwischen Bodenkreuzung</a></li>
<li><a href="../de420425/index.html">Theorie und Praxis der Verwendung von HBase</a></li>
<li><a href="../de420431/index.html">Mars Praktischer Leitfaden zum Terraforming für Hausfrauen</a></li>
<li><a href="../de420433/index.html">„Freitag-Format“: Musikalische Straßen - was ist das und warum sind sie nicht in Russland?</a></li>
<li><a href="../de420435/index.html">Schnellstart mit ARM Mbed: Entwicklung moderner Mikrocontroller für Anfänger</a></li>
<li><a href="../de420437/index.html">Eine praktische Einführung in den Paketmanager für Kubernetes - Helm</a></li>
<li><a href="../de420439/index.html">Fintech-Digest: Die Investitionen in Fintech beliefen sich auf 57 Milliarden US-Dollar, die Transaktionsgeschwindigkeit steigt und die Kosten sinken</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
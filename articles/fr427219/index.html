<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî∂ üë©üèæ‚Äçüíª üèáüèº Messagerie diff√©r√©e non bloquante inutile dans MPI: analyse l√©g√®re et tutoriel pour ceux qui sont un peu "dans le sujet" üå¶Ô∏è ü§≤ üöó</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Plus r√©cemment, j'ai d√ª r√©soudre une autre t√¢che de formation triviale de mon professeur. Cependant, en le r√©solvant, j'ai r√©ussi √† attirer l'attentio...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Messagerie diff√©r√©e non bloquante inutile dans MPI: analyse l√©g√®re et tutoriel pour ceux qui sont un peu "dans le sujet"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/427219/">  Plus r√©cemment, j'ai d√ª r√©soudre une autre t√¢che de formation triviale de mon professeur.  Cependant, en le r√©solvant, j'ai r√©ussi √† attirer l'attention sur des choses auxquelles je n'avais pas du tout pens√© auparavant, peut-√™tre que vous n'y avez pas pens√© non plus.  Cet article sera plus susceptible d'√™tre utile aux √©tudiants et √† tous ceux qui commencent leur voyage dans le monde de la programmation parall√®le √† l'aide de MPI. <br><br><img src="https://habrastorage.org/webt/v0/ik/2-/v0ik2-rxhe1gexlrsumqpwhslbu.jpeg"><br><br><h2>  Notre "Compte tenu:" </h2><br>  Ainsi, l'essence de notre t√¢che essentiellement informatique est de comparer le nombre de fois qu'un programme qui utilise des transferts point √† point retard√©s non bloquants est plus rapide que celui qui utilise des transferts point √† point bloquants.  Nous effectuerons des mesures pour des matrices d'entr√©e de dimensions 64, 256, 1024, 4096, 8192, 16384, 65536, 262144, 1048576, 4194304, 16777216, 33554432 √©l√©ments.  Par d√©faut, il est propos√© de le r√©soudre par quatre processus.  Et voici, en fait, ce que nous allons consid√©rer: <br><br><a name="habracut"></a><img src="https://habrastorage.org/webt/rt/vc/vo/rtvcvob3gfonidkax7qtskxfbc0.png"><cut></cut><br><br>  En sortie, nous devrions obtenir trois vecteurs: Y1, Y2 et Y3, que le processus z√©ro collectera.  Je vais tester tout cela sur mon syst√®me bas√© sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un processeur Intel</a> avec 16 Go de RAM.  Pour d√©velopper des programmes, nous utiliserons l'impl√©mentation de la norme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MPI de Microsoft version 9.0.1</a> (au moment de la r√©daction, c'est pertinent), Visual Studio Community 2017 et non Fortran. <br><br><h2>  Mat√©riel </h2><br>  Je ne voudrais pas d√©crire en d√©tail comment fonctionnent les fonctions MPI qui seront utilis√©es, vous pouvez toujours aller <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">consulter la documentation pour cela</a> , donc je ne donnerai qu'un bref aper√ßu de ce que nous utiliserons. <br><br><h4>  Bloquer l'√©change </h4><br>  <b>Pour bloquer la messagerie point √† point, nous utiliserons les fonctions:</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MPI_Send</a> - impl√©mente le blocage de l'envoi de messages, c'est-√†-dire  apr√®s avoir appel√© la fonction, le processus est bloqu√© jusqu'√† ce que les donn√©es qui lui sont envoy√©es soient √©crites de sa m√©moire dans la m√©moire tampon du syst√®me interne MPI, apr√®s quoi le processus continue de fonctionner davantage; <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MPI_Recv</a> - effectue la r√©ception du message de blocage, c'est-√†-dire  Apr√®s avoir appel√© la fonction, le processus est bloqu√© jusqu'√† l'arriv√©e des donn√©es du processus d'envoi et jusqu'√† ce que ces donn√©es soient compl√®tement √©crites dans le tampon du processus de r√©ception par l'environnement MPI. <br><br><h4>  √âchange diff√©r√© non bloquant </h4><br>  <b>Pour la messagerie point √† point non bloquante diff√©r√©e, nous utiliserons les fonctions:</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MPI_Send_init</a> - en arri√®re-plan pr√©pare l'environnement pour l'envoi de donn√©es qui se produiront dans un futur proche et sans verrouillage; <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MPI_Recv_init</a> - cette fonction fonctionne de mani√®re similaire √† la pr√©c√©dente, mais cette fois pour recevoir des donn√©es; <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MPI_Start</a> - d√©marre le processus de r√©ception ou de transmission d'un message, il s'ex√©cute √©galement en arri√®re-plan de a.k.a.  sans blocage; <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MPI_Wait</a> - est utilis√© pour v√©rifier et, si n√©cessaire, attendre la fin de l'envoi ou de la r√©ception d'un message, mais il bloque simplement le processus si n√©cessaire (si les donn√©es ne sont "pas envoy√©es" ou "non re√ßues").  Par exemple, un processus veut utiliser des donn√©es qui ne l'ont pas encore atteint - pas bon, donc nous ins√©rons MPI_Wait devant l'endroit o√π il aura besoin de ces donn√©es (nous l'ins√©rons m√™me s'il y a simplement un risque de corruption de donn√©es).  Un autre exemple, le processus a commenc√© le transfert de donn√©es en arri√®re-plan, et apr√®s avoir commenc√© le transfert de donn√©es, il a imm√©diatement commenc√© √† modifier ces donn√©es d'une mani√®re ou d'une autre - pas bon, donc nous ins√©rons MPI_Wait devant l'endroit dans le programme o√π il commence √† modifier ces donn√©es (ici nous l'ins√©rons √©galement m√™me si il y a simplement un risque de corruption des donn√©es). <br><br>  Ainsi, <i>s√©mantiquement, la</i> s√©quence d'appels avec un √©change non bloquant diff√©r√© est la suivante: <br><br><ol><li>  MPI_Send_init / MPI_Recv_init - pr√©parer l'environnement pour la r√©ception ou la transmission </li><li>  MPI_Start - d√©marrer le processus de r√©ception / transmission </li><li>  MPI_Wait - nous appelons au risque de dommages (y compris "sous-envoi" et "sous-d√©claration") des donn√©es transmises ou re√ßues </li></ol><br>  J'ai √©galement utilis√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MPI_Startall</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MPI_Waitall</a> dans mes programmes de test, leur signification est essentiellement la m√™me que MPI_Start et MPI_Wait, respectivement, seulement ils fonctionnent sur plusieurs packages et / ou transmissions.  Mais ce n'est pas toute la liste des fonctions de d√©marrage et d'attente, il existe plusieurs autres fonctions pour v√©rifier l'int√©gralit√© des op√©rations. <br><br><h2>  Architecture inter-processus </h2><br>  Pour plus de clart√©, nous construisons un graphique pour effectuer des calculs par quatre processus.  Dans ce cas, on devrait essayer de distribuer toutes les op√©rations arithm√©tiques vectorielles de mani√®re relativement √©gale sur les processus.  Voici ce que j'ai obtenu: <br><br><img src="https://habrastorage.org/webt/bq/_b/q4/bq_bq43yrgkgjayi8p5uy0g9ckk.png"><br><br>  Voir ces tableaux T0-T2?  Ce sont des tampons pour stocker les r√©sultats interm√©diaires des op√©rations.  De plus, sur un graphique lors de l'envoi de messages d'un processus √† un autre, au d√©but de la fl√®che se trouve le nom du tableau dont les donn√©es sont transmises et √† la fin de la fl√®che se trouve le tableau qui re√ßoit ces donn√©es. <br><br>  Eh bien, quand avons-nous finalement r√©pondu aux questions: <br><br><ol><li>  Quel genre de probl√®me r√©solvons-nous? </li><li>  Quels outils utiliserons-nous pour le r√©soudre? </li><li>  Comment allons-nous le r√©soudre? </li></ol><br>  Il ne reste plus qu'√† le r√©soudre ... <br><br><h2>  Notre ¬´solution:¬ª </h2><br>  Ensuite, je pr√©senterai les codes des deux programmes discut√©s ci-dessus, mais pour commencer, je donnerai quelques explications suppl√©mentaires sur quoi et comment. <br><br>  J'ai supprim√© toutes les op√©rations arithm√©tiques vectorielles dans des proc√©dures distinctes (add, sub, mul, div) afin d'augmenter la lisibilit√© du code.  Tous les tableaux d'entr√©e sont initialis√©s conform√©ment aux formules que j'ai indiqu√©es <i>presque</i> au hasard.  √âtant donn√© que le processus z√©ro recueille les r√©sultats du travail de tous les autres processus, il fonctionne donc le plus longtemps, il est donc logique de consid√©rer le temps de son travail √©gal √† l'ex√©cution du programme (comme nous nous en souvenons, nous sommes int√©ress√©s par: arithm√©tique + messagerie) dans les premier et deuxi√®me cas.  Nous mesurerons les intervalles de temps en utilisant la fonction <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MPI_Wtime,</a> et en m√™me temps j'ai d√©cid√© d'afficher quelle r√©solution des montres que j'ai l√† en utilisant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MPI_Wtick</a> (quelque part dans mon √¢me j'esp√®re qu'elles s'int√®grent dans mon TSC invariant, dans ce cas, je suis m√™me pr√™t √† leur pardonner l'erreur associ√©e √† l'heure √† laquelle la fonction a √©t√© appel√©e MPI_Wtime).  Donc, nous allons rassembler tout ce que j'ai √©crit ci-dessus et conform√©ment au graphique, nous allons enfin d√©velopper ces programmes (et d√©boguer bien s√ªr aussi). <br><br><hr><br>  Qui se soucie de voir le code: <br><br><div class="spoiler">  <b class="spoiler_title">Programme avec blocage des transferts de donn√©es</b> <div class="spoiler_text"><pre><code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"pch.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;iostream&gt; #include &lt;iomanip&gt; #include &lt;fstream&gt; #include &lt;mpi.h&gt; using namespace std; void add(double *A, double *B, double *C, int n); void sub(double *A, double *B, double *C, int n); void mul(double *A, double *B, double *C, int n); void div(double *A, double *B, double *C, int n); int main(int argc, char **argv) { if (argc &lt; 2) { return 1; } int n = atoi(argv[1]); int rank; double start_time, end_time; MPI_Status status; double *A = new double[n]; double *B = new double[n]; double *C = new double[n]; double *D = new double[n]; double *E = new double[n]; double *G = new double[n]; double *T0 = new double[n]; double *T1 = new double[n]; double *T2 = new double[n]; for (int i = 0; i &lt; n; i++) { A[i] = double (2 * i + 1); B[i] = double(2 * i); C[i] = double(0.003 * (i + 1)); D[i] = A[i] * 0.001; E[i] = B[i]; G[i] = C[i]; } cout.setf(ios::fixed); cout &lt;&lt; fixed &lt;&lt; setprecision(9); MPI_Init(&amp;argc, &amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank); if (rank == 0) { start_time = MPI_Wtime(); sub(A, B, T0, n); MPI_Send(T0, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD); MPI_Send(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD); div(T0, G, T1, n); MPI_Recv(T2, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;status); add(T1, T2, T0, n); mul(T0, T1, T2, n); MPI_Recv(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;status); MPI_Send(T2, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD); add(T0, T2, T1, n); MPI_Recv(T0, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;status); MPI_Recv(T2, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;status); end_time = MPI_Wtime(); cout &lt;&lt; "Clock resolution: " &lt;&lt; MPI_Wtick() &lt;&lt; " secs" &lt;&lt; endl; cout &lt;&lt; "Thread " &lt;&lt; rank &lt;&lt; " execution time: " &lt;&lt; end_time - start_time &lt;&lt; endl; } if (rank == 1) { add(C, C, T0, n); MPI_Recv(T1, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;status); MPI_Send(T0, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD); mul(T1, G, T2, n); add(T2, C, T0, n); MPI_Recv(T1, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;status); MPI_Send(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD); sub(T1, T0, T2, n); MPI_Recv(T0, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;status); add(T0, T2, T1, n); MPI_Send(T1, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD); } if (rank == 2) { mul(C, C, T0, n); MPI_Recv(T1, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;status); MPI_Recv(T2, n, MPI_DOUBLE, 3, 0, MPI_COMM_WORLD, &amp;status); MPI_Send(T0, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD); MPI_Send(T0, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD); add(T1, T2, T0, n); mul(T0, G, T1, n); MPI_Recv(T2, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;status); mul(T1, T2, T0, n); MPI_Recv(T1, n, MPI_DOUBLE, 3, 0, MPI_COMM_WORLD, &amp;status); mul(T0, T1, T2, n); MPI_Send(T2, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD); } if (rank == 3) { mul(E, D, T0, n); MPI_Send(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD); sub(T0, B, T1, n); mul(T1, T1, T2, n); sub(T1, G, T0, n); mul(T0, T2, T1, n); MPI_Send(T1, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD); } MPI_Finalize(); delete[] A; delete[] B; delete[] C; delete[] D; delete[] E; delete[] G; delete[] T0; delete[] T1; delete[] T2; return 0; } void add(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] + B[i]; } } void sub(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] - B[i]; } } void mul(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] * B[i]; } } void div(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] / B[i]; } }</span></span></span></span></code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">Programme avec transferts de donn√©es non bloquants diff√©r√©s</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"pch.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;iostream&gt; #include &lt;iomanip&gt; #include &lt;fstream&gt; #include &lt;mpi.h&gt; using namespace std; void add(double *A, double *B, double *C, int n); void sub(double *A, double *B, double *C, int n); void mul(double *A, double *B, double *C, int n); void div(double *A, double *B, double *C, int n); int main(int argc, char **argv) { if (argc &lt; 2) { return 1; } int n = atoi(argv[1]); int rank; double start_time, end_time; MPI_Request request[7]; MPI_Status statuses[4]; double *A = new double[n]; double *B = new double[n]; double *C = new double[n]; double *D = new double[n]; double *E = new double[n]; double *G = new double[n]; double *T0 = new double[n]; double *T1 = new double[n]; double *T2 = new double[n]; for (int i = 0; i &lt; n; i++) { A[i] = double(2 * i + 1); B[i] = double(2 * i); C[i] = double(0.003 * (i + 1)); D[i] = A[i] * 0.001; E[i] = B[i]; G[i] = C[i]; } cout.setf(ios::fixed); cout &lt;&lt; fixed &lt;&lt; setprecision(9); MPI_Init(&amp;argc, &amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank); if (rank == 0) { start_time = MPI_Wtime(); MPI_Send_init(T0, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;request[0]);// MPI_Send_init(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[1]);// MPI_Recv_init(T2, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;request[2]);// MPI_Recv_init(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[3]);// MPI_Send_init(T2, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;request[4]);// MPI_Recv_init(T0, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;request[5]);// MPI_Recv_init(T2, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[6]);// MPI_Start(&amp;request[2]); sub(A, B, T0, n); MPI_Startall(2, &amp;request[0]); div(T0, G, T1, n); MPI_Waitall(3, &amp;request[0], statuses); add(T1, T2, T0, n); mul(T0, T1, T2, n); MPI_Startall(2, &amp;request[3]); MPI_Wait(&amp;request[3], &amp;statuses[0]); add(T0, T2, T1, n); MPI_Startall(2, &amp;request[5]); MPI_Wait(&amp;request[4], &amp;statuses[0]); MPI_Waitall(2, &amp;request[5], statuses); end_time = MPI_Wtime(); cout &lt;&lt; "Clock resolution: " &lt;&lt; MPI_Wtick() &lt;&lt; " secs" &lt;&lt; endl; cout &lt;&lt; "Thread " &lt;&lt; rank &lt;&lt; " execution time: " &lt;&lt; end_time - start_time &lt;&lt; endl; } if (rank == 1) { MPI_Recv_init(T1, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[0]);// MPI_Send_init(T0, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[1]);// MPI_Recv_init(T1, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[2]);// MPI_Send_init(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[3]);// MPI_Recv_init(T0, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[4]);// MPI_Send_init(T1, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[5]);// MPI_Start(&amp;request[0]); add(C, C, T0, n); MPI_Start(&amp;request[1]); MPI_Wait(&amp;request[0], &amp;statuses[0]); mul(T1, G, T2, n); MPI_Start(&amp;request[2]); MPI_Wait(&amp;request[1], &amp;statuses[0]); add(T2, C, T0, n); MPI_Start(&amp;request[3]); MPI_Wait(&amp;request[2], &amp;statuses[0]); sub(T1, T0, T2, n); MPI_Wait(&amp;request[3], &amp;statuses[0]); MPI_Start(&amp;request[4]); MPI_Wait(&amp;request[4], &amp;statuses[0]); add(T0, T2, T1, n); MPI_Start(&amp;request[5]); MPI_Wait(&amp;request[5], &amp;statuses[0]); } if (rank == 2) { MPI_Recv_init(T1, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[0]);// MPI_Recv_init(T2, n, MPI_DOUBLE, 3, 0, MPI_COMM_WORLD, &amp;request[1]);// MPI_Send_init(T0, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;request[2]);// MPI_Send_init(T0, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[3]);// MPI_Recv_init(T2, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;request[4]);// MPI_Recv_init(T1, n, MPI_DOUBLE, 3, 0, MPI_COMM_WORLD, &amp;request[5]);// MPI_Send_init(T2, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[6]);// MPI_Startall(2, &amp;request[0]); mul(C, C, T0, n); MPI_Startall(2, &amp;request[2]); MPI_Waitall(4, &amp;request[0], statuses); add(T1, T2, T0, n); MPI_Start(&amp;request[4]); mul(T0, G, T1, n); MPI_Wait(&amp;request[4], &amp;statuses[0]); mul(T1, T2, T0, n); MPI_Start(&amp;request[5]); MPI_Wait(&amp;request[5], &amp;statuses[0]); mul(T0, T1, T2, n); MPI_Start(&amp;request[6]); MPI_Wait(&amp;request[6], &amp;statuses[0]); } if (rank == 3) { MPI_Send_init(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[0]); MPI_Send_init(T1, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[1]); mul(E, D, T0, n); MPI_Start(&amp;request[0]); sub(T0, B, T1, n); mul(T1, T1, T2, n); MPI_Wait(&amp;request[0], &amp;statuses[0]); sub(T1, G, T0, n); mul(T0, T2, T1, n); MPI_Start(&amp;request[1]); MPI_Wait(&amp;request[1], &amp;statuses[0]); } MPI_Finalize(); delete[] A; delete[] B; delete[] C; delete[] D; delete[] E; delete[] G; delete[] T0; delete[] T1; delete[] T2; return 0; } void add(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] + B[i]; } } void sub(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] - B[i]; } } void mul(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] * B[i]; } } void div(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] / B[i]; } }</span></span></span></span></code> </pre></div></div><br><hr><br><h2>  Test et analyse </h2><br>  Ex√©cutons nos programmes pour des tableaux de diff√©rentes tailles et voyons ce qui se passe.  Les r√©sultats des tests sont r√©sum√©s dans le tableau, dans la derni√®re colonne dont nous calculons et √©crivons le coefficient d'acc√©l√©ration, que nous d√©finissons comme suit: K <sub>accele</sub> = T <sub>ex.</sub>  <sub>non bloquant.</sub>  / <sub>Bloc</sub> T. <br><br><img src="https://habrastorage.org/webt/ba/hg/zv/bahgzvsgz67vnkfsji-swsyy_cg.png"><br><br>  Si vous regardez ce tableau un peu plus attentivement que d'habitude, vous remarquerez qu'avec une augmentation du nombre d'√©l√©ments trait√©s, le coefficient d'acc√©l√©ration diminue en quelque sorte comme ceci: <br><br><img src="https://habrastorage.org/webt/qq/to/hv/qqtohvv7azbc05r6x4mwtfbbxfe.png"><br><br>  Essayons de d√©terminer quel est le probl√®me?  Pour ce faire, je propose d'√©crire un petit programme de test qui mesurera le temps de chaque op√©ration arithm√©tique vectorielle et r√©duira soigneusement les r√©sultats dans un fichier texte ordinaire. <br><br><hr><br>  Ici, en fait, le programme lui-m√™me: <br><br><div class="spoiler">  <b class="spoiler_title">Mesure du temps</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"pch.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;iostream&gt; #include &lt;iomanip&gt; #include &lt;Windows.h&gt; #include &lt;fstream&gt; using namespace std; void add(double *A, double *B, double *C, int n); void sub(double *A, double *B, double *C, int n); void mul(double *A, double *B, double *C, int n); void div(double *A, double *B, double *C, int n); int main() { struct res { double add; double sub; double mul; double div; }; int i, j, k, n, loop; LARGE_INTEGER start_time, end_time, freq; ofstream fout("test_measuring.txt"); int N[12] = { 64, 256, 1024, 4096, 8192, 16384, 65536, 262144, 1048576, 4194304, 16777216, 33554432 }; SetConsoleOutputCP(1251); cout &lt;&lt; "   loop: "; cin &gt;&gt; loop; fout &lt;&lt; setiosflags(ios::fixed) &lt;&lt; setiosflags(ios::right) &lt;&lt; setprecision(9); fout &lt;&lt; " : " &lt;&lt; loop &lt;&lt; endl; fout &lt;&lt; setw(10) &lt;&lt; "\n " &lt;&lt; setw(30) &lt;&lt; ".   (c)" &lt;&lt; setw(30) &lt;&lt; ".   (c)" &lt;&lt; setw(30) &lt;&lt; ".  (c)" &lt;&lt; setw(30) &lt;&lt; ".   (c)" &lt;&lt; endl; QueryPerformanceFrequency(&amp;freq); cout &lt;&lt; "\n : " &lt;&lt; freq.QuadPart &lt;&lt; " " &lt;&lt; endl; for (k = 0; k &lt; sizeof(N) / sizeof(int); k++) { res output = {}; n = N[k]; double *A = new double[n]; double *B = new double[n]; double *C = new double[n]; for (i = 0; i &lt; n; i++) { A[i] = 2.0 * i; B[i] = 2.0 * i + 1; C[i] = 0; } for (j = 0; j &lt; loop; j++) { QueryPerformanceCounter(&amp;start_time); add(A, B, C, n); QueryPerformanceCounter(&amp;end_time); output.add += double(end_time.QuadPart - start_time.QuadPart) / double(freq.QuadPart); QueryPerformanceCounter(&amp;start_time); sub(A, B, C, n); QueryPerformanceCounter(&amp;end_time); output.sub += double(end_time.QuadPart - start_time.QuadPart) / double(freq.QuadPart); QueryPerformanceCounter(&amp;start_time); mul(A, B, C, n); QueryPerformanceCounter(&amp;end_time); output.mul += double(end_time.QuadPart - start_time.QuadPart) / double(freq.QuadPart); QueryPerformanceCounter(&amp;start_time); div(A, B, C, n); QueryPerformanceCounter(&amp;end_time); output.div += double(end_time.QuadPart - start_time.QuadPart) / double(freq.QuadPart); } fout &lt;&lt; setw(10) &lt;&lt; n &lt;&lt; setw(30) &lt;&lt; output.add / loop &lt;&lt; setw(30) &lt;&lt; output.sub / loop &lt;&lt; setw(30) &lt;&lt; output.mul / loop &lt;&lt; setw(30) &lt;&lt; output.div / loop &lt;&lt; endl; delete[] A; delete[] B; delete[] C; } fout.close(); cout &lt;&lt; endl; system("pause"); return 0; } void add(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] + B[i]; } } void sub(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] - B[i]; } } void mul(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] * B[i]; } } void div(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] / B[i]; } }</span></span></span></span></code> </pre></div></div><br><hr><br>  Au d√©marrage, il vous demande de saisir le nombre de cycles de mesure, j'ai test√© 10 000 cycles.  En sortie, on obtient le r√©sultat moyen pour chaque op√©ration: <br><br><img src="https://habrastorage.org/webt/iz/0g/bs/iz0gbs8ilynlmbchxtga_0at61s.png"><br><br>  Pour mesurer le temps, j'ai utilis√© le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">QueryPerformanceCounter de</a> haut niveau.  Je recommande fortement de lire <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cette FAQ</a> afin que la plupart des questions sur la mesure du temps avec cette fonction disparaissent d'elles-m√™mes.  Selon mes observations, il s'accroche au TSC (mais th√©oriquement ce n'est peut-√™tre pas pour lui), mais renvoie, selon l'aide, le nombre actuel de ticks du compteur.  Mais le fait est que mon compteur ne peut physiquement pas mesurer l'intervalle de temps de 32 ns (voir la premi√®re ligne du tableau des r√©sultats).  Ce r√©sultat est d√ª au fait qu'entre les deux appels du QueryPerformanceCounter, 0 tick ou 1 tick passe. Pour la premi√®re ligne du tableau, nous pouvons seulement conclure qu'environ un tiers des 10 000 r√©sultats sont √©gaux √† 1 tick.  <i>Ainsi, les donn√©es de ce tableau pour 64, 256 et m√™me pour 1024 √©l√©ments sont quelque chose d'assez approximatif.</i>  Maintenant, ouvrons l'un des programmes et calculons le nombre total d'op√©rations de chaque type qu'il rencontre, traditionnellement, nous ¬´r√©partissons¬ª tout selon le tableau suivant: <br><br><img src="https://habrastorage.org/webt/et/vo/w2/etvow2fj-vxgtusc9aez__9egxq.png"><br><br>  Enfin, nous connaissons le temps de chaque op√©ration arithm√©tique vectorielle et combien il est dans notre programme, essayons de savoir combien de temps est consacr√© √† ces op√©rations dans des programmes parall√®les et combien de temps est consacr√© au blocage et √† l'√©change de donn√©es non bloquant diff√©r√© entre les processus et encore, pour plus de clart√©, nous allons le r√©duire √† table: <br><br><img src="https://habrastorage.org/webt/no/k2/-0/nok2-0p1kpw8g1ahveqog4q9lzi.png"><br><br>  Sur la base des r√©sultats des donn√©es obtenues, nous construisons un graphique de trois fonctions: la premi√®re d√©crit le changement du temps pass√© √† bloquer les transferts entre les processus, √† partir du nombre d'√©l√©ments du tableau, le second d√©crit le changement du temps pass√© sur les transferts diff√©r√©s non bloquants entre les processus, sur le nombre d'√©l√©ments du tableau et le troisi√®me d√©crit le changement dans le temps, d√©pens√© en op√©rations arithm√©tiques, √† partir du nombre d'√©l√©ments de tableaux: <br><br><img src="https://habrastorage.org/webt/4e/w6/5h/4ew65htbb-s3vh7anlo0txafxpg.png"><br><br>  Comme vous l'avez d√©j√† remarqu√©, l'√©chelle verticale du graphique est logarithmique, c'est une mesure n√©cessaire, car  la dispersion des temps est trop grande et sur un graphique r√©gulier, rien n'aurait √©t√© visible.  Faites attention √† la fonction de la d√©pendance du temps pass√© √† l'arithm√©tique sur le nombre d'√©l√©ments, elle d√©passe en toute s√©curit√© les deux autres fonctions d'environ 1 million d'√©l√©ments.  Le truc c'est qu'il cro√Æt √† l'infini plus vite que ses deux adversaires.  Par cons√©quent, avec une augmentation du nombre d'√©l√©ments trait√©s, l'ex√©cution des programmes est de plus en plus d√©termin√©e par l'arithm√©tique plut√¥t que par les transferts.  Supposons que vous augmentiez le nombre de transferts entre les processus, conceptuellement, vous ne verrez que le moment o√π la fonction arithm√©tique d√©passera les deux autres se produira plus tard. <br><br><h2>  R√©sum√© </h2><br>  Ainsi, en continuant d'augmenter la longueur des tableaux, vous arriverez √† la conclusion qu'un programme avec des transferts non bloquants diff√©r√©s ne sera que tr√®s l√©g√®rement plus rapide que celui qui utilise l'√©change bloquant.  Et si vous dirigez la longueur des tableaux vers l'infini (enfin, ou prenez simplement des tableaux tr√®s longs), la dur√©e de fonctionnement de votre programme sera d√©termin√©e √† 100% par des calculs, et le coefficient d'acc√©l√©ration tendra en toute s√©curit√© √† 1. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr427219/">https://habr.com/ru/post/fr427219/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr427207/index.html">Les employ√©s de Rockstar se l√®vent pour l'entreprise apr√®s avoir critiqu√© les semaines de travail de 100 heures</a></li>
<li><a href="../fr427209/index.html">GeoPuzzle - faites le monde morceau par morceau</a></li>
<li><a href="../fr427211/index.html">Electron est un flash pour ordinateur de bureau</a></li>
<li><a href="../fr427215/index.html">Les microservices doivent grandir, pas commencer par eux</a></li>
<li><a href="../fr427217/index.html">Analyse des performances des serveurs WSGI: deuxi√®me partie</a></li>
<li><a href="../fr427221/index.html">Ce que j'ai r√©alis√© sur le chemin de mon r√™ve d'intelligence artificielle</a></li>
<li><a href="../fr427223/index.html">Quelle est la responsabilit√© du d√©veloppeur principal</a></li>
<li><a href="../fr427225/index.html">Sortie d'Oracle Database 18c XE</a></li>
<li><a href="../fr427227/index.html">Comment nous avons cr√©√© un jeu de soci√©t√© avec t√©l√©commande - Partie 2</a></li>
<li><a href="../fr427229/index.html">Programme de gestion de projet de jeu de 4 ans</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
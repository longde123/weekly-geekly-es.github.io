<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®‚Äçüè´ üë®‚Äç‚úàÔ∏è üï¶ La nueva edad de oro para la arquitectura de computadoras ‚¨ÜÔ∏è üïû üë∂üèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los autores son John Hennessey y David Patterson, ganadores del Premio Turing 2017 "por un enfoque innovador sistem√°tico y medible para el dise√±o y ve...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>La nueva edad de oro para la arquitectura de computadoras</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440760/">  <i><font color="gray">Los autores son John Hennessey y David Patterson, ganadores del Premio Turing 2017 "por un enfoque innovador sistem√°tico y medible para el dise√±o y verificaci√≥n de arquitecturas inform√°ticas que han tenido un impacto duradero en toda la industria de los microprocesadores".</font></i>  <i><font color="gray">Art√≠culo publicado en Communications of the ACM, febrero de 2019, Volumen 62, No. 2, pp. 48-60, doi: 10.1145 / 3282307</font></i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f32/766/d00/f32766d00d21a30b98a879e2a636a82f.jpg" align="left">  <i>"Los que no recuerdan el pasado est√°n condenados a repetirlo"</i> - George Santayana, 1905 <br><br>  Comenzamos nuestra <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">conferencia de Turing</a> el 4 de junio de 2018 con una revisi√≥n de la arquitectura de computadoras a partir de los a√±os 60.  Adem√°s de √©l, destacamos los problemas actuales e intentamos identificar oportunidades futuras que prometen una nueva era dorada en el campo de la arquitectura de computadoras en la pr√≥xima d√©cada.  Lo mismo que en la d√©cada de 1980, cuando realizamos nuestra investigaci√≥n para mejorar el costo, la eficiencia energ√©tica, la seguridad y el rendimiento de los procesadores, por lo que recibimos este honorable premio. <br><br><h4>  Ideas clave </h4><br><ul><li>  El progreso del software puede impulsar la innovaci√≥n arquitect√≥nica <br></li><li>  Aumentar el nivel de las interfaces de software y hardware crea oportunidades para la innovaci√≥n arquitect√≥nica. <br></li><li>  El mercado finalmente determina el ganador en la disputa de arquitectura </li></ul><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3LVeEjsn8Ts" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  El software "habla" con el equipo a trav√©s de un diccionario llamado "arquitectura del conjunto de instrucciones" (ISA).  A principios de la d√©cada de 1960, IBM ten√≠a cuatro series de computadoras incompatibles, cada una con su propio ISA, pila de software, sistema de E / S y nicho de mercado, orientado a peque√±as empresas, grandes empresas, aplicaciones cient√≠ficas y sistemas en tiempo real, respectivamente.  Los ingenieros de IBM, incluido el ganador del Premio Turing, Frederick Brooks Jr., decidieron crear un ISA √∫nico que efectivamente une a los cuatro. <br><br>  Necesitaban una soluci√≥n t√©cnica sobre c√≥mo proporcionar un ISA igualmente r√°pido para computadoras con buses de 8 y 64 bits.  En cierto sentido, los autobuses son los "m√∫sculos" de las computadoras: hacen el trabajo, pero son relativamente f√°ciles de "comprimir" y "expandir".  Entonces y ahora el mayor desaf√≠o para los dise√±adores es el "cerebro" del equipo de control del procesador.  Inspirado por la programaci√≥n, Maurice Wilkes, pionero en inform√°tica y ganador del Premio Turing, propuso opciones para simplificar este sistema.  El control se present√≥ como una matriz bidimensional, a la que llam√≥ el "almac√©n de control" (almac√©n de control).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cada columna de la matriz correspond√≠a a una l√≠nea de control, cada fila era microinstrucci√≥n y el registro de microinstrucciones se llamaba microprogramaci√≥n</a> .  La memoria de control contiene un int√©rprete ISA escrito por microinstrucciones, por lo que la ejecuci√≥n de una instrucci√≥n normal requiere varias microinstrucciones.  La memoria de control se implementa, de hecho, en la memoria, y es mucho m√°s barata que los elementos l√≥gicos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2f4/43f/818/2f443f8180eb7edbc2dbd66873b71c51.jpg"><br>  <i><font color="gray">Caracter√≠sticas de los cuatro modelos de la familia IBM System / 360;</font></i>  <i><font color="gray">IPS significa operaciones por segundo</font></i> <br><br>  La tabla muestra cuatro modelos del nuevo ISA en System / 360 de IBM, presentado el 7 de abril de 1964.  Los buses difieren en 8 veces, la capacidad de memoria es de 16, la velocidad del reloj es de casi 4, el rendimiento es de 50 y el costo es de casi 6. Las computadoras m√°s caras tienen la memoria de control m√°s extensa, porque los buses de datos m√°s complejos utilizan m√°s l√≠neas de control .  Las computadoras m√°s baratas tienen menos memoria de control debido a un hardware m√°s simple, pero necesitaban m√°s microinstrucciones, ya que necesitaban m√°s ciclos de reloj para ejecutar la instrucci√≥n System / 360. <br><br>  Gracias a la microprogramaci√≥n, IBM ha apostado a que la nueva ISA revolucionar√° la industria inform√°tica y gan√≥ la apuesta.  IBM dominaba sus mercados, y los descendientes de los viejos mainframes IBM de 55 a√±os todav√≠a generan $ 10 mil millones en ingresos anualmente. <br><br>  Como se ha se√±alado repetidamente, aunque el mercado es un √°rbitro imperfecto como tecnolog√≠a, pero dados los estrechos v√≠nculos entre la arquitectura y las computadoras comerciales, en √∫ltima instancia determina el √©xito de las innovaciones arquitect√≥nicas, que a menudo requieren una importante inversi√≥n en ingenier√≠a. <br><br><h3>  Circuitos integrados, CISC, 432, 8086, PC IBM </h3><br>  Cuando las computadoras cambiaron a circuitos integrados, la ley de Moore significaba que la memoria de control podr√≠a hacerse mucho m√°s grande.  A su vez, esto permiti√≥ una ISA mucho m√°s compleja.  Por ejemplo, la memoria de control VAX-11/780 de Digital Equipment Corp.  en 1977, ten√≠a 5120 palabras en 96 bits, mientras que su predecesor us√≥ solo 256 palabras en 56 bits. <br><br>  Algunos fabricantes han habilitado el firmware para clientes seleccionados que pueden haber agregado funciones personalizadas.  Esto se llama el almac√©n de control de escritura (WCS).  La computadora WCS m√°s famosa fue <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Alto</a> , que los ganadores del Premio Turing Chuck Tucker y Butler Lampson y sus colegas crearon para el Centro de Investigaci√≥n Xerox Palo Alto en 1973.  Realmente fue la primera computadora personal: aqu√≠ est√° la primera pantalla con im√°genes elemento por elemento y la primera red Ethernet local.  Los controladores para la innovadora pantalla y tarjeta de red eran microprogramas que se almacenan en el WCS con una capacidad de 4096 palabras en 32 bits. <br><br>  En los a√±os 70, los procesadores segu√≠an siendo de 8 bits (por ejemplo, Intel 8080) y se programaban principalmente en ensamblador.  Los competidores agregaron nuevas instrucciones para superarse mutuamente, mostrando sus logros con ejemplos de ensamblador. <br><br>  Gordon Moore cre√≠a que el pr√≥ximo ISA de Intel durar√≠a para siempre para la compa√±√≠a, por lo que contrat√≥ a muchos doctores inteligentes en inform√°tica y los envi√≥ a una nueva instalaci√≥n en Portland para inventar el pr√≥ximo gran ISA.  El procesador 8800, como Intel lo llam√≥ originalmente, se ha convertido en un proyecto de arquitectura de computadora absolutamente ambicioso para cualquier √©poca, por supuesto, fue el proyecto m√°s agresivo de los a√±os 80.  Inclu√≠a direccionamiento basado en capacidades de 32 bits, una arquitectura orientada a objetos, instrucciones de longitud variable y su propio sistema operativo en el nuevo lenguaje de programaci√≥n Ada. <br><br>  Desafortunadamente, este ambicioso proyecto requiri√≥ varios a√±os de desarrollo, lo que oblig√≥ a Intel a lanzar un proyecto de respaldo de emergencia en Santa Clara para lanzar r√°pidamente un procesador de 16 bits en 1979.  Intel le dio al nuevo equipo 52 semanas para desarrollar el nuevo ISA "8086", dise√±ar y construir el chip.  Dado un calendario apretado, el dise√±o de ISA tom√≥ solo 10 semanas-persona por tres semanas calendario regulares, principalmente debido a la expansi√≥n de registros de 8 bits y un conjunto de instrucciones 8080 a 16 bits.  El equipo complet√≥ 8086 seg√∫n lo programado, pero este procesador hecho a prueba de fallas se anunci√≥ sin mucha fanfarria. <br><br>  Intel tuvo mucha suerte de que IBM estuviera desarrollando una computadora personal para competir con la Apple II y necesitara un microprocesador de 16 bits.  IBM estaba mirando el Motorola 68000 con un ISA similar al IBM 360, pero estaba atrasado en el agresivo cronograma de IBM.  En cambio, IBM cambi√≥ a la versi√≥n de 8 bits del bus 8086. Cuando IBM anunci√≥ la PC el 12 de agosto de 1981, esperaba vender 250,000 computadoras para 1986.  En cambio, la compa√±√≠a vendi√≥ 100 millones en todo el mundo, presentando un futuro muy prometedor para la ISA de emergencia de Intel. <br><br>  El proyecto original Intel 8800 pas√≥ a llamarse iAPX-432.  Finalmente, se anunci√≥ en 1981, pero requiri√≥ varios chips y tuvo serios problemas de rendimiento.  Se complet√≥ en 1986, un a√±o despu√©s de que Intel expandi√≥ el ISA 8086 de 16 bits a 80386, aumentando los registros de 16 bits a 32 bits.  Por lo tanto, la predicci√≥n de Moore con respecto a la ISA result√≥ ser correcta, pero el mercado eligi√≥ el 8086 hecho por la mitad, en lugar del ungido iAPX-432.  Como se dieron cuenta los arquitectos de los procesadores Motorola 68000 e iAPX-432, el mercado rara vez puede mostrar paciencia. <br><br><h3>  De conjunto de instrucciones complejo a abreviado </h3><br>  A principios de la d√©cada de 1980, se realizaron varios estudios de computadoras con un conjunto de instrucciones complejas (CISC): tienen grandes microprogramas en una gran memoria de control.  Cuando Unix demostr√≥ que incluso el sistema operativo se puede escribir en un lenguaje de alto nivel, la pregunta principal fue: "¬øQu√© instrucciones generar√°n los compiladores?"  en lugar del anterior "¬øQu√© ensamblador usar√°n los programadores?"  Un aumento significativo en el nivel de la interfaz hardware-software ha creado una oportunidad para la innovaci√≥n en arquitectura. <br><br>  El ganador del Premio Turing, John Kokk, y sus colegas han desarrollado compiladores de minicomputadoras e ISA m√°s simples.  Como experimento, reorientaron sus compiladores de investigaci√≥n para usar el IBM 360 ISA para usar solo operaciones simples entre registros y cargar con memoria, evitando instrucciones m√°s complejas.  Notaron que los programas se ejecutan tres veces m√°s r√°pido si usan un subconjunto simple.  Emer y Clark <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">descubrieron</a> que el 20% de las instrucciones VAX ocupan el 60% del microc√≥digo y solo toman el 0.2% del tiempo de ejecuci√≥n.  Un autor de este art√≠culo (Patterson) pas√≥ unas vacaciones creativas en DEC, ayudando a reducir los errores en el microc√≥digo VAX.  Si los fabricantes de microprocesadores iban a seguir los dise√±os de ISA con un conjunto de comandos complejos de CISC en computadoras grandes, esperaban una gran cantidad de errores de microc√≥digo y quer√≠an encontrar una manera de solucionarlos.  Escribi√≥ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un art√≠culo as√≠</a> , pero <i>la</i> revista <i>Computer</i> lo rechaz√≥.  Los revisores sugirieron que la terrible idea de construir microprocesadores con ISA es tan compleja que necesitan repararse en el campo.  Esta falla arroja dudas sobre el valor de CISC para los microprocesadores.  Ir√≥nicamente, los microprocesadores CISC modernos incluyen mecanismos de recuperaci√≥n de microc√≥digo, pero la negativa a publicar el art√≠culo inspir√≥ al autor a desarrollar un ISA menos complejo para microprocesadores: computadoras con un conjunto de instrucciones reducido (RISC). <br><br>  Estos comentarios y la transici√≥n a lenguajes de alto nivel permitieron la transici√≥n de CISC a RISC.  Primero, las instrucciones RISC se simplifican, por lo que no hay necesidad de un int√©rprete.  Las instrucciones RISC suelen ser simples como microinstrucciones y pueden ejecutarse directamente por hardware.  En segundo lugar, la memoria r√°pida que se utiliz√≥ anteriormente para el int√©rprete de microc√≥digo CISC se redise√±√≥ en la memoria cach√© de instrucciones RISC (la memoria cach√© es una memoria peque√±a y r√°pida que almacena las instrucciones ejecutadas recientemente, ya que es probable que dichas instrucciones se reutilicen en un futuro pr√≥ximo).  En tercer lugar, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">los asignadores de registros basados ‚Äã‚Äãen el esquema de colores del gr√°fico de Gregory Chaitin</a> facilitaron en gran medida el uso eficiente de registros para compiladores, que se beneficiaron de estas NIA con operaciones de registro a registro.  Finalmente, la ley de Moore condujo al hecho de que en la d√©cada de 1980 hab√≠a suficientes transistores en un chip para acomodar un bus completo de 32 bits en un solo chip, junto con cach√©s para instrucciones y datos. <br><br>  Por ejemplo, en la fig.  La Figura 1 muestra los microprocesadores <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">RISC-I</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MIPS</a> desarrollados en la Universidad de California en Berkeley y la Universidad de Stanford en 1982 y 1983, que demostraron los beneficios de RISC.  Como resultado, en 1984 estos procesadores se presentaron en la conferencia l√≠der sobre dise√±o de circuitos, la Conferencia Internacional de Circuitos de Estado S√≥lido IEEE ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> ).  Fue un momento maravilloso cuando varios estudiantes graduados en Berkeley y Stanford crearon microprocesadores que excedieron las capacidades de la industria de esa √©poca. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/410/ca5/11d/410ca511d626e92ae1ea3179fa59bddb.jpg"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">1. Procesadores RISC-I de la Universidad de California en Berkeley y MIPS de la Universidad de Stanford</font></i> <br><br>  Esos chips acad√©micos inspiraron a muchas compa√±√≠as a crear microprocesadores RISC, que fueron los m√°s r√°pidos en los pr√≥ximos 15 a√±os.  La explicaci√≥n est√° relacionada con la siguiente f√≥rmula de rendimiento del procesador: <br><br>  <i>Tiempo / Programa = (Instrucciones / Programa) √ó (medidas / instrucci√≥n) √ó (tiempo / medida)</i> <br><br>  M√°s tarde, los ingenieros de DEC <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">demostraron</a> que para un programa, los CISC m√°s complejos requieren el 75% del n√∫mero de instrucciones RISC (el primer t√©rmino en la f√≥rmula), pero en una tecnolog√≠a similar (tercer t√©rmino) cada instrucci√≥n CISC toma 5-6 ciclos m√°s (segundo t√©rmino), que hace que los microprocesadores RISC sean aproximadamente 4 veces m√°s r√°pidos. <br><br>  No exist√≠an tales f√≥rmulas en la literatura inform√°tica de los a√±os 80, lo que nos hizo escribir el libro <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Computer Architecture: A Quantitective Approach</a></i> en 1989.  El subt√≠tulo explica el tema del libro: usar medidas y puntos de referencia para cuantificar las compensaciones, en lugar de confiar en la intuici√≥n y la experiencia del dise√±ador, como en el pasado.  Nuestro enfoque cuantitativo tambi√©n se inspir√≥ en lo que hizo el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">libro de Turing Laureate Donald Knuth</a> para algoritmos. <br><br><h3>  VLIW, EPIC, Itanium </h3><br>  Se supon√≠a que el pr√≥ximo ISA innovador superar√≠a el √©xito de RISC y CISC.  La <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arquitectura de</a> instrucciones de m√°quina muy larga <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VLIW</a> y su primo EPIC (Computaci√≥n con paralelismo expl√≠cito de instrucciones de m√°quina) de Intel y Hewlett-Packard utilizaron instrucciones largas, cada una de las cuales consist√≠a en varias operaciones independientes unidas entre s√≠.  Los partidarios de VLIW y EPIC en ese momento cre√≠an que si una instrucci√≥n pudiera indicar, por ejemplo, seis operaciones independientes (dos transferencias de datos, dos operaciones de enteros y dos operaciones de punto flotante) y la tecnolog√≠a del compilador podr√≠a asignar eficientemente operaciones a seis ranuras de instrucciones, entonces el equipo se puede simplificar.  Similar al enfoque de RISC, VLIW y EPIC transfirieron el trabajo del hardware al compilador. <br><br>  Juntos, Intel y Hewlett-Packard han desarrollado un procesador basado en EPIC de 64 bits para reemplazar la arquitectura x86 de 32 bits.  Se fijaron grandes expectativas en el primer procesador EPIC llamado Itanium, pero la realidad no se correspond√≠a con las primeras declaraciones de los desarrolladores.  Aunque el enfoque EPIC funcion√≥ bien para programas de punto flotante altamente estructurados, no pudo lograr un alto rendimiento para programas enteros con ramificaciones menos perdidas y menos predecibles.  Como Donald Knuth <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">se√±al√≥</a> m√°s tarde: "Se supon√≠a que Itanium era ... incre√≠ble, hasta que result√≥ que los compiladores deseados eran b√°sicamente imposibles de escribir".  Los cr√≠ticos notaron retrasos en el lanzamiento de Itanium y lo denominaron Itanik en honor al desafortunado barco de pasajeros Titanic.  El mercado nuevamente no mostr√≥ paciencia y adopt√≥ la versi√≥n de 64 bits de x86, y no Itanium, como el sucesor. <br><br>  La buena noticia es que VLIW sigue siendo adecuado para aplicaciones m√°s especializadas que ejecutan peque√±os programas con ramas m√°s simples sin errores de cach√©, incluido el procesamiento de se√±ales digitales. <br><br><h1>  RISC vs. CISC en la era de PC y Post-PC </h1><br>  AMD e Intel necesitaban 500 equipos de dise√±o y tecnolog√≠a de semiconductores superior para cerrar la brecha de rendimiento entre x86 y RISC.  Nuevamente, en aras del rendimiento logrado a trav√©s de la canalizaci√≥n, un decodificador de instrucciones sobre la marcha traduce instrucciones complejas x86 en microinstrucciones internas tipo RISC.  AMD e Intel luego crean una tuber√≠a para su implementaci√≥n.  Cualquier idea que los dise√±adores de RISC usaran para mejorar el rendimiento (cach√©s de instrucciones e informaci√≥n separadas, cach√©s de segundo nivel en el chip, una tuber√≠a profunda y la recepci√≥n y ejecuci√≥n simult√°nea de varias instrucciones) se incluyeron en x86.  En la cima de la era de las computadoras personales en 2011, AMD e Intel enviaron alrededor de 350 millones de microprocesadores x86 anualmente.  Los altos vol√∫menes y los bajos m√°rgenes de la industria tambi√©n significaron precios m√°s bajos que las computadoras RISC. <br><br>  Con cientos de millones de computadoras vendidas anualmente, el software se ha convertido en un gran mercado.  Si bien los proveedores de software de Unix tuvieron que lanzar diferentes versiones de software para diferentes arquitecturas RISC (Alpha, HP-PA, MIPS, Power y SPARC), las computadoras personales ten√≠an un ISA, por lo que los desarrolladores lanzaron software "reducido" que era compatible binariamente solo con la arquitectura x86.  Debido a su base de software mucho m√°s grande, rendimiento similar y precios m√°s bajos, para el a√±o 2000 la arquitectura x86 dominaba los mercados de escritorios y servidores peque√±os. <br><br>  Apple ayud√≥ a marcar el comienzo de la era posterior a la PC con el iPhone en 2007.  En lugar de comprar microprocesadores, las compa√±√≠as de tel√©fonos inteligentes crearon sus propios sistemas en un chip (SoC) utilizando los desarrollos de otras personas, incluidos los procesadores RISC de ARM.  Aqu√≠, los dise√±adores son importantes no solo en el rendimiento, sino tambi√©n en el consumo de energ√≠a y el √°rea de chips, lo que pone en desventaja la arquitectura CISC.  Adem√°s, Internet de las cosas ha aumentado significativamente tanto el n√∫mero de procesadores como las compensaciones necesarias en tama√±o de chip, potencia, costo y rendimiento.  Esta tendencia ha aumentado la importancia del tiempo de dise√±o y el costo, empeorando a√∫n m√°s la posici√≥n de los procesadores CISC.  En la era actual posterior a la PC, los env√≠os anuales x86 han ca√≠do casi un 10% desde el pico de 2011, mientras que los chips RISC se han disparado a 20 mil millones.  Hoy, el 99% de los procesadores de 32 y 64 bits en el mundo son RISC. <br><br>  Concluyendo esta revisi√≥n hist√≥rica, podemos decir que el mercado ha resuelto la disputa entre RISC y CISC.  Aunque CISC gan√≥ las etapas posteriores de la era de la PC, RISC gana ahora que ha llegado la era posterior a la PC.  No hay nuevas ISA en CISC durante d√©cadas.  Para nuestra sorpresa, el consenso general sobre los mejores principios ISA para los procesadores de prop√≥sito general de hoy todav√≠a est√° a favor de RISC, 35 a√±os despu√©s de su invenci√≥n. <br><br><h1>  Retos modernos para la arquitectura del procesador </h1><br>  <i>"Si un problema no tiene una soluci√≥n, tal vez no sea un problema, sino un hecho con el que deber√≠as aprender a vivir"</i> - Shimon Peres <br><br>  Aunque la secci√≥n anterior se centr√≥ en el desarrollo de una arquitectura de conjunto de instrucciones (ISA), la mayor√≠a de los dise√±adores de la industria no desarrollan nuevas ISA, sino que integran las ISA existentes en la tecnolog√≠a de fabricaci√≥n existente.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Desde finales de los a√±os 70, la tecnolog√≠a predominante ha sido los circuitos integrados en estructuras MOS (MOS), primero tipo n (nMOS) y luego complementario (CMOS). El sorprendente ritmo de mejora en la tecnolog√≠a MOS, capturado por las predicciones de Gordon Moore, fue la fuerza impulsora que permiti√≥ a los dise√±adores desarrollar m√©todos m√°s agresivos para lograr el rendimiento de una determinada ISA. La predicci√≥n inicial de Moore </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en 1965</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> preve√≠a una duplicaci√≥n anual de la densidad del transistor; en 1975, lo </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">revis√≥</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , prediciendo una duplicaci√≥n cada dos a√±os. Al final, este pron√≥stico comenz√≥ a llamarse la ley de Moore. Dado que la densidad de los transistores crece cuadr√°ticamente y la velocidad crece linealmente, el uso de m√°s transistores puede aumentar la productividad.</font></font><br><br><h1>        </h1><br>         (. . 2), -   2000    ,   2018           15-.  2003   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> ,    </a> .    ,           CMOS   . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/073/9b2/026/0739b20261c12234f330eff27f9c3062.jpg"><br> <i><font color="gray">. 2.     Intel     </font></i> <br><br>    ,      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">¬´ ¬ª</a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">que a medida que aumenta la densidad de los transistores, el consumo de energ√≠a del transistor disminuir√°, por lo que el consumo por mm¬≤ de silicio ser√° casi constante. A medida que la potencia inform√°tica de un mil√≠metro de silicio crec√≠a con cada nueva generaci√≥n de tecnolog√≠a, las computadoras se volvieron m√°s eficientes energ√©ticamente. La escala de Dennard comenz√≥ a disminuir significativamente en 2007, y en 2012 pr√°cticamente no hab√≠a llegado a nada (ver Fig. 3). </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/e40/d10/c1d/e40d10c1d7a21c64618f4bd246411e11.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. 3. El n√∫mero de transistores por chip y el consumo de energ√≠a por mm¬≤</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De 1986 a 2002, la concurrencia de nivel de instrucci√≥n (ILP) fue el principal m√©todo arquitect√≥nico para aumentar la productividad. Junto con el aumento de la velocidad de los transistores, esto dio un aumento anual en la productividad de aproximadamente el 50%. El final de la escala de Dennard significaba que los arquitectos ten√≠an que encontrar mejores formas de usar la concurrencia.</font></font><br><br>  ,   ILP  ,     ARM, Intel  AMD. ,    15-      .  ,         60 ,     15 ,     25%  .   ,  ,        .   ‚Äî     ILP,  .     ,         ‚Äî      ‚Äî     ,     ,       .        ,     ,      . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para comprender cu√°n complejo es un dise√±o de este tipo, imagine la dificultad de predecir correctamente los resultados de 15 ramas. Si el dise√±ador del procesador establece un l√≠mite de p√©rdida del 10%, el procesador debe predecir correctamente cada rama con una precisi√≥n del 99,3%. No hay muchos programas de sucursal de prop√≥sito general que puedan predecirse con tanta precisi√≥n.</font></font><br><br>  ,       ,    . 4,   ,   ,    ,      .   SPEC  Intel Core i7     19% .     ,          ,    . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9a2/ce3/f54/9a2ce3f54d26359ce98e036eac216a5d.jpg"><br> <i><font color="gray">.4.        ,   Intel Core i7     SPEC</font></i> <br><br>      ,         .    . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En este concepto, la responsabilidad de identificar la concurrencia y decidir c√≥mo usarla se transfiere al programador y al sistema de lenguaje. Multin√∫cleo no resuelve el problema de la computaci√≥n eficiente en energ√≠a, que se agrav√≥ al final de la escala de Dennard. Cada n√∫cleo activo consume energ√≠a, independientemente de si est√° involucrado en c√°lculos eficientes. El obst√°culo principal es una vieja observaci√≥n llamada ley de Amdahl. Dice que los beneficios de la computaci√≥n paralela est√°n limitados por la fracci√≥n de la computaci√≥n secuencial. Para evaluar la importancia de esta observaci√≥n, considere la Figura 5. Muestra cu√°nto m√°s r√°pido funciona la aplicaci√≥n con 64 n√∫cleos en comparaci√≥n con un n√∫cleo, suponiendo una proporci√≥n diferente de c√°lculos secuenciales cuando solo un procesador est√° activo. Por ejemploSi el 1% de las veces el c√°lculo se realiza de forma secuencial, la ventaja de la configuraci√≥n de 64 procesadores es solo del 35%. Desafortunadamente, el consumo de energ√≠a es proporcional a 64 procesadores, por lo que aproximadamente el 45% de la energ√≠a se desperdicia.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a8e/d85/9c6/a8ed859c61efb49a292ca4f5ac3cb5f4.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. 5. El efecto de la ley de Amdahl sobre el aumento de la velocidad, teniendo en cuenta la proporci√≥n de medidas en modo secuencial.</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Por supuesto, los programas reales tienen una estructura m√°s compleja. Hay fragmentos que le permiten usar un n√∫mero diferente de procesadores en un momento dado. Sin embargo, la necesidad de interactuar peri√≥dicamente y sincronizarlos significa que la mayor√≠a de las aplicaciones tienen algunas partes que solo pueden usar de manera eficiente parte de los procesadores. Aunque la ley de Amdahl tiene m√°s de 50 a√±os, sigue siendo un obst√°culo dif√≠cil.</font></font><br><br>          ,         .  ,          .  ,       (TDP)    ,       .    -     ,               ,    .  TDP    ¬´ ¬ª (dark silicon),         ,   .        ,             . <br><br>    ,        , ,           (. . 6). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f0a/f8f/cd0/f0af8fcd06385641a5cc1266fda37a0f.jpg"><br> <i><font color="gray">. 6.       (SPECintCPU)</font></i> <br><br>       ‚Äî      80-  90-  ‚Äî    ,        .       ,        ‚Äî . <br><br><h1>   </h1><br>  En los a√±os 70, los desarrolladores de procesadores garantizaron diligentemente la seguridad de la computadora con la ayuda de varios conceptos, que van desde anillos protectores hasta funciones especiales.  Entendieron bien que la mayor√≠a de los errores estar√≠an en el software, pero cre√≠an que el soporte arquitect√≥nico podr√≠a ayudar.  Estas caracter√≠sticas no fueron utilizadas principalmente por sistemas operativos que funcionaban en entornos supuestamente seguros (como las computadoras personales).  Por lo tanto, las funciones asociadas con una sobrecarga significativa han sido eliminadas.  En la comunidad del software, muchos cre√≠an que las pruebas formales y los m√©todos como el uso de un microkernel proporcionar√≠an mecanismos efectivos para crear software altamente seguro.  Desafortunadamente, la escala de nuestros sistemas de software comunes y la b√∫squeda del rendimiento significaron que dichos m√©todos no pod√≠an mantenerse al d√≠a con el rendimiento.  Como resultado, los grandes sistemas de software todav√≠a tienen muchas fallas de seguridad, y el efecto se amplifica debido a la enorme y creciente cantidad de informaci√≥n personal en Internet y al uso de la computaci√≥n en la nube, donde los usuarios comparten el mismo equipo f√≠sico con un atacante potencial. <br><br>  Aunque los dise√±adores de procesadores y otros pueden no haberse dado cuenta de la creciente importancia de la seguridad de inmediato, comenzaron a incluir soporte de hardware para m√°quinas virtuales y cifrado.  Desafortunadamente, la predicci√≥n de rama introdujo una falla de seguridad desconocida pero significativa en muchos procesadores.  En particular, las <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">vulnerabilidades Meltdown y Spectre explotan las caracter√≠sticas de microarquitectura, lo que permite la filtraci√≥n de informaci√≥n protegida</a> .  Ambos usan los llamados ataques en canales de terceros cuando la informaci√≥n se filtra de acuerdo con la diferencia en el tiempo dedicado a la tarea.  En 2018, los investigadores mostraron <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">c√≥mo usar una de las opciones de Spectre para extraer informaci√≥n a trav√©s de la red sin descargar c√≥digo al procesador de destino</a> .  Aunque este ataque, llamado NetSpectre, transfiere informaci√≥n lentamente, el solo hecho de que le permite atacar cualquier m√°quina en la misma red local (o en el mismo cl√∫ster en la nube) crea muchos nuevos vectores de ataque.  Posteriormente, se informaron dos vulnerabilidades m√°s en la arquitectura de las m√°quinas virtuales ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> ).  Uno de ellos, llamado Foreshadow, le permite penetrar en los mecanismos de seguridad Intel SGX dise√±ados para proteger los datos m√°s valiosos (como las claves de cifrado).  Nuevas vulnerabilidades se encuentran mensualmente. <br><br>  Los ataques a canales de terceros no son nuevos, pero en la mayor√≠a de los casos los errores de software fueron la culpa antes.  En Meltdown, Spectre y otros ataques, esta es una falla en la implementaci√≥n del hardware.  Hay una dificultad fundamental en c√≥mo los arquitectos de procesadores determinan cu√°l es la implementaci√≥n correcta de ISA porque la definici√≥n est√°ndar no dice nada sobre los efectos de ejecuci√≥n de una secuencia de instrucciones, solo el estado de ejecuci√≥n arquitect√≥nico visible de ISA.  Los arquitectos deber√≠an repensar su definici√≥n de la implementaci√≥n correcta de ISA para evitar tales fallas de seguridad.  Al mismo tiempo, deben repensar la atenci√≥n que prestan a la seguridad inform√°tica y c√≥mo los arquitectos pueden trabajar con los desarrolladores de software para implementar sistemas m√°s seguros.  Los arquitectos (y todos los dem√°s) no deben tomar la seguridad de otra manera que no sea como una necesidad primaria. <br><br><h1>  Oportunidades futuras en arquitectura de computadoras </h1><br>  <i>"Tenemos oportunidades incre√≠bles disfrazadas de problemas insolubles".</i> - John Gardner, 1965 <br><br>  Las ineficiencias inherentes de los procesadores de uso general, ya sea la tecnolog√≠a ILP o los procesadores multin√∫cleo, combinados con la finalizaci√≥n de la escala de Dennard y la ley de Moore hacen improbable que los arquitectos y desarrolladores de procesadores puedan mantener un ritmo significativo de mejora del rendimiento para los procesadores de uso general.  Dada la importancia de mejorar la productividad del software, debemos hacernos la pregunta: ¬øqu√© otros enfoques prometedores existen? <br><br>  Hay dos posibilidades obvias, as√≠ como una tercera creada al combinar las dos.  Primero, los m√©todos de desarrollo de software existentes hacen un uso extensivo de lenguajes de alto nivel con escritura din√°mica.  Desafortunadamente, tales lenguajes generalmente se interpretan y ejecutan de manera extremadamente ineficiente.  Para ilustrar esta ineficiencia, Leiserson y sus colegas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dieron un peque√±o ejemplo: la multiplicaci√≥n de matrices</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/31e/c75/ebe/31ec75ebe5c3134c14020655b89e8ac1.jpg"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">7. Posible aceleraci√≥n de la multiplicaci√≥n de matrices de Python despu√©s de cuatro optimizaciones.</font></i> <br><br>  Como se muestra en la fig.  7, simplemente reescribir el c√≥digo de Python a C mejora el rendimiento en 47 veces.  El uso de bucles paralelos en muchos n√∫cleos da un factor adicional de aproximadamente 7. La optimizaci√≥n de la estructura de memoria para usar cach√©s da un factor de 20, y el √∫ltimo factor de 9 proviene del uso de extensiones de hardware para realizar operaciones SIMD paralelas que son capaces de realizar 16 instrucciones de 32 bits.  Despu√©s de eso, la versi√≥n final altamente optimizada se ejecuta en el procesador multin√∫cleo de Intel 62.806 veces m√°s r√°pido que la versi√≥n original de Python.  Esto, por supuesto, es un peque√±o ejemplo.  Se puede suponer que los programadores utilizar√°n una biblioteca optimizada.  Aunque la brecha de rendimiento es exagerada, probablemente hay muchos programas que pueden optimizarse 100-1000 veces. <br><br>  Un √°rea interesante de investigaci√≥n es la cuesti√≥n de si es posible cerrar algunas brechas de rendimiento con la nueva tecnolog√≠a de compilaci√≥n, posiblemente con mejoras arquitect√≥nicas.  Aunque es dif√≠cil traducir y compilar eficientemente lenguajes de scripting de alto nivel como Python, la recompensa potencial es enorme.  Incluso una peque√±a optimizaci√≥n puede llevar al hecho de que los programas Python se ejecutar√°n decenas a cientos de veces m√°s r√°pido.  Este sencillo ejemplo muestra cu√°n grande es la brecha entre los lenguajes modernos centrados en el rendimiento del programador y los enfoques tradicionales que enfatizan el rendimiento. <br><br><h3>  Arquitecturas Especializadas </h3><br>  Un enfoque m√°s orientado al hardware es el dise√±o de arquitecturas adaptadas a un √°rea tem√°tica espec√≠fica, donde demuestran una eficiencia significativa.  Estas son arquitecturas especializadas de dominio espec√≠fico (arquitecturas espec√≠ficas de dominio, DSA).  Por lo general, estos son procesadores programables y completos, pero teniendo en cuenta una clase espec√≠fica de tareas.  En este sentido, difieren de los circuitos integrados espec√≠ficos de la aplicaci√≥n (ASIC), que a menudo se usan para la misma funci√≥n que el c√≥digo que rara vez cambia.  Los DSA a menudo se denominan aceleradores, ya que aceleran algunas aplicaciones en comparaci√≥n con ejecutar toda la aplicaci√≥n en una CPU de prop√≥sito general.  Adem√°s, los DSA pueden proporcionar un mejor rendimiento porque se adaptan con mayor precisi√≥n a las necesidades de la aplicaci√≥n.  Los ejemplos de DSA incluyen procesadores gr√°ficos (GPU), procesadores de redes neuronales utilizados para el aprendizaje profundo y procesadores para redes definidas por software (SDN).  Los DSA logran un mayor rendimiento y una mayor eficiencia energ√©tica por cuatro razones principales. <br><br>  Primero, los DSA usan una forma m√°s eficiente de concurrencia para un √°rea tem√°tica espec√≠fica.  Por ejemplo, SIMD (secuencia de instrucciones √∫nica, secuencia de datos m√∫ltiples) es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">m√°s eficiente que MIMD</a> (secuencia de instrucciones m√∫ltiples, secuencia de datos m√∫ltiples).  Aunque SIMD es menos flexible, es muy adecuado para muchos DSA.  Los procesadores especializados tambi√©n pueden usar los enfoques ILP de VLIW en lugar de mecanismos poco especulativos.  Como se mencion√≥ anteriormente, los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">procesadores VLIW son poco adecuados para el c√≥digo de uso general</a> , pero para √°reas estrechas son mucho m√°s eficientes porque los mecanismos de control son m√°s simples.  En particular, la mayor√≠a de los procesadores de prop√≥sito general de gama alta son excesivamente multiplexados, lo que requiere una l√≥gica de control compleja para iniciar y completar las instrucciones.  En contraste, VLIW realiza el an√°lisis y la planificaci√≥n necesarios en tiempo de compilaci√≥n, lo que puede funcionar bien para un programa claramente paralelo. <br><br>  Segundo, los servicios DSA hacen un mejor uso de la jerarqu√≠a de memoria.  El acceso a la memoria se ha vuelto mucho m√°s costoso que los c√°lculos aritm√©ticos, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">como se√±al√≥ Horowitz</a> .  Por ejemplo, acceder a un bloque en un cach√© de 32 KB requiere aproximadamente 200 veces m√°s energ√≠a que agregar enteros de 32 bits.  Tal gran diferencia hace que la optimizaci√≥n del acceso a la memoria sea cr√≠tica para lograr una alta eficiencia energ√©tica.  Los procesadores de prop√≥sito general ejecutan c√≥digo en el que los accesos a la memoria exhiben t√≠picamente una localidad espacial y temporal, pero por lo dem√°s no son muy predecibles en el momento de la compilaci√≥n.  Por lo tanto, para aumentar el rendimiento, las CPU usan cach√©s de varios niveles y ocultan el retraso en DRAM relativamente lentas fuera del chip.  Estos cach√©s de varios niveles a menudo consumen aproximadamente la mitad de la energ√≠a del procesador, pero evitan casi todas las llamadas a DRAM, lo que requiere aproximadamente 10 veces m√°s energ√≠a que acceder al cach√© de √∫ltimo nivel. <br><br>  Los cach√©s tienen dos defectos notables. <br><br>  <i>Cuando los conjuntos de datos son muy grandes</i> .  Las memorias cach√© simplemente no funcionan bien cuando los conjuntos de datos son muy grandes, tienen poca localidad temporal o espacial. <br><br>  <i>Cuando los cach√©s funcionan bien</i> .  Cuando los cach√©s funcionan bien, la localidad es muy alta, es decir, por definici√≥n, la mayor parte del cach√© est√° inactiva la mayor parte del tiempo. <br><br>  En las aplicaciones donde los patrones de acceso a la memoria est√°n bien definidos y son comprensibles en el momento de la compilaci√≥n, lo cual es cierto para los lenguajes espec√≠ficos de dominio (DSL) t√≠picos, los programadores y compiladores pueden optimizar el uso de la memoria mejor que los cach√©s asignados din√°micamente.  Por lo tanto, los DSA generalmente usan una jerarqu√≠a de memoria en movimiento que es controlada expl√≠citamente por el software, similar a c√≥mo funcionan los procesadores de vectores.  En las aplicaciones correspondientes, el control de memoria de usuario "manual" le permite gastar mucha menos energ√≠a que el cach√© est√°ndar. <br><br>  En tercer lugar, DSA puede reducir la precisi√≥n de los c√°lculos si no se necesita una alta precisi√≥n.  Las CPU de uso general generalmente admiten c√°lculos de enteros de 32 y 64 bits, as√≠ como datos de punto flotante (FP).  Para muchas aplicaciones de aprendizaje autom√°tico y gr√°ficos, esta es una precisi√≥n redundante.  Por ejemplo, en redes neuronales profundas, el c√°lculo a menudo usa n√∫meros de 4, 8 o 16 bits, mejorando tanto el rendimiento de datos como la potencia de procesamiento.  Del mismo modo, los c√°lculos de punto flotante son √∫tiles para entrenar redes neuronales, pero 32 bits, y a menudo 16 bits, son suficientes. <br><br>  Finalmente, los DSA se benefician de los programas escritos en lenguajes espec√≠ficos de dominio que permiten una mayor concurrencia, mejoran la estructura, la presentaci√≥n del acceso a la memoria y simplifican la superposici√≥n eficiente de aplicaciones en un procesador dedicado. <br><br><h1>  Lenguas Orientadas a la Materia </h1><br>  Los DSA requieren que las operaciones de nivel superior se adapten a la arquitectura del procesador, pero es muy dif√≠cil hacerlo en un lenguaje de prop√≥sito general como Python, Java, C o Fortran.  Los lenguajes espec√≠ficos de dominio (DSL) ayudan con esto y le permiten programar de manera efectiva los DSA.  Por ejemplo, los DSL pueden hacer expl√≠citas las operaciones expl√≠citas de vectores, matrices densas y matrices dispersas, lo que permite que el compilador DSL asigne eficientemente las operaciones al procesador.  Entre los lenguajes espec√≠ficos de dominio se encuentran Matlab, un lenguaje para trabajar con matrices, TensorFlow para programar redes neuronales, P4 para programar redes definidas por software y Halide para procesar im√°genes con transformaciones de alto nivel. <br><br>  El problema de DSL es c√≥mo mantener suficiente independencia arquitect√≥nica para que el software en √©l pueda ser portado a varias arquitecturas, mientras se logra una alta eficiencia al comparar el software con un DSA b√°sico.  Por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un sistema XLA traduce el</a> c√≥digo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tensorflow</a> a sistemas heterog√©neos con GPU Nvidia o procesadores de tensor (TPU).  Equilibrar la portabilidad entre DSA mientras se mantiene la eficiencia es una tarea de investigaci√≥n interesante para los desarrolladores de lenguaje, compiladores y DSA. <br><br><h3>  Ejemplo de DSA: TPU v1 </h3><br>  Como ejemplo de DSA, considere Google TPU v1, que est√° dise√±ado para acelerar el funcionamiento de una red neuronal ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> ).  Este TPU se ha producido desde 2015, y muchas aplicaciones se han estado ejecutando en √©l: desde consultas de b√∫squeda hasta traducci√≥n de texto y reconocimiento de im√°genes en AlphaGo y AlphaZero, programas DeepMind para jugar go y ajedrez.  El objetivo era aumentar la productividad y la eficiencia energ√©tica de las redes neuronales profundas en 10 veces. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/057/3d6/a1a/0573d6a1a8ed756450ae9088f8606897.jpg"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">8. Organizaci√≥n funcional Unidad de procesamiento de tensor de Google (TPU v1)</font></i> <br><br>  Como se muestra en la Figura 8, la organizaci√≥n de una TPU es radicalmente diferente de la de un procesador de prop√≥sito general.  La unidad de computaci√≥n principal es la unidad de matriz, la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">estructura de las matrices sist√≥licas</a> , que cada ciclo produce 256 √ó 256 de acumulaci√≥n m√∫ltiple.  La combinaci√≥n de precisi√≥n de 8 bits, una estructura sist√≥lica altamente eficiente, control SIMD y la asignaci√≥n de una parte significativa del chip para esta funci√≥n ayudan a realizar aproximadamente 100 veces m√°s operaciones de multiplicaci√≥n de acumulaci√≥n por ciclo que un n√∫cleo de CPU de uso general.  En lugar de cach√©s, TPU usa 24 MB de memoria local, que es aproximadamente el doble que los cach√©s de CPU de uso general de 2015 con el mismo TDP.  Finalmente, tanto la memoria de activaci√≥n neuronal como la memoria de equilibrio de la red neuronal (incluida la estructura FIFO que almacena los pesos) est√°n conectadas a trav√©s de canales de alta velocidad controlados por el usuario.  El rendimiento promedio ponderado de TPU para seis problemas t√≠picos de salida l√≥gica de redes neuronales en los centros de datos de Google es 29 veces mayor que el de los procesadores de prop√≥sito general.  Dado que los TPU requieren menos de la mitad de la potencia, su eficiencia energ√©tica para esta carga de trabajo es m√°s de 80 veces mayor que la de los procesadores de uso general. <br><br><h1>  Resumen </h1><br>  Examinamos dos enfoques diferentes para mejorar el rendimiento del programa al aumentar la eficiencia del uso de tecnolog√≠as de hardware.  En primer lugar, al aumentar la productividad de los lenguajes modernos de alto nivel que generalmente se interpretan.  En segundo lugar, mediante la creaci√≥n de arquitecturas para √°reas tem√°ticas espec√≠ficas, que mejoran significativamente el rendimiento y la eficiencia en comparaci√≥n con los procesadores de uso general.  Los lenguajes espec√≠ficos de dominio son otro ejemplo de c√≥mo mejorar la interfaz hardware-software que permite innovaciones arquitect√≥nicas como DSA.  Para lograr un √©xito significativo utilizando tales enfoques, se requerir√° un equipo de proyecto integrado verticalmente que est√© versado en aplicaciones, lenguajes orientados a temas y tecnolog√≠as de compilaci√≥n relacionadas, arquitectura de computadora, as√≠ como tecnolog√≠a de implementaci√≥n b√°sica.  La necesidad de integraci√≥n vertical y la toma de decisiones de dise√±o en diferentes niveles de abstracci√≥n era t√≠pica de la mayor√≠a de los primeros trabajos en el campo de la tecnolog√≠a inform√°tica antes de que la industria se estructurara horizontalmente.  En esta nueva era, la integraci√≥n vertical se ha vuelto m√°s importante.  Se dar√°n ventajas a los equipos que pueden encontrar y aceptar compromisos complejos y optimizaciones. <br><br>  Esta oportunidad ya ha llevado a un aumento en la innovaci√≥n arquitect√≥nica, atrayendo muchas filosof√≠as arquitect√≥nicas competidoras: <br><br>  <i>GPU</i>  Las GPU Nvidia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">usan</a> m√∫ltiples n√∫cleos, cada uno con grandes archivos de registro, m√∫ltiples flujos de hardware y cach√©s. <br><br>  <i>TPU</i>  Las <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TPU de</a> Google se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">basan</a> en grandes conjuntos sist√≥licos bidimensionales y memoria programable en chip. <br><br>  <i>FPGA</i>  Microsoft Corporation en sus centros de datos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">implementa</a> arreglos de puertas programables por el usuario (FPGA), que se utilizan en aplicaciones de redes neuronales. <br><br>  <i>CPU</i>  Intel ofrece procesadores con muchos n√∫cleos, una gran memoria cach√© multinivel e instrucciones SIMD unidimensionales, de forma similar al FPGA de Microsoft, y el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">nuevo neuroprocesador est√° m√°s cerca de TPU que de CPU</a> . <br><br>  Adem√°s de estos actores principales, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">docenas de nuevas empresas implementan sus propias ideas</a> .  Para satisfacer la creciente demanda, los dise√±adores est√°n combinando cientos y miles de chips para crear supercomputadoras de redes neuronales. <br><br>  Esta avalancha de arquitecturas de redes neuronales indica que ha llegado un momento interesante en la historia de la arquitectura de computadoras.  En 2019, es dif√≠cil predecir cu√°l de estas √°reas ganar√° (si es que alguien gana), pero el mercado definitivamente determinar√° el resultado, tal como ha establecido el debate arquitect√≥nico del pasado. <br><br><h1>  Arquitectura abierta </h1><br>  Siguiendo el ejemplo del software exitoso de c√≥digo abierto, ISA abierto representa una oportunidad alternativa en la arquitectura de computadoras.  Son necesarios para crear una especie de "Linux para procesadores", de modo que la comunidad pueda crear n√∫cleos de c√≥digo abierto adem√°s de compa√±√≠as individuales que posean n√∫cleos propietarios.  Si muchas organizaciones dise√±an procesadores utilizando el mismo ISA, m√°s competencia puede conducir a una innovaci√≥n a√∫n m√°s r√°pida.  El objetivo es proporcionar arquitectura para procesadores que cuestan desde unos pocos centavos hasta $ 100. <br><br>  El primer ejemplo es RISC-V (RISC Five), la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">quinta arquitectura RISC desarrollada en la Universidad de California en Berkeley</a> .  Ella es apoyada por una comunidad dirigida por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la Fundaci√≥n RISC-V</a> .<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La arquitectura abierta permite que la evoluci√≥n de la ISA tenga lugar en el ojo p√∫blico, con la participaci√≥n de expertos hasta que se tome una decisi√≥n final. Una ventaja adicional de un fondo abierto es que es poco probable que ISA se expanda principalmente por razones de marketing, porque a veces esta es la √∫nica explicaci√≥n para la expansi√≥n de sus propios conjuntos de instrucciones.</font></font><br><br> RISC-V ‚Äî    .            ,      ,          .    32-  64-  . RISC-V      ;       ,       .     ¬´¬ª     :  ,       ,       .  RISC-V  ,         ,     .      ,      :: <br><br><ul><li> M. /  . <br></li><li> A.    . <br></li><li> F/D.       / . <br></li><li> .  . </li></ul><br>    RISC-V   ISA.       ,      ARMv8,     ARM: <br><br><ul><li> <b> </b> .  RISC-V   .   50 ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">        RISC-I</a> .    (M, A, F  D)  53 ,  C   34,      137.  ,  ARMv8  500 . <br></li><li> <b>  </b> .  RISC-V    : ,    ARMv8    14. </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La simplicidad simplifica tanto el dise√±o del dise√±o de los procesadores como la verificaci√≥n de su correcci√≥n. Debido a que RISC-V se enfoca en todo, desde centros de datos hasta dispositivos IoT, la validaci√≥n del dise√±o puede ser una parte importante de los costos de desarrollo. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cuarto, RISC-V es un dise√±o de hoja limpia despu√©s de 25 a√±os, donde los arquitectos aprenden de los errores de sus predecesores. A diferencia de la arquitectura RISC de primera generaci√≥n, evita la microarquitectura o las funciones que dependen de la tecnolog√≠a (como ramas diferidas y descargas diferidas) o innovaciones (como ventanas de registro), que fueron suplantadas por los avances del compilador. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Finalmente, RISC-V admite DSA, reservando un amplio espacio de c√≥digo de operaci√≥n para aceleradores personalizados. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Adem√°s de RISC-V, Nvidia tambi√©n anunci√≥ (en 2017)</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Una arquitectura libre y abierta</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , lo llama Nvidia Deep Learning Accelerator (NVDLA). Es un DSA escalable y personalizable para inferencia en el aprendizaje autom√°tico. Los par√°metros de configuraci√≥n incluyen el tipo de datos (int8, int16 o fp16) y el tama√±o de la matriz de multiplicaci√≥n bidimensional. La escala del sustrato de silicio var√≠a de 0,5 mm¬≤ a 3 mm¬≤, y el consumo de energ√≠a es de 20 mW a 300 mW. ISA, la pila de software y la implementaci√≥n est√°n abiertos.</font></font><br><br>       . -,         ,    ,      .        ,        .     ,               . ,  RISC-V    .  ,  ,    ,    FPGA ,           ,     .  FPGA  10  ,   ,                 .  ,                . <br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Desarrollo de hardware flexible. </font></font></h1><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El Manifiesto de Desarrollo de Software Flexible (2001)</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Beck et al. Revolucionaron el desarrollo de software al eliminar los problemas de un sistema de cascada tradicional basado en la planificaci√≥n y la documentaci√≥n. </font><font style="vertical-align: inherit;">Peque√±os equipos de programadores crean r√°pidamente prototipos funcionales pero incompletos, y reciben comentarios de los clientes antes de comenzar la siguiente iteraci√≥n. </font><font style="vertical-align: inherit;">La versi√≥n Scrum de Agile re√∫ne equipos de cinco a diez programadores que corren de dos a cuatro semanas por iteraci√≥n.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Habiendo tomado nuevamente la idea del desarrollo de software, es posible organizar un desarrollo de hardware flexible. La buena noticia es que las herramientas modernas de dise√±o electr√≥nico asistido por computadora (ECAD) han aumentado el nivel de abstracci√≥n, permitiendo un desarrollo flexible. Este mayor nivel de abstracci√≥n tambi√©n aumenta el nivel de reutilizaci√≥n del trabajo entre diferentes dise√±os. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Los sprints de cuatro semanas parecen inveros√≠miles para los procesadores, dados los meses entre la creaci√≥n del dise√±o y la producci√≥n del chip. En la fig. La Figura 9 muestra c√≥mo puede funcionar un m√©todo flexible </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">modificando un prototipo a un nivel apropiado</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/278/4ae/e4c/2784aee4c39cbdfaeab3bbbfd500a056.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. 9. Metodolog√≠a de desarrollo de equipos flexibles.</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El nivel m√°s interno es un simulador de software, el lugar m√°s f√°cil y r√°pido para realizar cambios. El siguiente nivel son los chips FPGA, que pueden funcionar cientos de veces m√°s r√°pido que un simulador de software detallado. Los FPGA pueden trabajar con sistemas operativos y puntos de referencia completos, como la Standard Performance Evaluation Corporation (SPEC), que permite una evaluaci√≥n mucho m√°s precisa de los prototipos. Amazon Web Services ofrece FPGA en la nube, por lo que los arquitectos pueden usar FPGA sin tener que comprar primero equipo y configurar un laboratorio. El siguiente nivel utiliza herramientas ECAD para generar un circuito de chip, para documentar el tama√±o y el consumo de energ√≠a. Incluso despu√©s de que las herramientas funcionen, es necesario seguir algunos pasos manuales para refinar los resultados antes de enviar el nuevo procesador a producci√≥n.Los desarrolladores de procesadores llaman a esto el siguiente nivel.</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en la cinta</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Estos primeros cuatro niveles admiten sprints de cuatro semanas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para fines de investigaci√≥n, podr√≠amos detenernos en el nivel cuatro, ya que las estimaciones de √°rea, energ√≠a y rendimiento son muy precisas. Pero es como si un corredor corriera una marat√≥n y se detuviera 5 metros antes del final, porque su tiempo de finalizaci√≥n ya est√° despejado. A pesar de la dif√≠cil preparaci√≥n para la marat√≥n, extra√±ar√° la emoci√≥n y el placer de cruzar la l√≠nea de meta. Una de las ventajas de los ingenieros de hardware sobre los ingenieros de software es que crean cosas f√≠sicas. Obtener chips de la f√°brica: medir, ejecutar programas reales, mostrarlos a amigos y familiares es una gran alegr√≠a para el dise√±ador.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Muchos investigadores creen que deber√≠an detenerse porque la fabricaci√≥n de chips es demasiado asequible. </font><font style="vertical-align: inherit;">Pero si el dise√±o es peque√±o, es sorprendentemente econ√≥mico. </font><font style="vertical-align: inherit;">Los ingenieros pueden ordenar 100 microchips de 1 mm¬≤ por solo $ 14,000. A 28 nm, un chip de 1 mm¬≤ contiene millones de transistores: esto es suficiente para el procesador RISC-V y el acelerador NVLDA. </font><font style="vertical-align: inherit;">El nivel m√°s externo es costoso si el dise√±ador pretende crear un chip grande, pero se pueden demostrar muchas ideas nuevas en chips peque√±os.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclusi√≥n </font></font></h1><br> <i>¬´   ‚Äî   ¬ª</i> ‚Äî  , 1650 <br><br>      ,    ,       ,     /             . iAPX-432  Itanium ,        ,     S/360, 8086  ARM    ,    . <br><br>      ,        ‚Äî   ,   ,  , ,  ,   .  -   ,      ,       ,       .                  .       ,  ,  RISC,    .     ,       ,        ,   ,    . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> En la pr√≥xima d√©cada, se producir√° una explosi√≥n c√°mbrica de nuevas arquitecturas inform√°ticas, lo que significa tiempos emocionantes para los arquitectos inform√°ticos en la academia y la industria. </font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/440760/">https://habr.com/ru/post/440760/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../440748/index.html">La supercomputadora m√°s r√°pida del mundo rompe el r√©cord de IA</a></li>
<li><a href="../440752/index.html">Selecci√≥n de prioridad de solicitud de usuario</a></li>
<li><a href="../440754/index.html">Utilidad multiplataforma en ingl√©s para ver certificados rusos calificados x509</a></li>
<li><a href="../440756/index.html">CI / CD sin servidor en AWS</a></li>
<li><a href="../440758/index.html">¬°Ve a Meetup en Acronis! (Mosc√∫, Fiztehpark)</a></li>
<li><a href="../440762/index.html">Revisiones de los empleadores: la naturaleza y la falta de sentido de las revisiones an√≥nimas</a></li>
<li><a href="../440766/index.html">De geeks a geeks: regalos para el 23 de febrero</a></li>
<li><a href="../440772/index.html">Dise√±o impulsado por dominios: una receta para un pragm√°tico</a></li>
<li><a href="../440774/index.html">Los graves errores matem√°ticos de la NHTSA permiten a Tesla reclamar la seguridad del piloto autom√°tico</a></li>
<li><a href="../440776/index.html">Correo electr√≥nico, vista interior</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
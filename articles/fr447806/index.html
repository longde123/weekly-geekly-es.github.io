<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéØ ü§æüèº ‚òïÔ∏è Acc√©l√©rer les performances des r√©seaux de neurones √† l'aide du hachage üêæ ‚è∏Ô∏è üë®‚Äçüë©‚Äçüë¶‚Äçüë¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'industrie s'est concentr√©e sur l'acc√©l√©ration de la multiplication matricielle, mais l'am√©lioration de l'algorithme de recherche peut conduire √† une...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Acc√©l√©rer les performances des r√©seaux de neurones √† l'aide du hachage</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/447806/"><h3>  L'industrie s'est concentr√©e sur l'acc√©l√©ration de la multiplication matricielle, mais l'am√©lioration de l'algorithme de recherche peut conduire √† une augmentation plus s√©rieuse des performances </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/8e7/9a0/8e3/8e79a08e31fdeadd8258ab001cc23ec5.jpg"><br><br>  Ces derni√®res ann√©es, l'industrie informatique s'est efforc√©e d'acc√©l√©rer les calculs requis pour les r√©seaux de neurones artificiels - √† la fois pour la formation et pour tirer des conclusions de son travail.  En particulier, beaucoup d'efforts ont √©t√© consacr√©s au d√©veloppement de fer sp√©cial sur lequel ces calculs peuvent √™tre effectu√©s.  Google a d√©velopp√© la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tensor Processing Unit</a> , ou TPU, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pr√©sent√©e</a> pour la premi√®re <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">fois</a> au public en 2016.  Nvidia a ensuite pr√©sent√© l'unit√© de traitement graphique <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">V100</a> , la d√©crivant comme une puce sp√©cialement con√ßue pour la formation et l'utilisation de l'IA, ainsi que pour d'autres besoins informatiques √† hautes performances.  Plein d'autres startups, se concentrant sur d'autres types d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">acc√©l√©rateurs mat√©riels</a> . <br><a name="habracut"></a><br>  Peut-√™tre qu'ils font tous une grande erreur. <br><br>  Cette id√©e a √©t√© exprim√©e dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ouvrage</a> paru mi-mars sur le site arXiv.  Ses auteurs, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Beidi Chen</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tarun Medini</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Anshumali Srivastava</a> de l'Universit√© Rice, soutiennent que l'√©quipement sp√©cial d√©velopp√© pour le fonctionnement des r√©seaux de neurones est peut-√™tre optimis√© pour le mauvais algorithme. <br><br>  Le fait est que le travail des r√©seaux de neurones d√©pend g√©n√©ralement de la rapidit√© avec laquelle l'√©quipement peut effectuer la multiplication des matrices utilis√©es pour d√©terminer les param√®tres de sortie de chaque neutron artificiel - son ¬´activation¬ª - pour un ensemble donn√© de valeurs d'entr√©e.  Les matrices sont utilis√©es parce que chaque valeur d'entr√©e pour un neurone est multipli√©e par le param√®tre de poids correspondant, puis elles sont toutes additionn√©es - et cette multiplication avec addition est l'op√©ration de base de la multiplication matricielle. <br><br>  Les chercheurs de l'Universit√© Rice, comme certains autres scientifiques, ont r√©alis√© que l'activation de nombreux neurones dans une couche particuli√®re du r√©seau neuronal est trop petite et n'affecte pas la valeur de sortie calcul√©e par les couches suivantes.  Par cons√©quent, si vous savez ce que sont ces neurones, vous pouvez simplement les ignorer. <br><br>  Il peut sembler que la seule fa√ßon de savoir quels neurones d'une couche ne sont pas activ√©s est d'effectuer d'abord toutes les op√©rations de multiplication matricielle pour cette couche.  Mais les chercheurs ont r√©alis√© que vous pouvez r√©ellement d√©cider de cette mani√®re plus efficace si vous regardez le probl√®me sous un angle diff√©rent.  ¬´Nous abordons ce probl√®me comme une solution au probl√®me de recherche¬ª, explique Srivastava. <br><br>  Autrement dit, au lieu de calculer les multiplications matricielles et de voir quels neurones ont √©t√© activ√©s pour une entr√©e donn√©e, vous pouvez simplement voir quels types de neurones se trouvent dans la base de donn√©es.  L'avantage de cette approche dans le probl√®me est que vous pouvez utiliser une strat√©gie g√©n√©ralis√©e qui a longtemps √©t√© am√©lior√©e par les informaticiens pour acc√©l√©rer la recherche de donn√©es dans la base de donn√©es: le hachage. <br><br>  Le hachage vous permet de v√©rifier rapidement s'il existe une valeur dans la table de base de donn√©es, sans avoir √† parcourir chaque ligne d'une ligne.  Vous utilisez un hachage, facilement calcul√© en appliquant une fonction de hachage √† la valeur souhait√©e, indiquant o√π cette valeur doit √™tre stock√©e dans la base de donn√©es.  Ensuite, vous ne pouvez v√©rifier qu'un seul endroit pour savoir si cette valeur y est stock√©e. <br><br>  Les chercheurs ont fait quelque chose de similaire pour les calculs li√©s aux r√©seaux de neurones.  L'exemple suivant aidera √† illustrer leur approche: <br><br>  Supposons que nous avons cr√©√© un r√©seau de neurones qui reconna√Æt la saisie manuscrite de nombres.  Supposons que l'entr√©e soit des pixels gris dans un tableau 16x16, c'est-√†-dire un total de 256 nombres.  Nous alimentons ces donn√©es √† une couche cach√©e de 512 neurones, dont les r√©sultats d'activation sont aliment√©s par la couche de sortie de 10 neurones, un pour chacun des nombres possibles. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e73/dec/941/e73dec9413ed37b2235bbd1ee8369ca6.jpg"><br><br>  <i>Tableaux de r√©seaux: avant de calculer l'activation des neurones dans les couches cach√©es, nous utilisons des hachages pour nous aider √† d√©terminer quels neurones seront activ√©s.</i>  <i>Ici, le hachage des valeurs d'entr√©e H1 est utilis√© pour rechercher les neurones correspondants dans la premi√®re couche cach√©e - dans ce cas, ce seront les neurones 2 et 4. Le deuxi√®me hachage H2 montre quels neurones de la deuxi√®me couche cach√©e contribueront.</i>  <i>Une telle strat√©gie r√©duit le nombre d'activations √† calculer.</i> <br><br>  Il est assez difficile de former un tel r√©seau, mais pour l'instant, diminuons ce moment et imaginons que nous avons d√©j√† ajust√© tous les poids de chaque neurone afin que le r√©seau de neurones reconnaisse parfaitement les nombres manuscrits.  Lorsqu'un nombre √©crit lisiblement arrive √† son entr√©e, l'activation d'un des neurones de sortie (correspondant √† ce nombre) sera proche de 1. L'activation des neuf autres sera proche de 0. Classiquement, le fonctionnement d'un tel r√©seau n√©cessite une multiplication matricielle pour chacun des 512 neurones cach√©s, et un de plus pour chaque week-end - ce qui nous donne beaucoup de multiplications. <br><br>  Les chercheurs adoptent une approche diff√©rente.  La premi√®re √©tape consiste √† hacher les poids de chacun des 512 neurones de la couche cach√©e en utilisant un "hachage sensible √† la localit√©", dont l'une des propri√©t√©s est que des donn√©es d'entr√©e similaires donnent des valeurs de hachage similaires.  Vous pouvez ensuite regrouper des neurones avec des hachages similaires, ce qui signifierait que ces neurones ont des ensembles de poids similaires.  Chaque groupe peut √™tre stock√© dans une base de donn√©es et d√©termin√© par le hachage des valeurs d'entr√©e qui conduira √† l'activation de ce groupe de neurones. <br><br>  Apr√®s tout ce hachage, il s'av√®re facile de d√©terminer lequel des neurones cach√©s sera activ√© par une nouvelle entr√©e.  Vous devez ex√©cuter 256 valeurs d'entr√©e via des fonctions de hachage faciles √† calculer et utiliser le r√©sultat pour rechercher dans la base de donn√©es les neurones qui seront activ√©s.  De cette fa√ßon, vous devrez calculer les valeurs d'activation pour seulement quelques neurones importants.  Il n'est pas n√©cessaire de calculer l'activation de tous les autres neurones de la couche juste pour d√©couvrir qu'ils ne contribuent pas au r√©sultat. <br><br>  L'entr√©e d'un tel r√©seau neuronal de donn√©es peut √™tre repr√©sent√©e comme l'ex√©cution d'une requ√™te de recherche dans une base de donn√©es qui demande de trouver tous les neurones qui seraient activ√©s par comptage direct.  Vous obtenez la r√©ponse rapidement car vous utilisez des hachages pour rechercher.  Et puis, vous pouvez simplement calculer l'activation d'un petit nombre de neurones qui comptent vraiment. <br><br>  Les chercheurs ont utilis√© cette technique, qu'ils ont appel√©e SLIDE (Sub-LInear Deep learning Engine), pour former un r√©seau de neurones - pour un processus qui a plus de demandes de calcul qu'il ne le fait pour son objectif.  Ils ont ensuite compar√© les performances de l'algorithme d'apprentissage avec une approche plus traditionnelle utilisant un puissant GPU - en particulier, le GPU Nvidia V100.  En cons√©quence, ils ont obtenu quelque chose d'incroyable: "Nos r√©sultats montrent qu'en moyenne, la technologie CPU SLIDE peut fonctionner des ordres de grandeur plus rapidement que la meilleure alternative possible, impl√©ment√©e sur le meilleur √©quipement et avec n'importe quelle pr√©cision." <br><br>  Il est trop t√¥t pour tirer des conclusions quant √† la r√©sistance de ces r√©sultats (que les experts n'ont pas encore √©valu√©s) aux tests et s'ils vont obliger les fabricants de puces √† porter un regard diff√©rent sur le d√©veloppement d'√©quipements sp√©ciaux pour le deep learning.  Mais le travail souligne d√©finitivement le danger de l'entra√Ænement d'un certain type de fer dans les cas o√π il existe la possibilit√© d'un nouvel et meilleur algorithme pour le fonctionnement des r√©seaux de neurones. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr447806/">https://habr.com/ru/post/fr447806/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr447792/index.html">Les sch√©mas sombres et la loi: comment les r√©gulateurs am√©ricains essaient de contr√¥ler la m√©canique des produits et de r√©duire l'influence des entreprises technologiques</a></li>
<li><a href="../fr447794/index.html">√Ä propos de choses simples, compliqu√©es. Une lettre d'un chimiste √† une imprimante 3D. Solvants pour plastiques et protection contre eux</a></li>
<li><a href="../fr447798/index.html">Comment g√©n√©rer un √©norme graphique financier avec des sch√©mas de blanchiment d'argent?</a></li>
<li><a href="../fr447802/index.html">Isabella 2</a></li>
<li><a href="../fr447804/index.html">Dwarf Fortress abandonne les graphiques de texte, mais pas son essence</a></li>
<li><a href="../fr447808/index.html">Apprendre √† √©crire des contrats intelligents Waves sur RIDE et RIDE4DAPPS. Partie 2 (DAO - Organisme autonome d√©centralis√©)</a></li>
<li><a href="../fr447810/index.html">Analytics pour Azure DevOps Services est d√©sormais accessible au public</a></li>
<li><a href="../fr447812/index.html">Comment nous avons mis en ≈ìuvre la livraison de mise √† jour continue sur la plate-forme du client</a></li>
<li><a href="../fr447814/index.html">O√π et comment ouvrir un centre de d√©veloppement?</a></li>
<li><a href="../fr447816/index.html">Un peu de magie de mod√®le C ++ et CRTP pour contr√¥ler l'exactitude des actions du programmeur lors de la compilation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
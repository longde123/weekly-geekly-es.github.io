<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚵🏾 🕞 ⚪️ Experimente mit neuronalen JavaScript-Schnittstellen 🕴🏻 🏞️ 👆🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Der Autor des Materials, dessen Übersetzung wir heute veröffentlichen, sagt, dass er in den letzten Jahren ein stetiges Interesse an Neurotechnologien...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Experimente mit neuronalen JavaScript-Schnittstellen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/433874/">  Der Autor des Materials, dessen Übersetzung wir heute veröffentlichen, sagt, dass er in den letzten Jahren ein stetiges Interesse an Neurotechnologien festgestellt hat.  In diesem Artikel möchte sie über ihre Experimente mit verschiedenen Hardware- und Softwaresystemen sprechen, mit denen Sie die Kommunikation zwischen Gehirn und Computer herstellen können. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/gw/xa/hl/gwxahlizikvt65xbfo0wr-3vrts.jpeg"></a> <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Hintergrund</font> </h2><br>  Ich habe keine Computergrundausbildung (ich habe Werbung und Marketing studiert).  Ich beherrschte das Programmieren in Kursen in der Generalversammlung. <br><br>  Als ich nach dem ersten Job suchte, begann ich mit JavaScript und mit verschiedenen Geräten zu experimentieren.  Mein erstes Projekt war insbesondere die Organisation der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sphero-</a> Roboterballsteuerung mittels Armbewegung mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Leap Motion</a> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/032/a1b/9e4/032a1b9e490fa0c6a9c1875450e03f4e.gif"></div><br>  <i><font color="#999999">Sphero Ball angetrieben von Leap Motion</font></i> <br><br>  Dies war meine erste Erfahrung mit JavaScript, um etwas außerhalb des Browsers zu verwalten.  Es rief sofort an, was mich "süchtig" machte. <br><br>  Seitdem habe ich viel Zeit mit interaktiven Projekten verbracht.  Jedes Mal, wenn ich ein neues Projekt übernahm, versuchte ich, immer komplexere Aufgaben für mich zu finden.  Also habe ich mich ständig weiterentwickelt und etwas Neues gelernt. <br><br>  Nachdem ich mit verschiedenen Geräten experimentiert hatte, stieß ich auf der Suche nach einer weiteren interessanten Aufgabe auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NeuroSky-</a> Gehirnaktivitätssensoren. <br><br><h2>  <font color="#3AC1EF">Die ersten Experimente mit einem Neuro-Headset</font> </h2><br>  Als ich an Experimenten mit Gehirnaktivitätssensoren interessiert war, entschied ich mich für ein NeuroSky-Neuro-Headset.  Sie war viel billiger als andere ähnliche Angebote. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4bf/3a6/f45/4bf3a6f459737bb3ef29bc51ee256f71.png"></div><br>  <i><font color="#999999">NeuroSky Neuro Headset</font></i> <br><br>  Ich wusste nicht, ob meine Qualifikationen ausreichen würden, um zumindest etwas für ein solches Gerät zu schreiben (ich habe gerade die Programmierkurse abgeschlossen), also habe ich mich für etwas Billigeres entschieden, falls sich die Aufgabe herausstellen sollte Für mich ist es unerschwinglich schwierig, nicht zu viel Geld zu verschwenden.  Glücklicherweise wurde bereits ein JavaScript-Framework für die Verwendung mit dem Headset erstellt, sodass das Experimentieren recht einfach war.  Insbesondere habe ich meine Aufmerksamkeitsbewertung verwendet, um den Sphero-Ball und den Parrot AR.Drone-Quadrocopter zu steuern. <br><br>  Während der Experimente wurde mir schnell klar, dass dieses Neuro-Headset nicht besonders genau ist.  Sie hat nur drei Sensoren, so dass sie ziemlich grobe Daten über die Gehirnaktivität erhalten kann.  Das Gerät bietet Zugriff auf Rohdaten von jedem Sensor, wodurch beispielsweise diese Daten visualisiert werden können.  Die Tatsache, dass das Headset nur drei Elektroden hat, erlaubt es uns jedoch nicht, ernsthafte Schlussfolgerungen auf der Grundlage der von ihm erhaltenen Daten darüber zu ziehen, was im menschlichen Gehirn geschieht. <br><br>  Als ich mich entschied, nach anderen Geräten zum Lesen von Indikatoren für die Gehirnaktivität zu suchen, fand ich das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Emotiv Epoc Neuro-Headset</a> .  Ich hatte das Gefühl, dass dieses Ding im Vergleich zum NeuroSky-Headset ernstere Fähigkeiten hat, deshalb habe ich beschlossen, es zu kaufen, um meine Experimente fortzusetzen. <br><br>  Bevor ich über die Funktionsweise von Emotiv Epoc spreche, schlage ich kurz vor, über die Funktionsweise des menschlichen Gehirns zu sprechen. <br><br><h2>  <font color="#3AC1EF">Wie das Gehirn funktioniert</font> </h2><br>  Ich kann mich nicht als großen Kenner der Neurowissenschaften bezeichnen, daher wird meine Geschichte über das Gehirn ziemlich oberflächlich sein.  Ich möchte nämlich über einige grundlegende Dinge sprechen, die Sie für diejenigen wissen müssen, die besser verstehen möchten, wie Neuro-Headsets funktionieren. <br>  Das Gehirn besteht aus vielen Milliarden Neuronen - spezialisierten Zellen, die Informationen verarbeiten, speichern und übertragen.  Verschiedene Teile des Gehirns, bestehend aus Neuronen, sind für verschiedene physiologische Funktionen verantwortlich. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ddb/e6d/880/ddbe6d8800bda77bd95562ab92692f32.jpg"></div><br>  <i><font color="#999999">Verschiedene Teile des Gehirns (Quelle - macmillan.org.uk)</font></i> <br><br>  Lassen Sie uns zum Beispiel darüber sprechen, wie das Gehirn Bewegungen steuert.  Teile des Gehirns wie der primäre motorische Kortex und das Kleinhirn sind für Bewegung und Koordination verantwortlich.  Die Signale der entsprechenden Neuronen beeinflussen die Muskeln, was zu Bewegungen führt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/604/43a/ef2/60443aef22e4bb9cd5bc50e3dc694677.jpg"></div><br>  <i><font color="#999999">Neuronenanatomie</font></i> <br><br>  Wie ich bereits sagte, ist hier eine äußerst einfache Beschreibung des Gehirns, aber für uns ist das Wichtigste, dass die Aktivität von Neuronen durch Elektroenzephalographie (EEG) verfolgt werden kann, indem die Indikatoren der elektrischen Aktivität des Gehirns von der Oberfläche der Kopfhaut abgelesen werden. <br><br>  Andere Technologien können verwendet werden, um die Gehirnaktivität zu überwachen, aber ihre Verwendung beinhaltet eine Operation.  Insbesondere handelt es sich um Elektrokortographie - bei diesem Ansatz werden Elektroden direkt auf die Großhirnrinde aufgebracht. <br><br>  Nachdem wir festgestellt haben, dass das Gehirn während der Arbeit elektrische Signale erzeugt, die gelesen werden können, sprechen wir über das Emotiv Epoc-Headset. <br><br><h2>  <font color="#3AC1EF">Wie funktioniert ein Neuro-Headset?</font> </h2><br>  Das Unternehmen Emotiv stellt verschiedene Arten von Neuro-Headsets her: <br><br><ul><li>  Emotionale Einsicht </li><li>  Emotiv Epoc Flex Kit </li><li>  Emotiv epoc </li></ul><br>  Das Epoc-Headset verfügt über 14 Sensoren (sie werden auch als „Kanäle“ bezeichnet), die sich an verschiedenen Stellen am Kopf befinden. <br><br>  Die folgende Abbildung links zeigt ein von der Internationalen Föderation für Elektroenzephalographie und klinische Neurophysiologie empfohlenes 10-20-Elektroden-Platzierungsmuster.  Jede Elektrode entspricht einem bestimmten Bereich des Gehirns.  Die Verwendung des 10-20-Systems ermöglicht es Ihnen, einen bestimmten Standard zu befolgen, wenn Sie verschiedene Geräte erstellen und wissenschaftliche Untersuchungen am Gehirn durchführen. <br>  Die Abbildung rechts zeigt die Anordnung der Elektroden des Emotiv Epoc-Headsets.  Um es mit dem 10-20-System zu vergleichen, ist das Highlight grün und orange. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8c5/fd0/907/8c5fd0907892ad6a6b829b2ed646312f.png"></div><br>  <i><font color="#999999">Vergleich des internationalen 10-20-Elektrodenplatzierungssystems und des Emotiv Epoc-Headsets</font></i> <br><br>  14 Epoc-Kanäle - das ist nicht so viel, aber die Elektroden werden ziemlich gleichmäßig auf der Kopfhaut platziert.  Dies lässt uns hoffen, dass Sie mit Hilfe von Epoc ziemlich genaue Informationen über die Gehirnaktivität erhalten können. <br><br>  Das Headset liest Sensoren mit 2048 Abtastungen pro Sekunde (SPS).  Gleichzeitig hat der Benutzer Zugriff auf eine Signalabtastfrequenz von 128 oder 256 SPS.  Das Gerät kann Gehirnwellen mit einer Frequenz von 0,16 bis 43 Hz erfassen.  Es gibt verschiedene Rhythmen des Gehirns, deren kurze Eigenschaften in der folgenden Abbildung dargestellt sind. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fb5/9f0/8d5/fb59f08d59ec0df374852e294c593499.jpg"></div><br>  <i><font color="#999999">Arten von Gehirnwellen</font></i> <br><br>  Warum ist das wichtig?  Tatsache ist, dass wir abhängig von der Anwendung, die auf der Basis eines Elektroenzephalographen erstellt werden muss, möglicherweise Gehirnwellen einer bestimmten Frequenz besondere Aufmerksamkeit schenken müssen.  Wenn wir zum Beispiel ein Programm erstellen müssen, um Meditierenden zu helfen, werden wir wahrscheinlich nur an Theta-Wellen interessiert sein, deren Frequenz 4-8 Hz beträgt. <br><br>  Nachdem Sie die Prinzipien der Elektroenzephalographie verstanden haben, sprechen wir über die Funktionen von Emotiv Epoc und verwandter Software. <br><br><h2>  <font color="#3AC1EF">Emotiv Epoc Features</font> </h2><br>  Emotiv-Software ist keine Open Source-Software. Für den Zugriff auf das Rohsensorsignal ist eine spezielle Lizenz erforderlich.  Unter normalen Bedingungen stehen bei der Arbeit mit Emotiv Epoc folgende Optionen zur Verfügung: <br><br><ul><li>  Messung von Indikatoren, die die Position des Kopfes des Benutzers im Raum charakterisieren, unter Verwendung eines Beschleunigungsmessers und eines Gyroskops. </li><li>  Messung des Erregungsgrades, der Beteiligung, der Entspannung, des Interesses, des Stresses und der Konzentration. </li><li>  Erkennen von Gesichtsmuskelbewegungen, um eine Vorstellung vom Gesichtsausdruck des Benutzers zu bekommen.  Zum Beispiel sprechen wir über Blinzeln und Lächeln. </li><li>  Erkennen von mentalen Befehlen (Bewegungen und Wendungen). </li></ul><br>  Um die Erkennung von mentalen Befehlen nutzen zu können, muss der Benutzer zuerst das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">System</a> trainieren.  Trainingsdaten werden als Datei gespeichert. <br><br>  Wenn Sie Ihre eigenen Programme für Emotiv Epoc entwickeln möchten, können Sie die Cortex-API und das entsprechende SDK verwenden (die Unterstützung wurde nach der Veröffentlichung von Version 3.5 eingestellt).  Wenn Sie JavaScript verwenden möchten, können Sie sich meine Entwicklung ansehen - die <a href="">Epoc.js-</a> Bibliothek. <br><br><h2>  <font color="#3AC1EF">Epoc.js Bibliothek</font> </h2><br>  Epoc.js ist ein Framework zum Organisieren der Interaktion mit Emotiv Epoc- und Insight-Geräten mithilfe von JavaScript.  Dieses Framework ermöglicht dem Entwickler den Zugriff auf die oben beschriebenen Funktionen von Emotiv-Systemen und ermöglicht die Interaktion mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Emulator</a> . <br>  Hier ist das einfachste Projekt, das auf Epoc.js basiert: <br><br><pre><code class="plaintext hljs">const epoc = require('epocjs')(); epoc.connectToLiveData('path/to/profile/file', function(event){  var action = event.blink === 1 ? 'blinking' : 'not blinking';  console.log(action); });</code> </pre> <br>  In diesem Codebeispiel schließen wir das <code>epocjs</code> Modul Node.js <code>epocjs</code> und instanziieren das entsprechende Objekt.  Anschließend rufen wir die <code>connectToLiveData</code> Methode dieses Objekts auf und übergeben ihm den Pfad zur Datei mit den nach dem Training des Systems erhaltenen Benutzerdaten und einer Rückruffunktion.  An diese Funktion wird ein Ereignisobjekt übergeben, das verschiedene Eigenschaften enthält, die verfolgt werden können.  Wenn das Programm beispielsweise auf das Blinken reagieren soll, wird die Eigenschaft <code>event.blink</code> . <br><br>  Jede ähnliche Eigenschaft kann entweder auf 0 oder 1 gesetzt werden. Eine Einheit im Wert der Eigenschaft bedeutet, dass das System das entsprechende Ereignis aufgezeichnet hat.  Eine vollständige Liste dieser Eigenschaften finden Sie <a href="">hier</a> . <br><br>  Die beschriebene Bibliothek wurde mit dem Emotiv C ++ SDK, Node.js und drei Modulen für Node.js erstellt: Node-gyp, Bindings und Nan.  Während seiner Entwicklung wurde ein Ansatz verwendet, der nun als veraltet angesehen werden kann.  Nun die eigentliche Nutzung der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">N-API</a> . <br><br>  Nachdem ich die verschiedenen Funktionen von Neuro-Headsets und Möglichkeiten zur programmgesteuerten Arbeit mit ihnen besprochen habe, werde ich über mehrere von mir erstellte Prototypen sprechen, die eine Neuro-Schnittstelle verwenden. <br><br><h2>  <font color="#3AC1EF">Prototypen</font> </h2><br><h3>  <font color="#3AC1EF">▍1.</font>  <font color="#3AC1EF">Tastatur</font> </h3><br>  So sieht eine Tastatur aus, die Augenbewegungen steuert. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/64a/d35/786/64ad35786e964b66cddcdd62b7a38fc3.png"></div><br>  <i><font color="#999999">Prototyp einer Tastatur, die durch Augenbewegungen gesteuert wird</font></i> <br><br>  Dies war mein erstes Projekt mit Emotiv Epoc.  Ich war interessiert zu wissen, ob es möglich ist, mit einem Neuro-Headset eine einfache Benutzeroberfläche zu erstellen, mit der eine Person mithilfe von Augenbewegungen mit einem Computer interagieren kann.  Wenn Sie beispielsweise nach rechts oder links schauen, werden die entsprechenden Tasten auf der Tastatur hervorgehoben.  Um auf die markierte Taste zu "klicken", müssen Sie blinken.  Der entsprechende Buchstabe wird im Feld über der Tastatur angezeigt. <br><br>  Dieses Projekt sieht sehr einfach aus, aber das Wichtigste ist, dass es funktioniert. <br><br><h3>  <font color="#3AC1EF">▍2.</font>  <font color="#3AC1EF">Webvr</font> </h3><br>  In meinem zweiten Projekt habe ich mentale Befehle verwendet.  Als ich es schuf, wollte ich verstehen, ob es möglich ist, ein Objekt im dreidimensionalen Raum zu steuern, indem ich nur an etwas denke. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a3c/45d/6b2/a3c45d6b2d4be7a9b49a07aafa732bd2.gif"></div><br>  <i><font color="#999999">Gedankengesteuertes Webinterface</font></i> <br><br>  Um eine einfache dreidimensionale Umgebung zu erstellen, habe ich die Three.js-Bibliothek verwendet, die Epoc.js-Bibliothek wurde verwendet, um mentale Befehle zu erkennen, und Web-Sockets wurden verwendet, um Daten vom Server an den Client zu senden. <br><br><h3>  <font color="#3AC1EF">▍3.</font>  <font color="#3AC1EF">IoT</font> </h3><br>  Mit dem dritten Projekt wollte ich die Möglichkeiten untersuchen, reale Geräte mit mentalen Befehlen zu steuern.  Ich habe mich schon seit einiger Zeit für die IoT-Entwicklung mit JavaScript interessiert, daher war ich daran interessiert zu erfahren, was passiert, wenn Sie den Parrot Quadrocopter und ein Neuro-Headset kombinieren. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a68/38d/791/a6838d7917c54de10ed3366274e33801.jpg"></div><br>  <i><font color="#999999">Quadcopter</font></i> <br><br>  Alle oben beschriebenen Projekte, alle erstellten Prototypen sind ziemlich einfache Entwicklungen, die ich erstellt habe, um einige Ideen in der Praxis zu testen und die Möglichkeiten und Grenzen neuronaler Schnittstellen zu bewerten. <br><br><h2>  <font color="#3AC1EF">Einschränkungen der neuronalen Schnittstelle</font> </h2><br>  Das Wort "Neurointerface" klingt erstaunlich, und wenn sich herausstellt, dass der Computer durch die Kraft des Denkens gesteuert werden kann, scheint es, dass es die Zukunft ist, aber tatsächlich haben Neurocomputertechnologien noch einige Einschränkungen. <br><br><h3>  <font color="#3AC1EF">▍Notwendig für das Training</font> </h3><br>  Es ist ganz normal, dass Benutzer ein Systemtraining durchführen müssen, bei dem Gehirnwellen aufgezeichnet und mit bestimmten Teams verglichen werden. Für viele ist dieser Schritt jedoch ein Hindernis für die Einführung neuer Technologien.  Es fällt mir schwer, mir vorzustellen, dass jemand Zeit damit verbringen wird, Neurocomputersysteme zu trainieren, es sei denn, jemand braucht wirklich ein solches System, und gleichzeitig wird die Genauigkeit, mit der er mentale Befehle erkennt, auf einem sehr hohen Niveau liegen. <br><br><h3>  <font color="#3AC1EF">▍ Verzögerungen</font> </h3><br>  Als ich meinen Prototyp basierend auf der Wahrnehmung mentaler Befehle durch den Computer entwickelte, stellte ich fest, dass es zwischen dem Moment, in dem ich anfing zu denken, und dem Moment, in dem das Programm auf diesen Gedanken reagierte, eine gewisse Verzögerung gab. <br><br>  Ich denke, der Punkt hier ist, dass der im Prototyp verwendete Algorithmus für maschinelles Lernen Daten vom Gerät in Echtzeit empfängt.  Um den Gedanken zu erkennen, dessen Erkennung er zuvor studiert hatte, benötigt er Indikatoren, die über einen bestimmten Zeitraum gesammelt wurden. <br><br>  Dies wirkt sich darauf aus, welche Programme auf der Basis der neuronalen Schnittstelle erstellt werden können.  Zum Beispiel sieht ein Programm, das beim Meditieren hilft, ziemlich real aus, da Verzögerungen zwischen Änderungen des Gehirnzustands und der Reaktion des Programms die Ergebnisse eines solchen Programms nicht besonders beeinflussen.  Wenn man jedoch so etwas wie einen von Gedanken kontrollierten Rollstuhl schaffen will, wird das Problem der Verzögerungen viel akuter und stellt eine solche Entwicklung in Frage. <br><br><h3>  <font color="#3AC1EF">▍ Nicht-invasive Technologie und Genauigkeit</font> </h3><br>  EEG-Scanner eignen sich hervorragend für den täglichen Gebrauch in alltäglichen Situationen.  Es reicht aus, das Headset aufzusetzen, indem Sie ein spezielles Gel auf die Sensoren auftragen, und schon sind Sie fertig.  Die Tatsache, dass die vom Gehirn erzeugten Signale von der Kopfhaut und nicht etwa von der Oberfläche des Gehirns selbst gelesen werden, beeinträchtigt jedoch die Genauigkeit solcher Signale. <br><br>  Wenn wir über die Häufigkeit der Indikatorerfassung sprechen, ist dies bei vorhandenen Geräten sehr gut.  Gleiches gilt nicht für die räumlichen Eigenschaften der erhaltenen Daten.  EEG-Geräte können nur Signale lesen, die von den Teilen des Gehirns stammen, die sich nahe an der Oberfläche des Kopfes befinden.  Mit einem ähnlichen Ansatz ist es unmöglich herauszufinden, was in den tieferen Strukturen des Gehirns geschieht. <br><br><h3>  <font color="#3AC1EF">▍ Öffentliche Akzeptanz</font> </h3><br>  Ein Neuro-Headset ist nicht das schönste und bekannteste Gerät.  Ich denke, solange diese Headsets so aussehen, wie sie jetzt sind, ist es unwahrscheinlich, dass sie an öffentlichen Orten getragen werden.  Während sich die Technologie entwickelt, ist es möglich, dass Geräte erstellt werden, die in Zubehör wie Hüten versteckt werden können. Aber auch hier kann ein Problem auftreten, das damit zusammenhängt, dass solche Geräte für einen längeren Gebrauch unpraktisch sind. <br><br>  EEG-Sensoren sollten sich ziemlich nahe an der Kopfhaut befinden, um qualitative Indikatoren für die Gehirnaktivität zu erhalten.  Und wenn ihr Druck unmittelbar nach dem Aufsetzen des Headsets kaum zu spüren ist, verursacht er im Laufe der Zeit Unbehagen.  Wenn Sie außerdem Gel auf die Sensoren auftragen müssen, wird dies zu einer zusätzlichen Barriere für die weit verbreitete Verbreitung von Neuro-Headsets. <br><br>  Wie Sie sehen können, deutet der aktuelle Stand der Dinge auf dem Gebiet der neuronalen Schnittstellen darauf hin, dass es unwahrscheinlich ist, dass sie sich verbreiten.  Wenn wir jedoch über die Zukunft sprechen, können wir sagen, dass solche Geräte interessante Perspektiven haben. <br><br><h2>  <font color="#3AC1EF">Neuronale Schnittstellenfähigkeiten</font> </h2><br>  Wenn Sie den aktuellen Stand der Technik berücksichtigen und darüber nachdenken, wie sie in Zukunft aussehen könnten, finden Sie verschiedene Optionen für ihre Anwendung. <br><br><h3>  <font color="#3AC1EF">▍Helfen Sie Menschen mit Behinderungen</font> </h3><br>  Ich möchte, dass Neuro-Headsets Menschen mit Behinderungen helfen, ein volleres Leben zu führen und unabhängiger zu sein. <br><br>  Genau das habe ich mir gedacht, als ich meinen ersten Prototyp erstellt habe - eine Tastatur, die durch Augenbewegungen gesteuert wird.  Meine Entwicklung ist weit von der Ebene entfernt, auf der sie in der Praxis eingesetzt werden könnte, aber während ich an diesem Projekt arbeitete, war ich daran interessiert zu verstehen, ob ein völlig erschwingliches Consumer-Gerät wirklich jemandem helfen kann.  Nicht jeder hat Zugang zu komplexen medizinischen Systemen, und ich war einfach erfreut darüber, dass das nicht so teure Gizmo, das im Online-Shop frei erhältlich ist, wichtige und notwendige Aufgaben lösen kann. <br><br><h3>  <font color="#3AC1EF">▍ Mentale Praktiken</font> </h3><br>  Insbesondere mentale Praktiken - Meditation - dies ist der Anwendungsbereich von Neuro-Headsets, der bereits heute einige Aufmerksamkeit auf sich zieht (zum Beispiel hilft das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Muse-</a> Headset beim Meditieren).  Es geht darum, jemandem zu helfen, der meditieren möchte, alles richtig zu machen. <br><br><h3>  <font color="#3AC1EF">▍Hilfe bei der Lösung von Gesundheitsproblemen</font> </h3><br>  Wenn neuronale Headsets genauso in unser Leben eindringen würden wie Mobiltelefone, könnten wir möglicherweise Anwendungen erstellen, die auf gesundheitliche Probleme reagieren können.  Zum Beispiel wäre es großartig, wenn es Anwendungen gäbe, die auf der Grundlage einer Analyse der Gehirnaktivität helfen würden, Schlaganfälle, Panikattacken und Epilepsie-Attacken zu bekämpfen. <br><br><h3>  <font color="#3AC1EF">▍ Steigerung der Arbeitsproduktivität</font> </h3><br>  Ein Neuro-Headset kann beim Meditieren helfen, was bedeutet, dass Sie damit wirklich herausfinden können, zu welcher Tageszeit sich eine Person am besten konzentriert.  Diese Informationen, die Sie durch regelmäßiges Tragen des Headsets erhalten, können Ihnen helfen, zu verstehen, wann es am besten ist, eine Aktivität auszuführen.  Sie können sich sogar vorstellen, dass der Arbeitsplan nach den individuellen Merkmalen der Person organisiert wird, was ihre Produktivität erhöht. <br><br><h3>  <font color="#3AC1EF">TArt</font> </h3><br>  Ich mag es, aus eigener Initiative außerhalb der Geschäftszeiten die Phänomene zu erforschen, die sich an der Schnittstelle von Kunst und Technologie befinden.  Ich glaube, dass man die Arbeit in dieser Richtung in Bezug auf neuronale Schnittstellen nicht unterschätzen sollte, da sie, obwohl sie „frivol“ erscheinen mögen, dazu beitragen, die Technologien besser zu verstehen, die in „ernsteren“ Fällen ihrer Anwendung nützlich sein werden. <br><br><h2>  <font color="#3AC1EF">Kombination von elektrischen Aktivitätssensoren des Gehirns mit anderen Sensoren</font> </h2><br>  Vor kurzem hatte ich die Idee, dass EEG-Sensoren nicht als etwas völlig Unabhängiges betrachtet werden sollten.  Unser Gehirn nimmt die Welt durch die Sinne wahr.  Er kann nicht ohne Augen sehen und ohne Ohren hören.  Wenn wir also die Daten zur elektrischen Aktivität des Gehirns optimal nutzen möchten, müssen wir möglicherweise andere Vitalfunktionen verfolgen. <br><br>  Das Hauptproblem dabei ist, dass all dies dazu führen kann, dass Menschen buchstäblich mit verschiedenen Sensoren aufgehängt werden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d2e/28b/039/d2e28b039767959114ec7f1381849e03.png"></div><br>  <i><font color="#999999">Gibt es hier zu viele Sensoren?</font></i>  <i><font color="#999999">(Quelle der Illustration - cognionics.net)</font></i> <br><br>  Vielleicht trägt niemand ständig die in der vorherigen Abbildung dargestellten Sensoren. <br><br><h2>  <font color="#3AC1EF">Openbci</font> </h2><br>  Vor einigen Wochen habe ich etwas Neues erworben - das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenBCI-Paket</a> .  Mein nächster Schritt besteht darin, die von EEG-Sensoren erhaltenen Rohdaten zu untersuchen und auf diese Daten Methoden des maschinellen Lernens anzuwenden.  OpenBCI ist ein Open-Source-Projekt, daher scheint mir ihre Entwicklung für diesen Zweck perfekt geeignet zu sein.  Ich habe immer noch nicht viel mit ihrem Headset gearbeitet. Im Moment habe ich nur genug Zeit, um es an einen Computer anzuschließen und zu konfigurieren.  So sieht alles aus. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/112/860/ae0/112860ae0cdb6470d77d657664024e5a.gif"></div><br>  <i><font color="#999999">Openbci</font></i> <br><br><h2>  <font color="#3AC1EF">Zusammenfassung</font> </h2><br>  Der Autor dieses Materials sagt, dass er weiterhin neuronale Schnittstellen untersucht.  Wir hoffen, dass ihre Geschichte denjenigen hilft, die sich für dieses Thema interessieren, sich aber nicht trauen, praktische Maßnahmen zu ergreifen, und die ersten Schritte bei der Anwendung von Neuro-Headsets unternehmen.  Wenn Sie an all dem interessiert sind, finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> eine weitere unserer Veröffentlichungen zu Neuro-Headsets und JavaScript, die Muse gewidmet sind. <br><br>  <b>Liebe Leser!</b>  Planen Sie mit Neuro-Headsets zu experimentieren? <br><br><div style="text-align:center;"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/n0/ry/op/n0ryop7wfykgkeicz3mtuwghrcu.jpeg"></a> </div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de433874/">https://habr.com/ru/post/de433874/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de433864/index.html">Verbesserung der Entwicklungsproduktivität am Beispiel von Vue - Teil 1</a></li>
<li><a href="../de433866/index.html">"Home lokalki" werden in Form von Mesh-Netzwerken wiedergeboren. LibreRouter und andere kostenlose Router</a></li>
<li><a href="../de433868/index.html">Warum das Glukosemessgerät von Alphabet nicht hochgeflogen ist</a></li>
<li><a href="../de433870/index.html">Warum ist es so schwierig, Glukose kontinuierlich zu messen?</a></li>
<li><a href="../de433872/index.html">Mobiler Zugang - über ein Smartphone in Zugangskontrollsystemen</a></li>
<li><a href="../de433876/index.html">Dreidimensionale Produktpräsentationen auf Three.js für die Kleinsten</a></li>
<li><a href="../de433878/index.html">KVM, PCI-Passthrough, Spiegel und alles in allem</a></li>
<li><a href="../de433880/index.html">Life Hacks für Entwickler: Effektives Verwenden von SQ (Source Qualifier) ​​im Informatica Power Center</a></li>
<li><a href="../de433884/index.html">Rechtliche Aspekte der Videoüberwachung: Vermeidung von Gesetzesproblemen</a></li>
<li><a href="../de433886/index.html">Python Machine Learning mit interaktiven Jupyter-Demos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
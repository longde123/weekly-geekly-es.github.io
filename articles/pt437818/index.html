<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üè≠ üïµÔ∏è üçè Ensinamos um computador a distinguir sons: conhecendo o concurso DCASE e montando seu classificador de √°udio em 30 minutos üìâ üë©üèæ‚Äçü§ù‚Äçüë®üèº üë®üèª‚Äçüíº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este artigo foi escrito em conjunto com ananaskelly . 
 1. Introdu√ß√£o 


 Ol√° pessoal, Habr! Trabalhando no Centro de Tecnologia da Fala de S√£o Peters...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ensinamos um computador a distinguir sons: conhecendo o concurso DCASE e montando seu classificador de √°udio em 30 minutos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/speechpro/blog/437818/"><p> Este artigo foi escrito em conjunto com <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">ananaskelly</a> . </p><br><h3 id="vvedenie">  1. Introdu√ß√£o </h3><br><p>  Ol√° pessoal, Habr!  Trabalhando no Centro de Tecnologia da Fala de S√£o Petersburgo, adquirimos um pouco de experi√™ncia na solu√ß√£o de problemas de classifica√ß√£o e detec√ß√£o de eventos ac√∫sticos e decidimos que estamos prontos para compartilh√°-lo com voc√™.  O objetivo deste artigo √© apresentar algumas tarefas e falar sobre o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">concurso de</a> processamento autom√°tico de som <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">DCASE 2018</a> .  Falando sobre o concurso, ficaremos <u>sem f√≥rmulas e defini√ß√µes complexas</u> relacionadas ao aprendizado de m√°quina, para que o significado geral do artigo seja entendido por um <u>amplo p√∫blico</u> . </p><br><p>  Para aqueles que estavam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">interessados</a> na <b>montagem do classificador</b> , preparamos um pequeno c√≥digo python e, usando o link no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github,</a> voc√™ pode encontrar um notebook, onde usamos o exemplo da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">segunda faixa</a> do concurso DCASE para criar uma rede convolucional simples em keras para classificar arquivos de √°udio.  Falamos um pouco sobre a rede e os recursos usados ‚Äã‚Äãpara o treinamento, e como usar uma arquitetura simples para obter um resultado pr√≥ximo da linha de base ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MAP @ 3</a> = 0,6). </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cy/xk/ct/cyxkct2xgahwpajkvi4sxzvallu.png"></div><br><p>  Al√©m disso, abordagens b√°sicas para solu√ß√£o de problemas (linha de base) propostas pelos organizadores ser√£o descritas aqui.  Tamb√©m no futuro, haver√° v√°rios artigos nos quais falaremos com mais detalhes e detalhes, tanto sobre nossa experi√™ncia em participar da competi√ß√£o quanto sobre as solu√ß√µes propostas por outros participantes da competi√ß√£o.  Os links para esses artigos aparecer√£o gradualmente aqui. </p><a name="habracut"></a><br><p>  Certamente, muitas pessoas n√£o t√™m absolutamente nenhuma id√©ia sobre algum tipo de <b>"DCASE"</b> , ent√£o vamos descobrir que tipo de fruta √© e com que √© consumida.  A competi√ß√£o ‚Äú <abbr title="Detec√ß√£o e Classifica√ß√£o de Cenas e Eventos Ac√∫sticos (Detec√ß√£o e Classifica√ß√£o de Cenas e Eventos Ac√∫sticos))">DCASE</abbr> ‚Äù √© realizada anualmente, e todos os anos v√°rias tarefas s√£o dedicadas √† resolu√ß√£o de problemas no campo da classifica√ß√£o de grava√ß√µes de √°udio e detec√ß√£o de eventos ac√∫sticos.  Qualquer pessoa pode participar da competi√ß√£o, √© gratuita, basta basta se cadastrar no site como participante.  Como resultado da competi√ß√£o, √© realizada uma confer√™ncia sobre os mesmos t√≥picos, mas, diferentemente da competi√ß√£o em si, a participa√ß√£o j√° √© paga, e n√£o falaremos mais sobre isso.  Geralmente, as recompensas pelas melhores decis√µes n√£o s√£o confi√°veis, mas h√° exce√ß√µes (por exemplo, a terceira tarefa em 2018).  Este ano, os organizadores propuseram as 5 tarefas a seguir: </p><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Classifica√ß√£o de cenas ac√∫sticas (subdivididas em 3 subtarefas)</a> <br>  A. Conjuntos de dados de treinamento e teste registrados no mesmo dispositivo <br>  B. conjuntos de dados de treinamento e teste registrados em diferentes dispositivos <br>  C. O treinamento √© permitido usando dados n√£o fornecidos pelos organizadores </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Classifica√ß√£o de Eventos Ac√∫sticos</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Detec√ß√£o de canto de p√°ssaros</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Detec√ß√£o de eventos ac√∫sticos em casa usando um conjunto de dados com etiquetas fracas</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Classifica√ß√£o da atividade dom√©stica na sala de acordo com a grava√ß√£o multicanal</a> </li></ol><br><h4 id="o-detektirovanii-i-klassifikacii">  Sobre detec√ß√£o e classifica√ß√£o </h4><br><p>  Como podemos ver, os nomes de todas as tarefas cont√™m uma de duas palavras: "detec√ß√£o" ou "classifica√ß√£o".  Vamos esclarecer qual √© a diferen√ßa entre esses conceitos para que n√£o haja confus√£o. </p><br><p>  Imagine que temos uma grava√ß√£o de √°udio na qual um cachorro late em um momento, e um gato mia em outro, e simplesmente n√£o h√° outros eventos por l√°.  Ent√£o, se queremos entender exatamente quando esses eventos ocorrem, precisamos resolver o problema de detectar um evento ac√∫stico.  Ou seja, precisamos descobrir os hor√°rios de in√≠cio e fim de cada evento.  Tendo resolvido o problema de detec√ß√£o, descobrimos exatamente quando os eventos ocorrem, mas n√£o sabemos quem exatamente faz os sons encontrados - precisamos resolver o problema de classifica√ß√£o, ou seja, determinar o que exatamente aconteceu em um determinado per√≠odo de tempo. </p><br><p>  Para entender a descri√ß√£o das tarefas da competi√ß√£o, esses exemplos ser√£o suficientes, o que significa que a parte introdut√≥ria est√° conclu√≠da e podemos prosseguir com uma descri√ß√£o detalhada das pr√≥prias tarefas. </p><br><hr><br><h3 id="anchortrack1anchortrack-1-klassifikaciya-akusticheskih-scen"><a name="Track1"></a>  Faixa 1. Classifica√ß√£o de cenas ac√∫sticas </h3><br><p>  A primeira tarefa √© determinar o ambiente (cena ac√∫stica) em que o √°udio foi gravado, por exemplo, "Esta√ß√£o de Metr√¥", "Aeroporto" ou "Rua de Pedestres".  A solu√ß√£o para esse problema pode ser √∫til na avalia√ß√£o do ambiente com um sistema de intelig√™ncia artificial, por exemplo, em carros com piloto autom√°tico. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/db/4g/ff/db4gffctu9tgvd4upbse_eaaiwg.jpeg"></div><br><p>  Nesta tarefa, os conjuntos de dados TUT Urban Acoustic Scenes 2018 e TUT Urban Acoustic Scenes 2018 Mobile, que foram preparados pela Universidade de Tecnologia de Tampere (Finl√¢ndia), foram apresentados para treinamento.  Uma descri√ß√£o detalhada da prepara√ß√£o do conjunto de dados, bem como a solu√ß√£o b√°sica, √© descrita no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo</a> . </p><br><p>  No total, 10 cenas ac√∫sticas foram apresentadas para a competi√ß√£o, que os participantes tiveram que prever. </p><br><h4 id="podzadacha-a">  Subtarefa A </h4><br><p>  Como j√° dissemos, a tarefa √© dividida em tr√™s subtarefas, cada uma das quais difere na qualidade das grava√ß√µes de √°udio.  Por exemplo, na subtarefa A, foram usados ‚Äã‚Äãmicrofones especiais para grava√ß√£o, localizados nos ouvidos humanos.  Assim, a grava√ß√£o est√©reo foi aproximada da percep√ß√£o humana do som.  Os participantes tiveram a oportunidade de usar essa abordagem para gravar, a fim de melhorar a qualidade do reconhecimento da cena ac√∫stica. </p><br><h4 id="podzadacha-v">  Subtarefa B </h4><br><p>  Na subtarefa B, outros dispositivos (por exemplo, telefones celulares) tamb√©m foram usados ‚Äã‚Äãpara grava√ß√£o.  Os dados da subtarefa A foram convertidos para um formato mono, a frequ√™ncia de amostragem foi reduzida, n√£o h√° simula√ß√£o da ‚Äúaudibilidade‚Äù do som por uma pessoa no conjunto de dados para esta tarefa, mas h√° mais dados para treinamento. </p><br><h4 id="podzadacha-s">  Subtarefa C </h4><br><p>  O conjunto de dados da subtarefa C √© o mesmo da subtarefa A, mas, ao resolver esse problema, √© permitido o uso de quaisquer dados externos que o participante possa encontrar.  O objetivo de resolver esse problema √© descobrir se √© poss√≠vel melhorar o resultado obtido na subtarefa A usando dados de terceiros. </p><br><p>  A qualidade das decis√µes nessa trilha foi avaliada pela m√©trica <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Precis√£o</a> . </p><br><p>  A linha de base para esta tarefa √© uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rede neural convolucional de</a> duas camadas que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aprende</a> com os logaritmos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pequenos espectrogramas dos</a> dados de √°udio originais.  A arquitetura proposta usa as t√©cnicas padr√£o de BatchNormalization e Dropout.  O c√≥digo no GitHub pode ser visto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . </p><br><hr><br><h3 id="anchortrack2anchortrack-2-klassifikaciya-akusticheskih-sobytiy"><a name="Track2"></a>  Faixa 2. Classifica√ß√£o de Eventos Ac√∫sticos </h3><br><p>  Nesta tarefa, prop√µe-se criar um sistema que classifique eventos ac√∫sticos.  Esse sistema pode ser um complemento para resid√™ncias inteligentes, aumentar a seguran√ßa em locais lotados ou facilitar a vida de pessoas com defici√™ncia auditiva. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ut/r5/9_/utr59_-ugehiq9jyhe_hgpgzbrm.jpeg"></div><br><p>  O conjunto de dados para esta tarefa consiste em arquivos retirados do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">conjunto de dados Freesound</a> e marcados com tags do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AudioSet</a> do Google.  Mais detalhadamente, o processo de prepara√ß√£o do conjunto de dados √© descrito por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um artigo</a> preparado pelos organizadores do concurso. </p><br><p>  Vamos voltar √† tarefa em si, que possui v√°rios recursos. </p><br><p>  Primeiramente, os participantes tiveram que criar um modelo capaz de identificar diferen√ßas entre eventos ac√∫sticos de natureza muito diferente.  O conjunto de dados √© dividido na classe 41, apresenta v√°rios instrumentos musicais, sons produzidos por humanos, animais, sons dom√©sticos e muito mais. </p><br><p>  Em segundo lugar, al√©m da marca√ß√£o usual dos dados, tamb√©m h√° informa√ß√µes adicionais sobre a verifica√ß√£o manual do r√≥tulo.  Ou seja, os participantes sabem quais arquivos do conjunto de dados foram verificados pela pessoa quanto √† conformidade com o r√≥tulo e quais n√£o s√£o.  Como a pr√°tica demonstrou, os participantes que de alguma forma usaram essas informa√ß√µes adicionais receberam pr√™mios na solu√ß√£o desse problema. </p><br><p>  Al√©m disso, deve-se dizer que a dura√ß√£o dos registros no conjunto de dados varia muito: de 0,3 segundos a 30 segundos.  Nesse problema, a quantidade de dados por classe, na qual o modelo precisa ser treinado, tamb√©m varia bastante.  Isso √© melhor representado como um histograma, o c√≥digo de constru√ß√£o que √© retirado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">daqui</a> . </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tw/r4/gq/twr4gqwzkdivbpzkipwh6jesugi.jpeg"></div><br><p>  Como voc√™ pode ver no histograma, a marca√ß√£o manual para as aulas apresentadas tamb√©m √© desequilibrada, o que aumenta a dificuldade se voc√™ quiser usar essas informa√ß√µes ao treinar modelos. <br>  Os resultados nesta trilha foram avaliados usando a m√©trica de precis√£o m√©dia (Mean Mean Precision, MAP @ 3), uma demonstra√ß√£o bastante simples do c√°lculo dessa m√©trica com exemplos e c√≥digo pode ser encontrada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . </p><br><hr><br><h3 id="anchortrack3anchortrack-3-detektirovanie-ptichego-peniya"><a name="Track3"></a>  Faixa 3. Detec√ß√£o de canto de p√°ssaros </h3><br><p>  A pr√≥xima faixa √© a detec√ß√£o do canto dos p√°ssaros.  Um problema semelhante surge, por exemplo, em v√°rios sistemas de monitoramento autom√°tico da vida selvagem - este √© o primeiro passo no processamento de dados antes, por exemplo, da classifica√ß√£o.  Tais sistemas geralmente precisam de ajuste, s√£o inst√°veis ‚Äã‚Äãa novas condi√ß√µes ac√∫sticas, portanto, o objetivo desta faixa √© recorrer ao poder do aprendizado de m√°quina para resolver esses problemas. </p><br><p>  Esta faixa √© uma vers√£o estendida do concurso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">"Desafio de detec√ß√£o de √°udio de p√°ssaros"</a> , organizado pela Universidade de St Mary em Londres em 2017/2018.  Para os interessados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">,</a> voc√™ pode ler o artigo dos autores da competi√ß√£o, que fornece detalhes sobre a forma√ß√£o dos dados, a organiza√ß√£o da pr√≥pria competi√ß√£o e uma an√°lise das decis√µes tomadas. </p><br><p>  No entanto, de volta √† tarefa DCASE.  Os organizadores forneceram seis conjuntos de dados - tr√™s para treinamento e tr√™s para teste - todos eles s√£o muito diferentes - gravados em diferentes condi√ß√µes ac√∫sticas, usando v√°rios dispositivos de grava√ß√£o, e no fundo existem v√°rios ru√≠dos.  Portanto, a mensagem principal √© que o modelo n√£o deve depender do ambiente ou ser capaz de se adaptar a ele.  Apesar de o nome significar ‚Äúdetec√ß√£o‚Äù, a tarefa n√£o √© determinar os limites do evento, mas em uma classifica√ß√£o simples - a solu√ß√£o final √© um tipo de classificador bin√°rio que recebe uma entrada curta de √°udio e decide se h√° ou n√£o canto de p√°ssaro. .  A m√©trica da AUC foi usada para avaliar a precis√£o. </p><br><p>  Principalmente, os participantes tentaram obter generaliza√ß√£o e adapta√ß√£o atrav√©s de v√°rios aprimoramentos de dados.  Um dos comandos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">descreve a</a> aplica√ß√£o de v√°rias t√©cnicas - altera√ß√£o da resolu√ß√£o de frequ√™ncia nos recursos extra√≠dos, redu√ß√£o preliminar de ru√≠do, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um m√©todo de adapta√ß√£o</a> baseado no alinhamento de estat√≠sticas de segunda ordem para diferentes conjuntos de dados.  No entanto, esses m√©todos, bem como diferentes tipos de aumento, proporcionam um aumento muito pequeno em rela√ß√£o √† solu√ß√£o b√°sica, como observam muitos participantes. </p><br><p>  Como solu√ß√£o b√°sica, os autores prepararam uma modifica√ß√£o da solu√ß√£o mais bem-sucedida da competi√ß√£o original "Desafio de detec√ß√£o de √°udio de p√°ssaros".  O c√≥digo, como sempre, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">est√° dispon√≠vel no github</a> . </p><br><hr><br><h3 id="anchortrack4anchortrack-4-detektirovanie-akusticheskih-sobytiy-v-bytovyh-usloviyah-s-ispolzovaniem-slabo-razmechennogo-nabora-dannyh"><a name="Track4"></a>  Faixa 4. Detec√ß√£o de eventos ac√∫sticos em casa usando um conjunto de dados com etiquetas fracas. </h3><br><p>  Na quarta faixa, o problema de detec√ß√£o j√° est√° resolvido diretamente.  Os participantes receberam um conjunto de dados relativamente pequeno de dados marcados - um total de 1578 grava√ß√µes de √°udio de 10 segundos cada, com apenas marca√ß√£o de classe: sabe-se que o arquivo cont√©m um ou mais eventos dessas classes, mas n√£o h√° marca√ß√£o tempor√°ria.  Al√©m disso, foram fornecidos dois grandes conjuntos de dados de dados n√£o alocados - 14412 arquivos contendo eventos de destino das mesmas classes que nas amostras de treinamento e teste, al√©m de 39999 arquivos contendo eventos arbitr√°rios que n√£o foram inclu√≠dos nos destinos.  Todos os dados s√£o um subconjunto do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">enorme conjunto de dados do audioset compilado pelo google</a> . </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lx/td/h7/lxtdh7uaqxktdqu2bxzd4drrq0q.jpeg"></div><br><p>  Assim, os participantes precisavam criar um modelo capaz de aprender com dados fracamente rotulados para encontrar registros de data e hora do in√≠cio e final dos eventos (os eventos podem se sobrepor) e tentar aprimor√°-lo com uma grande quantidade de dados adicionais n√£o marcados.  Al√©m disso, vale a pena notar que uma m√©trica bastante r√≠gida foi usada nessa faixa - era necess√°rio prever os r√≥tulos de tempo dos eventos com uma precis√£o de 200 ms.  Em geral, os participantes tiveram que resolver uma tarefa bastante dif√≠cil de criar um modelo adequado, praticamente sem ter bons dados para o treinamento. <br>  A maioria das solu√ß√µes foi baseada em redes de recorr√™ncia convolucionais - uma arquitetura bastante popular no campo de detec√ß√£o de eventos ac√∫sticos recentemente (um exemplo pode ser lido <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ). </p><br><p>  A solu√ß√£o b√°sica dos autores, tamb√©m em redes recursivas convolucionais, √© baseada em dois modelos.  Os modelos t√™m quase a mesma arquitetura: tr√™s camadas convolucionais e uma recursiva.  A √∫nica diferen√ßa s√£o as redes de sa√≠da.  O primeiro modelo √© treinado para marcar dados n√£o alocados para expandir o conjunto de dados original - portanto, na sa√≠da, temos classes presentes no arquivo de evento.  O segundo √© para resolver o problema de detec√ß√£o diretamente, ou seja, na sa√≠da, obtemos uma marca√ß√£o tempor√°ria para o arquivo.  C√≥digo para o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">link</a> . </p><br><hr><br><h3 id="anchortrack5anchortrack-5-klassifikaciya-bytovoy-aktivnosti-v-pomeschenii-po-mnogokanalnoy-zapisi"><a name="Track5"></a>  Faixa 5. Classifica√ß√£o da atividade dom√©stica na sala de acordo com a grava√ß√£o multicanal. </h3><br><p>  A √∫ltima faixa diferia das outras principalmente porque os participantes receberam grava√ß√µes multicanais.  A tarefa em si estava na classifica√ß√£o: √© necess√°rio prever a classe de eventos que ocorreram no registro.  Diferentemente da faixa anterior, a tarefa √© um pouco mais simples - sabe-se que h√° apenas um evento no registro. </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hr/l1/ud/hrl1udue-onkcjfot9kptycgcw8.jpeg"></div><br><p>  O conjunto de dados √© representado por aproximadamente 200 horas de grava√ß√µes em um conjunto de microfones lineares de 4 microfones.  Eventos s√£o todos os tipos de atividades cotidianas - cozinhar, lavar a lou√ßa, atividade social (falar ao telefone, visitas e conversas pessoais), etc., tamb√©m √© destacada a classe de aus√™ncia de qualquer evento. </p><br><p>  Os autores da faixa enfatizam que as condi√ß√µes da tarefa s√£o relativamente simples, de modo que os participantes se concentram diretamente no uso de informa√ß√µes espaciais de grava√ß√µes multicanal.  Os participantes tamb√©m tiveram a oportunidade de usar dados adicionais e modelos pr√©-treinados.  A qualidade foi avaliada de acordo com a medida F1. </p><br><p>  Como solu√ß√£o b√°sica, os autores da faixa propuseram uma rede convolucional simples com duas camadas convolucionais.  Em sua solu√ß√£o, as informa√ß√µes espaciais n√£o foram usadas - os dados de quatro microfones foram usados ‚Äã‚Äãpara o treinamento de forma independente e as previs√µes foram calculadas em m√©dia durante o teste.  Descri√ß√£o e c√≥digo est√£o dispon√≠veis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no link</a> . </p><br><hr><br><h3 id="zaklyuchenie">  Conclus√£o </h3><br><p>  No artigo, tentamos falar brevemente sobre a detec√ß√£o de eventos ac√∫sticos e sobre uma competi√ß√£o como o DCASE.  Talvez eles tenham conseguido interessar algu√©m para participar de 2019 - a competi√ß√£o come√ßa em mar√ßo. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt437818/">https://habr.com/ru/post/pt437818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt437808/index.html">Perf e flamegraphs</a></li>
<li><a href="../pt437810/index.html">Realidade corporativa</a></li>
<li><a href="../pt437812/index.html">Xcode 10.2, macOS Mojave 10.14.4, iOS 12.1 e outros betas</a></li>
<li><a href="../pt437814/index.html">Xcode 10.2, macOS Mojave 10.14.4, iOS 12.1 e outras vers√µes beta</a></li>
<li><a href="../pt437816/index.html">MPLS est√° em todo lugar. Como √© a infraestrutura de rede Yandex.Cloud</a></li>
<li><a href="../pt437820/index.html">50 tons de seguran√ßa Drupal</a></li>
<li><a href="../pt437824/index.html">Extens√£o Universal 1C para o Planilhas Google e o Google Docs - use e use</a></li>
<li><a href="../pt437826/index.html">Como migramos o banco de dados do Redis e do Riak KV para o PostgreSQL. Parte 1: o processo</a></li>
<li><a href="../pt437828/index.html">Abra o webinar "SELECT ordem de execu√ß√£o da consulta e plano de consulta no MS SQL Server"</a></li>
<li><a href="../pt437830/index.html">Programa√ß√£o confi√°vel por idioma - revis√£o noob. Parte 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
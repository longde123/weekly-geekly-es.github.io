<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéá ü§≤üèΩ ‚ò£Ô∏è Cam√©ras de profondeur - r√©volution silencieuse (quand les robots verront) Partie 1 üí™üèæ üë© üëÇüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="R√©cemment, je l'ai d√©crit, gr√¢ce auquel les robots demain commenceront BEAUCOUP mieux √† penser (un article sur l'acc√©l√©ration mat√©rielle des r√©seaux d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cam√©ras de profondeur - r√©volution silencieuse (quand les robots verront) Partie 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457524/"><img src="https://habrastorage.org/getpro/habr/post_images/917/25a/9a4/91725a9a49451111a6d55d1015cc297c.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/f58/7fd/ebe/f587fdebeedd2f17fe6f4122a68dff9f.png"><br><br>  R√©cemment, je l'ai d√©crit, gr√¢ce auquel les robots demain commenceront BEAUCOUP mieux √† penser (un article sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'acc√©l√©ration mat√©rielle des r√©seaux de neurones</a> ).  Aujourd'hui, nous verrons pourquoi les robots seront bient√¥t beaucoup mieux √† voir.  Dans certaines situations, bien mieux qu'une personne. <br><br>  Nous parlerons des cam√©ras de profondeur qui tournent des vid√©os, dans chaque pixel duquel est stock√©e non pas la couleur, mais la distance √† l'objet √† ce stade.  Ces cam√©ras existent depuis plus de 20 ans, mais ces derni√®res ann√©es, la vitesse de leur d√©veloppement a augment√© de nombreuses fois et nous pouvons d√©j√† parler de la r√©volution.  Et multi-vecteur.  Un d√©veloppement rapide se d√©roule dans les domaines suivants: <br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lumi√®re structur√©e d'une cam√©ra</a> , ou d'une cam√©ra √† lumi√®re structurelle, lorsqu'il y a un projecteur (souvent infrarouge) et une cam√©ra qui enregistre la lumi√®re structurelle du projecteur; <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cam√©ras Time of Flight</a> ou cam√©ras bas√©es sur la mesure du retard de la lumi√®re r√©fl√©chie; <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Profondeur des cam√©ras st√©r√©o</a> - la direction classique et, peut-√™tre, la plus c√©l√®bre de la profondeur de construction de la st√©r√©o; <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cam√©ra de champ lumineux</a> - ce sont √©galement des cam√©ras de champ lumineux ou des cam√©ras pl√©noptiques, sur lesquelles il y avait un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">poste d√©taill√©</a> s√©par√©; <br></li><li>  Et enfin, les cam√©ras bas√©es sur la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">technologie Lidar</a> , en particulier les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lidars Solid State frais</a> , qui fonctionnent sans d√©faillance environ 100 fois plus longtemps que les lidars ordinaires et produisent l'image rectangulaire habituelle. <br></li></ul><br>  Peu importe √† quoi il ressemblera, ainsi qu'une comparaison des diff√©rentes approches et de leur application actuelle et de demain - bienvenue sous la coupe! <br><a name="habracut"></a><br>  Alors!  Nous analyserons les principales directions de d√©veloppement des chambres de profondeur ou en r√©alit√© diff√©rents principes de mesure de la profondeur.  Avec leurs avantages et leurs inconv√©nients. <br><br><h1>  M√©thode 1: Cam√©ra √† lumi√®re structur√©e </h1><br>  Commen√ßons par l'une des m√©thodes les plus simples, les plus anciennes et relativement bon march√© pour mesurer la lumi√®re structur√©e en profondeur.  Cette m√©thode est apparue essentiellement tout de suite, d√®s l'apparition des appareils photo num√©riques, c'est-√†-dire  il y a plus de 40 ans et consid√©rablement simplifi√© un peu plus tard, avec l'av√®nement des projecteurs num√©riques. <br><br>  L'id√©e de base est extr√™mement simple.  Nous pla√ßons √† c√¥t√© du projecteur, ce qui cr√©e, par exemple, des rayures horizontales (puis verticales) et √† c√¥t√© de la cam√©ra, qui prend une photo avec des rayures, comme le montre cette figure: <br><img src="https://habrastorage.org/getpro/habr/post_images/ed4/416/7c3/ed44167c3f6f9e1af2af2eda53f6ec97.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Autodesk: Num√©risation 3D √† lumi√®re structur√©e</a></i> <br><br>  √âtant donn√© que l'appareil photo et le projecteur sont d√©cal√©s l'un par rapport √† l'autre, les bandes seront √©galement d√©plac√©es proportionnellement √† la distance au sujet.  En mesurant ce d√©placement, nous pouvons calculer la distance √† l'objet: <br><img src="https://habrastorage.org/webt/27/oo/xp/27ooxpjh4fgdijfazupjylg1ang.png">  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://www.vision-systems.com/</a></i> <br><br>  En fait, avec le projecteur le moins cher (et leur prix commence √† 3000 roubles) et un smartphone, vous pouvez mesurer la profondeur des sc√®nes statiques dans une pi√®ce sombre: <br><img src="https://habrastorage.org/getpro/habr/post_images/f41/e50/8b8/f41e508b881e7d1f1b36bbc0dfb9c179.png"><img src="https://habrastorage.org/getpro/habr/post_images/464/662/9ee/4646629ee8562fe3a76beaef82e4c284.png"><img src="https://habrastorage.org/getpro/habr/post_images/85a/493/ee0/85a493ee0b020b885518bfcddb2c9b1d.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Autodesk: Num√©risation 3D √† lumi√®re structur√©e</a></i> <br><br>  Il est clair que ce faisant, un tas de t√¢ches devront √™tre r√©solues - il s'agit de l'√©talonnage du projecteur, de l'√©talonnage de la cam√©ra du t√©l√©phone, de la reconnaissance de d√©calage de bande, etc., mais toutes ces t√¢ches sont tout √† fait capables m√™me pour les √©l√®ves du secondaire avanc√©s qui apprennent la programmation. <br><br>  Ce principe de mesure de la profondeur est devenu le plus connu quand, en 2010, Microsoft a sorti le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">capteur de</a> profondeur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MS Kinect</a> pour 150 $, ce qui √† l'√©poque √©tait r√©volutionnaire et bon march√©. <br><img src="https://habrastorage.org/getpro/habr/post_images/89c/3d5/8b2/89c3d58b24c16b18593782bd822a5bd2.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Reconstruction d'objet partiellement occlus √† l'aide de plusieurs capteurs Kinect</a></i> <br><br>  Malgr√© le fait qu'en plus de mesurer r√©ellement la profondeur avec un projecteur IR et une cam√©ra IR, Kinect a √©galement film√© des vid√©os RVB r√©guli√®res, avait quatre microphones avec r√©duction du bruit et pouvait s'adapter √† une personne en hauteur, s'inclinant automatiquement vers le haut ou vers le bas, il a √©t√© imm√©diatement int√©gr√© √† l'int√©rieur traitement des donn√©es, qui a d√©livr√© √† la console imm√©diatement une carte de profondeur pr√™te: <br><img src="https://habrastorage.org/getpro/habr/post_images/a48/49e/1a1/a4849e1a19f745aedb92800debafc6f7.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Impl√©mentation de boutons d'interface utilisateur naturels √† l'aide de Kinect</a></i> <br><br>  Au total, environ 35 millions d'appareils ont √©t√© vendus, faisant de Kinect la premi√®re cam√©ra √† profondeur de masse de l'histoire.  Et si vous consid√©rez qu'il y avait certainement des cam√©ras de profondeur, mais g√©n√©ralement elles se vendaient au maximum par centaines et co√ªtaient au moins un ordre de grandeur plus cher - c'√©tait une r√©volution qui a fourni de grands investissements dans ce domaine. <br><br>  Une raison importante du succ√®s √©tait qu'au moment o√π Microsoft a sorti la Xbox 360, il y avait d√©j√† quelques jeux qui utilisaient activement Kinect comme capteur.  Le d√©collage a √©t√© rapide: <br><img width="75%" src="https://habrastorage.org/getpro/habr/post_images/895/5be/676/8955be6766420326e6fc7c1ab2371385.png"><br><br>  De plus, Kinect a m√™me r√©ussi √† entrer dans le livre Guinness des records en tant que gadget le plus vendu de l'histoire.  Certes, Apple a rapidement √©vinc√© Microsoft de cet endroit, mais n√©anmoins.  Pour un nouveau capteur exp√©rimental qui fonctionne en plus de l'appareil principal pour devenir l'appareil √©lectronique le plus vendu de l'histoire, c'est tout simplement une grande r√©ussite: <br><img src="https://habrastorage.org/getpro/habr/post_images/051/f2a/cf2/051f2acf275e677c10252fc38541ff82.png"><br><br>  En conf√©rence, j'aime demander au public d'o√π viennent tous ces millions de clients.  Qui √©taient tous ces gens? <br><br>  En r√®gle g√©n√©rale, personne ne devine, mais parfois, surtout si le public est plus √¢g√© et plus exp√©riment√©, ils donnent la bonne r√©ponse: les ventes ont √©t√© men√©es par des parents am√©ricains, qui ont vu avec plaisir que leurs enfants pouvaient jouer sur la console et ne pas s'asseoir sur le canap√© avec un butin √©pais, et sauter devant le t√©l√©viseur.  Ce fut une perc√©e !!!  Des millions de m√®res et de p√®res se sont pr√©cipit√©s pour commander un appareil pour leurs enfants. <br><br>  En g√©n√©ral, en ce qui concerne la reconnaissance des gestes, les gens croient g√©n√©ralement na√Øvement que seules les donn√©es d'une cam√©ra 2D sont suffisantes.  Apr√®s tout, ils ont vu beaucoup de belles d√©mos!  La r√©alit√© est beaucoup plus grave.  La pr√©cision de reconnaissance des gestes √† partir d'un flux vid√©o 2D d'une cam√©ra et la pr√©cision de reconnaissance des gestes √† partir d'une profondeur de cam√©ra diff√®rent d'un ordre de grandeur.  √Ä partir d'une cam√©ra de profondeur, ou plut√¥t d'une cam√©ra RVB combin√©e √† une cam√©ra de profondeur (cette derni√®re est importante), vous pouvez reconna√Ætre les gestes beaucoup plus pr√©cis√©ment et √† moindre co√ªt (m√™me si la pi√®ce est sombre), ce qui a fait le succ√®s de la premi√®re cam√©ra de profondeur de masse. <br><br>  √Ä propos de Kinect sur Habr√© √† l'√©poque, ils ont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">beaucoup</a> √©crit, donc tr√®s bri√®vement comment cela fonctionne. <br><br>  Un projecteur infrarouge donne un ensemble pseudo-al√©atoire de points dans l'espace, dont le d√©placement d√©termine la profondeur dans un pixel donn√©: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/55f/c46/d72/55fc46d72e36087ac7522312d791af6f.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Structures planaires √† d√©tection de profondeur: d√©tection des configurations de mobilier de bureau</a></i> <br><br>  La r√©solution de la cam√©ra est d√©clar√©e comme 640x480, mais il y a vraiment quelque part autour de 320x240 avec un filtrage assez fort et l'image sur des exemples r√©els ressemble √† ceci (c'est-√†-dire assez effrayant): <br><img src="https://habrastorage.org/webt/a9/ni/up/a9niup8_g7i8a1x3n_0oaikpee0.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Reconstruction d'objet partiellement occlus √† l'aide de plusieurs capteurs Kinect</a></i> <br><br>  Les ¬´ombres¬ª des objets sont clairement visibles, car la cam√©ra et le projecteur sont suffisamment √©loign√©s.  On peut voir que des d√©calages de plusieurs points du projecteur sont pris pour pr√©dire la profondeur.  De plus, il y a un filtrage (dur) par les voisins imm√©diats, mais la carte de profondeur est encore assez bruyante, surtout aux fronti√®res.  Il en r√©sulte un bruit assez perceptible √† la surface des objets r√©sultants, qui doit en outre √™tre liss√© de mani√®re non triviale: <br><img src="https://habrastorage.org/webt/ph/e-/dl/phe-dlp6dczaztxgy7q4p-tyxtg.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Biblioth√®que Java J4K pour le SDK Kinect de Microsoft</a></i> <br><br>  N√©anmoins, seulement 150 $ ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">aujourd'hui c'est d√©j√† 69 $</a> , bien que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce soit mieux pr√®s de 200 $</a> , bien s√ªr) - et vous "voyez" la profondeur!  Il y a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vraiment beaucoup de</a> produits en s√©rie. <br><br>  Soit dit en passant, en f√©vrier de cette ann√©e, un nouveau <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Azure Kinect a</a> √©t√© annonc√©: <br><img src="https://habrastorage.org/webt/l6/0y/b2/l60yb2lcfeuufoe6q6jdd0e-jg0.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Microsoft annonce Azure Kinect, disponible en pr√©-commande maintenant</a></i> <br><br>  Ses livraisons aux d√©veloppeurs aux USA et en Chine devraient d√©buter le 27 juin, soit  litt√©ralement en ce moment.  Parmi les capacit√©s, en plus de la r√©solution nettement meilleure du RVB et de la meilleure qualit√© des cam√©ras de profondeur (elles promettent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">1024x1024</a> √† 15 FPS et 512x512 √† 30 FPS et une qualit√© sup√©rieure est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">clairement visible par la d√©mo</a> , la cam√©ra ToF), la prise en charge de la collaboration de plusieurs appareils hors de la bo√Æte est d√©clar√©e, moins d'exposition √† le soleil, l'erreur est inf√©rieure √† 1 cm √† une distance de 4 m√®tres et 1-2 mm √† une distance de moins de 1 m√®tre, ce qui semble extr√™mement int√©ressant, alors nous attendons, nous attendons: <br><img src="https://habrastorage.org/getpro/habr/post_images/0d1/972/90b/0d197290bf6363f157fa9955070c4b5a.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pr√©sentation d'Azure Kinect DK</a></i> <br><br>  Le prochain produit de <b>masse</b> , o√π une cam√©ra de profondeur a √©t√© r√©alis√©e dans une lumi√®re structur√©e, n'√©tait pas une console de jeu, mais ... (roulement de tambour) correctement - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">iPhone X</a> ! <br><br>  Sa technologie Face ID est une cam√©ra de profondeur typique avec un projecteur √† points infrarouge typique et une cam√©ra infrarouge (√† propos, vous comprenez maintenant pourquoi ils sont sur les bords de la frange, espac√©s le plus possible l'un de l'autre - c'est une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">base st√©r√©o</a> ): <br><img src="https://habrastorage.org/getpro/habr/post_images/755/6e2/6de/7556e26dea5a132b997658d386d74e7f.png"><br><br>  La r√©solution de la carte de profondeur est encore inf√©rieure √† celle de Kinect - environ 150x200.  Il est clair que si vous dites: "Notre r√©solution est d'environ 150x200 pixels ou 0,03 m√©gapixels", les gens diront bri√®vement et succinctement: "Suce!"  Et si vous dites <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´Projecteur de points: plus de 30 000 points invisibles sont projet√©s sur votre visage¬ª</a> , les gens disent: ¬´Wow, 30 000 points invisibles, cool!¬ª.  Certaines blondes demanderont si des taches de rousseur apparaissent √† partir de points invisibles.  Et le sujet ira aux masses!  Par cons√©quent, la deuxi√®me option √©tait clairvoyante dans la publicit√©.  La r√©solution est faible pour trois raisons: premi√®rement, les exigences de la miniature, deuxi√®mement, la consommation d'√©nergie et, troisi√®mement, les prix. <br><br>  N√©anmoins, il s'agit d'un autre appareil photo de profondeur sous une lumi√®re structur√©e, qui est entr√© dans une s√©rie de millions d'exemplaires et a d√©j√† √©t√© r√©p√©t√© par d'autres fabricants de smartphones, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">par exemple (surprise-surprise!) Huawei</a> (qui a contourn√© Apple dans les ventes de smartphones l'ann√©e derni√®re).  Seul Huawei a un appareil photo √† droite, et le projecteur √† gauche, mais aussi, bien s√ªr, le long des bords de la "frange": <br><img src="https://habrastorage.org/webt/zt/2h/ab/zt2habvk5zl2pkyvmeerbzacjfq.png"><br>  <i>Source: la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mise √† jour Huawei Mate 20 Pro permet aux utilisateurs d'ajouter un deuxi√®me visage pour d√©verrouiller le visage</a></i> <br><br>  Dans le m√™me temps, 300 000 points sont d√©clar√©s, soit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">10 fois plus qu'Apple</a> , et la cam√©ra frontale est meilleure, <s>et la police est plus grande</s> .  Y a-t-il une exag√©ration concernant 300 000 - c'est difficile √† dire, mais Huawei d√©montre une tr√®s bonne <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">num√©risation 3D d'objets avec une cam√©ra frontale</a> .  Les tests ind√©pendants sont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plus effrayants</a> , mais c'est clairement le tout d√©but du sujet et les balbutiements de la technologie des cam√©ras miniatures √† faible consommation d'√©nergie et des annonces de cam√©ras √† la fin de cette ann√©e sont d√©j√† nettement meilleurs en termes de performances. <br><br>  Dans le m√™me temps, on comprend pourquoi la technologie d'identification faciale a √©t√© utilis√©e dans les t√©l√©phones.  Tout d'abord, vous ne pouvez plus tromper le d√©tecteur en montrant une photo de votre visage (ou une vid√©o de la tablette).  Deuxi√®mement, le visage change beaucoup lorsque l'√©clairage change, mais sa forme ne change pas, ce qui nous permet d'identifier plus pr√©cis√©ment la personne avec les donn√©es de la cam√©ra RVB: <br><img src="https://habrastorage.org/getpro/habr/post_images/5c9/12b/e86/5c912be86bf5a47aa02bcce67e48f148.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">photo TI de la m√™me personne</a></i> <br><br>  De toute √©vidence, le capteur infrarouge a des probl√®mes inh√©rents.  Premi√®rement, notre projecteur relativement faible brille une ou deux fois sur le soleil, de sorte que ces cam√©ras ne fonctionnent pas dans la rue.  M√™me √† l'ombre, si le mur blanc d'un b√¢timent est √©clair√© par le soleil, vous pouvez avoir de gros probl√®mes avec Face ID.  Le niveau de bruit dans Kinect roule √©galement m√™me lorsque le soleil est couvert de nuages: <br><img src="https://habrastorage.org/getpro/habr/post_images/e5b/477/bb5/e5b477bb581588840cb6d1219b7899dd.png"><br>  <i>Source: ceci et les deux images suivantes</i> - <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mat√©riaux Basler AG</a></i> <br><br>  Un autre gros probl√®me est la r√©flexion et la r√©flexion.  √âtant donn√© que la lumi√®re infrarouge est √©galement r√©fl√©chie, photographier une bouilloire en acier inoxydable co√ªteuse, une table vernie ou un abat-jour en verre avec Kinect sera probl√©matique: <br><img src="https://habrastorage.org/getpro/habr/post_images/872/913/e20/872913e207e550f6e7eb609510fd70f6.png"><br><br>  Et enfin, deux cam√©ras photographiant un objet peuvent interf√©rer.  Fait int√©ressant, dans le cas de la lumi√®re structur√©e, vous pouvez faire scintiller le projecteur et comprendre o√π sont nos points et o√π ils ne le sont pas, mais c'est une histoire distincte et plut√¥t compliqu√©e: <br><img src="https://habrastorage.org/getpro/habr/post_images/c9f/427/3e3/c9f4273e3bf9682c1b6869cbfaaf22b5.png"><br><br>  Vous savez maintenant comment casser FaceID ... <br><br>  Cependant, pour les appareils mobiles, la lumi√®re structur√©e semble √™tre le compromis le plus raisonnable aujourd'hui: <br><img src="https://habrastorage.org/getpro/habr/post_images/cc8/77f/743/cc877f74308b460ca7cd306856ba637a.png"><br>  <i>Source: Les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">entreprises de smartphones se d√©m√®nent pour correspondre aux performances et aux co√ªts des cam√©ras 3D Apple</a></i> <br><br>  Pour la lumi√®re structur√©e, le bon march√© d'un capteur conventionnel est tel que son utilisation dans la plupart des cas est plus que justifi√©e.  Ce qui a donn√© vie √† un grand nombre de startups fonctionnant selon la formule: capteur bon march√© + logiciel complexe = r√©sultat tout √† fait acceptable. <br><br>  Par exemple, notre ancien √©tudiant dipl√¥m√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Maxim Fedyukov</a> , qui est impliqu√© dans la reconstruction 3D depuis 2004, a cr√©√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Texel</a> , dont le produit principal est une plate-forme avec 4 cam√©ras Kinect et un logiciel qui transforme une personne en monument potentiel en 30 secondes.  Eh bien, ou une figurine de bureau.  C'est qui a assez d'argent.  Ou vous pouvez envoyer √† vos amis des photos d'amis bon march√© et joyeuses de votre mod√®le 3D (pour une raison quelconque, le cas le plus populaire pour une raison quelconque).  Maintenant, ils envoient leurs plates-formes et logiciels √† l'√©tranger du Royaume-Uni en Australie: <br><iframe width="560" height="315" src="https://www.youtube.com/embed/VLaZ_jDuZ30" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cr√©ation d'un mod√®le 3D d'une personne en 30 secondes</a></i> <br><br>  En tant que ballerine, je ne peux pas me tenir magnifiquement, donc je ne regarde que pensivement la nageoire d'un requin qui nage: <br><img src="https://habrastorage.org/getpro/habr/post_images/fca/b59/2b2/fcab592b290ca2a9838748bc3ac82ce2.gif"><br>  <i>Source: documents de l'auteur</i> <br><br>  En g√©n√©ral, un nouveau type de capteurs a engendr√© de nouveaux projets artistiques.  En hiver, j'ai vu un film VR assez curieux tourn√© avec Kinect.  Ci-dessous, une visualisation int√©ressante de la danse, √©galement r√©alis√©e avec Kinect (il semble que 4 cam√©ras aient √©t√© utilis√©es), et contrairement √† l'exemple pr√©c√©dent, ils ne se sont pas battus avec le bruit, ils ont plut√¥t ajout√© des d√©tails amusants: <br><img src="https://habrastorage.org/getpro/habr/post_images/cd3/072/e7f/cd3072e7ffef9e111604f9d6e83e640e.gif"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Une performance de danse captur√©e avec un capteur Kinect et visualis√©e avec un logiciel 3D</a></i> <br><br>  Quelles tendances peuvent √™tre observ√©es dans la r√©gion: <br><ul><li>  Comme vous le savez, les capteurs num√©riques des appareils photo modernes sont sensibles au rayonnement infrarouge, vous devez donc utiliser des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">filtres de blocage</a> sp√©ciaux afin que le bruit infrarouge ne g√¢che pas l'image (m√™me la direction de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la prise de vue artistique dans la plage infrarouge</a> appara√Æt, y compris lorsque le filtre est retir√© du capteur).  Cela signifie que d'√©normes sommes d'argent sont investies dans la miniaturisation, une r√©solution accrue et des capteurs moins chers, qui peuvent √™tre utilis√©s comme infrarouges (avec un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">filtre sp√©cial</a> ). <br></li><li>  De m√™me, les algorithmes de traitement des cartes de profondeur s'am√©liorent rapidement, y compris les m√©thodes de filtrage crois√©, lorsque les donn√©es d'un capteur RVB et les donn√©es bruyantes par profondeur vous permettent d'obtenir une tr√®s bonne vid√©o de profondeur ensemble.  Dans le m√™me temps, en utilisant des approches de r√©seau neuronal, il devient possible d'augmenter consid√©rablement la vitesse d'obtention d'un bon r√©sultat. <br></li><li>  Toutes les grandes entreprises travaillent dans ce domaine, en particulier les fabricants de smartphones. <br></li></ul><br>  En cons√©quence: <br><ul><li>  Nous pouvons nous attendre √† une augmentation spectaculaire de la r√©solution et de la pr√©cision du tournage des cam√©ras de profondeur de lumi√®re structur√©e au cours des 5 prochaines ann√©es. <br></li><li>  Il y aura une r√©duction (bien que plus lente) de la consommation d'√©nergie des capteurs mobiles, ce qui simplifiera l'utilisation des capteurs de nouvelle g√©n√©ration dans les smartphones, tablettes et autres appareils mobiles. <br></li></ul><br>  En tout cas, ce que nous voyons maintenant, c'est le d√©but de la technologie.  Les premiers produits de masse sur lesquels le d√©bogage de production et d'utilisation d'un nouveau type de donn√©es inhabituel vient d'√™tre lanc√© - la vid√©o en profondeur. <br><br><h1>  M√©thode 2: cam√©ra de temps de vol </h1><br>  La prochaine fa√ßon d'obtenir de la profondeur est plus int√©ressante.  Il est bas√© sur la mesure du retard lumineux aller-retour (ToF - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Time-of-Flight</a> ).  Comme vous le savez, la vitesse des processeurs modernes est √©lev√©e et la vitesse de la lumi√®re est faible.  Dans un cycle d'horloge du processeur √† 3 GHz, la lumi√®re parvient √† voler √† seulement 10 centim√®tres.  Ou 10 mesures par m√®tre.  Beaucoup de temps, si quelqu'un √©tait engag√© dans l'optimisation de bas niveau.  En cons√©quence, nous installons une source de lumi√®re puls√©e et une cam√©ra sp√©ciale: <br><img src="https://habrastorage.org/getpro/habr/post_images/6e0/565/fc8/6e0565fc82326ab1f3487051f20ef58d.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La cam√©ra Basler Time-of-Flight (ToF)</a></i> <br><br>  En fait, nous devons mesurer le retard avec lequel la lumi√®re revient √† chaque point: <br><img src="https://habrastorage.org/getpro/habr/post_images/26b/fd8/bc8/26bfd8bc85003daa2b45d9dd11dfb31d.png"><img src="https://habrastorage.org/getpro/habr/post_images/4f6/7a5/13d/4f67a513d6cd9fb6e9370d680a28db79.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La cam√©ra Basler Time-of-Flight (ToF)</a></i> <br><br>  Ou, si nous avons plusieurs capteurs avec des temps d'accumulation de charge diff√©rents, alors, connaissant le d√©calage temporel par rapport √† la source pour chaque capteur et la luminosit√© du flash, nous pouvons calculer le d√©calage et, en cons√©quence, la distance √† l'objet, et en augmentant le nombre de capteurs, nous augmentons la pr√©cision: <br><img src="https://habrastorage.org/getpro/habr/post_images/e78/c93/d70/e78c93d70d056347e6e963bb191f3016.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/27f/26f/e8d/27f26fe8d30826c317bbc54687fbe169.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Larry Li Camera Time-of-Flight - An Introduction</a></i> <br><br>  Le r√©sultat est un tel sch√©ma de la cam√©ra avec √©clairage infrarouge LED ou, plus commun√©ment, laser ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VCSEL</a> ): <br><img src="https://habrastorage.org/getpro/habr/post_images/1b8/5cf/e74/1b85cfe7436630ed22abf6f9ec4c0555.png"><br>  <i>Source: Une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tr√®s bonne description de poste de ToF sur allaboutcircuits.com</a></i> <br><br>  Dans le m√™me temps, l'image est obtenue √† une r√©solution assez faible (apr√®s tout, nous devons placer plusieurs capteurs √† c√¥t√© d'eux avec des temps d'interrogation diff√©rents), mais potentiellement avec des FPS √©lev√©s.  Et les probl√®mes se situent principalement aux limites des objets (ce qui est typique pour toutes les cam√©ras de profondeur).  Mais sans les ¬´ombres¬ª typiques de la lumi√®re structur√©e: <br><img src="https://habrastorage.org/getpro/habr/post_images/f25/aac/393/f25aac393d27eab254d2d2062f70aace.gif"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vid√©o Basler AG</a></i> <br><br>  En particulier, c'est ce type de cam√©ra (ToF) qui √† une √©poque a activement test√© Google dans le projet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Google Tango</a> , qui √©tait bien repr√©sent√© dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cette vid√©o</a> .  Le sens √©tait simple - combiner les donn√©es du gyroscope, de l'acc√©l√©rom√®tre, de la cam√©ra RVB et de la cam√©ra de profondeur, cr√©ant une sc√®ne en trois dimensions devant le smartphone: <br><img src="https://habrastorage.org/getpro/habr/post_images/0e5/48d/a33/0e548da33324491beed0083067daf629.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le projet Tango de Google est d√©sormais dimensionn√© pour les smartphones</a></i> <br><br>  Le projet lui-m√™me n'a pas abouti (mon avis √©tait qu'il √©tait quelque peu en avance sur son temps), mais il a cr√©√© des conditions pr√©alables importantes pour cr√©er une vague d'int√©r√™t pour la r√©alit√© augment√©e - et, par cons√©quent, d√©velopper des capteurs qui peuvent fonctionner avec.  Maintenant, toutes ses r√©alisations sont vers√©es dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ARCore</a> de Google. <br><br>  En g√©n√©ral, le volume du march√© des cam√©ras ToF augmente d'environ 30% tous les 3 ans, ce qui est une croissance assez exponentielle, et peu de march√©s se d√©veloppent aussi rapidement: <br><img src="https://habrastorage.org/getpro/habr/post_images/9ae/e45/a34/9aee45a343486d009e472897358a57c6.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Potentiel des cam√©ras √† temps de vol et p√©n√©tration du march√©</a></i> <br><br>  Un moteur s√©rieux du march√© aujourd'hui est le d√©veloppement rapide (et aussi exponentiel) des robots industriels, pour lesquels les cam√©ras ToF sont une solution id√©ale.  Par exemple, si votre robot emballe des bo√Ætes, alors avec une cam√©ra 2D ordinaire, d√©terminer que vous commencez √† bloquer le carton est une t√¢che extr√™mement simple.  Et pour une cam√©ra ToF, il est trivial de ¬´voir¬ª et de la traiter.  Et tr√®s vite.  En cons√©quence, nous voyons un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">boom des cam√©ras ToF industrielles</a> : <br><img width="50%" src="https://habrastorage.org/webt/rg/7k/oh/rg7kohuwwuzhwji6zrqr19a54yy.png"><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/843/1a9/ac6/8431a9ac68acfef82b2f9dc5e5579d32.png"><br><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/c66/2c5/5c1/c662c55c1309b666ef460c5944289fbd.png"><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/5d7/514/fda/5d7514fda4a985c28cbc6695e1a3e27a.png"><br>  Naturellement, cela conduit √©galement √† l'apparition de produits faits maison utilisant des cam√©ras de profondeur.  Par exemple, une cam√©ra de s√©curit√© avec une unit√© vid√©o de nuit et une cam√©ra de profondeur ToF de la soci√©t√© allemande <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PMD Technologies</a> , qui d√©veloppe des cam√©ras 3D depuis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plus de 20 ans</a> : <br><img src="https://habrastorage.org/webt/dj/uz/_m/djuz_mmy6htracd_tgkn_clt698.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La d√©tection de la profondeur du temps de vol 3D apporte de la magie √† la nouvelle cam√©ra Smart Home Lighthouse</a></i> <br><br>  Vous vous souvenez de la cape d'invisibilit√© sous laquelle Harry Potter se cachait? <br><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/4cc/5ac/d00/4cc5acd002df5032104a965cc01ec109.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La cape d'invisibilit√© de Harry Potter obtient une histoire d'origine et pourrait bient√¥t exister dans la vraie vie</a></i> <br><br>  J'ai peur que la cam√©ra allemande le d√©tecte une ou deux fois.  Et il sera difficile de placer un √©cran avec une image devant un tel appareil photo (ce n'est pas un garde distrayant pour vous): <br><img src="https://habrastorage.org/getpro/habr/post_images/af4/649/03f/af464903f5fdbda4fca2c1734f476ec5.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Fragment du film ¬´Mission impossible: protocole fant√¥me¬ª</a></i> <br><br>  Il semble que pour les nouvelles cam√©ras de vid√©osurveillance, la magie non enfantine de Poudlard sera n√©cessaire pour les tromper avec une cam√©ra de profondeur ToF, capable de filmer une telle vid√©o dans l'obscurit√© totale: <br><img width="25%" src="https://habrastorage.org/getpro/habr/post_images/b34/f9f/884/b34f9f8844825387a528da8d630a69cb.gif"><br>  Faire semblant d'√™tre un mur, un √©cran et d'autres moyens de se prot√©ger du fait que la cam√©ra ToF + RGB combin√©e d√©tectera un objet √©tranger devient techniquement cardinalement plus difficile. <br><br>  Une autre application pacifique massive pour les cam√©ras de profondeur est la reconnaissance des gestes.  Dans un avenir proche, vous pouvez vous attendre √† des t√©l√©viseurs, des consoles et des aspirateurs robotiques qui seront capables de percevoir non seulement les commandes vocales comme des haut-parleurs intelligents, mais aussi les imprudents "nettoyez-le!"  d'un geste de la main.  Ensuite, la t√©l√©commande (alias paresseux) de la Smart TV deviendra compl√®tement inutile et la science-fiction prendra vie.  En cons√©quence, ce qui <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©tait fantastique en 2002</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">est devenu exp√©rimental en 2013</a> et, enfin, en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">s√©rie en 2019</a> (alors que les gens ne sauront pas qu'il y a une cam√©ra de profondeur √† l'int√©rieur, <s>quelle diff√©rence cela fait-il, comment fonctionne cette magie?</s> ): <br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/9e6/bd8/2bd/9e6bd82bda38b0c8bb9cb939afee76a7.png"><img width="44%" src="https://habrastorage.org/getpro/habr/post_images/2a8/dcc/b9c/2a8dccb9cc86e1fe8ad57c613432e146.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exp√©riences</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">produit</a></i> <br><br>  Et la gamme compl√®te d'applications est encore plus large, bien s√ªr: <br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/66d/fc8/23d/66dfc823dd2619f52003f3dbd92bbf34.gif"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/0c5/819/751/0c5819751f59b53a33f4b0d37efb1caf.gif"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/7b0/266/402/7b02664025b9c9c4fbab5b5825822a2b.gif"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vid√©o des capteurs de profondeur de Terabee</a></i> <i>(au fait, quel</i> <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">type de</a></i> <i><b>souris</b> courent-ils sur le sol pour 2 et 3 vid√©os? Les voir? Je plaisante, c'est de la poussi√®re dans l'air - les frais pour la petite taille du capteur et la proximit√© de la source de lumi√®re avec le capteur)</i> <br><br>  Soit dit en passant - dans les c√©l√®bres ¬´magasins sans caissiers¬ª d'Amazon Go, il y a aussi de nombreuses cam√©ras sous le plafond: <br><img src="https://habrastorage.org/webt/ca/k9/ds/cak9ds3gc_8-a9n2tgwxdjhvpg0.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√Ä l'int√©rieur du d√©panneur sans contr√¥le, aliment√© par la surveillance d'Amazon</a></i> <br><br>  De plus, comme l'√©crit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TechCrunch</a> : <i>"Ils sont augment√©s par des <b>cam√©ras de d√©tection de profondeur</b> distinctes (en utilisant une technique de <b>temps de vol</b> , ou j'ai compris de Kumar) qui se fondent dans l'arri√®re-plan comme le reste, tout noir mat."</i>  C'est-√†-dire que le miracle de d√©terminer de quelle √©tag√®re le yaourt est tir√© est fourni, entre autres, par les myst√©rieuses cam√©ras ToF noires mates (une bonne question, sont-elles sur la photo): <br><img src="https://habrastorage.org/webt/25/qj/g1/25qjg1s8_o5uyjmoyv9r-haadms.png"><br><br>  Malheureusement, les informations directes sont souvent difficiles √† trouver.  Mais il y en a un indirect.  Par exemple, il y avait une soci√©t√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Softkinetic</a> , qui depuis 2007 d√©veloppe des cam√©ras ToF.  8 ans plus tard, ils ont √©t√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">achet√©s par Sony</a> (qui, soit dit en passant, est pr√™t √† conqu√©rir de nouveaux march√©s sous la marque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sony Depthsensing</a> ).  Ainsi, l'un des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">meilleurs employ√©s de</a> Softkinetic <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">travaille</a> d√©sormais uniquement sur Amazon Go.  Quelle co√Øncidence!  Dans quelques ann√©es, lorsque la technologie sera mise en place et les principaux brevets d√©pos√©s, les d√©tails seront tr√®s probablement r√©v√©l√©s. <br><br>  Eh bien, comme d'habitude, les Chinois s'enflamment.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pico Zense</a> , par exemple, a pr√©sent√© au CES 2019 une gamme tr√®s impressionnante de cam√©ras ToF, y compris pour une utilisation en ext√©rieur: <br><img src="https://habrastorage.org/getpro/habr/post_images/d8c/c1c/545/d8cc1c545595e42cdab55a1a790384c9.png"><br>  Ils promettent une r√©volution partout.  Les wagons seront plus denses en raison du chargement automatis√©, les distributeurs automatiques de billets seront plus s√ªrs, gr√¢ce aux cam√©ras de profondeur dans chacun, la navigation des robots deviendra plus facile et plus pr√©cise, les gens (et, surtout, les enfants!) Seront compt√©s un ordre de grandeur mieux dans le flux, de nouveaux simulateurs de fitness appara√Ætront c la capacit√© de contr√¥ler l'exactitude des exercices sans instructeur, et ainsi de suite.  Naturellement, les cam√©ras chinoises bon march√© d'une profondeur nouvelle g√©n√©ration sont d√©j√† pr√™tes pour toute cette magnificence.  Prenez et construisez! <br><br>  Fait int√©ressant, la derni√®re s√©rie Huawei P30 Pro dispose d'un capteur ToF √† c√¥t√© des cam√©ras principales, c'est-√†-dire  Huawei, qui souffre depuis longtemps, est mieux √† m√™me de faire fabriquer des capteurs de lumi√®re structur√©s frontaux par Apple et, semble-t-il, avec plus de succ√®s Google (Project Tango, qui a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©t√© ferm√©</a> ) a mis en place une cam√©ra √† c√¥t√© des principales cam√©ras ToF: <br><img width="60%" src="https://habrastorage.org/getpro/habr/post_images/fc9/eaf/763/fc9eaf76396c966eeab065ca641e8543.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">revue de la nouvelle technologie Ars Technica Huawei √† fin mars 2019</a></i> <br><br>  Les d√©tails de l'utilisation, bien s√ªr, ne sont pas divulgu√©s, mais en plus d'acc√©l√©rer la mise au point (ce qui est important pour les trois appareils photo principaux avec des objectifs diff√©rents), ce capteur peut √™tre utilis√© pour augmenter la qualit√© du flou de l'arri√®re-plan des photos (simulant une faible <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">profondeur de champ</a> ). <br><br>  Il est √©galement √©vident que la prochaine g√©n√©ration de capteurs de profondeur √† c√¥t√© des cam√©ras principales sera utilis√©e dans les applications AR, ce qui augmentera la pr√©cision de l'AR du niveau actuel "cool, mais souvent buggy" √† un niveau de travail de masse.  Et, √©videmment, √† la lumi√®re des succ√®s chinois, la grande question est de savoir combien Google voudra prendre en charge le mat√©riel r√©volutionnaire chinois dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ARCore</a> .  Les guerres de brevets peuvent ralentir consid√©rablement le march√© des technologies.  Le d√©veloppement de cette histoire dramatique, nous verrons litt√©ralement dans les deux prochaines ann√©es. <br><br><h1>  Sous-totaux </h1><br>  Il y a environ 25 ans, lorsque les premi√®res portes automatiques sont apparues, j'ai personnellement observ√© comment des oncles tout √† fait respectables acc√©l√©raient p√©riodiquement devant de telles portes.  R√©ussit √† s'ouvrir ou n'a pas le temps?  Elle est grande, lourde, en verre!  √Ä propos de la m√™me chose que j'ai observ√©e lors d'une tourn√©e de professeurs tout √† fait respectables dans une usine automatique en Chine r√©cemment.  Ils ont pris un peu de retard sur le groupe pour voir ce qui se passerait si vous vous teniez devant le robot, transportant paisiblement des pi√®ces et jouant une m√©lodie silencieuse et agr√©able en chemin.  Moi aussi, je me repens, je n'ai pas pu r√©sister ... Tu sais, √ßa s'arr√™te!  Peut-√™tre en douceur.  Peut-√™tre en tant que mort.  Les capteurs de profondeur fonctionnent! <br><img src="https://habrastorage.org/webt/6z/h_/xm/6zh_xmrkvzfljpw0hkymlngojrs.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√Ä l'int√©rieur du nouveau campus de Huawei Technology</a></i> <br><br>  L'h√¥tel a √©galement fonctionn√© comme robot de nettoyage, qui ressemblait √† ceci: <br><img src="https://habrastorage.org/webt/di/rm/bc/dirmbceths3wfdn1sbtswf9tduw.png"><br>  En m√™me temps, ils √©taient plus intimid√©s que les robots √† l'usine.  Pas aussi dur que dans l' <b><i>inhumain</i></b> dans tous les sens de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dynamique</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bosstown</a> , bien s√ªr.  Mais j'ai personnellement vu comment ils se sont lev√©s sur la route, le robot a essay√© de contourner une personne, la personne a boug√©, bloquant la route ... Une sorte de chat et de souris.  En g√©n√©ral, il semble que lorsque des v√©hicules sans pilote apparaissent sur les routes, la premi√®re fois, ils seront coup√©s plus souvent que d'habitude ... Oh, les gens-les gens ... Hmmm ... Cependant, nous √©tions distraits. <br><br>  R√©sumant les points cl√©s: <br><ul><li>  En raison d'un autre principe de fonctionnement, nous pouvons positionner la source de lumi√®re dans la cam√©ra ToF aussi pr√®s que possible du capteur (m√™me sous le m√™me objectif).  De plus, de nombreux mod√®les industriels ont des LED situ√©es autour du capteur.  En cons√©quence, les ¬´ombres¬ª sur la carte de profondeur sont radicalement r√©duites, voire disparaissent.  C'est-√†-dire  travail simplifi√© avec des objets g√©om√©triques complexes, ce qui est important pour les robots industriels. <br></li><li>  √âtant donn√© que l'√©clairage puls√© reste g√©n√©ralement infrarouge - tous les inconv√©nients de la cam√©ra infrarouge d√©crits dans la derni√®re section sont pr√©serv√©s: exposition au soleil, difficult√©s lorsque deux cam√©ras fonctionnent c√¥te √† c√¥te, etc.  Cependant, les robots industriels fonctionnent souvent √† l'int√©rieur et des cam√©ras avec √©clairage laser sont en cours de d√©veloppement. <br></li><li>  H√©las, les capteurs ToF sont plus difficiles √† "suivre" l'am√©lioration globale des capteurs des cam√©ras RVB, donc leur d√©veloppement est plus lent, mais √©tonnamment confiant et les nouvelles concernant l'introduction des cam√©ras ToF sont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TR√àS nombreuses et ce qui (l√†) n'est pas l√†</a> (seulement dans les smartphones a annonc√© l'int√©gration des capteurs et Samsung, Google Pixel et Sony Xperia ...). <br></li><li>  Le nouveau Sony promet que 2 cam√©ras sur 8 cam√©ras de t√©l√©phone (!!!) seront des cam√©ras de profondeur ToF (!), C'est-√†-dire  cam√©ras de profondeur seront des deux c√¥t√©s du t√©l√©phone: <img src="https://habrastorage.org/getpro/habr/post_images/5cb/319/b6a/5cb319b6ade6cec9232d201201d15a60.png"><br>  <i>Source: Le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">t√©l√©phone Sony Hexa-cam r√©v√®le les sp√©cifications de l'appareil photo</a></i> <br></li><li>  En cons√©quence, <b>nous trouverons beaucoup de choses int√©ressantes dans ce domaine m√™me dans l'ann√©e √† venir!</b>  Et l'ann√©e prochaine, jusqu'√† 20% des nouveaux t√©l√©phones seront √©quip√©s de cam√©ras de profondeur (Structured Light + ToF).  √âtant donn√© qu'en 2017, seul Apple √©tait sur le march√© dans un splendide isolement avec ¬´30 000 points¬ª, et maintenant ils n'en mettent pas moins de 300 000, le sujet s'est clairement bien pass√©: <br><img src="https://habrastorage.org/getpro/habr/post_images/463/6e5/971/4636e597115004d4a161719cfcafbe9d.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">croissance limit√©e du march√© de la d√©tection 3D de smartphones en 2019;</a></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apple sera le principal promoteur de la croissance en 2020</a></i> <br></li></ul><br>  Vous doutez encore de la r√©volution en cours? <br><br>  C'√©tait la premi√®re partie!  Une comparaison g√©n√©rale sera dans la seconde. <br><br>  Dans la prochaine s√©rie, attendez: <br><ul><li>  M√©thode 3, classique: profondeur de la st√©r√©o; <br></li><li>  M√©thode 4, nouvelle g√©n√©ration: profondeur des pl√©noptiques; <br></li><li>  M√©thode 5, √† croissance rapide: les lidars, y compris les lidars √† l'√©tat solide; <br></li><li>  Quelques probl√®mes de traitement vid√©o en profondeur; <br></li><li>  Et enfin, une br√®ve comparaison des 5 m√©thodes et des conclusions g√©n√©rales. <br></li></ul><br><br>  <b><s>Carthage doit √™tre bris√©e ... L'</s> ensemble de la vid√©o sera en trois dimensions d'ici la fin du si√®cle!</b> <br><br>  Restez √† l'√©coute!  (Si j'ai assez de temps, je d√©crirai de nouvelles cam√©ras, y compris des tests de Kinect frais, d'ici la fin de l'ann√©e.) <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2e partie</a> <br><br><div class="spoiler">  <b class="spoiler_title">Remerciements</b> <div class="spoiler_text">  Je remercie chaleureusement: <br><ul><li>  Laboratoire d'infographie VMK Universit√© d'√âtat de Moscou  MV Lomonosov pour sa contribution au d√©veloppement de l'infographie en Russie en g√©n√©ral et au travail avec les cam√©ras de profondeur en particulier, <br></li><li>  Microsoft, Apple, Huawei et Amazon pour des produits bas√©s sur une cam√©ra de grande profondeur, <br></li><li>  Texel pour le d√©veloppement de produits russes de haute technologie avec des cam√©ras de profondeur, <br></li><li>  personnellement Konstantin Kozhemyakov, qui a fait beaucoup pour rendre cet article meilleur et plus visuel, <br></li><li>  et, enfin, un grand merci √† Roman Kazantsev, Eugene Lyapustin, Egor Sklyarov, Maxim Fedyukov, Nikolai Oplachko et Ivan Molodetsky pour un grand nombre de commentaires judicieux et de corrections qui ont rendu ce texte bien meilleur! <br></li></ul><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr457524/">https://habr.com/ru/post/fr457524/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr457512/index.html">R√©plication logique entre les versions de PostgreSQL</a></li>
<li><a href="../fr457514/index.html">Nevanger</a></li>
<li><a href="../fr457516/index.html">√âcrire un mod√®le de menace</a></li>
<li><a href="../fr457518/index.html">Plasma Cash Chain comme solution au trilemme d'√©volutivit√© de la blockchain</a></li>
<li><a href="../fr457522/index.html">Augmentez votre service de liste de diffusion ou utilisez des solutions toutes faites? Ce que j'ai appris pendant 5 ans chez UniSender</a></li>
<li><a href="../fr457526/index.html">Les m√©dias techniques comme bazar</a></li>
<li><a href="../fr457532/index.html">Il est grand temps de faire partie d'un projet open source</a></li>
<li><a href="../fr457534/index.html">Versions certifi√©es - le r√¢teau que nous choisissons</a></li>
<li><a href="../fr457538/index.html">Comment puis-je utiliser des machines virtuelles Yandex.Cloud interrompues et √©conomiser sur la r√©solution de probl√®mes √† grande √©chelle</a></li>
<li><a href="../fr457540/index.html">Intel Optane DC Persistent Memory, un an plus tard</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
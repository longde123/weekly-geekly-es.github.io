<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòä üåô üòé Competi√ß√£o de risco padr√£o de cr√©dito residencial Kaggle - an√°lise de dados e modelos preditivos simples üêà üíÜüèΩ üìç</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="No festival de dados 2 em Minsk, Vladimir Iglovikov, engenheiro de vis√£o de m√°quina da Lyft, observou perfeitamente que a melhor maneira de aprender D...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Competi√ß√£o de risco padr√£o de cr√©dito residencial Kaggle - an√°lise de dados e modelos preditivos simples</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414613/">  No festival de dados 2 em Minsk, Vladimir Iglovikov, engenheiro de vis√£o de m√°quina da Lyft, observou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">perfeitamente</a> que a melhor maneira de aprender Data Science √© participar de competi√ß√µes, executar solu√ß√µes de outras pessoas, combin√°-las, obter resultados e mostrar seu trabalho.  Na verdade, dentro da estrutura desse paradigma, decidi examinar mais de perto a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">competi√ß√£o de</a> avalia√ß√£o de risco de cr√©dito ao cr√©dito imobili√°rio e explicar (para iniciantes, cientistas e, antes de tudo, para mim) como analisar adequadamente esses conjuntos de dados e criar modelos para eles. <br><br><img src="https://habrastorage.org/webt/iv/ji/-t/ivji-tusvam8d05dqef8wjbmbye.png"><br><a name="habracut"></a><br>  (foto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">daqui</a> ) <br><br><img src="https://habrastorage.org/webt/xc/er/pe/xcerpefrjvrblmubhxyeljevcie.png" width="250" align="right">  O Grupo Home Credit Group √© um grupo de bancos e organiza√ß√µes de cr√©dito n√£o banc√°rio que conduz opera√ß√µes em 11 pa√≠ses (incluindo a R√∫ssia como Home Credit and Finance Bank LLC).  O objetivo da competi√ß√£o √© criar uma metodologia para avaliar a capacidade credit√≠cia dos tomadores de empr√©stimos que n√£o possuem hist√≥rico de cr√©dito.  O que parece bastante nobre - os mutu√°rios dessa categoria geralmente n√£o conseguem cr√©dito do banco e s√£o for√ßados a recorrer a golpistas e microempr√©stimos.  √â interessante que o cliente n√£o defina requisitos de transpar√™ncia e interpretabilidade do modelo (como √© geralmente o caso dos bancos), voc√™ pode usar qualquer coisa, mesmo uma rede neural. <br><br>  A amostra de treinamento consiste em mais de 300 mil registros, existem muitos sinais - 122, entre os quais muitos categ√≥ricos (n√£o num√©ricos).  As placas descrevem o mutu√°rio em detalhes suficientes, at√© o material do qual s√£o feitas as paredes de sua casa.  Parte dos dados est√° contida em 6 tabelas adicionais (dados da ag√™ncia de cr√©dito, saldo do cart√£o de cr√©dito e empr√©stimos anteriores); esses dados tamb√©m devem ser processados ‚Äã‚Äãde alguma forma e carregados nas principais. <br><br>  A competi√ß√£o parece uma tarefa de classifica√ß√£o padr√£o (1 no campo TARGET significa alguma dificuldade com pagamentos, 0 significa nenhuma dificuldade).  No entanto, n√£o √© 0/1 que deve ser previsto, mas a probabilidade de problemas (que, ali√°s, podem ser facilmente resolvidos pelos m√©todos de previs√£o de probabilidade predict_proba que todos os modelos complexos possuem). <br><br>  √Ä primeira vista, o conjunto de dados √© bastante padr√£o para tarefas de aprendizado de m√°quina, os organizadores ofereceram um grande pr√™mio de US $ 70 mil. Como resultado, mais de 2.600 equipes est√£o participando da competi√ß√£o hoje, e a batalha √© em mil√©simos de um por cento.  No entanto, por outro lado, essa popularidade significa que o conjunto de dados foi estudado para cima e para baixo e muitos kernels foram criados com o bom EDA (Exploratory Data Analisys - pesquisa e an√°lise de dados na rede, incluindo gr√°ficos), Engenharia de recursos (trabalho com atributos) e com modelos interessantes.  (O kernel √© um exemplo de trabalho com um conjunto de dados que qualquer um pode criar para mostrar seu trabalho a outros malabaristas.) <br><br>  Os n√∫cleos merecem aten√ß√£o: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">EDA com uma descri√ß√£o detalhada para iniciantes e modelos simples</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Deep EDA com Plotly Package + Upload de dados do Bureau</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Agrad√°vel EDA com Seaborn Package</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">An√°lise comparativa de tomadores de problemas e inadimpl√™ncia</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LightGBM de 15 linhas em tr√™s sinais com velocidade final de 0,714</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">An√°lise de sinais segundo ag√™ncias de cr√©dito</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Processando add.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mesas + LightGBM</a> </li></ul><br>  Para trabalhar com dados, geralmente √© recomendado o seguinte plano, que tentaremos seguir. <br><br><ol><li>  Entendendo o problema e familiarizando-se com os dados </li><li>  Limpeza e formata√ß√£o de dados </li><li>  EDA </li><li>  Modelo base </li><li>  Melhoria do modelo </li><li>  Interpreta√ß√£o do modelo </li></ol><br>  Nesse caso, √© necess√°rio levar em considera√ß√£o o fato de que os dados s√£o bastante extensos e n√£o podem ser sobrecarregados imediatamente, faz sentido agir em etapas. <br><br>  Vamos come√ßar importando as bibliotecas que precisamos na an√°lise para trabalhar com dados na forma de tabelas, criar gr√°ficos e trabalhar com matrizes. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns %matplotlib inline</code> </pre> <br>  Fa√ßa o download dos dados.  Vamos ver o que todos n√≥s temos.  Este local no diret√≥rio "../input/", a prop√≥sito, est√° conectado ao requisito de colocar seus kernels no Kaggle. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os PATH=<span class="hljs-string"><span class="hljs-string">"../input/"</span></span> print(os.listdir(PATH))</code> </pre> <br> <code>['application_test.csv', 'application_train.csv', 'bureau.csv', 'bureau_balance.csv', 'credit_card_balance.csv', 'HomeCredit_columns_description.csv', 'installments_payments.csv', 'POS_CASH_balance.csv', 'previous_application.csv']</code> <br> <br>  Existem 8 tabelas com dados (sem contar a tabela HomeCredit_columns_description.csv, que cont√©m uma descri√ß√£o dos campos), que s√£o interconectadas da seguinte maneira: <br><br><img src="https://habrastorage.org/webt/vn/yr/84/vnyr84vhzozgnfinu2to2tyhlp8.png"><br><br>  application_train / application_test: dados mestre, o mutu√°rio √© identificado pelo campo SK_ID_CURR <br>  bureau: dados sobre empr√©stimos anteriores de outras institui√ß√µes de cr√©dito de uma ag√™ncia de cr√©dito <br>  bureau_balance: dados mensais sobre empr√©stimos anteriores.  Cada linha √© o m√™s de utiliza√ß√£o do empr√©stimo <br>  previous_application: solicita√ß√µes anteriores para empr√©stimos em Cr√©dito √† habita√ß√£o, cada uma possui um campo exclusivo SK_ID_PREV <br>  POS_CASH_BALANCE: dados mensais sobre empr√©stimos em cr√©dito imobili√°rio, com emiss√£o de caixa e empr√©stimos para compra de mercadorias <br>  credit_card_balance: dados mensais do saldo do cart√£o de cr√©dito em Cr√©dito √† habita√ß√£o <br>  parcelamentos_pagamento: hist√≥rico de pagamentos de empr√©stimos anteriores no cr√©dito residencial. <br><br>  Vamos primeiro focar na principal fonte de dados e ver quais informa√ß√µes podem ser extra√≠das dela e quais modelos construir.  Fa√ßa o download dos dados b√°sicos. <br><br><ul><li>  app_train = pd.read_csv (PATH + 'application_train.csv',) </li><li>  app_test = pd.read_csv (PATH + 'application_test.csv',) </li><li>  print ("formato do conjunto de treinamento:", app_train.shape) </li><li>  print ("formato de amostra de teste:", app_test.shape) </li><li>  formato de amostra de treinamento: (307511, 122) </li><li>  formato de amostra de teste: (48744, 121) </li></ul><br>  No total, temos 307 mil registros e 122 sinais na amostra de treinamento e 49 mil registros e 121 sinais no teste.  Obviamente, a discrep√¢ncia se deve ao fato de n√£o haver um atributo de destino TARGET na amostra de teste, e n√≥s a preveremos. <br><br>  Vamos dar uma olhada nos dados <br><br><pre> <code class="python hljs">pd.set_option(<span class="hljs-string"><span class="hljs-string">'display.max_columns'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) <span class="hljs-comment"><span class="hljs-comment">#  pandas     app_train.head()</span></span></code> </pre> <br><br><img src="https://habrastorage.org/webt/xo/yc/rg/xoycrgiodfhonfrjbt50ncthrls.png"><br>  (primeiras 8 colunas mostradas) <br><br>  √â muito dif√≠cil assistir a dados nesse formato.  Vejamos a lista de colunas: <br><br> <code>app_train.info(max_cols=122) <br> &lt;class 'pandas.core.frame.DataFrame'&gt; <br> RangeIndex: 307511 entries, 0 to 307510 <br> Data columns (total 122 columns): <br> SK_ID_CURR 307511 non-null int64 <br> TARGET 307511 non-null int64 <br> NAME_CONTRACT_TYPE 307511 non-null object <br> CODE_GENDER 307511 non-null object <br> FLAG_OWN_CAR 307511 non-null object <br> FLAG_OWN_REALTY 307511 non-null object <br> CNT_CHILDREN 307511 non-null int64 <br> AMT_INCOME_TOTAL 307511 non-null float64 <br> AMT_CREDIT 307511 non-null float64 <br> AMT_ANNUITY 307499 non-null float64 <br> AMT_GOODS_PRICE 307233 non-null float64 <br> NAME_TYPE_SUITE 306219 non-null object <br> NAME_INCOME_TYPE 307511 non-null object <br> NAME_EDUCATION_TYPE 307511 non-null object <br> NAME_FAMILY_STATUS 307511 non-null object <br> NAME_HOUSING_TYPE 307511 non-null object <br> REGION_POPULATION_RELATIVE 307511 non-null float64 <br> DAYS_BIRTH 307511 non-null int64 <br> DAYS_EMPLOYED 307511 non-null int64 <br> DAYS_REGISTRATION 307511 non-null float64 <br> DAYS_ID_PUBLISH 307511 non-null int64 <br> OWN_CAR_AGE 104582 non-null float64 <br> FLAG_MOBIL 307511 non-null int64 <br> FLAG_EMP_PHONE 307511 non-null int64 <br> FLAG_WORK_PHONE 307511 non-null int64 <br> FLAG_CONT_MOBILE 307511 non-null int64 <br> FLAG_PHONE 307511 non-null int64 <br> FLAG_EMAIL 307511 non-null int64 <br> OCCUPATION_TYPE 211120 non-null object <br> CNT_FAM_MEMBERS 307509 non-null float64 <br> REGION_RATING_CLIENT 307511 non-null int64 <br> REGION_RATING_CLIENT_W_CITY 307511 non-null int64 <br> WEEKDAY_APPR_PROCESS_START 307511 non-null object <br> HOUR_APPR_PROCESS_START 307511 non-null int64 <br> REG_REGION_NOT_LIVE_REGION 307511 non-null int64 <br> REG_REGION_NOT_WORK_REGION 307511 non-null int64 <br> LIVE_REGION_NOT_WORK_REGION 307511 non-null int64 <br> REG_CITY_NOT_LIVE_CITY 307511 non-null int64 <br> REG_CITY_NOT_WORK_CITY 307511 non-null int64 <br> LIVE_CITY_NOT_WORK_CITY 307511 non-null int64 <br> ORGANIZATION_TYPE 307511 non-null object <br> EXT_SOURCE_1 134133 non-null float64 <br> EXT_SOURCE_2 306851 non-null float64 <br> EXT_SOURCE_3 246546 non-null float64 <br> APARTMENTS_AVG 151450 non-null float64 <br> BASEMENTAREA_AVG 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_AVG 157504 non-null float64 <br> YEARS_BUILD_AVG 103023 non-null float64 <br> COMMONAREA_AVG 92646 non-null float64 <br> ELEVATORS_AVG 143620 non-null float64 <br> ENTRANCES_AVG 152683 non-null float64 <br> FLOORSMAX_AVG 154491 non-null float64 <br> FLOORSMIN_AVG 98869 non-null float64 <br> LANDAREA_AVG 124921 non-null float64 <br> LIVINGAPARTMENTS_AVG 97312 non-null float64 <br> LIVINGAREA_AVG 153161 non-null float64 <br> NONLIVINGAPARTMENTS_AVG 93997 non-null float64 <br> NONLIVINGAREA_AVG 137829 non-null float64 <br> APARTMENTS_MODE 151450 non-null float64 <br> BASEMENTAREA_MODE 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_MODE 157504 non-null float64 <br> YEARS_BUILD_MODE 103023 non-null float64 <br> COMMONAREA_MODE 92646 non-null float64 <br> ELEVATORS_MODE 143620 non-null float64 <br> ENTRANCES_MODE 152683 non-null float64 <br> FLOORSMAX_MODE 154491 non-null float64 <br> FLOORSMIN_MODE 98869 non-null float64 <br> LANDAREA_MODE 124921 non-null float64 <br> LIVINGAPARTMENTS_MODE 97312 non-null float64 <br> LIVINGAREA_MODE 153161 non-null float64 <br> NONLIVINGAPARTMENTS_MODE 93997 non-null float64 <br> NONLIVINGAREA_MODE 137829 non-null float64 <br> APARTMENTS_MEDI 151450 non-null float64 <br> BASEMENTAREA_MEDI 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_MEDI 157504 non-null float64 <br> YEARS_BUILD_MEDI 103023 non-null float64 <br> COMMONAREA_MEDI 92646 non-null float64 <br> ELEVATORS_MEDI 143620 non-null float64 <br> ENTRANCES_MEDI 152683 non-null float64 <br> FLOORSMAX_MEDI 154491 non-null float64 <br> FLOORSMIN_MEDI 98869 non-null float64 <br> LANDAREA_MEDI 124921 non-null float64 <br> LIVINGAPARTMENTS_MEDI 97312 non-null float64 <br> LIVINGAREA_MEDI 153161 non-null float64 <br> NONLIVINGAPARTMENTS_MEDI 93997 non-null float64 <br> NONLIVINGAREA_MEDI 137829 non-null float64 <br> FONDKAPREMONT_MODE 97216 non-null object <br> HOUSETYPE_MODE 153214 non-null object <br> TOTALAREA_MODE 159080 non-null float64 <br> WALLSMATERIAL_MODE 151170 non-null object <br> EMERGENCYSTATE_MODE 161756 non-null object <br> OBS_30_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DEF_30_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> OBS_60_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DEF_60_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DAYS_LAST_PHONE_CHANGE 307510 non-null float64 <br> FLAG_DOCUMENT_2 307511 non-null int64 <br> FLAG_DOCUMENT_3 307511 non-null int64 <br> FLAG_DOCUMENT_4 307511 non-null int64 <br> FLAG_DOCUMENT_5 307511 non-null int64 <br> FLAG_DOCUMENT_6 307511 non-null int64 <br> FLAG_DOCUMENT_7 307511 non-null int64 <br> FLAG_DOCUMENT_8 307511 non-null int64 <br> FLAG_DOCUMENT_9 307511 non-null int64 <br> FLAG_DOCUMENT_10 307511 non-null int64 <br> FLAG_DOCUMENT_11 307511 non-null int64 <br> FLAG_DOCUMENT_12 307511 non-null int64 <br> FLAG_DOCUMENT_13 307511 non-null int64 <br> FLAG_DOCUMENT_14 307511 non-null int64 <br> FLAG_DOCUMENT_15 307511 non-null int64 <br> FLAG_DOCUMENT_16 307511 non-null int64 <br> FLAG_DOCUMENT_17 307511 non-null int64 <br> FLAG_DOCUMENT_18 307511 non-null int64 <br> FLAG_DOCUMENT_19 307511 non-null int64 <br> FLAG_DOCUMENT_20 307511 non-null int64 <br> FLAG_DOCUMENT_21 307511 non-null int64 <br> AMT_REQ_CREDIT_BUREAU_HOUR 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_DAY 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_WEEK 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_MON 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_QRT 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_YEAR 265992 non-null float64 <br> dtypes: float64(65), int64(41), object(16) <br> memory usage: 286.2+ MB</code> <br> <br>  Lembre-se de anota√ß√µes detalhadas por campo no arquivo HomeCredit_columns_description.  Como voc√™ pode ver nas informa√ß√µes, parte dos dados est√° incompleta e parte √© categ√≥rica, eles s√£o exibidos como objeto.  A maioria dos modelos n√£o funciona com esses dados, teremos que fazer algo com eles.  Com isso, a an√°lise inicial pode ser considerada conclu√≠da, iremos diretamente para a EDA <br><br><h2>  An√°lise Explorat√≥ria de Dados ou Minera√ß√£o de Dados Prim√°rios </h2><br>  No processo da EDA, contamos as estat√≠sticas b√°sicas e desenhamos gr√°ficos para encontrar tend√™ncias, anomalias, padr√µes e relacionamentos nos dados.  O objetivo da EDA √© descobrir o que os dados podem dizer.  Normalmente, a an√°lise vai de cima para baixo - de uma vis√£o geral ao estudo de zonas individuais que atraem aten√ß√£o e podem ser de interesse.  Posteriormente, esses achados podem ser utilizados na constru√ß√£o do modelo, na sele√ß√£o de recursos para ele e em sua interpreta√ß√£o. <br><br><h3>  Distribui√ß√£o vari√°vel alvo </h3><br><pre> <code class="python hljs">app_train.TARGET.value_counts()</code> </pre> <br> <code>0 282686 <br> 1 24825 <br> Name: TARGET, dtype: int64</code> <br> <br><pre> <code class="python hljs">plt.style.use(<span class="hljs-string"><span class="hljs-string">'fivethirtyeight'</span></span>) plt.rcParams[<span class="hljs-string"><span class="hljs-string">"figure.figsize"</span></span>] = [<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>]‚Äã plt.hist(app_train.TARGET) plt.show()</code> </pre> <br><img src="https://habrastorage.org/webt/xm/rd/ch/xmrdchcab8eqbwt2p1pie4jmaeu.png"><br><br>  Deixe-me lembr√°-lo de que 1 significa problemas de qualquer tipo com retorno, 0 significa que n√£o h√° problemas.  Como voc√™ pode ver, principalmente os mutu√°rios n√£o t√™m problemas com o reembolso, a parcela problem√°tica √© de cerca de 8%.  Isso significa que as classes n√£o s√£o equilibradas e isso pode precisar ser levado em considera√ß√£o ao criar o modelo. <br><br><h3>  Pesquisa de dados ausentes </h3><br>  Vimos que a falta de dados √© bastante substancial.  Vamos ver com mais detalhes onde e o que est√° faltando. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      def missing_values_table(df): #   mis_val = df.isnull().sum() #    mis_val_percent = 100 * df.isnull().sum() / len(df) #    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1) #   mis_val_table_ren_columns = mis_val_table.rename( columns = {0 : 'Missing Values', 1 : '% of Total Values'}) #    mis_val_table_ren_columns = mis_val_table_ren_columns[ mis_val_table_ren_columns.iloc[:,1] != 0].sort_values( '% of Total Values', ascending=False).round(1) #  print ("   " + str(df.shape[1]) + " .\n" " " + str(mis_val_table_ren_columns.shape[0]) + "    .") #     return mis_val_table_ren_columns missing_values = missing_values_table(app_train) missing_values.head(10)</span></span></code> </pre> <br><br> <code>   122 . <br>  67    .</code> <br> <img src="https://habrastorage.org/webt/oa/jm/tp/oajmtpuvkymt4asczwqmhqziria.png"><br><br>  Em formato gr√°fico: <br><br><pre> <code class="python hljs">plt.style.use(<span class="hljs-string"><span class="hljs-string">'seaborn-talk'</span></span>)‚Äã fig = plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">18</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>)) miss_train = pd.DataFrame((app_train.isnull().sum())*<span class="hljs-number"><span class="hljs-number">100</span></span>/app_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]).reset_index() miss_test = pd.DataFrame((app_test.isnull().sum())*<span class="hljs-number"><span class="hljs-number">100</span></span>/app_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]).reset_index() miss_train[<span class="hljs-string"><span class="hljs-string">"type"</span></span>] = <span class="hljs-string"><span class="hljs-string">""</span></span> miss_test[<span class="hljs-string"><span class="hljs-string">"type"</span></span>] = <span class="hljs-string"><span class="hljs-string">""</span></span> missing = pd.concat([miss_train,miss_test],axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) ax = sns.pointplot(<span class="hljs-string"><span class="hljs-string">"index"</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,data=missing,hue=<span class="hljs-string"><span class="hljs-string">"type"</span></span>) plt.xticks(rotation =<span class="hljs-number"><span class="hljs-number">90</span></span>,fontsize =<span class="hljs-number"><span class="hljs-number">7</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">"    "</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">"  %"</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">""</span></span>)</code> </pre> <br><br><img src="https://habrastorage.org/webt/iv/fc/ib/ivfcibv85aaktlxybl8bps2vurw.png"><br><br>  Existem muitas respostas para a pergunta "o que fazer com tudo isso".  Voc√™ pode preench√™-lo com zeros, voc√™ pode usar valores medianos, voc√™ pode simplesmente excluir linhas sem as informa√ß√µes necess√°rias.  Tudo depende do modelo que planejamos usar, pois alguns deles lidam perfeitamente com os valores ausentes.  Enquanto nos lembramos desse fato e deixamos tudo como est√°. <br><br><h3>  Tipos de coluna e codifica√ß√£o categ√≥rica </h3><br>  Como nos lembramos.  parte das colunas √© do tipo objeto, ou seja, n√£o possui um valor num√©rico, mas reflete alguma categoria.  Vamos examinar essas colunas mais de perto. <br><br><pre> <code class="python hljs">app_train.dtypes.value_counts()</code> </pre> <br> <code>float64 65 <br> int64 41 <br> object 16 <br> dtype: int64</code> <br> <br><pre> <code class="python hljs">app_train.select_dtypes(include=[object]).apply(pd.Series.nunique, axis = <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br> <code>NAME_CONTRACT_TYPE 2 <br> CODE_GENDER 3 <br> FLAG_OWN_CAR 2 <br> FLAG_OWN_REALTY 2 <br> NAME_TYPE_SUITE 7 <br> NAME_INCOME_TYPE 8 <br> NAME_EDUCATION_TYPE 5 <br> NAME_FAMILY_STATUS 6 <br> NAME_HOUSING_TYPE 6 <br> OCCUPATION_TYPE 18 <br> WEEKDAY_APPR_PROCESS_START 7 <br> ORGANIZATION_TYPE 58 <br> FONDKAPREMONT_MODE 4 <br> HOUSETYPE_MODE 3 <br> WALLSMATERIAL_MODE 7 <br> EMERGENCYSTATE_MODE 2 <br> dtype: int64</code> <br> <br>  Temos 16 colunas, cada uma com 2 a 58 op√ß√µes de valores diferentes.  Em geral, os modelos de aprendizado de m√°quina n√£o podem fazer nada com essas colunas (exceto algumas, como LightGBM ou CatBoost).  Como planejamos experimentar modelos diferentes no conjunto de dados, algo precisa ser feito com isso.  Existem basicamente duas abordagens: <br><br><ul><li>  Codifica√ß√£o de etiqueta - as categorias recebem os d√≠gitos 0, 1, 2 e assim por diante e s√£o escritas na mesma coluna </li><li>  Codifica√ß√£o One-Hot - uma coluna √© decomposta em v√°rias de acordo com o n√∫mero de op√ß√µes e essas colunas indicam qual op√ß√£o esse registro possui. </li></ul><br>  Entre os populares, vale destacar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a codifica√ß√£o m√©dia do alvo</a> (obrigado pelo esclarecimento em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">roryorangepants</a> ). <br><br>  H√° um pequeno problema com a codifica√ß√£o de etiquetas - ela atribui valores num√©ricos que nada t√™m a ver com a realidade.  Por exemplo, se estivermos lidando com um valor num√©rico, a renda de 100.000 do tomador de empr√©stimo √© definitivamente maior e melhor que a de 20.000. Mas podemos dizer que, por exemplo, uma cidade √© melhor que outra porque √© atribu√≠do o valor 100 e a outra 200 ? <br><br>  A codifica√ß√£o One-Hot, por outro lado, √© mais segura, mas pode produzir colunas "extras".  Por exemplo, se codificarmos o mesmo g√™nero usando o One-Hot, obteremos duas colunas, "g√™nero masculino" e "g√™nero feminino", embora uma seja suficiente, "√© masculino". <br><br>  Para um bom conjunto de dados, seria necess√°rio codificar sinais com baixa variabilidade usando Label Encoding e tudo mais - One-Hot, mas por simplicidade, codificamos tudo de acordo com o One-Hot.  Praticamente n√£o afetar√° a velocidade de c√°lculo e o resultado.  O pr√≥prio processo de codifica√ß√£o de pandas √© muito simples. <br><br><pre> <code class="python hljs">app_train = pd.get_dummies(app_train) app_test = pd.get_dummies(app_test)‚Äã print(<span class="hljs-string"><span class="hljs-string">'Training Features shape: '</span></span>, app_train.shape) print(<span class="hljs-string"><span class="hljs-string">'Testing Features shape: '</span></span>, app_test.shape)</code> </pre> <br> <code>Training Features shape: (307511, 246) <br> Testing Features shape: (48744, 242)</code> <br> <br>  Como o n√∫mero de op√ß√µes nas colunas de sele√ß√£o n√£o √© igual, o n√∫mero de colunas agora n√£o corresponde.  O alinhamento √© necess√°rio - voc√™ precisa remover as colunas do conjunto de treinamento que n√£o est√£o no conjunto de teste.  Isso torna o m√©todo de alinhamento, voc√™ precisa especificar o eixo = 1 (para colunas). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># ,           . train_labels = app_train['TARGET']‚Äã #  -   .     app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)‚Äã print('  : ', app_train.shape) print('  : ', app_test.shape)‚Äã # Add target back in to the data app_train['TARGET'] = train_labels</span></span></code> </pre> <br> <code>  : (307511, 242) <br>   : (48744, 242)</code> <br> <br><h3>  Correla√ß√£o de dados </h3><br>  Uma boa maneira de entender os dados √© calcular os coeficientes de correla√ß√£o de Pearson para os dados relativos ao atributo de destino.  Este n√£o √© o melhor m√©todo para mostrar a relev√¢ncia dos recursos, mas √© simples e permite que voc√™ tenha uma id√©ia dos dados.  Os coeficientes podem ser interpretados da seguinte maneira: <br><br><ul><li>  00-.19 "muito fraco" </li><li>  20-.39 "fraco" </li><li>  40-.59 "m√©dio" </li><li>  60-.79 forte </li><li>  80-1,0 "muito forte" </li></ul><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    correlations = app_train.corr()['TARGET'].sort_values()‚Äã #  print('  : \n', correlations.tail(15)) print('\n  : \n', correlations.head(15))</span></span></code> </pre> <br> <code>  : <br> DAYS_REGISTRATION 0.041975 <br> OCCUPATION_TYPE_Laborers 0.043019 <br> FLAG_DOCUMENT_3 0.044346 <br> REG_CITY_NOT_LIVE_CITY 0.044395 <br> FLAG_EMP_PHONE 0.045982 <br> NAME_EDUCATION_TYPE_Secondary / secondary special 0.049824 <br> REG_CITY_NOT_WORK_CITY 0.050994 <br> DAYS_ID_PUBLISH 0.051457 <br> CODE_GENDER_M 0.054713 <br> DAYS_LAST_PHONE_CHANGE 0.055218 <br> NAME_INCOME_TYPE_Working 0.057481 <br> REGION_RATING_CLIENT 0.058899 <br> REGION_RATING_CLIENT_W_CITY 0.060893 <br> DAYS_BIRTH 0.078239 <br> TARGET 1.000000 <br> Name: TARGET, dtype: float64 <br> <br>   : <br> EXT_SOURCE_3 -0.178919 <br> EXT_SOURCE_2 -0.160472 <br> EXT_SOURCE_1 -0.155317 <br> NAME_EDUCATION_TYPE_Higher education -0.056593 <br> CODE_GENDER_F -0.054704 <br> NAME_INCOME_TYPE_Pensioner -0.046209 <br> ORGANIZATION_TYPE_XNA -0.045987 <br> DAYS_EMPLOYED -0.044932 <br> FLOORSMAX_AVG -0.044003 <br> FLOORSMAX_MEDI -0.043768 <br> FLOORSMAX_MODE -0.043226 <br> EMERGENCYSTATE_MODE_No -0.042201 <br> HOUSETYPE_MODE_block of flats -0.040594 <br> AMT_GOODS_PRICE -0.039645 <br> REGION_POPULATION_RELATIVE -0.037227 <br> Name: TARGET, dtype: float64</code> <br> <br>  Assim, todos os dados se correlacionam fracamente com o alvo (exceto o pr√≥prio alvo, que, √© claro, √© igual a ele).  No entanto, a idade e algumas "fontes de dados externas" s√£o diferenciadas dos dados.  Provavelmente s√£o alguns dados adicionais de outras organiza√ß√µes de cr√©dito.  √â engra√ßado que, embora o objetivo seja declarado como independ√™ncia de tais dados na tomada de uma decis√£o de cr√©dito, na verdade estaremos baseados principalmente neles. <br><br><h3>  Idade </h3><br>  √â claro que, quanto mais antigo o cliente, maior a probabilidade de um retorno (at√© um certo limite, √© claro).  Mas, por algum motivo, a idade √© indicada em dias negativos antes da emiss√£o do empr√©stimo; portanto, ela se correlaciona positivamente com o n√£o pagamento (o que parece um pouco estranho).  Trazemos isso a um valor positivo e observamos a correla√ß√£o. <br><br><pre> <code class="python hljs">app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>] = abs(app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>]) app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>].corr(app_train[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>])</code> </pre> <br> <code>-0.078239308309827088</code> <br> <br>  Vamos dar uma olhada mais de perto na vari√°vel.  Vamos come√ßar com o histograma. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     ,  25  plt.hist(app_train['DAYS_BIRTH'] / 365, edgecolor = 'k', bins = 25) plt.title('Age of Client'); plt.xlabel('Age (years)'); plt.ylabel('Count');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/v2/zq/1q/v2zq1qolo8rc5wx0tyao4ucygxc.png"><br><br>  O histograma de distribui√ß√£o em si pode ser um pouco √∫til, exceto pelo fato de n√£o vermos valores extremos especiais e tudo parecer mais ou menos cr√≠vel.  Para mostrar o efeito da influ√™ncia da idade no resultado, podemos construir um gr√°fico de estimativa da densidade do n√∫cleo (KDE) - a distribui√ß√£o da densidade nuclear, pintada nas cores do atributo de destino.  Ele mostra a distribui√ß√£o de uma vari√°vel e pode ser interpretado como um histograma suavizado (calculado como um n√∫cleo gaussiano para cada ponto, que √© calculado como m√©dia para suavizar). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365, label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365, label = 'target == 1')‚Äã #  plt.xlabel('Age (years)'); plt.ylabel('Density'); plt.title('Distribution of Ages');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/st/xs/e1/stxse1wipiaqcf0a7trlm0lwz0g.png"><br><br>  Como pode ser visto, a parcela de inadimpl√™ncia √© maior para os jovens e diminui com o aumento da idade.  Esta n√£o √© uma raz√£o para recusar cr√©dito aos jovens sempre, tal ‚Äúrecomenda√ß√£o‚Äù s√≥ levar√° √† perda de renda e de mercado para o banco.  Esta √© uma ocasi√£o para pensar em um monitoramento mais completo desses empr√©stimos, avalia√ß√µes e, possivelmente, at√© algum tipo de educa√ß√£o financeira para jovens mutu√°rios. <br><br><h3>  Fontes externas </h3><br>  Vamos dar uma olhada nas ‚Äúfontes de dados externas‚Äù EXT_SOURCE e sua correla√ß√£o. <br><br><pre> <code class="python hljs">ext_data = app_train[[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_1'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_2'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_3'</span></span>, <span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>]] ext_data_corrs = ext_data.corr() ext_data_corrs</code> </pre> <br><img src="https://habrastorage.org/webt/5k/ba/fe/5kbafej-y0vvcexlt6iebcjvjbs.png"><br><br>  Tamb√©m √© conveniente exibir correla√ß√£o usando o mapa de calor <br><br><pre> <code class="python hljs">sns.heatmap(ext_data_corrs, cmap = plt.cm.RdYlBu_r, vmin = <span class="hljs-number"><span class="hljs-number">-0.25</span></span>, annot = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, vmax = <span class="hljs-number"><span class="hljs-number">0.6</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'Correlation Heatmap'</span></span>);</code> </pre> <br><img src="https://habrastorage.org/webt/e6/wj/vw/e6wjvwnetgs2y-i65_4okda-6t8.png"><br><br>  Como voc√™ pode ver, todas as fontes mostram uma correla√ß√£o negativa com o destino.  Vamos dar uma olhada na distribui√ß√£o do KDE para cada fonte. <br><br><pre> <code class="python hljs">plt.figure(figsize = (<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment">#    for i, source in enumerate(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']): #  plt.subplot(3, 1, i + 1) #    sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, source], label = 'target == 0') #    sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, source], label = 'target == 1') #  plt.title('Distribution of %s by Target Value' % source) plt.xlabel('%s' % source); plt.ylabel('Density'); plt.tight_layout(h_pad = 2.5)</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/lf/ig/xm/lfigxmxlck1s4w2uyygfudghajm.png"><br><br>  O quadro √© semelhante √† distribui√ß√£o por idade - com um aumento no indicador, a probabilidade de retorno do empr√©stimo aumenta.  A terceira fonte √© a mais poderosa a esse respeito.  Embora em termos absolutos a correla√ß√£o com a vari√°vel alvo ainda esteja na categoria "muito baixa", fontes de dados externas e idade ser√£o da maior import√¢ncia na constru√ß√£o do modelo. <br><br><h3>  Programa√ß√£o de par </h3><br>  Para entender melhor o relacionamento dessas vari√°veis, voc√™ pode criar um gr√°fico de pares, nele podemos ver o relacionamento de cada par e um histograma da distribui√ß√£o ao longo da diagonal.  Acima da diagonal, voc√™ pode mostrar o gr√°fico de dispers√£o e abaixo - 2d KDE. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       age_data = app_train[['TARGET', 'DAYS_BIRTH']] age_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / 365‚Äã #     plot_data = ext_data.drop(labels = ['DAYS_BIRTH'], axis=1).copy()‚Äã #   plot_data['YEARS_BIRTH'] = age_data['YEARS_BIRTH']‚Äã #         100 .  plot_data = plot_data.dropna().loc[:100000, :]‚Äã #     def corr_func(x, y, **kwargs): r = np.corrcoef(x, y)[0][1] ax = plt.gca() ax.annotate("r = {:.2f}".format(r), xy=(.2, .8), xycoords=ax.transAxes, size = 20)‚Äã #   pairgrid object grid = sns.PairGrid(data = plot_data, size = 3, diag_sharey=False, hue = 'TARGET', vars = [x for x in list(plot_data.columns) if x != 'TARGET'])‚Äã #  -  grid.map_upper(plt.scatter, alpha = 0.2)‚Äã #  -  grid.map_diag(sns.kdeplot)‚Äã #  -   grid.map_lower(sns.kdeplot, cmap = plt.cm.OrRd_r);‚Äã plt.suptitle('Ext Source and Age Features Pairs Plot', size = 32, y = 1.05);</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/wu/bm/ut/wubmutz04p4kwsmmk34gbuoq71g.png"><br><br>  Empr√©stimos reembols√°veis ‚Äã‚Äãs√£o mostrados em azul, n√£o reembols√°veis ‚Äã‚Äãem vermelho.  Interpretar tudo isso √© bastante dif√≠cil, mas uma boa impress√£o em uma camiseta ou em uma foto de um museu de arte moderna pode sair dessa imagem. <br><br><h3>  Exame de outros sinais </h3><br>  Vamos considerar com mais detalhes outros recursos e sua depend√™ncia da vari√°vel de destino.  Como existem muitos categ√≥ricos (e j√° conseguimos codific√°-los), novamente precisamos dos dados iniciais.  Vamos cham√°-los um pouco diferente para evitar confus√£o <br><br><pre> <code class="python hljs">application_train = pd.read_csv(PATH+<span class="hljs-string"><span class="hljs-string">"application_train.csv"</span></span>) application_test = pd.read_csv(PATH+<span class="hljs-string"><span class="hljs-string">"application_test.csv"</span></span>)</code> </pre> <br>  Tamb√©m precisaremos de algumas fun√ß√µes para exibir lindamente as distribui√ß√µes e sua influ√™ncia na vari√°vel de destino.  Muito obrigado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a</a> eles pelo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">autor</a> deste <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">kernel</a> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_stats</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(feature,label_rotation=False,horizontal_layout=True)</span></span></span><span class="hljs-function">:</span></span> temp = application_train[feature].value_counts() df1 = pd.DataFrame({feature: temp.index,<span class="hljs-string"><span class="hljs-string">' '</span></span>: temp.values})‚Äã <span class="hljs-comment"><span class="hljs-comment">#   target=1   cat_perc = application_train[[feature, 'TARGET']].groupby([feature],as_index=False).mean() cat_perc.sort_values(by='TARGET', ascending=False, inplace=True) if(horizontal_layout): fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6)) else: fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12,14)) sns.set_color_codes("pastel") s = sns.barplot(ax=ax1, x = feature, y=" ",data=df1) if(label_rotation): s.set_xticklabels(s.get_xticklabels(),rotation=90) s = sns.barplot(ax=ax2, x = feature, y='TARGET', order=cat_perc[feature], data=cat_perc) if(label_rotation): s.set_xticklabels(s.get_xticklabels(),rotation=90) plt.ylabel(' ', fontsize=10) plt.tick_params(axis='both', which='major', labelsize=10)‚Äã plt.show();</span></span></code> </pre> <br>  Ent√£o, vamos considerar os principais sinais dos clientes <br><br><h3>  Tipo de empr√©stimo </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_TYPE'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/gf/xr/hd/gfxrhdfhqe7zyvlvwjmtgg-opam.png"><br><br>  Curiosamente, empr√©stimos rotativos (provavelmente descobertos ou algo parecido) representam menos de 10% do n√∫mero total de empr√©stimos.  Ao mesmo tempo, o percentual de n√£o retorno entre eles √© muito maior.  Um bom motivo para revisar a metodologia de trabalho com esses empr√©stimos e talvez at√© abandon√°-los. <br><br><h3>  Sexo do cliente </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CODE_GENDER'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/fj/vu/eu/fjvueuchpemqvpmijfzsslyiy5m.png"><br><br>  H√° quase o dobro de clientes mulheres do que homens, com os homens apresentando um risco muito maior. <br><br><h3>  Propriedade de carro e propriedade </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'FLAG_OWN_CAR'</span></span>) plot_stats(<span class="hljs-string"><span class="hljs-string">'FLAG_OWN_REALTY'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/l4/iv/u4/l4ivu4-yhdkdma8yjrnhj07evdq.png"><br><img src="https://habrastorage.org/webt/fg/qn/2-/fgqn2-3qqhjvkbovec9zm_qkfgo.png"><br><br>  Clientes com o carro s√£o metade do que "sem cavalos".  O risco √© quase o mesmo, os clientes com a m√°quina pagam um pouco melhor. <br><br>  No setor imobili√°rio, o oposto √© verdadeiro - h√° metade do n√∫mero de clientes sem ele.  O risco para os propriet√°rios tamb√©m √© um pouco menor. <br><br><h3>  Estado civil </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_FAMILY_STATUS'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/7u/qt/t1/7uqtt10kghqs01w-_y_1e6vx2jw.png"><br><br>  Enquanto a maioria dos clientes √© casada, os mais arriscados s√£o clientes civis e solteiros.  Os vi√∫vos mostram um risco m√≠nimo. <br><br><h3>  N√∫mero de filhos </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CNT_CHILDREN'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/5s/ux/o8/5suxo8vh8yl68pnxqf4vm7c-ixa.png"><br><br>  A maioria dos clientes n√£o tem filhos.  Ao mesmo tempo, clientes com 9 e 11 filhos mostram um reembolso total n√£o reembols√°vel <br><br><pre> <code class="python hljs">application_train.CNT_CHILDREN.value_counts()</code> </pre> <br> <code>0 215371 <br> 1 61119 <br> 2 26749 <br> 3 3717 <br> 4 429 <br> 5 84 <br> 6 21 <br> 7 7 <br> 14 3 <br> 19 2 <br> 12 2 <br> 10 2 <br> 9 2 <br> 8 2 <br> 11 1 <br> Name: CNT_CHILDREN, dtype: int64</code> <br> <br>  Como mostra o c√°lculo dos valores, esses dados s√£o estatisticamente insignificantes - apenas 1-2 clientes de ambas as categorias.  No entanto, todos os tr√™s entraram no padr√£o, assim como metade dos clientes com 6 filhos. <br><br><h3>  N√∫mero de membros da fam√≠lia </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CNT_FAM_MEMBERS'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/bw/tg/sc/bwtgsctk9vk_y8tcx9bv9fraogu.png"><br><br>  A situa√ß√£o √© semelhante - quanto menos bocas, maior o retorno. <br><br><h3>  Tipo de renda </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_INCOME_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/ow/la/kf/owlakfzs7cqh74msyjw9ngeq8h4.png"><br><br>  M√£es solteiras e desempregadas provavelmente ser√£o cortadas na fase de inscri√ß√£o - h√° muito poucas delas na amostra.  Mas os problemas est√£o mostrando de forma est√°vel. <br><br><h3>  Tipo de atividade </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'OCCUPATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/pw/m4/eu/pwm4eui3y46rrd0380w5jnkqiug.png"><br><br><pre> <code class="python hljs">application_train.OCCUPATION_TYPE.value_counts()</code> </pre> <br> <code>Laborers 55186 <br> Sales staff 32102 <br> Core staff 27570 <br> Managers 21371 <br> Drivers 18603 <br> High skill tech staff 11380 <br> Accountants 9813 <br> Medicine staff 8537 <br> Security staff 6721 <br> Cooking staff 5946 <br> Cleaning staff 4653 <br> Private service staff 2652 <br> Low-skill Laborers 2093 <br> Waiters/barmen staff 1348 <br> Secretaries 1305 <br> Realty agents 751 <br> HR staff 563 <br> IT staff 526 <br> Name: OCCUPATION_TYPE, dtype: int64</code> <br> <br>  √â de interesse dos motoristas e agentes de seguran√ßa que s√£o bastante numerosos e enfrentam problemas com mais frequ√™ncia do que outras categorias. <br><br><h3>  Educa√ß√£o </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_EDUCATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/dh/g9/-t/dhg9-t4wl5oaaultg0m4ujq4ky0.png"><br><br>  Quanto maior a educa√ß√£o, melhor a recorr√™ncia, obviamente. <br><br><h3>  Tipo de organiza√ß√£o - empregador </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'ORGANIZATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/nm/eq/p-/nmeqp-rvrmowwpqhkjzvygeah20.png"><br><br>  A maior porcentagem de n√£o retorno √© observada em Transporte: tipo 3 (16%), Ind√∫stria: tipo 13 (13,5%), Ind√∫stria: tipo 8 (12,5%) e Restaurante (at√© 12%). <br><br><h3>  Aloca√ß√£o de empr√©stimos </h3><br>  Considerar a distribui√ß√£o dos valores dos empr√©stimos e seu impacto no reembolso <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>)) plt.title(<span class="hljs-string"><span class="hljs-string">" AMT_CREDIT"</span></span>) ax = sns.distplot(app_train[<span class="hljs-string"><span class="hljs-string">"AMT_CREDIT"</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/x1/8k/qg/x18kqghr1tue4io96l_keuqcr94.png"><br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'AMT_CREDIT'], label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'AMT_CREDIT'], label = 'target == 1')‚Äã #  plt.xlabel(' '); plt.ylabel(''); plt.title(' ');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/_3/fu/cj/_3fucjn19lmxvjjaamrrlwumh5m.png"><br><br>  Como mostra o gr√°fico de densidade, quantidades robustas s√£o retornadas com mais frequ√™ncia <br><br><h3>  Distribui√ß√£o de densidade </h3><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>)) plt.title(<span class="hljs-string"><span class="hljs-string">" REGION_POPULATION_RELATIVE"</span></span>) ax = sns.distplot(app_train[<span class="hljs-string"><span class="hljs-string">"REGION_POPULATION_RELATIVE"</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/26/3h/os/263hoss0mbvvq2p0ewagrw5v-sm.png"><br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>))‚Äã <span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'REGION_POPULATION_RELATIVE'], label = 'target == 0')‚Äã # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'REGION_POPULATION_RELATIVE'], label = 'target == 1')‚Äã #  plt.xlabel(''); plt.ylabel(' '); plt.title(' ');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/fs/ez/82/fsez82q5fbqdkiqizkxjralpm-8.png"><br><br>  Clientes de regi√µes mais populosas tendem a pagar melhor empr√©stimos. <br><br>  Assim, tivemos uma id√©ia das principais caracter√≠sticas do conjunto de dados e sua influ√™ncia no resultado.  N√£o faremos nada especificamente com os listados neste artigo, mas eles podem se tornar muito importantes em trabalhos futuros. <br><br><h2>  Engenharia de recursos - Convers√£o de recursos </h2><br>  As competi√ß√µes no Kaggle s√£o vencidas pela transforma√ß√£o de sinais - quem pode criar os sinais mais √∫teis a partir dos dados ganha.  Pelo menos para dados estruturados, os modelos vencedores agora s√£o basicamente diferentes op√ß√µes de aumento de gradiente.  Na maioria das vezes, √© mais eficiente gastar tempo convertendo atributos do que configurar hiperpar√¢metros ou selecionar modelos.  Um modelo ainda pode aprender apenas com os dados que foram transferidos para ele.  Garantir que os dados sejam relevantes para a tarefa √© a principal responsabilidade da data do cientista. <br><br>  O processo de transforma√ß√£o de caracter√≠sticas pode incluir a cria√ß√£o de novos dados dispon√≠veis, a sele√ß√£o dos mais importantes dispon√≠veis, etc.  Vamos tentar desta vez sinais polinomiais. <br><br><h3>  Sinais polinomiais </h3><br>  O m√©todo polinomial de construir recursos √© que simplesmente criamos recursos que s√£o o grau de recursos dispon√≠veis e seus produtos.  Em alguns casos, esses recursos constru√≠dos podem ter uma correla√ß√£o mais forte com a vari√°vel alvo do que seus ‚Äúpais‚Äù.  Embora esses m√©todos sejam frequentemente usados ‚Äã‚Äãem modelos estat√≠sticos, eles s√£o muito menos comuns no aprendizado de m√°quina.  No entanto.  nada nos impede de experiment√°-los, especialmente porque o Scikit-Learn tem uma classe especificamente para esses fins - PolynomialFeatures - que cria recursos polinomiais e seus produtos, voc√™ s√≥ precisa especificar os recursos originais e o grau m√°ximo em que eles precisam ser aprimorados.  Usamos os efeitos mais poderosos no resultado de 4 atributos e no grau 3 para n√£o complicar demais o modelo e evitar o excesso de ajustes (treinamento excessivo do modelo - seu ajuste excessivo na amostra de treinamento). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       poly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']] poly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]‚Äã #    from sklearn.preprocessing import Imputer imputer = Imputer(strategy = 'median')‚Äã poly_target = poly_features['TARGET']‚Äã poly_features = poly_features.drop('TARGET', axis=1)‚Äã poly_features = imputer.fit_transform(poly_features) poly_features_test = imputer.transform(poly_features_test) from sklearn.preprocessing import PolynomialFeatures #     3 poly_transformer = PolynomialFeatures(degree = 3) #    poly_transformer.fit(poly_features) #   poly_features = poly_transformer.transform(poly_features) poly_features_test = poly_transformer.transform(poly_features_test) print('  : ', poly_features.shape)</span></span></code> </pre> <br> <code>  : (307511, 35) <br>        get_feature_names</code> <br> <br><pre> <code class="python hljs">poly_transformer.get_feature_names(input_features = [<span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_1'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_2'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_3'</span></span>, <span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>])[:<span class="hljs-number"><span class="hljs-number">15</span></span>]</code> </pre> <br> <code>['1', <br> 'EXT_SOURCE_1', <br> 'EXT_SOURCE_2', <br> 'EXT_SOURCE_3', <br> 'DAYS_BIRTH', <br> 'EXT_SOURCE_1^2', <br> 'EXT_SOURCE_1 EXT_SOURCE_2', <br> 'EXT_SOURCE_1 EXT_SOURCE_3', <br> 'EXT_SOURCE_1 DAYS_BIRTH', <br> 'EXT_SOURCE_2^2', <br> 'EXT_SOURCE_2 EXT_SOURCE_3', <br> 'EXT_SOURCE_2 DAYS_BIRTH', <br> 'EXT_SOURCE_3^2', <br> 'EXT_SOURCE_3 DAYS_BIRTH', <br> 'DAYS_BIRTH^2']</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um total de 35 recursos polinomiais e derivados. </font><font style="vertical-align: inherit;">Verifique sua correla√ß√£o com o alvo.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     poly_features = pd.DataFrame(poly_features, columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']))‚Äã #   poly_features['TARGET'] = poly_target‚Äã #   poly_corrs = poly_features.corr()['TARGET'].sort_values()‚Äã #      print(poly_corrs.head(10)) print(poly_corrs.tail(5))</span></span></code> </pre> <br> <code>EXT_SOURCE_2 EXT_SOURCE_3 -0.193939 <br> EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3 -0.189605 <br> EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH -0.181283 <br> EXT_SOURCE_2^2 EXT_SOURCE_3 -0.176428 <br> EXT_SOURCE_2 EXT_SOURCE_3^2 -0.172282 <br> EXT_SOURCE_1 EXT_SOURCE_2 -0.166625 <br> EXT_SOURCE_1 EXT_SOURCE_3 -0.164065 <br> EXT_SOURCE_2 -0.160295 <br> EXT_SOURCE_2 DAYS_BIRTH -0.156873 <br> EXT_SOURCE_1 EXT_SOURCE_2^2 -0.156867 <br> Name: TARGET, dtype: float64 <br> DAYS_BIRTH -0.078239 <br> DAYS_BIRTH^2 -0.076672 <br> DAYS_BIRTH^3 -0.074273 <br> TARGET 1.000000 <br> 1 NaN <br> Name: TARGET, dtype: float64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Portanto, alguns sinais mostram uma correla√ß√£o maior que a original. </font><font style="vertical-align: inherit;">Faz sentido tentar aprender com eles e sem eles (como muito mais no aprendizado de m√°quina, isso pode ser determinado experimentalmente). </font><font style="vertical-align: inherit;">Para fazer isso, crie uma c√≥pia dos quadros de dados e adicione novos recursos l√°.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      poly_features_test = pd.DataFrame(poly_features_test, columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']))‚Äã #    poly_features['SK_ID_CURR'] = app_train['SK_ID_CURR'] app_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')‚Äã #    poly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR'] app_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')‚Äã #   app_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)‚Äã #   print('    : ', app_train_poly.shape) print('    : ', app_test_poly.shape)</span></span></code> </pre> <br> <code>    : (307511, 277) <br>     : (48744, 277)</code> <br> <br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modelo de treinamento </font></font></h2><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> N√≠vel b√°sico </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nos c√°lculos, voc√™ precisa come√ßar com algum n√≠vel b√°sico do modelo, abaixo do qual n√£o √© mais poss√≠vel cair. </font><font style="vertical-align: inherit;">No nosso caso, isso pode ser 0,5 para todos os clientes de teste - isso mostra que n√£o temos id√©ia de se o cliente reembolsar√° o empr√©stimo ou n√£o. </font><font style="vertical-align: inherit;">No nosso caso, o trabalho preliminar j√° foi realizado e modelos mais complexos podem ser usados.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Regress√£o log√≠stica </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para calcular a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">regress√£o log√≠stica,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> precisamos pegar tabelas com recursos categ√≥ricos codificados, preencher os dados ausentes e normaliz√°-los (lev√°-los a valores de 0 a 1). </font><font style="vertical-align: inherit;">Tudo isso executa o seguinte c√≥digo:</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MinMaxScaler, Imputer‚Äã <span class="hljs-comment"><span class="hljs-comment">#      if 'TARGET' in app_train: train = app_train.drop(labels = ['TARGET'], axis=1) else: train = app_train.copy() features = list(train.columns)‚Äã #    test = app_test.copy()‚Äã #     imputer = Imputer(strategy = 'median')‚Äã #  scaler = MinMaxScaler(feature_range = (0, 1))‚Äã #    imputer.fit(train)‚Äã #      train = imputer.transform(train) test = imputer.transform(app_test)‚Äã #      scaler.fit(train) train = scaler.transform(train) test = scaler.transform(test)‚Äã print('  : ', train.shape) print('  : ', test.shape)</span></span></code> </pre> <br> <code>  : (307511, 242) <br>   : (48744, 242)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Utilizamos a regress√£o log√≠stica do Scikit-Learn como o primeiro modelo. </font><font style="vertical-align: inherit;">Vamos pegar o modelo de desfolhamento com uma corre√ß√£o - abaixamos o par√¢metro de regulariza√ß√£o C para evitar o ajuste excessivo. </font><font style="vertical-align: inherit;">A sintaxe √© normal - criamos um modelo, treinamos e prevemos a probabilidade usando o prog_proba (precisamos de probabilidade, n√£o 0/1)</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LogisticRegression‚Äã <span class="hljs-comment"><span class="hljs-comment">#   log_reg = LogisticRegression(C = 0.0001)‚Äã #   log_reg.fit(train, train_labels) LogisticRegression(C=0.0001, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='liblinear', tol=0.0001, verbose=0, warm_start=False)      .  prdict_proba     mx 2,  m -  ,   -  0,  -  1.    ( ). log_reg_pred = log_reg.predict_proba(test)[:, 1]</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Agora voc√™ pode criar um arquivo para fazer upload no Kaggle. </font><font style="vertical-align: inherit;">Crie um quadro de dados a partir do ID do cliente e probabilidade de n√£o retorno e fa√ßa o upload dele.</font></font><br><br><pre> <code class="python hljs">submit = app_test[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]] submit[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>] = log_reg_pred‚Äã submit.head()</code> </pre> <br> <code>SK_ID_CURR TARGET <br> 0 100001 0.087954 <br> 1 100005 0.163151 <br> 2 100013 0.109923 <br> 3 100028 0.077124 <br> 4 100038 0.151694</code> <br> <br><pre> <code class="python hljs">submit.to_csv(<span class="hljs-string"><span class="hljs-string">'log_reg_baseline.csv'</span></span>, index = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Portanto, o resultado do nosso trabalho tit√¢nico: 0,673, com o melhor resultado para hoje, √© 0,802.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modelo Aprimorado - Floresta Aleat√≥ria </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Logreg n√£o se mostra muito bem, vamos tentar usar um modelo melhorado - uma floresta aleat√≥ria. </font><font style="vertical-align: inherit;">Este √© um modelo muito mais poderoso que pode construir centenas de √°rvores e produzir um resultado muito mais preciso. </font><font style="vertical-align: inherit;">N√≥s usamos 100 √°rvores. </font><font style="vertical-align: inherit;">O esquema de trabalhar com o modelo √© o mesmo, completamente padr√£o - carregando o classificador, treinando. </font><font style="vertical-align: inherit;">previs√£o.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier‚Äã <span class="hljs-comment"><span class="hljs-comment">#   random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50)‚Äã #     random_forest.fit(train, train_labels)‚Äã #     predictions = random_forest.predict_proba(test)[:, 1]‚Äã #     submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #  submit.to_csv('random_forest_baseline.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">resultado aleat√≥rio da floresta √© ligeiramente melhor - 0,683</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modelo de treinamento com recursos polinomiais </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Agora que temos um modelo. </font><font style="vertical-align: inherit;">que faz pelo menos alguma coisa - √© hora de testar nossos sinais polinomiais. </font><font style="vertical-align: inherit;">Vamos fazer o mesmo com eles e comparar o resultado.</font></font><br><br><pre> <code class="python hljs">poly_features_names = list(app_train_poly.columns)‚Äã <span class="hljs-comment"><span class="hljs-comment">#         imputer = Imputer(strategy = 'median')‚Äã poly_features = imputer.fit_transform(app_train_poly) poly_features_test = imputer.transform(app_test_poly)‚Äã #  scaler = MinMaxScaler(feature_range = (0, 1))‚Äã poly_features = scaler.fit_transform(poly_features) poly_features_test = scaler.transform(poly_features_test)‚Äã random_forest_poly = RandomForestClassifier(n_estimators = 100, random_state = 50) #     random_forest_poly.fit(poly_features, train_labels)‚Äã #  predictions = random_forest_poly.predict_proba(poly_features_test)[:, 1]‚Äã #    submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #   submit.to_csv('random_forest_baseline_engineered.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o resultado de uma floresta aleat√≥ria com caracter√≠sticas polinomiais se tornou pior - 0,633. </font><font style="vertical-align: inherit;">O que questiona muito a necessidade de seu uso.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Aumento de gradiente </font></font></h3><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O aumento de gradiente</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √© um "modelo s√©rio" para aprendizado de m√°quina. </font><font style="vertical-align: inherit;">Quase todas as competi√ß√µes mais recentes s√£o "arrastadas" exatamente. </font><font style="vertical-align: inherit;">Vamos construir um modelo simples e testar seu desempenho.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LGBMClassifier‚Äã clf = LGBMClassifier() clf.fit(train, train_labels)‚Äã predictions = clf.predict_proba(test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]‚Äã <span class="hljs-comment"><span class="hljs-comment">#    submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions‚Äã #   submit.to_csv('lightgbm_baseline.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O resultado do LightGBM √© 0,735, o que deixa para tr√°s todos os outros modelos.</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Interpreta√ß√£o do Modelo - Import√¢ncia dos Atributos </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A maneira mais f√°cil de interpretar um modelo √© examinar a import√¢ncia dos recursos (o que nem todos os modelos podem fazer). </font><font style="vertical-align: inherit;">Como nosso classificador processou a matriz, ser√° necess√°rio algum trabalho para redefinir os nomes das colunas de acordo com as colunas dessa matriz.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      def show_feature_importances(model, features): plt.figure(figsize = (12, 8)) #          results = pd.DataFrame({'feature': features, 'importance': model.feature_importances_}) results = results.sort_values('importance', ascending = False) #  print(results.head(10)) print('\n     0.01 = ', np.sum(results['importance'] &gt; 0.01)) #  results.head(20).plot(x = 'feature', y = 'importance', kind = 'barh', color = 'red', edgecolor = 'k', title = 'Feature Importances'); return results #         feature_importances = show_feature_importances(clf, features)</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como seria de esperar, o mais importante para modelar todos os mesmos 4 caracter√≠sticas. </font><font style="vertical-align: inherit;">A import√¢ncia dos atributos n√£o √© o melhor m√©todo de interpreta√ß√£o do modelo, mas permite entender os principais fatores que o modelo usa para previs√µes</font></font><code>feature importance <br> 28 EXT_SOURCE_1 310 <br> 30 EXT_SOURCE_3 282 <br> 29 EXT_SOURCE_2 271 <br> 7 DAYS_BIRTH 192 <br> 3 AMT_CREDIT 161 <br> 4 AMT_ANNUITY 142 <br> 5 AMT_GOODS_PRICE 129 <br> 8 DAYS_EMPLOYED 127 <br> 10 DAYS_ID_PUBLISH 102 <br> 9 DAYS_REGISTRATION 69 <br> <br>     0.01 = 158</code> <br> <br><img src="https://habrastorage.org/webt/uc/pi/ox/ucpiox1dno_vps4lsuk0lmxk7si.png"><br><br><font style="vertical-align: inherit;"></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Adicionando dados de outras tabelas </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Agora vamos considerar cuidadosamente tabelas adicionais e o que pode ser feito com elas. </font><font style="vertical-align: inherit;">Comece imediatamente a preparar as mesas para treinamento adicional. </font><font style="vertical-align: inherit;">Mas primeiro, exclua as volumosas tabelas antigas da mem√≥ria, limpe a mem√≥ria usando o coletor de lixo e importe as bibliotecas necess√°rias para an√°lises adicionais.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gc‚Äã <span class="hljs-comment"><span class="hljs-comment">#del app_train, app_test, train_labels, application_train, application_test, poly_features, poly_features_test‚Äã gc.collect() import pandas as pd import numpy as np‚Äã from sklearn.preprocessing import MinMaxScaler, LabelEncoder from sklearn.model_selection import train_test_split, KFold from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix from sklearn.feature_selection import VarianceThreshold‚Äã from lightgbm import LGBMClassifier</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Importe dados, remova imediatamente a coluna de destino em uma coluna separada </font></font><br><br><pre> <code class="python hljs">data = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/application_train.csv'</span></span>) test = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/application_test.csv'</span></span>) prev = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/previous_application.csv'</span></span>) buro = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/bureau.csv'</span></span>) buro_balance = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/bureau_balance.csv'</span></span>) credit_card = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/credit_card_balance.csv'</span></span>) POS_CASH = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/POS_CASH_balance.csv'</span></span>) payments = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/installments_payments.csv'</span></span>)‚Äã <span class="hljs-comment"><span class="hljs-comment">#Separate target variable y = data['TARGET'] del data['TARGET']</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Codifique imediatamente os recursos categ√≥ricos. </font><font style="vertical-align: inherit;">J√° fizemos isso antes, codificamos as amostras de treinamento e teste separadamente e, em seguida, alinhamos os dados. </font><font style="vertical-align: inherit;">Vamos tentar uma abordagem um pouco diferente - encontraremos todos esses recursos categ√≥ricos, combinaremos os quadros de dados, codificaremos a partir da lista de encontrados e, em seguida, dividiremos novamente as amostras em treinamento e teste.</font></font><br><br><pre> <code class="python hljs">categorical_features = [col <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> data[col].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>]‚Äã one_hot_df = pd.concat([data,test]) one_hot_df = pd.get_dummies(one_hot_df, columns=categorical_features)‚Äã data = one_hot_df.iloc[:data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>],:] test = one_hot_df.iloc[data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]:,]‚Äã <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, data.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, test.shape)</code> </pre> <br> <code>   (307511, 245) <br>    (48744, 245)</code> <br> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dados da ag√™ncia de cr√©dito sobre o saldo mensal do empr√©stimo. </font></font></h3><br><pre> <code class="python hljs">buro_balance.head()</code> </pre> <br><img src="https://habrastorage.org/webt/pa/im/0s/paim0sea2cdjnvm7lok--vi8oke.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MONTHS_BALANCE - o n√∫mero de meses antes da data do pedido de empr√©stimo. </font><font style="vertical-align: inherit;">Veja mais de perto os "status"</font></font><br><br><pre> <code class="python hljs">buro_balance.STATUS.value_counts()</code> </pre> <br> <code>C 13646993 <br> 0 7499507 <br> X 5810482 <br> 1 242347 <br> 5 62406 <br> 2 23419 <br> 3 8924 <br> 4 5847 <br> Name: STATUS, dtype: int64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Status significa o seguinte: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - fechado, ou seja, empr√©stimo reembolsado. </font><font style="vertical-align: inherit;">X √© um status desconhecido. </font><font style="vertical-align: inherit;">0 - empr√©stimo atual, sem inadimpl√™ncia. </font><font style="vertical-align: inherit;">1 - atraso de 1 a 30 dias, 2 - atraso de 31 a 60 dias e assim por diante at√© o status 5 - o empr√©stimo √© vendido a terceiros ou baixado. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aqui, por exemplo, os seguintes sinais podem ser distinguidos: buro_grouped_size - o n√∫mero de entradas no banco de dados buro_grouped_max - o saldo m√°ximo de empr√©stimos buro_grouped_min - o saldo m√≠nimo de empr√©stimos </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">E todos esses status de empr√©stimo podem ser codificados (usamos o m√©todo desempilhar e, em seguida, anexamos os dados recebidos √† tabela buro, pois SK_ID_BUREAU √© o mesmo aqui e ali.</font></font><br><br><pre> <code class="python hljs">buro_grouped_size = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].size() buro_grouped_max = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].max() buro_grouped_min = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].min()‚Äã buro_counts = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'STATUS'</span></span>].value_counts(normalize = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) buro_counts_unstacked = buro_counts.unstack(<span class="hljs-string"><span class="hljs-string">'STATUS'</span></span>) buro_counts_unstacked.columns = [<span class="hljs-string"><span class="hljs-string">'STATUS_0'</span></span>, <span class="hljs-string"><span class="hljs-string">'STATUS_1'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_2'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_3'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_4'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_5'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_C'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_X'</span></span>,] buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_COUNT'</span></span>] = buro_grouped_size buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_MIN'</span></span>] = buro_grouped_min buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_MAX'</span></span>] = buro_grouped_max‚Äã buro = buro.join(buro_counts_unstacked, how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> buro_balance gc.collect()</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Informa√ß√µes gerais sobre ag√™ncias de cr√©dito </font></font></h3><br><pre> <code class="python hljs">buro.head()</code> </pre> <br><img src="https://habrastorage.org/webt/00/7q/dz/007qdzakfbvd5qiizsxqwxvoari.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(primeiras 7 colunas s√£o mostradas) Existem </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">muitos dados que, em geral, voc√™ pode tentar codificar com One-Hot-Encoding, agrupado por SK_ID_CURR, m√©dio e, da mesma maneira, se preparar para ingressar na tabela principal</font></font><br><br><pre> <code class="python hljs">buro_cat_features = [bcol <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> bcol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> buro.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> buro[bcol].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>] buro = pd.get_dummies(buro, columns=buro_cat_features) avg_buro = buro.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() avg_buro[<span class="hljs-string"><span class="hljs-string">'buro_count'</span></span>] = buro[[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>, <span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).count()[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_buro[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> buro gc.collect()</code> </pre> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dados sobre aplicativos anteriores </font></font></h3><br><pre> <code class="python hljs">prev.head()</code> </pre> <br><img src="https://habrastorage.org/webt/nx/sv/z-/nxsvz-simhdingy0zqgnwg9xxpi.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Da mesma forma, codificamos recursos categ√≥ricos, medimos e combinamos sobre o ID atual. </font></font><br><br><pre> <code class="python hljs">prev_cat_features = [pcol <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> pcol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> prev.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> prev[pcol].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>] prev = pd.get_dummies(prev, columns=prev_cat_features) avg_prev = prev.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() cnt_prev = prev[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).count() avg_prev[<span class="hljs-string"><span class="hljs-string">'nb_app'</span></span>] = cnt_prev[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_prev[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> prev gc.collect()</code> </pre> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Saldo do cart√£o de cr√©dito </font></font></h3><br><pre> <code class="python hljs">POS_CASH.head()</code> </pre> <br><img src="https://habrastorage.org/webt/aq/25/er/aq25erq2wzuknck85ina4twk2g8.png"><br><br><pre> <code class="python hljs">POS_CASH.NAME_CONTRACT_STATUS.value_counts()</code> </pre> <br> <code>Active 9151119 <br> Completed 744883 <br> Signed 87260 <br> Demand 7065 <br> Returned to the store 5461 <br> Approved 4917 <br> Amortized debt 636 <br> Canceled 15 <br> XNA 2 <br> Name: NAME_CONTRACT_STATUS, dtype: int64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Codificamos recursos categ√≥ricos e preparamos uma tabela para combinar </font></font><br><br><pre> <code class="python hljs">le = LabelEncoder() POS_CASH[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] = le.fit_transform(POS_CASH[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>].astype(str)) nunique_status = POS_CASH[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).nunique() nunique_status2 = POS_CASH[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() POS_CASH[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS'</span></span>] = nunique_status[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] POS_CASH[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS2'</span></span>] = nunique_status2[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] POS_CASH.drop([<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dados do cart√£o </font></font></h3><br><pre> <code class="python hljs">credit_card.head()</code> </pre> <br><img src="https://habrastorage.org/webt/q5/wj/pj/q5wjpj8s-vak-svacdtlhqrwlus.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(primeiras 7 colunas) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Trabalho semelhante</font></font><br><br><pre> <code class="python hljs">credit_card[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] = le.fit_transform(credit_card[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>].astype(str)) nunique_status = credit_card[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).nunique() nunique_status2 = credit_card[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() credit_card[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS'</span></span>] = nunique_status[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] credit_card[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS2'</span></span>] = nunique_status2[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] credit_card.drop([<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dados de pagamento </font></font></h3><br><pre> <code class="python hljs">payments.head()</code> </pre> <br><img src="https://habrastorage.org/webt/ay/fy/3y/ayfy3yp5tzdxsffurkrgjd4udwu.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(primeiras 7 colunas mostradas) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vamos criar tr√™s tabelas - com os valores m√©dio, m√≠nimo e m√°ximo desta tabela.</font></font><br><br><pre> <code class="python hljs">avg_payments = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() avg_payments2 = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() avg_payments3 = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).min() <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_payments[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> payments gc.collect()</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Jun√ß√£o de tabela </font></font></h3><br><pre> <code class="python hljs">data = data.merge(right=avg_prev.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_prev.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_buro.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_buro.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(POS_CASH.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(POS_CASH.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(credit_card.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(credit_card.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments2.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments2.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)‚Äã data = data.merge(right=avg_payments3.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments3.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_prev, avg_buro, POS_CASH, credit_card, avg_payments, avg_payments2, avg_payments3 gc.collect() <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, data.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, test.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, y.shape)</code> </pre> <br> <code>   (307511, 504) <br>    (48744, 504) <br>    (307511,)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> E, na verdade, chegaremos a essa mesa dobrada com aumento de gradiente! </font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LGBMClassifier‚Äã clf2 = LGBMClassifier() clf2.fit(data, y)‚Äã predictions = clf2.predict_proba(test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]‚Äã <span class="hljs-comment"><span class="hljs-comment">#    submission = test[['SK_ID_CURR']] submission['TARGET'] = predictions‚Äã #   submission.to_csv('lightgbm_full.csv', index = False)</span></span></code> </pre> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o resultado √© 0,770. </font></font></b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OK, finalmente, vamos tentar uma t√©cnica mais complexa, com dobras em dobras, valida√ß√£o cruzada e escolha da melhor itera√ß√£o.</font></font><br><br><pre> <code class="python hljs">folds = KFold(n_splits=<span class="hljs-number"><span class="hljs-number">5</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">546789</span></span>) oof_preds = np.zeros(data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) sub_preds = np.zeros(test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>])‚Äã feature_importance_df = pd.DataFrame()‚Äã feats = [f <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> [<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]]‚Äã <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n_fold, (trn_idx, val_idx) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(folds.split(data)): trn_x, trn_y = data[feats].iloc[trn_idx], y.iloc[trn_idx] val_x, val_y = data[feats].iloc[val_idx], y.iloc[val_idx] clf = LGBMClassifier( n_estimators=<span class="hljs-number"><span class="hljs-number">10000</span></span>, learning_rate=<span class="hljs-number"><span class="hljs-number">0.03</span></span>, num_leaves=<span class="hljs-number"><span class="hljs-number">34</span></span>, colsample_bytree=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, subsample=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, max_depth=<span class="hljs-number"><span class="hljs-number">8</span></span>, reg_alpha=<span class="hljs-number"><span class="hljs-number">.1</span></span>, reg_lambda=<span class="hljs-number"><span class="hljs-number">.1</span></span>, min_split_gain=<span class="hljs-number"><span class="hljs-number">.01</span></span>, min_child_weight=<span class="hljs-number"><span class="hljs-number">375</span></span>, silent=<span class="hljs-number"><span class="hljs-number">-1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">-1</span></span>, ) clf.fit(trn_x, trn_y, eval_set= [(trn_x, trn_y), (val_x, val_y)], eval_metric=<span class="hljs-string"><span class="hljs-string">'auc'</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">100</span></span>, early_stopping_rounds=<span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-comment"><span class="hljs-comment">#30 ) oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1] sub_preds += clf.predict_proba(test[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits fold_importance_df = pd.DataFrame() fold_importance_df["feature"] = feats fold_importance_df["importance"] = clf.feature_importances_ fold_importance_df["fold"] = n_fold + 1 feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0) print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx]))) del clf, trn_x, trn_y, val_x, val_y gc.collect()‚Äã print('Full AUC score %.6f' % roc_auc_score(y, oof_preds))‚Äã test['TARGET'] = sub_preds‚Äã test[['SK_ID_CURR', 'TARGET']].to_csv('submission_cross.csv', index=False)</span></span></code> </pre> <br> <code>Full AUC score 0.785845</code> <br> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pontua√ß√£o final no kaggle 0.783</font></font></b> <br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Para onde ir a seguir </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Definitivamente continue a trabalhar com sinais. Explore os dados, selecione alguns dos sinais, combine-os, anexe tabelas adicionais de uma maneira diferente. Voc√™ pode experimentar os hiperpar√¢metros Mogheli - muitas dire√ß√µes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Espero que esta pequena compila√ß√£o tenha mostrado m√©todos modernos de pesquisa de dados e prepara√ß√£o de modelos preditivos. Aprenda dataaens, participe de competi√ß√µes, seja legal! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">E, novamente, links para os kernels que me ajudaram a preparar este artigo. O artigo tamb√©m √© publicado na forma de um </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">laptop no Github</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , voc√™ pode baix√°-lo, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">conjunto de dados</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e executar e experimentar. </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Will Koehrsen. Comece aqui: uma introdu√ß√£o suave </font></font></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sban. HomeCreditRisk: EDA abrangente + linha de base [0,772]</font></font></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Gabriel Preda. Home Credit Default Risk Extensive EDA</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pavan Raj. Loan repayers v/s Loan defaulters ‚Äî HOME CREDIT</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Lem Lordje Ko. 15 lines: Just EXT_SOURCE_x</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Shanth. HOME CREDIT ‚Äî BUREAU DATA ‚Äî FEATURE ENGINEERING</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Dmitriy Kisil. Good_fun_with_LigthGBM</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt414613/">https://habr.com/ru/post/pt414613/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt414597/index.html">Pergunte a Ethan: Qu√£o perto as civiliza√ß√µes alien√≠genas podem se unir?</a></li>
<li><a href="../pt414601/index.html">Quando as montanhas eram altas e os laptops eram grandes: um pouco mais da hist√≥ria da TI</a></li>
<li><a href="../pt414605/index.html">Mini imp√©rios</a></li>
<li><a href="../pt414609/index.html">O 2018 PWA (Progressive Web Apps) pode ser uma competi√ß√£o digna para aplicativos nativos?</a></li>
<li><a href="../pt414611/index.html">Minha hist√≥ria de cria√ß√£o de um aplicativo motivacional (iOS e Android) para uma filha com uma filha no Unity e C #</a></li>
<li><a href="../pt414615/index.html">Esque√ßa o RGPD: a reforma dos direitos autorais da UE pode mudar completamente a web</a></li>
<li><a href="../pt414617/index.html">Efici√™ncia de recursos de computa√ß√£o</a></li>
<li><a href="../pt414621/index.html">O sistema rob√≥tico acelera a amostragem e os testes de sangue</a></li>
<li><a href="../pt414625/index.html">Data Center World: vale a pena a viagem?</a></li>
<li><a href="../pt414627/index.html">Desenvolvimento Seguro no PHDays 8: Resultados da Reuni√£o da Comunidade PDUG</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
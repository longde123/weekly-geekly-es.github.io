<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😵 🔊 🦄 关于在手指上创建预算立体图像（立体图，浮雕图，立体镜） 🏴󠁧󠁢󠁷󠁬󠁳󠁿 🗼 🧗🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="下周末到了，您需要编写几十行代码并画一幅画，但是没有一个更好。 因此，上周末在最后一个周末之前，我展示了如何进行光线追踪 ，甚至炸毁所有东西。 这对于许多人来说是令人惊讶的，但是计算机图形是非常简单的事情，几百行裸C ++足以创建有趣的图片。 

 今天的对话主题是双目视觉，今天我们甚至无法达到一百...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>关于在手指上创建预算立体图像（立体图，浮雕图，立体镜）</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/438646/"> 下周末到了，您需要编写几十行代码并画一幅画，但是没有一个更好。 因此，上周末在最后一个周末之前，我展示了如何<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">进行光线追踪</a> ，甚至<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">炸毁所有东西。</a> 这对于许多人来说是令人惊讶的，但是计算机图形是非常简单的事情，几百行裸C ++足以创建有趣的图片。 <br><br> 今天的对话主题是双目视觉，今天我们甚至无法达到一百行代码。 能够渲染三维场景，通过立体修复是很愚蠢的，今天我们将绘制如下内容： <br><br><img src="https://habrastorage.org/webt/2-/8t/3n/2-8t3n-oonieil_v4f_lntjpvzk.jpeg"><br><a name="habracut"></a><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Magic Carpet</a>开发人员的愚蠢行为困扰着我。 对于那些没有找到它的人，该游戏使<b>在主要设置</b>中的立体字和立体图<b>中</b>进行3D渲染成为可能<b>，这些菜单仅在菜单中可用！</b> 这个大脑专门爆炸了。 <br><br><h1> 视差 </h1><br> 因此，让我们开始吧。 首先，为什么我们的视觉设备可以让我们感知深度？ 有一个聪明的词“视差”。 如果在手指上，那么我们将注意力集中在屏幕上。 我们大脑屏幕平面中的所有内容都存在一个副本中。 但是，如果突然有苍蝇在屏幕前飞过，那么（如果我们不改变视线！）我们的大脑将一式两份地记录下来。 同时，屏幕后面的墙上的蜘蛛也会分叉，分叉的方向取决于对象位于焦点的前面还是后面： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a40/e9b/b9d/a40e9bb9d4a6e0cddcdce4bdfcc5095d.png"><br><br> 我们的大脑是一种非常有效的机器，用于分析略有不同的图像。 它使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">视差</a>从二维视网膜图像中获取深度信息以进行<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">立体视</a> 。 好吧，上帝保佑他们，用这些文字，让我们更好地画画吧！ <br><br> 假设我们的屏幕是进入虚拟世界的窗口：) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c9a/645/594/c9a645594d957d52f5d4c3e067bd3cb7.png"><br><br> 我们的任务是绘制两张图片，通过此“窗口”将可见。 在上图中，有两张图片，每只眼睛一张，我给它们显示了红色和蓝色的“三明治”。 我们不必担心我们如何将这些图片准确地馈送到视觉设备，我们只需要保存两个文件即可。 我对如何使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">光线追踪器</a>获取这些图像特别感兴趣。 <br><br> 好吧，假设外观的方向不变，它是一个向量（0,0，-1）。 假设我们可以将摄像机的位置移动两眼之间的距离，还有什么呢？ 有一个小妙处：通过我们的“窗口”的视锥是不对称的。 而且我们的光线追踪器只能渲染对称的凝视锥： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e00/5c1/b99/e005c1b996cc7eb9978bc434f6773196.png"><br><br> 怎么办 阅读:) <br> 实际上，我们可以将图片渲染得比所需的宽，而仅裁剪多余的图片： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cb8/f49/3d1/cb8f493d14679c297d6510a1a79ef1a3.png"><br><br><h1> 浮雕 </h1><br> 有了一般的渲染机制，应该很清楚，现在是时候问问自己将图像传输到我们的大脑了。 最简单的选择之一是红蓝色眼镜： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd4/7fb/815/cd47fb815c7a1e80e2d908049e8e4bf0.jpg"><br><br> 我们只是使两个预渲染器不是黑色而是白色，将左图写在红色通道中，将右图写成蓝色。 您将获得以下图片： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9d7/8f6/4f3/9d78f64f371b5960b1d19f5deaff0d9e.jpg"><br><br> 红色玻璃将切断一个通道，蓝色玻璃将切断另一个通道，以便每只眼睛都能收到自己的图片，我们可以用3D视角看世界。 这是对<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">第一篇文章的主要提交</a>的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">更改</a> ，其中显示了双眼和通道部件的相机设置。 <br><br> 浮雕效果渲染是查看（计算机！）立体图片的最古老的方法之一。 它们有很多缺点，例如，较差的色彩渲染（顺便说一下，请尝试在最终图片的绿色通道中记录右眼的绿色通道）。 好处之一-这种眼镜很容易用即兴的材料制成。 <br><br><h1> 立体镜 </h1><br> 随着智能手机的普及，我们记得什么是立体镜（有史以来第二个是在19世纪发明的）！ 几年前， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Google建议</a>使用两分钱的镜片（不幸的是，它们并没有在膝盖上完成），一些硬纸板（随处可见）和智能手机（躺在口袋中）来获得可忍受的虚拟现实眼镜： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/328/5d8/98a/3285d898a99110b217a0fbdbc8ddb535.jpg"><br><br> 在速卖通上，它们是堆，一块一百卢布。 与浮雕相比，您根本不需要做任何事情，只需拍摄两张照片并排组成， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">这就是提交</a> 。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/82e/563/cfe/82e563cfe69db42b7f5f2f399261d12d.jpg"><br><br> 严格来说，视镜头而定，可能需要<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">校正</a>镜头<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">畸变</a> ，但我一点也不费心，而且在我的眼镜上看起来很棒。 但是，如果您确实需要应用桶形预失真来补偿镜头的畸变，那么这就是我的智能手机和眼镜的外观： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9e2/583/9f5/9e25839f5ea28b1f4e092106f60bebfe.jpg"><br><br><h1> 立体图 </h1><br> 但是，如果您不想使用其他设备怎么办？ 然后只有一种选择-麻木。 一般来说，上一张图片足以观看立体声，只需使用技巧即可观看立体声。 查看立体图有两个原理：移开眼睛或移开眼睛。 因此，我绘制了一个图表，其中显示了如何查看上一张图片。 上一张是双图，图中的两个红色条显示了左视网膜上的两个图像，右边的两个蓝条。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/86e/14a/47b/86e14a47b4e2ae8aa9246becb7155827.png"><br><br> 如果我们将视线集中在屏幕上，那么在四张图像中，我们会得到两张。 如果我们斜着眼睛看鼻子，就很有可能显示大脑的“三张”照片。 反之亦然，如果睁开眼睛，还可以获得“三张”照片。 叠加中央图像将使大脑具有立体效果。 <br><br> 这些方法以不同的方式提供给不同的人，例如，我根本不知道如何移动眼睛，但我很容易繁殖。 重要的是，必须以相同的方式查看为一种方法构造的立体图，否则将获得倒置的深度图（请参见负视差和正视差）。 这种观看立体声的方法的问题在于，相对于正常状态，很难<b>强烈地</b>移动眼睛，因此您必须对小图片感到满意。 而且，如果您想要大的呢？ 让我们完全牺牲色彩，只想要深度的感觉。 展望未来，这是我们在本部分末尾看到的图片： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f7b/e7b/ab2/f7be7bab228dcd5133b2d1ff3a9032e1.jpg"><br><br> 该立体图旨在“稀释”眼睛（壁眼立体图）。 对于那些喜欢反向观看的人， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">请在此处拍照</a> 。 如果您不习惯于立体图，请尝试不同的条件：全屏图像，小图像，明亮的光线，黑暗的环境。 任务是睁开眼睛，使两个相邻的涡旋带重合。 专注于左上方的最简单方法是 她很平坦。 例如，我被哈勃（Habr）的环境所包围，我全屏打开图片。 不要忘记从中删除鼠标！ <br><br> 对缺陷的3D效果不满意。 如果您只是模糊地意识到随机点中间的圆形以及一些微弱的3D效果，那肯定是不完整的幻觉！ 如果您正确看待，球应该清楚地从屏幕平面向观察者伸出，并且由于对图像的每个部分（前景和背景）都进行了持续而细致的研究，效果应该稳定并保持不变。 立体视觉有滞后现象：一旦获得稳定的图像，您看得越久越清晰。 屏幕离眼睛越远，深度效果就越大。 <br><br> 该立体图是根据Thimbleby等人在25年前提出的方法绘制的，该方法在他们的文章“ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">显示3D图像：单图像随机点立体图的算法</a> ”中。 <br><br><h3> 起点 </h3><br> 渲染立体图的起点是深度图（我们忘记了颜色）。  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">这是一个</a>渲染图<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">的提交</a> ： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/53c/201/75f/53c20175f5fa2667a7dd7592fee343c4.jpg"><br><br> 我们渲染中的深度被近平面和远平面所截断，也就是说，我的地图中最远的点的深度为0，最接近的点为0。 <br><br><h3> 基本原理 </h3><br> 让我们的眼睛与屏幕保持距离d。 将（假想的）远平面（z = 0）放在屏幕后面相同的距离处。 我们选择一个常数μ，该常数决定了近平面的位置（z = 0）：它将与另一平面相距μd。 我在代码中选择了μ= 1/3。 总的来说，我们整个世界的生活距离d-μd到屏幕后面的d。 让我们在两眼之间定义一个距离e（以像素为单位，在我的代码中，我选择了400像素）。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c6/0eb/e87/5c60ebe872837aea90879fa0798ac7e7.png"><br><br> 如果我们查看对象在图上标记为红色的点，则两个标记为绿色的像素在立体图中应具有相同的颜色。 如何找到这些像素之间的距离？ 很简单 如果当前投影点的深度为z，则视差与眼睛之间距离的比率等于相应深度的比率：p / e =（d-dμz）/（2d-dμz）。 顺便说一下，请注意d正在缩小，并且在其他任何地方都没有涉及！ 也就是说，p / e =（1-μz）/（2-μz），这意味着视差等于p = e *（1-μz）/（2-μz）像素。 <br><br> 也就是说，构造立体图的基本原理是：我们遍历整个深度图，对于每个深度值，我们确定哪些像素应具有相同的颜色，并将其写入我们的限制系统。 然后，我们从任意图片开始，并尝试满足所有先前施加的限制。 <br><br><h3> 准备原始图片 </h3><br> 在此阶段，我们将准备一张图片，稍后将对其施加视差限制。 <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在这里，提交</a> ，他画出这幅画： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/197/441/685/197441685bf85d56e5416e0af899ace1.jpg"><br><br> 请注意，通常，颜色只是随机的，除了我在红色通道中放入rand（）* sin以提供周期性波。 这些波产生的距离为200个像素，这（选择的μ= 1/3和e = 400）是我们世界上的最大视差值，它也是一个遥远的平面。 这些波是可选的，但它们将有助于视觉的必要聚焦。 <br><br><h3> 渲染立体图 </h3><br> 实际上，与立体图相关的完整代码如下所示： <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parallax</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> z)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> eye_separation = <span class="hljs-number"><span class="hljs-number">400.</span></span>; <span class="hljs-comment"><span class="hljs-comment">// interpupillary distance in pixels const float mu = .33; // if the far plane is a distance D behind the screen, then the near plane is a distance mu*D in front of the far plane return static_cast&lt;int&gt;(eye_separation*((1.-z*mu)/(2.-z*mu))+.5); } size_t uf_find(std::vector&lt;size_t&gt; &amp;same, size_t x) { return same[x]==x ? x : uf_find(same, same[x]); } void uf_union(std::vector&lt;size_t&gt; &amp;same, size_t x, size_t y) { if ((x=uf_find(same, x)) != (y=uf_find(same, y))) same[x] = y; } int main() { [...] for (size_t j=0; j&lt;height; j++) { // autostereogram rendering loop std::vector&lt;size_t&gt; same(width); std::iota(same.begin(), same.end(), 0); // initialize the union-find data structure (same[i]=i) for (size_t i=0; i&lt;width; i++) { // put the constraints int par = parallax(zbuffer[i+j*width]); int left = i - par/2; int right = left + par; // works better than i+par/2 for odd values of par if (left&gt;=0 &amp;&amp; right&lt;(int)width) uf_union(same, left, right); // left and right pixels will have the same color } for (size_t i=0; i&lt;width; i++) { // resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; } } [...]</span></span></code> </pre> <br> 如果有的话， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在这里提交</a> 。  int视差（const float z）函数给出当前深度值相同颜色的像素之间的距离。 由于线彼此独立（我们没有垂直视差），因此我们逐行绘制立体图。 因此，主循环仅遍历所有行。 对于它们中的每一个，我们从一组完整的无限制像素开始，然后在其上施加成对相等限制，最后，我们将具有一定数量的相同颜色（不相连）像素的簇。 例如，具有左索引的像素和具有右索引的像素最终应该是相同的。 <br><br> 如何存储这组限制？ 最简单的答案是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">并集-查找数据结构</a> 。 我不会描述它，这只是三行代码，您可以在Wikipedia上阅读它。 主要思想是，对于每个群集，我们将对其有一定的“负责任”，它也是一个根像素，我们将使其与原始图片中的颜色相同，并重新绘制群集中的所有其他像素： <br><br><pre> <code class="cpp hljs"> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;width; i++) { <span class="hljs-comment"><span class="hljs-comment">// resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; }</span></span></code> </pre><br><h1> 结论 </h1><br> 好吧，实际上，仅此而已。 二十行代码-我们的立体图已准备就绪，睁开眼睛和头脑，画画！ 顺便说一句，仅立体图中的随机颜色通常是一种奢侈，原则上，如果您尝试尝试，还可以部分传输图片的颜色。 <br><br> 例如，其他立体声观看系统<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">与极化有关</a> ，我超出了讨论范围，因为它们超出了一百卢布的预算。 如果您错过了某些内容，请添加并更正！ </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN438646/">https://habr.com/ru/post/zh-CN438646/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN438636/index.html">Go中的功能嵌入不良</a></li>
<li><a href="../zh-CN438638/index.html">我们分析寻呼机消息POCSAG的协议，第2部分</a></li>
<li><a href="../zh-CN438640/index.html">高速开放电子货币</a></li>
<li><a href="../zh-CN438642/index.html">使用RxJS进行反应式编程的基础</a></li>
<li><a href="../zh-CN438644/index.html">机器学习算法的安全性。 使用Python保护和测试模型</a></li>
<li><a href="../zh-CN438648/index.html">BI系统的比较（Tableau，Power BI，Oracle，Qlik）</a></li>
<li><a href="../zh-CN438650/index.html">火箭9M729。 关于INF条约“违反者”的几句话</a></li>
<li><a href="../zh-CN438652/index.html">Portabelization IDA</a></li>
<li><a href="../zh-CN438654/index.html">OpenSceneGraph：与Qt框架集成</a></li>
<li><a href="../zh-CN438658/index.html">如何学习学习</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨‍🏭 ⬅️ 👩🏿‍🤝‍👨🏽 Haute disponibilité MySQL sur GitHub 👆🏿 🧑 🤳🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="GitHub utilise MySQL comme son principal entrepôt de données pour tout ce qui n'est pas lié à git , donc la disponibilité de MySQL est la clé du fonct...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Haute disponibilité MySQL sur GitHub</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/432088/"><p> GitHub utilise MySQL comme son principal entrepôt de données pour tout ce qui n'est pas lié à <code>git</code> , donc la disponibilité de MySQL est la clé du fonctionnement normal de GitHub.  Le site lui-même, l'API GitHub, le système d'authentification et de nombreuses autres fonctionnalités nécessitent un accès aux bases de données.  Nous utilisons plusieurs clusters MySQL pour gérer divers services et tâches.  Ils sont configurés selon le schéma classique avec un nœud <em>principal</em> disponible pour l'enregistrement et ses répliques.  <em>Les répliques</em> (autres nœuds de cluster) reproduisent de manière asynchrone les modifications apportées au nœud principal et fournissent un accès en lecture. </p><br><p>  La disponibilité des sites hôtes est critique.  Sans le nœud principal, le cluster ne prend pas en charge l'enregistrement, ce qui signifie que vous ne pouvez pas enregistrer les modifications nécessaires.  Corriger les transactions, enregistrer les problèmes, créer de nouveaux utilisateurs, des référentiels, des avis et bien plus sera tout simplement impossible. </p><br><p>  Pour prendre en charge l'enregistrement, un nœud accessible correspondant est requis - le nœud principal du cluster.  Cependant, la capacité d'identifier ou de <em>détecter</em> un tel nœud est tout aussi importante. </p><br><p>  En cas de panne du nœud principal actuel, il est important de s'assurer de l'apparition rapide d'un nouveau serveur pour le remplacer, ainsi que de pouvoir notifier rapidement tous les services de ce changement.  Le temps d'arrêt total correspond au temps nécessaire pour détecter une défaillance, basculer et notifier un nouveau nœud principal. </p><br><p><img src="https://habrastorage.org/webt/m8/ah/po/m8ahpo0jhrucgwj3kb5u7hn9edo.jpeg"></p><a name="habracut"></a><br><p>  Cette publication décrit une solution pour assurer une haute disponibilité de MySQL sur GitHub et découvrir le service principal, ce qui nous permet d'effectuer de manière fiable des opérations couvrant plusieurs centres de données, de maintenir l'opérabilité lorsque certains de ces centres ne sont pas disponibles et de garantir un temps d'arrêt minimum en cas de panne. </p><br><h3 id="celi-obespecheniya-vysokoy-dostupnosti">  Objectifs de haute disponibilité </h3><br><p>  La solution décrite dans cet article est une nouvelle version améliorée des précédentes solutions haute disponibilité (HA) implémentées sur GitHub.  À mesure que nous grandissons, nous devons adapter la stratégie MySQL HA pour changer.  Nous nous efforçons de suivre des approches similaires pour MySQL et d'autres services sur GitHub. </p><br><p>  Pour trouver la bonne solution pour la haute disponibilité et la découverte de services, vous devez d'abord répondre à quelques questions spécifiques.  En voici un exemple: </p><br><ul><li>  Quel temps d'arrêt maximum n'est pas critique pour vous? </li><li>  Quelle est la fiabilité des outils de détection de pannes?  Les faux positifs (traitement des défaillances prématurées) sont-ils critiques pour vous? </li><li>  Quelle est la fiabilité du système de basculement?  Où une panne peut-elle se produire? </li><li>  Quelle est l'efficacité de la solution dans plusieurs centres de données?  Quelle est l'efficacité de la solution dans les réseaux à latence faible et élevée? </li><li>  La solution continuera-t-elle de fonctionner en cas de panne complète du centre de données (DPC) ou d'isolement du réseau? </li><li>  Quel mécanisme (le cas échéant) empêche ou atténue les conséquences de l'émergence de deux serveurs principaux dans le cluster qui enregistrent indépendamment? </li><li>  La perte de données est-elle critique pour vous?  Si oui, dans quelle mesure? </li></ul><br><p>  Afin de démontrer, considérons d'abord la solution précédente et discutons des raisons pour lesquelles nous avons décidé de l'abandonner. </p><br><h3 id="otkaz-ot-ispolzovaniya-vip-i-dns-dlya-obnaruzheniya">  Refus d'utiliser VIP et DNS pour la découverte </h3><br><p>  Dans le cadre de la solution précédente, nous avons utilisé: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">orchestrateur</a> pour la détection des pannes et le basculement; </li><li>  VIP et DNS pour la découverte d'hôte. </li></ul><br><p>  Dans ce cas, les clients ont découvert un nœud d'enregistrement par son nom, par exemple, <code>mysql-writer-1.github.net</code> .  Le nom a été utilisé pour déterminer l'adresse IP virtuelle (VIP) du nœud principal. </p><br><p>  Ainsi, dans une situation normale, les clients devaient simplement résoudre le nom et se connecter à l'adresse IP reçue, où le nœud principal les attendait déjà. </p><br><p>  Considérez la topologie de réplication suivante qui couvre trois centres de données différents: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8fa/e2e/4f3/8fae2e4f382f3060b5a14ed9d80a5f67.png" alt="image"></p><br><p>  En cas de panne du nœud principal, un nouveau serveur doit être affecté à sa place (une des répliques). </p><br><p>  <code>orchestrator</code> détecte une défaillance, sélectionne un nouveau nœud maître, puis attribue le nom / VIP.  En réalité, les clients ne connaissent pas l'identité du nœud principal, ils ne connaissent que le nom, qui devrait désormais pointer vers le nouveau nœud.  Attention cependant à cela. </p><br><p>  Les adresses VIP sont partagées, les serveurs de bases de données eux-mêmes en font la demande et en sont propriétaires.  Pour recevoir ou libérer un VIP, le serveur doit envoyer une demande ARP.  Le serveur propriétaire du VIP doit d'abord le libérer avant que le nouveau maître puisse accéder à cette adresse.  Cette approche entraîne des conséquences indésirables: </p><br><ul><li>  En mode normal, le système de basculement contactera d'abord le nœud principal défaillant et lui demandera de libérer le VIP, puis se tournera vers le nouveau serveur principal avec une demande d'affectation VIP.  Mais que faire si le premier nœud principal n'est pas disponible ou refuse une demande de libération de l'adresse VIP?  Étant donné que le serveur est actuellement en état de défaillance, il est peu probable qu'il puisse répondre à une demande à temps ou y répondre du tout. <br><ol><li>  En conséquence, une situation peut survenir lorsque deux hôtes revendiquent leurs droits sur le même VIP.  Différents clients peuvent se connecter à n'importe lequel de ces serveurs en fonction du chemin réseau le plus court. </li><li>  Le bon fonctionnement dans cette situation dépend de l'interaction de deux serveurs indépendants et une telle configuration n'est pas fiable. </li></ol></li><li>  Même si le premier nœud principal répond aux demandes, nous perdons un temps précieux: le basculement vers le nouveau serveur principal ne se produit pas lorsque nous contactons l'ancien. </li><li>  De plus, même en cas de réaffectation de VIP, il n'y a aucune garantie que les connexions client existantes sur l'ancien serveur seront déconnectées.  Encore une fois, nous courons le risque d'être dans une situation avec deux nœuds principaux indépendants. </li></ul><br><p>  Ici et là, dans notre environnement, les adresses VIP sont associées à un emplacement physique.  Ils sont affectés à un commutateur ou un routeur.  Par conséquent, nous ne pouvons réaffecter une adresse VIP qu'à un serveur situé dans le même environnement que l'hôte d'origine.  En particulier, dans certains cas, nous ne pourrons pas attribuer un serveur VIP dans un autre centre de données et nous devrons apporter des modifications au DNS. </p><br><ul><li>  La distribution des modifications au DNS prend plus de temps.  Les clients stockent les noms DNS pour une période prédéfinie.  Le basculement impliquant plusieurs centres de données implique un temps d'arrêt plus long, car il faut plus de temps pour fournir à tous les clients des informations sur le nouveau nœud principal. </li></ul><br><p>  Ces restrictions ont été suffisantes pour nous obliger à commencer la recherche d'une nouvelle solution, mais nous avons également dû tenir compte des éléments suivants: </p><br><ul><li>  Les nœuds principaux ont transmis indépendamment des paquets d'impulsions via le service <code>pt-heartbeat</code> pour <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mesurer le retard et la régulation de charge</a> .  Le service a dû être transféré au nœud principal nouvellement nommé.  Si possible, il aurait dû être désactivé sur l'ancien serveur. </li><li>  De même, les nœuds principaux contrôlaient indépendamment le fonctionnement du <a href="">Pseudo-GTID</a> .  Il était nécessaire de démarrer ce processus sur le nouveau nœud principal et de préférence de s'arrêter sur l'ancien. </li><li>  Le nouveau nœud maître est devenu accessible en écriture.  L'ancien nœud (si possible) devrait avoir <code>read_only</code> (lecture seule). </li></ul><br><p>  Ces étapes supplémentaires ont entraîné une augmentation des temps d'arrêt globaux et ajouté leurs propres points de défaillance et de problèmes. </p><br><p>  La solution a fonctionné et GitHub a réussi à gérer les échecs MySQL en arrière-plan, mais nous voulions améliorer notre approche de HA comme suit: </p><br><ul><li>  garantir l'indépendance vis-à-vis de centres de données spécifiques; </li><li>  garantir l'opérabilité en cas de panne du centre de données; </li><li>  Abandonnez les workflows collaboratifs peu fiables </li><li>  réduire les temps d'arrêt totaux; </li><li>  Effectuez, dans la mesure du possible, le basculement sans perte. </li></ul><br><h3 id="ha-reshenie-github-orchestrator-consul-glb">  Solution GitHub HA: orchestrateur, Consul, GLB </h3><br><p>  Notre nouvelle stratégie, ainsi que les améliorations qui l'accompagnent, éliminent la plupart des problèmes mentionnés ci-dessus ou atténuent leurs conséquences.  Notre système HA actuel se compose des éléments suivants: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">orchestrateur</a> pour la détection des pannes et le basculement.  Nous utilisons le schéma <a href="">orchestrateur / raft</a> avec plusieurs centres de données, comme indiqué dans la figure ci-dessous; </li><li>  Hashicorp <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Consul</a> pour la découverte de services; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GLB / HAProxy</a> comme couche proxy entre les clients et les nœuds d'enregistrement.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le code source</a> du GLB Director est ouvert; </li><li>  <code>anycast</code> technologie <code>anycast</code> pour le routage réseau. </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/762/fb4/7a0/762fb47a0de253cce045889faa945228.png" alt="image"></p><br><p>  Le nouveau schéma a permis d'abandonner complètement les modifications apportées au VIP et au DNS.  Désormais, lors de l'introduction de nouveaux composants, nous pouvons les séparer et simplifier la tâche.  De plus, nous avons eu l'opportunité d'utiliser des solutions fiables et stables.  Une analyse détaillée de la nouvelle solution est donnée ci-dessous. </p><br><h3 id="normalnyy-potok">  Débit normal </h3><br><p>  Dans une situation normale, les applications se connectent aux nœuds d'enregistrement via GLB / HAProxy. </p><br><p>  Les applications ne reçoivent pas l'identité du serveur principal.  Comme auparavant, ils n'utilisent que le nom.  Par exemple, le nœud principal de <code>cluster1</code> serait <code>mysql-writer-1.github.net</code> .  Cependant, dans notre configuration actuelle, ce nom se résout en l'adresse IP <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">anycast</a> . </p><br><p>  Grâce à la technologie <code>anycast</code> , le nom est résolu à la même adresse IP n'importe où, mais le trafic est dirigé différemment, compte tenu de l'emplacement du client.  En particulier, plusieurs instances de GLB, notre équilibreur de charge hautement disponible, sont déployées dans chacun de nos centres de données.  Le trafic sur <code>mysql-writer-1.github.net</code> toujours acheminé vers le cluster GLB du centre de données local.  Pour cette raison, tous les clients sont servis par des mandataires locaux. </p><br><p>  Nous exécutons GLB sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HAProxy</a> .  Notre serveur HAProxy fournit <em>des pools d'écriture</em> : un pour chaque cluster MySQL.  De plus, chaque pool ne possède qu'un seul serveur (le nœud <em>principal</em> du cluster).  Toutes les instances GLB / HAProxy dans tous les centres de données ont les mêmes pools, et elles pointent toutes vers les mêmes serveurs dans ces pools.  Ainsi, si l'application souhaite écrire des données dans la base de données sur <code>mysql-writer-1.github.net</code> , peu importe le serveur GLB auquel elle se connecte.  Dans les deux cas, une redirection vers le nœud de cluster principal réel <code>cluster1</code> sera effectuée. </p><br><p>  Pour les applications, la découverte se termine sur GLB et la redécouverte n'est pas nécessaire.  Ce GLB redirige le trafic au bon endroit. </p><br><p>  Où le GLB obtient-il des informations sur les serveurs à répertorier?  Comment modifions-nous le GLB? </p><br><h3 id="obnaruzhenie-cherez-consul">  Découverte par le consul </h3><br><p>  Le service Consul est largement connu comme une solution de découverte de services, et il prend également en charge les fonctions DNS.  Cependant, dans notre cas, nous l'utilisons comme un stockage hautement accessible des valeurs clés (KV). </p><br><p>  Dans le référentiel KV de Consul, nous enregistrons l'identité des nœuds principaux du cluster.  Pour chaque cluster, il existe un ensemble d'enregistrements KV pointant vers les données du nœud principal correspondant: ses adresses <code>fqdn</code> , port, ipv4 et ipv6. </p><br><p>  Chaque nœud GLB / HAProxy lance un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">modèle de consul</a> , un service qui suit les changements dans les données du consul (dans notre cas, les changements dans les données des nœuds principaux).  Le <code>consul-template</code> crée un fichier de configuration et peut recharger HAProxy lors de la modification des paramètres. </p><br><p>  Pour cette raison, des informations sur la modification de l'identité du nœud principal dans Consul sont disponibles pour chaque instance GLB / HAProxy.  Sur la base de ces informations, la configuration des instances est effectuée, les nouveaux nœuds principaux sont indiqués comme la seule entité dans le pool de serveurs de cluster.  Après cela, les instances sont rechargées pour que les modifications prennent effet. </p><br><p>  Nous avons déployé des instances Consul dans chaque centre de données et chaque instance offre une haute disponibilité.  Cependant, ces instances sont indépendantes les unes des autres.  Ils ne se répliquent pas et n'échangent aucune donnée. </p><br><p>  Où Consul obtient-il des informations sur les changements et comment est-il distribué entre les centres de données? </p><br><h3 id="orchestratorraft">  orchestrateur / radeau </h3><br><p>  Nous utilisons le schéma <code>orchestrator/raft</code> : <code>orchestrator</code> nœuds d' <code>orchestrator</code> communiquent entre eux par le biais d'un consensus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">radeau</a> .  Dans chaque centre de données, nous avons un ou deux nœuds d' <code>orchestrator</code> . </p><br><p>  <code>orchestrator</code> est chargé de détecter les pannes, le basculement MySQL et de transférer les données modifiées du nœud maître vers Consul.  Le basculement est géré par un seul hôte <code>orchestrator/raft</code> , mais les <em>modifications</em> , nouvelles que le cluster est désormais un nouveau maître, sont propagées à tous <code>orchestrator</code> nœuds d' <code>orchestrator</code> à l'aide du mécanisme <code>raft</code> . </p><br><p>  Lorsque les nœuds d' <code>orchestrator</code> reçoivent des informations sur une modification des données du nœud principal, chacun d'eux contacte sa propre instance locale de Consul et lance un enregistrement KV.  Les centres de données avec plusieurs instances d' <code>orchestrator</code> recevront plusieurs enregistrements (identiques) dans Consul. </p><br><h3 id="obobschennoe-predstavlenie-vsego-potoka">  Vue généralisée de l'ensemble du flux </h3><br><p>  Si le nœud maître échoue: </p><br><ul><li>  <code>orchestrator</code> nœuds d' <code>orchestrator</code> détectent les pannes; </li><li>  <code>orchestrator/raft</code> master lance la récupération.  Un nouveau nœud maître est attribué; </li><li>  le schéma <code>orchestrator/raft</code> transfère les données sur le changement du nœud principal à tous les nœuds du cluster de <code>raft</code> ; </li><li>  chaque instance d' <code>orchestrator/raft</code> reçoit une notification concernant un changement de nœud et écrit l'identité du nouveau nœud maître dans le stockage KV local dans Consul; </li><li>  sur chaque instance GLB / HAProxy, le service de <code>consul-template</code> est lancé, qui surveille les changements dans le référentiel KV dans Consul, reconfigure et redémarre HAProxy; </li><li>  Le trafic client est redirigé vers le nouveau nœud maître. </li></ul><br><p>  Pour chaque composante, les responsabilités sont clairement réparties et l'ensemble de la structure est diversifié et simplifié.  <code>orchestrator</code> n'interagit pas avec les équilibreurs de charge.  Le consul n'a pas besoin d'informations sur l'origine des informations.  Les serveurs proxy fonctionnent uniquement avec Consul.  Les clients ne fonctionnent qu'avec des serveurs proxy. </p><br><p>  De plus: </p><br><ul><li>  Pas besoin d'apporter des modifications au DNS et de diffuser des informations à leur sujet; </li><li>  TTL n'est pas utilisé; </li><li>  le thread n'attend pas les réponses de l'hôte dans un état d'erreur.  En général, il est ignoré. </li></ul><br><h3 id="dopolnitelnaya-informaciya">  Information additionnelle </h3><br><p>  Pour stabiliser le flux, nous appliquons également les méthodes suivantes: </p><br><ul><li>  Le paramètre d' <code>hard-stop-after</code> fixe HAProxy est défini sur une très petite valeur.  Lorsque HAProxy redémarre avec le nouveau serveur dans le pool d'écriture, le serveur met automatiquement fin à toutes les connexions existantes à l'ancien nœud maître. <br><ol><li>  La définition du paramètre d' <code>hard-stop-after</code> urgence vous permet de ne pas attendre d'actions des clients, en outre, les conséquences négatives de l'occurrence possible de deux nœuds principaux dans le cluster sont minimisées.  Il est important de comprendre qu'il n'y a pas de magie ici, et en tout cas, un <em>certain temps</em> s'écoule avant que les anciens liens ne soient rompus.  Mais il y a un moment où nous pouvons cesser d'attendre des surprises désagréables. </li></ol></li><li>  Nous n'exigeons pas la disponibilité continue du service Consul.  En fait, nous avons besoin qu'il soit disponible uniquement pendant le basculement.  Si le service Consul ne répond pas, alors GLB continue de travailler avec les dernières valeurs connues et ne prend pas de mesures drastiques. </li><li>  Le GLB est configuré pour vérifier l'identité du nœud maître nouvellement affecté.  Comme pour nos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pools MySQL contextuels</a> , une vérification est effectuée pour confirmer que le serveur est bien accessible en écriture.  Si nous supprimons accidentellement l'identité du nœud principal dans Consul, il n'y aura aucun problème, un enregistrement vide sera ignoré.  Si nous écrivons par erreur le nom d'un autre serveur (pas le principal) dans Consul, alors dans ce cas, tout va bien: GLB ne le mettra pas à jour et continuera de fonctionner avec le dernier état valide. </li></ul><br><p>  Dans les sections suivantes, nous examinons les problèmes et analysons les objectifs de haute disponibilité. </p><br><h3 id="obnaruzhenie-sboev-s-pomoschyu-orchestratorraft">  Détection de crash avec orchestrateur / radeau </h3><br><p>  <code>orchestrator</code> adopte une <a href="">approche globale</a> de la détection des pannes, ce qui garantit une grande fiabilité de l'outil.  Nous ne rencontrons pas de faux résultats positifs, les pannes prématurées ne sont pas effectuées, ce qui signifie que les temps d'arrêt inutiles sont exclus. </p><br><p>  Les circuits d' <code>orchestrator/raft</code> également face à des situations d'isolement complet du réseau du centre de données (clôture du centre de données).  L'isolement du réseau du centre de données peut être source de confusion: les serveurs à l'intérieur du centre de données peuvent communiquer entre eux.  Comment comprendre qui est vraiment isolé - les serveurs d' <em>un</em> centre de données <em>donné</em> ou de tous les <em>autres</em> centres de données? </p><br><p>  Dans le schéma <code>orchestrator/raft</code> , le maître de <code>orchestrator/raft</code> est le basculement.  Le nœud devient le leader, qui reçoit le soutien de la majorité du groupe (quorum).  Nous avons déployé le nœud d' <code>orchestrator</code> de telle manière qu'aucun centre de données unique ne peut fournir la majorité, tandis que n'importe quel centre de données <code>n-1</code> peut le fournir. </p><br><p>  Dans le cas d'une isolation complète du réseau du centre de données, les nœuds d' <code>orchestrator</code> de ce centre sont déconnectés des nœuds similaires d'autres centres de données.  Par conséquent, les nœuds d' <code>orchestrator</code> d'un centre de données isolé ne peuvent pas devenir les leaders d'un cluster de <code>raft</code> .  Si un tel nœud était le maître, il perd ce statut.  Un nouvel hôte se verra attribuer l'un des nœuds des autres centres de données.  Ce leader aura le soutien de tous les autres centres de données qui peuvent interagir les uns avec les autres. </p><br><p>  De cette façon, le maître d' <code>orchestrator</code> sera toujours en dehors du centre de données isolé du réseau.  Si le nœud maître se trouvait dans le centre de données isolé, <code>orchestrator</code> lance un basculement pour le remplacer par le serveur de l'un des centres de données disponibles.  Nous atténuons l'impact de l'isolement des centres de données en déléguant des décisions au quorum des centres de données disponibles. </p><br><h3 id="uskorennoe-opoveschenie">  Notification plus rapide </h3><br><p>  Le temps d'indisponibilité total peut être encore réduit en accélérant la notification d'un changement dans le nœud principal.  Comment y parvenir? </p><br><p>  Lorsque l' <code>orchestrator</code> démarre le basculement, il considère un groupe de serveurs, dont l'un peut être affecté comme serveur principal.  Compte tenu des règles de réplication, des recommandations et des limites, il est en mesure de prendre une décision éclairée sur la meilleure ligne de conduite. </p><br><p>  Selon les signes suivants, il peut également comprendre qu'un serveur accessible est <em>un candidat idéal</em> pour une nomination comme principal: </p><br><ul><li>  rien n'empêche le serveur de devenir élevé (et peut-être que l'utilisateur recommande ce serveur); </li><li>  il est prévu que le serveur pourra utiliser tous les autres serveurs comme répliques. </li></ul><br><p>  Dans ce cas, <code>orchestrator</code> configure d'abord le serveur comme accessible en écriture et annonce immédiatement une augmentation de son état (dans notre cas, il écrit l'enregistrement dans le référentiel KV dans Consul).   orchestrator     ,     . </p><br><p>  ,    ,    GLB   ,     ,     .   :    ! </p><br><h3 id="polusinhronnaya-replikaciya">   </h3><br><p>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a> MySQL         ,           .       :  ,    ,   ,        . </p><br><p>     ,      .        ,    ,   .  ,    ,           ,    . </p><br><p>       : <code>500 </code> .                    .          (    ),          . </p><br><p>                   (   )    .           ,      . </p><br><p>       ,        <em> </em>     .            <em></em> ,      ,  <em></em>    .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> ,       <em> </em> , ,       . </p><br><h3 id="peredacha-paketov-pulsa">    </h3><br><p>  ,   /  <code>pt-heartbeat</code>  /  ,       .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> ,   <code>pt-heartbeat</code>     ,       <code>read_only</code> ,    . </p><br><p>      <code>pt-heartbeat</code>     ,     .       .               .     ,  <code>pt-heartbeat</code>              . </p><br><h3 id="delegirovanie-zadach-orchestrator">   orchestrator </h3><br><p>    orchestrator  : </p><br><ul><li>  Pseudo-GTID; </li><li>       ,    ; </li><li>         ( <code>read_only</code> ),   . </li></ul><br><p>    ,     . ,      ,      ,      .     <code>orchestrator</code>         . </p><br><h3 id="ogranicheniya-i-nedostatki">    </h3><br><p>  -   ,        ,         .     ,   -,         . </p><br><p>     ,       . </p><br><p> ,      ,     ,     -      .         .               <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">STONITH</a>    .    ,  <em> </em> ,       ,    «» -   .  ,       ,  . </p><br><p>    :  Consul    ,     . .  , ,      ,    ,      . </p><br><h3 id="rezultaty">  </h3><br><p>   orchestrator/GLB/Consul   : </p><br><ul><li>   ; </li><li>      ; </li><li>       ; </li><li>    ; </li><li>  ,      (    ); </li><li>    ; </li><li>    <code>10-13 </code>   . <br><ol><li>        <code>20 </code> ,      — <code>25 </code> . </li></ol></li></ul><br><h3 id="zaklyuchenie">  Conclusion </h3><br><p>  «// »         ,   ,   .       .     ,    . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr432088/">https://habr.com/ru/post/fr432088/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr432078/index.html">Trafic au bout du tunnel ou DNS dans le pentest</a></li>
<li><a href="../fr432080/index.html">Idées fausses des joueurs lors de l'évaluation des risques. Contrôle du générateur de nombres aléatoires en développement</a></li>
<li><a href="../fr432082/index.html">Microsoft AI Chatbot lance une collection de vêtements en Chine</a></li>
<li><a href="../fr432084/index.html">Comment nous avons organisé une compétition par équipes entre les travailleurs de la production (comme en URSS)</a></li>
<li><a href="../fr432086/index.html">Impression 3D à l'école internationale du nom de M.V. Lomonosov</a></li>
<li><a href="../fr432090/index.html">Magento Meetup Kharkiv No. 4 - rapports vidéo</a></li>
<li><a href="../fr432092/index.html">Erreurs désagréables lors de l'écriture des tests unitaires</a></li>
<li><a href="../fr432094/index.html">Hackathon en ligne conjoint d'OpenGift et de la plateforme Blockchain de crédits</a></li>
<li><a href="../fr432096/index.html">Guide CMake complet. Deuxième partie: Build System</a></li>
<li><a href="../fr432098/index.html">Pilotes automatiques dans le transport routier, comment interagir avec les spéciaux. en transport?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
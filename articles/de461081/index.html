<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§ß üòª ü§¶üèΩ Der Tag, an dem Dodo aufgeh√∂rt hat. Asynchrones Skript üëÜüèΩ üôè ü¶ñ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! Jeder SRE in unserem Team tr√§umte einmal davon, nachts friedlich zu schlafen. Tr√§ume werden wahr. In diesem Artikel werde ich dar√ºber spre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Der Tag, an dem Dodo aufgeh√∂rt hat. Asynchrones Skript</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dodopizzadev/blog/461081/">  Hallo Habr!  Jeder SRE in unserem Team tr√§umte einmal davon, nachts friedlich zu schlafen.  Tr√§ume werden wahr.  In diesem Artikel werde ich dar√ºber sprechen und wie wir die Leistung und Stabilit√§t unseres Dodo IS-Systems erreichen. <br><br><img src="https://habrastorage.org/webt/wk/2o/t6/wk2ot6razkmzgly1s69fdwz5quq.png"><a name="habracut"></a><br><blockquote>  <b>Eine Reihe von Artikeln √ºber den Zusammenbruch des Dodo IS * -Systems</b> : <br><br>  1. Der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tag, an dem Dodo aufgeh√∂rt hat.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Synchrones Skript.</a> <br>  2. Der Tag, an dem Dodo aufgeh√∂rt hat.  Asynchrones Skript. <br><br>  * Die <i>Materialien wurden basierend auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">meiner Leistung bei DotNext 2018 in Moskau geschrieben</a></i> . </blockquote>  In einem fr√ºheren Artikel haben wir uns mit dem Blockieren von Codeproblemen im Preemptive Multitasking-Paradigma befasst.  Es wurde angenommen, dass es notwendig war, den Blockierungscode auf async / await neu zu schreiben.  Also haben wir es getan.  Lassen Sie uns nun dar√ºber sprechen, welche Probleme dabei aufgetreten sind. <br><br><h2>  Wir f√ºhren den Begriff Parallelit√§t ein </h2><br>  Bevor Sie zu Async gelangen, m√ºssen Sie den Begriff Parallelit√§t eingeben. <br><blockquote>  In der Warteschlangentheorie ist <b>Parallelit√§t</b> die Anzahl der Clients, die sich derzeit im System befinden.  Parallelit√§t wird manchmal mit Parallelit√§t verwechselt, aber in Wirklichkeit sind dies zwei verschiedene Dinge. </blockquote>  F√ºr diejenigen, die zum ersten Mal neu bei Concurrency sind, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">empfehle ich Rob Pikes Video</a> .  Parallelit√§t ist, wenn wir viele Dinge gleichzeitig erledigen, und Parallelit√§t ist, wenn wir viele Dinge gleichzeitig tun. <br><br>  In Computern passieren nicht viele Dinge parallel.  Eine solche Sache ist das Rechnen auf mehreren Prozessoren.  Der Grad der Parallelit√§t wird durch die Anzahl der CPU-Threads begrenzt. <br><br>  Tats√§chlich ist Threads Teil des Preemptive Multitasking-Konzepts, einer M√∂glichkeit, die Parallelit√§t in einem Programm zu modellieren, wenn wir uns in der Frage der Parallelit√§t auf das Betriebssystem verlassen.  Dieses Modell bleibt n√ºtzlich, solange wir verstehen, dass wir uns speziell mit dem Parallelit√§tsmodell und nicht mit der Parallelit√§t befassen. <br><br>  Async / await ist syntaktischer Zucker f√ºr State Machine, ein weiteres n√ºtzliches Parallelit√§tsmodell, das in einer Single-Thread-Umgebung ausgef√ºhrt werden kann.  Im Wesentlichen handelt es sich um kooperatives Multitasking - das Modell selbst ber√ºcksichtigt die Parallelit√§t √ºberhaupt nicht.  In Kombination mit Multithreading erhalten wir ein Modell √ºber das andere, und das Leben ist sehr kompliziert. <br><br><h2>  Vergleich der beiden Modelle </h2><br><h4>  Wie es im Preemptive Multitasking-Modell funktioniert hat </h4><br>  Angenommen, wir haben 20 Threads und 20 Anforderungen in der Verarbeitung pro Sekunde.  Das Bild zeigt einen Spitzenwert - 200 Anforderungen gleichzeitig im System.  Wie konnte das passieren: <br><br><ul><li>  Anforderungen k√∂nnen gruppiert werden, wenn 200 Clients gleichzeitig auf eine Schaltfl√§che klicken. </li><li>  Der Garbage Collector konnte Anforderungen f√ºr einige zehn Millisekunden stoppen. </li><li>  Anforderungen k√∂nnen in jeder Warteschlange verz√∂gert werden, wenn der Proxy die Warteschlange unterst√ºtzt. </li></ul><br>  Es gibt viele Gr√ºnde, warum sich Anfragen f√ºr einen kurzen Zeitraum angesammelt haben und in einem einzigen B√ºndel eingehen.  Auf jeden Fall passierte nichts Schreckliches, sie standen in der Thread Pool Warteschlange und wurden langsam fertig.  Es gibt keine Gipfel mehr, alles geht weiter, als w√§re nichts passiert. <br><br>  Angenommen, der Smart Thread Pool-Algorithmus (und es gibt dort Elemente des maschinellen Lernens) hat entschieden, dass es bisher keinen Grund gibt, die Anzahl der Threads zu erh√∂hen.  Der Verbindungspool in MySql ist ebenfalls 20, da Threads = 20 ist.  Dementsprechend ben√∂tigen wir nur 20 Verbindungen zu SQL. <br><br><img src="https://habrastorage.org/webt/gm/ch/pz/gmchpzxpvegoyljdauranwzgn7k.png"><br><br>  In diesem Fall ist die Parallelit√§tsstufe des Servers aus Sicht des externen Systems = 200. Der Server hat diese Anforderungen bereits empfangen, aber noch nicht abgeschlossen.  F√ºr eine Anwendung, die im Multithreading-Paradigma ausgef√ºhrt wird, ist die Anzahl gleichzeitiger Anforderungen jedoch durch die aktuelle Gr√∂√üe des Thread-Pools = 20 begrenzt. Es handelt sich also um den Grad der Parallelit√§t = 20. <br><br><h4>  Wie jetzt alles im asynchronen Modell funktioniert </h4><br><img width="33%" height="33%" src="https://habrastorage.org/webt/dg/yz/pz/dgyzpzj-nl9rawn5ctxdfr3gxgm.png"><br><br>  Mal sehen, was in einer Anwendung passiert, die async / await mit derselben Last und Verteilung von Anforderungen ausf√ºhrt.  Vor dem Erstellen einer Aufgabe gibt es keine Warteschlange, und die Anforderung wird sofort verarbeitet.  Nat√ºrlich wird Thread von ThreadPool f√ºr kurze Zeit verwendet, und der erste Teil der Anforderung wird sofort ausgef√ºhrt, bevor die Datenbank kontaktiert wird.  Da Thread schnell zum Thread-Pool zur√ºckkehrt, ben√∂tigen wir nicht viele Threads zur Verarbeitung.  In diesem Diagramm wird der Thread-Pool √ºberhaupt nicht angezeigt, er ist transparent. <br><br><img src="https://habrastorage.org/webt/bm/6h/to/bm6hto7o6gxnrlg9ruzhfsxfet0.png"><br><br>  Was bedeutet das f√ºr unsere Bewerbung?  Das externe Bild ist das gleiche - der Grad der Parallelit√§t = 200. Gleichzeitig hat sich die Situation im Inneren ge√§ndert.  Fr√ºher waren Anforderungen in der ThreadPool-Warteschlange "√ºberf√ºllt", jetzt betr√§gt der Grad der Parallelit√§t der Anwendung ebenfalls 200, da TaskScheduler keine Einschr√§nkungen aufweist.  Hurra!  Wir haben das Ziel der Asynchronit√§t erreicht - die Anwendung "bew√§ltigt" nahezu jeden Grad an Parallelit√§t! <br><br><h4>  Folgen: nichtlineare Verschlechterung des Systems </h4><br>  Die Anwendung ist aus Sicht der Parallelit√§t transparent geworden, sodass die Parallelit√§t jetzt auf die Datenbank projiziert wird.  Jetzt brauchen wir einen Verbindungspool mit der gleichen Gr√∂√üe = 200. Die Datenbank ist die CPU, der Speicher, das Netzwerk, der Speicher.  Dies ist der gleiche Dienst mit seinen Problemen wie jeder andere.  Je mehr Anforderungen wir gleichzeitig ausf√ºhren m√∂chten, desto langsamer werden sie ausgef√ºhrt. <br><br>  Bei voller Auslastung der Datenbank verschlechtert sich die Antwortzeit bestenfalls linear: Sie haben doppelt so viele Abfragen gestellt, sie begann doppelt so langsam zu arbeiten.  In der Praxis tritt aufgrund des Abfragewettbewerbs zwangsl√§ufig ein Overhead auf, und es kann sich herausstellen, dass sich das System nicht linear verschlechtert. <br><br><h4>  Warum passiert das? </h4><br>  Gr√ºnde f√ºr die zweite Bestellung: <br><br><ul><li>  Jetzt muss die Datenbank gleichzeitig im Speicher der Datenstruktur gespeichert werden, um mehr Anforderungen zu bedienen. </li><li>  Jetzt muss die Datenbank gr√∂√üere Sammlungen bedienen (und dies ist algorithmisch nachteilig). </li></ul><br>  Grund erster Ordnung: <br><br><ul><li>  Streit, der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im vorherigen Artikel</a> ein wenig diskutiert wurde. </li></ul><br>  Am Ende k√§mpft Async gegen begrenzte Ressourcen und ... gewinnt!  Die Datenbank schl√§gt fehl und wird langsamer.  Dadurch erh√∂ht der Server die Parallelit√§t weiter und das System kann diese Situation nicht mehr mit Ehre verlassen. <br><br><h2>  Server Sudden Death Syndrom </h2><br>  Manchmal tritt eine interessante Situation auf.  Wir haben einen Server.  Er arbeitet so f√ºr sich, alles ist in Ordnung.  Es gibt gen√ºgend Ressourcen, auch mit einem Spielraum.  Dann erhalten wir pl√∂tzlich eine Nachricht von Clients, dass der Server langsamer wird.  Wir sehen uns das Diagramm an und stellen fest, dass die Kundenaktivit√§t etwas zugenommen hat, aber jetzt ist alles normal.  Denken Sie an einen DOS-Angriff oder Zufall.  Jetzt scheint alles in Ordnung zu sein.  Erst jetzt ist der Server weiterhin dumm und alles ist h√§rter, bis Zeit√ºberschreitungen auftreten.  Nach einiger Zeit beginnt sich auch ein anderer Server zu verbiegen, der dieselbe Datenbank verwendet.  Eine vertraute Situation? <br><br><h4>  Warum ist das System gestorben? </h4><br>  Sie k√∂nnen versuchen, dies dadurch zu erkl√§ren, dass der Server irgendwann eine Spitzenanzahl von Anforderungen erhalten hat und ‚Äûpleite‚Äú ist.  Wir wissen jedoch, dass die Last reduziert wurde und der Server danach lange Zeit nicht besser wurde, bis die Last vollst√§ndig verschwunden war. <br><br>  Die rhetorische Frage: Sollte der Server wegen √ºberm√§√üiger Auslastung kaputt gehen?  Tun sie das? <br><br><h4>  Wir simulieren eine Serverabsturzsituation </h4><br>  Hier werden keine Grafiken aus einem realen Produktionssystem analysiert.  Wenn der Server abst√ºrzt, k√∂nnen wir oft keinen solchen Zeitplan erhalten.  Dem Server gehen die CPU-Ressourcen aus, und daher kann er keine Protokolle schreiben und keine Metriken angeben.  In den Diagrammen zum Zeitpunkt der Katastrophe wird h√§ufig ein Bruch in allen Diagrammen beobachtet. <br><br>  SREs sollten in der Lage sein, √úberwachungssysteme herzustellen, die f√ºr diesen Effekt weniger anf√§llig sind.  Systeme, die in jeder Situation zumindest einige Informationen liefern und gleichzeitig Post-Mortem-Systeme mithilfe fragmentarischer Informationen analysieren k√∂nnen.  F√ºr Bildungszwecke verwenden wir in diesem Artikel einen etwas anderen Ansatz. <br><br>  Versuchen wir, ein Modell zu erstellen, das mathematisch wie ein Server unter Last funktioniert.  Als n√§chstes werden wir die Eigenschaften des Servers untersuchen.  Wir verwerfen die Nichtlinearit√§t realer Server und simulieren eine Situation, in der eine lineare Verz√∂gerung auftritt, wenn die Last √ºber den Nennwert steigt.  Doppelt so viele Anfragen wie n√∂tig - wir bedienen doppelt so langsam. <br><br>  Dieser Ansatz erm√∂glicht: <br><br><ul><li>  √úberlegen Sie, was am besten passieren wird. </li><li>  Nehmen Sie genaue Metriken. </li></ul><br>  Geplante Navigation: <br><br><ul><li>  blau - die Anzahl der Anfragen an den Server; </li><li>  gr√ºn - Serverantworten; </li><li>  gelb - Timeouts; </li><li>  dunkelgrau - Anforderungen, die an Serverressourcen gesendet wurden, weil der Client nicht auf eine Timeout-Antwort gewartet hat.  Manchmal kann ein Client dies dem Server durch eine Trennung melden, aber im Allgemeinen ist ein solcher Luxus technisch m√∂glicherweise nicht realisierbar, beispielsweise wenn der Server CPU-gebundene Arbeit ohne Zusammenarbeit mit dem Client ausf√ºhrt. </li></ul><br><br><img src="https://habrastorage.org/webt/8d/r8/lr/8dr8lr7gizm-ovozc0laylwadaa.png"><br><br>  Warum stellte sich heraus, dass das Anforderungsdiagramm des Kunden (blau im Diagramm) so war?  In der Regel w√§chst der Bestellplan in unseren Pizzerien morgens reibungslos und nimmt abends ab.  Wir beobachten jedoch drei Peaks vor dem Hintergrund der √ºblichen gleichm√§√üigen Kurve.  Diese Form des Diagramms wurde nicht zuf√§llig f√ºr das Modell ausgew√§hlt, sondern.  Das Modell wurde w√§hrend der Untersuchung eines realen Vorfalls mit dem Server des Pizzeria Contact Centers in Russland w√§hrend der Weltmeisterschaft geboren. <br><br><h2>  Fall "Weltmeisterschaft" </h2><br>  Wir sa√üen und warteten auf weitere Bestellungen.  Vorbereitet f√ºr die Meisterschaft k√∂nnen die Server nun einen Festigkeitstest bestehen. <br><br>  Der erste H√∂hepunkt - Fu√üballfans schauen sich die Meisterschaft an, sie haben Hunger und kaufen Pizza.  W√§hrend der ersten H√§lfte sind sie besch√§ftigt und k√∂nnen nicht bestellen.  Aber Menschen, denen der Fu√üball gleichg√ºltig ist, k√∂nnen, also geht auf der Karte alles wie gewohnt weiter. <br><br>  Und dann endet die erste H√§lfte und der zweite H√∂hepunkt kommt.  Die Fans wurden nerv√∂s, hungrig und machten dreimal mehr Bestellungen als auf dem ersten Gipfel.  Pizza wird zu einem schrecklichen Preis gekauft.  Dann beginnt die zweite H√§lfte und wieder keine Pizza. <br><br>  In der Zwischenzeit beginnt sich der Contact Center-Server langsam zu biegen und Anforderungen immer langsamer zu bearbeiten.  Die Systemkomponente, in diesem Fall der Call Center-Webserver, ist destabilisiert. <br><br>  Der dritte H√∂hepunkt wird kommen, wenn das Spiel vorbei ist.  Fans und das System warten auf eine Strafe. <br><br><h4>  Wir analysieren die Gr√ºnde f√ºr den Serverabsturz </h4><br>  Was ist passiert?  Der Server kann 100 bedingte Anforderungen enthalten.  Wir verstehen, dass es f√ºr diese Kraft ausgelegt ist und es nicht mehr aush√§lt.  Es kommt ein Gipfel, der an sich nicht so gro√ü ist.  Die Grauzone der Parallelit√§t ist jedoch viel h√∂her. <br><br>  Das Modell ist so konzipiert, dass die Parallelit√§t numerisch der Anzahl der Bestellungen pro Sekunde entspricht. In der Grafik sollte sie also visuell den gleichen Ma√üstab haben.  Es ist jedoch viel h√∂her, weil es sich ansammelt. <br><br>  Wir sehen hier einen Schatten aus dem Diagramm - dies sind Anforderungen, die ausgef√ºhrt wurden und ausgef√ºhrt wurden (angezeigt durch den ersten roten Pfeil).  Die Zeitskala ist abh√§ngig vom Zeitversatz.  Der zweite Peak hat unseren Server bereits ausgeschaltet.  Er st√ºrzte ab und begann viermal weniger Anfragen als gew√∂hnlich zu bearbeiten. <br><br><img src="https://habrastorage.org/webt/n1/92/qw/n192qwxtwdrfatt_a-lb8y8eire.png"><br><br>  In der zweiten H√§lfte des Diagramms ist klar, dass einige Anforderungen zun√§chst noch ausgef√ºhrt wurden, dann aber gelbe Flecken auftraten - die Anforderungen wurden vollst√§ndig gestoppt. <br><br><img src="https://habrastorage.org/webt/pi/la/nv/pilanvzebdl_vl3k3hno9vwezga.png"><br><br>  Noch einmal den ganzen Zeitplan.  Es ist zu sehen, dass die Parallelit√§t wild wird.  Ein riesiger Berg erscheint. <br><br><img src="https://habrastorage.org/webt/ci/l6/kb/cil6kblebzhjokmuvzkwolmngvo.png"><br><br>  Normalerweise haben wir v√∂llig unterschiedliche Metriken analysiert: Wie langsam wurde die Anfrage abgeschlossen, wie viele Anfragen pro Sekunde.  Wir haben uns nicht einmal die Parallelit√§t angesehen, wir haben nicht einmal √ºber diese Metrik nachgedacht.  Aber vergebens, denn genau diese Menge zeigt den Moment des Serverausfalls am besten. <br><br>  Aber woher kam so ein riesiger Berg?  Die gr√∂√üte Lastspitze ist l√§ngst vorbei! <br><br><h2>  Kleines Gesetz </h2><br>  Das Gesetz von Little regelt die Parallelit√§t. <br><br>  <i>L (Anzahl der Kunden im System) = Œª (Geschwindigkeit ihres Aufenthalts) ‚àó W (Zeit, die sie im System verbringen)</i> <br><br>  Dies ist ein Durchschnitt.  Unsere Situation entwickelt sich jedoch dramatisch, der Durchschnitt passt nicht zu uns.  Wir werden diese Gleichung differenzieren und dann integrieren.  Schauen Sie sich dazu das Buch von John Little an, der diese Formel erfunden hat, und sehen Sie dort das Integral. <br><br><img src="https://habrastorage.org/webt/sx/f5/dz/sxf5dzgwc9l7low8fild5cpsrf0.png"><br><br>  Wir haben die Anzahl der Eintr√§ge im System und die Anzahl derer, die das System verlassen.  Die Anfrage kommt und geht, wenn alles abgeschlossen ist.  Unten sehen Sie eine grafische Wachstumsregion, die dem linearen Wachstum der Parallelit√§t entspricht. <br><br><img src="https://habrastorage.org/webt/ax/rv/du/axrvdu3vyx1iw9afieohv5pe-cs.png"><br><br>  Es gibt nur wenige gr√ºne Anfragen.  Dies sind diejenigen, die tats√§chlich implementiert werden.  Die blauen sind diejenigen, die kommen.  Zwischen den Zeiten haben wir die √ºbliche Anzahl von Anfragen, die Situation ist stabil.  Aber die Parallelit√§t w√§chst weiter.  Der Server wird diese Situation selbst nicht mehr bew√§ltigen.  Dies bedeutet, dass er bald fallen wird. <br><br>  Aber warum nimmt die Parallelit√§t zu?  Wir betrachten das Integral der Konstanten.  In unserem System √§ndert sich nichts, aber das Integral sieht aus wie eine lineare Funktion, die nur erwachsen wird. <br><br><h2>  Werden wir spielen? </h2><br>  Die Erkl√§rung mit Integralen ist kompliziert, wenn Sie sich nicht an Mathematik erinnern.  Hier schlage ich vor, mich aufzuw√§rmen und das Spiel zu spielen. <br><br><h4>  Spiel Nummer 1 </h4><br>  <b>Voraussetzungen</b> : Der Server empf√§ngt Anforderungen, die jeweils drei Verarbeitungsperioden auf der CPU erfordern.  Die CPU-Ressource wird gleichm√§√üig auf alle Aufgaben aufgeteilt.  Dies √§hnelt dem Verbrauch von CPU-Ressourcen w√§hrend des pr√§emptiven Multitasking.  Die Zahl in der Zelle gibt an, wie viel Arbeit nach dieser Ma√ünahme noch √ºbrig ist.  F√ºr jeden bedingten Schritt kommt eine neue Anforderung an. <br><br>  Stellen Sie sich vor, Sie haben eine Anfrage erhalten.  Nur 3 Arbeitseinheiten, am Ende der ersten Verarbeitungsperiode verbleiben 2 Einheiten. <br><br>  In der zweiten Periode wird eine weitere Anforderung geschichtet, jetzt sind beide CPUs besch√§ftigt.  Sie haben eine Arbeitseinheit f√ºr die ersten beiden Abfragen ausgef√ºhrt.  Es bleiben 1 und 2 Einheiten f√ºr die erste bzw. zweite Anforderung zu vervollst√§ndigen. <br><br>  Jetzt ist die dritte Anfrage gekommen und der Spa√ü beginnt.  Es scheint, dass die erste Anforderung h√§tte abgeschlossen werden m√ºssen, aber in diesem Zeitraum teilen sich bereits drei Anforderungen die CPU-Ressource, sodass der Abschlussgrad f√ºr alle drei Anforderungen am Ende des dritten Verarbeitungszeitraums jetzt gebrochen ist: <br><br><img src="https://habrastorage.org/webt/k-/tq/mv/k-tqmvjsqabbv0zgwt_vmkfkhy4.png"><br><br>  Noch interessanter!  Die vierte Anforderung wird hinzugef√ºgt, und jetzt betr√§gt der Grad der Parallelit√§t bereits 4, da f√ºr alle vier Anforderungen in diesem Zeitraum eine Ressource erforderlich war.  In der Zwischenzeit ist die erste Anforderung bis zum Ende der vierten Periode bereits abgeschlossen, sie geht nicht zur n√§chsten Periode √ºber und es sind noch 0 Jobs f√ºr die CPU √ºbrig. <br><br>  Da die erste Anfrage bereits abgeschlossen ist, lassen Sie uns f√ºr ihn zusammenfassen: Sie lief ein Drittel l√§nger als erwartet.  Es wurde angenommen, dass die L√§nge jeder Aufgabe horizontal idealerweise = 3 ist, je nach Arbeitsaufwand.  Wir markieren es mit Orange, als Zeichen daf√ºr, dass wir mit dem Ergebnis nicht ganz zufrieden sind. <br><br><img src="https://habrastorage.org/webt/ap/9n/uy/ap9nuyfqun_gd1ggeidqdlomxuy.png"><br><br>  Die f√ºnfte Anfrage kommt an.  Der Grad der Parallelit√§t betr√§gt immer noch 4, aber wir sehen, dass in der f√ºnften Spalte die verbleibende Arbeit insgesamt mehr ist.  Dies liegt daran, dass in der vierten Spalte mehr Arbeit √ºbrig ist als in der dritten. <br><br>  Wir fahren mit drei weiteren Perioden fort.  Warten auf Antworten. <br>  - Server, hallo! <br>  - ... <br><br><img src="https://habrastorage.org/webt/tv/2m/8r/tv2m8r8selzumgub75zkvs78deu.png"><br><br>  "Ihr Anruf ist uns sehr wichtig ..." <br><br><img src="https://habrastorage.org/webt/ud/k9/rk/udk9rk7ynqduovmhyymp7shqe0q.png"><br><br>  Nun, endlich kam die Antwort auf die zweite Anfrage.  Die Reaktionszeiten sind doppelt so lang wie erwartet. <br><br><img src="https://habrastorage.org/webt/tt/7m/iv/tt7mivq-stfincjhlwxm7wqznsq.png"><br><br>  Der Grad der Parallelit√§t hat sich bereits verdreifacht, und nichts deutet darauf hin, dass sich die Situation zum Besseren √§ndern wird.  Ich habe nicht weiter gezeichnet, da die Antwortzeit auf die dritte Anfrage nicht mehr ins Bild passt. <br><br><blockquote>  Unser Server ist in einen unerw√ºnschten Zustand eingetreten, aus dem er niemals alleine austritt.  <b>Spiel vorbei</b> </blockquote><br><h2>  Was kennzeichnet den GameOver-Status des Servers? </h2><br>  Anforderungen werden auf unbestimmte Zeit im Speicher gespeichert.  Fr√ºher oder sp√§ter wird die Erinnerung einfach enden.  Dar√ºber hinaus erh√∂ht sich mit zunehmender Skalierung der CPU-Overhead f√ºr die Wartung verschiedener Datenstrukturen.  Beispielsweise sollte der Verbindungspool jetzt Zeit√ºberschreitungen f√ºr weitere Verbindungen verfolgen, der Garbage Collector sollte jetzt mehr Objekte auf dem Heap √ºberpr√ºfen und so weiter. <br><br>  Die Untersuchung aller m√∂glichen Konsequenzen der Anh√§ufung aktiver Objekte ist nicht das Ziel dieses Artikels, aber selbst eine einfache Anh√§ufung von Daten im RAM reicht bereits aus, um den Server zu f√ºllen.  Dar√ºber hinaus haben wir bereits festgestellt, dass der Client-Server seine Parallelit√§tsprobleme auf den Datenbankserver und andere Server projiziert, die er als Client verwendet. <br><br>  Das Interessanteste: Selbst wenn Sie jetzt eine geringere Last an den Server senden, wird dieser immer noch nicht wiederhergestellt.  Alle Anforderungen enden mit einem Timeout und der Server verbraucht alle verf√ºgbaren Ressourcen. <br><br>  Und was haben wir eigentlich erwartet ?!  Schlie√ülich haben wir dem Server wissentlich eine Menge Arbeit gegeben, die er nicht bew√§ltigen konnte. <br><br>  Wenn Sie sich mit verteilter Systemarchitektur befassen, ist es hilfreich dar√ºber nachzudenken, wie normale Menschen solche Probleme l√∂sen.  Nehmen Sie zum Beispiel einen Nachtclub.  Es funktioniert nicht mehr, wenn zu viele Personen es betreten.  Der T√ºrsteher bew√§ltigt das Problem einfach: Es sieht so aus, wie viele Menschen sich darin befinden.  Einer links - startet einen anderen.  Ein neuer Gast wird kommen und die Gr√∂√üe der Warteschlange sch√§tzen.  Wenn die Schlange lang ist, wird er nach Hause gehen.  Was ist, wenn Sie diesen Algorithmus auf den Server anwenden? <br><br><img src="https://habrastorage.org/webt/wg/tn/p3/wgtnp3n6qq57dqzfi-ac9s0rj1u.png"><br><br>  Lass uns nochmal spielen. <br><br><h4>  Spiel Nummer 2 </h4><br>  <b>Voraussetzungen</b> : Wir haben wieder zwei CPUs, die gleichen Aufgaben von 3 Einheiten, die in jeder Periode eintreffen, aber jetzt werden wir den T√ºrsteher einstellen und die Aufgaben werden klug sein - wenn sie sehen, dass die Warteschlange 2 ist, gehen sie sofort nach Hause. <br><br><img src="https://habrastorage.org/webt/b4/cs/gt/b4csgtkcmi3hw1qog4fko6aus2o.png"><br><br><img src="https://habrastorage.org/webt/uw/gi/-v/uwgi-vopihzere8fs_c5f5yctfo.png"><br><br>  Die dritte Anfrage kam.  In dieser Zeit steht er in der Schlange.  Er hat die Nummer 3 am Ende des Zeitraums.  Die Residuen enthalten keine Bruchzahlen, da zwei CPUs zwei Aufgaben ausf√ºhren, eine f√ºr einen bestimmten Zeitraum. <br><br>  Obwohl wir drei √ºberlagerte Anforderungen haben, ist der Grad der Parallelit√§t innerhalb des Systems = 2. Der dritte befindet sich in der Warteschlange und z√§hlt nicht. <br><br><img src="https://habrastorage.org/webt/nm/x4/yw/nmx4ywd6xdqyte5b6vkwgco3hdq.png"><br><br>  Der vierte kam - das gleiche Bild, obwohl bereits mehr Arbeit angesammelt wurde. <br><br><img src="https://habrastorage.org/webt/uq/jb/_5/uqjb_5b8whjwjzzetwqwrzjusfy.png"><br>  ... <br>  ... <br><br>  In der sechsten Periode wurde die dritte Anforderung mit einer dritten Verz√∂gerung abgeschlossen, und der Grad der Parallelit√§t betr√§gt bereits = 4. <br><br><img src="https://habrastorage.org/webt/xs/i1/sf/xsi1sf60jniqqbamvlko-bmd_xa.png"><br><br>  Der Grad der Parallelit√§t hat sich verdoppelt.  Sie kann nicht mehr wachsen, weil wir dies eindeutig verboten haben.  Mit maximaler Geschwindigkeit wurden nur die ersten beiden Anfragen erf√ºllt - diejenigen, die zuerst in den Club kamen, w√§hrend gen√ºgend Platz f√ºr alle vorhanden war. <br><br>  Die gelben Anforderungen waren l√§nger im System, standen jedoch in einer Reihe und verz√∂gerten die CPU-Ressource nicht.  Deshalb hatten diejenigen, die drinnen waren, Spa√ü.  Dies k√∂nnte so weitergehen, bis ein Mann kam und sagte, er w√ºrde nicht in der Schlange stehen, sondern nach Hause gehen.  Dies ist eine fehlgeschlagene Anforderung: <br><br><img src="https://habrastorage.org/webt/tf/qf/qr/tfqfqrsfqvhxphy3wzrdqf_cpvk.png"><br><br>  Die Situation kann endlos wiederholt werden, w√§hrend die Ausf√ºhrungszeit der Abfrage auf dem gleichen Niveau bleibt - genau doppelt so lange, wie wir m√∂chten. <br><br><img src="https://habrastorage.org/webt/xh/l2/8-/xhl28-uoe_jao9hjppy5zc30in8.png"><br><br>  Wir sehen, dass eine einfache Einschr√§nkung der Parallelit√§tsebene das Problem der Serverlebensf√§higkeit beseitigt. <br><br><h4>  So erh√∂hen Sie die Server-Lebensf√§higkeit durch Begrenzung der Parallelit√§t </h4><br>  Sie k√∂nnen den einfachsten "T√ºrsteher" selbst schreiben.  Unten ist der Code mit dem Semaphor.  Die L√§nge der Leitung au√üerhalb ist unbegrenzt.    ,    . <br><br><pre><code class="swift hljs">const int <span class="hljs-type"><span class="hljs-type">MaxConcurrency</span></span> = <span class="hljs-number"><span class="hljs-number">100</span></span>; <span class="hljs-type"><span class="hljs-type">SemaphoreSlim</span></span> bulkhead = new <span class="hljs-type"><span class="hljs-type">SemaphoreSlim</span></span>(<span class="hljs-type"><span class="hljs-type">MaxConcurrency</span></span>, <span class="hljs-type"><span class="hljs-type">MaxConcurrency</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> async <span class="hljs-type"><span class="hljs-type">Task</span></span> <span class="hljs-type"><span class="hljs-type">ProcessRequest</span></span>() { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!await bulkhead.<span class="hljs-type"><span class="hljs-type">WaitAsync</span></span>()) { <span class="hljs-keyword"><span class="hljs-keyword">throw</span></span> new <span class="hljs-type"><span class="hljs-type">OperationCanceledException</span></span>(); } <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> { await <span class="hljs-type"><span class="hljs-type">ProcessRequestInternal</span></span>(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; } finally { bulkhead.<span class="hljs-type"><span class="hljs-type">Release</span></span>(); } }</code> </pre> <br>  Um eine begrenzte Warteschlange zu erstellen, ben√∂tigen Sie zwei Semaphoren.  Hierf√ºr eignet sich die von Microsoft empfohlene <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Polly-Bibliothek</a> .  Achten Sie auf das Schottmuster.  W√∂rtlich √ºbersetzt als "Schott" - ein Strukturelement, das es dem Schiff erm√∂glicht, nicht zu sinken.  Um ehrlich zu sein, denke ich, dass der Begriff T√ºrsteher besser geeignet ist.  Wichtig ist, dass dieses Muster es dem Server erm√∂glicht, in hoffnungslosen Situationen zu √ºberleben. <br><br>  Zuerst dr√ºcken wir alles, was auf der Ladebank m√∂glich ist, vom Server aus, bis wir bestimmen, wie viele Anforderungen es halten kann.  Zum Beispiel haben wir festgestellt, dass es 100 ist. Wir setzen Schott. <br><br>  Au√üerdem √ºberspringt der Server nur die erforderliche Anzahl von Anforderungen, der Rest wird in die Warteschlange gestellt.  Es w√§re ratsam, eine etwas kleinere Zahl zu w√§hlen, damit ein Spielraum entsteht.  Ich habe keine vorgefertigte Empfehlung zu diesem Thema, da eine starke Abh√§ngigkeit vom Kontext und der spezifischen Situation besteht. <br><br><ol><li>  Wenn das Serververhalten in Bezug auf die Ressourcen stabil von der Auslastung abh√§ngt, kann sich diese Anzahl dem Grenzwert n√§hern. </li><li>  Wenn das Medium Lastschwankungen ausgesetzt ist, sollte unter Ber√ºcksichtigung der Gr√∂√üe dieser Schwankungen eine konservativere Anzahl gew√§hlt werden.  Solche Schwankungen k√∂nnen aus verschiedenen Gr√ºnden auftreten, beispielsweise ist die Leistungsumgebung mit GC durch kleine Lastspitzen auf der CPU gekennzeichnet. </li><li>  Wenn der Server regelm√§√üig Aufgaben nach einem Zeitplan ausf√ºhrt, sollte dies ebenfalls ber√ºcksichtigt werden.  Sie k√∂nnen sogar ein adaptives Schott entwickeln, das berechnet, wie viele Abfragen gleichzeitig ohne Serververschlechterung gesendet werden k√∂nnen (dies geht jedoch bereits √ºber den Rahmen dieser Studie hinaus). </li></ol><br><h2>  Abfrageexperimente </h2><br>  Schauen Sie sich zuletzt dieses Post-Mortem an, wir werden es nicht wieder sehen. <br><img src="https://habrastorage.org/webt/n1/qn/1i/n1qn1irfrgm-fezifzonark7j94.png"><br>  All dieser graue Haufen korreliert eindeutig mit dem Serverabsturz.  Grau ist der Tod f√ºr den Server.  Lassen Sie es uns einfach abschneiden und sehen, was passiert.  Es scheint, dass eine bestimmte Anzahl von Anfragen nach Hause gehen wird, einfach nicht erf√ºllt wird.  Aber wie viel? <br><br><h4>  100 innen, 100 au√üen </h4><br><img src="https://habrastorage.org/webt/u0/6c/m5/u06cm5odrt-dxltnomhwatmhwze.png"><br>  Es stellte sich heraus, dass unser Server sehr gut und unterhaltsam zu leben begann.  Er pfl√ºgt st√§ndig mit maximaler Leistung.  Wenn ein Peak auftritt, wird er nat√ºrlich rausgeschmissen, aber nicht lange. <br><br>  Inspiriert vom Erfolg werden wir versuchen sicherzustellen, dass er √ºberhaupt nicht abprallt.  Versuchen wir, die L√§nge der Warteschlange zu erh√∂hen. <br><br><h4>  100 innen, 500 au√üen </h4><br><img src="https://habrastorage.org/webt/sk/5i/gi/sk5igi9cfgyjajp8lujawwunace.png"><br><br>  Es wurde besser, aber der Schwanz wuchs.  Dies sind die Anforderungen, die lange Zeit sp√§ter ausgef√ºhrt werden. <br><br><h4>  100 innen, 1000 au√üen </h4><br>  Da etwas besser geworden ist, versuchen wir, es auf den Punkt der Absurdit√§t zu bringen.  L√∂sen wir die Warteschlangenl√§nge zehnmal l√§nger auf, als wir gleichzeitig bedienen k√∂nnen: <br><br><img src="https://habrastorage.org/webt/2g/qd/s6/2gqds68piszleawyid_yk_rtdhg.png"><br><br>  Wenn wir √ºber die Metapher des Clubs und der T√ºrsteher sprechen, ist eine solche Situation kaum m√∂glich - niemand m√∂chte l√§nger am Eingang warten, als Zeit im Club zu verbringen.  Wir werden auch nicht so tun, als w√§re dies eine normale Situation f√ºr unser System. <br><br>  Es ist besser, den Kunden √ºberhaupt nicht zu bedienen, als ihn auf der Website oder in der mobilen Anwendung zu qu√§len, indem Sie jeden Bildschirm 30 Sekunden lang laden und den Ruf des Unternehmens beeintr√§chtigen.  Es ist besser, einem kleinen Teil der Kunden sofort ehrlich zu sagen, dass wir sie jetzt nicht mehr bedienen k√∂nnen.  Andernfalls werden wir alle Kunden um ein Vielfaches langsamer bedienen, da die Grafik zeigt, dass die Situation noch einige Zeit anh√§lt. <br><br>  Es gibt noch ein weiteres Risiko: Andere Systemkomponenten sind m√∂glicherweise nicht f√ºr ein solches Serververhalten ausgelegt, und wie wir bereits wissen, wird Parallelit√§t auf Clients projiziert. <br><br>  Daher kehren wir zur ersten Option ‚Äû100 pro 100‚Äú zur√ºck und √ºberlegen, wie wir unsere Kapazit√§ten skalieren k√∂nnen. <br><br><h4>  Gewinner - 100 innen, 100 au√üen </h4><br><img src="https://habrastorage.org/webt/z5/cg/pv/z5cgpvn4qs9abj5ifewfelapa6g.png"><br><br>  ¬Ø \ _ („ÉÑ) _ / ¬Ø <br><br>  Mit diesen Parametern ist die gr√∂√üte Verschlechterung der Laufzeit genau das Zweifache des ‚ÄûNennwerts‚Äú.  Gleichzeitig wird die Ausf√ºhrungszeit der Abfrage um 100% verk√ºrzt. <br><br>  Wenn Ihr Client empfindlich auf die Laufzeit reagiert (und dies gilt normalerweise sowohl f√ºr menschliche Clients als auch f√ºr Server-Clients), k√∂nnen Sie die Warteschlangenl√§nge weiter reduzieren.  In diesem Fall k√∂nnen wir einen bestimmten Prozentsatz der internen Parallelit√§t √ºbernehmen, und wir werden sicher wissen, dass sich die Antwortzeit des Dienstes im Durchschnitt nicht um mehr als diesen Prozentsatz verschlechtert. <br><br>  Tats√§chlich versuchen wir nicht, eine Warteschlange zu erstellen, sondern uns vor Lastschwankungen zu sch√ºtzen.  Genau wie bei der Bestimmung des ersten Parameters der Trennwand (Menge im Inneren) ist es hier n√ºtzlich zu bestimmen, welche Schwankungen in der Last der Kunde verursachen kann.  Wir werden also wissen, in welchen F√§llen wir grob gesagt den Gewinn aus potenziellen Dienstleistungen verpassen werden. <br><br>  Es ist noch wichtiger zu bestimmen, welche Latenzschwankungen anderen Systemkomponenten standhalten k√∂nnen, die mit dem Server interagieren.  Wir werden also wissen, dass wir wirklich das Maximum aus dem vorhandenen System herausholen, ohne die Gefahr eines vollst√§ndigen Verlusts des Dienstes. <br><br><h2>  Diagnose und Behandlung </h2><br>  Wir behandeln unkontrollierte Parallelit√§t mit Schottisolierung. <br>  Diese Methode wird, wie die anderen in dieser Artikelserie beschriebenen, bequem von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Polly-Bibliothek</a> implementiert. <br><br>  Der Vorteil des Verfahrens besteht darin, dass es √§u√üerst schwierig sein wird, eine einzelne Komponente des Systems als solche zu destabilisieren.  Das System erh√§lt ein sehr vorhersehbares zeitliches Verhalten f√ºr erfolgreiche Anforderungen und viel h√∂here Chancen f√ºr erfolgreiche vollst√§ndige Anforderungen. <br><br>  Wir l√∂sen jedoch nicht alle Probleme.  Zum Beispiel das Problem der unzureichenden Serverleistung.  In dieser Situation m√ºssen Sie sich nat√ºrlich daf√ºr entscheiden, den Ballast im Falle eines Lastsprungs, den wir als √ºberm√§√üig eingestuft haben, fallen zu lassen. <br><br>  Weitere Ma√ünahmen, die in unserer Studie nicht behandelt werden, k√∂nnen beispielsweise die dynamische Skalierung umfassen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de461081/">https://habr.com/ru/post/de461081/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de461071/index.html">Optimierung von Datenbankabfragen am Beispiel eines B2B-Service f√ºr Builder</a></li>
<li><a href="../de461073/index.html">Wir verbinden Online-Karten mit dem Navigator auf dem Smartphone. Teil 3 - OverpassTurbo</a></li>
<li><a href="../de461075/index.html">Business Intelligence. IT-Objekte, Komponenten, Tools</a></li>
<li><a href="../de461077/index.html">Wie werden Pentester gekocht? Eingangstests f√ºr Praktikanten im Bereich digitale Sicherheit</a></li>
<li><a href="../de461079/index.html">Stadt ohne Stau</a></li>
<li><a href="../de461083/index.html">Schreiben von Software mit der Funktionalit√§t von Client-Server-Dienstprogrammen Windows, Teil 02</a></li>
<li><a href="../de461085/index.html">Wechseln Sie die Sprache in der Android App</a></li>
<li><a href="../de461087/index.html">Dungeons und H√∂hlen f√ºr mein Spiel generieren</a></li>
<li><a href="../de461091/index.html">LED Camelion Lampen</a></li>
<li><a href="../de461093/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 469 (07/09/2019 - 07/07/2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõ©Ô∏è ‚òÄÔ∏è ‚õ∫Ô∏è Bagaimana kami menerapkan cache pada basis data Tarantool üî∂ üåé ‚ÜñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hari baik! 

 Saya ingin berbagi dengan Anda kisah tentang penerapan cache pada basis data Tarantool dan fitur pekerjaan saya. 
 Saya bekerja sebagai ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bagaimana kami menerapkan cache pada basis data Tarantool</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441686/"> Hari baik! <br><br>  Saya ingin berbagi dengan Anda kisah tentang penerapan cache pada basis data Tarantool dan fitur pekerjaan saya. <br>  Saya bekerja sebagai pengembang Java di perusahaan telekomunikasi.  Tugas utama: implementasi logika bisnis untuk platform yang dibeli perusahaan dari vendor.  Dari fitur pertama, ini adalah pekerjaan sabun dan hampir tidak ada caching, kecuali dalam memori JVM.  Semua ini tentu saja baik sampai jumlah instance aplikasi melebihi dua lusin ... <br><br>  Dalam perjalanan kerja dan munculnya pemahaman tentang fitur platform, upaya dilakukan untuk melakukan caching.  Pada saat itu, MongoDB sudah diluncurkan, dan sebagai hasilnya, kami tidak mendapatkan hasil positif khusus seperti dalam tes. <br><br>  Dalam pencarian lebih lanjut untuk alternatif dan saran dari teman baik saya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" class="user_link">mr_elzor</a> , diputuskan untuk mencoba database Tarantool. <br><a name="habracut"></a><br>  Dalam sebuah studi sepintas, hanya keraguan muncul di lua, karena saya belum menulis di atasnya dari kata "sepenuhnya."  Tetapi menyingkirkan semua keraguan, dia mulai menginstal.  Tentang jaringan tertutup dan firewall, saya pikir hanya sedikit orang yang tertarik, tetapi saya menyarankan Anda untuk mencoba menyiasatinya dan meletakkan semuanya dari sumber publik. <br><br>  Server uji dengan konfigurasi: 8 Cpu, Ram 16 GB, HDD 100 Gb, Debian 9.4. <br><br>  Instalasi sesuai dengan instruksi dari situs.  Jadi saya mendapat opsi contoh.  Idenya segera muncul dari antarmuka visual yang dengannya dukungan akan bekerja dengan nyaman.  Selama pencarian cepat, saya menemukan dan mengkonfigurasi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tarantool-admin</a> .  Bekerja di Docker dan mencakup tugas dukungan 100%, setidaknya untuk saat ini. <br><br>  Tapi mari kita bicara tentang yang lebih menarik. <br><br>  Pikiran berikutnya adalah mengkonfigurasi versi saya di konfigurasi master - slave dalam server yang sama, karena dokumentasi hanya berisi contoh dengan dua server yang berbeda. <br><br>  Setelah menghabiskan waktu untuk memahami lua dan menjelaskan konfigurasi, saya meluncurkan wizard. <br><br><pre><code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># systemctl start tarantool@master Job for tarantool@master.service failed because the control process exited with error code. See "systemctl status tarantool@master.service" and "journalctl -xe" for details.</span></span></code> </pre> <br>  Saya langsung jatuh pingsan dan tidak mengerti mengapa kesalahan itu terjadi, tetapi saya melihat bahwa itu ada dalam status "memuat". <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># systemctl status tarantool@master ‚óè tarantool@master.service - Tarantool Database Server Loaded: loaded (/lib/systemd/system/tarantool@.service; enabled; vendor preset: enabled) Active: activating (start) since Tue 2019-02-19 17:03:24 MSK; 17s ago Docs: man:tarantool(1) Process: 20111 ExecStop=/usr/bin/tarantoolctl stop master (code=exited, status=0/SUCCESS) Main PID: 20120 (tarantool) Status: "loading" Tasks: 5 (limit: 4915) CGroup: /system.slice/system-tarantool.slice/tarantool@master.service ‚îî‚îÄ20120 tarantool master.lua &lt;loading&gt; Feb 19 17:03:24 tarantuldb-tst4 systemd[1]: Starting Tarantool Database Server... Feb 19 17:03:24 tarantuldb-tst4 tarantoolctl[20120]: Starting instance master... Feb 19 17:03:24 tarantuldb-tst4 tarantoolctl[20120]: Run console at unix/:/var/run/tarantool/master.control Feb 19 17:03:24 tarantuldb-tst4 tarantoolctl[20120]: started</span></span></code> </pre><br>  Saya menjalankan slave: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># systemctl start tarantool@slave2 Job for tarantool@slave2.service failed because the control process exited with error code. See "systemctl status tarantool@slave2.service" and "journalctl -xe" for details.</span></span></code> </pre><br>  Dan saya melihat kesalahan yang sama.  Di sini, saya biasanya mulai tegang dan tidak mengerti apa yang terjadi, karena tidak ada dalam dokumentasi tentang hal itu sama sekali ... Tetapi ketika memeriksa statusnya, saya melihat bahwa itu tidak dimulai sama sekali, meskipun dikatakan bahwa statusnya "berjalan": <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># systemctl status tarantool@slave2 ‚óè tarantool@slave2.service - Tarantool Database Server Loaded: loaded (/lib/systemd/system/tarantool@.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Tue 2019-02-19 17:04:52 MSK; 27s ago Docs: man:tarantool(1) Process: 20258 ExecStop=/usr/bin/tarantoolctl stop slave2 (code=exited, status=0/SUCCESS) Process: 20247 ExecStart=/usr/bin/tarantoolctl start slave2 (code=exited, status=1/FAILURE) Main PID: 20247 (code=exited, status=1/FAILURE) Status: "running" Feb 19 17:04:52 tarantuldb-tst4 systemd[1]: tarantool@slave2.service: Unit entered failed state. Feb 19 17:04:52 tarantuldb-tst4 systemd[1]: tarantool@slave2.service: Failed with result 'exit-code'. Feb 19 17:04:52 tarantuldb-tst4 systemd[1]: tarantool@slave2.service: Service hold-off time over, scheduling restart. Feb 19 17:04:52 tarantuldb-tst4 systemd[1]: Stopped Tarantool Database Server. Feb 19 17:04:52 tarantuldb-tst4 systemd[1]: tarantool@slave2.service: Start request repeated too quickly. Feb 19 17:04:52 tarantuldb-tst4 systemd[1]: Failed to start Tarantool Database Server. Feb 19 17:04:52 tarantuldb-tst4 systemd[1]: tarantool@slave2.service: Unit entered failed state. Feb 19 17:04:52 tarantuldb-tst4 systemd[1]: tarantool@slave2.service: Failed with result 'exit-code'.</span></span></code> </pre><br>  Tetapi pada saat yang sama, sang master mulai bekerja: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># ps -ef | grep taran taranto+ 20158 1 0 17:04 ? 00:00:00 tarantool master.lua &lt;running&gt; root 20268 2921 0 17:06 pts/1 00:00:00 grep taran</span></span></code> </pre><br>  Memulai kembali budak tidak membantu.  Saya bertanya-tanya mengapa? <br><br>  Saya menghentikan tuan.  Dan melakukan tindakan dalam urutan terbalik. <br><br>  Saya melihat bahwa budak sedang mencoba untuk memulai. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># ps -ef | grep taran taranto+ 20399 1 0 17:09 ? 00:00:00 tarantool slave2.lua &lt;loading&gt;</span></span></code> </pre><br>  Saya memulai wizard dan melihat bahwa wizard tidak naik dan umumnya beralih ke status yatim piatu, sementara budak umumnya jatuh. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># ps -ef | grep taran taranto+ 20428 1 0 17:09 ? 00:00:00 tarantool master.lua &lt;orphan&gt;</span></span></code> </pre><br>  Itu menjadi lebih menarik. <br><br>  Saya melihat di log pada budak bahwa dia bahkan melihat master dan mencoba menyinkronkan. <br><br><pre> <code class="bash hljs">2019-02-19 17:13:45.113 [20751] iproto/101/main D&gt; binary: binding to 0.0.0.0:3302... 2019-02-19 17:13:45.113 [20751] iproto/101/main I&gt; binary: bound to 0.0.0.0:3302 2019-02-19 17:13:45.113 [20751] iproto/101/main D&gt; binary: listening on 0.0.0.0:3302... 2019-02-19 17:13:45.113 [20751] iproto D&gt; cpipe_flush_cb: locking &amp;endpoint-&gt;mutex 2019-02-19 17:13:45.113 [20751] iproto D&gt; cpipe_flush_cb: unlocking &amp;endpoint-&gt;mutex 2019-02-19 17:13:45.113 [20751] main D&gt; cbus_endpoint_fetch: locking &amp;endpoint-&gt;mutex 2019-02-19 17:13:45.113 [20751] main D&gt; cbus_endpoint_fetch: unlocking &amp;endpoint-&gt;mutex 2019-02-19 17:13:45.113 [20751] main/101/slave2 I&gt; connecting to 1 replicas 2019-02-19 17:13:45.113 [20751] main/106/applier/replicator@tarantuldb-t D&gt; =&gt; CONNECT 2019-02-19 17:13:45.114 [20751] main/106/applier/replicator@tarantuldb-t I&gt; remote master 825af7c3-f8df-4db0-8559-a866b8310077 at 10.78.221.74:3301 running Tarantool 1.10.2 2019-02-19 17:13:45.114 [20751] main/106/applier/replicator@tarantuldb-t D&gt; =&gt; CONNECTED 2019-02-19 17:13:45.114 [20751] main/101/slave2 I&gt; connected to 1 replicas 2019-02-19 17:13:45.114 [20751] coio V&gt; loading vylog 14 2019-02-19 17:13:45.114 [20751] coio V&gt; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span> loading vylog 2019-02-19 17:13:45.114 [20751] main/101/slave2 I&gt; recovery start 2019-02-19 17:13:45.114 [20751] main/101/slave2 I&gt; recovering from `/var/lib/tarantool/cache_slave2/00000000000000000014.snap<span class="hljs-string"><span class="hljs-string">' 2019-02-19 17:13:45.114 [20751] main/101/slave2 D&gt; memtx_tuple_new(47) = 0x7f99a4000080 2019-02-19 17:13:45.114 [20751] main/101/slave2 I&gt; cluster uuid 4035b563-67f8-4e85-95cc-e03429f1fa4d 2019-02-19 17:13:45.114 [20751] main/101/slave2 D&gt; memtx_tuple_new(11) = 0x7f99a4004080 2019-02-19 17:13:45.114 [20751] main/101/slave2 D&gt; memtx_tuple_new(17) = 0x7f99a4008068</span></span></code> </pre><br>  Dan upaya itu berhasil: <br><br><pre> <code class="bash hljs">2019-02-19 17:13:45.118 [20751] main/101/slave2 D&gt; memtx_tuple_new(40) = 0x7f99a40004c0 2019-02-19 17:13:45.118 [20751] main/101/slave2 I&gt; assigned id 1 to replica 825af7c3-f8df-4db0-8559-a866b8310077 2019-02-19 17:13:45.118 [20751] main/101/slave2 D&gt; memtx_tuple_new(40) = 0x7f99a4000500 2019-02-19 17:13:45.118 [20751] main/101/slave2 I&gt; assigned id 2 to replica 403c0323-5a9b-480d-9e71-5ba22d4ccf1b 2019-02-19 17:13:45.118 [20751] main/101/slave2 I&gt; recover from `/var/lib/tarantool/slave2/00000000000000000014.xlog<span class="hljs-string"><span class="hljs-string">' 2019-02-19 17:13:45.118 [20751] main/101/slave2 I&gt; done `/var/lib/tarantool/slave2/00000000000000000014.xlog'</span></span></code> </pre><br>  Itu bahkan dimulai: <br><br><pre> <code class="bash hljs">2019-02-19 17:13:45.119 [20751] main/101/slave2 D&gt; systemd: sending message <span class="hljs-string"><span class="hljs-string">'STATUS=running'</span></span></code> </pre><br>  Tetapi karena alasan yang tidak diketahui, ia kehilangan koneksi dan jatuh: <br><br><pre> <code class="bash hljs">2019-02-19 17:13:45.129 [20751] main/101/slave2 D&gt; SystemError at /build/tarantool-1.10.2.146/src/coio_task.c:416 2019-02-19 17:13:45.129 [20751] main/101/slave2 tarantoolctl:532 E&gt; Start failed: /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share/lua/5.1/http/server.lua:1146: Can<span class="hljs-string"><span class="hljs-string">'t create tcp_server: Input/output error</span></span></code> </pre><br>  Mencoba memulai budak lagi tidak membantu. <br><br>  Sekarang hapus file yang dibuat oleh instance.  Dalam kasus saya, saya menghapus semuanya dari direktori / var / lib / tarantool. <br><br>  Saya mulai menjadi budak pertama, dan baru kemudian menguasai.  Dan lihatlah ... <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># ps -ef | grep tara taranto+ 20922 1 0 17:20 ? 00:00:00 tarantool slave2.lua &lt;running&gt; taranto+ 20933 1 1 17:21 ? 00:00:00 tarantool master.lua &lt;running&gt;</span></span></code> </pre><br>  Saya tidak menemukan penjelasan untuk perilaku ini, kecuali sebagai "fitur dari perangkat lunak ini." <br>  Situasi ini akan muncul setiap kali jika server Anda telah sepenuhnya reboot. <br><br>  Setelah analisis lebih lanjut dari arsitektur perangkat lunak ini, ternyata direncanakan untuk menggunakan hanya satu vCPU untuk satu contoh dan banyak lagi sumber daya tetap bebas. <br><br>  Dalam ideologi n vCPU, kita dapat mengangkat master dan n-2 budak untuk membaca. <br><br>  Mengingat bahwa pada server uji 8 vCPU kita dapat menaikkan master dan 6 instance untuk membaca. <br>  Saya menyalin file untuk slave, memperbaiki port dan menjalankan, yaitu  ditambahkan beberapa budak lagi. <br><br>  Penting!  Saat menambahkan contoh lain, Anda harus mendaftarkannya di wisaya. <br>  Tetapi Anda harus terlebih dahulu memulai budak baru, dan baru kemudian restart master. <br><br><h4>  Contoh </h4><br>  Saya sudah memiliki konfigurasi yang berjalan dengan penyihir dan dua budak. <br><br>  Saya memutuskan untuk menambahkan budak ketiga. <br><br>  Saya mendaftarkannya di master dan me-restart master terlebih dahulu, dan ini yang saya lihat: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># ps -ef | grep tara taranto+ 20922 1 0 Feb19 ? 00:00:29 tarantool slave2.lua &lt;running&gt; taranto+ 20965 1 0 Feb19 ? 00:00:29 tarantool slave3.lua &lt;running&gt; taranto+ 21519 1 0 09:16 ? 00:00:00 tarantool master.lua &lt;orphan&gt;</span></span></code> </pre><br>  Yaitu  tuan kita menjadi penyendiri, dan replikasi berantakan. <br><br>  Memulai seorang budak baru tidak akan lagi membantu dan akan menghasilkan kesalahan: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># systemctl restart tarantool@slave4 Job for tarantool@slave4.service failed because the control process exited with error code. See "systemctl status tarantool@slave4.service" and "journalctl -xe" for details.</span></span></code> </pre><br>  Dan di log saya melihat entri informatif: <br><br><pre> <code class="bash hljs">2019-02-20 09:20:10.616 [21601] main/101/slave4 I&gt; bootstrapping replica from 3c77eb9d-2fa1-4a27-885f-e72defa5cd96 at 10.78.221.74:3301 2019-02-20 09:20:10.617 [21601] main/106/applier/replicator@tarantuldb-t I&gt; can<span class="hljs-string"><span class="hljs-string">'t join/subscribe 2019-02-20 09:20:10.617 [21601] main/106/applier/replicator@tarantuldb-t xrow.c:896 E&gt; ER_READONLY: Can'</span></span>t modify data because this instance is <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-built_in"><span class="hljs-built_in">read</span></span>-only mode. 2019-02-20 09:20:10.617 [21601] main/106/applier/replicator@tarantuldb-t D&gt; =&gt; STOPPED 2019-02-20 09:20:10.617 [21601] main/101/slave4 xrow.c:896 E&gt; ER_READONLY: Can<span class="hljs-string"><span class="hljs-string">'t modify data because this instance is in read-only mode. 2019-02-20 09:20:10.617 [21601] main/101/slave4 F&gt; can'</span></span>t initialize storage: Can<span class="hljs-string"><span class="hljs-string">'t modify data because this instance is in read-only mode.</span></span></code> </pre><br>  Kami menghentikan wizard dan memulai budak baru.  Akan ada kesalahan, seperti pada awal pertama, tetapi kita akan melihat bahwa itu memuat status. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># ps -ef | grep tara taranto+ 20922 1 0 Feb19 ? 00:00:29 tarantool slave2.lua &lt;running&gt; taranto+ 20965 1 0 Feb19 ? 00:00:30 tarantool slave3.lua &lt;running&gt; taranto+ 21659 1 0 09:23 ? 00:00:00 tarantool slave4.lua &lt;loading&gt;</span></span></code> </pre><br>  Tetapi ketika Anda memulai master, slave baru crash, dan master tidak berjalan dengan status running. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># ps -ef | grep tara taranto+ 20922 1 0 Feb19 ? 00:00:29 tarantool slave2.lua &lt;running&gt; taranto+ 20965 1 0 Feb19 ? 00:00:30 tarantool slave3.lua &lt;running&gt; taranto+ 21670 1 0 09:23 ? 00:00:00 tarantool master.lua &lt;orphan&gt;</span></span></code> </pre><br>  Dalam situasi ini, hanya ada satu jalan keluar.  Seperti yang saya tulis sebelumnya, saya menghapus file yang dibuat oleh instance dan menjalankan slave terlebih dahulu, lalu master. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># ps -ef | grep tarantool taranto+ 21892 1 0 09:30 ? 00:00:00 tarantool slave4.lua &lt;running&gt; taranto+ 21907 1 0 09:30 ? 00:00:00 tarantool slave3.lua &lt;running&gt; taranto+ 21922 1 0 09:30 ? 00:00:00 tarantool slave2.lua &lt;running&gt; taranto+ 21931 1 0 09:30 ? 00:00:00 tarantool master.lua &lt;running&gt;</span></span></code> </pre><br>  Semuanya dimulai dengan sukses. <br><br>  Begitulah, melalui coba-coba, saya menemukan cara mengkonfigurasi dan memulai replikasi dengan benar. <br><br>  Akibatnya, konfigurasi berikut ini dirakit: <br><br>  <i>2 server.</i> <i><br></i>  <i>2 tuan.</i>  <i>Cadangan panas.</i> <i><br></i>  <i>12 budak.</i>  <i>Semua aktif.</i> <br><br>  Dalam logika tarantool, http.server digunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://github.com/tarantool/">agar</a> tidak <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://github.com/tarantool/">memblokir</a> adaptor tambahan (ingat vendor, platform dan sabun) atau kencangkan perpustakaan untuk setiap proses bisnis. <br><br>  Untuk menghindari perbedaan antara master, pada penyeimbang (NetScaler, HAProxy, atau lainnya favorit Anda), kami menetapkan aturan cadangan, mis.  menyisipkan, memperbarui, menghapus operasi hanya pergi ke master aktif pertama. <br><br>  Pada saat ini, yang kedua hanya mereplikasi catatan dari yang pertama.  Budak sendiri terhubung ke master yang ditentukan pertama dari konfigurasi, yang merupakan apa yang kita butuhkan dalam situasi ini. <br><br>  Pada lua, operasi CRUD diimplementasikan untuk nilai kunci.  Saat ini, ini sudah cukup untuk menyelesaikan masalah. <br><br>  Mengingat fitur bekerja dengan sabun, proses bisnis proxy diimplementasikan, di mana logika bekerja dengan tarantula via http diletakkan. <br><br>  Jika data kunci ada, maka segera dikembalikan.  Jika tidak, maka permintaan dikirim ke sistem master, dan disimpan dalam database Tarantool. <br><br>  Akibatnya, satu proses bisnis dalam pengujian memproses hingga 4k permintaan.  Dalam hal ini, waktu respons dari tarantula adalah ~ 1 ms.  Waktu respons rata-rata hingga 3 ms. <br><br>  Berikut ini beberapa informasi dari tes: <br><br><img src="https://habrastorage.org/webt/n6/ae/lg/n6aelg4tipin2jgomzrgsw_8nie.png"><br><br>  Ada 50 proses bisnis yang masuk ke 4 sistem master dan cache data dalam memori mereka.  Duplikasi informasi dalam pertumbuhan penuh di setiap contoh.  Mengingat bahwa java sudah menyukai memori ... prospeknya bukan yang terbaik. <br><br><h4>  Sekarang </h4><br>  50 proses bisnis meminta informasi melalui cache.  Sekarang informasi dari 4 instance wizard disimpan di satu tempat, dan tidak di-cache di memori pada setiap instance.  Dimungkinkan untuk secara signifikan mengurangi beban pada sistem master, tidak ada duplikat informasi, dan konsumsi memori pada contoh dengan logika bisnis telah menurun. <br><br>  Contoh ukuran penyimpanan informasi dalam memori tarantula: <br><br><img src="https://habrastorage.org/webt/es/93/ex/es93exozhrhnihbnq6-zpzjobma.png"><br><br>  Pada akhirnya, angka-angka ini mungkin berlipat ganda, tetapi tidak ada "drawdown" dalam kinerja. <br><br>  Dalam pertempuran, versi saat ini membuat permintaan 2k - 2.5k per detik dari beban nyata.  Waktu respons rata-rata mirip dengan tes hingga 3 ms. <br><br>  Jika Anda melihat htop di salah satu server dengan tarantool, kita akan melihat bahwa mereka "mendinginkan": <br><br><img src="https://habrastorage.org/webt/jt/mt/vf/jtmtvfat0ohxhugounnve47l7ju.png"><br><br><h4>  Ringkasan </h4><br>  Terlepas dari semua kehalusan dan nuansa basis data Tarantool, Anda dapat mencapai kinerja luar biasa. <br><br>  Saya harap proyek ini akan berkembang dan saat-saat tidak nyaman ini akan diselesaikan. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id441686/">https://habr.com/ru/post/id441686/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id441676/index.html">Cara berteman PLUTO dan HDSDR</a></li>
<li><a href="../id441678/index.html">Fisika tornado permainan: bagaimana aerodinamika diterapkan di Just Cause 4 (lalu lintas)</a></li>
<li><a href="../id441680/index.html">Lua In Moscow 2019 program konferensi</a></li>
<li><a href="../id441682/index.html">HyperX Fury 3D - SSD dengan silsilah yang jelas</a></li>
<li><a href="../id441684/index.html">Prediksi: awan akan berubah 2019</a></li>
<li><a href="../id441688/index.html">Game mengubah dunia: bagaimana Hellblade menarik perhatian pada masalah orang dengan penyakit mental</a></li>
<li><a href="../id441690/index.html">Anda Tidak Perlu Blockchain: Delapan Kasus Penggunaan Yang Terkenal Dan Mengapa Mereka Tidak Bekerja</a></li>
<li><a href="../id441692/index.html">Bagaimana cara menutupi trek di blockchain? Konsep Mixer Transaksi Kami</a></li>
<li><a href="../id441694/index.html">Mengapa grafik lalu lintas "berbohong"</a></li>
<li><a href="../id441696/index.html">Sejarah Cyrillic LiveJournal: bagaimana manajemen Rusia menghancurkan kebangkitan blogging berbahasa Rusia</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
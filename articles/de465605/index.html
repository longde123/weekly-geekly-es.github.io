<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👷 🧑🏽 🐮 Das Buch „Deep Reinforcement Learning in Python. OpenAI Gym und TensorFlow für Profis » ✊🏽 ⬇️ 🔊</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo habrozhiteli! Reinforcement Learning ist der beliebteste und vielversprechendste Bereich der künstlichen Intelligenz. Praktisches Lernen RL in P...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Das Buch „Deep Reinforcement Learning in Python. OpenAI Gym und TensorFlow für Profis »</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/465605/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/hf/sc/yz/hfscyzhjnopaerkvbdvf89gflfc.jpeg" align="left" alt="Bild"></a>  Hallo habrozhiteli!  Reinforcement Learning ist der beliebteste und vielversprechendste Bereich der künstlichen Intelligenz.  Praktisches Lernen RL in Python hilft Ihnen dabei, nicht nur die grundlegenden, sondern auch die fortgeschrittenen Deep-Learning-Algorithmen mit Verstärkung zu beherrschen.  Dieses Buch richtet sich an MO-Entwickler und Deep-Learning-Enthusiasten, die sich für künstliche Intelligenz interessieren und die Methode des verstärkenden Lernens erlernen möchten.  Lesen Sie dieses Buch und werden Sie ein Experte für verstärktes Lernen, indem Sie praktische Beispiele in oder außerhalb der Arbeit implementieren.  Kenntnisse der linearen Algebra, der mathematischen Analyse und der Programmiersprache Python helfen Ihnen, die Logik der Präsentation zu verstehen. <br><a name="habracut"></a><br><h3>  Auszug.  Erstellen von Texten mit LSTM RNN </h3><br>  Nun wollen wir sehen, wie man LSTM verwendet, um Zayn Malik-Texte zu generieren.  Der Songtext-Datensatz von Zane kann unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/sudharsan13296/Hands-On-Reinforcement-Learning-With-Python/blob/master/07.%20Deep%20Learning%20Fundamentals/data/ZaynLyrics.txt</a> heruntergeladen werden . <br><br>  Die Arbeit beginnt mit dem Import der erforderlichen Bibliotheken: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np</code> </pre> <br>  Dann wird die Datei mit den Texten gelesen: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">"Zayn_Lyrics.txt"</span></span>,<span class="hljs-string"><span class="hljs-string">"r"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: data=f.read() data=data.replace(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>,<span class="hljs-string"><span class="hljs-string">''</span></span>) data = data.lower()</code> </pre> <br>  Stellen Sie sicher, dass die Daten erfolgreich hochgeladen wurden: <br><br><pre> <code class="python hljs">data[:<span class="hljs-number"><span class="hljs-number">50</span></span>] <span class="hljs-string"><span class="hljs-string">"now i'm on the edge can't find my way it's inside "</span></span></code> </pre> <br>  Jetzt werden alle Zeichen in der Variablen all_chars gespeichert: <br><br><pre> <code class="plaintext hljs">all_chars=list(set(data))</code> </pre> <br>  Die Anzahl der eindeutigen Zeichen wird in unique_chars gespeichert: <br><br><pre> <code class="python hljs">unique_chars = len(all_chars)</code> </pre> <br>  Die Gesamtzahl der Zeichen wird in der Variablen total_chars gespeichert: <br><br><pre> <code class="python hljs">total_chars =len(data)</code> </pre> <br>  Zuerst weisen wir jedem Zeichen einen Index zu.  char_to_ix enthält die Zuordnung des Zeichens zum Index und ix_to_char enthält die Zuordnung des Zeichens zum Index: <br><br><pre> <code class="python hljs">char_to_ix = { ch:i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i,ch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(all_chars) } ix_to_char = { i:ch <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i,ch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(all_chars) }</code> </pre> <br>  Ein Beispiel: <br><br><pre> <code class="python hljs">char_to_ix[<span class="hljs-string"><span class="hljs-string">'e'</span></span>] <span class="hljs-number"><span class="hljs-number">9</span></span> ix_to_char[<span class="hljs-number"><span class="hljs-number">9</span></span>] e</code> </pre> <br>  Anschließend wird die Funktion generate_batch definiert, die die Eingabe- und Zielwerte generiert.  Die Zielwerte sind gleich der Verschiebung der Eingabewerte mal i. <br><br>  Wenn beispielsweise Eingabe = [12,13,24] mit einem Verschiebungswert von 1 ist, sind die Zielwerte [13,24]: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generate_batch</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(seq_length,i)</span></span></span><span class="hljs-function">:</span></span> inputs = [char_to_ix[ch] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data[i:i+seq_length]] targets = [char_to_ix[ch] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data[i+<span class="hljs-number"><span class="hljs-number">1</span></span>:i+seq_length+<span class="hljs-number"><span class="hljs-number">1</span></span>]] inputs=np.array(inputs).reshape(seq_length,<span class="hljs-number"><span class="hljs-number">1</span></span>) targets=np.array(targets).reshape(seq_length,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> inputs,targets</code> </pre> <br>  Wir werden die Länge der Sequenz, die Lerngeschwindigkeit und die Anzahl der Knoten bestimmen, die der Anzahl der Neuronen entspricht: <br><br><pre> <code class="python hljs">seq_length = <span class="hljs-number"><span class="hljs-number">25</span></span> learning_rate = <span class="hljs-number"><span class="hljs-number">0.1</span></span> num_nodes = <span class="hljs-number"><span class="hljs-number">300</span></span></code> </pre> <br>  Erstellen Sie die LSTM-RNN.  TensorFlow bietet die Funktion BasicLSTMCell () zum Erstellen von LSTM-Zellen.  Sie müssen die Anzahl der Einheiten in der LSTM-Zelle und die Art der verwendeten Aktivierungsfunktion angeben. <br><br>  Also erstellen wir die LSTM-Zelle und bauen mit dieser Zelle das RNN-Netzwerk mit der Funktion tf.nn.dynamic_rnn () auf, die die Ausgabe und den Statuswert zurückgibt: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_rnn</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> cell= tf.contrib.rnn.BasicLSTMCell(num_units=num_nodes, activation=tf.nn.relu) outputs, states = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> outputs,states</code> </pre> <br>  Erstellen Sie nun einen Ersatz für Eingabe X und Ziel Y: <br><br><pre> <code class="python hljs">X=tf.placeholder(tf.float32,[<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>]) Y=tf.placeholder(tf.float32,[<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br>  Konvertieren Sie X und Y in int: <br><br><pre> <code class="python hljs">X=tf.cast(X,tf.int32) Y=tf.cast(Y,tf.int32)</code> </pre> <br>  Erstellen Sie auch Onehot-Ansichten für X und Y: <br><br><pre> <code class="python hljs">X_onehot=tf.one_hot(X,unique_chars) Y_onehot=tf.one_hot(Y,unique_chars)</code> </pre> <br>  Rufen Sie die Ausgaben und Zustände vom RNN ab, indem Sie die Funktion build_rnn aufrufen: <br><br><pre> <code class="python hljs">outputs,states=build_rnn(X_onehot)</code> </pre> <br>  Transponieren Sie die Ausgabe: <br><br><pre> <code class="python hljs">outputs=tf.transpose(outputs,perm=[<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>])</code> </pre> <br>  Wir initialisieren die Gewichte und Offsets: <br><br><pre> <code class="python hljs">W=tf.Variable(tf.random_normal((num_nodes,unique_chars),stddev=<span class="hljs-number"><span class="hljs-number">0.001</span></span>)) B=tf.Variable(tf.zeros((<span class="hljs-number"><span class="hljs-number">1</span></span>,unique_chars)))</code> </pre> <br>  Wir berechnen die Ausgabe, indem wir die Ausgabe mit dem Gewicht multiplizieren und den Versatz addieren: <br><br><pre> <code class="python hljs">Ys=tf.matmul(outputs[<span class="hljs-number"><span class="hljs-number">0</span></span>],W)+B</code> </pre> <br>  Jetzt werden wir die Softmax-Aktivierung durchführen und die Wahrscheinlichkeiten ermitteln: <br><br><pre> <code class="python hljs">prediction = tf.nn.softmax(Ys)</code> </pre> <br>  Der Verlust von cross_entropy wird wie folgt berechnet: <br><br><pre> <code class="python hljs">cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels =Y_onehot,logits=Ys))</code> </pre> <br>  Unser Ziel ist es, Verluste zu minimieren, damit wir eine Rückausbreitung für das Netzwerk durchführen und einen Gradientenabstieg durchführen können: <br><br><pre> <code class="python hljs">optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cro ss_entropy)</code> </pre> <br>  Dann wird die Vorhersage der Hilfsfunktion definiert, die die Indizes des nächsten vorhergesagten Symbols gemäß dem RNN-Modell ergibt: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predict</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(seed,i)</span></span></span><span class="hljs-function">:</span></span> x=np.zeros((<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>)) x[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]= seed indices=[] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(i): p=sess.run(prediction,{X:x}) index = np.random.choice(range(unique_chars), p=p.ravel()) x[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]=index indices.append(index) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> indices</code> </pre> <br>  Dann werden die Paketgröße batch_size, die Anzahl der Pakete und die Anzahl der Epochen sowie der Verschiebungswert zum Erzeugen des Pakets festgelegt: <br><br><pre> <code class="python hljs">batch_size=<span class="hljs-number"><span class="hljs-number">100</span></span> total_batch=int(total_chars//batch_size) epochs=<span class="hljs-number"><span class="hljs-number">1000</span></span> shift=<span class="hljs-number"><span class="hljs-number">0</span></span></code> </pre> <br>  Schließlich erstellen wir eine TensorFlow-Sitzung und erstellen ein Modell: <br><br><pre> <code class="python hljs">init=tf.global_variables_initializer() <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.Session() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sess: sess.run(init) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> epoch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(epoch): print(<span class="hljs-string"><span class="hljs-string">"Epoch {}:"</span></span>.format(epoch)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> shift + batch_size+<span class="hljs-number"><span class="hljs-number">1</span></span> &gt;= len(data): shift =<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#         # generate_batch,      shift, #    for i in range(total_batch): inputs,targets=generate_batch(batch_size,shift) shift += batch_size # calculate loss if(i%100==0): loss=sess.run(cross_entropy,feed_dict={X:inputs, Y:targets}) #      #    predict index =predict(inputs[0],200) #     ix_to_char #    txt = ''.join(ix_to_char[ix] for ix in index) print('Iteration %i: '%(i)) print ('\n %s \n' % (txt, )) sess.run(optimiser,feed_dict={X:inputs,Y:targets})</span></span></code> </pre> <br>  Wie Sie den Ergebnissen entnehmen können, besteht die Ausgabe in der Anfangszeit aus zufälligen Zeichen, aber wie Sie lernen, verbessern sich die Ergebnisse: <br><br><pre> <code class="python hljs">Epoch <span class="hljs-number"><span class="hljs-number">0</span></span>: Iteration <span class="hljs-number"><span class="hljs-number">0</span></span>: wsadrpud,kpswkypeqawnlfyweudkgt,khdi nmgo<span class="hljs-string"><span class="hljs-string">f' u vnvlmbis . snsblp,podwjqehb,e;g- '</span></span>fyqjsyeg,byjgyotsrdf;;u,ha;ik<span class="hljs-string"><span class="hljs-string">'sfc;dvtauofd.,q.;npsw'</span></span>wjy-quw<span class="hljs-string"><span class="hljs-string">'quspfqw- . . . Epoch 113: Iteration 0: i wanna see you, yes, and she said yes!</span></span></code> </pre> <br><h3>  Über den Autor </h3><br>  <i>Sudharsan Ravichandiran</i> ist Spezialist für Datenverarbeitung und -analyse, <i>begeisterter</i> Fan künstlicher Intelligenz und Videoblogger.  Er erwarb einen Bachelor-Abschluss in Informatik an der Anne University und forscht an der praktischen Umsetzung von Deep Learning und verstärktem Lernen, einschließlich Verarbeitung natürlicher Sprache und Computer Vision.  Zuvor war er als freiberuflicher Webdesigner und Entwickler an der Erstellung mehrerer preisgekrönter Websites beteiligt.  Derzeit nimmt er an Open Source-Projekten teil und beantwortet häufig Fragen zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Stapelüberlauf</a> . <br><br><h3>  Über Wissenschaftsredakteure </h3><br>  <i>Sujit Pal</i> ist technischer Forschungsdirektor bei Elsevier Labs, dem neuesten Technologieentwicklungsteam der Reed-Elsevier Group.  Er forscht auf dem Gebiet der semantischen Suche, der Verarbeitung natürlicher Sprache, des maschinellen und tiefen Lernens.  Bei Elsevier arbeitete er an mehreren Initiativprojekten, darunter der Bewertung und Verbesserung der Suchqualität, der Klassifizierung von Bildern und der Identifizierung von Duplikaten sowie der Kommentierung und Entwicklung von Anthologien medizinischer und wissenschaftlicher Texte.  Er schrieb mit Antonio Gulli ein Deep-Learning-Buch und schreibt über Technologie in seinem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Salmon Run-</a> Blog. <br><br>  <i>Suriyadeepan Ramamoorthy</i> ist ein Forscher und Ingenieur für künstliche Intelligenz von einem KI-Forscher und Ingenieur in Pondicherry, Indien.  Das Hauptthema seiner Arbeit ist das Verstehen natürlicher Sprachen und das Bilden von Argumenten.  Er schreibt ausführlich in einem Deep-Learning-Blog.  Bei SAAMA Technologies verwendet er fortgeschrittene Deep-Learning-Methoden, um biomedizinische Texte zu analysieren.  Als begeisterter Befürworter freier Software beteiligt er sich aktiv an Projekten zu deren Entwicklung in der FSFTN-Community.  Er interessiert sich auch für kollaborative Netzwerke, Datenvisualisierung und kreative Programmierung. <br><br>  »Weitere Informationen zum Buch finden Sie auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Website des Herausgebers</a> <br>  » <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Inhalt</a> <br>  » <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Auszug</a> <br><br>  25% Rabatt auf Gutschein für Händler - <b>Python</b> <br><br>  Nach Bezahlung der Papierversion des Buches wird ein elektronisches Buch per E-Mail verschickt. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de465605/">https://habr.com/ru/post/de465605/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de465595/index.html">5G kommt zu uns?</a></li>
<li><a href="../de465597/index.html">STM8S Slow Start lernen. Teil 0</a></li>
<li><a href="../de465599/index.html">IPFS ohne Schmerzen (aber das ist nicht genau)</a></li>
<li><a href="../de465601/index.html">Warum brauchen Sie DevOps und wer sind DevOps-Spezialisten?</a></li>
<li><a href="../de465603/index.html">Kurse gegen Praktikum. Wie unterrichten wir Midbells bei SimbirSoft?</a></li>
<li><a href="../de465607/index.html">Lean und Agile in der Softwareentwicklung verstehen</a></li>
<li><a href="../de465609/index.html">Warum 1C-Bitrix ab dem 1. Dezember 2019 zu einem Kürbis werden kann</a></li>
<li><a href="../de465611/index.html">Musik für den Programmierer</a></li>
<li><a href="../de465613/index.html">Eine vollständige Anleitung zu Golang-Arrays und -Schnitten</a></li>
<li><a href="../de465615/index.html">Intelligente Schlösser: Was sie sind, wie sie funktionieren (und wer installiert)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
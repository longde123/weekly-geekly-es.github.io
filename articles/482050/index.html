<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ÜóÔ∏è üêâ ‚úçüèª T√©cnica de reducci√≥n de red de convoluci√≥n Jedi - poda ‚ùì üíπ üí•</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ante ustedes nuevamente, la tarea de detectar objetos. Prioridad: velocidad con precisi√≥n aceptable. Tomas la arquitectura de YOLOv3 y la entrenas. La...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>T√©cnica de reducci√≥n de red de convoluci√≥n Jedi - poda</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482050/"><p><img src="https://habrastorage.org/webt/tf/oa/br/tfoabr16w_dawnzb9hnjndyv_bg.png" alt="imagen"></p><br><p>  Ante ustedes nuevamente, la tarea de detectar objetos.  Prioridad: velocidad con precisi√≥n aceptable.  Tomas la arquitectura de YOLOv3 y la entrenas.  La precisi√≥n (mAp75) es mayor que 0.95.  Pero la velocidad de carrera sigue siendo baja.  El infierno </p><br><p>  Hoy evitaremos la cuantizaci√≥n.  Y debajo del corte, considere la <strong>poda de modelos</strong> : recorte de partes de red redundantes para acelerar la inferencia sin perder precisi√≥n.  Visualmente: d√≥nde, cu√°nto y c√≥mo cortar.  Veamos c√≥mo hacerlo manualmente y d√≥nde puede automatizar.  Al final hay un repositorio sobre keras. </p><a name="habracut"></a><br><h3 id="vvedenie">  Introduccion </h3><br><p>  En el √∫ltimo lugar de trabajo, Perm Macroscop, tuve un h√°bito: siempre monitorear el tiempo de ejecuci√≥n de los algoritmos.  Y el tiempo de ejecuci√≥n de la red siempre debe verificarse a trav√©s del filtro de adecuaci√≥n.  Por lo general, el estado de la t√©cnica en el producto no pasa este filtro, lo que me llev√≥ a la poda. </p><br><p>  La poda es un tema antiguo del que se habl√≥ en las <a href="https://www.youtube.com/watch%3Fv%3DeZdOkDtYMoo" rel="nofollow">conferencias de Stanford de</a> 2017.  La idea principal es reducir el tama√±o de la red entrenada sin perder precisi√≥n eliminando varios nodos.  Suena bien, pero rara vez escucho sobre su uso.  Probablemente, no hay suficientes implementaciones, no hay art√≠culos en ruso, o simplemente todo el mundo considera los conocimientos t√©cnicos de poda y silenciosos. <br>  Pero ve a desmontar </p><br><h3 id="vzglyad-v-biologiyu">  Una mirada a la biolog√≠a </h3><br><p>  Me encanta cuando en Deep Learning las ideas provienen de la biolog√≠a.  Se puede confiar en ellos, como la evoluci√≥n (¬øsab√≠as que ReLU es muy similar a la <a href="http://www.gatsby.ucl.ac.uk/~lmate/biblio/dayanabbott.pdf" rel="nofollow">funci√≥n de activar las neuronas en el cerebro</a> ?) </p><br><p>  El proceso de poda modelo tambi√©n est√° cerca de la biolog√≠a.  La respuesta de la red aqu√≠ se puede comparar con la plasticidad del cerebro.  Un par de ejemplos interesantes est√°n en <a href="https://www.litres.ru/norman-doydzh/plastichnost-mozga/%3Futm_medium%3Dcpc%26utm_source%3Dgoogle%26utm_campaign%3DDSA%257C149839530%26utm_term%3D%26utm_content%3Dk50id%257Caud-499675211712%253Adsa-179513627318%257Ccid%257C149839530%257Caid%257C248455294996%257Cgid%257C6837176850%257Cpos%257C1t1%257Csrc%257Cg_%257Cdvc%257Cc%257Creg%257C1011993%257Crin%257C%257C%26k50id%3D6837176850%257Caud-499675211712%253Adsa-179513627318%26gclid%3DCj0KCQiA0ZHwBRCRARIsAK0Tr-oKPqkmL7_Oxg62JZO8Jlk9zO-9nYKIRFxHi_lgoCvsQQadvUGxUzkaApgpEALw_wcB" rel="nofollow">el</a> libro de <a href="https://www.litres.ru/norman-doydzh/plastichnost-mozga/%3Futm_medium%3Dcpc%26utm_source%3Dgoogle%26utm_campaign%3DDSA%257C149839530%26utm_term%3D%26utm_content%3Dk50id%257Caud-499675211712%253Adsa-179513627318%257Ccid%257C149839530%257Caid%257C248455294996%257Cgid%257C6837176850%257Cpos%257C1t1%257Csrc%257Cg_%257Cdvc%257Cc%257Creg%257C1011993%257Crin%257C%257C%26k50id%3D6837176850%257Caud-499675211712%253Adsa-179513627318%26gclid%3DCj0KCQiA0ZHwBRCRARIsAK0Tr-oKPqkmL7_Oxg62JZO8Jlk9zO-9nYKIRFxHi_lgoCvsQQadvUGxUzkaApgpEALw_wcB" rel="nofollow">Norman Dodge</a> : </p><br><ol><li>  El cerebro de una mujer que ten√≠a solo la mitad del nacimiento se reprogram√≥ para realizar las funciones de la mitad desaparecida. </li><li>  El tipo se dispar√≥ a s√≠ mismo la parte del cerebro responsable de la visi√≥n.  Con el tiempo, otras partes del cerebro asumieron estas funciones.  (no intentes de nuevo) </li></ol><br><p>  Entonces, desde su modelo, puede cortar algunos de los paquetes d√©biles.  En casos extremos, los paquetes restantes ayudar√°n a reemplazar los cortados. </p><br><h3 id="lyubish-transfer-learning-ili-uchish-s-nulya">  ¬øTe gusta Transferir aprendizaje o aprender desde cero? </h3><br><p>  <strong>Opci√≥n n√∫mero uno.</strong>  Est√°s utilizando Transfer Learning en Yolov3.  Retina, M√°scara-RCNN o U-Net.  Pero la mayor√≠a de las veces, no necesitamos reconocer 80 clases de objetos, como en COCO.  En mi pr√°ctica, todo est√° limitado a 1-2 clases.  Se puede suponer que la arquitectura para 80 clases es redundante aqu√≠.  Supone la idea de que la arquitectura necesita ser reducida.  Adem√°s, me gustar√≠a hacer esto sin perder los pesos pre-entrenados existentes. </p><br><p>  <strong>Opci√≥n n√∫mero dos.</strong>  Quiz√°s tenga muchos datos y recursos inform√°ticos, o simplemente necesite una arquitectura s√∫per personalizada.  No importa  Pero aprendes la red desde cero.  El orden habitual es observar la estructura de datos, seleccionar una arquitectura que se REDUZCA en t√©rminos de potencia e impulsar el abandono del reciclaje.  Vi abandonos 0.6, Carl. </p><br><p>  En ambos casos, la red se puede reducir.  Promocionado  Ahora vamos a averiguar qu√© tipo de <del>  circuncisi√≥n </del>  poda </p><br><h3 id="obschiy-algoritm">  Algoritmo general </h3><br><p>  Decidimos que podr√≠amos eliminar la convoluci√≥n.  Se ve muy simple: </p><br><p><img src="https://habrastorage.org/webt/ey/yt/-g/eyyt-g-b6pfzjrbnim_ssosyqqk.png"></p><br><p>  Eliminar cualquier convoluci√≥n es un estr√©s para la red, que generalmente conduce a un aumento en el error.  Por un lado, este crecimiento en error es un indicador de cu√°n correctamente eliminamos las convoluciones (por ejemplo, un gran crecimiento indica que estamos haciendo algo mal).  Pero el crecimiento peque√±o es bastante aceptable y a menudo se elimina mediante un entrenamiento posterior f√°cil y posterior con un LR peque√±o.  Agregamos un paso de reentrenamiento: </p><br><p><img src="https://habrastorage.org/webt/kb/ui/5d/kbui5dm1k8sgflm5xzu0wggbbhs.png"></p><br><p>  Ahora tenemos que entender cu√°ndo queremos detener nuestro ciclo de Aprendizaje &lt;-&gt; Poda.  Puede haber opciones ex√≥ticas cuando necesitamos reducir la red a un cierto tama√±o y velocidad de ejecuci√≥n (por ejemplo, para dispositivos m√≥viles).  Sin embargo, la opci√≥n m√°s com√∫n es continuar el ciclo hasta que el error sea m√°s alto que el permitido.  A√±adir condici√≥n: </p><br><p><img src="https://habrastorage.org/webt/1i/pi/52/1ipi52uqhkciw2ne-1zt2rbdmje.png"></p><br><p>  Entonces, el algoritmo se vuelve claro.  Queda por desmontar c√≥mo determinar las circunvoluciones eliminadas. </p><br><h3 id="poisk-udalyaemyh-svertok">  Busque la convoluci√≥n que se eliminar√° </h3><br><p>  Necesitamos eliminar algunas convoluciones.  Avanzar y "disparar" cualquiera es una mala idea, aunque funcionar√°.  Pero si tiene cabeza, puede pensar e intentar seleccionar convoluciones "d√©biles" para eliminarlas.  Hay varias opciones: </p><br><ol><li>  <a href="https://openreview.net/pdf%3Fid%3DrJqFGTslg" rel="nofollow">La medida L1 m√°s peque√±a o poda de baja_magnitud</a> .  La idea de que las convoluciones con peque√±os pesos hacen una peque√±a contribuci√≥n a la decisi√≥n final </li><li>  La medida L1 m√°s peque√±a teniendo en cuenta la desviaci√≥n promedio y est√°ndar.  Complementamos la evaluaci√≥n de la naturaleza de la distribuci√≥n. </li><li>  <a href="https://arxiv.org/abs/1512.08571" rel="nofollow">Enmascarar las convoluciones y eliminar lo menos que afecte la precisi√≥n resultante</a> .  Una definici√≥n m√°s precisa de convoluciones insignificantes, pero que consume mucho tiempo y recursos. </li><li>  Otros </li></ol><br><p>  Cada una de las opciones tiene derecho a la vida y sus propias caracter√≠sticas de implementaci√≥n.  Aqu√≠ consideramos la variante con la medida L1 m√°s peque√±a </p><br><h3 id="ruchnoy-process-dlya-yolov3">  Proceso manual para YOLOv3 </h3><br><p>  La arquitectura original contiene bloques residuales.  Pero no importa cu√°n geniales sean para las redes profundas, nos obstaculizar√°n un poco.  La dificultad es que no puede eliminar las conciliaciones con diferentes √≠ndices en estas capas: </p><br><p><img src="https://habrastorage.org/webt/mh/p-/-k/mhp--ksk3ifgurz5jx6exgcrm5c.png"></p><br><p>  Por lo tanto, seleccionamos las capas de las que podemos eliminar libremente las conciliaciones: </p><br><p><img src="https://habrastorage.org/webt/qy/ek/zo/qyekzofcur-q0auqurg3egxnato.png"></p><br><p>  Ahora construyamos un ciclo de trabajo: </p><br><ol><li>  Descarga de activaci√≥n </li><li>  Nos preguntamos cuanto cortar </li><li>  Recortar </li><li>  Aprende 10 eras con LR = 1e-4 </li><li>  Prueba </li></ol><br><p>  La descarga de convoluciones es √∫til para evaluar qu√© parte podemos eliminar en un determinado paso.  Ejemplos de descarga: </p><br><p><img src="https://habrastorage.org/webt/rp/jo/pk/rpjopk6dzfrl6psoucr8tgj0log.png"></p><br><p>  Vemos que en casi todas partes, el 5% de las convoluciones tienen una norma L1 muy baja y podemos eliminarlas.  En cada paso, dicha descarga se repiti√≥ y se realiz√≥ una evaluaci√≥n de qu√© capas y cu√°nto podr√≠an cortarse. </p><br><p>  Todo el proceso se complet√≥ en 4 pasos (aqu√≠ y en todas partes los n√∫meros para el RTX 2060 Super): </p><br><div class="scrollable-table"><table><thead><tr><th>  Paso </th><th>  mAp75 </th><th>  El n√∫mero de par√°metros, millones </th><th>  Tama√±o de red, mb </th><th>  Del original,% </th><th>  Tiempo de ejecuci√≥n, ms </th><th>  Condici√≥n de circuncisi√≥n </th></tr></thead><tbody><tr><td>  0 0 </td><td>  0.9656 </td><td>  60 60 </td><td>  241 </td><td>  100 </td><td>  180 </td><td>  - </td></tr><tr><td>  1 </td><td>  0,9622 </td><td>  55 </td><td>  218 </td><td>  91 91 </td><td>  175 </td><td>  5% de todos </td></tr><tr><td>  2 </td><td>  0,9625 </td><td>  50 </td><td>  197 </td><td>  83 </td><td>  168 </td><td>  5% de todos </td></tr><tr><td>  3 </td><td>  0,9633 </td><td>  39 </td><td>  155 </td><td>  64 </td><td>  155 </td><td>  15% para capas con m√°s de 400 convoluciones </td></tr><tr><td><del>  4 4 </del></td><td><del>  0.9555 </del></td><td><del>  31 </del></td><td><del>  124 </del></td><td><del>  51 </del></td><td><del>  146 </del></td><td><del>  10% para capas con m√°s de 100 convoluciones </del></td></tr></tbody></table></div><br><p>  Al paso 2, se agreg√≥ un efecto positivo: el tama√±o del parche 4 qued√≥ en la memoria, lo que aceler√≥ enormemente el proceso de reentrenamiento. <br>  En el paso 4, el proceso se detuvo porque  incluso una educaci√≥n superior prolongada no elev√≥ el mAp75 a valores antiguos. <br>  Como resultado, logramos acelerar la inferencia en un <strong>15%</strong> , reducir el tama√±o en un <strong>35%</strong> y no perder precisi√≥n. </p><br><h3 id="avtomatizaciya-dlya-bolee-prostyh-arhitektur">  Automatizaci√≥n para arquitecturas m√°s simples. </h3><br><p>  Para arquitecturas de red m√°s simples (sin adici√≥n condicional, bloques concaternos y residuales), es muy posible centrarse en el procesamiento de todas las capas convolucionales y automatizar el proceso de corte de convoluciones. </p><br><p>  He implementado <a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">esta</a> opci√≥n <a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">aqu√≠</a> . <br>  Es simple: solo tiene una funci√≥n de p√©rdida, un optimizador y generadores de lotes: </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pruning <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequence train_batch_generator = BatchGenerator... score_batch_generator = BatchGenerator... opt = Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>) pruner = pruning.Pruner(<span class="hljs-string"><span class="hljs-string">"config.json"</span></span>, <span class="hljs-string"><span class="hljs-string">"categorical_crossentropy"</span></span>, opt) pruner.prune(train_batch, valid_batch)</code> </pre> <br><p>  Si es necesario, puede cambiar los par√°metros de configuraci√≥n: </p><br><pre> <code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"input_model_path"</span></span>: <span class="hljs-string"><span class="hljs-string">"model.h5"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"output_model_path"</span></span>: <span class="hljs-string"><span class="hljs-string">"model_pruned.h5"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"finetuning_epochs"</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, # the number of epochs for train between pruning steps <span class="hljs-attr"><span class="hljs-attr">"stop_loss"</span></span>: <span class="hljs-number"><span class="hljs-number">0.1</span></span>, # loss for stopping process <span class="hljs-attr"><span class="hljs-attr">"pruning_percent_step"</span></span>: <span class="hljs-number"><span class="hljs-number">0.05</span></span>, # part of convs for delete on every pruning step <span class="hljs-attr"><span class="hljs-attr">"pruning_standart_deviation_part"</span></span>: <span class="hljs-number"><span class="hljs-number">0.2</span></span> # shift for limit pruning part }</code> </pre> <br><p>  Adem√°s, se implementa una restricci√≥n basada en la desviaci√≥n est√°ndar.  El objetivo es limitar una parte de las eliminadas, excluyendo convoluciones con medidas L1 ya "suficientes": </p><br><p><img src="https://habrastorage.org/webt/bh/_9/nq/bh_9nqasnp91xifixn7ilhco0mw.png"></p><br><p>  Por lo tanto, podemos eliminar solo convoluciones d√©biles de distribuciones similares a la derecha y no afectar la eliminaci√≥n de distribuciones como la izquierda: </p><br><p><img src="https://habrastorage.org/webt/pr/r5/zp/prr5zpjrdvh1wow6slejnn6axya.png"></p><br><p>  Cuando la distribuci√≥n se acerca a lo normal, el coeficiente pruning_standart_deviation_part se puede seleccionar de: </p><br><p><img src="https://habrastorage.org/webt/dl/yl/7d/dlyl7dub216jsr67dcbnhez5fl8.png"><br>  Recomiendo una suposici√≥n de 2 sigma.  O no puede enfocarse en esta caracter√≠stica, dejando el valor &lt;1.0. </p><br><p>  El resultado es un gr√°fico del tama√±o de la red, la p√©rdida y el tiempo de ejecuci√≥n de la red para toda la prueba, normalizado a 1.0.  Por ejemplo, aqu√≠ el tama√±o de la red se redujo casi 2 veces sin p√©rdida de calidad (una red de convoluci√≥n peque√±a para 100k pesos): </p><br><p><img src="https://habrastorage.org/webt/ig/hu/x_/ighux_gyoaptm71iu2hk_txga_g.png"></p><br><p>  La velocidad de carrera est√° sujeta a fluctuaciones normales y no ha cambiado mucho.  Hay una explicaci√≥n para esto: </p><br><ol><li>  El n√∫mero de convoluciones cambia de conveniente (32, 64, 128) a no el m√°s conveniente para tarjetas de video: 27, 51, etc.  Aqu√≠ puedo estar equivocado, pero lo m√°s probable es que afecte. </li><li>  La arquitectura no es amplia, sino consistente.  Al reducir el ancho, no tocamos la profundidad.  Por lo tanto, reducimos la carga, pero no cambiamos la velocidad. </li></ol><br><p>  Por lo tanto, la mejora se expres√≥ en una disminuci√≥n en la carga de CUDA durante la ejecuci√≥n en un 20-30%, pero no en una disminuci√≥n en el tiempo de ejecuci√≥n </p><br><h3 id="itogi">  Resumen </h3><br><p>  Reflexionar.  Consideramos 2 opciones de poda: para YOLOv3 (cuando tiene que trabajar con las manos) y para redes con arquitecturas m√°s f√°ciles.  Se puede ver que en ambos casos es posible lograr una reducci√≥n en el tama√±o de la red y la aceleraci√≥n sin p√©rdida de precisi√≥n.  Resultados: </p><br><ul><li>  Reducci√≥n de personal </li><li>  Ejecutar la aceleraci√≥n </li><li>  Reducci√≥n de carga CUDA </li><li>  Como resultado, respeto al medio ambiente (Optimizamos el uso futuro de los recursos inform√°ticos. En alg√∫n lugar, <a href="https://meduza.io/feature/2019/12/12/kto-takaya-greta-tunberg-i-pochemu-ona-stala-chelovekom-goda-zhurnal-time" rel="nofollow">Greta Tunberg se</a> regocija sola) </li></ul><br><h3 id="appendix">  Ap√©ndice </h3><br><ul><li>  Despu√©s del paso de poda, tambi√©n puede girar la cuantizaci√≥n (por ejemplo, con TensorRT) </li><li>  Tensorflow proporciona caracter√≠sticas para <a href="https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras" rel="nofollow">baja_magnitud_pruning</a> .  Funciona </li><li>  Quiero desarrollar el <a href="https://github.com/PaginDm/keras-L1-pruning" rel="nofollow">repositorio</a> y estar√© encantado de ayudar </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/482050/">https://habr.com/ru/post/482050/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../482034/index.html">Yandex: hay de todo ... acerca de los usuarios</a></li>
<li><a href="../482038/index.html">Estamos resumiendo los resultados de 2019 en Haber Career</a></li>
<li><a href="../482040/index.html">Ofrece programas de creaci√≥n de perfiles en C ++</a></li>
<li><a href="../482042/index.html">Trabajando con la biblioteca Newtonsoft.Json con un ejemplo real. Parte 2</a></li>
<li><a href="../482044/index.html">10 mejores pr√°cticas para asegurar las im√°genes de Docker. Parte 2</a></li>
<li><a href="../482052/index.html">Conjunto de datos de A√±o Nuevo 2019: diccionario tonal abierto del idioma ruso</a></li>
<li><a href="../482054/index.html">3. Pila el√°stica: an√°lisis de registro de seguridad. Tableros</a></li>
<li><a href="../482058/index.html">¬øDepredador o presa? ¬øQui√©n proteger√° a las autoridades de certificaci√≥n?</a></li>
<li><a href="../482060/index.html">Modelo de mandato de control de acceso (MAC): descripci√≥n general y aplicaciones de aplicaci√≥n</a></li>
<li><a href="../482064/index.html">Facilidad de desarrollar sitios multiling√ºes en CMS Umbraco 8</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
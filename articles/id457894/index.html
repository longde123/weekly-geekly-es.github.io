<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äç‚öñÔ∏è üöÇ üîß Bekerja dengan kluster Proxmox: instalasi, pengaturan jaringan, ZFS, memecahkan masalah umum ‚è¨ üïå üêÅ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Selama beberapa tahun terakhir, saya telah bekerja sangat dekat dengan kluster Proxmox: banyak klien membutuhkan infrastruktur mereka sendiri di mana ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bekerja dengan kluster Proxmox: instalasi, pengaturan jaringan, ZFS, memecahkan masalah umum</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457894/"> Selama beberapa tahun terakhir, saya telah bekerja sangat dekat dengan kluster Proxmox: banyak klien membutuhkan infrastruktur mereka sendiri di mana mereka dapat mengembangkan proyek mereka.  Itulah sebabnya saya dapat memberi tahu Anda tentang kesalahan dan masalah paling umum yang mungkin Anda temui.  Selain itu, kita tentu saja akan mengkonfigurasi sekelompok tiga node dari awal. <br><img src="https://habrastorage.org/webt/jz/j-/lq/jzj-lqgwozo7rze1o8ij7bvzday.png"><br><a name="habracut"></a><br>  Cluster Proxmox dapat terdiri dari dua atau lebih server.  Jumlah maksimum node dalam sebuah cluster adalah 32 buah.  Cluster kami sendiri akan terdiri dari tiga node pada multicast (dalam artikel saya juga akan menjelaskan cara meningkatkan cluster pada keunikan - ini penting jika Anda mendasarkan infrastruktur cluster Anda pada Hetzner atau OVH, misalnya).  Singkatnya, multicast memungkinkan transfer data ke beberapa node secara bersamaan.  Dengan multicast, kita tidak bisa memikirkan jumlah node dalam cluster (fokus pada batasan di atas). <br><br>  Cluster itu sendiri dibangun di jaringan internal (penting bahwa alamat IP berada di subnet yang sama), Hetzner dan OVH yang sama memiliki kemampuan untuk menggabungkan node di pusat data yang berbeda menggunakan teknologi Virtual Switch (Hetzner) dan vRack (OVH) - tentang Virtual Switch kami juga akan berbicara dalam artikel.  Jika penyedia hosting Anda tidak memiliki teknologi serupa di tempat kerja, maka Anda dapat menggunakan OVS (Open Virtual Switch), yang secara asli didukung oleh Proxmox, atau menggunakan VPN.  Namun, dalam kasus ini, saya sarankan menggunakan Unicast dengan sejumlah kecil node - situasi sering muncul di mana cluster hanya "berantakan" berdasarkan infrastruktur jaringan seperti itu dan harus dipulihkan.  Oleh karena itu, saya mencoba menggunakan OVH dan Hetzner dalam pekerjaan saya - saya telah melihat lebih sedikit insiden seperti itu, tetapi pertama-tama, pelajari penyedia hosting yang akan di-host: apakah ia memiliki teknologi alternatif, solusi apa yang ditawarkannya, apakah itu mendukung multicast, dan sebagainya . <br><br><h3>  Instal Proxmox </h3><br>  Proxmox dapat diinstal dengan dua cara: ISO-installer dan instalasi melalui shell.  Kami memilih metode kedua, jadi instal Debian di server. <br><br>  Kami langsung melanjutkan ke instalasi Proxmox di setiap server.  Instalasi sangat sederhana dan dijelaskan dalam dokumentasi resmi di sini. <br><br>  Tambahkan repositori Proxmox dan kunci repositori ini: <br><br><pre><code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://download.proxmox.com/debian/pve stretch pve-no-subscription"</span></span> &gt; /etc/apt/sources.list.d/pve-install-repo.list wget http://download.proxmox.com/debian/proxmox-ve-release-5.x.gpg -O /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg chmod +r /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg <span class="hljs-comment"><span class="hljs-comment"># optional, if you have a changed default umask</span></span></code> </pre> <br>  Memperbarui repositori dan sistem itu sendiri: <br><br><pre> <code class="bash hljs">apt update &amp;&amp; apt dist-upgrade</code> </pre> <br>  Setelah pembaruan berhasil, instal paket Proxmox yang diperlukan: <br><br><pre> <code class="bash hljs">apt install proxmox-ve postfix open-iscsi</code> </pre> <br>  <b>Catatan</b> : Postfix dan grub akan dikonfigurasikan selama instalasi - salah satunya mungkin gagal.  Mungkin ini akan disebabkan oleh fakta bahwa nama host tidak diselesaikan dengan nama.  Edit entri host dan lakukan pembaruan apt-get <br><br>  Mulai sekarang, kita dapat masuk ke antarmuka web Proxmox di https: // &lt;external-ip-address&gt;: 8006 (Anda akan menemukan sertifikat yang tidak dipercaya selama sambungan). <br><br><img src="https://habrastorage.org/webt/e_/cg/mv/e_cgmvs9rrh3qwq0su222v2j0iw.png"><br>  <b>Gambar 1.</b> Antarmuka web simpul Proxmox <br><br><h3>  Instal Nginx dan Let's Encrypt Certificate </h3><br>  Saya tidak terlalu menyukai situasi dengan sertifikat dan alamat IP, jadi saya sarankan untuk menginstal Nginx dan menyiapkan sertifikat Mari Enkripsi.  Saya tidak akan menjelaskan penginstalan Nginx, saya hanya akan meninggalkan file-file penting agar sertifikat enkripsi Mari berfungsi: <br><br><div class="spoiler">  <b class="spoiler_title">/etc/nginx/snippets/letsencrypt.conf</b> <div class="spoiler_text"><pre> <code class="nginx hljs"><span class="hljs-attribute"><span class="hljs-attribute">location</span></span><span class="hljs-regexp"><span class="hljs-regexp"> ^~</span></span> /.well-known/acme-challenge/ { <span class="hljs-attribute"><span class="hljs-attribute">allow</span></span> all; <span class="hljs-attribute"><span class="hljs-attribute">root</span></span> /var/lib/letsencrypt/; <span class="hljs-attribute"><span class="hljs-attribute">default_type</span></span> <span class="hljs-string"><span class="hljs-string">"text/plain"</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">try_files</span></span> <span class="hljs-variable"><span class="hljs-variable">$uri</span></span> =<span class="hljs-number"><span class="hljs-number">404</span></span>; }</code> </pre><br><br></div></div><br>  Perintah untuk menerbitkan sertifikat SSL: <br><br><pre> <code class="bash hljs">certbot certonly --agree-tos --email sos@livelinux.info --webroot -w /var/lib/letsencrypt/ -d proxmox1.domain.name</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Konfigurasi Situs di NGINX</b> <div class="spoiler_text"><pre> <code class="nginx hljs"><span class="hljs-attribute"><span class="hljs-attribute">upstream</span></span> proxmox1.domain.name { <span class="hljs-attribute"><span class="hljs-attribute">server</span></span> <span class="hljs-number"><span class="hljs-number">127.0.0.1:8006</span></span>; } <span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">listen</span></span> <span class="hljs-number"><span class="hljs-number">80</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">server_name</span></span> proxmox1.domain.name; <span class="hljs-attribute"><span class="hljs-attribute">include</span></span> snippets/letsencrypt.conf; <span class="hljs-attribute"><span class="hljs-attribute">return</span></span> <span class="hljs-number"><span class="hljs-number">301</span></span> https://<span class="hljs-variable"><span class="hljs-variable">$host</span></span><span class="hljs-variable"><span class="hljs-variable">$request_uri</span></span>; } <span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">listen</span></span> <span class="hljs-number"><span class="hljs-number">443</span></span> ssl; <span class="hljs-attribute"><span class="hljs-attribute">server_name</span></span> proxmox1.domain.name; <span class="hljs-attribute"><span class="hljs-attribute">access_log</span></span> /var/log/nginx/proxmox1.domain.name.access.log; <span class="hljs-attribute"><span class="hljs-attribute">error_log</span></span> /var/log/nginx/proxmox1.domain.name.<span class="hljs-literal"><span class="hljs-literal">error</span></span>.log; <span class="hljs-attribute"><span class="hljs-attribute">include</span></span> snippets/letsencrypt.conf; <span class="hljs-attribute"><span class="hljs-attribute">ssl_certificate</span></span> /etc/letsencrypt/live/proxmox1.domain.name/fullchain.pem; <span class="hljs-attribute"><span class="hljs-attribute">ssl_certificate_key</span></span> /etc/letsencrypt/live/proxmox1.domain.name/privkey.pem; <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> / { <span class="hljs-attribute"><span class="hljs-attribute">proxy_pass</span></span> https://proxmox1.domain.name; <span class="hljs-attribute"><span class="hljs-attribute">proxy_next_upstream</span></span> <span class="hljs-literal"><span class="hljs-literal">error</span></span> timeout invalid_header http_500 http_502 http_503 http_504; <span class="hljs-attribute"><span class="hljs-attribute">proxy_redirect</span></span> <span class="hljs-literal"><span class="hljs-literal">off</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_buffering</span></span> <span class="hljs-literal"><span class="hljs-literal">off</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_set_header</span></span> Host <span class="hljs-variable"><span class="hljs-variable">$host</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_set_header</span></span> X-Real-IP <span class="hljs-variable"><span class="hljs-variable">$remote_addr</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_set_header</span></span> X-Forwarded-For <span class="hljs-variable"><span class="hljs-variable">$proxy_add_x_forwarded_for</span></span>; }</code> </pre> <br></div></div><br>  Setelah menginstal sertifikat SSL, jangan lupa untuk mengaturnya untuk diperpanjang secara otomatis melalui cron: <br><br><pre> <code class="bash hljs">0 */12 * * * /usr/bin/certbot -a \! -d /run/systemd/system &amp;&amp; perl -e <span class="hljs-string"><span class="hljs-string">'sleep int(rand(3600))'</span></span> &amp;&amp; certbot -q renew --renew-hook <span class="hljs-string"><span class="hljs-string">"systemctl reload nginx"</span></span></code> </pre> <br>  Hebat!  Sekarang kita dapat mengakses domain kita melalui HTTPS. <br><br>  <b>Catatan</b> : untuk menonaktifkan jendela informasi berlangganan, jalankan perintah ini: <br><br><pre> <code class="bash hljs">sed -i.bak <span class="hljs-string"><span class="hljs-string">"s/data.status !== 'Active'/false/g"</span></span> /usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js &amp;&amp; systemctl restart pveproxy.service</code> </pre> <br>  <b>Pengaturan jaringan</b> <br><br>  Sebelum menghubungkan ke cluster, konfigurasikan antarmuka jaringan pada hypervisor.  Perlu dicatat bahwa konfigurasi node yang tersisa tidak berbeda, kecuali untuk alamat IP dan nama server, jadi saya tidak akan menduplikasi pengaturan mereka. <br><br>  Kami akan membuat jembatan jaringan untuk jaringan internal sehingga mesin virtual kami (dalam versi saya akan ada wadah LXC untuk kenyamanan), pertama, mereka terhubung ke jaringan internal hypervisor dan dapat berinteraksi satu sama lain.  Kedua, beberapa saat kemudian kami akan menambahkan jembatan untuk jaringan eksternal sehingga mesin virtual memiliki alamat IP eksternal mereka sendiri.  Dengan demikian, kontainer akan berada di belakang NAT'om bersama kami. <br><br>  Ada dua cara untuk bekerja dengan konfigurasi jaringan Proxmox: melalui antarmuka web atau melalui file konfigurasi / etc / network / interfaces.  Pada opsi pertama, Anda perlu me-restart server (atau Anda cukup mengganti nama file interfaces.new menjadi interface dan me-restart layanan jaringan melalui systemd).  Jika Anda baru mulai mengonfigurasi dan belum ada mesin virtual atau wadah LXC, maka disarankan untuk memulai kembali hypervisor setelah perubahan. <br><br>  Sekarang buat jembatan jaringan yang disebut vmbr1 di tab jaringan di panel web Proxmox. <br><br><img src="https://habrastorage.org/webt/i3/6k/wp/i36kwpe0ky3khngufngwifulwcs.png"><br>  <b>Gambar 2.</b> Antarmuka jaringan node proxmox1 <br><br><img src="https://habrastorage.org/webt/ro/k6/tg/rok6tgyuqyvte_dswvl-0xgvbxe.png"><br>  <b>Gambar 3.</b> Membuat jembatan jaringan <br><br><img src="https://habrastorage.org/webt/kx/xu/kg/kxxukgzgym97cjezlvrczgtji8g.png"><br>  <b>Gambar 4.</b> Konfigurasi konfigurasi jaringan vmbr1 <br><br>  Penyiapannya sangat sederhana - kita perlu vmbr1 sehingga instans mendapatkan akses ke Internet. <br><br>  Sekarang restart hypervisor kami dan periksa apakah antarmuka telah dibuat: <br><br><img src="https://habrastorage.org/webt/cx/b9/ga/cxb9ga2zhwn0fefphugyihuj6fg.png"><br>  <b>Gambar 5.</b> Antarmuka jaringan vmbr1 di ip output perintah <br><br>  Catatan: Saya sudah memiliki antarmuka ens19 - ini adalah antarmuka dengan jaringan internal, berdasarkan di mana sebuah cluster akan dibuat. <br><br>  Ulangi langkah-langkah ini di dua hypervisor lainnya, dan kemudian lanjutkan ke langkah berikutnya - mempersiapkan cluster. <br><br>  Juga, tahap penting sekarang adalah mengaktifkan penerusan paket - tanpanya, instance tidak akan mendapatkan akses ke jaringan eksternal.  Buka file sysctl.conf dan ubah nilai parameter net.ipv4.ip_forward menjadi 1, setelah itu kita masukkan perintah berikut: <br><br><pre> <code class="bash hljs">sysctl -p</code> </pre> <br>  Dalam output Anda harus melihat direktif net.ipv4.ip_forward (jika Anda belum mengubahnya sebelumnya) <br><br>  <b>Mengkonfigurasi Cluster Proxmox</b> <br><br>  Sekarang mari kita langsung ke cluster.  Setiap node harus menyelesaikan dirinya sendiri dan node lain di jaringan internal, untuk ini perlu untuk mengubah nilai dalam catatan host sebagai berikut (setiap node harus memiliki catatan tentang yang lain): <br><br><pre> <code class="bash hljs">172.30.0.15 proxmox1.livelinux.info proxmox1 172.30.0.16 proxmox2.livelinux.info proxmox2 172.30.0.17 proxmox3.livelinux.info proxmox3</code> </pre><br>  Juga diperlukan untuk menambahkan kunci publik dari setiap node ke yang lain - ini diperlukan untuk membuat sebuah cluster. <br><br>  Buat cluster melalui panel web: <br><br><img src="https://habrastorage.org/webt/vl/rm/rh/vlrmrhkpwn5dle9gcnomfueoega.png"><br>  <b>Gambar 6.</b> Membuat cluster melalui antarmuka web <br><br>  Setelah membuat cluster, kita perlu mendapatkan informasi tentangnya.  Buka tab yang sama dari kluster dan klik tombol "Gabung Informasi": <br><br><img src="https://habrastorage.org/webt/gj/ur/t2/gjurt2tqr_pgtlfsxv7l3hrz398.png"><br>  <b>Gambar 7.</b> Informasi tentang cluster yang dibuat <br><br>  Informasi ini berguna bagi kami ketika bergabung dengan node kedua dan ketiga di cluster.  Kami terhubung ke node kedua dan di tab Cluster klik tombol "Gabung Cluster": <br><br><img src="https://habrastorage.org/webt/fo/8u/zh/fo8uzhx-lzxfyqkapqdqsfuoalq.png"><br>  <b>Gambar 8.</b> Menghubungkan ke cluster node <br><br>  Mari kita menganalisis parameter untuk koneksi lebih detail: <br><br><ol><li>  <b>Peer Address: Alamat</b> IP dari server pertama (ke yang kami sambungkan) </li><li>  <b>Kata sandi:</b> kata sandi server pertama </li><li>  <b>Sidik jari:</b> kami mendapatkan nilai ini dari informasi cluster </li></ol><br><img src="https://habrastorage.org/webt/l4/zp/eo/l4zpeodynxiuqubl1fjc4b9iona.png"><br>  <b>Gambar 9.</b> Keadaan cluster setelah menghubungkan node kedua <br><br>  Node kedua berhasil terhubung!  Namun, ini tidak selalu terjadi.  Jika Anda mengikuti langkah-langkah yang salah atau masalah jaringan muncul, maka bergabung dengan cluster akan gagal, dan cluster itu sendiri akan "rusak".  Solusi terbaik adalah dengan memutus node dari cluster, hapus semua informasi tentang cluster di atasnya, kemudian restart server dan periksa langkah-langkah sebelumnya.  Bagaimana cara melepaskan node dari sebuah cluster dengan aman?  Pertama, hapus dari cluster di server pertama: <br><br><pre> <code class="bash hljs">pvecm del proxmox2</code> </pre> <br>  Setelah itu node akan terputus dari cluster.  Sekarang pergi ke simpul yang rusak dan nonaktifkan layanan berikut ini: <br><br><pre> <code class="bash hljs">systemctl stop pvestatd.service systemctl stop pvedaemon.service systemctl stop pve-cluster.service systemctl stop corosync systemctl stop pve-cluster</code> </pre><br>  Cluster Proxmox menyimpan informasi tentang dirinya di database sqlite, juga perlu dibersihkan: <br><br><pre> <code class="bash hljs">sqlite3 /var/lib/pve-cluster/config.db delete from tree <span class="hljs-built_in"><span class="hljs-built_in">where</span></span> name = <span class="hljs-string"><span class="hljs-string">'corosync.conf'</span></span>; .quit</code> </pre><br>  Data tentang kulit kayu berhasil dihapus.  Hapus file yang tersisa, untuk ini Anda harus memulai sistem file cluster dalam mode mandiri: <br><br><pre> <code class="bash hljs">pmxcfs -l rm /etc/pve/corosync.conf rm /etc/corosync/* rm /var/lib/corosync/* rm -rf /etc/pve/nodes/*</code> </pre><br>  Kami me-restart server (ini tidak perlu, tetapi kami aman: semua layanan pada akhirnya harus berjalan dengan benar. Agar tidak ketinggalan apa pun, kami akan memulai ulang).  Setelah diaktifkan, kita akan mendapatkan node kosong tanpa informasi tentang cluster sebelumnya dan kita dapat memulai koneksi lagi. <br><br><h3>  Instal dan konfigurasikan ZFS </h3><br>  ZFS adalah sistem file yang dapat digunakan dengan Proxmox.  Dengan itu, Anda dapat membiarkan diri Anda mereplikasi data ke hypervisor lain, memigrasikan wadah mesin / LXC virtual, mengakses wadah LXC dari sistem host, dan sebagainya.  Menginstalnya cukup sederhana, mari kita lanjutkan ke analisis.  Tiga SSD tersedia di server saya, yang akan kami gabungkan menjadi array RAID. <br><br>  Tambahkan repositori: <br><br><pre> <code class="bash hljs">nano /etc/apt/sources.list.d/stretch-backports.list deb http://deb.debian.org/debian stretch-backports main contrib deb-src http://deb.debian.org/debian stretch-backports main contrib nano /etc/apt/preferences.d/90_zfs Package: libnvpair1linux libuutil1linux libzfs2linux libzpool2linux spl-dkms zfs-dkms zfs-test zfsutils-linux zfsutils-linux-dev zfs-zed Pin: release n=stretch-backports Pin-Priority: 990</code> </pre><br>  Memperbarui daftar paket: <br><br><pre> <code class="bash hljs">apt update</code> </pre> <br>  Atur dependensi yang diperlukan: <br><br><pre> <code class="bash hljs"> apt install --yes dpkg-dev linux-headers-$(uname -r) linux-image-amd64</code> </pre> <br>  Instal ZFS sendiri: <br><br><pre> <code class="bash hljs">apt-get install zfs-dkms zfsutils-linux</code> </pre> <br>  Jika di masa depan Anda mendapatkan kesalahan fusermount: perangkat sekering tidak ditemukan, coba 'modprobe fuse' terlebih dahulu, kemudian jalankan perintah berikut: <br><br><pre> <code class="bash hljs">modprobe fuse</code> </pre> <br>  Sekarang mari kita lanjutkan langsung ke pengaturan.  Pertama kita perlu memformat SSD dan mengkonfigurasinya melalui parted: <br><br><div class="spoiler">  <b class="spoiler_title">Konfigurasikan / dev / hda</b> <div class="spoiler_text"><pre> <code class="bash hljs">parted /dev/sda (parted) <span class="hljs-built_in"><span class="hljs-built_in">print</span></span> Model: ATA SAMSUNG MZ7LM480 (scsi) Disk /dev/sda: 480GB Sector size (logical/physical): 512B/512B Partition Table: msdos Disk Flags: Number Start End Size Type File system Flags 1 1049kB 4296MB 4295MB primary raid 2 4296MB 4833MB 537MB primary raid 3 4833MB 37,0GB 32,2GB primary raid (parted) mkpart Partition <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>? primary/extended? primary File system <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>? [ext2]? zfs Start? 33GB End? 480GB Warning: You requested a partition from 33,0GB to 480GB (sectors 64453125..937500000). The closest location we can manage is 37,0GB to 480GB (sectors 72353792..937703087). Is this still acceptable to you? Yes/No? yes</code> </pre><br></div></div><br>  Tindakan serupa harus dilakukan untuk drive lain.  Setelah semua disk disiapkan, lanjutkan ke langkah berikutnya: <br><br>  zpool membuat -f -o ashift = 12 rpool / dev / sda4 / dev / sdb4 / dev / sdc4 <br><br>  Kami memilih ashift = 12 untuk alasan kinerja - ini adalah rekomendasi dari zfsonlinux itu sendiri, Anda dapat membaca lebih lanjut tentang itu di wiki mereka: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">github.com/zfsonlinux/zfs/wiki/faq#performance-considerations</a> <br><br>  Terapkan beberapa pengaturan untuk ZFS: <br><br><pre> <code class="bash hljs">zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> atime=off rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> compression=lz4 rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> dedup=off rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> snapdir=visible rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> primarycache=all rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> aclinherit=passthrough rpool zfs inherit acltype rpool zfs get -r acltype rpool zfs get all rpool | grep compressratio</code> </pre><br>  Sekarang kita perlu menghitung beberapa variabel untuk menghitung zfs_arc_max, saya melakukan ini sebagai berikut: <br><br><pre> <code class="bash hljs">mem =`free --giga | grep Mem | awk <span class="hljs-string"><span class="hljs-string">'{print $2}'</span></span>` partofmem=$((<span class="hljs-variable"><span class="hljs-variable">$mem</span></span>/10)) <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">$setzfscache</span></span> &gt; /sys/module/zfs/parameters/zfs_arc_max grep c_max /proc/spl/kstat/zfs/arcstats zfs create rpool/data cat &gt; /etc/modprobe.d/zfs.conf &lt;&lt; EOL options zfs zfs_arc_max=<span class="hljs-variable"><span class="hljs-variable">$setzfscache</span></span> EOL <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">$setzfscache</span></span> &gt; /sys/module/zfs/parameters/zfs_arc_max grep c_max /proc/spl/kstat/zfs/arcstats</code> </pre> <br>  Saat ini, kolam telah berhasil dibuat, kami juga membuat subpool data.  Anda dapat memeriksa status kumpulan Anda dengan perintah status zpool.  Tindakan ini harus dilakukan pada semua hypervisor, dan kemudian melanjutkan ke langkah berikutnya. <br><br>  Sekarang tambahkan ZFS ke Proxmox.  Kita pergi ke pengaturan pusat data (yaitu, dan bukan simpul terpisah) di bagian "Penyimpanan", klik tombol "Tambah" dan pilih opsi "ZFS", setelah itu kita akan melihat parameter berikut: <br><br>  ID: Nama seratus.  Saya memberinya nama local-zfs <br>  ZFS Pool: Kami membuat rpool / data, dan kami menambahkannya di sini. <br>  Node: tentukan semua node yang tersedia <br><br>  Perintah ini menciptakan kumpulan baru dengan drive yang kami pilih.  Pada setiap hypervisor, sebuah penyimpanan baru akan muncul bernama local-zfs, setelah itu Anda dapat memigrasikan mesin virtual Anda dari penyimpanan lokal ke ZFS. <br><br><h3>  Contoh replikasi untuk hypervisor tetangga </h3><br>  Cluster Proxmox memiliki kemampuan untuk mereplikasi data dari satu hypervisor ke yang lain: opsi ini memungkinkan Anda untuk mengubah instance dari satu server ke yang lain.  Data akan relevan pada saat sinkronisasi terakhir - waktunya dapat diatur saat membuat replikasi (15 menit ditetapkan sebagai standar).  Ada dua cara untuk memigrasi instance ke node Proxmox lain: manual dan otomatis.  Mari kita lihat opsi manual terlebih dahulu, dan pada akhirnya saya akan memberi Anda skrip Python yang akan memungkinkan Anda untuk membuat mesin virtual pada hypervisor yang dapat diakses ketika salah satu hypervisor tidak tersedia. <br><br>  Untuk membuat replikasi, buka panel web Proxmox dan buat mesin virtual atau wadah LXC.  Dalam paragraf sebelumnya, kami mengkonfigurasi jembatan vmbr1 dengan NAT, yang akan memungkinkan kami untuk pergi ke jaringan eksternal.  Saya akan membuat wadah LXC dengan MySQL, Nginx dan PHP-FPM dengan situs uji untuk menguji replikasi.  Di bawah ini adalah instruksi langkah demi langkah. <br><br>  Kami memuat templat yang sesuai (pergi ke penyimpanan -&gt; Konten -&gt; Templat), contoh dalam tangkapan layar: <br><br><img src="https://habrastorage.org/webt/sd/bd/57/sdbd579lmmzxefsigiivaftvpce.png"><br>  <b>Gambar 10.</b> Penyimpanan lokal dengan templat dan gambar VM <br><br>  Klik tombol "Templates" dan muatkan templat kontainer LXC yang kami butuhkan: <br><br><img src="https://habrastorage.org/webt/qx/ug/he/qxughewqdsfniccmaamka9idie0.png"><br>  <b>Gambar 11.</b> Memilih dan memuat template <br><br>  Sekarang kita dapat menggunakannya saat membuat wadah LXC baru.  Pilih hypervisor pertama dan klik tombol "Buat CT" di sudut kanan atas: kita akan melihat panel untuk membuat contoh baru.  Langkah-langkah instalasi cukup sederhana dan saya hanya akan memberikan file konfigurasi untuk wadah LXC ini: <br><br><pre> <code class="bash hljs">arch: amd64 cores: 3 memory: 2048 nameserver: 8.8.8.8 net0: name=eth0,bridge=vmbr1,firewall=1,gw=172.16.0.1,hwaddr=D6:60:C5:39:98:A0,ip=172.16.0.2/24,<span class="hljs-built_in"><span class="hljs-built_in">type</span></span>=veth ostype: centos rootfs: <span class="hljs-built_in"><span class="hljs-built_in">local</span></span>:100/vm-100-disk-1.raw,size=10G swap: 512 unprivileged:</code> </pre><br>  Wadah berhasil dibuat.  Anda dapat terhubung ke wadah LXC melalui perintah enter pct, saya juga menambahkan kunci hypervisor SSH sebelum instalasi untuk terhubung langsung melalui SSH (ada beberapa masalah dengan tampilan terminal di PCT).  Saya menyiapkan server dan menginstal semua aplikasi server yang diperlukan di sana, sekarang Anda dapat melanjutkan untuk membuat replikasi. <br><br>  Kami klik pada wadah LXC dan pergi ke tab "Replikasi", di mana kami membuat parameter replikasi menggunakan tombol "Tambah": <br><br><img src="https://habrastorage.org/webt/ub/ac/si/ubacsivqghyu5w9np8dlnjdqe3g.png"><br>  <b>Gambar 12.</b> Membuat replikasi di antarmuka Proxmox <br><br><img src="https://habrastorage.org/webt/ea/mb/48/eamb489i0yqndxdcknvr2f1vefi.png"><br>  <b>Gambar 13.</b> Jendela penciptaan pekerjaan Replikasi <br><br>  Saya membuat tugas mereplikasi wadah ke simpul kedua, seperti yang dapat Anda lihat di tangkapan layar berikutnya, replikasi berhasil - perhatikan bidang "Status", ini memberitahukan tentang status replikasi, juga perlu memperhatikan bidang "Durasi" untuk mengetahui berapa lama replikasi data berlangsung. <br><br><img src="https://habrastorage.org/webt/wr/hd/t7/wrhdt7uk4szufdqrvboovxwr6t0.png"><br>  <b>Gambar 14.</b> Daftar sinkronisasi VM <br><br>  Sekarang cobalah untuk memigrasi mesin ke node kedua menggunakan tombol "Migrasi" <br><br>  Migrasi wadah akan dimulai, log dapat dilihat dalam daftar tugas - akan ada migrasi kami.  Setelah itu, wadah akan dipindahkan ke simpul kedua. <br><br>  <b>Galat "Verifikasi Kunci Host Gagal"</b> <br><br>  Kadang-kadang ketika mengkonfigurasi cluster, masalah serupa mungkin muncul - mencegah mesin dari migrasi dan membuat replikasi, yang menghilangkan keuntungan dari solusi cluster.  Untuk memperbaiki kesalahan ini, hapus file known_hosts dan hubungkan melalui SSH ke node yang bentrok: <br><br><pre> <code class="bash hljs">/usr/bin/ssh -o <span class="hljs-string"><span class="hljs-string">'HostKeyAlias=proxmox2'</span></span> root@172.30.0.16</code> </pre><br>  Terima Hostkey dan coba masukkan perintah ini, itu harus menghubungkan Anda ke server: <br><br><pre> <code class="bash hljs">/usr/bin/ssh -o <span class="hljs-string"><span class="hljs-string">'BatchMode=yes'</span></span> -o <span class="hljs-string"><span class="hljs-string">'HostKeyAlias=proxmox2'</span></span> root@172.30.0.16</code> </pre><br><h3>  Fitur pengaturan jaringan di Hetzner </h3><br>  Pergi ke panel Robot dan klik tombol "Virtual Switches".  Pada halaman berikutnya Anda akan melihat panel untuk membuat dan mengelola antarmuka Switch Virtual: pertama Anda harus membuatnya, dan kemudian "menghubungkan" server khusus untuk itu.  Dalam pencarian, tambahkan server yang diperlukan untuk terhubung - mereka tidak perlu di-boot ulang, hanya perlu menunggu hingga 10-15 menit ketika koneksi ke Virtual Switch akan aktif. <br><br>  Setelah menambahkan server ke Virtual Switch melalui panel web, kami terhubung ke server dan membuka file konfigurasi antarmuka jaringan, tempat kami membuat antarmuka jaringan baru: <br><br><pre> <code class="bash hljs">auto enp4s0.4000 iface enp4s0.4000 inet static address 10.1.0.11/24 mtu 1400 vlan-raw-device enp4s0</code> </pre> <br>  Mari kita lihat lebih dekat apa itu.  Pada intinya, itu adalah VLAN yang terhubung ke antarmuka fisik tunggal yang disebut enp4s0 (mungkin berbeda untuk Anda), dengan nomor VLAN - ini adalah nomor Virtual Switch yang Anda buat di panel web Robot Hetzner.  Anda dapat menentukan alamat apa saja, asalkan alamat itu lokal. <br><br>  Saya perhatikan bahwa Anda harus mengonfigurasi enp4s0 seperti biasa, bahkan harus berisi alamat IP eksternal yang dikeluarkan ke server fisik Anda.  Ulangi langkah-langkah ini di hypervisor lain, lalu reboot layanan jaringannya, ping ke simpul tetangga menggunakan alamat IP Switch Virtual.  Jika ping berhasil, maka Anda telah berhasil membuat koneksi antara server menggunakan Virtual Switch. <br><br>  Saya juga akan melampirkan file konfigurasi sysctl.conf, itu akan diperlukan jika Anda memiliki masalah dengan paket penerusan dan parameter jaringan lainnya: <br><br><pre> <code class="bash hljs">net.ipv6.conf.all.disable_ipv6=0 net.ipv6.conf.default.disable_ipv6 = 0 net.ipv6.conf.all.forwarding=1 net.ipv4.conf.all.rp_filter=1 net.ipv4.tcp_syncookies=1 net.ipv4.ip_forward=1 net.ipv4.conf.all.send_redirects=0</code> </pre><br>  <b>Menambahkan Subnet IPv4 ke Hetzner</b> <br><br>  Sebelum mulai bekerja, Anda perlu memesan subnet di Hetzner, Anda dapat melakukan ini melalui panel Robot. <br><br>  Buat jembatan jaringan dengan alamat yang akan berasal dari subnet ini.  Contoh Konfigurasi: <br><br><pre> <code class="bash hljs">auto vmbr2 iface vmbr2 inet static address ip-address netmask 29 bridge-ports none bridge-stp off bridge-fd 0</code> </pre> <br>  Sekarang pergi ke pengaturan mesin virtual di Proxmox dan buat antarmuka jaringan baru yang akan dilampirkan ke jembatan vmbr2.  Saya menggunakan wadah LXC, konfigurasinya dapat segera diubah di Proxmox.  Konfigurasi akhir untuk Debian: <br><br><pre> <code class="bash hljs">auto eth0 iface eth0 inet static address ip-address netmask 26 gateway bridge-address</code> </pre> <br>  Harap dicatat: Saya menetapkan 26 mask, bukan 29 - ini diperlukan agar jaringan dapat bekerja pada mesin virtual. <br><br>  <b>Menambahkan Alamat IPv4 ke Hetzner</b> <br><br>  Situasi dengan satu alamat IP berbeda - biasanya Hetzner memberi kami alamat tambahan dari server subnet.  Ini berarti bahwa alih-alih vmbr2 kita perlu menggunakan vmbr0, tetapi saat ini kita tidak memilikinya.  Intinya adalah bahwa vmbr0 harus berisi alamat IP dari server besi (yaitu, gunakan alamat yang menggunakan antarmuka jaringan fisik enp2s0).  Alamat harus dipindahkan ke vmbr0, konfigurasi berikut cocok untuk ini (saya sarankan Anda memesan KVM, untuk melanjutkan operasi jaringan): <br><br><pre> <code class="bash hljs">auto enp2s0 iface enp2s0 inet manual auto vmbr0 iface vmbr0 inet static address ip-address netmask 255.255.255.192 gateway ip-gateway bridge-ports enp2s0 bridge-stp off bridge-fd 0</code> </pre><br>  Mulai ulang server, jika mungkin (jika tidak, mulai ulang layanan jaringan), lalu periksa antarmuka jaringan melalui ip a: <br><br><pre> <code class="bash hljs">2: enp2s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master vmbr0 state UP group default qlen 1000 link/ether 44:8a:5b:2c:30:c2 brd ff:ff:ff:ff:ff:ff</code> </pre><br>  Seperti yang Anda lihat di sini, enp2s0 terhubung ke vmbr0 dan tidak memiliki alamat IP, karena itu ditugaskan untuk vmbr0. <br><br>  Sekarang dalam pengaturan mesin virtual, tambahkan antarmuka jaringan yang akan terhubung ke vmbr0.  Untuk gateway, tentukan alamat yang dilampirkan pada vmbr0. <br><br><h3>  Pada akhirnya </h3><br>  Saya harap artikel ini berguna ketika Anda mengatur cluster Proxmox di Hetzner.  Jika waktu mengizinkan, saya akan memperluas artikel dan menambahkan instruksi untuk OVH - di sana juga, tidak semuanya jelas, seperti yang terlihat pada pandangan pertama.  Materi ternyata cukup banyak, jika Anda menemukan kesalahan, maka silakan tulis di komentar, saya akan memperbaikinya.  Terima kasih atas perhatiannya. <br><br>  <i>Diposting oleh Ilya Andreev, diedit oleh Alexei Zhadan dan Tim Live Linux</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id457894/">https://habr.com/ru/post/id457894/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id457876/index.html">Terjemahan: IEEE 802.15.4z Standar. Apa yang menanti kita di masa depan?</a></li>
<li><a href="../id457884/index.html">Sovereign Internet - klarifikasi pesanan</a></li>
<li><a href="../id457886/index.html">Otentikasi dua faktor di situs menggunakan token USB. Sekarang untuk Linux</a></li>
<li><a href="../id457888/index.html">Pengujian mutasi: pengujian pengujian</a></li>
<li><a href="../id457892/index.html">Profesor Roulette</a></li>
<li><a href="../id457896/index.html">Zimbra dan perlindungan server berlebih</a></li>
<li><a href="../id457900/index.html">Komisi Komunikasi Federal AS Melawan Meteorologis</a></li>
<li><a href="../id457902/index.html">Mitap untuk Ilmu Data</a></li>
<li><a href="../id457904/index.html">Radio atom - siaran musik pertama</a></li>
<li><a href="../id457906/index.html">Dokter percaya bahwa dalam waktu dekat, perangkat pembuat vaksin akan muncul di rumah dan apotek</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
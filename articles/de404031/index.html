<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî∏ ‚úäüèø üë©üèº‚Äçüé® Google Maps-Update durch eingehendes Lernen und Street View üöé üö§ ‚ù£Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Jeden Tag erstellt Google Maps n√ºtzliche Routen und bietet Millionen von Menschen Informationen zu Staus und kommerziellen Organisationen. Damit sich ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Google Maps-Update durch eingehendes Lernen und Street View</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/404031/"> Jeden Tag erstellt Google Maps n√ºtzliche Routen und bietet Millionen von Menschen Informationen zu Staus und kommerziellen Organisationen.  Damit sich unsere Benutzer wohler f√ºhlen, sollten diese Informationen die sich st√§ndig √§ndernde Welt in Echtzeit widerspiegeln.  Street View-Autos sammeln t√§glich Millionen von Bildern, und es ist unm√∂glich, mehr als 80 Milliarden hochaufl√∂sende Bilder, die heute gesammelt wurden, manuell zu analysieren, um neue oder aktualisierte Informationen zu finden, die f√ºr die Platzierung in Google Maps geeignet sind.  Eines der Ziele des Ground Truth-Teams ist das automatische Extrahieren von Informationen aus georeferenzierten Bildern, um Google Maps zu verbessern. <br><br>  In dem Artikel ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Extrahieren strukturierter Informationen aus der Street View-Bilddatenbank mithilfe von Aufmerksamkeitsalgorithmen</a> ‚Äú haben wir unseren Ansatz zur genauen automatischen Erkennung von Stra√üennamen in sehr komplexen Street View-Fotos aus verschiedenen L√§ndern mithilfe eines tiefen neuronalen Netzwerks beschrieben.  Unser Algorithmus zeigte eine Genauigkeit von 84,2% im komplexen FSNS-Datensatz ( <a href="">French Street Name Signs</a> ) und war den bisherigen Marktf√ºhrern in diesem Bereich weit voraus.  Was wichtig ist, unser System l√§sst sich leicht skalieren, um andere Arten von Informationen aus Street View-Fotos zu extrahieren, und jetzt k√∂nnen wir Anzeichen von Handelsunternehmen automatisch erkennen.  Und wir freuen uns, Ihnen mitteilen zu k√∂nnen, dass dieses Modell <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gemeinfrei ist</a> ! <br><a name="habracut"></a><br><img src="https://habrastorage.org/getpro/geektimes/post_images/1a0/609/1fd/1a06091fd91d8c6b6a23c1bd37e5ffe4.png" alt="Bild"><br>  <i>Ein Beispiel f√ºr einen Stra√üennamen, der vom System erfolgreich erkannt wurde.</i>  <i>Ein und dasselbe Zeichen kann durch mehrere Fotos dargestellt werden, bis zu 4 St√ºck.</i> <br><br>  Das Erkennen von Text in einer nat√ºrlichen Umgebung ist eine schwierige Aufgabe f√ºr Computer Vision und maschinelles Lernen.  Herk√∂mmliche <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zeichenerkennungssysteme</a> (OCR) extrahieren Text aus gescannten Dokumenten, und Text aus Stra√üenfotos ist aufgrund visueller Artefakte - Verzerrung, Behinderung, Unsch√§rfe, komplexer Hintergrund oder unterschiedliche Sichtweisen - schwieriger zu erkennen.  Unsere Versuche, diese Forschungsprobleme zu l√∂sen, begannen 2008, als wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mithilfe neuronaler Netze Gesichter und Nummernschilder verwischten</a> , um die Privatsph√§re unserer Benutzer zu sch√ºtzen.  Nach dieser Studie haben wir festgestellt, dass wir mit einer ausreichend gro√üen Menge markierter Daten maschinelles Lernen verwenden k√∂nnen, um nicht nur die Privatsph√§re der Nutzer zu sch√ºtzen, sondern auch um Google Maps neue Informationen hinzuzuf√ºgen. <br><br>  Im Jahr 2014 ver√∂ffentlichte das Ground Truth-Team den SVHN-Datensatz ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Street View House Numbers</a> ), eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erweiterte Methode zur Erkennung von Hausnummern</a> , die von dem damaligen Studenten, jetzt Google-Mitarbeiter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Jan Goodfellow, durchgef√ºhrt wurde</a> .  Diese Arbeit war nicht nur von akademischem Interesse, sondern auch entscheidend f√ºr die Verbesserung der Genauigkeit von Google Maps.  Heute wird dank dieses Systems rund ein Drittel der Standorte weltweit verbessert.  In einigen L√§ndern wie Brasilien hat dieser Algorithmus den Standort von mehr als 90% der Adressen in Google Maps angegeben, was die Benutzerfreundlichkeit unserer Karten erheblich verbessert hat. <br><br>  Der n√§chste logische Schritt bestand darin, diese Techniken auf Stra√üennamen zu √ºbertragen.  Um dieses Problem zu l√∂sen, haben wir den Datensatz <a href="">French Street Name Signs</a> (FSNS) erstellt und ver√∂ffentlicht, einen gro√üen Satz mit mehr als einer Million Stra√üennamen.  Der FSNS-Satz war das Ergebnis langj√§hriger Arbeit, die darauf abzielte, jedem die M√∂glichkeit zu geben, seine OCR-Modelle an einem komplexen und realen Datensatz zu verbessern.  FSNS ist viel gr√∂√üer und komplexer als SVHN, da f√ºr die genaue Erkennung von Stra√üennamen Informationen aus mehreren verschiedenen Bildern kombiniert werden m√ºssen. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/e32/da4/491/e32da44913785ab3bc28a38cb28980c5.png" alt="Bild"><br>  <i>Beispiele f√ºr schwer erkennbare Zeichen, die unser System mithilfe einer Kombination verschiedener Bilder erfolgreich erkannt hat.</i>  <i>Zuf√§lliges Rauschen wird verwendet, wenn f√ºr ein einzelnes Zeichen keine vier verschiedenen Fotos vorhanden sind.</i> <br><br>  Mit diesem Kit hat die Google-Praktikantin Vozhna Zbigniew ein Deep-Learning-Modell entwickelt, mit dem Street View-Bilder den ganzen Sommer 2016 automatisch markiert werden k√∂nnen.  Eine der interessanten und n√ºtzlichen Funktionen des neuen Modells ist die M√∂glichkeit, Text gem√§√ü unseren Standards f√ºr Titel zu normalisieren und √ºbersch√ºssigen Text aus Bildern zu ignorieren. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/270/9cf/167/2709cf1674a1fd4dd14ee43550211e85.png" alt="Bild"><br>  <i>Ein Beispiel f√ºr eine Textnormalisierung nach brasilianischen Daten.</i>  <i>"AV."</i>  <i>Verwandelt sich in "Avenida" und "Pres".</i>  <i>in "Presidente"</i> <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/a6b/23e/4c4/a6b23e4c4e388ef12efc7b3b5dafb57f.png" alt="Bild"><br>  <i>In diesem Beispiel wird das Modell nicht gel√∂scht, nachdem zwei Zeichen gleichzeitig getroffen wurden, verwandelt "Av" korrekt in "Avenue" und ignoriert die Nummer "1600" korrekt.</i> <br><br>  Das neue System in Kombination mit der Extraktion von Hausnummern erm√∂glicht es uns, neue Adressen direkt aus Fotos an Orten zu erstellen, an denen kein Stra√üenname oder keine Adresse bekannt war.  Jedes Mal, wenn ein Street View-Auto auf einer neuen Stra√üe f√§hrt, kann unser System Zehntausende von Bildern analysieren, die von der Maschine empfangen wurden, Stra√üennamen und Hausnummern extrahieren und neue Adressen korrekt zuordnen. <br><br>  Die automatische Erstellung von Adressen reicht jedoch nicht aus. Wir m√∂chten kommerziellen Organisationen dennoch einen Weg mit ihrem Namen bieten.  Im Jahr 2015 ver√∂ffentlichten wir die Arbeit ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gro√üfl√§chige Anerkennung kommerzieller Organisationen</a> anhand <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von Street View-Fotos</a> ‚Äú, in der eine Methode zur genauen Erkennung von Beschilderungen von kommerziellen Einrichtungen vorgeschlagen wurde.  Nachdem das Schaufenster der Organisation entdeckt wurde, muss der Name jedoch noch genau extrahiert werden. Das Modell muss herausfinden, wo der Name auf dem Foto angegeben ist und wo der Text nicht damit zusammenh√§ngt.  Wir nennen diese extrahierten Informationen "strukturierten Text".  Und das ist nicht nur Text, sondern Text kombiniert mit seiner semantischen Bedeutung. <br><br>  Mithilfe verschiedener Trainingsdaten k√∂nnen wir unser Modell, das den Stra√üennamen liest, dazu zwingen, die Namen von Gewerbebetrieben aus den Geb√§udefassaden zu extrahieren.  In diesem Fall k√∂nnten wir den Namen extrahieren und anhand von Informationen aus Google Maps pr√ºfen, ob uns diese Institution bekannt ist.  Auf diese Weise k√∂nnen wir genauere und aktuellere Listen kommerzieller Organisationen erstellen. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/d4d/38d/36b/d4d38d36b0f1ff478bebef355eda4766.png" alt="Bild"><br>  <i>Das System hat den Gesch√§ftsnamen trotz fehlender Informationen √ºber den Standort des Gesch√§fts korrekt als "Zelina Pneus" erkannt.</i>  <i>Sie ignorierte auch die Namen der Reifenmarken, die im Laden verkauft wurden.</i> <br><br>  Die Verwendung dieser gro√üen Modelle f√ºr 80 Milliarden Street View-Bilder erfordert erhebliche Rechenleistung.  Daher war das Ground Truth-Team das erste, das Zugang zur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tensor Processing Unit erhielt</a> , die in diesem Jahr angek√ºndigt wurde, um die Rechenkosten drastisch zu senken. <br><br>  Menschen verlassen sich auf die Genauigkeit von Google Maps und ihre F√§higkeit, Menschen zu helfen.  Wir halten Google Maps im Umgang mit sich st√§ndig √§ndernden Stadtlandschaften auf dem neuesten Stand.  Stra√üen und Gewerbebetriebe stellen uns vor technische Schwierigkeiten, die wir noch nicht zu 100% √ºberwinden konnten.  Die Mission von Ground Truth ist es, beim maschinellen Lernen an vorderster Front zu stehen und ein bequemeres Produkt f√ºr mehr als eine Milliarde Google Maps-Nutzer zu entwickeln. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de404031/">https://habr.com/ru/post/de404031/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de404019/index.html">Likbez √ºber Kryonika: in einfacher Sprache zu einem komplexen Thema</a></li>
<li><a href="../de404021/index.html">Der Doomsday-Bunker in Norwegen wurde aufgrund des Auftauens des Permafrosts mit Millionen von ‚Äûarchivierten‚Äú Samen √ºberflutet</a></li>
<li><a href="../de404023/index.html">"Gib mir zwei!" √úbersicht √ºber Apple iPhone 7 und Samsung Galaxy S7 Repliken</a></li>
<li><a href="../de404025/index.html">In Erwartung des Starts des elektrischen Elektrons</a></li>
<li><a href="../de404029/index.html">Patente f√ºr das MP3-Format sind abgelaufen, aber nur wenige haben es bemerkt</a></li>
<li><a href="../de404033/index.html">Rostelecom fordert, dem Verkehr der Telekommunikationsunternehmen, die in russischen Netzen daf√ºr bezahlt haben, Vorrang einzur√§umen</a></li>
<li><a href="../de404035/index.html">Solarbatterie auf dem Balkon: Testen des Ladereglers</a></li>
<li><a href="../de404037/index.html">Tesla-Fabrikarbeiter in den USA beschweren sich √ºber die Arbeitsbedingungen</a></li>
<li><a href="../de404039/index.html">William Coley - Pionier der Krebsimmuntherapie</a></li>
<li><a href="../de404045/index.html">Xiaomi Roller durch die Augen des Besitzers</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
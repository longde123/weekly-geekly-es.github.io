<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõ¥ üë©‚Äç‚öñÔ∏è üêä An√°lise lexical de express√£o regular profissional üë©üèº‚Äçü§ù‚Äçüë©üèª üåê üèúÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A an√°lise de texto sempre come√ßa com an√°lise lexical ou tokeniza√ß√£o. Existe uma maneira f√°cil de resolver esse problema para quase qualquer idioma usa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>An√°lise lexical de express√£o regular profissional</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/462781/"><p>  A an√°lise de texto sempre come√ßa com an√°lise lexical ou tokeniza√ß√£o.  Existe uma maneira f√°cil de resolver esse problema para quase qualquer idioma usando express√µes regulares.  Outro uso do bom e velho regexp. </p><a name="habracut"></a><br><p>  Costumo encontrar a tarefa de analisar textos.  Para tarefas simples, como analisar um valor inserido pelo usu√°rio, a funcionalidade b√°sica da express√£o regular √© suficiente.  Para tarefas complexas e pesadas, como escrever um compilador ou an√°lise de c√≥digo est√°tico, voc√™ pode usar ferramentas especializadas (AntLR, JavaCC, Yacc).  Mas muitas vezes encontro tarefas de n√≠vel intermedi√°rio, quando n√£o h√° express√µes regulares suficientes, mas n√£o sinto vontade de colocar ferramentas pesadas no projeto.  Al√©m disso, essas ferramentas geralmente funcionam no est√°gio de compila√ß√£o e no tempo de execu√ß√£o n√£o permitem alterar os par√¢metros de an√°lise (por exemplo, formar uma lista de palavras-chave a partir de uma tabela de arquivo ou banco de dados). </p><br><p> Como exemplo, darei uma tarefa que surgiu durante o processo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">acelera√ß√£o de consultas SQL</a> .  Analisamos os logs de nossas consultas SQL e quer√≠amos encontrar consultas "ruins" de acordo com certas regras.  Por exemplo, consultas nas quais o mesmo campo √© verificado para um conjunto de valores usando OR </p><br><pre><code class="sql hljs">name = 'John' OR name = 'Michael' OR name = 'Bob'</code> </pre> <br><p>  Quer√≠amos substituir esses pedidos por </p><br><pre> <code class="sql hljs">name IN ('John', 'Michael', 'Bob')</code> </pre> <br><p>  Express√µes regulares n√£o podem mais lidar, mas eu tamb√©m n√£o queria criar um analisador SQL completo usando o AntLR.  Seria poss√≠vel dividir o texto da solicita√ß√£o em tokens e usar c√≥digo simples para fazer a an√°lise sem nenhuma ferramenta especializada. </p><br><p>  Esse problema pode ser resolvido usando a funcionalidade b√°sica de express√µes regulares.  Vamos tentar dividir a consulta SQL em tokens.  Veremos uma vers√£o simplificada do SQL para n√£o sobrecarregar o texto com detalhes.  Para criar um lexer SQL completo, voc√™ precisar√° escrever express√µes regulares um pouco mais complexas. </p><br><p>  Aqui est√° um conjunto de express√µes para tokens b√°sicos da linguagem SQL: </p><br><pre> <code class="plaintext hljs">1. keyword : \b(?:select|from|where|group|by|order|or|and|not|exists|having|join|left|right|inner)\b 2. id : [A-Za-z][A-Za-z0-9]* 3. real_number : [0-9]+\.[0-9]* 4. number : [0-9]+ 5. string : '[^']*' 6. space : \s+ 7. comment : \-\-[^\n\r]* 8. operation : [+\-\*/.=\(\)]</code> </pre> <br><p>  Quero prestar aten√ß√£o √† express√£o regular da palavra-chave </p><br><pre> <code class="plaintext hljs">keyword : \b(?:select|from|where|group|by|order|or|and|not|exists|having|join|left|right|inner)\b</code> </pre> <br><p>  Possui dois recursos. </p><br><ol><li>  O operador \ b √© usado no in√≠cio e no final, por exemplo, para n√£o cortar o prefixo <strong>ou</strong> da <strong>organiza√ß√£o de</strong> palavras, que √© uma palavra-chave e que alguns mecanismos de regex separar√£o em um token separado sem usar o operador \ b. </li><li>  todas as palavras s√£o agrupadas por colchetes que n√£o capturam (? :) que n√£o capturam a correspond√™ncia.  Isso ser√° usado no futuro para n√£o violar a indexa√ß√£o de express√µes regulares parciais na express√£o geral. </li></ol><br><p>  Agora voc√™ pode combinar todas essas express√µes em um √∫nico todo, usando o agrupamento e o operador <strong>|</strong> </p><br><pre> <code class="plaintext hljs">(\b(?:select|from|where|group|by|order|or|and|not|exists|having|join|left|right|inner)\b)|([A-Za-z][A-Za-z0-9]*)|([0-9]+\.[0-9]*)|([0-9]+)|('[^']*')|(\s+)|(\-\-[^\n\r]*)|([+\-\*/.=\(\)])</code> </pre> <br><p>  Agora voc√™ pode tentar aplicar essa express√£o a uma express√£o SQL, por exemplo, para </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">id</span></span>) <span class="hljs-comment"><span class="hljs-comment">-- count of 'Johns' FROM person WHERE name = 'John'</span></span></code> </pre> <br><p>  Aqui est√° o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">resultado</a> no Regex Tester.  Ao clicar no link, voc√™ pode brincar com a express√£o e o resultado da an√°lise.  Pode-se observar que, por exemplo, <strong>SELECT</strong> corresponde imediatamente a um grupo 1, que corresponde ao tipo de <strong>palavra</strong> - <strong>chave</strong> . </p><br><p><img src="https://habrastorage.org/webt/2_/aq/mp/2_aqmpj7fpnwgnmgwlf-rtp9rr4.png" alt="imagem"></p><br><p>  Voc√™ pode perceber que o texto inteiro da solicita√ß√£o acabou sendo dividido em substrings e cada um corresponde a um determinado grupo.  Pelo n√∫mero do grupo, voc√™ pode correlacion√°-lo com o tipo de token (token). </p><br><p>  Transformar o algoritmo em um programa em qualquer linguagem de programa√ß√£o que suporte express√µes regulares n√£o √© dif√≠cil.  Aqui est√° uma pequena classe que implementa isso em Java. </p><br><div class="spoiler">  <b class="spoiler_title">RegexTokenizer.java (+ mais algumas aulas)</b> <div class="spoiler_text"><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> org.example; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.ArrayList; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.Enumeration; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.List; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.regex.Matcher; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.regex.Pattern; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.util.stream.Collectors; <span class="hljs-comment"><span class="hljs-comment">/** *    . *   ,         . */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RegexTokenizer</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">implements</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Enumeration</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Token</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// ,      private final String content; //         private final ITokenType[] tokenTypes; private final Matcher matcher; //    private int currentPosition = 0; /** * @param content    * @param tokenTypes         */ public RegexTokenizer(String content, ITokenType[] tokenTypes) { this.content = content; this.tokenTypes = tokenTypes; //       List&lt;String&gt; regexList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; tokenTypes.length; i++) { ITokenType tokenType = tokenTypes[i]; regexList.add("(?&lt;g" + i + "&gt;" + tokenType.getRegex() + ")"); } String regex = regexList.stream().collect(Collectors.joining("|")); Pattern pattern = Pattern.compile(regex, Pattern.CASE_INSENSITIVE); //    matcher = pattern.matcher(content); matcher.find(); } @Override public boolean hasMoreElements() { return currentPosition &lt; content.length(); } @Override public Token nextElement() { boolean found = currentPosition &gt; matcher.start() ? matcher.find() : true; int start = found ? matcher.start() : content.length(); int end = found ? matcher.end() : content.length(); if(found &amp;&amp; currentPosition == start) { currentPosition = end; //  -   for (int i = 0; i &lt; tokenTypes.length; i++) { String si = "g" + i; if (matcher.start(si) == start &amp;&amp; matcher.end(si) == end) { return createToken(content, tokenTypes[i], start, end); } } } throw new IllegalStateException("      " + currentPosition); } /** *  -  ,    ,     , *            (, ) * @param content     * @param tokenType   * @param start      * @param end      * @return  - */ protected Token createToken(String content, ITokenType tokenType, int start, int end) { return new Token(content.substring(start, end), tokenType, start); } /** *     SQL */ public enum SQLTokenType implements ITokenType { KEYWORD("\\b(?:select|from|where|group|by|order|or|and|not|exists|having|join|left|right|inner)\\b"), ID("[A-Za-z][A-Za-z0-9]*"), REAL_NUMBER("[0-9]+\\.[0-9]*"), NUMBER("[0-9]+"), STRING("'[^']*'"), SPACE("\\s+"), COMMENT("\\-\\-[^\\n\\r]*"), OPERATION("[+\\-\\*/.=\\(\\)]"); private final String regex; SQLTokenType(String regex) { this.regex = regex; } @Override public String getRegex() { return regex; } } public static void main(String[] args) { String s = "select count(id) -- count of 'Johns' \n" + "FROM person\n" + "where name = 'John'"; RegexTokenizer tokenizer = new RegexTokenizer(s, SQLTokenType.values()); while(tokenizer.hasMoreElements()) { Token token = tokenizer.nextElement(); System.out.println(token.getText() + " : " + token.getType()); } } } /** * -  () */ public class Token { //   private final String text; //   private final ITokenType type; //      private final int start; public Token(String text, ITokenType type, int start) { this.text = text; this.type = type; this.start = start; } public String getText() { return text; } public ITokenType getType() { return type; } public int getStart() { return start; } } /** *     */ public interface ITokenType { /** *       */ String getRegex(); }</span></span></code> </pre></div></div><br><p>  Nesta classe, o algoritmo √© implementado usando grupos nomeados, que n√£o est√£o presentes em todos os mecanismos.  Esse recurso permite acessar grupos n√£o por √≠ndice, mas por nome, o que √© um pouco mais conveniente do que acessar por √≠ndice. </p><br><p>  No meu I7 de 2,3 GHz, essa classe demonstra uma velocidade de an√°lise de 5 a 20 MB por segundo (dependendo da complexidade das express√µes).  O algoritmo pode ser paralelo analisando v√°rios arquivos de uma s√≥ vez, aumentando a velocidade geral do trabalho. </p><br><p>  Encontrei v√°rios algoritmos semelhantes na rede, mas encontrei op√ß√µes que n√£o formam uma express√£o regular comum, mas aplicam express√µes regulares de forma consistente para cada tipo de token no in√≠cio da linha, depois descarte o token encontrado no in√≠cio da linha e tente aplicar todos os regexps.  Isso funciona de 10 a 20 vezes mais lento, requer mais mem√≥ria e o algoritmo √© mais complicado.  Consegui uma velocidade maior de trabalho apenas usando minha implementa√ß√£o de express√£o regular baseada no DFA (m√°quina <strong>determin√≠stica de</strong> estados finitos).  Nos motores regex, o NKA √© geralmente usado - uma <strong>m√°quina de</strong> estados finitos <strong>n√£o determin√≠sticos</strong> ).  O DFA √© 2-3 vezes mais r√°pido, mas as express√µes regulares s√£o mais dif√≠ceis de escrever devido a um conjunto limitado de operadores. </p><br><p>  No meu exemplo para SQL, simplifiquei um pouco as express√µes regulares e o tokenizer resultante n√£o pode ser considerado um analisador lexical completo de consultas SQL, mas o objetivo do artigo √© mostrar o princ√≠pio e n√£o criar um tokenizer SQL real.  Eu usei essa abordagem em minha pr√°tica e criei analisadores lexicais completos para SQL, Java, C, XML, HTML, JSON, Pascal e at√© COBOL (tive que mexer com ela). </p><br><p>  Aqui est√£o algumas regras simples para escrever express√µes regulares para an√°lise lexical. </p><br><ol><li>  Se o mesmo token puder ser atribu√≠do a tipos diferentes (por exemplo, qualquer palavra-chave pode ser reconhecida como um identificador), um tipo mais restrito dever√° ser definido no in√≠cio.  Em seguida, a express√£o regular ser√° aplicada primeiro e determinar√° o tipo de token.  Por exemplo, no meu exemplo, as <strong>palavras</strong> - <strong>chave s√£o</strong> definidas antes do <strong>id</strong> e o token de <em>sele√ß√£o</em> ser√° reconhecido como <strong>palavra-chave</strong> , n√£o <strong>id</strong> </li><li>  Defina primeiro os tokens mais longos, depois os mais curtos.  Por exemplo, primeiro voc√™ precisa definir <em>&lt;=</em> , <em>&gt; =</em> e depois separar <em>&gt;</em> , <em>&lt;</em> , <em>=</em> Nesse caso, o texto <em>&lt;=</em> ser√° corretamente reconhecido como um √∫nico token do operador menor ou igual e n√£o dois tokens separados <em>&lt;</em> e <em>=</em> </li><li>  Aprenda a usar <strong>lookahead</strong> e <strong>lookbehind</strong> .  Por exemplo, o caractere * no SQL tem o significado de um operador de multiplica√ß√£o e uma indica√ß√£o de todos os campos em uma tabela.  Usando uma simples <strong>observa√ß√£o, voc√™ pode</strong> separar esses dois casos, por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> regexp <strong>(? &lt;=. \ S <em>| select \ s</em> ) *</strong> localiza o caractere * apenas no valor "todos os campos da tabela". </li><li>  √Äs vezes, √© √∫til definir express√µes regulares para erros que ocorrem no texto.  Por exemplo, se voc√™ real√ßar a sintaxe, pode definir o tipo do token de sequ√™ncia inacabada como <code>'[^\n\r]*</code> .  No processo de edi√ß√£o do texto, o usu√°rio pode n√£o ter tempo para fechar as aspas na sequ√™ncia, mas o seu tokenizador poder√° reconhecer corretamente essa situa√ß√£o e destac√°-la corretamente. </li></ol><br><p>  Usando essas regras e aplicando esse algoritmo, voc√™ pode dividir rapidamente o texto em tokens para praticamente qualquer idioma. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt462781/">https://habr.com/ru/post/pt462781/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt462769/index.html">Aplica√ß√£o de aprendizado de m√°quina e ci√™ncia de dados na ind√∫stria</a></li>
<li><a href="../pt462771/index.html">Eles n√£o tinham nada a esconder</a></li>
<li><a href="../pt462773/index.html">Como trabalhar com o Google Trends: um guia completo para iniciantes</a></li>
<li><a href="../pt462775/index.html">Automa√ß√£o Homebridge com Node-Red</a></li>
<li><a href="../pt462777/index.html">Como avaliar o desempenho do servidor Linux: ferramentas abertas de benchmarking</a></li>
<li><a href="../pt462783/index.html">Matrix: 20 anos depois</a></li>
<li><a href="../pt462787/index.html">Como domar um j√∫nior?</a></li>
<li><a href="../pt462789/index.html">Para a Alemanha por um desenvolvedor sem ensino m√©dio</a></li>
<li><a href="../pt462793/index.html">Esteira com um elefante e um cavalo. O m√©todo c√≠clico "Prisioneiro do C√°ucaso"</a></li>
<li><a href="../pt462795/index.html">Esquema declarativo e o que h√° de errado com ele no Magento 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë∂üèª üë©üèø‚Äçüè´ ü§Ø Kaggle: no puede caminar - corramos üëàüèø üêë üîö</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬øCu√°n complejo es el tema del aprendizaje autom√°tico? Si eres bueno en matem√°ticas, pero la cantidad de conocimiento sobre el aprendizaje autom√°tico t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kaggle: no puede caminar - corramos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/singularis/blog/440026/">  ¬øCu√°n complejo es el tema del aprendizaje autom√°tico?  Si eres bueno en matem√°ticas, pero la cantidad de conocimiento sobre el aprendizaje autom√°tico tiende a cero, ¬øhasta d√≥nde puedes llegar en una competencia seria en la plataforma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kaggle</a> ? <br><br><img src="https://habrastorage.org/webt/3y/zi/_f/3yzi_f6ybvxg_uq9392v4rqoml0.png"><br><a name="habracut"></a><br><h2>  Sobre el sitio y la competencia </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kaggle</a> es una comunidad de personas interesadas en ML (desde principiantes hasta profesionales geniales) y un lugar para concursos (a menudo con un impresionante premio acumulado). <br><br>  Para sumergirme de inmediato en todos los encantos de ML, decid√≠ elegir inmediatamente una competencia seria.  Tal solo estaba disponible: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Two Sigma: Uso de noticias para predecir movimientos de acciones</a> .  La esencia del concurso en pocas palabras es predecir el precio de las acciones de varias compa√±√≠as en funci√≥n del estado del activo y las noticias relacionadas con este activo.  El fondo de premios del concurso es de $ 100,000, que se distribuir√° entre los participantes que ganaron los primeros 7 lugares. <br><br>  La competencia es especial por dos razones: <br><br><ul><li>  este es un concurso exclusivo de Kernels: solo puedes entrenar modelos en la nube de Kaggle Kernels; <br></li><li>  la distribuci√≥n final de los asientos se conocer√° solo seis meses despu√©s de la finalizaci√≥n de la toma de decisiones;  durante este tiempo, las decisiones predecir√°n los precios en la fecha actual. <br></li></ul><br><h2>  Sobre la tarea </h2><br>  Por condici√≥n, debemos predecir la confianza <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>e</mi><mi>n</mi><mo stretchy=&quot;false&quot;>[</mo><mo>&amp;#x2212;</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="16.041ex" height="2.66ex" viewBox="0 -832 6906.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="1356" y="0"></use><g transform="translate(1717,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="361" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-65" x="3057" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-6E" x="3524" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-5B" x="4124" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-2212" x="4403" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-31" x="5181" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-2C" x="5682" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-31" x="6127" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-5D" x="6628" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">h</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><msub><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y</font></font></mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></mrow></msub><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></mi><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[</font></font></mo><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-</font></font></mo><mn><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></mn><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">,</font></font></mo><mn><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></mn><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">]</font></font></mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> \ hat {y} _ {ti} \ en [-1,1] </script>  en eso aumentar√° el rendimiento del activo.  El rendimiento de un activo se considera en relaci√≥n con el rendimiento del mercado en su conjunto.  La m√©trica objetivo es personalizada: no es el <abbr title="Error cuadr√°tico medio">RMSE</abbr> o el <abbr title="Error absoluto medio">MAE</abbr> m√°s familiares, sino <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la relaci√≥n de Sharpe</a> , que en este caso se considera de la siguiente manera: <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></mrow><mo>,</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="35.757ex" height="2.66ex" viewBox="0 -832 15395.3 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-65" x="611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="1078" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="1650" y="0"></use><g transform="translate(2012,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-73" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-63" x="469" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-6F" x="903" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-72" x="1388" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-65" x="1840" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-3D" x="4596" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-66" x="5902" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-72" x="6453" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="6904" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-63" x="7434" y="0"></use><g transform="translate(7867,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use></g></g><g transform="translate(10456,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-29" x="4271" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-2C" x="15116" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">c</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e</font></font></mi></mrow><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">=</font></font></mo><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">f</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">c</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">b</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r</font></font></mi><msub><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi></mrow><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub></mrow><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">g</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(</font></font></mo><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">)</font></font></mo></mrow><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">,</font></font></mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> \ text {score} = \ frac {\ bar {x} _t} {\ sigma (x_t)}, </script></p>  donde <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.782ex" height="2.539ex" viewBox="0 -780.1 9808.8 1093.4" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-3D" x="1205" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-73" x="2512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-75" x="2981" y="0"></use><g transform="translate(3554,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="1242" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-68" x="5026" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="5603" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="6132" y="0"></use><g transform="translate(6494,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(7584,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(8636,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="361" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">=</font></font></mo><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tu</font></font></mi><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></msub><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">h</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><msub><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y</font></font></mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></mrow></msub><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></mrow></msub><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tu</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> x_t = \ sum_i \ hat {y} _ {ti} r_ {ti} u_ {ti} </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.442ex" height="1.817ex" viewBox="0 -520.7 1051.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-4"> r_ {ti} </script>  - el rendimiento del activo i en relaci√≥n con el mercado para el d√≠a t en un horizonte de 10 d√≠as, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="1.817ex" viewBox="0 -520.7 1172.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tu</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-5"> u_ {ti} </script>  - una variable booleana que indica si el i-√©simo activo est√° incluido en la valoraci√≥n para el d√≠a t, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.012ex" height="2.419ex" viewBox="0 -780.1 2588.6 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">b</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r</font></font></mi><msub><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi></mrow><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-6"> \ bar {x} _t </script>  - valor medio <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-7"> x_t </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.825ex" height="2.66ex" viewBox="0 -832 4660.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-29" x="4271" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">g</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(</font></font></mo><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">)</font></font></mo></math></span></span><script type="math/tex" id="MathJax-Element-8"> \ sigma (x_t) </script>  - desviaci√≥n est√°ndar <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-9"> x_t </script>  . <br><br>  La relaci√≥n de Sharpe es el rendimiento ajustado al riesgo, los valores del coeficiente muestran la efectividad del operador: <br><br><ul><li>  menos de 1: bajo rendimiento <br></li><li>  1 - 2: media, eficiencia normal, <br></li><li>  2-3: excelente rendimiento, <br></li><li>  m√°s de 3: perfecto. <br></li></ul><br><div class="spoiler">  <b class="spoiler_title">Datos de movimiento del mercado</b> <div class="spoiler_text"><ul><li>  <b>hora</b> (datetime64 [ns, UTC]) - hora actual (en los datos sobre el movimiento del mercado en todas las l√≠neas a las 22:00 UTC) <br></li><li>  <b>assetCode</b> (objeto) - identificador de activo <br></li><li>  <b>assetName</b> (categor√≠a): un identificador de un grupo de activos para la comunicaci√≥n con datos de noticias <br></li><li>  <b>universo</b> (float64): un valor booleano que indica si este activo se tendr√° en cuenta en el c√°lculo de la puntuaci√≥n <br></li><li>  <b>volumen</b> (float64) - volumen diario de negociaci√≥n <br></li><li>  <b>close</b> (float64) - precio de cierre para este d√≠a <br></li><li>  <b>abierto</b> (float64) - precio abierto para este d√≠a <br></li><li>  <b>returnClosePrevRaw1</b> (float64): rendimiento desde el cierre hasta el cierre del d√≠a anterior <br></li><li>  <b>returnOpenPrevRaw1</b> (float64): rentabilidad desde la apertura hasta la apertura del d√≠a anterior <br></li><li>  <b>returnClosePrevMktres1</b> (float64): rendimiento de cierre a cierre del d√≠a anterior, ajustado en relaci√≥n con el movimiento del mercado en su conjunto <br></li><li>  <b>returnOpenPrevMktres1</b> (float64): rentabilidad desde la apertura hasta la apertura del d√≠a anterior, ajustada en relaci√≥n con el movimiento del mercado en su conjunto <br></li><li>  <b>returnClosePrevRaw10</b> (float64) - rendimiento de cerca a cerrar durante los 10 d√≠as anteriores <br></li><li>  <b>returnOpenPrevRaw10</b> (float64): rentabilidad desde la apertura hasta la apertura durante los 10 d√≠as anteriores <br></li><li>  <b>returnClosePrevMktres10</b> (float64): rendimiento de cierre a cierre durante los 10 d√≠as anteriores, ajustado en relaci√≥n con el movimiento del mercado en su conjunto <br></li><li>  <b>returnOpenPrevMktres10</b> (float64): rendimiento de apertura a apertura durante los 10 d√≠as anteriores, ajustado en relaci√≥n con el movimiento del mercado en su conjunto <br></li><li>  <b>returnOpenNextMktres10</b> (float64): rendimiento de abierto a abierto durante los pr√≥ximos 10 d√≠as, ajustado por el movimiento del mercado en su conjunto.  Vamos a predecir este valor. <br></li></ul><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Datos de noticias</b> <div class="spoiler_text"><ul><li>  <b>time</b> (datetime64 [ns, UTC]) - hora en disponibilidad de datos UTC <br></li><li>  <b>sourceTimestamp</b> (datetime64 [ns, UTC]) - hora en las noticias de publicaci√≥n UTC <br></li><li>  <b>firstCreated</b> (datetime64 [ns, UTC]) - hora en UTC de la primera versi√≥n de los datos <br></li><li>  <b>sourceId</b> (objeto) - identificador de registro <br></li><li>  <b>t√≠tulo</b> (objeto) - t√≠tulo <br></li><li>  <b>urgencia</b> (int8) - tipos de noticias (1: alerta, 3: art√≠culo) <br></li><li>  <b>takeSequence</b> (int16) - par√°metro no muy claro, n√∫mero en alguna secuencia <br></li><li>  <b>proveedor</b> (categor√≠a): identificador del proveedor de noticias <br></li><li>  <b>temas</b> (categor√≠a): una lista de c√≥digos de temas de noticias (puede ser un signo geogr√°fico, evento, sector industrial, etc.) <br></li><li>  <b>audiencias</b> (categor√≠a) - lista de noticias de c√≥digos de audiencia <br></li><li>  <b>bodySize</b> (int32): n√∫mero de caracteres en el cuerpo de noticias <br></li><li>  companyCount (int8): n√∫mero de empresas mencionadas expl√≠citamente en las noticias <br></li><li>  <b>headlineTag</b> (objeto): cierta etiqueta de t√≠tulo de Thomson Reuters <br></li><li>  <b>marketCommentary</b> (bool): una se√±al de que las noticias se relacionan con las condiciones generales del mercado <br></li><li>  <b>sentenceCount</b> (int16) - n√∫mero de ofertas en las noticias <br></li><li>  <b>wordCount</b> (int32): n√∫mero de palabras y signos de puntuaci√≥n en las noticias <br></li><li>  <b>assetCodes</b> (categor√≠a): lista de activos mencionados en las noticias <br></li><li>  <b>assetName</b> (categor√≠a) - c√≥digo de grupo de activos <br></li><li>  <b>firstMentionSentence</b> (int16): una oraci√≥n que primero menciona un activo: <br></li><li>  <b>relevancia</b> (float32): un n√∫mero del 0 al 1, que muestra la relevancia de las noticias sobre el activo <br></li><li>  <b>sentimentClass</b> (int8) - clase de tonalidad de noticias <br></li><li>  <b>sentimentNegative</b> (float32) - probabilidad de que la tonalidad sea negativa <br></li><li>  <b>sentimentNeutral</b> (float32) - probabilidad de que el tono sea neutral <br></li><li>  <b>sentimentPositive</b> (float32) - probabilidad de que la clave sea positiva <br></li><li>  <b>sentimentWordCount</b> (int32): la cantidad de palabras en el texto que est√°n relacionadas con el activo <br></li><li>  <b>noveltyCount12H</b> (int16) - noticias de "novedad" en 12 horas, calculadas en relaci√≥n con las noticias anteriores sobre este activo <br></li><li>  <b>novetyCount24H</b> (int16) - mismo, en 24 horas <br></li><li>  <b>noveltyCount3D</b> (int16) - igual, en 3 d√≠as <br></li><li>  <b>novetyCount5D</b> (int16) - igual, en 5 d√≠as <br></li><li>  <b>novetyCount7D</b> (int16) - mismo, en 7 d√≠as <br></li><li>  <b>volumeCounts12H</b> (int16): la cantidad de noticias sobre este activo en 12 horas <br></li><li>  <b>volumeCounts24H</b> (int16) - igual, en 24 horas <br></li><li>  <b>volumeCounts3D</b> (int16) - igual, en 3 d√≠as <br></li><li>  <b>volumeCounts5D</b> (int16): igual, durante 5 d√≠as <br></li><li>  <b>volumeCounts7D</b> (int16) - igual, en 7 d√≠as <br></li></ul><br></div></div><br>  La tarea es esencialmente una tarea de clasificaci√≥n binaria, es decir, predecimos un signo binario, ya sea que el rendimiento aumente (1 clase) o disminuya (clase 0). <br><br><h2>  Sobre herramientas </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kaggle Kernels</a> es una plataforma de computaci√≥n en la nube que admite la colaboraci√≥n.  Se admiten los siguientes tipos de n√∫cleos: <br><ul><li>  Script de Python <br></li><li>  R script <br></li><li>  Cuaderno Jupyter <br></li><li>  RMarkdown <br></li></ul><br>  Cada n√∫cleo se ejecuta en su contenedor acoplable.  Se instala una gran cantidad de paquetes en el contenedor, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> se puede encontrar una lista de Python.  Las especificaciones t√©cnicas son las siguientes: <br><br><ul><li>  CPU: 4 n√∫cleos, </li><li>  RAM: 17 GB, </li><li>  unidad: 5 GB permanentes y 16 GB temporales, </li><li>  tiempo m√°ximo de ejecuci√≥n del script: 9 horas (en el momento del inicio de la competencia eran 6 horas). </li></ul><br>  Las GPU tambi√©n est√°n disponibles en Kernels, sin embargo, la GPU estaba prohibida en este concurso. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Keras</a> es un marco de red neuronal de alto nivel que se ejecuta sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TensorFlow</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CNTK</a> o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Theano</a> .  Es una API muy conveniente y comprensible, y es posible agregar sus topolog√≠as de red, funciones de p√©rdida y m√°s utilizando la API de back-end. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Scikit-learn</a> es una gran biblioteca de algoritmos de aprendizaje autom√°tico.  Una fuente √∫til de preprocesamiento de datos y algoritmos de an√°lisis de datos para su uso con marcos m√°s especializados. <br><br><h2>  Validaci√≥n del modelo </h2><br>  Antes de enviar un modelo para evaluaci√≥n, debe verificar de alguna manera localmente qu√© tan bien funciona, es decir, encontrar una forma de validaci√≥n local.  Intent√© los siguientes enfoques: <br><br><ol><li>  validaci√≥n cruzada <i>versus</i> divisi√≥n proporcional simple en conjuntos de entrenamiento / prueba; </li><li>  C√°lculo local de la relaci√≥n de Sharpe <i>vs</i> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><abbr title="Caracter√≠sticas de funcionamiento del receptor">ROC</abbr> <abbr title="√Årea bajo curva">AUC</abbr></a> . </li></ol><br>  Como resultado, los resultados m√°s cercanos a la evaluaci√≥n competitiva, por extra√±o que parezca, mostraron una combinaci√≥n de la partici√≥n proporcional (seleccionada emp√≠ricamente la partici√≥n 0.85 / 0.15) y AUC.  La validaci√≥n cruzada probablemente no sea muy adecuada, ya que el comportamiento del mercado es muy diferente en las primeras etapas de los datos de capacitaci√≥n y en el per√≠odo de evaluaci√≥n.  ¬øPor qu√© las AUC funcionaron mejor que la relaci√≥n de Sharpe? No puedo decir nada. <br><br><h2>  Primeros intentos </h2><br>  Dado que la tarea es predecir la serie temporal, se prob√≥ la primera soluci√≥n cl√°sica: una red neuronal recurrente ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">RNN</a> ), o m√°s bien, sus variantes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><abbr title="Memoria a corto y largo plazo">LSTM</abbr></a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><abbr title="Unidad recurrente cerrada">GRU</abbr></a> . <br><br>  El principio principal de las redes recurrentes es que para cada valor de salida, no se ingresa una muestra, sino una secuencia completa.  De esto se desprende que: <br><br><ul><li>  necesitamos un preprocesamiento de los datos iniciales: la generaci√≥n de estas mismas secuencias de duraci√≥n t d√≠as para cada activo; <br></li><li>  un modelo basado en una red recurrente no puede predecir el valor de salida si no hay datos para los t d√≠as anteriores. <br></li></ul><br>  Gener√© secuencias para cada d√≠a, comenzando con t, por lo que para t bastante grande (de 20) el conjunto completo de muestras de entrenamiento dej√≥ de caber en la memoria.  El problema se resolvi√≥ usando generadores, ya que Keras puede usar generadores como conjuntos de datos de entrada y salida para entrenamiento y predicci√≥n. <br><br>  La preparaci√≥n inicial de los datos fue lo m√°s ingenua posible: tomamos todos los datos del mercado y agregamos un par de caracter√≠sticas (d√≠a de la semana, mes, n√∫mero de semana del a√±o), y no tocamos los datos de las noticias en absoluto. <br><br>  El primer modelo us√≥ t = 10 y se ve√≠a as√≠: <br><br><pre><code class="python hljs">model = Sequential() model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.tanh, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, input_shape=(data.timesteps, data.features))) model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(data.assets, activation=act.relu)) model.add(Dense(data.assets))</code> </pre> <br>  No se sac√≥ nada adecuado de este modelo, el puntaje fue cercano a cero (incluso un poco menos). <br><br><h2>  Redes Convolucionales Temporales </h2><br>  Una soluci√≥n de red neuronal m√°s moderna para la predicci√≥n de series temporales es TCN.  La esencia de esta topolog√≠a es muy simple: tomamos una red convolucional unidimensional y la aplicamos a nuestra secuencia de longitud t.  Las opciones m√°s avanzadas utilizan varias capas convolucionales con dilataci√≥n diferente.  La implementaci√≥n de TCN se copi√≥ parcialmente (a veces a nivel de idea) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">desde aqu√≠</a> (visualizaci√≥n de la pila de TCN tomada del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo de Wavenet</a> ). <br><br><img src="https://habrastorage.org/webt/rf/sb/-4/rfsb-4f0bydwgmhhkwvbrenuxu0.png"><br><br>  La primera soluci√≥n relativamente exitosa fue este modelo, que incluye una capa GRU sobre TCN: <br><br><pre> <code class="python hljs">model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">256</span></span>)) model.add(Dense(data.assets, activation=act.relu))</code> </pre><br>  Tal modelo produce una puntuaci√≥n = 0.27668.  Con un poco de ajuste (n√∫mero de filtros TCN, tama√±o de lote) y un aumento de t a 100, ya obtenemos 0.41092: <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">16</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br>  A continuaci√≥n, agregamos normalizaci√≥n y abandono: <br><br><div class="spoiler">  <b class="spoiler_title">C√≥digo</b> <div class="spoiler_text"><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> dropout_rate = <span class="hljs-number"><span class="hljs-number">0.05</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">channel_normalization</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> max_values = K.max(K.abs(x), <span class="hljs-number"><span class="hljs-number">2</span></span>, keepdims=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) + <span class="hljs-number"><span class="hljs-number">1e-5</span></span> out = x / max_values <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out model = Sequential() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(data.timesteps &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>**i)) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) model.add(Flatten()) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: model.add(Flatten(input_shape=(data.timesteps, data.features))) model.add(Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br></div></div><br>  Aplicando este modelo, incluso en los primeros pasos (con t = 1), obtenemos una puntuaci√≥n = 0.53578. <br><br><h2>  M√°quinas de refuerzo de gradiente </h2><br>  En esta etapa, las ideas terminaron y decid√≠ hacer lo que deb√≠a hacerse desde el principio: ver las decisiones p√∫blicas de otros participantes.  La mayor√≠a de las buenas soluciones no usaban redes neuronales en absoluto, prefiriendo GBM. <br><br>  Gradient Boosting es un m√©todo de ML, en el que obtenemos un conjunto de modelos simples (con mayor frecuencia √°rboles de decisi√≥n).  Debido a la gran cantidad de modelos tan simples, la funci√≥n de p√©rdida est√° optimizada.  Puede leer m√°s sobre Gradient Boosting, por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><br>  Como la implementaci√≥n de GBM utiliz√≥ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">lightgbm</a> , un marco bastante conocido de Microsoft. <br><br>  El modelo y el preprocesamiento de datos tomados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de aqu√≠</a> dan inmediatamente una puntuaci√≥n de aproximadamente 0,64: <br><br><div class="spoiler">  <b class="spoiler_title">C√≥digo</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">prepare_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(marketdf, newsdf)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># a bit of feature engineering marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int) marketdf['bartrend'] = marketdf['close'] / marketdf['open'] marketdf['average'] = (marketdf['close'] + marketdf['open'])/2 marketdf['pricevolume'] = marketdf['volume'] * marketdf['close'] newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int) newsdf['assetCode'] = newsdf['assetCodes'].map(lambda x: list(eval(x))[0]) newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount'] newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount'] # filter pre-2012 data, no particular reason marketdf = marketdf.loc[marketdf['time'] &gt; 20120000] # get rid of extra junk from news data droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence', 'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass', 'assetName', 'assetCodes','urgency','wordCount','sentimentWordCount'] newsdf.drop(droplist, axis=1, inplace=True) marketdf.drop(['assetName', 'volume'], axis=1, inplace=True) # combine multiple news reports for same assets on same day newsgp = newsdf.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index() # join news reports to market data, note many assets will have many days without news data return pd.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) import lightgbm as lgb print ('Training lightgbm') # money params = { "objective" : "binary", "metric" : "binary_logloss", "num_leaves" : 60, "max_depth": -1, "learning_rate" : 0.01, "bagging_fraction" : 0.9, # subsample "feature_fraction" : 0.9, # colsample_bytree "bagging_freq" : 5, # subsample_freq "bagging_seed" : 2018, "verbosity" : -1 } lgtrain, lgval = lgb.Dataset(Xt, Yt[:,0]), lgb.Dataset(Xv, Yv[:,0]) lgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)</span></span></code> </pre><br></div></div><br>  El preprocesamiento aqu√≠ ya incluye datos de noticias, combin√°ndolos con datos de mercado (sin embargo, al hacerlo de manera bastante ingenua, solo se tiene en cuenta un c√≥digo de activo de todos los que se mencionan en las noticias).  Tom√© esta opci√≥n de preprocesamiento como base para todas las decisiones posteriores. <br><br>  Al agregar una peque√±a caracter√≠stica (firstMentionSentence, marketCommentary, sentimentClass) y tambi√©n reemplazar la m√©trica con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ROC AUC</a> , obtenemos un puntaje de 0.65389. <br><br><h2>  Conjunto </h2><br>  La siguiente decisi√≥n exitosa fue utilizar un conjunto compuesto por un modelo de red neuronal y GBM (aunque "conjunto" es un gran nombre para dos modelos).  La predicci√≥n resultante se obtiene promediando las predicciones de los dos modelos, aplicando as√≠ el mecanismo de votaci√≥n suave.  Esta decisi√≥n permiti√≥ obtener un puntaje de 0,66879. <br><br><h2>  An√°lisis exploratorio de datos e ingenier√≠a de caracter√≠sticas </h2><br>  Otra cosa para comenzar fue EDA.  Despu√©s de leer que es importante comprender la correlaci√≥n entre las caracter√≠sticas, creamos una imagen de este tipo (se puede hacer clic en las im√°genes de esta secci√≥n): <br><br> <a href=""><img src="https://habrastorage.org/webt/hw/xl/b2/hwxlb2agjx113qtsyciwbeuulvk.png"></a> <br><br>  Aqu√≠ se ve claramente que la correlaci√≥n por separado dentro del mercado y los datos de noticias es bastante alta, sin embargo, solo los valores de los rendimientos se correlacionan con el valor objetivo al menos de alguna manera.  Dado que los datos representan una serie de tiempo, tiene sentido considerar tambi√©n la autocorrelaci√≥n del valor objetivo: <br><br> <a href=""><img src="https://habrastorage.org/webt/gg/t_/ft/ggt_ftesggo-ro3hnbohztculz0.png"></a> <br><br>  Se puede ver que despu√©s de un per√≠odo de 10 d√≠as, la dependencia disminuye significativamente.  Esto es probablemente lo que hace que GBM funcione bien, teniendo en cuenta solo las caracter√≠sticas con un retraso de 10 d√≠as (que ya est√°n en el conjunto de datos original). <br><br>  La selecci√≥n de caracter√≠sticas y el preprocesamiento son cruciales para todos los algoritmos de ML.  Intentemos utilizar formas autom√°ticas para extraer caracter√≠sticas, a saber, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el</a> <abbr title="An√°lisis de componentes principales">an√°lisis de</abbr> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">componentes principales</a> ( <abbr title="An√°lisis de componentes principales">PCA</abbr> ): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.decomposition <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PCA <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler market_x = market_data.loc[:,features] scaler = StandardScaler() scaler.fit(market_x) market_x = scaler.transform(market_x) pca = PCA(<span class="hljs-number"><span class="hljs-number">.95</span></span>) pca.fit(market_x) market_pca = pca.transform(market_x)</code> </pre><br>  Veamos qu√© caracter√≠sticas genera la PCA: <br><br> <a href=""><img src="https://habrastorage.org/webt/oh/1e/a1/oh1ea1byez3dcgjpklh-6gbzvic.png"></a> <br><br>  Vemos que el m√©todo no funciona muy bien en nuestros datos, ya que la correlaci√≥n final de las nuevas caracter√≠sticas con el valor objetivo es peque√±a. <br><br><h2>  Ajuste fino y si es necesario </h2><br>  Muchos modelos de ML tienen una cantidad bastante grande de hiperpar√°metros, es decir, "configuraciones" del algoritmo mismo.  Se pueden seleccionar manualmente, pero tambi√©n hay mecanismos de selecci√≥n autom√°tica.  Para este √∫ltimo, hay una biblioteca de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hiperoptos</a> que implementa dos algoritmos de coincidencia: b√∫squeda aleatoria y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">estimador de Parzen estructurado en √°rbol (TPE)</a> .  Trat√© de optimizar: <br><br><ul><li>  par√°metros lightgbm (tipo de algoritmo, n√∫mero de hojas, tasa de aprendizaje y otros), <br></li><li>  par√°metros de modelos de redes neuronales (n√∫mero de filtros <abbr title="Redes Convolucionales Temporales">TCN</abbr> , n√∫mero de <abbr title="Unidad recurrente cerrada">bloques de</abbr> memoria <abbr title="Unidad recurrente cerrada">GRU</abbr> , tasa de abandono, tasa de aprendizaje, tipo de solucionador). <br></li></ul><br>  Como resultado, todas las soluciones encontradas usando esta optimizaci√≥n dieron una puntuaci√≥n m√°s baja, aunque funcionaron mejor en los datos de la prueba.  Probablemente, la raz√≥n radica en el hecho de que los datos para los cuales se considera el puntaje no son muy similares a los datos de validaci√≥n seleccionados de la capacitaci√≥n.  Por lo tanto, para esta tarea, el ajuste fino no es muy adecuado, ya que conduce a la reentrenamiento del modelo. <br><br><h2>  Decisi√≥n final </h2><br>  De acuerdo con las reglas de la competencia, los participantes pueden elegir dos soluciones para la etapa final.  Mis decisiones finales son casi las mismas y contienen un conjunto de dos modelos: <abbr title="M√°quina de aumento de gradiente">GBM</abbr> y <abbr title="Unidad recurrente cerrada">GRU</abbr> multicapa.  La √∫nica diferencia es que una soluci√≥n no usa datos de noticias en absoluto, y la otra los usa, sino solo para el modelo de red neuronal. <br><br>  Soluci√≥n de datos de noticias: <br><br><img src="https://habrastorage.org/webt/lq/ql/g7/lqqlg7lzgqnkhjuvlakbvtwcmks.png"><br><div class="spoiler">  <b class="spoiler_title">Importaciones</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> p <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> functools <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> kaggle.competitions <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> twosigmanews <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler, LabelEncoder <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential, Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense, GRU, LSTM, Conv1D, Reshape, Flatten, SpatialDropout1D, Lambda, Input, Average <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam, SGD, RMSprop <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> losses <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> ls <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> activations <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> act <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras.backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> lgb</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Preprocesamiento de datos</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># fix random from numpy.random import seed seed(42) from tensorflow import set_random_seed set_random_seed(42) env = twosigmanews.make_env() (market_train_df, news_train_df) = env.get_training_data() def cleanData(market_data, news_data):   market_data = market_data[(market_data['returnsOpenNextMktres10'] &lt;= 1) &amp; (market_data['returnsOpenNextMktres10'] &gt;= -1)]   return market_data, news_data def prepareData(marketdf, newsdf, scaler=None):   print('Preparing data...')     print('...preparing features...')   marketdf = marketdf.copy()   newsdf = newsdf.copy()   # a bit of feature engineering   marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int)   marketdf['bartrend'] = marketdf['close'] / marketdf['open']   marketdf['average'] = (marketdf['close'] + marketdf['open'])/2   marketdf['pricevolume'] = marketdf['volume'] * marketdf['close']     newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int)   newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount']   newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount']   # filter pre-2012 data, no particular reason   marketdf = marketdf.loc[marketdf['time'] &gt; 20120000]     # get rid of extra junk from news data   droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider',               'sentenceCount','bodySize','headlineTag', 'subjects','audiences',               'assetName', 'wordCount','sentimentWordCount', 'companyCount',                'coverage']   newsdf.drop(droplist, axis=1, inplace=True)   marketdf.drop(['assetName', 'volume'], axis=1, inplace=True)     # unstack news   newsdf['assetCodes'] = newsdf['assetCodes'].apply(lambda x: x[1:-1].replace("'", ""))   codes = []   indices = []   for i, values in newsdf['assetCodes'].iteritems():       explode = values.split(", ")       codes.extend(explode)       repeat_index = [int(i)]*len(explode)       indices.extend(repeat_index)   index_df = p.DataFrame({'news_index': indices, 'assetCode': codes})   newsdf['news_index'] = newsdf.index.copy()   # Merge news on unstacked assets   news_unstack = index_df.merge(newsdf, how='left', on='news_index')   news_unstack.drop(['news_index', 'assetCodes'], axis=1, inplace=True)     # combine multiple news reports for same assets on same day   newsgp = news_unstack.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index()     # join news reports to market data, note many assets will have many days without news data   res = p.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) #, right_on=['time', 'assetCodes'])   res.marketCommentary = res.marketCommentary.astype(float)     targetcol = 'returnsOpenNextMktres10'   target_presented = targetcol in res.columns   features = [col for col in res.columns if col not in ['time', 'assetCode', 'universe', targetcol]]     print('...scaling...')   if(scaler == None):       scaler = StandardScaler()       scaler = scaler.fit(res[features])   res[features] = scaler.transform(res[features])   print('...done.')   return type('', (object,), {       'scaler': scaler,       'data': res,       'x': res[features],       'y': (res[targetcol] &gt; 0).astype(int).values if target_presented else None,       'features': features,       'samples': len(res),       'assets': res['assetCode'].unique(),       'target_presented': target_presented   }) def generateTimeSeries(data, n_timesteps=1):     data.data[data.features] = data.data[data.features].fillna(data.data[data.features].mean())   #data.data[data.features] = data.data[data.features].fillna(0)   assets = data.data.groupby('assetCode', sort=False)     def grouper(n, iterable):       it = iter(iterable)       while True:          chunk = list(itertools.islice(it, n))          if not chunk:              return          yield chunk     def sample_generator():       while True:           for assetCode, days in assets:               x = days[data.features].values               y = (days['returnsOpenNextMktres10'] &gt; 0).astype(int).values if data.target_presented else None               for i in range(0, len(days) - n_timesteps + 1):                   yield (x[i: i + n_timesteps], y[i + n_timesteps - 1] if data.target_presented else 0)     def batch_generator(batch_size):       for batch in grouper(batch_size, sample_generator()):           yield tuple([np.array(t) for t in zip(*batch)])     n_samples = functools.reduce(lambda x,y : x + y, map(lambda t : 0 if len(t[1]) + 1 &lt;= n_timesteps else len(t[1]) - n_timesteps + 1, assets))   return type('', (object,), {       'gen': batch_generator,       'timesteps': n_timesteps,       'features': len(data.features),       'samples': n_samples,       'assets': list(map(lambda x: x[0], filter(lambda t : len(t[1]) + 1 &gt; n_timesteps, assets)))   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Modelo de red neuronal</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   x2 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,<span class="hljs-number"><span class="hljs-number">13</span></span>:])(i)   x2 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x2)   x2 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x2)   x = Average()([x1, x2])   model = Model(inputs=i, outputs=x)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model_time_series</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)   batch_size = <span class="hljs-number"><span class="hljs-number">4096</span></span>     optimizer = RMSprop()     <span class="hljs-comment"><span class="hljs-comment"># define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505   def auc_roc(y_true, y_pred):       value, update_op = tf.metrics.auc(y_true, y_pred)       metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]       for v in metric_vars:           tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)       with tf.control_dependencies([update_op]):           value = tf.identity(value)           return value     model.compile(loss=ls.binary_crossentropy, optimizer=optimizer, metrics=['binary_accuracy', auc_roc])     print(model.summary())     print('Training model...')     if(val_data == None):       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           verbose=1)   else:       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           validation_data=val_data.gen(batch_size),           validation_steps=int(val_data.samples / batch_size),           verbose=1)   return type('', (object,), {       'predict': lambda x: model.predict_generator(x, steps=1)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Modelo GBM</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)     params = {       <span class="hljs-string"><span class="hljs-string">"objective"</span></span> : <span class="hljs-string"><span class="hljs-string">"binary"</span></span>,       <span class="hljs-string"><span class="hljs-string">"metric"</span></span> : <span class="hljs-string"><span class="hljs-string">"auc"</span></span>,       <span class="hljs-string"><span class="hljs-string">"num_leaves"</span></span> : <span class="hljs-number"><span class="hljs-number">60</span></span>,       <span class="hljs-string"><span class="hljs-string">"max_depth"</span></span>: <span class="hljs-number"><span class="hljs-number">-1</span></span>,       <span class="hljs-string"><span class="hljs-string">"learning_rate"</span></span> : <span class="hljs-number"><span class="hljs-number">0.01</span></span>,       <span class="hljs-string"><span class="hljs-string">"bagging_fraction"</span></span> : <span class="hljs-number"><span class="hljs-number">0.9</span></span>,  <span class="hljs-comment"><span class="hljs-comment"># subsample       "feature_fraction" : 0.9,  # colsample_bytree       "bagging_freq" : 5,        # subsample_freq       "bagging_seed" : 2018,       "verbosity" : -1 }     ds, val_ds = lgb.Dataset(data.x.iloc[:,:13], data.y), lgb.Dataset(val_data.x.iloc[:,:13], val_data.y)   print('...training...')   model = lgb.train(params, ds, 2000, valid_sets=[ds, val_ds], early_stopping_rounds=100, verbose_eval=100)   print('...done.')     return type('', (object,), {       'model': model,       'predict': lambda x: model.predict(x.iloc[:,:13], num_iteration=model.best_iteration)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Entrenamiento</b> <div class="spoiler_text"><pre> <code class="python hljs">n_timesteps = <span class="hljs-number"><span class="hljs-number">30</span></span> market_data, news_data = cleanData(market_train_df, news_train_df) dates = market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].unique() train = range(len(dates))[:int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates))] val = range(len(dates))[int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates)):] train_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[train])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &lt;= max(dates[train])]) val_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[val])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &gt; max(dates[train])], scaler=train_data_prepared.scaler) model_gbm = train_model(train_data_prepared, val_data_prepared) train_data_ts = generateTimeSeries(train_data_prepared, n_timesteps=n_timesteps) val_data_ts = generateTimeSeries(val_data_prepared, n_timesteps=n_timesteps) rnn = buildRNN(train_data_ts.timesteps, train_data_ts.features) model_rnn = train_model_time_series(rnn, train_data_ts, val_data_ts)</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Predicci√≥n</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_predictions</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, template, model)</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(hasattr(data, <span class="hljs-string"><span class="hljs-string">'gen'</span></span>)):       prediction = (model.predict(data.gen(data.samples)) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>)[:,<span class="hljs-number"><span class="hljs-number">-1</span></span>]   <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>:       prediction = model.predict(data.x) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>   predsdf = p.DataFrame({<span class="hljs-string"><span class="hljs-string">'ast'</span></span>:data.assets,<span class="hljs-string"><span class="hljs-string">'conf'</span></span>:prediction})   template[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>][template[<span class="hljs-string"><span class="hljs-string">'assetCode'</span></span>].isin(predsdf.ast)] = predsdf[<span class="hljs-string"><span class="hljs-string">'conf'</span></span>].values   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> template day = <span class="hljs-number"><span class="hljs-number">1</span></span> days_data = p.DataFrame({}) days_data_len = [] days_data_n = p.DataFrame({}) days_data_n_len = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (market_obs_df, news_obs_df, predictions_template_df) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> env.get_prediction_days():   print(<span class="hljs-string"><span class="hljs-string">f'Predicting day </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{day}</span></span></span><span class="hljs-string">'</span></span>)   days_data = p.concat([days_data, market_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_len.append(len(market_obs_df))   days_data_n = p.concat([days_data_n, news_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_n_len.append(len(news_obs_df))   data = prepareData(market_obs_df, news_obs_df, scaler=train_data_prepared.scaler)   predictions_df = make_predictions(data, predictions_template_df.copy(), model_gbm)   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(day &gt;= n_timesteps):       data = prepareData(days_data, days_data_n, scaler=train_data_prepared.scaler)       data = generateTimeSeries(data, n_timesteps=n_timesteps)       predictions_df_s = make_predictions(data, predictions_template_df.copy(), model_rnn)       predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] = (predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] + predictions_df_s[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>]) / <span class="hljs-number"><span class="hljs-number">2</span></span>       days_data = days_data[days_data_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_n = days_data_n[days_data_n_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_len = days_data_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]       days_data_n_len = days_data_n_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]   env.predict(predictions_df)   day += <span class="hljs-number"><span class="hljs-number">1</span></span> env.write_submission_file()</code> </pre><br></div></div><br>  Soluci√≥n sin datos de noticias: <br><br><img src="https://habrastorage.org/webt/m8/vr/05/m8vr05gvobi5ffv6qrb5rz0zzqq.png"><br><br><div class="spoiler">  <b class="spoiler_title">C√≥digo (solo un m√©todo diferente)</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br></div></div><br>  Ambas decisiones dieron un resultado similar (aproximadamente 0,69) en la primera etapa de la competencia, que correspondi√≥ a 566 de 2,927 lugares. Despu√©s del primer mes de nuevos datos, las posiciones en la lista de participantes se mezclaron, y la soluci√≥n con datos de noticias se ubic√≥ en el lugar 65 de los 697 equipos restantes con el resultado de 3.19251, y lo que suceder√° en los pr√≥ximos cinco meses, nadie lo sabe. <br><br><h2>  ¬øQu√© m√°s prob√©? </h2><br><h3>  M√©tricas personalizadas </h3><br>  Dado que las decisiones se eval√∫an utilizando la relaci√≥n de Sharpe, es l√≥gico intentar utilizarla como una m√©trica para la finalizaci√≥n temprana del entrenamiento. <br><br>  M√©trica para lightgbm: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sharpe_metric</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_pred, train_data)</span></span></span><span class="hljs-function">:</span></span> y_true = train_data.get_label() * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span> std = np.std(y_true * y_pred) mean = np.mean(y_true * y_pred) sharpe = np.divide(mean, std, out=np.zeros_like(mean), where=std!=<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">"sharpe"</span></span>, sharpe, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span></code> </pre><br>  La verificaci√≥n mostr√≥ que dicha m√©trica funciona peor en este problema que AUC. <br><br><h3>  Mecanismo de atenci√≥n </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El mecanismo de atenci√≥n</a> permite que la red neuronal se centre en las caracter√≠sticas "m√°s importantes" en los datos de origen.  T√©cnicamente, la atenci√≥n est√° representada por un vector de pesos (generalmente obtenido usando una capa completamente conectada con activaci√≥n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">softmax</a> ), que se multiplica por la salida de otra capa.  Utilic√© una implementaci√≥n en la que se aplica la atenci√≥n al eje del tiempo: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>     <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">attention_3d_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(inputs)</span></span></span><span class="hljs-function">:</span></span>       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(inputs)       a = Dense(timesteps, activation=act.softmax)(a)       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(a)       mul = Multiply()([inputs, a])       <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mul     i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br>  Este modelo se ve bastante bonito, pero este enfoque no dio un aumento en la puntuaci√≥n, result√≥ ser de aproximadamente 0,67. <br><br><h2>  Lo que no tuvo tiempo de hacer </h2><br>  Varias √°reas que parecen prometedoras: <br><br><ul><li>  tratar m√°s espec√≠ficamente el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">mecanismo de atenci√≥n</a> , <br></li><li>  intente usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">codificadores autom√°ticos</a> , <br></li><li>  prueba <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el aprendizaje en l√≠nea</a> <br></li><li>  Cuide con cuidado la integraci√≥n de noticias y datos de mercado, as√≠ como con el procesamiento previo de noticias. <br></li></ul><br><h2>  Conclusiones </h2><br>  Nuestra aventura ha llegado a su fin, puedes intentar resumirla.  La competencia result√≥ ser dif√≠cil, pero no pudimos enfrentar la suciedad.  Esto sugiere que el umbral para ingresar al ML no es tan alto, pero, como en cualquier negocio, la magia real (y hay mucho en el aprendizaje autom√°tico) ya est√° disponible para los profesionales. <br><br>  Resultados en n√∫meros: <br><br><ul><li>  El puntaje m√°ximo en la primera etapa: ~ 0.69 contra ~ 1.5 en primer lugar.  Algo as√≠ como el promedio del hospital, unos pocos superaron el valor de 0.7, el puntaje m√°ximo de la decisi√≥n p√∫blica tambi√©n fue ~ 0.69, un poco m√°s que el m√≠o. <br></li><li>  Lugar en la primera etapa: 566 de 2927. <br></li><li>  Puntuaci√≥n en la segunda etapa: 3.19251 despu√©s del primer mes. <br></li><li>  Lugar en la segunda etapa: 65 de 697 despu√©s del primer mes. <br></li></ul><br>  Le llamo la atenci√≥n sobre el hecho de que los n√∫meros en la segunda etapa no hablan particularmente de nada, ya que todav√≠a hay muy pocos datos para una evaluaci√≥n cualitativa de las decisiones. <br><br><h2>  Referencias </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La soluci√≥n final usando noticias</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Two Sigma: Uso de noticias para predecir movimientos de acciones</a> - P√°gina del concurso <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Keras</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Marco de red</a> neuronal <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LightGBM</a> - Marco GBM <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Scikit-learn</a> - biblioteca de algoritmos de aprendizaje autom√°tico <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Hyperopt</a> - biblioteca para optimizar hiperpar√°metros <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Art√≠culo sobre WaveNet</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/440026/">https://habr.com/ru/post/440026/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../440016/index.html">Cuando se puede tocar la lectura: ONYX BOOX Monte Cristo 4 review</a></li>
<li><a href="../440018/index.html">Exposici√≥n local din√°mica</a></li>
<li><a href="../440020/index.html">Regresi√≥n o regresi√≥n en pruebas</a></li>
<li><a href="../440022/index.html">Un peque√±o Ferrari: Fintech-startup Rally Rd te permitir√° comprar "acciones" de autos raros</a></li>
<li><a href="../440024/index.html">Redireccionar printf () de STM32 a Qt Creator Console</a></li>
<li><a href="../440030/index.html">Identifique el bloqueo de PKH en un enrutador OpenWrt con WireGuard y DNSCrypt</a></li>
<li><a href="../440032/index.html">Inteligencia Artificial Horizon Zero Dawn</a></li>
<li><a href="../440034/index.html">BESO Arquitectura. Del microservicio al monolito</a></li>
<li><a href="../440036/index.html">Mecanograf√≠a t√°ctil</a></li>
<li><a href="../440040/index.html">En desarrollo, cada uno por s√≠ mismo. Pero a veces conduce a un callej√≥n sin salida.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
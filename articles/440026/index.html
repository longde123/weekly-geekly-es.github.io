<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👶🏻 👩🏿‍🏫 🤯 Kaggle: no puede caminar - corramos 👈🏿 🐑 🔚</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¿Cuán complejo es el tema del aprendizaje automático? Si eres bueno en matemáticas, pero la cantidad de conocimiento sobre el aprendizaje automático t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kaggle: no puede caminar - corramos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/singularis/blog/440026/">  ¿Cuán complejo es el tema del aprendizaje automático?  Si eres bueno en matemáticas, pero la cantidad de conocimiento sobre el aprendizaje automático tiende a cero, ¿hasta dónde puedes llegar en una competencia seria en la plataforma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kaggle</a> ? <br><br><img src="https://habrastorage.org/webt/3y/zi/_f/3yzi_f6ybvxg_uq9392v4rqoml0.png"><br><a name="habracut"></a><br><h2>  Sobre el sitio y la competencia </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kaggle</a> es una comunidad de personas interesadas en ML (desde principiantes hasta profesionales geniales) y un lugar para concursos (a menudo con un impresionante premio acumulado). <br><br>  Para sumergirme de inmediato en todos los encantos de ML, decidí elegir inmediatamente una competencia seria.  Tal solo estaba disponible: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Two Sigma: Uso de noticias para predecir movimientos de acciones</a> .  La esencia del concurso en pocas palabras es predecir el precio de las acciones de varias compañías en función del estado del activo y las noticias relacionadas con este activo.  El fondo de premios del concurso es de $ 100,000, que se distribuirá entre los participantes que ganaron los primeros 7 lugares. <br><br>  La competencia es especial por dos razones: <br><br><ul><li>  este es un concurso exclusivo de Kernels: solo puedes entrenar modelos en la nube de Kaggle Kernels; <br></li><li>  la distribución final de los asientos se conocerá solo seis meses después de la finalización de la toma de decisiones;  durante este tiempo, las decisiones predecirán los precios en la fecha actual. <br></li></ul><br><h2>  Sobre la tarea </h2><br>  Por condición, debemos predecir la confianza <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>e</mi><mi>n</mi><mo stretchy=&quot;false&quot;>[</mo><mo>&amp;#x2212;</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="16.041ex" height="2.66ex" viewBox="0 -832 6906.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="1356" y="0"></use><g transform="translate(1717,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="361" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-65" x="3057" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-6E" x="3524" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-5B" x="4124" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-2212" x="4403" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-31" x="5181" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-2C" x="5682" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-31" x="6127" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-5D" x="6628" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">h</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><msub><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y</font></font></mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></mrow></msub><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></mi><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[</font></font></mo><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-</font></font></mo><mn><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></mn><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">,</font></font></mo><mn><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></mn><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">]</font></font></mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> \ hat {y} _ {ti} \ en [-1,1] </script>  en eso aumentará el rendimiento del activo.  El rendimiento de un activo se considera en relación con el rendimiento del mercado en su conjunto.  La métrica objetivo es personalizada: no es el <abbr title="Error cuadrático medio">RMSE</abbr> o el <abbr title="Error absoluto medio">MAE</abbr> más familiares, sino <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la relación de Sharpe</a> , que en este caso se considera de la siguiente manera: <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></mrow><mo>,</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="35.757ex" height="2.66ex" viewBox="0 -832 15395.3 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-65" x="611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="1078" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="1650" y="0"></use><g transform="translate(2012,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-73" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-63" x="469" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-6F" x="903" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-72" x="1388" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-65" x="1840" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-3D" x="4596" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-66" x="5902" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-72" x="6453" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="6904" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-63" x="7434" y="0"></use><g transform="translate(7867,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use></g></g><g transform="translate(10456,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-29" x="4271" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-2C" x="15116" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">c</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e</font></font></mi></mrow><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">=</font></font></mo><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">f</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">c</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">b</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r</font></font></mi><msub><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi></mrow><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub></mrow><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">g</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(</font></font></mo><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">)</font></font></mo></mrow><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">,</font></font></mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> \ text {score} = \ frac {\ bar {x} _t} {\ sigma (x_t)}, </script></p>  donde <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.782ex" height="2.539ex" viewBox="0 -780.1 9808.8 1093.4" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-3D" x="1205" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-73" x="2512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-75" x="2981" y="0"></use><g transform="translate(3554,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="1242" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-68" x="5026" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="5603" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="6132" y="0"></use><g transform="translate(6494,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(7584,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(8636,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="361" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub><mo><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">=</font></font></mo><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tu</font></font></mi><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></msub><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">h</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><msub><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y</font></font></mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></mrow></msub><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></mrow></msub><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tu</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> x_t = \ sum_i \ hat {y} _ {ti} r_ {ti} u_ {ti} </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.442ex" height="1.817ex" viewBox="0 -520.7 1051.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-4"> r_ {ti} </script>  - el rendimiento del activo i en relación con el mercado para el día t en un horizonte de 10 días, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="1.817ex" viewBox="0 -520.7 1172.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tu</font></font></mi><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-5"> u_ {ti} </script>  - una variable booleana que indica si el i-ésimo activo está incluido en la valoración para el día t, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.012ex" height="2.419ex" viewBox="0 -780.1 2588.6 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">b</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r</font></font></mi><msub><mrow class="MJX-TeXAtom-ORD"><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi></mrow><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-6"> \ bar {x} _t </script>  - valor medio <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-7"> x_t </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.825ex" height="2.66ex" viewBox="0 -832 4660.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMAIN-29" x="4271" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">s</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yo</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">g</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></mi><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(</font></font></mo><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub><mo stretchy="false"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">)</font></font></mo></math></span></span><script type="math/tex" id="MathJax-Element-8"> \ sigma (x_t) </script>  - desviación estándar <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhzujjsr8h15q3xg03f5GbEtssUGw#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></mi><mi><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">t</font></font></mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-9"> x_t </script>  . <br><br>  La relación de Sharpe es el rendimiento ajustado al riesgo, los valores del coeficiente muestran la efectividad del operador: <br><br><ul><li>  menos de 1: bajo rendimiento <br></li><li>  1 - 2: media, eficiencia normal, <br></li><li>  2-3: excelente rendimiento, <br></li><li>  más de 3: perfecto. <br></li></ul><br><div class="spoiler">  <b class="spoiler_title">Datos de movimiento del mercado</b> <div class="spoiler_text"><ul><li>  <b>hora</b> (datetime64 [ns, UTC]) - hora actual (en los datos sobre el movimiento del mercado en todas las líneas a las 22:00 UTC) <br></li><li>  <b>assetCode</b> (objeto) - identificador de activo <br></li><li>  <b>assetName</b> (categoría): un identificador de un grupo de activos para la comunicación con datos de noticias <br></li><li>  <b>universo</b> (float64): un valor booleano que indica si este activo se tendrá en cuenta en el cálculo de la puntuación <br></li><li>  <b>volumen</b> (float64) - volumen diario de negociación <br></li><li>  <b>close</b> (float64) - precio de cierre para este día <br></li><li>  <b>abierto</b> (float64) - precio abierto para este día <br></li><li>  <b>returnClosePrevRaw1</b> (float64): rendimiento desde el cierre hasta el cierre del día anterior <br></li><li>  <b>returnOpenPrevRaw1</b> (float64): rentabilidad desde la apertura hasta la apertura del día anterior <br></li><li>  <b>returnClosePrevMktres1</b> (float64): rendimiento de cierre a cierre del día anterior, ajustado en relación con el movimiento del mercado en su conjunto <br></li><li>  <b>returnOpenPrevMktres1</b> (float64): rentabilidad desde la apertura hasta la apertura del día anterior, ajustada en relación con el movimiento del mercado en su conjunto <br></li><li>  <b>returnClosePrevRaw10</b> (float64) - rendimiento de cerca a cerrar durante los 10 días anteriores <br></li><li>  <b>returnOpenPrevRaw10</b> (float64): rentabilidad desde la apertura hasta la apertura durante los 10 días anteriores <br></li><li>  <b>returnClosePrevMktres10</b> (float64): rendimiento de cierre a cierre durante los 10 días anteriores, ajustado en relación con el movimiento del mercado en su conjunto <br></li><li>  <b>returnOpenPrevMktres10</b> (float64): rendimiento de apertura a apertura durante los 10 días anteriores, ajustado en relación con el movimiento del mercado en su conjunto <br></li><li>  <b>returnOpenNextMktres10</b> (float64): rendimiento de abierto a abierto durante los próximos 10 días, ajustado por el movimiento del mercado en su conjunto.  Vamos a predecir este valor. <br></li></ul><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Datos de noticias</b> <div class="spoiler_text"><ul><li>  <b>time</b> (datetime64 [ns, UTC]) - hora en disponibilidad de datos UTC <br></li><li>  <b>sourceTimestamp</b> (datetime64 [ns, UTC]) - hora en las noticias de publicación UTC <br></li><li>  <b>firstCreated</b> (datetime64 [ns, UTC]) - hora en UTC de la primera versión de los datos <br></li><li>  <b>sourceId</b> (objeto) - identificador de registro <br></li><li>  <b>título</b> (objeto) - título <br></li><li>  <b>urgencia</b> (int8) - tipos de noticias (1: alerta, 3: artículo) <br></li><li>  <b>takeSequence</b> (int16) - parámetro no muy claro, número en alguna secuencia <br></li><li>  <b>proveedor</b> (categoría): identificador del proveedor de noticias <br></li><li>  <b>temas</b> (categoría): una lista de códigos de temas de noticias (puede ser un signo geográfico, evento, sector industrial, etc.) <br></li><li>  <b>audiencias</b> (categoría) - lista de noticias de códigos de audiencia <br></li><li>  <b>bodySize</b> (int32): número de caracteres en el cuerpo de noticias <br></li><li>  companyCount (int8): número de empresas mencionadas explícitamente en las noticias <br></li><li>  <b>headlineTag</b> (objeto): cierta etiqueta de título de Thomson Reuters <br></li><li>  <b>marketCommentary</b> (bool): una señal de que las noticias se relacionan con las condiciones generales del mercado <br></li><li>  <b>sentenceCount</b> (int16) - número de ofertas en las noticias <br></li><li>  <b>wordCount</b> (int32): número de palabras y signos de puntuación en las noticias <br></li><li>  <b>assetCodes</b> (categoría): lista de activos mencionados en las noticias <br></li><li>  <b>assetName</b> (categoría) - código de grupo de activos <br></li><li>  <b>firstMentionSentence</b> (int16): una oración que primero menciona un activo: <br></li><li>  <b>relevancia</b> (float32): un número del 0 al 1, que muestra la relevancia de las noticias sobre el activo <br></li><li>  <b>sentimentClass</b> (int8) - clase de tonalidad de noticias <br></li><li>  <b>sentimentNegative</b> (float32) - probabilidad de que la tonalidad sea negativa <br></li><li>  <b>sentimentNeutral</b> (float32) - probabilidad de que el tono sea neutral <br></li><li>  <b>sentimentPositive</b> (float32) - probabilidad de que la clave sea positiva <br></li><li>  <b>sentimentWordCount</b> (int32): la cantidad de palabras en el texto que están relacionadas con el activo <br></li><li>  <b>noveltyCount12H</b> (int16) - noticias de "novedad" en 12 horas, calculadas en relación con las noticias anteriores sobre este activo <br></li><li>  <b>novetyCount24H</b> (int16) - mismo, en 24 horas <br></li><li>  <b>noveltyCount3D</b> (int16) - igual, en 3 días <br></li><li>  <b>novetyCount5D</b> (int16) - igual, en 5 días <br></li><li>  <b>novetyCount7D</b> (int16) - mismo, en 7 días <br></li><li>  <b>volumeCounts12H</b> (int16): la cantidad de noticias sobre este activo en 12 horas <br></li><li>  <b>volumeCounts24H</b> (int16) - igual, en 24 horas <br></li><li>  <b>volumeCounts3D</b> (int16) - igual, en 3 días <br></li><li>  <b>volumeCounts5D</b> (int16): igual, durante 5 días <br></li><li>  <b>volumeCounts7D</b> (int16) - igual, en 7 días <br></li></ul><br></div></div><br>  La tarea es esencialmente una tarea de clasificación binaria, es decir, predecimos un signo binario, ya sea que el rendimiento aumente (1 clase) o disminuya (clase 0). <br><br><h2>  Sobre herramientas </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kaggle Kernels</a> es una plataforma de computación en la nube que admite la colaboración.  Se admiten los siguientes tipos de núcleos: <br><ul><li>  Script de Python <br></li><li>  R script <br></li><li>  Cuaderno Jupyter <br></li><li>  RMarkdown <br></li></ul><br>  Cada núcleo se ejecuta en su contenedor acoplable.  Se instala una gran cantidad de paquetes en el contenedor, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> se puede encontrar una lista de Python.  Las especificaciones técnicas son las siguientes: <br><br><ul><li>  CPU: 4 núcleos, </li><li>  RAM: 17 GB, </li><li>  unidad: 5 GB permanentes y 16 GB temporales, </li><li>  tiempo máximo de ejecución del script: 9 horas (en el momento del inicio de la competencia eran 6 horas). </li></ul><br>  Las GPU también están disponibles en Kernels, sin embargo, la GPU estaba prohibida en este concurso. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Keras</a> es un marco de red neuronal de alto nivel que se ejecuta sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TensorFlow</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CNTK</a> o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Theano</a> .  Es una API muy conveniente y comprensible, y es posible agregar sus topologías de red, funciones de pérdida y más utilizando la API de back-end. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Scikit-learn</a> es una gran biblioteca de algoritmos de aprendizaje automático.  Una fuente útil de preprocesamiento de datos y algoritmos de análisis de datos para su uso con marcos más especializados. <br><br><h2>  Validación del modelo </h2><br>  Antes de enviar un modelo para evaluación, debe verificar de alguna manera localmente qué tan bien funciona, es decir, encontrar una forma de validación local.  Intenté los siguientes enfoques: <br><br><ol><li>  validación cruzada <i>versus</i> división proporcional simple en conjuntos de entrenamiento / prueba; </li><li>  Cálculo local de la relación de Sharpe <i>vs</i> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><abbr title="Características de funcionamiento del receptor">ROC</abbr> <abbr title="Área bajo curva">AUC</abbr></a> . </li></ol><br>  Como resultado, los resultados más cercanos a la evaluación competitiva, por extraño que parezca, mostraron una combinación de la partición proporcional (seleccionada empíricamente la partición 0.85 / 0.15) y AUC.  La validación cruzada probablemente no sea muy adecuada, ya que el comportamiento del mercado es muy diferente en las primeras etapas de los datos de capacitación y en el período de evaluación.  ¿Por qué las AUC funcionaron mejor que la relación de Sharpe? No puedo decir nada. <br><br><h2>  Primeros intentos </h2><br>  Dado que la tarea es predecir la serie temporal, se probó la primera solución clásica: una red neuronal recurrente ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">RNN</a> ), o más bien, sus variantes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><abbr title="Memoria a corto y largo plazo">LSTM</abbr></a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><abbr title="Unidad recurrente cerrada">GRU</abbr></a> . <br><br>  El principio principal de las redes recurrentes es que para cada valor de salida, no se ingresa una muestra, sino una secuencia completa.  De esto se desprende que: <br><br><ul><li>  necesitamos un preprocesamiento de los datos iniciales: la generación de estas mismas secuencias de duración t días para cada activo; <br></li><li>  un modelo basado en una red recurrente no puede predecir el valor de salida si no hay datos para los t días anteriores. <br></li></ul><br>  Generé secuencias para cada día, comenzando con t, por lo que para t bastante grande (de 20) el conjunto completo de muestras de entrenamiento dejó de caber en la memoria.  El problema se resolvió usando generadores, ya que Keras puede usar generadores como conjuntos de datos de entrada y salida para entrenamiento y predicción. <br><br>  La preparación inicial de los datos fue lo más ingenua posible: tomamos todos los datos del mercado y agregamos un par de características (día de la semana, mes, número de semana del año), y no tocamos los datos de las noticias en absoluto. <br><br>  El primer modelo usó t = 10 y se veía así: <br><br><pre><code class="python hljs">model = Sequential() model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.tanh, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, input_shape=(data.timesteps, data.features))) model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(data.assets, activation=act.relu)) model.add(Dense(data.assets))</code> </pre> <br>  No se sacó nada adecuado de este modelo, el puntaje fue cercano a cero (incluso un poco menos). <br><br><h2>  Redes Convolucionales Temporales </h2><br>  Una solución de red neuronal más moderna para la predicción de series temporales es TCN.  La esencia de esta topología es muy simple: tomamos una red convolucional unidimensional y la aplicamos a nuestra secuencia de longitud t.  Las opciones más avanzadas utilizan varias capas convolucionales con dilatación diferente.  La implementación de TCN se copió parcialmente (a veces a nivel de idea) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">desde aquí</a> (visualización de la pila de TCN tomada del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">artículo de Wavenet</a> ). <br><br><img src="https://habrastorage.org/webt/rf/sb/-4/rfsb-4f0bydwgmhhkwvbrenuxu0.png"><br><br>  La primera solución relativamente exitosa fue este modelo, que incluye una capa GRU sobre TCN: <br><br><pre> <code class="python hljs">model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">256</span></span>)) model.add(Dense(data.assets, activation=act.relu))</code> </pre><br>  Tal modelo produce una puntuación = 0.27668.  Con un poco de ajuste (número de filtros TCN, tamaño de lote) y un aumento de t a 100, ya obtenemos 0.41092: <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">16</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br>  A continuación, agregamos normalización y abandono: <br><br><div class="spoiler">  <b class="spoiler_title">Código</b> <div class="spoiler_text"><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> dropout_rate = <span class="hljs-number"><span class="hljs-number">0.05</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">channel_normalization</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> max_values = K.max(K.abs(x), <span class="hljs-number"><span class="hljs-number">2</span></span>, keepdims=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) + <span class="hljs-number"><span class="hljs-number">1e-5</span></span> out = x / max_values <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out model = Sequential() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(data.timesteps &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>**i)) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) model.add(Flatten()) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: model.add(Flatten(input_shape=(data.timesteps, data.features))) model.add(Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br></div></div><br>  Aplicando este modelo, incluso en los primeros pasos (con t = 1), obtenemos una puntuación = 0.53578. <br><br><h2>  Máquinas de refuerzo de gradiente </h2><br>  En esta etapa, las ideas terminaron y decidí hacer lo que debía hacerse desde el principio: ver las decisiones públicas de otros participantes.  La mayoría de las buenas soluciones no usaban redes neuronales en absoluto, prefiriendo GBM. <br><br>  Gradient Boosting es un método de ML, en el que obtenemos un conjunto de modelos simples (con mayor frecuencia árboles de decisión).  Debido a la gran cantidad de modelos tan simples, la función de pérdida está optimizada.  Puede leer más sobre Gradient Boosting, por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> . <br><br>  Como la implementación de GBM utilizó <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">lightgbm</a> , un marco bastante conocido de Microsoft. <br><br>  El modelo y el preprocesamiento de datos tomados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de aquí</a> dan inmediatamente una puntuación de aproximadamente 0,64: <br><br><div class="spoiler">  <b class="spoiler_title">Código</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">prepare_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(marketdf, newsdf)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># a bit of feature engineering marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int) marketdf['bartrend'] = marketdf['close'] / marketdf['open'] marketdf['average'] = (marketdf['close'] + marketdf['open'])/2 marketdf['pricevolume'] = marketdf['volume'] * marketdf['close'] newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int) newsdf['assetCode'] = newsdf['assetCodes'].map(lambda x: list(eval(x))[0]) newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount'] newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount'] # filter pre-2012 data, no particular reason marketdf = marketdf.loc[marketdf['time'] &gt; 20120000] # get rid of extra junk from news data droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence', 'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass', 'assetName', 'assetCodes','urgency','wordCount','sentimentWordCount'] newsdf.drop(droplist, axis=1, inplace=True) marketdf.drop(['assetName', 'volume'], axis=1, inplace=True) # combine multiple news reports for same assets on same day newsgp = newsdf.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index() # join news reports to market data, note many assets will have many days without news data return pd.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) import lightgbm as lgb print ('Training lightgbm') # money params = { "objective" : "binary", "metric" : "binary_logloss", "num_leaves" : 60, "max_depth": -1, "learning_rate" : 0.01, "bagging_fraction" : 0.9, # subsample "feature_fraction" : 0.9, # colsample_bytree "bagging_freq" : 5, # subsample_freq "bagging_seed" : 2018, "verbosity" : -1 } lgtrain, lgval = lgb.Dataset(Xt, Yt[:,0]), lgb.Dataset(Xv, Yv[:,0]) lgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)</span></span></code> </pre><br></div></div><br>  El preprocesamiento aquí ya incluye datos de noticias, combinándolos con datos de mercado (sin embargo, al hacerlo de manera bastante ingenua, solo se tiene en cuenta un código de activo de todos los que se mencionan en las noticias).  Tomé esta opción de preprocesamiento como base para todas las decisiones posteriores. <br><br>  Al agregar una pequeña característica (firstMentionSentence, marketCommentary, sentimentClass) y también reemplazar la métrica con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ROC AUC</a> , obtenemos un puntaje de 0.65389. <br><br><h2>  Conjunto </h2><br>  La siguiente decisión exitosa fue utilizar un conjunto compuesto por un modelo de red neuronal y GBM (aunque "conjunto" es un gran nombre para dos modelos).  La predicción resultante se obtiene promediando las predicciones de los dos modelos, aplicando así el mecanismo de votación suave.  Esta decisión permitió obtener un puntaje de 0,66879. <br><br><h2>  Análisis exploratorio de datos e ingeniería de características </h2><br>  Otra cosa para comenzar fue EDA.  Después de leer que es importante comprender la correlación entre las características, creamos una imagen de este tipo (se puede hacer clic en las imágenes de esta sección): <br><br> <a href=""><img src="https://habrastorage.org/webt/hw/xl/b2/hwxlb2agjx113qtsyciwbeuulvk.png"></a> <br><br>  Aquí se ve claramente que la correlación por separado dentro del mercado y los datos de noticias es bastante alta, sin embargo, solo los valores de los rendimientos se correlacionan con el valor objetivo al menos de alguna manera.  Dado que los datos representan una serie de tiempo, tiene sentido considerar también la autocorrelación del valor objetivo: <br><br> <a href=""><img src="https://habrastorage.org/webt/gg/t_/ft/ggt_ftesggo-ro3hnbohztculz0.png"></a> <br><br>  Se puede ver que después de un período de 10 días, la dependencia disminuye significativamente.  Esto es probablemente lo que hace que GBM funcione bien, teniendo en cuenta solo las características con un retraso de 10 días (que ya están en el conjunto de datos original). <br><br>  La selección de características y el preprocesamiento son cruciales para todos los algoritmos de ML.  Intentemos utilizar formas automáticas para extraer características, a saber, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el</a> <abbr title="Análisis de componentes principales">análisis de</abbr> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">componentes principales</a> ( <abbr title="Análisis de componentes principales">PCA</abbr> ): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.decomposition <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PCA <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler market_x = market_data.loc[:,features] scaler = StandardScaler() scaler.fit(market_x) market_x = scaler.transform(market_x) pca = PCA(<span class="hljs-number"><span class="hljs-number">.95</span></span>) pca.fit(market_x) market_pca = pca.transform(market_x)</code> </pre><br>  Veamos qué características genera la PCA: <br><br> <a href=""><img src="https://habrastorage.org/webt/oh/1e/a1/oh1ea1byez3dcgjpklh-6gbzvic.png"></a> <br><br>  Vemos que el método no funciona muy bien en nuestros datos, ya que la correlación final de las nuevas características con el valor objetivo es pequeña. <br><br><h2>  Ajuste fino y si es necesario </h2><br>  Muchos modelos de ML tienen una cantidad bastante grande de hiperparámetros, es decir, "configuraciones" del algoritmo mismo.  Se pueden seleccionar manualmente, pero también hay mecanismos de selección automática.  Para este último, hay una biblioteca de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hiperoptos</a> que implementa dos algoritmos de coincidencia: búsqueda aleatoria y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">estimador de Parzen estructurado en árbol (TPE)</a> .  Traté de optimizar: <br><br><ul><li>  parámetros lightgbm (tipo de algoritmo, número de hojas, tasa de aprendizaje y otros), <br></li><li>  parámetros de modelos de redes neuronales (número de filtros <abbr title="Redes Convolucionales Temporales">TCN</abbr> , número de <abbr title="Unidad recurrente cerrada">bloques de</abbr> memoria <abbr title="Unidad recurrente cerrada">GRU</abbr> , tasa de abandono, tasa de aprendizaje, tipo de solucionador). <br></li></ul><br>  Como resultado, todas las soluciones encontradas usando esta optimización dieron una puntuación más baja, aunque funcionaron mejor en los datos de la prueba.  Probablemente, la razón radica en el hecho de que los datos para los cuales se considera el puntaje no son muy similares a los datos de validación seleccionados de la capacitación.  Por lo tanto, para esta tarea, el ajuste fino no es muy adecuado, ya que conduce a la reentrenamiento del modelo. <br><br><h2>  Decisión final </h2><br>  De acuerdo con las reglas de la competencia, los participantes pueden elegir dos soluciones para la etapa final.  Mis decisiones finales son casi las mismas y contienen un conjunto de dos modelos: <abbr title="Máquina de aumento de gradiente">GBM</abbr> y <abbr title="Unidad recurrente cerrada">GRU</abbr> multicapa.  La única diferencia es que una solución no usa datos de noticias en absoluto, y la otra los usa, sino solo para el modelo de red neuronal. <br><br>  Solución de datos de noticias: <br><br><img src="https://habrastorage.org/webt/lq/ql/g7/lqqlg7lzgqnkhjuvlakbvtwcmks.png"><br><div class="spoiler">  <b class="spoiler_title">Importaciones</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> p <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> functools <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> kaggle.competitions <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> twosigmanews <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler, LabelEncoder <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential, Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense, GRU, LSTM, Conv1D, Reshape, Flatten, SpatialDropout1D, Lambda, Input, Average <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam, SGD, RMSprop <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> losses <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> ls <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> activations <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> act <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras.backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> lgb</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Preprocesamiento de datos</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># fix random from numpy.random import seed seed(42) from tensorflow import set_random_seed set_random_seed(42) env = twosigmanews.make_env() (market_train_df, news_train_df) = env.get_training_data() def cleanData(market_data, news_data):   market_data = market_data[(market_data['returnsOpenNextMktres10'] &lt;= 1) &amp; (market_data['returnsOpenNextMktres10'] &gt;= -1)]   return market_data, news_data def prepareData(marketdf, newsdf, scaler=None):   print('Preparing data...')     print('...preparing features...')   marketdf = marketdf.copy()   newsdf = newsdf.copy()   # a bit of feature engineering   marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int)   marketdf['bartrend'] = marketdf['close'] / marketdf['open']   marketdf['average'] = (marketdf['close'] + marketdf['open'])/2   marketdf['pricevolume'] = marketdf['volume'] * marketdf['close']     newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int)   newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount']   newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount']   # filter pre-2012 data, no particular reason   marketdf = marketdf.loc[marketdf['time'] &gt; 20120000]     # get rid of extra junk from news data   droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider',               'sentenceCount','bodySize','headlineTag', 'subjects','audiences',               'assetName', 'wordCount','sentimentWordCount', 'companyCount',                'coverage']   newsdf.drop(droplist, axis=1, inplace=True)   marketdf.drop(['assetName', 'volume'], axis=1, inplace=True)     # unstack news   newsdf['assetCodes'] = newsdf['assetCodes'].apply(lambda x: x[1:-1].replace("'", ""))   codes = []   indices = []   for i, values in newsdf['assetCodes'].iteritems():       explode = values.split(", ")       codes.extend(explode)       repeat_index = [int(i)]*len(explode)       indices.extend(repeat_index)   index_df = p.DataFrame({'news_index': indices, 'assetCode': codes})   newsdf['news_index'] = newsdf.index.copy()   # Merge news on unstacked assets   news_unstack = index_df.merge(newsdf, how='left', on='news_index')   news_unstack.drop(['news_index', 'assetCodes'], axis=1, inplace=True)     # combine multiple news reports for same assets on same day   newsgp = news_unstack.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index()     # join news reports to market data, note many assets will have many days without news data   res = p.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) #, right_on=['time', 'assetCodes'])   res.marketCommentary = res.marketCommentary.astype(float)     targetcol = 'returnsOpenNextMktres10'   target_presented = targetcol in res.columns   features = [col for col in res.columns if col not in ['time', 'assetCode', 'universe', targetcol]]     print('...scaling...')   if(scaler == None):       scaler = StandardScaler()       scaler = scaler.fit(res[features])   res[features] = scaler.transform(res[features])   print('...done.')   return type('', (object,), {       'scaler': scaler,       'data': res,       'x': res[features],       'y': (res[targetcol] &gt; 0).astype(int).values if target_presented else None,       'features': features,       'samples': len(res),       'assets': res['assetCode'].unique(),       'target_presented': target_presented   }) def generateTimeSeries(data, n_timesteps=1):     data.data[data.features] = data.data[data.features].fillna(data.data[data.features].mean())   #data.data[data.features] = data.data[data.features].fillna(0)   assets = data.data.groupby('assetCode', sort=False)     def grouper(n, iterable):       it = iter(iterable)       while True:          chunk = list(itertools.islice(it, n))          if not chunk:              return          yield chunk     def sample_generator():       while True:           for assetCode, days in assets:               x = days[data.features].values               y = (days['returnsOpenNextMktres10'] &gt; 0).astype(int).values if data.target_presented else None               for i in range(0, len(days) - n_timesteps + 1):                   yield (x[i: i + n_timesteps], y[i + n_timesteps - 1] if data.target_presented else 0)     def batch_generator(batch_size):       for batch in grouper(batch_size, sample_generator()):           yield tuple([np.array(t) for t in zip(*batch)])     n_samples = functools.reduce(lambda x,y : x + y, map(lambda t : 0 if len(t[1]) + 1 &lt;= n_timesteps else len(t[1]) - n_timesteps + 1, assets))   return type('', (object,), {       'gen': batch_generator,       'timesteps': n_timesteps,       'features': len(data.features),       'samples': n_samples,       'assets': list(map(lambda x: x[0], filter(lambda t : len(t[1]) + 1 &gt; n_timesteps, assets)))   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Modelo de red neuronal</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   x2 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,<span class="hljs-number"><span class="hljs-number">13</span></span>:])(i)   x2 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x2)   x2 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x2)   x = Average()([x1, x2])   model = Model(inputs=i, outputs=x)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model_time_series</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)   batch_size = <span class="hljs-number"><span class="hljs-number">4096</span></span>     optimizer = RMSprop()     <span class="hljs-comment"><span class="hljs-comment"># define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505   def auc_roc(y_true, y_pred):       value, update_op = tf.metrics.auc(y_true, y_pred)       metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]       for v in metric_vars:           tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)       with tf.control_dependencies([update_op]):           value = tf.identity(value)           return value     model.compile(loss=ls.binary_crossentropy, optimizer=optimizer, metrics=['binary_accuracy', auc_roc])     print(model.summary())     print('Training model...')     if(val_data == None):       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           verbose=1)   else:       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           validation_data=val_data.gen(batch_size),           validation_steps=int(val_data.samples / batch_size),           verbose=1)   return type('', (object,), {       'predict': lambda x: model.predict_generator(x, steps=1)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Modelo GBM</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)     params = {       <span class="hljs-string"><span class="hljs-string">"objective"</span></span> : <span class="hljs-string"><span class="hljs-string">"binary"</span></span>,       <span class="hljs-string"><span class="hljs-string">"metric"</span></span> : <span class="hljs-string"><span class="hljs-string">"auc"</span></span>,       <span class="hljs-string"><span class="hljs-string">"num_leaves"</span></span> : <span class="hljs-number"><span class="hljs-number">60</span></span>,       <span class="hljs-string"><span class="hljs-string">"max_depth"</span></span>: <span class="hljs-number"><span class="hljs-number">-1</span></span>,       <span class="hljs-string"><span class="hljs-string">"learning_rate"</span></span> : <span class="hljs-number"><span class="hljs-number">0.01</span></span>,       <span class="hljs-string"><span class="hljs-string">"bagging_fraction"</span></span> : <span class="hljs-number"><span class="hljs-number">0.9</span></span>,  <span class="hljs-comment"><span class="hljs-comment"># subsample       "feature_fraction" : 0.9,  # colsample_bytree       "bagging_freq" : 5,        # subsample_freq       "bagging_seed" : 2018,       "verbosity" : -1 }     ds, val_ds = lgb.Dataset(data.x.iloc[:,:13], data.y), lgb.Dataset(val_data.x.iloc[:,:13], val_data.y)   print('...training...')   model = lgb.train(params, ds, 2000, valid_sets=[ds, val_ds], early_stopping_rounds=100, verbose_eval=100)   print('...done.')     return type('', (object,), {       'model': model,       'predict': lambda x: model.predict(x.iloc[:,:13], num_iteration=model.best_iteration)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Entrenamiento</b> <div class="spoiler_text"><pre> <code class="python hljs">n_timesteps = <span class="hljs-number"><span class="hljs-number">30</span></span> market_data, news_data = cleanData(market_train_df, news_train_df) dates = market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].unique() train = range(len(dates))[:int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates))] val = range(len(dates))[int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates)):] train_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[train])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &lt;= max(dates[train])]) val_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[val])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &gt; max(dates[train])], scaler=train_data_prepared.scaler) model_gbm = train_model(train_data_prepared, val_data_prepared) train_data_ts = generateTimeSeries(train_data_prepared, n_timesteps=n_timesteps) val_data_ts = generateTimeSeries(val_data_prepared, n_timesteps=n_timesteps) rnn = buildRNN(train_data_ts.timesteps, train_data_ts.features) model_rnn = train_model_time_series(rnn, train_data_ts, val_data_ts)</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Predicción</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_predictions</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, template, model)</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(hasattr(data, <span class="hljs-string"><span class="hljs-string">'gen'</span></span>)):       prediction = (model.predict(data.gen(data.samples)) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>)[:,<span class="hljs-number"><span class="hljs-number">-1</span></span>]   <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>:       prediction = model.predict(data.x) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>   predsdf = p.DataFrame({<span class="hljs-string"><span class="hljs-string">'ast'</span></span>:data.assets,<span class="hljs-string"><span class="hljs-string">'conf'</span></span>:prediction})   template[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>][template[<span class="hljs-string"><span class="hljs-string">'assetCode'</span></span>].isin(predsdf.ast)] = predsdf[<span class="hljs-string"><span class="hljs-string">'conf'</span></span>].values   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> template day = <span class="hljs-number"><span class="hljs-number">1</span></span> days_data = p.DataFrame({}) days_data_len = [] days_data_n = p.DataFrame({}) days_data_n_len = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (market_obs_df, news_obs_df, predictions_template_df) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> env.get_prediction_days():   print(<span class="hljs-string"><span class="hljs-string">f'Predicting day </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{day}</span></span></span><span class="hljs-string">'</span></span>)   days_data = p.concat([days_data, market_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_len.append(len(market_obs_df))   days_data_n = p.concat([days_data_n, news_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_n_len.append(len(news_obs_df))   data = prepareData(market_obs_df, news_obs_df, scaler=train_data_prepared.scaler)   predictions_df = make_predictions(data, predictions_template_df.copy(), model_gbm)   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(day &gt;= n_timesteps):       data = prepareData(days_data, days_data_n, scaler=train_data_prepared.scaler)       data = generateTimeSeries(data, n_timesteps=n_timesteps)       predictions_df_s = make_predictions(data, predictions_template_df.copy(), model_rnn)       predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] = (predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] + predictions_df_s[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>]) / <span class="hljs-number"><span class="hljs-number">2</span></span>       days_data = days_data[days_data_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_n = days_data_n[days_data_n_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_len = days_data_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]       days_data_n_len = days_data_n_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]   env.predict(predictions_df)   day += <span class="hljs-number"><span class="hljs-number">1</span></span> env.write_submission_file()</code> </pre><br></div></div><br>  Solución sin datos de noticias: <br><br><img src="https://habrastorage.org/webt/m8/vr/05/m8vr05gvobi5ffv6qrb5rz0zzqq.png"><br><br><div class="spoiler">  <b class="spoiler_title">Código (solo un método diferente)</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br></div></div><br>  Ambas decisiones dieron un resultado similar (aproximadamente 0,69) en la primera etapa de la competencia, que correspondió a 566 de 2,927 lugares. Después del primer mes de nuevos datos, las posiciones en la lista de participantes se mezclaron, y la solución con datos de noticias se ubicó en el lugar 65 de los 697 equipos restantes con el resultado de 3.19251, y lo que sucederá en los próximos cinco meses, nadie lo sabe. <br><br><h2>  ¿Qué más probé? </h2><br><h3>  Métricas personalizadas </h3><br>  Dado que las decisiones se evalúan utilizando la relación de Sharpe, es lógico intentar utilizarla como una métrica para la finalización temprana del entrenamiento. <br><br>  Métrica para lightgbm: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sharpe_metric</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_pred, train_data)</span></span></span><span class="hljs-function">:</span></span> y_true = train_data.get_label() * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span> std = np.std(y_true * y_pred) mean = np.mean(y_true * y_pred) sharpe = np.divide(mean, std, out=np.zeros_like(mean), where=std!=<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">"sharpe"</span></span>, sharpe, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span></code> </pre><br>  La verificación mostró que dicha métrica funciona peor en este problema que AUC. <br><br><h3>  Mecanismo de atención </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El mecanismo de atención</a> permite que la red neuronal se centre en las características "más importantes" en los datos de origen.  Técnicamente, la atención está representada por un vector de pesos (generalmente obtenido usando una capa completamente conectada con activación <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">softmax</a> ), que se multiplica por la salida de otra capa.  Utilicé una implementación en la que se aplica la atención al eje del tiempo: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>     <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">attention_3d_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(inputs)</span></span></span><span class="hljs-function">:</span></span>       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(inputs)       a = Dense(timesteps, activation=act.softmax)(a)       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(a)       mul = Multiply()([inputs, a])       <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mul     i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br>  Este modelo se ve bastante bonito, pero este enfoque no dio un aumento en la puntuación, resultó ser de aproximadamente 0,67. <br><br><h2>  Lo que no tuvo tiempo de hacer </h2><br>  Varias áreas que parecen prometedoras: <br><br><ul><li>  tratar más específicamente el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">mecanismo de atención</a> , <br></li><li>  intente usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">codificadores automáticos</a> , <br></li><li>  prueba <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el aprendizaje en línea</a> <br></li><li>  Cuide con cuidado la integración de noticias y datos de mercado, así como con el procesamiento previo de noticias. <br></li></ul><br><h2>  Conclusiones </h2><br>  Nuestra aventura ha llegado a su fin, puedes intentar resumirla.  La competencia resultó ser difícil, pero no pudimos enfrentar la suciedad.  Esto sugiere que el umbral para ingresar al ML no es tan alto, pero, como en cualquier negocio, la magia real (y hay mucho en el aprendizaje automático) ya está disponible para los profesionales. <br><br>  Resultados en números: <br><br><ul><li>  El puntaje máximo en la primera etapa: ~ 0.69 contra ~ 1.5 en primer lugar.  Algo así como el promedio del hospital, unos pocos superaron el valor de 0.7, el puntaje máximo de la decisión pública también fue ~ 0.69, un poco más que el mío. <br></li><li>  Lugar en la primera etapa: 566 de 2927. <br></li><li>  Puntuación en la segunda etapa: 3.19251 después del primer mes. <br></li><li>  Lugar en la segunda etapa: 65 de 697 después del primer mes. <br></li></ul><br>  Le llamo la atención sobre el hecho de que los números en la segunda etapa no hablan particularmente de nada, ya que todavía hay muy pocos datos para una evaluación cualitativa de las decisiones. <br><br><h2>  Referencias </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La solución final usando noticias</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Two Sigma: Uso de noticias para predecir movimientos de acciones</a> - Página del concurso <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Keras</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Marco de red</a> neuronal <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LightGBM</a> - Marco GBM <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Scikit-learn</a> - biblioteca de algoritmos de aprendizaje automático <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Hyperopt</a> - biblioteca para optimizar hiperparámetros <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Artículo sobre WaveNet</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/440026/">https://habr.com/ru/post/440026/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../440016/index.html">Cuando se puede tocar la lectura: ONYX BOOX Monte Cristo 4 review</a></li>
<li><a href="../440018/index.html">Exposición local dinámica</a></li>
<li><a href="../440020/index.html">Regresión o regresión en pruebas</a></li>
<li><a href="../440022/index.html">Un pequeño Ferrari: Fintech-startup Rally Rd te permitirá comprar "acciones" de autos raros</a></li>
<li><a href="../440024/index.html">Redireccionar printf () de STM32 a Qt Creator Console</a></li>
<li><a href="../440030/index.html">Identifique el bloqueo de PKH en un enrutador OpenWrt con WireGuard y DNSCrypt</a></li>
<li><a href="../440032/index.html">Inteligencia Artificial Horizon Zero Dawn</a></li>
<li><a href="../440034/index.html">BESO Arquitectura. Del microservicio al monolito</a></li>
<li><a href="../440036/index.html">Mecanografía táctil</a></li>
<li><a href="../440040/index.html">En desarrollo, cada uno por sí mismo. Pero a veces conduce a un callejón sin salida.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
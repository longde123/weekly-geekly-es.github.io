<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçâ üî∫ üë®‚Äçüé® Einfacher P300-Klassifikator f√ºr offene Daten ‚óΩÔ∏è üë® üôåüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mein Kollege Rafael Grigoryan eegdude schrieb k√ºrzlich einen Artikel dar√ºber, warum die Menschheit ein EEG ben√∂tigt und welche signifikanten Ph√§nomene...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Einfacher P300-Klassifikator f√ºr offene Daten</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/480060/"><p>  Mein Kollege Rafael Grigoryan <a href="https://habr.com/ru/users/eegdude/" class="user_link">eegdude</a> <a href="https://m.habr.com/ru/post/479164/">schrieb k√ºrzlich</a> einen Artikel dar√ºber, warum die Menschheit ein EEG ben√∂tigt und welche signifikanten Ph√§nomene darin aufgezeichnet werden k√∂nnen.  In Fortsetzung des Themas der neuronalen Schnittstellen verwenden wir heute einen der offenen Datens√§tze, die in einem Spiel mithilfe der P300-Mechanik aufgezeichnet wurden, um das EEG-Signal zu visualisieren, die Struktur der aufgerufenen Potentiale zu sehen, die Hauptklassifikatoren zu konstruieren und die Qualit√§t zu bewerten, mit der wir das Vorhandensein eines solchen aufgerufenen Potentials vorhersagen k√∂nnen. </p><br><p>  Lassen Sie mich daran erinnern, dass P300 ein sogenanntes Potential (VP) ist, eine spezifische Reaktion des Gehirns, die mit der Entscheidungsfindung und der Unterscheidung von Reizen verbunden ist (die wir unten sehen werden).  Es wird normalerweise verwendet, um modernes BCI zu bauen. </p><br><p><img src="https://habrastorage.org/webt/l5/xn/iy/l5xniylmkybexkk6cym8dbhrmjq.png"></p><br><p>  Um die EEG-Klassifizierung durchzuf√ºhren, k√∂nnen Sie Freunde anrufen, ein Spiel √ºber Waschb√§ren und D√§monen in VR schreiben, Ihre eigenen Reaktionen aufschreiben und einen wissenschaftlichen Artikel schreiben (dar√ºber werde ich ein andermal sprechen), aber gl√ºcklicherweise Wissenschaftler aus der ganzen Welt einige Experimente f√ºr uns durchgef√ºhrt und es bleibt nur die Daten herunterzuladen. </p><br><p>  Eine Analyse zum Erstellen einer neuronalen Schnittstelle auf dem P300 mit schrittweisen Codes und Visualisierungen sowie einem Link zum Repository finden Sie unter der Katze. </p><a name="habracut"></a><br><p>  Der Artikel zeigt nur die wichtigsten Punkte aus dem Code, die voll reproduzierbare Version in Jupyter Notebook <a href="https://gitlab.com/impulse-neiry_public/posts">, um hier zu suchen</a> </p><br><p>  Aus Sicht eines EEG ist der P300 in bestimmten Kan√§len nur ein Burst zu einer bestimmten Zeit.  Es gibt viele M√∂glichkeiten, es aufzurufen, zum Beispiel, wenn Sie sich auf ein Objekt konzentrieren und es zu einem zuf√§lligen Zeitpunkt aktiviert wird (Form, Farbe, Helligkeit √§ndern oder irgendwo abspringen).  So wurde es in der Antike implementiert. </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wKDimrzvwYA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Im Allgemeinen lautet das Schema wie folgt: Es gibt mehrere (normalerweise 3 bis 7) Reize im Gesichtsfeld einer Person.  Eine Person w√§hlt eine davon aus und konzentriert sich darauf (eine gute Methode ist es, die Anzahl der Aktivierungen zu z√§hlen). Dann blinkt jedes Objekt in zuf√§lliger Reihenfolge.  Wenn wir die Aktivierungszeit jedes Stimulus kennen, k√∂nnen wir jetzt das n√§chste EEG betrachten und feststellen, ob es einen charakteristischen Peak enth√§lt (wir werden ihn in den folgenden Visualisierungen sehen).  Da sich die Person nur auf einen Stimulus konzentriert hat, sollte der Peak einer sein.  Daher wird in diesen neuronalen Schnittstellen eine von mehreren Optionen ausgew√§hlt (Buchstaben zum Schreiben, Aktionen im Spiel und Gott wei√ü, was sonst noch).  Wenn es mehr als sieben Optionen gibt, k√∂nnen Sie sie in das Raster einf√ºgen und die Aufgabe auf die Auswahl einer Zeile + Spalte reduzieren.  So sieht der oben gezeigte klassische Matrix-P300-Speller aus. </p><br><p>  Im Falle des heute betrachteten Datensatzes wurde der visuelle Teil (sowie der Name) von den ber√ºhmten Game <a href="https://en.wikipedia.org/wiki/Space_Invaders">Space Invidern ausgeliehen</a> .  Es sah ungef√§hr so ‚Äã‚Äãaus </p><br><p><img src="https://habrastorage.org/webt/xg/yb/du/xgybdulftmr0dpr4muypl7avlro.png" alt="Das Gameplay von Brain Inviders"></p><br><p>  In der Tat ist dies der gleiche Buchstabierer, nur die Buchstaben werden durch Au√üerirdische ersetzt. <br>  Das <a href="https://www.youtube.com/watch%3Fv%3Ds73l8ZfQcWw">Video des Spielprozesses</a> und die <a href="https://arxiv.org/ftp/arxiv/papers/1905/1905.05182.pdf">technischen Berichte wurden</a> ebenfalls beibehalten. </p><br><p>  Auf die eine oder andere Weise sind die mit diesem Spiel gesammelten Daten im Internet erschienen und wir k√∂nnen auf sie zugreifen.  Die Daten bestehen aus 16 EEG-Kan√§len und einem Ereigniskanal, die anzeigen, zu welchem ‚Äã‚ÄãZeitpunkt das (vom Spieler erstellte) Ziel und die nicht zum Ziel geh√∂renden Anreize aktiviert wurden. Wir werden mit ihnen arbeiten. </p><br><p> Die meisten Datens√§tze f√ºr BCI wurden von Neurophysiologen aufgezeichnet, und das sind Leute, die sich nicht wirklich f√ºr Kompatibilit√§t interessieren, daher sind die Datenformate sehr unterschiedlich: von verschiedenen Versionen der <code>.mat</code> Dateien bis zu den "Standard" -Formaten <a href="https://en.wikipedia.org/wiki/European_Data_Format"><code>.edf</code></a> und <a href="https://en.wikipedia.org/wiki/General_Data_Format_for_Biomedical_Signals"><code>.gdf</code></a> . <br>  Das Wichtigste, was Sie √ºber diese Formate wissen m√ºssen, ist, dass Sie sie nicht analysieren oder direkt damit arbeiten m√∂chten. <br>  Gl√ºcklicherweise hat eine Gruppe von Enthusiasten von <a href="https://neurotechx.com/">NeuroTechX</a> Downloader f√ºr einige Datens√§tze direkt in Zahlen geschrieben. <br>  Diese Bootloader sind Teil des <a href="https://github.com/NeuroTechX/moabb/tree/master/moabb">moabb-</a> Projekts, das behauptet, eine universelle L√∂sung f√ºr BCI zu sein. </p><br><h2 id="zagruzka-syrogo-dataseta">  Rohdatensatz herunterladen </h2><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> moabb.datasets sampling_rate = <span class="hljs-number"><span class="hljs-number">512</span></span> m_dataset = moabb.datasets.bi2013a( NonAdaptive=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, Adaptive=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, Training=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, Online=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, ) m_dataset.download() m_data = m_dataset.get_data()</code> </pre> <br><p>  Zu diesem Zeitpunkt haben wir eine <a href="https://mne.tools/stable/generated/mne.io.Raw.html">RawEDF-</a> Struktur erhalten, die EEG-Aufzeichnungen enth√§lt.  Dies ist eine Struktur aus dem <a href="https://mne.tools/stable/index.html"><code>mne</code></a> Paket, die Biologen normalerweise zur Interaktion mit Signalen verwenden: Diese Struktur verf√ºgt √ºber integrierte Methoden zum Filtern, Visualisieren und Speichern von Etiketten, und Sie wissen es nie.  Aber wir werden diesen Weg seitdem nicht mehr gehen  Die Paketschnittstelle ist in der Regel instabil (die aktuelle Version ist <code>0.19</code> , wir verwenden jedoch <code>0.17</code> da der Datensatz von der neuen Version nicht mehr gelesen wird) und schlecht dokumentiert. Dadurch k√∂nnen unsere Ergebnisse m√∂glicherweise nicht mehr reproduzierbar werden. </p><br><p>  Was wir aus der resultierenden Struktur entnehmen, sind die Kanalbezeichnungen im <a href="https://en.wikipedia.org/wiki/10%25E2%2580%259320_system_(EEG)">10-20-System</a> .  Hierbei handelt es sich um eine internationale Anordnung von Elektroden am Kopf einer Person, mit deren Hilfe Wissenschaftler Gehirnzonen und EEG-Kanalpositionen korrelieren k√∂nnen.  Unten sehen Sie die Anordnung der Elektroden im 10-10-System (unterscheidet sich von 10-20 durch die doppelte Markierungsdichte) und die Kan√§le, die in diesem Datensatz aufgezeichnet wurden, sind rot markiert. <br><img src="https://habrastorage.org/webt/j0/x0/uq/j0x0uq27-vjl277bgamcuuz3qpy.jpeg" alt="System 10-10"></p><br><pre> <code class="python hljs">print(m_data[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-string"><span class="hljs-string">'session_1'</span></span>][<span class="hljs-string"><span class="hljs-string">'run_1'</span></span>]) <span class="hljs-comment"><span class="hljs-comment"># &lt;RawEDF | 1.gdf, n_channels x n_times : 17 x 159232 (311.0 sec), ~20.7 MB, data loaded&gt; channels = m_data[1]['session_1']['run_1'].ch_names[:-1] channels # ['FP1', 'FP2', 'F5', 'AFz', 'F6', 'T7', 'Cz', 'T8', 'P7', 'P3', 'Pz', 'P4', 'P8', 'O1', 'Oz', 'O2']</span></span></code> </pre><br><p>  Zun√§chst ordnen wir aus den heruntergeladenen Daten f√ºr jedes Subjekt 16 Sekunden lang Arrays mit kontinuierlichem EEG und alle Labels f√ºr dieses Intervall zu (in den Daten ist dies nur ein weiterer Kanal, in dem der Beginn der f√ºr uns interessanten Ereignisse vermerkt ist). </p><br><p>  In diesem Stadium behalten wir die maximale L√§nge des kontinuierlichen EEG bei, um Kanteneffekte bei der weiteren Filterung zu vermeiden. </p><br><pre> <code class="python hljs">raw_dataset = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _, sessions <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sorted(m_data.items()): eegs, markers = [], [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> item, run <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sorted(sessions[<span class="hljs-string"><span class="hljs-string">'session_1'</span></span>].items()): data = run.get_data() eegs.append(data[:<span class="hljs-number"><span class="hljs-number">-1</span></span>]) markers.append(data[<span class="hljs-number"><span class="hljs-number">-1</span></span>]) raw_dataset.append((eegs, markers))</code> </pre> <br><h2 id="filtraciya-i-razdelenie-na-epohi">  Filterung und Trennung </h2><br><p>  Generell kann ich zur √úberpr√ºfung der Methoden der Vorverarbeitung und Klassifizierung des EEG <a href="https://iopscience.iop.org/article/10.1088/1741-2552/aab2f2/meta">einen hervorragenden √úberblick</a> von den Meistern der Neurocomputer-Interfaces empfehlen.  Ebenfalls vor nicht allzu langer Zeit wurde eine <a href="https://iopscience.iop.org/article/10.1088/1741-2552/ab0ab5">neuere √úbersicht √ºber</a> neuronale Netzwerktests ver√∂ffentlicht. </p><br><p>  Die minimale Vorverarbeitung des EEG-Signals zur Klassifizierung umfasst 3 Schritte: </p><br><ul><li>  Dezimation </li><li>  Filterung </li><li>  Skalierung </li></ul><br><p>  Um diese Schritte zu implementieren, werden wir das gute alte <code>sklearn</code> und sein Paradigma f√ºr Transformatoren und Pipelines verwenden, damit unsere Vorverarbeitung leicht erweiterbar ist. <br>  Der Code des Transformers wird in einer separaten Datei abgelegt. Nachfolgend werden einige Details beschrieben. </p><br><p>  <strong>Dezimation</strong> </p><br><p>  Aus irgendeinem Grund habe ich in einigen Artikeln und Verarbeitungsbeispielen eine Abnahme der Signalfrequenz <code>eeg = eeg[:, ::10]</code> indem ich einfach Samples im Stil <code>eeg = eeg[:, ::10]</code> .  Dies ist v√∂llig falsch (warum - siehe ein Buch √ºber Signalverarbeitung).  Wir verwenden die Standardimplementierung <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.decimate.html"><code>  scipy</code></a> . </p><br><p>  <strong>Filtern</strong> </p><br><p>  Hier verlassen wir uns auch auf <code>scipy</code> Filter, indem wir ein Butterworth-Bandpassfilter 4-Ordnung ausw√§hlen und es in Vorw√§rts- und R√ºckw√§rtsrichtung ( <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.filtfilt.html"><code>filtfilt</code></a> ) <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.filtfilt.html"><code>filtfilt</code></a> , um die Phase aufrechtzuerhalten.  Grenzfrequenzen - von 0,5 bis 20 Hz, das ist der Standardbereich f√ºr unsere Aufgabe. </p><br><p>  <strong>Skalierung</strong> </p><br><p>  Wir haben einen <code>StandardScaler</code> pro Kanal verwendet (subtrahiert den Durchschnitt, dividiert durch die Standardabweichung), der alle Signale aus dem Sample anzeigt.  In der Tat wird an dieser Stelle ein kleines Datenleck eingef√ºhrt.  Formal sieht der Scaler auch Daten aus der Testprobe, aber bei ausreichend gro√üen Datenmengen sind der Mittelwert und die Abweichung gleich. <br>  Die Masturbation wird kanalweise durchgef√ºhrt, sodass es m√∂glich ist, Daten von verschiedenen Sensoren mit unterschiedlichen Gr√∂√üenordnungen und Eigenschaften (z. B. <a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D0%25BB%25D0%25B5%25D0%25BA%25D1%2582%25D1%2580%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D0%25B0%25D0%25BA%25D1%2582%25D0%25B8%25D0%25B2%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C_%25D0%25BA%25D0%25BE%25D0%25B6%25D0%25B8">hautgalvanische Reaktion (RAG)</a> ) innerhalb desselben Datensatzes zu aggregieren. </p><br><p>  Zus√§tzlich zu den oben genannten Operationen konnten auch Artefakte im EEG (Blinken, Kauen, Kopfbewegungen) unterschieden werden. Dieser Datensatz ist jedoch bereits sehr sauber. Lassen Sie ihn also bis zum n√§chsten Mal. </p><br><pre> <code class="python hljs">reload(transformers) decimation_factor = <span class="hljs-number"><span class="hljs-number">10</span></span> final_rate = sampling_rate // decimation_factor epoch_duration = <span class="hljs-number"><span class="hljs-number">0.9</span></span> <span class="hljs-comment"><span class="hljs-comment"># seconds epoch_count = int(epoch_duration * final_rate) eeg_pipe = make_pipeline( transformers.Decimator(decimation_factor), transformers.ButterFilter(sampling_rate // decimation_factor, 4, 0.5, 20), transformers.ChannellwiseScaler(StandardScaler()), ) markers_pipe = transformers.MarkersTransformer(labels_mapping, decimation_factor)</span></span></code> </pre> <br><p>  Als n√§chstes werden wir die Vorverarbeitungs-Pipeline auf unsere Daten anwenden und das kontinuierliche EEG-Signal in Epochen aufteilen.  Wir bezeichnen die Epoche als die Zeitspanne unmittelbar nach der Aktivierung des Stimulus mit einer charakteristischen Dauer von 0,5 bis 1 Sekunde, in unserem Fall betr√§gt die Dauer 900 ms, obwohl sie verk√ºrzt werden kann. </p><br><p>  In unserem Datensatz gibt es 16 EEG-Kan√§le. Nachdem die Dezimierung angewendet wurde, f√§llt die Frequenz auf 50 Hz ab, sodass eine Epoche durch eine Matrix <code>(16, 45)</code> 900 ms bei 50 Hz sind 45 Zeitabtastwerte. </p><br><p>  Die Tags in diesem Datensatz sind nur Bin√§rdateien - sie markieren die Signale des Ziels (vom Player ausgeblendet, aktiv, 1) und des Nichtziels (leer, 0). </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> eegs, _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> raw_dataset: eeg_pipe.fit(eegs) dataset = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> eegs, markers <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> raw_dataset: epochs = [] labels = [] filtered = eeg_pipe.transform(eegs) markups = markers_pipe.transform(markers) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> signal, markup <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(filtered, markups): epochs.extend([signal[:, start:(start + epoch_count)] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> start <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> markup[:, <span class="hljs-number"><span class="hljs-number">0</span></span>]]) labels.extend(markup[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]) dataset.append((np.array(epochs), np.array(labels)))</code> </pre> <br><pre> <code class="python hljs">dataset[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>].shape, dataset[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>].shape <span class="hljs-comment"><span class="hljs-comment"># ((1308, 16, 45), (1308,))</span></span></code> </pre> <br><p>  Wir haben also einen <code>Pytorch</code> im Pytorch-Stil, in dem der erste Index verschiedene Personen z√§hlt.  Mit dieser Struktur k√∂nnen wir beide eine Kreuzvalidierung innerhalb der Daten einer Person durchf√ºhren und die Toleranz des Klassifikators zwischen verschiedenen Personen testen (sogenanntes Transferlernen, kalibrierungslose Vorhersage).  Die Daten einer Person bestehen aus einer Reihe von Epochen und Klassenbezeichnungen.  Die Anzahl der Epochen f√ºr jede Person variiert geringf√ºgig aufgrund der Eigenschaften der Aufnahme. </p><br><h2 id="issledovanie-i-vizualizaciya-dannyh">  Datenrecherche und Visualisierung </h2><br><p>  Schauen Sie sich zun√§chst eines der kontinuierlichen Signale an, bevor Sie in Epochen aufteilen. </p><br><p>  Trotz der Tatsache, dass es bereits herausgefiltert wurde, zeigt es keine Aktivierungen am Auge und sieht eher wie eine Art Ger√§usch aus. </p><br><p><img src="https://habrastorage.org/webt/mb/xy/js/mbxyjsh7g4ch3an8smi2wtpujpw.png" alt="Gefiltertes EEG-Signal eines Durchlaufs des Spiels"></p><br><p>  Wenn wir nur eine Zielepoche aus unserem Datensatz betrachten, sehen wir einen charakteristischen Anstieg im Intervall von 400 bis 600 ms.  Dies ist unser gesuchtes Potenzial P300. </p><br><p><img src="https://habrastorage.org/webt/eu/v9/k-/euv9k-t6w0nss44m2fnvt_mrhxs.png" alt="p300 epoche"></p><br><p>  Insgesamt gibt es in unserem Datensatz ungef√§hr 35.000 Epochen, dh Stimulusaktivierung.  Jede Person hat ungef√§hr 1300 bis 1750 (dies liegt an der Tatsache, dass jemand Aliens schneller und jemand langsamer abgeschossen hat). </p><br><p>  Es gibt auch ein merkliches Ungleichgewicht in den Klassen: 1 bis 5 zugunsten leerer Reize.  Wir haben 6 Zeilen und Spalten in der Matrix und nur eine davon ist das Ziel.  Wir werden sp√§ter darauf zur√ºckkommen, wenn wir die erhaltenen Metriken diskutieren. </p><br><p><img src="https://habrastorage.org/webt/ed/7n/jb/ed7njbim3sdcge3lpb-_ll8ucls.png" alt="Klassenbalance"></p><br><p>  Jetzt ist es Zeit, den Unterschied zwischen dem Zielsignal und dem Nichtziel zu untersuchen </p><br><p><img src="https://habrastorage.org/webt/c5/tx/oa/c5txoadzfwl8qzg8t-29siuftnw.png" alt="Dataset Mean Response"></p><br><p>  In der linken Grafik k√∂nnen Sie sehen, dass die durchschnittlichen Signale sehr unterschiedlich sind und beide eine unspezifische Reaktion im Bereich von 180 ms haben, aber die Zielamplitude ist viel gr√∂√üer, das Ziel hat auch einen charakteristischen Buckel von 250 bis 500 ms - dies ist der ber√ºchtigte P300. </p><br><p>  Bei einem solchen Unterschied im Signal mag unsere Aufgabe wie eine Kleinigkeit erscheinen, aber wenn wir die Standardabweichung an jedem Punkt zur Grafik hinzuf√ºgen, werden wir sehen, dass das Bild nicht so rosig ist - das Signal ist ziemlich verrauscht.  Und dies trotz der Tatsache, dass das Signal-Rausch-Verh√§ltnis f√ºr den P300 als eines der h√∂chsten in der Neurophysiologie gilt. </p><br><p>  (Tats√§chlich sind diese Graphen nicht ganz ehrlich aufgebaut, da das Leersignal √ºber f√ºnfmal so viele verschiedene Abtastwerte gemittelt wird, sodass zuf√§llige Abweichungen st√§rker gedrosselt werden. Wie wir jedoch an der Streuung derselben Reihenfolge erkennen k√∂nnen, hilft dies nicht allzu viel.) </p><br><p><img src="https://habrastorage.org/webt/7b/nw/hw/7bnwhwdx7xrbkvwgqiw9jc5um5g.png" alt="Mittlere Antwort der Person"></p><br><p>  Es ist auch n√ºtzlich, die durchschnittlichen Signale einer Person zu betrachten. </p><br><p>  Hier findet sich die bisherige Bemerkung zur ‚Äûunehrlichen‚Äú Mittelung - das Leersignal ist sp√ºrbar amplitudenst√§rker als bei der Mittelung √ºber alles.  Au√üerdem ist der Peak von P300 bei einer Person h√∂her, da weniger gemittelt wird. </p><br><p>  Es ist wichtig, ein anderes Merkmal des Signals einer Person zu beachten - es hat eine etwas andere Form als das generalisierte.  Die zwischenmenschliche Variabilit√§t der neurophysiologischen Reaktionen ist recht hoch, wir werden den Einfluss dieses Faktors in der Arbeit der Klassifikatoren noch sehen.  Intrapersonale Unterschiede (eine Person in einer anderen Stimmung, Stresslevel, M√ºdigkeit) sind jedoch auch ziemlich gro√ü. </p><br><p><img src="https://habrastorage.org/webt/jt/kj/sj/jtkjsjbgmym86-unjyshdxgtd80.png" alt="png"></p><br><p>  Als n√§chstes sehen wir den kanalweisen Sweep der Signale.  Die Sichtweise hier stimmt mit dem obigen Bild √ºberein, das die Position der Elektroden zeigt - Nase oben usw. </p><br><p>  Die Reaktion jedes Teils des Kopfes ist unterschiedlich.  Bei Fp1,2 sind zwei negative Peaks vor dem positiven Peak ausgepr√§gt.  Au√üerdem gibt es in einigen Kan√§len zwei positive Peaks und in einigen einen oder einen √úbergang zwischen diesen. </p><br><p>  Verschiedene Kan√§le sind f√ºr die Bestimmung des Vorhandenseins von P300 von unterschiedlicher Bedeutung. Sie k√∂nnen mithilfe verschiedener Methoden gesch√§tzt werden - Berechnung der gegenseitigen Information (gegenseitige Information) oder Add-Delete-Methode (auch bekannt als schrittweise Regression).  Die Anwendung dieser Methoden werden wir zu einem anderen Zeitpunkt behandeln. </p><br><p>  Es sei daran erinnert, dass wir die Potentialdifferenz zwischen den Elektroden mit Elektroden messen, was bedeutet, dass wir zu bestimmten Zeitpunkten Spannungskarten f√ºr den gesamten Kopf unter Verwendung von Spannungs√§nderungen an einzelnen Punkten erstellen k√∂nnen.  Es ist klar, dass, wenn es 16 Elektroden gibt, die Genauigkeit einer solchen Karte sehr zu w√ºnschen √ºbrig l√§sst, aber ein gewisses Verst√§ndnis sollte hergestellt werden.  ( <code>mne</code> erwartet standardm√§√üig Mikrovolt, aber die Skalierung wurde bereits angewendet, sodass die absoluten Werte nicht korrekt sind.) </p><br><p><img src="https://habrastorage.org/webt/zq/2y/kz/zq2ykzbpc6oxqz2woyizwuswod4.png" alt="png"></p><br><p><img src="https://habrastorage.org/webt/l5/xn/iy/l5xniylmkybexkk6cym8dbhrmjq.png" alt="png"></p><br><h2 id="klassifikaciya">  Klassifizierung </h2><br><p>  Schlie√ülich ist es Zeit, maschinelle Lernmethoden auf unsere Stichprobe anzuwenden. </p><br><p>  Mehrere grundlegende wurden als Klassifikatoren ausgew√§hlt - ein Protokoll.  Regression, die Support-Vektor-Methode (SVM) und mehrere Methoden unter Verwendung der Korrelationsanalyse aus dem <a href="https://github.com/alexandrebarachant/pyRiemann"><code>pyriemann</code></a> Paket (Details zu den einzelnen Methoden finden Sie in der Dokumentation). Es ist anzumerken, dass diese Methoden speziell f√ºr die Anwendung im EEG entwickelt wurden und mit ihrer Hilfe <a href="https://www.kaggle.com/c/inria-bci-challenge/discussion/12819">mehrere</a> <a href="https://www.kaggle.com/c/grasp-and-lift-eeg-detection/discussion/16479">Wettbewerbe gewonnen</a> wurden kaggle. </p><br><pre> <code class="python hljs">clfs = { <span class="hljs-string"><span class="hljs-string">'LR'</span></span>: ( make_pipeline(Vectorizer(), LogisticRegression()), {<span class="hljs-string"><span class="hljs-string">'logisticregression__C'</span></span>: np.exp(np.linspace(<span class="hljs-number"><span class="hljs-number">-4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>))}, ), <span class="hljs-string"><span class="hljs-string">'LDA'</span></span>: ( make_pipeline(Vectorizer(), LDA(shrinkage=<span class="hljs-string"><span class="hljs-string">'auto'</span></span>, solver=<span class="hljs-string"><span class="hljs-string">'eigen'</span></span>)), {}, ), <span class="hljs-string"><span class="hljs-string">'SVM'</span></span>: ( make_pipeline(Vectorizer(), SVC()), {<span class="hljs-string"><span class="hljs-string">'svc__C'</span></span>: np.exp(np.linspace(<span class="hljs-number"><span class="hljs-number">-4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>))}, ), <span class="hljs-string"><span class="hljs-string">'CSP LDA'</span></span>: ( make_pipeline(CSP(), LDA(shrinkage=<span class="hljs-string"><span class="hljs-string">'auto'</span></span>, solver=<span class="hljs-string"><span class="hljs-string">'eigen'</span></span>)), {<span class="hljs-string"><span class="hljs-string">'csp__n_components'</span></span>: (<span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>, <span class="hljs-number"><span class="hljs-number">13</span></span>), <span class="hljs-string"><span class="hljs-string">'csp__cov_est'</span></span>: (<span class="hljs-string"><span class="hljs-string">'concat'</span></span>, <span class="hljs-string"><span class="hljs-string">'epoch'</span></span>)}, ), <span class="hljs-string"><span class="hljs-string">'Xdawn LDA'</span></span>: ( make_pipeline(Xdawn(<span class="hljs-number"><span class="hljs-number">2</span></span>, classes=[<span class="hljs-number"><span class="hljs-number">1</span></span>]), Vectorizer(), LDA(shrinkage=<span class="hljs-string"><span class="hljs-string">'auto'</span></span>, solver=<span class="hljs-string"><span class="hljs-string">'eigen'</span></span>)), {}, ), <span class="hljs-string"><span class="hljs-string">'ERPCov TS LR'</span></span>: ( make_pipeline(ERPCovariances(estimator=<span class="hljs-string"><span class="hljs-string">'oas'</span></span>), TangentSpace(), LogisticRegression()), {<span class="hljs-string"><span class="hljs-string">'erpcovariances__estimator'</span></span>: (<span class="hljs-string"><span class="hljs-string">'lwf'</span></span>, <span class="hljs-string"><span class="hljs-string">'oas'</span></span>)}, ), <span class="hljs-string"><span class="hljs-string">'ERPCov MDM'</span></span>: ( make_pipeline(ERPCovariances(), MDM()), {<span class="hljs-string"><span class="hljs-string">'erpcovariances__estimator'</span></span>: (<span class="hljs-string"><span class="hljs-string">'lwf'</span></span>, <span class="hljs-string"><span class="hljs-string">'oas'</span></span>)}, ), }</code> </pre> <br><p><img src="https://habrastorage.org/webt/3x/yb/qc/3xybqcusgidyxfs5lfcilxqn-gs.png" alt="Kreuzvalidierungssatz"></p><br><p>  Das gebr√§uchlichste Schema neuronaler Schnittstellen ist "Kalibrierung + Arbeit", d.h.  Zun√§chst ist es notwendig, dass sich eine Person f√ºr einige Zeit auf die zuvor angegebenen Reize konzentriert, und erst danach sagen wir ihre Wahl voraus.  Dieser Ansatz hat den offensichtlichen Nachteil eines langweiligen Anfangsstadiums. </p><br><p>  Um die Leistung unserer Methoden in diesem Modus zu bewerten, f√ºhren wir eine Kreuzvalidierung innerhalb einer Person durch. <br>  Die Genauigkeitsmetrik ist in diesem Fall aufgrund des Ungleichgewichts des Datensatzes nicht relevant (die Grundlinie hier ist 5/6 ~ 83%), daher ziehe ich es vor, die Genauigkeits-R√ºckruf-f1 drei zu betrachten. </p><br><p>  Um den gesamten Datensatz zu √ºberpr√ºfen, werden die Ergebnisse einer solchen Kreuzvalidierung √ºber alle Personen gemittelt.  Im Allgemeinen ist die Leistung der besten Modelle ziemlich hoch im Vergleich zu dem, was wir bei <a href="https://impulse-neiry.com/">Neiry</a> unter den "Feldbedingungen" eines Vergn√ºgungsparks haben (ich erinnere mich, dass dieser Datensatz im Labor aufgezeichnet wurde). </p><br><p>  In diesem Datensatz gibt es nur bin√§re Bezeichnungen f√ºr die Daten.  Im Allgemeinen m√ºssen wir das Mehrklassenproblem der Auswahl eines der Stimuli l√∂sen (√ºbrigens ist es ausgeglichen, da jeder Stimulus gleich oft aktiviert wird).  Um dies zu l√∂sen, wird normalerweise die Anzahl der Aktivierungen jedes Stimulus festgelegt (z. B. 6 Stimuli mit jeweils 5 Aktivierungen), und alle Stimuli werden zuf√§llig aktiviert (30-mal), 30 Epochen werden erhalten und die Wahrscheinlichkeiten seiner Aktivierungen werden addiert, um gezielt zu sein, wonach der Stimulus das Maximum erreicht hat der betrag wird als ziel anerkannt.  Wir werden die Umsetzung dieses Ansatzes in einem zuk√ºnftigen Beitrag an einem geeigneten Datensatz demonstrieren. </p><br><p><img src="https://habrastorage.org/webt/zx/-o/lm/zx-olmert9y5wdjpebgqa1dy8zm.png" alt="crossvalidate_dataset"></p><br><p>  Das zweite Schema nennt sich Transferlernen - also die √úbertragung des Klassifikators zwischen Personen.  Tatsache ist, dass wir bei der Kalibrierung tats√§chlich zur Peakform einer Person zur√ºckkehren, sodass wir dies in nachfolgenden Tests gut vorhersagen k√∂nnen.  Ohne Kalibrierung sollte ein vorab geschulter Klassifikator in der Lage sein, das P300-Konzept zu isolieren, ohne die Wellenform einer bestimmten Person im Voraus zu kennen. </p><br><p>  Wir werden zwei Experimente durchf√ºhren - wir werden den Klassifikator auf eine Person trainieren, und wir werden f√ºnf vorhersagen, und dann werden wir die Trainingsstichprobe auf 10 Personen erh√∂hen und die Ergebnisse vergleichen, um sicherzustellen, dass die Modelle in der Lage sind, ihre Verallgemeinerungsf√§higkeit zu erh√∂hen </p><br><p>  Training f√ºr 1 Person <br><img src="https://habrastorage.org/webt/fk/n5/5w/fkn55wh6yl7hfpjtjrqesq8gm8e.png" alt="transfer_validate_1"></p><br><p>  Training f√ºr 10 Personen <br><img src="https://habrastorage.org/webt/in/ol/kq/inolkqy3-fezzcavmstah4vwhic.png" alt="transfer_valiidate_10"></p><br><p>  Also stieg f1 f√ºr einen besseren Klassifikator von 0,23 auf 0,4 (in beiden F√§llen handelt es sich um eine logarithmische Regression mit derselben Regularisierung). </p><br><p>  Dies bedeutet, dass die Vorhersagef√§higkeit von "nein" auf "akzeptabel" angestiegen ist.  Basierend auf unserer Erfahrung reichen mit solchen bin√§ren Aufgabenmetriken 5 Aktivierungen jedes Stimulus aus, um die Genauigkeit eines Mehrklassenproblems von etwa 75% zu erreichen. </p><br><p>  Abschlie√üend m√∂chte ich darauf hinweisen, dass die obige Methode ziemlich primitiv ist, was zum Beispiel am hohen Grad der Regularisierung der logarithmischen Regression zu erkennen ist - die Kan√§le in den Daten sind ziemlich stark korreliert und es gibt verschiedene Ans√§tze, um diesen Umstand zu l√∂sen. </p><br><h2 id="zaklyuchenie">  Fazit </h2><br><p>  Heute haben wir uns mit dem hervorgerufenen Potenzial des P300 vertraut gemacht und eine einfache Pipeline f√ºr die neuronale Schnittstelle erstellt.  Ich empfehle Interessenten, einen eigenen Laptop (im <a href="https://gitlab.com/impulse-neiry_public/posts">Repository</a> ) zu √∂ffnen und mit Visualisierungsoptionen und Klassifikatoren zu experimentieren. </p><br><p>  Mit einem grundlegenden Verst√§ndnis der Arbeitsweise mit dem EEG-Signal k√∂nnen wir dieses Thema vertiefen - um fortgeschrittene Vorverarbeitungsmethoden sowie neuronale Netze anzuwenden und die Probleme beim Aufbau neuronaler Schnittstellen zu l√∂sen.  Fortsetzung folgt... </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de480060/">https://habr.com/ru/post/de480060/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de480048/index.html">Entmystifizierung des neuen .NET Core 3 Worker Service</a></li>
<li><a href="../de480050/index.html">Feldstudien zum Konzept ‚ÄûDokumentation als Code‚Äú</a></li>
<li><a href="../de480052/index.html">SEO vs. PPC - Was ist besser f√ºr Ihr Unternehmen?</a></li>
<li><a href="../de480056/index.html">Versteckte Kameraaktivierung durch Browser: Big Brother oder Technologie-Fehleinsch√§tzung?</a></li>
<li><a href="../de480058/index.html">Transformatorstern auf dem Weihnachtsbaum</a></li>
<li><a href="../de480062/index.html">10 Steuersysteme. Wo ist es bequemer, √ºber Aufgaben zu kommunizieren und Dateien zu teilen?</a></li>
<li><a href="../de480064/index.html">W√∂rter thematisch gruppiert lernen</a></li>
<li><a href="../de480068/index.html">[Update] Unsere Leute sind geschlagen, und wir werden schweigen?</a></li>
<li><a href="../de480070/index.html">Vorteile reagieren: Ein Segen f√ºr Unternehmen?</a></li>
<li><a href="../de480072/index.html">Kubernetes: Warum ist es so wichtig, ein Systemressourcenmanagement einzurichten?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
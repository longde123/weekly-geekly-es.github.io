<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🍉 🔺 👨‍🎨 Einfacher P300-Klassifikator für offene Daten ◽️ 👨 🙌🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mein Kollege Rafael Grigoryan eegdude schrieb kürzlich einen Artikel darüber, warum die Menschheit ein EEG benötigt und welche signifikanten Phänomene...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Einfacher P300-Klassifikator für offene Daten</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/480060/"><p>  Mein Kollege Rafael Grigoryan <a href="https://habr.com/ru/users/eegdude/" class="user_link">eegdude</a> <a href="https://m.habr.com/ru/post/479164/">schrieb kürzlich</a> einen Artikel darüber, warum die Menschheit ein EEG benötigt und welche signifikanten Phänomene darin aufgezeichnet werden können.  In Fortsetzung des Themas der neuronalen Schnittstellen verwenden wir heute einen der offenen Datensätze, die in einem Spiel mithilfe der P300-Mechanik aufgezeichnet wurden, um das EEG-Signal zu visualisieren, die Struktur der aufgerufenen Potentiale zu sehen, die Hauptklassifikatoren zu konstruieren und die Qualität zu bewerten, mit der wir das Vorhandensein eines solchen aufgerufenen Potentials vorhersagen können. </p><br><p>  Lassen Sie mich daran erinnern, dass P300 ein sogenanntes Potential (VP) ist, eine spezifische Reaktion des Gehirns, die mit der Entscheidungsfindung und der Unterscheidung von Reizen verbunden ist (die wir unten sehen werden).  Es wird normalerweise verwendet, um modernes BCI zu bauen. </p><br><p><img src="https://habrastorage.org/webt/l5/xn/iy/l5xniylmkybexkk6cym8dbhrmjq.png"></p><br><p>  Um die EEG-Klassifizierung durchzuführen, können Sie Freunde anrufen, ein Spiel über Waschbären und Dämonen in VR schreiben, Ihre eigenen Reaktionen aufschreiben und einen wissenschaftlichen Artikel schreiben (darüber werde ich ein andermal sprechen), aber glücklicherweise Wissenschaftler aus der ganzen Welt einige Experimente für uns durchgeführt und es bleibt nur die Daten herunterzuladen. </p><br><p>  Eine Analyse zum Erstellen einer neuronalen Schnittstelle auf dem P300 mit schrittweisen Codes und Visualisierungen sowie einem Link zum Repository finden Sie unter der Katze. </p><a name="habracut"></a><br><p>  Der Artikel zeigt nur die wichtigsten Punkte aus dem Code, die voll reproduzierbare Version in Jupyter Notebook <a href="https://gitlab.com/impulse-neiry_public/posts">, um hier zu suchen</a> </p><br><p>  Aus Sicht eines EEG ist der P300 in bestimmten Kanälen nur ein Burst zu einer bestimmten Zeit.  Es gibt viele Möglichkeiten, es aufzurufen, zum Beispiel, wenn Sie sich auf ein Objekt konzentrieren und es zu einem zufälligen Zeitpunkt aktiviert wird (Form, Farbe, Helligkeit ändern oder irgendwo abspringen).  So wurde es in der Antike implementiert. </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wKDimrzvwYA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Im Allgemeinen lautet das Schema wie folgt: Es gibt mehrere (normalerweise 3 bis 7) Reize im Gesichtsfeld einer Person.  Eine Person wählt eine davon aus und konzentriert sich darauf (eine gute Methode ist es, die Anzahl der Aktivierungen zu zählen). Dann blinkt jedes Objekt in zufälliger Reihenfolge.  Wenn wir die Aktivierungszeit jedes Stimulus kennen, können wir jetzt das nächste EEG betrachten und feststellen, ob es einen charakteristischen Peak enthält (wir werden ihn in den folgenden Visualisierungen sehen).  Da sich die Person nur auf einen Stimulus konzentriert hat, sollte der Peak einer sein.  Daher wird in diesen neuronalen Schnittstellen eine von mehreren Optionen ausgewählt (Buchstaben zum Schreiben, Aktionen im Spiel und Gott weiß, was sonst noch).  Wenn es mehr als sieben Optionen gibt, können Sie sie in das Raster einfügen und die Aufgabe auf die Auswahl einer Zeile + Spalte reduzieren.  So sieht der oben gezeigte klassische Matrix-P300-Speller aus. </p><br><p>  Im Falle des heute betrachteten Datensatzes wurde der visuelle Teil (sowie der Name) von den berühmten Game <a href="https://en.wikipedia.org/wiki/Space_Invaders">Space Invidern ausgeliehen</a> .  Es sah ungefähr so ​​aus </p><br><p><img src="https://habrastorage.org/webt/xg/yb/du/xgybdulftmr0dpr4muypl7avlro.png" alt="Das Gameplay von Brain Inviders"></p><br><p>  In der Tat ist dies der gleiche Buchstabierer, nur die Buchstaben werden durch Außerirdische ersetzt. <br>  Das <a href="https://www.youtube.com/watch%3Fv%3Ds73l8ZfQcWw">Video des Spielprozesses</a> und die <a href="https://arxiv.org/ftp/arxiv/papers/1905/1905.05182.pdf">technischen Berichte wurden</a> ebenfalls beibehalten. </p><br><p>  Auf die eine oder andere Weise sind die mit diesem Spiel gesammelten Daten im Internet erschienen und wir können auf sie zugreifen.  Die Daten bestehen aus 16 EEG-Kanälen und einem Ereigniskanal, die anzeigen, zu welchem ​​Zeitpunkt das (vom Spieler erstellte) Ziel und die nicht zum Ziel gehörenden Anreize aktiviert wurden. Wir werden mit ihnen arbeiten. </p><br><p> Die meisten Datensätze für BCI wurden von Neurophysiologen aufgezeichnet, und das sind Leute, die sich nicht wirklich für Kompatibilität interessieren, daher sind die Datenformate sehr unterschiedlich: von verschiedenen Versionen der <code>.mat</code> Dateien bis zu den "Standard" -Formaten <a href="https://en.wikipedia.org/wiki/European_Data_Format"><code>.edf</code></a> und <a href="https://en.wikipedia.org/wiki/General_Data_Format_for_Biomedical_Signals"><code>.gdf</code></a> . <br>  Das Wichtigste, was Sie über diese Formate wissen müssen, ist, dass Sie sie nicht analysieren oder direkt damit arbeiten möchten. <br>  Glücklicherweise hat eine Gruppe von Enthusiasten von <a href="https://neurotechx.com/">NeuroTechX</a> Downloader für einige Datensätze direkt in Zahlen geschrieben. <br>  Diese Bootloader sind Teil des <a href="https://github.com/NeuroTechX/moabb/tree/master/moabb">moabb-</a> Projekts, das behauptet, eine universelle Lösung für BCI zu sein. </p><br><h2 id="zagruzka-syrogo-dataseta">  Rohdatensatz herunterladen </h2><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> moabb.datasets sampling_rate = <span class="hljs-number"><span class="hljs-number">512</span></span> m_dataset = moabb.datasets.bi2013a( NonAdaptive=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, Adaptive=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, Training=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, Online=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, ) m_dataset.download() m_data = m_dataset.get_data()</code> </pre> <br><p>  Zu diesem Zeitpunkt haben wir eine <a href="https://mne.tools/stable/generated/mne.io.Raw.html">RawEDF-</a> Struktur erhalten, die EEG-Aufzeichnungen enthält.  Dies ist eine Struktur aus dem <a href="https://mne.tools/stable/index.html"><code>mne</code></a> Paket, die Biologen normalerweise zur Interaktion mit Signalen verwenden: Diese Struktur verfügt über integrierte Methoden zum Filtern, Visualisieren und Speichern von Etiketten, und Sie wissen es nie.  Aber wir werden diesen Weg seitdem nicht mehr gehen  Die Paketschnittstelle ist in der Regel instabil (die aktuelle Version ist <code>0.19</code> , wir verwenden jedoch <code>0.17</code> da der Datensatz von der neuen Version nicht mehr gelesen wird) und schlecht dokumentiert. Dadurch können unsere Ergebnisse möglicherweise nicht mehr reproduzierbar werden. </p><br><p>  Was wir aus der resultierenden Struktur entnehmen, sind die Kanalbezeichnungen im <a href="https://en.wikipedia.org/wiki/10%25E2%2580%259320_system_(EEG)">10-20-System</a> .  Hierbei handelt es sich um eine internationale Anordnung von Elektroden am Kopf einer Person, mit deren Hilfe Wissenschaftler Gehirnzonen und EEG-Kanalpositionen korrelieren können.  Unten sehen Sie die Anordnung der Elektroden im 10-10-System (unterscheidet sich von 10-20 durch die doppelte Markierungsdichte) und die Kanäle, die in diesem Datensatz aufgezeichnet wurden, sind rot markiert. <br><img src="https://habrastorage.org/webt/j0/x0/uq/j0x0uq27-vjl277bgamcuuz3qpy.jpeg" alt="System 10-10"></p><br><pre> <code class="python hljs">print(m_data[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-string"><span class="hljs-string">'session_1'</span></span>][<span class="hljs-string"><span class="hljs-string">'run_1'</span></span>]) <span class="hljs-comment"><span class="hljs-comment"># &lt;RawEDF | 1.gdf, n_channels x n_times : 17 x 159232 (311.0 sec), ~20.7 MB, data loaded&gt; channels = m_data[1]['session_1']['run_1'].ch_names[:-1] channels # ['FP1', 'FP2', 'F5', 'AFz', 'F6', 'T7', 'Cz', 'T8', 'P7', 'P3', 'Pz', 'P4', 'P8', 'O1', 'Oz', 'O2']</span></span></code> </pre><br><p>  Zunächst ordnen wir aus den heruntergeladenen Daten für jedes Subjekt 16 Sekunden lang Arrays mit kontinuierlichem EEG und alle Labels für dieses Intervall zu (in den Daten ist dies nur ein weiterer Kanal, in dem der Beginn der für uns interessanten Ereignisse vermerkt ist). </p><br><p>  In diesem Stadium behalten wir die maximale Länge des kontinuierlichen EEG bei, um Kanteneffekte bei der weiteren Filterung zu vermeiden. </p><br><pre> <code class="python hljs">raw_dataset = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _, sessions <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sorted(m_data.items()): eegs, markers = [], [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> item, run <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sorted(sessions[<span class="hljs-string"><span class="hljs-string">'session_1'</span></span>].items()): data = run.get_data() eegs.append(data[:<span class="hljs-number"><span class="hljs-number">-1</span></span>]) markers.append(data[<span class="hljs-number"><span class="hljs-number">-1</span></span>]) raw_dataset.append((eegs, markers))</code> </pre> <br><h2 id="filtraciya-i-razdelenie-na-epohi">  Filterung und Trennung </h2><br><p>  Generell kann ich zur Überprüfung der Methoden der Vorverarbeitung und Klassifizierung des EEG <a href="https://iopscience.iop.org/article/10.1088/1741-2552/aab2f2/meta">einen hervorragenden Überblick</a> von den Meistern der Neurocomputer-Interfaces empfehlen.  Ebenfalls vor nicht allzu langer Zeit wurde eine <a href="https://iopscience.iop.org/article/10.1088/1741-2552/ab0ab5">neuere Übersicht über</a> neuronale Netzwerktests veröffentlicht. </p><br><p>  Die minimale Vorverarbeitung des EEG-Signals zur Klassifizierung umfasst 3 Schritte: </p><br><ul><li>  Dezimation </li><li>  Filterung </li><li>  Skalierung </li></ul><br><p>  Um diese Schritte zu implementieren, werden wir das gute alte <code>sklearn</code> und sein Paradigma für Transformatoren und Pipelines verwenden, damit unsere Vorverarbeitung leicht erweiterbar ist. <br>  Der Code des Transformers wird in einer separaten Datei abgelegt. Nachfolgend werden einige Details beschrieben. </p><br><p>  <strong>Dezimation</strong> </p><br><p>  Aus irgendeinem Grund habe ich in einigen Artikeln und Verarbeitungsbeispielen eine Abnahme der Signalfrequenz <code>eeg = eeg[:, ::10]</code> indem ich einfach Samples im Stil <code>eeg = eeg[:, ::10]</code> .  Dies ist völlig falsch (warum - siehe ein Buch über Signalverarbeitung).  Wir verwenden die Standardimplementierung <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.decimate.html"><code>  scipy</code></a> . </p><br><p>  <strong>Filtern</strong> </p><br><p>  Hier verlassen wir uns auch auf <code>scipy</code> Filter, indem wir ein Butterworth-Bandpassfilter 4-Ordnung auswählen und es in Vorwärts- und Rückwärtsrichtung ( <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.filtfilt.html"><code>filtfilt</code></a> ) <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.filtfilt.html"><code>filtfilt</code></a> , um die Phase aufrechtzuerhalten.  Grenzfrequenzen - von 0,5 bis 20 Hz, das ist der Standardbereich für unsere Aufgabe. </p><br><p>  <strong>Skalierung</strong> </p><br><p>  Wir haben einen <code>StandardScaler</code> pro Kanal verwendet (subtrahiert den Durchschnitt, dividiert durch die Standardabweichung), der alle Signale aus dem Sample anzeigt.  In der Tat wird an dieser Stelle ein kleines Datenleck eingeführt.  Formal sieht der Scaler auch Daten aus der Testprobe, aber bei ausreichend großen Datenmengen sind der Mittelwert und die Abweichung gleich. <br>  Die Masturbation wird kanalweise durchgeführt, sodass es möglich ist, Daten von verschiedenen Sensoren mit unterschiedlichen Größenordnungen und Eigenschaften (z. B. <a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D0%25BB%25D0%25B5%25D0%25BA%25D1%2582%25D1%2580%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D0%25B0%25D0%25BA%25D1%2582%25D0%25B8%25D0%25B2%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C_%25D0%25BA%25D0%25BE%25D0%25B6%25D0%25B8">hautgalvanische Reaktion (RAG)</a> ) innerhalb desselben Datensatzes zu aggregieren. </p><br><p>  Zusätzlich zu den oben genannten Operationen konnten auch Artefakte im EEG (Blinken, Kauen, Kopfbewegungen) unterschieden werden. Dieser Datensatz ist jedoch bereits sehr sauber. Lassen Sie ihn also bis zum nächsten Mal. </p><br><pre> <code class="python hljs">reload(transformers) decimation_factor = <span class="hljs-number"><span class="hljs-number">10</span></span> final_rate = sampling_rate // decimation_factor epoch_duration = <span class="hljs-number"><span class="hljs-number">0.9</span></span> <span class="hljs-comment"><span class="hljs-comment"># seconds epoch_count = int(epoch_duration * final_rate) eeg_pipe = make_pipeline( transformers.Decimator(decimation_factor), transformers.ButterFilter(sampling_rate // decimation_factor, 4, 0.5, 20), transformers.ChannellwiseScaler(StandardScaler()), ) markers_pipe = transformers.MarkersTransformer(labels_mapping, decimation_factor)</span></span></code> </pre> <br><p>  Als nächstes werden wir die Vorverarbeitungs-Pipeline auf unsere Daten anwenden und das kontinuierliche EEG-Signal in Epochen aufteilen.  Wir bezeichnen die Epoche als die Zeitspanne unmittelbar nach der Aktivierung des Stimulus mit einer charakteristischen Dauer von 0,5 bis 1 Sekunde, in unserem Fall beträgt die Dauer 900 ms, obwohl sie verkürzt werden kann. </p><br><p>  In unserem Datensatz gibt es 16 EEG-Kanäle. Nachdem die Dezimierung angewendet wurde, fällt die Frequenz auf 50 Hz ab, sodass eine Epoche durch eine Matrix <code>(16, 45)</code> 900 ms bei 50 Hz sind 45 Zeitabtastwerte. </p><br><p>  Die Tags in diesem Datensatz sind nur Binärdateien - sie markieren die Signale des Ziels (vom Player ausgeblendet, aktiv, 1) und des Nichtziels (leer, 0). </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> eegs, _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> raw_dataset: eeg_pipe.fit(eegs) dataset = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> eegs, markers <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> raw_dataset: epochs = [] labels = [] filtered = eeg_pipe.transform(eegs) markups = markers_pipe.transform(markers) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> signal, markup <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(filtered, markups): epochs.extend([signal[:, start:(start + epoch_count)] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> start <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> markup[:, <span class="hljs-number"><span class="hljs-number">0</span></span>]]) labels.extend(markup[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]) dataset.append((np.array(epochs), np.array(labels)))</code> </pre> <br><pre> <code class="python hljs">dataset[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>].shape, dataset[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">1</span></span>].shape <span class="hljs-comment"><span class="hljs-comment"># ((1308, 16, 45), (1308,))</span></span></code> </pre> <br><p>  Wir haben also einen <code>Pytorch</code> im Pytorch-Stil, in dem der erste Index verschiedene Personen zählt.  Mit dieser Struktur können wir beide eine Kreuzvalidierung innerhalb der Daten einer Person durchführen und die Toleranz des Klassifikators zwischen verschiedenen Personen testen (sogenanntes Transferlernen, kalibrierungslose Vorhersage).  Die Daten einer Person bestehen aus einer Reihe von Epochen und Klassenbezeichnungen.  Die Anzahl der Epochen für jede Person variiert geringfügig aufgrund der Eigenschaften der Aufnahme. </p><br><h2 id="issledovanie-i-vizualizaciya-dannyh">  Datenrecherche und Visualisierung </h2><br><p>  Schauen Sie sich zunächst eines der kontinuierlichen Signale an, bevor Sie in Epochen aufteilen. </p><br><p>  Trotz der Tatsache, dass es bereits herausgefiltert wurde, zeigt es keine Aktivierungen am Auge und sieht eher wie eine Art Geräusch aus. </p><br><p><img src="https://habrastorage.org/webt/mb/xy/js/mbxyjsh7g4ch3an8smi2wtpujpw.png" alt="Gefiltertes EEG-Signal eines Durchlaufs des Spiels"></p><br><p>  Wenn wir nur eine Zielepoche aus unserem Datensatz betrachten, sehen wir einen charakteristischen Anstieg im Intervall von 400 bis 600 ms.  Dies ist unser gesuchtes Potenzial P300. </p><br><p><img src="https://habrastorage.org/webt/eu/v9/k-/euv9k-t6w0nss44m2fnvt_mrhxs.png" alt="p300 epoche"></p><br><p>  Insgesamt gibt es in unserem Datensatz ungefähr 35.000 Epochen, dh Stimulusaktivierung.  Jede Person hat ungefähr 1300 bis 1750 (dies liegt an der Tatsache, dass jemand Aliens schneller und jemand langsamer abgeschossen hat). </p><br><p>  Es gibt auch ein merkliches Ungleichgewicht in den Klassen: 1 bis 5 zugunsten leerer Reize.  Wir haben 6 Zeilen und Spalten in der Matrix und nur eine davon ist das Ziel.  Wir werden später darauf zurückkommen, wenn wir die erhaltenen Metriken diskutieren. </p><br><p><img src="https://habrastorage.org/webt/ed/7n/jb/ed7njbim3sdcge3lpb-_ll8ucls.png" alt="Klassenbalance"></p><br><p>  Jetzt ist es Zeit, den Unterschied zwischen dem Zielsignal und dem Nichtziel zu untersuchen </p><br><p><img src="https://habrastorage.org/webt/c5/tx/oa/c5txoadzfwl8qzg8t-29siuftnw.png" alt="Dataset Mean Response"></p><br><p>  In der linken Grafik können Sie sehen, dass die durchschnittlichen Signale sehr unterschiedlich sind und beide eine unspezifische Reaktion im Bereich von 180 ms haben, aber die Zielamplitude ist viel größer, das Ziel hat auch einen charakteristischen Buckel von 250 bis 500 ms - dies ist der berüchtigte P300. </p><br><p>  Bei einem solchen Unterschied im Signal mag unsere Aufgabe wie eine Kleinigkeit erscheinen, aber wenn wir die Standardabweichung an jedem Punkt zur Grafik hinzufügen, werden wir sehen, dass das Bild nicht so rosig ist - das Signal ist ziemlich verrauscht.  Und dies trotz der Tatsache, dass das Signal-Rausch-Verhältnis für den P300 als eines der höchsten in der Neurophysiologie gilt. </p><br><p>  (Tatsächlich sind diese Graphen nicht ganz ehrlich aufgebaut, da das Leersignal über fünfmal so viele verschiedene Abtastwerte gemittelt wird, sodass zufällige Abweichungen stärker gedrosselt werden. Wie wir jedoch an der Streuung derselben Reihenfolge erkennen können, hilft dies nicht allzu viel.) </p><br><p><img src="https://habrastorage.org/webt/7b/nw/hw/7bnwhwdx7xrbkvwgqiw9jc5um5g.png" alt="Mittlere Antwort der Person"></p><br><p>  Es ist auch nützlich, die durchschnittlichen Signale einer Person zu betrachten. </p><br><p>  Hier findet sich die bisherige Bemerkung zur „unehrlichen“ Mittelung - das Leersignal ist spürbar amplitudenstärker als bei der Mittelung über alles.  Außerdem ist der Peak von P300 bei einer Person höher, da weniger gemittelt wird. </p><br><p>  Es ist wichtig, ein anderes Merkmal des Signals einer Person zu beachten - es hat eine etwas andere Form als das generalisierte.  Die zwischenmenschliche Variabilität der neurophysiologischen Reaktionen ist recht hoch, wir werden den Einfluss dieses Faktors in der Arbeit der Klassifikatoren noch sehen.  Intrapersonale Unterschiede (eine Person in einer anderen Stimmung, Stresslevel, Müdigkeit) sind jedoch auch ziemlich groß. </p><br><p><img src="https://habrastorage.org/webt/jt/kj/sj/jtkjsjbgmym86-unjyshdxgtd80.png" alt="png"></p><br><p>  Als nächstes sehen wir den kanalweisen Sweep der Signale.  Die Sichtweise hier stimmt mit dem obigen Bild überein, das die Position der Elektroden zeigt - Nase oben usw. </p><br><p>  Die Reaktion jedes Teils des Kopfes ist unterschiedlich.  Bei Fp1,2 sind zwei negative Peaks vor dem positiven Peak ausgeprägt.  Außerdem gibt es in einigen Kanälen zwei positive Peaks und in einigen einen oder einen Übergang zwischen diesen. </p><br><p>  Verschiedene Kanäle sind für die Bestimmung des Vorhandenseins von P300 von unterschiedlicher Bedeutung. Sie können mithilfe verschiedener Methoden geschätzt werden - Berechnung der gegenseitigen Information (gegenseitige Information) oder Add-Delete-Methode (auch bekannt als schrittweise Regression).  Die Anwendung dieser Methoden werden wir zu einem anderen Zeitpunkt behandeln. </p><br><p>  Es sei daran erinnert, dass wir die Potentialdifferenz zwischen den Elektroden mit Elektroden messen, was bedeutet, dass wir zu bestimmten Zeitpunkten Spannungskarten für den gesamten Kopf unter Verwendung von Spannungsänderungen an einzelnen Punkten erstellen können.  Es ist klar, dass, wenn es 16 Elektroden gibt, die Genauigkeit einer solchen Karte sehr zu wünschen übrig lässt, aber ein gewisses Verständnis sollte hergestellt werden.  ( <code>mne</code> erwartet standardmäßig Mikrovolt, aber die Skalierung wurde bereits angewendet, sodass die absoluten Werte nicht korrekt sind.) </p><br><p><img src="https://habrastorage.org/webt/zq/2y/kz/zq2ykzbpc6oxqz2woyizwuswod4.png" alt="png"></p><br><p><img src="https://habrastorage.org/webt/l5/xn/iy/l5xniylmkybexkk6cym8dbhrmjq.png" alt="png"></p><br><h2 id="klassifikaciya">  Klassifizierung </h2><br><p>  Schließlich ist es Zeit, maschinelle Lernmethoden auf unsere Stichprobe anzuwenden. </p><br><p>  Mehrere grundlegende wurden als Klassifikatoren ausgewählt - ein Protokoll.  Regression, die Support-Vektor-Methode (SVM) und mehrere Methoden unter Verwendung der Korrelationsanalyse aus dem <a href="https://github.com/alexandrebarachant/pyRiemann"><code>pyriemann</code></a> Paket (Details zu den einzelnen Methoden finden Sie in der Dokumentation). Es ist anzumerken, dass diese Methoden speziell für die Anwendung im EEG entwickelt wurden und mit ihrer Hilfe <a href="https://www.kaggle.com/c/inria-bci-challenge/discussion/12819">mehrere</a> <a href="https://www.kaggle.com/c/grasp-and-lift-eeg-detection/discussion/16479">Wettbewerbe gewonnen</a> wurden kaggle. </p><br><pre> <code class="python hljs">clfs = { <span class="hljs-string"><span class="hljs-string">'LR'</span></span>: ( make_pipeline(Vectorizer(), LogisticRegression()), {<span class="hljs-string"><span class="hljs-string">'logisticregression__C'</span></span>: np.exp(np.linspace(<span class="hljs-number"><span class="hljs-number">-4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>))}, ), <span class="hljs-string"><span class="hljs-string">'LDA'</span></span>: ( make_pipeline(Vectorizer(), LDA(shrinkage=<span class="hljs-string"><span class="hljs-string">'auto'</span></span>, solver=<span class="hljs-string"><span class="hljs-string">'eigen'</span></span>)), {}, ), <span class="hljs-string"><span class="hljs-string">'SVM'</span></span>: ( make_pipeline(Vectorizer(), SVC()), {<span class="hljs-string"><span class="hljs-string">'svc__C'</span></span>: np.exp(np.linspace(<span class="hljs-number"><span class="hljs-number">-4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>))}, ), <span class="hljs-string"><span class="hljs-string">'CSP LDA'</span></span>: ( make_pipeline(CSP(), LDA(shrinkage=<span class="hljs-string"><span class="hljs-string">'auto'</span></span>, solver=<span class="hljs-string"><span class="hljs-string">'eigen'</span></span>)), {<span class="hljs-string"><span class="hljs-string">'csp__n_components'</span></span>: (<span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>, <span class="hljs-number"><span class="hljs-number">13</span></span>), <span class="hljs-string"><span class="hljs-string">'csp__cov_est'</span></span>: (<span class="hljs-string"><span class="hljs-string">'concat'</span></span>, <span class="hljs-string"><span class="hljs-string">'epoch'</span></span>)}, ), <span class="hljs-string"><span class="hljs-string">'Xdawn LDA'</span></span>: ( make_pipeline(Xdawn(<span class="hljs-number"><span class="hljs-number">2</span></span>, classes=[<span class="hljs-number"><span class="hljs-number">1</span></span>]), Vectorizer(), LDA(shrinkage=<span class="hljs-string"><span class="hljs-string">'auto'</span></span>, solver=<span class="hljs-string"><span class="hljs-string">'eigen'</span></span>)), {}, ), <span class="hljs-string"><span class="hljs-string">'ERPCov TS LR'</span></span>: ( make_pipeline(ERPCovariances(estimator=<span class="hljs-string"><span class="hljs-string">'oas'</span></span>), TangentSpace(), LogisticRegression()), {<span class="hljs-string"><span class="hljs-string">'erpcovariances__estimator'</span></span>: (<span class="hljs-string"><span class="hljs-string">'lwf'</span></span>, <span class="hljs-string"><span class="hljs-string">'oas'</span></span>)}, ), <span class="hljs-string"><span class="hljs-string">'ERPCov MDM'</span></span>: ( make_pipeline(ERPCovariances(), MDM()), {<span class="hljs-string"><span class="hljs-string">'erpcovariances__estimator'</span></span>: (<span class="hljs-string"><span class="hljs-string">'lwf'</span></span>, <span class="hljs-string"><span class="hljs-string">'oas'</span></span>)}, ), }</code> </pre> <br><p><img src="https://habrastorage.org/webt/3x/yb/qc/3xybqcusgidyxfs5lfcilxqn-gs.png" alt="Kreuzvalidierungssatz"></p><br><p>  Das gebräuchlichste Schema neuronaler Schnittstellen ist "Kalibrierung + Arbeit", d.h.  Zunächst ist es notwendig, dass sich eine Person für einige Zeit auf die zuvor angegebenen Reize konzentriert, und erst danach sagen wir ihre Wahl voraus.  Dieser Ansatz hat den offensichtlichen Nachteil eines langweiligen Anfangsstadiums. </p><br><p>  Um die Leistung unserer Methoden in diesem Modus zu bewerten, führen wir eine Kreuzvalidierung innerhalb einer Person durch. <br>  Die Genauigkeitsmetrik ist in diesem Fall aufgrund des Ungleichgewichts des Datensatzes nicht relevant (die Grundlinie hier ist 5/6 ~ 83%), daher ziehe ich es vor, die Genauigkeits-Rückruf-f1 drei zu betrachten. </p><br><p>  Um den gesamten Datensatz zu überprüfen, werden die Ergebnisse einer solchen Kreuzvalidierung über alle Personen gemittelt.  Im Allgemeinen ist die Leistung der besten Modelle ziemlich hoch im Vergleich zu dem, was wir bei <a href="https://impulse-neiry.com/">Neiry</a> unter den "Feldbedingungen" eines Vergnügungsparks haben (ich erinnere mich, dass dieser Datensatz im Labor aufgezeichnet wurde). </p><br><p>  In diesem Datensatz gibt es nur binäre Bezeichnungen für die Daten.  Im Allgemeinen müssen wir das Mehrklassenproblem der Auswahl eines der Stimuli lösen (übrigens ist es ausgeglichen, da jeder Stimulus gleich oft aktiviert wird).  Um dies zu lösen, wird normalerweise die Anzahl der Aktivierungen jedes Stimulus festgelegt (z. B. 6 Stimuli mit jeweils 5 Aktivierungen), und alle Stimuli werden zufällig aktiviert (30-mal), 30 Epochen werden erhalten und die Wahrscheinlichkeiten seiner Aktivierungen werden addiert, um gezielt zu sein, wonach der Stimulus das Maximum erreicht hat der betrag wird als ziel anerkannt.  Wir werden die Umsetzung dieses Ansatzes in einem zukünftigen Beitrag an einem geeigneten Datensatz demonstrieren. </p><br><p><img src="https://habrastorage.org/webt/zx/-o/lm/zx-olmert9y5wdjpebgqa1dy8zm.png" alt="crossvalidate_dataset"></p><br><p>  Das zweite Schema nennt sich Transferlernen - also die Übertragung des Klassifikators zwischen Personen.  Tatsache ist, dass wir bei der Kalibrierung tatsächlich zur Peakform einer Person zurückkehren, sodass wir dies in nachfolgenden Tests gut vorhersagen können.  Ohne Kalibrierung sollte ein vorab geschulter Klassifikator in der Lage sein, das P300-Konzept zu isolieren, ohne die Wellenform einer bestimmten Person im Voraus zu kennen. </p><br><p>  Wir werden zwei Experimente durchführen - wir werden den Klassifikator auf eine Person trainieren, und wir werden fünf vorhersagen, und dann werden wir die Trainingsstichprobe auf 10 Personen erhöhen und die Ergebnisse vergleichen, um sicherzustellen, dass die Modelle in der Lage sind, ihre Verallgemeinerungsfähigkeit zu erhöhen </p><br><p>  Training für 1 Person <br><img src="https://habrastorage.org/webt/fk/n5/5w/fkn55wh6yl7hfpjtjrqesq8gm8e.png" alt="transfer_validate_1"></p><br><p>  Training für 10 Personen <br><img src="https://habrastorage.org/webt/in/ol/kq/inolkqy3-fezzcavmstah4vwhic.png" alt="transfer_valiidate_10"></p><br><p>  Also stieg f1 für einen besseren Klassifikator von 0,23 auf 0,4 (in beiden Fällen handelt es sich um eine logarithmische Regression mit derselben Regularisierung). </p><br><p>  Dies bedeutet, dass die Vorhersagefähigkeit von "nein" auf "akzeptabel" angestiegen ist.  Basierend auf unserer Erfahrung reichen mit solchen binären Aufgabenmetriken 5 Aktivierungen jedes Stimulus aus, um die Genauigkeit eines Mehrklassenproblems von etwa 75% zu erreichen. </p><br><p>  Abschließend möchte ich darauf hinweisen, dass die obige Methode ziemlich primitiv ist, was zum Beispiel am hohen Grad der Regularisierung der logarithmischen Regression zu erkennen ist - die Kanäle in den Daten sind ziemlich stark korreliert und es gibt verschiedene Ansätze, um diesen Umstand zu lösen. </p><br><h2 id="zaklyuchenie">  Fazit </h2><br><p>  Heute haben wir uns mit dem hervorgerufenen Potenzial des P300 vertraut gemacht und eine einfache Pipeline für die neuronale Schnittstelle erstellt.  Ich empfehle Interessenten, einen eigenen Laptop (im <a href="https://gitlab.com/impulse-neiry_public/posts">Repository</a> ) zu öffnen und mit Visualisierungsoptionen und Klassifikatoren zu experimentieren. </p><br><p>  Mit einem grundlegenden Verständnis der Arbeitsweise mit dem EEG-Signal können wir dieses Thema vertiefen - um fortgeschrittene Vorverarbeitungsmethoden sowie neuronale Netze anzuwenden und die Probleme beim Aufbau neuronaler Schnittstellen zu lösen.  Fortsetzung folgt... </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de480060/">https://habr.com/ru/post/de480060/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de480048/index.html">Entmystifizierung des neuen .NET Core 3 Worker Service</a></li>
<li><a href="../de480050/index.html">Feldstudien zum Konzept „Dokumentation als Code“</a></li>
<li><a href="../de480052/index.html">SEO vs. PPC - Was ist besser für Ihr Unternehmen?</a></li>
<li><a href="../de480056/index.html">Versteckte Kameraaktivierung durch Browser: Big Brother oder Technologie-Fehleinschätzung?</a></li>
<li><a href="../de480058/index.html">Transformatorstern auf dem Weihnachtsbaum</a></li>
<li><a href="../de480062/index.html">10 Steuersysteme. Wo ist es bequemer, über Aufgaben zu kommunizieren und Dateien zu teilen?</a></li>
<li><a href="../de480064/index.html">Wörter thematisch gruppiert lernen</a></li>
<li><a href="../de480068/index.html">[Update] Unsere Leute sind geschlagen, und wir werden schweigen?</a></li>
<li><a href="../de480070/index.html">Vorteile reagieren: Ein Segen für Unternehmen?</a></li>
<li><a href="../de480072/index.html">Kubernetes: Warum ist es so wichtig, ein Systemressourcenmanagement einzurichten?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
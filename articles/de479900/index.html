<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®‚Äç‚úàÔ∏è üñêüèª üîì Kundenorientierter Data Lake in einem Gaming-Unternehmen üõë üï¥üèæ üìÜ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Quelle 

 Hallo habr Mein Name ist Maxim Pchelin und ich leite die Entwicklung von BI-DWH bei MyGames (Gaming Division der Mail.ru Group). In diesem A...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kundenorientierter Data Lake in einem Gaming-Unternehmen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/479900/"><img src="https://habrastorage.org/webt/ic/em/yw/icemywxszsrmzmrife7stz9ltpg.jpeg"><br>  <a href="https://www.filthymonkeymen.com/2016/06/16/neanderthal-hunting-strategy/">Quelle</a> <br><br>  Hallo habr  Mein Name ist Maxim Pchelin und ich leite die Entwicklung von BI-DWH bei MyGames (Gaming Division der Mail.ru Group).  In diesem Artikel werde ich dar√ºber sprechen, wie und warum wir einen kundenorientierten DataLake-Speicher erstellt haben. <br><br>  Der Artikel besteht aus drei Teilen.  Zun√§chst erkl√§re ich, warum wir uns f√ºr die Implementierung von DataLake entschieden haben.  Im zweiten Teil werde ich beschreiben, welche Technologien und L√∂sungen wir verwenden, damit der Speicher funktionieren und mit Daten gef√ºllt werden kann.  Und im dritten Teil beschreibe ich, was wir tun, um die Qualit√§t unserer Dienstleistungen zu verbessern. <br><a name="habracut"></a><br><h1>  Was hat uns zu DataLake gebracht? </h1><br>  Wir bei <a href="https://my.games/">MyGames</a> arbeiten in der BI-DWH-Abteilung und bieten Dienstleistungen in zwei Kategorien an: ein Repository f√ºr Datenanalysten und regelm√§√üige Berichterstellungsdienste f√ºr Gesch√§ftsanwender (Manager, Vermarkter, Spieleentwickler und andere). <br><br><h3>  Warum so ein nicht standardm√§√üiger Speicher? </h3><br>  In der Regel impliziert BI-DWH nicht die Implementierung von DataLake-Speicher, dies kann nicht als typische L√∂sung bezeichnet werden.  Und wie werden dann solche Dienste aufgebaut? <br><br>  Normalerweise hat ein Unternehmen ein Projekt - in unserem Fall ist dies ein Spiel.  Das Projekt verf√ºgt √ºber ein Protokollierungssystem, das am h√§ufigsten Daten in die Datenbank schreibt.  Dar√ºber hinaus werden Storefronts f√ºr Aggregate, Metriken und andere Entit√§ten f√ºr zuk√ºnftige Analysen erstellt.  Die regelm√§√üige Berichterstellung basiert auf Storefronts mit einem geeigneten BI-Tool sowie Ad-Hoc-Analysesystemen, angefangen bei einfachen SQL-Abfragen und Excel-Tabellen bis hin zum Jupyter Notebook f√ºr DS und ML.  Das gesamte System wird von einem Entwicklungsteam unterst√ºtzt. <br><br>  Angenommen, eine andere Firma wird in einer Firma geboren.  Ein anderes Entwicklungsteam und eine andere Infrastruktur zu haben, ist attraktiv, aber teuer.  Das Projekt muss also "angeschlossen" werden.  Dies kann auf verschiedene Arten geschehen: auf Datenbankebene, auf Storefront-Ebene oder zumindest auf Anzeigeebene - das Problem ist behoben. <br><br>  Und wenn das Unternehmen ein drittes Projekt hat?  Das ‚ÄûTeilen‚Äú kann bereits zu einem schlechten Ende f√ºhren: M√∂glicherweise treten Probleme bei der Zuweisung von Ressourcen oder Zugriffsrechten auf.  Zum Beispiel wird eines der Projekte von einem externen Team durchgef√ºhrt, das nichts √ºber die ersten beiden Projekte wissen muss.  Die Situation wird riskanter. <br><br>  Stellen Sie sich vor, es gibt nicht drei Projekte, sondern viel mehr.  Und so geschah es, dass genau dies unser Fall ist. <br><br>  MyGames ist einer der gr√∂√üten Gesch√§ftsbereiche der Mail.ru Group. Wir haben 150 Projekte in unserem Portfolio.  Dar√ºber hinaus sind sie alle sehr unterschiedlich: ihre eigene Entwicklung und f√ºr Operationen in Russland gekauft.  Sie arbeiten auf verschiedenen Plattformen: PC, Xbox, Playstation, iOS und Android.  Diese Projekte werden in zehn B√ºros auf der ganzen Welt mit Hunderten von Entscheidungstr√§gern entwickelt. <br><br><img src="https://habrastorage.org/webt/6y/33/c5/6y33c5pfbswcdiqeikzuptzbs9k.jpeg"><br><br>  F√ºr Unternehmen ist dies eine gro√üartige Sache, erschwert jedoch die Aufgabe f√ºr das BI-DWH-Team. <br><br>  In unseren Spielen werden viele Spieleraktionen protokolliert: Als er das Spiel betrat, wo und wie er die Level bekam, mit wem und wie erfolgreich er gek√§mpft hat, was und f√ºr welche W√§hrung er gekauft hat.  Wir m√ºssen all diese Daten f√ºr jedes Spiel sammeln. <br><br>  Wir brauchen dies, damit das Unternehmen Antworten auf seine Fragen zu den Projekten erh√§lt.  Was ist letzte Woche nach dem Start der Aktion passiert?  Wie sehen unsere Prognosen f√ºr den Umsatz oder die Auslastung der Spieleserverkapazit√§ten f√ºr den n√§chsten Monat aus?  Was kann getan werden, um diese Prognosen zu beeinflussen? <br><br>  Es ist wichtig, dass MyGames den Projekten kein Entwicklungsparadigma auferlegt.  Jedes Spielstudio zeichnet Daten auf, da es dies f√ºr effizienter h√§lt.  Einige Projekte generieren Protokolle auf der Clientseite, andere auf der Serverseite.  Einige Projekte verwenden RDBMS, um sie zu sammeln, w√§hrend andere v√∂llig andere Tools verwenden: Kafka, Elasticsearch, Hadoop, Tarantool oder Redis.  Und wir greifen auf diese Datenquellen zur√ºck, um sie in das Repository hochzuladen. <br><br><h3>  Was m√∂chten Sie von unserem BI-DWH? </h3><br>  Zun√§chst m√∂chten sie von der BI-DWH-Abteilung Daten zu allen unseren Spielen erhalten, um sowohl t√§gliche als auch strategische Aufgaben zu l√∂sen.  Beginnend damit, wie viele Leben ein schreckliches Monster am Ende des Levels beschert und wie die Ressourcen im Unternehmen richtig verteilt werden: Welche Projekte sollten mehr Entwickler bescheren oder wer sollte ein Marketingbudget zuweisen? <br><br>  Zuverl√§ssigkeit wird auch von uns erwartet.  Wir arbeiten in einem gro√üen Unternehmen und k√∂nnen nicht nach dem Prinzip ‚ÄûGestern haben wir gearbeitet, aber heute ist das System vorhanden, und es wird sich erst in einer Woche entwickeln, wenn wir uns etwas einfallen lassen.‚Äú <br><br>  Sie wollen Ersparnisse von uns.  Gerne l√∂sen wir alle Probleme, indem wir Eisen kaufen oder Leute einstellen.  Aber wir sind eine kommerzielle Organisation und k√∂nnen es uns nicht leisten.  Wir versuchen, dem Unternehmen Gewinn zu bringen. <br><br>  Wichtig ist, dass sie Kundenorientierung von uns wollen.  Kunden sind in diesem Fall unsere Verbraucher, Kunden: Manager, Analysten usw. Wir m√ºssen uns an unsere Spiele anpassen und so arbeiten, dass es f√ºr Kunden bequem ist, mit uns zusammenzuarbeiten.  Zum Beispiel k√∂nnen wir in einigen F√§llen, wenn wir Projekte auf dem asiatischen Markt f√ºr Operationen kaufen, zusammen mit dem Spiel Basen mit Namen auf Chinesisch erhalten.  Und die Dokumentation f√ºr diese Grundlagen auf Chinesisch.  Wir k√∂nnten nach einem ETL-Entwickler mit Chinesischkenntnissen suchen oder das Herunterladen von Spieldaten verweigern. Stattdessen schlie√üen wir uns in den Besprechungsraum ein, nehmen die Uhr und fangen an zu spielen.  Das Spiel betreten und verlassen, kaufen, schie√üen, sterben.  Und wir schauen, was und wann in dieser oder jener Tabelle erscheint.  Dann schreiben wir die Dokumentation und bauen auf deren Basis ETL. <br><br>  In diesem Fall ist es wichtig, die Kante zu f√ºhlen.  Es ist ein unzul√§ssiger Luxus, sich in die einzigartige Protokollierung eines Spiels mit einer DAU von 50 Personen zu vertiefen, wenn Sie einem Projekt mit einer DAU von 500.000 in der N√§he helfen m√ºssen.  Wir k√∂nnen uns also nat√ºrlich sehr viel M√ºhe geben, um eine ma√ügeschneiderte L√∂sung zu entwickeln, aber nur, wenn das Gesch√§ft dies wirklich ben√∂tigt. <br><br>  Sobald Entwickler, insbesondere Anf√§nger, jedoch h√∂ren, dass sie sich auf diese Weise anpassen m√ºssen, haben sie den Wunsch, dies niemals zu tun.  Jeder Entwickler m√∂chte eine ideale Architektur erstellen, diese niemals √§ndern und Artikel dar√ºber auf Habr schreiben. <br><br>  Aber was passiert, wenn wir aufh√∂ren, uns an unsere Spiele anzupassen?  Angenommen, wir fordern sie auf, Daten an eine einzelne Eingabe-API zu senden.  Das Ergebnis wird eins sein - jeder wird anfangen sich zu zerstreuen. <br><br><ul><li>  Einige Projekte werden anfangen, ihre BI-DWH-L√∂sungen mit Vorliebe und Dichterinnen zu k√ºrzen.  Dies f√ºhrt zu doppelten Ressourcen und Schwierigkeiten beim Datenaustausch zwischen Systemen. <br></li><li>  Andere Projekte werden die Erstellung ihres BI-DWH nicht beeinflussen, aber sie werden sich auch nicht an unsere anpassen wollen.  Und wieder andere verwenden keine Daten mehr, was noch schlimmer ist. <br></li><li>  Nun, und was am wichtigsten ist, das Management wird keine aktuellen systematischen Informationen dar√ºber haben, was in den Projekten vor sich geht. <br></li></ul><br><h3>  K√∂nnen wir Speicher auf einfache Weise implementieren? </h3><br>  150 Projekte sind viel.  Die L√∂sung sofort f√ºr alle umzusetzen ist zu lang.  Das Gesch√§ft wird nicht ein Jahr auf die ersten Ergebnisse warten.  Aus diesem Grund haben wir drei Projekte mit maximalem Umsatz ausgew√§hlt und den ersten Prototyp f√ºr sie implementiert.  Wir wollten wichtige Daten daraus sammeln und Basis-Dashboards mit den beliebtesten Messwerten erstellen - DAU, MAU, Umsatz, Registrierungen, Aufbewahrung sowie ein bisschen Wirtschaftlichkeit und Prognosen. <br><br>  Wir konnten die Spielebasen der Projekte selbst daf√ºr nicht nutzen.  Erstens w√ºrde dies die design√ºbergreifende Analyse erschweren, da Daten aus mehreren Datenbanken aggregiert werden m√ºssen.  Zweitens arbeiten die Spiele selbst auf diesen Datenbanken, was wichtig ist, damit die Master und Repliken nicht √ºberlastet werden.  Schlie√ülich l√∂schen alle Spiele zu einem bestimmten Zeitpunkt den gesamten Datenverlauf, den sie nicht ben√∂tigen, in ihren Datenbanken, was f√ºr die Analyse nicht akzeptabel ist. <br><br>  Daher besteht die einzige M√∂glichkeit darin, alles, was Sie f√ºr die Analyse ben√∂tigen, an einem einzigen Ort zu sammeln.  Zu diesem Zeitpunkt passte jede relationale Datenbank oder jedes Klartext-Repository zu uns.  Wir w√ºrden BI schrauben und Dashboards bauen.  Es gibt viele M√∂glichkeiten f√ºr Kombinationen solcher L√∂sungen: <br><br><img src="https://habrastorage.org/webt/vx/1e/hm/vx1ehmdjxzv-nimt1x3_ivm3sd8.jpeg"><br><br>  Aber wir haben verstanden, dass wir sp√§ter alle anderen 150 Spiele abdecken m√ºssen.  M√∂glicherweise kann eine relationale Clusterdatenbank die generierte Datenmenge verarbeiten.  Die Quellen befinden sich aber nicht nur in v√∂llig unterschiedlichen Systemen, sondern haben auch sehr unterschiedliche Datenstrukturen.  Wir treffen relationale Strukturen, Data Vault und andere.  Es wird nicht funktionieren, all dies in einer Datenbank ohne komplexe und m√ºhsame Tricks unterzubringen. <br><br>  All dies f√ºhrte uns zu dem Verst√§ndnis, dass wir einen DataLake erstellen m√ºssen. <br><br><h1>  Implementierung von DataLake </h1><br>  Erstens ist DataLake Storage f√ºr unsere Bedingungen geeignet, da es uns erm√∂glicht, unstrukturierte Daten zu speichern.  DataLake kann zu einem zentralen Einstiegspunkt f√ºr alle Quellen werden, angefangen bei Tabellen aus RDBMS bis hin zu JSON, das wir von Kafka oder Mongo aus versenden.  Infolgedessen kann DataLake die Grundlage f√ºr design√ºbergreifende Analysen werden, die auf der Grundlage von Schnittstellen f√ºr verschiedene Benutzer implementiert werden: SQL, Python, R, Spark usw. <br><br><h3>  Wechseln Sie zu Hadoop </h3><br>  F√ºr DataLake haben wir die naheliegende L√∂sung gew√§hlt - Hadoop.  Insbesondere seine Montage aus Cloudera.  Mit Hadoop k√∂nnen Sie mit unstrukturierten Daten arbeiten. Durch Hinzuf√ºgen von Datenknoten k√∂nnen Sie diese problemlos skalieren.  Dar√ºber hinaus wurde dieses Produkt gut untersucht, sodass die Antwort auf jede Frage im Bereich Stackoverflow zu finden ist und keine Ressourcen f√ºr Forschung und Entwicklung aufgewendet werden m√ºssen. <br><br>  Nach der Implementierung von Hadoop haben wir das folgende Diagramm unseres ersten Unified Storage erhalten: <br><br><img src="https://habrastorage.org/webt/95/fn/2u/95fn2uesgfvlgfqrxdohrfnltsa.jpeg"><br><br>  Daten wurden aus einer kleinen Anzahl von Quellen in Hadoop gesammelt und anschlie√üend mit mehreren Schnittstellen versehen: BI-Tools und -Services f√ºr Ad-Hoc-Analysen. <br><br>  Weitere Ereignisse entwickelten sich unerwartet: Unser Hadoop startete perfekt, und Kunden, f√ºr die Daten in den Laden flossen, gaben alte Analysesysteme auf und nutzten das neue Produkt t√§glich f√ºr ihre Arbeit. <br><br>  Aber es entstand ein Problem: Je mehr Sie tun, desto mehr wollen sie von Ihnen.  Sehr schnell forderten Projekte, die bereits in Hadoop integriert waren, mehr Daten an.  Und diejenigen Projekte, die noch nicht hinzugef√ºgt wurden, begannen danach zu fragen.  Die Anforderungen an die Stabilit√§t begannen stark zuzunehmen. <br><br>  Gleichzeitig ist es nicht sinnvoll, das Team linear zu vergr√∂√üern.  Wenn zwei DWH-Entwickler mit zwei Projekten fertig werden, k√∂nnen wir f√ºr vier Projekte keine weiteren Entwickler einstellen.  Deshalb sind wir erstmal den anderen Weg gegangen. <br><br><h3>  Prozesseinrichtung </h3><br>  Bei begrenzten Ressourcen ist die kosteng√ºnstigste L√∂sung die Optimierung von Prozessen.  Dar√ºber hinaus ist es in einem gro√üen Unternehmen unm√∂glich, einfach eine Speicherarchitektur zu entwickeln und diese zu implementieren.  M√ºssen mit einer gro√üen Anzahl von Menschen verhandeln. <br><br><ul><li>  Zuallererst mit Gesch√§ftsvertretern, die Ressourcen f√ºr die Analyse bereitstellen.  Sie m√ºssen nachweisen, dass Sie nur die Aufgaben Ihrer Kunden ausf√ºhren m√ºssen, die dem Unternehmen zugute kommen. <br></li><li>  Sie m√ºssen auch mit Analysten verhandeln, damit diese Ihnen eine Gegenleistung f√ºr die von Ihnen angebotenen Services bieten - Systemanalyse, Gesch√§ftsanalyse, Testen.  Zum Beispiel gaben wir die Systemanalyse unserer Datenquellen an Analysten weiter.  Nat√ºrlich sind sie nicht gl√ºcklich, aber sonst wird es einfach niemanden geben, der das tut. <br></li><li>  Zu guter Letzt m√ºssen Sie mit den Spielentwicklern verhandeln: Installieren Sie SLAs und einigen Sie sich auf eine Datenstruktur.  Wenn die Felder st√§ndig verschwinden, angezeigt und umbenannt werden, werden Sie unabh√§ngig von der Gr√∂√üe des Teams immer Ihre H√§nde vermissen. <br></li><li>  Sie m√ºssen auch mit Ihrem eigenen Team verhandeln: Suchen Sie einen Kompromiss zwischen idealen L√∂sungen, die alle Entwickler erstellen m√∂chten, und Standardl√∂sungen, die nicht so interessant sind, die sich aber billig und schnell nieten lassen. <br></li><li>  Es wird notwendig sein, sich mit den Administratoren √ºber die √úberwachung der Infrastruktur abzustimmen.  Sobald Sie √ºber zus√§tzliche Ressourcen verf√ºgen, ist es jedoch besser, einen eigenen DevOps-Spezialisten im Speicherteam zu beauftragen. <br></li></ul><br>  An dieser Stelle k√∂nnte ich den Artikel beenden, wenn eine solche Variante des Repository alle daf√ºr festgelegten Ziele erf√ºllen w√ºrde.  Aber das ist nicht so.  Warum? <br><br>  Vor Hadoop konnten wir Daten und Statistiken f√ºr f√ºnf Projekte bereitstellen.  Mit der Implementierung von Hadoop und ohne Verst√§rkung des Teams konnten wir 10 Projekte abdecken.  Nach der Festlegung der Prozesse hat unser Team bereits 15 Projekte betreut.  Das ist cool, aber wir haben 150 Projekte, wir brauchten etwas Neues. <br><br><h3>  Airflow-Implementierung </h3><br>  Zun√§chst haben wir mit Cron Daten aus Quellen gesammelt.  Zwei Projekte sind normal.  10 - es tut weh, aber ok.  Mittlerweile werden jedoch t√§glich ca. 12.000 Prozesse geladen, um 150 Projekte in DataLake zu laden.  Cron ist nicht mehr geeignet.  Dazu ben√∂tigen wir ein leistungsstarkes Tool zum Verwalten von Daten-Download-Streams. <br><br>  Wir haben uns f√ºr den Open Source Airflow Task Manager entschieden.  Er wurde in den Eingeweiden von Airbnb geboren und danach nach Apache versetzt.  Dies ist ein Tool f√ºr codegesteuertes ETL.  Das hei√üt, Sie schreiben ein Skript in Python und es wird in eine DAG (Directed Acyclic Graph) konvertiert.  DAGs eignen sich hervorragend zur Aufrechterhaltung von Abh√§ngigkeiten zwischen Tasks. Sie k√∂nnen keine Storefront mit noch nicht geladenen Daten erstellen. <br><br>  Airflow hat einen gro√üartigen Fehlerbehandler.  Wenn ein Prozess abst√ºrzt oder ein Problem mit dem Netzwerk vorliegt, startet der Dispatcher den Prozess so oft neu, wie Sie dies angegeben haben.  Wenn beispielsweise viele Fehler aufgetreten sind und sich die Tabelle in der Quelle ge√§ndert hat, wird eine Benachrichtigung angezeigt. <br><br>  Airflow hat eine gro√üartige Benutzeroberfl√§che: Sie zeigt bequem an, welche Prozesse ausgef√ºhrt werden, welche erfolgreich abgeschlossen wurden oder einen Fehler aufweisen.  Wenn Aufgaben mit Fehlern gest√ºrzt sind, k√∂nnen Sie sie √ºber die Schnittstelle neu starten und den Prozess durch √úberwachung steuern, ohne in den Code zu gelangen. <br><br>  Airflow ist anpassbar und basiert auf Operatoren. Dies sind Plugins f√ºr die Arbeit mit bestimmten Quellen.  Einige Betreiber sind sofort einsatzbereit, viele haben die Airflow-Community angeschrieben.  Wenn Sie m√∂chten, k√∂nnen Sie Ihren eigenen Operator erstellen, die Oberfl√§che hierf√ºr ist sehr einfach. <br><br><h3>  Wie verwenden wir den Luftstrom? </h3><br>  Zum Beispiel m√ºssen wir eine Tabelle aus PostgreSQL in Hadoop laden.  Die Task <code>sql_sensor_battle_log</code> pr√ºft, ob die Quelle die Daten enth√§lt, die wir f√ºr gestern ben√∂tigen.  In diesem <code>load_stg_data_from_battle_log</code> Task <code>load_stg_data_from_battle_log</code> Daten aus dem PG und f√ºgt sie Hadoop hinzu.  Schlie√ülich f√ºhrt <code>load_oda_data_from_battle_log</code> die anf√§ngliche Verarbeitung durch, beispielsweise die Konvertierung von der Unix-Zeit in die vom Menschen lesbare Zeit. <br><br>  In einer solchen Aufgabenkette werden Daten von einer Entit√§t in einer Quelle abgerufen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/347/38d/4af/34738d4afc911f105891070f97f90097.png"><br><br>  Und so - von allen Entit√§ten, die wir brauchen, aus einer Hand: <br><br><img src="https://habrastorage.org/webt/bs/2i/ne/bs2ines-6me7a6f677u7rc4wgac.jpeg"><br><br>  Diese Gruppe von Downloads ist die DAG.  Derzeit verf√ºgen wir √ºber 250 solcher DAGs, mit denen Rohdaten geladen, verarbeitet, transformiert und Storefronts erstellt werden k√∂nnen. <br><br>  Das aktualisierte Unified Storage-Schema sieht wie folgt aus: <br><br><img src="https://habrastorage.org/webt/a4/9m/ag/a49magbaiqyrtasd2awg6mqnjmk.jpeg"><br><br><ol><li>  Nach der Einf√ºhrung von Airflow konnten wir die Anzahl der Bezugsquellen deutlich steigern - bis zu 400 St√ºck.  Datenquellen sind sowohl interne (aus unseren Spielen) als auch externe: gekaufte Statistiksysteme, heterogene APIs.  Mit Airflow k√∂nnen wir t√§glich 12.000 Prozesse ausf√ºhren und steuern, die Daten aus all unseren 150 Spielen verarbeiten. <br></li><li>  Ausf√ºhrlicher √ºber unseren Luftstrom schrieb Dean Safina in ihrem Artikel ( <a href="https://habr.com/ru/company/mailru/blog/344398/">https://habr.com/ru/company/mailru/blog/344398/</a> ).  Treten Sie auch der Airflow-Community √ºber Telegram ( <a href="https://t.me/ruairflow">https://t.me/ruairflow</a> ) bei.  Viele Fragen zu Airflow k√∂nnen mithilfe der Dokumentation gel√∂st werden. Manchmal werden jedoch weitere benutzerdefinierte Anforderungen angezeigt: Wie kann ich Airflow in Docker packen, warum funktioniert das nicht am dritten Tag und so weiter?  Dies kann in dieser Community beantwortet werden. <br></li></ol><br><h1>  Was in DataLake zu verbessern </h1><br>  Zu diesem Zeitpunkt sind die DWH-Entwickler zuversichtlich, dass alles bereit ist und Sie sich jetzt beruhigen k√∂nnen.  Leider oder zum Gl√ºck gibt es in DataLake noch etwas zu verbessern. <br><br><h3>  Datenqualit√§t </h3><br>  Bei einer gro√üen Anzahl von Tabellen in DataLake leidet zuerst die Datenqualit√§t.  Nehmen Sie zum Beispiel einen Tisch mit Zahlungen.  Es enth√§lt user_id, Betrag, Datum und Uhrzeit der Zahlung: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/998/c18/2df/998c182df294a894a55c0c7822eead23.png" width="400"></div><br>  T√§glich werden ungef√§hr 10 Tausend Zahlungen get√§tigt: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b46/115/a01/b46115a0116d11be5373b93fc4d872e8.png" width="400"><br><br>  Einmal in der Tabelle f√ºr den Tag kamen nur 28 Eintr√§ge.  Ja, und user_id ist alles leer: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/606/7c2/d84/6067c2d840a71002e83364d5c0aef2ae.png" width="200"></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6b5/055/af6/6b5055af6affe4417834ee051947e57c.png" width="400"></div><br><br>  Wenn pl√∂tzlich etwas in unserer Quelle kaputt geht, werden wir dank Airflow sofort davon erfahren.  Aber wenn es formal Daten gibt und auch im richtigen Format, dann erfahren wir nicht sofort von der Aufschl√ºsselung und schon von den Datenkonsumenten.  Es ist nicht realistisch, unsere 5000 Tische mit eigenen H√§nden zu √ºberpr√ºfen. <br><br>  Um dies zu verhindern, haben wir ein eigenes Datenqualit√§tskontrollsystem (DQ) entwickelt.  T√§glich √ºberwacht es die wichtigsten Downloads in unser Repository: Es verfolgt pl√∂tzliche √Ñnderungen in der Anzahl der Zeilen, sucht nach leeren Feldern und pr√ºft, ob Daten dupliziert wurden.  Das System wendet auch benutzerdefinierte Pr√ºfungen von Analysten an.  Darauf aufbauend benachrichtigt sie die Mail dar√ºber, was wo schief gelaufen ist.  Analysten gehen zu Projekten und finden heraus, warum beispielsweise zu wenig Daten vorhanden sind, beseitigen die Gr√ºnde und laden die Daten erneut. <br><br><h3>  Priorisieren Sie Downloads </h3><br>  Mit der zunehmenden Anzahl von Aufgaben zum Laden von Daten in DataLake entsteht schnell ein Priorit√§tskonflikt.  Die √ºbliche Situation: Einige nicht so wichtige Projekte haben nachts alle Ressourcen mit ihren Downloads in Anspruch genommen, und die Tabellen, die zur Berechnung der Kennzahlen f√ºr das Top-Management ben√∂tigt werden, haben zu Beginn des Arbeitstages keine Zeit zum Laden.  Wir gehen auf verschiedene Arten damit um. <br><br><ul><li>  √úberwachen von Schl√ºsseldownloads.  Airflow verf√ºgt √ºber ein eigenes SLA-System, mit dem Sie feststellen k√∂nnen, ob alle Schl√ºssel rechtzeitig eingegangen sind.  Wenn einige Daten nicht geladen sind, werden wir dies einige Stunden fr√ºher als die Benutzer herausfinden und Zeit haben, dies zu beheben. <br></li><li>  Priorit√§t einstellen.  Dazu verwenden wir das Airflow-Warteschlangen- und Priorit√§tssystem.  Es erm√∂glicht uns, die Ladereihenfolge von DAGs und die Anzahl der parallelen Prozesse in ihnen zu bestimmen.  Es ist nicht sinnvoll, Protokolle hochzuladen, die viertelj√§hrlich analysiert werden, bevor Daten f√ºr Kennzahlen des Top-Managements heruntergeladen werden. <br></li></ul><br><h3>  √úberwachung der Dauer der Nachtreihe </h3><br>  Wir haben ein Sammellager.  Nachts bauen wir gerade daran, und es ist wichtig, dass gen√ºgend Nacht zur Verf√ºgung steht, um die t√§gliche Charge zu verarbeiten.  Ansonsten stehen den Analysten w√§hrend der Arbeitszeit nicht gen√ºgend Speicherressourcen zur Verf√ºgung, um zu arbeiten.  Wir l√∂sen dieses Problem regelm√§√üig auf verschiedene Arten: <br><br><ul><li>  Umgekehrte Skalierung.  Wir versenden nicht alle Daten, sondern nur das, was die Analysten ben√∂tigen.  Wir √ºberwachen alle geladenen Tabellen, und wenn eine davon sechs Monate lang nicht verwendet wird, schalten wir das Laden ab. <br></li><li>  Kapazit√§tsaufbau.  Wenn wir verstehen, dass wir durch die Netzwerkf√§higkeiten, die Anzahl der Kerne oder die Festplattenkapazit√§t begrenzt sind, f√ºgen wir Hadoop Datenknoten hinzu. <br></li><li>  Optimierung des Luftstroms der Arbeiter.  Wir tun alles, damit jeder Teil unseres Systems zu jedem Zeitpunkt der Speicherbauzeit optimal genutzt wird. <br></li><li>  Refactoring nicht optimaler Prozesse.  Zum Beispiel betrachten wir die Wirtschaftlichkeit eines frischen Spiels und es dauert 5 Minuten.  Aber nach einem Jahr wachsen die Daten und die gleiche Anfrage wird 2 Stunden lang bearbeitet.  Irgendwann m√ºssen wir uns auf eine inkrementelle Neuberechnung einstellen, obwohl dies zu Beginn als unn√∂tige Komplikation erscheinen k√∂nnte. <br></li></ul><br><h3>  Ressourcensteuerung </h3><br>  Es ist wichtig, nicht nur Zeit zu haben, um das Repository f√ºr den Beginn des Arbeitstages fertig vorzubereiten, sondern auch, um danach die Verf√ºgbarkeit seiner Ressourcen zu √ºberwachen.  Damit k√∂nnen sich im Laufe der Zeit Schwierigkeiten ergeben.  Der Grund daf√ºr ist, dass Analysten suboptimale Abfragen schreiben.  Auch hier werden die Analysten selbst immer mehr.  In diesem Fall ist es am einfachsten, die Hardwarekapazit√§t zu erh√∂hen.  Eine nicht optimale Anforderung beansprucht jedoch immer noch alle verf√ºgbaren Ressourcen.  Das hei√üt, fr√ºher oder sp√§ter werden Sie ohne nennenswerten Nutzen Geld f√ºr Eisen ausgeben.  Aus diesem Grund verwenden wir mehrere andere Ans√§tze. <br><br><ul><li>  Zitat: Wir √ºberlassen den Nutzern zumindest ein wenig Ressourcen.  Ja, Anforderungen werden langsam ausgef√ºhrt, aber zumindest werden sie ausgef√ºhrt. <br></li><li>  √úberwachung der verbrauchten Ressourcen: Wie viele Kerne werden von Benutzeranforderungen verwendet, die die Verwendung von Partitionen in Hadoop vergessen haben und den gesamten Arbeitsspeicher in Anspruch genommen haben usw. Au√üerdem sind diese √úberwachungen f√ºr die Analysten selbst sichtbar, und wenn bei ihnen etwas nicht funktioniert, finden sie selbst den Schuldigen und l√∂sen sie ihn.  Wenn wir nur wenige Projekte h√§tten, w√ºrden wir den Ressourcenverbrauch selbst verfolgen.  Aber bei so vielen m√ºssten wir ein separates, st√§ndig wachsendes √úberwachungsteam einstellen.  Und auf lange Sicht ist das unvern√ºnftig. <br></li><li>  Freiwillige Benutzerschulung.  Analysten schreiben keine Qualit√§tsabfragen in Ihr Repository.  Ihre Aufgabe ist es, gesch√§ftliche Fragen zu beantworten.  Und au√üer uns - dem Repository-Team - k√ºmmert sich niemand um die Qualit√§t der Analystenanfragen.  Aus diesem Grund erstellen wir h√§ufig gestellte Fragen und Pr√§sentationen, halten Vorlesungen f√ºr unsere Analysten und erkl√§ren, wie wir mit unserem DataLake arbeiten k√∂nnen und wie nicht. <br></li></ul><br>  In der Tat ist es viel wichtiger, Zeit f√ºr die Bereitstellung von Daten zu investieren, als sie auszuf√ºllen.  Wenn sich Daten im Speicher befinden, diese jedoch nicht verf√ºgbar sind, sind sie aus gesch√§ftlicher Sicht immer noch vorhanden, und Sie haben sich bereits um das Herunterladen bem√ºht. <br><br><h3>  Flexibilit√§t in der Architektur </h3><br>  Es ist wichtig, die Flexibilit√§t des gebauten DataLake nicht zu vergessen und keine Angst zu haben, die Architektur zu √§ndern, wenn die Eingabefaktoren ge√§ndert werden: Welche Daten m√ºssen in den Speicher hochgeladen werden, wer verwendet sie und wie.  Wir glauben nicht, dass unsere Architektur immer unver√§ndert bleibt. <br><br>  Zum Beispiel haben wir ein neues Handyspiel gestartet.  Sie schreibt JSON von Clients an Nginx, Nginx wirft Daten an Kafka, wir analysieren sie mit Spark und f√ºgen sie in Hadoop ein.  Alles funktioniert, die Aufgabe ist erledigt. <br><br><img src="https://habrastorage.org/webt/mj/2i/cq/mj2icqljg45ckemxfjwjp1idafy.jpeg"><br><br>  Ein paar Monate vergingen, und in der Lagerung begannen alle Prozesse der Nachtcharge l√§nger zu laufen.  Wir fangen an herauszufinden, was los ist: Es hat sich herausgestellt, dass beim Spielstart 50-mal mehr Daten generiert wurden und Spark die JSON-Analyse nicht bew√§ltigen konnte, wodurch die H√§lfte der Speicherressourcen aufgebraucht wurde.  Zu Beginn wurden alle Daten an ein Kafka-Thema gesendet und Spark sortierte sie in verschiedene Entit√§ten.  Wir haben Spieleentwickler gebeten, Daten √ºber Kunden mit verschiedenen Entit√§ten zu teilen und sie in separate Kafka-Themen zu unterteilen.  Es wurde einfacher, aber nicht lange.  Dann haben wir beschlossen, von der t√§glichen JSON-Analyse auf die st√ºndliche umzustellen.  Der Bau des Lagers begann jedoch nicht nur nachts, sondern rund um die Uhr, was f√ºr uns nicht w√ºnschenswert war.  Nach solchen Versuchen, dieses Problem zu l√∂sen, haben wir Spark aufgegeben und ClickHouse implementiert. <br><br><img src="https://habrastorage.org/webt/wv/xw/bo/wvxwbo1pgsxynb8u3lif75uttfw.jpeg"><br><br>  Es hat eine gro√üartige JSON-Parsing-Engine, die Daten sofort in Tabellen zerlegt.  Wir senden zuerst Informationen von Kafka an ClickHouse und holen sie von dort in Hadoop ab.  Dies hat unser Problem vollst√§ndig gel√∂st. <br><br>  Nat√ºrlich versuchen wir, keine Zoosysteme in unserem DataLake-Speicher zu z√ºchten, aber wir versuchen, die am besten geeigneten Technologien f√ºr bestimmte Aufgaben auszuw√§hlen. <br><br><h1>  War es das wert? </h1><br>  Hat es sich gelohnt, Hadoop, ein Qualit√§tskontrollsystem, einzusetzen, sich mit Airflow zu befassen und Gesch√§ftsprozesse einzurichten?  Nat√ºrlich hat es sich gelohnt: <br><br><ul><li>  Das Unternehmen verf√ºgt √ºber aktuelle Informationen zu allen Projekten, die in einzelnen Services verf√ºgbar sind. <br></li><li>  Benutzer unseres Systems, von Spieledesignern bis hin zu Managern, h√∂rten auf, Entscheidungen nur auf der Grundlage von Intuition zu treffen, und wechselten zu datengetriebenen Ans√§tzen. <br></li><li>  Wir haben den Analysten die Werkzeuge an die Hand gegeben, um ihre eigene Raketenwissenschaft zu entwickeln.  Jetzt beantworten sie komplexe Gesch√§ftsanfragen, erstellen Prognosemodelle, empfehlen Systeme und verbessern Spiele.  Eigentlich arbeiten wir daf√ºr in BI-DWH. <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de479900/">https://habr.com/ru/post/de479900/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de479890/index.html">Probleme und Aufgaben bei der Umsetzung des Konzepts des Internet der Dinge</a></li>
<li><a href="../de479892/index.html">√úber Gradle-Plugins, Multithreading in verteilten Systemen und √úberwachungsautomatisierung: Video von Yandex.Money Metap</a></li>
<li><a href="../de479894/index.html">Von Hyper-V zu VMware und umgekehrt: Konvertieren virtueller Festplatten</a></li>
<li><a href="../de479896/index.html">Samstag: Gedanken eines Programmierers zu Wirtschaft, Marx, Lenin und Kapital</a></li>
<li><a href="../de479898/index.html">Nackte Wahrheit</a></li>
<li><a href="../de479902/index.html">IntelliJ IDEA 2019.3: Leistungsoptimierung und Qualit√§tsverbesserung</a></li>
<li><a href="../de479904/index.html">Was ist NFC und wie funktioniert es? Grundlagen auffrischen?</a></li>
<li><a href="../de479906/index.html">FinTech-Branchen√ºberblick: Die vielversprechendsten Finanztechnologien Ende 2019</a></li>
<li><a href="../de479908/index.html">Wie Apples AR / VR der brutalen Realit√§t begegnete</a></li>
<li><a href="../de479910/index.html">So √∂ffnen Sie einen Tunnel in Kubernetes Pod oder Container mit tcpserver und netcat</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
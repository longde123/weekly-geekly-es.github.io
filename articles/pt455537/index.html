<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõ≥Ô∏è üë®‚Äçüë®‚Äçüëß‚Äçüë¶ ‚úåüèΩ Otimiza√ß√£o de pesquisa ampla: como processar um gr√°fico com 10 bilh√µes de estados üëêüèª ü§¶üèæ ü§¥üèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="H√° alguns meses, finalmente tive que admitir que n√£o era inteligente o suficiente para passar por alguns n√≠veis do quebra-cabe√ßa do Snakebird . A √∫nic...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Otimiza√ß√£o de pesquisa ampla: como processar um gr√°fico com 10 bilh√µes de estados</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455537/"><div style="text-align:center;"><img src="https://nordicgame.com/wp-content/uploads/2015/05/noumenon.games_.snakebird.850.560.jpg" alt="imagem"></div><br>  H√° alguns meses, finalmente tive que admitir que n√£o era inteligente o suficiente para passar por alguns n√≠veis do quebra-cabe√ßa do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Snakebird</a> .  A √∫nica maneira de recuperar parte da auto-estima era escrever um solucionador.  Ent√£o, eu poderia fingir que criar um programa para resolver o quebra-cabe√ßa √© quase o mesmo que resolv√™-lo.  O c√≥digo para o programa C ++ resultante est√° dispon√≠vel no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Github</a> .  A parte principal do c√≥digo considerado no artigo √© implementada em <a href="">search.he</a> <a href="">compress.h</a> .  Neste post, falarei principalmente sobre como otimizar a pesquisa pela primeira vez, o que exigiria de 50 a 100 GB de mem√≥ria para caber em 4 GB. <br><br>  Mais tarde vou escrever outro post, que descrever√° as especificidades do jogo.  Neste post, voc√™ precisa saber que n√£o consegui encontrar boas alternativas √† for√ßa bruta, porque nenhum dos truques usuais funcionou.  O jogo tem muitos estados, porque existem muitos objetos em movimento ou empurrados, e a forma de alguns deles √© importante, o que pode mudar com o tempo.  N√£o havia heur√≠stica conservadora adequada para algoritmos como A * para restringir o espa√ßo de pesquisa.  O gr√°fico de pesquisa foi orientado e especificado implicitamente; portanto, a pesquisa simult√¢nea nas dire√ß√µes para frente e para tr√°s era imposs√≠vel.  O √∫nico movimento poderia mudar o estado de muitas maneiras n√£o relacionadas, para que nada pudesse ser √∫til como fazer o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">hash de Zobrist</a> . <br><br>  Estimativas aproximadas mostraram que no maior quebra-cabe√ßa, depois de eliminar todas as posi√ß√µes sim√©tricas, haver√° cerca de 10 bilh√µes de estados.  Mesmo depois de compactar as descri√ß√µes de estado com densidade m√°xima, o tamanho do estado era de 8 a 10 bytes.  Com 100 GB de mem√≥ria, a tarefa seria trivial, mas n√£o para minha m√°quina dom√©stica com 16 GB de mem√≥ria.  E como o Chrome precisa de 12 GB, meu suprimento de mem√≥ria real est√° mais pr√≥ximo de 4 GB.  Tudo o que exceder esse volume ter√° que ser salvo no disco (disco r√≠gido antigo e enferrujado). <br><a name="habracut"></a><br>  Como ajustar 100 GB de dados em 4 GB de RAM?  A) os estados precisam ser compactados para 1/20 do tamanho original j√° otimizado, ou b) o algoritmo deve ser capaz de salvar efetivamente os estados em disco e vice-versa, ou c) uma combina√ß√£o dos dois m√©todos acima, ou d) preciso comprar mais RAM ou alugue uma poderosa m√°quina virtual por v√°rios dias.  N√£o considerei a op√ß√£o D, porque √© muito chata.  As op√ß√µes A e B foram exclu√≠das ap√≥s a prova de conceito usando gzip: um fragmento de uma descri√ß√£o de estado de 50 MB foi compactado para apenas 35 MB.  Isso √© cerca de 7 bytes por estado, e minha mem√≥ria tem cerca de 0,4 bytes por estado.  Ou seja, a op√ß√£o B permaneceu, embora a pesquisa pela primeira vez parecesse bastante inconveniente para armazenamento em unidades secund√°rias. <br><br><h2>  Conte√∫do </h2><br>  Esta √© uma postagem bastante longa, ent√£o aqui est√° uma breve vis√£o geral das seguintes se√ß√µes: <br><br><ul><li>  Pesquisa da primeira largura da primeira largura - qual √© o texto usual da pesquisa da primeira largura (BFS) e por que n√£o √© adequado para armazenar partes de um estado em disco? </li><li>  <b>BFS com classifica√ß√£o e mesclagem</b> - uma altera√ß√£o no algoritmo para descarte eficiente de dados redundantes em lote. </li><li>  <b>Compacta√ß√£o</b> - reduzindo a quantidade de mem√≥ria usada em cem vezes devido √† combina√ß√£o de compacta√ß√£o padr√£o e nativa. </li><li>  <b>Oh-oh, eu trapacei!</b>  - nas primeiras se√ß√µes, fiquei em sil√™ncio sobre algo: n√£o basta saber apenas onde est√° a solu√ß√£o, mas precisamos entender exatamente como alcan√ß√°-la.  Nesta se√ß√£o, atualizamos o algoritmo b√°sico para que ele transfira dados suficientes para recriar a solu√ß√£o a partir do √∫ltimo estado. </li><li>  <b>Classificar + mesclar com v√°rias sa√≠das</b> - armazenar mais estados nega completamente os benef√≠cios da compacta√ß√£o.  O algoritmo de classifica√ß√£o + mesclagem precisa ser alterado para armazenar dois conjuntos de dados de sa√≠da: um, bem compactado, √© usado durante a pesquisa e o outro √© usado apenas para recriar a solu√ß√£o ap√≥s encontrar o primeiro. </li><li>  <b>Trocar</b> - <b>Trocar</b> no Linux √© muito pior do que eu pensava. </li><li>  <b>Compacta√ß√£o de novos estados antes da mesclagem</b> - at√© agora, as otimiza√ß√µes de mem√≥ria funcionavam apenas com muitos estados visitados.  Por√©m, a lista de novos estados gerados √© muito maior do que voc√™ imagina.  Esta se√ß√£o mostra um diagrama para uma descri√ß√£o mais eficiente de novos estados. </li><li>  <b>Economizando espa√ßo nos estados-pai</b> - explore as vantagens e desvantagens entre usar CPU / mem√≥ria para recriar a solu√ß√£o no final. </li><li>  <b>O que n√£o deu certo ou n√£o deu</b> certo - algumas id√©ias pareciam promissoras, mas, como resultado, tiveram que ser revertidas, enquanto outras, que deveriam ser pesquisadores, me parecem intuitivamente inadequadas neste caso. </li></ul><br><h2>  Ampla pesquisa "por livro" </h2><br>  Como √© a pesquisa pela primeira vez e por que voc√™ n√£o deve usar um disco?  Antes deste pequeno projeto, considerei apenas as op√ß√µes de reda√ß√£o ‚Äúde livros did√°ticos‚Äù, por exemplo, como: <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> visited = {start} todo = [start] <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> todo: node = todo.pop_first() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> visited: visited.add(kid) todo.push_back(kid) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">False</span></span></code> </pre> <br>  No processo de cria√ß√£o de novos n√≥s candidatos pelo programa, cada n√≥ √© verificado com uma tabela de hash dos n√≥s j√° visitados.  Se j√° estiver na tabela de hash, o n√≥ ser√° ignorado.  Caso contr√°rio, ele ser√° adicionado √† fila e √† tabela de hash.  √Äs vezes, nas implementa√ß√µes, as informa√ß√µes "visitadas" s√£o inseridas nos n√≥s, e n√£o em uma tabela estrangeira;  mas essa √© uma otimiza√ß√£o arriscada e √© completamente imposs√≠vel se o gr√°fico for implicitamente especificado. <br><br>  Por que o uso de uma tabela de hash √© problem√°tico?  Como as tabelas de hash tendem a criar um padr√£o de acesso √† mem√≥ria completamente aleat√≥rio.  Caso contr√°rio, essa √© uma fun√ß√£o de hash incorreta e a tabela de hash provavelmente ter√° um desempenho ruim devido a colis√µes.  Esse padr√£o de acesso aleat√≥rio pode causar problemas de desempenho, mesmo que os dados caibam na mem√≥ria: o acesso a uma enorme tabela de hash provavelmente causar√° erros de cache e TLBs (associat translation translation buffers).  Mas e se uma parte significativa dos dados estiver no disco e n√£o na mem√≥ria?  As consequ√™ncias ser√£o catastr√≥ficas: algo da ordem de 10 ms por opera√ß√£o de pesquisa. <br><br>  Com 10 bilh√µes de estados √∫nicos, apenas o acesso √† tabela de hash levar√° cerca de quatro meses para aguardar a E / S do disco.  Isso n√£o nos conv√©m;  a tarefa deve definitivamente ser transformada para que o programa possa processar grandes pacotes de dados de uma s√≥ vez. <br><br><h2>  BFS com classifica√ß√£o e mesclagem </h2><br>  Se quis√©ssemos integrar o m√°ximo poss√≠vel as opera√ß√µes de acesso a dados nos pacotes, qual seria a aproxima√ß√£o m√°xima poss√≠vel?  Como o programa n√£o sabe quais n√≥s processar em uma camada de profundidade N + 1 at√© que a camada N seja completamente processada, parece √≥bvio que √© necess√°rio deduplicar os estados pelo menos uma vez por profundidade. <br><br>  Se trabalharmos com toda a camada ao mesmo tempo, podemos abandonar as tabelas de hash e descrever o conjunto de estados visitados e novos como alguns fluxos classificados (por exemplo, como fluxos de arquivos, matrizes, listas).  Podemos encontrar trivialmente o novo conjunto visitado combinando os conjuntos de fluxos e √© igualmente trivial encontrar todo o conjunto usando a diferen√ßa de conjuntos. <br><br>  Duas opera√ß√µes com conjuntos podem ser combinadas para que funcionem de uma s√≥ vez com os dois encadeamentos.  De fato, examinamos os dois fluxos, processamos o elemento menor e avan√ßamos ao longo do fluxo do qual o elemento foi retirado (ou ao longo dos dois fluxos, se os elementos no in√≠cio forem os mesmos).  Nos dois casos, adicionamos o item ao novo conjunto visitado.  Em seguida, avan√ßamos ao longo do fluxo de novos estados e tamb√©m adicionamos um elemento ao novo conjunto de tarefas: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> visited = Stream() todo = Stream() visited.add(start) todo.add(start) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: new = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> todo: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): new.push_back(kid) new_stream = Stream() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> new.sorted().uniq(): new_stream.add(node) todo, visited = merge_sorted_streams(new_stream, visited) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> <span class="hljs-comment"><span class="hljs-comment"># Merges sorted streams new and visited. Return a sorted stream of # elements that were just present in new, and another sorted # stream containing the elements that were present in either or # both of new and visited. def merge_sorted_streams(new, visited): out_todo, out_visited = Stream(), Stream() while visited or new: if visited and new: if visited.peek() == new.peek(): out_visited.add(visited.pop()) new.pop() elif visited.peek() &lt; new.peek(): out_visited.add(visited.pop()) elif visited.peek() &gt; new.peek(): out_todo.add(new.peek()) out_visited.add(new.pop()) elif visited: out_visited.add(visited.pop()) elif new: out_todo.add(new.peek()) out_visited.add(new.pop()) return out_todo, out_visited</span></span></code> </pre> <br>  O padr√£o de acesso a dados agora √© completamente linear e previs√≠vel; n√£o h√° acessos arbitr√°rios durante a fus√£o.  Portanto, o atraso nas opera√ß√µes do disco n√£o se torna importante para n√≥s e a √∫nica coisa que permanece importante √© a largura de banda. <br><br>  Como ser√° o desempenho te√≥rico com uma distribui√ß√£o simplificada de dados acima de 100 n√≠veis de profundidade, cada um com 100 milh√µes de estados?  O estado m√©dio ser√° lido e gravado 50 vezes.  Isso fornece 10 bytes / estado * 5 bilh√µes de estados * 50 = 2,5 TB.  Meu disco r√≠gido pode presumivelmente ler e gravar a uma velocidade m√©dia de 100 MB / s, ou seja, em m√©dia a E / S levar√° (2 * 2,5 TB) / (100 MB / s) = ~ 50k / s = ~ 13 horas .  Este √© um n√∫mero de pedidos menor que o resultado anterior (quatro meses)! <br><br>  Tamb√©m √© importante notar que esse modelo simplificado n√£o leva em considera√ß√£o o tamanho dos novos estados gerados.  Antes da etapa de mesclagem, eles devem ser armazenados na mem√≥ria para classifica√ß√£o + deduplica√ß√£o.  Abordaremos isso nas se√ß√µes abaixo. <br><br><h2>  Compress√£o </h2><br>  Na introdu√ß√£o, eu disse que nos experimentos iniciais, a compacta√ß√£o de estado n√£o parecia promissora e a taxa de compacta√ß√£o era de apenas 30%.  Mas, depois de fazer altera√ß√µes no algoritmo, os estados foram simplificados.  Eles devem ser muito mais f√°ceis de compactar. <br><br>  Para testar essa teoria, usei o zstd com um quebra-cabe√ßa de 14,6 milh√µes de estados, cada um dos quais com 8 bytes de tamanho.  Ap√≥s a classifica√ß√£o, eles foram compactados em m√©dia para 1,4 bytes por estado.  Parece um passo s√©rio em frente.  N√£o √© suficiente executar o programa inteiro na mem√≥ria, mas pode reduzir o tempo de E / S do disco para apenas algumas horas. <br><br>  √â poss√≠vel, de alguma forma, melhorar o resultado do moderno algoritmo de compacta√ß√£o de uso geral se soubermos algo sobre a estrutura de dados?  Voc√™ pode ter quase certeza disso.  Um bom exemplo disso √© o formato PNG.  Teoricamente, a compacta√ß√£o √© apenas uma passagem padr√£o do Deflate.  Mas, em vez de compactar dados brutos, a imagem √© convertida primeiro usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">filtros PNG</a> .  O filtro PNG √© essencialmente uma f√≥rmula para prever o valor de um byte de dados brutos com base no valor do mesmo byte na linha anterior e / ou no mesmo byte do pixel anterior.  Por exemplo, o filtro "para cima" converte cada byte subtraindo os valores da linha anterior ao compactar e executando a opera√ß√£o oposta ao desembalar.  Dados os tipos de imagens para os quais o PNG √© usado, o resultado quase sempre consistir√° em zeros ou n√∫meros pr√≥ximos a zero.  Deflate pode compactar esses dados muito melhor do que dados brutos. <br><br>  Esse princ√≠pio pode ser aplicado aos registros de estado do BFS?  Parece que isso deveria ser poss√≠vel.  Assim como no PNG, temos um tamanho de linha constante e podemos esperar que as linhas adjacentes sejam muito semelhantes.  As primeiras amostras com o filtro de subtra√ß√£o / adi√ß√£o, seguidas por zstd, levaram a uma melhoria na taxa de compacta√ß√£o em outros 40%: 0,87 bytes por estado.  As opera√ß√µes de filtragem s√£o triviais, portanto, do ponto de vista do consumo de CPU, elas s√£o praticamente "gratuitas". <br><br>  N√£o estava claro para mim se outras melhorias poderiam ser feitas ou se esse era um limite pr√°tico.  Nos dados da imagem, voc√™ pode esperar logicamente que os bytes adjacentes da mesma linha sejam semelhantes.  Mas nesses estados n√£o existe.  Mas, na verdade, filtros um pouco mais sofisticados ainda podem melhorar os resultados.  No final, eu vim para este sistema: <br><br>  Suponha que tenhamos linhas adjacentes R1 = [1, 2, 3, 4] e R2 = [1, 2, 6, 4].  Ao emitir R2, comparamos cada byte com o mesmo byte da linha anterior, e 0 indica uma correspond√™ncia e 1 indica uma incompatibilidade: diff = [0, 0, 1, 0].  Em seguida, passamos esse bitmap, codificado como VarInt, seguido por apenas bytes que n√£o correspondem √† linha anterior.  Neste exemplo, obtemos dois bytes 0b00000100 6. Por si s√≥, esse filtro compacta os dados de refer√™ncia para 2,2 bytes / estado.  Mas, combinando o filtro + zstd, reduzimos o tamanho dos dados para 0,42 bytes / estado.  Ou, em outras palavras, isso equivale a 3,36 bits por estado, o que √© um pouco mais do que nossos indicadores calculados aproximados necess√°rios para garantir que todos os dados se ajustem √† RAM. <br><br>  Na pr√°tica, as taxas de compacta√ß√£o melhoram porque os conjuntos classificados se tornam mais densos.  Quando a pesquisa chega ao ponto em que a mem√≥ria come√ßa a causar problemas, as taxas de compacta√ß√£o podem ficar muito melhores.  O maior problema √© que, no final, temos 4,6 bilh√µes de estados visitados.  Ap√≥s a classifica√ß√£o, esses estados ocupam 405 MB e s√£o compactados de acordo com o esquema apresentado acima.  Isso nos d√° <b>0,7 bits por estado</b> .  No final, a compacta√ß√£o e descompacta√ß√£o ocupam cerca de 25% do tempo de CPU do programa, mas esse √© um excelente compromisso para reduzir o consumo de mem√≥ria em cem vezes. <br><br>  O filtro acima parece um pouco caro devido ao cabe√ßalho VarInt em cada linha.  Parece f√°cil atualizar com o custo baixo da CPU ou com um ligeiro aumento na complexidade.  Tentei v√°rias op√ß√µes diferentes, transpondo dados em ordem por colunas ou escrevendo m√°scaras de bits em blocos maiores, etc.  Somente essas op√ß√µes geraram taxas de compacta√ß√£o muito mais altas, mas n√£o tiveram um desempenho t√£o bom quando a sa√≠da do filtro foi compactada pelo zstd.  E n√£o foi algum tipo de erro zstd, os resultados com gzip e bzip2 foram semelhantes.  N√£o tenho teorias particularmente engenhosas sobre por que esse tipo espec√≠fico de codifica√ß√£o se mostrou muito melhor em compress√£o do que outras op√ß√µes. <br><br>  Outro mist√©rio: a taxa de compacta√ß√£o se mostrou muito melhor quando os dados s√£o classificados por little-endian, em vez de big-endian.  Inicialmente, pensei que isso acontecesse, porque na classifica√ß√£o little-endiana existem mais zeros √† esquerda com a m√°scara de bits codificada por VarInt.  Mas essa diferen√ßa persiste mesmo com filtros que n√£o possuem essas depend√™ncias. <br><br>  (H√° muita pesquisa sobre a compacta√ß√£o de conjuntos ordenados de n√∫meros inteiros, porque eles s√£o os componentes b√°sicos dos mecanismos de pesquisa. No entanto, n√£o encontrei muita informa√ß√£o sobre a compacta√ß√£o de registros classificados de comprimento constante e n√£o queria adivinhar, apresentando os dados como valores inteiros com precis√£o arbitr√°ria.) <br><br><h2>  Oh-oh, eu trapacei! </h2><br>  Voc√™ deve ter notado que as implementa√ß√µes de BFS acima no pseudo-c√≥digo retornam apenas valores booleanos - a solu√ß√£o foi encontrada / n√£o foi encontrada.  Isso n√£o √© particularmente √∫til.  Na maioria dos casos, precisaremos criar uma lista das etapas exatas da solu√ß√£o, e n√£o apenas informar sobre a disponibilidade da solu√ß√£o. <br><br>  A princ√≠pio, parece que esse problema √© f√°cil de resolver.  Em vez de coletar conjuntos de estados, voc√™ precisa coletar rela√ß√µes de estado com os estados pai.  Depois de encontrar a solu√ß√£o, voc√™ pode simplesmente voltar da lista de solu√ß√µes dos pais do in√≠cio ao fim.  Para uma solu√ß√£o baseada em tabela de hash, isso seria algo como isto: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> visited = {start: <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>} todo = [start] <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> todo: node = todo.pop_first() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> trace_solution(node, visited) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> visited: visited[kid] = node todo.push_back(kid) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">trace_solution</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(state, visited)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> state <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [] <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> trace_solution(start, visited[state]) + [state]</code> </pre> <br>  Infelizmente, isso destruir√° todos os benef√≠cios de compacta√ß√£o obtidos na se√ß√£o anterior;  eles s√£o baseados no pressuposto de que as linhas adjacentes s√£o muito semelhantes.  Quando olhamos para os pr√≥prios estados, isso √© verdade.  Mas n√£o h√° raz√£o para acreditar que isso seja verdade para os estados parentais;  de fato, s√£o dados aleat√≥rios.  Em segundo lugar, uma solu√ß√£o de classifica√ß√£o + mesclagem deve ler e gravar todos os estados exibidos em cada itera√ß√£o.  Para salvar a liga√ß√£o do estado / estado pai, precisamos ler e gravar no disco a cada itera√ß√£o todos esses dados mal compactados. <br><br><h2>  Classificar + mesclar com v√°rias sa√≠das </h2><br>  No final, ao retornar √† solu√ß√£o, o programa precisar√° apenas de pacotes de estados / estados principais, portanto, podemos armazenar duas estruturas de dados em paralelo.  Visitados continuar√° sendo o conjunto de estados visitados, conforme recalculado anteriormente durante a mesclagem.  Pais √© pelo menos uma lista classificada de pares de estado / estado pai que n√£o s√£o substitu√≠dos.  Ap√≥s cada opera√ß√£o de mesclagem, o par "estado + estado pai" √© adicionado aos pais. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> parents = Stream() visited = Stream() todo = Stream() parents.add((start, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>)) visited.add(start) todo.add(start) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: new = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> todo: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> trace_solution(node, parents) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): new.push_back(kid) new_stream = Stream() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> new.sorted().uniq(): new_stream.add(node) todo, visited = merge_sorted_streams(new_stream, visited, parents) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-comment"><span class="hljs-comment"># Merges sorted streams new and visited. New contains pairs of # key + value (just the keys are compared), visited contains just # keys. # # Returns a sorted stream of keys that were just present in new, # another sorted stream containing the keys that were present in either or # both of new and visited. Also adds the keys + values to the parents # stream for keys that were only present in new. def merge_sorted_streams(new, visited, parents): out_todo, out_visited = Stream(), Stream() while visited or new: if visited and new: visited_head = visited.peek() new_head = new.peek()[0] if visited_head == new_head: out_visited.add(visited.pop()) new.pop() elif visited_head &lt; new_head: out_visited.add(visited.pop()) elif visited_head &gt; new_head: out_todo.add(new_head) out_visited.add(new_head) out_parents.add(new.pop()) elif visited: out_visited.add(visited.pop()) elif new: out_todo.add(new.peek()[0]) out_visited.add(new.peek()[0]) out_parents.add(new.pop()) return out_todo, out_visited</span></span></code> </pre> <br>  Isso nos permite tirar proveito de ambas as abordagens em termos de tempo de execu√ß√£o e conjuntos de trabalho, mas requer mais espa√ßo de armazenamento secund√°rio.  Al√©m disso, no futuro, por outras raz√µes, uma c√≥pia separada dos estados visitados ser√° √∫til, agrupada por profundidade. <br><br><h2>  Trocar </h2><br>  Outro detalhe √© ignorado no pseudo-c√≥digo: n√£o h√° c√≥digo expl√≠cito para a E / S do disco, mas apenas a interface abstrata do Stream.  O fluxo pode ser um fluxo de arquivo ou uma matriz dentro da mem√≥ria, mas ignoramos esses detalhes de implementa√ß√£o.  Em vez disso, o pseudo-c√≥digo est√° criando um padr√£o de acesso √† mem√≥ria que permite o uso ideal do disco.  Em um mundo ideal, isso seria suficiente e o restante poderia ser ocupado pelo subsistema de mem√≥ria virtual do SO. <br><br>  Mas isso n√£o acontece, pelo menos no Linux.  Em algum momento (antes que o conjunto de dados de trabalho pudesse ser compactado para tamanhos de mem√≥ria), o programa foi executado em cerca de 11 horas e os dados foram salvos principalmente no disco.  Ent√£o fiz o programa usar p√°ginas an√¥nimas em vez de armazenadas em arquivos, e selecionei um arquivo de troca de tamanho suficiente na mesma unidade.  No entanto, tr√™s dias depois, o programa percorreu apenas um quarto do caminho e, mesmo assim, com o tempo, ficou mais lento.  De acordo com minhas estimativas otimistas, ela deveria terminar o trabalho em 20 dias. <br><br>  Vou esclarecer: era o mesmo c√≥digo e <i>exatamente o mesmo padr√£o de acesso</i> .  A √∫nica coisa que mudou foi que a mem√≥ria foi salva n√£o como um arquivo de disco expl√≠cito, mas como uma troca.  Quase n√£o s√£o necess√°rias evid√™ncias de que a troca destrua completamente o desempenho do Linux, enquanto a E / S de arquivo regular n√£o.  Sempre presumi que isso se deve ao fato de os programas tenderem a considerar a RAM como mem√≥ria de acesso aleat√≥rio.  Mas esse n√£o √© o caso. <br><br>  Acontece que p√°ginas para salvar arquivos e p√°ginas an√¥nimas s√£o tratadas de maneira diferente pelo subsistema de m√°quina virtual.  Eles s√£o armazenados em caches LRU separados com pol√≠ticas de expira√ß√£o diferentes;  al√©m disso, parece que eles t√™m diferentes propriedades de leitura / carregamento de leitura antecipada. <br><br>  Agora eu sei: a troca no Linux provavelmente n√£o funcionar√° bem, mesmo em condi√ß√µes ideais.  Se √© prov√°vel que partes do espa√ßo de endere√ßo sejam descarregadas por algum tempo no disco, √© melhor salv√°-las manualmente em arquivos do que confiar na troca.  Consegui isso implementando minha pr√≥pria classe de vetores, que inicialmente funciona apenas na mem√≥ria e, ap√≥s exceder um determinado limite de tamanho, ele muda para o mmap em um arquivo separado tempor√°rio. <br><br><h2>  Compacta√ß√£o de novos estados antes da mesclagem </h2><br>  Em um modelo de desempenho simplificado, assumimos que 100 milh√µes de novas condi√ß√µes ocorreriam a cada profundidade.  Verificou-se que isso n√£o est√° muito longe da realidade (no quebra-cabe√ßa mais complexo, um m√°ximo de mais de 150 milh√µes de novos estados √∫nicos em uma camada de profundidade).  Mas isso n√£o deve ser medido;  o conjunto de trabalho antes da mesclagem est√° associado n√£o apenas a estados exclusivos, mas tamb√©m a todos os estados deduzidos para essa itera√ß√£o.  Esse n√∫mero atinge 880 milh√µes de estados de sa√≠da por camada de profundidade.  Esses 880 milh√µes de estados a) precisam ser processados ‚Äã‚Äãcom um padr√£o de acesso aleat√≥rio para classifica√ß√£o; b) n√£o podem ser efetivamente compactados devido √† falta de classifica√ß√£o; c) devem ser armazenados juntamente com o estado pai.  Este conjunto de trabalho tem aproximadamente 16 GB. <br><br>  A solu√ß√£o √≥bvia: use algum tipo de classifica√ß√£o externa.  Basta gravar todos os estados no disco, executar classifica√ß√£o externa, desduplicar e mesclar como de costume.  No come√ßo, usei essa solu√ß√£o e, embora no m√°ximo eliminasse o problema A, n√£o conseguia lidar com B e C. <br><br>  No final, adotei uma abordagem alternativa: coletei os estados em uma matriz na mem√≥ria.  Se a matriz se tornar muito grande (por exemplo, mais de 100 milh√µes de elementos), ela ser√° classificada, deduplicada e compactada.  Isso nos fornece um pacote de execu√ß√µes de estado classificadas e n√£o h√° duplicatas dentro de cada execu√ß√£o, mas elas s√£o poss√≠veis entre as execu√ß√µes.  Fundamentalmente, o c√≥digo para mesclar estados novos e visitados permanece o mesmo;  ainda √© baseado em uma passagem gradual pelas correntes.  A √∫nica diferen√ßa √© que, em vez de apenas passar por dois fluxos, existe um fluxo separado para cada uma das execu√ß√µes classificadas de novos estados. <br><br>  Obviamente, as taxas de compacta√ß√£o dessas execu√ß√µes de 100 milh√µes de estados n√£o s√£o t√£o boas quanto a compacta√ß√£o do conjunto de todos os estados visitados.  Mas mesmo com esses indicadores, reduz significativamente o volume do conjunto de trabalho e os requisitos de E / S do disco.  Voc√™ precisa de um pouco mais de recursos de CPU para processar a fila priorit√°ria de threads, mas ainda √© um grande compromisso. <br><br><h2>  Economizando espa√ßo nos estados pai </h2><br>  Nesse est√°gio, a grande maioria do espa√ßo ocupado pelo programa √© gasta no armazenamento dos estados pais, para que, depois de encontrar a solu√ß√£o, possamos recriar seu processo.  Provavelmente, eles dificilmente podem ser espremidos bem, mas talvez haja algum tipo de compromisso entre a CPU e a mem√≥ria? <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Precisamos conectar o estado S 'na profundidade D + 1 ao estado pai S na profundidade D. Se pudermos iterar todos os estados parentais poss√≠veis S', podemos verificar se algum deles aparece na profundidade D no conjunto visitado. . (J√° criamos muitas visitas, agrupadas por profundidade como um subproduto conveniente da deriva√ß√£o de pacotes de estado / estado parental durante a mesclagem). Infelizmente, essa abordagem n√£o funcionar√° para esta tarefa; √© simplesmente muito dif√≠cil para n√≥s gerar todos os estados poss√≠veis de S para um dado S '. No entanto, para muitas outras tarefas de pesquisa, essa solu√ß√£o pode funcionar.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Se apenas podemos gerar transi√ß√µes entre estados para a frente, mas n√£o para tr√°s, por que n√£o fazer isso? Vamos analisar iterativamente todos os estados na profundidade D e ver que tipo de estados de sa√≠da eles obt√™m. Se algum estado na sa√≠da der S ', encontramos um S. adequado. O problema com este plano √© que ele aumenta o consumo total de CPU do programa em 50%. (N√£o 100%, porque, em m√©dia, encontraremos S olhando a metade dos estados na profundidade D).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Portanto, n√£o gosto de nenhum dos casos limitantes, mas aqui, pelo menos, √© poss√≠vel um compromisso entre a CPU / mem√≥ria. </font><font style="vertical-align: inherit;">Existe uma solu√ß√£o mais aceit√°vel em algum lugar? </font><font style="vertical-align: inherit;">No final, decidi n√£o armazenar o par (S ', S), mas o par (S', H (S)), onde H √© uma fun√ß√£o hash de 8 bits. </font><font style="vertical-align: inherit;">Para encontrar S para um dado S ', repetimos iterativamente todos os estados na profundidade D. Mas antes de fazer qualquer outra coisa, calculamos o mesmo hash. </font><font style="vertical-align: inherit;">Se a sa√≠da n√£o corresponder a H (S), esse n√£o √© o estado que estamos procurando e podemos simplesmente ignor√°-lo. </font><font style="vertical-align: inherit;">Essa otimiza√ß√£o significa que rec√°lculos caros precisam ser executados apenas para 1/256 estados, o que representa um pequeno aumento na carga da CPU e, ao mesmo tempo, reduzem a quantidade de mem√≥ria para armazenar estados-pai de 8 a 10 bytes a 1 byte.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O que n√£o funcionou ou pode n√£o funcionar </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nas se√ß√µes anteriores, examinamos a sequ√™ncia de otimiza√ß√µes de alto n√≠vel que funcionaram. Tentei outras coisas que n√£o funcionaram ou que encontrei na literatura, mas decidi que, nesse caso espec√≠fico, elas n√£o funcionariam. Aqui est√° uma lista parcial.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neste ponto, n√£o recalculo o conjunto inteiro visitado em cada itera√ß√£o. Em vez disso, ele era armazenado como muitas execu√ß√µes classificadas, e essas execu√ß√µes eram compactadas de tempos em tempos. A vantagem dessa abordagem √© que menos grava√ß√µes em disco e recursos da CPU s√£o usados ‚Äã‚Äãpara compacta√ß√£o. A desvantagem √© o aumento da complexidade do c√≥digo e a taxa de compacta√ß√£o reduzida. Inicialmente, achei que esse esquema fazia sentido, porque no meu caso, as opera√ß√µes de grava√ß√£o s√£o mais caras que a leitura. Mas, no final, a taxa de compress√£o acabou sendo duas vezes maior. As vantagens de tal compromisso n√£o s√£o √≥bvias, portanto, como resultado, voltei a uma forma mais simples. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">J√° foram realizados pequenos estudos sobre a realiza√ß√£o de uma pesquisa volum√©trica de largura em primeiro lugar para gr√°ficos definidos implicitamente no armazenamento secund√°rio. Voc√™ pode come√ßar a explorar este t√≥pico</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">deste artigo de 2008</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Como voc√™ pode imaginar, a id√©ia de desduplicar junto com a classifica√ß√£o + mesclagem no armazenamento secund√°rio n√£o √© nova. O que √© surpreendente sobre isso √© que ele foi aberto apenas em 1993. Muito tarde! Existem sugest√µes posteriores para a pesquisa pela primeira vez no armazenamento secund√°rio que n√£o exigem uma etapa de classifica√ß√£o. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um deles era vincular estados a n√∫meros inteiros e armazenar na mem√≥ria um bitmap dos estados visitados. No meu caso, isso √© completamente in√∫til, porque os tamanhos do estado codificado s√£o muito diferentes em compara√ß√£o com os espa√ßos de estado realmente alcan√ß√°veis. E duvido muito que haja problemas interessantes nos quais essa abordagem funcionaria.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Outra alternativa s√©ria √© baseada em tabelas de hash tempor√°rias. Os estados visitados s√£o armazenados sem classifica√ß√£o em um arquivo. Salvamos a sa√≠da obtida da profundidade D na tabela de hash. Em seguida, percorra os estados visitados iterativamente e procure-os na tabela de hash. Se o item for encontrado na tabela de hash, exclua-o. Depois de percorrer o arquivo inteiro de forma iterativa, apenas elementos n√£o duplicados permanecer√£o nele. Eles s√£o adicionados ao arquivo e usados ‚Äã‚Äãpara inicializar a lista de tarefas para a pr√≥xima itera√ß√£o. Se a quantidade de sa√≠da for t√£o grande que a tabela de hash n√£o couber na mem√≥ria, os arquivos e as tabelas de hash poder√£o ser divididos em partes usando o mesmo crit√©rio (por exemplo, os bits de status superiores) e cada parte dever√° ser processada separadamente. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Embora haja </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">benchmarks</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mostrando que a abordagem baseada em hash √© cerca de 30% mais r√°pida que a classifica√ß√£o + mesclagem, mas parece que elas n√£o levam em considera√ß√£o a compacta√ß√£o. Eu simplesmente n√£o vi como a rejei√ß√£o dos benef√≠cios da compacta√ß√£o pode se justificar, ent√£o nem experimentei essas abordagens. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Outra √°rea de pesquisa digna de aten√ß√£o foi a otimiza√ß√£o de consultas ao banco de dados. Parece que sim. que a tarefa de desduplica√ß√£o est√° fortemente relacionada √† jun√ß√£o ao banco de dados, que tamb√©m possui exatamente o mesmo </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dilema de </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classifica√ß√£o versus hash</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Obviamente, alguns desses estudos podem ser aplicados ao problema de pesquisa. A diferen√ßa pode ser que a sa√≠da do banco de dados de jun√ß√£o seja tempor√°ria, enquanto a sa√≠da de deduplica√ß√£o do BFS √© armazenada at√© o final do c√°lculo. Parece que isso est√° mudando o equil√≠brio de compromissos: agora, ele diz respeito n√£o apenas ao processamento mais eficiente de uma itera√ß√£o, mas tamb√©m √† cria√ß√£o do formato de dados de sa√≠da mais ideal para a pr√≥xima itera√ß√£o.</font></font><br><br><h2>  Conclus√£o </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Isso conclui minha conta do que aprendi de um projeto que geralmente √© aplic√°vel a outras tarefas de pesquisa por for√ßa bruta. </font><font style="vertical-align: inherit;">A combina√ß√£o desses truques permitiu reduzir o volume de solu√ß√µes para os quebra-cabe√ßas mais complexos do jogo de 50-100 GB para 500 MB e aumentar suavemente os custos se a tarefa exceder a mem√≥ria dispon√≠vel e for gravada em disco. </font><font style="vertical-align: inherit;">Al√©m disso, minha solu√ß√£o √© 50% mais r√°pida que uma desduplica√ß√£o ing√™nua de estados com base em tabelas de hash, mesmo para quebra-cabe√ßas que se encaixam na mem√≥ria. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O Snakebird pode ser comprado no </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Steam</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google Play</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">App Store</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Eu o recomendo para quem estiver interessado em quebra-cabe√ßas muito complexos, mas honestos.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt455537/">https://habr.com/ru/post/pt455537/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt455525/index.html">Zimbra e Mail Bomb Defense</a></li>
<li><a href="../pt455527/index.html">O que est√° escrito nisso? Nos bastidores dos objetos JavaScript</a></li>
<li><a href="../pt455529/index.html">Como reverter e invadir o disco r√≠gido externo auto-criptografado do Aigo. Parte 2: Despejando com Cypress PSoC</a></li>
<li><a href="../pt455533/index.html">F√≠sica da bolha: uma busca pelo mecanismo de destrui√ß√£o da espuma</a></li>
<li><a href="../pt455535/index.html">Gerenciando certificados SSL / TLS nas nuvens e cont√™ineres - n√£o no trabalho humano</a></li>
<li><a href="../pt455539/index.html">Videntes m√≥veis: 10 fatos novos sobre como os dispositivos vest√≠veis est√£o observando voc√™</a></li>
<li><a href="../pt455543/index.html">O Kubernetes Cluster √© f√°cil e conveniente de preparar? Anunciar addon-operator</a></li>
<li><a href="../pt455545/index.html">Processos de constru√ß√£o do zero: do caos ao pedido</a></li>
<li><a href="../pt455547/index.html">Internet das coisas em russo. Baseband Hotel LoRaWAN para propriet√°rios de RTL-SDR</a></li>
<li><a href="../pt455549/index.html">Como usar grupos do Facebook para promover: criar uma web</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
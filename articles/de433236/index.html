<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª‚Äçüåæ ü§öüèæ ü§¥üèº Der Chef von Google glaubt, dass die Angst vor KI "v√∂llig gerechtfertigt" ist. üßõüèø üß§ üéöÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sundar Pichai, CEO von Google, einem der gr√∂√üten Unternehmen auf dem Gebiet der k√ºnstlichen Intelligenz, sagte in einem Interview in dieser Woche, das...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Der Chef von Google glaubt, dass die Angst vor KI "v√∂llig gerechtfertigt" ist.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/433236/"><img src="https://habrastorage.org/getpro/habr/post_images/a3b/dcb/b48/a3bdcbb48a6abae827d4f070ba57e363.jpg"><br><br>  Sundar Pichai, CEO von Google, einem der gr√∂√üten Unternehmen auf dem Gebiet der k√ºnstlichen Intelligenz, sagte in einem Interview in dieser Woche, dass Bef√ºrchtungen hinsichtlich des sch√§dlichen Einsatzes von Technologie ‚Äûv√∂llig berechtigt‚Äú seien - wir m√ºssen jedoch der Technologiebranche vertrauen, dass dies m√∂glich sein wird Alle Verantwortung f√ºr die Regulierung seiner Verwendung. <br><br>  In einem Interview mit der Washington Post sagte Pichai, dass neue KI-Tools - die Grundlage f√ºr Innovationen wie Robomobile und Algorithmen zur Erkennung von Krankheiten - von Unternehmen verlangen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, einen ethischen Rahmen</a> zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">definieren</a> und sorgf√§ltig zu √ºberlegen, wie diese Technologie missbraucht werden kann. <br><a name="habracut"></a><br>  "Ich denke, das Technologieunternehmen sollte verstehen, dass man es nicht zuerst erstellen und dann reparieren kann", sagte Pichai.  "Ich denke, es wird nicht funktionieren." <br><br>  Technologische Giganten m√ºssen sicherstellen, dass KI ‚Äûmit ihren Zielen‚Äú der Menschheit keinen Schaden zuf√ºgt, sagte Pichai.  Er sagte, er sei optimistisch hinsichtlich der langfristigen Vorteile der Technologie, aber seine Einsch√§tzung der potenziellen Risiken der KI stimme mit einigen der Technologiekritiker √ºberein, die behaupten, dass die Technologie verwendet werden k√∂nnte, um invasive √úberwachung einzuf√ºhren, t√∂dliche Waffen herzustellen und Fehlinformationen zu verbreiten.  Andere Manager von Technologieunternehmen, wie der Gr√ºnder von SpaceX und Tesla, Elon Musk, machten mutige Vorhersagen, dass KI "viel gef√§hrlicher als Atombomben" sein k√∂nnte. <br><br>  Die KI-Technologie von Google steht im Mittelpunkt aller Aktivit√§ten, von einem umstrittenen chinesischen Unternehmensprojekt bis hin zu Hass- und Verschw√∂rungstheorien auf YouTube, einer Abteilung des Unternehmens.  Pichai versprach, dieses Problem n√§chstes Jahr zu l√∂sen.  Die Art und Weise, wie Google sich f√ºr die Verwendung von KI entscheidet, hat in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">j√ºngster Zeit auch zu Unruhen</a> bei den Mitarbeitern des Unternehmens gef√ºhrt. <br><br>  Pichais Aufruf zur Selbstregulierung folgte seiner <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rede im Kongress</a> , wo der Gesetzgeber drohte, den Einsatz von Technologie als Reaktion auf deren Missbrauch einzuschr√§nken, auch als Vermittler f√ºr die Verbreitung von Fehlinformationen und Hassreden [Hassreden].  Seine Anerkennung der Existenz m√∂glicher Bedrohungen durch die KI-Seite war von entscheidender Bedeutung, da der in Indien geborene Programmierer fr√ºher oft ank√ºndigte, wie die Konsequenzen der Einf√ºhrung automatisierter Systeme, die ohne menschliche Aufsicht lernen und Entscheidungen treffen k√∂nnen, die Welt ver√§ndern w√ºrden. <br><br>  Pichai sagte in einem Interview, dass Gesetzgeber auf der ganzen Welt immer noch versuchen, die Auswirkungen der KI und die potenzielle Notwendigkeit ihrer staatlichen Regulierung zu erkennen.  "Manchmal st√∂rt es mich, dass die Leute das Ausma√ü der kurz- und mittelfristigen Ver√§nderungen untersch√§tzen, und ich denke, dass diese Probleme tats√§chlich √§u√üerst komplex sind", sagte er.  Andere Technologie-Giganten, darunter Microsoft, haben k√ºrzlich die KI-Regulierung √ºbernommen, sowohl von den Unternehmen, die diese Technologie entwickeln, als auch von den Regierungen, die ihre Verwendung √ºberwachen. <br><br>  Bei richtiger Handhabung kann KI jedoch ‚Äûenorme Vorteile‚Äú bieten, erkl√§rte Pichai, einschlie√ülich der Unterst√ºtzung von √Ñrzten bei der Erkennung von Augenkrankheiten und anderen Krankheiten durch automatisches Scannen von Krankenakten.  "Die Regulierung der Technologie in einem fr√ºhen Stadium der Entwicklung ist schwierig, aber ich denke, dass Unternehmen sich selbst regulieren sollten", sagte er.  - Deshalb versuchen wir so aktiv, die Prinzipien der KI auszusprechen.  Wir haben vielleicht nicht alles richtig gemacht, aber wir hielten es f√ºr wichtig, diesen Dialog zu beginnen. ‚Äú <br><br>  Pichai, der 2004 zu Google kam und nach seiner √úbernahme als CEO AI im Januar als ‚Äûeines der wichtigsten Dinge, an denen die Menschheit arbeitet‚Äú bezeichnete, sagte, dass es f√ºr die Menschheit ‚Äûwichtiger‚Äú sein k√∂nnte als ‚ÄûElektrizit√§t oder Feuer. "  Der Wettlauf um die Verbesserung von Maschinen, die selbstst√§ndig betrieben werden k√∂nnen, hat jedoch zu den bekannten Bef√ºrchtungen gef√ºhrt, dass der Unternehmensgeist von Silicon Valley - ‚Äûschnell machen, Schaden anrichten‚Äú, wie Facebook es einmal beschrieben hat - dazu f√ºhren k√∂nnte, dass leistungsstarke und unvollst√§ndige Technologien Arbeitspl√§tze beseitigen und Schaden anrichten zu Menschen. <br><br>  Bei Google selbst sind Versuche, KI zu erstellen, ebenfalls umstritten: Das Unternehmen wurde in diesem Jahr wegen der Arbeit an einem Vertrag f√ºr das Verteidigungsministerium heftig kritisiert, wonach KI, die Autos, Geb√§ude und andere Objekte automatisch markieren kann, in Milit√§rdrohnen eingesetzt wird.  Einige Mitarbeiter k√ºndigten sogar und nannten den Grund daf√ºr die Einnahmen des Unternehmens im "Milit√§rgesch√§ft". <br><br>  Pichai antwortete der Zeitung auf Fragen zu dieser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Reaktion der Mitarbeiter,</a> dass diese Mitarbeiter ‚Äûein wichtiger Teil unserer Kultur seien.  Sie haben die M√∂glichkeit, ihr Wort zu sagen, und das ist wichtig f√ºr das Unternehmen, das sch√§tzen wir ‚Äú, sagte er. <br><br>  Im Juni, nach der Ank√ºndigung, dass das Unternehmen diesen Vertrag nicht verl√§ngern werde, enth√ºllte Pichai bei der Schaffung von KI eine Reihe ethischer Grunds√§tze, darunter ein Verbot der Entwicklung von Systemen, die dazu dienen k√∂nnten, Schaden zu verursachen, Menschenrechte zu verletzen oder Menschen zu √ºberwachen. " unter Versto√ü gegen international anerkannte Standards. ‚Äú <br><br>  Das Unternehmen wurde daf√ºr kritisiert, KI-Tools f√ºr den allgemeinen Gebrauch freizugeben, die zum Nachteil eingesetzt werden k√∂nnen.  Das 2015 ver√∂ffentlichte TensorFlow-Softwarepaket, Googles internes maschinelles Lernsystem, beschleunigte die massive Entwicklung der KI, automatisierte jedoch die Erstellung gef√§lschter Videos, die dann zur Fehlinformation und Bel√§stigung verwendet wurden. <br><br>  Google und Pichai verteidigten die Ver√∂ffentlichung pers√∂nlich und argumentierten, dass eine Einschr√§nkung der Verbreitung von Technologie bedeuten w√ºrde, dass die √ñffentlichkeit sie nicht sorgf√§ltig genug kontrollieren w√ºrde und Entwickler und Forscher ihre F√§higkeiten nicht verbessern k√∂nnten, so dass sie davon profitieren w√ºrde. <br><br>  "Ich glaube, dass es im Laufe der Zeit wichtig ist, ethische Fragen und kognitive Vorurteile zu diskutieren und gleichzeitig zu entwickeln, um Technologie erfolgreich zu entwickeln", sagte Pichai in einem Interview. <br><br>  "In gewissem Sinne wollen wir eine ethische Plattform entwickeln, um Wissenschaftler anzuziehen, die nicht aus dem Bereich der Informatik in einem fr√ºhen Stadium der Entwicklung stammen", sagte er.  "Es ist notwendig, die Menschheit aktiver einzubeziehen, da diese Technologie die Menschheit beeinflussen wird." <br><br>  Pichai verglich die fr√ºhen Versuche, KI-Parameter festzulegen, mit den Bem√ºhungen der wissenschaftlichen Gemeinschaft, die Genforschung in den fr√ºhen Stadien dieses Gebiets einzuschr√§nken.  "Viele Biologen haben begonnen, Unterscheidungen zu treffen, die angeben, wo sich die Technologie entwickeln sollte", sagte er.  "Die akademische Gemeinschaft hat eine aktive Selbstregulierung aufgenommen, die meiner Meinung nach √§u√üerst wichtig war." <br><br>  Google Director sagte, dass ein solcher Ansatz f√ºr die Entwicklung autonomer Waffen absolut notwendig w√§re - und dieses Problem qu√§lt Direktoren und Mitarbeiter von Technologieunternehmen.  Im Juli unterzeichneten Tausende von Industriearbeitern, die Unternehmen wie Google vertraten, eine Petition zum Verbot von KI-Tools, die zum T√∂ten programmiert werden k√∂nnten. <br><br>  Pichai sagte, er finde die von YouTube gehassten Verschw√∂rungstheorien, die im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">WP-Artikel</a> "ekelhaft" beschrieben sind, "ekelhaft" und machte klar, dass das Unternehmen daran arbeiten werde, Systeme zu verbessern, die problematische Inhalte erkennen.  In diesen Videos, deren Gesamtansicht seit ihrem Erscheinen im April mehrere Millionen Mal √ºberschritten wurde, diskutierten sie die unbegr√ºndeten Anschuldigungen von Hillary Clinton und ihrer langj√§hrigen Assistentin Hume Abedin, sie h√§tten das M√§dchen angegriffen, sie get√∂tet und ihr Blut getrunken. <br><br>  Pichai sagte, dass er selbst diese Videos nicht gesehen habe, denen ihm im Kongress <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fragen</a> gestellt wurden, und weigerte sich zu berichten, ob solche YouTube-Fehler das Ergebnis von Einschr√§nkungen f√ºr Systeme sind, die unangemessene Inhalte oder Regeln f√ºr die Bewertung der Notwendigkeit zum Entfernen von Videos erkennen.  Aber er f√ºgte hinzu: "2019 werden Sie von unserer Seite aus mehr Arbeit in diesem Bereich sehen." <br><br>  Pichai beschrieb auch die Versuche von Google, ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">neues Produkt</a> im von China kontrollierten Segment des Internets zu entwickeln, als vorl√§ufig und sagte nicht, um welche Art von Produkt es sich handeln k√∂nnte und wann es, wenn √ºberhaupt, auf den Markt kommen k√∂nnte. <br><br>  Er hei√üt "Project Dragonfly" und hat eine starke Gegenreaktion von Mitarbeitern und Rechtsaktivisten ausgel√∂st, die vor Googles m√∂glicher Unterst√ºtzung bei der staatlichen √úberwachung von B√ºrgern warnen, die gegen√ºber politischen Dissidenten intolerant sind.  Als Antwort auf die Frage nach der M√∂glichkeit, dass Google ein Produkt entwickelt, mit dem chinesische Beamte herausfinden k√∂nnen, wann eine Person nach sensiblen W√∂rtern wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem Massaker am Platz des Himmlischen Friedens</a> sucht <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">,</a> sagte Pichai, es sei zu fr√ºh, um solche Urteile zu f√§llen. <br><br>  "Dies sind alles hypothetische √úberlegungen", sagte Pichai.  "Wir sind furchtbar weit von diesem Zustand entfernt." </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de433236/">https://habr.com/ru/post/de433236/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de433224/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 437 (27.11.2008 - 03.12.2008)</a></li>
<li><a href="../de433226/index.html">Methodik zur Bewertung des Wissens eines Ingenieurs. Der Weg eines Architekten und der Weg eines Experten</a></li>
<li><a href="../de433228/index.html">SamsPcbGuide Teil 8: So erhalten Sie die richtige Wellenform</a></li>
<li><a href="../de433232/index.html">Lyft enth√ºllt seine Vision eines Interaktionssystems f√ºr Fu√üg√§nger</a></li>
<li><a href="../de433234/index.html">Ein perfektes Kinderm√§dchen ist erforderlich; Stellen Sie sicher, dass Sie einen KI-Scan durchf√ºhren, um Respekt und gute Manieren zu beurteilen</a></li>
<li><a href="../de433242/index.html">Giftige Maske</a></li>
<li><a href="../de433246/index.html">Framework: Analyse von DLT-Systemen</a></li>
<li><a href="../de433248/index.html">Analysieren der Speicherforensik mit OtterCTF und Einf√ºhrung des Volatility Framework</a></li>
<li><a href="../de433250/index.html">OpenVPN mit erweiterter Authentifizierung und Autorisierung</a></li>
<li><a href="../de433252/index.html">Schaufensterpuppe auf einem turbojetelektrischen Hybrid-Copter</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
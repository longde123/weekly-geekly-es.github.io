<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩‍🎨 🖖🏿 👨🏻‍⚕️ 适用于VMware vSphere的AccelStor AFA配置指南 🉑 👨🏿‍🏫 👩‍🍳</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="在本文中，我想谈谈与最流行的虚拟化平台之一-VMware vSphere一起使用的All Flash AccelStor阵列的功能。 特别是，专注于那些将有助于通过使用功能强大的工具（如All Flash）获得最大效果的参数。 





 所有Flash AccelStor NeoSapphire...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>适用于VMware vSphere的AccelStor AFA配置指南</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/accelstor/blog/447390/"><p> 在本文中，我想谈谈与最流行的虚拟化平台之一-VMware vSphere一起使用的All Flash AccelStor阵列的功能。 特别是，专注于那些将有助于通过使用功能强大的工具（如All Flash）获得最大效果的参数。 </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/di/xc/nq/dixcnqzpdskxe4whal3u7wyxcnw.jpeg"></div><a name="habracut"></a><br><p> 所有Flash AccelStor NeoSapphire™阵列都是基于SSD的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">一</a>或<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">两个</a>节点设备，采用根本不同的方法来实现使用自己的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">FlexiRemap®</a>技术而不是非常流行的RAID算法来实现存储数据和组织对数据的访问的概念。 阵列通过光纤通道或iSCSI接口为主机提供块访问。 公平地说，我们注意到具有ISCSI接口的模型也具有文件访问权限，这是一个不错的选择。 但是在本文中，我们将重点介绍使用块协议作为全闪存最高效的方法。 </p><br><p> 在AccelStor阵列与VMware vSphere虚拟化系统之间部署然后设置协作的整个过程可以分为几个阶段： </p><br><p></p><ul><li> 实现SAN网络的连接拓扑和配置； </li><li> 设置全闪存阵列； </li><li> 配置ESXi主机； </li><li> 配置虚拟机。 </li></ul><br><p> 具有光纤通道和iSCSI的AccelStor NeoSapphire™阵列用作示例设备。 基本软件是VMware vSphere 6.7U1。 </p><br><p> 部署本文中所述的系统之前，强烈建议您熟悉VMware有关性能问题（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">VMware vSphere 6.7的性能最佳实践</a> ）和iSCSI设置（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在iSCSI上运行VMware vSphere的最佳实践</a> ）的文档。 </p><br><h3>  <i><b>连接拓扑和SAN配置</b></i> </h3><br><p>  SAN网络的主要组件是ESXi主机，SAN交换机和阵列节点上的HBA。 这种网络的典型拓扑如下所示： </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/ci/wt/lg/ciwtlgk31rhm06xplvzbbwkxu0y.png"></div><br><p> 此处的术语交换机是指单个物理交换机或一组交换机（Fabric），或在不同服务之间共享的设备（对于光纤通道，是VSAN；对于iSCSI，是VLAN）。 使用两个独立的交换机/ Fabric消除了可能的故障点。 </p><br><p> 强烈建议不要将主机直接连接到阵列，尽管可以支持。 全闪存阵列的性能很高。 为了获得最大速度，您需要使用阵列的所有端口。 因此，至少需要在主机和NeoSapphire™之间进行一次切换。 </p><br><p> 在HBA主机上具有两个端口也是最大性能和容错能力的先决条件。 </p><br><p> 如果使用光纤通道接口，则需要配置分区，以避免启动器和目标之间可能的冲突。 区域基于“一个启动器端口-一个或多个阵列端口”的原理构建。 </p><br><p> 如果使用iSCSI连接，并且使用与其他服务共享的交换机，则必须将iSCSI通信隔离在单独的VLAN中。 强烈建议您启用巨型帧支持（MTU = 9000），以增加网络上数据包的大小，从而减少传输期间的开销。 但是，值得记住的是，为了正确操作，需要更改启动器-交换机-目标链上所有网络组件上的MTU参数。 </p><br><h3>  <i><b>设置所有闪存阵列</b></i> </h3><br><p> 该阵列通过已组建的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">FlexiRemap®</a>组交付给客户。 因此，无需执行任何操作即可将驱动器集成到单个结构中。 创建所需大小和数量的卷就足够了。 </p><br><p></p><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/zn/x9/nc/znx9ncuyd2rgm8-jfvwf620zaqg.png"></div><br><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/wx/8l/ua/wx8lualewtdkixfwg0petpxbsre.png"></div><p></p><br><p> 为方便起见，有一个功能可以一次批量创建给定卷的多个卷。 默认情况下会创建“精简”卷，因为这可以更合理地使用可用存储空间（包括感谢空间回收）。 就性能而言，薄体积和厚体积之间的差异不超过1％。 但是，如果要从阵列中“榨汁”，则始终可以将任何“稀”体积转换为“浓”。 但是应该记住，这种操作是不可逆的。 </p><br><p> 然后剩下的工作就是“发布”已创建的卷，并使用ACL（iSCSI的IP地址和FC的WWPN）以及阵列上端口的物理分隔从主机设置对它们的访问权限。 对于iSCSI型号，这是通过创建Target来完成的。 </p><br><p></p><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/mw/8y/cg/mw8ycgqngghoyuelortgysofswi.png"></div><br><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/py/xe/28/pyxe28gnrsxh_cx4ltjleogwsmw.png"></div><p></p><br><p> 对于FC型号，发布是通过为阵列中的每个端口创建LUN来进行的。 </p><br><p></p><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/qh/u3/bx/qhu3bxhm-kqinygguz298izbw7e.png"></div><br><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/oh/al/ey/ohaleyllpb-0bmot9kawc4-ssyg.png"></div><p></p><br><p> 为了加快配置过程，可以对主机进行分组。 此外，如果主机使用多端口FC HBA（在实践中最常发生），由于WWPN，系统会自动确定此类HBA的端口属于同一主机，两者相差一个。 此外，两个接口均支持批量创建目标/ LUN。 </p><br><p> 使用iSCSI接口时，重要的一点是一次为卷创建多个目标以提高性能，因为无法更改目标队列，而实际上这将成为瓶颈。 </p><br><p></p><h3> 配置ESXi主机 </h3><p></p><br><p> 在ESXi方面，基本配置是根据完全可以预期的方案完成的。  iSCSI连接步骤： </p><br><p></p><ol><li> 添加软件iSCSI适配器（如果已经添加或使用硬件iSCSI适配器，则不需要）； </li><li> 创建vSwitch，iSCSI流量将通过该vSwitch，并向其中添加物理上行链路和VMkernal； </li><li> 向动态发现添加阵列地址； </li><li> 创建数据存储 </li></ol><br><p>  <b>一些重要的注意事项：</b> </p><br><blockquote><ul><li> 当然，在一般情况下，您可以使用现有的vSwitch，但是在单独的vSwitch的情况下，管理主机设置将更加简单。 </li><li> 有必要将管理流量和iSCSI分为单独的物理链接和/或VLAN，以避免性能问题。 </li><li> 再次由于性能问题，VMkernal的IP地址和全闪存阵列的相应端口必须位于同一子网中。 </li><li> 为了确保VMware的容错能力，vSwitch必须至少具有两个物理上行链路 </li><li> 如果使用巨型帧，则必须同时更改vSwitch和VMkernal的MTU </li><li> 一定要记得，根据VMware对于将用于iSCSI流量的物理适配器的建议，必须配置成组和故障转移。 特别是，每个VMkernal仅应通过一个上行链路工作，第二个上行链路必须切换为未使用模式。 为了容错，您需要添加两个VMkernal，每个VMkernal都将通过其上行链路工作。 </li></ul><br></blockquote><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/_h/jb/va/_hjbvatnuhjwts4duy2epgb7bbi.png"></div><p></p><br><table><tbody><tr><th>  VMkernel适配器（vmk＃） </th><th> 物理网络适配器（vmnic＃） </th></tr><tr><td>  vmk1（Storage01） </td><td> 有源适配器 <br>  vmnic2 <br> 未使用的适配器 <br>  vmnic3 <br></td></tr><tr><td>  vmk2（Storage02） </td><td> 有源适配器 <br>  vmnic3 <br> 未使用的适配器 <br>  vmnic2 <br></td></tr></tbody></table><br><p> 无需光纤通道连接。 您可以立即创建一个数据存储。 </p><br><p> 创建数据存储区后，您需要确保将循环策略用于通向目标/ LUN的路径，以提高生产力。 </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/zh/zr/t1/zhzrt15baoc1qlp0w6ds-mys3hu.png"></div><p></p><br><p> 默认情况下，VMware设置根据方案提供此策略的使用：通过第一条路径的1000个请求，通过第二条路径的下1000个请求，等等。 与双控制器阵列的主机交互将不平衡。 因此，我们建议通过Esxcli / PowerCLI将Round Robin策略设置为1。 </p><br><div class="spoiler">  <b class="spoiler_title">参量</b> <div class="spoiler_text"><p> 对于Esxcli： </p><br><ul><li> 打印可用的LUN </li></ul><br><p>  <b>esxcli storage nmp设备列表</b> </p><br><ul><li> 复制设备名称 </li><li> 更改轮循政策 </li></ul><br><p>  <b>esxcli storage nmp psp roundrobin deviceconfig set --type = iops --iops = 1 --device =“设备ID”</b> </p></div></div><br><p> 大多数现代应用程序旨在交换大数据包，以最大程度地利用带宽并减少CPU负载。 因此，默认情况下，ESXi最多可将I / O请求最大批量传输到存储设备32767KB。 但是，在许多情况下，交换较小的部分将更有效率。 对于AccelStor阵列，以下情况是： </p><br><ul><li> 虚拟机使用UEFI代替旧版BIOS </li><li> 由vSphere Replication使用 </li></ul><br><p> 对于这种情况，建议您将Disk.DiskMaxIOSize参数值更改为4096。 </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/1g/et/3g/1get3g8odkem1onrpkwjdilbnsi.png"></div><p></p><br><p> 对于iSCSI连接，建议将Login Timeout参数更改为30（默认值为5），以提高连接的稳定性并关闭对转发的DelayedAck数据包的确认延迟。 这两个选项都在vSphere Client中：主机→配置→存储→存储适配器→iSCSI适配器的高级选项 </p><br><p></p><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/1y/5_/c8/1y5_c80zsijgqtngo-9vt2zbbo8.png"></div><br><div style="text-align:center;"><img width="50%" src="https://habrastorage.org/webt/bh/yi/tv/bhyitvuujofnioaunwhzypx3fe0.png"></div><p></p><br><p> 一个相当微妙的一点是用于数据存储的卷数。 显然，为了易于管理，期望为阵列的整个体积创建一个较大的体积。 但是，多个卷以及相应的数据存储的存在对整体性能有有益的影响（在稍后的文本中，对队列的影响更大）。 因此，我们建议至少创建两个卷。 </p><br><p> 最近，VMware建议再次限制单个数据存储上的虚拟机数量，以便获得最佳性能。 但是，现在，尤其是随着VDI的普及，这个问题不再那么严重。 但这并不能取消长期存在的规则-将需要大量IO的虚拟机分布在不同的数据存储上。 确定每个卷的最佳虚拟机数量没有比在其基础架构中对<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">AccelStor的全闪存阵列</a>进行<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">负载测试</a>更好的了。 </p><br><h3>  <i><b>配置虚拟机</b></i> </h3><br><p> 设置虚拟机时没有特殊要求，或者相当普通： </p><br><ul><li> 使用可能的最高版本的VM（兼容性） </li><li> 在虚拟机密集放置时（例如，在VDI中）设置RAM大小更为准确（默认情况下，在启动时，创建的分页文件与RAM大小相当，这会消耗有用的容量并影响最终性能） </li><li> 使用最高效的IO版本的适配器：网络类型VMXNET 3和SCSI类型PVSCSI </li><li> 使用Thick Provision Eager Zeroed驱动器类型可实现最佳性能，而Thin Provisioning可实现最大存储利用率 </li><li> 如果可能，请使用虚拟磁盘限制来限制非关键I / O计算机的工作 </li><li> 确保安装VMware Tools </li></ul><br><h3>  <i><b>排队笔记</b></i> </h3><br><p> 队列（或未完成的I / O）是在特定时间从特定设备/应用程序等待处理的I / O请求（SCSI命令）的数量。 如果队列溢出，则会生成QFULL错误，最终导致等待时间参数增加。 理论上，当使用磁盘（主轴）存储系统时，队列越高，它们的性能就越高。 但是，您不应滥用它，因为它很容易遇到QFULL。 一方面，在全闪存系统中，一切都比较简单：阵列的延迟降低了几个数量级，因此，通常无需单独调整队列的大小。 但是另一方面，在某些用例中（特定虚拟机对IO的要求有很大的偏见，为了获得最大性能而进行的测试等），如果不更改队列参数，则至少要了解可以实现哪些指标，并且，最重要的是，以什么方式。 </p><br><p>  AccelStor的全闪存阵列本身对卷或I / O端口没有限制。 如有必要，即使是单个卷也可以获取阵列的所有资源。 唯一的队列限制是iSCSI目标。 出于这个原因，上面指出了需要为每个体积创建多个（理想情况下最多8个）目标以克服此限制。 而且，AccelStor阵列是高生产率的解决方案。 因此，应该使用系统的所有接口端口以达到最大速度。 </p><br><p> 在主机的ESXi端，情况完全不同。 主持人本身对所有参与者都实行对资源的平等访问的做法。 因此，来宾OS和HBA有单独的IO队列。 来宾操作系统的队列从队列到虚拟SCSI适配器和虚拟磁盘的组合： </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/pv/gu/sk/pvguskcy3y4yo7whrx8jiuggtdm.png"></div><br><p>  HBA的队列取决于特定的类型/供应商： </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/tn/hs/6h/tnhs6h0wpivfrb5xfv2qms4tzjy.png"></div><br><p> 虚拟机的最终性能将由主机组件中的最低队列深度限制确定。 </p><br><p> 由于这些值，您可以评估我们可以在一种或另一种配置中获得的性能指标。 例如，我们想知道延迟为0.5ms的虚拟机（不绑定到块）的理论性能。 然后它的IOPS =（1,000 /延迟）*未完成的I / O（队列深度限制） </p><br><div class="spoiler">  <b class="spoiler_title">例子</b> <div class="spoiler_text"><p>  <b>例子1</b> </p><br><ul><li>  FC Emulex HBA适配器 </li><li> 数据存储上一台虚拟机 </li><li>  VMware半虚拟SCSI适配器 </li></ul><br><p> 此处，队列深度限制由Emulex HBA确定。 因此，IOPS =（1000 / 0.5）* 32 = 64K </p><br><p>  <b>例子2</b> </p><br><ul><li>  VMware iSCSI软件适配器 </li><li> 数据存储上一台虚拟机 </li><li>  VMware半虚拟SCSI适配器 </li></ul><br><p> 在这里，“队列深度”限制已由准虚拟SCSI适配器定义。 因此，IOPS =（1000 / 0.5）* 64 = 128K </p></div></div><br><p> 顶部的All AccelStor All Flash阵列（例如<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">P710</a> ）能够提供700K IOPS性能，以4K块进行记录。 在这样的块大小下，很明显单个虚拟机无法加载这样的阵列。 为此，您将需要11个（例如1）或6个（例如2）虚拟机。 </p><br><p> 因此，通过正确配置虚拟数据中心中所有已描述的组件，您可以获得非常出色的性能结果。 </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/uj/xy/cs/ujxycs-_fo-zworv8wds9kgp1j4.jpeg"></div><br><p>  <i>4K随机，读70％/写30％</i> </p><br><p> 实际上，用简单的公式描述现实世界要困难得多。 单个主机始终具有许多具有不同配置和IO要求的虚拟机。 是的，功能无限的主机处理器正在进行I / O处理。 因此，为了<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">释放</a>相同<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">型号的</a>全部潜能，实际上<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">P710</a>将需要三台主机。 另外，在虚拟机内部运行的应用程序也会进行调整。 因此，为了精确地确定大小，我们建议在客户基础架构内的所有Flash <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">AccelStor</a>阵列<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">的测试模型的情况下使用测试，以</a>完成当前的实际任务。 </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN447390/">https://habr.com/ru/post/zh-CN447390/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN447376/index.html">SNA Hackathon 2019</a></li>
<li><a href="../zh-CN447380/index.html">Kotlin例外及其功能</a></li>
<li><a href="../zh-CN447382/index.html">《统一与C＃》一书。 Gamedev从构思到实施。 第二版</a></li>
<li><a href="../zh-CN447384/index.html">功率半导体保护生态</a></li>
<li><a href="../zh-CN447388/index.html">TL； ITMO大学的摘要：非经典的大学入学，即将发生的事件和最有趣的资料</a></li>
<li><a href="../zh-CN447392/index.html">英语语法检查服务的三个问题以及是否可以解决</a></li>
<li><a href="../zh-CN447394/index.html">尼古拉·利哈切夫（Nikolai Likhachev）的父亲弗拉基米尔·利哈切夫（Vladimir Likhachev）的访谈，克里斯·卡巴斯基（Chris Kaspersky）</a></li>
<li><a href="../zh-CN447396/index.html">您的公司数据在AI时代有价值吗？</a></li>
<li><a href="../zh-CN447398/index.html">机器人过程自动化-旧技术的新面貌</a></li>
<li><a href="../zh-CN447402/index.html">Docker中的Splunk Universal Forwarder作为系统记录器</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
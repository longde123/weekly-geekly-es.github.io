<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üè≥Ô∏è‚Äçüåà üî∂ üë©üèº‚Äçüç≥ AI, curso pr√°ctico. Descripci√≥n general de las redes neuronales para la clasificaci√≥n de im√°genes ‚òùüèΩ üòπ üóìÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este art√≠culo proporciona una visi√≥n general te√≥rica accesible de las redes neuronales convolucionales (CNN) y explica su aplicaci√≥n al problema de cl...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, curso pr√°ctico. Descripci√≥n general de las redes neuronales para la clasificaci√≥n de im√°genes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/415811/">  Este art√≠culo proporciona una visi√≥n general te√≥rica accesible de las redes neuronales convolucionales (CNN) y explica su aplicaci√≥n al problema de clasificaci√≥n de im√°genes. <br><br><img src="https://habrastorage.org/webt/_d/ve/hi/_dvehi4kbgauxndfn56s7-tmtku.jpeg"><br><a name="habracut"></a><br><h2>  <font color="#0071c5">Enfoque com√∫n: sin aprendizaje profundo</font> </h2><br>  El t√©rmino "procesamiento de im√°genes" se refiere a una amplia clase de tareas para las cuales los datos de entrada son im√°genes, y la salida puede ser im√°genes o conjuntos de caracter√≠sticas asociadas.  Hay muchas opciones: clasificaci√≥n, segmentaci√≥n, anotaci√≥n, detecci√≥n de objetos, etc. En este art√≠culo, examinamos la clasificaci√≥n de im√°genes, no solo porque es la tarea m√°s simple, sino tambi√©n porque subyace a muchas otras tareas. <br><br>  El enfoque general para la clasificaci√≥n de im√°genes consta de los siguientes dos pasos: <br><br><ol><li>  Generaci√≥n de caracter√≠sticas significativas de la imagen. </li><li>  Clasificaci√≥n de una imagen en funci√≥n de sus atributos. </li></ol><br>  La secuencia com√∫n de operaciones utiliza modelos simples como MultiLayer Perceptron (MLP), Support Vector Machine (SVM), k m√©todo de vecinos m√°s cercanos y regresi√≥n log√≠stica sobre las caracter√≠sticas creadas manualmente.  Los atributos se generan usando varias transformaciones (por ejemplo, detecci√≥n de umbral y escala de grises) y descriptores, por ejemplo, histograma de gradientes orientados ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">HOG</a> ) o transformaciones de transformaci√≥n de caracter√≠sticas invariantes de escala ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SIFT</a> ), y etc. <br><br>  La principal limitaci√≥n de los m√©todos generalmente aceptados es la participaci√≥n de un experto que elige un conjunto y una secuencia de pasos para generar caracter√≠sticas. <br><br>  Con el tiempo, se not√≥ que la mayor√≠a de las t√©cnicas para generar caracter√≠sticas se pueden generalizar utilizando n√∫cleos (filtros): matrices peque√±as (generalmente de tama√±o 5 √ó 5), que son convoluciones de las im√°genes originales.  La convoluci√≥n puede considerarse como un proceso secuencial de dos etapas: <br><br><ol><li> Pase el mismo n√∫cleo fijo en toda la imagen de origen. </li><li>  En cada paso, calcule el producto escalar del n√∫cleo y la imagen original en la ubicaci√≥n actual del n√∫cleo. </li></ol><br>  El resultado de la convoluci√≥n de la imagen y el n√∫cleo se denomina mapa de caracter√≠sticas. <br>  Una explicaci√≥n matem√°ticamente m√°s rigurosa se da en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cap√≠tulo correspondiente del</a> libro recientemente publicado, Aprendizaje profundo, de I. Goodfellow, I. Benjio y A. Courville. <br><br><img src="https://habrastorage.org/webt/kw/lm/rd/kwlmrdg1y8wsniz94riol_8fiie.png"><br>  <i>El proceso de convoluci√≥n del n√∫cleo (verde oscuro) con la imagen original (verde), como resultado de lo cual se obtiene un mapa de caracter√≠sticas (amarillo).</i> <br><br>  Un ejemplo simple de una transformaci√≥n que se puede hacer con filtros es desenfocar una imagen.  Tome un filtro que consta de todas las unidades.  Calcula el promedio del vecindario determinado por el filtro.  En este caso, el vecindario es una secci√≥n cuadrada, pero puede ser cruciforme o cualquier otra cosa.  El promedio lleva a la p√©rdida de informaci√≥n sobre la posici√≥n exacta de los objetos, lo que hace borrosa toda la imagen.  Se puede dar una explicaci√≥n intuitiva similar para cualquier filtro creado manualmente. <br><br><img src="https://habrastorage.org/webt/5t/ud/g7/5tudg7ebng4ocb6jdc1-1alsqpo.png"><br>  <i>El resultado de la convoluci√≥n de la imagen del edificio de la Universidad de Harvard con tres n√∫cleos diferentes.</i> <br><br><h2>  <font color="#0071c5">Redes neuronales convolucionales</font> </h2><br>  El enfoque convolucional para la clasificaci√≥n de im√°genes tiene una serie de inconvenientes importantes: <br><br><ul><li>  Un proceso de varios pasos en lugar de una secuencia de extremo a extremo. </li><li>  Los filtros son una gran herramienta de generalizaci√≥n, pero son matrices fijas.  ¬øC√≥mo elegir pesos en filtros? </li></ul><br>  Afortunadamente, se han inventado filtros que se pueden aprender, que son el principio b√°sico de CNN.  El principio es simple: entrenaremos los filtros aplicados a la descripci√≥n de las im√°genes para cumplir mejor su tarea. <br><br>  CNN no tiene un inventor, pero uno de los primeros casos de su aplicaci√≥n es LeNet-5 * en el trabajo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"</a> Aprendizaje basado en el gradiente aplicado al reconocimiento de documentos" por I. LeCun y otros autores. <br><br>  CNN mata a dos p√°jaros de un tiro: no hay necesidad de una definici√≥n preliminar de los filtros, y el proceso de aprendizaje se vuelve de extremo a extremo.  Una arquitectura t√≠pica de CNN consta de las siguientes partes: <br><br><ul><li>  Capas convolucionales </li><li>  Capas de submuestreo </li><li>  Capas densas (completamente conectadas) </li></ul><br>  Consideremos cada parte con m√°s detalle. <br><br><h3>  <font color="#0071c5">Capas convolucionales</font> </h3><br>  La capa convolucional es el principal elemento estructural de CNN.  La capa convolucional tiene un conjunto de caracter√≠sticas: <br>  <i>Conectividad local (escasa)</i> .  En las capas densas, cada neurona est√° conectada a cada neurona de la capa anterior (por lo tanto, se llamaron densas).  En la capa convolucional, cada neurona est√° conectada solo a una peque√±a parte de las neuronas de la capa anterior. <br><br><img src="https://habrastorage.org/webt/nl/1a/6t/nl1a6t8bvbzna0rv_y3qjv_gsua.png"><br>  <i>Un ejemplo de una red neuronal unidimensional.</i>  <i>(izquierda) Conexi√≥n de neuronas en una red densa t√≠pica, (derecha) Caracterizaci√≥n de la conectividad local inherente a la capa convolucional.</i>  <i>Im√°genes tomadas de I. Goodfellow y otros por Deep Learning</i> <br><br>  <i>El tama√±o del √°rea a la que est√° conectada la neurona se</i> denomina tama√±o del filtro (la longitud del filtro en el caso de datos unidimensionales, por ejemplo, series de tiempo, o el ancho / alto en el caso de datos bidimensionales, por ejemplo, im√°genes).  En la figura de la derecha, el tama√±o del filtro es 3. Los <i>pesos con los que se realiza la conexi√≥n</i> se denominan filtro (un vector en el caso de datos unidimensionales y una matriz para datos bidimensionales).  <i>El paso es la distancia que el filtro se mueve sobre los datos</i> (en la figura de la derecha, el paso es 1).  La idea de conectividad local no es m√°s que un n√∫cleo que se mueve un paso.  Cada neurona de nivel convolucional representa e implementa una posici√≥n espec√≠fica del n√∫cleo desliz√°ndose a lo largo de la imagen original. <br><br><img src="https://habrastorage.org/webt/nu/we/gf/nuwegftvmoigtcdz2mlt0xwmm5g.png"><br>  <i>Dos capas convolucionales unidimensionales adyacentes</i> <br><br>  Otra propiedad importante es la llamada <i>zona de susceptibilidad</i> .  Refleja el n√∫mero de posiciones de la se√±al original que la neurona actual puede "ver".  Por ejemplo, la zona de susceptibilidad de la primera capa de red, que se muestra en la figura, es igual al tama√±o del filtro 3, ya que cada neurona est√° conectada a solo tres neuronas de la se√±al original.  Sin embargo, en la segunda capa, la zona de susceptibilidad ya es 5, ya que la neurona de la segunda capa agrega tres neuronas de la primera capa, cada una de las cuales tiene una zona de susceptibilidad 3. Con una profundidad creciente, la zona de susceptibilidad crece linealmente. <br><br>  <i>Par√°metros compartidos</i>  Recuerde que en el procesamiento cl√°sico de im√°genes, el mismo n√∫cleo se desliz√≥ por toda la imagen.  La misma idea se aplica aqu√≠.  Solo fijamos el tama√±o del filtro de pesos para una capa y aplicaremos estos pesos a todas las neuronas de la capa.  Esto es equivalente a deslizar el mismo n√∫cleo por toda la imagen.  Pero puede surgir la pregunta: ¬øc√≥mo podemos aprender algo con un n√∫mero tan peque√±o de par√°metros? <br><br><img src="https://habrastorage.org/webt/ue/qo/gi/ueqogixaqstaotlmnlfnjfn3dtc.png"><br>  <i>Las flechas oscuras representan los mismos pesos.</i>  <i>(izquierda) MLP regular, donde cada factor de ponderaci√≥n es un par√°metro separado, (derecha) Un ejemplo de separaci√≥n de par√°metros, donde varios factores de ponderaci√≥n indican el mismo par√°metro de entrenamiento</i> <br><br>  <i>Estructura espacial</i> .  La respuesta a esta pregunta es simple: ¬°entrenaremos varios filtros en una capa!  Se colocan paralelos entre s√≠, formando as√≠ una nueva dimensi√≥n. <br><br>  Hacemos una pausa breve y explicamos la idea presentada por el ejemplo de una imagen RGB bidimensional de 227 √ó 227. Tenga en cuenta que aqu√≠ se trata de una imagen de entrada de tres canales, lo que, en esencia, significa que tenemos tres im√°genes de entrada o datos de entrada tridimensionales. <br><br><img src="https://habrastorage.org/webt/ol/9r/ty/ol9rtyiz5s9btzfnldhf6bo_0wi.png"><br>  <i>La estructura espacial de la imagen de entrada.</i> <br><br>  Consideraremos las dimensiones de los canales como la profundidad de la imagen (tenga en cuenta que esto no es lo mismo que la profundidad de las redes neuronales, que es igual al n√∫mero de capas de red).  La pregunta es c√≥mo determinar el n√∫cleo para este caso. <br><br><img src="https://habrastorage.org/webt/l6/pt/be/l6ptberff4a-rbz81bq-uxa-10w.png"><br>  <i>Un ejemplo de un n√∫cleo bidimensional, que es esencialmente una matriz tridimensional con una medici√≥n de profundidad adicional.</i>  <i>Este filtro da una convoluci√≥n con la imagen;</i>  <i>es decir, se desliza sobre la imagen en el espacio, calculando productos escalares</i> <br><br>  La respuesta es simple, aunque todav√≠a no es obvia: haremos que el n√∫cleo tambi√©n sea tridimensional.  Las dos primeras dimensiones seguir√°n siendo las mismas (ancho y alto del n√∫cleo), y la tercera dimensi√≥n siempre es igual a la profundidad de los datos de entrada. <br><br><img src="https://habrastorage.org/webt/yu/e3/xz/yue3xziqupgpwtmqvtit8ik5hos.png"><br>  <i>Un ejemplo de un paso de convoluci√≥n espacial.</i>  <i>El resultado del producto escalar del filtro y una peque√±a porci√≥n de la imagen 5 √ó 5 √ó 3 (es decir, 5 √ó 5 √ó 5 + 1 = 76, la dimensi√≥n del producto escalar + desplazamiento) es un n√∫mero</i> <br><br>  En este caso, toda la secci√≥n 5 √ó 5 √ó 3 de la imagen original se transforma en un n√∫mero, y la imagen tridimensional en s√≠ se transformar√° en <i>un mapa de caracter√≠sticas</i> ( <i>mapa de activaci√≥n</i> ).  Un mapa de caracter√≠sticas es un conjunto de neuronas, cada una de las cuales calcula su propia funci√≥n, teniendo en cuenta dos principios b√°sicos discutidos anteriormente: <i>conectividad local</i> (cada neurona est√° asociada con solo una peque√±a parte de los datos de entrada) y <i>separaci√≥n de par√°metros</i> (todas las neuronas usan el mismo filtro).  Idealmente, este mapa de caracter√≠sticas ser√° el mismo que el que se encuentra en el ejemplo de una red generalmente aceptada: almacena los resultados de convoluci√≥n de la imagen de entrada y el filtro. <br><br><img src="https://habrastorage.org/webt/iw/4w/qr/iw4wqr77vslpfjqblrgtjlxyxkw.png"><br>  <i>Mapa de caracter√≠sticas como resultado de la convoluci√≥n del n√∫cleo con todas las posiciones espaciales</i> <br><br>  Tenga en cuenta que la profundidad del mapa de entidades es 1, ya que solo usamos un filtro.  Pero nada nos impide usar m√°s filtros;  por ejemplo, 6. Todos ellos interactuar√°n con los mismos datos de entrada y funcionar√°n independientemente uno del otro.  Vayamos un paso m√°s all√° y combinemos estas tarjetas de caracter√≠sticas.  Sus dimensiones espaciales son las mismas ya que las dimensiones de los filtros son las mismas.  Por lo tanto, los mapas de caracter√≠sticas recopilados juntos pueden considerarse como una nueva matriz tridimensional, cuya dimensi√≥n de profundidad est√° representada por mapas de caracter√≠sticas de diferentes n√∫cleos.  En este sentido, los canales RGB de la imagen de entrada no son otros que los tres mapas de caracter√≠sticas originales. <br><br><img src="https://habrastorage.org/webt/c8/f1/23/c8f123tp1nnbklt5oimm4gkmwj4.png"><br>  <i>La aplicaci√≥n paralela de varios filtros a la imagen de entrada y el conjunto resultante de tarjetas de activaci√≥n</i> <br><br>  Tal comprensi√≥n de los mapas de caracter√≠sticas y su combinaci√≥n es muy importante, ya que, al darnos cuenta de esto, podemos expandir la arquitectura de red e instalar capas convolucionales una encima de la otra, aumentando as√≠ la zona de susceptibilidad y enriqueciendo nuestro clasificador. <br><br><img src="https://habrastorage.org/webt/7_/3g/hp/7_3ghputtiaz-2l-hbbs7dagmvi.png"><br>  <i>Capas convolucionales instaladas una encima de la otra.</i>  <i>En cada capa, el tama√±o de los filtros y su n√∫mero pueden variar.</i> <br><br>  Ahora entendemos qu√© es una red convolucional.  El objetivo principal de estas capas es el mismo que con el enfoque generalmente aceptado: detectar signos significativos de la imagen.  Y, si en la primera capa estos signos pueden ser muy simples (la presencia de l√≠neas verticales / horizontales), la profundidad de la red aumenta el grado de su abstracci√≥n (la presencia de un perro / gato / persona). <br><br><h3>  <font color="#0071c5">Capas de submuestreo</font> </h3><br>  Las capas convolucionales son el bloque de construcci√≥n principal de CNN.  Pero hay otra parte importante y de uso frecuente: estas son capas de submuestra.  En el procesamiento de im√°genes convencional, no existe un an√°logo directo, pero una submuestra puede considerarse como otro tipo de n√∫cleo.  Que es esto <br><br><img src="https://habrastorage.org/webt/n4/fm/df/n4fmdf4o-i1pa7qs4w4oj7wmzgy.png"><br>  <i>Ejemplos de submuestreo.</i>  <i>(izquierda) C√≥mo una submuestra cambia los tama√±os espaciales (¬°pero no de canal!) de las matrices de datos, (derecha) Un esquema b√°sico de c√≥mo funciona una submuestra</i> <br><br>  Una submuestra filtra una parte de la vecindad de cada p√≠xel de los datos de entrada con una funci√≥n de agregaci√≥n espec√≠fica, por ejemplo, m√°ximo, promedio, etc. La submuestra es esencialmente lo mismo que convoluci√≥n, pero la funci√≥n de combinaci√≥n de p√≠xeles no se limita al producto escalar.  Otra diferencia importante es que el submuestreo solo funciona en la dimensi√≥n espacial.  Un rasgo caracter√≠stico de la capa de submuestreo es que el <i>tono suele ser igual al tama√±o del filtro</i> (el valor t√≠pico es 2). <br><br>  Una submuestra tiene tres objetivos principales: <br><br><ul><li>  Disminuci√≥n de la dimensi√≥n espacial o submuestreo.  Esto se hace para reducir el n√∫mero de par√°metros. </li><li>  El crecimiento de la zona de susceptibilidad.  Debido a las neuronas de la submuestra en las capas posteriores, se acumulan m√°s pasos de la se√±al de entrada </li><li>  Invarianza traslacional a peque√±as heterogeneidades en la posici√≥n de los patrones en la se√±al de entrada.  Al calcular estad√≠sticas de agregaci√≥n de vecindades peque√±as de la se√±al de entrada, una submuestra puede ignorar peque√±os desplazamientos espaciales en ella. </li></ul><br><h3>  <font color="#0071c5">Capas gruesas</font> </h3><br>  Las capas convolucionales y las capas de submuestra sirven al mismo prop√≥sito: generar atributos de imagen.  El √∫ltimo paso es clasificar la imagen de entrada en funci√≥n de las caracter√≠sticas detectadas.  En CNN, las capas densas en la parte superior de la red hacen esto.  Esta parte de la red se llama <i>clasificaci√≥n</i> .  Puede contener varias capas una encima de la otra con conectividad completa, pero generalmente termina con una capa de clase <i>softmax</i> activada por una funci√≥n de activaci√≥n log√≠stica <i>multivariable</i> , en la que el n√∫mero de bloques es igual al n√∫mero de clases.  En la salida de esta capa est√° la distribuci√≥n de probabilidad por clase para el objeto de entrada.  Ahora la imagen se puede clasificar eligiendo la clase m√°s probable. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es415811/">https://habr.com/ru/post/es415811/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es415795/index.html">Escribir una interfaz de usuario de Snapchat en Swift</a></li>
<li><a href="../es415797/index.html">Expresiones regulares + programaci√≥n l√≥gica. Cual es el resultado?</a></li>
<li><a href="../es415801/index.html">Google: nuestra IA de "tel√©fono" no es lo suficientemente buena como para ser peligrosa</a></li>
<li><a href="../es415805/index.html">Modificaci√≥n del m√≥dulo de barrera GSM Doorhan para control de Internet</a></li>
<li><a href="../es415809/index.html">C√≥mo usar soja, requirejs, backbone js en complementos para Atlassian Jira</a></li>
<li><a href="../es415813/index.html">Algunas notas sobre el estado actual de Cloud Gaming</a></li>
<li><a href="../es415815/index.html">A la vanguardia de la ciencia: un an√°lisis de los art√≠culos de arxiv.org</a></li>
<li><a href="../es415817/index.html">Overclockeamos la copia de seguridad. Conferencia de Yandex</a></li>
<li><a href="../es415819/index.html">Informe del Club de Roma 2018, Cap√≠tulo 3.16: Gobierno global</a></li>
<li><a href="../es415821/index.html">La forma de organizar una casa "inteligente" con el control el√©ctrico m√°s amplio posible</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
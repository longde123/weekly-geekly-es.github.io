<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üì¥ üçõ üóÑÔ∏è Gespr√§ch mit dem Auto: die F√§higkeit zu h√∂ren und zuzuh√∂ren üôç üï° ‚ú≥Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Unser Tag beginnt mit dem Satz "Guten Morgen!". Tags√ºber sprechen wir mit Kollegen, Verwandten, Freunden und sogar Fremden, die nach dem Weg zur n√§chs...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Gespr√§ch mit dem Auto: die F√§higkeit zu h√∂ren und zuzuh√∂ren</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/409523/"><img src="https://habrastorage.org/webt/8c/wn/c6/8cwnc6nbik0i9ewk0vmfccar8v4.jpeg"><br><br>  Unser Tag beginnt mit dem Satz "Guten Morgen!".  Tags√ºber sprechen wir mit Kollegen, Verwandten, Freunden und sogar Fremden, die nach dem Weg zur n√§chsten U-Bahn fragen.  Wir sprechen auch dann, wenn niemand um uns herum ist, um unsere eigenen √úberlegungen besser wahrzunehmen.  All dies ist unsere Rede - ein Geschenk, das mit vielen anderen M√∂glichkeiten des menschlichen K√∂rpers wirklich unvergleichlich ist.  Die Sprache erm√∂glicht es uns, soziale Verbindungen herzustellen, Gedanken und Emotionen auszudr√ºcken und uns beispielsweise in Liedern auszudr√ºcken. <a name="habracut"></a><br><br>  Und so tauchten intelligente Autos im Leben der Menschen auf.  Eine Person, entweder aus Neugier oder aus Durst nach neuen Errungenschaften, versucht, der Maschine das Sprechen beizubringen.  Aber um sprechen zu k√∂nnen, m√ºssen Sie h√∂ren und zuh√∂ren.  Heutzutage ist es schwierig, mit einem Programm (zum Beispiel Siri) zu √ºberraschen, das Sprache erkennen, ein Restaurant auf der Karte finden, Mutter anrufen und sogar einen Witz erz√§hlen kann.  Sie versteht viel, nat√ºrlich nicht alles, aber viel.  Aber das war nat√ºrlich nicht immer so.  Vor Jahrzehnten war es zum Gl√ºck, wenn eine Maschine mindestens ein Dutzend W√∂rter verstehen konnte. <br><br>  Heute werden wir in die Geschichte eintauchen, wie die Menschheit mit der Maschine sprechen konnte. Die Durchbr√ºche im Laufe der Jahrhunderte in diesem Bereich haben als Impuls f√ºr die Entwicklung der Spracherkennungstechnologie gedient.  Wir untersuchen auch, wie moderne Ger√§te unsere Stimmen wahrnehmen und verarbeiten.  Lass uns gehen. <br><br><h2>  Die Urspr√ºnge der Spracherkennung </h2><br>  Was ist Sprache?  Grob gesagt ist das gesund.  Um Sprache zu erkennen, m√ºssen Sie zuerst den Ton erkennen und aufnehmen. <br><br>  Jetzt haben wir iPods, MP3-Player, bevor es Tonbandger√§te gab, noch fr√ºhere Grammophone und Grammophone.  Dies sind alles Ger√§te zum Abspielen von Sounds.  Aber wer war der Stammvater von allen? <br><br><img src="https://habrastorage.org/webt/8s/mb/eu/8smbeu5msfrmoe0p2ci1muysue4.jpeg"><br>  <i>Thomas Edison mit seiner Erfindung.</i>  <i>1878 Jahre</i> <br><br>  Es war ein Phonograph.  29. November 1877 Der gro√üe Erfinder Thomas Edison demonstrierte seine neue Kreation, die Kl√§nge aufnehmen und wiedergeben kann.  Es war ein Durchbruch, der das gr√∂√üte Interesse der Gesellschaft weckte. <br><br>  <b>Das Prinzip des Phonographen</b> <br><br><img src="https://habrastorage.org/webt/rp/fv/24/rpfv24kfbznfnx4daut4ejm8us8.jpeg"><br><br>  Die Hauptteile des Schallaufzeichnungsmechanismus waren ein mit Folie beschichteter Zylinder und eine Schneidnadel.  Die Nadel bewegte sich entlang eines sich drehenden Zylinders.  Mechanische Schwingungen wurden mit einer Mikrofonmembran erfasst.  Infolgedessen hinterlie√ü die Nadel Markierungen auf der Folie.  Als Ergebnis erhielten wir einen Zylinder mit einem Rekord.  Um es zu reproduzieren, wurde urspr√ºnglich der gleiche Zylinder wie bei der Aufnahme verwendet.  Aber die Folie war zu zerbrechlich und schnell abgenutzt, weil die Aufzeichnungen nur von kurzer Dauer waren.  Dann fingen sie an, Wachs aufzutragen, das den Zylinder bedeckte.  Um die Existenz der Aufzeichnungen zu verl√§ngern, begannen sie mit dem Galvanisieren zu kopieren.  Durch die Verwendung h√§rterer Materialien hielten die Kopien viel l√§nger. <br><br><img src="https://habrastorage.org/webt/5e/7r/c6/5e7rc6csca_nlluhjoawmsnwgjs.jpeg"><br>  <i>Schematische Darstellung eines Phonographen auf einem Patent.</i>  <i>1880, 18. Mai</i> <br><br>  Angesichts der oben genannten Nachteile war der Phonograph zwar eine interessante Maschine, wurde aber nicht aus den Regalen gewischt.  Erst mit dem Aufkommen des Plattenphonographen - besser bekannt als das Grammophon - kam die √∂ffentliche Anerkennung.  Die Neuheit erm√∂glichte l√§ngere Aufnahmen (der erste Phonograph konnte nur ein paar Minuten aufnehmen), was lange Zeit diente.  Und das Grammophon selbst war mit einem Lautsprecher ausgestattet, der die Wiedergabelautst√§rke erh√∂hte. <br><br>  Thomas Edison hat den Phonographen urspr√ºnglich als Ger√§t zur Aufzeichnung von Telefongespr√§chen konzipiert, beispielsweise als moderne Diktierger√§te.  Seine Kreation hat jedoch bei der Reproduktion von Musikwerken gro√üe Popularit√§t erlangt.  Als Beginn f√ºr die Bildung der Aufnahmeindustrie gedient. <br><br><h2>  Rede "Orgel" </h2><br>  Bell Labs ist ber√ºhmt f√ºr seine Erfindungen auf dem Gebiet der Telekommunikation.  Eine solche Erfindung war Voder. <br><br>  Bereits 1928 begann Homer Dudley mit der Arbeit an einem Vocoder, einem Ger√§t, das Sprache synthetisieren kann.  Wir werden sp√§ter √ºber ihn sprechen.  Jetzt werden wir seinen Teil betrachten - den Vader. <br><br><img src="https://habrastorage.org/webt/ei/h1/jr/eih1jrd-ectvwvrzuvpa5f2kkjq.jpeg"><br>  <i>Schematische Darstellung eines Vaders</i> <br><br>  Das Grundprinzip des Vaders bestand darin, die menschliche Sprache in akustische Komponenten zu zerlegen.  Die Maschine war √§u√üerst komplex und konnte nur von einem geschulten Bediener bedient werden. <br><br>  Vader ahmte die Auswirkungen des menschlichen Stimmapparates nach.  Es gab 2 Hauptger√§usche, die der Bediener mit seinem Handgelenk ausw√§hlen konnte.  Fu√üpedale wurden verwendet, um den Generator f√ºr diskontinuierliche Schwingungen (Summger√§usche) zu steuern, die stimmhafte Vokale und Nasenger√§usche erzeugten.  Eine Gasentladungsr√∂hre (Zischen) erzeugte Zischlaute (Reibungskonsonanten).  Alle diese Sounds wurden durch einen der 10 Filter geleitet, der mit den Tasten ausgew√§hlt wurde.  Es gab auch spezielle Tasten f√ºr Kl√§nge wie "p" oder "d" und f√ºr die Affrikate "j" im Wort "Kiefer" und "ch" im Wort "K√§se". <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/0rAyrmm7vv0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>Dieser kleine Auszug aus der Pr√§sentation des Vaders zeigt deutlich das Prinzip seiner Bedienung und Bedieneraktionen</i> <br><br>  Ein Bediener kann erst nach mehreren Monaten intensiven Trainings und Trainings eine g√ºltige Sprache wiedergeben. <br><br>  Zum ersten Mal wurde der Tr√§ger 1939 auf einer Ausstellung in New York vorgef√ºhrt. <br><br><h2>  Speichern durch Sprachsynthese </h2><br>  Stellen Sie sich nun einen Vocoder vor, zu dem auch der oben genannte Fahrer geh√∂rte. <br><br><img src="https://habrastorage.org/webt/dx/ha/06/dxha06zj1kaojh6_zn0tpo8i7g4.jpeg"><br>  <i>Eines der Vocoder-Modelle: HY-2 (1961)</i> <br><br>  Der Vocoder sollte urspr√ºnglich die Frequenzressourcen von Funkverbindungen beim √úbertragen von Sprachnachrichten sparen.  Anstelle der Stimme selbst wurden die Werte ihrer spezifischen Parameter √ºbertragen, die vom Sprachsynthesizer am Ausgang verarbeitet wurden. <br><br>  Die Basis des Vocoders waren drei Haupteigenschaften: <br><br><ul><li>  Ger√§uschgenerator (Konsonantent√∂ne); </li><li>  Tongenerator (Vokale); </li><li>  formale Filter (Wiederherstellung der individuellen Eigenschaften des Sprechers). </li></ul><br>  Trotz seines ernsthaften Zwecks zog der Vocoder die Aufmerksamkeit elektronischer Musiker auf sich.  Durch die Umwandlung des Quellensignals und die Wiedergabe auf einem anderen Ger√§t konnten verschiedene Effekte erzielt werden, beispielsweise der Effekt eines Musikinstruments, das mit einer ‚Äûmenschlichen Stimme‚Äú singt. <br><br><h2>  Z√§hlmaschine </h2><br>  Bereits 1952 waren die Technologien nicht so fortschrittlich wie heute.  Dies hinderte die begeisterten Wissenschaftler jedoch nicht daran, sich nach Ansicht vieler unm√∂gliche Aufgaben zu stellen.  Die Herren Stephen Balashek (S. Balashek), Ralon Biddulf (R. Biddulph) und K.Kh.  Davis (KH Davis) beschloss, der Maschine beizubringen, ihre Sprache zu verstehen.  Der Idee folgend entstand Audreys Auto.  Ihre F√§higkeiten waren sehr begrenzt - sie konnte nur Zahlen von 0 bis 9 erkennen. Dies reichte jedoch bereits aus, um einen Durchbruch in der Computertechnologie sicher zu erkl√§ren. <br><br><img src="https://habrastorage.org/webt/ij/k0/t9/ijk0t9mp7xm-wqeotducqfvoxiw.png"><br>  <i>Audrey mit einem seiner Sch√∂pfer (laut Internet korrigieren Sie mich, wenn es nicht ist)</i> <br><br>  Trotz seiner geringen F√§higkeiten konnte sich Audrey nicht der gleichen Dimensionen r√ºhmen.  Sie war ein ziemlich gro√ües ‚ÄûM√§dchen‚Äú - der Relaisschrank war fast 2 Meter hoch und alle Elemente besetzten einen kleinen Raum.  Was f√ºr Computer dieser Zeit nicht √ºberraschend ist. <br><br>  Das Verfahren der Interaktion zwischen dem Bediener und Audrey hatte auch einige Bedingungen.  Der Bediener sprach die W√∂rter (in diesem Fall Zahlen) in das Mobilteil eines normalen Telefons. Achten Sie darauf, dass zwischen den einzelnen W√∂rtern eine Pause von 350 Millisekunden eingehalten wird.  Audrey akzeptierte die Informationen, √ºbersetzte sie in ein elektronisches Format und schaltete eine bestimmte Gl√ºhbirne ein, die einer bestimmten Ziffer entsprach.  Ganz zu schweigen von der Tatsache, dass nicht jeder Bediener eine genaue Antwort erhalten konnte.  Um eine Genauigkeit von 97% zu erreichen, musste der Bediener eine Person sein, die lange Zeit mit Audrey ‚ÄûGeschw√§tz‚Äú ge√ºbt hatte.  Mit anderen Worten, Audrey verstand nur ihre Sch√∂pfer. <br><br>  Selbst unter Ber√ºcksichtigung aller M√§ngel von Audrey, die nicht mit Konstruktionsfehlern, sondern mit den Einschr√§nkungen der damaligen Technologie verbunden sind, wurde sie der erste Stern am Horizont von Maschinen, die die menschliche Stimme verstehen. <br><br><h2>  Die Zukunft im Schuhkarton </h2><br>  1961 wurde im IBM Advanced Systems Development Laboratory ein neues Wunderger√§t entwickelt - die Shoebox, die 16 W√∂rter (ausschlie√ülich auf Englisch) und Zahlen von 0 bis 9 erkennen kann. Der Autor dieses Computers war William C. Dersch. <br><br><img src="https://habrastorage.org/webt/ho/fk/di/hofkdicpxszuykelh9vujhrrh7a.jpeg"><br>  <i>Schuhkarton von IBM</i> <br><br>  Der ungew√∂hnliche Name entsprach dem Aussehen der Maschine, sie hatte Gr√∂√üe und Form wie ein Schuhkarton.  Das einzige, was mir aufgefallen ist, war das Mikrofon, das an die drei Audiofilter angeschlossen war, die zur Erkennung von hohen, mittleren und niedrigen T√∂nen erforderlich sind.  Die Filter wurden mit einem Logikdecoder (Diodentransistor-Logikschaltung) und einem Lichtschaltermechanismus verbunden. <br><br>  Der Bediener nahm das Mikrofon an den Mund und sprach ein Wort aus (z. B. Nummer 7).  Die Maschine wandelte akustische Daten in elektronische Signale um.  Das Ergebnis des Verst√§ndnisses war die Aufnahme einer Gl√ºhbirne mit der Signatur "7".  Shoebox versteht nicht nur einzelne W√∂rter, sondern kann auch einfache Rechenprobleme (wie 5 + 6 oder 7-3) verstehen und die richtige Antwort geben. <br><br>  Shoebox wurde 1962 von seinem Sch√∂pfer auf der Seattle World Expo vorgestellt. <br><br><h2>  Telefongespr√§ch mit dem Auto </h2><br>  Im Jahr 1971 beschloss IBM, bekannt f√ºr seine Liebe zu innovativen Erfindungen und Technologien, die Spracherkennung in die Praxis umzusetzen.  Das automatische Anrufidentifizierungssystem erm√∂glichte es einem Techniker in den USA, einen Computer in Raleigh, North Carolina, anzurufen.  Der Anrufer k√∂nnte eine Frage stellen und eine Sprachantwort darauf erhalten.  Die Einzigartigkeit dieses Systems bestand darin, die vielen Stimmen aufgrund ihrer Tonalit√§t, Betonung, Sprachlautst√§rke usw. zu verstehen. <br><br><h2>  Harpyie schwebt hoch </h2><br>  Das B√ºro f√ºr fortgeschrittene Forschungsprojekte des Verteidigungsministeriums (kurz DARPA) k√ºndigte 1971 den Start eines Entwicklungs- und Forschungsprogramms zur Spracherkennung an, mit dem eine Maschine geschaffen werden soll, die 1.000 W√∂rter erkennen kann.  Ein mutiges Projekt angesichts der Erfolge seines Vorg√§ngers in zehn Worten.  Dem menschlichen Einfallsreichtum sind jedoch keine Grenzen gesetzt.  1976 demonstriert die Carnegie Mellon University die Harpyie, die 1011 W√∂rter erkennen kann. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/32KKg3aP3Vw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>Harpyie-Videodemonstration</i> <br><br>  Die Universit√§t hat bereits Spracherkennungssysteme entwickelt - Hearsay-1 und Dragon.  Sie wurden als Grundlage f√ºr die Implementierung von Harpyie verwendet. <br><br>  In Hearsay-1 wird Wissen (d. H. Ein Maschinenw√∂rterbuch) in Form von Prozeduren und in Dragon in Form eines Markov-Netzwerks mit einem a priori probabilistischen √úbergang dargestellt.  Bei Harpy wurde beschlossen, das neueste Modell zu verwenden, jedoch ohne diesen √úbergang. <br><br><div class="spoiler">  <b class="spoiler_title">In diesem Video wird das Funktionsprinzip genauer beschrieben.</b> <div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/N3i6NoUZsSw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br></div></div><br>  Einfach ausgedr√ºckt, k√∂nnen Sie ein Netzwerk darstellen - eine Folge von W√∂rtern und deren Kombinationen sowie T√∂ne mit einem einzigen Wort, damit die Maschine die unterschiedliche Aussprache desselben Wortes versteht. <br><br>  Harpyie verstand 5 Bediener, darunter drei M√§nner und zwei Frauen.  Das sprach f√ºr die gr√∂√üeren Rechenkapazit√§ten dieser Maschine.  Die Spracherkennungsgenauigkeit betrug ungef√§hr 95%. <br><br><h2>  Tangora von IBM </h2><br>  In den fr√ºhen 1980er Jahren beschloss IBM, ein System zu entwickeln, das bis Mitte des Jahrzehnts mehr als 20.000 W√∂rter erkennen kann.  So wurde Tangora geboren, in dessen Arbeit versteckte Markov-Modelle verwendet wurden.  Trotz des ziemlich beeindruckenden Wortschatzes ben√∂tigte das System nicht mehr als 20 Minuten Zusammenarbeit mit dem neuen Bediener (der sprechenden Person), um zu lernen, wie man seine Sprache erkennt. <br><br><h2>  Lebende Puppe </h2><br>  1987 ver√∂ffentlichte die Spielzeugfirma Worlds of Wonder eine revolution√§re Neuheit - eine sprechende Puppe namens Julie.  Das beeindruckendste Merkmal des d√§nischen Spielzeugs war die F√§higkeit, es zu trainieren, um die Rede des Besitzers zu erkennen.  Julie konnte ziemlich gut sprechen.  Dar√ºber hinaus war die Puppe mit vielen Sensoren ausgestattet, dank derer sie reagierte, wenn sie aufgenommen, gekitzelt oder von einem dunklen in einen hellen Raum gebracht wurde. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/UkU9SbIictc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>Worlds of Wonder-Werbespot Julie zeigt seine Funktionen</i> <br><br>  Ihre Augen und Lippen waren beweglich, was ein noch lebendigeres Bild erzeugte.  Neben der Puppe selbst konnte ein Buch gekauft werden, in dem Bilder und W√∂rter in Form von speziellen Aufklebern gemacht wurden.  Wenn Sie die Puppen mit den Fingern √ºber sie halten, spricht sie an, was sie sich bei Ber√ºhrung ‚Äûanf√ºhlt‚Äú.  Doll Julie war das erste Ger√§t mit einer Spracherkennungsfunktion, die jedem zur Verf√ºgung stand. <br><br><h2>  Die erste Diktiersoftware </h2><br><img src="https://habrastorage.org/webt/ox/xe/b3/oxxeb39l8-xwudht04ehub99swu.jpeg"><br><br>  1990 ver√∂ffentlichte Dragon Systems mit DragonDictate die erste auf Spracherkennung basierende Personal Computer-Software.  Das Programm funktionierte ausschlie√ülich unter Windows.  Der Benutzer musste zwischen jedem Wort kleine Pausen einlegen, damit das Programm sie analysieren konnte.  In Zukunft wurde eine perfektere Version ver√∂ffentlicht, mit der Sie kontinuierlich sprechen k√∂nnen - Dragon NaturallySpeaking (es ist jetzt verf√ºgbar, w√§hrend das urspr√ºngliche DragonDictate seit Windows 98 nicht mehr aktualisiert wird).  Trotz seiner ‚ÄûLangsamkeit‚Äú hat DragonDictate bei PC-Benutzern, insbesondere bei Menschen mit Behinderungen, gro√üe Popularit√§t erlangt. <br><br><h2>  Nicht √§gyptische Sphinx </h2><br>  Die Carnegie Mellon University, die bereits fr√ºher "beleuchtet" wurde, ist der Geburtsort eines anderen historisch wichtigen Spracherkennungssystems - Sphinx 2. <br><br><img src="https://habrastorage.org/webt/b6/9r/pw/b69rpwedqsvxgtayu6kfb-sdnek.jpeg"><br>  <i>Sch√∂pfer der Sphinx Xuedong Huang</i> <br><br>  Der direkte Autor des Systems war Xuedong Huang.  Sphinx 2 unterschied sich von seinem Vorg√§nger durch seine Geschwindigkeit.  Das System konzentrierte sich auf die Spracherkennung in Echtzeit f√ºr Programme, die gesprochene (allt√§gliche) Sprache verwenden.  Zu den Merkmalen von Sphinx 2 geh√∂rten: Hypothesenbildung, dynamisches Umschalten zwischen Sprachmodellen, Erkennung von √Ñquivalenten usw. <br><br>  Sphinx 2-Code wurde in vielen kommerziellen Produkten verwendet.  Und im Jahr 2000 ver√∂ffentlichte Kevin Lenzo auf der SourceForge-Website den Quellcode des Systems zur allgemeinen Anzeige.  Diejenigen, die den Quellcode von Sphinx 2 und seinen anderen Variationen studieren m√∂chten, k√∂nnen dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a> folgen. <br><br><h2>  Medizinisches Diktat </h2><br>  1996 brachte IBM MedSpeak auf den Markt, das erste kommerzielle Produkt mit Spracherkennung.  Es sollte dieses Programm bei √Ñrzten verwenden, um medizinische Aufzeichnungen zusammenzustellen.  Zum Beispiel √§u√üerte eine Radiologe, die die Bilder der Patientin untersuchte, ihre Kommentare, die das MedSpeak-System in Text √ºbersetzte. <br><br>  Bevor wir zu den bekanntesten Vertretern von Programmen mit Spracherkennung √ºbergehen, wollen wir kurz auf einige weitere historische Ereignisse im Zusammenhang mit dieser Technologie eingehen. <br><br><h2>  Historischer Blitz </h2><br><ul><li>  2002 - Microsoft integriert die Spracherkennung in alle Office-Produkte. </li><li>  2006 - Die US National Security Agency beginnt mit der Verwendung von Spracherkennungsprogrammen, um Grenzwertschl√ºsselw√∂rter in Konversationsaufzeichnungen zu identifizieren. </li><li>  2007 (30. Januar) - Microsoft ver√∂ffentlicht Windows Vista - das erste Betriebssystem mit Spracherkennung; </li><li>  2007 - Google f√ºhrt toget-411 ein - ein Telefonweiterleitungssystem (eine Person ruft eine Nummer an, gibt an, welche Organisation oder Person sie ben√∂tigt, und das System verbindet sie).  Das System funktionierte in den USA und Kanada. </li><li>  2008 (14. November) - Google startet die Sprachsuche auf iPhone-Mobilger√§ten.  Dies war der erste Einsatz der Spracherkennungstechnologie in Mobiltelefonen. </li></ul><br>  Und jetzt kommen wir zu einer Zeit, in der viele Menschen auf Spracherkennungstechnologie gesto√üen sind. <br><br><h2>  Damen streiten sich nicht </h2><br>  Am 4. Oktober 2011 k√ºndigte Apple Siri an, dessen Dekodierung f√ºr sich selbst spricht - die Schnittstelle f√ºr Sprachinterpretation und Spracherkennung (d. H. Die Schnittstelle f√ºr Interpretation und Spracherkennung). <br><br><img src="https://habrastorage.org/webt/6r/q4/iv/6rq4ivje-xftjg1t6c__vsbew4w.jpeg"><br><br>  Die Geschichte der Siri-Entwicklung ist sehr lang (tats√§chlich hat sie 40 Jahre Arbeit) und interessant.  Die Tatsache seiner Existenz und seiner umfangreichen Funktionalit√§t ist die gemeinsame Arbeit vieler Unternehmen und Universit√§ten.  Wir werden uns jedoch nicht auf dieses Produkt konzentrieren, da es in dem Artikel nicht um Siri geht, sondern um die Spracherkennung im Allgemeinen. <br><br>  Microsoft wollte nicht den R√ºcken streifen, weil sie 2014 (2. April) ihren virtuellen digitalen Assistenten Cortana ank√ºndigten. <br><br><img src="https://habrastorage.org/webt/k0/ni/gx/k0nigx6urkm0vs09jg5gwxepw9w.jpeg"><br><br>  Die Funktionalit√§t von Cortana √§hnelt der seines Konkurrenten Siri, mit Ausnahme eines flexibleren Systems zum Festlegen des Zugriffs auf Informationen. <br><br>  Debatte √ºber Cortana oder Siri.  Wer ist besser? "  durchgef√ºhrt seit ihrem Erscheinen auf dem Markt.  Wie im Allgemeinen und der Kampf zwischen Benutzern von iOS und Android.  Das ist aber gut  Konkurrierende Produkte, die versuchen, besser als ihre Konkurrenten zu wirken, bieten immer mehr neue M√∂glichkeiten, entwickeln und verwenden fortschrittlichere Technologien und Techniken auf demselben Gebiet der Spracherkennung.  Mit nur einem Vertreter in einem Bereich der Verbrauchertechnologie besteht keine Notwendigkeit, √ºber deren rasche Entwicklung zu sprechen. <br><br>  Ein kleines lustiges Video des Gespr√§chs zwischen Siri und Cortana (offensichtlich gebaut, aber nicht weniger lustig).  Achtung !: In diesem Video gibt es Obsz√∂nit√§ten. <br><br><div class="spoiler">  <b class="spoiler_title">Siri gegen Cortana</b> <div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/AQyf8xbITms" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br></div></div><br><h2>  Gespr√§ch mit Autos.  Wie verstehen sie uns? </h2><br>  Wie ich bereits erw√§hnt habe, ist Sprache grob gesagt gesund.  Und was ist der Sound f√ºr das Auto?  Dies sind √Ñnderungen (Schwankungen) des Luftdrucks, d.h.  Schallwellen.  Damit das Ger√§t (Computer oder Telefon) Sprache erkennen kann, m√ºssen Sie zuerst diese Schwankungen ber√ºcksichtigen.  Die Messfrequenz sollte mindestens 8.000 Mal pro Sekunde betragen (noch besser - 44.100 Mal pro Sekunde).  Wenn die Messungen mit gro√üen Zeitunterbrechungen durchgef√ºhrt werden, erhalten wir einen ungenauen Ton, was unleserliche Sprache bedeutet.  Der oben beschriebene Prozess wird als 8-kHz- oder 44,1-kHz-Digitalisierung bezeichnet. <br><br><img src="https://habrastorage.org/webt/mo/rq/ta/morqtag1dhh1b4lkoxyot4sna3g.png"><br><br>  Wenn Daten √ºber die Schwingungen von Schallwellen gesammelt werden, m√ºssen diese sortiert werden.  Da wir im allgemeinen Haufen sowohl Sprach- als auch Sekund√§rger√§usche haben (Maschinenger√§usche, raschelndes Papier, Ger√§usche eines funktionierenden Computers usw.).  Durch die Durchf√ºhrung mathematischer Operationen k√∂nnen wir genau unsere Sprache aussortieren, die erkannt werden muss. <br><br>  Als n√§chstes folgt die Analyse der ausgew√§hlten Schallwellensprache.  Da es aus vielen separaten Komponenten besteht, die bestimmte Kl√§nge bilden (zum Beispiel "ah" oder "ee").  Durch Hervorheben dieser Funktionen und Konvertieren in numerische Entsprechungen k√∂nnen Sie bestimmte W√∂rter definieren. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die englische Sprache besteht zum Beispiel aus mehr als 40 Phonemen (44, um genau zu sein, und nach einigen Theorien gibt es mehr als 100), d.h. </font><font style="vertical-align: inherit;">Sprachlaute. </font><font style="vertical-align: inherit;">Die Maschine bestimmt sie alle, da im Verlauf ihrer Entwicklung Trainingstests durchgef√ºhrt wurden, bei denen verschiedene Personen dieselben W√∂rter und S√§tze aussprachen. </font><font style="vertical-align: inherit;">So k√∂nnte die Maschine die √Ñhnlichkeiten und Unterschiede bestimmen und einen Algorithmus zur Bestimmung von Ger√§uschen bilden. </font><font style="vertical-align: inherit;">Es ist zu ber√ºcksichtigen, dass das ‚ÄûAussehen‚Äú eines Klangs nicht nur von einer Person (oder vielmehr von ihrer Aussprache, seinem Akzent, dem Timbre der Stimme usw.) beeinflusst wird, sondern auch von einer Kombination verschiedener Phoneme in einem Wort. </font><font style="vertical-align: inherit;">Zum Beispiel sehen "t" in "sTar" und "t" in "ciTy" f√ºr ein Auto v√∂llig anders aus. </font></font><br><br><img src="https://habrastorage.org/webt/cx/i5/wv/cxi5wv0eromqfqqt8w9mkrtozai.jpeg"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Markov-Modell mit dem Wort "Kartoffel" (Kartell) als Beispiel / ist im Video √ºber das Harpyie-System vorhanden</font></font></i> <br><br>   ,     ,      . ,   ¬´hang ten¬ª,        ‚Äî ¬´hey, ngten¬ª,         ¬´ngten¬ª. <br><br>  ,        ,        .       ,     (),     ,        ‚Ññ2    ‚Ññ1.  ¬´What do cats like for breakfast?¬ª    ¬´water gaslight four brick vast?¬ª. ,   .         .         , ,   ,   .          . <br><br>      ,        .    ,         ,     . <br><br><h2>  Nachwort </h2><br>   ,          .    .     -  ,         (    ,   ),    .           .        ,  , ,    .       ,  -,  ,      . <br><br> <b>  .             25%       3  6 ! <br><br></b>     !  VPS (KVM)   ,       ,     ‚Äî ! <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">  VPS (KVM) c      </a> (  VPS (KVM) ‚Äî E5-2650v4 (6 Cores) / 10GB DDR4 / 240GB SSD  4TB HDD / 1Gbps 10TB      ‚Äî  $29 / ,    RAID1  RAID10)</b> ,          ,     ,   ,    ,     ¬´¬ª! <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">   .  c   Dell R730xd 5-2650 v4  9000   ?</a> <b>Dell R730xd  2  ?</b>    <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">2  Intel Dodeca-Core Xeon E5-2650v4 128GB DDR4 6x480GB SSD 1Gbps 100   $249</a>    !</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de409523/">https://habr.com/ru/post/de409523/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de409511/index.html">SORM auf Kosten der Betreiber und Yarovaya?</a></li>
<li><a href="../de409515/index.html">OMower SDK f√ºr Radroboter (Open Source, Open Hardware)</a></li>
<li><a href="../de409517/index.html">Der Geist begann, als die G√∂tter aufh√∂rten zu reden</a></li>
<li><a href="../de409519/index.html">James Webb Teleskop durch extrem niedrige Temperaturen und Vakuum √ºberpr√ºft</a></li>
<li><a href="../de409521/index.html">Neue Stabilisatoren DJI Osmo Mobile 2 und Ronin-S</a></li>
<li><a href="../de409525/index.html">Wie nur ein Unternehmen die Grenzen dessen erweitern kann, was im Bereich unbemannter Luftfahrzeuge m√∂glich ist</a></li>
<li><a href="../de409527/index.html">VRChat - der neue Wilde Westen in der virtuellen Realit√§t</a></li>
<li><a href="../de409529/index.html">SpaceX hat Zumas geheime US-Milit√§rmission erfolgreich abgeschlossen</a></li>
<li><a href="../de409531/index.html">Microsoft hat eine KI entwickelt, die Text lesen und Fragen zum Lesen beantworten kann.</a></li>
<li><a href="../de409533/index.html">Das neue Botnetz infiziert die Technologie der Bergleute und ersetzt die Brieftaschenadressen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
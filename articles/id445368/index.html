<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôåüèª üñï üíÉ Muat pengujian game dengan beberapa ratus ribu pengguna virtual üì® üõ∑ üë©‚Äçüî¨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo, Habr! 

 Saya bekerja untuk perusahaan game yang mengembangkan game online. Saat ini, semua permainan kami dibagi menjadi banyak "pasar" (satu "...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Muat pengujian game dengan beberapa ratus ribu pengguna virtual</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/445368/">  Halo, Habr! <br><br>  Saya bekerja untuk perusahaan game yang mengembangkan game online.  Saat ini, semua permainan kami dibagi menjadi banyak "pasar" (satu "pasar" per negara) dan di setiap "pasar" ada selusin dunia di mana para pemain didistribusikan selama pendaftaran (baik, atau kadang-kadang mereka dapat memilih sendiri).  Setiap dunia memiliki satu basis data dan satu atau lebih server web / aplikasi.  Dengan demikian, bebannya dibagi dan didistribusikan di seluruh dunia / server hampir secara merata dan sebagai hasilnya, kami mendapatkan online maksimum dari pemain 6K-8K (ini adalah jumlah maksimum, kebanyakan beberapa kali lebih sedikit) dan 200-300 permintaan per waktu "perdana" untuk satu dunia. <br><br>  Struktur seperti ini dengan pembagian pemain ke pasar dan dunia menjadi usang, pemain menginginkan sesuatu yang global.  Dalam pertandingan terakhir, kami berhenti membagi orang berdasarkan negara dan hanya menyisakan satu / dua pasar (Amerika dan Eropa), tetapi masih dengan banyak dunia di masing-masingnya.  Langkah selanjutnya adalah pengembangan game dengan arsitektur baru dan penyatuan semua pemain dalam satu dunia dengan <b>satu basis data</b> . <br><br>  Hari ini saya ingin berbicara sedikit tentang bagaimana saya ditugaskan memeriksa bagaimana jika keseluruhan online (dan itu adalah 50-200 ribu pengguna sekaligus) dari salah satu game populer kami ‚Äúkirim‚Äù untuk memainkan game berikutnya yang dibangun di atas arsitektur baru dan apakah seluruh sistem, terutama database ( <b>PostgreSQL 11</b> ) secara praktis dapat menahan beban seperti itu dan, jika tidak, cari tahu di mana maksimum kami.  Saya akan memberi tahu Anda sedikit tentang masalah yang muncul dan keputusan untuk mempersiapkan pengujian banyak pengguna, proses itu sendiri, dan sedikit tentang hasilnya. <br><a name="habracut"></a><br><h2>  Intro </h2><br>  Di masa lalu, di <b>InnoGames GmbH,</b> setiap tim game membuat proyek game sesuai dengan selera dan warna mereka, seringkali menggunakan berbagai teknologi, bahasa pemrograman, dan basis data.  Selain itu, kami memiliki banyak sistem eksternal yang bertanggung jawab untuk pembayaran, mengirimkan pemberitahuan push, pemasaran, dan lainnya.  Untuk bekerja dengan sistem ini, pengembang juga menciptakan antarmuka unik mereka sebaik mungkin. <br><br>  Saat ini di bisnis game mobile banyak <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">uang</a> dan, karenanya, banyak persaingan.  Sangat penting di sini untuk mendapatkannya kembali dari setiap dolar yang dihabiskan untuk pemasaran dan sedikit lebih banyak dari atas, oleh karena itu semua perusahaan game sangat sering "menutup" game bahkan pada tahap pengujian tertutup, jika mereka tidak memenuhi ekspektasi analitis.  Dengan demikian, kehilangan waktu pada penemuan roda berikutnya tidak menguntungkan, sehingga diputuskan untuk membuat platform terpadu yang akan memberikan pengembang solusi siap pakai untuk integrasi dengan semua sistem eksternal, database dengan replikasi dan semua praktik terbaik.  Yang dibutuhkan pengembang adalah mengembangkan dan "menempatkan" game yang bagus di atas ini dan tidak membuang waktu untuk pengembangan yang tidak terkait dengan game itu sendiri. <br><br>  Platform ini disebut <b>GameStarter</b> : <br><br><img src="https://habrastorage.org/webt/fz/go/g3/fzgog3jsz4rzjqi0zvbwzysz-po.jpeg" alt="gambar"><br><br>  Jadi, to the point.  Semua game InnoGames di masa depan akan dibangun di platform ini, yang memiliki dua database - master dan game (PostgreSQL 11).  Master menyimpan informasi dasar tentang para pemain (login, kata sandi, dll.) Dan berpartisipasi, terutama, hanya dalam proses login / registrasi dalam game itu sendiri.  Game - database game itu sendiri, di mana, dengan demikian, semua data game dan entitas disimpan, yang merupakan inti dari game, di mana seluruh beban akan pergi. <br>  Dengan demikian, timbul pertanyaan apakah seluruh struktur ini dapat bertahan dari jumlah pengguna yang potensial yang sama dengan online maksimum dari salah satu permainan kami yang paling populer. <br><br><h2>  Tantangan </h2><br>  Tugasnya sendiri adalah ini: untuk memeriksa apakah database (PostgreSQL 11), dengan replikasi yang diaktifkan, dapat menahan semua beban yang saat ini kami miliki dalam gim yang paling banyak dimuat, dengan memiliki seluruh hypervisor PowerEdge M630 (HV). <br>  Saya akan mengklarifikasi bahwa tugas saat ini <b>hanya untuk memverifikasi</b> , menggunakan konfigurasi basis data yang ada, yang kami bentuk dengan mempertimbangkan praktik terbaik dan pengalaman kami sendiri. <br><br>  Saya akan segera mengatakan databasenya, dan seluruh sistem menunjukkan dirinya dengan baik, dengan pengecualian beberapa poin.  Tetapi proyek game khusus ini berada pada tahap prototipe dan di masa depan, dengan kerumitan mekanik game, permintaan ke basis data akan menjadi lebih rumit dan bebannya sendiri dapat meningkat secara signifikan dan sifatnya dapat berubah.  Untuk mencegah hal ini, perlu untuk menguji proyek secara iteratif dengan masing-masing tonggak yang kurang lebih signifikan.  Mengotomatiskan kemampuan untuk menjalankan tes semacam ini dengan beberapa ratus ribu pengguna telah menjadi tugas utama pada tahap ini. <br><br><h2>  Profil </h2><br>  Seperti halnya pengujian beban, semuanya dimulai dengan profil beban. <br>  Nilai potensial kami CCU60 (CCU adalah jumlah maksimum pengguna untuk periode waktu tertentu, dalam hal ini 60 menit) dianggap <b>250.000</b> pengguna.  Jumlah pengguna virtual kompetitif (VU) lebih rendah dari CCU60 dan analis telah menyarankan bahwa itu dapat dibagi dengan aman menjadi dua.  Kumpulkan dan terima <b>150.000</b> VU kompetitif. <br><br>  Jumlah total permintaan per detik diambil dari satu game yang agak dimuat: <br><br><img src="https://habrastorage.org/webt/lv/te/69/lvte69rifceelurn7r3t7trbgs4.png"><br><br>  Dengan demikian, target beban kami adalah ~ <b>20.000 permintaan / s</b> pada <b>150.000</b> VU. <br><br><h2>  Struktur </h2><br><h3>  Karakteristik "berdiri" </h3><br>  Dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel</a> sebelumnya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">,</a> saya sudah berbicara tentang mengotomatisasi seluruh proses pengujian beban.  Lebih jauh, saya mungkin akan mengulangi diri saya sedikit, tetapi saya akan memberi tahu Anda beberapa poin lebih terinci. <br><br><img src="https://habrastorage.org/webt/zh/hz/eo/zhhzeorw5_gboyuocu9ajmb3ulo.png"><br><br>  Dalam diagram, kotak biru adalah hypervisor kami (HV), awan yang terdiri dari banyak server (Dell M620 - M640).  Pada setiap HV, selusin mesin virtual (VM) diluncurkan melalui KVM (web / aplikasi dan db dalam campuran).  Saat membuat VM baru, penyeimbangan dan pencarian melalui set parameter HV yang sesuai terjadi dan pada awalnya tidak diketahui server mana yang akan dihidupkan. <br><br><h4>  Basis Data (Game DB): </h4><br>  Tetapi untuk tujuan db1 kami, kami memesan <b>targer_hypervisor</b> HV terpisah berdasarkan M630. <br><br>  Karakteristik singkat dari targer_hypervisor: <br><br>  Dell M_630 <br>  Nama model: Intel¬Æ Xeon¬Æ CPU E5-2680 v3 @ 2.50GHz <br>  CPU: 48 <br>  Utas per inti: 2 <br>  Inti per soket: 12 <br>  Soket: 2 <br>  RAM: 128 GB <br>  Debian GNU / Linux 9 (peregangan) <br>  4.9.0-8-amd64 # 1 SMP Debian 4.9.130-2 (2018-10-27) <br><br><div class="spoiler">  <b class="spoiler_title">Spesifikasi detail</b> <div class="spoiler_text">  Debian GNU / Linux 9 (peregangan) <br>  4.9.0-8-amd64 # 1 SMP Debian 4.9.130-2 (2018-10-27) <br>  lscpu <br>  Arsitektur: x86_64 <br>  Mode operasi CPU: 32-bit, 64-bit <br>  Byte Order: Little Endian <br>  CPU: 48 <br>  Daftar CPU online: 0-47 <br>  Utas per inti: 2 <br>  Inti per soket: 12 <br>  Soket: 2 <br>  NUMA simpul: 2 <br>  ID Vendor: GenuineIntel <br>  Keluarga CPU: 6 <br>  Model: 63 <br>  Nama model: Intel¬Æ Xeon¬Æ CPU E5-2680 v3 @ 2.50GHz <br>  Melangkah: 2 <br>  CPU MHz: 1309.356 <br>  CPU maks MHz: 3300.0000 <br>  CPU min MHz: 1200.0000 <br>  BogoMIPS: 4988.42 <br>  Virtualisasi: VT-x <br>  L1d cache: 32K <br>  L1i cache: 32K <br>  L2 cache: 256 ribu <br>  L3 cache: 30720K <br>  NUMA node0 CPU: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42 44.46 <br>  NUMA node1 CPU: 1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,39,41,43 , 45,47 <br>  Tandai: fpu vme de pse tsc msr pae mc cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm konstantaoptoptsoptsoptsoptoktokkahsampaisampaisampunangkungtoptoptoptoptoptoptoptsoptoptsoptsoptspts. smx est tm2 SSSE3 sdbg FMA cx16 xtpr pdcm PCID DCA sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave AVX f16c rdrand lahf_lm ABM EPB invpcid_single ssbd IBRS ibpb stibp kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 AVX2 SMEP bmi2 Erms invpcid CQM xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts flush_l1d <br><br>  / usr / bin / qemu-system-x86_64 --version <br>  QEMU versi emulator 2.8.1 (Debian 1: 2.8 + dfsg-6 + deb9u5) <br>  Hak Cipta ¬© 2003-2016 Fabrice Bellard dan pengembang Proyek QEMU <br></div></div><br>  Karakteristik singkat dari db1: <br>  Arsitektur: x86_64 <br>  CPU: 48 <br>  RAM: 64 GB <br>  4.9.0-8-amd64 # 1 SMP Debian 4.9.144-3.1 (2019-02-19) x86_64 GNU / Linux <br>  Debian GNU / Linux 9 (peregangan) <br>  psql (PostgreSQL) 11.2 (Debian 11.2-1.pgdg90 +1) <br><br><div class="spoiler">  <b class="spoiler_title">Konfigurasi PostgreSQL dengan beberapa penjelasan</b> <div class="spoiler_text">  seq_page_cost = 1.0 <br>  random_page_cost = 1.1 # Kami memiliki SSD <br>  termasuk '/etc/postgresql/11/main/extension.conf' <br>  log_line_prefix = '% t [% p-% l]% q% u @% h' <br>  log_checkpoints = on <br>  log_lock_waits = on <br>  log_statement = ddl <br>  log_min_duration_statement = 100 <br>  log_temp_files = 0 <br>  autovacuum_max_workers = 5 <br>  autovacuum_naptime = 10s <br>  autovacuum_vacuum_cost_delay = 20ms <br>  vacuum_cost_limit = 2000 <br>  maintenance_work_mem = 128MB <br>  syncous_commit = off <br>  checkpoint_timeout = 30 menit <br>  listen_addresses = '*' <br>  work_mem = 32MB <br>  effective_cache_size = 26214MB # 50% dari memori yang tersedia <br>  shared_buffers = 16384MB # 25% dari memori yang tersedia <br>  max_wal_size = 15GB <br>  min_wal_size = 80MB <br>  wal_level = hot_standby <br>  max_wal_senders = 10 <br>  wal_compression = on <br>  archive_mode = aktif <br>  archive_command = '/ bin / true' <br>  archive_timeout = 1800 <br>  hot_standby = aktif <br>  wal_log_hints = on <br>  hot_standby_feedback = aktif <br></div></div><br>  <b>hot_standby_feedback</b> default tidak aktif, kami telah dihidupkan, tetapi kemudian harus dimatikan untuk melakukan tes yang berhasil.  Saya akan jelaskan nanti mengapa. <br><br>  Tabel aktif utama dalam database (konstruksi, produksi, game_entity, bangunan, core_inventory_player_resource, survivor) sudah diisi sebelumnya dengan data (sekitar 80GB) menggunakan skrip bash. <br><br><div class="spoiler">  <b class="spoiler_title">db-fill-script.sh</b> <div class="spoiler_text"><pre><code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash --clean TRUNCATE TABLE production CASCADE; TRUNCATE TABLE construction CASCADE; TRUNCATE TABLE building CASCADE; TRUNCATE TABLE grid CASCADE; TRUNCATE TABLE core_inventory_player_resource CASCADE; TRUNCATE TABLE survivor CASCADE; TRUNCATE TABLE city CASCADE; TRUNCATE TABLE game_entity CASCADE; TRUNCATE TABLE player CASCADE; TRUNCATE TABLE core_player CASCADE; TRUNCATE TABLE core_client_device CASCADE; --core_client_device INSERT INTO core_client_device (id, creation_date, modification_date, device_model, device_name, locale, platform, user_agent, os_type, os_version, network_type, device_type) SELECT (1000000000+generate_series(0,999999)) AS id, now(), now(), 'device model', 'device name', 'en_DK', 'ios', 'ios user agent', 'android', '8.1', 'wlan', 'browser'; --core_player INSERT INTO core_player (id, guest, name, nickname, premium_points, soft_deleted, session_id, tracking_device_data_id) SELECT (1000000000+generate_series(0,999999)) AS id, true, 'guest0000000000000000000', null, 100, false, '00000000-0000-0000-0000-000000000000', (1000000000+generate_series(0,999999)) ; --player INSERT INTO player (id, creation_date, modification_date, core_player_id) SELECT (1000000000+generate_series(0,999999)) , now(), now(), (1000000000+generate_series(0,999999)) ; --city INSERT INTO game_entity (id, type, creation_date, modification_date) SELECT (1000000000+generate_series(0,999999)) , 'city', now(), now(); INSERT INTO city (id, game_design, player_id) SELECT (1000000000+generate_series(0,999999)) , 'city.default', (1000000000+generate_series(0,999999)) ; --survivor INSERT INTO game_entity (id, type, creation_date, modification_date) SELECT (1001000000+generate_series(0,999999)) , 'survivor', now(), now(); INSERT INTO survivor (id, game_design, owning_entity_id, type) SELECT (1001000000+generate_series(0,999999)) , 'survivor.prod_1', (1000000000+generate_series(0,999999)) , 'survivor'; --core_inventory_player_resource INSERT INTO core_inventory_player_resource (id, creation_date, modification_date, amount, player_id, resource_key) SELECT (1000000000+generate_series(0,1999999)) , NOW(), NOW(), 1000, (1000000000+generate_series(0,1999999)/2) , CONCAT('resource_', (1000000000+generate_series(0,1999999)) % 2); --grid DROP INDEX grid_area_idx; INSERT INTO grid (id, creation_date, modification_date, area, city_id) SELECT (1000000000+generate_series(0,19999999)) , NOW(), NOW(), BOX '0,0,4,4', (1000000000+generate_series(0,19999999)/20) ; create index on grid using gist (area box_ops); --building INSERT INTO game_entity (id, type, creation_date, modification_date) SELECT (1002000000+generate_series(0,99999999)) , 'building', now(), now(); INSERT INTO building (id, game_design, owning_entity_id, x, y, rotation, type) SELECT (1002000000+generate_series(0,99999999)) , 'building.building_prod_1', (1000000000+generate_series(0,99999999)/100) , 0, 0, 'DEGREES_0', 'building'; --construction INSERT INTO construction (id, creation_date, modification_date, definition, entity_id, start) SELECT (1000000000+generate_series(0,1999999)) , NOW(), NOW(), 'construction.building_prod_1-construction', (1002000000+generate_series(0,1999999)*50) , NOW(); --production INSERT INTO production (id, creation_date, modification_date, active, definition, entity_id, start_time) SELECT (1000000000+generate_series(0,49999999)) , NOW(), NOW(), true, 'production.building_prod_1_production_1', (1002000000+generate_series(0,49999999)*2) , NOW();</span></span></code> </pre> <br></div></div><br>  Replikasi: <br><br><pre> <code class="plaintext hljs">SELECT * FROM pg_stat_replication; pid | usesysid | usename | application_name | client_addr | client_hostname | client_port | backend_start | backend_xmin | state | sent_lsn | write_lsn | flush_lsn | replay_lsn | write_lag | flush_lag | replay_lag | sync_priority | sync_state -----+----------+---------+---------------------+--------------+---------------------+-------------+-------------------------------+--------------+-----------+------------+------------+------------+------------+-----------------+-----------------+-----------------+---------------+------------ 759 | 17035 | repmgr | xl1db2 | xxxx | xl1db2 | 51142 | 2019-01-27 08:56:44.581758+00 | | streaming | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 00:00:00.000393 | 00:00:00.001159 | 00:00:00.001313 | 0 | async 977 | 17035 | repmgr | xl1db3 |xxxxx | xl1db3 | 42888 | 2019-01-27 08:57:03.232969+00 | | streaming | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 00:00:00.000373 | 00:00:00.000798 | 00:00:00.000919 | 0 | async</code> </pre><br><h4>  Server aplikasi </h4><br>  Kemudian, pada HV produktif (prod_hypervisors) dari berbagai konfigurasi dan kapasitas, 15 server aplikasi diluncurkan: 8 core, 4GB.  Hal utama yang bisa dikatakan: openjdk 11.0.1 2018-10-16, spring, interaksi dengan database via <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">hikari</a> (hikari.maximum-pool-size: 50) <br><br><h4>  Lingkungan uji stres </h4><br>  Seluruh lingkungan pengujian beban terdiri dari satu server <b>admin.loadtest</b> utama, dan beberapa server <b>generatorN.loadtest</b> (dalam hal ini ada 14). <br><br>  <b>generatorN.loadtest</b> - "telanjang" VM Debian Linux 9, dengan Java yang diinstal 8. 32 kernel / 32 gigabytes.  Mereka berada di HV non-produktif sehingga tidak secara tidak sengaja membunuh kinerja VM penting. <br><br>  <b>admin.loadtest</b> - <b>Mesin virtual</b> Debian Linux 9, 16 core / 16 gigs, menjalankan Jenkins, JLTC, dan perangkat lunak tambahan lainnya yang tidak penting. <br><br>  JLTC - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pusat uji beban jmeter</a> .  Sistem pada Py / Django yang mengontrol dan mengotomatiskan peluncuran tes, serta analisis hasil. <br><br><h3>  Skema Peluncuran Tes </h3><br><img src="https://habrastorage.org/webt/pb/f_/th/pbf_thx7mwuois96bffvbeehtxk.png"><br><br>  Proses menjalankan tes terlihat seperti ini: <br><br><ul><li>  Tes diluncurkan dari <b>Jenkins</b> .  Pilih Pekerjaan yang diperlukan, maka Anda harus memasukkan parameter tes yang diinginkan: <ul><li>  <b>DURASI</b> - durasi tes </li><li>  <b>RAMPUP</b> - waktu "pemanasan" </li><li>  <b>THREAD_COUNT_TOTAL</b> - jumlah pengguna virtual (VU) atau utas yang diinginkan </li><li>  <b>TARGET_RESPONSE_TIME</b> adalah parameter penting, agar tidak membebani seluruh sistem dengan bantuannya, kami menetapkan waktu respons yang diinginkan, sehingga pengujian akan menjaga beban pada tingkat di mana waktu respons seluruh sistem tidak lebih dari yang ditentukan. </li></ul></li><li>  Luncurkan </li><li>  Jenkins mengkloning rencana tes dari Gitlab, mengirimkannya ke JLTC. </li><li>  JLTC bekerja sedikit dengan rencana pengujian (misalnya, menyisipkan penulis sederhana CSV). </li><li>  JLTC menghitung jumlah server Jmeter yang diperlukan untuk menjalankan jumlah VU yang diinginkan (THREAD_COUNT_TOTAL). </li><li>  JLTC terhubung ke setiap generator loadgeneratorN dan memulai server jmeter. </li></ul><br>  Selama pengujian, <b>klien JMeter</b> menghasilkan file CSV dengan hasilnya.  Jadi selama pengujian, jumlah data dan ukuran file ini tumbuh pada kecepatan yang <b>gila</b> , dan itu tidak dapat digunakan untuk analisis setelah pengujian - <b>Daemon</b> ditemukan (sebagai percobaan), yang menguraikannya <i>"dengan cepat"</i> . <br><br><h3>  Rencana uji </h3><br>  Anda dapat mengunduh paket tes di <a href="">sini</a> . <br><br>  Setelah pendaftaran / masuk, pengguna bekerja dalam modul <b>Behavior</b> , yang terdiri dari beberapa <b>pengontrol Throughput</b> yang menentukan kemungkinan fungsi game tertentu.  Di setiap pengontrol Throughput, ada <b>Pengontrol modul</b> , yang merujuk ke modul terkait yang mengimplementasikan fungsi. <br><br><img src="https://habrastorage.org/webt/t0/ws/qp/t0wsqpbkgo-w6dt55gvxd6aw9pm.png"><br><br><h4>  Di luar topik </h4><br>  Selama pengembangan skrip, kami mencoba menggunakan Groovy secara maksimal, dan terima kasih kepada programmer Java kami, saya menemukan beberapa trik untuk diri saya sendiri (mungkin ini akan berguna bagi seseorang): <br><br><ul><li>  Anda dapat mendeklarasikan suatu fungsi di suatu tempat di awal rencana pengujian, dan kemudian menggunakannya di pra-, pasca-prosesor dan sampler.  Lebih Banyak <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kebaikan Groovy: Ubah Metode menjadi Penutupan</a> : <br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//     - def sum(Integer x, Integer y) { return x + y } vars.putObject('sum', this.&amp;sum) //      closure.   . //     sampler`       def sum= vars.getObject('sum'); println sum(2, 2);</span></span></code> </pre> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">groovy.json.JsonSlurper</a> adalah parser JSON cepat yang bagus.  Bersama dengan groovy, ini memungkinkan Anda untuk mengurai data secara elegan dan memprosesnya: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> groovy.json.JsonSlurper def canBuild = vars.getObject(canBuild); <span class="hljs-comment"><span class="hljs-comment">// ""       def content = jsonSlurper.parseText(response).content def buildings = content[0].buildings //         //               def constructableBuildingDefs = buildings .collect { k,v -&gt; v } .grep{ it.definitions .grep { it2 -&gt; it2['@type'] == 'type.googleapis.com/ConstructionDefinitionDTO'} .grep { it2 -&gt; canBuild(it2) } //   .size() &gt; 0 } if (!constructableBuildingDefs) { return; } Collections.shuffle(constructableBuildingDefs) //       </span></span></code> </pre></li></ul><br><h3>  VU / Utas </h3><br>  Ketika pengguna memasukkan jumlah VU yang diinginkan menggunakan parameter THREAD_COUNT_TOTAL ketika mengkonfigurasi pekerjaan di Jenkins, perlu untuk memulai jumlah server Jmeter yang diperlukan dan mendistribusikan jumlah VU terakhir yang diperlukan di antara mereka.  Bagian ini terletak pada JLTC di bagian yang disebut <b>pengontrol / ketentuan</b> . <br><br>  Intinya, algoritma ini adalah sebagai berikut: <br><br><ul><li>  Kami membagi jumlah VU <b>threads_num yang</b> diinginkan menjadi 200-300 utas dan berdasarkan pada ukuran yang kurang lebih <b>-Xmsm -Xmxm, kami</b> menentukan nilai memori yang diperlukan untuk satu <i>jmeter-server</i> <b>required_memory_for_jri</b> (JRI - Saya memanggil instance jarak jauh Jmeter, bukan Jmeter-server). </li><li>  Dari threads_num dan required_memory_for_jri kami menemukan jumlah total jmeter-server: <b>target_amount_jri</b> dan nilai total memori yang <b>diperlukan</b> : <b>required_memory_total</b> . </li><li>  Kami memilah-milah semua generator loadgeneratorN satu per satu dan memulai jumlah maksimum server-jmeter berdasarkan memori yang tersedia di dalamnya.  Selama jumlah instance instalan current_amount_jri <b>tidak sama dengan</b> target_amount_jri. </li><li>  (Jika jumlah generator dan total memori tidak cukup, tambahkan yang baru ke kumpulan) </li><li>  Kami terhubung ke setiap generator, menggunakan <b>netstat yang kami</b> ingat semua port sibuk, dan berjalan pada port acak (yang tidak dihuni) jumlah yang diperlukan dari server-jmeter: <br><br><pre> <code class="python hljs"> netstat_cmd= <span class="hljs-string"><span class="hljs-string">'netstat -tulpn | grep LISTEN'</span></span> stdin, stdout, stderr = ssh.exec_command(cmd1) used_ports = [] netstat_output = str(stdout.readlines()) ports = re.findall(<span class="hljs-string"><span class="hljs-string">'\d+\.\d+\.\d+\.\d+\:(\d+)'</span></span>, netstat_output) ports_ipv6 = re.findall(<span class="hljs-string"><span class="hljs-string">'\:\:\:(\d+)'</span></span>, netstat_output) p.wait() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> port <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> ports: used_ports.append(int(port)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> port <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> ports_ipv6: used_ports.append(int(port)) ssh.close() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, possible_jris_on_host + <span class="hljs-number"><span class="hljs-number">1</span></span>): port = int(random.randint(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">20000</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> port <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> used_ports: port = int(random.randint(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">20000</span></span>)) <span class="hljs-comment"><span class="hljs-comment"># ...  Jmeter-    </span></span></code> </pre></li><li>  Kami mengumpulkan semua server jmeter yang berjalan dalam satu waktu dalam format alamat: port, misalnya <b>generator13: 15576, generator9: 14015, generator11: 19152, generator14: 12125, generator2: 17602</b> </li><li>  Daftar dan threads_per_host yang dihasilkan dikirim ke JMeter-client ketika tes dimulai: <br><br><pre> <code class="bash hljs">REMOTE_TESTING_FLAG=<span class="hljs-string"><span class="hljs-string">" -R </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$REMOTE_HOSTS_STRING</span></span></span><span class="hljs-string">"</span></span> java -jar -Xms7g -Xmx7g -Xss228k <span class="hljs-variable"><span class="hljs-variable">$JMETER_DIR</span></span>/bin/ApacheJMeter.jar -Jserver.rmi.ssl.disable=<span class="hljs-literal"><span class="hljs-literal">true</span></span> -n -t <span class="hljs-variable"><span class="hljs-variable">$TEST_PLAN</span></span> -j <span class="hljs-variable"><span class="hljs-variable">$WORKSPACE</span></span>/loadtest.log -GTHREAD_COUNT=<span class="hljs-variable"><span class="hljs-variable">$THREADS_PER_HOST</span></span> <span class="hljs-variable"><span class="hljs-variable">$OTHER_VARS</span></span> <span class="hljs-variable"><span class="hljs-variable">$REMOTE_TESTING_FLAG</span></span> -Jjmeter.save.saveservice.default_delimiter=,</code> </pre></li></ul><br>  Dalam kasus kami, pengujian berlangsung secara simultan dari 300 server Jmeter, masing-masing 500 utas, format peluncuran satu server Jmeter dengan parameter Java tampak seperti ini: <br><br><pre> <code class="bash hljs">nohup java -server -Xms1200m -Xmx1200m -Xss228k -XX:+DisableExplicitGC -XX:+CMSClassUnloadingEnabled -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -Djava.net.preferIPv6Addresses=<span class="hljs-literal"><span class="hljs-literal">true</span></span> -Djava.net.preferIPv4Stack=<span class="hljs-literal"><span class="hljs-literal">false</span></span> -jar <span class="hljs-string"><span class="hljs-string">"/tmp/jmeter-JwKse5nY/bin/ApacheJMeter.jar"</span></span> -Jserver.rmi.ssl.disable=<span class="hljs-literal"><span class="hljs-literal">true</span></span> <span class="hljs-string"><span class="hljs-string">"-Djava.rmi.server.hostname=generator12.loadtest.ig.local"</span></span> -Duser.dir=/tmp/jmeter-JwKse5nY/bin/ -Dserver_port=13114 -s -Jpoll=49 &gt; /dev/null 2&gt;&amp;1</code> </pre> <br><h3>  50 ms </h3><br>  Tugasnya adalah untuk menentukan seberapa banyak basis data kita dapat bertahan, daripada membebani secara berlebihan dan keseluruhan sistem secara keseluruhan hingga ke kondisi kritis.  Dengan begitu banyak server Jmeter, Anda perlu mempertahankan beban pada tingkat tertentu dan tidak mematikan keseluruhan sistem.  Parameter <b>TARGET_RESPONSE_TIME yang</b> ditentukan saat memulai tes bertanggung jawab untuk ini.  Kami sepakat bahwa <b>50ms</b> adalah waktu respons optimal yang menjadi tanggung jawab sistem. <br><br>  Di JMeter, secara default, ada banyak timer berbeda yang memungkinkan Anda untuk mengontrol throughput, tetapi tidak diketahui di mana mendapatkannya dalam kasus kami.  Tetapi ada <b>JSR223-Timer</b> yang dengannya Anda dapat menemukan sesuatu menggunakan <b>waktu respons</b> sistem <b>saat ini</b> .  Timer itu sendiri ada di blok <b>Perilaku</b> utama: <br><br><img src="https://habrastorage.org/webt/uv/o8/rb/uvo8rb9ph7mr1xhxkzxccsfa06a.png"><br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//      = 0 vars.put('samples', '20'); vars.putObject('respAvg', ${TARGET_RESPONSE_TIME}.0); vars.putObject('sleep', 0.0); //  JSR223-Timer           "" double sleep = vars.getObject('sleep'); double respAvg = vars.getObject('respAvg'); double previous = sleep; double target = ${TARGET_RESPONSE_TIME}; if (respAvg &lt; target) { sleep /= 1.5; } if (respAvg &gt; target) { sleep *= 1.1; } sleep = Math.max(10, sleep); //      sleep = Math.min(20000, sleep); vars.putObject('sleep', sleep); return (int)sleep;</span></span></code> </pre><br><h3>  Analisis hasil (daemon) </h3><br>  Selain grafik di Grafana, juga perlu memiliki hasil tes agregat sehingga tes selanjutnya dapat dibandingkan di JLTC. <br><br>  Salah satu tes tersebut menghasilkan 16k-20k permintaan per detik, mudah untuk menghitung bahwa dalam 4 jam itu menghasilkan file CSV berukuran beberapa ratus GB, jadi perlu untuk membuat pekerjaan yang mem-parsing data setiap menit, mengirimkannya ke database dan membersihkan file utama. <br><br><img src="https://habrastorage.org/webt/pb/mj/kc/pbmjkcwgjcxupnihgzpzmqd0nvq.png"><br><br>  Algoritma adalah sebagai berikut: <br><br><ul><li>  Kami membaca data dari file CSV <b>result.jtl yang</b> dihasilkan oleh jmeter-client, simpan dan bersihkan file tersebut (Anda harus membersihkannya dengan benar, jika tidak, file yang tampak kosong akan memiliki FD yang sama dengan ukuran yang sama): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(jmeter_results_file, <span class="hljs-string"><span class="hljs-string">'r+'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: rows = f.readlines() f.seek(<span class="hljs-number"><span class="hljs-number">0</span></span>) f.truncate(<span class="hljs-number"><span class="hljs-number">0</span></span>) f.writelines(rows[<span class="hljs-number"><span class="hljs-number">-1</span></span>])</code> </pre></li><li>  Kami menulis data baca ke file sementara <b>temp_result.jtl</b> : <br><br><pre> <code class="python hljs">rows_num = len(rows) open(temp_result_filename, <span class="hljs-string"><span class="hljs-string">'w'</span></span>).writelines(rows[<span class="hljs-number"><span class="hljs-number">0</span></span>:rows_num]) <span class="hljs-comment"><span class="hljs-comment"># avoid last line</span></span></code> </pre> </li><li>  Kami membaca file <b>temp_result.jtl</b> .  Kami mendistribusikan data baca "dalam hitungan menit": <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> r <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f.readlines(): row = r.split(<span class="hljs-string"><span class="hljs-string">','</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(row[<span class="hljs-number"><span class="hljs-number">0</span></span>]) == <span class="hljs-number"><span class="hljs-number">13</span></span>: ts_c = int(row[<span class="hljs-number"><span class="hljs-number">0</span></span>]) dt_c = datetime.datetime.fromtimestamp(ts_c/<span class="hljs-number"><span class="hljs-number">1000</span></span>) minutes_data.setdefault(dt_c.strftime(<span class="hljs-string"><span class="hljs-string">'%Y_%m_%d_%H_%M'</span></span>), []).append(r)</code> </pre></li><li>  Data untuk setiap menit dari <b>minutes_data</b> ditulis ke file yang sesuai di folder <b>to_parse</b> .  (dengan demikian, pada saat ini, setiap menit tes memiliki file datanya sendiri, maka selama agregasi <b>itu</b> tidak masalah dalam urutan apa data masuk ke setiap file): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> key, value <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> minutes_data.iteritems(): <span class="hljs-comment"><span class="hljs-comment">#      timestamp (key) temp_ts_file = os.path.join(temp_to_parse_path, key) open(temp_ts_file, 'a+').writelines(value)</span></span></code> </pre></li><li>  Sepanjang jalan, kami menganalisis file dalam folder to_parse dan jika ada yang tidak berubah dalam satu menit, maka file ini adalah kandidat untuk analisis data, agregasi, dan mengirim ke database JLTC: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> filename <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> os.listdir(temp_to_parse_path): data_file = os.path.join(temp_to_parse_path, filename) file_mod_time = os.stat(data_file).st_mtime last_time = (time.time() - file_mod_time) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> last_time &gt; <span class="hljs-number"><span class="hljs-number">60</span></span>: logger.info(<span class="hljs-string"><span class="hljs-string">'[DAEMON] File {} was not modified since 1min, adding to parse list.'</span></span>.format(data_file)) files_to_parse.append(data_file)</code> </pre></li><li>  Jika ada file seperti itu (satu atau beberapa), maka kami mengirimnya diurai ke fungsi <b>parse_csv_data</b> (setiap file secara paralel): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> files_to_parse: logger.info(<span class="hljs-string"><span class="hljs-string">'[DAEMON THREAD] Parse {}.'</span></span>.format(f)) t = threading.Thread( target=parse_csv_data, args=( f, jmeter_results_file_fields, test, data_resolution)) t.start() threads.append(t) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> threads: t.join()</code> </pre></li></ul><br>  Daemon itu sendiri di cron.d dimulai setiap menit: <br><br>  daemon dimulai setiap menit dengan cron.d: <br><br><pre> <code class="bash hljs">* * * * * root sleep 21 &amp;&amp; /usr/bin/python /var/lib/jltc/manage.py daemon</code> </pre> <br>  Dengan demikian, file dengan hasil tidak membengkak ke ukuran yang tak terbayangkan, tetapi dianalisis <i>dengan cepat</i> dan dibersihkan. <br><br><h2>  Hasil </h2><br><h3>  Aplikasi </h3><br>  150.000 pemain virtual kami: <br><br><img src="https://habrastorage.org/webt/sv/ex/ep/svexepi9ikzy0unpxur96mty5q8.png"><br><br>  Tes ini mencoba untuk "mencocokkan" waktu respons 50 ms, sehingga beban itu sendiri secara konstan melompat di wilayah antara 16k-18k permintaan / c: <br><br><img src="https://habrastorage.org/webt/-z/98/oi/-z98oi-_8a41hkqbrmz2rvzmryk.png"><br><br>  Aplikasi memuat server (15 aplikasi).  Dua server "sial" berada di M620 yang lebih lambat: <br><br><img src="https://habrastorage.org/webt/nc/xy/et/ncxyetqyk_a8mbhjocndd-yxgkm.png"><br><br>  Waktu respons basis data (untuk server aplikasi): <br><br><img src="https://habrastorage.org/webt/zr/a-/gw/zra-gwtq_vqhtfhlrjzzy1osisg.png"><br><br><h3>  Basis data </h3><br>  Penggunaan CPU pada db1 (VM): <br><br><img src="https://habrastorage.org/webt/ej/hn/in/ejhnin0jo_7rrzhlj7pqko6udnq.png"><br><br>  Penggunaan CPU pada hypervisor: <br><br><img src="https://habrastorage.org/webt/uw/ik/tz/uwiktzvcdzydlsjaoexqfbr3tay.png"><br><br>  Beban pada mesin virtual lebih rendah, karena ia percaya bahwa ia memiliki 48 core nyata yang tersedia, pada kenyataannya, ada 24 core <b>hyperhreading</b> pada hypervisor. <br><br>  <b>Maksimal ~ 250K kueri / s</b> masuk ke basis data, terdiri dari (83% selektif, 3% - sisipan, 11,6% - pembaruan (90% HOT), 1,6% dihapus): <br><br><img src="https://habrastorage.org/webt/lx/lu/bl/lxlublobhm4nm3c45g9jikcstc4.png"><br><br><img src="https://habrastorage.org/webt/18/jw/gp/18jwgpmebrkyot3ngvarsl_3ysu.png"><br><br>  Dengan nilai default <b>autovacuum_vacuum_scale_factor</b> = 0,2, jumlah tupel mati tumbuh sangat cepat dengan pengujian (dengan meningkatnya ukuran tabel), yang menyebabkan beberapa kali masalah pendek kinerja database yang merusak seluruh tes beberapa kali.  Saya harus "menjinakkan" pertumbuhan ini untuk beberapa tabel dengan menetapkan nilai pribadi ke parameter ini autovacuum_vacuum_scale_factor: <br><br><div class="spoiler">  <b class="spoiler_title">ALTER TABEL ... SET (autovacuum_vacuum_scale_factor = ...)</b> <div class="spoiler_text">  SET konstruksi ALTER TABEL (autovacuum_vacuum_scale_factor = 0.10); <br>  ALTER TABLE SET produksi (autovacuum_vacuum_scale_factor = 0,01); <br>  ALTER TABLE game_entity SET (autovacuum_vacuum_scale_factor = 0,01); <br>  ALTER TABLE game_entity SET (autovacuum_analyze_scale_factor = 0,01); <br>  SET bangunan ALTER TABEL (autovacuum_vacuum_scale_factor = 0,01); <br>  SET bangunan ALTER TABEL (autovacuum_analyze_scale_factor = 0,01); <br>  ALTER TABLE core_inventory_player_resource SET (autovacuum_vacuum_scale_factor = 0,10); <br>  SET ALTER TABEL selamat (autovacuum_vacuum_scale_factor = 0,01); <br>  SET ALTER TABEL selamat (autovacuum_analyze_scale_factor = 0,01); <br></div></div><br><img src="https://habrastorage.org/webt/0s/ja/1e/0sja1e1m3-2gitbmhh8j24t2ktu.png"><br><br>  Idealnya, rows_fetched harus dekat dengan rows_returned, yang kami, untungnya, kami amati: <br><br><img src="https://habrastorage.org/webt/e4/k6/zo/e4k6zobp25h5asrmxhmficoea3a.png"><br><br><h4>  hot_standby_feedback </h4><br>  Masalahnya adalah dengan parameter <b>hot_standby_feedback</b> , yang dapat sangat mempengaruhi kinerja server <b>utama</b> jika server <b>siaga</b> tidak punya waktu untuk menerapkan perubahan dari file WAL.  Dokumentasi (https://postgrespro.ru/docs/postgrespro/11/runtime-config-replication) menyatakan bahwa ia "menentukan apakah server siaga panas akan memberi tahu master atau budak superior tentang permintaan yang saat ini dieksekusi."  Secara default tidak aktif, tetapi dihidupkan dalam konfigurasi kami.  Yang menyebabkan konsekuensi yang menyedihkan, jika ada 2 server siaga dan jeda replikasi selama pemuatan berbeda dari nol (karena berbagai alasan), Anda dapat mengamati gambar seperti itu, yang dapat menyebabkan runtuhnya seluruh pengujian: <br><br><img src="https://habrastorage.org/webt/vl/1l/jd/vl1ljdockxrjlfsoiybq751vo9y.png"><br><br><img src="https://habrastorage.org/webt/qh/4s/m_/qh4sm_hpnunb2w0axzhk90lmf6u.png"><br><br>  Ini disebabkan oleh fakta bahwa ketika hot_standby_feedback diaktifkan, VACUUM tidak ingin menghapus tupel mati jika server siaga ketinggalan dalam id transaksi mereka untuk mencegah konflik replikasi.  Artikel terperinci <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Apa sebenarnya hot_standby_feedback di PostgreSQL</a> : <br><br><pre> <code class="plaintext hljs">xl1_game=# VACUUM VERBOSE core_inventory_player_resource; INFO: vacuuming "public.core_inventory_player_resource" INFO: scanned index "core_inventory_player_resource_pkey" to remove 62869 row versions DETAIL: CPU: user: 1.37 s, system: 0.58 s, elapsed: 4.20 s ‚Ä¶‚Ä¶‚Ä¶... INFO: "core_inventory_player_resource": found 13682 removable, 7257082 nonremovable row versions in 71842 out of 650753 pages &lt;b&gt;DETAIL: 3427824 dead row versions cannot be removed yet, oldest xmin: 3810193429&lt;/b&gt; There were 1920498 unused item pointers. Skipped 8 pages due to buffer pins, 520953 frozen pages. 0 pages are entirely empty. CPU: user: 4.55 s, system: 1.46 s, elapsed: 11.74 s.</code> </pre><br>  Sejumlah besar tupel mati mengarah ke gambar yang ditunjukkan di atas.  Berikut adalah dua tes, dengan hot_standby_feedback dihidupkan dan dimatikan: <br><br><img src="https://habrastorage.org/webt/8f/od/n6/8fodn60lohgzsu-twheqysldjzy.png"><br><br>  Dan ini adalah keterlambatan replikasi kami selama pengujian, yang dengannya diperlukan untuk melakukan sesuatu di masa depan: <br><br><img src="https://habrastorage.org/webt/et/s0/7h/ets07hkl8skkv5wexxjrgi-3x7m.png"><br><br><h2>  Kesimpulan </h2><br>  Tes ini, untungnya (atau sayangnya untuk konten artikel) menunjukkan bahwa pada tahap prototipe permainan ini sangat mungkin untuk menyerap beban yang diinginkan pada bagian pengguna, yang cukup memberikan lampu hijau untuk prototipe dan pengembangan lebih lanjut.  Pada tahap pengembangan selanjutnya, perlu untuk mengikuti aturan dasar (untuk menjaga kesederhanaan dari pertanyaan yang dieksekusi, untuk mencegah kelebihan indeks, serta pembacaan yang tidak diindeks, dll.) Dan yang paling penting, uji proyek pada setiap tahap perkembangan yang signifikan untuk menemukan dan memperbaiki masalah seperti bisa lebih awal.  Mungkin sebentar lagi, saya akan menulis artikel karena kami telah memecahkan masalah khusus. <br><br>  Semoga beruntung untuk semuanya! <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">GitHub</a> kami untuk jaga-jaga;) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id445368/">https://habr.com/ru/post/id445368/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id445356/index.html">Tinjauan umum bagian Seluler di DUMP-2019: maksimum diterapkan dan berguna dalam pekerjaan sehari-hari</a></li>
<li><a href="../id445358/index.html">Organisasi sistem acara di Unity - melalui mata seorang desainer game</a></li>
<li><a href="../id445360/index.html">5 tugas khas untuk wawancara JavaScript: penguraian dan solusi</a></li>
<li><a href="../id445362/index.html">Buku "Sistem Terdistribusi. Pola Desain</a></li>
<li><a href="../id445366/index.html">Cara mempercepat enkripsi menurut GOST 28147-89 pada prosesor Baikal-T1 karena blok SIMD</a></li>
<li><a href="../id445370/index.html">Analisis TSDB di Prometheus 2</a></li>
<li><a href="../id445372/index.html">Visi mesin vs intuisi manusia: algoritma untuk mengganggu operasi program pengenalan objek</a></li>
<li><a href="../id445378/index.html">Labirin: klasifikasi, pembangkitan, mencari solusi</a></li>
<li><a href="../id445380/index.html">PHP modern itu indah dan produktif</a></li>
<li><a href="../id445384/index.html">Misi Chang'e-4 - peralatan ilmiah pada modul pendaratan dan satelit repeater</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
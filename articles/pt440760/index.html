<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìï üë®üèø‚Äç‚úàÔ∏è ‚öîÔ∏è A nova era de ouro da arquitetura de computadores ‚ö°Ô∏è üï§ üõ•Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Os autores s√£o John Hennessey e David Patterson, vencedores do Turing Award de 2017 "por uma abordagem sistem√°tica e mensur√°vel inovadora ao design e ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>A nova era de ouro da arquitetura de computadores</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440760/">  <i><font color="gray">Os autores s√£o John Hennessey e David Patterson, vencedores do Turing Award de 2017 "por uma abordagem sistem√°tica e mensur√°vel inovadora ao design e verifica√ß√£o de arquiteturas de computadores que tiveram um impacto duradouro em toda a ind√∫stria de microprocessadores".</font></i>  <i><font color="gray">Artigo publicado em Communications of the ACM, fevereiro de 2019, volume 62, n¬∫ 2, pp. 48-60, doi: 10.1145 / 3282307</font></i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f32/766/d00/f32766d00d21a30b98a879e2a636a82f.jpg" align="left">  <i>‚ÄúQuem n√£o se lembra do passado est√° fadado a repeti-lo‚Äù</i> - George Santayana, 1905 <br><br>  Come√ßamos nossa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">palestra</a> em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Turing</a> em 4 de junho de 2018 com uma revis√£o da arquitetura de computadores a partir dos anos 60.  Al√©m dele, destacamos as quest√µes atuais e tentamos identificar oportunidades futuras que prometem uma nova era de ouro no campo da arquitetura de computadores na pr√≥xima d√©cada.  O mesmo da d√©cada de 1980, quando realizamos nossa pesquisa para melhorar o custo, a efici√™ncia energ√©tica, a seguran√ßa e o desempenho dos processadores, pelos quais recebemos esse honor√°vel pr√™mio. <br><br><h4>  Ideias-chave </h4><br><ul><li>  O progresso do software pode impulsionar a inova√ß√£o arquitet√¥nica <br></li><li>  Aumentar o n√≠vel de interfaces de software e hardware cria oportunidades para inova√ß√£o arquitet√¥nica <br></li><li>  O mercado finalmente determina o vencedor na disputa pela arquitetura </li></ul><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3LVeEjsn8Ts" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  O software "conversa" com o equipamento atrav√©s de um dicion√°rio chamado "arquitetura do conjunto de instru√ß√µes" (ISA).  No in√≠cio dos anos 60, a IBM tinha quatro s√©ries incompat√≠veis de computadores, cada uma com seu pr√≥prio ISA, pilha de software, sistema de E / S e nicho de mercado - orientado para pequenas empresas, grandes empresas, aplicativos cient√≠ficos e sistemas em tempo real, respectivamente.  Os engenheiros da IBM, incluindo o vencedor do Pr√™mio Turing Frederick Brooks Jr., decidiram criar um √∫nico ISA que unisse efetivamente todos os quatro. <br><br>  Eles precisavam de uma solu√ß√£o t√©cnica sobre como fornecer ISA igualmente r√°pido para computadores com barramentos de 8 e 64 bits.  Em certo sentido, os √¥nibus s√£o os "m√∫sculos" dos computadores: eles fazem o trabalho, mas s√£o relativamente f√°ceis de "compactar" e "expandir".  Ent√£o, e agora o maior desafio para os designers √© o "c√©rebro" do equipamento de controle do processador.  Inspirado pela programa√ß√£o, o pioneiro da ci√™ncia da computa√ß√£o e o vencedor do Pr√™mio Turing Maurice Wilkes prop√¥s op√ß√µes para simplificar esse sistema.  O controle foi apresentado como uma matriz bidimensional, que ele chamou de "armazenamento de controle" (armazenamento de controle).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cada coluna da matriz correspondia a uma linha de controle, cada linha era micro-instru√ß√£o e o registro de micro-instru√ß√µes era chamado de microprograma√ß√£o</a> .  A mem√≥ria de controle cont√©m um int√©rprete ISA escrito por micro-instru√ß√µes, portanto a execu√ß√£o de uma instru√ß√£o normal requer v√°rias micro-instru√ß√µes.  A mem√≥ria de controle √© implementada, de fato, na mem√≥ria e √© muito mais barata que os elementos l√≥gicos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2f4/43f/818/2f443f8180eb7edbc2dbd66873b71c51.jpg"><br>  <i><font color="gray">Recursos dos quatro modelos da fam√≠lia IBM System / 360;</font></i>  <i><font color="gray">IPS significa opera√ß√µes por segundo</font></i> <br><br>  A tabela mostra quatro modelos do novo ISA no System / 360 da IBM, lan√ßado em 7 de abril de 1964.  Os barramentos diferem 8 vezes, a capacidade de mem√≥ria √© 16, a velocidade do rel√≥gio √© quase 4, o desempenho √© 50 e o custo √© quase 6. Os computadores mais caros t√™m a mem√≥ria de controle mais extensa, porque os barramentos de dados mais complexos usavam mais linhas de controle .  Os computadores mais baratos possuem menos mem√≥ria de controle devido ao hardware mais simples, mas precisavam de mais micro-instru√ß√µes, pois precisavam de mais ciclos de clock para executar a instru√ß√£o System / 360. <br><br>  Gra√ßas √† microprograma√ß√£o, a IBM apostou que o novo ISA revolucionaria o setor de computa√ß√£o - e ganhou a aposta.  A IBM dominava seus mercados, e os descendentes dos mainframes antigos de 55 anos de idade ainda geram receita de US $ 10 bilh√µes anualmente. <br><br>  Como j√° foi observado repetidamente, embora o mercado seja um √°rbitro imperfeito como tecnologia, mas devido aos la√ßos estreitos entre arquitetura e computadores comerciais, em √∫ltima an√°lise, determina o sucesso das inova√ß√µes arquitet√¥nicas, que geralmente exigem investimentos significativos em engenharia. <br><br><h3>  Circuitos integrados, CISC, 432, 8086, IBM PC </h3><br>  Quando os computadores mudaram para circuitos integrados, a lei de Moore significava que a mem√≥ria de controle poderia se tornar muito maior.  Por sua vez, isso permitiu um ISA muito mais complexo.  Por exemplo, a mem√≥ria de controle VAX-11/780 da Digital Equipment Corp.  em 1977, eram 5120 palavras em 96 bits, enquanto seu antecessor usava apenas 256 palavras em 56 bits. <br><br>  Alguns fabricantes ativaram o firmware para clientes selecionados que podem ter adicionado recursos personalizados.  Isso √© chamado de armazenamento de controle grav√°vel (WCS).  O computador WCS mais famoso foi o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Alto</a> , que os vencedores do Pr√™mio Turing Chuck Tucker e Butler Lampson e colegas criaram para o Centro de Pesquisa Xerox Palo Alto em 1973.  Foi realmente o primeiro computador pessoal: aqui est√° o primeiro monitor com imagens elemento a elemento e a primeira rede Ethernet local.  Os controladores do inovador monitor e placa de rede eram microprogramas armazenados no WCS com capacidade para 4096 palavras em 32 bits. <br><br>  Nos anos 70, os processadores ainda permaneciam 8 bits (por exemplo, Intel 8080) e eram programados principalmente em assembler.  Os concorrentes adicionaram novas instru√ß√µes para superar um ao outro, mostrando suas realiza√ß√µes com exemplos de montadores. <br><br>  Gordon Moore acreditava que o pr√≥ximo ISA da Intel duraria para sempre para a empresa, ent√£o ele contratou muitos m√©dicos inteligentes em ci√™ncia da computa√ß√£o e os enviou para uma nova instala√ß√£o em Portland para inventar o pr√≥ximo grande ISA.  O processador 8800, como a Intel originalmente o chamou, tornou-se um projeto de arquitetura de computador absolutamente ambicioso para qualquer √©poca, √© claro, foi o projeto mais agressivo dos anos 80.  Ele incluiu endere√ßamento baseado em capacidade de 32 bits, uma arquitetura orientada a objetos, instru√ß√µes de comprimento vari√°vel e seu pr√≥prio sistema operacional na nova linguagem de programa√ß√£o Ada. <br><br>  Infelizmente, esse projeto ambicioso exigiu v√°rios anos de desenvolvimento, o que for√ßou a Intel a lan√ßar um projeto de backup de emerg√™ncia em Santa Clara para lan√ßar rapidamente um processador de 16 bits em 1979.  A Intel deu √† nova equipe 52 semanas para desenvolver o novo ISA "8086", projetar e construir o chip.  Dado um cronograma apertado, o design do ISA levou apenas 10 pessoas-semana por tr√™s semanas regulares, principalmente devido √† expans√£o de registros de 8 bits e um conjunto de instru√ß√µes 8080 para 16 bits.  A equipe completou o 8086 dentro do cronograma, mas esse processador foi anunciado sem muita alarde. <br><br>  A Intel teve muita sorte que a IBM estava desenvolvendo um computador pessoal para competir com o Apple II e precisava de um microprocessador de 16 bits.  A IBM estava de olho no Motorola 68000 com um ISA semelhante ao IBM 360, mas estava atrasado no cronograma agressivo da IBM.  Em vez disso, a IBM mudou para a vers√£o de 8 bits do barramento 8086. Quando a IBM anunciou o PC em 12 de agosto de 1981, esperava vender 250.000 computadores at√© 1986.  Em vez disso, a empresa vendeu 100 milh√µes em todo o mundo, apresentando um futuro muito promissor para o ISA de emerg√™ncia da Intel. <br><br>  O projeto original Intel 8800 foi renomeado para iAPX-432.  Finalmente, foi anunciado em 1981, mas exigia v√°rios chips e apresentava s√©rios problemas de desempenho.  Foi conclu√≠da em 1986, um ano ap√≥s a Intel ter expandido o ISA 8086 de 16 bits para 80386, aumentando os registros de 16 para 32 bits.  Portanto, a previs√£o de Moore em rela√ß√£o ao ISA estava correta, mas o mercado escolheu o 8086 feito pela metade, em vez do iAPX-432 ungido.  Como os arquitetos dos processadores Motorola 68000 e iAPX-432 perceberam, o mercado raramente consegue demonstrar paci√™ncia. <br><br><h3>  Do conjunto de instru√ß√µes complexo ao abreviado </h3><br>  No in√≠cio dos anos 80, v√°rios estudos de computadores com um conjunto de instru√ß√µes complexas (CISC) foram realizados: eles possuem grandes microprogramas na grande mem√≥ria de controle.  Quando o Unix demonstrou que mesmo o sistema operacional pode ser escrito em uma linguagem de alto n√≠vel, a pergunta principal era: ‚ÄúQuais instru√ß√µes os compiladores gerar√£o?‚Äù  em vez do antigo "Que montador os programadores usar√£o?"  Um aumento significativo no n√≠vel da interface hardware-software criou uma oportunidade para inova√ß√£o na arquitetura. <br><br>  O vencedor do Pr√™mio Turing John Kokk e seus colegas desenvolveram ISAs mais simples e compiladores de minicomputadores.  Como um experimento, eles reorientaram seus compiladores de pesquisa a usar o IBM 360 ISA para usar apenas opera√ß√µes simples entre registradores e carregar a mem√≥ria, evitando instru√ß√µes mais complexas.  Eles notaram que os programas s√£o executados tr√™s vezes mais r√°pido se usarem um subconjunto simples.  Emer e Clark <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">descobriram</a> que 20% das instru√ß√µes do VAX ocupam 60% do microc√≥digo e apenas 0,2% do tempo de execu√ß√£o.  Um autor deste artigo (Patterson) passou umas f√©rias criativas na DEC, ajudando a reduzir erros no microc√≥digo VAX.  Se os fabricantes de microprocessadores seguiriam os projetos ISA com um conjunto de comandos CISC complexos em computadores grandes, esperavam um grande n√∫mero de erros de microc√≥digo e queriam encontrar uma maneira de corrigi-los.  Ele escreveu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">esse artigo</a> , mas a revista <i>Computer o</i> rejeitou.  Os revisores sugeriram que a p√©ssima id√©ia de construir microprocessadores com o ISA √© t√£o complexa que eles precisam ser reparados em campo.  Essa falha colocou em d√∫vida o valor do CISC para microprocessadores.  Ironicamente, os modernos microprocessadores CISC incluem mecanismos de recupera√ß√£o de microc√≥digo, mas a recusa em publicar o artigo inspirou o autor a desenvolver um ISA menos complexo para microprocessadores - computadores com um conjunto de instru√ß√µes reduzido (RISC). <br><br>  Esses coment√°rios e a transi√ß√£o para idiomas de alto n√≠vel permitiram a transi√ß√£o do CISC para o RISC.  Primeiro, as instru√ß√µes RISC s√£o simplificadas, portanto, n√£o h√° necessidade de um int√©rprete.  As instru√ß√µes RISC s√£o geralmente simples como micro-instru√ß√µes e podem ser executadas diretamente por hardware.  Em segundo lugar, a mem√≥ria r√°pida usada anteriormente para o interpretador de microc√≥digo CISC foi redesenhada no cache de instru√ß√µes RISC (o cache √© uma mem√≥ria pequena e r√°pida que armazena em buffer as instru√ß√µes executadas recentemente, pois essas instru√ß√µes provavelmente ser√£o reutilizadas em um futuro pr√≥ximo).  Em terceiro lugar, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">alocadores de registro com base no esquema de cores do gr√°fico de Gregory Chaitin</a> facilitaram muito o uso eficiente de registradores para compiladores, que se beneficiaram dessas ISAs com opera√ß√µes de registro em registro.  Finalmente, a lei de Moore levou ao fato de que, na d√©cada de 1980, havia transistores suficientes em um chip para acomodar um barramento completo de 32 bits em um √∫nico chip, juntamente com caches para instru√ß√µes e dados. <br><br>  Por exemplo, na fig.  A Figura 1 mostra os microprocessadores <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RISC-I</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MIPS</a> desenvolvidos na Universidade da Calif√≥rnia em Berkeley e Stanford University em 1982 e 1983, que demonstraram os benef√≠cios do RISC.  Como resultado, em 1984 esses processadores foram apresentados na confer√™ncia l√≠der em design de circuitos, a Confer√™ncia Internacional de Circuitos de Estado S√≥lido da IEEE ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">2</a> ).  Foi um momento maravilhoso quando v√°rios estudantes de p√≥s-gradua√ß√£o em Berkeley e Stanford criaram microprocessadores que excederam as capacidades da ind√∫stria daquela √©poca. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/410/ca5/11d/410ca511d626e92ae1ea3179fa59bddb.jpg"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">1. Processadores RISC-I da Universidade da Calif√≥rnia em Berkeley e MIPS da Stanford University</font></i> <br><br>  Esses chips acad√™micos inspiraram muitas empresas a criar microprocessadores RISC, que foram os mais r√°pidos nos pr√≥ximos 15 anos.  A explica√ß√£o est√° relacionada √† seguinte f√≥rmula de desempenho do processador: <br><br>  <i>Tempo / Programa = (Instru√ß√µes / Programa) √ó (medidas / instru√ß√£o) √ó (tempo / medida)</i> <br><br>  Os engenheiros do DEC <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mostraram</a> mais tarde que, para um programa, CISCs mais complexos exigem 75% do n√∫mero de instru√ß√µes RISC (o primeiro termo na f√≥rmula), mas em uma tecnologia semelhante (terceiro termo), cada instru√ß√£o CISC leva de 5 a 6 ciclos a mais (segundo termo), o que torna os microprocessadores RISC cerca de 4 vezes mais r√°pidos. <br><br>  N√£o havia tais f√≥rmulas na literatura de computa√ß√£o dos anos 80, o que nos levou a escrever o livro <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Computer Architecture: A Quantitective Approach</a></i> em 1989.  A legenda explica o tema do livro: usar medidas e par√¢metros de refer√™ncia para quantificar compensa√ß√µes, em vez de confiar na intui√ß√£o e na experi√™ncia do designer, como no passado.  Nossa abordagem quantitativa tamb√©m foi inspirada no que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o livro de Donald Knuth, vencedor do pr√™mio Turing,</a> fez para algoritmos. <br><br><h3>  VLIW, EPIC, Itanium </h3><br>  O pr√≥ximo ISA inovador deveria superar o sucesso do RISC e do CISC.  A <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arquitetura</a> muito longa de instru√ß√µes de m√°quinas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">VLIW</a> e seu primo EPIC (Computing with paralelismo expl√≠cito de instru√ß√µes de m√°quinas) da Intel e da Hewlett-Packard usavam instru√ß√µes longas, cada uma das quais consistindo em v√°rias opera√ß√µes independentes ligadas entre si.  Os apoiadores do VLIW e EPIC na √©poca acreditavam que se uma instru√ß√£o pudesse indicar, digamos, seis opera√ß√µes independentes - duas transfer√™ncias de dados, duas opera√ß√µes inteiras e duas opera√ß√µes de ponto flutuante - e a tecnologia do compilador poderia atribuir opera√ß√µes com efici√™ncia a seis slots de instru√ß√µes, ent√£o o equipamento pode ser simplificado.  Semelhante √† abordagem do RISC, o VLIW e o EPIC transferiram o trabalho do hardware para o compilador. <br><br>  Juntas, a Intel e a Hewlett-Packard desenvolveram um processador baseado em EPIC de 64 bits para substituir a arquitetura de 32 bits x86.  Grandes expectativas foram depositadas no primeiro processador EPIC chamado Itanium, mas a realidade n√£o correspondeu √†s primeiras declara√ß√µes dos desenvolvedores.  Embora a abordagem EPIC tenha funcionado bem para programas de ponto flutuante altamente estruturados, n√£o foi poss√≠vel obter alto desempenho para programas inteiros com menos ramifica√ß√£o e falhas de cache previs√≠veis.  Como Donald Knuth <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">observou</a> mais tarde: "O Itanium deveria ser ... incr√≠vel - at√© que os compiladores desejados fossem basicamente imposs√≠veis de escrever".  Os cr√≠ticos notaram atrasos no lan√ßamento do Itanium e o apelidaram de Itanik em homenagem ao infeliz navio de passageiros Titanic.  O mercado novamente n√£o demonstrou paci√™ncia e adotou a vers√£o de 64 bits do x86, e n√£o o Itanium, como sucessora. <br><br>  A boa not√≠cia √© que o VLIW ainda √© adequado para aplicativos mais especializados que executam pequenos programas com ramifica√ß√µes mais simples sem falhas de cache, incluindo o processamento de sinal digital. <br><br><h1>  RISC vs. CISC na era PC e p√≥s-PC </h1><br>  A AMD e a Intel precisavam de 500 equipes de design e tecnologia superior de semicondutores para preencher a lacuna de desempenho entre x86 e RISC.  Novamente, por uma quest√£o de desempenho alcan√ßado por meio de pipelining, um decodificador de instru√ß√µes on-the-fly converte instru√ß√µes complexas x86 em microinstru√ß√µes internas do tipo RISC.  A AMD e a Intel ent√£o constroem um pipeline para sua implementa√ß√£o.  Quaisquer id√©ias que os designers do RISC usaram para melhorar o desempenho - caches separados de instru√ß√µes e dados, caches de segundo n√≠vel no chip, um pipeline profundo e o recebimento e execu√ß√£o simult√¢neos de v√°rias instru√ß√µes - foram inclu√≠dos no x86.  No auge da era dos computadores pessoais em 2011, a AMD e a Intel enviavam anualmente cerca de 350 milh√µes de microprocessadores x86.  Altos volumes e baixas margens da ind√∫stria tamb√©m significaram pre√ßos mais baixos do que os computadores RISC. <br><br>  Com centenas de milh√µes de computadores vendidos anualmente, o software se tornou um mercado enorme.  Enquanto os fornecedores de software Unix precisavam lan√ßar vers√µes diferentes de software para diferentes arquiteturas RISC - Alpha, HP-PA, MIPS, Power e SPARC - os computadores pessoais tinham um ISA, ent√£o os desenvolvedores lan√ßaram software "encolhido" que era bin√°rio compat√≠vel apenas com arquitetura x86.  Devido √† sua base de software muito maior, desempenho semelhante e pre√ßos mais baixos, at√© o ano 2000 a arquitetura x86 dominava os mercados de desktops e pequenos servidores. <br><br>  A Apple ajudou a inaugurar a era p√≥s-PC com o iPhone em 2007.  Em vez de comprar microprocessadores, as empresas de smartphones criaram seus pr√≥prios sistemas em um chip (SoC) usando o desenvolvimento de outras pessoas, incluindo processadores RISC da ARM.  Aqui, os designers s√£o importantes n√£o apenas no desempenho, mas tamb√©m no consumo de energia e na √°rea de chips, o que coloca em desvantagem a arquitetura CISC.  Al√©m disso, a Internet das Coisas aumentou significativamente o n√∫mero de processadores e as compensa√ß√µes necess√°rias em tamanho de chip, energia, custo e desempenho.  Essa tend√™ncia aumentou a import√¢ncia do tempo e do custo do projeto, piorando ainda mais a posi√ß√£o dos processadores CISC.  Na era p√≥s-PC de hoje, as remessas anuais de x86 ca√≠ram quase 10% desde o pico de 2011, enquanto os chips RISC dispararam para 20 bilh√µes.  Hoje, 99% dos processadores de 32 e 64 bits no mundo s√£o RISC. <br><br>  Concluindo esta revis√£o hist√≥rica, podemos dizer que o mercado resolveu a disputa entre RISC e CISC.  Embora o CISC tenha vencido as fases posteriores da era dos PCs, o RISC vence agora que a era p√≥s-PC chegou.  N√£o h√° novas ISAs na CISC h√° d√©cadas.  Para nossa surpresa, o consenso geral sobre os melhores princ√≠pios ISA para processadores de uso geral hoje ainda √© a favor do RISC, 35 anos ap√≥s sua inven√ß√£o. <br><br><h1>  Desafios modernos para a arquitetura do processador </h1><br>  <i>‚ÄúSe um problema n√£o tem solu√ß√£o, talvez n√£o seja um problema, mas um fato com o qual voc√™ deve aprender a viver‚Äù</i> - Shimon Peres <br><br>  Embora a se√ß√£o anterior tenha focado no desenvolvimento de uma arquitetura de conjunto de instru√ß√µes (ISA), a maioria dos designers do setor n√£o desenvolve novos ISAs, mas integra os ISAs existentes √† tecnologia de fabrica√ß√£o existente.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Desde o final dos anos 70, a tecnologia predominante tem sido circuitos integrados em estruturas MOS (MOS), primeiro tipo n (nMOS) e, em seguida, complementares (CMOS). O impressionante ritmo de melhoria na tecnologia MOS - capturado pelas previs√µes de Gordon Moore - foi a for√ßa motriz que permitiu aos designers desenvolver m√©todos mais agressivos para obter desempenho para um determinado ISA. A previs√£o inicial de Moore </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">em 1965</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> previa uma duplica√ß√£o anual da densidade do transistor; em 1975, ele a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">revisou</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , prevendo uma duplica√ß√£o a cada dois anos. No final, essa previs√£o come√ßou a ser chamada de lei de Moore. Como a densidade dos transistores cresce quadraticamente e a velocidade cresce linearmente, o uso de mais transistores pode aumentar a produtividade.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O fim da lei de Moore e da lei de escala de Dennard </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Embora a lei de Moore esteja em vigor h√° muitas d√©cadas (veja a Figura 2), por volta de 2000, ela come√ßou a desacelerar e, em 2018, a diferen√ßa entre a previs√£o de Moore e as capacidades atuais aumentou para 15 vezes. </font><font style="vertical-align: inherit;">Em 2003, Moore </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sugeriu que isso era inevit√°vel</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Atualmente, espera-se que a diferen√ßa continue a aumentar √† medida que a tecnologia CMOS se aproxima dos limites fundamentais. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/073/9b2/026/0739b20261c12234f330eff27f9c3062.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. </font><font style="vertical-align: inherit;">2. O n√∫mero de transistores em um chip Intel comparado √†</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Lei de Moore. </font><i><font color="gray"><font style="vertical-align: inherit;">A</font></font></i><font style="vertical-align: inherit;"> Lei de Moore foi acompanhada por uma proje√ß√£o feita por Robert Dennard chamada </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Dennard Scaling"</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">que √† medida que a densidade dos transistores aumenta, o consumo de energia do transistor diminui, portanto o consumo por mm¬≤ de sil√≠cio ser√° quase constante. √Ä medida que o poder computacional de um mil√≠metro de sil√≠cio crescia a cada nova gera√ß√£o de tecnologia, os computadores se tornavam mais eficientes em termos energ√©ticos. A escala de Dennard come√ßou a desacelerar significativamente em 2007 e, em 2012, praticamente n√£o havia chegado a nada (veja a Figura 3). </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/e40/d10/c1d/e40d10c1d7a21c64618f4bd246411e11.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. 3. N√∫mero de transistores por chip e consumo de energia por mm¬≤</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De 1986 a 2002, a concorr√™ncia em n√≠vel de instru√ß√£o (ILP) foi o principal m√©todo de arquitetura para aumentar a produtividade. Juntamente com o aumento da velocidade dos transistores, isso proporcionou um aumento anual de produtividade de cerca de 50%. O fim do dimensionamento de Dennard significava que os arquitetos tinham que encontrar melhores maneiras de usar a simultaneidade.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para entender por que um aumento na ILP reduziu a efici√™ncia, considere o n√∫cleo dos modernos processadores ARM, Intel e AMD. Suponha que ele tenha um pipeline de 15 est√°gios e quatro instru√ß√µes por rel√≥gio. Assim, a qualquer momento no transportador existem at√© 60 instru√ß√µes, incluindo cerca de 15 ramais, uma vez que elas representam cerca de 25% das instru√ß√µes executadas. Para preencher o pipeline, as ramifica√ß√µes s√£o previstas e o c√≥digo √© colocado especulativamente no pipeline para execu√ß√£o. A previs√£o especulativa √© a fonte do desempenho e da inefici√™ncia do ILP. Quando a previs√£o de ramifica√ß√£o √© ideal, a especula√ß√£o melhora o desempenho e apenas aumenta levemente o consumo de energia - e pode at√© economizar energia - mas quando as ramifica√ß√µes n√£o s√£o previstas corretamente, o processador deve jogar fora os c√°lculos errados.e todo o trabalho e energia desperdi√ßados. O estado interno do processador tamb√©m precisar√° ser restaurado para o estado que existia antes da ramifica√ß√£o incompreendida, com a despesa de tempo e energia adicionais.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para entender como esse projeto √© complexo, imagine a dificuldade de prever corretamente os resultados de 15 ramos. Se o construtor do processador definir um limite de 10% de perdas, o processador dever√° prever corretamente cada ramo com uma precis√£o de 99,3%. N√£o h√° muitos programas de ramifica√ß√£o de uso geral que possam ser previstos com tanta precis√£o.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para avaliar em que consiste esse trabalho desperdi√ßado, considere os dados na Fig. 4, mostrando a propor√ß√£o de instru√ß√µes que s√£o executadas com efici√™ncia, mas s√£o desperdi√ßadas porque o processador previu incorretamente ramifica√ß√µes. Nos testes SPEC no Intel Core i7, uma m√©dia de 19% das instru√ß√µes s√£o desperdi√ßadas. No entanto, a quantidade de energia gasta √© maior, uma vez que o processador deve usar energia adicional para restaurar o estado quando √© previsto incorretamente. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/9a2/ce3/f54/9a2ce3f54d26359ce98e036eac216a5d.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. 4. Instru√ß√µes desperdi√ßadas como uma porcentagem de todas as instru√ß√µes executadas no Intel Core i7 para v√°rios testes SPEC inteiros.Essas</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> medi√ß√µes levaram muitos a concluir que uma abordagem diferente deve ser buscada para obter melhor desempenho. Assim nasceu a era multicore.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nesse conceito, a responsabilidade de identificar a simultaneidade e decidir como us√°-la √© transferida para o programador e o sistema de linguagem. O Multicore n√£o resolve o problema da computa√ß√£o com efici√™ncia energ√©tica, que foi agravada no final do dimensionamento de Dennard. Cada n√∫cleo ativo consome energia, independentemente de estar envolvido em c√°lculos eficientes. O principal obst√°culo √© uma observa√ß√£o antiga chamada lei de Amdahl. Ele diz que os benef√≠cios da computa√ß√£o paralela s√£o limitados pela fra√ß√£o da computa√ß√£o seq√ºencial. Para avaliar a import√¢ncia dessa observa√ß√£o, considere a Figura 5. Ele mostra quanto mais r√°pido o aplicativo trabalha com 64 n√∫cleos em compara√ß√£o com um n√∫cleo, assumindo uma propor√ß√£o diferente de c√°lculos seq√ºenciais quando apenas um processador est√° ativo. Por exemplose 1% do tempo o c√°lculo √© realizado seq√ºencialmente, a vantagem da configura√ß√£o de 64 processadores √© de apenas 35%. Infelizmente, o consumo de energia √© proporcional a 64 processadores, portanto, aproximadamente 45% da energia √© desperdi√ßada.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a8e/d85/9c6/a8ed859c61efb49a292ca4f5ac3cb5f4.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. 5. O efeito da lei de Amdahl no aumento da velocidade, levando em considera√ß√£o a propor√ß√£o de medidas no modo seq√ºencial.</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √â claro que os programas reais t√™m uma estrutura mais complexa. Existem fragmentos que permitem usar um n√∫mero diferente de processadores a qualquer momento. No entanto, a necessidade de interagir periodicamente e sincroniz√°-los significa que a maioria dos aplicativos possui algumas partes que podem usar apenas parte dos processadores com efici√™ncia. Embora a lei de Amdahl tenha mais de 50 anos, ela continua sendo um obst√°culo dif√≠cil.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Com o final da escala de Dennard, um aumento no n√∫mero de n√∫cleos no chip significava que a pot√™ncia tamb√©m aumentava quase na mesma taxa. Infelizmente, a voltagem fornecida ao processador deve ser removida como calor. Assim, os processadores com v√°rios n√∫cleos s√£o limitados pela TDP (Thermal Output Power) ou pela quantidade m√©dia de energia que o chassi e o sistema de refrigera√ß√£o podem remover. Embora alguns data centers sofisticados usem tecnologias de refrigera√ß√£o mais avan√ßadas, nenhum usu√°rio deseja colocar um pequeno trocador de calor em cima da mesa ou carregar um radiador nas costas para resfriar o telefone m√≥vel. O limite do TDP levou √† era do sil√≠cio escuro, quando os processadores diminuem a velocidade do rel√≥gio e desligam os n√∫cleos ociosos para evitar superaquecimento. Outra maneira de considerar essa abordagem √©que alguns microcircuitos podem redistribuir seu poder precioso de n√∫cleos inativos para n√∫cleos ativos.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A era sem a escala de Dennard, juntamente com a redu√ß√£o da lei de Moore e da lei de Amdahl, significa que a inefici√™ncia limita a melhoria da produtividade a apenas alguns por cento ao ano (veja a Figura 6). </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/f0a/f8f/cd0/f0af8fcd06385641a5cc1266fda37a0f.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. </font><font style="vertical-align: inherit;">6. Crescimento do desempenho do computador por testes inteiros (SPECintCPU)</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Atingir taxas mais altas de melhoria de desempenho - como foi observado nas d√©cadas de 80 e 90 - requer novas abordagens arquitet√¥nicas que tiram vantagem dos circuitos integrados com muito mais efici√™ncia. </font><font style="vertical-align: inherit;">Voltaremos √† discuss√£o de abordagens potencialmente eficazes, mencionando outra s√©ria desvantagem dos computadores modernos - a seguran√ßa.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Seguran√ßa esquecida </font></font></h1><br>  Nos anos 70, os desenvolvedores de processadores garantiram diligentemente a seguran√ßa do computador com a ajuda de v√°rios conceitos, desde an√©is de prote√ß√£o at√© fun√ß√µes especiais.  Eles entendiam bem que a maioria dos erros estaria no software, mas acreditavam que o suporte √† arquitetura poderia ajudar.  Esses recursos geralmente n√£o eram usados ‚Äã‚Äãpor sistemas operacionais que funcionavam em ambientes supostamente seguros (como computadores pessoais).  Portanto, as fun√ß√µes associadas a despesas gerais significativas foram eliminadas.  Na comunidade de software, muitos acreditavam que testes e m√©todos formais, como o uso de um microkernel, forneceriam mecanismos eficazes para a cria√ß√£o de software altamente seguro.  Infelizmente, a escala de nossos sistemas de software comuns e a busca pelo desempenho fizeram com que esses m√©todos n√£o pudessem acompanhar o desempenho.  Como resultado, grandes sistemas de software ainda apresentam muitas falhas de seguran√ßa, e o efeito √© amplificado devido √† enorme e crescente quantidade de informa√ß√µes pessoais na Internet e ao uso da computa√ß√£o em nuvem, onde os usu√°rios compartilham o mesmo equipamento f√≠sico com um poss√≠vel invasor. <br><br>  Embora os designers de processadores e outros possam n√£o ter percebido a crescente import√¢ncia da seguran√ßa imediatamente, eles come√ßaram a incluir suporte de hardware para m√°quinas virtuais e criptografia.  Infelizmente, a previs√£o de ramifica√ß√£o introduziu uma falha de seguran√ßa desconhecida, mas significativa, em muitos processadores.  Em particular, as <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">vulnerabilidades Meltdown e Spectre exploram os recursos da microarquitetura, permitindo o vazamento de informa√ß√µes protegidas</a> .  Ambos usam os chamados ataques a canais de terceiros quando as informa√ß√µes vazam de acordo com a diferen√ßa de tempo gasto na tarefa.  Em 2018, os pesquisadores mostraram <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">como usar uma das op√ß√µes do Spectre para extrair informa√ß√µes pela rede sem baixar o c√≥digo no processador de destino</a> .  Embora esse ataque, chamado NetSpectre, transfira informa√ß√µes lentamente, o pr√≥prio fato de permitir atacar qualquer m√°quina na mesma rede local (ou no mesmo cluster na nuvem) cria muitos novos vetores de ataque.  Posteriormente, foram relatadas mais duas vulnerabilidades na arquitetura de m√°quinas virtuais ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">2</a> ).  Um deles, chamado Foreshadow, permite que voc√™ penetre nos mecanismos de seguran√ßa Intel SGX projetados para proteger os dados mais valiosos (como chaves de criptografia).  Novas vulnerabilidades s√£o encontradas mensalmente. <br><br>  Ataques em canais de terceiros n√£o s√£o novos, mas na maioria dos casos, os bugs de software eram a falha anterior.  No Meltdown, Spectre e outros ataques, essa √© uma falha na implementa√ß√£o do hardware.  H√° uma dificuldade fundamental em como os arquitetos de processadores determinam qual √© a implementa√ß√£o correta do ISA, porque a defini√ß√£o padr√£o n√£o diz nada sobre os efeitos de desempenho da execu√ß√£o de uma sequ√™ncia de instru√ß√µes, apenas o estado de execu√ß√£o arquitetural vis√≠vel do ISA.  Os arquitetos devem repensar sua defini√ß√£o da implementa√ß√£o correta do ISA para evitar essas falhas de seguran√ßa.  Ao mesmo tempo, eles devem repensar a aten√ß√£o que prestam √† seguran√ßa do computador e como os arquitetos podem trabalhar com desenvolvedores de software para implementar sistemas mais seguros.  Arquitetos (e todos os outros) n√£o devem ter seguran√ßa de outra maneira que n√£o seja uma necessidade prim√°ria. <br><br><h1>  Oportunidades futuras em arquitetura de computadores </h1><br>  <i>‚ÄúTemos oportunidades incr√≠veis, disfar√ßadas de problemas insol√∫veis.‚Äù</i> - John Gardner, 1965 <br><br>  As inefici√™ncias inerentes aos processadores de uso geral, seja a tecnologia ILP ou os processadores com m√∫ltiplos n√∫cleos, combinadas com a conclus√£o do dimensionamento de Dennard e a lei de Moore tornam improv√°vel que arquitetos e desenvolvedores de processadores sejam capazes de manter um ritmo significativo na melhoria do desempenho dos processadores de uso geral.  Dada a import√¢ncia de melhorar a produtividade do software, devemos fazer a pergunta: que outras abordagens promissoras existem? <br><br>  Existem duas possibilidades √≥bvias, bem como uma terceira criada pela combina√ß√£o das duas.  Primeiro, os m√©todos de desenvolvimento de software existentes fazem uso extensivo de linguagens de alto n√≠vel com digita√ß√£o din√¢mica.  Infelizmente, essas linguagens s√£o geralmente interpretadas e executadas de maneira extremamente ineficiente.  Para ilustrar essa inefici√™ncia, Leiserson e colegas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">deram um pequeno exemplo: multiplica√ß√£o de matrizes</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/31e/c75/ebe/31ec75ebe5c3134c14020655b89e8ac1.jpg"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">7. Acelera√ß√£o potencial da multiplica√ß√£o de matrizes Python ap√≥s quatro otimiza√ß√µes</font></i> <br><br>  Como mostrado na fig.  7, simplesmente reescrever o c√≥digo do Python para C melhora o desempenho em 47 vezes.  O uso de loops paralelos em muitos n√∫cleos fornece um fator adicional de cerca de 7. A otimiza√ß√£o da estrutura de mem√≥ria para o uso de caches fornece um fator de 20 e o √∫ltimo fator de 9 vem do uso de extens√µes de hardware para executar opera√ß√µes SIMD paralelas capazes de executar 16 instru√ß√µes de 32 bits.  Depois disso, a vers√£o final, altamente otimizada, roda no processador multi-core da Intel 62.806 vezes mais r√°pido que a vers√£o original do Python.  Obviamente, este √© um pequeno exemplo.  Pode-se supor que os programadores usar√£o uma biblioteca otimizada.  Embora a diferen√ßa de desempenho seja exagerada, provavelmente existem muitos programas que podem ser otimizados 100-1000 vezes. <br><br>  Uma √°rea interessante de pesquisa √© a quest√£o de saber se √© poss√≠vel preencher algumas lacunas de desempenho com a nova tecnologia de compilador, possivelmente com melhorias na arquitetura.  Embora seja dif√≠cil traduzir e compilar com efici√™ncia as linguagens de script de alto n√≠vel, como o Python, o retorno potencial √© enorme.  Mesmo uma pequena otimiza√ß√£o pode levar ao fato de que os programas Python ser√£o executados dezenas a centenas de vezes mais r√°pido.  Este exemplo simples mostra qu√£o grande √© a diferen√ßa entre as linguagens modernas focadas no desempenho do programador e as abordagens tradicionais que enfatizam o desempenho. <br><br><h3>  Arquiteturas especializadas </h3><br>  Uma abordagem mais orientada a hardware √© o design de arquiteturas adaptadas a uma √°rea espec√≠fica, onde elas demonstram efici√™ncia significativa.  Essas s√£o arquiteturas espec√≠ficas de dom√≠nio especializadas (arquiteturas espec√≠ficas de dom√≠nio, DSAs).  Geralmente, s√£o processadores program√°veis ‚Äã‚Äãe completos, mas levam em considera√ß√£o uma classe espec√≠fica de tarefas.  Nesse sentido, eles diferem dos circuitos integrados espec√≠ficos da aplica√ß√£o (ASICs), que geralmente s√£o usados ‚Äã‚Äãpara a mesma fun√ß√£o que o c√≥digo que raramente muda.  Os DSAs s√£o freq√ºentemente chamados de aceleradores, pois aceleram alguns aplicativos em compara√ß√£o com a execu√ß√£o de todo o aplicativo em uma CPU de uso geral.  Al√©m disso, os DSAs podem oferecer melhor desempenho porque s√£o mais precisamente adaptados √†s necessidades do aplicativo.  Exemplos de DSAs incluem processadores gr√°ficos (GPUs), processadores de rede neural usados ‚Äã‚Äãpara aprendizado profundo e processadores para redes definidas por software (SDNs).  Os DSAs alcan√ßam desempenho superior e efici√™ncia energ√©tica por quatro raz√µes principais. <br><br>  Primeiro, os DSAs usam uma forma mais eficiente de simultaneidade para uma √°rea de assunto espec√≠fica.  Por exemplo, o SIMD (fluxo √∫nico de instru√ß√µes, fluxo m√∫ltiplo de dados) √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mais eficiente que o MIMD</a> (fluxo m√∫ltiplo de instru√ß√µes, fluxo m√∫ltiplo de dados).  Embora o SIMD seja menos flex√≠vel, √© adequado para muitos DSAs.  Processadores especializados tamb√©m podem usar as abordagens ILP da VLIW em vez de mecanismos pouco especulativos.  Como mencionado anteriormente, os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">processadores VLIW s√£o pouco adequados para c√≥digos de uso geral</a> , mas para √°reas estreitas s√£o muito mais eficientes porque os mecanismos de controle s√£o mais simples.  Em particular, os processadores de uso geral de ponta s√£o excessivamente multi-pipelines, o que requer l√≥gica de controle complexa para iniciar e concluir as instru√ß√µes.  Por outro lado, o VLIW realiza a an√°lise e o planejamento necess√°rios em tempo de compila√ß√£o, o que pode funcionar bem para um programa claramente paralelo. <br><br>  Segundo, os servi√ßos DSA fazem melhor uso da hierarquia de mem√≥ria.  O acesso √† mem√≥ria se tornou muito mais caro que os c√°lculos aritm√©ticos, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">como observou Horowitz</a> .  Por exemplo, acessar um bloco em um cache de 32 KB requer cerca de 200 vezes mais energia do que adicionar n√∫meros inteiros de 32 bits.  Uma diferen√ßa t√£o grande faz com que otimizar o acesso √† mem√≥ria seja fundamental para alcan√ßar alta efici√™ncia energ√©tica.  Os processadores de uso geral executam c√≥digo no qual os acessos √† mem√≥ria geralmente exibem localidade espacial e temporal, mas, de outra forma, n√£o s√£o muito previs√≠veis em tempo de compila√ß√£o.  Portanto, para aumentar a taxa de transfer√™ncia, as CPUs usam caches de v√°rios n√≠veis e ocultam o atraso em DRAMs relativamente lentas fora do chip.  Esses caches de v√°rios n√≠veis geralmente consomem cerca de metade da energia do processador, mas evitam quase todas as chamadas para DRAM, o que leva cerca de 10 vezes mais energia do que o acesso ao cache de √∫ltimo n√≠vel. <br><br>  Os caches t√™m duas falhas not√°veis. <br><br>  <i>Quando os conjuntos de dados s√£o muito grandes</i> .  Os caches simplesmente n√£o funcionam bem quando os conjuntos de dados s√£o muito grandes, possuem baixa localidade temporal ou espacial. <br><br>  <i>Quando caches funcionam bem</i> .  Quando os caches funcionam bem, a localidade √© muito alta, ou seja, por defini√ß√£o, a maior parte do cache fica ociosa na maioria das vezes. <br><br>  Em aplicativos em que os padr√µes de acesso √† mem√≥ria s√£o bem definidos e compreens√≠veis no momento da compila√ß√£o, o que √© verdade para DSLs (t√≠picas de dom√≠nio espec√≠fico), programadores e compiladores podem otimizar o uso da mem√≥ria melhor do que os caches alocados dinamicamente.  Portanto, os DSAs normalmente usam uma hierarquia de mem√≥ria m√≥vel explicitamente controlada pelo software, semelhante √† maneira como os processadores de vetores funcionam.  Nos aplicativos correspondentes, o controle ‚Äúmanual‚Äù da mem√≥ria do usu√°rio permite gastar muito menos energia que o cache padr√£o. <br><br>  Em terceiro lugar, o DSA pode reduzir a precis√£o dos c√°lculos se n√£o for necess√°ria alta precis√£o.  As CPUs de uso geral geralmente suportam c√°lculos de n√∫meros inteiros de 32 e 64 bits, bem como dados de ponto flutuante (FP).  Para muitos aplicativos de aprendizado de m√°quina e gr√°ficos, essa √© uma precis√£o redundante.  Por exemplo, em redes neurais profundas, o c√°lculo geralmente usa n√∫meros de 4, 8 ou 16 bits, melhorando a taxa de transfer√™ncia de dados e o poder de processamento.  Da mesma forma, os c√°lculos de ponto flutuante s√£o √∫teis para o treinamento de redes neurais, mas 32 bits, e geralmente 16 bits, s√£o suficientes. <br><br>  Por fim, os DSAs se beneficiam de programas escritos em linguagens espec√≠ficas de dom√≠nio que permitem mais simultaneidade, melhoram a estrutura, a apresenta√ß√£o do acesso √† mem√≥ria e simplificam a sobreposi√ß√£o eficiente de aplicativos em um processador especializado. <br><br><h1>  Idiomas orientados ao assunto </h1><br>  Os DSAs exigem que opera√ß√µes de n√≠vel superior sejam adaptadas √† arquitetura do processador, mas √© muito dif√≠cil fazer isso em uma linguagem de uso geral, como Python, Java, C ou Fortran.  Os idiomas espec√≠ficos do dom√≠nio (DSLs) ajudam nisso e permitem que voc√™ programe efetivamente os DSAs.  Por exemplo, as DSLs podem tornar expl√≠citas as opera√ß√µes de vetores expl√≠citos, matriz densa e matriz esparsa, permitindo que o compilador DSL mapeie de maneira eficiente as opera√ß√µes para o processador.  Entre as linguagens espec√≠ficas do dom√≠nio est√£o o Matlab, uma linguagem para trabalhar com matrizes, o TensorFlow para programar redes neurais, P4 para programar redes definidas por software e Halide para processar imagens com transforma√ß√µes de alto n√≠vel. <br><br>  O problema do DSL √© como manter independ√™ncia arquitetural suficiente para que o software nele possa ser portado para v√°rias arquiteturas, enquanto obt√©m alta efici√™ncia ao comparar o software com um DSA b√°sico.  Por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um sistema XLA converte o</a> c√≥digo do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tensorflow</a> em sistemas heterog√™neos com GPUs da Nvidia ou processadores de tens√£o (TPUs).  Equilibrar a portabilidade entre DSAs enquanto mant√©m a efici√™ncia √© uma tarefa de pesquisa interessante para desenvolvedores de linguagem, compiladores e os pr√≥prios DSAs. <br><br><h3>  Exemplo de DSA: TPU v1 </h3><br>  Como exemplo do DSA, considere o Google TPU v1, projetado para acelerar a opera√ß√£o de uma rede neural ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">2</a> ).  Esse TPU √© produzido desde 2015 e muitos aplicativos est√£o sendo executados nele: de consultas de pesquisa a tradu√ß√£o de texto e reconhecimento de imagem no AlphaGo e AlphaZero, programas DeepMind para jogar go e xadrez.  O objetivo era aumentar a produtividade e a efici√™ncia energ√©tica de redes neurais profundas em 10 vezes. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/057/3d6/a1a/0573d6a1a8ed756450ae9088f8606897.jpg"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">8. Unidade funcional de processamento do tensor do Google da organiza√ß√£o (TPU v1)</font></i> <br><br>  Como mostra a Figura 8, a organiza√ß√£o de uma TPU √© radicalmente diferente de um processador de uso geral.  A principal unidade de computa√ß√£o √© a unidade da matriz, a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">estrutura das matrizes sist√≥licas</a> , que cada ciclo produz 256 √ó 256 com acumula√ß√£o m√∫ltipla.  A combina√ß√£o de precis√£o de 8 bits, uma estrutura sist√≥lica altamente eficiente, controle SIMD e a aloca√ß√£o de uma parte significativa do chip para esta fun√ß√£o ajudam a executar cerca de 100 vezes mais opera√ß√µes de multiplica√ß√£o de acumula√ß√£o por ciclo do que um n√∫cleo de CPU de uso geral.  Em vez de caches, o TPU usa 24 MB de mem√≥ria local, que √© aproximadamente o dobro dos caches de CPU de uso geral de 2015 com o mesmo TDP.  Finalmente, a mem√≥ria de ativa√ß√£o neuronal e a mem√≥ria de equil√≠brio de rede neural (incluindo a estrutura FIFO que armazena os pesos) s√£o conectadas atrav√©s de canais de alta velocidade controlados pelo usu√°rio.  O desempenho m√©dio ponderado da TPU para seis problemas t√≠picos da sa√≠da l√≥gica de redes neurais nos datacenters do Google √© 29 vezes maior que o dos processadores de uso geral.  Como as TPUs requerem menos da metade da energia, sua efici√™ncia energ√©tica para essa carga de trabalho √© mais de 80 vezes a dos processadores de uso geral. <br><br><h1>  Sum√°rio </h1><br>  Examinamos duas abordagens diferentes para melhorar o desempenho do programa, aumentando a efici√™ncia do uso de tecnologias de hardware.  Primeiro, aumentando a produtividade das linguagens modernas de alto n√≠vel que geralmente s√£o interpretadas.  Em segundo lugar, criando arquiteturas para √°reas espec√≠ficas, que melhoram significativamente o desempenho e a efici√™ncia em compara√ß√£o com os processadores de uso geral.  Os idiomas espec√≠ficos do dom√≠nio s√£o outro exemplo de como melhorar a interface de hardware e software que permite inova√ß√µes arquiteturais como o DSA.  Para obter um sucesso significativo usando essas abordagens, ser√° necess√°ria uma equipe de projeto verticalmente versada em aplicativos, linguagens orientadas ao assunto e tecnologias de compila√ß√£o relacionadas, arquitetura de computadores e tecnologia b√°sica de implementa√ß√£o.  A necessidade de integra√ß√£o vertical e tomada de decis√µes de design em diferentes n√≠veis de abstra√ß√£o era t√≠pica na maior parte dos trabalhos iniciais no campo da tecnologia da computa√ß√£o antes que o setor se tornasse estruturado horizontalmente.  Nesta nova era, a integra√ß√£o vertical tornou-se mais importante.  Ser√£o dadas vantagens √†s equipes que encontrarem e aceitarem compromissos e otimiza√ß√µes complexos. <br><br>  Essa oportunidade j√° levou a um aumento na inova√ß√£o arquitet√¥nica, atraindo muitas filosofias arquitet√¥nicas concorrentes: <br><br>  <i>GPU</i>  As GPUs da Nvidia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">usam</a> v√°rios n√∫cleos, cada um com grandes arquivos de registro, v√°rios fluxos de hardware e caches. <br><br>  <i>TPU</i>  As <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TPUs do</a> Google <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">contam</a> com grandes matrizes sist√≥licas bidimensionais e mem√≥ria program√°vel no chip. <br><br>  <i>FPGA</i>  A Microsoft Corporation em seus datacenters <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">implementa</a> matrizes de portas program√°veis ‚Äã‚Äãpelo usu√°rio (FPGAs), usadas em aplicativos de rede neural. <br><br>  <i>CPU</i>  A Intel oferece processadores com muitos n√∫cleos, um grande cache multin√≠vel e instru√ß√µes SIMD unidimensionais, de maneira semelhante ao FPGA da Microsoft, e o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">novo neuroprocessador est√° mais pr√≥ximo do TPU do que da CPU</a> . <br><br>  Al√©m desses grandes players, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dezenas de startups implementam suas pr√≥prias id√©ias</a> .  Para atender √† crescente demanda, os designers est√£o combinando centenas e milhares de chips para criar supercomputadores de redes neurais. <br><br>  Essa avalanche de arquiteturas de redes neurais indica que chegou um momento interessante na hist√≥ria da arquitetura de computadores.  Em 2019, √© dif√≠cil prever quais dessas muitas √°reas vencer√£o (se algu√©m vencer), mas o mercado definitivamente determinar√° o resultado, assim como resolveu o debate arquitet√¥nico do passado. <br><br><h1>  Arquitetura aberta </h1><br>  Seguindo o exemplo de software de c√≥digo aberto bem-sucedido, o ISA aberto representa uma oportunidade alternativa na arquitetura de computadores.  Eles s√£o necess√°rios para criar um tipo de "Linux para processadores", para que a comunidade possa criar kernels de c√≥digo aberto, al√©m de empresas individuais que possuem kernels propriet√°rios.  Se muitas organiza√ß√µes projetam processadores usando o mesmo ISA, mais concorr√™ncia pode levar a inova√ß√µes ainda mais r√°pidas.  O objetivo √© fornecer arquitetura para processadores que custam de alguns centavos a US $ 100. <br><br>  O primeiro exemplo √© o RISC-V (RISC Five), a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">quinta arquitetura do RISC desenvolvida na Universidade da Calif√≥rnia em Berkeley</a> .  Ela √© apoiada por uma comunidade liderada pela <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Funda√ß√£o RISC-V</a> .<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A arquitetura aberta permite que a evolu√ß√£o do ISA ocorra aos olhos do p√∫blico, com o envolvimento de especialistas at√© que uma decis√£o final seja tomada. Uma vantagem adicional de um fundo aberto √© que √© improv√°vel que o ISA se expanda principalmente por raz√µes de marketing, porque √†s vezes essa √© a √∫nica explica√ß√£o para a expans√£o de seus pr√≥prios conjuntos de instru√ß√µes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O RISC-V √© um conjunto de instru√ß√µes modular. Uma pequena base de instru√ß√µes lan√ßa uma pilha completa de software de c√≥digo aberto, seguida por extens√µes padr√£o adicionais que os designers podem ativar ou desativar, dependendo de suas necessidades. Esse banco de dados cont√©m vers√µes de 32 e 64 bits dos endere√ßos. O RISC-V pode crescer apenas atrav√©s de extens√µes opcionais; a pilha de software ainda funcionar√° bem, mesmo que os arquitetos n√£o aceitem novas extens√µes. As arquiteturas propriet√°rias geralmente requerem compatibilidade ascendente no n√≠vel bin√°rio: isso significa que se a empresa do processador adicionar um novo recurso, todos os futuros processadores tamb√©m dever√£o inclu√≠-lo. O RISC-V n√£o, aqui todos os aprimoramentos s√£o opcionais e podem ser removidos se o aplicativo n√£o precisar deles.Aqui est√£o as extens√µes padr√£o no momento, com as primeiras letras do nome completo:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> M. Multiplica√ß√£o / divis√£o de um n√∫mero inteiro. </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> A. Opera√ß√µes de mem√≥ria at√¥mica. </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">F / d. </font><font style="vertical-align: inherit;">Opera√ß√µes de ponto flutuante de precis√£o simples / dupla.</font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> C. Instru√ß√µes compactadas. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A terceira caracter√≠stica do RISC-V √© a simplicidade do ISA. </font><font style="vertical-align: inherit;">Embora esse indicador n√£o seja quantific√°vel, aqui est√£o duas compara√ß√µes com a arquitetura do ARMv8, desenvolvida em paralelo pelo ARM:</font></font><br><br><ul><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Menos instru√ß√µes</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">O RISC-V tem muito menos instru√ß√µes. </font><font style="vertical-align: inherit;">Existem 50 no banco de dados e s√£o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">surpreendentemente semelhantes em n√∫mero e car√°ter ao RISC-I original</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">O restante das extens√µes padr√£o (M, A, F e D) adicionam 53 instru√ß√µes, e C adiciona 34 mais, portanto o n√∫mero total √© 137. Para compara√ß√£o, o ARMv8 possui mais de 500 instru√ß√µes.</font></font><br></li><li> <b>  </b> .  RISC-V    : ,    ARMv8    14. </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A simplicidade simplifica o design do processador e a verifica√ß√£o da corre√ß√£o. Como o RISC-V se concentra em tudo, desde datacenters a dispositivos IoT, a valida√ß√£o do projeto pode ser uma parte significativa dos custos de desenvolvimento. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quarto, o RISC-V √© um projeto simples ap√≥s 25 anos, onde os arquitetos aprendem com os erros de seus antecessores. Diferentemente da arquitetura RISC de primeira gera√ß√£o, evita microarquitetura ou fun√ß√µes que dependem de tecnologia (como ramifica√ß√µes e downloads adiados) ou inova√ß√µes (como janelas de registro), que foram suplantadas pelos avan√ßos do compilador. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por fim, o RISC-V suporta DSA, reservando um amplo espa√ßo de c√≥digo de opera√ß√£o para aceleradores personalizados. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Al√©m do RISC-V, a Nvidia tamb√©m anunciou (em 2017)</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Uma arquitetura livre e aberta</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , ela chama de Nvidia Deep Learning Accelerator (NVDLA). √â um DSA escal√°vel e personaliz√°vel para infer√™ncia no aprendizado de m√°quina. Os par√¢metros de configura√ß√£o incluem o tipo de dados (int8, int16 ou fp16) e o tamanho da matriz de multiplica√ß√£o bidimensional. A escala do substrato de sil√≠cio varia de 0,5 mm¬≤ a 3 mm¬≤ e o consumo de energia √© de 20 mW a 300 mW. ISA, pilha de software e implementa√ß√£o est√£o abertos.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Arquiteturas abertas e simples combinam bem com seguran√ßa. Primeiro, os especialistas em seguran√ßa n√£o acreditam em seguran√ßa pela obscuridade, portanto as implementa√ß√µes de c√≥digo aberto s√£o atraentes e as implementa√ß√µes de c√≥digo aberto exigem uma arquitetura aberta. Igualmente importante √© o aumento no n√∫mero de pessoas e organiza√ß√µes que podem inovar no campo das arquiteturas seguras. As arquiteturas propriet√°rias limitam a participa√ß√£o dos funcion√°rios, mas as arquiteturas abertas permitem que as melhores mentes da academia e da ind√∫stria ajudem na seguran√ßa. Por fim, a simplicidade do RISC-V simplifica a verifica√ß√£o de suas implementa√ß√µes. Al√©m disso, arquiteturas abertas, implementa√ß√µes e pilhas de software, al√©m da flexibilidade dos FPGAs, significam que os arquitetos podem implantar e avaliar novas solu√ß√µes on-line com ciclos de lan√ßamento semanais e n√£o anuais. Embora os FPGAs sejam 10 vezes mais lentos que os chips personalizados,mas o desempenho deles √© suficiente para trabalhar on-line e exibir inova√ß√µes de seguran√ßa na frente de invasores reais para verifica√ß√£o. Esperamos que as arquiteturas abertas sejam exemplos de design colaborativo de hardware e software por arquitetos e especialistas em seguran√ßa.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Desenvolvimento de hardware flex√≠vel </font></font></h1><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O Manifesto Flex√≠vel de Desenvolvimento de Software (2001)</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Beck e outros revolucionaram o desenvolvimento de software, eliminando os problemas de um sistema em cascata tradicional com base no planejamento e documenta√ß√£o. </font><font style="vertical-align: inherit;">Pequenas equipes de programadores criam rapidamente prot√≥tipos funcionais, mas incompletos, e recebem feedback do cliente antes de iniciar a pr√≥xima itera√ß√£o. </font><font style="vertical-align: inherit;">A vers√£o Scrum do Agile re√∫ne equipes de cinco a dez programadores que correm por duas a quatro semanas por itera√ß√£o.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tendo emprestado a id√©ia do desenvolvimento de software novamente, √© poss√≠vel organizar o desenvolvimento de hardware flex√≠vel. </font><font style="vertical-align: inherit;">A boa not√≠cia √© que as ferramentas modernas de desenho eletr√¥nico auxiliado por computador (ECAD) aumentaram o n√≠vel de abstra√ß√£o, permitindo um desenvolvimento flex√≠vel. </font><font style="vertical-align: inherit;">Esse n√≠vel mais alto de abstra√ß√£o tamb√©m aumenta o n√≠vel de reutiliza√ß√£o do trabalho entre diferentes designs. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sprints de quatro semanas parecem implaus√≠veis para os processadores, considerando os meses entre a cria√ß√£o do projeto e a produ√ß√£o de chips.</font></font> Na fig.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A Figura 9 mostra como um m√©todo flex√≠vel pode funcionar </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">modificando um prot√≥tipo em um n√≠vel apropriado</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/278/4ae/e4c/2784aee4c39cbdfaeab3bbbfd500a056.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. </font><font style="vertical-align: inherit;">9. Metodologia de desenvolvimento de equipamentos flex√≠veis</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O n√≠vel mais interno √© um simulador de software, o local mais f√°cil e r√°pido para fazer altera√ß√µes. O pr√≥ximo n√≠vel s√£o os chips FPGA, que podem funcionar centenas de vezes mais r√°pido que um simulador de software detalhado. Os FPGAs podem trabalhar com sistemas operacionais e benchmarks completos, como a Standard Performance Evaluation Corporation (SPEC), que permite uma avalia√ß√£o muito mais precisa dos prot√≥tipos. O Amazon Web Services oferece FPGAs na nuvem, para que os arquitetos possam usar os FPGAs sem precisar primeiro comprar equipamentos e montar um laborat√≥rio. O pr√≥ximo n√≠vel usa as ferramentas do ECAD para gerar um circuito de chip e documentar o tamanho e o consumo de energia. Mesmo ap√≥s o trabalho das ferramentas, √© necess√°rio seguir algumas etapas manuais para refinar os resultados antes de enviar o novo processador para produ√ß√£o.Os desenvolvedores de processadores chamam esse pr√≥ximo n√≠vel.</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">fita adesiva</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Esses quatro primeiros n√≠veis suportam sprints de quatro semanas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para fins de pesquisa, poder√≠amos parar no n√≠vel quatro, pois as estimativas de √°rea, energia e desempenho s√£o muito precisas. Mas √© como um corredor que correu uma maratona e parou 5 metros antes da finaliza√ß√£o, porque seu tempo de finaliza√ß√£o j√° est√° claro. Apesar da dif√≠cil prepara√ß√£o para a maratona, ele sentir√° falta da emo√ß√£o e do prazer de realmente cruzar a linha de chegada. Uma das vantagens dos engenheiros de hardware sobre os engenheiros de software √© que eles criam coisas f√≠sicas. Obter chips da f√°brica: medir, executar programas reais, mostr√°-los a amigos e familiares √© uma grande alegria para o designer.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Muitos pesquisadores acreditam que deveriam parar porque a fabrica√ß√£o de chips √© muito acess√≠vel. </font><font style="vertical-align: inherit;">Mas se o design √© pequeno, √© surpreendentemente barato. </font><font style="vertical-align: inherit;">Os engenheiros podem encomendar 100 microchips de 1 mm¬≤ por apenas US $ 14.000. A 28 nm, um chip de 1 mm¬≤ cont√©m milh√µes de transistores: isso √© suficiente para o processador RISC-V e o acelerador NVLDA. </font><font style="vertical-align: inherit;">O n√≠vel mais externo √© caro se o designer pretende criar um chip grande, mas muitas novas id√©ias podem ser demonstradas em chips pequenos.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclus√£o </font></font></h1><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄúA hora mais escura √© antes do amanhecer‚Äù</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - Thomas Fuller, 1650 </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para se beneficiar das li√ß√µes da hist√≥ria, os criadores dos processadores devem entender que muito pode ser adotado pela ind√∫stria de software, que o aumento do n√≠vel de abstra√ß√£o da interface de hardware / software oferece oportunidades para inova√ß√£o e que o mercado em em √∫ltima an√°lise, determinar o vencedor. O iAPX-432 e o Itanium demonstram como os investimentos em arquitetura n√£o podem fazer nada, enquanto o S / 360, 8086 e ARM oferecem altos resultados h√° d√©cadas, sem fim √† vista.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A conclus√£o da lei de Moore e a escala de Dennard, bem como a desacelera√ß√£o no desempenho dos microprocessadores padr√£o, n√£o s√£o problemas que devem ser resolvidos, mas um dado que, como voc√™ sabe, oferece oportunidades interessantes. Linguagens e arquiteturas orientadas para o assunto de alto n√≠vel, livres de cadeias de conjuntos de instru√ß√µes propriet√°rias, juntamente com a demanda do p√∫blico por maior seguran√ßa, dar√° in√≠cio a uma nova era de ouro para a arquitetura de computadores. Nos ecossistemas de c√≥digo aberto, os chips projetados artificialmente demonstrar√£o conquistas convincentes e, assim, acelerar√£o a implementa√ß√£o comercial. A filosofia do processador de prop√≥sito geral nesses chips provavelmente √© RISC, que resistiu ao teste do tempo. Espere a mesma inova√ß√£o acelerada que voc√™ fez na era de ouro passada,mas desta vez em termos de custo, energia e seguran√ßa, n√£o apenas desempenho.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Na pr√≥xima d√©cada, ocorrer√° uma explos√£o cambriana de novas arquiteturas de computadores, significando momentos emocionantes para os arquitetos de computadores na academia e na ind√∫stria. </font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt440760/">https://habr.com/ru/post/pt440760/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt440748/index.html">Supercomputador mais r√°pido do mundo bate recorde de IA</a></li>
<li><a href="../pt440752/index.html">Sele√ß√£o de prioridade de solicita√ß√£o do usu√°rio</a></li>
<li><a href="../pt440754/index.html">Utilit√°rio ingl√™s de plataforma cruzada para exibi√ß√£o de certificados qualificados russos x509</a></li>
<li><a href="../pt440756/index.html">CI / CD sem servidor na AWS</a></li>
<li><a href="../pt440758/index.html">V√° ao Meetup na Acronis! (Moscou, Fiztehpark)</a></li>
<li><a href="../pt440762/index.html">Revis√µes dos empregadores: a natureza e a falta de sentido das revis√µes an√¥nimas</a></li>
<li><a href="../pt440766/index.html">De geeks a geeks: presentes para 23 de fevereiro</a></li>
<li><a href="../pt440772/index.html">Design orientado a dom√≠nio: uma receita para um pragm√°tico</a></li>
<li><a href="../pt440774/index.html">Graves erros de matem√°tica do NHTSA permitem que a Tesla reivindique seguran√ßa no piloto autom√°tico</a></li>
<li><a href="../pt440776/index.html">E-mail, vis√£o interna</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìï ü•ß üë´ Optimizaci√≥n de la arquitectura de inteligencia artificial: comienza la carrera ü¶í üéöÔ∏è ü§∏üèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A medida que la arquitectura de inteligencia artificial mejora y los costos caen, los expertos dicen que cada vez m√°s empresas dominar√°n estas tecnolo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Optimizaci√≥n de la arquitectura de inteligencia artificial: comienza la carrera</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/icl_services/blog/415929/">  A medida que la arquitectura de inteligencia artificial mejora y los costos caen, los expertos dicen que cada vez m√°s empresas dominar√°n estas tecnolog√≠as, lo que impulsar√° las innovaciones y generar√° grandes dividendos tanto para las empresas como para los desarrolladores de inteligencia artificial. <br><br>  Las aplicaciones de IA a menudo funcionan sobre la base de arquitecturas completamente diferentes a las aplicaciones empresariales tradicionales.  A su vez, los proveedores est√°n dispuestos a hacer mucho para proporcionar nuevos componentes que est√°n creciendo en demanda. <br><br><img src="https://habrastorage.org/webt/kx/tl/dk/kxtldk4vqyzwqzmeaxzo5u8pulo.jpeg" align="left"><blockquote> "La industria de la computaci√≥n est√° experimentando cambios importantes: el inter√©s de las empresas en la inteligencia artificial impulsa las innovaciones que ayudar√°n a dominar e implementar la inteligencia artificial a cualquier escala", dijo Keith Strier, experto en inteligencia artificial y consultor de EY.  Los inversores est√°n invirtiendo mucho dinero en nuevas empresas que optimizan la IA, y los grandes fabricantes est√°n comenzando a ofrecer no solo chips y almacenamiento, sino tambi√©n los servicios de red y en la nube necesarios para la implementaci√≥n ". </blockquote>  . <br>  Seg√∫n √©l, ahora la tarea principal de los directores de TI es elegir la arquitectura de inteligencia artificial adecuada para las necesidades de la empresa. <br><br>  Streer dice que dado que la IA es matem√°tica en una escala sin precedentes, la implementaci√≥n de esta tecnolog√≠a requiere condiciones t√©cnicas y herramientas de seguridad completamente diferentes a las cargas de trabajo corporativas familiares.  Para aprovechar al m√°ximo la inteligencia artificial, los proveedores deber√°n proporcionar la infraestructura t√©cnica, la nube y otros servicios necesarios para la inteligencia artificial, sin los cuales ser√≠a imposible realizar c√°lculos tan complejos. <br><a name="habracut"></a><br>  Pero ya estamos en camino a esto, y en el futuro habr√° arquitecturas a√∫n m√°s avanzadas de inteligencia artificial.  Streer cree que proporcionar flexibilidad, potencia y velocidad de las arquitecturas inform√°ticas no solo ser√°n peque√±as empresas para el desarrollo de la inform√°tica de alto rendimiento, sino tambi√©n otros representantes de la industria inform√°tica de alto rendimiento, incluidas las nuevas empresas para crear microchips y servicios en la nube que buscan establecer un alto est√°ndar para la IA. inform√°tica <br><br>  A medida que aparezcan m√°s especialistas y desarrolladores en el campo de la IA, esta tecnolog√≠a se volver√° m√°s accesible, lo que dar√° un buen impulso a las innovaciones y generar√° dividendos notables para las empresas y proveedores. <br><br>  Mientras tanto, los directores de TI deben familiarizarse con las dificultades asociadas con la creaci√≥n de una arquitectura de inteligencia artificial para uso corporativo con el fin de estar listos para resolverlos. <br><br><h3>  Desarrollo de chips <br></h3><br>  La condici√≥n m√°s importante para la transici√≥n de las arquitecturas inform√°ticas tradicionales a la IA fue el desarrollo de procesadores gr√°ficos, circuitos integrados l√≥gicos programables (FPGA) y chips de IA especializados.  La proliferaci√≥n de arquitecturas basadas en GPU y FPGA ayudar√° a aumentar la productividad y la flexibilidad de los sistemas inform√°ticos y de almacenamiento, lo que permitir√° a los proveedores de soluciones ofrecer una gama de servicios avanzados para aplicaciones de inteligencia artificial y aprendizaje autom√°tico. <br><br><img src="https://habrastorage.org/webt/ik/yt/d4/ikytd4x8p5ajbjv_m4tjqq-lgzi.jpeg" align="left"><blockquote>  "Estas son arquitecturas de chips que liberan una gran cantidad de funciones avanzadas de la carga [como el entrenamiento de inteligencia artificial] y ayudan a implementar una pila mejorada para la inform√°tica y el almacenamiento que ofrece un rendimiento y eficiencia inigualables", dice Surya Varanasi, fundadora y CTO de Vexata Inc., proveedor de soluciones de gesti√≥n de datos. </blockquote><br>  Pero mientras los nuevos microcircuitos no son capaces de algo m√°s complejo.  Para seleccionar la arquitectura √≥ptima para las cargas de trabajo de IA, es necesario realizar c√°lculos a gran escala que requieran un alto rendimiento y que no puedan realizarse sin demoras.  La clave del √©xito aqu√≠ son las redes de alta velocidad.  Pero muchos algoritmos de IA deben esperar hasta que se escriba el siguiente conjunto de datos, por lo que no debe perder de vista el retraso. <br><br>  Adem√°s, cuando se cruzan los l√≠mites del servidor o se transfieren de los servidores al almacenamiento, los datos pasan a trav√©s de varios protocolos.  Para simplificar estos procesos, los expertos en datos pueden intentar localizar los datos localmente para que un servidor pueda procesar grandes cantidades de datos sin esperar a otros.  La integraci√≥n mejorada entre las GPU y el almacenamiento tambi√©n ayuda a ahorrar dinero.  Otros proveedores est√°n buscando formas de simplificar el dise√±o de los servidores de IA para garantizar la compatibilidad, de modo que los mismos servidores puedan usarse para diferentes cargas de trabajo. <br><br><h3>  Memoria no vol√°til para procesar cargas de trabajo de IA <br></h3><br>  El n√∫cleo de muchas soluciones basadas en la GPU es una unidad de conexi√≥n directa (DAS), que complica enormemente el aprendizaje distribuido y la formaci√≥n de conclusiones l√≥gicas para la IA.  Como resultado, instalar y administrar estas l√≠neas de datos para el aprendizaje profundo se est√° convirtiendo en una tarea compleja y que requiere mucho tiempo. <br><br>  Para resolver este problema, la memoria no vol√°til (NVM) es adecuada, que fue dise√±ada originalmente para proporcionar conectividad de alta calidad entre unidades de estado s√≥lido (SSD) y servidores corporativos tradicionales.  Ahora este tipo de memoria a menudo se incluye en las matrices de E / S para optimizar las cargas de trabajo de AI. <br><br>  La conclusi√≥n es que NVMe over Fabrics (NVMeF), las llamadas estas interfaces, ayudar√°n a reducir el costo de la conversi√≥n entre protocolos de red y controlar las caracter√≠sticas de cada tipo de SSD.  Esto permitir√° a los CIO justificar el costo de las aplicaciones de inteligencia artificial que utilizan grandes conjuntos de datos. <br><br>  Las interfaces NVMeF conllevan sus riesgos, incluida la necesidad de altos costos para las tecnolog√≠as avanzadas.  Adem√°s, todav√≠a hay dependencia de los proveedores de NVMeF en esta industria, por lo que los directores de TI deben tratar de evitar relaciones espec√≠ficas del proveedor al elegir un producto. <br>  Pero la implementaci√≥n de NVMeF le permitir√° dar un paso m√°s hacia la optimizaci√≥n de la arquitectura corporativa de la inteligencia artificial, cree Varanasi. <br><br><img src="https://habrastorage.org/webt/ik/yt/d4/ikytd4x8p5ajbjv_m4tjqq-lgzi.jpeg" align="left"><blockquote>  "A pesar de que la expansi√≥n de la arquitectura NVMe sobre Fabrics a escala industrial puede tomar otro a√±o o a√±o y medio, ya tenemos los componentes principales, y los pioneros ya est√°n reportando resultados prometedores", dice Varanasi. <br><br></blockquote><br>  Los CIO que desean desarrollar aplicaciones de inteligencia artificial pueden intentar crear un grupo de almacenamiento compartido optimizado para inteligencia artificial para NVMeF si puede reemplazar con √©xito las redes de almacenamiento existentes en el corto plazo.  Pero si espera hasta que NVMeF sea compatible con versiones anteriores, puede perder mucho. <br><br><h3>  Reduce el movimiento de datos <br></h3><br>  Cuando planifique las distintas etapas de la implementaci√≥n de AI, debe prestar especial atenci√≥n al costo de mover datos.  Los proyectos de IA, incluidos los de procesamiento y transformaci√≥n de datos, as√≠ como para algoritmos de entrenamiento, requieren grandes cantidades de datos. <br><br>  El hardware y los recursos humanos necesarios para completar estas tareas, as√≠ como el tiempo que lleva mover los datos en s√≠, pueden hacer que los proyectos de IA sean demasiado costosos.  Si los CIO logran evitar mover datos entre etapas, es probable que puedan desarrollar una infraestructura de IA viable que satisfaga estas necesidades, dijo Haris Pozidis, Ph.D., gerente, especialista en tecnolog√≠a de aceleraci√≥n de almacenamiento de IBM Research.  Los fabricantes ya est√°n trabajando en este tema. <br><br>  Por ejemplo, IBM est√° experimentando con varias opciones de optimizaci√≥n de hardware y software para reducir el movimiento de datos para aplicaciones de IA a gran escala en laboratorios en Zurich.  Dichas optimizaciones han ayudado a aumentar 46 veces el rendimiento del script de prueba de la popular herramienta de an√°lisis de clics.  Pozidis dice que el aprendizaje distribuido y la aceleraci√≥n de GPU est√°n en el coraz√≥n de este trabajo, que mejora el soporte para estructuras de datos dispersas. <br><br>  La concurrencia es otro componente importante para acelerar las cargas de trabajo de IA.  Para la capacitaci√≥n distribuida, es necesario realizar cambios en los niveles de hardware y software, lo que mejorar√° la eficiencia de procesamiento de los algoritmos de procesadores gr√°ficos paralelos.  Los investigadores de IBM han creado una plataforma prototipo con paralelismo de datos, que le permite escalar y aprender sobre grandes cantidades de datos que exceden la cantidad de memoria en una m√°quina.  Esto es muy importante para aplicaciones a gran escala.  Una nueva plataforma optimizada para el aprendizaje de la comunicaci√≥n y para proporcionar la localidad de datos ha ayudado a reducir el movimiento de datos. <br><br>  A nivel de hardware, los investigadores de IBM utilizaron NVMeF para mejorar la interconectividad de la GPU, la CPU y los componentes de memoria en los servidores, as√≠ como entre los servidores y el almacenamiento. <br><br><img src="https://habrastorage.org/webt/es/li/m1/eslim1mvwlg3vqgesw1lfuzlyqa.jpeg" align="left"><blockquote>  ‚ÄúEl rendimiento de diferentes cargas de trabajo de IA puede verse limitado por los cuellos de botella de la red, el ancho de banda de la memoria y el ancho de banda entre la CPU y la GPU.  Pero si implementa algoritmos y protocolos de conexi√≥n m√°s eficientes en todas las partes del sistema, puede dar un gran paso hacia el desarrollo de aplicaciones de IA m√°s r√°pidas ", dice Pozidis. </blockquote><br><br><h3>  Computaci√≥n Compuesta <br></h3>  Hoy, la mayor√≠a de las cargas de trabajo utilizan una base de datos preconfigurada optimizada para una arquitectura de hardware particular. <br><br><img src="https://habrastorage.org/webt/iy/qd/xq/iyqdxqbenrorpibc--ylt9o0zfs.jpeg" align="left"><br><blockquote>  Chad Miley, vicepresidente de productos y soluciones anal√≠ticas de Teradata, dice que el mercado se est√° moviendo hacia hardware basado en software, lo que permitir√° a las organizaciones distribuir de manera inteligente el procesamiento entre GPU y CPU dependiendo de la tarea actual. </blockquote><br><br>  La dificultad radica en el hecho de que las empresas utilizan diferentes motores inform√°ticos para acceder a diferentes opciones de almacenamiento.  Las grandes corporaciones prefieren almacenar datos valiosos que necesitan acceso regular, por ejemplo, informaci√≥n sobre clientes, finanzas, la cadena de suministro, productos y otros componentes, utilizando entornos de entrada-salida de alto rendimiento.  A su vez, los conjuntos de datos raramente utilizados, tales como lecturas de sensores, contenido web y multimedia, se almacenan en un almacenamiento en la nube de bajo costo. <br><br>  Uno de los objetivos de la inform√°tica compuesta es usar contenedores para optimizar el rendimiento de instancias como motores SQL, motores de gr√°ficos, aprendizaje autom√°tico y motores de aprendizaje profundo que acceden a datos distribuidos en diferentes repositorios.  El despliegue de varios motores de computaci√≥n anal√≠tica permite el uso de modelos multiprocesador que usan datos de diferentes motores y, como regla, brindan mejores resultados. <br><br>  Los proveedores de TI como Dell Technologies, Hewlett Packard Enterprise y Liquid se est√°n alejando gradualmente de las arquitecturas tradicionales que asignan cargas de trabajo a nivel inform√°tico.  En cambio, buscan asignar cargas de trabajo de IA a un sistema completo que consiste en unidades centrales de procesamiento, GPU, dispositivos de memoria y almacenamiento.  Para tal transici√≥n, es necesario dominar los nuevos componentes de la red, que aumentan la velocidad y reducen el retraso al conectar varios componentes del sistema. <br><br>  Por ejemplo, muchos centros de datos en la nube usan Ethernet para conectar componentes inform√°ticos y almacenamiento, donde el retraso es de aproximadamente 15 microsegundos.  La red inform√°tica conmutada de alta velocidad de InfiniBand, que se utiliza en muchas infraestructuras convergentes, puede reducir la latencia hasta en 1,5 microsegundos.  Liquid ha creado un conjunto de herramientas para conectar diferentes nodos utilizando PCI Express (PCIE), lo que reduce el retraso a 150 nanosegundos. <br><br>  Adem√°s, algunos expertos sugieren aumentar la cantidad de memoria para las GPU utilizadas para manejar grandes cargas con conexiones r√°pidas.  Por ejemplo, DDR4 a menudo se usa junto con RAM, lo que reduce el retraso a 14 nanosegundos.  Pero esto solo funciona para peque√±os segmentos de unas pocas pulgadas. <br><br>  Little Marrek, fundador y desarrollador del servicio de gesti√≥n de IA ClusterOne, cree que se necesita m√°s trabajo para garantizar la compatibilidad de las cargas de trabajo de IA en un entorno de software.  A pesar del hecho de que algunas empresas ya est√°n tratando de garantizar la compatibilidad con Docker y Kubernetes, es demasiado pronto para aplicar el mismo enfoque a las GPU. <br><br><img src="https://habrastorage.org/webt/gy/kf/vo/gykfvonm7odfn4osmkaya-lwfas.jpeg" align="left"><blockquote>  "En general, ejecutar cargas de trabajo de GPU y monitorearlas no es f√°cil", dice Marrek.  "No existe una soluci√≥n universal que permita el monitoreo de todos los sistemas". <br><br></blockquote><br><br><h3>  Almacenamiento y GPU <br></h3><br>  Otro enfoque es utilizar un procesador de gr√°ficos para preprocesar los datos con el fin de reducir la cantidad necesaria para un tipo particular de an√°lisis, y ayudar a organizar los datos y asignarles etiquetas.  Esto le permitir√° preparar un conjunto de datos adecuado para varias GPU involucradas en el procesamiento, de modo que el algoritmo pueda funcionar desde el interior de la memoria en lugar de transferir datos desde los almacenes a trav√©s de redes lentas. <br><br><img src="https://habrastorage.org/webt/ys/qp/cb/ysqpcbtqxhszcgd3hpgn9kutmss.jpeg" align="left"><blockquote>  "Percibimos el almacenamiento, la inform√°tica y la memoria como componentes separados de la soluci√≥n, que se ha desarrollado hist√≥ricamente y, por lo tanto, tratamos de aumentar los vol√∫menes de procesamiento", dijo Alex St. John, CTO y fundador de Nyriad Ltd., una compa√±√≠a de software de almacenamiento que apareci√≥ en El resultado de la investigaci√≥n del radiotelescopio m√°s grande del mundo: un telescopio con una matriz de antenas de kil√≥metro cuadrado (SKA). </blockquote>  Cuanto mayor sea la cantidad de datos, m√°s dif√≠cil ser√° moverlos a alg√∫n lugar para procesarlos. <br><br>  El telescopio SKA necesitaba grandes cantidades de energ√≠a para procesar 160 TB de datos de se√±al de radio en tiempo real, que era el principal obst√°culo para los investigadores.  Como resultado, decidieron abandonar los almacenamientos RAID que se usan con mayor frecuencia en los centros de datos e implementar un sistema de archivos de cl√∫ster paralelo, como BeeGFS, que simplifica la preparaci√≥n de datos para las cargas de trabajo de AI. <br><br>  Los directores de TI que trabajan en la estrategia √≥ptima para la arquitectura de inteligencia artificial deben prestar especial atenci√≥n a la usabilidad.  Si los desarrolladores, los especialistas en datos y los equipos de integraci√≥n de desarrollo y operaciones pueden dominar r√°pidamente la nueva tecnolog√≠a, pueden invertir su tiempo y energ√≠a para crear una l√≥gica comercial exitosa en lugar de resolver problemas de implementaci√≥n y l√≠neas de datos. <br><br>  Adem√°s, las organizaciones deben considerar cuidadosamente cu√°nto esfuerzo y tiempo llevar√° construir una nueva arquitectura de inteligencia artificial en un ecosistema existente. <br><br>  "Antes de implementar nuevas infraestructuras y planificar grandes cargas de trabajo, los CIO deben evaluar cu√°ntos recursos agotables se necesitar√°n", dice Asaf Someh, fundador y CEO de Iguazio. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es415929/">https://habr.com/ru/post/es415929/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es415917/index.html">La "Ley de primavera" entr√≥ en vigor: ¬øqu√© sigue?</a></li>
<li><a href="../es415919/index.html">Refactorizando un programa en Go: aceleraci√≥n 23 veces</a></li>
<li><a href="../es415923/index.html">¬øLa unidad es lenta? Precauci√≥n LINQ</a></li>
<li><a href="../es415925/index.html">Tecnolog√≠a de cadena de bloques an√≥nima patentada MasterCard</a></li>
<li><a href="../es415927/index.html">L√°mpara industrial Breeze 50</a></li>
<li><a href="../es415933/index.html">C√≥mo construir una arquitectura IIoT de bricolaje</a></li>
<li><a href="../es415935/index.html">Clases de inserci√≥n</a></li>
<li><a href="../es415937/index.html">El cohete privado japon√©s MOMO-2 explot√≥ en la plataforma de lanzamiento</a></li>
<li><a href="../es415939/index.html">Procesamiento gr√°fico distribuido con Spark GraphX</a></li>
<li><a href="../es415941/index.html">C√≥mo tratamos de descifrar c√≥digos de barras y no entendimos nada</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
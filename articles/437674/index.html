<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõê üò∑ üë©‚Äçüë©‚Äçüëß‚Äçüë¶ M√©todos de reconocimiento de objetos en 3D para veh√≠culos no tripulados. Informe Yandex üë®üèæ‚Äçüè´ üòΩ üåÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los autos no tripulados no pueden prescindir de comprender qu√© hay alrededor y d√≥nde exactamente. En diciembre del a√±o pasado, el desarrollador Victor...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>M√©todos de reconocimiento de objetos en 3D para veh√≠culos no tripulados. Informe Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/437674/">  Los autos no tripulados no pueden prescindir de comprender qu√© hay alrededor y d√≥nde exactamente.  En diciembre del a√±o pasado, el desarrollador Victor Otliga <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">vitonka</a> hizo una presentaci√≥n sobre la detecci√≥n de objetos 3D en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el √°rbol de Navidad de datos</a> .  Victor trabaja en la direcci√≥n de veh√≠culos no tripulados Yandex, en el grupo que maneja la situaci√≥n del tr√°fico (y tambi√©n ense√±a en el ShAD).  Explic√≥ c√≥mo resolvemos el problema de reconocer a otros usuarios de la carretera en una nube de puntos tridimensional, c√≥mo este problema difiere del reconocimiento de objetos en una imagen y c√≥mo beneficiarse de compartir diferentes tipos de sensores. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/celzhoWh2TE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - Hola a todos!  Mi nombre es Victor Otliga, trabajo en la oficina de Yandex en Minsk y estoy desarrollando veh√≠culos no tripulados.  Hoy hablar√© sobre una tarea bastante importante para los drones: el reconocimiento de los objetos 3D que nos rodean. <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/ky/wn/hu/kywnhuprs-iq34tx4rgohnvwqm8.jpeg"><br><br>  Para montar, necesitas entender lo que hay alrededor.  Te dir√© brevemente qu√© sensores y sensores se usan en veh√≠culos no tripulados y cu√°les usamos.  Te dir√© cu√°l es la tarea de detectar objetos 3D y c√≥mo medir la calidad de la detecci√≥n.  Luego te dir√© en qu√© se puede medir esta calidad.  Y luego har√© una breve revisi√≥n de buenos algoritmos modernos, incluidos aquellos en los que se basan nuestras soluciones.  Y al final, peque√±os resultados, una comparaci√≥n de estos algoritmos, incluido el nuestro. <br><br><img src="https://habrastorage.org/webt/pk/sf/vo/pksfvoxtqwlyf6k-wido8ixektg.jpeg"><br><br>  As√≠ es como se ve nuestro prototipo funcional de un autom√≥vil no tripulado ahora.  Tal taxi puede ser alquilado por cualquier persona sin conductor en la ciudad de Innopolis en Rusia, as√≠ como en Skolkovo.  Y si te fijas bien, hay un gran dado en la parte superior.  ¬øQu√© hay adentro? <br><br><img src="https://habrastorage.org/webt/ei/3c/mq/ei3cmqe3l4kjfzjju-s1ndavkwi.jpeg"><br><br>  Dentro de un conjunto simple de sensores.  Hay una antena GNSS y GSM para determinar d√≥nde est√° el autom√≥vil y para comunicarse con el mundo exterior.  Donde sin un sensor tan cl√°sico como una c√°mara.  Pero hoy nos interesar√°n los lidares. <br><br><img src="https://habrastorage.org/webt/cm/s6/pd/cms6pdxey7d4ykgktlc8lvyd8fc.jpeg"><br><br><img src="https://habrastorage.org/webt/un/ia/bg/uniabgh6yomlr2rourl7ynj3coc.jpeg"><br><br>  Lidar produce aproximadamente una nube de puntos a su alrededor, que tiene tres coordenadas.  Y tienes que trabajar con ellos.  Te dir√© c√≥mo, usando una imagen de c√°mara y una nube lidar, reconocer cualquier objeto. <br><br><img src="https://habrastorage.org/webt/yx/rt/si/yxrtsiwsnt_gcdgjbz42pp8lqvc.jpeg"><br><br>  ¬øCu√°l es el desaf√≠o?  Se ingresa la imagen de la c√°mara, la c√°mara se sincroniza con el LIDAR.  Ser√≠a extra√±o usar la imagen de la c√°mara hace un segundo, tomar la nube lidar desde un momento completamente diferente e intentar reconocer objetos en ella. <br><br><img src="https://habrastorage.org/webt/xa/g6/aj/xag6ajjiigpo5m737kklxiwkmb0.jpeg"><br><br>  Sin embargo, de alguna manera sincronizamos c√°maras y lidares, esta es una tarea dif√≠cil por separado, pero lo superamos con √©xito.  Dichos datos ingresan la entrada, y al final queremos obtener cuadros, cuadros delimitadores que limitan el objeto: peatones, ciclistas, autom√≥viles y otros usuarios de la carretera y no solo. <br><br>  La tarea fue establecida.  ¬øC√≥mo lo evaluaremos? <br><br><img src="https://habrastorage.org/webt/ew/hm/wd/ewhmwdgektceevdbmgu838n5wui.jpeg"><br><br>  El problema del reconocimiento 2D de objetos en una imagen ha sido ampliamente estudiado. <br><br><img src="https://habrastorage.org/webt/-c/ri/cu/-cricuguziob4idgyr_u-ihfq-e.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace desde la diapositiva</a></sub></sup> </h5><br>  Puede usar m√©tricas est√°ndar o sus an√°logos.  Hay un coeficiente Jacquard o una intersecci√≥n sobre la uni√≥n, un coeficiente maravilloso que muestra qu√© tan bien detectamos un objeto.  Podemos tomar un cuadro donde, como suponemos, se encuentra el objeto, y un cuadro donde se encuentra realmente.  Cuenta esta m√©trica.  Hay umbrales est√°ndar; digamos que para los autom√≥viles a menudo toman un umbral de 0.7.  Si este valor es mayor que 0.7, creemos que hemos detectado con √©xito el objeto, que el objeto est√° all√≠.  Somos geniales, podemos ir m√°s all√°. <br><br>  Adem√°s, para detectar un objeto y comprender que est√° en alg√∫n lugar, nos gustar√≠a confiar en que realmente vemos el objeto all√≠ y tambi√©n medirlo.  Puede medir simple, considerar la precisi√≥n promedio.  Puede tomar la curva de recuperaci√≥n de precisi√≥n y el √°rea debajo de ella y decir: cuanto m√°s grande sea, mejor. <br><br><img src="https://habrastorage.org/webt/p7/jk/z5/p7jkz5xnyyhehx99e73nijtb798.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace desde la diapositiva</a></sub></sup> </h5><br>  Por lo general, para medir la calidad de la detecci√≥n 3D, toman un conjunto de datos y lo dividen en varias partes, ya que los objetos pueden estar cerca o m√°s lejos, pueden estar parcialmente ocultos por otra cosa.  Por lo tanto, la muestra de validaci√≥n a menudo se divide en tres partes.  Objetos que son f√°ciles de detectar, de complejidad media y complejos, distantes o que est√°n muy oscurecidos.  Y miden por separado en tres partes.  Y en los resultados de la comparaci√≥n, tambi√©n tomaremos dicha partici√≥n. <br><br><img src="https://habrastorage.org/webt/6v/d9/tx/6vd9tx38777pdvhxt4iij_rc4xu.jpeg"><br><br>  Puede medir la calidad como en 3D, un an√°logo de intersecci√≥n sobre uni√≥n, pero no la proporci√≥n de √°reas, sino, por ejemplo, los vol√∫menes.  Pero, por regla general, a un autom√≥vil no tripulado no le importa lo que est√© sucediendo en la coordenada Z. Podemos tomar una vista panor√°mica desde arriba y tomar alg√∫n tipo de m√©trica, como si lo estuvi√©ramos viendo todo en 2D.  El hombre se navega m√°s o menos en 2D, y un veh√≠culo no tripulado es el mismo.  La altura de la caja no es muy importante. <br><br><img src="https://habrastorage.org/webt/gs/gg/js/gsggjsnlbhi0qd_ppdpnvqvlncm.jpeg"><br><br>  ¬øQu√© medir? <br><br><img src="https://habrastorage.org/webt/-p/vq/qn/-pvqqnyi_yovi_bit9x6lergyva.jpeg"><br><br>  Probablemente todos los que al menos de alguna manera se enfrentaron a la tarea de detectar en 3D por la nube lidar escucharon sobre un conjunto de datos como KITTI. <br><br><img src="https://habrastorage.org/webt/bp/bz/wn/bpbzwnd-1o69xdoonrm1k81vndo.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace desde la diapositiva</a></sub></sup> </h5><br>  En algunas ciudades de Alemania, se registr√≥ un conjunto de datos, un autom√≥vil equipado con sensores fue, ten√≠a sensores GPS, c√°maras y lidares.  Luego se marc√≥ alrededor de 8000 escenas, y se dividi√≥ en dos partes.  Una parte es la capacitaci√≥n, en la cual todos pueden entrenar, y la segunda es la validaci√≥n, para medir los resultados.  La muestra de validaci√≥n KITTI se considera una medida de calidad.  En primer lugar, hay una tabla de l√≠deres en el sitio del conjunto de datos de KITTI, puede enviar su decisi√≥n all√≠, sus resultados en el conjunto de datos de validaci√≥n y comparar con las decisiones de otros actores o investigadores del mercado.  Pero tambi√©n este conjunto de datos est√° disponible p√∫blicamente, puede descargarlo, no decirle a nadie, verificar el suyo propio, compararlo con la competencia, pero no cargarlo p√∫blicamente. <br><br><img src="https://habrastorage.org/webt/12/mu/8_/12mu8_z9hlu8-zuvhlm1bofiko4.jpeg"><br><br>  Los conjuntos de datos externos son buenos, no tiene que gastar su tiempo y recursos en ellos, pero por regla general, un autom√≥vil que viaj√≥ a Alemania puede estar equipado con sensores completamente diferentes.  Y siempre es bueno tener su propio conjunto de datos interno.  Adem√°s, es m√°s dif√≠cil expandir un conjunto de datos externo a expensas de otros, pero es m√°s f√°cil administrar el suyo propio.  Por lo tanto, utilizamos el maravilloso servicio Yandex.Tolok. <br><br><img src="https://habrastorage.org/webt/i4/ha/ns/i4hansnkczrkhpeq9_liyn8t9bk.jpeg"><br><br>  Finalizamos nuestro sistema de tareas especiales.  Para el usuario que quiere ayudar con el marcado y obtener una recompensa por esto, le damos una imagen de la c√°mara, le damos una nube lidar que puede rotar, acercar, alejar y pedirle que coloque cuadros que limiten nuestros cuadros delimitadores para que un autom√≥vil o un peat√≥n se meta en ellos. o algo m√°s.  Por lo tanto, recolectamos muestras internas para uso personal. <br><br>  Supongamos que hemos decidido qu√© tarea resolveremos, c√≥mo asumiremos que lo hicimos bien o mal.  Llevamos a alg√∫n lado los datos. <br><br>  ¬øCu√°les son los algoritmos?  Comencemos con 2D.  La tarea de detecci√≥n 2D es muy conocida y estudiada. <br><br><img src="https://habrastorage.org/webt/6x/vq/ta/6xvqtadjyarjzn9h9v0xz6cqrny.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace desde la diapositiva</a></sub></sup> </h5><br>  Seguramente, muchas personas conocen el algoritmo SSD, que es uno de los m√©todos m√°s modernos para detectar objetos 2D y, en principio, podemos suponer que de alguna manera el problema de detectar objetos en la imagen est√° bastante bien resuelto.  En todo caso, podemos usar estos resultados como alg√∫n tipo de informaci√≥n adicional. <br><br>  Pero nuestra nube lidar tiene sus propias caracter√≠sticas que la distinguen en gran medida de la imagen.  En primer lugar, es muy escaso.  Si la imagen es una estructura densa, los p√≠xeles est√°n cerca, todo es denso, entonces la nube es muy delgada, no hay tantos puntos y no tiene una estructura regular.  Puramente f√≠sicamente hay muchos m√°s puntos cerca de all√≠ que en la distancia, y cuanto m√°s lejos vayas, menos puntos hay, menos precisi√≥n hay, m√°s dif√≠cil es determinar algo. <br><br>  Bueno, los puntos, en principio, de la nube vienen en un orden incomprensible.  Nadie garantiza que un punto siempre ser√° anterior a otro.  Vienen en un orden relativamente aleatorio.  De alguna manera, puede aceptar ordenarlos o reordenarlos por adelantado, y solo luego enviar modelos a la entrada, pero esto ser√° bastante inconveniente, debe dedicar tiempo para cambiarlos, y as√≠ sucesivamente. <br><br>  Nos gustar√≠a crear un sistema que sea invariable para nuestros problemas, que resuelva todos estos problemas.  Afortunadamente, el a√±o pasado CVPR present√≥ dicho sistema.  Hab√≠a tal arquitectura: PointNet.  Como trabaja ella? <br><br><img src="https://habrastorage.org/webt/ny/ay/np/nyaynp7lrsoopcumwsbjmm9ynik.jpeg"><br><br>  Una nube de n puntos llega a la entrada, cada uno con tres coordenadas.  Luego, cada punto est√° de alguna manera estandarizado por una peque√±a transformaci√≥n especial.  Adem√°s, se conduce a trav√©s de una red totalmente conectada para enriquecer estos puntos con signos.  Luego, nuevamente, se produce la transformaci√≥n, y al final se enriquece adicionalmente.  En alg√∫n momento, se obtienen n puntos, pero cada uno tiene aproximadamente 1024 caracter√≠sticas, de alguna manera est√°n estandarizadas.  Pero hasta ahora no hemos resuelto el problema con respecto a la invariancia de turnos, turnos, etc.  Aqu√≠ se propone hacer una agrupaci√≥n m√°xima, tomar el m√°ximo entre los puntos en cada canal y obtener un vector de 1024 signos, que ser√° un descriptor de nuestra nube, que contendr√° informaci√≥n sobre toda la nube.  Y luego con este descriptor puedes hacer muchas cosas diferentes. <br><br><img src="https://habrastorage.org/webt/qj/lr/hc/qjlrhclpvd2smfl3q2j28bft0sw.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace desde la diapositiva</a></sub></sup> </h5><br>  Por ejemplo, puede pegarlo a los descriptores de puntos individuales y resolver el problema de segmentaci√≥n, para que cada punto determine a qu√© objeto pertenece.  Es solo una carretera, una persona o un autom√≥vil.  Y aqu√≠ est√°n los resultados del art√≠culo. <br><br><img src="https://habrastorage.org/webt/kh/-o/cw/kh-ocwqrkgelcs958zio30nc7ek.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace desde la diapositiva</a></sub></sup> </h5><br>  Puede notar que este algoritmo hace un muy buen trabajo.  En particular, me gusta mucho esa peque√±a mesa en la que se arrojaron algunos de los datos sobre la encimera, y sin embargo determin√≥ d√≥nde est√°n las patas y d√≥nde est√° la encimera.  Y este algoritmo, en particular, puede usarse como un ladrillo para construir m√°s sistemas. <br><br>  Un enfoque que utiliza esto es el enfoque Frustum PointNets o el enfoque de la pir√°mide truncada.  La idea es algo como esto: reconozcamos los objetos en 2D, somos buenos para hacer esto. <br><br><img src="https://habrastorage.org/webt/lh/xb/uv/lhxbuvbemlftwpvufw7hbpmmhog.jpeg"><br><br>  Luego, sabiendo c√≥mo funciona la c√°mara, podemos estimar en qu√© √°rea puede estar el objeto de inter√©s para nosotros, la m√°quina.  Para proyectar, corte solo esta √°rea, y ya en ella resuelva el problema de encontrar un objeto interesante, por ejemplo, una m√°quina.  Esto es mucho m√°s f√°cil que buscar cualquier cantidad de autom√≥viles en la nube.  La b√∫squeda de un auto exactamente en la misma nube parece ser mucho m√°s clara y eficiente. <br><br><img src="https://habrastorage.org/webt/lt/t-/0v/ltt-0v8iobuju4yfoj-ips2uka8.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace desde la diapositiva</a></sub></sup> </h5><br>  La arquitectura se parece a esto.  Primero, de alguna manera seleccionamos las regiones que nos interesan, en cada regi√≥n hacemos segmentaci√≥n, y luego resolvemos el problema de encontrar un cuadro delimitador que limite el objeto que nos interesa. <br><br><img src="https://habrastorage.org/webt/2w/lj/8g/2wlj8gt2m9vyiljomkkz0tjvd_y.jpeg"><br><br>  El enfoque ha demostrado su eficacia.  En las im√°genes se puede ver que funciona bastante bien, pero tambi√©n tiene inconvenientes.  El enfoque es de dos niveles, por eso puede ser lento.  Primero debemos aplicar redes y reconocer objetos 2D, luego cortar y luego resolver la segmentaci√≥n y la asignaci√≥n del cuadro delimitador en una parte de la nube, para que pueda funcionar un poco lentamente. <br><br>  Otro enfoque  ¬øPor qu√© no convertimos nuestra nube en alg√∫n tipo de estructura que se parece a una imagen?  La idea es esta: echemos un vistazo desde arriba y pruebe nuestra nube lidar.  Obtenemos cubos de espacios. <br><br><img src="https://habrastorage.org/webt/sc/7l/3h/sc7l3h0ewwcfmiuejsxnl7ozx5c.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace desde la diapositiva</a></sub></sup> </h5><br>  Dentro de cada cubo tenemos algunos puntos.  Podemos contar algunas caracter√≠sticas en ellas, pero podemos usar PointNet, que para cada espacio contar√° alg√∫n tipo de descriptor.  Obtendremos un v√≥xel, cada v√≥xel tiene una descripci√≥n caracter√≠stica, y se ver√° m√°s o menos como una estructura densa, como una imagen.  Ya podemos hacer diferentes arquitecturas, por ejemplo, arquitectura tipo SSD para detectar objetos. <br><br><img src="https://habrastorage.org/webt/x_/tb/c_/x_tbc_hsv_yuahyllkmlxijsowe.jpeg"><br><br>  El √∫ltimo enfoque, que fue uno de los primeros enfoques para combinar datos de m√∫ltiples sensores.  Ser√≠a un pecado usar solo datos LIDAR cuando tambi√©n tenemos datos de la c√°mara.  Uno de estos enfoques se llama Red de detecci√≥n de objetos 3D de vista m√∫ltiple.  Su idea es esta: alimentar tres canales de datos de entrada a la entrada de una red grande. <br><br><img src="https://habrastorage.org/webt/tz/xv/ty/tzxvty86li7jozjwozhqlun8r9a.jpeg"><br><h5>  <sup><sub><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace desde la diapositiva</a></sub></sup> </h5><br>  Esta es una imagen de la c√°mara y, en dos versiones, una nube lidar: desde arriba, con una vista de p√°jaro y alg√∫n tipo de vista frontal, lo que vemos frente a nosotros.  Enviamos esto a la entrada de la neurona, y configurar√° todo dentro de s√≠ mismo, nos dar√° el resultado final: el objeto. <br><br>  Quiero comparar estos modelos.  En el conjunto de datos KITTI, en las unidades de validaci√≥n, la calidad se eval√∫a como un porcentaje en la precisi√≥n promedio. <br><br><img src="https://habrastorage.org/webt/pt/ny/8x/ptny8xzcmojphtluvg5pxm1-mlq.jpeg"><br><br>  Puede notar que F-PointNet funciona bastante bien y lo suficientemente r√°pido, supera a todos los dem√°s en diferentes √°reas, al menos seg√∫n los autores. <br><br>  Nuestro enfoque se basa en m√°s o menos todas las ideas que he enumerado.  Si compara, obtiene la siguiente imagen.  Si no ocupamos el primer lugar, al menos el segundo.  Adem√°s, en aquellos objetos que son dif√≠ciles de detectar, nos separamos en los l√≠deres.  Y lo m√°s importante, nuestro enfoque es lo suficientemente r√°pido.  Esto significa que ya es bastante aplicable para sistemas en tiempo real, y es especialmente importante para un veh√≠culo no tripulado monitorear lo que sucede en el camino y resaltar todos estos objetos. <br><br><img src="https://habrastorage.org/webt/ad/dx/bk/addxbko462x7r4doq22akwwkpik.jpeg"><br><br>  En conclusi√≥n, un ejemplo de nuestro detector: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/celzhoWh2TE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Se puede ver que la situaci√≥n es complicada: algunos de los objetos est√°n cerrados y otros no son visibles para la c√°mara.  Peatones, ciclistas.  Pero el detector hace frente lo suficientemente bien.  Gracias </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/437674/">https://habr.com/ru/post/437674/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../437660/index.html">Actualizaci√≥n de perfil de por vida en Visual Studio 2019 Preview 2</a></li>
<li><a href="../437664/index.html">Recuperaci√≥n compuesta</a></li>
<li><a href="../437666/index.html">Anuncio de la vista previa de F # 4.6</a></li>
<li><a href="../437670/index.html">Actualizaciones de back-end de MSVC en Visual Studio 2019 Preview 2: Nuevas optimizaciones, OpenMP y mejoras de rendimiento de compilaci√≥n</a></li>
<li><a href="../437672/index.html">Cyberd: Calcular el conocimiento de web3</a></li>
<li><a href="../437676/index.html">Las universidades y los aceleradores corporativos como apalancamiento para lanzar una startup B2B en los EE. UU.</a></li>
<li><a href="../437680/index.html">Mi colecci√≥n de bricolaje en Youtube</a></li>
<li><a href="../437682/index.html">Escribir otra herramienta de plantillas de Kubernetes</a></li>
<li><a href="../437684/index.html">Algoritmo Supremo - Compendio sesgado</a></li>
<li><a href="../437686/index.html">Aprendizaje: escribir un mensajero p2p con cifrado de extremo a extremo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
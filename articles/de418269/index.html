<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤱 😑 🙆🏻 Funktionsweise des CPU-Managers in Kubernetes 🧑🏽‍🤝‍🧑🏼 👨🏻‍🎓 👩‍💻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hinweis perev. : Dieser Artikel wurde im offiziellen Kubernetes-Blog veröffentlicht und von zwei Intel-Mitarbeitern verfasst, die direkt an der Entwic...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Funktionsweise des CPU-Managers in Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/418269/">  <i><b>Hinweis</b></i>  <i><b>perev.</b></i>  <i>: Dieser Artikel wurde im offiziellen Kubernetes-Blog veröffentlicht und von zwei Intel-Mitarbeitern verfasst, die direkt an der Entwicklung von CPU Manager beteiligt sind, einer neuen Funktion in Kubernetes, über die wir in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Version 1.8-</a> Rezension geschrieben haben.</i>  <i>Im Moment (d. H. Für K8s 1.11) hat diese Funktion den Beta-Status und lesen Sie später in der Notiz mehr über ihren Zweck.</i> <br><br>  Die Veröffentlichung befasst sich mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CPU Manager</a> , einer Beta-Funktion in Kubernetes.  Mit dem CPU-Manager können Sie Workloads in Kubelet besser verteilen, d. H.  auf dem Kubernetes-Hostagenten durch Zuweisen dedizierter CPUs zu Containern eines bestimmten Herdes. <br><br><img src="https://habrastorage.org/webt/h-/5g/yo/h-5gyocq5lrz2vsvso7ioblnb3q.png"><a name="habracut"></a><br><br><h2>  Hört sich toll an!  Aber hilft mir der CPU-Manager? </h2><br>  Hängt von der Arbeitsbelastung ab.  Der einzige Rechenknoten im Kubernetes-Cluster kann viele Herde ausführen, und einige von ihnen können Lasten ausführen, die im CPU-Verbrauch aktiv sind.  In diesem Szenario können die Herde um die auf diesem Knoten verfügbaren Prozessressourcen konkurrieren.  Wenn dieser Wettbewerb eskaliert, kann sich die Arbeitslast auf andere CPUs verlagern, je nachdem, ob sie <i>gedrosselt wurde</i> und welche CPUs zum Zeitpunkt der Planung verfügbar waren.  Darüber hinaus kann es Fälle geben, in denen die Arbeitslast für Kontextwechsel empfindlich ist.  In all diesen Szenarien kann die Workload-Leistung beeinträchtigt werden. <br><br>  Wenn Ihre Arbeitslast für solche Szenarien empfindlich ist, können Sie CPU Manager aktivieren, um eine bessere Leistungsisolation zu erzielen, indem Sie der Last bestimmte CPUs zuweisen. <br><br>  Der CPU-Manager kann beim Laden mit den folgenden Funktionen helfen: <br><br><ul><li>  Empfindlich gegenüber CPU-Drosseleffekten </li><li>  empfindlich gegenüber Kontextwechseln; </li><li>  Prozessor-Cache-Fehler; </li><li>  Profitieren von der Aufteilung der Prozessorressourcen (z. B. Datencache und Anweisungen); </li><li>  speicherempfindlicher Speicher zwischen Prozessorsockeln <i>(eine ausführliche Erklärung der Autoren finden Sie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Unix Stack Exchange</a> - <b>ca. übersetzt</b> )</i> ; </li><li>  Hyperthreads, die von demselben physischen Kern der CPU empfindlich sind oder diesen benötigen. </li></ul><br><h2>  Ok!  Wie benutzt man es? </h2><br>  Die Verwendung des CPU-Managers ist einfach.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aktivieren Sie es zunächst mithilfe der statischen Richtlinie</a> in Kubelet, die auf den Rechenknoten des Clusters ausgeführt wird.  Konfigurieren Sie dann die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">QoS-</a> Klasse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">( <i>Guaranteed</i> Quality of Service)</a> für den Herd.  Fordern Sie eine ganzzahlige Anzahl von CPU-Kernen (z. B. <code>1000m</code> oder <code>4000m</code> <code>1000m</code> ) für Container an, die dedizierte Kerne benötigen.  Erstellen Sie nach der vorherigen Methode (z. B. <code>kubectl create -f pod.yaml</code> ) ... und voila - der CPU-Manager weist jedem Herdcontainer je nach CPU-Anforderungen dedizierte Prozessorkerne zu. <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: Pod metadata: name: exclusive-2 spec: containers: - image: quay.io/connordoyle/cpuset-visualizer name: exclusive-2 resources: # Pod is in the Guaranteed QoS class because requests == limits requests: # CPU request is an integer cpu: 2 memory: "256M" limits: cpu: 2 memory: "256M"</code> </pre> <br>  <i>Spezifikation eines Herdes, der 2 dedizierte CPUs anfordert.</i> <br><br><h2>  Wie funktioniert der CPU Manager? </h2><br>  Wir betrachten drei Arten der CPU-Ressourcensteuerung, die in den meisten Linux-Distributionen verfügbar sind und für Kubernetes und die Zwecke dieser Veröffentlichung relevant sind.  Die ersten beiden sind CFS-Freigaben (was ist mein gewichteter „ehrlicher“ Anteil an der CPU-Zeit im System) und CFS-Kontingent (was ist die maximale CPU-Zeit, die mir für den Zeitraum zugewiesen wurde).  Der CPU-Manager verwendet auch eine dritte, die als CPU-Affinität bezeichnet wird (auf welchen logischen CPUs ich Berechnungen durchführen darf). <br><br>  Standardmäßig können alle Pods und Container, die auf dem Kubernetes-Clusterknoten ausgeführt werden, auf allen verfügbaren Systemkernen ausgeführt werden.  Die Gesamtzahl der zugewiesenen Freigaben und Kontingente wird durch die für <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes und Systemdämonen</a> reservierten CPU-Ressourcen begrenzt.  Die Grenzen der verwendeten CPU-Zeit können jedoch unter Verwendung der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Grenzen der CPU in der Herdspezifikation bestimmt werden</a> .  Kubernetes verwendet das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CFS-Kontingent</a> , um CPU-Grenzwerte für Herdcontainer durchzusetzen. <br><br>  Wenn Sie den CPU-Manager mit einer <i>statischen</i> Richtlinie aktivieren, verwaltet er einen dedizierten Pool von CPUs.  Zu Beginn enthält dieser Pool die gesamte CPU des Rechenknotens.  Wenn Kubelet einen Container im Herd mit einer garantierten Anzahl dedizierter Prozessorkerne erstellt, werden ihm die diesem Container zugewiesenen CPUs für seine Lebensdauer zugewiesen und aus dem gemeinsam genutzten Pool entfernt.  Lasten von den verbleibenden Containern werden von diesen dedizierten Kernen auf andere übertragen. <br><br>  Alle Container ohne dedizierte CPUs ( <i>Burstable</i> , <i>BestEffort</i> und <i>Garantiert mit nicht ganzzahligen CPUs</i> ) werden auf Kerneln ausgeführt, die im gemeinsam genutzten Pool <i>verbleiben</i> .  Wenn ein Container mit dedizierten CPUs nicht mehr funktioniert, kehren seine Kernel zum gemeinsam genutzten Pool zurück. <br><br><h2>  Weitere Details bitte ... </h2><br><img src="https://habrastorage.org/webt/cr/w-/-8/crw--8xnqnkcu8fl18xxbbeyfzk.png"><br><br>  Das obige Diagramm zeigt die Anatomie des CPU-Managers.  Es verwendet die <code>UpdateContainerResources</code> Methode von der Container Runtime Interface (CRI), um die CPUs zu ändern, auf denen die Container ausgeführt werden.  <i>Der Manager vergleicht</i> <code>cgroupfs</code> regelmäßig mit dem aktuellen Status der CPU-Ressourcen für jeden ausgeführten Container. <br><br>  Der CPU-Manager verwendet <a href=""><i>Richtlinien</i></a> , um über die Zuweisung von CPU-Kernen zu entscheiden.  Es sind zwei Richtlinien implementiert: <i>Keine</i> und <i>Statisch</i> .  Ab Kubernetes Version 1.10 wird es standardmäßig mit der Richtlinie <i>Keine</i> aktiviert. <br><br>  Die <i>statische</i> Richtlinie weist der garantierten QoS-Klasse CPU-zugewiesene Pod-Container zu, die eine ganzzahlige Anzahl von Kernen anfordert.  Die <i>statische</i> Richtlinie versucht, die CPU in der besten topologischen Weise und in der folgenden Reihenfolge zu bestimmen: <br><br><ul><li>  Weisen Sie alle CPUs einem Prozessorsockel zu, falls verfügbar, und der Container benötigt eine CPU in Höhe von mindestens einem gesamten CPU-Sockel. </li><li>  Weisen Sie alle logischen CPUs (Hyperthreads) eines physischen CPU-Kerns zu, falls verfügbar, und der Container benötigt eine CPU mit mindestens dem gesamten Kern. </li><li>  Weisen Sie alle verfügbaren logischen CPUs mit einer Präferenz für CPUs aus einem einzelnen Socket zu. </li></ul><br><h2>  Wie verbessert der CPU-Manager die Rechenisolation? </h2><br>  Wenn die <i>statische</i> Richtlinie im CPU-Manager aktiviert ist, können Workloads aus einem der folgenden Gründe eine bessere Leistung erzielen: <br><br><ul><li>  Dedizierte CPUs können einem Container mit einer Workload zugewiesen werden, anderen Containern jedoch nicht.  Diese (anderen) Container verwenden nicht dieselben CPU-Ressourcen.  Infolgedessen erwarten wir eine bessere Leistung aufgrund der Isolation im Falle des Auftretens eines „Angreifers“ <i>(CPU-anspruchsvolle Prozesse - <b>ca. übersetzt</b> )</i> oder einer angrenzenden Arbeitslast. </li><li>  Es gibt weniger Wettbewerb um Ressourcen, die von der Arbeitslast verwendet werden, da wir die CPU durch die Arbeitslast selbst aufteilen können.  Diese Ressourcen können nicht nur die CPU, sondern auch die Cache-Hierarchien und die Speicherbandbreite umfassen.  Dies verbessert die Gesamtleistung der Arbeitslast. </li><li>  Der CPU-Manager weist die CPU in einer topologischen Reihenfolge zu, basierend auf den besten verfügbaren Optionen.  Wenn der gesamte Socket frei ist, werden alle seine CPUs der Arbeitslast zugewiesen.  Dies verbessert die Workload-Leistung aufgrund des fehlenden Datenverkehrs zwischen Sockets. </li><li>  Container in Pods mit <i>garantierter</i> QoS unterliegen dem CFS-Kontingent.  Arbeitslasten, die zu plötzlichen Ausbrüchen neigen, können geplant werden und ihre Quote vor dem Ende ihres zugewiesenen Zeitraums überschreiten, wodurch sie <i>gedrosselt werden</i> .  Die zu diesem Zeitpunkt beteiligten CPUs können sowohl bedeutende als auch wenig nützliche Arbeit leisten.  Solche Container unterliegen jedoch keiner CFS-Drosselung, wenn die Kontingent-CPU durch eine dedizierte CPU-Zuweisungsrichtlinie ergänzt wird. </li></ul><br><h2>  Ok!  Hast du irgendwelche Ergebnisse? </h2><br>  Um die Leistungsverbesserungen und die Isolation zu sehen, die durch die Aufnahme des CPU-Managers in Kubelet erzielt wurden, haben wir Experimente an einem Rechenknoten mit zwei Sockeln (Intel Xeon CPU E5-2680 v3) und aktiviertem Hyperthreading durchgeführt.  Der Knoten besteht aus 48 logischen CPUs (24 physische Kerne mit jeweils Hyperthreading).  Die Leistungs- und Isolationsvorteile des CPU-Managers, die durch Benchmark- und reale Workloads in drei verschiedenen Szenarien erfasst werden, sind nachstehend aufgeführt. <br><br><h3>  Wie interpretiere ich Diagramme? </h3><br>  Für jedes Szenario werden Diagramme angezeigt ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Span-Diagramme</a> , Box-Plots), die die normalisierte Ausführungszeit und ihre Variabilität beim Starten eines Benchmarks oder einer realen Last bei ein- und ausgeschaltetem CPU-Manager veranschaulichen.  Die Laufzeit wird auf die Starts mit der besten Leistung normalisiert (1,00 auf der Y-Achse steht für die beste Startzeit: Je niedriger der Wert des Diagramms, desto besser).  Die Höhe des Diagramms in der Grafik zeigt die Variabilität der Leistung.  Wenn es sich bei der Site beispielsweise um eine Linie handelt, gibt es bei diesen Starts keine Leistungsunterschiede.  In diesen Bereichen selbst ist die Mittellinie der Median, die Oberseite das 75. Perzentil und die Unterseite das 25. Perzentil.  Die Höhe des Diagramms (d. H. Die Differenz zwischen dem 75. und dem 25. Perzentil) ist als Interquartilbereich (IQR) definiert.  "Moustache" zeigt Daten außerhalb dieses Intervalls und Punkte zeigen Ausreißer.  Emissionen sind alle Daten, die sich 1,5-mal vom IQR unterscheiden - weniger oder mehr als das entsprechende Quartil.  Jedes Experiment wurde 10 Mal durchgeführt. <br><br><h3>  Aggressiver Schutz </h3><br>  Wir haben sechs Benchmark'ov aus einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Reihe von PARSEC</a> (Workloads - "Opfer") gestartet <i>[mehr über Workloads von Opfern finden Sie beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> - <b>ca.</b></i>  <i><b>perev.</b></i>  <i>]</i> neben dem Container, der die CPU lädt ("Aggressor" -Arbeitslast), während der CPU-Manager ein- und ausgeschaltet ist. <br><br>  Der Aggressor-Container wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wie unter</a> mit der <i>Burstable</i> QoS-Klasse gestartet, die 23 CPU-Flag <code>--cpus 48</code> .  Benchmarks werden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">als Pods</a> mit der Klasse " <i>Garantierte</i> QoS" ausgeführt, für die ein Satz CPUs von einem vollen Socket (d. H. 24 CPUs auf diesem System) erforderlich ist.  Die folgenden Grafiken zeigen die normalisierte Startzeit des Pods mit einem Benchmark neben dem Pod-Angreifer, mit <i>statischer</i> CPU-Manager-Richtlinie und ohne diesen.  In allen Testfällen können Sie bei aktivierter Richtlinie eine verbesserte Leistung und eine geringere Leistungsvariabilität feststellen. <br><br><img src="https://habrastorage.org/webt/tb/aj/gu/tbajgurqlbubtzm3il4d9vzoh8i.png"><br><br><h3>  Isolierung für benachbarte Lasten </h3><br>  Dies zeigt, wie nützlich der CPU-Manager für viele am selben Standort befindliche Workloads sein kann.  Die folgenden Span-Diagramme zeigen die Leistung von zwei Benchmarks aus dem PARSEC-Satz ( <i>Blackscholes</i> und <i>Canneal</i> ), die für die <i>nebeneinander liegenden</i> QoS-Klassen <i>Garantiert</i> (Gu) und <i>Burstable</i> (Bu) gestartet wurden, wobei die <i>statische</i> Richtlinie <i>aktiviert</i> und <i>deaktiviert ist</i> . <br><br>  <i>Ausgehend</i> von der Grafik oben links im Uhrzeigersinn sehen wir die Leistung von <i>Blackscholes</i> für Bu QoS (oben links), <i>Canneal</i> für Bu QoS (oben rechts), <i>Canneal</i> für Gu QoS (unten rechts) und <i>Blackscholes</i> für Gu QoS (unten links).  In jedem Diagramm befinden sie sich (wieder im Uhrzeigersinn) zusammen mit <i>Canneal</i> für Gu QoS (oben links), <i>Blackscholes</i> für Gu QoS (oben rechts), <i>Blackscholes</i> für Bu QoS (unten rechts) und <i>Canneal</i> für Bu QoS (unten links). entsprechend.  Das <i>Bu-blackscholes-Gu-canneal-Diagramm</i> (oben links) zeigt beispielsweise die Leistung von <i>Blackscholes,</i> die mit Bu QoS ausgeführt werden und sich neben <i>Canneal</i> mit der Gu QoS-Klasse befinden.  In jedem Fall erfordert unter mit der Klasse Gu QoS ein vollständiger Socket-Kern (d. H. 24 CPUs) und unter mit der Klasse Bu QoS - 23 CPUs. <br><br>  In allen Tests gibt es für beide benachbarten Workloads eine bessere Leistung und weniger Leistungsschwankungen.  Schauen Sie sich zum Beispiel <i>Bu-blackscholes-Gu-canneal</i> (oben links) und <i>Gu-canneal-Bu-blackscholes</i> (unten rechts) an.  Sie zeigen die Leistung von <i>Blackscholes</i> und <i>Canneal</i> bei <i>ein-</i> und <i>ausgeschaltetem</i> CPU-Manager.  In diesem Fall empfängt <i>Canneal</i> mehr dedizierte Kerne vom CPU-Manager, da es zur Gu QoS-Klasse gehört und eine ganzzahlige Anzahl von CPU-Kernen anfordert.  <i>Blackscholes</i> erhält jedoch auch einen dedizierten Satz von CPUs, da dies die einzige Arbeitslast im gemeinsam genutzten Pool ist.  Infolgedessen nutzen sowohl <i>Blackscholes</i> als auch <i>Canneal</i> die <i>Lastisolation</i> bei Verwendung von CPU Manager. <br><br><img src="https://habrastorage.org/webt/et/wj/93/etwj93f4gv4pbjyoq8-6_nfmtmm.png"><br><br><h3>  Isolierung für freistehende Lasten </h3><br>  Es zeigt, wie nützlich CPU Manager für eigenständige Workloads aus dem realen Leben sein kann.  Wir haben zwei Ladungen von den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offiziellen TensorFlow-Modellen genommen</a> : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">breit und tief</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ResNet</a> .  Für sie werden typische Datensätze verwendet (Volkszählung bzw. CIFAR10).  In beiden Fällen benötigen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Herde</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">breit und tief</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ResNet</a> ) 24 CPUs, was einem vollen Sockel entspricht.  Wie in den Diagrammen gezeigt, bietet der CPU-Manager in beiden Fällen eine bessere Isolation. <br><br><img src="https://habrastorage.org/webt/ln/hv/a6/lnhva6g-1coouyustgjq-ziwybk.png"><br><br><h2>  Einschränkungen </h2><br>  Benutzer möchten möglicherweise CPUs auf einem Socket in der Nähe des Busses zuweisen lassen, der mit einem externen Gerät wie einem Beschleuniger oder einer Hochleistungsnetzwerkkarte verbunden ist, um Datenverkehr zwischen Sockets zu vermeiden.  Diese Art der Konfiguration wird im CPU-Manager noch nicht unterstützt.  Da der CPU-Manager die bestmögliche Zuordnung von CPUs bietet, die zu einem Socket oder physischen Kern gehören, reagiert er empfindlich auf Extremfälle und kann zu Fragmentierung führen.  Der CPU-Manager berücksichtigt den Boot-Parameter des <code>isolcpus</code> Linux-Kernels nicht, obwohl er in einigen Fällen als gängige Praxis verwendet wird <i>(weitere Einzelheiten zu diesem Parameter finden Sie beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> - <b>ca. Transl.</b> )</i> . <br><br><h2>  PS vom Übersetzer </h2><br>  Lesen Sie auch in unserem Blog: <br><br><ul><li>  „Was passiert in Kubernetes, wenn der Kubectl-Lauf startet?“: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 1</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 2</a> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wie funktioniert der Kubernetes-Scheduler tatsächlich?"</a>  "; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes: Das Leben des Herdes</a> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CRI-O - eine Alternative zu Docker zum Starten von Containern in Kubernetes</a> "; </li><li>  „ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Unsere Erfahrung mit Kubernetes in kleinen Projekten</a> “ <i>(Videobericht, der eine Einführung in das technische Gerät von Kubernetes enthält);</i> </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Infrastruktur mit Kubernetes als erschwinglichem Service</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de418269/">https://habr.com/ru/post/de418269/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de418257/index.html">Github.com weigert sich, jQuery zu verwenden und wechselt zu reinem JavaScript</a></li>
<li><a href="../de418261/index.html">Selbst gemachter Elektroschockerhandschuh - eine Waffe für einen Geek</a></li>
<li><a href="../de418263/index.html">Russische Wissenschaftler entwickeln ein kompaktes und billiges MEG-System</a></li>
<li><a href="../de418265/index.html">Organisation der Netzwerkinteraktion zwischen physischen und virtuellen Maschinen</a></li>
<li><a href="../de418267/index.html">August IT Events Digest</a></li>
<li><a href="../de418271/index.html">Brechen Sie eine Linie durch ein Trennzeichen. Ein wenig über CONNECT BY</a></li>
<li><a href="../de418273/index.html">Entwicklungswerkzeuge für die Baikal-T1-Plattform wurden auf die russische Distribution ALT umgestellt</a></li>
<li><a href="../de418275/index.html">3D-Druckunterricht. Drucken dünnwandiger Modelle aus 3Dtool</a></li>
<li><a href="../de418277/index.html">Box-Shadows-Gerät</a></li>
<li><a href="../de418279/index.html">Zurücksetzen des Kennworts auf dem Cisco ASA ohne Ausfallzeit für die Aktiv / Standby-Failover-Verbindung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
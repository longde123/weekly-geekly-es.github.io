<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîª üëÉ üëéüèº Postgres-Tuesday # 5: ‚ÄúPostgreSQL und Kubernetes. CI / CD. Testautomatisierung ¬ª üë©üèº‚Äçüç≥ ü§òüèæ üôèüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ende letzten Jahres fand eine weitere Live-√úbertragung der russischen PostgreSQL-Community #RuPostgres statt , bei der der Mitbegr√ºnder Nikolai Samokh...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Postgres-Tuesday # 5: ‚ÄúPostgreSQL und Kubernetes. CI / CD. Testautomatisierung ¬ª</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/479438/"><img src="https://habrastorage.org/webt/qm/rm/ln/qmrmlnm8gjj_8gih4dzhy2ybrvy.jpeg"><br><br>  Ende letzten Jahres fand eine weitere Live-√úbertragung der russischen PostgreSQL-Community <a href="https://www.meetup.com/postgresqlrussia/">#RuPostgres statt</a> , bei der der Mitbegr√ºnder Nikolai Samokhvalov im Rahmen von Kubernetes mit dem technischen Direktor von Flanta, Dmitry Stolyarov, √ºber dieses DBMS sprach. <br><br>  Wir ver√∂ffentlichen eine Abschrift des Hauptteils dieser Diskussion. Ein vollst√§ndiges Video wurde <a href="https://www.youtube.com/channel/UC0SBGSNmBLrTZIkbN-lJHnw">auf dem YouTube-Kanal der Community ver√∂ffentlicht</a> : <a name="habracut"></a><br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/qXc9VTr4TFc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Datenbanken und Kubernetes </h2><br>  <i><b>NS</b> : Wir werden heute nicht √ºber VACUUM und CHECKPOINTs sprechen.</i>  <i>Wir wollen √ºber Kubernetes sprechen.</i>  <i>Ich wei√ü, dass Sie langj√§hrige Erfahrung haben.</i>  <i>Ich habe mir deine Videos angesehen und sogar einige davon angesehen ... Lass uns gleich zum Steinbruch gehen: Warum ist Postgres oder MySQL √ºberhaupt in K8s?</i> <br><br>  <b>DS</b> : Es gibt keine einzige Antwort auf diese Frage und es kann auch nicht sein.  Aber im Allgemeinen ist es Einfachheit und Bequemlichkeit ... Potenzial.  Schlie√ülich m√∂chte jeder Managed Services. <br><br>  <i><b>NS</b> : <a href="https://aws.amazon.com/rds/">RDS</a> nur zu Hause m√∂gen?</i> <br><br>  <b>DS</b> : Ja, um RDS zu m√∂gen, nur √ºberall. <br><br>  <i><b>NS</b> : "√úberall" ist ein guter Punkt.</i>  <i>In gro√üen Unternehmen befindet sich alles an verschiedenen Orten.</i>  <i>Und warum dann, wenn dies ein gro√ües Unternehmen ist, keine fertige L√∂sung nehmen?</i>  <i>Zum Beispiel hat Nutanix eigene Entwicklungen, andere Unternehmen (VMware ...) haben das gleiche "RDS, nur zu Hause".</i> <br><br>  <b>DS</b> : Es handelt sich jedoch um eine einzelne Implementierung, die nur unter bestimmten Bedingungen funktioniert.  Und wenn wir √ºber Kubernetes sprechen, dann gibt es eine Vielzahl von Infrastrukturen (die in K8s vorhanden sein k√∂nnen).  Dies ist im Wesentlichen der Standard f√ºr die API zur Cloud ... <br><br>  <i><b>NS</b> : Es ist auch kostenlos!</i> <br><br>  <b>DS</b> : Das ist nicht so wichtig.  Kostenlos ist f√ºr ein sehr gro√ües Marktsegment nicht wichtig.  Eine andere Sache ist wichtig ... Sie erinnern sich wahrscheinlich an den Bericht " <a href="https://habr.com/ru/company/flant/blog/431500/">Datenbanken und Kubernetes</a> "? <br><br>  <i><b>NS</b> : Ja.</i> <br><br>  <b>DS</b> : Mir wurde klar, dass er sehr vieldeutig wahrgenommen wurde.  Einige Leute dachten, dass ich sagte: "Leute, alle Datenbanken gingen an Kubernetes!", W√§hrend andere entschieden, dass sie alle schreckliche Fahrr√§der waren.  Und ich wollte noch etwas ganz anderes sagen: ‚ÄûSchau, was passiert, was sind die Probleme und wie k√∂nnen sie gel√∂st werden.  Gehen jetzt St√ºtzpunkte in Kubernetes?  Produktion?  Nun, nur wenn du es liebst ... bestimmte Dinge zu tun.  Aber f√ºr Entwickler kann ich sagen, dass ich es empfehle.  F√ºr Entwickler ist das dynamische Erstellen / L√∂schen von Umgebungen sehr wichtig. ‚Äú <br><br>  <i>NS: Mit dev meinen Sie alle Umgebungen, die nicht prod sind?</i>  <i>Inszenierung, QA ...</i> <br><br>  <b>DS</b> : Wenn wir √ºber Perf-St√§nde sprechen, dann wahrscheinlich nicht schon, weil die Anforderungen dort spezifisch sind.  Wenn es sich um spezielle F√§lle handelt, in denen Staging eine sehr gro√üe Datenbank ben√∂tigt, dann wahrscheinlich auch nicht ... Wenn dies eine statische, langlebige Umgebung ist, was ist dann der Vorteil, wenn sich die Basis in K8s befindet? <br><br>  <i><b>NS</b> : Keine.</i>  <i>Aber wo sehen wir statische Umgebungen?</i>  <i>Die statische Umgebung ist morgen veraltet.</i> <br><br>  <b>DS</b> : Staging kann statisch sein.  Wir haben Kunden ... <br><br>  <i><b>NS</b> : Ja, das habe ich auch.</i>  <i>Das gro√üe Problem ist, wenn Sie eine Basis von 10 TB und Staging haben - 200 GB ...</i> <br><br>  <b>DS</b> : Ich habe einen sehr coolen Fall!  Bei der Inszenierung gibt es eine prod'ovy Basis, in der √Ñnderungen vorgenommen werden.  Und ein Knopf steht zur Verf√ºgung: "Roll out to Production".  Diese √Ñnderungen - Deltas - werden in der Produktion hinzugef√ºgt (anscheinend werden sie nur durch APIs synchronisiert).  Dies ist eine sehr exotische Option. <br><br>  <i><b>NS</b> : Ich habe Startups im Tal gesehen, die noch in RDS oder sogar in Heroku sitzen - das sind Geschichten von vor zwei bis drei Jahren - und sie haben den Dump auf ihren Laptop heruntergeladen.</i>  <i>Weil die Basis bisher nur 80 GB hat und es einen Platz auf dem Laptop gibt.</i>  <i>Dann kaufen sie f√ºr jeden Platten, damit sie 3 Basen haben, damit sie unterschiedliche Entwicklungen durchf√ºhren k√∂nnen.</i>  <i>Das passiert auch.</i>  <i>Ich habe auch gesehen, dass sie keine Angst haben, Produkte in die Inszenierung zu kopieren - es h√§ngt sehr stark von der Firma ab.</i>  <i>Aber er sah, dass sie gro√üe Angst hatten und oft nicht genug Zeit und H√§nde hatten.</i>  <i>Bevor wir jedoch zu diesem Thema √ºbergehen, m√∂chte ich etwas √ºber Kubernetes erfahren.</i>  <i>Ich verstehe richtig, dass in prod'e bisher niemand?</i> <br><br>  <b>DS</b> : Wir haben kleine Basen in prod.  Wir sprechen von Dutzenden von Gigabyte und nicht kritischen Diensten, f√ºr die es zu tr√§ge war, Replikate zu erstellen (und es gibt keinen solchen Bedarf).  Und sofern es unter Kubernetes einen normalen Speicher gibt.  Diese Datenbank arbeitete in einer virtuellen Maschine - bedingt in VMware, zus√§tzlich zum Speicher.  Wir haben es in <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">PV gelegt</a> und jetzt k√∂nnen wir es von Auto zu Auto √ºbertragen. <br><br>  <i><b>NS</b> : Basen dieser Gr√∂√üe, bis zu 100 GB, auf guten Festplatten und mit einem guten Netzwerk k√∂nnen in wenigen Minuten bereitgestellt werden, oder?</i>  <i>Eine Geschwindigkeit von 1 GB pro Sekunde ist nicht l√§nger exotisch.</i> <br><br>  <b>DS</b> : Ja, f√ºr eine lineare Operation ist dies kein Problem. <br><br>  <i><b>NS</b> : Okay, wir sollten nur √ºber Produkte nachdenken.</i>  <i>Und wenn wir Kubernetes f√ºr Non-Prod-Umgebungen in Betracht ziehen - wie geht das?</i>  <i>Ich sehe, dass sie in Zalando <a href="https://github.com/zalando/postgres-operator">einen Operator herstellen</a> , in Crunchy <a href="https://github.com/CrunchyData/postgres-operator">s√§gen sie</a> , es gibt einige andere Optionen.</i>  <i>Und da ist <a href="https://ongres.com/">OnGres</a> - das ist unser guter Freund Alvaro aus Spanien: Sie sind im Grunde nicht nur ein <a href="https://habr.com/ru/company/flant/blog/326414/">Operator</a> , sondern eine ganze Distribution ( <a href="https://gitlab.com/ongresinc/stackgres">StackGres</a> ), in der sie neben Postgres selbst auch beschlossen haben, das Backup, den Envoy-Proxy ...</i> <br><br>  <b>DS</b> : Gesandter f√ºr was?  Postgres Verkehrsbilanzierung genau? <br><br>  <i><b>NS</b> : Ja.</i>  <i>Das hei√üt, sie sehen es als: Wenn Sie die Linux-Distribution und den Kernel nehmen, dann ist der √ºbliche PostgreSQL-Kernel und sie wollen eine Distribution erstellen, die Cloud-freundlich ist und auf Kubernetes l√§uft.</i>  <i>Sie docken Komponenten (Backups usw.) an und debuggen, damit sie gut funktionieren.</i> <br><br>  <b>DS</b> : Sehr cool!  Im Wesentlichen ist es eine Software, mit der Sie Ihre verwalteten Postgres erstellen k√∂nnen. <br><br>  <i><b>NS</b> : Linux-Distributionen haben ewige Probleme: Wie werden Treiber erstellt, damit die gesamte Hardware unterst√ºtzt wird?</i>  <i>Und sie haben die Idee, bei Kubernetes zu arbeiten.</i>  <i>Ich wei√ü, dass wir im Zalando-Operator k√ºrzlich die Aug√§pfel auf AWS gesehen haben und das ist nicht sehr gut.</i>  <i>Es sollte keine Bindung an eine bestimmte Infrastruktur geben - worum geht es dann?</i> <br><br>  <b>DS</b> : Ich wei√ü nicht, in welcher konkreten Situation Zalando involviert war, aber in Kubernetes wird der Speicher nun so erstellt, dass es unm√∂glich ist, ein Festplatten-Backup auf generische Weise zu entfernen.  K√ºrzlich hat der Standard - in der neuesten Version <a href="https://habr.com/ru/company/flant/blog/465417/">der CSI-Spezifikation</a> - die M√∂glichkeit von Snapshots geschaffen, aber wo ist er implementiert?  Ehrlich gesagt, es ist immer noch so rau ... Wir testen CSI auf AWS, GCE, Azure, vSphere, aber wir beginnen, es ein wenig zu verwenden, da Sie sehen, dass es noch nicht fertig ist. <br><br>  <i><b>NS</b> : Deshalb muss man sich manchmal an die Infrastruktur binden.</i>  <i>Ich denke, dies ist noch ein fr√ºhes Stadium - Wachstumsprobleme.</i>  <i>Frage: Was w√ºrden Sie Anf√§ngern empfehlen, die PgSQL in K8s ausprobieren m√∂chten?</i>  <i>Welcher Betreiber vielleicht?</i> <br><br>  <b>DS</b> : Das Problem ist, dass Postgres f√ºr uns 3% betr√§gt.  Wir haben immer noch eine sehr gro√üe Liste verschiedener Software in Kubernetes, ich werde nicht einmal alles auflisten.  Zum Beispiel Elasticsearch.  Es gibt viele Betreiber: Einige entwickeln sich aktiv, andere nicht.  F√ºr uns selbst haben wir Anforderungen gestellt, die im Betreiber liegen sollten, damit wir ihn ernst nehmen.  Der Operator ist speziell f√ºr Kubernetes - nicht der "Operator, der unter Amazon-Bedingungen etwas unternimmt ..." Tats√§chlich verwenden wir einen einzigen Operator (= f√ºr fast alle Clients) - <a href="https://github.com/spotahome/redis-operator">f√ºr Redis</a> <i>(wir werden in K√ºrze einen Artikel dar√ºber ver√∂ffentlichen)</i> . <br><br>  <i><b>NS</b> : Aber auch f√ºr MySQL?</i>  <i>Ich wei√ü, dass Percona ... da sie jetzt in MySQL, MongoDB und Postgres involviert sind, m√ºssen sie eine Art universelles Problem beheben: f√ºr alle Datenbanken, f√ºr alle Cloud-Anbieter.</i> <br><br>  <b>DS</b> : Wir hatten keine Zeit, uns die Anweisungen f√ºr MySQL anzuschauen.  F√ºr uns steht dies derzeit nicht im Vordergrund.  MySQL funktioniert gut in Standalone.  Warum ein Operator, wenn Sie nur die Datenbank starten k√∂nnen? Sie k√∂nnen den Docker-Container mit Postrges oder auf einfache Weise starten. <br><br>  <i><b>NS</b> : Das war auch eine Frage.</i>  <i>Kein Operator?</i> <br><br>  <b>DS</b> : Ja, 100% von uns haben PostgreSQL ohne Operator.  So weit so.  Wir verwenden den Operator aktiv f√ºr Prometheus, f√ºr Redis.  Wir haben vor, einen Operator f√ºr Elasticsearch zu finden - er brennt am meisten, weil wir ihn in Kubernetes in 100% der F√§lle installieren wollen.  So wie wir sicherstellen wollen, dass MongoDB immer auch in Kubernetes installiert ist.  Bestimmte Merkzettel erscheinen hier - es besteht das Gef√ºhl, dass in diesen F√§llen etwas getan werden kann.  Und √ºber Postgres haben wir nicht mal geschaut.  Nat√ºrlich wissen wir √ºber die Existenz verschiedener Optionen Bescheid, aber in der Tat haben wir Standalone. <br><br><h2>  Testen der Datenbank in Kubernetes </h2><br>  <i><b>NS</b> : Kommen wir zum Thema Testen.</i>  <i>So rollen Sie √Ñnderungen in der Datenbank aus - aus Sicht von DevOps.</i>  <i>Es gibt Microservices, viele Datenbanken, die ganze Zeit √§ndert sich irgendwo etwas.</i>  <i>So stellen Sie sicher, dass die normale CI / CD von der DBMS-Position aus in Ordnung ist.</i>  <i>Was ist dein Ansatz?</i> <br><br>  <b>DS</b> : Es kann keine Antwort geben.  Es gibt verschiedene M√∂glichkeiten.  Der erste ist die Gr√∂√üe der Basis, die wir ausrollen m√∂chten.  Sie selbst haben erw√§hnt, dass Unternehmen eine andere Einstellung dazu haben, eine Kopie des Produkts auf der Basis von Entwickler und B√ºhne zu haben. <br><br>  <i><b>NS</b> : Und was die DSGVO angeht, denke ich, dass sie immer ordentlicher werden ... Ich kann sagen, dass sie in Europa bereits angefangen haben, in Ordnung zu kommen.</i> <br><br>  <b>DS</b> : Aber Sie k√∂nnen oft Software schreiben, die die Produktion auslagert und verschleiert.  Es stellt sich heraus, prod'ovye Daten (Snapshot, Dump, Bin√§rkopie ...), aber sie sind anonym.  Stattdessen kann es Generierungsskripte geben: Fixtures oder nur ein Skript, das eine gro√üe Datenbank generiert.  Das Problem ist, was: Wie lange dauert es, bis das Basisimage erstellt ist?  Und wie viel Zeit ist f√ºr die Bereitstellung in der richtigen Umgebung erforderlich? <br><br>  Wir sind zum Schema gekommen: Wenn der Client einen Fixture-Datensatz (minimale Version der Datenbank) hat, dann verwenden wir diese standardm√§√üig.  Wenn es sich um √úberpr√ºfungsumgebungen handelt, haben wir beim Erstellen einer Verzweigung eine Anwendungsinstanz implementiert - wir rollen dort eine kleine Datenbank aus.  Aber die <a href="https://habr.com/ru/company/flant/blog/417509/">Option hat</a> sich als gut erwiesen, wenn wir den Dump einmal t√§glich (nachts) aus der Produktion entfernen und anhand dieser geladenen Daten einen Docker-Container mit PostgreSQL und MySQL sammeln.  Wenn Sie die Basis 50-mal von diesem Image aus bereitstellen m√ºssen, ist dies recht einfach und schnell. <br><br>  <i><b>NS</b> : Einfaches Kopieren?</i> <br><br>  <b>DS</b> : Daten werden direkt im Docker-Image gespeichert.  Das hei√üt  Wir haben ein fertiges Image, wenn auch 100 GB.  Dank der Ebenen in Docker k√∂nnen wir dieses Image so oft wie n√∂tig schnell bereitstellen.  Die Methode ist dumm, aber sie funktioniert ziemlich gut. <br><br>  <i><b>NS</b> : Au√üerdem √§ndert es sich beim Testen direkt im Docker, oder?</i>  <i>Copy-on-Write in Docker - werfen Sie es weg und gehen Sie noch einmal, alles ist in Ordnung.</i>  <i>Klasse!</i>  <i>Und Sie verwenden es bereits mit Macht und Hauptsache?</i> <br><br>  <b>DS</b> : F√ºr eine lange Zeit. <br><br>  <i><b>NS</b> : Wir machen sehr √§hnliche Dinge.</i>  <i>Nur verwenden wir nicht Dockers Copy-on-Write, sondern einige mehr.</i> <br><br>  <b>JS</b> : Er ist nicht generisch.  Und Docker'ny arbeitet √ºberall. <br><br>  <i><b>NS</b> : Theoretisch ja.</i>  <i>Wir haben dort aber auch Module, Sie k√∂nnen verschiedene Module erstellen und mit verschiedenen Dateisystemen arbeiten.</i>  <i>Was f√ºr ein moment</i>  <i>Von Postgres aus sehen wir das alles anders.</i>  <i>Jetzt schaute ich von der Seite von Docker und sah, dass alles f√ºr Sie funktioniert.</i>  <i>Aber wenn die Datenbank riesig ist, zum Beispiel 1 TB, dann ist das alles lang: sowohl Operationen nachts als auch alles in Docker stopfen ... Und wenn 5 TB in Docker stopfen ... Oder ist alles normal?</i> <br><br>  <b>DS</b> : Welchen Unterschied macht es: Es sind Blobs, nur Bits und Bytes. <br><br>  <i><b>NS</b> : Der Unterschied ist: Tun Sie dies durch Dump und Restore?</i> <br><br>  <b>DS</b> : <b>√úberhaupt</b> nicht notwendig.  Die Methoden zum Generieren dieses Bildes k√∂nnen unterschiedlich sein. <br><br>  <i><b>NS</b> : F√ºr einige Kunden haben wir es so gestaltet, dass wir nicht regelm√§√üig ein Basisimage generieren, sondern es st√§ndig auf dem neuesten Stand halten.</i>  <i>Es handelt sich im Wesentlichen um eine Replik, die Daten werden jedoch nicht direkt vom Master, sondern √ºber das Archiv empfangen.</i>  <i>Im Bin√§rarchiv, in dem die WALs jeden Tag gerollt werden, werden auch Backups entfernt ... Diese WALs fliegen dann - mit einer leichten Verz√∂gerung (im wahrsten Sinne des Wortes 1-2 Sekunden) - zum Basisimage.</i>  <i>Wir klonen es auf irgendeine Weise - jetzt haben wir standardm√§√üig ZFS.</i> <br><br>  <b>DS</b> : Mit ZFS sind Sie jedoch auf einen Knoten beschr√§nkt. <br><br>  <i><b>NS</b> : Ja.</i>  <i>ZFS hat aber auch ein magisches <a href="https://docs.oracle.com/cd/E18752_01/html/819-5461/gbchx.html">Send</a> : Sie k√∂nnen damit einen Schnappschuss senden und sogar (ich habe es noch nicht wirklich getestet, aber ...) ein Delta zwischen zwei <code>PGDATA</code> .</i>  <i>Tats√§chlich haben wir ein anderes Werkzeug, das wir f√ºr solche Aufgaben nicht besonders in Betracht gezogen haben.</i>  <i>In PostgreSQL gibt es <a href="https://www.postgresql.org/docs/12/app-pgrewind.html">pg_rewind</a> , das als "intelligentes" rsync funktioniert und viele Dinge √ºberspringt, die Sie nicht beobachten m√ºssen, da sich dort mit Sicherheit nichts ge√§ndert hat.</i>  <i>Wir k√∂nnen eine schnelle Synchronisation zwischen den beiden Servern durchf√ºhren und genauso zur√ºckspulen.</i> <br><br>  <i>Also versuchen wir, mehr DBA'noy als bisher, ein Tool zu entwickeln, mit dem Sie das Gleiche tun k√∂nnen, was Sie gesagt haben: Wir haben eine Basis, aber wir m√∂chten etwas 50 Mal testen, fast zur gleichen Zeit.</i> <br><br>  <b>DS</b> : 50-mal bedeutet, dass Sie 50 Spot-Instanzen bestellen m√ºssen. <br><br>  <i><b>NS</b> : Nein, wir machen alles auf einer Maschine.</i> <br><br>  <b>DS</b> : Aber wie k√∂nnen Sie 50-mal bereitstellen, wenn diese eine Basis beispielsweise ein Terabyte ist?  Ben√∂tigt sie h√∂chstwahrscheinlich bedingt 256 GB RAM? <br><br>  <i><b>NS</b> : Ja, manchmal wird viel Speicher ben√∂tigt - das ist normal.</i>  <i>Aber ein solches Beispiel aus dem Leben.</i>  <i>Die Produktionsmaschine hat 96 Kerne und 600 GB.</i>  <i>Gleichzeitig werden 32 Kerne f√ºr die Datenbank verwendet (manchmal werden jetzt sogar 16 Kerne verwendet) und 100-120 GB Arbeitsspeicher.</i> <br><br>  <b>DS</b> : Und 50 Exemplare kommen da rein? <br><br>  <i><b>NS</b> : Also gibt es nur eine Kopie, dann funktioniert Copy-on-Write (ZFS'ny) ... ich erz√§hle dir mehr.</i> <br><br>  <i>Zum Beispiel haben wir eine Basis von 10 TB.</i>  <i>Sie machten eine Scheibe daf√ºr, ZFS dr√ºckte immer noch seine prozentuale Gr√∂√üe um 30-40.</i>  <i>Da wir keine Lasttests durchf√ºhren, spielt die genaue Reaktionszeit f√ºr uns keine Rolle: Lassen Sie es bis zu 2-mal langsamer sein - das ist in Ordnung.</i> <br><br>  <i>Wir erm√∂glichen Programmierern, QA, DBA usw.</i>  <i>F√ºhren Sie Tests in 1-2 Threads durch.</i>  <i>Zum Beispiel k√∂nnen sie eine Art Migration starten.</i>  <i>Es werden nicht 10 Kerne gleichzeitig ben√∂tigt - es wird 1 Postgres-Backend und 1 Kern ben√∂tigt.</i>  <i>Die Migration wird gestartet - m√∂glicherweise <a href="https://www.postgresql.org/docs/12/routine-vacuuming.html">startet das automatische Vakuum immer</a> noch, dann wird der zweite Kern aktiviert.</i>  <i>Wir haben 16-32 Kerne zugewiesen, so dass 10 Personen gleichzeitig arbeiten k√∂nnen, es gibt keine Probleme.</i> <br><br>  <i>Da <code>PGDATA</code> physikalisch identisch ist, stellt sich heraus, dass wir tats√§chlich Postgres zum Narren halten.</i>  <i>Der Trick ist folgender: Es werden beispielsweise 10 Postgres gleichzeitig gestartet.</i>  <i>Welches Problem ist in der Regel was?</i>  <i>Sie <a href="https://www.postgresql.org/docs/current/runtime-config-resource.html">setzen shared_buffer</a> auf 25%.</i>  <i>Das sind dementsprechend 200 GB.</i>  <i>Sie werden nicht mehr als drei davon starten, da die Erinnerung enden wird.</i> <br><br>  <i>Irgendwann stellten wir jedoch fest, dass dies nicht notwendig war: Wir setzten shared_buffer auf 2 GB.</i>  <i>PostgreSQL hat <a href="https://www.postgresql.org/docs/current/runtime-config-query.html">effective_cache_size</a> und betrifft in Wirklichkeit nur <a href="https://en.wikipedia.org/wiki/Query_plan">Pl√§ne</a> .</i>  <i>Wir setzen es bei 0,5 Tb.</i>  <i>Und es ist nicht einmal wichtig, dass sie nicht wirklich da sind: Er macht Pl√§ne, als ob sie es w√§ren.</i> <br><br>  <i>Wenn wir also eine Art Migration testen, k√∂nnen wir alle Pl√§ne sammeln - wir werden sehen, wie es in der Produktion passieren wird.</i>  <i>Die Sekunden dort sind unterschiedlich (langsamer), aber die Daten, die wir tats√§chlich lesen, und die Pl√§ne selbst (welche Art von JOINs usw.) werden genauso erhalten wie bei der Produktion.</i>  <i>Parallel dazu k√∂nnen Sie viele dieser √úberpr√ºfungen auf einem Computer ausf√ºhren.</i> <br><br>  <b>DS</b> : Glaubst du, dass es mehrere Probleme gibt?  Die erste ist eine L√∂sung, die nur unter PostgreSQL funktioniert.  Dieser Ansatz ist sehr privat, er ist nicht generisch.  Das zweite - Kubernetes (und das ist, wohin die Wolke jetzt geht) bezieht viele Knoten mit ein, und diese Knoten sind kurzlebig.  Und in Ihrem Fall ist es ein zustandsbehafteter, best√§ndiger Knoten.  Diese Dinge widersprechen mir. <br><br>  <i><b>NS</b> : Erstens - ich stimme zu, das ist eine reine Postgres-Geschichte.</i>  <i>Ich denke, wenn wir irgendeine direkte Eingabe und einen Pufferpool f√ºr fast den gesamten Speicher haben, wird dieser Ansatz nicht funktionieren - es wird unterschiedliche Pl√§ne geben.</i>  <i>Momentan arbeiten wir jedoch nur mit Postgres, wir denken nicht an andere.</i> <br><br>  <i>√úber Kubernetes.</i>  <i>Sie selbst sagen immer, dass wir eine best√§ndige Basis haben.</i>  <i>Wenn die Instanz abst√ºrzt, m√ºssen Sie zun√§chst die Festplatte sichern.</i>  <i>Hier haben wir auch die gesamte Plattform in Kubernetes, und die Komponente mit Postgres ist separat (obwohl sie eines Tages dort sein wird).</i>  <i>Daher ist alles so: Die Instanz ist abgest√ºrzt, aber wir haben die PV gespeichert und nur eine Verbindung zu einer anderen (neuen) Instanz hergestellt, als w√§re nichts passiert.</i> <br><br>  <b>DS</b> : Aus meiner Sicht erstellen wir Pods in Kubernetes.  K8s - elastisch: Bauteile werden bei Bedarf einzeln bestellt.  Die Aufgabe besteht darin, einfach einen Pod zu erstellen und zu sagen, dass er X-Ressourcen ben√∂tigt, und dann wird K8s es herausfinden.  Die Speicherunterst√ºtzung in Kubernetes ist jedoch immer noch instabil: In <a href="https://habr.com/ru/company/flant/blog/467477/">1.16</a> , <a href="https://habr.com/ru/company/flant/blog/476998/">1.17</a> (diese Version wurde vor <i>Wochen</i> ver√∂ffentlicht), werden diese Funktionen nur als Beta-Versionen angeboten. <br><br>  Sechs Monate oder ein Jahr vergehen - es wird mehr oder weniger stabil oder zumindest als solches deklariert.  Dann l√∂st die M√∂glichkeit von Snapshots und Resize'a Ihr Problem bereits vollst√§ndig.  Weil du eine Basis hast.  Ja, es ist m√∂glicherweise nicht sehr schnell, aber die Geschwindigkeit h√§ngt davon ab, was sich unter der Haube befindet, da einige Implementierungen auf der Ebene des Festplattensubsystems kopieren und beim Schreiben kopiert werden k√∂nnen. <br><br>  <i><b>NS</b> : Es ist auch erforderlich, dass alle Engines (Amazon, Google ...) diese Version unterst√ºtzen - es dauert auch einige Zeit.</i> <br><br>  <b>DS</b> : W√§hrend wir sie nicht benutzen.  Wir benutzen unsere. <br><br><h2>  Lokale Entwicklung unter Kubernetes </h2><br>  <i><b>NS</b> : Sind Sie auf eine solche Wunschliste gesto√üen, wenn Sie alle Pods auf einer Maschine heben und so ein wenig testen m√ºssen.</i>  <i>Um schnell einen Proof of Concept zu erhalten, m√ºssen Sie sicherstellen, dass die Anwendung in Kubernetes ausgef√ºhrt wird, ohne eine Reihe von Computern daf√ºr zuzuweisen.</i>  <i>Gibt es einen Minikube, richtig?</i> <br><br>  <b>DS</b> : Meiner Meinung nach handelt es sich bei diesem Fall - der Bereitstellung auf einem Knoten - ausschlie√ülich um die lokale Entwicklung.  Oder einige Manifestationen eines solchen Musters.  Es gibt <a href="https://habr.com/ru/company/flant/blog/333470/">Minikube</a> , es gibt <a href="https://k3s.io/">K3s</a> , <a href="https://github.com/kubernetes-sigs/kind">KIND</a> .  Wir werden Kubernetes IN Docker verwenden.  Jetzt fingen sie an, mit ihm f√ºr Tests zu arbeiten. <br><br>  <i><b>NS</b> : Fr√ºher dachte ich, dass dies ein Versuch ist, alle Pods in ein Docker-Image zu packen.</i>  <i>Es stellte sich jedoch heraus, dass es sich um etwas anderes handelt.</i>  <i>Wie auch immer, es gibt separate Container, separate H√ºlsen - nur im Docker.</i> <br><br>  <b>DS</b> : Ja.  Und da wird eine ziemlich lustige Nachahmung gemacht, aber der Punkt ist ... Wir haben ein Bereitstellungstool - <a href="https://werf.io/">werf</a> .  Wir wollen einen Modus darin machen - bedingt <code>werf up</code> : "Raise me a local Kubernetes".  Und dann laufen die bedingten <code>werf follow</code> .  Dann kann der Entwickler die IDE bearbeiten, und im System wird ein Prozess gestartet, der die √Ñnderungen erkennt, die Bilder neu zusammensetzt und sie in die lokalen K8s umwandelt.  Wir wollen also versuchen, das Problem der lokalen Entwicklung zu l√∂sen. <br><br><h2>  Snapshots und Datenbankklonen in der Realit√§t von K8s </h2><br>  <i><b>NS</b> : Wenn Sie zur√ºck zu Copy-on-Write gehen.</i>  <i>Mir ist aufgefallen, dass die Wolken auch Schnappsch√ºsse haben.</i>  <i>Sie arbeiten anders.</i>  <i>Zum Beispiel in GCP: Sie haben eine Multi-Terabyte-Instanz an der Ostk√ºste der USA.</i>  <i>Sie machen regelm√§√üig Schnappsch√ºsse.</i>  <i>Sie nehmen eine Kopie der Festplatte an der Westk√ºste aus einem Schnappschuss - in wenigen Minuten ist alles fertig, es funktioniert sehr schnell, nur der Cache muss im Speicher gef√ºllt werden.</i>  <i>Aber diese Klone (Schnappsch√ºsse) - um ein neues Volume "bereitzustellen".</i>  <i>Dies ist ideal, wenn Sie viele Instanzen erstellen m√ºssen.</i> <br><br>  <i>Aber f√ºr die Tests, so scheint es mir, Schnappsch√ºsse, von denen Sie in Docker sprechen, oder von denen ich in ZFS, BTRFS und sogar in LVM spreche ... - sie erm√∂glichen es Ihnen, keine wirklich neuen Daten auf demselben Computer zu erstellen.</i>  <i>In der Cloud m√ºssen Sie immer noch jedes Mal daf√ºr bezahlen und nicht Minuten, sondern Minuten warten (und im Fall einer <a href="https://aws.amazon.com/about-aws/whats-new/2019/11/amazon-ebs-fast-snapshot-restore-eliminates-need-for-prewarming-data-into-volumes-created-snapshots/">langsamen Last</a> sind es wahrscheinlich Stunden).</i> <br><br>  <i>Stattdessen k√∂nnen Sie diese Daten in ein oder zwei Sekunden abrufen, den Test fahren und wegwerfen.</i>  <i>Diese Schnappsch√ºsse l√∂sen verschiedene Probleme.</i>  <i>Im ersten Fall - um neue Replikate zu skalieren und zu erhalten, und im zweiten Fall - f√ºr Tests.</i> <br><br>  <b>DS</b> : Dem stimme ich nicht zu.  Das Klonen von Volumes ist normalerweise Aufgabe der Cloud.  Ich habe ihre Implementierung nicht beobachtet, aber ich wei√ü, wie wir es auf Hardware machen.  Wir haben Ceph, in dem Sie jedem physischen Volume ( <a href="https://docs.ceph.com/docs/master/rbd/">RBD</a> ) <a href="https://en.wikipedia.org/wiki/IOPS">anweisen</a> k√∂nnen, innerhalb von zehn Millisekunden zu <i>klonen</i> und ein zweites Volume mit denselben Eigenschaften, <a href="https://en.wikipedia.org/wiki/IOPS">IOPSs</a> usw. <a href="https://en.wikipedia.org/wiki/IOPS">abzurufen</a> .  Sie m√ºssen verstehen, dass es ein kniffliges Copy-on-Write gibt.  Warum funktioniert die Cloud nicht genauso?  Ich bin mir sicher, dass sie das irgendwie versuchen. <br><br>  <i><b>NS</b> : Aber sie werden noch einige Sekunden brauchen, um die Instanz zu erh√∂hen, Docker dorthin zu bringen usw.</i> <br><br>  <b>DS</b> : Warum muss eine gesamte Instanz ausgel√∂st werden?  Aber wir haben eine Instanz f√ºr 32 Kerne, f√ºr 16 ... und sie passt irgendwie hinein - zum Beispiel vier.  Wenn wir den f√ºnften bestellen, steigt die Instanz und wird dann gel√∂scht. <br><br>  <i><b>NS</b> : Ja, interessanterweise hat Kubernetes eine andere Geschichte.</i>  <i>Unsere Datenbank ist nicht in K8s und eine Instanz.</i>  <i>Das Klonen einer Multi-Terabyte-Datenbank dauert jedoch nicht l√§nger als zwei Sekunden.</i> <br><br>  <b>DS</b> : Das ist cool.  Meine anf√§ngliche Botschaft ist jedoch, dass dies keine generische L√∂sung ist.  Ja, es ist cool, aber nur Postgres ist geeignet und nur auf einem Knoten. <br><br>  <i><b>NS</b> : Es ist nicht nur f√ºr Postgres geeignet: Diese Pl√§ne werden, wie ich beschrieben habe, nur auf diese Weise funktionieren.</i>  <i>Wenn Sie sich jedoch nicht um die Pl√§ne k√ºmmern, sondern nur alle Daten f√ºr Funktionstests ben√∂tigen, ist dies f√ºr jedes DBMS geeignet.</i> <br><br>  <b>DS</b> : Vor vielen Jahren haben wir das mit LVM-Snapshots gemacht.  Das ist ein Klassiker.  Dieser Ansatz wurde sehr aktiv genutzt.  Nur zustandsbehaftete Knoten sind ein Schmerz.  Weil sie nicht fallen gelassen werden m√ºssen, denken Sie immer an sie ... <br><br>  <i><b>NS</b> : Sehen Sie hier eine hybride M√∂glichkeit?</i>  <i>Nehmen wir an, Stateful ist eine Art Pod, die f√ºr mehrere Personen (viele Tester) funktioniert.</i>  <i>Wir haben ein Volume, aber dank des Dateisystems sind die Klone lokal.</i>  <i>Wenn der Pod herunterf√§llt, bleibt die Festplatte erhalten - der Pod wird angehoben, es werden die Informationen zu allen Klonen ber√ºcksichtigt, alles wird zur√ºckgenommen und es wird gesagt: "Hier sind Ihre Klone an diesen Ports, arbeiten Sie weiter mit ihnen."</i> <br><br>  <b>DS</b> : Technisch bedeutet dies, dass dies innerhalb von Kubernetes ein Pod ist, in dem wir viele Postgres betreiben. <br><br>  <i><b>NS</b> : Ja.</i>  <i>Er hat eine Grenze: Angenommen, nicht mehr als 10 Personen arbeiten gleichzeitig mit ihm.</i>  <i>Wenn Sie 20 brauchen, starten Sie den zweiten solchen Pod.</i>  <i>Wenn Sie das zweite vollst√§ndige Volume erhalten haben, werden die gleichen 10 "d√ºnnen" Klone erstellt.</i>  <i>Sehen Sie eine solche Gelegenheit nicht?</i> <br><br>  <b>DS</b> : Wir m√ºssen hier Sicherheitsprobleme hinzuf√ºgen.  Eine solche Organisationsoption impliziert, dass dieser Pod √ºber hohe Funktionen verf√ºgt, da er nicht standardm√§√üige Vorg√§nge auf dem Dateisystem ausf√ºhren kann. Aber ich wiederhole: Ich glaube, dass der Speicher mittelfristig in Kubernetes festgelegt wird, die gesamte Geschichte mit Volumes wird in den Clouds festgelegt - Alles wird "nur funktionieren".  Die Gr√∂√üe wird ge√§ndert, geklont ... Es gibt ein Volume - wir sagen: "Erstellen Sie ein neues auf dieser Grundlage" - und nach eineinhalb Sekunden erhalten wir, was wir brauchen. <br><br>  <i><b>NS</b> : Ich glaube nicht an eineinhalb Sekunden f√ºr viele Terabyte.</i>  <i>Bei Ceph machst du es selbst und redest √ºber Wolken.</i>  <i>Gehen Sie auf EC2 in die Cloud, machen Sie einen Klon des EBS-Volumens von vielen Terabyte und sehen Sie, wie hoch die Leistung sein wird.</i>  <i>Es dauert nicht einige Sekunden.</i>  <i>Ich bin sehr interessiert, wenn sie einen solchen Indikator erreichen.</i>  <i>Ich verstehe, wovon Sie sprechen, aber lassen Sie mich nicht zustimmen.</i> <br><br>  <b>DS</b> : Ok, aber das habe ich mittelfristig gesagt, nicht kurzfristig.  Seit mehreren Jahren. <br><br><h2>  Pro Operator f√ºr PostgreSQL von Zalando </h2><br>  W√§hrend dieses Treffens kam auch Alexey Klyukin, ein ehemaliger Entwickler von Zalando, der √ºber die Geschichte des PostgreSQL-Betreibers sprach, zu ihr: <br><br><blockquote>  Es ist gro√üartig, dass dieses Thema allgemein angesprochen wurde: sowohl Postgres als auch Kubernetes.  Als wir 2017 in Zalando damit begannen, war es ein Thema, das jeder wollte, aber niemand tat es.  Jeder hatte bereits Kubernetes, aber auf die Frage, was mit den Datenbanken geschehen soll, sagten sogar Leute wie <a href="https://github.com/kelseyhightower">Kelsey Hightower</a> , die K8 predigten, etwas in der Art: <br><br>  <i>Gehen Sie zu verwalteten Diensten und verwenden Sie sie. Starten Sie die Datenbank nicht in Kubernetes.</i>  <i>Andernfalls entscheidet sich Ihr K8 beispielsweise f√ºr ein Upgrade, l√∂scht alle Knoten und Ihre Daten fliegen weit, weit weg. "</i> <br><br>  Wir haben uns f√ºr einen Betreiber entschieden, der entgegen dieser Empfehlung die Postgres-Datenbank in Kubernetes einrichtet.  Und wir hatten eine gute Grundlage - <a href="https://github.com/zalando/patroni">Patroni</a> .  Dies ist ein automatisches Failover f√ºr PostgreSQL, das korrekt durchgef√ºhrt wurde, d. H.  Verwendung von etcd, consul oder ZooKeeper als Repository f√ºr Clusterinformationen.  Ein solches Repository wird jedem gegeben, der zum Beispiel fragt, welcher Anf√ºhrer jetzt die gleichen Informationen hat - trotz der Tatsache, dass wir alles verteilt haben - damit es kein gespaltenes Gehirn gibt.  Au√üerdem hatten wir ein <a href="https://github.com/zalando/patroni/tree/master/docker">Docker-Image</a> f√ºr ihn. <br><br>  Im Allgemeinen trat die Notwendigkeit eines automatischen Failovers im Unternehmen nach der Migration vom internen Eisendatenzentrum in die Cloud auf.  Die Cloud basierte auf einer propriet√§ren PaaS-L√∂sung (Platform-as-a-Service).  Es ist Open Source, aber um es zu erh√∂hen, musste man hart arbeiten.  Es hie√ü <a href="https://stups.io/">STUPS</a> . <br><br>  Anfangs gab es keine Kubernetes.  Genauer gesagt, als die eigene L√∂sung eingesetzt wurde, war K8s bereits so grob, dass es nicht f√ºr die Produktion geeignet war.  Meiner Meinung nach war es 2015 oder 2016.  Bis 2017 waren Kubernetes mehr oder weniger ausgereift - es bestand die Notwendigkeit, dorthin zu migrieren. <br><br>  Und wir hatten bereits einen Hafencontainer.  Es gab PaaS, das Docker verwendete.  Warum nicht K8s ausprobieren?  Warum schreibst du nicht deine eigene Aussage?  Murat Kabilov, der von Avito zu uns kam, startete dies aus eigener Initiative - ‚Äûspielen‚Äú - und das Projekt ‚Äûstartete‚Äú. <br><br>  Aber im Allgemeinen wollte ich √ºber AWS sprechen.  Warum gab es in der Vergangenheit AWS-bezogenen Code? <br><br>  Wenn Sie etwas in Kubernetes ausf√ºhren, m√ºssen Sie verstehen, dass K8s gerade in Arbeit ist.  Es wird st√§ndig weiterentwickelt, verbessert und regelm√§√üig ausgeglichen.  Sie m√ºssen alle √Ñnderungen in Kubernetes sorgf√§ltig √ºberwachen, Sie m√ºssen bereit sein, sich darauf einzulassen und herauszufinden, wie es im Detail funktioniert - vielleicht mehr, als Sie m√∂chten.  Dies ist im Prinzip jede Plattform, auf der Sie Ihre Datenbanken ausf√ºhren ... <br><br>  Als wir die Aussage machten, hatten wir Postgres, das mit einem externen Volume arbeitete (in diesem Fall EBS, da wir in AWS arbeiteten).  Die Datenbank wuchs, irgendwann musste die Gr√∂√üe ge√§ndert werden: Beispielsweise betr√§gt die urspr√ºngliche Gr√∂√üe von EBS 100 TB, die Datenbank ist darauf angewachsen, jetzt m√∂chten wir EBS auf 200 TB erweitern.  Wie?  Angenommen, Sie k√∂nnen eine neue Instanz sichern / wiederherstellen, dies ist jedoch lang und mit Ausfallzeiten verbunden. <br><br>  Aus diesem Grund wollte ich eine Gr√∂√üen√§nderung, mit der die EBS-Partition erweitert und das Dateisystem angewiesen wird, den neuen Speicherplatz zu verwenden.  Und wir haben es geschafft, aber damals hatte Kubernetes keine API f√ºr die Gr√∂√üen√§nderung.  Da wir an AWS gearbeitet haben, haben wir Code f√ºr dessen API geschrieben. <br><br>  Niemand m√∂chte dasselbe f√ºr andere Plattformen tun.  Die Aussage, dass es nur auf AWS ausgef√ºhrt werden kann, ist unkompliziert und funktioniert nicht auf allen anderen Systemen.  Im Allgemeinen handelt es sich um ein Open Source-Projekt: Wenn jemand die Verwendung der neuen API beschleunigen m√∂chte, sind wir herzlich willkommen.  Es gibt <a href="https://github.com/zalando/postgres-operator">GitHub</a> , Pull-Requests - das Zalando-Team versucht, schnell auf sie zu reagieren und den Operator zu promoten.  Soweit mir bekannt ist, hat das Projekt <a href="https://summerofcode.withgoogle.com/archive/2019/organizations/6187982082539520/">an</a> Google Summer of Code und anderen √§hnlichen Initiativen <a href="https://summerofcode.withgoogle.com/archive/2019/organizations/6187982082539520/">teilgenommen</a> .  Zalando ist sehr aktiv dabei. <br></blockquote><br><h2>  PS Bonus! </h2><br>  Wenn Sie sich f√ºr das Thema PostgreSQL und Kubernetes interessieren, dann weisen wir auch darauf hin, dass letzte Woche das n√§chste Postgres stattgefunden hat, bei dem <b>Alexander Kukushkin aus Zalando</b> mit Nikolai gesprochen hat.  Ein Video davon gibt es <a href="https://www.youtube.com/watch%3Fv%3DFE0xi7SBqsg">hier</a> . <br><br><h2>  PPS </h2><br>  Lesen Sie auch in unserem Blog: <br><br><ul><li>  " <a href="https://habr.com/ru/company/flant/blog/431500/">Datenbanken und Kubernetes (Review und Videobericht)</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/475036/">Cassandra Migration zu Kubernetes: Funktionen und L√∂sungen</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/461149/">Freie Migration von MongoDB nach Kubernetes</a> "; </li><li>  <a href="https://habr.com/ru/company/flant/blog/450662/">Msgstr</a> " <a href="https://habr.com/ru/company/flant/blog/450662/">Freie RabbitMQ - Migration zu Kubernetes</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de479438/">https://habr.com/ru/post/de479438/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de479422/index.html">[Videoanimation] Kabelgebundene Welt: Wie in 35 Jahren ein Netz von U-Boot-Kabeln den Globus umh√ºllte</a></li>
<li><a href="../de479426/index.html">Sicherheitswoche 50: Man-in-the-Middle-Angriffe in Confluence und Linux</a></li>
<li><a href="../de479428/index.html">Digitale Veranstaltungen in Moskau vom 9. bis 15. Dezember</a></li>
<li><a href="../de479430/index.html">Digitale Veranstaltungen in St. Petersburg vom 9. bis 15. Dezember</a></li>
<li><a href="../de479432/index.html">Yandex.Maps: Ich bin zum Karten-Controller gegangen - ich habe sofort die Position des Benutzers erhalten (okay, jetzt im Ernst)</a></li>
<li><a href="../de479442/index.html">Alexey Savvateev: Spieltheoretisches Modell der sozialen Spaltung (+ Nginx-Umfrage)</a></li>
<li><a href="../de479446/index.html">Autos sind den Lesetests bereits voraus. aber verstehen sie, was sie lesen?</a></li>
<li><a href="../de479450/index.html">AppCode 2019.3: Arbeitet schneller, versteht Swift besser, kennt sich mit Mac Catalyst aus und zeigt Versammlungsnachrichten an</a></li>
<li><a href="../de479452/index.html">Wie sich das Domain Name System entwickelte: Das ARPANET-Zeitalter</a></li>
<li><a href="../de479458/index.html">Sch√∂nheit oder Zweckm√§√üigkeit im Serverraum</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
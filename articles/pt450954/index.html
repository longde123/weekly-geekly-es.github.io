<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöê üêΩ ‚ôæ Como aprendemos a explorar Java no Docker üòª üöµüèæ üçÜ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sob o cap√¥, o hh.ru cont√©m um grande n√∫mero de servi√ßos Java em execu√ß√£o nos cont√™ineres do docker. Durante sua opera√ß√£o, encontramos muitos problemas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como aprendemos a explorar Java no Docker</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/hh/blog/450954/">  Sob o cap√¥, o hh.ru cont√©m um grande n√∫mero de servi√ßos Java em execu√ß√£o nos cont√™ineres do docker.  Durante sua opera√ß√£o, encontramos muitos problemas n√£o triviais.  Em muitos casos, para chegar ao fundo da solu√ß√£o, tive que pesquisar no Google por um longo tempo, ler as fontes do OpenJDK e at√© mesmo criar um perfil dos servi√ßos na produ√ß√£o.  Neste artigo, tentarei transmitir a quintess√™ncia do conhecimento adquirido no processo. <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Limites de CPU</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Docker e m√°quina de classe de servidor</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Limites de CPU (sim, novamente) e fragmenta√ß√£o de mem√≥ria</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Processamos Java-OOM</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Otimizando o consumo de mem√≥ria</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Limitando o consumo de mem√≥ria: heap, non-heap, mem√≥ria direta</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Limitando o consumo de mem√≥ria: Rastreamento de Mem√≥ria Nativa</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Java e unidades</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Como acompanhar tudo?</a> </li></ul><br><a name="habracut"></a><a name="cpu"></a><h4>  Limites de CPU </h4><br>  Costum√°vamos viver em m√°quinas virtuais kvm com limita√ß√µes de CPU e mem√≥ria e, mudando para o Docker, definimos restri√ß√µes semelhantes nos cgroups.  E o primeiro problema que encontramos foi precisamente os limites da CPU.  Devo dizer imediatamente que esse problema n√£o √© mais relevante para as vers√µes recentes do Java 8 e Java ‚â• 10. Se voc√™ acompanhar os hor√°rios, poder√° ignorar esta se√ß√£o com seguran√ßa. <br><br>  Portanto, iniciamos um pequeno servi√ßo no cont√™iner e vemos que ele produz um grande n√∫mero de threads.  Ou a CPU consome muito mais do que o esperado, o tempo limite √© em v√£o.  Ou aqui est√° outra situa√ß√£o real: em uma m√°quina, o servi√ßo √© iniciado normalmente e, em outra, com as mesmas configura√ß√µes, ele falha, pregado por um assassino da OOM. <br><br>  A solu√ß√£o acaba sendo muito simples - apenas o Java n√£o v√™ as limita√ß√µes do <code>--cpus</code> definidas na janela de encaixe e acredita que todos os kernels da m√°quina host est√£o acess√≠veis a ela.  E pode haver muitos deles (em nossa configura√ß√£o padr√£o - 80). <br>  As bibliotecas ajustam o tamanho dos conjuntos de encadeamentos ao n√∫mero de processadores dispon√≠veis - da√≠ o grande n√∫mero de encadeamentos. <br>  O pr√≥prio Java dimensiona o n√∫mero de encadeamentos da GC da mesma maneira, da√≠ o consumo e os tempos limites da CPU - o servi√ßo come√ßa a gastar uma grande quantidade de recursos na coleta de lixo, usando a maior parte da cota alocada a ele. <br>  Al√©m disso, as bibliotecas (em particular a Netty) podem, em certos casos, ajustar o tamanho da mem√≥ria fora do quadril ao n√∫mero de CPUs, o que leva a uma alta probabilidade de exceder os limites definidos para o cont√™iner ao executar em um hardware mais poderoso. <br><br>  Inicialmente, como esse problema se manifestou, tentamos usar as seguintes rodadas de trabalho: <br>  - tentou usar alguns servi√ßos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">libnumcpus</a> - uma biblioteca que permite "enganar" o Java, definindo um n√∫mero diferente de processadores dispon√≠veis; <br>  - indicou explicitamente o n√∫mero de threads do GC, <br>  - definir explicitamente limites para o uso de buffers diretos de bytes. <br><br>  Mas, √© claro, mover-se com essas muletas n√£o √© muito conveniente, e a mudan√ßa para o Java 10 (e depois o Java 11), em que todos esses problemas est√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ausentes</a> , foi uma solu√ß√£o real.  Para ser justo, vale dizer que nos oito tamb√©m tudo correu bem com a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">atualiza√ß√£o 191</a> , lan√ßada em outubro de 2018.  Naquele momento, j√° era irrelevante para n√≥s, o que tamb√©m desejo para voc√™. <br><br>  Este √© um exemplo em que a atualiza√ß√£o da vers√£o Java oferece n√£o apenas satisfa√ß√£o moral, mas tamb√©m um lucro real tang√≠vel na forma de opera√ß√£o simplificada e aumento do desempenho do servi√ßo. <br><br><a name="server-class"></a><h4>  Docker e m√°quina de classe de servidor </h4><br>  Portanto, no Java 10, as op√ß√µes <code>-XX:ActiveProcessorCount</code> e <code>-XX:+UseContainerSupport</code> apareceram (e foram portadas para o Java 8), levando em considera√ß√£o os limites padr√£o do cgroups.  Agora tudo estava maravilhoso.  Ou n√£o? <br><br>  Algum tempo depois de mudarmos para o Java 10/11, come√ßamos a notar algumas esquisitices.  Por alguma raz√£o, em alguns servi√ßos, os gr√°ficos do GC pareciam n√£o usar o G1: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gc/69/bo/gc69boghbrkf2wmxiuioszq5qgg.png"></div><br><br>  Isso foi, para dizer o m√≠nimo, um pouco inesperado, pois sab√≠amos com certeza que o G1 √© o coletor padr√£o, come√ßando com o Java 9. Ao mesmo tempo, n√£o h√° esse problema em alguns servi√ßos - o G1 est√° ativado, conforme o esperado. <br><br>  Come√ßamos a entender e trope√ßar em <a href="">algo interessante</a> .  Acontece que, se o Java estiver sendo executado em menos de 3 processadores e com um limite de mem√≥ria inferior a 2 GB, ele se considerar√° cliente e n√£o permitir√° o uso de outro que n√£o o SerialGC. <br><br>  A prop√≥sito, isso afeta apenas a <a href="">escolha do GC</a> e n√£o tem nada a ver com as op√ß√µes de compila√ß√£o -client / -server e JIT. <br><br>  Obviamente, quando usamos o Java 8, ele n√£o levou em considera√ß√£o os limites do docker e achou que tinha muitos processadores e mem√≥ria.  Ap√≥s a atualiza√ß√£o para o Java 10, muitos servi√ßos com limites mais baixos come√ßaram subitamente a usar o SerialGC.  Felizmente, isso √© tratado com muita simplicidade - configurando explicitamente a op√ß√£o <code>-XX:+AlwaysActAsServerClassMachine</code> . <br><br><a name="malloc"></a><h4>  Limites de CPU (sim, novamente) e fragmenta√ß√£o de mem√≥ria </h4><br>  Observando os gr√°ficos no monitoramento, de alguma forma percebemos que o tamanho do conjunto residente do cont√™iner √© muito grande - at√© tr√™s vezes o tamanho m√°ximo do quadril.  Esse poderia ser o caso de algum pr√≥ximo mecanismo complicado escalonado de acordo com o n√∫mero de processadores no sistema e n√£o sabe as limita√ß√µes da janela de encaixe? <br><br>  Acontece que o mecanismo n√£o √© nada complicado - √© o malloc bem conhecido da glibc.  Em resumo, a glibc usa as chamadas arenas para alocar mem√≥ria.  Ao criar, cada segmento recebe uma das arenas.  Quando um encadeamento usando glibc deseja alocar uma certa quantidade de mem√≥ria no heap nativo para suas necessidades e chama malloc, a mem√≥ria √© alocada na arena atribu√≠da a ele.  Se a arena atender a v√°rios t√≥picos, eles competir√£o por ele.  Quanto mais arenas, menos concorr√™ncia, mas mais fragmenta√ß√£o, pois cada arena tem sua pr√≥pria lista de √°reas livres. <br><br>  Em sistemas de 64 bits, o n√∫mero padr√£o de arenas √© definido como 8 * o n√∫mero de CPUs.  Obviamente, isso representa uma enorme sobrecarga para n√≥s, porque nem todas as CPUs est√£o dispon√≠veis para o cont√™iner.  Al√©m disso, para aplicativos baseados em Java, a competi√ß√£o por arenas n√£o √© t√£o relevante, pois a maioria das aloca√ß√µes √© feita no heap Java, cuja mem√≥ria pode ser completamente alocada na inicializa√ß√£o. <br><br>  Esse recurso do malloc √© conhecido h√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">muito</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tempo</a> , bem como sua solu√ß√£o - para usar a vari√°vel de ambiente <code>MALLOC_ARENA_MAX</code> para indicar explicitamente o n√∫mero de arenas.  √â muito f√°cil de fazer para qualquer cont√™iner.  Aqui est√° o efeito de especificar <code>MALLOC_ARENA_MAX = 4</code> para o nosso back-end principal: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jk/zq/lo/jkzqlo_pqiu4xppzbe-itkjvviy.png"></div><br><br>  Existem duas inst√¢ncias no gr√°fico RSS: em uma (azul), ligamos <code>MALLOC_ARENA_MAX</code> , na outra (vermelha), apenas reiniciamos.  A diferen√ßa √© √≥bvia. <br><br>  Mas depois disso, existe um desejo razo√°vel de descobrir em que Java geralmente gasta mem√≥ria.  √â poss√≠vel executar um microsservi√ßo em Java com um limite de mem√≥ria de 300 a 400 megabytes e n√£o ter medo de que ele caia do Java-OOM ou n√£o seja morto por um assassino de OOM do sistema? <br><br><a name="oom"></a><h4>  Processamos Java-OOM </h4><br>  Primeiro de tudo, voc√™ precisa se preparar para o fato de que as OOMs s√£o inevit√°veis ‚Äã‚Äãe precisa lidar com elas corretamente - pelo menos salve os quadris.  Curiosamente, mesmo este simples empreendimento tem suas pr√≥prias nuances.  Por exemplo, despejos de quadril n√£o s√£o substitu√≠dos - se um despejo de quadril com o mesmo nome j√° estiver salvo, um novo simplesmente n√£o ser√° criado. <br><br>  Java pode <a href="">adicionar automaticamente o</a> n√∫mero de s√©rie <a href="">do</a> dump e a identifica√ß√£o do processo ao nome do arquivo, mas isso n√£o nos ajudar√°.  O n√∫mero de s√©rie n√£o √© √∫til, porque esse √© o OOM, e n√£o o despejo de quadril solicitado regularmente - o aplicativo √© reiniciado depois dele, redefinindo o contador.  E a identifica√ß√£o do processo n√£o √© adequada, pois na janela de encaixe √© sempre a mesma (geralmente 1). <br><br>  Portanto, chegamos a esta op√ß√£o: <br><br> <code>-XX:+HeapDumpOnOutOfMemoryError <br> -XX:+ExitOnOutOfMemoryError <br> -XX:HeapDumpPath=/var/crash/java.hprof <br> -XX:OnOutOfMemoryError="mv /var/crash/java.hprof /var/crash/heapdump.hprof"</code> <br> <br>  √â bastante simples e, com algumas melhorias, voc√™ pode at√© ensinar a armazen√°-lo n√£o apenas no mais recente despejo de quadril, mas, para nossas necessidades, isso √© mais que suficiente. <br><br>  Java OOM n√£o √© a √∫nica coisa que temos que enfrentar.  Cada cont√™iner tem um limite na mem√≥ria que ocupa e pode ser excedido.  Se isso acontecer, o cont√™iner ser√° <code>restart_policy: always</code> pelo killer do OOM do sistema e reiniciado (usamos <code>restart_policy: always</code> ).  Naturalmente, isso √© indesej√°vel e queremos aprender como definir corretamente os limites dos recursos utilizados pela JVM. <br><br><a name="opt-mem"></a><h4>  Otimizando o consumo de mem√≥ria </h4><br>  Mas antes de definir limites, √© necess√°rio garantir que a JVM n√£o esteja desperdi√ßando recursos.  J√° conseguimos reduzir o consumo de mem√≥ria usando um limite no n√∫mero de CPUs e na vari√°vel <code>MALLOC_ARENA_MAX</code> .  Existem outras maneiras "quase gratuitas" de fazer isso? <br><br>  Acontece que existem mais alguns truques que economizar√£o um pouco de mem√≥ria. <br><br>  O primeiro √© o uso da op√ß√£o <code>-Xss</code> (ou <code>-XX:ThreadStackSize</code> ), que controla o tamanho da pilha dos encadeamentos.  O padr√£o para uma JVM de 64 bits √© 1 MB.  Descobrimos que 512 KB √© suficiente para n√≥s.  Por esse motivo, um StackOverflowException nunca foi detectado antes, mas admito que isso n√£o √© adequado para todos.  E o lucro disso √© muito pequeno. <br><br>  O segundo √© o <code>-XX:+UseStringDeduplication</code> (com o G1 GC ativado).  Permite economizar mem√≥ria recolhendo linhas duplicadas devido √† carga adicional do processador.  A troca entre a mem√≥ria e a CPU depende apenas do aplicativo espec√≠fico e das configura√ß√µes do pr√≥prio mecanismo de deduplica√ß√£o.  Leia o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dock</a> e teste em seus servi√ßos, temos essa op√ß√£o ainda n√£o encontrou sua aplica√ß√£o. <br><br>  E, finalmente, um m√©todo que n√£o √© adequado para todos (mas nos conv√©m) √© usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">jemalloc em</a> vez do malloc nativo.  Essa implementa√ß√£o √© voltada para reduzir a fragmenta√ß√£o da mem√≥ria e melhor suporte a multithreading comparado ao malloc da glibc.  Para nossos servi√ßos, o jemalloc proporcionou um pouco mais de mem√≥ria que o malloc com <code>MALLOC_ARENA_MAX=4</code> , sem afetar significativamente o desempenho. <br><br>  Outras op√ß√µes, incluindo as descritas por Alexei Shipilev no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">JVM Anatomy Quark # 12: Native Memory Tracking</a> , pareciam bastante perigosas ou levavam a uma degrada√ß√£o percept√≠vel no desempenho.  No entanto, para fins educacionais, recomendo a leitura deste artigo. <br><br>  Enquanto isso, vamos para o pr√≥ximo t√≥pico e, finalmente, tente aprender como limitar o consumo de mem√≥ria e selecionar os limites corretos. <br><br><a name="lim-mem-1"></a><h4>  Limitando o consumo de mem√≥ria: heap, non-heap, mem√≥ria direta </h4><br>  Para fazer tudo certo, voc√™ precisa lembrar em que consiste a mem√≥ria em geral em Java.  Primeiro, vamos olhar para os conjuntos cujo status pode ser monitorado atrav√©s do JMX. <br><br>  O primeiro, √© claro, √© <b>moderno</b> .  √â simples: <code>-Xmx</code> , mas como fazer isso certo?  Infelizmente, n√£o existe uma receita universal aqui, tudo depende da aplica√ß√£o e do perfil de carga.  Para novos servi√ßos, come√ßamos com um tamanho de heap relativamente razo√°vel (128 MB) e, se necess√°rio, aumentamos ou diminu√≠mos.  Para dar suporte aos j√° existentes, h√° monitoramento com gr√°ficos de consumo de mem√≥ria e m√©tricas de GC. <br><br>  Ao mesmo tempo que <code>-Xmx</code> , configuramos <code>-Xms == -Xmx</code> .  N√£o temos mem√≥ria excedente; portanto, √© do nosso interesse que o servi√ßo use os recursos que fornecemos ao m√°ximo.  Al√©m disso, em servi√ßos comuns, inclu√≠mos <code>-XX:+AlwaysPreTouch</code> e o mecanismo Transparent Huge Pages: <code>-XX:+UseTransparentHugePages -XX:+UseLargePagesInMetaspace</code> .  No entanto, antes de ativar o THP, leia atentamente a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o</a> e teste como os servi√ßos se comportam com essa op√ß√£o por um longo tempo.  N√£o s√£o descartadas surpresas em m√°quinas com RAM insuficiente (por exemplo, tivemos que desativar o THP em bancos de teste). <br><br>  O pr√≥ximo √© <b>n√£o-heap</b> .  A mem√≥ria n√£o heap inclui: <br>  - Metaspace e espa√ßo de classe compactado, <br>  - Cache de c√≥digo. <br><br>  Considere esses conjuntos em ordem. <br><br>  Claro, todo mundo j√° ouviu falar sobre o <b>Metaspace</b> , n√£o vou falar sobre isso em detalhes.  Ele armazena metadados de classe, m√©todo bytecode e assim por diante.  De fato, o uso do Metaspace depende diretamente do n√∫mero e tamanho das classes carregadas, e voc√™ pode determin√°-lo, como hip, apenas iniciando o aplicativo e removendo as m√©tricas via JMX.  Por padr√£o, o Metaspace n√£o √© limitado por nada, mas √© muito f√°cil fazer isso com a <code>-XX:MaxMetaspaceSize</code> . <br><br>  <b>O espa√ßo de classe compactado</b> faz parte do Metaspace e aparece quando a op√ß√£o <code>-XX:+UseCompressedClassPointers</code> est√° ativada (ativada por padr√£o para montes inferiores a 32 GB, ou seja, quando pode proporcionar um ganho real de mem√≥ria).  O tamanho desse pool pode ser limitado pela op√ß√£o <code>-XX:CompressedClassSpaceSize</code> , mas n√£o faz muito sentido, pois o Compressed Class Space est√° inclu√≠do no Metaspace e a quantidade total de mem√≥ria bloqueada para o Metaspace e o Compressed Class Space √© finalmente limitada a uma <code>-XX:MaxMetaspaceSize</code> . <br><br>  A prop√≥sito, se voc√™ observar as leituras JMX, a quantidade de mem√≥ria n√£o-heap ser√° sempre calculada como a <a href="">soma do</a> Metaspace, do Espa√ßo de Classe Compactado e do Cache de C√≥digo.  Na verdade, voc√™ s√≥ precisa resumir o Metaspace e o CodeCache. <br><br>  Portanto, no n√£o heap, apenas o <b>Code Cache</b> permaneceu - o reposit√≥rio de c√≥digo compilado pelo compilador JIT.  Por padr√£o, seu tamanho m√°ximo √© definido como 240 MB e, para servi√ßos pequenos, √© v√°rias vezes maior que o necess√°rio.  O tamanho do cache de c√≥digo pode ser definido com a op√ß√£o <code>-XX:ReservedCodeCacheSize</code> .  O tamanho correto s√≥ pode ser determinado executando o aplicativo e seguindo-o em um perfil de carga t√≠pico. <br><br>  √â importante n√£o cometer um erro aqui, uma vez que o Cache de C√≥digo insuficiente exclui o c√≥digo frio e antigo do cache (a op√ß√£o <code>-XX:+UseCodeCacheFlushing</code> ativada por padr√£o) e isso, por sua vez, pode levar a um maior consumo da CPU e degrada√ß√£o do desempenho .  Seria √≥timo se voc√™ pudesse lan√ßar o OOM quando o cache de c√≥digo <code>-XX:+ExitOnFullCodeCache</code> , pois existe at√© o <code>-XX:+ExitOnFullCodeCache</code> , mas, infelizmente, ele est√° dispon√≠vel apenas na <a href="">vers√£o de desenvolvimento da</a> JVM. <br><br>  O √∫ltimo conjunto sobre o qual h√° informa√ß√µes no JMX √© <b>a mem√≥ria direta</b> .  Por padr√£o, seu tamanho n√£o √© limitado, portanto, √© importante definir algum tipo de limite para ele - pelo menos bibliotecas como o Netty, que usam ativamente buffers de byte direto, ser√£o orientadas por ele.  N√£o √© dif√≠cil definir um limite usando o <code>-XX:MaxDirectMemorySize</code> e, novamente, apenas o monitoramento nos ajudar√° a determinar o valor correto. <br><br>  Ent√£o, o que chegamos at√© agora? <br><br><pre>  Mem√≥ria de processo Java = 
     Heap + Metaspace + Cache de c√≥digo + Mem√≥ria direta =
         -Xmx +
         -XX: MaxMetaspaceSize
         -XX: ReservedCodeCacheSize
         -XX: MaxDirectMemorySize </pre><br><br>  Vamos tentar desenhar tudo no gr√°fico e compar√°-lo com o cont√™iner da janela de encaixe RSS. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pg/ue/fx/pguefx_0kisoyxg8mna7dxlmimo.png"></div><br><br>  A linha acima √© o RSS do cont√™iner e √© uma vez e meia mais que o consumo de mem√≥ria da JVM, que podemos monitorar atrav√©s da JMX. <br><br>  Cavando mais! <br><br><a name="lim-mem-2"></a><h4>  Limitando o consumo de mem√≥ria: Rastreamento de Mem√≥ria Nativa </h4><br>  Obviamente, al√©m da mem√≥ria heap, n√£o heap e direta, a JVM usa muitos outros conjuntos de mem√≥rias.  O sinalizador <code>-XX:NativeMemoryTracking=summary</code> nos ajudar√° a <code>-XX:NativeMemoryTracking=summary</code> com eles <code>-XX:NativeMemoryTracking=summary</code> .  Ao ativar esta op√ß√£o, poderemos obter informa√ß√µes sobre conjuntos conhecidos pela JVM, mas n√£o dispon√≠veis na JMX.  Voc√™ pode ler mais sobre como usar esta op√ß√£o na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o</a> . <br><br>  Vamos come√ßar com o mais √≥bvio - a mem√≥ria ocupada pelas <b>pilhas de threads</b> .  A NMT produz algo parecido com o seguinte para o nosso servi√ßo: <br><br><pre>  Encadeamento (reservado = 32166 KB, confirmado = 5358 KB)
     (segmento # 52)
     (pilha: reservada = 31920 KB, confirmada = 5112 KB)
     (malloc = 185 KB # 270) 
     (arena = 61KB # 102) </pre><br>  A prop√≥sito, seu tamanho tamb√©m pode ser encontrado sem o Native Memory Tracking, usando o jstack e cavando um pouco em <code>/proc/&lt;pid&gt;/smaps</code> .  Andrey Pangin estabeleceu um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">utilit√°rio especial</a> para isso. <br><br>  O tamanho do <b>espa√ßo de classe compartilhado</b> √© ainda mais f√°cil de avaliar: <br><br><pre>  Espa√ßo de classe compartilhado (reservado = 17084KB, confirmado = 17084KB)
     (mmap: reservado = 17084 KB, confirmado = 17084 KB) </pre><br>  Este √© o mecanismo de compartilhamento de dados de classe, <code>-Xshare</code> e <code>-XX:+UseAppCDS</code> .  No Java 11, a op√ß√£o <code>-Xshare</code> √© definida como autom√°tica por padr√£o, o que significa que se voc√™ tiver o <code>$JAVA_HOME/lib/server/classes.jsa</code> (ele est√° na imagem oficial do dockJDK), ele carregar√° o mapa de mem√≥ria- Ohm na inicializa√ß√£o da JVM, acelerando o tempo de inicializa√ß√£o.  Assim, √© f√°cil determinar o tamanho do Espa√ßo de Classe Compartilhado se voc√™ souber o tamanho dos arquivos jsa. <br><br>  A seguir est√£o as estruturas nativas do <b>coletor de lixo</b> : <br><br><pre>  GC (reservado = 42137 KB, confirmado = 41801 KB)
     (malloc = 5705 KB # 9460) 
     (mmap: reservado = 36432 KB, confirmado = 36096 KB) </pre><br>  Alexey Shipilev no manual j√° mencionado no Native Memory Tracking <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">diz</a> que eles ocupam cerca de 4-5% do tamanho do heap, mas em nossa configura√ß√£o para heap pequeno (at√© v√°rias centenas de megabytes) a sobrecarga atingiu 50% do tamanho do heap. <br><br>  Muito espa√ßo pode ser ocupado por <b>tabelas de s√≠mbolos</b> : <br><br><pre>  S√≠mbolo (reservado = 16421KB, confirmado = 16421KB)
     (malloc = 15261KB # 203089) 
     (arena = 1159 KB # 1) </pre><br>  Eles armazenam os nomes dos m√©todos, assinaturas e links para cadeias estendidas.  Infelizmente, parece poss√≠vel estimar o tamanho da tabela de s√≠mbolos somente ap√≥s factum usando o Native Memory Tracking. <br><br>  O que resta?  De acordo com o Native Memory Tracking, muitas coisas: <br><br><pre>  Compilador (reservado = 509KB, confirmado = 509KB)
 Interno (reservado = 1647 KB, confirmado = 1647 KB)
 Outro (reservado = 2110 KB, confirmado = 2110 KB)
 Peda√ßo da arena (reservado = 1712 KB, confirmado = 1712 KB)
 Log (reservado = 6 KB, confirmado = 6 KB)
 Argumentos (reservados = 19KB, confirmados = 19KB)
 M√≥dulo (reservado = 227KB, confirmado = 227KB)
 Desconhecido (reservado = 32 KB, confirmado = 32 KB) </pre><br>  Mas tudo isso ocupa bastante espa√ßo. <br><br>  Infelizmente, muitas das √°reas mencionadas da mem√≥ria n√£o podem ser limitadas nem controladas e, se pudesse, a configura√ß√£o se tornaria um inferno.  Mesmo monitorando seu status n√£o √© uma tarefa trivial, uma vez que a inclus√£o do Native Memory Tracking drena levemente o desempenho do aplicativo e habilit√°-lo na produ√ß√£o em um servi√ßo cr√≠tico n√£o √© uma boa id√©ia. <br><br>  No entanto, por uma quest√£o de interesse, vamos tentar refletir no gr√°fico tudo o que o Native Memory Tracking relata: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/t_/5d/kn/t_5dkncjh0wrn9qmftrp3wgwg2w.png"></div><br><br>  Nada mal!  A diferen√ßa restante √© uma sobrecarga para fragmenta√ß√£o / aloca√ß√£o de mem√≥ria (√© bastante pequena, pois usamos jemalloc) ou a mem√≥ria que as bibliotecas nativas alocaram.  Apenas usamos um deles para armazenamento eficiente da √°rvore de prefixos. <br><br>  Portanto, para nossas necessidades, basta limitar o que podemos: Heap, Metaspace, Cache de c√≥digo, Mem√≥ria direta.  Para todo o resto, deixamos algumas bases razo√°veis, determinadas pelos resultados de medi√ß√µes pr√°ticas. <br><br>  Tendo lidado com a CPU e a mem√≥ria, passamos para o pr√≥ximo recurso pelo qual os aplicativos podem competir - para os discos. <br><br><a name="disks"></a><h4>  Java e unidades </h4><br>  E com eles, tudo est√° muito ruim: eles s√£o lentos e podem levar a um embotamento tang√≠vel do aplicativo.  Portanto, desvinculamos o Java dos discos o m√°ximo poss√≠vel: <br><br><ul><li>  Escrevemos todos os logs de aplicativos no syslog local via UDP.  Isso deixa algumas chances de que os logs necess√°rios sejam perdidos em algum lugar ao longo do caminho, mas, como a pr√°tica demonstrou, esses casos s√£o muito raros. </li><li>  Escreveremos logs da JVM em tmpfs; para isso, basta montar a janela de encaixe no local desejado com o <code>/dev/shm</code> . </li></ul><br><br>  Se escrevermos logs no syslog ou no tmpfs, e o pr√≥prio aplicativo gravar nada al√©m de despejos de mem√≥ria no disco, ent√£o o hist√≥rico de discos pode ser considerado fechado nisso? <br><br>  Claro que n√£o. <br><br>  Prestamos aten√ß√£o ao gr√°fico da dura√ß√£o das pausas do tipo "pare o mundo" e vemos uma imagem triste - as pausas do tipo "Pare o mundo" nos hosts s√£o centenas de milissegundos e, em um host, elas podem chegar a um segundo: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tf/nd/pb/tfndpbg7mtpaylny7-cflvrukzg.png"></div><br><br>  Escusado ser√° dizer que isso afeta negativamente a aplica√ß√£o?  Aqui, por exemplo, est√° um gr√°fico que reflete o tempo de resposta do servi√ßo de acordo com os clientes: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nc/d0/_n/ncd0_ndoybiyy42wzrh68ppj-_0.png"></div><br><br>  Este √© um servi√ßo muito simples, geralmente fornecendo respostas em cache; portanto, de onde s√£o esses intervalos proibitivos, come√ßando com o percentil 95?  Outros servi√ßos t√™m uma imagem semelhante; al√©m disso, os tempos limite est√£o chovendo com const√¢ncia invej√°vel ao levar a conex√£o do pool de conex√µes ao banco de dados, ao executar solicita√ß√µes e assim por diante. <br><br>  O que a unidade tem a ver com isso?  - voc√™ pergunta.  Acontece muito a ver com isso. <br>  Uma an√°lise detalhada do problema mostrou que longas pausas no STW surgem devido ao fato de os encadeamentos permanecerem no ponto seguro por um longo tempo.  Ap√≥s ler o c√≥digo da JVM, percebemos que durante a sincroniza√ß√£o de encadeamentos no ponto seguro, a JVM pode gravar o arquivo <code>/tmp/hsperfdata*</code> atrav√©s do mapa de mem√≥ria, para o qual exporta algumas estat√≠sticas.  Utilit√°rios como <code>jstat</code> e <code>jps</code> usam <code>jstat</code> <code>jps</code> . <br><br>  Desative-o na mesma m√°quina com a op√ß√£o <code>-XX:+PerfDisableSharedMem</code> e ... <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1r/aw/q7/1rawq7kjvmrjznko2781or7kzdm.png"></div><br><br>  As m√©tricas do cais de esteiras estabilizam: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qz/bs/pj/qzbspjvpdjfhjjtbwrn6et55wns.png"></div><br><br>         (,         ): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ni/ig/ji/niigjizzguoke8dcfdz2ssqnqa8.png"></div><br><br>  ,         ,  ,        . <br><br><a name="monitor"></a><h4>    ? </h4><br>     Java-  , ,  ,    . <br><br>         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Nuts and Bolts</a> ,          .              ,     .     ,      ,  JMX. <br><br>      ,          .          . <br><br>     statsd    JVM,    (heap,   non-heap   ): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/n9/iw/vs/n9iwvsjan7hxeo-xsksaggthrqy.png"></div><br><br>  ,    ,       . <br><br>    ‚Äî       ,    ,  ,    ,    ?        .     ()  -,     ,   RPS   . <br><br>     :   ,              .         .        ammo-  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">.</a> .    . : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qr/ry/wh/qrrywh-id3u5lbk7ldms8n-n_ck.png"></div><br><br>        . <br><br>               ,     .  ,      ,     - ,   ,   . <br><br><h4>  Em conclus√£o </h4><br>   ,  Java  Docker ‚Äî    ,      .     . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt450954/">https://habr.com/ru/post/pt450954/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt450942/index.html">Sidecar para uma divis√£o de c√≥digo</a></li>
<li><a href="../pt450946/index.html">Telefone celular em disco LPC810</a></li>
<li><a href="../pt450948/index.html">MU-MIMO: um dos algoritmos de implementa√ß√£o</a></li>
<li><a href="../pt450950/index.html">Fundamentos do Dart Streams</a></li>
<li><a href="../pt450952/index.html">√çndice M√©dio e Antibanco</a></li>
<li><a href="../pt450956/index.html">Compara√ß√£o de COB industrial: ISIM vs. Kics</a></li>
<li><a href="../pt450958/index.html">AnyStub, biblioteca de stub de conex√£o Java</a></li>
<li><a href="../pt450962/index.html">Bombas de insulina, microchips inviol√°veis ‚Äã‚Äãe r√°dio definido por software</a></li>
<li><a href="../pt450964/index.html">Nova biblioteca intr√≠nseca x86 SIMD - immintrin debug</a></li>
<li><a href="../pt450966/index.html">Gravando v√≠deo de um computador antigo - m√©todos da LGR</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
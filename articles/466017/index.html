<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•õ üõÇ ü§òüèº Livy: el eslab√≥n perdido en la cadena de Python Hadoop Spark Airflow üó∫Ô∏è ü§õ üõ§Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos, alguna informaci√≥n "de debajo del cap√≥" es la fecha del taller de ingenier√≠a de Alfastrakhovaniya, que emociona nuestras mentes t√©cnicas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Livy: el eslab√≥n perdido en la cadena de Python Hadoop Spark Airflow</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/alfastrah/blog/466017/"><p>  Hola a todos, alguna informaci√≥n "de debajo del cap√≥" es la fecha del taller de ingenier√≠a de Alfastrakhovaniya, que emociona nuestras mentes t√©cnicas. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/956/f04/a6a/956f04a6ae545bee58a8c34f2938a850.png" alt="imagen"></p><br><p>  Apache Spark es una herramienta maravillosa que le permite procesar r√°pida y f√°cilmente grandes cantidades de datos en recursos inform√°ticos bastante modestos (me refiero al procesamiento de cl√∫ster). </p><br><p>  Tradicionalmente, el jupyter notebook se usa en el procesamiento de datos ad hoc.  En combinaci√≥n con Spark, esto nos permite manipular marcos de datos de larga duraci√≥n (Spark se ocupa de la asignaci√≥n de recursos, los marcos de fechas viven en alg√∫n lugar del cl√∫ster, su vida √∫til est√° limitada por la vida √∫til del contexto de Spark). </p><br><p>  Despu√©s de transferir el procesamiento de datos a Apache Airflow, la vida √∫til de los marcos se reduce considerablemente: el contexto de Spark "vive" dentro de la misma declaraci√≥n de Airflow.  C√≥mo evitar esto, por qu√© moverse y qu√© tiene que ver Livy con eso, lea debajo del corte. </p><a name="habracut"></a><br><p>  Veamos un ejemplo muy, muy simple: supongamos que necesitamos desnormalizar datos en una tabla grande y guardar el resultado en otra tabla para su posterior procesamiento (un elemento t√≠pico de la tuber√≠a de procesamiento de datos). </p><br><p>  ¬øC√≥mo har√≠amos esto? </p><br><ul><li>  datos cargados en el marco de datos (selecci√≥n de una tabla grande y directorios) </li><li>  mir√≥ con "ojos" el resultado (¬øfuncion√≥ correctamente?) </li><li>  marco de datos guardado en la tabla de Hive (por ejemplo) </li></ul><br><p>  Seg√∫n los resultados del an√°lisis, es posible que debamos insertar en el segundo paso un procesamiento espec√≠fico (reemplazo del diccionario u otra cosa).  En t√©rminos de l√≥gica, tenemos tres pasos. </p><br><ul><li>  paso 1: descargar </li><li>  paso 2: procesamiento </li><li>  Paso 3: guardar </li></ul><br><p>  En jupyter notebook, as√≠ es como lo hacemos: podemos procesar los datos descargados durante un tiempo arbitrariamente largo, lo que le da a Spark el control de los recursos. </p><br><p> Es l√≥gico esperar que dicha partici√≥n se pueda transferir a Airflow.  Es decir, tener un gr√°fico de este tipo </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/312/30b/d7e/31230bd7e4c3beb62f92aebb709e2010.png" alt="imagen"></p><br><p>  Desafortunadamente, esto no es posible cuando se usa la combinaci√≥n Airflow + Spark: cada declaraci√≥n de Airflow se ejecuta en su propio int√©rprete de Python, por lo tanto, entre otras cosas, cada declaraci√≥n debe de alguna manera "persistir" en los resultados de sus actividades.  Por lo tanto, nuestro procesamiento se "comprime" en un solo paso: "desnormalizar datos". </p><br><p>  ¬øC√≥mo se puede devolver la flexibilidad del port√°til jupyter a Airflow?  Est√° claro que el ejemplo anterior "no vale la pena" (tal vez, por el contrario, resulta un buen paso de procesamiento comprensible).  Pero a√∫n as√≠, ¬øc√≥mo hacer que las declaraciones de Airflow se ejecuten en el mismo contexto de Spark en un espacio de trama de datos com√∫n? </p><br><h2 id="privetstvuem-livy">  Bienvenida Livy </h2><br><p>  Otro producto del ecosistema Hadoop viene al rescate: Apache Livy. </p><br><p>  No tratar√© de describir aqu√≠ qu√© tipo de "bestia" es.  Si es muy breve y en blanco y negro, Livy le permite "inyectar" c√≥digo de Python en un programa que ejecuta el controlador: </p><br><ul><li>  primero creamos una sesi√≥n de Livy </li><li>  despu√©s de eso, tenemos la capacidad de ejecutar c√≥digo arbitrario de Python en esta sesi√≥n (muy similar a la ideolog√≠a jupyter / ipython) </li></ul><br><p>  Y para todo esto hay una API REST. </p><br><p>  Volviendo a nuestra tarea simple: con Livy podemos guardar la l√≥gica original de nuestra desnormalizaci√≥n </p><br><ul><li>  en el primer paso (la primera declaraci√≥n de nuestro gr√°fico) cargaremos y ejecutaremos el c√≥digo de carga de datos en el marco de datos </li><li>  en el segundo paso (segunda instrucci√≥n): ejecute el c√≥digo para el procesamiento adicional necesario de este marco de datos </li><li>  en el tercer paso: el c√≥digo para guardar el marco de datos en la tabla </li></ul><br><p>  Lo que en t√©rminos de flujo de aire podr√≠a verse as√≠: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b9b/255/bcd/b9b255bcd00525201a000ef1a3fbafa3.png" alt="imagen"></p><br><p>  (dado que la imagen es una captura de pantalla muy real, se agregaron "realidades" adicionales: la creaci√≥n del contexto de Spark se convirti√≥ en una operaci√≥n separada con un nombre extra√±o, el "procesamiento" de los datos desapareci√≥ porque no era necesario, etc.) </p><br><p>  Para resumir, obtenemos </p><br><ul><li>  declaraci√≥n de flujo de aire universal que ejecuta c√≥digo python en una sesi√≥n de Livy </li><li>  la capacidad de "organizar" el c√≥digo de Python en gr√°ficos bastante complejos (flujo de aire para eso) </li><li>  la capacidad de abordar optimizaciones de nivel superior, por ejemplo, en qu√© orden necesitamos realizar nuestras transformaciones para que Spark pueda mantener los datos generales en la memoria del cl√∫ster durante el mayor tiempo posible </li></ul><br><p>  Una canalizaci√≥n t√≠pica para preparar datos para modelar contiene alrededor de 25 consultas en 10 tablas, es obvio que algunas tablas se usan con m√°s frecuencia que otras (los mismos "datos generales") y hay algo que optimizar. </p><br><h2 id="chto-dalshe">  Que sigue </h2><br><p>  La capacidad t√©cnica ha sido probada, pensamos m√°s all√°: c√≥mo traducir m√°s tecnol√≥gicamente nuestras transformaciones en este paradigma.  Y c√≥mo abordar la optimizaci√≥n mencionada anteriormente.  Todav√≠a estamos al comienzo de esta parte de nuestro viaje; cuando hay algo interesante, definitivamente lo compartiremos. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/466017/">https://habr.com/ru/post/466017/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../465991/index.html">Trabajadores de la arquitectura Clean Swift</a></li>
<li><a href="../465993/index.html">No es necesario ahorrar en seguridad digital</a></li>
<li><a href="../465995/index.html">LDC - Excursi√≥n</a></li>
<li><a href="../466001/index.html">Feng Shui "m√≥vil", o dormimos correctamente (caf√©, cucarachas e intolerancia en Habr√©)</a></li>
<li><a href="../466015/index.html">Un poco m√°s sobre trigonometr√≠a en inform√°tica</a></li>
<li><a href="../466019/index.html">ABBYY Mobile Web Capture: fotos de alta calidad de documentos directamente en el navegador de su tel√©fono inteligente</a></li>
<li><a href="../466021/index.html">C√≥mo le ense√±√© a Yandex.Alice a hablar sobre juguetes sexuales</a></li>
<li><a href="../466027/index.html">El libro "El camino de Python. Cintur√≥n negro para desarrollo, escalado, prueba y despliegue ‚Äù</a></li>
<li><a href="../466029/index.html">C√≥mo convertir una computadora cu√°ntica en un generador de n√∫meros aleatorios perfecto</a></li>
<li><a href="../466031/index.html">La misi√≥n √©pica de DeepMind para resolver el problema cient√≠fico m√°s complejo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
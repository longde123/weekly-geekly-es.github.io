<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔪 🤷🏼 👨🏻‍⚖️ Tidak berguna menangguhkan pesan non-pemblokiran di MPI: analisis ringan dan tutorial untuk mereka yang sedikit "dalam subjek" 🆘 🤙🏼 ⏏️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Baru-baru ini, saya harus menyelesaikan tugas pelatihan sepele lainnya dari guru saya. Namun, menyelesaikannya, saya berhasil menarik perhatian pada h...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tidak berguna menangguhkan pesan non-pemblokiran di MPI: analisis ringan dan tutorial untuk mereka yang sedikit "dalam subjek"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/427219/">  Baru-baru ini, saya harus menyelesaikan tugas pelatihan sepele lainnya dari guru saya.  Namun, menyelesaikannya, saya berhasil menarik perhatian pada hal-hal yang sebelumnya tidak saya pikirkan, mungkin Anda juga tidak memikirkannya.  Artikel ini akan lebih bermanfaat bagi siswa dan semua orang yang memulai perjalanan mereka ke dunia pemrograman paralel menggunakan MPI. <br><br><img src="https://habrastorage.org/webt/v0/ik/2-/v0ik2-rxhe1gexlrsumqpwhslbu.jpeg"><br><br><h2>  "Diberikan:" </h2><br>  Jadi, esensi dari tugas komputasi kami adalah membandingkan berapa kali suatu program yang menggunakan transfer point-to-point yang tertunda lebih cepat daripada yang menggunakan transfer point-to-point blocking.  Kami akan melakukan pengukuran untuk input array dimensi 64, 256, 1024, 4096, 8192, 16384, 65536, 262144, 1048576, 4194304, 16777216, 16777216, 33554432 elemen.  Secara default, diusulkan untuk menyelesaikannya dengan empat proses.  Dan di sini, pada kenyataannya, adalah apa yang akan kita pertimbangkan: <br><br><a name="habracut"></a><img src="https://habrastorage.org/webt/rt/vc/vo/rtvcvob3gfonidkax7qtskxfbc0.png"><cut></cut><br><br>  Pada output, kita harus mendapatkan tiga vektor: Y1, Y2 dan Y3, yang proses nol akan kumpulkan.  Saya akan menguji semua ini pada sistem saya berdasarkan pada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">prosesor Intel</a> dengan 16 GB RAM.  Untuk mengembangkan program, kami akan menggunakan implementasi standar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MPI dari Microsoft versi 9.0.1</a> (pada saat penulisan, ini relevan), Visual Studio Community 2017 dan bukan Fortran. <br><br><h2>  Materiel </h2><br>  Saya tidak ingin menjelaskan secara rinci bagaimana fungsi MPI yang akan digunakan bekerja, Anda selalu dapat pergi dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">melihat dokumentasi untuk ini</a> , jadi saya hanya akan memberikan gambaran singkat tentang apa yang akan kita gunakan. <br><br><h4>  Memblokir pertukaran </h4><br>  <b>Untuk memblokir pengiriman pesan titik-ke-titik, kami akan menggunakan fungsi-fungsi:</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MPI_Send</a> - mengimplementasikan pemblokiran pengiriman pesan, mis.  setelah memanggil fungsi, proses diblokir sampai data yang dikirim ke dalamnya ditulis dari memorinya ke buffer sistem internal MPI, setelah itu proses terus bekerja lebih jauh; <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MPI_Recv</a> - melakukan pemblokiran penerimaan pesan, mis.  Setelah memanggil fungsi, proses diblokir sampai data dari proses pengiriman tiba dan sampai data ini sepenuhnya ditulis ke buffer proses penerimaan oleh lingkungan MPI. <br><br><h4>  Pertukaran non-blocking yang ditangguhkan </h4><br>  <b>Untuk pengiriman pesan titik-ke-titik yang ditangguhkan, kami akan menggunakan fungsi-fungsi ini:</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MPI_Send_init</a> - di latar belakang menyiapkan lingkungan untuk mengirim data yang akan terjadi di masa depan dan tidak ada kunci; <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MPI_Recv_init</a> - fungsi ini bekerja mirip dengan yang sebelumnya, hanya kali ini untuk menerima data; <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MPI_Start</a> - memulai proses penerimaan atau pengiriman pesan, ini juga berjalan di latar belakang a.k.a.  tanpa menghalangi; <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MPI_Wait</a> - digunakan untuk memeriksa dan, jika perlu, menunggu penyelesaian pengiriman atau penerimaan pesan, tetapi hanya memblokir proses jika perlu (jika data "tidak terkirim" atau "tidak diterima").  Misalnya, suatu proses ingin menggunakan data yang belum mencapainya - tidak baik, oleh karena itu, masukkan MPI_Tunggu di depan tempat yang membutuhkan data ini (masukkan meskipun ada risiko korupsi data).  Contoh lain, proses memulai transfer data latar belakang, dan setelah memulai transfer data, ia segera mulai mengubah data ini entah bagaimana - tidak baik, jadi kami menyisipkan MPI_Wait di depan tempat dalam program di mana ia mulai mengubah data ini (di sini kami juga memasukkannya meskipun hanya ada risiko korupsi data). <br><br>  Dengan demikian, secara <i>semantik</i> urutan panggilan dengan pertukaran non-pemblokiran yang ditangguhkan adalah sebagai berikut: <br><br><ol><li>  MPI_Send_init / MPI_Recv_init - mempersiapkan lingkungan untuk menerima atau mentransmisikan </li><li>  MPI_Start - mulai proses penerimaan / transmisi </li><li>  MPI_Wait - kami menyebut beresiko kerusakan (termasuk "undersending" dan "underreporting") dari data yang dikirim atau diterima </li></ol><br>  Saya juga menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MPI_Startall</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MPI_Waitall</a> dalam program pengujian saya, artinya pada dasarnya sama dengan MPI_Start dan MPI_Wait, masing-masing, hanya beroperasi pada beberapa paket dan / atau transmisi.  Tapi ini bukan daftar seluruh fungsi mulai dan menunggu, ada beberapa fungsi lagi untuk memeriksa kelengkapan operasi. <br><br><h2>  Arsitektur antar proses </h2><br>  Untuk kejelasan, kami membuat grafik untuk melakukan perhitungan dengan empat proses.  Pada saat yang sama, seseorang harus mencoba untuk mendistribusikan semua operasi aritmatika vektor relatif merata selama proses.  Inilah yang saya dapatkan: <br><br><img src="https://habrastorage.org/webt/bq/_b/q4/bq_bq43yrgkgjayi8p5uy0g9ckk.png"><br><br>  Lihat array ini T0-T2?  Ini adalah buffer untuk menyimpan hasil operasi menengah.  Juga, pada grafik saat mengirim pesan dari satu proses ke proses lainnya, di awal panah adalah nama array yang datanya ditransmisikan, dan di ujung panah adalah array yang menerima data ini. <br><br>  Nah, kapan kita akhirnya menjawab pertanyaan: <br><br><ol><li>  Masalah apa yang kita selesaikan? </li><li>  Alat apa yang akan kita gunakan untuk menyelesaikannya? </li><li>  Bagaimana kita akan menyelesaikannya? </li></ol><br>  Tetap hanya untuk menyelesaikannya ... <br><br><h2>  "Solusi:" kami </h2><br>  Selanjutnya, saya akan mempresentasikan kode-kode dari dua program yang dibahas di atas, tetapi untuk permulaan saya akan memberikan beberapa penjelasan lebih lanjut tentang apa dan bagaimana. <br><br>  Saya mengambil semua operasi aritmatika vektor dalam prosedur terpisah (tambahkan, sub, mul, div) untuk meningkatkan keterbacaan kode.  Semua array input diinisialisasi sesuai dengan rumus yang saya sebutkan <i>hampir</i> secara acak.  Karena proses nol mengumpulkan hasil kerja dari semua proses lain, maka, itu bekerja paling lama, oleh karena itu logis untuk mempertimbangkan waktu kerjanya sama dengan runtime program (seperti yang kita ingat, kita tertarik pada: aritmatika + pesan) dalam kasus pertama dan kedua.  Kami akan mengukur interval waktu menggunakan fungsi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MPI_Wtime,</a> dan pada saat yang sama saya memutuskan untuk menampilkan resolusi jam tangan apa yang saya miliki di sana menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MPI_Wtick</a> (di suatu tempat di jiwa saya, saya berharap mereka cocok dengan TSC saya yang invarian, dalam hal ini, saya bahkan siap memaafkan kesalahan mereka. terkait dengan waktu fungsi itu disebut MPI_Wtime).  Jadi, kita akan mengumpulkan semua yang saya tulis di atas dan sesuai dengan grafik kita akhirnya akan mengembangkan program-program ini (dan tentu saja debug juga). <br><br><hr><br>  Siapa yang peduli melihat kode: <br><br><div class="spoiler">  <b class="spoiler_title">Program dengan memblokir transfer data</b> <div class="spoiler_text"><pre><code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"pch.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;iostream&gt; #include &lt;iomanip&gt; #include &lt;fstream&gt; #include &lt;mpi.h&gt; using namespace std; void add(double *A, double *B, double *C, int n); void sub(double *A, double *B, double *C, int n); void mul(double *A, double *B, double *C, int n); void div(double *A, double *B, double *C, int n); int main(int argc, char **argv) { if (argc &lt; 2) { return 1; } int n = atoi(argv[1]); int rank; double start_time, end_time; MPI_Status status; double *A = new double[n]; double *B = new double[n]; double *C = new double[n]; double *D = new double[n]; double *E = new double[n]; double *G = new double[n]; double *T0 = new double[n]; double *T1 = new double[n]; double *T2 = new double[n]; for (int i = 0; i &lt; n; i++) { A[i] = double (2 * i + 1); B[i] = double(2 * i); C[i] = double(0.003 * (i + 1)); D[i] = A[i] * 0.001; E[i] = B[i]; G[i] = C[i]; } cout.setf(ios::fixed); cout &lt;&lt; fixed &lt;&lt; setprecision(9); MPI_Init(&amp;argc, &amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank); if (rank == 0) { start_time = MPI_Wtime(); sub(A, B, T0, n); MPI_Send(T0, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD); MPI_Send(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD); div(T0, G, T1, n); MPI_Recv(T2, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;status); add(T1, T2, T0, n); mul(T0, T1, T2, n); MPI_Recv(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;status); MPI_Send(T2, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD); add(T0, T2, T1, n); MPI_Recv(T0, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;status); MPI_Recv(T2, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;status); end_time = MPI_Wtime(); cout &lt;&lt; "Clock resolution: " &lt;&lt; MPI_Wtick() &lt;&lt; " secs" &lt;&lt; endl; cout &lt;&lt; "Thread " &lt;&lt; rank &lt;&lt; " execution time: " &lt;&lt; end_time - start_time &lt;&lt; endl; } if (rank == 1) { add(C, C, T0, n); MPI_Recv(T1, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;status); MPI_Send(T0, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD); mul(T1, G, T2, n); add(T2, C, T0, n); MPI_Recv(T1, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;status); MPI_Send(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD); sub(T1, T0, T2, n); MPI_Recv(T0, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;status); add(T0, T2, T1, n); MPI_Send(T1, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD); } if (rank == 2) { mul(C, C, T0, n); MPI_Recv(T1, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;status); MPI_Recv(T2, n, MPI_DOUBLE, 3, 0, MPI_COMM_WORLD, &amp;status); MPI_Send(T0, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD); MPI_Send(T0, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD); add(T1, T2, T0, n); mul(T0, G, T1, n); MPI_Recv(T2, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;status); mul(T1, T2, T0, n); MPI_Recv(T1, n, MPI_DOUBLE, 3, 0, MPI_COMM_WORLD, &amp;status); mul(T0, T1, T2, n); MPI_Send(T2, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD); } if (rank == 3) { mul(E, D, T0, n); MPI_Send(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD); sub(T0, B, T1, n); mul(T1, T1, T2, n); sub(T1, G, T0, n); mul(T0, T2, T1, n); MPI_Send(T1, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD); } MPI_Finalize(); delete[] A; delete[] B; delete[] C; delete[] D; delete[] E; delete[] G; delete[] T0; delete[] T1; delete[] T2; return 0; } void add(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] + B[i]; } } void sub(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] - B[i]; } } void mul(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] * B[i]; } } void div(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] / B[i]; } }</span></span></span></span></code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">Program dengan transfer data non-pemblokiran yang ditangguhkan</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"pch.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;iostream&gt; #include &lt;iomanip&gt; #include &lt;fstream&gt; #include &lt;mpi.h&gt; using namespace std; void add(double *A, double *B, double *C, int n); void sub(double *A, double *B, double *C, int n); void mul(double *A, double *B, double *C, int n); void div(double *A, double *B, double *C, int n); int main(int argc, char **argv) { if (argc &lt; 2) { return 1; } int n = atoi(argv[1]); int rank; double start_time, end_time; MPI_Request request[7]; MPI_Status statuses[4]; double *A = new double[n]; double *B = new double[n]; double *C = new double[n]; double *D = new double[n]; double *E = new double[n]; double *G = new double[n]; double *T0 = new double[n]; double *T1 = new double[n]; double *T2 = new double[n]; for (int i = 0; i &lt; n; i++) { A[i] = double(2 * i + 1); B[i] = double(2 * i); C[i] = double(0.003 * (i + 1)); D[i] = A[i] * 0.001; E[i] = B[i]; G[i] = C[i]; } cout.setf(ios::fixed); cout &lt;&lt; fixed &lt;&lt; setprecision(9); MPI_Init(&amp;argc, &amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank); if (rank == 0) { start_time = MPI_Wtime(); MPI_Send_init(T0, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;request[0]);// MPI_Send_init(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[1]);// MPI_Recv_init(T2, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;request[2]);// MPI_Recv_init(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[3]);// MPI_Send_init(T2, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;request[4]);// MPI_Recv_init(T0, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;request[5]);// MPI_Recv_init(T2, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[6]);// MPI_Start(&amp;request[2]); sub(A, B, T0, n); MPI_Startall(2, &amp;request[0]); div(T0, G, T1, n); MPI_Waitall(3, &amp;request[0], statuses); add(T1, T2, T0, n); mul(T0, T1, T2, n); MPI_Startall(2, &amp;request[3]); MPI_Wait(&amp;request[3], &amp;statuses[0]); add(T0, T2, T1, n); MPI_Startall(2, &amp;request[5]); MPI_Wait(&amp;request[4], &amp;statuses[0]); MPI_Waitall(2, &amp;request[5], statuses); end_time = MPI_Wtime(); cout &lt;&lt; "Clock resolution: " &lt;&lt; MPI_Wtick() &lt;&lt; " secs" &lt;&lt; endl; cout &lt;&lt; "Thread " &lt;&lt; rank &lt;&lt; " execution time: " &lt;&lt; end_time - start_time &lt;&lt; endl; } if (rank == 1) { MPI_Recv_init(T1, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[0]);// MPI_Send_init(T0, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[1]);// MPI_Recv_init(T1, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[2]);// MPI_Send_init(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[3]);// MPI_Recv_init(T0, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[4]);// MPI_Send_init(T1, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[5]);// MPI_Start(&amp;request[0]); add(C, C, T0, n); MPI_Start(&amp;request[1]); MPI_Wait(&amp;request[0], &amp;statuses[0]); mul(T1, G, T2, n); MPI_Start(&amp;request[2]); MPI_Wait(&amp;request[1], &amp;statuses[0]); add(T2, C, T0, n); MPI_Start(&amp;request[3]); MPI_Wait(&amp;request[2], &amp;statuses[0]); sub(T1, T0, T2, n); MPI_Wait(&amp;request[3], &amp;statuses[0]); MPI_Start(&amp;request[4]); MPI_Wait(&amp;request[4], &amp;statuses[0]); add(T0, T2, T1, n); MPI_Start(&amp;request[5]); MPI_Wait(&amp;request[5], &amp;statuses[0]); } if (rank == 2) { MPI_Recv_init(T1, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[0]);// MPI_Recv_init(T2, n, MPI_DOUBLE, 3, 0, MPI_COMM_WORLD, &amp;request[1]);// MPI_Send_init(T0, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;request[2]);// MPI_Send_init(T0, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[3]);// MPI_Recv_init(T2, n, MPI_DOUBLE, 1, 0, MPI_COMM_WORLD, &amp;request[4]);// MPI_Recv_init(T1, n, MPI_DOUBLE, 3, 0, MPI_COMM_WORLD, &amp;request[5]);// MPI_Send_init(T2, n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;request[6]);// MPI_Startall(2, &amp;request[0]); mul(C, C, T0, n); MPI_Startall(2, &amp;request[2]); MPI_Waitall(4, &amp;request[0], statuses); add(T1, T2, T0, n); MPI_Start(&amp;request[4]); mul(T0, G, T1, n); MPI_Wait(&amp;request[4], &amp;statuses[0]); mul(T1, T2, T0, n); MPI_Start(&amp;request[5]); MPI_Wait(&amp;request[5], &amp;statuses[0]); mul(T0, T1, T2, n); MPI_Start(&amp;request[6]); MPI_Wait(&amp;request[6], &amp;statuses[0]); } if (rank == 3) { MPI_Send_init(T0, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[0]); MPI_Send_init(T1, n, MPI_DOUBLE, 2, 0, MPI_COMM_WORLD, &amp;request[1]); mul(E, D, T0, n); MPI_Start(&amp;request[0]); sub(T0, B, T1, n); mul(T1, T1, T2, n); MPI_Wait(&amp;request[0], &amp;statuses[0]); sub(T1, G, T0, n); mul(T0, T2, T1, n); MPI_Start(&amp;request[1]); MPI_Wait(&amp;request[1], &amp;statuses[0]); } MPI_Finalize(); delete[] A; delete[] B; delete[] C; delete[] D; delete[] E; delete[] G; delete[] T0; delete[] T1; delete[] T2; return 0; } void add(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] + B[i]; } } void sub(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] - B[i]; } } void mul(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] * B[i]; } } void div(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] / B[i]; } }</span></span></span></span></code> </pre></div></div><br><hr><br><h2>  Pengujian dan analisis </h2><br>  Mari kita jalankan program kami untuk array dengan ukuran berbeda dan lihat apa yang terjadi.  Hasil pengujian dirangkum dalam tabel, di kolom terakhir yang kami hitung dan tulis koefisien percepatannya, yang kami definisikan sebagai berikut: K <sub>accele</sub> = T <sub>ex.</sub>  <sub>non-blok.</sub>  / T <sub>blok.</sub> <br><br><img src="https://habrastorage.org/webt/ba/hg/zv/bahgzvsgz67vnkfsji-swsyy_cg.png"><br><br>  Jika Anda melihat tabel ini sedikit lebih hati-hati dari biasanya, Anda akan melihat bahwa dengan peningkatan jumlah elemen yang diproses, koefisien percepatan menurun entah bagaimana seperti ini: <br><br><img src="https://habrastorage.org/webt/qq/to/hv/qqtohvv7azbc05r6x4mwtfbbxfe.png"><br><br>  Mari kita coba menentukan apa masalahnya?  Untuk melakukan ini, saya mengusulkan untuk menulis program uji kecil yang akan mengukur waktu setiap operasi aritmatika vektor dan dengan hati-hati mengurangi hasilnya menjadi file teks biasa. <br><br><hr><br>  Di sini, pada kenyataannya, program itu sendiri: <br><br><div class="spoiler">  <b class="spoiler_title">Pengukuran waktu</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"pch.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;iostream&gt; #include &lt;iomanip&gt; #include &lt;Windows.h&gt; #include &lt;fstream&gt; using namespace std; void add(double *A, double *B, double *C, int n); void sub(double *A, double *B, double *C, int n); void mul(double *A, double *B, double *C, int n); void div(double *A, double *B, double *C, int n); int main() { struct res { double add; double sub; double mul; double div; }; int i, j, k, n, loop; LARGE_INTEGER start_time, end_time, freq; ofstream fout("test_measuring.txt"); int N[12] = { 64, 256, 1024, 4096, 8192, 16384, 65536, 262144, 1048576, 4194304, 16777216, 33554432 }; SetConsoleOutputCP(1251); cout &lt;&lt; "   loop: "; cin &gt;&gt; loop; fout &lt;&lt; setiosflags(ios::fixed) &lt;&lt; setiosflags(ios::right) &lt;&lt; setprecision(9); fout &lt;&lt; " : " &lt;&lt; loop &lt;&lt; endl; fout &lt;&lt; setw(10) &lt;&lt; "\n " &lt;&lt; setw(30) &lt;&lt; ".   (c)" &lt;&lt; setw(30) &lt;&lt; ".   (c)" &lt;&lt; setw(30) &lt;&lt; ".  (c)" &lt;&lt; setw(30) &lt;&lt; ".   (c)" &lt;&lt; endl; QueryPerformanceFrequency(&amp;freq); cout &lt;&lt; "\n : " &lt;&lt; freq.QuadPart &lt;&lt; " " &lt;&lt; endl; for (k = 0; k &lt; sizeof(N) / sizeof(int); k++) { res output = {}; n = N[k]; double *A = new double[n]; double *B = new double[n]; double *C = new double[n]; for (i = 0; i &lt; n; i++) { A[i] = 2.0 * i; B[i] = 2.0 * i + 1; C[i] = 0; } for (j = 0; j &lt; loop; j++) { QueryPerformanceCounter(&amp;start_time); add(A, B, C, n); QueryPerformanceCounter(&amp;end_time); output.add += double(end_time.QuadPart - start_time.QuadPart) / double(freq.QuadPart); QueryPerformanceCounter(&amp;start_time); sub(A, B, C, n); QueryPerformanceCounter(&amp;end_time); output.sub += double(end_time.QuadPart - start_time.QuadPart) / double(freq.QuadPart); QueryPerformanceCounter(&amp;start_time); mul(A, B, C, n); QueryPerformanceCounter(&amp;end_time); output.mul += double(end_time.QuadPart - start_time.QuadPart) / double(freq.QuadPart); QueryPerformanceCounter(&amp;start_time); div(A, B, C, n); QueryPerformanceCounter(&amp;end_time); output.div += double(end_time.QuadPart - start_time.QuadPart) / double(freq.QuadPart); } fout &lt;&lt; setw(10) &lt;&lt; n &lt;&lt; setw(30) &lt;&lt; output.add / loop &lt;&lt; setw(30) &lt;&lt; output.sub / loop &lt;&lt; setw(30) &lt;&lt; output.mul / loop &lt;&lt; setw(30) &lt;&lt; output.div / loop &lt;&lt; endl; delete[] A; delete[] B; delete[] C; } fout.close(); cout &lt;&lt; endl; system("pause"); return 0; } void add(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] + B[i]; } } void sub(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] - B[i]; } } void mul(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] * B[i]; } } void div(double *A, double *B, double *C, int n) { for (size_t i = 0; i &lt; n; i++) { C[i] = A[i] / B[i]; } }</span></span></span></span></code> </pre></div></div><br><hr><br>  Saat startup, ia meminta Anda untuk memasukkan jumlah siklus pengukuran, saya menguji 10.000 siklus.  Pada output, kami memperoleh hasil rata-rata untuk setiap operasi: <br><br><img src="https://habrastorage.org/webt/iz/0g/bs/iz0gbs8ilynlmbchxtga_0at61s.png"><br><br>  Untuk mengukur waktu, saya menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">QueryPerformanceCounter</a> tingkat tinggi.  Saya sangat menyarankan membaca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">FAQ ini</a> sehingga sebagian besar pertanyaan tentang mengukur waktu dengan fungsi ini akan hilang sendiri.  Menurut pengamatan saya, itu melekat pada TSC (tetapi secara teoritis mungkin bukan untuk itu), tetapi mengembalikan, menurut bantuan, jumlah kutu saat ini dari kutu.  Tetapi kenyataannya adalah bahwa penghitung saya secara fisik tidak dapat mengukur interval waktu 32 ns (lihat baris pertama dari tabel hasil).  Hasil ini disebabkan oleh fakta bahwa antara dua panggilan dari QueryPerformanceCounter 0 ticks atau 1 ticks pass. Untuk baris pertama dalam tabel, kita hanya dapat menyimpulkan bahwa sekitar sepertiga dari 10.000 hasil adalah 1 tick.  <i>Jadi data dalam tabel ini untuk 64, 256 dan bahkan untuk 1024 elemen adalah sesuatu yang cukup mendekati.</i>  Sekarang, mari kita buka salah satu program dan hitung berapa banyak total operasi dari setiap jenis yang dihadapinya, secara tradisional kita akan “menyebar” semuanya sesuai dengan tabel berikut: <br><br><img src="https://habrastorage.org/webt/et/vo/w2/etvow2fj-vxgtusc9aez__9egxq.png"><br><br>  Akhirnya, kita tahu waktu setiap operasi aritmatika vektor dan berapa banyak yang ada dalam program kami, cobalah untuk mencari tahu berapa banyak waktu yang dihabiskan untuk operasi ini dalam program paralel dan berapa banyak waktu yang dihabiskan untuk memblokir dan menunda pertukaran data non-blocking antara proses dan sekali lagi, untuk kejelasan, kami akan mengurangi ini menjadi meja: <br><br><img src="https://habrastorage.org/webt/no/k2/-0/nok2-0p1kpw8g1ahveqog4q9lzi.png"><br><br>  Berdasarkan hasil data yang diperoleh, kami membuat grafik tiga fungsi: yang pertama menjelaskan perubahan waktu yang dihabiskan untuk memblokir transfer antar proses, dari jumlah elemen array, yang kedua menjelaskan perubahan waktu yang dihabiskan untuk transfer non-blocking yang ditangguhkan antar proses, pada jumlah elemen array dan yang ketiga menjelaskan perubahan waktu, dihabiskan untuk operasi aritmatika, dari sejumlah elemen array: <br><br><img src="https://habrastorage.org/webt/4e/w6/5h/4ew65htbb-s3vh7anlo0txafxpg.png"><br><br>  Seperti yang telah Anda perhatikan, skala vertikal grafik adalah logaritmik, karena itu adalah ukuran yang perlu, karena  penyebaran waktu terlalu besar dan pada grafik biasa tidak ada yang terlihat.  Perhatikan fungsi ketergantungan waktu yang dihabiskan untuk aritmatika pada jumlah elemen, itu dengan aman menyalip dua fungsi lainnya oleh sekitar 1 juta elemen.  Masalahnya adalah ia tumbuh lebih cepat daripada dua lawannya.  Oleh karena itu, dengan peningkatan jumlah elemen yang diproses, runtime program lebih banyak ditentukan oleh aritmatika daripada transfer.  Misalkan Anda meningkatkan jumlah transfer antar proses, secara konseptual Anda hanya akan melihat bahwa saat ketika fungsi aritmatika menyusul dua lainnya akan terjadi kemudian. <br><br><h2>  Ringkasan </h2><br>  Dengan demikian, terus meningkatkan panjang array, Anda akan sampai pada kesimpulan bahwa program dengan transfer non-blocking yang ditangguhkan hanya akan sedikit lebih cepat daripada yang menggunakan blocking exchange.  Dan jika Anda mengarahkan panjang array ke tak terhingga (baik, atau hanya mengambil array sangat lama), maka waktu operasi program Anda akan 100% ditentukan oleh perhitungan, dan koefisien akselerasi dengan aman akan cenderung ke 1. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id427219/">https://habr.com/ru/post/id427219/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id427207/index.html">Karyawan Rockstar membela perusahaan setelah kritik selama 100 jam minggu kerja</a></li>
<li><a href="../id427209/index.html">GeoPuzzle - buat sepotong demi sepotong dunia</a></li>
<li><a href="../id427211/index.html">Elektron adalah flash untuk desktop</a></li>
<li><a href="../id427215/index.html">Layanan microser perlu tumbuh, bukan memulainya</a></li>
<li><a href="../id427217/index.html">Analisis Kinerja Server WSGI: Bagian Dua</a></li>
<li><a href="../id427221/index.html">Apa yang saya sadari dalam perjalanan saya ke mimpi kecerdasan buatan</a></li>
<li><a href="../id427223/index.html">Apa tanggung jawab pengembang utama</a></li>
<li><a href="../id427225/index.html">Oracle Database 18c XE dirilis</a></li>
<li><a href="../id427227/index.html">Bagaimana kami membuat permainan papan dengan remote control - Bagian 2</a></li>
<li><a href="../id427229/index.html">4 tahun program Manajemen Proyek Game</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
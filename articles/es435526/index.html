<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶è ‚û∞ üì† Aventuras con un grupo de Kubernetes casero ü§ß üôåüèø üßöüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nota perev. : El autor del art√≠culo, Marshall Brekka, ocupa el puesto de director de dise√±o de sistemas en Fair.com, que ofrece su aplicaci√≥n para el ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aventuras con un grupo de Kubernetes casero</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/435526/">  <i><b>Nota</b></i>  <i><b>perev.</b></i>  <i>: El autor del art√≠culo, Marshall Brekka, ocupa el puesto de director de dise√±o de sistemas en Fair.com, que ofrece su aplicaci√≥n para el arrendamiento de autom√≥viles.</i>  <i>En su tiempo libre, le gusta usar su amplia experiencia para resolver problemas de "hogar" que probablemente no sorprendan a ning√∫n geek (por lo tanto, la pregunta "¬øPor qu√©?", ‚Äã‚ÄãCon respecto a las acciones que se describen a continuaci√≥n, se omite a priori).</i>  <i>Entonces, en su publicaci√≥n, Marshall comparte los resultados del reciente despliegue de Kubernetes en ... tableros ARM.</i> <br><br><img src="https://habrastorage.org/webt/ul/nj/do/ulnjdoyysctwv-34jhuyn-wvsp8.png"><br><br>  Como muchos otros geeks, a lo largo de los a√±os he acumulado una variedad de placas de desarrollo como la Raspberry Pi.  Y como muchos geeks, se sacudieron el polvo en los estantes con la idea de que alg√∫n d√≠a ser√≠an √∫tiles.  ¬°Y ahora para m√≠ este d√≠a finalmente ha llegado! <a name="habracut"></a><br><br>  Durante las vacaciones de invierno, aparecieron varias semanas fuera del trabajo, dentro de las cuales hab√≠a suficiente tiempo para inventariar todo el hierro acumulado y decidir qu√© hacer con √©l.  Aqu√≠ est√° lo que ten√≠a: <br><br><ul><li>  Caja RAID de 5 unidades con conexi√≥n USB3; </li><li>  Raspberry Pi Modelo B (modelo OG); </li><li>  CubbieBoard 1; </li><li>  Banana Pi M1; </li><li>  Netbook HP (2012?). </li></ul><br>  De los 5 componentes de hierro enumerados, utilic√© a menos que RAID y una netbook como un NAS temporal.  Sin embargo, debido a la falta de compatibilidad con USB3 en el netbook, RAID no utiliz√≥ el potencial de velocidad m√°xima. <br><br><h2>  Metas de la vida </h2><br>  Dado que trabajar con RAID no era √≥ptimo al usar una netbook, establec√≠ los siguientes objetivos para obtener la mejor configuraci√≥n: <br><br><ol><li>  NAS con USB3 y Gigabit Ethernet; </li><li>  La mejor manera de administrar el software en su dispositivo </li><li>  (bono) la capacidad de transmitir contenido multimedia de RAID a Fire TV. </li></ol><br>  Dado que ninguno de los dispositivos disponibles admit√≠a USB3 y Gigabit Ethernet, desafortunadamente, tuve que hacer compras adicionales.  La elecci√≥n recay√≥ en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ROC-RK3328-CC</a> .  Ella pose√≠a todas las especificaciones necesarias y suficiente soporte para los sistemas operativos. <br><br>  Habiendo resuelto mis necesidades de hardware (y esperando la llegada de esta soluci√≥n), cambi√© al segundo objetivo. <br><br><h2>  Administrar software en el dispositivo </h2><br>  En parte, mis proyectos anteriores relacionados con las juntas de desarrollo han fallado debido a una atenci√≥n insuficiente a los problemas de reproducibilidad y documentaci√≥n.  Al crear la siguiente configuraci√≥n para mis necesidades actuales, no me molest√© en escribir los pasos tomados o los enlaces a las publicaciones de blog que segu√≠.  Y cuando, despu√©s de meses o a√±os, algo sali√≥ mal y trat√© de solucionar el problema, no entend√≠ c√≥mo estaba todo arreglado originalmente. <br><br>  ¬°Entonces me dije que esta vez todo ser√° diferente! <br><br><img src="https://habrastorage.org/webt/dm/vb/iv/dmvbivkoa65wfd1ve5mo5wh5jdc.jpeg"><br><br>  Y se volvi√≥ hacia el hecho de que yo s√© bastante bien: a Kubernetes. <br><br>  Aunque K8s es una soluci√≥n demasiado dif√≠cil para un problema bastante simple, despu√©s de casi tres a√±os de administrar cl√∫steres utilizando varias herramientas (la m√≠a, la de Kops, etc.) en mi trabajo principal, estoy muy familiarizado con este sistema.  Adem√°s, desplegar K8 fuera de un entorno de nube, e incluso en dispositivos ARM, todo esto parec√≠a una tarea interesante. <br><br>  Tambi√©n pens√© que, dado que el hardware disponible no cumple con los requisitos necesarios para el NAS, intentar√© al menos ensamblar un cl√∫ster a partir de √©l y, tal vez, alg√∫n software que no requiera tantos recursos pueda funcionar en dispositivos m√°s antiguos. <br><br><h2>  Kubernetes en ARM </h2><br>  En el trabajo, no tuve la oportunidad de usar la utilidad <code>kubeadm</code> para implementar cl√∫steres, as√≠ que decid√≠ que ahora era el momento de probarlo en acci√≥n. <br><br>  Raspbian fue elegido como sistema operativo, porque es famoso por el mejor soporte para mis tableros. <br><br>  Encontr√© un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">buen art√≠culo</a> sobre c√≥mo configurar Kubernetes en una Raspberry Pi usando HypriotOS.  Como no estaba seguro de la disponibilidad de HypriotOS para todos mis tableros, adapt√© estas instrucciones para Debian / Raspbian. <br><br><h3>  Componentes requeridos </h3><br>  Primero, se requiri√≥ la instalaci√≥n de las siguientes herramientas: <br><br><ul><li>  Docker </li><li>  kubelet </li><li>  kubeadm, </li><li>  kubectl. </li></ul><br>  Docker debe instalarse usando un script especial: script de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">conveniencia</a> (como se indica para el caso de usar Raspbian). <br><br><pre> <code class="bash hljs">curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh</code> </pre> <br>  Despu√©s de eso, instal√© los componentes de Kubernetes de acuerdo con las instrucciones del blog de Hypriot, adapt√°ndolos para que se usen versiones espec√≠ficas para todas las dependencias: <br><br><pre> <code class="bash hljs">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://apt.kubernetes.io/ kubernetes-xenial main"</span></span> &gt; /etc/apt/sources.list.d/kubernetes.list apt-get update apt-get install -y kubelet=1.13.1-00 kubectl=1.13.1-00 kubeadm=1.13.1-00</code> </pre> <br><h3>  Frambuesa pi b </h3><br>  La primera dificultad surgi√≥ al intentar arrancar un cl√∫ster en la Raspberry Pi B: <br><br><pre> <code class="bash hljs">$ kubeadm init Illegal instruction</code> </pre> <br>  Result√≥ que Kubernetes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">elimin√≥ el soporte para ARMv6</a> .  Bueno, tambi√©n tengo CubbieBoard y Banana Pi. <br><br><h3>  Pi pi√±a </h3><br>  Inicialmente, la misma secuencia de acciones para Banana Pi parec√≠a ser m√°s exitosa, sin embargo, el comando <code>kubeadm init</code> tiempo de espera al intentar que el avi√≥n de control funcionara: <br><br><pre> <code class="plaintext hljs">error execution phase wait-control-plane: couldn't initialize a Kubernetes cluster</code> </pre> <br>  Al descubrir con <code>docker ps</code> lo que estaba sucediendo con los contenedores, vi que tanto <code>kube-controller-manager</code> como <code>kube-scheduler</code> hab√≠an estado trabajando durante al menos 4-5 minutos, pero <code>kube-api-server</code> se levant√≥ hace solo 1-2 minutos: <br><br><pre> <code class="bash hljs">$ docker ps CONTAINER ID COMMAND CREATED STATUS de22427ad594 <span class="hljs-string"><span class="hljs-string">"kube-apiserver --au‚Ä¶"</span></span> About a minute ago Up About a minute dc2b70dd803e <span class="hljs-string"><span class="hljs-string">"kube-scheduler --ad‚Ä¶"</span></span> 5 minutes ago Up 5 minutes 60b6cc418a66 <span class="hljs-string"><span class="hljs-string">"kube-controller-man‚Ä¶"</span></span> 5 minutes ago Up 5 minutes 1e1362a9787c <span class="hljs-string"><span class="hljs-string">"etcd --advertise-cl‚Ä¶"</span></span> 5 minutes ago Up 5 minutes</code> </pre> <br>  Obviamente, el <code>api-server</code> estaba muriendo o el proceso de estroncio lo estaba matando y reiniciando. <br><br>  Al revisar los registros, vi procedimientos de inicio muy est√°ndar: hubo un registro del comienzo de la escucha del puerto seguro y una larga pausa antes de la aparici√≥n de numerosos errores en los apretones de manos TLS: <br><br><pre> <code class="plaintext hljs">20:06:48.604881 naming_controller.go:284] Starting NamingConditionController 20:06:48.605031 establishing_controller.go:73] Starting EstablishingController 20:06:50.791098 log.go:172] http: TLS handshake error from 192.168.1.155:50280: EOF 20:06:51.797710 log.go:172] http: TLS handshake error from 192.168.1.155:50286: EOF 20:06:51.971690 log.go:172] http: TLS handshake error from 192.168.1.155:50288: EOF 20:06:51.990556 log.go:172] http: TLS handshake error from 192.168.1.155:50284: EOF 20:06:52.374947 log.go:172] http: TLS handshake error from 192.168.1.155:50486: EOF 20:06:52.612617 log.go:172] http: TLS handshake error from 192.168.1.155:50298: EOF 20:06:52.748668 log.go:172] http: TLS handshake error from 192.168.1.155:50290: EOF</code> </pre> <br>  Y poco despu√©s, el servidor finaliza su trabajo.  Buscar en Google condujo a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tal problema</a> , lo que indica una posible raz√≥n para la lenta operaci√≥n de los algoritmos criptogr√°ficos en algunos dispositivos ARM. <br><br>  Fui m√°s all√° y pens√© que tal vez el <code>api-server</code> recibiendo demasiadas solicitudes repetidas del <code>scheduler</code> y el <code>controller-manager</code> . <br><br>  Eliminar estos archivos del directorio de manifiesto le indicar√° a kubelet que detenga la ejecuci√≥n de los pods correspondientes: <br><br><pre> <code class="bash hljs">mkdir /etc/kubernetes/manifests.bak mv /etc/kubernetes/manifests/kube-scheduler.yaml /etc/kubernetes/manifests.bak/ mv /etc/kubernetes/manifests/kube-controller-mananger.yaml /etc/kubernetes/manifests.bak/</code> </pre> <br>  Ver los √∫ltimos registros de <code>api-server</code> mostr√≥ que ahora el proceso fue m√°s all√°, sin embargo, todav√≠a muri√≥ despu√©s de unos 2 minutos.  Entonces record√© que el manifiesto podr√≠a contener una muestra de vida con tiempos de espera que tienen valores demasiado bajos para un dispositivo tan lento. <br><br>  Por lo tanto, revis√© <code>/etc/kubernetes/manifests/kube-api-server.yaml</code> , y en √©l, por supuesto ... <br><br><pre> <code class="plaintext hljs">livenessProbe: failureThreshold: 8 httpGet: host: 192.168.1.155 path: /healthz port: 6443 scheme: HTTPS initialDelaySeconds: 15 timeoutSeconds: 15</code> </pre> <br>  El pod se mat√≥ despu√©s de 135 segundos ( <code>initialDelaySeconds</code> + <code>timeoutSeconds</code> * <code>failureThreshold</code> ).  Aumente <code>initialDelaySeconds</code> a 120 ... <br><br>  <b>√âxito!</b>  Bueno, todav√≠a ocurren errores de apret√≥n de manos (presumiblemente de kubelet), sin embargo, el lanzamiento a√∫n tuvo lugar: <br><br><pre> <code class="plaintext hljs">20:06:54.957236 log.go:172] http: TLS handshake error from 192.168.1.155:50538: EOF 20:06:55.004865 log.go:172] http: TLS handshake error from 192.168.1.155:50384: EOF 20:06:55.118343 log.go:172] http: TLS handshake error from 192.168.1.155:50292: EOF 20:06:55.252586 cache.go:39] Caches are synced for autoregister controller 20:06:55.253907 cache.go:39] Caches are synced for APIServiceRegistrationController controller 20:06:55.545881 controller_utils.go:1034] Caches are synced for crd-autoregister controller ... 20:06:58.921689 storage_rbac.go:187] created clusterrole.rbac.authorization.k8s.io/cluster-admin 20:06:59.049373 storage_rbac.go:187] created clusterrole.rbac.authorization.k8s.io/system:discovery 20:06:59.214321 storage_rbac.go:187] created clusterrole.rbac.authorization.k8s.io/system:basic-user</code> </pre> <br>  Cuando el <code>api-server</code> se levant√≥, mov√≠ los archivos YAML para el controlador y el planificador nuevamente al directorio de manifiesto, despu√©s de lo cual tambi√©n comenzaron normalmente. <br><br>  Ahora es el momento de asegurarse de que la descarga se realizar√° correctamente si deja todos los archivos en el directorio de origen: ¬øes suficiente para cambiar el retraso permitido en la inicializaci√≥n de <code>livenessProbe</code> ? <br><br><pre> <code class="plaintext hljs">20:29:33.306983 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.Service: Get https://192.168.1.155:6443/api/v1/services?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:33.434541 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.ReplicationController: Get https://192.168.1.155:6443/api/v1/replicationcontrollers?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:33.435799 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.PersistentVolume: Get https://192.168.1.155:6443/api/v1/persistentvolumes?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:33.477405 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1beta1.PodDisruptionBudget: Get https://192.168.1.155:6443/apis/policy/v1beta1/poddisruptionbudgets?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:33.493660 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.PersistentVolumeClaim: Get https://192.168.1.155:6443/api/v1/persistentvolumeclaims?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:37.974938 controller_utils.go:1027] Waiting for caches to sync for scheduler controller 20:29:38.078558 controller_utils.go:1034] Caches are synced for scheduler controller 20:29:38.078867 leaderelection.go:205] attempting to acquire leader lease kube-system/kube-scheduler 20:29:38.291875 leaderelection.go:214] successfully acquired lease kube-system/kube-scheduler</code> </pre> <br>  S√≠, todo funciona, aunque tales dispositivos antiguos, aparentemente, no estaban destinados a lanzar el avi√≥n de control, ya que las conexiones TLS repetidas causan frenos significativos.  De una forma u otra: se recibe una instalaci√≥n funcional de K8 en ARM.  Vamos m√°s all√° ... <br><br><h3>  Montaje RAID </h3><br>  Como las tarjetas SD no son adecuadas para grabar a largo plazo, decid√≠ usar un almacenamiento m√°s confiable para las partes m√°s vol√°tiles del sistema de archivos, en este caso, RAID.  Se destacaron 4 secciones: <br><br><ul><li>  50 GB; </li><li>  2 √ó 20 GB; </li><li>  3.9 Tb. </li></ul><br>  Todav√≠a no se me ocurri√≥ un prop√≥sito espec√≠fico para las particiones de 20 gigabytes, pero quer√≠a dejar oportunidades adicionales para el futuro. <br><br>  En el <code>/etc/fstab</code> para la partici√≥n de 50 GB, el punto de montaje se especific√≥ como <code>/mnt/root</code> y para 3.9 TB - <code>/mnt/raid</code> .  Despu√©s de eso, mont√© los directorios con etcd y docker en la partici√≥n de 50 GB: <br><br><pre> <code class="plaintext hljs">UUID=655a39e8-9a5d-45f3-ae14-73b4c5ed50c3 /mnt/root ext4 defaults,rw,user,auto,exec 0 0 UUID=0633df91-017c-4b98-9b2e-4a0d27989a5c /mnt/raid ext4 defaults,rw,user,auto 0 0 /mnt/root/var/lib/etcd /var/lib/etcd none defaults,bind 0 0 /mnt/root/var/lib/docker /var/lib/docker none defaults,bind 0 0</code> </pre> <br><h3>  Llegada ROC-RK3328-CC </h3><br>  Cuando se entreg√≥ la nueva placa, instal√© los componentes necesarios para los K8 en ella <i>(vea el comienzo del art√≠culo)</i> y <code>kubeadm init</code> .  Unos minutos de espera es el √©xito y la salida del comando de <code>join</code> para ejecutarse en otros nodos. <br><br>  Genial  Sin problemas con los tiempos de espera. <br><br>  Y dado que RAID tambi√©n se usar√° en esta placa, los montajes deber√°n configurarse nuevamente.  Para resumir todos los pasos: <br><br><h4>  1. Monte los discos en / etc / fstab </h4><br><pre> <code class="plaintext hljs">UUID=655a39e8-9a5d-45f3-ae14-73b4c5ed50c3 /mnt/root ext4 defaults,rw,user,auto,exec 0 0 UUID=0633df91-017c-4b98-9b2e-4a0d27989a5c /mnt/raid ext4 defaults,rw,user,auto 0 0 /mnt/root/var/lib/etcd /var/lib/etcd none defaults,bind 0 0 /mnt/root/var/lib/docker /var/lib/docker none defaults,bind 0 0</code> </pre> <br><h4>  2. Instalaci√≥n de los binarios de Docker y K8s </h4><br><pre> <code class="bash hljs">curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh</code> </pre> <br><pre> <code class="bash hljs">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://apt.kubernetes.io/ kubernetes-xenial main"</span></span> &gt; /etc/apt/sources.list.d/kubernetes.list apt-get update apt-get install -y kubelet=1.13.1-00 kubectl=1.13.1-00 kubeadm=1.13.1-00</code> </pre> <br><h4>  3. Configuraci√≥n de un nombre de host √∫nico (importante ya que se agregan muchos nodos) </h4><br><pre> <code class="bash hljs">hostnamectl <span class="hljs-built_in"><span class="hljs-built_in">set</span></span>-hostname k8s-master-1</code> </pre> <br><h4>  4. Inicializaci√≥n de Kubernetes </h4><br>  Omito la fase con el plano de control, porque quiero poder planificar pods normales en este nodo: <br><br><pre> <code class="bash hljs">kubeadm init --skip-phases mark-control-plane</code> </pre> <br><h4>  5. Instalar el complemento de red </h4><br>  La informaci√≥n sobre esto en el art√≠culo de Hypriot estaba un poco anticuada porque el complemento de red Weave ahora tambi√©n es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">compatible con ARM</a> : <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> KUBECONFIG=/etc/kubernetes/admin.conf kubectl apply -f <span class="hljs-string"><span class="hljs-string">"https://cloud.weave.works/k8s/net?k8s-version=</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$(kubectl version | base64 | tr -d '\n')</span></span></span><span class="hljs-string">"</span></span></code> </pre> <br><h4>  6. Agregar etiquetas de host </h4><br>  En este nodo, voy a iniciar el servidor NAS, as√≠ que lo marcar√© con etiquetas para un posible uso futuro en el programador: <br><br><pre> <code class="bash hljs">kubectl label nodes k8s-master-1 marshallbrekka.raid=<span class="hljs-literal"><span class="hljs-literal">true</span></span> kubectl label nodes k8s-master-1 marshallbrekka.network=gigabit</code> </pre> <br><h3>  Conectar otros nodos al cl√∫ster </h3><br>  Configurar otros dispositivos (Banana Pi, CubbieBoard) fue igual de f√°cil.  Para ellos, debe repetir los primeros 3 pasos (cambiar la configuraci√≥n para montar discos / medios flash, seg√∫n su disponibilidad) y ejecutar el comando <code>kubeadm join</code> lugar de <code>kubeadm init</code> . <br><br><h2>  Encontrar contenedores Docker para ARM </h2><br>  La mayor√≠a de los contenedores Docker necesarios se crean normalmente en una Mac, pero para ARM es un poco m√°s complicado.  Despu√©s de haber encontrado muchos art√≠culos sobre c√≥mo usar QEMU para estos fines, llegu√© a la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">conclusi√≥n de</a> que la mayor√≠a de las aplicaciones que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">necesito</a> ya est√°n ensambladas, y muchas de ellas est√°n disponibles en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">linuxserver</a> . <br><br><h2>  Pr√≥ximos pasos </h2><br>  A√∫n sin obtener la configuraci√≥n inicial de los dispositivos en una forma tan automatizada / programada como me gustar√≠a, al menos compuse un conjunto de comandos b√°sicos (monturas, <code>kubeadm</code> <code>docker</code> y <code>kubeadm</code> ) y los document√© en el repositorio de Git.  El resto de las aplicaciones utilizadas tambi√©n recibieron configuraciones YAML para K8 almacenados en el mismo repositorio, por lo que ahora es muy f√°cil obtener la configuraci√≥n necesaria desde cero. <br><br>  En el futuro, me gustar√≠a lograr lo siguiente: <br><br><ol><li>  Hacer sitios maestros altamente disponibles </li><li>  agregar monitoreo / notificaciones para saber sobre fallas en cualquier componente; </li><li>  Cambie la configuraci√≥n de DCHP del enrutador para usar un servidor DNS del cl√∫ster para simplificar el descubrimiento de aplicaciones (¬øqui√©n quiere recordar las direcciones IP internas?); </li><li>  ejecute <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MetalLB</a> para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">reenviar</a> servicios de cl√∫ster a una red privada (DNS, etc.). </li></ol><br><br><h2>  PD del traductor </h2><br>  Lea tambi√©n en nuestro blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Consejos y trucos de Kubernetes: sobre la asignaci√≥n de nodos y la carga en la aplicaci√≥n web</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Consejos y trucos de Kubernetes: acceso a sitios de desarrollo</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Consejos y trucos de Kubernetes: acelerar el arranque de grandes bases de datos</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">11 maneras de (no) convertirse en una v√≠ctima del pirateo de Kubernetes</a> " </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Jugar con Kubernetes es un servicio para conocer los K8 en la pr√°ctica</a> ". </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es435526/">https://habr.com/ru/post/es435526/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es435510/index.html">Microelectr√≥nica, neurofisiolog√≠a y aprendizaje autom√°tico, agite pero no mezcle</a></li>
<li><a href="../es435512/index.html">Los desarrolladores de Royole muestran un tel√©fono inteligente flexible plegable</a></li>
<li><a href="../es435514/index.html">En Rusia, est√°n desarrollando un procesador para acelerar las redes neuronales.</a></li>
<li><a href="../es435520/index.html">Escribimos nuestro lenguaje de programaci√≥n, parte 3: Arquitectura del traductor. An√°lisis de estructuras del lenguaje y expresiones matem√°ticas.</a></li>
<li><a href="../es435522/index.html">Instant√°neas de eventos en Axonframework 3, mejorando el rendimiento</a></li>
<li><a href="../es435528/index.html">5 razones para el √©xito: por qu√© Amazon se ha convertido en la empresa m√°s cara del mundo</a></li>
<li><a href="../es435530/index.html">Suscripciones pagas: dependencia de la conexi√≥n autom√°tica en un dispositivo m√≥vil</a></li>
<li><a href="../es435532/index.html">Tornado vs Aiohttp: un viaje a la naturaleza de los marcos asincr√≥nicos</a></li>
<li><a href="../es435534/index.html">Ciencia de datos: libros de nivel b√°sico</a></li>
<li><a href="../es435536/index.html">Robots humanoides: beneficios y problemas de los mecanismos antropom√≥rficos.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
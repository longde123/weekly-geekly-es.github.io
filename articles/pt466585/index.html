<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèø‚Äçüé® üë®üèΩ‚Äçüî¨ üëèüèº Entendendo os Corretores de Mensagens. Aprendendo a mec√¢nica das mensagens atrav√©s do ActiveMQ e Kafka. Cap√≠tulo 3. Kafka üôéüèø üë©üèΩ‚ÄçüöÄ üë©üèΩ‚Äçüç≥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Continua√ß√£o da tradu√ß√£o de um pequeno livro: 
 "Entendendo os Message Brokers", 
 autor: Jakub Korab, editor: O'Reilly Media, Inc., data de publica√ß√£o...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Entendendo os Corretores de Mensagens. Aprendendo a mec√¢nica das mensagens atrav√©s do ActiveMQ e Kafka. Cap√≠tulo 3. Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/466585/"> Continua√ß√£o da tradu√ß√£o de um pequeno livro: <br>  "Entendendo os Message Brokers", <br>  autor: Jakub Korab, editor: O'Reilly Media, Inc., data de publica√ß√£o: junho de 2017, ISBN: 9781492049296. <br><br>  <b>Tradu√ß√£o conclu√≠da: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tele.gg/middle_java</a></b> <br><br>  Parte anterior: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Compreendendo os Message Brokers.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aprendendo a mec√¢nica das mensagens atrav√©s do ActiveMQ e Kafka.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 2. ActiveMQ</a> <br><a name="habracut"></a><br><h2>  CAP√çTULO 3 </h2><br><h2>  Kafka </h2><br>  O Kafka foi desenvolvido no LinkedIn para contornar algumas das limita√ß√µes dos agentes de mensagens tradicionais e evitar a necessidade de configurar v√°rios agentes de mensagens para diferentes intera√ß√µes ponto a ponto, conforme descrito no livro "Escala vertical e horizontal" na p√°gina 28 deste livro. O LinkedIn se baseou fortemente na absor√ß√£o unidirecional de grandes quantidades de dados, como cliques em p√°ginas e logs de acesso, permitindo que v√°rios sistemas usassem esses dados.  am, sem afetar o desempenho de outros produtores ou konsyumerov.  De fato, a raz√£o pela qual Kafka existe √© obter a arquitetura de mensagens que o Universal Data Pipeline descreve. <br><br>  Dado esse objetivo final, outros requisitos surgiram naturalmente.  Kafka deve: <br><br><ul><li>  Seja extremamente r√°pido </li><li>  Forne√ßa maior rendimento de mensagens </li><li>  Suporte aos modelos Publisher-Subscriber e Point-to-Point </li><li>  N√£o diminua a velocidade com a adi√ß√£o de consumidores.  Por exemplo, o desempenho das filas e dos t√≥picos no ActiveMQ se deteriora √† medida que o n√∫mero de consumidores no destino aumenta. </li><li>  Seja escal√°vel horizontalmente;  se uma √∫nica mensagem persistente puder fazer isso apenas na velocidade m√°xima do disco, para aumentar o desempenho, faz sentido ir al√©m dos limites de uma inst√¢ncia do broker </li><li>  Delinear o acesso ao armazenamento e recupera√ß√£o de mensagens </li></ul><br>  Para conseguir tudo isso, Kafka adotou uma arquitetura que redefiniu as fun√ß√µes e responsabilidades de clientes e intermedi√°rios de mensagens.  O modelo JMS √© muito focado no broker, onde ele √© respons√°vel pela distribui√ß√£o de mensagens, e os clientes precisam apenas se preocupar em enviar e receber mensagens.  Kafka, por outro lado, √© orientado ao cliente, com o cliente assumindo muitas das fun√ß√µes de um corretor tradicional, como a distribui√ß√£o justa de mensagens relevantes entre os consumidores, em troca de receber um corretor extremamente r√°pido e escal√°vel.  Para as pessoas que trabalham com sistemas de mensagens tradicionais, trabalhar com Kafka requer uma mudan√ßa fundamental de atitude. <br>  Essa dire√ß√£o de engenharia levou √† cria√ß√£o de uma infraestrutura de mensagens que pode aumentar a taxa de transfer√™ncia em muitas ordens de magnitude em compara√ß√£o com um corretor convencional.  Como veremos, essa abordagem est√° cheia de compromissos, o que significa que o Kafka n√£o √© adequado para certos tipos de cargas e software instalado. <br><br><h3>  Modelo de destino unificado </h3><br>  Para cumprir os requisitos descritos acima, Kafka combinou a assinatura de publica√ß√£o e as mensagens ponto a ponto em um tipo de destinat√°rio - <i>t√≥pico</i> .  Isso √© confuso para as pessoas que trabalham com sistemas de mensagens, onde a palavra "t√≥pico" se refere a um mecanismo de transmiss√£o do qual (a partir do t√≥pico) a leitura n√£o √© confi√°vel (n√£o √© dur√°vel).  Os t√≥picos Kafka devem ser considerados um tipo de destino h√≠brido, conforme definido na introdu√ß√£o deste livro. <br><blockquote>  No restante deste cap√≠tulo, a menos que especifique explicitamente o contr√°rio, o termo t√≥pico se referir√° ao t√≥pico Kafka. </blockquote><br>  Para entender completamente como os t√≥picos se comportam e quais garantias eles fornecem, primeiro precisamos considerar como eles s√£o implementados no Kafka. <br>  <i>Cada t√≥pico no Kafka tem seu pr√≥prio di√°rio.</i> <br>  Os produtores que enviam mensagens para Kafka anexam-se a esta revista, e os consumidores l√™em a revista usando indicadores que avan√ßam constantemente.  Kafka exclui periodicamente as partes mais antigas do di√°rio, independentemente de as mensagens nessas partes terem sido lidas ou n√£o.  Uma parte central do design da Kafka √© que o broker n√£o se importa se as mensagens s√£o lidas ou n√£o - essa √© a responsabilidade do cliente. <br><blockquote>  Os termos "di√°rio" e "√≠ndice" n√£o s√£o encontrados na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kafka</a> .  Esses termos conhecidos s√£o usados ‚Äã‚Äãaqui para ajudar a entender. </blockquote><br>  Esse modelo √© completamente diferente do ActiveMQ, em que as mensagens de todas as filas s√£o armazenadas em um di√°rio e o broker marca as mensagens como exclu√≠das ap√≥s serem lidas. <br>  Vamos agora um pouco mais fundo e examinar a revista de t√≥picos com mais detalhes. <br>  A Revista Kafka consiste em v√°rias parti√ß√µes ( <a href="">Figura 3-1</a> ).  O Kafka garante pedidos rigorosos em todas as parti√ß√µes.  Isso significa que as mensagens gravadas na parti√ß√£o em uma determinada ordem ser√£o lidas na mesma ordem.  Cada parti√ß√£o √© implementada como um arquivo de log cont√≠nuo (log) que cont√©m um <i>subconjunto de</i> todas as mensagens enviadas ao t√≥pico por seus produtores.  O t√≥pico criado cont√©m uma parti√ß√£o por padr√£o.  O particionamento √© a ideia central de Kafka para dimensionamento horizontal. <br><br><img src="https://habrastorage.org/webt/tm/w2/yf/tmw2yf3lanppqtrumxoidotplhi.png"><br>  <i>Figura 3-1.</i>  <i>Divis√≥rias Kafka</i> <br><br>  Quando o produtor envia uma mensagem para o t√≥pico Kafka, ele decide para qual parti√ß√£o enviar a mensagem.  Consideraremos isso com mais detalhes posteriormente. <br><br><h2>  Lendo mensagens </h2><br>  Um cliente que deseja ler mensagens controla um ponteiro nomeado chamado <i>grupo de consumidores</i> , que indica o <i>deslocamento de uma</i> mensagem em uma parti√ß√£o.  Um deslocamento √© uma posi√ß√£o com um n√∫mero crescente que come√ßa em 0 no in√≠cio da parti√ß√£o.  Esse grupo de consumidores, referido na API por meio de um identificador definido pelo usu√°rio group_id, corresponde a um <i>√∫nico consumidor ou sistema l√≥gico</i> . <br><br>  A maioria dos sistemas de mensagens l√™ dados do destinat√°rio atrav√©s de v√°rias inst√¢ncias e threads para processar mensagens em paralelo.  Assim, geralmente haver√° muitos casos de consumidores que compartilham o mesmo grupo de consumidores. <br><br>  O problema de leitura pode ser representado da seguinte maneira: <br><br><ul><li>  O t√≥pico possui v√°rias parti√ß√µes </li><li>  V√°rios grupos de consumidores podem usar o t√≥pico ao mesmo tempo. </li><li>  Um grupo de consumidores pode ter v√°rias inst√¢ncias separadas. </li></ul><br>  Esse √© um problema n√£o trivial de muitos para muitos.  Para entender como o Kafka lida com os relacionamentos entre grupos de consumidores, inst√¢ncias de consumidores e parti√ß√µes, vamos dar uma olhada em uma s√©rie de scripts de leitura cada vez mais complexos. <br><br><h3>  Consumidores e grupos de consumidores </h3><br>  Vamos considerar um t√≥pico de parti√ß√£o √∫nica como ponto de partida ( <a href="">Figura 3-2</a> ). <br><br><img src="https://habrastorage.org/webt/6z/tz/dh/6ztzdhqmjweck-z15htxb2xbe28.png"><br>  <i>Figura 3-2.</i>  <i>O consumidor l√™ da parti√ß√£o</i> <br><br>  Quando uma inst√¢ncia do consumidor √© conectada com seu pr√≥prio group_id nesse t√≥pico, √© designada uma parti√ß√£o para leitura e um deslocamento nessa parti√ß√£o.  A posi√ß√£o desse deslocamento √© configurada no cliente como um ponteiro para a posi√ß√£o mais recente (a mensagem mais recente) ou a posi√ß√£o mais antiga (a mensagem mais antiga).  O consumidor solicita (pesquisas) mensagens do t√≥pico, o que leva √† leitura sequencial do di√°rio. <br>  A posi√ß√£o de deslocamento √© confirmada regularmente de volta ao Kafka e salva como mensagens no t√≥pico interno <i>_consumer_offsets</i> .  As mensagens de leitura ainda n√£o s√£o exclu√≠das, ao contr√°rio de um broker regular, e o cliente pode retroceder o deslocamento para processar novamente as mensagens j√° exibidas. <br><br>  Quando um segundo consumidor l√≥gico √© conectado usando outro group_id, ele controla um segundo ponteiro que √© independente do primeiro ( <a href="">Figura 3-3</a> ).  Assim, o t√≥pico Kafka atua como uma fila na qual h√° um consumidor e, como um t√≥pico regular, como assinante-publicador (pub-sub), ao qual v√°rios consumidores est√£o inscritos, com a vantagem adicional de que todas as mensagens s√£o salvas e podem ser processadas v√°rias vezes. <br><br><img src="https://habrastorage.org/webt/qe/v1/yk/qev1yktga3s-g1gqlynylbe3n9w.png"><br>  <i>Figura 3-3.</i>  <i>Dois consumidores em diferentes grupos de consumidores l√™em da mesma parti√ß√£o</i> <br><br><h3>  Consumidores no grupo de consumidores </h3><br>  Quando uma inst√¢ncia do consumidor l√™ dados da parti√ß√£o, controla completamente o ponteiro e processa as mensagens, conforme descrito na se√ß√£o anterior. <br>  Se v√°rias inst√¢ncias dos consumidores foram conectadas com o mesmo group_id ao t√≥pico com uma parti√ß√£o, a inst√¢ncia que foi conectada por √∫ltimo ter√° controle sobre o ponteiro e a partir de ent√£o receber√° todas as mensagens ( <a href="">Figura 3-4</a> ). <br><br><img src="https://habrastorage.org/webt/0j/ao/f2/0jaof2mdwg3cqvmwemhtxkrltuq.png"><br>  <i>Figura 3-4.</i>  <i>Dois consumidores no mesmo grupo de consumidores l√™em da mesma parti√ß√£o</i> <br><br>  Esse modo de processamento, no qual o n√∫mero de inst√¢ncias de consumidores excede o n√∫mero de parti√ß√µes, pode ser considerado como um tipo de consumidor de monop√≥lio.  Isso pode ser √∫til se voc√™ precisar do cluster "ativo-passivo" (ou "quente e quente") de suas inst√¢ncias de consumidores, embora a opera√ß√£o paralela de v√°rios consumidores ("ativo-ativo" ou "quente e quente") seja muito mais t√≠pica do que os consumidores no modo de espera. <br><blockquote>  Esse comportamento de distribui√ß√£o de mensagens, descrito acima, pode ser surpreendente em compara√ß√£o com o comportamento de uma fila JMS comum.  Nesse modelo, as mensagens enviadas para a fila ser√£o distribu√≠das igualmente entre os dois consumidores. </blockquote><br>  Na maioria das vezes, quando criamos v√°rias inst√¢ncias de compiladores, fazemos isso para processamento paralelo de mensagens, ou para aumentar a velocidade da leitura ou para aumentar a estabilidade do processo de leitura.  Como apenas uma inst√¢ncia de um consumidor pode ler dados de uma parti√ß√£o, como isso √© alcan√ßado no Kafka? <br><br>  Uma maneira de fazer isso √© usar uma inst√¢ncia do consumidor para ler todas as mensagens e envi√°-las ao conjunto de encadeamentos.  Embora essa abordagem aumente a taxa de transfer√™ncia de processamento, aumenta a complexidade da l√≥gica dos consumidores e n√£o faz nada para aumentar a estabilidade do sistema de leitura.  Se uma inst√¢ncia do consumidor desligar devido a uma falha de energia ou evento semelhante, a revis√£o ser√° interrompida. <br><br>  A maneira can√¥nica de resolver esse problema no Kafka √© usar mais parti√ß√µes. <br><br><h3>  Particionamento </h3><br>  Parti√ß√µes s√£o o principal mecanismo para paralelizar a leitura e o dimensionamento do t√≥pico al√©m da largura de banda de uma inst√¢ncia do broker.  Para entender melhor isso, vejamos uma situa√ß√£o em que h√° um t√≥pico com duas parti√ß√µes e um consumidor assina esse t√≥pico ( <a href="">Figura 3-5</a> ). <br><br><img src="https://habrastorage.org/webt/en/9g/ct/en9gct0o017cqp8buawguwlscty.png"><br>  <i>Figura 3-5.</i>  <i>Um consumidor l√™ de v√°rias parti√ß√µes</i> <br><br>  Nesse cen√°rio, o consultor tem controle sobre os ponteiros correspondentes ao seu group_id em ambas as parti√ß√µes, e a leitura das mensagens de ambas as parti√ß√µes √© iniciada. <br>  Quando um compurador adicional √© adicionado a este t√≥pico para o mesmo group_id, o Kafka reatribui (realoca) uma das parti√ß√µes da primeira para a segunda.  Depois disso, cada inst√¢ncia do consumidor ser√° subtra√≠da de uma parti√ß√£o do t√≥pico ( <a href="">Figura 3-6</a> ). <br><br>  Para garantir que as mensagens sejam processadas em paralelo em 20 threads, voc√™ precisar√° de pelo menos 20 parti√ß√µes.  Se houver menos parti√ß√µes, voc√™ ainda ter√° consumidores com os quais n√£o trabalhar, conforme descrito anteriormente na discuss√£o de monitores exclusivos. <br><br><img src="https://habrastorage.org/webt/8b/a0/um/8ba0umn2yzr9yy3vztonhdfiub0.png"><br>  <i>Figura 3-6.</i>  <i>Dois consumidores no mesmo grupo de consumidores l√™em parti√ß√µes diferentes</i> <br><br>  Esse esquema reduz significativamente a complexidade do broker Kafka em compara√ß√£o com a distribui√ß√£o de mensagens necess√°ria para suportar a fila JMS.  N√£o h√° necessidade de cuidar dos seguintes pontos: <br><br><ul><li>  Qual consumidor deve receber a pr√≥xima mensagem com base na distribui√ß√£o round-robin, capacidade atual do buffer de pr√©-busca ou mensagens anteriores (como nos grupos de mensagens JMS). </li><li>  Quais mensagens foram enviadas para quais consumidores e se eles devem ser reenviados em caso de falha. </li></ul><br>  Tudo o que o corretor Kafka deve fazer √© enviar consistentemente mensagens ao consultor quando este solicitar. <br><br>  No entanto, os requisitos para paralelizar a revis√£o e reenviar mensagens sem √™xito n√£o desaparecem - a responsabilidade por eles simplesmente passa do intermedi√°rio para o cliente.  Isso significa que eles devem ser inclu√≠dos no seu c√≥digo. <br><br><h2>  Enviando mensagens </h2><br>  A responsabilidade de decidir para qual parti√ß√£o enviar a mensagem √© o produtor da mensagem.  Para entender o mecanismo pelo qual isso √© feito, voc√™ primeiro precisa considerar o que exatamente estamos enviando. <br><br>  Enquanto no JMS usamos uma estrutura de mensagens com metadados (cabe√ßalhos e propriedades) e um corpo contendo uma carga, no Kafka a mensagem √© <i>um par de valores-chave</i> .  A carga √∫til da mensagem √© enviada como um valor.  Uma chave, por outro lado, √© usada principalmente para particionar e deve conter uma <i>chave espec√≠fica da l√≥gica de neg√≥cios</i> para colocar as mensagens relacionadas na mesma parti√ß√£o. <br><br>  No cap√≠tulo 2, discutimos o cen√°rio de apostas on-line, quando eventos relacionados devem ser processados ‚Äã‚Äãem ordem por um √∫nico consumidor: <br><br><ol><li>  A conta do usu√°rio est√° configurada. </li><li>  O dinheiro √© creditado na conta. </li><li>  √â feita uma aposta que retira dinheiro da conta. </li></ol><br>  Se cada evento for uma mensagem enviada ao t√≥pico, nesse caso, o identificador da conta ser√° a chave natural. <br>  Quando uma mensagem √© enviada usando a API do Kafka Producer, ela √© passada para a fun√ß√£o de parti√ß√£o, que, dada a mensagem e o estado atual do cluster Kafka, retorna o identificador da parti√ß√£o para a qual a mensagem deve ser enviada.  Esse recurso √© implementado em Java atrav√©s da interface do Partitioner. <br><br>  Essa interface √© a seguinte: <br><br><pre><code class="java hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">interface</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Partitioner</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">partition</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String topic, Object key, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] keyBytes, Object value, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] valueBytes, Cluster cluster)</span></span></span></span>; }</code> </pre> <br>  A implementa√ß√£o do Particionador usa o algoritmo de hash de uso geral padr√£o sobre a chave ou round-robin se a chave n√£o for especificada para determinar a parti√ß√£o.  Esse valor padr√£o funciona bem na maioria dos casos.  No entanto, no futuro voc√™ vai querer escrever o seu. <br><br><h3>  Escrevendo sua pr√≥pria estrat√©gia de particionamento </h3><br>  Vejamos um exemplo quando voc√™ deseja enviar metadados junto com a carga √∫til da mensagem.  A carga √∫til em nosso exemplo √© uma instru√ß√£o para fazer um dep√≥sito em uma conta de jogo.  Uma instru√ß√£o √© algo que gostar√≠amos de garantir para n√£o modificar durante a transmiss√£o, e queremos ter certeza de que apenas um sistema superior confi√°vel pode iniciar essa instru√ß√£o.  Nesse caso, os sistemas de envio e recebimento concordam com o uso da assinatura para autenticar a mensagem. <br>  Em um JMS regular, simplesmente definimos a propriedade de assinatura da mensagem e a adicionamos √† mensagem.  No entanto, Kafka n√£o nos fornece um mecanismo para transmitir metadados - apenas a chave e o valor. <br><br>  Como o valor √© a carga √∫til de uma transfer√™ncia banc√°ria (carga √∫til de transfer√™ncia banc√°ria), cuja integridade queremos manter, n√£o temos escolha a n√£o ser determinar a estrutura de dados para uso na chave.  Supondo que precisamos de um identificador de conta para particionar, como todas as mensagens relacionadas √† conta devem ser processadas em ordem, criaremos a seguinte estrutura JSON: <br><br><pre> <code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"signature"</span></span>: <span class="hljs-string"><span class="hljs-string">"541661622185851c248b41bf0cea7ad0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"accountId"</span></span>: <span class="hljs-string"><span class="hljs-string">"10007865234"</span></span> }</code> </pre> <br>  Como o valor da assinatura varia de acordo com a carga, a estrat√©gia padr√£o de hash da interface do Partitioner n√£o agrupar√° mensagens relacionadas de maneira confi√°vel.  Portanto, precisaremos escrever nossa pr√≥pria estrat√©gia, que analisar√° essa chave e compartilhar√° o valor de accountId. <br><blockquote>  O Kafka inclui somas de verifica√ß√£o para detectar corrup√ß√£o de mensagens no reposit√≥rio e possui um conjunto completo de recursos de seguran√ßa.  Mesmo assim, √†s vezes aparecem requisitos espec√≠ficos do setor, como o acima. </blockquote><br>  A estrat√©gia de particionamento do usu√°rio deve garantir que todas as mensagens relacionadas terminem na mesma parti√ß√£o.  Embora isso pare√ßa simples, o requisito pode ser complicado devido √† import√¢ncia de solicitar mensagens relacionadas e √† corre√ß√£o do n√∫mero de parti√ß√µes no t√≥pico. <br><br>  O n√∫mero de parti√ß√µes no t√≥pico pode mudar ao longo do tempo, pois elas podem ser adicionadas se o tr√°fego ultrapassar as expectativas iniciais.  Assim, as chaves de mensagem podem ser associadas √† parti√ß√£o para a qual foram originalmente enviadas, implicando uma parte do estado que deve ser distribu√≠da entre as inst√¢ncias do produtor. <br><br>  Outro fator a considerar √© a distribui√ß√£o uniforme de mensagens entre parti√ß√µes.  Como regra, as chaves n√£o s√£o distribu√≠das igualmente entre as mensagens e as fun√ß√µes de hash n√£o garantem uma distribui√ß√£o justa de mensagens para um pequeno conjunto de chaves. <br>  √â importante observar que, n√£o importa como voc√™ decida dividir as mensagens, talvez o pr√≥prio separador precise ser reutilizado. <br><br>  Considere o requisito para replica√ß√£o de dados entre clusters Kafka em diferentes localiza√ß√µes geogr√°ficas.  Para esse fim, o Kafka vem com uma ferramenta de linha de comando chamada MirrorMaker, usada para ler mensagens de um cluster e transferi-las para outro. <br><br>  O MirrorMaker deve entender as chaves do t√≥pico replicado para manter a ordem relativa entre as mensagens durante a replica√ß√£o entre clusters, pois o n√∫mero de parti√ß√µes para esse t√≥pico pode n√£o coincidir em dois clusters. <br><br>  Estrat√©gias de particionamento personalizadas s√£o relativamente raras, pois hashes padr√£o ou rod√≠zio funcionam com √™xito na maioria dos cen√°rios.  No entanto, se voc√™ precisar de garantias estritas de pedido ou extrair metadados das cargas, o particionamento √© algo que voc√™ deve examinar mais de perto. <br><br>  Os benef√≠cios de escalabilidade e desempenho da Kafka v√™m da transfer√™ncia de algumas das responsabilidades de um corretor tradicional para um cliente.  Nesse caso, √© tomada uma decis√£o sobre a distribui√ß√£o de mensagens potencialmente relacionadas entre v√°rios consumidores que trabalham em paralelo. <br><blockquote>  Os corretores JMS tamb√©m devem lidar com esses requisitos.  Curiosamente, o mecanismo para enviar mensagens relacionadas para a mesma conta implementada por meio dos Grupos de Mensagens JMS (um tipo de estrat√©gia de balanceamento de SLB) tamb√©m requer que o remetente marque as mensagens como relacionadas.  No caso do JMS, o broker √© respons√°vel por enviar esse grupo de mensagens relacionadas a um dos muitos clientes e transferir a propriedade do grupo se o cliente cair. </blockquote><br><h2>  Acordo de Produtor </h2><br>  Particionar n√£o √© a √∫nica coisa a considerar ao enviar mensagens.  Vejamos os m√©todos send () da classe Producer na API Java: <br><br><pre> <code class="java hljs">Future &lt; RecordMetadata &gt; send(ProducerRecord &lt; K, V &gt; record); Future &lt; RecordMetadata &gt; send(ProducerRecord &lt; K, V &gt; record, Callback callback);</code> </pre> <br>  Deve-se notar imediatamente que ambos os m√©todos retornam Future, o que indica que a opera√ß√£o de envio n√£o √© executada imediatamente.  Como resultado, verifica-se que a mensagem (ProducerRecord) √© gravada no buffer de envio para cada parti√ß√£o ativa e transmitida ao broker no fluxo em segundo plano na biblioteca do cliente Kafka.  Embora isso torne o trabalho incrivelmente r√°pido, significa que um aplicativo inexperiente pode perder mensagens se o processo for interrompido. <br><br>  Como sempre, existe uma maneira de tornar a opera√ß√£o de envio mais confi√°vel devido ao desempenho.  O tamanho desse buffer pode ser definido como 0 e o encadeamento do aplicativo de envio ser√° for√ßado a esperar at√© que a mensagem seja enviada ao broker, da seguinte maneira: <br><br><pre> <code class="java hljs">RecordMetadata metadata = producer.send(record).get();</code> </pre> <br><h2>  Mais uma vez sobre a leitura de mensagens </h2><br>  A leitura de mensagens tem dificuldades adicionais que precisam ser consideradas.  Diferente da API JMS, que pode iniciar um ouvinte de mensagem em resposta a uma mensagem, a interface <i>Consumer</i> Kafka √© pesquisada apenas.  Vamos dar uma olhada no m√©todo <i>poll ()</i> usado para esta finalidade: <br><br><pre> <code class="java hljs">ConsumerRecords &lt; K, V &gt; poll(<span class="hljs-keyword"><span class="hljs-keyword">long</span></span> timeout);</code> </pre> <br>  O valor de retorno do m√©todo √© uma estrutura de cont√™iner que cont√©m v√°rios objetos <i>ConsumerRecord</i> de potencialmente v√°rias parti√ß√µes.  <i>Um ConsumerRecord em</i> si √© um objeto detentor de um par de valores-chave com metadados associados, como a parti√ß√£o da qual √© derivada. <br><br>  Conforme discutido no Cap√≠tulo 2, devemos lembrar constantemente o que acontece com as mensagens depois que elas s√£o processadas com ou sem √™xito, por exemplo, se o cliente n√£o puder processar a mensagem ou se interromper o trabalho.  No JMS, isso foi tratado atrav√©s do modo de reconhecimento.  O broker excluir√° a mensagem processada com √™xito ou entregar√° novamente a mensagem bruta ou invertida (desde que as transa√ß√µes tenham sido usadas). <br>  Kafka funciona de uma maneira completamente diferente.  As mensagens n√£o s√£o exclu√≠das no broker ap√≥s a revis√£o, e a responsabilidade pelo que acontece ap√≥s a falha est√° no pr√≥prio c√≥digo. <br><br>  Como j√° dissemos, um grupo de consumidores est√° associado a um deslocamento na revista.  A posi√ß√£o do log associada a esse vi√©s corresponde √† pr√≥xima mensagem que ser√° emitida em resposta a <i>poll ()</i> .  Crucial na leitura √© o momento em que esse deslocamento aumenta. <br><br>  Retornando ao modelo de leitura discutido anteriormente, o processamento de mensagens consiste em tr√™s est√°gios: <br><br><ol><li>  Recupere uma mensagem para ler. </li><li>  Processe a mensagem. </li><li>  Confirme a mensagem. </li></ol><br>  O Kafka Consumer Advisor vem com a <i>op√ß√£o de</i> configura√ß√£o <i>enable.auto.commit</i> .  Essa √© uma configura√ß√£o padr√£o comumente usada, como √© geralmente o caso das configura√ß√µes que cont√™m a palavra "autom√°tico". <br><br>  Antes do Kafka 0.10, o cliente que usava esse par√¢metro enviava o deslocamento da √∫ltima mensagem lida na pr√≥xima chamada <i>poll ()</i> ap√≥s o processamento.  Isso significava que todas as mensagens que j√° foram buscadas poderiam ser processadas novamente se o cliente j√° as tivesse processado, mas foram destru√≠das inesperadamente antes de chamar <i>poll ()</i> .  Como o broker n√£o mant√©m nenhum status com rela√ß√£o a quantas vezes a mensagem foi lida, o pr√≥ximo consumidor que recupera essa mensagem n√£o saber√° que algo ruim aconteceu.  Esse comportamento foi pseudo-transacional.  O deslocamento foi confirmado apenas no caso de processamento bem-sucedido da mensagem, mas se o cliente interrompido, o broker enviou novamente a mesma mensagem para outro cliente.  Esse comportamento foi consistente com a garantia de entrega " <i>pelo menos uma vez</i> ". <br><br>  No Kafka 0.10, o c√≥digo do cliente foi alterado de forma que o commit come√ßou a ser iniciado periodicamente pela biblioteca do cliente, de acordo com a configura√ß√£o <i>auto.commit.interval.ms</i> .  Esse comportamento est√° em algum lugar entre os modos JMS AUTO_ACKNOWLEDGE e DUPS_OK_ACKNOWLEDGE.  Ao usar a confirma√ß√£o autom√°tica, as mensagens podem ser confirmadas independentemente de terem sido realmente processadas - isso pode acontecer no caso de um consumidor lento.  Se o computador foi interrompido, as mensagens foram recuperadas pelo computador seguinte, iniciando em uma posi√ß√£o segura, o que poderia levar a uma mensagem pulando.  Nesse caso, Kafka n√£o perdeu mensagens, o c√≥digo de leitura simplesmente n√£o as processou. <br><br>  Esse modo tem as mesmas perspectivas da vers√£o 0.9: as mensagens podem ser processadas, mas no caso de uma falha, o deslocamento pode n√£o ser fechado, o que pode levar a uma duplica√ß√£o da entrega.  Quanto mais mensagens voc√™ recuperar ao fazer <i>poll ()</i> , maior ser√° esse problema. <br><br>  Conforme discutido na se√ß√£o "Subtraindo mensagens da fila" no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 2</a> , n√£o existe entrega de mensagens √∫nicas no sistema de mensagens, dados os modos de falha. <br><br>  No Kafka, existem duas maneiras de corrigir (confirmar) um deslocamento (deslocamento): autom√°tica e manualmente.  Nos dois casos, as mensagens podem ser processadas v√°rias vezes, caso a mensagem tenha sido processada, mas falhou antes de ser confirmada.  Tamb√©m n√£o √© poss√≠vel processar a mensagem se a confirma√ß√£o ocorreu em segundo plano e seu c√≥digo foi conclu√≠do antes de iniciar o processamento (possivelmente no Kafka 0.9 e vers√µes anteriores). <br><br>  Voc√™ pode controlar o processo de confirmar compensa√ß√µes manualmente na API do Kafka <i>Consumer</i> , definindo <i>enable.auto.commit</i> como false e chamando explicitamente um dos seguintes m√©todos: <br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">commitSync</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">commitAsync</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>;</code> </pre> <br>  Se voc√™ deseja processar a mensagem ‚Äúpelo menos uma vez‚Äù, confirme o deslocamento manualmente usando <i>commitSync ()</i> executando este comando imediatamente ap√≥s o processamento das mensagens. <br><br>  Esses m√©todos n√£o permitem que mensagens reconhecidas sejam processadas antes de serem processadas, mas n√£o fazem nada para eliminar a poss√≠vel duplica√ß√£o de processamento, criando ao mesmo tempo a apar√™ncia de transacionalidade.  Kafka n√£o tem transa√ß√µes.  O cliente n√£o tem a oportunidade de fazer o seguinte: <br><br><ul><li>  Reverter automaticamente uma mensagem de revers√£o.  Os pr√≥prios consumidores devem lidar com exce√ß√µes decorrentes de cargas problem√°ticas e desconex√µes de back-end, pois n√£o podem confiar no broker para entregar novamente as mensagens. </li><li>  Envie mensagens para v√°rios t√≥picos em uma opera√ß√£o at√¥mica.  Como veremos em breve, o controle sobre v√°rios t√≥picos e parti√ß√µes pode estar localizado em m√°quinas diferentes no cluster Kafka, que n√£o coordenam as transa√ß√µes durante o envio.  No momento da reda√ß√£o deste artigo, algum trabalho foi feito para tornar isso poss√≠vel com o KIP-98. </li><li>  Associe a leitura de uma mensagem de um t√≥pico ao envio de outra mensagem para outro t√≥pico.  Novamente, a arquitetura do Kafka depende de muitas m√°quinas independentes funcionando como um barramento e nenhuma tentativa √© feita para ocult√°-lo.  Por exemplo, n√£o h√° componentes de API que permitam que o <i>Consumidor</i> e o <i>Produtor</i> sejam vinculados em uma transa√ß√£o.  No JMS, isso √© fornecido pelo objeto <i>Session a</i> partir do qual <i>MessageProducers</i> e <i>MessageConsumers</i> s√£o criados. </li></ul><br>  Se n√£o podemos confiar nas transa√ß√µes, como podemos fornecer sem√¢nticas mais pr√≥ximas das fornecidas pelos sistemas de mensagens tradicionais? <br><br>  Se houver a possibilidade de o deslocamento do consumidor aumentar antes que a mensagem tenha sido processada, por exemplo, durante a falha do cliente, o cliente n√£o ter√° como saber se o grupo de clientes perdeu a mensagem ao receber uma parti√ß√£o.  Assim, uma estrat√©gia √© rebobinar o deslocamento para a posi√ß√£o anterior.  A API do Kafka Consumer Advisor fornece os seguintes m√©todos para isso: <br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">seek</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(TopicPartition partition, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">long</span></span></span></span><span class="hljs-function"><span class="hljs-params"> offset)</span></span></span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">seekToBeginning</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Collection &lt; TopicPartition &gt; partitions)</span></span></span></span>;</code> </pre> <br>  O m√©todo <i>seek ()</i> pode ser usado com o m√©todo <br>  <i>offsetsForTimes (Map &lt;TopicPartition, Long&gt; timestampsToSearch)</i> para retroceder para um estado em qualquer ponto espec√≠fico do passado. <br><br>  Implicitamente, o uso dessa abordagem significa que √© muito prov√°vel que algumas mensagens processadas anteriormente sejam lidas e processadas novamente.  Para evitar isso, podemos usar a leitura idempotente, conforme descrito no Cap√≠tulo 4, para rastrear mensagens visualizadas anteriormente e eliminar duplicatas. <br><br>  Como alternativa, o c√≥digo do seu consumidor pode ser simples se a perda ou duplica√ß√£o de mensagens for permitida.  Quando analisamos os cen√°rios de uso nos quais o Kafka geralmente √© usado, por exemplo, processando eventos de log, m√©tricas, rastreamento de cliques etc., entendemos que √© improv√°vel que a perda de mensagens individuais tenha um impacto significativo nos aplicativos vizinhos.  Nesses casos, os valores padr√£o s√£o aceit√°veis.  Por outro lado, se seu aplicativo precisar transferir pagamentos, voc√™ dever√° cuidar cuidadosamente de cada mensagem individual.  Tudo se resume ao contexto. <br><br>  Observa√ß√µes pessoais mostram que, com o aumento da intensidade da mensagem, o valor de cada mensagem individual diminui.  As mensagens de alto volume tendem a se tornar valiosas quando exibidas de forma agregada. <br><br><h2>  Alta disponibilidade </h2><br>  A abordagem de alta disponibilidade de Kafka √© muito diferente do ActiveMQ.  O Kafka √© desenvolvido com base em clusters escal√°veis ‚Äã‚Äãhorizontalmente, nos quais todas as inst√¢ncias do broker recebem e distribuem mensagens simultaneamente. <br><br>  O cluster Kafka consiste em v√°rias inst√¢ncias do broker em execu√ß√£o em servidores diferentes.  O Kafka foi projetado para funcionar em um hardware independente convencional, em que cada n√≥ tem seu pr√≥prio armazenamento dedicado.  O uso do SAN (Network Attached Storage) n√£o √© recomendado porque v√°rios n√≥s de computa√ß√£o podem competir por intervalos de tempo de armazenamento e criar conflitos. <br><br>  Kafka √© um sistema <i>constantemente</i> ativo.  Muitos usu√°rios grandes do Kafka nunca extinguem seus clusters e o software sempre fornece atualiza√ß√µes por meio de uma reinicializa√ß√£o consistente.  Isso √© obtido garantindo a compatibilidade com a vers√£o anterior para mensagens e intera√ß√µes entre os intermedi√°rios. <br><br>  Os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">intermedi√°rios</a> est√£o conectados a um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cluster de</a> servidores <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ZooKeeper</a> , que atua como um determinado registro de configura√ß√£o e √© usado para coordenar as fun√ß√µes de cada intermedi√°rio.  O ZooKeeper em si √© um sistema distribu√≠do que fornece alta disponibilidade atrav√©s da replica√ß√£o de informa√ß√µes, estabelecendo um <i>quorum</i> . <br><br>  No caso base, o t√≥pico √© criado no cluster Kafka com as seguintes propriedades: <br><br><ul><li>  O n√∫mero de parti√ß√µes.  Como discutido anteriormente, o valor exato usado aqui depende do n√≠vel desejado de leitura simult√¢nea. </li><li>  O coeficiente de replica√ß√£o (fator) determina quantas inst√¢ncias do broker no cluster devem conter os logs para esta parti√ß√£o. </li></ul><br>  Usando o ZooKeepers para coordena√ß√£o, Kafka est√° tentando distribuir de forma justa novas parti√ß√µes entre os intermedi√°rios no cluster.  Isso √© feito por uma inst√¢ncia, que atua como o Controller. <br><br>  Em tempo <i>de</i> execu√ß√£o <i>para cada parti√ß√£o do t√≥pico, o</i> <i>Controlador</i> atribui ao intermedi√°rio as fun√ß√µes de <i>l√≠der</i> (l√≠der, mestre, l√≠der) e <i>seguidores</i> (seguidores, escravos, subordinados).  O corretor, atuando como l√≠der dessa parti√ß√£o, √© respons√°vel por receber todas as mensagens enviadas a ele pelos produtores e distribuir mensagens aos consumidores.  Ao enviar mensagens para uma parti√ß√£o de t√≥pico, elas s√£o replicadas para todos os n√≥s do intermedi√°rio que atuam como seguidores dessa parti√ß√£o.  Cada n√≥ que cont√©m os logs da parti√ß√£o √© chamado de <i>r√©plica</i> .  Um corretor pode atuar como l√≠der em algumas parti√ß√µes e como seguidor em outras. <br><br>  Um seguidor que cont√©m todas as mensagens armazenadas pelo l√≠der √© chamado de <i>r√©plica sincronizada</i> (uma r√©plica em estado sincronizado, r√©plica sincronizada).  Se o intermedi√°rio que atua como l√≠der da parti√ß√£o for desconectado, qualquer intermedi√°rio que esteja no estado atualizado ou sincronizado para esta parti√ß√£o poder√° assumir a fun√ß√£o de l√≠der.  Este √© um design incrivelmente sustent√°vel. <br><br>  Parte da configura√ß√£o do produtor √© o par√¢metro <i>acks</i> , que determina quantas r√©plicas devem confirmar o recebimento de uma mensagem antes que o fluxo do aplicativo continue enviando: 0, 1 ou todos.  Se o valor estiver definido como <i>todos</i> , quando a mensagem for recebida, o l√≠der enviar√° uma confirma√ß√£o de volta ao produtor assim que receber a confirma√ß√£o das v√°rias r√©plicas (incluindo ele mesmo) definidas pela <i>configura√ß√£o do</i> t√≥pico <i>min.insync.replicas</i> (por padr√£o 1).  Se a mensagem n√£o puder ser replicada com √™xito, o produtor lan√ßar√° uma exce√ß√£o para o aplicativo ( <i>NotEnoughReplicas</i> ou <i>NotEnoughReplicasAfterAppend</i> ). <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Em uma configura√ß√£o t√≠pica, um t√≥pico √© criado com um coeficiente de replica√ß√£o 3 (1 l√≠der, 2 seguidores para cada parti√ß√£o) e o par√¢metro </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">min.insync.replicas √©</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> definido como 2. Nesse caso, o cluster permitir√° que um dos intermedi√°rios que gerenciam a parti√ß√£o seja desconectado. sem afetar os aplicativos clientes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Isso nos leva de volta ao compromisso j√° familiar entre desempenho e confiabilidade. A replica√ß√£o ocorre devido ao tempo de espera adicional para agradecimentos (agradecimentos) dos seguidores. Embora, como √© executado em paralelo, a replica√ß√£o de pelo menos tr√™s n√≥s tenha o mesmo desempenho que dois (ignorando o aumento no uso da largura de banda da rede).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Usando esse esquema de replica√ß√£o, o Kafka evita inteligentemente a necessidade de gravar fisicamente cada mensagem no disco usando a opera√ß√£o </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sync ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Cada mensagem enviada pelo produtor ser√° gravada no log da parti√ß√£o, mas, conforme discutido no Cap√≠tulo 2, a grava√ß√£o no arquivo √© inicialmente executada no buffer do sistema operacional. Se essa mensagem for replicada para outra inst√¢ncia do Kafka e estiver em sua mem√≥ria, a perda de um l√≠der n√£o significa que a mensagem foi perdida - uma r√©plica sincronizada pode assumir isso sozinha. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Desativar a opera√ß√£o </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sync ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">significa que Kafka pode receber mensagens na velocidade com que pode grav√°-las na mem√≥ria. Por outro lado, quanto mais voc√™ evitar a descarga da mem√≥ria no disco, melhor. Por esse motivo, n√£o √© incomum os corretores Kafka alocarem 64 GB ou mais de mem√≥ria. Esse uso de mem√≥ria significa que uma inst√¢ncia do Kafka pode funcionar facilmente em velocidades milhares de vezes mais r√°pidas que um broker de mensagens tradicional. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O Kafka tamb√©m pode ser configurado para usar </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sync ()</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">para pacotes de mensagens. Como tudo no Kafka √© orientado a pacotes, ele realmente funciona muito bem para muitos casos de uso e √© uma ferramenta √∫til para usu√°rios que exigem garantias muito fortes. A maior parte do desempenho puro de Kafka est√° relacionada √†s mensagens enviadas ao broker como pacotes e ao fato de que essas mensagens s√£o lidas do broker em blocos sucessivos usando </font><font style="vertical-align: inherit;">opera√ß√µes de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">c√≥pia zero</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (opera√ß√µes que n√£o executam a tarefa de copiar dados de uma √°rea de mem√≥ria para outro). O √∫ltimo √© um grande ganho em termos de desempenho e recursos e s√≥ √© poss√≠vel atrav√©s do uso da estrutura de dados de log subjacente que define o esquema de parti√ß√£o.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Em um cluster Kafka, √© poss√≠vel um desempenho muito mais alto do que ao usar um √∫nico broker Kafka, pois as parti√ß√µes de t√≥picos podem ser dimensionadas horizontalmente em muitas m√°quinas separadas. </font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Sum√°rio </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neste cap√≠tulo, examinamos como a arquitetura Kafka reinterpreta o relacionamento entre clientes e corretores para fornecer um pipeline de mensagens incrivelmente robusto, com largura de banda muitas vezes maior que um corretor de mensagens comum. Discutimos a funcionalidade usada para atingir esse objetivo e revisamos brevemente a arquitetura dos aplicativos que fornecem essa funcionalidade. No pr√≥ximo cap√≠tulo, discutiremos problemas comuns que os aplicativos de mensagens precisam resolver e discutir estrat√©gias para resolv√™-los. Conclu√≠mos o cap√≠tulo descrevendo como falar sobre tecnologias de mensagens em geral, para que voc√™ possa avaliar a adequa√ß√£o deles para seus casos de uso. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tradu√ß√£o conclu√≠da: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tele.gg/middle_java</font></font></a></b> <br><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Continua ...</font></font></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt466585/">https://habr.com/ru/post/pt466585/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt466575/index.html">Passando listas bidimensionais de python para DLL</a></li>
<li><a href="../pt466577/index.html">Como dois alunos fizeram o jogo no iOS e quanto ganharam nele</a></li>
<li><a href="../pt466579/index.html">A hist√≥ria dos algoritmos de randomiza√ß√£o Tetris</a></li>
<li><a href="../pt466581/index.html">Darwinismo qu√¢ntico: uma id√©ia que explica a realidade objetiva passa no primeiro teste</a></li>
<li><a href="../pt466583/index.html">Uma Breve Hist√≥ria do Detector de Mentiras</a></li>
<li><a href="../pt466587/index.html">Vari√°veis ‚Äã‚ÄãCSS e tema de cores para o site em v√°rias linhas</a></li>
<li><a href="../pt466589/index.html">Como receber dados do Google Analytics usando R no Microsoft SQL Server</a></li>
<li><a href="../pt466591/index.html">MVC sem C: O que mudar√° o SwiftUI na arquitetura do aplicativo?</a></li>
<li><a href="../pt466593/index.html">Situa√ß√£o: nuvem h√≠brida e perspectivas de IaaS</a></li>
<li><a href="../pt466597/index.html">Hist√≥rico do Segundo Lugar no Mini AI Cup 4: Paper IO</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
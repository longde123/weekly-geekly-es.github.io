<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíΩ üÜó ü¶Ä 6 errores de sistema entretenidos en la operaci√≥n de Kubernetes [y su soluci√≥n] ‚úåÔ∏è ü§≥üèø üèôÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A lo largo de los a√±os de operaci√≥n de Kubernetes en producci√≥n, hemos acumulado muchas historias interesantes, ya que los errores en varios component...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>6 errores de sistema entretenidos en la operaci√≥n de Kubernetes [y su soluci√≥n]</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/443458/"><img src="https://habrastorage.org/webt/7o/mz/o2/7omzo2vcqpqijlxsewel9gyhcsq.png"><br><br>  A lo largo de los a√±os de operaci√≥n de Kubernetes en producci√≥n, hemos acumulado muchas historias interesantes, ya que los errores en varios componentes del sistema llevaron a consecuencias desagradables y / o incomprensibles que afectan el funcionamiento de contenedores y contenedores.  En este art√≠culo, hemos hecho una selecci√≥n de algunos de los m√°s frecuentes o interesantes.  Incluso si nunca tienes la suerte de enfrentarte a tales situaciones, leer acerca de detectives tan breves, sobre todo de primera mano, siempre es entretenido, ¬øno? <a name="habracut"></a><br><br><h2>  Historia 1. Docker supercr√≥nico y congelante </h2><br>  En uno de los grupos, recibimos peri√≥dicamente un Docker "congelado", que interfiere con el funcionamiento normal del grupo.  Al mismo tiempo, se observ√≥ lo siguiente en los registros de Docker <br><br><pre><code class="plaintext hljs">level=error msg="containerd: start init process" error="exit status 2: \"runtime/cgo: pthread_create failed: No space left on device SIGABRT: abort PC=0x7f31b811a428 m=0 goroutine 0 [idle]: goroutine 1 [running]: runtime.systemstack_switch() /usr/local/go/src/runtime/asm_amd64.s:252 fp=0xc420026768 sp=0xc420026760 runtime.main() /usr/local/go/src/runtime/proc.go:127 +0x6c fp=0xc4200267c0 sp=0xc420026768 runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:2086 +0x1 fp=0xc4200267c8 sp=0xc4200267c0 goroutine 17 [syscall, locked to thread]: runtime.goexit() /usr/local/go/src/runtime/asm_amd64.s:2086 +0x1 ‚Ä¶</code> </pre> <br>  En este error, estamos m√°s interesados ‚Äã‚Äãen el mensaje: <code>pthread_create failed: No space left on device</code> .  Un estudio r√°pido de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentaci√≥n</a> explic√≥ que Docker no pod√≠a bifurcar el proceso, lo que ocasionaba que se "congelara" peri√≥dicamente. <br><br>  Al monitorear lo que est√° sucediendo, la siguiente imagen corresponde: <br><br><img src="https://habrastorage.org/webt/7r/cq/gv/7rcqgvafvtlmis1kl7maxyz5jgk.png"><br><br>  Una situaci√≥n similar se observa en otros nodos: <br><br><img src="https://habrastorage.org/webt/lj/mw/-h/ljmw-hrrlyukwgmigltivjwyxig.png"><br><br><img src="https://habrastorage.org/webt/ap/tw/5u/aptw5ufxl-9woo5zszegfg1nqvc.png"><br><br>  En los mismos nodos vemos: <br><br><pre> <code class="bash hljs">root@kube-node-1 ~ <span class="hljs-comment"><span class="hljs-comment"># ps auxfww | grep curl -c 19782 root@kube-node-1 ~ # ps auxfww | grep curl | head root 16688 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 17398 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 16852 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 9473 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 4664 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 30571 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 24113 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 16475 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 7176 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt; root 1090 0.0 0.0 0 0 ? Z Feb06 0:00 | \_ [curl] &lt;defunct&gt;</span></span></code> </pre> <br>  Result√≥ que este comportamiento es una consecuencia del trabajo del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pod</a> con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">supercronic</a> (la utilidad en Go que usamos para ejecutar tareas cron en pods): <br><br><pre> <code class="plaintext hljs"> \_ docker-containerd-shim 833b60bb9ff4c669bb413b898a5fd142a57a21695e5dc42684235df907825567 /var/run/docker/libcontainerd/833b60bb9ff4c669bb413b898a5fd142a57a21695e5dc42684235df907825567 docker-runc | \_ /usr/local/bin/supercronic -json /crontabs/cron | \_ /usr/bin/newrelic-daemon --agent --pidfile /var/run/newrelic-daemon.pid --logfile /dev/stderr --port /run/newrelic.sock --tls --define utilization.detect_aws=true --define utilization.detect_azure=true --define utilization.detect_gcp=true --define utilization.detect_pcf=true --define utilization.detect_docker=true | | \_ /usr/bin/newrelic-daemon --agent --pidfile /var/run/newrelic-daemon.pid --logfile /dev/stderr --port /run/newrelic.sock --tls --define utilization.detect_aws=true --define utilization.detect_azure=true --define utilization.detect_gcp=true --define utilization.detect_pcf=true --define utilization.detect_docker=true -no-pidfile | \_ [newrelic-daemon] &lt;defunct&gt; | \_ [curl] &lt;defunct&gt; | \_ [curl] &lt;defunct&gt; | \_ [curl] &lt;defunct&gt; ‚Ä¶</code> </pre> <br>  El problema es este: cuando una tarea comienza en supercr√≥nica, el proceso generado por ella <b>no puede completarse correctamente</b> , convirti√©ndose en un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">zombie</a> . <br><br>  <i><b>Nota</b> : Para ser m√°s precisos, los procesos son generados por tareas cron, sin embargo, supercronic no es un sistema init y no puede "adoptar" los procesos que generaron sus hijos.</i>  <i>Cuando se producen se√±ales SIGHUP o SIGTERM, no se transmiten a los procesos generados, como resultado de lo cual los procesos secundarios no terminan, quedando en estado zombie.</i>  <i>Puede leer m√°s sobre todo esto, por ejemplo, en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dicho art√≠culo</a> .</i> <br><br>  Hay un par de formas de resolver problemas: <br><br><ol><li>  Como soluci√≥n temporal: aumente el n√∫mero de PID en el sistema en un solo momento: <br><br><pre> <code class="plaintext hljs"> /proc/sys/kernel/pid_max (since Linux 2.5.34) This file specifies the value at which PIDs wrap around (ie, the value in this file is one greater than the maximum PID). PIDs greater than this value are not allo‚Äê cated; thus, the value in this file also acts as a system-wide limit on the total number of processes and threads. The default value for this file, 32768, results in the same range of PIDs as on earlier kernels</code> </pre> </li><li>  O bien, realice el inicio de tareas en supercr√≥nico no directamente, sino con la ayuda del mismo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tini</a> , que puede finalizar correctamente los procesos y no generar un zombi. </li></ol><br><h2>  Historia 2. "Zombis" al eliminar cgroup </h2><br>  Kubelet comenz√≥ a consumir mucha CPU: <br><br><img src="https://habrastorage.org/webt/ns/lh/mp/nslhmpwfnmennya-btg5icbkh8e.png"><br><br>  A nadie le gusta esto, as√≠ que nos armamos con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">perf</a> y comenzamos a lidiar con el problema.  Los resultados de la investigaci√≥n fueron los siguientes: <br><br><ul><li>  Kubelet gasta m√°s de un tercio del tiempo de CPU extrayendo datos de memoria de todos los cgroups: <br><br><img src="https://habrastorage.org/webt/yf/u7/qv/yfu7qvvcnryl5iknz4zosagh0is.png"></li><li>  En la lista de correo de desarrolladores de kernel puede encontrar una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">discusi√≥n del problema</a> .  En resumen, la conclusi√≥n es que los <b>diferentes archivos tmpfs y otras cosas similares no se eliminan por completo del sistema</b> cuando se elimina cgroup; el llamado <b>zombie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">memcg</a></b> permanece.  Tarde o temprano, sin embargo, se eliminar√°n de la cach√© de la p√°gina, sin embargo, la memoria en el servidor es grande y el n√∫cleo no ve el punto de perder el tiempo elimin√°ndolos.  Por lo tanto, contin√∫an acumul√°ndose.  ¬øPor qu√© est√° pasando esto?  Este es un servidor con trabajos cron que constantemente crea nuevos trabajos, y con ellos nuevos pods.  Por lo tanto, se crean nuevos cgroups para contenedores en ellos, que se eliminar√°n pronto. </li><li>  ¬øPor qu√© cAdvisor en kubelet pasa tanto tiempo?  Esto se ve f√°cilmente en la ejecuci√≥n m√°s simple de <code>time cat /sys/fs/cgroup/memory/memory.stat</code> .  Si la operaci√≥n toma 0.01 segundos en una m√°quina en buen estado, luego 1.2 segundos en un cron02 problem√°tico.  La cuesti√≥n es que cAdvisor, que lee los datos de sysfs muy lentamente, tambi√©n trata de tener en cuenta la memoria utilizada en los grupos de zombies. </li><li>  Para eliminar a la fuerza los zombies, intentamos borrar los cach√©s, como se recomienda en LKML: <code>sync; echo 3 &gt; /proc/sys/vm/drop_caches</code>  <code>sync; echo 3 &gt; /proc/sys/vm/drop_caches</code> , pero el n√∫cleo result√≥ ser m√°s complicado y bloque√≥ la m√°quina. </li></ul><br>  Que hacer  El problema se soluciona ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">confirmar</a> y la descripci√≥n, ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el mensaje de lanzamiento</a> ) actualizando el kernel de Linux a la versi√≥n 4.16. <br><br><h2>  Historia 3. Systemd y su montura </h2><br>  Nuevamente, kubelet consume demasiados recursos en algunos nodos, pero esta vez ya es memoria: <br><br><img src="https://habrastorage.org/webt/ud/l3/vl/udl3vlr9r5c6hzxoamdmnzvvm5m.png"><br><br>  Result√≥ que hay un problema en el systemd usado en Ubuntu 16.04, y ocurre cuando se controlan los montajes que se crean para conectar <code>subPath</code> desde ConfigMaps o secretos.  Una vez que se completa el pod, el <b>servicio systemd y su soporte de servicio permanecen</b> en el sistema.  Con el tiempo, acumulan una gran cantidad.  Incluso hay problemas sobre este tema: <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">kops # 5916</a> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kubernetes # 57345</a> . </li></ol><br>  ... en el √∫ltimo de los cuales se refieren a PR en systemd: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="># 7811</a> (el problema en systemd es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="># 7798</a> ). <br><br>  El problema ya no est√° en Ubuntu 18.04, pero si desea continuar usando Ubuntu 16.04, nuestra soluci√≥n sobre este tema puede ser √∫til. <br><br>  Entonces, hicimos el siguiente DaemonSet: <br><br><pre> <code class="plaintext hljs">--- apiVersion: extensions/v1beta1 kind: DaemonSet metadata: labels: app: systemd-slices-cleaner name: systemd-slices-cleaner namespace: kube-system spec: updateStrategy: type: RollingUpdate selector: matchLabels: app: systemd-slices-cleaner template: metadata: labels: app: systemd-slices-cleaner spec: containers: - command: - /usr/local/bin/supercronic - -json - /app/crontab Image: private-registry.org/systemd-slices-cleaner/systemd-slices-cleaner:v0.1.0 imagePullPolicy: Always name: systemd-slices-cleaner resources: {} securityContext: privileged: true volumeMounts: - name: systemd mountPath: /run/systemd/private - name: docker mountPath: /run/docker.sock - name: systemd-etc mountPath: /etc/systemd - name: systemd-run mountPath: /run/systemd/system/ - name: lsb-release mountPath: /etc/lsb-release-host imagePullSecrets: - name: antiopa-registry priorityClassName: cluster-low tolerations: - operator: Exists volumes: - name: systemd hostPath: path: /run/systemd/private - name: docker hostPath: path: /run/docker.sock - name: systemd-etc hostPath: path: /etc/systemd - name: systemd-run hostPath: path: /run/systemd/system/ - name: lsb-release hostPath: path: /etc/lsb-release</code> </pre> <br>  ... y utiliza el siguiente script: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash # we will work only on xenial hostrelease="/etc/lsb-release-host" test -f ${hostrelease} &amp;&amp; grep xenial ${hostrelease} &gt; /dev/null || exit 0 # sleeping max 30 minutes to dispense load on kube-nodes sleep $((RANDOM % 1800)) stoppedCount=0 # counting actual subpath units in systemd countBefore=$(systemctl list-units | grep subpath | grep "run-" | wc -l) # let's go check each unit for unit in $(systemctl list-units | grep subpath | grep "run-" | awk '{print $1}'); do # finding description file for unit (to find out docker container, who born this unit) DropFile=$(systemctl status ${unit} | grep Drop | awk -F': ' '{print $2}') # reading uuid for docker container from description file DockerContainerId=$(cat ${DropFile}/50-Description.conf | awk '{print $5}' | cut -d/ -f6) # checking container status (running or not) checkFlag=$(docker ps | grep -c ${DockerContainerId}) # if container not running, we will stop unit if [[ ${checkFlag} -eq 0 ]]; then echo "Stopping unit ${unit}" # stoping unit in action systemctl stop $unit # just counter for logs ((stoppedCount++)) # logging current progress echo "Stopped ${stoppedCount} systemd units out of ${countBefore}" fi done</span></span></code> </pre> <br>  ... y comienza cada 5 minutos con el supercr√≥nico ya mencionado.  Su Dockerfile se ve as√≠: <br><br><pre> <code class="plaintext hljs">FROM ubuntu:16.04 COPY rootfs / WORKDIR /app RUN apt-get update &amp;&amp; \ apt-get upgrade -y &amp;&amp; \ apt-get install -y gnupg curl apt-transport-https software-properties-common wget RUN add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu xenial stable" &amp;&amp; \ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add - &amp;&amp; \ apt-get update &amp;&amp; \ apt-get install -y docker-ce=17.03.0* RUN wget https://github.com/aptible/supercronic/releases/download/v0.1.6/supercronic-linux-amd64 -O \ /usr/local/bin/supercronic &amp;&amp; chmod +x /usr/local/bin/supercronic ENTRYPOINT ["/bin/bash", "-c", "/usr/local/bin/supercronic -json /app/crontab"]</code> </pre> <br><h2>  Historia 4. Competencia en vainas de planificaci√≥n </h2><br>  Se se√±al√≥ que: si se coloca una c√°psula en nuestro nodo y su imagen se bombea durante mucho tiempo, entonces la otra c√°psula que "lleg√≥" al mismo nodo simplemente <b>no comienza a extraer la imagen de la nueva c√°psula</b> .  En cambio, espera a que se extraiga la imagen de la c√°psula anterior.  Como resultado, un pod que ya ha sido planeado y cuya imagen podr√≠a descargarse en solo un minuto terminar√° en el estado de creaci√≥n de <code>containerCreating</code> durante mucho tiempo. <br><br>  En eventos, habr√° algo como esto: <br><br><pre> <code class="plaintext hljs">Normal Pulling 8m kubelet, ip-10-241-44-128.ap-northeast-1.compute.internal pulling image "registry.example.com/infra/openvpn/openvpn:master"</code> </pre> <br>  Resulta que <b>una sola imagen del registro lento puede bloquear la implementaci√≥n</b> en el nodo. <br><br>  Desafortunadamente, no hay muchas maneras de salir de la situaci√≥n: <br><br><ol><li>  Intente utilizar su Docker Registry directamente en el cl√∫ster o directamente con el cl√∫ster (por ejemplo, GitLab Registry, Nexus, etc.); </li><li>  Use utilidades como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">kraken</a> . </li></ol><br><h2>  Historia 5. Nodos colgantes sin memoria </h2><br>  Durante el funcionamiento de varias aplicaciones, tambi√©n recibimos una situaci√≥n en la que el nodo deja de ser accesible por completo: SSH no responde, todos los demonios de monitoreo se caen y luego nada (o casi nada) es anormal en los registros. <br><br>  Te dir√© en las im√°genes el ejemplo de un nodo donde funcion√≥ MongoDB. <br><br>  As√≠ es como se ve <b>antes del</b> accidente: <br><br><img src="https://habrastorage.org/webt/l5/ef/az/l5efazbhjmzsuxdv6puz1tlvbzs.png"><br><br>  Y as√≠, <b>despu√©s del</b> accidente: <br><br><img src="https://habrastorage.org/webt/wx/mh/q7/wxmhq71060dhvxsxk-dh8m--pas.png"><br><br>  Tambi√©n en la supervisi√≥n, hay un salto brusco en el que el nodo deja de ser accesible: <br><br><img src="https://habrastorage.org/webt/tp/fm/wf/tpfmwftsui_eoz91ojyy5rzektc.png"><br><br>  Por lo tanto, las capturas de pantalla muestran que: <br><br><ol><li>  RAM en la m√°quina est√° cerca del final; </li><li>  Se observa un salto brusco en el consumo de RAM, despu√©s de lo cual el acceso a toda la m√°quina se deshabilita bruscamente; </li><li>  Una gran tarea llega a Mongo, que obliga al proceso DBMS a usar m√°s memoria y leer activamente desde el disco. </li></ol><br>  Resulta que si Linux se queda sin memoria libre (se produce presi√≥n de memoria) y no hay intercambio, entonces <b>antes de que</b> llegue el asesino OOM, puede ocurrir un equilibrio entre tirar p√°ginas en el cach√© de p√°ginas y volver a escribirlas en el disco.  Esto se hace mediante kswapd, que con valent√≠a libera tantas p√°ginas de memoria como sea posible para su posterior distribuci√≥n. <br><br>  Desafortunadamente, con una gran carga de E / S, junto con una peque√±a cantidad de memoria libre, <b>kswapd se convierte en el cuello de botella de todo el sistema</b> , porque <b>todas las</b> fallas de p√°gina de las p√°ginas de memoria en el sistema est√°n vinculadas a √©l.  Esto puede continuar durante mucho tiempo si los procesos ya no quieren usar memoria, pero se arreglan en el borde del abismo asesino de OOM. <br><br>  La pregunta l√≥gica es: ¬øpor qu√© el asesino OOM llega tan tarde?  En la iteraci√≥n actual de OOM, killer es extremadamente est√∫pido: matar√° el proceso solo cuando el intento de asignar una p√°gina de memoria falle, es decir  Si falla la p√°gina.  Esto no sucede durante mucho tiempo, porque kswapd libera valientemente p√°ginas de memoria volcando el cach√© de p√°ginas (de hecho, todas las E / S de disco en el sistema) de nuevo al disco.  Con m√°s detalle, con una descripci√≥n de los pasos necesarios para eliminar tales problemas en el n√∫cleo, puede leer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><br>  Este comportamiento <a href="">deber√≠a mejorar</a> con el kernel Linux 4.6+. <br><br><h2>  Historia 6. Las vainas est√°n pendientes </h2><br>  En algunos grupos, en los que hay muchas c√°psulas, comenzamos a notar que la mayor√≠a de ellos estuvieron colgados en el estado <code>Pending</code> durante mucho tiempo, aunque los contenedores Docker ya se estaban ejecutando en los nodos y se pod√≠a trabajar manualmente con ellos. <br><br>  No hay nada malo con <code>describe</code> : <br><br><pre> <code class="plaintext hljs"> Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 1m default-scheduler Successfully assigned sphinx-0 to ss-dev-kub07 Normal SuccessfulAttachVolume 1m attachdetach-controller AttachVolume.Attach succeeded for volume "pvc-6aaad34f-ad10-11e8-a44c-52540035a73b" Normal SuccessfulMountVolume 1m kubelet, ss-dev-kub07 MountVolume.SetUp succeeded for volume "sphinx-config" Normal SuccessfulMountVolume 1m kubelet, ss-dev-kub07 MountVolume.SetUp succeeded for volume "default-token-fzcsf" Normal SuccessfulMountVolume 49s (x2 over 51s) kubelet, ss-dev-kub07 MountVolume.SetUp succeeded for volume "pvc-6aaad34f-ad10-11e8-a44c-52540035a73b" Normal Pulled 43s kubelet, ss-dev-kub07 Container image "registry.example.com/infra/sphinx-exporter/sphinx-indexer:v1" already present on machine Normal Created 43s kubelet, ss-dev-kub07 Created container Normal Started 43s kubelet, ss-dev-kub07 Started container Normal Pulled 43s kubelet, ss-dev-kub07 Container image "registry.example.com/infra/sphinx/sphinx:v1" already present on machine Normal Created 42s kubelet, ss-dev-kub07 Created container Normal Started 42s kubelet, ss-dev-kub07 Started container</code> </pre> <br>  Despu√©s de investigar, asumimos que Kubelet simplemente no tiene tiempo para enviar al servidor API toda la informaci√≥n sobre el estado de los pods, muestras de vida / disponibilidad. <br><br>  Y despu√©s de estudiar ayuda, encontramos los siguientes par√°metros: <br><br><pre> <code class="plaintext hljs">--kube-api-qps - QPS to use while talking with kubernetes apiserver (default 5) --kube-api-burst - Burst to use while talking with kubernetes apiserver (default 10) --event-qps - If &gt; 0, limit event creations per second to this value. If 0, unlimited. (default 5) --event-burst - Maximum size of a bursty event records, temporarily allows event records to burst to this number, while still not exceeding event-qps. Only used if --event-qps &gt; 0 (default 10) --registry-qps - If &gt; 0, limit registry pull QPS to this value. --registry-burst - Maximum size of bursty pulls, temporarily allows pulls to burst to this number, while still not exceeding registry-qps. Only used if --registry-qps &gt; 0 (default 10)</code> </pre> <br>  Como puede ver, los <b>valores predeterminados son bastante peque√±os</b> , y en un 90% cubren todas las necesidades ... Sin embargo, en nuestro caso esto no fue suficiente.  Por lo tanto, establecemos estos valores: <br><br><pre> <code class="plaintext hljs">--event-qps=30 --event-burst=40 --kube-api-burst=40 --kube-api-qps=30 --registry-qps=30 --registry-burst=40</code> </pre> <br><br>  ... y reiniciaron los kubelets, despu√©s de lo cual vieron la siguiente imagen en los gr√°ficos de acceso al servidor API: <br><br><img src="https://habrastorage.org/webt/nq/-i/oq/nq-ioqoyt6_qudmacm5dwfe8hnk.png"><br><br>  ... y s√≠, ¬°todo comenz√≥ a volar! <br><br><h2>  PS </h2><br>  Para obtener ayuda en la recolecci√≥n de errores y la preparaci√≥n del art√≠culo, expreso mi profunda gratitud a los numerosos ingenieros de nuestra empresa, y en particular a Andrei Klimentyev (colega de nuestro equipo de I + D) ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">zuzzas</a> ). <br><br><h2>  PPS </h2><br>  Lea tambi√©n en nuestro blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Complemento Kubectl-debug para depurar en los pods de Kubernetes</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Monitoreo y Kubernetes (revisi√≥n e informe de video)</a> "; </li><li>  Ciclo de consejos y trucos de Kubernetes: <ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Transferencia de recursos que trabajan en un cl√∫ster a la gesti√≥n de Helm 2</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Sobre la asignaci√≥n de nodos y la carga en la aplicaci√≥n web</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Acceso a sitios de desarrollo</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Acelerar el arranque de grandes bases de datos</a> " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">.</a> </li></ul></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/443458/">https://habr.com/ru/post/443458/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../443438/index.html">7 √∫tiles extensiones de Firefox para aprender ingl√©s</a></li>
<li><a href="../443440/index.html">M√≥dulo PHP para trabajar con datos jer√°rquicos en InterSystems IRIS</a></li>
<li><a href="../443450/index.html">¬øPor qu√© los pobres no pueden estar saludables?</a></li>
<li><a href="../443452/index.html">El ej√©rcito ruso crear√° su propio Internet cerrado</a></li>
<li><a href="../443456/index.html">Te invitamos a Yandex NLP por una semana</a></li>
<li><a href="../443460/index.html">11 respuestas sobre Yandex.Directory</a></li>
<li><a href="../443462/index.html">Hackear c√°maras: vectores de ataque, herramientas de b√∫squeda de vulnerabilidades y anti-seguimiento</a></li>
<li><a href="../443464/index.html">Gu√≠a completa para cambiar expresiones en Java 12</a></li>
<li><a href="../443466/index.html">Rey del desarrollo</a></li>
<li><a href="../443468/index.html">¬øQu√© herramientas de monitoreo de red se han convertido en l√≠deres en la versi√≥n de Gartner?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
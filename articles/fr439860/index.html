<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçΩÔ∏è üåµ üèáüèæ Ubuntu 18.04 Root sur ZFS üé™ üåπ üçá</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'ann√©e derni√®re, j'avais besoin de cr√©er des instructions pour l'installation du syst√®me d'exploitation Ubuntu 18.04. Soit dit en passant, il n'y a r...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ubuntu 18.04 Root sur ZFS</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439860/"><p>  L'ann√©e derni√®re, j'avais besoin de cr√©er des instructions pour l'installation du syst√®me d'exploitation Ubuntu 18.04.  Soit dit en passant, il n'y a rien de compliqu√© √† installer Ubuntu, mais il y a une nuance: je voulais utiliser le syst√®me de fichiers ZFS comme base.  D'une part, Ubuntu prend en charge ZFS au niveau du noyau, mais il n'y a pas encore de programme d'installation pour cela, mais il y a une instruction, oui: </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://github.com/zfsonlinux/zfs/wiki/Ubuntu-18.04-Root-on-ZFS</a> </p><br><p>  La s√©quence d'actions dans ce manuel est g√©n√©ralement correcte, mais certains points n√©cessitent un ajustement.  Ce qui suit n'est donc pas une traduction directe des instructions, mais gratuite, en tenant compte des corrections, de mon exp√©rience avec ZFS et autres.  Je ne consid√®re pas non plus les probl√®mes de chiffrement du disque et j'utilise le chargeur de d√©marrage MBR.  Mes instructions d'installation peuvent √™tre obtenues <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici.</a> </p><br><a name="habracut"></a><br><h2><blockquote>  0. Pr√©paration du serveur </blockquote></h2><br><p> La premi√®re chose qui manque dans les instructions et qui n'est en aucun cas prise en compte est que ZFS ne fonctionne pas tr√®s bien avec les matrices RAID mat√©rielles, en particulier, il est connect√© au cache d'√©criture, ce qui est compr√©hensible: le syst√®me de fichiers ZFS est journalis√© et n√©cessite un contr√¥le complet sur les op√©rations d'√©criture.  De plus, lorsque vous utilisez une matrice RAID mat√©rielle pr√™te √† l'emploi, les capacit√©s ZFS sont perdues en termes de cache, de rechange et plus encore.  Par cons√©quent, tous les disques doivent √™tre transf√©r√©s en mode HBA, et si cela n'est pas possible, cr√©ez un RAID distinct pour chaque disque et d√©sactivez le contr√¥leur de cache d'√©criture. </p><br><p>  De plus, lorsque vous utilisez l'agr√©gation de ports r√©seau, vous pouvez les d√©sactiver au stade de l'installation, afin de ne pas le compliquer (j'effectuerai toutes les autres op√©rations sans liaison). </p><br><h2>  1. Pr√©paration de l'environnement d'installation </h2><br><h3>  1.1.  Livecd </h3><br><p>  Comme mentionn√© pr√©c√©demment, malheureusement, il n'y a pas de programme d'installation Ubuntu pr√™t √† l'emploi utilisant root sur ZFS, donc l'installation est effectu√©e √† l'aide d'un disque LiveCD: </p><br><p>  T√©l√©chargez ici: <a href="">http://releases.ubuntu.com/18.04/ubuntu-18.04.1-desktop-amd64.iso</a> </p><br><blockquote>  En m√™me temps, j'ai essay√© avec des coll√®gues d'utiliser diff√©rentes images de disque car je ne voulais pas vraiment utiliser le shell graphique, mais cela n'a rien donn√© de bon. </blockquote><br><p>  Nous d√©marrons √† partir du LiveCD, s√©lectionnez Try Ubuntu et ouvrons le terminal (Ctrl + Alt + T). </p><br><h3>  1.2.  Mise √† jour et installation de r√©f√©rentiels </h3>  '' <br><pre><code class="bash hljs">sudo apt-add-repository universe sudo apt update</code> </pre> <br><blockquote>  Ici, nous attendons la premi√®re erreur si les param√®tres r√©seau du serveur ne sont pas d√©termin√©s par DHCP.  La mise √† jour des r√©f√©rentiels ne fonctionnera pas, alors configurons le r√©seau. </blockquote><br><p>  Nous examinons les interfaces r√©seau et trouvons celle par laquelle nous nous connecterons: </p><br><pre> <code class="bash hljs">sudo ip a</code> </pre> <br><p>  Configurez l'interface r√©seau: </p><br><pre> <code class="bash hljs">sudo <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"auto {{ NAME }}"</span></span> &gt;&gt; /etc/network/interfaces sudo <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"iface {{ NAME }} inet static"</span></span> &gt;&gt; /etc/network/interfaces sudo <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">" address {{ IP }}"</span></span> &gt;&gt; /etc/network/interfaces sudo <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">" netmask {{ NETMASK }}"</span></span> &gt;&gt; /etc/network/interfaces sudo <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">" gateway {{ GATEWAY }}"</span></span> &gt;&gt; /etc/network/interfaces sudo service networking restart</code> </pre><br><p>  Et r√©solveur DNS: </p><br><pre> <code class="bash hljs">sudo <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'nameserver 8.8.8.8'</span></span> &gt;&gt; /etc/resolv.conf</code> </pre> <br><p>  Mise √† jour des r√©f√©rentiels: </p><br><pre> <code class="bash hljs">sudo apt update</code> </pre> <br><h3>  1.3.  Serveur SSH (facultatif) </h3><br><p>  Pour faciliter l'installation, vous pouvez augmenter le serveur OpenSSH et effectuer toutes les autres op√©rations via le client SSH </p><br><p>  D√©finissez le mot de passe de l'utilisateur ubuntu: </p><br><pre> <code class="bash hljs">passwd</code> </pre> <br><blockquote>  C'est important!  Sinon, l'acc√®s via ssh se fera sans mot de passe avec les droits sudo.  Cependant, vous ne pouvez pas d√©finir un mot de passe simple. </blockquote><br><p>  Installez et ex√©cutez OpenSSH: </p><br><pre> <code class="bash hljs">sudo apt install openssh-server sudo service ssh start</code> </pre> <br><p>  Et dans le terminal du poste de travail: </p><br><pre> <code class="bash hljs">ssh ubuntu@{{ ip server }}</code> </pre> <br><h3>  1.4.  Devenez root </h3><br><pre> <code class="bash hljs">sudo -s</code> </pre> <br><h3>  1.5.  Installation de la prise en charge ZFS dans un environnement LiveCD </h3><br><pre> <code class="bash hljs">apt install --yes debootstrap gdisk zfs-initramfs</code> </pre> <br><h2>  2. Partitionnement et formatage des disques durs </h2><br><h3><blockquote>  2.0.  D√©finition de tableaux de disques </blockquote></h3><br><p>  L'instruction principale ne contient pas de point important sur la fa√ßon de d√©terminer les matrices de disques. </p><br><p>  En r√®gle g√©n√©rale, le nombre de disques sur les serveurs est le suivant: </p><br><ul><li>  2 disques; </li><li>  4 disques; </li><li>  de nombreux disques; </li></ul><br><p>  Nous ne consid√©rons pas 1 disque car il s'agit g√©n√©ralement d'une anomalie. </p><br><h4>  2.0.1.  2 disques </h4><br><p>  Ici, tout est simple, une baie MIRROR (RAID1).  S'il existe un autre troisi√®me disque, vous pouvez le placer dans un disque de secours (SPARE) ou assembler une matrice RAIDZ (RAID5).  Mais 3 disques sur le serveur sont tr√®s rares. </p><br><h4>  2.0.2.  4 disques </h4><br><p>  Si tous les disques sont identiques, il n'y a que trois options (le quatri√®me RAID0 que je ne consid√®re pas fondamentalement): </p><br><ul><li>  MIRROR + MIRROR est un analogue de RAID10, plus pr√©cis√©ment RAID01, car dans ZFS c'est miroir + miroir.  50% de l'espace disque disponible; </li><li>  RAIDZ est un analogue de RAID5.  75% de l'espace disque disponible; </li><li>  RAIDZ2 est un analogue de RAID6.  50% de l'espace disque disponible; </li></ul><br><p>  En pratique, j'utilise le tableau MIRROR + MIRROR, alors qu'il est √©vident que le tableau RAIDZ est le plus rentable, car il fournit plus d'espace disque, mais il y a des nuances </p><br><p>  En termes de tol√©rance aux pannes, les tableaux sont class√©s dans cet ordre (du meilleur au pire): </p><br><ul><li>  RAIDZ2 - deux disques peuvent √™tre perdus sans perte de donn√©es; </li><li>  MIROIR + MIROIR - un disque peut √™tre perdu sans perte de donn√©es, et avec une probabilit√© de 66% un deuxi√®me disque peut √™tre perdu sans perte de donn√©es; </li><li>  RAIDZ - un seul disque peut √™tre perdu sans perte de donn√©es; </li></ul><br><p>  En termes de vitesse, les tableaux sont organis√©s dans cet ordre: </p><br><ul><li>  MIROIR + MIROIR - √† la fois en termes d'√©criture et de lecture; </li><li>  RAIDZ - en termes d'enregistrement est plus lent, car en plus de l'enregistrement, il est n√©cessaire de calculer la somme de contr√¥le; </li><li>  RAIDZ2 - en termes d'√©criture est encore plus lent car il n√©cessite le calcul de sommes de contr√¥le plus complexes; </li></ul><br><p>  En termes de vitesse de la baie lors de la d√©gradation d'un disque: </p><br><ul><li>  MIROIR + MIROIR - lorsqu'un lecteur tombe en panne, essentiellement seule la lecture parall√®le d'un miroir est perdue, le deuxi√®me miroir fonctionne sans d√©gradation des performances; </li><li>  RAIDZ2 - la d√©gradation de la d√©gradation des performances est plus √©lev√©e car elle n√©cessite une allocation en arri√®re du bloc √† partir de la somme de contr√¥le pour 1/4 des donn√©es + recherche de bloc; </li><li>  RAIDZ - la d√©gradation est beaucoup plus importante, car elle n√©cessite un recalcul du bloc √† partir de la somme de contr√¥le pour 1/3 des donn√©es + recherche de bloc; </li></ul><br><p>  La comparaison des caract√©ristiques est subjective, mais refl√®te suffisamment mon choix comme terrain d'entente. </p><br><p>  Dans le m√™me temps, vous devez comprendre que ¬´plus lent¬ª et ¬´encore plus lent¬ª ne l'est pas parfois, mais seulement 10 √† 20% dans le pire des cas. Par cons√©quent, si votre base de donn√©es ou votre application pour travailler avec des disques n'est pas optimis√©e, vous perdrez de la vitesse en principe, ne remarquez pas.  Le facteur de vitesse d'enregistrement ne doit √™tre pris en compte que lorsque vous en avez vraiment besoin. </p><br><h4>  2.0.2.  De nombreux disques </h4><br><p>  Le probl√®me principal est que si nous avons beaucoup de disques et que nous voulons cr√©er une matrice commune pour tout, nous devrons marquer chaque disque avec le secteur de d√©marrage ou faire une petite feinte avec nos oreilles.  En pratique, pour les plateformes multi-disques, j'essaye de construire cette configuration: </p><br><ul><li>  2 disques SSD - nous faisons un miroir et en tant que baie de d√©marrage principale avec le syst√®me d'exploitation et le cache ZFS pour la deuxi√®me baie de disques; </li><li>  Le reste est encombr√© de disques SATA ou SAS et sans balisage, nous collectons une matrice de disques ZFS; </li></ul><br><p>  La m√™me chose s'applique aux serveurs √† 4 disques si nous voulons obtenir une plate-forme assez universelle; </p><br><p>  Si les disques sont tous identiques et qu'il est inutile d'allouer deux disques √† une baie distincte (par exemple, 6 disques de 8 To chacun), vous pouvez cr√©er des disques amor√ßables du premier groupe de la baie.  Autrement dit, si vous allez cr√©er un tableau comme: MIRROR + MIRROR + MIRROR ou RAIDZ + RAIDZ, alors nous marquons le secteur de d√©marrage uniquement pour le premier groupe.  En principe, il est possible de partitionner un seul disque, m√™me pour MIRROR et RAIDZ, et de remplacer le reste sous une forme brute, ZFS fera le tableau par le plus petit √©l√©ment lui-m√™me, mais dans ce cas, si le premier disque tombe en panne, vous perdez le seul disque de d√©marrage, donc vous ne le faites pas √ßa vaut le coup. </p><br><p>  Il est important de comprendre que dans le syst√®me de fichiers √† bandes ZFS, ce n'est pas exactement RAID0, et cela fonctionne un peu diff√©remment et ne n√©cessite pas les m√™mes tailles de disque, donc l'allocation d'un petit espace pour le secteur de d√©marrage de la m√©t√©o ne fera pas grand-chose, l'essentiel est d'indiquer dans le BIOS le disque correct √† partir duquel d√©marrer . </p><br><h3>  2.1.  Partitionnement et nettoyage de disque </h3><br><p>  Le package mdadm est utilis√© pour marquer le disque, mettez-le: </p><br><pre> <code class="bash hljs">apt install --yes mdadm</code> </pre> <br><p>  Nous regardons quels disques nous avons disponibles: </p><br><pre> <code class="bash hljs">lsblk</code> </pre> <br><p>  Et nettoyez-les: </p><br><pre> <code class="bash hljs">sgdisk --zap-all /dev/{{ disk name }}</code> </pre> <br><h3>  2.2.  Disposition du disque </h3><br><p>  En fait, la partition de d√©marrage: </p><br><pre> <code class="bash hljs">sgdisk -a1 -n1:34:2047 -t1:EF02 /dev/{{ disk name }}</code> </pre> <br><p>  La section principale. </p><br><blockquote>  Ici, il peut y avoir des variations: si vous devez allouer une partition suppl√©mentaire de disques SSD, par exemple, pour ZFS Cache ou pour Aerospike, alors vous faites la partition principale de volume limit√©: </blockquote><br><pre> <code class="bash hljs">sgdisk -n2:0:+100GB -t2:BF01 /dev/{{ disk name }} sgdisk -n3:0:0 -t2:BF01 /dev/{{ disk name }}</code> </pre><br><p>  Si nous utilisons tout l'espace, cr√©ez simplement une section pour l'espace restant: </p><br><pre> <code class="bash hljs">sgdisk -n2:0:0 -t2:BF01 /dev/{{ disk name }}</code> </pre> <br><p>  N'oubliez pas de v√©rifier comment cela s'est av√©r√©: </p><br><pre> <code class="bash hljs">lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 1.8T 0 disk ‚îú‚îÄsda1 8:1 0 1007K 0 part ‚îî‚îÄsda2 8:2 0 1.8T 0 part sdb 8:16 0 1.8T 0 disk ‚îú‚îÄsdb1 8:17 0 1007K 0 part ‚îî‚îÄsdb2 8:18 0 1.8T 0 part ...</code> </pre><br><h3>  2.3.  Cr√©ation d'un tableau ZFS </h3><br><pre> <code class="bash hljs">zpool create \ -o ashift=12 \ -O atime=off \ -O canmount=off \ -O compression=lz4 \ -O checksum=fletcher4 \ -O normalization=formD \ -m legacy \ -R /mnt \ -f \ tank \ mirror \ /dev/{{ disk a part 2}} \ /dev/{{ disk b part 2}}</code> </pre> <br><blockquote>  Le premier rake sur lequel l'un de mes administrateurs familiers est imm√©diatement intervenu, c'est que lors de la cr√©ation d'un tableau ZFS, il est n√©cessaire de sp√©cifier non pas un disque mais une partition sur le disque, s'il est sp√©cialement cr√©√© pour cela. </blockquote><br><p>  Ensuite, dans l'ordre: </p><br><ul><li>  ashift = 12 - utilise la taille de bloc en 4K, en principe, je ne comprends toujours pas pourquoi souvent dans les syst√®mes d'exploitation la taille de bloc par d√©faut est de 512 octets alors qu'il n'y a pratiquement pas de tels disques; </li><li>  atime = off - d√©sactiver la mise √† jour de la date d'acc√®s aux fichiers, je la d√©sactive toujours car je n'ai jamais vraiment eu besoin de ces informations et il n'est pas n√©cessaire de charger √† nouveau le noyau; </li><li>  canmount = off - d√©sactive la possibilit√© de monter la partition racine; </li><li>  compression = lz4 - active la compression des donn√©es avec l'algorithme LZ4.  Il est recommand√© d'inclure ce param√®tre non seulement pour √©conomiser de l'espace disque, mais √©galement pour r√©duire le nombre d'op√©rations d'E / S.  Dans le m√™me temps, pour ce rythme de compression, utilisation extr√™mement faible du CPU; </li><li>  checksum = fletcher4 - l'algorithme de somme de contr√¥le par d√©faut, et donc fletcher4 m√©rite d'√™tre v√©rifi√© √† nouveau; </li><li>  normalisation = formD - utilis√© pour am√©liorer le travail avec UTF-8, limitant en fait la possibilit√© d'utiliser des noms de fichiers non UTF-8.  Ici, chacun d√©cide pour lui-m√™me, dans notre travail, nous n'utilisons toujours que l'encodage UTF-8; </li><li>  xattr = sa - Acc√©l√©ration du travail avec des attributs √©tendus.  Je n'utilise pas cette option car, lorsque cette option est utilis√©e, la compatibilit√© avec d'autres impl√©mentations OpenZFS est d√©sactiv√©e (par exemple: FreeBSD).  Et la compatibilit√© avec Windows et d'ailleurs, je dois.  De plus, cette option peut √™tre activ√©e sur la derni√®re section; </li><li>  -m legacy - point de montage vers nulle part, et pas besoin de monter la partition racine; </li><li>  -R / mnt - pr√©fixe de montage de partition temporaire pour l'installation du noyau; </li><li>  -f - force la cr√©ation d'un tableau.  Si la baie ZFS a d√©j√† √©t√© collect√©e sur des disques, la commande create ne fonctionnera pas, vous ne savez jamais, vous avez peut-√™tre fait une erreur et vous voulez effacer des donn√©es importantes; </li></ul><br><blockquote><p>  J'indique habituellement le nom de la matrice de disques du syst√®me racine en tant que tank, bien qu'√† l'heure actuelle, ils pr√©f√®rent utiliser le nom rpool (pool racine) dans l'environnement Linux.  Dans ma pratique, j'utilise g√©n√©ralement cette d√©nomination des tableaux: </p><br><ul><li>  tank - le r√©seau principal du syst√®me; </li><li>  store - une baie suppl√©mentaire avec de grands disques pour le stockage des donn√©es; </li><li>  cache - un tableau suppl√©mentaire de disques SSD, si la partition principale ne s'y trouve pas; </li></ul><br><p>  En g√©n√©ral, je recommande fortement de d√©velopper imm√©diatement une pratique de nommer quelque chose qui ne serait pas confondu. </p></blockquote><br><h2>  3. Installation du syst√®me </h2><br><h3>  3.1.  et 3.2.  Cr√©ation d'un syst√®me de fichiers racine </h3><br><blockquote>  J'ai sp√©cifiquement combin√© les paragraphes 3.1.  et 3.2.  car je pense que sp√©cifier la partition racine au troisi√®me niveau est absolument redondant.  C'est vrai, pendant plusieurs ann√©es de travail avec ZFS, je n'ai jamais eu besoin de faire de manipulations avec la partition racine.  De plus, il existe des images avec lesquelles vous pouvez cr√©er des points de contr√¥le.  Par cons√©quent, ma section racine est tank / root: </blockquote><br><pre> <code class="bash hljs">zfs create -o mountpoint=/ tank/root</code> </pre> <br><blockquote>  Dans le m√™me temps, la premi√®re erreur fatale est d√©tect√©e dans l'instruction d'origine, √† savoir l'absence de partition de d√©marrage pour la matrice de disques: </blockquote><br><pre> <code class="bash hljs">zpool <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> bootfs=tank/root tank</code> </pre> <br><h3>  3.3.  Cr√©er des partitions suppl√©mentaires </h3><br><blockquote><p>  Dans cette partie des instructions de base, vous pouvez tout jeter et oublier.  Les gars ont √©videmment exag√©r√© avec l'√©crasement et les options, √† cause de quoi, en cours de route, j'ai d√ª r√©parer quelque chose.  Certes, cela n'a pas beaucoup aid√©.  Etant donn√© que des probl√®mes ult√©rieurs apparaissent √† nouveau et qu'en fin de compte, il s'av√®re que cela ne fonctionne tout de m√™me pas, par cons√©quent, au paragraphe 4.11.  cela est √† nouveau corrig√©. </p><br><p>  S√©parer une section distincte pour / var / games semble assez √©pique.  Cela ne me d√©range pas, mais c'est clairement trop. </p><br><p>  Le fait que les partitions soient cr√©√©es dans ZFS simplement et prennent en charge une hi√©rarchie ne signifie pas que les r√©pertoires classiques doivent √™tre abandonn√©s.  Un exemple simple: j'ai d√©j√† eu plus de 4K partitions ZFS sur un groupe de serveurs, c'√©tait n√©cessaire, mais le red√©marrage du serveur a ralenti pendant plusieurs minutes en raison du montage de ces partitions. </p></blockquote><br><p>  Commen√ßons par une table rase. </p><br><p>  Il existe des partitions de fichiers statiques et dynamiques. </p><br><p>  Les sections de fichiers statiques incluent des sections avec des programmes et leurs param√®tres, elles sont remplies une fois et ne changent pas pendant le fonctionnement.  En m√™me temps, les anciennes partitions statiques √©taient divis√©es en partitions syst√®me et partitions utilisateur (/ usr), mais pour le moment elles sont m√©lang√©es dans les syst√®mes d'exploitation Linux et il n'y a aucun sens √† les s√©parer, et cela ne fonctionnera pas. </p><br><p>  Les sections de fichiers dynamiques incluent des sections dans lesquelles sont stock√©es: </p><br><ul><li>  Donn√©es temporaires - √©q.: Tmp, swap; </li><li>  Journaux de travail - √©q.: Var / log; </li><li>  Donn√©es utilisateur - par exemple: domicile; </li><li>  Donn√©es - √©q.: Var / db et quelle chance; </li><li>  D'autres programmes se pr√©sentent sous forme de fichiers; </li></ul><br><p>  Dans les familles Linux, les partitions dynamiques incluent / tmp et / var, mais ce n'est pas exact, car elles peuvent entrer dans / var / lib, les programmes et les biblioth√®ques, en g√©n√©ral, tout est m√©lang√©, mais n√©anmoins ... </p><br><p>  Vous devez d'abord d√©cider de cr√©er la partition / tmp sur le disque ou en m√©moire en tant que tmpfs.  Si nous cr√©ons sur disque, alors cr√©ez une partition distincte pour cela: </p><br><pre> <code class="bash hljs">zfs create -o mountpoint=legacy tank/tmp</code> </pre> <br><blockquote>  Options com.sun: auto-snapshot = false setuid = bien, peu importe la m√©t√©o, ne vous compliquez pas.  Mais avec SWAP, nous le ferons plus tard √† l'√©tape 7. </blockquote><br><p>  S√©parez la section var s√©par√©ment: </p><br><pre> <code class="bash hljs">zfs create -o mountpoint=legacy tank/var</code> </pre> <br><p>  Et les sections utilisateurs: </p><br><pre> <code class="bash hljs">zfs create -o mountpoint=/home tank/home zfs create -o mountpoint=legacy tank/home/root</code> </pre> <br><blockquote>  Il est logique d'allouer des partitions utilisateur, car dans la pratique, elles sont p√©riodiquement obstru√©es par diff√©rents artefacts et pour faciliter leur surveillance, il est pr√©f√©rable de cr√©er des partitions distinctes pour elles, ainsi que le r√©pertoire personnel de l'utilisateur root (en particulier pour ceux qui aiment travailler en tant que root).  L'utilisation de quotas sur les r√©pertoires utilisateur non seulement n'aide pas √† obstruer l'espace disque, mais interf√®re √©galement, car dans de tels cas, les utilisateurs commencent √† laisser des artefacts n'importe o√π et il peut √™tre assez difficile de les retrouver plus tard.  Ce n'est pas trait√©, il vous suffit donc de contr√¥ler et de battre les mains. </blockquote><br><p>  Le point de montage tank / home / root est r√©pertori√© comme h√©rit√©, pas comme / root.  Ceci est correct, car le montage de cette section est effectu√© dans la section 4.11 </p><br><p>  Nous devons maintenant monter temporairement nos partitions dynamiques dans / mnt: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /mnt/ mkdir var tmp root mount -t zfs tank/var /mnt/var/ mount -t zfs tank/tmp /mnt/tmp/ mount -t zfs tank/home/root /mnt/root/</code> </pre> <br><h3>  3.4 Installer le noyau </h3><br><blockquote>  Dans l'instruction principale, il y a quelques commandes suppl√©mentaires inutiles, nous n'y pr√™tons pas attention, apparemment des artefacts d'exp√©riences: </blockquote><br><pre> <code class="bash hljs">debootstrap bionic /mnt</code> </pre> <br><p>  En cons√©quence, vous devriez obtenir quelque chose comme ceci: </p><br><pre> <code class="bash hljs">zfs list NAME USED AVAIL REFER MOUNTPOINT tank 213M 1.76T 96K legacy tank/home 208K 1.76T 96K /mnt/home tank/home/root 112K 1.76T 112K legacy tank/root 147M 1.76T 147M /mnt tank/tmp 96K 1.76T 96K legacy tank/var 64.6M 1.76T 64.6M legacy</code> </pre><br><p>  La taille de la partition 96K vide, respectivement, seul tank / tmp est rest√© vide, et le reste a √©t√© enregistr√© lors de l'installation du noyau, ce qui signifie que les partitions ont √©t√© mont√©es correctement. </p><br><h2>  4. Configuration du syst√®me </h2><br><h3>  4.1.  Configurer les h√¥tes et le nom d'h√¥te </h3><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> HOSTNAME &gt; /mnt/etc/hostname <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> ‚Äú127.0.0.1 localhost‚Äù &gt; /mnt/etc/hosts <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> ‚Äú127.0.0.1 HOSTNAME‚Äù &gt;&gt; /mnt/etc/hosts</code> </pre> <br><h3>  4.2.  Configurer l'interface r√©seau </h3><br><blockquote>  Alors oui, nous avons d√©j√† netplan ici: </blockquote><br><pre> <code class="bash hljs">nano /mnt/etc/netplan/setup.yaml network: version: 2 renderer: networkd ethernets: eno2: dhcp4: no dhcp6: no addresses: [ {{ IP }}/{{ netmask }}, ] gateway4: {{ gateway IP }} nameservers: addresses: [8.8.8.8]</code> </pre> <br><h3>  4.3.  Configurer les r√©f√©rentiels apt </h3><br><pre> <code class="bash hljs">nano /mnt/etc/apt/sources.list deb http://archive.ubuntu.com/ubuntu/ bionic main restricted universe deb http://security.ubuntu.com/ubuntu/ bionic-security main restricted universe deb http://archive.ubuntu.com/ubuntu/ bionic-updates main restricted universe</code> </pre> <br><blockquote>  src - pas n√©cessaire surtout </blockquote><br><h3>  4.4.  Nous montons les sections de fichiers virtuels LiveCD et ¬´allons¬ª au nouveau syst√®me </h3><br><pre> <code class="bash hljs">mount --rbind /dev /mnt/dev mount --rbind /proc /mnt/proc mount --rbind /sys /mnt/sys chroot /mnt /bin/bash --login</code> </pre><br><blockquote>  il est n√©cessaire d'utiliser - rbind, mais pas - bind </blockquote><br><p>  Nous sommes d√©j√† dans le nouveau syst√®me ... </p><br><h3>  4.5.  Configurer l'environnement de base </h3><br><pre> <code class="bash hljs">ln -s /proc/self/mounts /etc/mtab chmod 1777 /tmp apt update</code> </pre> <br><p>  Param√®tres r√©gionaux et heure: </p><br><pre> <code class="bash hljs">dpkg-reconfigure locales * en_US.UTF-8 * ru_RU.UTF-8 dpkg-reconfigure tzdata</code> </pre> <br><p>  Et des √©diteurs suppl√©mentaires qui aiment quoi: </p><br><pre> <code class="bash hljs">apt install --yes vim nano</code> </pre> <br><h3>  4.6.  Installation du support ZFS </h3><br><pre> <code class="bash hljs">apt install --yes --no-install-recommends linux-image-generic apt install --yes zfs-initramfs</code> </pre> <br><h3>  4.8.  Installez le chargeur de d√©marrage </h3><br><p>  Comme dit pr√©c√©demment, j'utilise un MBR obsol√®te: </p><br><pre> <code class="bash hljs">apt install --yes grub-pc</code> </pre> <br><blockquote>  Pendant l'installation du chargeur de d√©marrage, il est n√©cessaire de s√©lectionner tous nos disques que nous avons identifi√©s comme amor√ßables, tandis que le programme d'installation jure sur tous les autres disques sauf le premier, nous sommes d'accord et faisons l'√©tape 5 (on ne sait pas pourquoi le reste a √©t√© laiss√© pour plus tard): </blockquote><br><h4>  4.8.1.  (5.1) V√©rifiez que le syst√®me de fichiers racine est reconnu: </h4><br><pre> <code class="bash hljs">grub-probe / zfs</code> </pre> <br><h4>  4.8.2.  (5.2) Mettre √† jour initrd </h4><br><pre> <code class="bash hljs">update-initramfs -u -k al</code> </pre> <br><h4>  4.8.3.  (5.3) Simplifier le d√©bogage GRUB </h4><br><pre> <code class="bash hljs">vi /etc/default/grub ... GRUB_CMDLINE_LINUX_DEFAULT=<span class="hljs-string"><span class="hljs-string">""</span></span> GRUB_CMDLINE_LINUX=<span class="hljs-string"><span class="hljs-string">"console"</span></span> ...</code> </pre><br><h4>  4.8.4.  (5.4.) Mise √† jour de la configuration du chargeur de d√©marrage </h4><br><pre> <code class="bash hljs">update-grub</code> </pre> <br><h4>  4.8.5.  (5.5.) Installez le chargeur de d√©marrage sur chaque disque marqu√© comme amor√ßable </h4><br><pre> <code class="bash hljs">grub-install /dev/sda grub-install /dev/sdb ...</code> </pre><br><blockquote>  Il est important que ces commandes fonctionnent correctement.  Pour √™tre honn√™te, je ne pouvais pas obtenir le contraire au moins une fois, donc je ne sais pas quoi faire, mais tr√®s probablement, si vous avez une erreur, vous avez probablement fait quelque chose de mal lors du marquage du disque (Section 2.2.). </blockquote><br><h4>  4.8.6.  (5.6.) V√©rifiez que le module ZFS est install√© </h4><br><pre> <code class="bash hljs">ls /boot/grub/*/zfs.mod /boot/grub/i386-pc/zfs.mod</code> </pre> <br><h3>  4.10.  D√©finissez le mot de passe root (difficile!) </h3><br><pre> <code class="bash hljs">passwd</code> </pre> <br><blockquote>  Et oui, nous installerons openssh tout de suite, sinon nous aurons une surprise apr√®s le red√©marrage si nous travaillons √† distance: </blockquote><br><pre> <code class="bash hljs">apt install --yes openssh-server</code> </pre> <br><p>  N'oubliez pas de corriger la configuration sshd: </p><br><pre> <code class="bash hljs">vi /etc/ssh/sshd_config ... PermitRootLogin yes ... PasswordAuthentication yes ...</code> </pre> <br><h3>  4.11.  Fixer les syst√®mes de fichiers de montage </h3><br><blockquote>  Ici, nous sommes arriv√©s au plus int√©ressant.  Le fait est que les partitions ZFS sont mont√©es apr√®s le d√©marrage de certains d√©mons (nous avons √©galement fait basculer ZFS_INITRD_ADDITIONAL_DATASETS dans / etc / default / zfs), ce qui, √† son tour, cr√©e une structure par eux-m√™mes dans / var commence √† remplir les journaux syst√®me.  Lorsque vient le temps de monter des partitions ZFS, il s'av√®re que les points de montage ne sont pas vides et que rien ne monte, les donn√©es sont dispers√©es, tout va mal.  Par cons√©quent, vous devez sp√©cifier des points de montage dans / etc / fstab car systemd se concentre principalement sur eux lors de l'acc√®s au dossier: </blockquote><br><pre> <code class="bash hljs">vi /etc/fstab tank/var /var zfs noatime,nodev 0 0 tank/tmp /tmp zfs noatime,nodev 0 0 tank/home/root /root zfs noatime,nodev 0 0</code> </pre> <br><blockquote>  Le reste d√©pend de l'article 6.  d√©j√† fait </blockquote><br><h2>  6. Premier red√©marrage </h2><br><h3>  6.1.  Prenez une photo de la partition racine </h3><br><pre> <code class="bash hljs">zfs snapshot tank/root@setup</code> </pre> <br><blockquote>  Cela n'a aucun sens de sa part, dans la pratique, je n'ai jamais secou√© la partition racine du syst√®me et je n'ai jamais utilis√© d'instantan√©s de cette partition, mais laissez-la n√©anmoins mentir, cela peut √™tre utile </blockquote><br><h3>  6.2.  Quitter chroot </h3><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> <br><h3>  6.3.  D√©montez les partitions LiveCD et exportez le tableau ZFS </h3><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> mount | grep -v zfs | tac | awk <span class="hljs-string"><span class="hljs-string">'/\/mnt/ {print $3}'</span></span> | xargs -i{} umount -lf {} umount /mnt/root umount /mnt/var umount /mnt/tmp zpool <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> tank</code> </pre> <br><blockquote>  Exportation de la baie de disques requise pour vider le cache zfs </blockquote><br><h3>  6.4 Red√©marrage </h3><br><blockquote>  Le red√©marrage est mieux effectu√© dans le terminal LiveCD, car si vous travaillez via un client ssh, le red√©marrage via celui-ci peut entra√Æner le gel du serveur. </blockquote><br><pre> <code class="bash hljs">reboot</code> </pre> <br><blockquote>  Si, n√©anmoins, quelque chose s'est mal pass√© et que le serveur n'est pas all√© red√©marrer, vous pouvez red√©marrer de quelque mani√®re que ce soit, car le tableau ZFS est export√© et il est difficile de l'endommager. </blockquote><br><h3>  6.5.  Nous attendons un red√©marrage et allons en tant que root </h3><br><h3>  6.6.  Cr√©ez votre compte utilisateur </h3><br><pre> <code class="bash hljs">zfs create tank/home/{{ LOGIN }} useradd -u {{ UID }} -G adm,sudo -d /home/{{ LOGIN }}/ -s /bin/bash {{ LOGIN }} cp -a /etc/skel/.[!.]* /home/{{ LOGIN }} chown -R {{ LOGIN }}:{{ LOGIN }} /home/{{ LOGIN }}</code> </pre> <br><p>  Ajoutez la cl√© publique ssh √† l'utilisateur et d√©finissez le mot de passe pour lui: </p><br><pre> <code class="bash hljs">su - {{ LOGIN }} mkdir .ssh chmod 0700 .ssh vi .ssh/authorized_keys <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span> passwd {{ LOGIN }}</code> </pre> <br><blockquote>  Dans OpenSSH, nous supprimons la possibilit√© de se connecter en tant qu'authentification root et mot de passe: </blockquote><br><pre> <code class="bash hljs">vi /etc/ssh/sshd_config ... PermitRootLogin no ... PubkeyAuthentication yes ... PasswordAuthentication no ... service ssh restart</code> </pre> <br><h3>  6.7.  6.8.  Plus n√©cessaire </h3><br><h2>  7. Configuration du swap </h2><br><h3>  7.1.  Cr√©er une partition ZFS </h3><br><pre> <code class="bash hljs">zfs create \ -V 32G \ -b $(getconf PAGESIZE) \ -o compression=<span class="hljs-built_in"><span class="hljs-built_in">zle</span></span> \ -o logbias=throughput \ -o sync=always \ -o primarycache=metadata \ -o secondarycache=none \ tank/swap</code> </pre> <br><ul><li>  -V 32G - La taille de notre SWAP, vous pouvez d√©terminer celle qui est vraiment n√©cessaire; </li><li>  -b $ (getconf PAGESIZE) - taille de bloc (4K avec ashift = 12); </li><li>  compression = zle - choisissez l'algorithme de compression qui est minimal en termes de consommation de ressources, car en fait la taille du bloc est 4K, la compression en tant que telle ne permettra pas l'utilisation pour l'entr√©e-sortie, mais il sera possible d'√©conomiser sur z√©ro bloc; </li><li>  logbias = throughput - d√©finition de la bande passante pour optimiser les op√©rations synchrones; </li><li>  sync = always - synchronise toujours l'enregistrement.  Cela r√©duit l√©g√®rement les performances, mais garantit pleinement la fiabilit√© des donn√©es; </li><li>  primarycache = metadata - met en cache uniquement les m√©tadonn√©es, car le swap ne sera pas utilis√© pour lire le m√™me bloc plusieurs fois; </li><li>  secondairecache = aucun - d√©sactiver compl√®tement le cache secondaire pour les raisons mentionn√©es ci-dessus; </li></ul><br><h3>  7.2.  Configurer la partition de swap </h3><br><pre> <code class="bash hljs">mkswap -f /dev/zvol/tank/swap <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> /dev/zvol/tank/swap none swap defaults 0 0 &gt;&gt; /etc/fstab <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> RESUME=none &gt; /etc/initramfs-tools/conf.d/resume</code> </pre><br><h3>  7.3.  Activer l'√©change </h3><br><pre> <code class="bash hljs">swapon -av</code> </pre> <br><blockquote><p>  En suivant les instructions, il n'y a pas grand-chose d'int√©ressant, car cela d√©pend fortement des pr√©f√©rences d'administrateurs sp√©cifiques et des t√¢ches du serveur dans son ensemble, √† l'exception d'un point, √† savoir: "D√©marrage d'urgence" </p><p>  Et n'oubliez pas de mettre le pare-feu </p></blockquote><br><h2>  R. Botte d'urgence </h2><br><p>  Nous pr√©parons l'environnement d'installation (point 1.) </p><br><p>  Pendant la pr√©paration, le tableau ZFS est import√©, vous devez donc le r√©importer, mais avec le point de montage correct: </p><br><pre> <code class="bash hljs">zpool <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> -a zpool import -N -R /mnt tank zfs mount -a</code> </pre> <br><blockquote> , ,      ,        fstab,    : </blockquote><br><pre> <code class="bash hljs">mount -t zfs tank/var /mnt/var/ mount -t zfs tank/tmp /mnt/tmp/ mount -t zfs tank/home/root /mnt/root/</code> </pre> <br><p> ,   ,   chroot   .4.4.,          . 6.3. </p><br><h2> D.   </h2><br><p>   3.3.             .      ,        : ,       /spool,      /data.       ZFS     . </p><br><h2>  R√©sum√© </h2><br><ul><li>       ZFS  ,     ,     ; </li><li>        ZFS,                 ,     .    ZFS ‚Äî       ,   ; </li><li>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">.</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr439860/">https://habr.com/ru/post/fr439860/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr439850/index.html">D√©tection d'√©motions contextuelles dans les conversations textuelles √† l'aide de r√©seaux de neurones</a></li>
<li><a href="../fr439852/index.html">Version de l'application de contr√¥le √† distance: Aspia 1.1.0</a></li>
<li><a href="../fr439854/index.html">Eh, une, une fois de plus: que faire avec un client CRM apr√®s avoir achet√©</a></li>
<li><a href="../fr439856/index.html">Yandex! Merci pour Uber</a></li>
<li><a href="../fr439858/index.html">Prometheus + Grafana + Node Exporter + Docker dans Azure avec notifications dans Telegram</a></li>
<li><a href="../fr439862/index.html">√âv√©nements num√©riques √† Moscou du 11 au 17 f√©vrier</a></li>
<li><a href="../fr439864/index.html">Gestion des connaissances, pourquoi et comment nous l'avons fait</a></li>
<li><a href="../fr439866/index.html">Les principes de conception des r√©pertoires de nomenclature dans 1C Enterprise Management 2 (ERP 2.4.6)</a></li>
<li><a href="../fr439868/index.html">La vie sans Facebook: vues moins radicales, bonne humeur, plus de temps pour les proches. Maintenant prouv√© par la science</a></li>
<li><a href="../fr439870/index.html">La vid√©o comme moteur de progr√®s: l'√©volution des syst√®mes de surveillance</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéüÔ∏è ü§öüèª üí≥ Aufbau eines automatischen Nachrichtenmoderationssystems ‚òùÔ∏è üêß ‚ö±Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Automatische Moderationssysteme werden in Webdiensten und Anwendungen implementiert, in denen eine gro√üe Anzahl von Benutzernachrichten verarbeitet we...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aufbau eines automatischen Nachrichtenmoderationssystems</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454628/"><img src="https://habrastorage.org/webt/xu/yp/u9/xuypu9acrj8o6qbkrhu53ue4kni.png" alt="Bild"><br>  Automatische Moderationssysteme werden in Webdiensten und Anwendungen implementiert, in denen eine gro√üe Anzahl von Benutzernachrichten verarbeitet werden muss.  Solche Systeme k√∂nnen die Kosten f√ºr die manuelle Moderation senken, beschleunigen und alle Benutzernachrichten in Echtzeit verarbeiten.  In dem Artikel werden wir √ºber den Aufbau eines automatischen Moderationssystems f√ºr die Verarbeitung von Englisch unter Verwendung von Algorithmen f√ºr maschinelles Lernen sprechen.  Wir werden die gesamte Pipeline-Arbeit von Forschungsaufgaben und der Auswahl von ML-Algorithmen bis zur Einf√ºhrung in die Produktion diskutieren.  Lassen Sie uns sehen, wo Sie nach vorgefertigten Datens√§tzen suchen und wie Sie selbst Daten f√ºr die Aufgabe sammeln k√∂nnen. <br><a name="habracut"></a><br><br>  <i>Vorbereitet mit Ira Stepanyuk ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">id_step</a> ), Data Scientist bei Poteha Labs</i> <br><br><h2>  Aufgabenbeschreibung </h2><br>  Wir arbeiten mit aktiven Chats f√ºr mehrere Benutzer, bei denen jede Minute Kurznachrichten von Dutzenden von Benutzern in einem Chat eingehen k√∂nnen.  Die Aufgabe besteht darin, toxische Nachrichten und Nachrichten mit obsz√∂nen Bemerkungen in Dialogen aus solchen Chats hervorzuheben.  Aus Sicht des maschinellen Lernens handelt es sich um eine bin√§re Klassifizierungsaufgabe, bei der jede Nachricht einer der Klassen zugeordnet werden muss. <br><br>  Um dieses Problem zu l√∂sen, musste zun√§chst verstanden werden, was toxische Botschaften sind und was sie genau toxisch macht.  Zu diesem Zweck haben wir uns eine gro√üe Anzahl typischer Benutzernachrichten im Internet angesehen.  Hier sind einige Beispiele, die wir bereits in toxische und normale Nachrichten unterteilt haben. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Giftig </th><th>  Normal </th></tr><tr><td>  Du bist eine verdammte Schwuchtel </td><td>  Dieses Buch ist so dumm </td></tr><tr><td>  Dein Kind ist so h√§sslich (1) </td><td>  Gewinner gewinnen, Verlierer machen Ausreden </td></tr><tr><td>  Wei√üe sind Besitzer von Schwarz (2) </td><td>  schwarz wie meine Seele (2) </td></tr></tbody></table></div><br>  Es ist ersichtlich, dass giftige Botschaften oft obsz√∂ne W√∂rter enthalten, dies ist jedoch keine Voraussetzung.  Die Nachricht enth√§lt m√∂glicherweise keine unangemessenen W√∂rter, ist jedoch f√ºr jemanden anst√∂√üig (Beispiel (1)).  Dar√ºber hinaus enthalten toxische und normale Nachrichten manchmal dieselben W√∂rter, die in unterschiedlichen Kontexten verwendet werden - anst√∂√üig oder nicht (Beispiel (2)).  Solche Nachrichten m√ºssen auch unterscheiden k√∂nnen. <br>  Nachdem wir verschiedene Botschaften studiert hatten, nannten wir f√ºr unser Moderationssystem solche Botschaften <b><i>giftig</i></b> , die Aussagen mit obsz√∂nen, beleidigenden Ausdr√ºcken oder Hass auf jemanden enthalten. <br><br><h2>  Daten </h2><br><h4>  Daten √∂ffnen </h4><br>  Einer der bekanntesten Moderationsdatens√§tze ist der Datensatz der Kaggle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Toxic Comment Classification Challenge</a> .  Ein Teil des Markups im Datensatz ist falsch: Beispielsweise k√∂nnen Nachrichten mit obsz√∂nen W√∂rtern als normal markiert werden.  Aus diesem Grund k√∂nnen Sie nicht einfach an Kernel-Wettbewerben teilnehmen und einen gut funktionierenden Klassifizierungsalgorithmus erhalten.  Sie m√ºssen mehr mit den Daten arbeiten, herausfinden, welche Beispiele nicht ausreichen, und mit solchen Beispielen zus√§tzliche Daten hinzuf√ºgen. <br><br>  Neben Wettbewerben gibt es mehrere wissenschaftliche Ver√∂ffentlichungen mit Links zu geeigneten Datens√§tzen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beispiel</a> ), aber nicht alle k√∂nnen in kommerziellen Projekten verwendet werden.  Meistens enthalten diese Datens√§tze Nachrichten aus dem sozialen Netzwerk Twitter, in dem Sie viele giftige Tweets finden.  Dar√ºber hinaus werden Daten von Twitter gesammelt, da bestimmte Hashtags zum Suchen und Markieren toxischer Benutzernachrichten verwendet werden k√∂nnen. <br><br><h4>  Manuelle Daten </h4><br>  Nachdem wir den Datensatz aus offenen Quellen gesammelt und das Grundmodell darauf trainiert hatten, wurde klar, dass offene Daten nicht ausreichen: Die Qualit√§t des Modells ist nicht zufriedenstellend.  Zus√§tzlich zu den offenen Daten zur L√∂sung des Problems stand uns eine nicht zugewiesene Auswahl von Nachrichten von einem Game Messenger mit einer gro√üen Anzahl toxischer Nachrichten zur Verf√ºgung. <br><br><img src="https://habrastorage.org/webt/eh/sp/5o/ehsp5oivhvjnfgxrnjqc7wszf9u.gif" alt="Bild"><br><br>  Um diese Daten f√ºr ihre Aufgabe zu verwenden, mussten sie irgendwie beschriftet werden.  Zu diesem Zeitpunkt gab es bereits einen ausgebildeten Basisklassifikator, den wir f√ºr die halbautomatische Markierung verwendeten.  Nachdem wir alle Nachrichten durch das Modell gef√ºhrt haben, haben wir die Toxizit√§tswahrscheinlichkeiten jeder Nachricht ermittelt und in absteigender Reihenfolge sortiert.  Am Anfang dieser Liste wurden Nachrichten mit obsz√∂nen und beleidigenden Worten gesammelt.  Am Ende gibt es im Gegenteil normale Benutzernachrichten.  Daher konnten die meisten Daten (mit sehr gro√üen und sehr kleinen Wahrscheinlichkeitswerten) nicht markiert, sondern sofort einer bestimmten Klasse zugeordnet werden.  Es bleiben die Nachrichten zu markieren, die in die Mitte der Liste fielen, was manuell gemacht wurde. <br><br><h4>  Datenerweiterung </h4><br>  Oft sehen Sie in Datens√§tzen ge√§nderte Nachrichten, bei denen der Klassifikator falsch ist, und die Person versteht ihre Bedeutung richtig. <br>  Dies liegt daran, dass Benutzer Moderationssysteme anpassen und lernen, sie zu betr√ºgen, sodass die Algorithmen Fehler bei toxischen Nachrichten machen und die Bedeutung f√ºr die Person klar bleibt.  Was Benutzer jetzt tun: <br><br><ul><li>  Tippfehler erzeugen: <i>Sie sind dumm Arschloch, ficken Sie</i> , </li><li>  Ersetzen Sie alphabetische Zeichen durch Zahlen, die in der Beschreibung √§hnlich sind: <i>n1gga, b0ll0cks</i> , </li><li>  zus√§tzliche Leerzeichen einf√ºgen: <i>Idiot</i> , </li><li>  Leerzeichen zwischen W√∂rtern entfernen: <i>dieyoustupid</i> . </li></ul><br><br>  Um einen Klassifikator zu trainieren, der gegen solche Ersetzungen resistent ist, m√ºssen Sie das tun, was Benutzer tun: Generieren Sie dieselben √Ñnderungen in Nachrichten und f√ºgen Sie sie dem Trainingssatz zu den Hauptdaten hinzu. <br>  Im Allgemeinen ist dieser Kampf unvermeidlich: Benutzer werden immer versuchen, Schwachstellen und Hacks zu finden, und Moderatoren werden neue Algorithmen implementieren. <br><br><h3>  Beschreibung der Unteraufgaben </h3><br>  Wir standen vor Unteraufgaben zur Analyse von Nachrichten in zwei verschiedenen Modi: <br><br><ul><li>  Online-Modus - Echtzeitanalyse von Nachrichten mit maximaler Antwortgeschwindigkeit; </li><li>  Offline-Modus - Analyse von Nachrichtenprotokollen und Zuordnung toxischer Dialoge. </li></ul><br>  Im Online-Modus verarbeiten wir jede Benutzernachricht und f√ºhren sie durch das Modell.  Wenn die Nachricht giftig ist, verstecken Sie sie in der Chat-Oberfl√§che. Wenn sie normal ist, zeigen Sie sie an.  In diesem Modus sollten alle Nachrichten sehr schnell verarbeitet werden: Das Modell sollte so schnell eine Antwort geben, dass die Struktur des Dialogs zwischen Benutzern nicht gest√∂rt wird. <br>  Im Offline-Modus gibt es keine zeitlichen Beschr√§nkungen f√ºr die Arbeit, und deshalb wollte ich das Modell mit der h√∂chsten Qualit√§t implementieren. <br><br><h3>  Online-Modus.  W√∂rterbuchsuche </h3><br>  Unabh√§ngig davon, welches Modell als n√§chstes ausgew√§hlt wird, m√ºssen wir Nachrichten mit obsz√∂nen W√∂rtern finden und filtern.  Um dieses Teilproblem zu l√∂sen, ist es am einfachsten, ein W√∂rterbuch mit ung√ºltigen W√∂rtern und Ausdr√ºcken zu erstellen, die nicht √ºbersprungen werden k√∂nnen, und in jeder Nachricht nach solchen W√∂rtern zu suchen.  Die Suche sollte schnell sein, daher passt der Suchalgorithmus f√ºr naive Teilzeichenfolgen f√ºr diese Zeit nicht.  Ein geeigneter Algorithmus zum Finden einer Reihe von W√∂rtern in einer Zeichenfolge ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Aho-Korasik-Algorithmus</a> .  Aufgrund dieses Ansatzes ist es m√∂glich, einige toxische Beispiele schnell zu identifizieren und Nachrichten zu blockieren, bevor sie an den Hauptalgorithmus √ºbertragen werden.  Mit dem ML-Algorithmus k√∂nnen Sie die Bedeutung von Nachrichten "verstehen" und die Qualit√§t der Klassifizierung verbessern. <br><br><h3>  Online-Modus.  Grundlegendes Modell des maschinellen Lernens </h3><br>  F√ºr das Basismodell haben wir uns f√ºr einen Standardansatz f√ºr die Textklassifizierung entschieden: TF-IDF + klassischer Klassifizierungsalgorithmus.  Wieder aus Geschwindigkeits- und Leistungsgr√ºnden. <br><br>  TF-IDF ist ein statistisches Ma√ü, mit dem Sie die wichtigsten W√∂rter f√ºr Text im Textk√∂rper anhand von zwei Parametern bestimmen k√∂nnen: der H√§ufigkeit der W√∂rter in jedem Dokument und der Anzahl der Dokumente, die ein bestimmtes Wort enthalten ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ausf√ºhrlicher).  Nachdem wir f√ºr jedes Wort in der TF-IDF-Nachricht berechnet haben, erhalten wir eine Vektordarstellung dieser Nachricht. <br>  TF-IDF kann sowohl f√ºr W√∂rter im Text als auch f√ºr n-Gramm-W√∂rter und -Zeichen berechnet werden.  Eine solche Erweiterung funktioniert besser, da sie h√§ufig vorkommende Phrasen und W√∂rter verarbeiten kann, die nicht im Trainingssatz enthalten sind (au√üerhalb des Wortschatzes). <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.feature_extraction.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TfidfVectorizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sparse vect_word = TfidfVectorizer(max_features=<span class="hljs-number"><span class="hljs-number">10000</span></span>, lowercase=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, analyzer=<span class="hljs-string"><span class="hljs-string">'word'</span></span>, min_df=<span class="hljs-number"><span class="hljs-number">8</span></span>, stop_words=stop_words, ngram_range=(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) vect_char = TfidfVectorizer(max_features=<span class="hljs-number"><span class="hljs-number">30000</span></span>, lowercase=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, analyzer=<span class="hljs-string"><span class="hljs-string">'char'</span></span>, min_df=<span class="hljs-number"><span class="hljs-number">8</span></span>, ngram_range=(<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>)) x_vec_word = vect_word.fit_transform(x_train) x_vec_char = vect_char.fit_transform(x_train) x_vec = sparse.hstack([x_vec_word, x_vec_char])</code> </pre>  <i>Beispiel f√ºr die Verwendung von TF-IDF f√ºr n-Gramm W√∂rter und Zeichen</i> <br><br>  Nach dem Konvertieren von Nachrichten in Vektoren k√∂nnen Sie eine beliebige klassische Methode zur Klassifizierung verwenden: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">logistische Regression, SVM</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zuf√§llige Gesamtstruktur, Boosten</a> . <br><br>  Wir haben uns f√ºr die Verwendung der logistischen Regression f√ºr unsere Aufgabe entschieden, da dieses Modell im Vergleich zu anderen klassischen ML-Klassifikatoren eine h√∂here Geschwindigkeit bietet und Klassenwahrscheinlichkeiten vorhersagt, sodass Sie einen Klassifizierungsschwellenwert in der Produktion flexibel ausw√§hlen k√∂nnen. <br><br>  Der mit TF-IDF und logistischer Regression erhaltene Algorithmus funktioniert schnell und definiert Nachrichten mit obsz√∂nen W√∂rtern und Ausdr√ºcken gut, versteht jedoch nicht immer die Bedeutung.  Beispielsweise fielen Nachrichten mit den W√∂rtern " <i>schwarz</i> " und " <i>feministisch</i> " h√§ufig in die toxische Klasse.  Ich wollte dieses Problem beheben und lernen, die Bedeutung von Nachrichten mit der n√§chsten Version des Klassifikators besser zu verstehen. <br><br><h3>  Offline-Modus </h3><br>  Um die Bedeutung von Nachrichten besser zu verstehen, k√∂nnen Sie neuronale Netzwerkalgorithmen verwenden: <br><br><ul><li>  Einbettungen (Word2Vec, FastText) </li><li>  Neuronale Netze (CNN, RNN, LSTM) </li><li>  Neue vorgefertigte Modelle (ELMo, ULMFiT, BERT) </li></ul><br>  Wir werden einige dieser Algorithmen diskutieren und wie sie detaillierter verwendet werden k√∂nnen. <br><br><h4>  Word2Vec und FastText </h4><br>  Durch das Einbetten von Modellen k√∂nnen Sie Vektordarstellungen von W√∂rtern aus Texten abrufen.  Es gibt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zwei Arten von Word2Vec</a> : Skip-Gramm und CBOW (Continuous Bag of Words).  In Skip-Gramm wird der Kontext durch das Wort vorhergesagt, in CBOW umgekehrt: Das Wort wird durch den Kontext vorhergesagt. <br><img src="https://habrastorage.org/webt/rc/kb/iv/rckbivfc1dvmna3bvccy6xoai_g.png" alt="Bild"><br>  Solche Modelle werden auf gro√üen Textkorps trainiert und erm√∂glichen es Ihnen, Vektordarstellungen von W√∂rtern aus einer verborgenen Schicht eines trainierten neuronalen Netzwerks zu erhalten.  Der Nachteil dieser Architektur besteht darin, dass das Modell aus einer begrenzten Anzahl von W√∂rtern lernt, die im Korpus enthalten sind.  Dies bedeutet, dass f√ºr alle W√∂rter, die sich in der Trainingsphase nicht im Textk√∂rper befanden, keine Einbettungen vorgenommen werden.  Und diese Situation tritt h√§ufig auf, wenn vorab trainierte Modelle f√ºr ihre Aufgaben verwendet werden: Bei einigen W√∂rtern gibt es keine Einbettungen, dementsprechend geht eine gro√üe Menge n√ºtzlicher Informationen verloren. <br><br>  Um das Problem mit W√∂rtern zu l√∂sen, die nicht im W√∂rterbuch enthalten sind (OOV, au√üerhalb des Wortschatzes), gibt es ein verbessertes Einbettungsmodell - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">FastText</a> .  Anstatt einzelne W√∂rter zum Trainieren des neuronalen Netzwerks zu verwenden, zerlegt FastText die W√∂rter in n-Gramm (Unterw√∂rter) und lernt daraus.  Um eine Vektordarstellung eines Wortes zu erhalten, m√ºssen Sie Vektordarstellungen des n-Gramms dieses Wortes erhalten und diese hinzuf√ºgen. <br><br>  Somit k√∂nnen vorab trainierte Word2Vec- und FastText-Modelle verwendet werden, um Merkmalsvektoren aus Nachrichten zu erhalten.  Die erhaltenen Eigenschaften k√∂nnen unter Verwendung klassischer ML-Klassifikatoren oder eines vollst√§ndig verbundenen neuronalen Netzwerks klassifiziert werden. <br><br><img src="https://habrastorage.org/webt/jb/bp/ma/jbbpma-miqfsht7roadxuk2bap4.png" alt="Bild"><br>  <i>Ein Beispiel f√ºr die Ausgabe der W√∂rter "am n√§chsten" in der Bedeutung mit vorab <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">trainiertem FastText</a></i> <br><br><h4>  CNN-Klassifikator </h4><br>  Zur Verarbeitung und Klassifizierung von Texten aus neuronalen Netzwerkalgorithmen werden h√§ufiger wiederkehrende Netzwerke (LSTM, GRU) verwendet, da sie gut mit Sequenzen funktionieren.  Faltungsnetzwerke (CNNs) werden am h√§ufigsten f√ºr die Bildverarbeitung verwendet, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">k√∂nnen jedoch</a> auch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">f√ºr</a> die Textklassifizierungsaufgabe verwendet werden.  √úberlegen Sie, wie dies getan werden kann. <br>  Jede Nachricht ist eine Matrix, in die in jede Zeile f√ºr das Token (Wort) seine Vektordarstellung geschrieben ist.  Die Faltung wird auf eine bestimmte Weise auf eine solche Matrix angewendet: Der Faltungsfilter ‚Äûgleitet‚Äú √ºber ganze Zeilen der Matrix (Wortvektoren), erfasst jedoch mehrere W√∂rter gleichzeitig (normalerweise 2 bis 5 W√∂rter) und verarbeitet so die W√∂rter im Kontext benachbarter W√∂rter.  Details dazu finden Sie auf dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bild</a> . <br><img src="https://habrastorage.org/webt/hx/yd/vf/hxydvfho2bzzmgyjedkkt9lz9gc.png" alt="Bild"><br>  Warum Faltungsnetzwerke f√ºr die Textverarbeitung verwenden, wenn Sie wiederkehrende verwenden k√∂nnen?  Tatsache ist, dass Windungen viel schneller arbeiten.  Wenn Sie sie f√ºr die Klassifizierung von Nachrichten verwenden, k√∂nnen Sie beim Training erheblich Zeit sparen. <br><br><h4>  ELMo </h4><br>  ELMo (Einbettungen aus Sprachmodellen) ist ein Einbettungsmodell, das auf einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">k√ºrzlich eingef√ºhrten</a> Sprachmodell basiert.  Das neue Einbettungsmodell unterscheidet sich von den Modellen Word2Vec und FastText.  ELMo-Wortvektoren haben bestimmte Vorteile: <br><br><ul><li>  Die Darstellung jedes Wortes h√§ngt vom gesamten Kontext ab, in dem es verwendet wird. </li><li>  Die Darstellung basiert auf Symbolen, die die Bildung zuverl√§ssiger Darstellungen f√ºr OOV-W√∂rter (au√üerhalb des Wortschatzes) erm√∂glichen. </li></ul><br><br>  ELMo kann f√ºr verschiedene Aufgaben in NLP verwendet werden.  F√ºr unsere Aufgabe k√∂nnen beispielsweise mit ELMo empfangene Nachrichtenvektoren an den klassischen ML-Klassifizierer gesendet werden oder ein Faltungsnetzwerk oder ein vollst√§ndig verbundenes Netzwerk verwenden. <br>  Vorgefertigte Einbettungen von ELMo sind f√ºr Ihre Aufgabe recht einfach zu verwenden. Ein Beispiel f√ºr die Verwendung finden Sie <a href="">hier</a> . <br><br><h3>  Implementierungsfunktionen </h3><br><h4>  Kolben-API </h4><br>  Die Prototyp-API wurde in Flask geschrieben, da sie einfach zu verwenden ist. <br><br><h4>  Zwei Docker-Bilder </h4><br>  F√ºr die Bereitstellung haben wir zwei Docker-Images verwendet: das Basis-Image, in dem alle Abh√§ngigkeiten installiert wurden, und das Haupt-Image zum Starten der Anwendung.  Dies spart erheblich Montagezeit, da das erste Image selten neu erstellt wird, und dies spart Zeit w√§hrend der Bereitstellung.  Es wird ziemlich viel Zeit f√ºr das Erstellen und Herunterladen von Bibliotheken f√ºr maschinelles Lernen aufgewendet, was nicht bei jedem Commit erforderlich ist. <br><br><h4>  Testen </h4><br>  Die Besonderheit der Implementierung einer relativ gro√üen Anzahl von Algorithmen f√ºr maschinelles Lernen besteht darin, dass selbst bei hohen Metriken im Validierungsdatensatz die tats√§chliche Qualit√§t des Algorithmus in der Produktion gering sein kann.  Um die Funktionsweise des Algorithmus zu testen, verwendete das gesamte Team den Bot in Slack.  Dies ist sehr praktisch, da jedes Mitglied des Teams √ºberpr√ºfen kann, welche Antwort die Algorithmen auf eine bestimmte Nachricht geben.  Mit dieser Testmethode k√∂nnen Sie sofort sehen, wie die Algorithmen mit Live-Daten funktionieren. <br>  Eine gute Alternative ist die Einf√ºhrung der L√∂sung auf √∂ffentlichen Websites wie Yandex Toloka und AWS Mechanical Turk. <br><br><h3>  Fazit </h3><br>  Wir haben verschiedene Ans√§tze zur L√∂sung des Problems der automatischen Nachrichtenmoderation untersucht und die Merkmale unserer Implementierung beschrieben. <br>  Die wichtigsten Beobachtungen w√§hrend der Arbeit: <br><br><ul><li>  Der Algorithmus f√ºr W√∂rterbuchsuche und maschinelles Lernen basierend auf TF-IDF und logistischer Regression erm√∂glichte die schnelle Klassifizierung von Nachrichten, jedoch nicht immer korrekt. </li><li>  Neuronale Netzwerkalgorithmen und vorab trainierte Einbettungsmodelle bew√§ltigen diese Aufgabe besser und k√∂nnen die Toxizit√§t im Sinne der Nachricht bestimmen. </li></ul><br><br>  Nat√ºrlich haben wir die offene Demo zur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erkennung toxischer Kommentare von Poteha</a> auf dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Facebook-</a> Bot ver√∂ffentlicht.  Helfen Sie uns, den Bot besser zu machen! <br><br>  Gerne beantworte ich Fragen in den Kommentaren. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de454628/">https://habr.com/ru/post/de454628/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de454616/index.html">Der Einsatz von KI zur Steigerung der Effizienz von Geistesarbeitern</a></li>
<li><a href="../de454618/index.html">Produktivit√§tsgrube: Wie locker unser Workflow schadet</a></li>
<li><a href="../de454620/index.html">#NoDeployFriday: hilft oder schadet?</a></li>
<li><a href="../de454622/index.html">Kreisel EVEX 910e: historisches Modell - neues Leben</a></li>
<li><a href="../de454626/index.html">DevOops gestern und heute</a></li>
<li><a href="../de454630/index.html">Ausnahmesituationen: Teil 1 von 4</a></li>
<li><a href="../de454634/index.html">Sicherheitswoche 23: Notepad-Sicherheitsl√ºcke, eine Million Systeme mit nicht gepatchten RDP</a></li>
<li><a href="../de454640/index.html">Remote-Microservice-Debugging √ºber SSH unter VPN in 4 Runden</a></li>
<li><a href="../de454642/index.html">"Machen Sie eine Anwendung f√ºr Menschen" - dies ist nicht auf das Knie zu kritzeln ": √ºber die mobile Entwicklung in der CFT</a></li>
<li><a href="../de454644/index.html">Schulung Cisco 200-125 CCNA v3.0. Tag 8. Setup wechseln</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
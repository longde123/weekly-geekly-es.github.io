<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï° üë©üèæ‚Äçüé§ üôç Spracherkennungsproblem noch nicht gel√∂st üòÖ üëäüèª ü•û</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Seit Deep Learning in die Szene der Spracherkennung eingetreten ist, hat sich die Anzahl der Fehler bei der Worterkennung drastisch verringert. Trotz ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Spracherkennungsproblem noch nicht gel√∂st</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/408017/">  Seit Deep Learning in die Szene der Spracherkennung eingetreten ist, hat sich die Anzahl der Fehler bei der Worterkennung drastisch verringert.  Trotz aller Artikel, die Sie lesen konnten, haben wir immer noch keine Spracherkennung auf menschlicher Ebene.  Spracherkenner weisen viele Arten von Fehlern auf.  Zur weiteren Verbesserung m√ºssen sie zugewiesen werden und versuchen, sie zu beseitigen.  Dies ist der einzige Weg von der Anerkennung, die f√ºr manche Menschen die meiste Zeit geeignet ist, zur Anerkennung, die f√ºr alle Menschen immer funktioniert. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/geektimes/post_images/443/a84/749/443a8474981289cde040380c76002864.svg"></div><br>  <i>Verbesserung der Anzahl falsch erkannter W√∂rter.</i>  <i>Die Test-Sprachwahl wurde im Jahr 2000 an einer Telefonzentrale aus 40 zuf√§lligen Gespr√§chen von zwei Personen zusammengestellt, deren Muttersprache Englisch ist</i> <br><br>  Zu sagen, dass wir in Gespr√§chen das Niveau einer Person bei der Spracherkennung erreicht haben, die nur auf einer Reihe von Gespr√§chen √ºber eine Telefonzentrale basiert, ist dasselbe wie zu sagen, dass ein Robomobil nicht schlechter f√§hrt als eine Person und es in einer einzelnen Stadt an einem sonnigen Tag ohne Verkehr testet .  Die j√ºngsten Entwicklungen bei der Spracherkennung waren √ºberraschend.  Aussagen zur Spracherkennung auf menschlicher Ebene sind jedoch zu k√ºhn.  Hier sind einige Bereiche, in denen noch Verbesserungen erforderlich sind. <br><a name="habracut"></a><br><h2>  Akzente und L√§rm </h2><br>  Einer der offensichtlichen Nachteile der Spracherkennung ist die Verarbeitung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Akzenten</a> und Hintergrundger√§uschen.  Der Hauptgrund daf√ºr ist, dass die meisten Trainingsdaten aus amerikanischem Dialekt mit einem hohen Signal-Rausch-Verh√§ltnis bestehen.  In den Gespr√§chen √ºber die Telefonzentrale gibt es beispielsweise nur Gespr√§che mit Personen, deren Muttersprache Englisch ist (zum gr√∂√üten Teil Amerikaner), mit geringen Hintergrundger√§uschen. <br><br>  Eine Erh√∂hung der Trainingsdaten allein wird dieses Problem jedoch h√∂chstwahrscheinlich nicht l√∂sen.  Es gibt viele Sprachen, die viele Dialekte und Akzente enthalten.  Es ist unrealistisch, markierte Daten f√ºr alle F√§lle zu sammeln.  Um eine qualitativ hochwertige Spracherkennung nur f√ºr amerikanisches Englisch zu erstellen, sind bis zu 5.000 Stunden Audioaufnahmen erforderlich, die in Text √ºbersetzt werden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/geektimes/post_images/072/946/fac/072946faca72dac55d3a3acd20bfba3f.svg"></div><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Vergleich von</a> Personen, die Sprache in Text umwandeln, mit Baidus Deep Speech 2 zu verschiedenen Arten von Sprache.</i>  <i>Die Menschen erkennen nichtamerikanische Akzente schlechter - vielleicht wegen der F√ºlle an Amerikanern unter ihnen.</i>  <i>Ich denke, dass Menschen, die in einer bestimmten Region mit einer viel geringeren Anzahl von Fehlern aufgewachsen sind, in der Lage w√§ren, die Betonung dieser Region zu erkennen.</i> <br><br>  Bei Hintergrundger√§uschen in einem fahrenden Auto kann das Signal-Rausch-Verh√§ltnis Werte von -5 dB erreichen.  Menschen k√∂nnen unter solchen Bedingungen leicht mit der Spracherkennung einer anderen Person umgehen.  Automatische Erkenner verschlechtern sich mit zunehmendem Rauschen viel schneller.  Die Grafik zeigt, wie stark die Trennung von Personen mit zunehmendem Rauschen zunimmt (bei niedrigem SNR, Signal-Rausch-Verh√§ltnis) <br><br><h2>  Semantische Fehler </h2><br>  Oft ist die Anzahl von falsch erkannten W√∂rtern kein Selbstzweck in einem Spracherkennungssystem.  Wir streben die Anzahl der semantischen Fehler an.  Dies ist der Anteil der Ausdr√ºcke, in denen wir die Bedeutung falsch erkennen. <br><br>  Ein Beispiel f√ºr einen semantischen Fehler ist, wenn jemand "Treffen wir uns am Dienstag" anbietet [sich am Dienstag treffen] und der Erkenner "Treffen wir uns heute treffen" [Treffen wir uns heute] anbietet.  Es gibt Fehler in Worten ohne semantische Fehler.  Wenn der Erkenner "up" nicht erkannte und "lass uns Dienstag treffen" ausgab, √§nderte sich die Semantik des Satzes nicht. <br><br>  Wir m√ºssen die Anzahl der falsch erkannten W√∂rter sorgf√§ltig als Kriterium verwenden.  Um dies zu veranschaulichen, werde ich Ihnen ein Beispiel mit den schlimmsten F√§llen geben.  5% der Fehler in W√∂rtern entsprechen einem fehlenden Wort von 20. Wenn jeder Satz 20 W√∂rter enth√§lt (was durchaus im Durchschnitt f√ºr Englisch liegt), n√§hert sich die Anzahl der falsch erkannten S√§tze 100%.  Man kann hoffen, dass falsch erkannte W√∂rter die semantische Bedeutung von S√§tzen nicht √§ndern.  Andernfalls kann der Erkenner jeden Satz falsch entschl√ºsseln, selbst wenn 5% der Anzahl der falsch erkannten W√∂rter vorhanden sind. <br><br>  Beim Vergleich von Modellen mit Personen ist es wichtig, das Wesen von Fehlern zu √ºberpr√ºfen und nicht nur die Anzahl falsch erkannter W√∂rter zu √ºberwachen.  Nach meiner Erfahrung machen Menschen, die Sprache in Text √ºbersetzen, weniger Fehler und sind nicht so ernst wie Computer. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Microsoft-Forscher haben k√ºrzlich die</a> Fehler von Personen und Computererkennern auf einem √§hnlichen Niveau <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verglichen</a> .  Einer der festgestellten Unterschiede besteht darin, dass das Modell "uh" [uh ...] viel h√§ufiger mit "uh huh" [aha] verwechselt als Menschen.  Diese beiden Begriffe haben eine sehr unterschiedliche Semantik: "uh" f√ºllt die Pausen aus, und "uh huh" bedeutet Best√§tigung durch den H√∂rer.  Au√üerdem fanden Modelle und Personen viele Fehler des gleichen Typs. <br><br><h2>  Viele Stimmen in einem Kanal </h2><br>  Das Erkennen aufgezeichneter Telefongespr√§che ist auch einfacher, da jeder Lautsprecher auf einem separaten Mikrofon aufgezeichnet wurde.  Es gibt keine √úberlappung mehrerer Stimmen in einem Audiokanal.  Menschen k√∂nnen mehrere Sprecher verstehen, manchmal gleichzeitig. <br><br>  Ein guter Spracherkenner sollte in der Lage sein, den Audiostream je nach Sprecher in Segmente zu unterteilen (vorbehaltlich seiner <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Diarisierung</a> ).  Er sollte auch die Audioaufnahme mit zwei √ºberlappenden Stimmen (Trennung der Quellen) verstehen.  Dies muss ohne ein Mikrofon erfolgen, das sich direkt an der M√ºndung jedes Lautsprechers befindet, dh damit der Erkenner an einer beliebigen Stelle gut funktioniert. <br><br><h2>  Aufnahmequalit√§t </h2><br>  Akzente und Hintergrundger√§usche sind nur zwei Faktoren, gegen die ein Spracherkenner resistent sein muss.  Hier noch ein paar mehr: <br><br>  ‚Ä¢ Hall unter verschiedenen akustischen Bedingungen. <br>  ‚Ä¢ Artefakte in Bezug auf Ausr√ºstung. <br>  ‚Ä¢ Artefakte des Codecs, mit dem das Signal aufgezeichnet und komprimiert wird. <br>  ‚Ä¢ Abtastrate. <br>  ‚Ä¢ Das Alter des Sprechers. <br><br>  Die meisten Menschen werden nicht durch Ohraufnahmen von MP3- und WAV-Dateien unterscheiden.  Vor der Erkl√§rung von Indikatoren, die mit denen des Menschen vergleichbar sind, sollten Erkenner gegen die aufgef√ºhrten Variationsquellen resistent werden. <br><br><h2>  Kontext </h2><br>  Sie k√∂nnen sehen, dass die Anzahl der Fehler, die Menschen bei Tests in Aufzeichnungen von der Telefonzentrale machen, ziemlich hoch ist.  Wenn Sie mit einem Freund sprechen w√ºrden, der 1 von 20 W√∂rtern nicht versteht, w√§re es f√ºr Sie sehr schwierig zu kommunizieren. <br><br>  Ein Grund daf√ºr ist die kontextlose Erkennung.  Im wirklichen Leben verwenden wir viele verschiedene zus√§tzliche Zeichen, um zu verstehen, was die andere Person sagt.  Einige Beispiele f√ºr den Kontext, der von Menschen verwendet und von Spracherkennern ignoriert wird: <br><br>  ‚Ä¢ Gespr√§chsverlauf und diskutiertes Thema. <br>  ‚Ä¢ Visuelle Hinweise zum Sprecher - Mimik, Lippenbewegungen. <br>  ‚Ä¢ Der Wissensbestand √ºber die Person, mit der wir sprechen. <br><br>  Jetzt verf√ºgt der Spracherkenner in Android √ºber eine Liste Ihrer Kontakte, sodass er <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Namen Ihrer Freunde erkennen kann</a> .  Die Sprachsuche auf Karten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verwendet die Geolokalisierung</a> , um die Anzahl der m√∂glichen Optionen einzugrenzen, zu denen Sie eine Route erstellen m√∂chten. <br><br>  Die Genauigkeit von Erkennungssystemen nimmt mit der Aufnahme solcher Signale in die Daten zu.  Wir fangen jedoch gerade erst an, uns mit der Art des Kontexts zu befassen, den wir in die Verarbeitung und in die Methoden seiner Verwendung einbeziehen k√∂nnten. <br><br><h2>  Bereitstellung </h2><br>  Die neuesten Fortschritte bei der Spracherkennung k√∂nnen nicht eingesetzt werden.  Wenn Sie sich den Einsatz eines Spracherkennungsalgorithmus vorstellen, m√ºssen Sie sich an Verz√∂gerungen und Rechenleistung erinnern.  Diese Parameter h√§ngen zusammen, da Algorithmen, die den Strombedarf erh√∂hen, auch die Latenz erh√∂hen.  Der Einfachheit halber werden wir sie jedoch separat diskutieren. <br><br>  Verz√∂gerung: Die Zeit vom Ende der Rede des Benutzers bis zum Ende des Empfangs der Transkription.  Eine leichte Verz√∂gerung ist eine typische Erkennungsanforderung.  Dies hat erhebliche Auswirkungen auf die Benutzererfahrung mit dem Produkt.  Oft gibt es eine Grenze von zehn Millisekunden.  Dies mag zu streng erscheinen, aber denken Sie daran, dass die Ausgabe der Entschl√ºsselung normalerweise der erste Schritt in einer Reihe komplexer Berechnungen ist.  Beispielsweise m√ºssen Sie bei der Sprachsuche im Internet nach der Spracherkennung noch eine Suche durchf√ºhren. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bidirektionale Wiederholungsschichten</a> sind ein typisches Beispiel f√ºr eine Verbesserung, die die Verz√∂gerungssituation verschlechtert.  Mit ihrer Hilfe werden die neuesten hochwertigen Entschl√ºsselungsergebnisse erzielt.  Das einzige Problem ist, dass wir nach dem Passieren der ersten bidirektionalen Ebene nichts z√§hlen k√∂nnen, bis die Person mit dem Sprechen fertig ist.  Daher nimmt die Verz√∂gerung mit der L√§nge des Satzes zu. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/geektimes/post_images/fe9/dfd/ab2/fe9dfdab2e62e5265f9cbe0cd8c854b1.svg"></div><br>  <i>Links: Durch die direkte Wiederholung kann die Entschl√ºsselung sofort beginnen.</i>  <i>Rechts: Bei einer bidirektionalen Wiederholung muss vor dem Decodieren gewartet werden, bis die Sprache beendet ist.</i> <br><br>  Es wird immer noch nach einem guten Weg gesucht, um zuk√ºnftige Informationen effektiv in die Spracherkennung einzubeziehen. <br><br>  Rechenleistung: Diese Option wird durch wirtschaftliche Einschr√§nkungen beeinflusst.  Die Kosten des Banketts m√ºssen bei jeder Verbesserung der Genauigkeit des Erkenners ber√ºcksichtigt werden.  Wenn die Verbesserung die wirtschaftliche Schwelle nicht erreicht, wird sie nicht funktionieren. <br><br>  Ein klassisches Beispiel f√ºr eine kontinuierliche Verbesserung, die sie niemals einsetzen, ist das kollaborative Deep Learning [Ensemble].  Eine Reduzierung der Fehleranzahl um 1-2% rechtfertigt selten eine 2-8-fache Steigerung der Rechenleistung.  Moderne Modelle wiederkehrender Netzwerke fallen ebenfalls in diese Kategorie, da es sehr nachteilig ist, sie bei der Suche nach einer Reihe von Trajektorien zu verwenden, obwohl sich die Situation meiner Meinung nach in Zukunft √§ndern wird. <br><br>  Ich m√∂chte klarstellen - ich sage nicht, dass eine Verbesserung der Erkennungsgenauigkeit bei einem ernsthaften Anstieg der Rechenkosten nutzlos ist.  Wir haben bereits gesehen, wie in der Vergangenheit das Prinzip "zuerst langsam, aber genau und dann schnell" funktioniert.  Der Punkt ist, dass Sie es nicht verwenden k√∂nnen, bis die Verbesserung schnell genug ist. <br><br><h2>  In den n√§chsten f√ºnf Jahren </h2><br>  Auf dem Gebiet der Spracherkennung gibt es immer noch viele ungel√∂ste und komplexe Probleme.  Unter ihnen: <br><br>  ‚Ä¢ Erweiterung der Funktionen neuer Speichersysteme, Hervorhebungserkennung und Sprache vor dem Hintergrund lauter Ger√§usche. <br>  ‚Ä¢ Einbeziehung des Kontexts in den Erkennungsprozess. <br>  ‚Ä¢ Diarisierung und Trennung von Quellen. <br>  ‚Ä¢ Anzahl der semantischen Fehler und innovativen Methoden zur Bewertung von Erkennern. <br>  ‚Ä¢ Sehr geringe Latenz. <br><br>  Ich freue mich auf die Fortschritte, die in den n√§chsten f√ºnf Jahren an diesen und anderen Fronten erzielt werden. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de408017/">https://habr.com/ru/post/de408017/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de408001/index.html">Und wieder w√§chst Bitcoin. Aber warum?</a></li>
<li><a href="../de408003/index.html">Flightradar24 - wie geht das?</a></li>
<li><a href="../de408005/index.html">Wie gehen wir mit dem Aussterben der Natur um?</a></li>
<li><a href="../de408011/index.html">Video√ºberpr√ºfung des 3D-Druckers UP! Mini 2</a></li>
<li><a href="../de408015/index.html">Reflexionen √ºber Token (√úbersetzung)</a></li>
<li><a href="../de408019/index.html">Interessante Merkmale des BMW 7er</a></li>
<li><a href="../de408023/index.html">Raise3D: Die Verwendung von 3D-Druckern im Film</a></li>
<li><a href="../de408025/index.html">√úbertragung "Wunder der Technologie" √ºber Leser: Wir empfehlen, zu sehen. Und Schlussfolgerungen ziehen</a></li>
<li><a href="../de408027/index.html">Ein Geschenk von Geek - einen K√ºchentimer machen</a></li>
<li><a href="../de408029/index.html">Apple gewinnt schlie√ülich eine Klage in H√∂he von 120 Millionen US-Dollar gegen Samsung wegen Patentverletzung bei Slide-to-Unlock</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
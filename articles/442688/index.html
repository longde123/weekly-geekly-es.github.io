<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèΩ üë®üèª‚Äçüåæ üíê An√°lisis de datos Scala: ¬øuna necesidad urgente o una oportunidad agradable? üë®‚Äçüëß‚Äçüë¶ üë®üèº‚Äç‚úàÔ∏è ‚ò¢Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Las herramientas tradicionales en el campo de la ciencia de datos son lenguajes como R y Python : la sintaxis relajada y una gran cantidad de bibliote...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>An√°lisis de datos Scala: ¬øuna necesidad urgente o una oportunidad agradable?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/442688/"><p><img src="https://habrastorage.org/webt/5q/1e/fr/5q1efrbkxbuk_ndqoensinfl80a.jpeg"></p><br><p>  Las herramientas tradicionales en el campo de la ciencia de datos son lenguajes como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">R</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Python</a> : la sintaxis relajada y una gran cantidad de bibliotecas para el aprendizaje autom√°tico y el procesamiento de datos le permiten obtener r√°pidamente algunas soluciones de trabajo.  Sin embargo, hay situaciones en las que las limitaciones de estas herramientas se convierten en un obst√°culo importante, en primer lugar, si necesita lograr un alto rendimiento en t√©rminos de velocidad de procesamiento y / o trabajar con conjuntos de datos realmente grandes.  En este caso, el especialista tiene que recurrir a rega√±adientes a la ayuda del "lado oscuro" y conectar las herramientas en los lenguajes de programaci√≥n "industrial": <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Scala</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Java</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C ++</a> . </p><br><p> ¬øPero es este lado tan oscuro?  A lo largo de los a√±os de desarrollo, las herramientas de la ciencia de datos "industrial" han recorrido un largo camino y hoy son muy diferentes de sus propias versiones hace 2-3 a√±os.  Intentemos usar el ejemplo de la tarea <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SNA Hackathon 2019</a> para calcular cu√°nto puede corresponder el ecosistema Scala + Spark con Python Data Science. </p><a name="habracut"></a><br><p>  En el marco de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SNA Hackathon 2019, los</a> participantes resuelven el problema de clasificar la fuente de noticias de un usuario de una red social en una de tres "disciplinas": usar datos de textos, im√°genes o registros de funciones.  En esta publicaci√≥n, veremos c√≥mo en Spark es posible resolver un problema sobre la base de un registro de signos utilizando herramientas cl√°sicas de aprendizaje autom√°tico. </p><br><p>  Al resolver el problema, seguiremos el camino est√°ndar que cualquier especialista en an√°lisis de datos sigue al desarrollar un modelo: </p><br><ul><li>  Realizaremos an√°lisis de datos de investigaci√≥n, construiremos gr√°ficos. </li><li>  Analizamos las propiedades estad√≠sticas de los signos en los datos, observamos sus diferencias entre los conjuntos de entrenamiento y prueba. </li><li>  Realizaremos una selecci√≥n inicial de caracter√≠sticas basadas en propiedades estad√≠sticas. </li><li>  Calculamos las correlaciones entre los signos y la variable objetivo, as√≠ como la correlaci√≥n cruzada entre los signos. </li><li>  Formaremos el conjunto final de caracter√≠sticas, entrenaremos al modelo y verificaremos su calidad. </li><li>  Analicemos la estructura interna del modelo para identificar puntos de crecimiento. </li></ul><br><p>  Durante nuestro "viaje" nos familiarizaremos con herramientas como el cuaderno interactivo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Zeppelin</a> , la biblioteca de aprendizaje autom√°tico <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Spark ML</a> y su extensi√≥n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PravdaML</a> , el paquete de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">gr√°ficos</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GraphX</a> , la biblioteca de visualizaci√≥n de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Vegas</a> y, por supuesto, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Spark</a> en todo su esplendor: )  Todos los resultados del c√≥digo y del experimento est√°n disponibles en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">plataforma de</a> cuaderno colaborativo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Zepl</a> . </p><br><h1 id="zagruzka-dannyh">  Carga de datos </h1><br><p>  La peculiaridad de los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">datos</a> presentados en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SNA Hackathon 2019</a> es que es posible procesarlos directamente usando Python, pero es dif√≠cil: los datos originales se empaquetan de manera bastante eficiente gracias a las capacidades del formato de columna Apache Parquet y cuando se lee en la memoria "por la frente" se descomprime en varias decenas de gigabytes.  Cuando se trabaja con Apache Spark, no hay necesidad de cargar completamente los datos en la memoria, la arquitectura Spark est√° dise√±ada para procesar datos en partes, cargando desde el disco seg√∫n sea necesario. </p><br><p>  Por lo tanto, el primer paso, verificar la distribuci√≥n de datos por d√≠a, se realiza f√°cilmente mediante herramientas en caja: </p><br><pre><code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> train = sqlContext.read.parquet(<span class="hljs-string"><span class="hljs-string">"/events/hackatons/SNAHackathon/2019/collabTrain"</span></span>) z.show(train.groupBy($<span class="hljs-string"><span class="hljs-string">"date"</span></span>).agg( functions.count($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>).as(<span class="hljs-string"><span class="hljs-string">"count"</span></span>), functions.countDistinct($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>).as(<span class="hljs-string"><span class="hljs-string">"users"</span></span>), functions.countDistinct($<span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>).as(<span class="hljs-string"><span class="hljs-string">"objects"</span></span>), functions.countDistinct($<span class="hljs-string"><span class="hljs-string">"metadata_ownerId"</span></span>).as(<span class="hljs-string"><span class="hljs-string">"owners"</span></span>)) .orderBy(<span class="hljs-string"><span class="hljs-string">"date"</span></span>))</code> </pre> <br><p>  Lo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">que</a> mostrar√° el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">gr√°fico</a> correspondiente en Zeppelin: </p><br><p><img src="https://habrastorage.org/webt/jp/lh/pw/jplhpwwz4tfgdtrs1u_u-tqsvzi.png"></p><br><p>  Debo decir que la sintaxis de Scala es bastante flexible, y el mismo c√≥digo puede verse, por ejemplo, as√≠: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> train = sqlContext.read.parquet(<span class="hljs-string"><span class="hljs-string">"/events/hackatons/SNAHackathon/2019/collabTrain"</span></span>) z.show( train groupBy $<span class="hljs-string"><span class="hljs-string">"date"</span></span> agg( count($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>) as <span class="hljs-string"><span class="hljs-string">"count"</span></span>, countDistinct($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>) as <span class="hljs-string"><span class="hljs-string">"users"</span></span>, countDistinct($<span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>) as <span class="hljs-string"><span class="hljs-string">"objects"</span></span>, countDistinct($<span class="hljs-string"><span class="hljs-string">"metadata_ownerId"</span></span>) as <span class="hljs-string"><span class="hljs-string">"owners"</span></span>) orderBy <span class="hljs-string"><span class="hljs-string">"date"</span></span> )</code> </pre> <br><p>  Aqu√≠ debe hacerse una advertencia importante: cuando se trabaja en un equipo grande, donde todos se acercan a escribir el c√≥digo Scala exclusivamente desde el punto de vista de su propio gusto, la comunicaci√≥n es mucho m√°s dif√≠cil.  Por lo tanto, es mejor desarrollar un concepto unificado de estilo de c√≥digo. </p><br><p>  Pero volvamos a nuestra tarea.  Un an√°lisis simple por d√≠a mostr√≥ la presencia de puntos anormales el 17 y 18 de febrero;  Probablemente en estos d√≠as se han recopilado datos incompletos y la distribuci√≥n de los rasgos puede estar sesgada.  Esto debe tenerse en cuenta en un an√°lisis posterior.  Adem√°s, es sorprendente que el n√∫mero de usuarios √∫nicos sea muy cercano al n√∫mero de objetos, por lo que tiene sentido estudiar la distribuci√≥n de usuarios con diferentes n√∫meros de objetos: </p><br><pre> <code class="scala hljs">z.show(filteredTrain .groupBy($<span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>).count .groupBy(<span class="hljs-string"><span class="hljs-string">"count"</span></span>).agg(functions.log(functions.count(<span class="hljs-string"><span class="hljs-string">"count"</span></span>)).as(<span class="hljs-string"><span class="hljs-string">"withCount"</span></span>)) .orderBy($<span class="hljs-string"><span class="hljs-string">"withCount"</span></span>.desc) .limit(<span class="hljs-number"><span class="hljs-number">100</span></span>) .orderBy($<span class="hljs-string"><span class="hljs-string">"count"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/dh/i-/pp/dhi-ppdka19zurhimccpq7tij5w.png"></p><br><p>  Se espera ver una distribuci√≥n cercana a exponencial, con una cola muy larga.  En tales tareas, por regla general, es posible lograr una mejora en la calidad del trabajo segmentando modelos para usuarios con diferentes niveles de actividad.  Para verificar si vale la pena hacer esto, compare la distribuci√≥n del n√∫mero de objetos por usuario en el conjunto de prueba: </p><br><p><img src="https://habrastorage.org/webt/du/sy/xt/dusyxten5shm24an736n7akolnm.png"></p><br><p>  La comparaci√≥n con la prueba muestra que los usuarios de la prueba tienen al menos dos objetos en los registros (dado que el problema de clasificaci√≥n se resuelve en el hackathon, esta es una condici√≥n necesaria para evaluar la calidad).  En el futuro, recomiendo mirar m√°s de cerca a los usuarios en el conjunto de entrenamiento, para lo cual declaramos la Funci√≥n definida por el usuario con un filtro: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//  ,     "",   , //     val testSimilar = sc.broadcast(filteredTrain.groupBy($"instanceId_userId") .agg( functions.count("feedback").as("count"), functions.sum(functions.expr("IF(array_contains(feedback, 'Liked'), 1.0, 0.0)")).as("sum") ) .where("count &gt; sum AND sum &gt; 0") .select("instanceId_userId").rdd.map(_.getInt(0)).collect.sorted) //           // User Defined Function val isTestSimilar = sqlContext.udf.register("isTestSimilar", (x: Int) =&gt; java.util.Arrays.binarySearch(testSimilar.value, x) &gt;= 0)</span></span></code> </pre> <br><p>  Tambi√©n deber√≠a hacerse una observaci√≥n importante: es desde el punto de vista de la definici√≥n de UDF que el uso de Spark desde debajo de Scala / Java y desde debajo de Python es notablemente diferente.  Si bien el c√≥digo PySpark utiliza la funcionalidad b√°sica, todo funciona casi tan r√°pido, pero cuando aparecen funciones anuladas, el rendimiento de PySpark se degrada en un orden de magnitud. </p><br><h1 id="pervyy-ml-konveyer">  La primera tuber√≠a de ML </h1><br><p>  En el siguiente paso, intentaremos calcular las estad√≠sticas b√°sicas sobre acciones y atributos.  Pero para esto necesitamos las capacidades de SparkML, as√≠ que primero veremos su arquitectura general: </p><br><p><img src="https://habrastorage.org/webt/j7/ev/en/j7evenhyzzfvzouqfkbfq1j9hvu.png"></p><br><p>  SparkML se basa en los siguientes conceptos: </p><br><ul><li>  Transformador: toma un conjunto de datos como entrada y devuelve un conjunto modificado (transformaci√≥n).  Como regla general, se utiliza para implementar algoritmos de preprocesamiento y posprocesamiento, extracci√≥n de caracter√≠sticas y tambi√©n puede representar los modelos ML resultantes. </li><li>  Estimador: toma un conjunto de datos como entrada y devuelve Transformador (ajuste).  Naturalmente, Estimator puede representar el algoritmo ML. </li><li>  Pipeline es un caso especial de Estimator, que consiste en una cadena de transformadores y estimadores.  Cuando se llama al m√©todo, el ajuste pasa a trav√©s de la cadena, y si ve un transformador, lo aplica a los datos, y si ve un estimador, entrena el transformador con √©l, lo aplica a los datos y va m√°s all√°. </li><li>  PipelineModel: el resultado de Pipeline tambi√©n contiene una cadena en su interior, pero que consiste exclusivamente en transformadores.  En consecuencia, PipelineModel es tambi√©n un transformador. </li></ul><br><p>  Tal enfoque para la formaci√≥n de algoritmos ML ayuda a lograr una estructura modular clara y una buena reproducibilidad: tanto los modelos como las tuber√≠as se pueden guardar. </p><br><p>  Para comenzar, construiremos una tuber√≠a simple con la que calcularemos las estad√≠sticas de la distribuci√≥n de acciones (campo de comentarios) de los usuarios en el conjunto de capacitaci√≥n: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> feedbackAggregator = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-comment"><span class="hljs-comment">//         (feedback)  one-hot  new MultinominalExtractor().setInputCol("feedback").setOutputCol("feedback"), //       new VectorStatCollector() .setGroupByColumns("date").setInputCol("feedback") .setPercentiles(Array(0.1,0.5,0.9)), //        new VectorExplode().setValueCol("feedback") )).fit(train) z.show(feedbackAggregator .transform(filteredTrain) .orderBy($"date", $"feedback"))</span></span></code> </pre> <br><p>  En esta tuber√≠a, la funcionalidad de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PravdaML</a> se usa activamente: bibliotecas con bloques √∫tiles extendidos para SparkML, a saber: </p><br><ul><li>  MultinominalExtractor se utiliza para codificar un car√°cter de tipo "matriz de cadenas" en un vector de acuerdo con el principio de hot-one.  Este es el √∫nico estimador en la tuber√≠a (para construir una codificaci√≥n, debe recopilar l√≠neas √∫nicas del conjunto de datos). </li><li>  VectorStatCollector se utiliza para calcular estad√≠sticas vectoriales. </li><li>  VectorExplode se utiliza para convertir el resultado a un formato conveniente para la visualizaci√≥n. </li></ul><br><p>  El resultado del trabajo ser√° un gr√°fico que muestra que las clases en el conjunto de datos no est√°n equilibradas, sin embargo, el desequilibrio para la clase de Me gusta de destino no es extremo: </p><br><p><img src="https://habrastorage.org/webt/aa/db/x4/aadbx4el5s5lhuyput_cj4ns9zo.png"></p><br><p>  El an√°lisis de una distribuci√≥n similar entre usuarios similares a los de prueba (que tienen tanto "positivo" como "negativo" en los registros) muestra que est√° sesgado hacia la clase positiva: </p><br><p><img src="https://habrastorage.org/webt/x5/lu/px/x5lupxmayvvodo7lsb3meob1dou.png"></p><br><h1 id="statisticheskiy-analiz-priznakov">  An√°lisis estad√≠stico de signos. </h1><br><p>  En la siguiente etapa, realizaremos un an√°lisis detallado de las propiedades estad√≠sticas de los atributos.  Esta vez necesitamos un transportador m√°s grande: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> statsAggregator = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">NullToDefaultReplacer</span></span>(), <span class="hljs-comment"><span class="hljs-comment">//          new AutoAssembler() .setColumnsToExclude( (Seq("date", "feedback") ++ train.schema.fieldNames.filter(_.endsWith("Id")) : _*)) .setOutputCol("features"), new VectorStatCollector() .setGroupByColumns("date").setInputCol("features") .setPercentiles(Array(0.1,0.5,0.9)), new VectorExplode().setValueCol("features") ))</span></span></code> </pre> <br><p>  Como ahora necesitamos trabajar no con un campo separado, sino con todos los atributos a la vez, utilizaremos dos utilidades <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PravdaML</a> m√°s √∫tiles: </p><br><ul><li>  NullToDefaultReplacer le permite reemplazar elementos faltantes en los datos con sus valores predeterminados (0 para n√∫meros, falso para variables l√≥gicas, etc.).  Si no realiza esta conversi√≥n, aparecer√°n valores de NaN en los vectores resultantes, lo cual es fatal para muchos algoritmos (aunque, por ejemplo, XGBoost puede sobrevivir a esto).  Una alternativa para reemplazar con ceros puede ser reemplazar con promedios, esto se implementa en NaNToMeanReplacerEstimator. </li><li>  AutoAssembler es una utilidad muy poderosa que analiza el dise√±o de la tabla y para cada columna selecciona un esquema de vectorizaci√≥n que coincide con el tipo de columna. </li></ul><br><p>  Usando la tuber√≠a resultante, calculamos las estad√≠sticas para tres conjuntos (entrenamiento, entrenamiento con filtro de usuario y prueba) y los guardamos en archivos separados: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//   (   AutoAssembler  ) val trained = statsAggregator.fit(filteredTrain) //       - ,     . trained .transform(filteredTrain .withColumn("date", //  ,      ,     , //        All   functions.explode(functions.array(functions.lit("All"), $"date")))) .coalesce(7).write.mode("overwrite").parquet("sna2019/featuresStat") trained .transform(filteredTrain .where(isTestSimilar($"instanceId_userId")) .withColumn("date", functions.explode(functions.array(functions.lit("All"), $"date")))) .coalesce(7).write.mode("overwrite").parquet("sna2019/filteredFeaturesStat") trained .transform(filteredTest.withColumn("date", functions.explode(functions.array(functions.lit("All"), $"date")))) .coalesce(3).write.mode("overwrite").parquet("sna2019/testFeaturesStat")</span></span></code> </pre> <br><p>  Habiendo recibido tres conjuntos de datos con estad√≠sticas de atributos, analizamos las siguientes cosas: </p><br><ul><li>  ¬øTenemos se√±ales de que hay grandes emisiones? <br>  - Tales signos deben ser limitados, o los registros at√≠picos deben ser filtrados. </li><li>  ¬øTenemos signos con un gran sesgo de la media en relaci√≥n con la mediana. <br>  - Tal cambio a menudo ocurre en presencia de una distribuci√≥n de potencia, tiene sentido logaritmar estos signos. </li><li>  ¬øHay un cambio en las distribuciones promedio entre los conjuntos de entrenamiento y prueba? </li><li>  Cu√°n apretada nuestra matriz de caracter√≠sticas. </li></ul><br><p>  Para aclarar estos aspectos, dicha solicitud nos ayudar√° a: </p><br><pre> <code class="scala hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">compareWithTest</span></span></span></span>(data: <span class="hljs-type"><span class="hljs-type">DataFrame</span></span>) : <span class="hljs-type"><span class="hljs-type">DataFrame</span></span> = { data.where(<span class="hljs-string"><span class="hljs-string">"date = 'All'"</span></span>) .select( $<span class="hljs-string"><span class="hljs-string">"features"</span></span>, <span class="hljs-comment"><span class="hljs-comment">//         // ( ) functions.log($"features_mean" / $"features_p50").as("skewenes"), //    90-      //    90-  ‚Äî    functions.log( ($"features_max" - $"features_p90") / ($"features_p90" - $"features_p50")).as("outlieres"), //       ,  //    ($"features_nonZeros" / $"features_count").as("train_fill"), $"features_mean".as("train_mean")) .join(testStat.where("date = 'All'") .select($"features", $"features_mean".as("test_mean"), ($"features_nonZeros" / $"features_count").as("test_fill")), Seq("features")) //          .withColumn("meanDrift", (($"train_mean" - $"test_mean" ) / ($"train_mean" + $"test_mean"))) //      .withColumn("fillDrift", ($"train_fill" - $"test_fill") / ($"train_fill" + $"test_fill")) } //         val comparison = compareWithTest(trainStat).withColumn("mode", functions.lit("raw")) .unionByName(compareWithTest(filteredStat).withColumn("mode", functions.lit("filtered")))</span></span></code> </pre> <br><p>  En esta etapa, surge la pregunta de visualizaci√≥n: es dif√≠cil mostrar de inmediato todos los aspectos utilizando herramientas regulares de Zeppelin, y los cuadernos con una gran cantidad de gr√°ficos comienzan a disminuir notablemente debido al DOM hinchado.  Las <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Vegas</a> : la biblioteca DSL en Scala para construir especificaciones <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">vega-lite</a> puede resolver este problema.  Vegas no solo proporciona capacidades de visualizaci√≥n m√°s ricas (comparables a matplotlib), sino que tambi√©n las dibuja en Canvas sin inflar el DOM :). </p><br><p>  La especificaci√≥n de la tabla que nos interesa se ver√° as√≠: </p><br><pre> <code class="scala hljs">vegas.<span class="hljs-type"><span class="hljs-type">Vegas</span></span>(width = <span class="hljs-number"><span class="hljs-number">1024</span></span>, height = <span class="hljs-number"><span class="hljs-number">648</span></span>) <span class="hljs-comment"><span class="hljs-comment">//   .withDataFrame(comparison.na.fill(0.0)) //           .encodeX("meanDrift", Quant, scale = Scale(domainValues = List(-1.0, 1.0), clamp = true)) //   -       .encodeY("train_fill", Quant) //       .encodeColor("outlieres", Quant, scale=Scale( rangeNominals=List("#00FF00", "#FF0000"), domainValues = List(0.0, 5), clamp = true)) //       .encodeSize("skewenes", Quant) //   -   (   ) .encodeShape("mode", Nom) .mark(vegas.Point) .show</span></span></code> </pre> <br><p>  El cuadro a continuaci√≥n deber√≠a leer as√≠: </p><br><ul><li>  El eje X muestra el desplazamiento de los centros de distribuci√≥n entre los conjuntos de prueba y entrenamiento (cuanto m√°s cerca de 0, m√°s estable es el signo). </li><li>  El porcentaje de elementos distintos de cero se traza a lo largo del eje Y (cuanto m√°s alto, m√°s datos hay para el mayor n√∫mero de puntos por atributo). </li><li>  El tama√±o muestra el desplazamiento del promedio en relaci√≥n con la mediana (cuanto mayor es el punto, m√°s probable es la distribuci√≥n de la ley de potencia para √©l). </li><li>  El color indica emisiones (cuanto m√°s rojo, m√°s emisiones). </li><li>  Bueno, la forma se distingue por un modo de comparaci√≥n: con un filtro de usuario en el conjunto de entrenamiento o sin filtro. </li></ul><br><p><img src="https://habrastorage.org/webt/op/hb/6g/ophb6gi3wa_uvsld9rre6ujzquu.png"></p><br><p>  Entonces, podemos sacar las siguientes conclusiones: </p><br><ul><li>  Algunas se√±ales necesitan un filtro de emisi√≥n: limitaremos los valores m√°ximos para el percentil 90. </li><li>  Algunos signos muestran una distribuci√≥n cercana a la exponencial: tomaremos el logaritmo. </li><li>  Algunas caracter√≠sticas no se presentan en la prueba; las excluiremos de la capacitaci√≥n. </li></ul><br><h1 id="korrelyacionnyy-analiz">  An√°lisis de correlaci√≥n </h1><br><p>  Despu√©s de tener una idea general de c√≥mo se distribuyen los atributos y c√≥mo se relacionan entre los conjuntos de entrenamiento y prueba, intentemos analizar las correlaciones.  Para hacer esto, configure el extractor de caracter√≠sticas basado en observaciones anteriores: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//             val expressions = filteredTrain.schema.fieldNames //          .filterNot(x =&gt; x == "date" || x == "audit_experiment" || idsColumns(x) || x.contains("vd_")) .map(x =&gt; if(skewedFeautres(x)) { //      s"log($x) AS $x" } else { //     cappedFeatures.get(x).map(capping =&gt; s"IF($x &lt; $capping, $x, $capping) AS $x").getOrElse(x) }) val rawFeaturesExtractor = new Pipeline().setStages(Array( new SQLTransformer().setStatement(s"SELECT ${expressions.mkString(", ")} FROM __THIS__"), new NullToDefaultReplacer(), new AutoAssembler().setOutputCol("features") )) //       val raw = rawFeaturesExtractor.fit(filteredTrain).transform( filteredTrain.where(isTestSimilar($"instanceId_userId")))</span></span></code> </pre> <br><p>  De la nueva maquinaria en esta tuber√≠a, la utilidad SQLTransformer llama la atenci√≥n, lo que permite transformaciones arbitrarias de SQL de la tabla de entrada. </p><br><p>  Cuando se analizan las correlaciones, es importante filtrar el ruido creado por la correlaci√≥n natural de las caracter√≠sticas √∫nicas.  Para hacer esto, me gustar√≠a entender qu√© elementos del vector corresponden a qu√© columnas de origen.  Esta tarea en Spark se realiza utilizando metadatos de columna (almacenados con datos) y grupos de atributos.  El siguiente bloque de c√≥digo se usa para filtrar pares de nombres de atributos que provienen de la misma columna de tipo String: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> attributes = <span class="hljs-type"><span class="hljs-type">AttributeGroup</span></span>.fromStructField(raw.schema(<span class="hljs-string"><span class="hljs-string">"features"</span></span>)).attributes.get <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> originMap = filteredTrain .schema.filter(_.dataType == <span class="hljs-type"><span class="hljs-type">StringType</span></span>) .flatMap(x =&gt; attributes.map(_.name.get).filter(_.startsWith(x.name + <span class="hljs-string"><span class="hljs-string">"_"</span></span>)).map(_ -&gt; x.name)) .toMap <span class="hljs-comment"><span class="hljs-comment">//   ,          val isNonTrivialCorrelation = sqlContext.udf.register("isNonTrivialCorrelation", (x: String, y : String) =&gt; //    Scala-quiz   Option originMap.get(x).map(_ != originMap.getOrElse(y, "")).getOrElse(true))</span></span></code> </pre> <br><p>  Tener a mano un conjunto de datos con una columna vectorial, calcular las correlaciones cruzadas usando Spark es bastante simple, pero el resultado es una matriz, para la implementaci√≥n de la cual tendr√°s que jugar un poco en un conjunto de pares: </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> pearsonCorrelation = <span class="hljs-comment"><span class="hljs-comment">//    Pearson  Spearman Correlation.corr(raw, "features", "pearson").rdd.flatMap( //           _.getAs[Matrix](0).rowIter.zipWithIndex.flatMap(x =&gt; { //   ,   (  , //  ) val name = attributes(x._2).name.get //    ,     x._1.toArray.zip(attributes).map(y =&gt; (name, y._2.name.get, y._1)) } //     DataFrame )).toDF("feature1", "feature2", "corr") .na.drop //   .where(isNonTrivialCorrelation($"feature1", $"feature2")) //    . pearsonCorrelation.coalesce(1).write.mode("overwrite") .parquet("sna2019/pearsonCorrelation")</span></span></code> </pre> <br><p>  Y, por supuesto, visualizaci√≥n: necesitaremos nuevamente la ayuda de Vegas para dibujar un mapa de calor: </p><br><pre> <code class="scala hljs">vegas.<span class="hljs-type"><span class="hljs-type">Vegas</span></span>(<span class="hljs-string"><span class="hljs-string">"Pearson correlation heatmap"</span></span>) .withDataFrame(pearsonCorrelation .withColumn(<span class="hljs-string"><span class="hljs-string">"isPositive"</span></span>, $<span class="hljs-string"><span class="hljs-string">"corr"</span></span> &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) .withColumn(<span class="hljs-string"><span class="hljs-string">"abs_corr"</span></span>, functions.abs($<span class="hljs-string"><span class="hljs-string">"corr"</span></span>)) .where(<span class="hljs-string"><span class="hljs-string">"feature1 &lt; feature2 AND abs_corr &gt; 0.05"</span></span>) .orderBy(<span class="hljs-string"><span class="hljs-string">"feature1"</span></span>, <span class="hljs-string"><span class="hljs-string">"feature2"</span></span>)) .encodeX(<span class="hljs-string"><span class="hljs-string">"feature1"</span></span>, <span class="hljs-type"><span class="hljs-type">Nom</span></span>) .encodeY(<span class="hljs-string"><span class="hljs-string">"feature2"</span></span>, <span class="hljs-type"><span class="hljs-type">Nom</span></span>) .encodeColor(<span class="hljs-string"><span class="hljs-string">"abs_corr"</span></span>, <span class="hljs-type"><span class="hljs-type">Quant</span></span>, scale=<span class="hljs-type"><span class="hljs-type">Scale</span></span>(rangeNominals=<span class="hljs-type"><span class="hljs-type">List</span></span>(<span class="hljs-string"><span class="hljs-string">"#FFFFFF"</span></span>, <span class="hljs-string"><span class="hljs-string">"#FF0000"</span></span>))) .encodeShape(<span class="hljs-string"><span class="hljs-string">"isPositive"</span></span>, <span class="hljs-type"><span class="hljs-type">Nom</span></span>) .mark(vegas.<span class="hljs-type"><span class="hljs-type">Point</span></span>) .show</code> </pre> <br><p>  El resultado es mejor mirar en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Zepl-e</a> .  Para una comprensi√≥n general: </p><br><p><img src="https://habrastorage.org/webt/nm/d9/bm/nmd9bmrion4goaov9_vgx5vbjoy.png"></p><br><p>  El mapa de calor muestra que algunas correlaciones est√°n claramente all√≠.  Intentemos seleccionar los bloques de las caracter√≠sticas m√°s fuertemente correlacionadas, para esto usamos la biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GraphX</a> : convertimos la matriz de correlaci√≥n en un gr√°fico, filtramos los bordes por peso, despu√©s de lo cual encontramos los componentes conectados y dejamos solo los no degenerados (de m√°s de un elemento).  Tal procedimiento es esencialmente similar a la aplicaci√≥n del algoritmo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">DBSCAN</a> y es el siguiente: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//   (GrpahX   ID) val featureIndexMap = spearmanCorrelation.select("feature1").distinct.rdd.map( _.getString(0)).collect.zipWithIndex.toMap val featureIndex = sqlContext.udf.register("featureIndex", (x: String) =&gt; featureIndexMap(x)) //    val vertices = sc.parallelize(featureIndexMap.map(x =&gt; x._2.toLong -&gt; x._1).toSeq, 1) //    val edges = spearmanCorrelation.select(featureIndex($"feature1"), featureIndex($"feature2"), $"corr") //     .where("ABS(corr) &gt; 0.7") .rdd.map(r =&gt; Edge(r.getInt(0), r.getInt(1), r.getDouble(2))) //       val components = Graph(vertices, edges).connectedComponents() val reversedMap = featureIndexMap.map(_.swap) //    ,    ,   //   val clusters = components .vertices.map(x =&gt; reversedMap(x._2.toInt) -&gt; reversedMap(x._1.toInt)) .groupByKey().map(x =&gt; x._2.toSeq) .filter(_.size &gt; 1) .sortBy(-_.size) .collect</span></span></code> </pre> <br><p>  El resultado se presenta en forma de tabla: </p><br><p><img src="https://habrastorage.org/webt/4b/t2/bl/4bt2blcjzmxbzucnm7zynpvpj-q.png"></p><br><p>  Con base en los resultados de la agrupaci√≥n, podemos concluir que los grupos m√°s correlacionados se formaron alrededor de los signos asociados con la membres√≠a del usuario en el grupo (member_status_A), as√≠ como alrededor del tipo de objeto (instanceId_objectType).  Para el mejor modelado de la interacci√≥n de los signos, tiene sentido aplicar la segmentaci√≥n del modelo, para entrenar diferentes modelos para diferentes tipos de objetos, por separado para grupos en los que el usuario es y no es. </p><br><h1 id="mashinnoe-obuchenie">  Aprendizaje autom√°tico </h1><br><p>  Nos acercamos a lo m√°s interesante: el aprendizaje autom√°tico.  La tuber√≠a para entrenar el modelo m√°s simple (regresi√≥n log√≠stica) usando extensiones SparkML y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PravdaML</a> es la siguiente: </p><br><pre> <code class="scala hljs"> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">SQLTransformer</span></span>().setStatement( <span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">"SELECT *, IF(array_contains(feedback, 'Liked'), 1.0, 0.0) AS label FROM __THIS__"</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">NullToDefaultReplacer</span></span>(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">AutoAssembler</span></span>() .setColumnsToExclude(<span class="hljs-string"><span class="hljs-string">"date"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>, <span class="hljs-string"><span class="hljs-string">"feedback"</span></span>, <span class="hljs-string"><span class="hljs-string">"label"</span></span>) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"features"</span></span>), <span class="hljs-type"><span class="hljs-type">Scaler</span></span>.scale(<span class="hljs-type"><span class="hljs-type">Interceptor</span></span>.intercept(<span class="hljs-type"><span class="hljs-type">UnwrappedStage</span></span>.repartition( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">LogisticRegressionLBFSG</span></span>(), numPartitions = <span class="hljs-number"><span class="hljs-number">127</span></span>)))</code> </pre> <br><p>  Aqu√≠ vemos no solo muchos elementos familiares, sino tambi√©n varios elementos nuevos: </p><br><ul><li>  LogisticRegressionLBFSG es un estimador con entrenamiento distribuido de regresi√≥n log√≠stica. </li><li>  Para lograr el m√°ximo rendimiento de algoritmos ML distribuidos.  los datos deben distribuirse de manera √≥ptima entre las particiones.  La utilidad UnwrappedStage.repartition ayudar√° en esto, agregando una operaci√≥n de reparto a la tuber√≠a de tal manera que se use solo en la etapa de entrenamiento (despu√©s de todo, cuando se construyen pron√≥sticos, ya no es necesario). </li><li>  Para que el modelo lineal pueda dar un buen resultado.  los datos deben ser escalados, de los cuales la utilidad Scaler.scale es responsable.  Sin embargo, la presencia de dos transformaciones lineales consecutivas (escala y multiplicaci√≥n por los pesos de regresi√≥n) conduce a gastos innecesarios, y es deseable colapsar estas operaciones.  Al usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PravdaML,</a> la salida ser√° un modelo limpio con una transformaci√≥n :). </li><li>  Bueno, por supuesto, para tales modelos necesita un miembro gratuito, que agregamos usando la operaci√≥n Interceptor.intercept. </li></ul><br><p>  La canalizaci√≥n resultante, aplicada a todos los datos, proporciona AUC por usuario 0.6889 (el c√≥digo de validaci√≥n est√° disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Zepl</a> ).  Ahora queda por aplicar toda nuestra investigaci√≥n: filtrar datos, transformar caracter√≠sticas y segmentar modelos.  La tuber√≠a final se ver√° as√≠: </p><br><pre> <code class="scala hljs"> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">SQLTransformer</span></span>().setStatement(<span class="hljs-string"><span class="hljs-string">s"SELECT instanceId_userId, instanceId_objectId, </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${expressions.mkString(", ")}</span></span></span><span class="hljs-string"> FROM __THIS__"</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">SQLTransformer</span></span>().setStatement(<span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">"SELECT *, IF(array_contains(feedback, 'Liked'), 1.0, 0.0) AS label, concat(IF(membership_status = 'A', 'OwnGroup_', 'NonUser_'), instanceId_objectType) AS type FROM __THIS__"</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">NullToDefaultReplacer</span></span>(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">AutoAssembler</span></span>() .setColumnsToExclude(<span class="hljs-string"><span class="hljs-string">"date"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>, <span class="hljs-string"><span class="hljs-string">"feedback"</span></span>, <span class="hljs-string"><span class="hljs-string">"label"</span></span>, <span class="hljs-string"><span class="hljs-string">"type"</span></span>,<span class="hljs-string"><span class="hljs-string">"instanceId_objectType"</span></span>) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"features"</span></span>), <span class="hljs-type"><span class="hljs-type">CombinedModel</span></span>.perType( <span class="hljs-type"><span class="hljs-type">Scaler</span></span>.scale(<span class="hljs-type"><span class="hljs-type">Interceptor</span></span>.intercept(<span class="hljs-type"><span class="hljs-type">UnwrappedStage</span></span>.repartition( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">LogisticRegressionLBFSG</span></span>(), numPartitions = <span class="hljs-number"><span class="hljs-number">127</span></span>))), numThreads = <span class="hljs-number"><span class="hljs-number">6</span></span>) ))</code> </pre> <br><p>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PravdaML</a> ‚Äî    CombinedModel.perType.       ,     numThreads = 6.             . </p><br><p> ,   ,  per-user AUC 0.7004.    ?  ,   " "    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">XGBoost</a> : </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Pipeline</span></span>().setStages(<span class="hljs-type"><span class="hljs-type">Array</span></span>( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">SQLTransformer</span></span>().setStatement(<span class="hljs-string"><span class="hljs-string">""</span></span><span class="hljs-string"><span class="hljs-string">"SELECT *, IF(array_contains(feedback, 'Liked'), 1.0, 0.0) AS label FROM __THIS__"</span></span><span class="hljs-string"><span class="hljs-string">""</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">NullToDefaultReplacer</span></span>(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">AutoAssembler</span></span>() .setColumnsToExclude(<span class="hljs-string"><span class="hljs-string">"date"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_userId"</span></span>, <span class="hljs-string"><span class="hljs-string">"instanceId_objectId"</span></span>, <span class="hljs-string"><span class="hljs-string">"feedback"</span></span>, <span class="hljs-string"><span class="hljs-string">"label"</span></span>) .setOutputCol(<span class="hljs-string"><span class="hljs-string">"features"</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">XGBoostRegressor</span></span>() .setNumRounds(<span class="hljs-number"><span class="hljs-number">100</span></span>) .setMaxDepth(<span class="hljs-number"><span class="hljs-number">15</span></span>) .setObjective(<span class="hljs-string"><span class="hljs-string">"reg:logistic"</span></span>) .setNumWorkers(<span class="hljs-number"><span class="hljs-number">17</span></span>) .setNthread(<span class="hljs-number"><span class="hljs-number">4</span></span>) .setTrackerConf(<span class="hljs-number"><span class="hljs-number">600000</span></span>L, <span class="hljs-string"><span class="hljs-string">"scala"</span></span>) ))</code> </pre> <br><p> ,     ‚Äî XGBoost  Spark !         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">DLMC</a> ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PravdaML</a> ,       (  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> ).  XGboost " "   10     per-user AUC 0.6981. </p><br><h1 id="analiz-rezultatov">   </h1><br><p> ,     ,  ,       .    SparkML     ,      .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PravdaML</a>  :      Parquet            Spark: </p><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//     val perTypeWeights = sqlContext.read.parquet("sna2019/perType/stages/*/weights") //     20    ( //  ) val topFeatures = new TopKTransformer[Double]() .setGroupByColumns("type") .setColumnToOrderGroupsBy("abs_weight") .setTopK(20) .transform(perTypeWeights.withColumn("abs_weight", functions.abs($"unscaled_weight"))) .orderBy("type", "unscaled_weight")</span></span></code> </pre> <br><p>     Parquet,        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PravdaML</a> ‚Äî TopKTransformer,           . </p><br><p>      Vegas (   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Zepl</a> ): </p><br><p><img src="https://habrastorage.org/webt/q7/_n/fn/q7_nfnto-hw-9nbdgjf3chhm0oc.png"></p><br><p> ,    -   .      XGBoost? </p><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> significance = sqlContext.read.parquet( <span class="hljs-string"><span class="hljs-string">"sna2019/xgBoost15_100_raw/stages/*/featuresSignificance"</span></span> vegas.<span class="hljs-type"><span class="hljs-type">Vegas</span></span>() .withDataFrame(significance.na.drop.orderBy($<span class="hljs-string"><span class="hljs-string">"significance"</span></span>.desc).limit(<span class="hljs-number"><span class="hljs-number">40</span></span>)) .encodeX(<span class="hljs-string"><span class="hljs-string">"name"</span></span>, <span class="hljs-type"><span class="hljs-type">Nom</span></span>, sortField = <span class="hljs-type"><span class="hljs-type">Sort</span></span>(<span class="hljs-string"><span class="hljs-string">"significance"</span></span>, <span class="hljs-type"><span class="hljs-type">AggOps</span></span>.<span class="hljs-type"><span class="hljs-type">Mean</span></span>)) .encodeY(<span class="hljs-string"><span class="hljs-string">"significance"</span></span>, <span class="hljs-type"><span class="hljs-type">Quant</span></span>) .mark(vegas.<span class="hljs-type"><span class="hljs-type">Bar</span></span>) .show</code> </pre> <br><p><img src="https://habrastorage.org/webt/i2/oy/zb/i2oyzbrjlo15x7u1uwadmeswocq.png"></p><br><p>  ,   ,   XGBoost,         ,    .           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> .   ,  XGBoost     ,    ,   . </p><br><h1 id="vyvody">  </h1><br><p>  ,       :).     : </p><br><ol><li>    ,     Scala  Spark    ,      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">  </a> ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> . </li><li>    Scala  Spark        Python:    ETL  ML,    ,      ,     . </li><li>  ,   ,   ,    (,  )    ,     ,      . </li><li> ,     ,       .          ,      ,     , -, . </li></ol><br><p> ,       ,    ,        ,    -.        , ,  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">   Scala</a> "  Newprolab. </p><br><p> ,  ,      ‚Äî   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SNA Hackathon 2019</a> . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/442688/">https://habr.com/ru/post/442688/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../442678/index.html">El proyecto m√°s grande en litograf√≠a est√©reo: esqueleto de mamut impreso en una impresora 3D</a></li>
<li><a href="../442680/index.html">Las tecnolog√≠as de reemplazo sensorial le permitir√°n ver el mundo con la ayuda de los sonidos: c√≥mo funciona la neuroplasticidad del cerebro humano</a></li>
<li><a href="../442682/index.html">Qu√© escribir y c√≥mo ensamblar un proyecto C ++</a></li>
<li><a href="../442684/index.html">Rendimiento equilibrado del sitio. Parte 3: contenido</a></li>
<li><a href="../442686/index.html">Tutorial de DataPower</a></li>
<li><a href="../442690/index.html">Misi√≥n lunar "Bereshit" - selfie en el fondo de la Tierra</a></li>
<li><a href="../442692/index.html">Blockchain sin intermediarios: c√≥mo enviamos valores a un registro distribuido</a></li>
<li><a href="../442694/index.html">Uno de los gigantes del streaming lanzado en India y atrajo a un mill√≥n de usuarios en una semana.</a></li>
<li><a href="../442696/index.html">S for Security: Internet Security of Things e informes en InoThings ++ 2019</a></li>
<li><a href="../442698/index.html">Aplicaci√≥n del metro de Mosc√∫ para la Tienda Windows</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏪 🧡 🧑 AI, tentu saja praktis. Model dasar untuk mengenali emosi dalam gambar 🎐 ⚒️ 🧒🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pada artikel ini, kita akan membangun model dasar dari jaringan saraf convolutional yang mampu melakukan pengenalan emosi dalam gambar. Pengenalan emo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, tentu saja praktis. Model dasar untuk mengenali emosi dalam gambar</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/420635/"><img src="https://habrastorage.org/webt/kp/it/ob/kpitobaccifc3jg-td-z6lgmz9i.jpeg"><br><br>  Pada artikel ini, kita akan membangun model dasar dari jaringan saraf convolutional yang mampu melakukan <i>pengenalan emosi</i> dalam gambar.  Pengenalan emosi dalam kasus kami adalah tugas klasifikasi biner, yang tujuannya adalah untuk membagi gambar menjadi positif dan negatif. <br><br>  Semua kode, dokumen buku catatan, dan materi lainnya, termasuk Dockerfile, dapat ditemukan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> . <br><a name="habracut"></a><br><h2>  <font color="#0071c5">Data</font> </h2><br>  Langkah pertama dalam hampir semua tugas pembelajaran mesin adalah memahami data.  Ayo lakukan. <br><br><h3>  <font color="#0071c5">Struktur dataset</font> </h3><br>  Data mentah dapat diunduh di <a href="">sini</a> (dalam dokumen <i>Baseline.ipynb</i> , semua tindakan di bagian ini dilakukan secara otomatis).  Awalnya, data ada di arsip format Zip *.  Buka paketnya dan kenali struktur file yang diterima. <br><br><img src="https://habrastorage.org/webt/wm/wj/ne/wmwjne07sdpbzoitoa0xxz1zcie.png"><br><br>  Semua gambar disimpan di dalam katalog “dataset 50:50” dan didistribusikan di antara dua subdirektori, nama yang sesuai dengan kelasnya - Negatif dan Positif.  Harap perhatikan bahwa tugasnya sedikit <i>tidak seimbang</i> - 53 persen gambar positif, dan hanya 47 persen negatif.  Biasanya, data dalam masalah klasifikasi dianggap tidak seimbang jika jumlah contoh dalam kelas yang berbeda bervariasi sangat signifikan.  Ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">beberapa cara untuk</a> bekerja dengan data yang tidak seimbang - misalnya, oversampling, oversampling, perubahan faktor pembobotan data, dll. Dalam kasus kami, ketidakseimbangan tidak signifikan dan tidak boleh secara dramatis mempengaruhi proses pembelajaran.  Hanya perlu diingat bahwa classifier naif, selalu menghasilkan nilai "positif", akan memberikan nilai akurasi sekitar 53 persen untuk kumpulan data ini. <br><br>  Mari kita lihat beberapa gambar dari masing-masing kelas. <br><br>  <b>Negatif</b> <br><br><img src="https://habrastorage.org/webt/q4/5d/fc/q45dfcprljvv5tnm0aqvwwgs0uy.jpeg"><br><br><img src="https://habrastorage.org/webt/ep/0p/4q/ep0p4qkimflvz7euzaam1bc39a8.jpeg"><br><br><img src="https://habrastorage.org/webt/dj/ep/px/djeppxcpw5hgct0melwhlvjafsu.jpeg"><br><br>  <b>Positif</b> <br><br><img src="https://habrastorage.org/webt/w6/rs/5j/w6rs5je45iwv-m22jf4vjomcs1s.jpeg"><br><br><img src="https://habrastorage.org/webt/fa/r4/af/far4afuqyyajc3xfqjwnj98xkbo.jpeg"><br><br><img src="https://habrastorage.org/webt/ky/ae/q2/kyaeq2nx8wqpkmnba9y2mugejai.jpeg"><br><br>  Pada pandangan pertama, gambar dari kelas yang berbeda sebenarnya berbeda satu sama lain.  Namun, mari kita telaah lebih dalam dan coba temukan contoh buruk - gambar serupa milik kelas yang berbeda. <br><br>  Sebagai contoh, kami memiliki sekitar 90 gambar ular berlabel negatif dan sekitar 40 gambar sangat mirip ular berlabel positif. <br><br>  <b>Gambar positif seekor ular</b> <br><br><img src="https://habrastorage.org/webt/-m/es/5g/-mes5gboq8vn6p28etujmipmjme.jpeg"><br><br>  <b>Gambar negatif ular</b> <br><br><img src="https://habrastorage.org/webt/np/1f/dv/np1fdvdekusz5cokd96cjou7smu.jpeg"><br><br>  Dualitas yang sama terjadi pada laba-laba (130 gambar negatif dan 20 positif), ketelanjangan (15 gambar negatif dan 45 positif), dan beberapa kelas lainnya.  Orang merasa bahwa penandaan gambar dilakukan oleh orang yang berbeda, dan persepsi mereka tentang gambar yang sama mungkin berbeda.  Karena itu, pelabelan mengandung inkonsistensi yang melekat.  Dua gambar ular ini hampir identik, sementara para ahli yang berbeda menghubungkannya dengan kelas yang berbeda.  Dengan demikian, kita dapat menyimpulkan bahwa hampir tidak mungkin untuk memastikan akurasi 100% ketika bekerja dengan tugas ini karena sifatnya.  Kami percaya bahwa perkiraan akurasi yang lebih realistis adalah nilai 80 persen - nilai ini didasarkan pada proporsi gambar serupa yang ditemukan di kelas yang berbeda selama pemeriksaan visual pendahuluan. <br><br><h3>  <font color="#0071c5">Pemisahan proses pelatihan / verifikasi</font> </h3><br>  Kami selalu berusaha untuk menciptakan model terbaik.  Namun, apa arti dari konsep ini?  Ada banyak kriteria berbeda untuk ini, seperti: kualitas, lead time (belajar + mendapatkan output), dan konsumsi memori.  Beberapa dari mereka dapat dengan mudah dan obyektif diukur (misalnya, waktu dan ukuran memori), sementara yang lain (kualitas) jauh lebih sulit untuk ditentukan.  Misalnya, model Anda dapat menunjukkan akurasi 100 persen ketika belajar dari contoh yang telah digunakan berkali-kali, tetapi gagal bekerja dengan contoh baru.  Masalah ini disebut <i>overfitting</i> dan merupakan salah satu yang paling penting dalam pembelajaran mesin.  Ada juga masalah <i>kekurangan dana</i> : dalam hal ini, model tidak dapat belajar dari data yang disajikan dan menunjukkan prediksi yang buruk bahkan ketika menggunakan kumpulan data pelatihan tetap. <br><br>  Untuk mengatasi masalah overfitting, teknik yang disebut <i>memegang bagian dari sampel digunakan</i> .  Gagasan utamanya adalah untuk membagi data sumber menjadi dua bagian: <br><br><ul><li>  <i>Satu set pelatihan</i> , yang biasanya membentuk sebagian besar set data dan digunakan untuk melatih model. </li><li>  <i>Set tes</i> biasanya merupakan bagian kecil dari data sumber, yang dibagi menjadi dua bagian sebelum melakukan semua prosedur pelatihan.  Set ini tidak digunakan sama sekali dalam pelatihan dan dianggap sebagai contoh baru untuk menguji model setelah selesai pelatihan. </li></ul><br>  Dengan menggunakan metode ini, kita dapat mengamati seberapa baik <i>generalisasi</i> model kita (yaitu, ia bekerja dengan contoh-contoh yang sebelumnya tidak diketahui). <br><br>  Artikel ini akan menggunakan rasio 4/1 untuk pelatihan dan set tes.  Teknik lain yang kami gunakan adalah apa yang disebut <i>stratifikasi</i> .  Istilah ini mengacu pada partisi setiap kelas secara independen dari semua kelas lainnya.  Pendekatan ini memungkinkan menjaga keseimbangan yang sama antara ukuran kelas dalam pelatihan dan set tes.  Stratifikasi secara implisit menggunakan asumsi bahwa distribusi contoh tidak berubah ketika sumber data berubah dan tetap sama ketika menggunakan contoh baru. <br><br><img src="https://habrastorage.org/webt/pn/gq/lz/pngqlzmf15cnm-4cwjvblndwpsg.png"><br><br>  Kami menggambarkan konsep stratifikasi dengan contoh sederhana.  Misalkan kita memiliki empat kelompok data / kelas dengan jumlah objek yang sesuai di dalamnya: anak-anak (5), remaja (10), dewasa (80) dan orang tua (5);  lihat gambar di sebelah kanan (dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Wikipedia</a> ).  Sekarang kita perlu memecah data ini menjadi dua set sampel dalam rasio 3/2.  Ketika menggunakan stratifikasi contoh, pemilihan objek akan dilakukan secara independen dari masing-masing kelompok: 2 objek dari kelompok anak-anak, 4 objek dari kelompok remaja, 32 objek dari kelompok orang dewasa dan 2 objek dari kelompok orang tua.  Set data baru berisi 40 objek, yang persis 2/5 dari data asli.  Pada saat yang sama, keseimbangan antara kelas-kelas dalam dataset baru sesuai dengan keseimbangan mereka dalam data sumber. <br><br>  Semua tindakan di atas diimplementasikan dalam satu fungsi, yang disebut <i>prep_data</i> ;  fungsi ini dapat ditemukan di file Python <i>utils.py</i> .  Fungsi ini memuat data, membaginya menjadi pelatihan dan set tes menggunakan nomor acak tetap (untuk pemutaran nanti), dan kemudian mendistribusikan data sesuai antara direktori pada hard drive untuk digunakan nanti. <br><br><h3>  <font color="#0071c5">Pretreatment dan Augmentasi</font> </h3><br>  Dalam salah satu artikel sebelumnya, tindakan pra-pemrosesan dan kemungkinan alasan penggunaannya dalam bentuk augmentasi data dijelaskan.  Jaringan saraf convolutional adalah model yang cukup kompleks, dan sejumlah besar data diperlukan untuk melatihnya.  Dalam kasus kami, hanya ada 1.600 contoh - ini, tentu saja, tidak cukup. <br><br>  Oleh karena itu, kami ingin memperluas set data yang digunakan oleh <i>augmentasi</i> data.  Sesuai dengan informasi yang terkandung dalam artikel tentang preprocessing data, perpustakaan Keras * menyediakan kemampuan untuk menambah data dengan cepat saat membacanya dari hard drive.  Ini dapat dilakukan melalui kelas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ImageDataGenerator</a> . <br><br><img src="https://habrastorage.org/webt/3m/j8/oe/3mj8oewbjg3j8eriel5opmj43cc.png"><br><br>  Dua contoh generator dibuat di sini.  Contoh pertama adalah untuk pelatihan dan menggunakan banyak transformasi acak - seperti rotasi, shift, konvolusi, penskalaan, dan rotasi horizontal - sambil membaca data dari disk dan mentransfernya ke model.  Akibatnya, model menerima contoh yang dikonversi, dan setiap contoh yang diterima oleh model adalah unik karena sifat acak konversi ini.  Salinan kedua untuk verifikasi, dan hanya memperbesar gambar.  Pembelajaran dan pengujian generator hanya memiliki satu transformasi umum - zooming.  Untuk memastikan stabilitas komputasi model, perlu menggunakan rentang [0;  1] bukannya [0;  255]. <br><br><h2>  <font color="#0071c5">Arsitektur model</font> </h2><br>  Setelah mempelajari dan menyiapkan data awal, tahap pembuatan model mengikuti.  Karena sejumlah kecil data tersedia bagi kami, kami akan membangun model yang relatif sederhana agar dapat melatihnya dengan tepat dan menghilangkan situasi overfitting.  Mari kita coba <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">arsitektur</a> gaya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">VGG</a> , tetapi gunakan lebih sedikit layer dan filter. <br><br><img src="https://habrastorage.org/webt/xa/dl/ae/xadlae7ebpbynxk60facw3_bxho.png"><br><br><img src="https://habrastorage.org/webt/2b/xr/cy/2bxrcyazsu_gasst_aqr5ao7ayu.png"><br><br>  Arsitektur jaringan terdiri dari bagian-bagian berikut: <br>  <b>[Lapisan konvolusi + lapisan konvolusi + pemilihan nilai maksimum] × 2</b> <br>  Bagian pertama berisi dua lapisan convolutional superimposed dengan 64 filter (dengan ukuran 3 dan langkah 2) dan lapisan untuk memilih nilai maksimum (dengan ukuran 2 dan langkah 2) yang terletak setelahnya.  Bagian ini juga biasa disebut sebagai <i>unit ekstraksi fitur</i> , karena filter secara efisien mengekstraksi fitur yang berarti dari data input (lihat artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tinjauan Jaringan Syaraf Konvolusional untuk klasifikasi gambar</a> untuk informasi lebih lanjut). <br><br>  <b>Perataan</b> <br><br>  Bagian ini wajib, karena tensor empat dimensi diperoleh pada keluaran bagian konvolusional (contoh, tinggi, lebar, dan saluran).  Namun, untuk lapisan yang sepenuhnya terhubung, kita memerlukan tensor dua dimensi (contoh, fitur) sebagai input.  Oleh karena itu, perlu untuk <i>menyelaraskan</i> tensor di sekitar tiga sumbu terakhir untuk menggabungkannya menjadi satu sumbu.  Bahkan, ini berarti bahwa kami mempertimbangkan setiap titik di setiap peta fitur sebagai properti terpisah dan menyelaraskannya ke dalam satu vektor.  Gambar di bawah ini menunjukkan contoh gambar 4 × 4 dengan 128 saluran, yang disejajarkan dalam satu vektor yang diperluas dengan panjang 1024 elemen. <br><br><img src="https://habrastorage.org/webt/zs/-f/_h/zs-f_h8_mr6flzz62vo21qttt0u.png"><br><br>  <b>[Metode lapisan penuh + pengecualian] × 2</b> <br><br>  Ini adalah bagian <i>klasifikasi dari</i> jaringan.  Dia mengambil tampilan yang selaras dari karakteristik gambar dan mencoba untuk mengklasifikasikannya dengan cara terbaik.  Bagian dari jaringan ini terdiri dari dua blok yang dilapiskan yang terdiri dari lapisan yang sepenuhnya terhubung dan <i>metode pengecualian</i> .  Kami telah berkenalan dengan lapisan yang terhubung sepenuhnya - biasanya ini adalah lapisan dengan koneksi yang terhubung sepenuhnya.  Tapi apa "metode pengecualian"?  Metode eksklusi adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">teknik regularisasi</a> yang membantu mencegah overfitting.  Salah satu tanda kemungkinan overfitting adalah nilai koefisien berat yang sangat berbeda (urutan besarnya).  Ada banyak cara untuk mengatasi masalah ini, termasuk pengurangan berat badan dan metode eliminasi.  Gagasan metode eliminasi adalah untuk memutus neuron acak selama pelatihan (daftar neuron yang terputus harus diperbarui setelah setiap paket / era pelatihan).  Ini sangat kuat mencegah memperoleh nilai yang sama sekali berbeda untuk koefisien bobot - dengan cara ini jaringan diatur. <br><br><img src="https://habrastorage.org/webt/1x/g5/vw/1xg5vwjp4syjmujonokwl9i-ilo.png"><br><br>  Contoh penerapan metode pengecualian (gambar diambil dari artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Metode pengecualian: cara mudah untuk mencegah overfitting di jaringan saraf</a> ): <br><br>  <b>Modul Sigmoid</b> <br><br>  Lapisan output harus sesuai dengan pernyataan masalah.  Dalam kasus ini, kita berhadapan dengan masalah klasifikasi biner, oleh karena itu, kita memerlukan satu neuron keluaran dengan fungsi aktivasi <i>sigmoid</i> , yang memperkirakan probabilitas P milik kelas dengan nomor 1 (dalam kasus kami, ini akan menjadi citra positif).  Maka probabilitas milik kelas dengan angka 0 (gambar negatif) dapat dengan mudah dihitung sebagai 1 - P. <br><br><h2>  <font color="#0071c5">Opsi pengaturan dan pelatihan</font> </h2><br>  Kami memilih arsitektur model dan menetapkannya menggunakan pustaka Keras untuk bahasa Python.  Selain itu, sebelum memulai model pelatihan, perlu untuk <i>mengkompilasinya</i> . <br><br><img src="https://habrastorage.org/webt/th/pv/l8/thpvl8hahgpnyucfsfhxpk5qq8w.png"><br><br>  Pada tahap kompilasi, model disetel untuk pelatihan.  Dalam hal ini, tiga parameter utama harus ditentukan: <br><br><ul><li>  <i>Pengoptimal</i> .  Dalam hal ini, kami menggunakan pengoptimal default <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Adam</a> *, yang merupakan jenis algoritme penurunan gradien stokastik dengan momen dan kecepatan belajar adaptif (untuk informasi lebih lanjut lihat entri blog oleh S. Ruder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Gambaran umum algoritma pengoptimalan penurunan gradien</a> ). </li><li>  <i>Fungsi kerugian</i> .  Tugas kita adalah masalah klasifikasi biner, jadi akan tepat untuk menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">entropi silang biner</a> sebagai fungsi kerugian. </li><li>  <i>Metrik</i> .  Ini adalah argumen opsional yang dengannya Anda dapat menentukan metrik tambahan untuk dilacak selama proses pelatihan.  Dalam hal ini, kita perlu melacak akurasi bersama dengan fungsi tujuan. </li></ul><br>  Sekarang kita siap untuk melatih modelnya.  Harap dicatat bahwa prosedur pelatihan dilakukan dengan menggunakan generator yang diinisialisasi pada bagian sebelumnya. <br><br>  Jumlah era adalah hiperparameter lain yang dapat disesuaikan.  Di sini kami hanya menetapkan nilai 10. Kami juga ingin menyimpan model dan sejarah pembelajaran agar dapat mengunduhnya nanti. <br><br><img src="https://habrastorage.org/webt/mt/3o/cd/mt3ocd0xfdxmshq_7tv1xptw5de.png"><br><br><h2>  <font color="#0071c5">Peringkat</font> </h2><br>  Sekarang mari kita lihat seberapa baik model kita bekerja.  Pertama-tama, kami mempertimbangkan perubahan metrik dalam proses pembelajaran. <br><br><img src="https://habrastorage.org/webt/d-/_j/1l/d-_j1lty0qibl5gkwrhy3avbgzq.png"><br><br>  Pada gambar, Anda dapat melihat bahwa entropi verifikasi dan akurasi lintas tidak berkurang dari waktu ke waktu.  Selain itu, metrik akurasi untuk pelatihan dan set tes hanya berfluktuasi di sekitar nilai classifier acak.  Akurasi akhir untuk set tes adalah 55 persen, yang hanya sedikit lebih baik dari perkiraan acak. <br><br>  Mari kita lihat bagaimana prediksi model didistribusikan antar kelas.  Untuk tujuan ini, perlu membuat dan memvisualisasikan <i>matriks ketidakakuratan</i> menggunakan fungsi yang sesuai dari paket Sklearn * untuk bahasa Python. <br>  Setiap sel dalam matriks ketidakakuratan memiliki namanya sendiri: <br><br><img src="https://habrastorage.org/webt/p4/9j/mj/p49jmjgtuc4fhqxfd_szqm6qvtw.png"><br><br><ul><li>  True Positive Rate = TPR (sel kanan atas) mewakili proporsi contoh positif (kelas 1, yaitu, emosi <i>positif</i> dalam kasus kami), diklasifikasikan dengan benar sebagai positif. </li><li>  False Positive Rate = FPR (sel kanan bawah) mewakili proporsi contoh positif yang secara keliru diklasifikasikan sebagai <i>negatif</i> (kelas 0, yaitu, emosi negatif). </li><li>  True Negative Rate = TNR (sel kiri bawah) mewakili proporsi contoh negatif yang diklasifikasikan dengan benar sebagai negatif. </li><li>  False Negative Rate = FNR (sel kiri atas) mewakili proporsi contoh negatif yang salah diklasifikasikan sebagai positif. </li></ul><br>  Dalam kasus kami, baik TPR dan FPR mendekati 1. Ini berarti bahwa hampir semua objek diklasifikasikan sebagai positif.  Dengan demikian, model kami tidak jauh dari model dasar naif dengan prediksi konstan dari kelas yang lebih besar (dalam kasus kami, ini adalah gambar positif). <br><br>  Metrik menarik lainnya yang menarik untuk diamati adalah kurva kinerja penerima (kurva ROC) dan area di bawah kurva ini (ROC AUC).  Definisi formal dari konsep-konsep ini dapat ditemukan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> .  Singkatnya, kurva ROC menunjukkan seberapa baik classifier biner bekerja. <br><br>  Pengklasifikasi dari jaringan saraf convolutional kami memiliki modul sigmoid sebagai output, yang memberikan probabilitas contoh ke kelas 1. Sekarang anggap bahwa pengklasifikasi kami menunjukkan pekerjaan yang baik dan memberikan nilai probabilitas rendah untuk contoh kelas 0 (histogram hijau pada gambar di bawah) nilai probabilitas tinggi untuk contoh Kelas 1 (histogram biru). <br><br><img src="https://habrastorage.org/webt/wq/e_/us/wqe_usitkajallhk1ymcsq472pu.png"><br><br>  Kurva ROC menunjukkan bagaimana indikator TPR tergantung pada indikator FPR ketika memindahkan ambang klasifikasi dari 0 ke 1 (gambar kanan, bagian atas).  Untuk pemahaman yang lebih baik tentang konsep ambang batas, ingatlah bahwa kita memiliki kemungkinan untuk menjadi anggota kelas 1 untuk setiap contoh.  Namun, probabilitas belum merupakan label kelas.  Oleh karena itu, harus dibandingkan dengan ambang batas untuk menentukan kelas mana yang dimiliki contoh.  Misalnya, jika nilai ambang adalah 1, maka semua contoh harus diklasifikasikan sebagai milik kelas 0, karena nilai probabilitas tidak boleh lebih dari 1, dan nilai indikator FPR dan TPR dalam kasus ini adalah 0 (karena tidak ada sampel yang diklasifikasikan sebagai positif). )  Situasi ini sesuai dengan titik paling kiri pada kurva ROC.  Di sisi lain dari kurva ada titik di mana nilai ambang adalah 0: ini berarti bahwa semua sampel diklasifikasikan sebagai milik kelas 1, dan nilai-nilai TPR dan FPR sama dengan 1. Poin-poin perantara menunjukkan perilaku ketergantungan TPR / FPR ketika nilai ambang batas berubah. <br><br>  Garis diagonal pada grafik berhubungan dengan penggolong acak.  Semakin baik classifier kita bekerja, semakin dekat kurva nya ke titik kiri atas grafik.  Dengan demikian, indikator objektif kualitas classifier adalah area di bawah kurva ROC (indikator ROC AUC).  Nilai indikator ini harus sedekat mungkin dengan 1. Nilai AUC 0,5 sesuai dengan penggolong acak. <br><br>  AUC dalam model kami (lihat gambar di atas) adalah 0,57, yang jauh dari hasil terbaik. <br><br><img src="https://habrastorage.org/webt/oo/vu/-t/oovu-t0vyxvlbgb4zgp4qyvodsw.png"><br><br>  Semua metrik ini menunjukkan bahwa model yang dihasilkan hanya sedikit lebih baik daripada pengelompokan acak.  Ada beberapa alasan untuk ini, yang utama dijelaskan di bawah ini: <br><br><ul><li>  Jumlah data yang sangat kecil untuk pelatihan, tidak cukup untuk menyorot fitur karakteristik gambar.  Bahkan augmentasi data tidak dapat membantu dalam kasus ini. </li><li>  Model jaringan saraf convolutional yang relatif kompleks (dibandingkan dengan model pembelajaran mesin lainnya) dengan sejumlah besar parameter. </li></ul><br><h2>  <font color="#0071c5">Kesimpulan</font> </h2><br>  Dalam artikel ini, kami membuat model jaringan saraf convolutional sederhana untuk mengenali emosi dalam gambar.  Pada saat yang sama, pada tahap pelatihan, sejumlah metode digunakan untuk menambah data, dan model juga dievaluasi menggunakan seperangkat metrik seperti akurasi, kurva ROC, ROC AUC dan matriks ketidaktepatan.  Model menunjukkan hasil, hanya beberapa yang terbaik acak.       . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id420635/">https://habr.com/ru/post/id420635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id420625/index.html">KDD 2018, Hari Pertama, tutorial</a></li>
<li><a href="../id420627/index.html">C # Asynchronous Programming: Bagaimana kinerja Anda?</a></li>
<li><a href="../id420629/index.html">PHP Digest No. 137 (6 - 20 Agustus 2018)</a></li>
<li><a href="../id420631/index.html">Kami tidak takut pada "awan"</a></li>
<li><a href="../id420633/index.html">Menulis eksportir GeoIP untuk Prometheus dengan visualisasi di Grafana dalam 15 menit</a></li>
<li><a href="../id420637/index.html">Ulasan Printer 3D WANHAO D9 / 300: Video</a></li>
<li><a href="../id420639/index.html">Akka antipatterns: terlalu banyak aktor</a></li>
<li><a href="../id420641/index.html">Respons teknis 3CX merespons: mencadangkan dan memulihkan 3CX dari baris perintah</a></li>
<li><a href="../id420643/index.html">Hampir semuanya sama, hanya 10 kali lebih murah</a></li>
<li><a href="../id420645/index.html">Insinyur perekrutan yang realistis</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
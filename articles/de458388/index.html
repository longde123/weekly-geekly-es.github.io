<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎛️ 👐🏼 🎁 Deep (Learning + Random) Wald- und Artikelanalyse 🍈 ⛹🏽 🌾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir sprechen weiterhin über die Konferenz zu Statistik und maschinellem Lernen AISTATS 2019. In diesem Beitrag werden wir Artikel über Tiefenmodelle a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Deep (Learning + Random) Wald- und Artikelanalyse</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ru_mts/blog/458388/"><p>  Wir sprechen weiterhin über die Konferenz zu Statistik und maschinellem Lernen AISTATS 2019. In diesem Beitrag werden wir Artikel über Tiefenmodelle aus Baumensembles analysieren, Regularisierung für sehr spärliche Daten mischen und zeiteffiziente Annäherung an die Kreuzvalidierung. </p><br><p><img src="https://habrastorage.org/webt/n-/uv/xj/n-uvxjud1se0puoearqtlott2de.jpeg"></p><a name="habracut"></a><br><h2 id="algoritm-glubokiy-les-an-exploration-to-non-nn-deep-models-based-on-non-differentiable-modules">  Deep Forest-Algorithmus: Eine Untersuchung von Nicht-NN-Tiefenmodellen basierend auf nicht differenzierbaren Modulen </h2><br><p>  Zhi-Hua Zhou (Universität Nanjing) <br>  → <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Präsentation</a> <br>  → <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> <br>  Implementierungen - unten </p><br><p>  Ein Professor aus China sprach über das Baumensemble, das die Autoren als erstes tiefes Training für nicht differenzierbare Module bezeichnen.  Dies mag wie eine zu laute Aussage erscheinen, aber dieser Professor und sein H-Index 95 sind eingeladene Redner. Diese Tatsache ermöglicht es uns, die Aussage ernster zu nehmen.  Die grundlegende Theorie von Deep Forest wurde für eine lange Zeit entwickelt, der ursprüngliche Artikel ist bereits 2017 (fast 200 Zitate), aber die Autoren schreiben Bibliotheken und jedes Jahr verbessern sie den Algorithmus in der Geschwindigkeit.  Und jetzt, so scheint es, haben sie den Punkt erreicht, an dem diese schöne Theorie endlich in die Praxis umgesetzt werden kann. </p><br><p>  <em>Gesamtansicht der Tiefwaldarchitektur</em> <br><img src="https://habrastorage.org/webt/4k/7q/1q/4k7q1qlzs5rixw4itr5luctdpuq.jpeg"></p><br><p>  <strong>Hintergrund</strong> </p><br><p>  Tiefe Modelle, die heute als tiefe neuronale Netze verstanden werden, werden verwendet, um komplexe Datenabhängigkeiten zu erfassen.  Darüber hinaus stellte sich heraus, dass das Erhöhen der Anzahl von Schichten effizienter ist als das Erhöhen der Anzahl von Einheiten auf jeder Schicht.  Neuronale Netze haben jedoch ihre Nachteile: </p><br><ul><li>  Es braucht viele Daten, um nicht umzuschulen, </li><li>  Es erfordert eine Menge Rechenressourcen, um in angemessener Zeit zu lernen. </li><li>  Zu viele Hyperparameter, die sich nur schwer optimal konfigurieren lassen </li></ul><br><p>  Darüber hinaus sind Elemente tiefer neuronaler Netze differenzierbare Module, die nicht unbedingt für jede Aufgabe wirksam sind.  Trotz der Komplexität neuronaler Netze funktionieren konzeptionell einfache Algorithmen wie eine zufällige Gesamtstruktur oft besser oder nicht viel schlechter.  Für solche Algorithmen müssen Sie jedoch Features manuell entwerfen, was auch schwierig optimal zu tun ist. </p><br><p>  Forscher haben bereits festgestellt, dass die Ensembles auf Kaggle: „sehr perfekt“ sind. Inspiriert von den Worten von Scholl und Hinton, dass Differenzierung die schwächste Seite von Deep Learning ist, haben sie beschlossen, ein Ensemble von Bäumen mit DL-Eigenschaften zu erstellen. </p><br><p>  <em>Folie „Wie man ein gutes Ensemble macht“</em> <br><img src="https://habrastorage.org/webt/8w/cb/z9/8wcbz9ml-7qidb5ii4-meqcinec.jpeg"></p><br><p>  Die Architektur wurde aus den Eigenschaften der Ensembles abgeleitet: Die Elemente der Ensembles sollten nicht von sehr schlechter Qualität sein und sich unterscheiden. </p><br><p>  GcForest besteht aus zwei Phasen: Cascade Forest und Multi-Grained Scanning.  Damit die Kaskade nicht umgeschult wird, besteht sie außerdem aus zwei Baumarten - von denen eine absolut zufällige Bäume sind, die für nicht zugewiesene Daten verwendet werden können.  Die Anzahl der Schichten wird innerhalb des Kreuzvalidierungsalgorithmus bestimmt. <br><img src="https://habrastorage.org/webt/qv/co/-b/qvco-br5vregwj-rrxn3bxnyfeq.jpeg"></p><br><p>  <em>Zwei Arten von Bäumen</em> <br><img src="https://habrastorage.org/webt/mc/kp/ia/mckpiaiavjyh9hawcxhvtbusego.jpeg"></p><br><p>  <strong>Ergebnisse</strong> </p><br><p>  Zusätzlich zu den Ergebnissen für Standarddatensätze versuchten die Autoren, gcForest für Transaktionen des chinesischen Zahlungssystems zu verwenden, um nach Betrug zu suchen, und erzielten F1 und AUC viel höher als die von LR und DNN.  Diese Ergebnisse sind nur in der Präsentation enthalten, aber der Code, der für einige Standarddatensätze ausgeführt werden soll, befindet sich auf Git. </p><br><p><img src="https://habrastorage.org/webt/y3/kf/gy/y3kfgytp_qawqyskwmvrrumzdna.jpeg"></p><br><p>  <em>Ergebnisse der Algorithmusersetzung.</em>  <em>mdDF ist die optimale Margin Distribution Deep Forest, eine Variante von gcForest</em> </p><br><p><img src="https://habrastorage.org/webt/e1/oh/wq/e1ohwqrilda60nmdnosaa_ye4yk.jpeg"></p><br><p>  Vorteile: </p><br><ul><li>  Bei wenigen Hyperparametern wird die Anzahl der Ebenen innerhalb des Algorithmus automatisch angepasst </li><li>  Die Standardeinstellungen sind so gewählt, dass sie bei vielen Aufgaben gut funktionieren. </li><li>  Adaptive Komplexität des Modells für kleine Daten - ein kleines Modell </li><li>  Keine Notwendigkeit, Funktionen einzustellen </li><li>  Es funktioniert qualitativ vergleichbar mit tiefen neuronalen Netzen und manchmal besser </li></ul><br><p>  Nachteile: </p><br><ul><li>  Nicht auf GPU beschleunigt </li><li>  In den Bildern verliert DNNs </li></ul><br><p>  Neuronale Netze haben ein Problem mit der Gradientendämpfung, während tiefe Wälder ein Problem mit dem Verschwinden der Vielfalt haben.  Da es sich um ein Ensemble handelt, ist die Qualität umso höher, je mehr „unterschiedliche“ und „gute“ Elemente verwendet werden.  Das Problem ist, dass die Autoren bereits fast alle klassischen Ansätze (Stichproben, Randomisierung) ausprobiert haben.  Solange keine neue Grundlagenforschung zum Thema „Unterschiede“ erscheint, wird es schwierig sein, die Qualität tiefer Wälder zu verbessern.  Jetzt ist es jedoch möglich, die Rechengeschwindigkeit zu verbessern. </p><br><p>  <strong>Reproduzierbarkeit der Ergebnisse</strong> </p><br><p>  Ich war von XGBoost in Bezug auf die Tabellendaten fasziniert und wollte das Ergebnis reproduzieren.  Ich nahm das Adults-Dataset und wandte GcForestCS (eine leicht beschleunigte Version von GcForest) mit Parametern der Autoren des Artikels und XGBoost mit Standardparametern an.  In dem Beispiel, das die Autoren hatten, wurden kategoriale Merkmale bereits irgendwie vorverarbeitet, aber es wurde nicht angegeben, wie.  Als Ergebnis habe ich CatBoostEncoder und eine andere Metrik verwendet - ROC AUC.  Die Ergebnisse waren statistisch unterschiedlich - XGBoost gewann.  Die Betriebszeit von XGBoost ist vernachlässigbar, während gcForestCS 20 Minuten jeder Kreuzvalidierung mit 5 Falten hat.  Andererseits haben die Autoren den Algorithmus an verschiedenen Datensätzen getestet und die Parameter für diesen Datensatz an ihre Feature-Vorverarbeitung angepasst. </p><br><p>  Den Code finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . </p><br><p>  <strong>Implementierungen</strong> </p><br><p>  → <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der offizielle Code der Autoren des Artikels</a> <br>  → <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Offizielle verbesserte Änderung, schneller, aber keine Dokumentation</a> <br>  → Die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Implementierung ist einfacher</a> </p><br><h2 id="pclasso-the-lasso-meets-principal-components-regression">  PcLasso: Das Lasso erfüllt die Regression der Hauptkomponenten </h2><br><p>  J. Kenneth Tay, Jerome Friedman, Robert Tibshirani (Stanford University) </p><br><p>  → <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> <br>  → <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Präsentation</a> <br>  → <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anwendungsbeispiel</a> </p><br><p>  Anfang 2019 schlugen J. Kenneth Tay, Jerome Friedman und Robert Tibshirani von der Stanford University eine neue Unterrichtsmethode mit einem Lehrer vor, die besonders für spärliche Daten geeignet ist. </p><br><p>  Die Autoren des Artikels lösten das Problem der Analyse von Daten zu Genexpressionsstudien, die in Zeng &amp; Breesy (2016) beschrieben sind.  Ziel ist der Mutationsstatus des p53-Gens, der die Genexpression als Reaktion auf verschiedene Signale von zellulärem Stress reguliert.  Ziel der Studie ist es, Prädiktoren zu identifizieren, die mit dem Mutationsstatus von p53 korrelieren.  Die Daten bestehen aus 50 Zeilen, von denen 17 als normal klassifiziert sind und die restlichen 33 Mutationen im p53-Gen tragen.  Nach einer Analyse von Subramanian et al.  (2005) 308 Sätze von Genen zwischen 15 und 500 sind in dieser Analyse enthalten.  Diese Gen-Kits enthalten insgesamt 4.301 Gene und sind im Paket grpregOverlap R verfügbar.  Beim Erweitern von Daten zur Verarbeitung überlappender Gruppen werden 13.237 Spalten ausgegeben.  Die Autoren des Artikels verwendeten die pcLasso-Methode, die zur Verbesserung der Modellergebnisse beitrug. </p><br><p>  <em>Im Bild sehen wir einen Anstieg der AUC bei Verwendung von "pcLasso"</em> <br><img src="https://habrastorage.org/webt/ok/p6/mg/okp6mgex-l9p49vcz5gedg8xa5o.jpeg"></p><br><p>  <strong>Die Essenz der Methode</strong> </p><br><p>  Methode kombiniert <img src="https://tex.s2cms.ru/svg/l_1" alt="l_1">  -regelmäßigkeit mit <img src="https://tex.s2cms.ru/svg/l_2" alt="l_2">  , wodurch der Koeffizientenvektor auf die Hauptkomponenten der Merkmalsmatrix eingegrenzt wird.  Sie nannten die vorgeschlagene Methode "Kern-Lasso-Komponenten" ("pcLasso" auf R verfügbar).  Die Methode kann besonders leistungsfähig sein, wenn die Variablen zuvor gruppiert wurden (der Benutzer wählt aus, was und wie gruppiert werden soll).  In diesem Fall komprimiert pcLasso jede Gruppe und erhält die Lösung in Richtung der Hauptkomponenten dieser Gruppe.  Während des Lösungsprozesses wird auch die Auswahl signifikanter Gruppen unter den verfügbaren durchgeführt. </p><br><p>  Wir präsentieren die diagonale Matrix der singulären Zerlegung einer zentrierten Matrix von Merkmalen <img src="https://tex.s2cms.ru/svg/X" alt="X.">  wie folgt: </p><br><p>  Wir repräsentieren unsere singuläre Zerlegung der zentrierten Matrix X (SVD) als <img src="https://tex.s2cms.ru/svg/X%3DUDV%5ET" alt="X = UDV ^ T.">  wo <img src="https://tex.s2cms.ru/svg/D" alt="D.">  Ist eine Diagonalmatrix, die aus singulären Werten besteht.  In dieser Form <img src="https://tex.s2cms.ru/svg/l_2" alt="l_2">  - Regularisierung kann dargestellt werden: <br><img src="https://tex.s2cms.ru/svg/%5Cbeta%5ET%20VZV%5ET%20%5Cbeta" alt="\ beta ^ T VZV ^ T \ beta">  wo <img src="https://tex.s2cms.ru/svg/Z" alt="Z.">  - Diagonalmatrix mit der Funktion von Quadraten singulärer Werte: <img src="https://tex.s2cms.ru/svg/Z_%7B11%7D%3Df_1%20(d_1%5E2%2Cd_2%5E2%2C%E2%80%A6%2Cd_m%5E2%20)%2C%E2%80%A6%2CZ_%7B22%7D%3Df_2%20(d_1%5E2%2Cd_2%5E2%2C%E2%80%A6%2Cd_m%5E2%20)" alt="Z_ {11} = f_1 (d_1 ^ 2, d_2 ^ 2, ..., d_m ^ 2), ..., Z_ {22} = f_2 (d_1 ^ 2, d_2 ^ 2, ..., d_m ^ 2)">  . </p><br><p>  Im Allgemeinen in <img src="https://tex.s2cms.ru/svg/l_2" alt="l_2">  -regelmäßigkeit <img src="https://tex.s2cms.ru/svg/Z_%7Bjj%7D%3D1" alt="Z_ {jj} = 1">  für alle <img src="https://tex.s2cms.ru/svg/j" alt="j">  das entspricht <img src="https://tex.s2cms.ru/svg/%5Cbeta%5ET%20%5Cbeta" alt="\ beta ^ T \ beta">  .  Sie schlagen vor, die folgenden Funktionen zu minimieren: </p><br><p><img src="https://habrastorage.org/webt/6l/fj/lv/6lfjlv9m-zy8qfhcvrcqcymuuxa.jpeg"></p><br><p>  Hier <img src="https://tex.s2cms.ru/svg/D" alt="D.">  - Matrix der Unterschiede der diagonalen Elemente <img src="https://tex.s2cms.ru/svg/d_1%5E2-d_1%5E2%2Cd_1%5E2-d_2%5E2%2C%E2%80%A6%2Cd_1%5E2-d_m%5E2" alt="d_1 ^ 2-d_1 ^ 2, d_1 ^ 2-d_2 ^ 2, ..., d_1 ^ 2-d_m ^ 2">  .  Mit anderen Worten, wir steuern den Vektor <img src="https://tex.s2cms.ru/svg/%5Cbeta%20" alt="\ beta">  auch mit Hyperparameter <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  . <br>  Wenn wir diesen Ausdruck transformieren, erhalten wir die Lösung: </p><br><p><img src="https://habrastorage.org/webt/vf/qs/6b/vfqs6b8fnqo3bmlacyr5j4fpigs.jpeg"></p><br><p>  Das Hauptmerkmal der Methode ist natürlich die Fähigkeit, Daten zu gruppieren und auf der Grundlage dieser Gruppen die Hauptkomponenten der Gruppe hervorzuheben.  Dann schreiben wir unsere Lösung in der Form um: </p><br><p><img src="https://habrastorage.org/webt/9l/ij/wc/9lijwc3_kvwtvxalszzyt4zq4l4.jpeg"></p><br><p>  Hier <img src="https://tex.s2cms.ru/svg/%5Cbeta_k" alt="\ beta_k">  - Vektorsubvektor <img src="https://tex.s2cms.ru/svg/%5Cbeta" alt="\ beta">  entsprechend der Gruppe k, <img src="https://tex.s2cms.ru/svg/d_k%3D(d_%7Bk1%7D%2C%E2%80%A6%2Cd_%7Bkmk%7D)" alt="d_k = (d_ {k1}, ..., d_ {kmk})">  - singuläre Werte <img src="https://tex.s2cms.ru/svg/X_k" alt="X_k">  in absteigender Reihenfolge angeordnet, und <img src="https://tex.s2cms.ru/svg/D_%7Bd_%7Bk1%7D%5E2-d_%7Bkj%7D%5E2%7D" alt="D_ {d_ {k1} ^ 2-d_ {kj} ^ 2}">  - Diagonalmatrix <img src="https://tex.s2cms.ru/svg/d_%7Bk1%7D%5E2-d_%7Bkj%7D%5E2%2C%20j%3D1%2C2%2C%E2%80%A6%2Cm_k" alt="d_ {k1} ^ 2-d_ {kj} ^ 2, j = 1,2, ..., m_k"></p><br><p>  Einige Hinweise zur Lösung der Zielfunktion: </p><br><ol><li><p>  Die Zielfunktion ist konvex und die nicht glatte Komponente ist trennbar.  Daher kann es unter Verwendung eines Gradientenabfalls effektiv optimiert werden. <br>  Der Ansatz besteht darin, mehrere Werte festzuschreiben <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  (einschließlich Null, um den Standard zu erhalten <img src="https://tex.s2cms.ru/svg/l_1" alt="l_1">  -regelmäßigkeit) und dann optimieren: <img src="https://habrastorage.org/webt/uz/bf/eo/uzbfeori9kupj8b05x46dcj6iri.jpeg">  abholen <img src="https://tex.s2cms.ru/svg/%5Clambda" alt="\ lambda">  .  Dementsprechend sind die Parameter <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  und <img src="https://tex.s2cms.ru/svg/%5Clambda" alt="\ lambda">  werden zur Kreuzvalidierung ausgewählt. </p><br></li><li><p>  Parameter <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  schwer zu interpretieren.  In der Software (pcLasso-Paket) legt der Benutzer den Wert dieses Parameters fest, der zum Intervall [0,1] gehört, wobei 1 entspricht <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  = 0 (Lasso). </p><br></li></ol><br><p>  In der Praxis variieren die Werte <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  = 0,25, 0,5, 0,75, 0,9, 0,95 und 1 können Sie eine breite Palette von Modellen abdecken. </p><br><p>  <em>Der Algorithmus selbst ist wie folgt</em> <br><img src="https://habrastorage.org/webt/l-/3x/si/l-3xsipork2hzeh7ws1bg1hz86o.jpeg"></p><br><p>  Dieser Algorithmus ist bereits in R geschrieben. Wenn Sie möchten, können Sie ihn bereits verwenden.  Die Bibliothek heißt 'pcLasso'. </p><br><h2>  Ein Infinitesimal Jackjack der Schweizer Armee </h2><br><p>  Ryan Giordano (UC Berkeley);  William Stephenson (MIT);  Runjing Liu (UC Berkeley); <br>  Michael Jordan (UC Berkeley);  Tamara Broderick (MIT) </p><br><p>  → <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> <br>  → <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code</a> </p><br><p>  Die Qualität von Algorithmen für maschinelles Lernen wird häufig durch mehrfache Kreuzvalidierung (Kreuzvalidierung oder Bootstrap) gemessen.  Diese Methoden sind leistungsstark, bei großen Datenmengen jedoch langsam. </p><br><p>  In dieser Arbeit verwenden Kollegen die lineare Approximation von Gewichten, um Ergebnisse zu erzielen, die schneller funktionieren.  Diese lineare Näherung ist in der statistischen Literatur als "infinitesimales Klappmesser" bekannt.  Es wird hauptsächlich als theoretisches Instrument zum Nachweis asymptotischer Ergebnisse verwendet.  Die Ergebnisse des Artikels sind unabhängig davon anwendbar, ob die Gewichte und Daten stochastisch oder deterministisch sind.  Infolgedessen schätzt diese Näherung sequentiell die wahre Kreuzvalidierung für jedes feste k. </p><br><p>  <em>Verleihung des Paper Award an den Autor des Artikels</em> <br><img src="https://habrastorage.org/webt/3n/1a/-k/3n1a-kygdmkbs0drfjdg38b9z5g.jpeg"></p><br><p>  <strong>Die Essenz der Methode</strong> </p><br><p>  Betrachten Sie das Problem der Schätzung eines unbekannten Parameters <img src="https://tex.s2cms.ru/svg/%5Ctheta%20%5Cin%20%5COmega_%7B%5Ctheta%7D%20%5Csubset%20R%5E%7BD%7D" alt="\ theta \ in \ Omega _ {\ theta} \ Teilmenge R ^ {D}">  wo <img src="https://tex.s2cms.ru/svg/%5COmega_%7B%5Ctheta%7D%20" alt="\ Omega _ {\ theta}">  Ist kompakt und die Größe unseres Datensatzes ist <img src="https://tex.s2cms.ru/svg/N" alt="N.">  .  Unsere Analyse wird an einem festen Datensatz durchgeführt.  Definieren Sie unsere Bewertung <img src="https://tex.s2cms.ru/svg/%5Ctheta%20%5Cin%20%5COmega_%7B%5Ctheta%7D%20" alt="\ theta \ in \ Omega _ {\ theta}">  wie folgt: </p><br><ol><li>  Für jeden <img src="https://tex.s2cms.ru/svg/n%3D1%2C2%E2%80%A6%2CN" alt="n = 1,2 ..., N.">  einstellen <img src="https://tex.s2cms.ru/svg/g_n" alt="g_n">  ( <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  ) Ist eine Funktion von <img src="https://tex.s2cms.ru/svg/%5COmega_%7B%5Ctheta%7D%20%5Csubset%20R%5E%7BD%7D" alt="\ Omega _ {\ theta} \ Teilmenge R ^ {D}"></li><li><img src="https://tex.s2cms.ru/svg/%5Comega_n%20" alt="\ omega_n">  Ist eine reelle Zahl und <img src="https://tex.s2cms.ru/svg/%5Comega" alt="\ Omega">  Ist ein Vektor bestehend aus <img src="https://tex.s2cms.ru/svg/%5Comega_n" alt="\ omega_n"></li></ol><br><p>  Dann <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D" alt="\ hat {\ theta}">  kann dargestellt werden als: </p><br><p><img src="https://habrastorage.org/webt/zh/ce/yi/zhceyifw80rl6neeoaedkd7x-20.jpeg"></p><br><p>  Wenn wir dieses Optimierungsproblem mit der Gradientenmethode lösen, nehmen wir an, dass die Funktionen differenzierbar sind und wir den Hessischen berechnen können.  Das Hauptproblem, das wir lösen, sind die mit der Bewertung verbundenen Rechenkosten <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D%20%CC%82(%5Comega)" alt="\ hat {\ theta} ̂ (\ omega)">  für alle <img src="https://tex.s2cms.ru/svg/%5Comega%E2%88%88W" alt="\ omega∈W">  .  Der Hauptbeitrag der Autoren des Artikels besteht in der Berechnung der Schätzung <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_1%3D%5Chat%7B%5Ctheta%7D_1%20(1_%7B%5Comega%7D)" alt="\ hat {\ theta} _1 = \ hat {\ theta} _1 (1 _ {\ omega})">  wo <img src="https://tex.s2cms.ru/svg/1_%5Comega%3D(1%2C1%2C%E2%80%A6%2C1)" alt="1_ \ omega = (1,1, ..., 1)">  .  Mit anderen Worten, unsere Optimierung hängt nur von Derivaten ab <img src="https://tex.s2cms.ru/svg/g_n%20(%5Ctheta)" alt="g_n (\ theta)">  von denen wir annehmen, dass sie existieren und hessisch sind: </p><br><p><img src="https://habrastorage.org/webt/tb/zb/t2/tbzbt2u2q_bdqidfjxfl9ywqesc.jpeg"></p><br><p>  Als nächstes definieren wir eine Gleichung mit einem festen Punkt und seiner Ableitung: <br><img src="https://habrastorage.org/webt/hj/8f/x3/hj8fx3broftye-ssmq4mwpkvaui.jpeg"></p><br><p>  Hier lohnt es sich, darauf zu achten <img src="https://tex.s2cms.ru/svg/G(%5Ctheta%20%CC%82(%5Comega)%2Cw)%3D0" alt="G (\ theta ̂ (\ omega), w) = 0">  , als <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D%20(%5Comega)" alt="\ hat {\ theta} (\ omega)">  - Lösung für <img src="https://tex.s2cms.ru/svg/%5Cfrac%7B%201%20%7D%7B%20N%20%7D%20%5Csum_%7Bn%3D1%7D%5E%7BN%7D%20%5Comega_n%20g_n%20(%5Ctheta)%3D0" alt="\ frac {1} {N} \ sum_ {n = 1} ^ {N} \ omega_n g_n (\ theta) = 0">  .  Wir definieren auch: <img src="https://tex.s2cms.ru/svg/H_1%3DH(%5Chat%7B%5Ctheta%7D_1%2C1_%5Comega)" alt="H_1 = H (\ hat {\ theta} _1,1_ \ omega)">  und die Matrix der Gewichte als: <img src="https://tex.s2cms.ru/svg/%5CDelta%5Comega%3D%20%5Comega-1_%5Comega%20%5Cin%20R%5E%7Bn%7D" alt="\ Delta \ omega = \ omega-1_ \ omega \ in R ^ {n}">  .  In dem Fall, wenn <img src="https://tex.s2cms.ru/svg/H_1" alt="H_1">  hat eine inverse Matrix, können wir den impliziten Funktionssatz und die 'Kettenregel' verwenden: </p><br><p><img src="https://habrastorage.org/webt/c7/iv/x2/c7ivx2dadeupxwlo2hzgmxslrxe.jpeg"></p><br><p>  Diese Ableitung ermöglicht es uns, eine lineare Näherung zu bilden <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D%20%CC%82(%5Comega)" alt="\ hat {\ theta} ̂ (\ omega)">  durch <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_1" alt="\ hat {\ theta} _1">  das sieht so aus: </p><br><p><img src="https://habrastorage.org/webt/lc/rc/5h/lcrc5hirn1act9jl8lp2jakjpsk.jpeg"></p><br><p>  Als <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_%7BIJ%7D" alt="\ hat {\ theta} _ {IJ}">  hängt nur ab von <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_1" alt="\ hat {\ theta} _1">  und <img src="https://tex.s2cms.ru/svg/%5CDelta%20%5Comega" alt="\ Delta \ Omega">  und nicht aus Lösungen für andere Werte <img src="https://tex.s2cms.ru/svg/%5Comega" alt="\ Omega">  Dementsprechend besteht keine Notwendigkeit, neue Werte von &amp; ohgr; neu zu berechnen und zu finden.  Stattdessen muss man das SLE (System linearer Gleichungen) lösen. </p><br><p>  <strong>Ergebnisse</strong> </p><br><p>  In der Praxis reduziert dies die Zeit im Vergleich zur Kreuzvalidierung erheblich: <br><img src="https://habrastorage.org/webt/sw/dr/6-/swdr6-j8t7pqcdwf_96705qs1tg.jpeg"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458388/">https://habr.com/ru/post/de458388/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458374/index.html">TJBOT als Beispiel für IBM Watson-Services</a></li>
<li><a href="../de458376/index.html">Keine andere Programmiersprache. Teil 1: Domänenlogik</a></li>
<li><a href="../de458378/index.html">Verwenden von Avocode für das Site-Layout. Bewertung für Anfänger. Bonus - Registrieren Sie eine 30-tägige Testphase</a></li>
<li><a href="../de458382/index.html">Warum unterrichten wir das?</a></li>
<li><a href="../de458384/index.html">HP 3D Strukturierter Lichtscanner Pro S3 Überprüfung und Test</a></li>
<li><a href="../de458390/index.html">Ceph - von "auf dem Knie" bis "Produktion" Teil 2</a></li>
<li><a href="../de458400/index.html">Microservices-Architektur und -Implementierung Schritt für Schritt Teil 1</a></li>
<li><a href="../de458404/index.html">Übergang vom Monolithen zum Mikrodienst: Geschichte und Praxis</a></li>
<li><a href="../de458406/index.html">Über 30 Fragen zu Dienstprogrammen und Nicht-Dienstprogrammen</a></li>
<li><a href="../de458408/index.html">Sicherheitswoche 27: Sicherheitslücken in der Insulinpumpe</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
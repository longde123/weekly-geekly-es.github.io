<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéõÔ∏è üëêüèº üéÅ Deep (Learning + Random) Wald- und Artikelanalyse üçà ‚õπüèΩ üåæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir sprechen weiterhin √ºber die Konferenz zu Statistik und maschinellem Lernen AISTATS 2019. In diesem Beitrag werden wir Artikel √ºber Tiefenmodelle a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Deep (Learning + Random) Wald- und Artikelanalyse</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ru_mts/blog/458388/"><p>  Wir sprechen weiterhin √ºber die Konferenz zu Statistik und maschinellem Lernen AISTATS 2019. In diesem Beitrag werden wir Artikel √ºber Tiefenmodelle aus Baumensembles analysieren, Regularisierung f√ºr sehr sp√§rliche Daten mischen und zeiteffiziente Ann√§herung an die Kreuzvalidierung. </p><br><p><img src="https://habrastorage.org/webt/n-/uv/xj/n-uvxjud1se0puoearqtlott2de.jpeg"></p><a name="habracut"></a><br><h2 id="algoritm-glubokiy-les-an-exploration-to-non-nn-deep-models-based-on-non-differentiable-modules">  Deep Forest-Algorithmus: Eine Untersuchung von Nicht-NN-Tiefenmodellen basierend auf nicht differenzierbaren Modulen </h2><br><p>  Zhi-Hua Zhou (Universit√§t Nanjing) <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pr√§sentation</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> <br>  Implementierungen - unten </p><br><p>  Ein Professor aus China sprach √ºber das Baumensemble, das die Autoren als erstes tiefes Training f√ºr nicht differenzierbare Module bezeichnen.  Dies mag wie eine zu laute Aussage erscheinen, aber dieser Professor und sein H-Index 95 sind eingeladene Redner. Diese Tatsache erm√∂glicht es uns, die Aussage ernster zu nehmen.  Die grundlegende Theorie von Deep Forest wurde f√ºr eine lange Zeit entwickelt, der urspr√ºngliche Artikel ist bereits 2017 (fast 200 Zitate), aber die Autoren schreiben Bibliotheken und jedes Jahr verbessern sie den Algorithmus in der Geschwindigkeit.  Und jetzt, so scheint es, haben sie den Punkt erreicht, an dem diese sch√∂ne Theorie endlich in die Praxis umgesetzt werden kann. </p><br><p>  <em>Gesamtansicht der Tiefwaldarchitektur</em> <br><img src="https://habrastorage.org/webt/4k/7q/1q/4k7q1qlzs5rixw4itr5luctdpuq.jpeg"></p><br><p>  <strong>Hintergrund</strong> </p><br><p>  Tiefe Modelle, die heute als tiefe neuronale Netze verstanden werden, werden verwendet, um komplexe Datenabh√§ngigkeiten zu erfassen.  Dar√ºber hinaus stellte sich heraus, dass das Erh√∂hen der Anzahl von Schichten effizienter ist als das Erh√∂hen der Anzahl von Einheiten auf jeder Schicht.  Neuronale Netze haben jedoch ihre Nachteile: </p><br><ul><li>  Es braucht viele Daten, um nicht umzuschulen, </li><li>  Es erfordert eine Menge Rechenressourcen, um in angemessener Zeit zu lernen. </li><li>  Zu viele Hyperparameter, die sich nur schwer optimal konfigurieren lassen </li></ul><br><p>  Dar√ºber hinaus sind Elemente tiefer neuronaler Netze differenzierbare Module, die nicht unbedingt f√ºr jede Aufgabe wirksam sind.  Trotz der Komplexit√§t neuronaler Netze funktionieren konzeptionell einfache Algorithmen wie eine zuf√§llige Gesamtstruktur oft besser oder nicht viel schlechter.  F√ºr solche Algorithmen m√ºssen Sie jedoch Features manuell entwerfen, was auch schwierig optimal zu tun ist. </p><br><p>  Forscher haben bereits festgestellt, dass die Ensembles auf Kaggle: ‚Äûsehr perfekt‚Äú sind. Inspiriert von den Worten von Scholl und Hinton, dass Differenzierung die schw√§chste Seite von Deep Learning ist, haben sie beschlossen, ein Ensemble von B√§umen mit DL-Eigenschaften zu erstellen. </p><br><p>  <em>Folie ‚ÄûWie man ein gutes Ensemble macht‚Äú</em> <br><img src="https://habrastorage.org/webt/8w/cb/z9/8wcbz9ml-7qidb5ii4-meqcinec.jpeg"></p><br><p>  Die Architektur wurde aus den Eigenschaften der Ensembles abgeleitet: Die Elemente der Ensembles sollten nicht von sehr schlechter Qualit√§t sein und sich unterscheiden. </p><br><p>  GcForest besteht aus zwei Phasen: Cascade Forest und Multi-Grained Scanning.  Damit die Kaskade nicht umgeschult wird, besteht sie au√üerdem aus zwei Baumarten - von denen eine absolut zuf√§llige B√§ume sind, die f√ºr nicht zugewiesene Daten verwendet werden k√∂nnen.  Die Anzahl der Schichten wird innerhalb des Kreuzvalidierungsalgorithmus bestimmt. <br><img src="https://habrastorage.org/webt/qv/co/-b/qvco-br5vregwj-rrxn3bxnyfeq.jpeg"></p><br><p>  <em>Zwei Arten von B√§umen</em> <br><img src="https://habrastorage.org/webt/mc/kp/ia/mckpiaiavjyh9hawcxhvtbusego.jpeg"></p><br><p>  <strong>Ergebnisse</strong> </p><br><p>  Zus√§tzlich zu den Ergebnissen f√ºr Standarddatens√§tze versuchten die Autoren, gcForest f√ºr Transaktionen des chinesischen Zahlungssystems zu verwenden, um nach Betrug zu suchen, und erzielten F1 und AUC viel h√∂her als die von LR und DNN.  Diese Ergebnisse sind nur in der Pr√§sentation enthalten, aber der Code, der f√ºr einige Standarddatens√§tze ausgef√ºhrt werden soll, befindet sich auf Git. </p><br><p><img src="https://habrastorage.org/webt/y3/kf/gy/y3kfgytp_qawqyskwmvrrumzdna.jpeg"></p><br><p>  <em>Ergebnisse der Algorithmusersetzung.</em>  <em>mdDF ist die optimale Margin Distribution Deep Forest, eine Variante von gcForest</em> </p><br><p><img src="https://habrastorage.org/webt/e1/oh/wq/e1ohwqrilda60nmdnosaa_ye4yk.jpeg"></p><br><p>  Vorteile: </p><br><ul><li>  Bei wenigen Hyperparametern wird die Anzahl der Ebenen innerhalb des Algorithmus automatisch angepasst </li><li>  Die Standardeinstellungen sind so gew√§hlt, dass sie bei vielen Aufgaben gut funktionieren. </li><li>  Adaptive Komplexit√§t des Modells f√ºr kleine Daten - ein kleines Modell </li><li>  Keine Notwendigkeit, Funktionen einzustellen </li><li>  Es funktioniert qualitativ vergleichbar mit tiefen neuronalen Netzen und manchmal besser </li></ul><br><p>  Nachteile: </p><br><ul><li>  Nicht auf GPU beschleunigt </li><li>  In den Bildern verliert DNNs </li></ul><br><p>  Neuronale Netze haben ein Problem mit der Gradientend√§mpfung, w√§hrend tiefe W√§lder ein Problem mit dem Verschwinden der Vielfalt haben.  Da es sich um ein Ensemble handelt, ist die Qualit√§t umso h√∂her, je mehr ‚Äûunterschiedliche‚Äú und ‚Äûgute‚Äú Elemente verwendet werden.  Das Problem ist, dass die Autoren bereits fast alle klassischen Ans√§tze (Stichproben, Randomisierung) ausprobiert haben.  Solange keine neue Grundlagenforschung zum Thema ‚ÄûUnterschiede‚Äú erscheint, wird es schwierig sein, die Qualit√§t tiefer W√§lder zu verbessern.  Jetzt ist es jedoch m√∂glich, die Rechengeschwindigkeit zu verbessern. </p><br><p>  <strong>Reproduzierbarkeit der Ergebnisse</strong> </p><br><p>  Ich war von XGBoost in Bezug auf die Tabellendaten fasziniert und wollte das Ergebnis reproduzieren.  Ich nahm das Adults-Dataset und wandte GcForestCS (eine leicht beschleunigte Version von GcForest) mit Parametern der Autoren des Artikels und XGBoost mit Standardparametern an.  In dem Beispiel, das die Autoren hatten, wurden kategoriale Merkmale bereits irgendwie vorverarbeitet, aber es wurde nicht angegeben, wie.  Als Ergebnis habe ich CatBoostEncoder und eine andere Metrik verwendet - ROC AUC.  Die Ergebnisse waren statistisch unterschiedlich - XGBoost gewann.  Die Betriebszeit von XGBoost ist vernachl√§ssigbar, w√§hrend gcForestCS 20 Minuten jeder Kreuzvalidierung mit 5 Falten hat.  Andererseits haben die Autoren den Algorithmus an verschiedenen Datens√§tzen getestet und die Parameter f√ºr diesen Datensatz an ihre Feature-Vorverarbeitung angepasst. </p><br><p>  Den Code finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . </p><br><p>  <strong>Implementierungen</strong> </p><br><p>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der offizielle Code der Autoren des Artikels</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Offizielle verbesserte √Ñnderung, schneller, aber keine Dokumentation</a> <br>  ‚Üí Die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Implementierung ist einfacher</a> </p><br><h2 id="pclasso-the-lasso-meets-principal-components-regression">  PcLasso: Das Lasso erf√ºllt die Regression der Hauptkomponenten </h2><br><p>  J. Kenneth Tay, Jerome Friedman, Robert Tibshirani (Stanford University) </p><br><p>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pr√§sentation</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anwendungsbeispiel</a> </p><br><p>  Anfang 2019 schlugen J. Kenneth Tay, Jerome Friedman und Robert Tibshirani von der Stanford University eine neue Unterrichtsmethode mit einem Lehrer vor, die besonders f√ºr sp√§rliche Daten geeignet ist. </p><br><p>  Die Autoren des Artikels l√∂sten das Problem der Analyse von Daten zu Genexpressionsstudien, die in Zeng &amp; Breesy (2016) beschrieben sind.  Ziel ist der Mutationsstatus des p53-Gens, der die Genexpression als Reaktion auf verschiedene Signale von zellul√§rem Stress reguliert.  Ziel der Studie ist es, Pr√§diktoren zu identifizieren, die mit dem Mutationsstatus von p53 korrelieren.  Die Daten bestehen aus 50 Zeilen, von denen 17 als normal klassifiziert sind und die restlichen 33 Mutationen im p53-Gen tragen.  Nach einer Analyse von Subramanian et al.  (2005) 308 S√§tze von Genen zwischen 15 und 500 sind in dieser Analyse enthalten.  Diese Gen-Kits enthalten insgesamt 4.301 Gene und sind im Paket grpregOverlap R verf√ºgbar.  Beim Erweitern von Daten zur Verarbeitung √ºberlappender Gruppen werden 13.237 Spalten ausgegeben.  Die Autoren des Artikels verwendeten die pcLasso-Methode, die zur Verbesserung der Modellergebnisse beitrug. </p><br><p>  <em>Im Bild sehen wir einen Anstieg der AUC bei Verwendung von "pcLasso"</em> <br><img src="https://habrastorage.org/webt/ok/p6/mg/okp6mgex-l9p49vcz5gedg8xa5o.jpeg"></p><br><p>  <strong>Die Essenz der Methode</strong> </p><br><p>  Methode kombiniert <img src="https://tex.s2cms.ru/svg/l_1" alt="l_1">  -regelm√§√üigkeit mit <img src="https://tex.s2cms.ru/svg/l_2" alt="l_2">  , wodurch der Koeffizientenvektor auf die Hauptkomponenten der Merkmalsmatrix eingegrenzt wird.  Sie nannten die vorgeschlagene Methode "Kern-Lasso-Komponenten" ("pcLasso" auf R verf√ºgbar).  Die Methode kann besonders leistungsf√§hig sein, wenn die Variablen zuvor gruppiert wurden (der Benutzer w√§hlt aus, was und wie gruppiert werden soll).  In diesem Fall komprimiert pcLasso jede Gruppe und erh√§lt die L√∂sung in Richtung der Hauptkomponenten dieser Gruppe.  W√§hrend des L√∂sungsprozesses wird auch die Auswahl signifikanter Gruppen unter den verf√ºgbaren durchgef√ºhrt. </p><br><p>  Wir pr√§sentieren die diagonale Matrix der singul√§ren Zerlegung einer zentrierten Matrix von Merkmalen <img src="https://tex.s2cms.ru/svg/X" alt="X.">  wie folgt: </p><br><p>  Wir repr√§sentieren unsere singul√§re Zerlegung der zentrierten Matrix X (SVD) als <img src="https://tex.s2cms.ru/svg/X%3DUDV%5ET" alt="X = UDV ^ T.">  wo <img src="https://tex.s2cms.ru/svg/D" alt="D.">  Ist eine Diagonalmatrix, die aus singul√§ren Werten besteht.  In dieser Form <img src="https://tex.s2cms.ru/svg/l_2" alt="l_2">  - Regularisierung kann dargestellt werden: <br><img src="https://tex.s2cms.ru/svg/%5Cbeta%5ET%20VZV%5ET%20%5Cbeta" alt="\ beta ^ T VZV ^ T \ beta">  wo <img src="https://tex.s2cms.ru/svg/Z" alt="Z.">  - Diagonalmatrix mit der Funktion von Quadraten singul√§rer Werte: <img src="https://tex.s2cms.ru/svg/Z_%7B11%7D%3Df_1%20(d_1%5E2%2Cd_2%5E2%2C%E2%80%A6%2Cd_m%5E2%20)%2C%E2%80%A6%2CZ_%7B22%7D%3Df_2%20(d_1%5E2%2Cd_2%5E2%2C%E2%80%A6%2Cd_m%5E2%20)" alt="Z_ {11} = f_1 (d_1 ^ 2, d_2 ^ 2, ..., d_m ^ 2), ..., Z_ {22} = f_2 (d_1 ^ 2, d_2 ^ 2, ..., d_m ^ 2)">  . </p><br><p>  Im Allgemeinen in <img src="https://tex.s2cms.ru/svg/l_2" alt="l_2">  -regelm√§√üigkeit <img src="https://tex.s2cms.ru/svg/Z_%7Bjj%7D%3D1" alt="Z_ {jj} = 1">  f√ºr alle <img src="https://tex.s2cms.ru/svg/j" alt="j">  das entspricht <img src="https://tex.s2cms.ru/svg/%5Cbeta%5ET%20%5Cbeta" alt="\ beta ^ T \ beta">  .  Sie schlagen vor, die folgenden Funktionen zu minimieren: </p><br><p><img src="https://habrastorage.org/webt/6l/fj/lv/6lfjlv9m-zy8qfhcvrcqcymuuxa.jpeg"></p><br><p>  Hier <img src="https://tex.s2cms.ru/svg/D" alt="D.">  - Matrix der Unterschiede der diagonalen Elemente <img src="https://tex.s2cms.ru/svg/d_1%5E2-d_1%5E2%2Cd_1%5E2-d_2%5E2%2C%E2%80%A6%2Cd_1%5E2-d_m%5E2" alt="d_1 ^ 2-d_1 ^ 2, d_1 ^ 2-d_2 ^ 2, ..., d_1 ^ 2-d_m ^ 2">  .  Mit anderen Worten, wir steuern den Vektor <img src="https://tex.s2cms.ru/svg/%5Cbeta%20" alt="\ beta">  auch mit Hyperparameter <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  . <br>  Wenn wir diesen Ausdruck transformieren, erhalten wir die L√∂sung: </p><br><p><img src="https://habrastorage.org/webt/vf/qs/6b/vfqs6b8fnqo3bmlacyr5j4fpigs.jpeg"></p><br><p>  Das Hauptmerkmal der Methode ist nat√ºrlich die F√§higkeit, Daten zu gruppieren und auf der Grundlage dieser Gruppen die Hauptkomponenten der Gruppe hervorzuheben.  Dann schreiben wir unsere L√∂sung in der Form um: </p><br><p><img src="https://habrastorage.org/webt/9l/ij/wc/9lijwc3_kvwtvxalszzyt4zq4l4.jpeg"></p><br><p>  Hier <img src="https://tex.s2cms.ru/svg/%5Cbeta_k" alt="\ beta_k">  - Vektorsubvektor <img src="https://tex.s2cms.ru/svg/%5Cbeta" alt="\ beta">  entsprechend der Gruppe k, <img src="https://tex.s2cms.ru/svg/d_k%3D(d_%7Bk1%7D%2C%E2%80%A6%2Cd_%7Bkmk%7D)" alt="d_k = (d_ {k1}, ..., d_ {kmk})">  - singul√§re Werte <img src="https://tex.s2cms.ru/svg/X_k" alt="X_k">  in absteigender Reihenfolge angeordnet, und <img src="https://tex.s2cms.ru/svg/D_%7Bd_%7Bk1%7D%5E2-d_%7Bkj%7D%5E2%7D" alt="D_ {d_ {k1} ^ 2-d_ {kj} ^ 2}">  - Diagonalmatrix <img src="https://tex.s2cms.ru/svg/d_%7Bk1%7D%5E2-d_%7Bkj%7D%5E2%2C%20j%3D1%2C2%2C%E2%80%A6%2Cm_k" alt="d_ {k1} ^ 2-d_ {kj} ^ 2, j = 1,2, ..., m_k"></p><br><p>  Einige Hinweise zur L√∂sung der Zielfunktion: </p><br><ol><li><p>  Die Zielfunktion ist konvex und die nicht glatte Komponente ist trennbar.  Daher kann es unter Verwendung eines Gradientenabfalls effektiv optimiert werden. <br>  Der Ansatz besteht darin, mehrere Werte festzuschreiben <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  (einschlie√ülich Null, um den Standard zu erhalten <img src="https://tex.s2cms.ru/svg/l_1" alt="l_1">  -regelm√§√üigkeit) und dann optimieren: <img src="https://habrastorage.org/webt/uz/bf/eo/uzbfeori9kupj8b05x46dcj6iri.jpeg">  abholen <img src="https://tex.s2cms.ru/svg/%5Clambda" alt="\ lambda">  .  Dementsprechend sind die Parameter <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  und <img src="https://tex.s2cms.ru/svg/%5Clambda" alt="\ lambda">  werden zur Kreuzvalidierung ausgew√§hlt. </p><br></li><li><p>  Parameter <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  schwer zu interpretieren.  In der Software (pcLasso-Paket) legt der Benutzer den Wert dieses Parameters fest, der zum Intervall [0,1] geh√∂rt, wobei 1 entspricht <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  = 0 (Lasso). </p><br></li></ol><br><p>  In der Praxis variieren die Werte <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  = 0,25, 0,5, 0,75, 0,9, 0,95 und 1 k√∂nnen Sie eine breite Palette von Modellen abdecken. </p><br><p>  <em>Der Algorithmus selbst ist wie folgt</em> <br><img src="https://habrastorage.org/webt/l-/3x/si/l-3xsipork2hzeh7ws1bg1hz86o.jpeg"></p><br><p>  Dieser Algorithmus ist bereits in R geschrieben. Wenn Sie m√∂chten, k√∂nnen Sie ihn bereits verwenden.  Die Bibliothek hei√üt 'pcLasso'. </p><br><h2>  Ein Infinitesimal Jackjack der Schweizer Armee </h2><br><p>  Ryan Giordano (UC Berkeley);  William Stephenson (MIT);  Runjing Liu (UC Berkeley); <br>  Michael Jordan (UC Berkeley);  Tamara Broderick (MIT) </p><br><p>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code</a> </p><br><p>  Die Qualit√§t von Algorithmen f√ºr maschinelles Lernen wird h√§ufig durch mehrfache Kreuzvalidierung (Kreuzvalidierung oder Bootstrap) gemessen.  Diese Methoden sind leistungsstark, bei gro√üen Datenmengen jedoch langsam. </p><br><p>  In dieser Arbeit verwenden Kollegen die lineare Approximation von Gewichten, um Ergebnisse zu erzielen, die schneller funktionieren.  Diese lineare N√§herung ist in der statistischen Literatur als "infinitesimales Klappmesser" bekannt.  Es wird haupts√§chlich als theoretisches Instrument zum Nachweis asymptotischer Ergebnisse verwendet.  Die Ergebnisse des Artikels sind unabh√§ngig davon anwendbar, ob die Gewichte und Daten stochastisch oder deterministisch sind.  Infolgedessen sch√§tzt diese N√§herung sequentiell die wahre Kreuzvalidierung f√ºr jedes feste k. </p><br><p>  <em>Verleihung des Paper Award an den Autor des Artikels</em> <br><img src="https://habrastorage.org/webt/3n/1a/-k/3n1a-kygdmkbs0drfjdg38b9z5g.jpeg"></p><br><p>  <strong>Die Essenz der Methode</strong> </p><br><p>  Betrachten Sie das Problem der Sch√§tzung eines unbekannten Parameters <img src="https://tex.s2cms.ru/svg/%5Ctheta%20%5Cin%20%5COmega_%7B%5Ctheta%7D%20%5Csubset%20R%5E%7BD%7D" alt="\ theta \ in \ Omega _ {\ theta} \ Teilmenge R ^ {D}">  wo <img src="https://tex.s2cms.ru/svg/%5COmega_%7B%5Ctheta%7D%20" alt="\ Omega _ {\ theta}">  Ist kompakt und die Gr√∂√üe unseres Datensatzes ist <img src="https://tex.s2cms.ru/svg/N" alt="N.">  .  Unsere Analyse wird an einem festen Datensatz durchgef√ºhrt.  Definieren Sie unsere Bewertung <img src="https://tex.s2cms.ru/svg/%5Ctheta%20%5Cin%20%5COmega_%7B%5Ctheta%7D%20" alt="\ theta \ in \ Omega _ {\ theta}">  wie folgt: </p><br><ol><li>  F√ºr jeden <img src="https://tex.s2cms.ru/svg/n%3D1%2C2%E2%80%A6%2CN" alt="n = 1,2 ..., N.">  einstellen <img src="https://tex.s2cms.ru/svg/g_n" alt="g_n">  ( <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ Theta">  ) Ist eine Funktion von <img src="https://tex.s2cms.ru/svg/%5COmega_%7B%5Ctheta%7D%20%5Csubset%20R%5E%7BD%7D" alt="\ Omega _ {\ theta} \ Teilmenge R ^ {D}"></li><li><img src="https://tex.s2cms.ru/svg/%5Comega_n%20" alt="\ omega_n">  Ist eine reelle Zahl und <img src="https://tex.s2cms.ru/svg/%5Comega" alt="\ Omega">  Ist ein Vektor bestehend aus <img src="https://tex.s2cms.ru/svg/%5Comega_n" alt="\ omega_n"></li></ol><br><p>  Dann <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D" alt="\ hat {\ theta}">  kann dargestellt werden als: </p><br><p><img src="https://habrastorage.org/webt/zh/ce/yi/zhceyifw80rl6neeoaedkd7x-20.jpeg"></p><br><p>  Wenn wir dieses Optimierungsproblem mit der Gradientenmethode l√∂sen, nehmen wir an, dass die Funktionen differenzierbar sind und wir den Hessischen berechnen k√∂nnen.  Das Hauptproblem, das wir l√∂sen, sind die mit der Bewertung verbundenen Rechenkosten <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D%20%CC%82(%5Comega)" alt="\ hat {\ theta} ÃÇ (\ omega)">  f√ºr alle <img src="https://tex.s2cms.ru/svg/%5Comega%E2%88%88W" alt="\ omega‚ààW">  .  Der Hauptbeitrag der Autoren des Artikels besteht in der Berechnung der Sch√§tzung <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_1%3D%5Chat%7B%5Ctheta%7D_1%20(1_%7B%5Comega%7D)" alt="\ hat {\ theta} _1 = \ hat {\ theta} _1 (1 _ {\ omega})">  wo <img src="https://tex.s2cms.ru/svg/1_%5Comega%3D(1%2C1%2C%E2%80%A6%2C1)" alt="1_ \ omega = (1,1, ..., 1)">  .  Mit anderen Worten, unsere Optimierung h√§ngt nur von Derivaten ab <img src="https://tex.s2cms.ru/svg/g_n%20(%5Ctheta)" alt="g_n (\ theta)">  von denen wir annehmen, dass sie existieren und hessisch sind: </p><br><p><img src="https://habrastorage.org/webt/tb/zb/t2/tbzbt2u2q_bdqidfjxfl9ywqesc.jpeg"></p><br><p>  Als n√§chstes definieren wir eine Gleichung mit einem festen Punkt und seiner Ableitung: <br><img src="https://habrastorage.org/webt/hj/8f/x3/hj8fx3broftye-ssmq4mwpkvaui.jpeg"></p><br><p>  Hier lohnt es sich, darauf zu achten <img src="https://tex.s2cms.ru/svg/G(%5Ctheta%20%CC%82(%5Comega)%2Cw)%3D0" alt="G (\ theta ÃÇ (\ omega), w) = 0">  , als <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D%20(%5Comega)" alt="\ hat {\ theta} (\ omega)">  - L√∂sung f√ºr <img src="https://tex.s2cms.ru/svg/%5Cfrac%7B%201%20%7D%7B%20N%20%7D%20%5Csum_%7Bn%3D1%7D%5E%7BN%7D%20%5Comega_n%20g_n%20(%5Ctheta)%3D0" alt="\ frac {1} {N} \ sum_ {n = 1} ^ {N} \ omega_n g_n (\ theta) = 0">  .  Wir definieren auch: <img src="https://tex.s2cms.ru/svg/H_1%3DH(%5Chat%7B%5Ctheta%7D_1%2C1_%5Comega)" alt="H_1 = H (\ hat {\ theta} _1,1_ \ omega)">  und die Matrix der Gewichte als: <img src="https://tex.s2cms.ru/svg/%5CDelta%5Comega%3D%20%5Comega-1_%5Comega%20%5Cin%20R%5E%7Bn%7D" alt="\ Delta \ omega = \ omega-1_ \ omega \ in R ^ {n}">  .  In dem Fall, wenn <img src="https://tex.s2cms.ru/svg/H_1" alt="H_1">  hat eine inverse Matrix, k√∂nnen wir den impliziten Funktionssatz und die 'Kettenregel' verwenden: </p><br><p><img src="https://habrastorage.org/webt/c7/iv/x2/c7ivx2dadeupxwlo2hzgmxslrxe.jpeg"></p><br><p>  Diese Ableitung erm√∂glicht es uns, eine lineare N√§herung zu bilden <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D%20%CC%82(%5Comega)" alt="\ hat {\ theta} ÃÇ (\ omega)">  durch <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_1" alt="\ hat {\ theta} _1">  das sieht so aus: </p><br><p><img src="https://habrastorage.org/webt/lc/rc/5h/lcrc5hirn1act9jl8lp2jakjpsk.jpeg"></p><br><p>  Als <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_%7BIJ%7D" alt="\ hat {\ theta} _ {IJ}">  h√§ngt nur ab von <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_1" alt="\ hat {\ theta} _1">  und <img src="https://tex.s2cms.ru/svg/%5CDelta%20%5Comega" alt="\ Delta \ Omega">  und nicht aus L√∂sungen f√ºr andere Werte <img src="https://tex.s2cms.ru/svg/%5Comega" alt="\ Omega">  Dementsprechend besteht keine Notwendigkeit, neue Werte von &amp; ohgr; neu zu berechnen und zu finden.  Stattdessen muss man das SLE (System linearer Gleichungen) l√∂sen. </p><br><p>  <strong>Ergebnisse</strong> </p><br><p>  In der Praxis reduziert dies die Zeit im Vergleich zur Kreuzvalidierung erheblich: <br><img src="https://habrastorage.org/webt/sw/dr/6-/swdr6-j8t7pqcdwf_96705qs1tg.jpeg"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458388/">https://habr.com/ru/post/de458388/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458374/index.html">TJBOT als Beispiel f√ºr IBM Watson-Services</a></li>
<li><a href="../de458376/index.html">Keine andere Programmiersprache. Teil 1: Dom√§nenlogik</a></li>
<li><a href="../de458378/index.html">Verwenden von Avocode f√ºr das Site-Layout. Bewertung f√ºr Anf√§nger. Bonus - Registrieren Sie eine 30-t√§gige Testphase</a></li>
<li><a href="../de458382/index.html">Warum unterrichten wir das?</a></li>
<li><a href="../de458384/index.html">HP 3D Strukturierter Lichtscanner Pro S3 √úberpr√ºfung und Test</a></li>
<li><a href="../de458390/index.html">Ceph - von "auf dem Knie" bis "Produktion" Teil 2</a></li>
<li><a href="../de458400/index.html">Microservices-Architektur und -Implementierung Schritt f√ºr Schritt Teil 1</a></li>
<li><a href="../de458404/index.html">√úbergang vom Monolithen zum Mikrodienst: Geschichte und Praxis</a></li>
<li><a href="../de458406/index.html">√úber 30 Fragen zu Dienstprogrammen und Nicht-Dienstprogrammen</a></li>
<li><a href="../de458408/index.html">Sicherheitswoche 27: Sicherheitsl√ºcken in der Insulinpumpe</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
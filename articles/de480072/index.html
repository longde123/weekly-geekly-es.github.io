<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêÜ üë©üèΩ‚Äçüåæ ‚è© Kubernetes: Warum ist es so wichtig, ein Systemressourcenmanagement einzurichten? üò∑ ‚òÄÔ∏è üëéüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In der Regel muss jeder Anwendung immer ein dedizierter Ressourcenpool zur Verf√ºgung gestellt werden, damit sie ordnungsgem√§√ü und stabil funktioniert....">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kubernetes: Warum ist es so wichtig, ein Systemressourcenmanagement einzurichten?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nixys/blog/480072/"><p>  In der Regel muss jeder Anwendung immer ein dedizierter Ressourcenpool zur Verf√ºgung gestellt werden, damit sie ordnungsgem√§√ü und stabil funktioniert.  Was aber, wenn mehrere Anwendungen gleichzeitig mit derselben Kapazit√§t arbeiten?  Wie kann man die minimal notwendigen Ressourcen f√ºr jeden von ihnen bereitstellen?  Wie kann ich den Ressourcenverbrauch begrenzen?  Wie verteile ich die Last richtig auf die Knoten?  Wie kann der Mechanismus der horizontalen Skalierung bei erh√∂hter Belastung der Anwendung sichergestellt werden? </p><br><p><img src="https://habrastorage.org/webt/-f/yj/hw/-fyjhwhkhcibnshgzndgd4w4e_c.png"></p><a name="habracut"></a><br><p>  Sie m√ºssen damit beginnen, welche grundlegenden Arten von Ressourcen im System vorhanden sind - nat√ºrlich Prozessorzeit und RAM.  In k8s-Manifesten werden diese Ressourcentypen in den folgenden Einheiten gemessen: </p><br><ul><li>  CPU - in den Kernen </li><li>  RAM - in Bytes </li></ul><br><p>  Dar√ºber hinaus gibt es f√ºr jede Ressource die M√∂glichkeit, zwei Arten von Anforderungen festzulegen - <strong>Anforderungen</strong> und <strong>Grenzwerte</strong> .  Anforderungen - beschreibt die Mindestanforderungen an die freien Ressourcen des Knotens zum Ausf√ºhren des Containers (und des Herds im Allgemeinen), w√§hrend Grenzwerte eine strikte Begrenzung der f√ºr den Container verf√ºgbaren Ressourcen festlegen. </p><br><p>  Es ist wichtig zu verstehen, dass es im Manifest nicht erforderlich ist, beide Typen explizit zu definieren. Das Verhalten ist wie folgt: </p><br><ul><li>  Wenn nur die Grenzwerte der Ressource explizit festgelegt werden, erhalten Anforderungen f√ºr diese Ressource automatisch einen Wert, der den Grenzwerten entspricht (dies kann durch Aufrufen von describe entitys √ºberpr√ºft werden).  Das hei√üt  Tats√§chlich wird der Betrieb des Containers durch dieselbe Menge an Ressourcen begrenzt, die f√ºr die Ausf√ºhrung erforderlich sind. </li><li>  Wenn nur Anforderungen explizit f√ºr eine Ressource festgelegt werden, werden keine Einschr√§nkungen f√ºr diese Ressource festgelegt - d. H.  Der Container ist nur durch die Ressourcen des Knotens selbst begrenzt. </li></ul><br><p>  Es ist auch m√∂glich, die Ressourcenverwaltung nicht nur auf der Ebene eines bestimmten Containers, sondern auch auf der Namespace-Ebene mithilfe der folgenden Entit√§ten zu konfigurieren: </p><br><ul><li>  <strong>LimitRange</strong> - beschreibt die Einschr√§nkungsrichtlinie auf Container- / <strong>Herdebene</strong> in ns und wird ben√∂tigt, um die Standardeinschr√§nkungen f√ºr den Container / Herd zu beschreiben sowie die Erzeugung offensichtlich fetter Container / Herde (oder umgekehrt) zu verhindern, deren Anzahl zu begrenzen und m√∂gliche Wertunterschiede innerhalb von Grenzen zu ermitteln und Anfragen </li><li>  <strong>ResourceQuotas</strong> - Beschreibt die Einschr√§nkungsrichtlinie im Allgemeinen f√ºr alle Container in ns und wird in der Regel zum Abgrenzen von Ressourcen zwischen Umgebungen verwendet (n√ºtzlich, wenn Umgebungen auf Knotenebene nicht starr abgegrenzt sind). </li></ul><br><p>  Im Folgenden finden Sie Beispiele f√ºr Manifeste, f√ºr die Ressourcenlimits festgelegt sind: </p><br><ul><li><p>  Auf der spezifischen Containerebene: </p><br><pre><code class="plaintext hljs">containers: - name: app-nginx image: nginx resources: requests: memory: 1Gi limits: cpu: 200m</code> </pre> <br><p>  Das hei√üt  In diesem Fall ben√∂tigen Sie zum Starten eines Containers mit nginx mindestens das Vorhandensein von freiem 1G-OP und 0,2 CPU auf dem Knoten, w√§hrend der maximale Container 0,2 CPU und alle verf√ºgbaren OP auf dem Knoten aufnehmen kann. </p><br></li><li><p>  Auf ganzzahliger Ebene ns: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: ResourceQuota metadata: name: nxs-test spec: hard: requests.cpu: 300m requests.memory: 1Gi limits.cpu: 700m limits.memory: 2Gi</code> </pre> <br><p>  Das hei√üt  Die Summe aller Anforderungscontainer in der Standardeinstellung ns darf 300 m f√ºr die CPU und 1 G f√ºr das OP nicht √ºberschreiten, und die Summe aller Grenzwerte betr√§gt 700 m f√ºr die CPU und 2 G f√ºr das OP. </p><br></li><li><p>  Standardeinschr√§nkungen f√ºr Container in ns: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: LimitRange metadata: name: nxs-limit-per-container spec: limits: - type: Container defaultRequest: cpu: 100m memory: 1Gi default: cpu: 1 memory: 2Gi min: cpu: 50m memory: 500Mi max: cpu: 2 memory: 4Gi</code> </pre> <br><p>  Das hei√üt  Im Standard-Namespace f√ºr alle Container wird die Anforderung standardm√§√üig auf 100 m f√ºr die CPU und auf 1 G f√ºr das OP festgelegt, das Limit auf 1 CPU und 2 G.  Gleichzeitig wurde eine Einschr√§nkung der m√∂glichen Werte in Request / Limit f√ºr die CPU (50m &lt;x &lt;2) und RAM (500M &lt;x &lt;4G) festgelegt. </p><br></li><li><p>  Einschr√§nkungen auf der ns Herdebene: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: LimitRange metadata: name: nxs-limit-pod spec: limits: - type: Pod max: cpu: 4 memory: 1Gi</code> </pre> <br><p>  Das hei√üt  F√ºr jeden Herd in der Standardeinstellung ns wird ein Limit von 4 vCPU und 1G festgelegt. </p><br></li></ul><br><p>  Nun m√∂chte ich Ihnen mitteilen, welche Vorteile die Installation dieser Einschr√§nkungen f√ºr uns hat. </p><br><h2 id="mehanizm-balansirovki-nagruzki-mezhdu-nodami">  Der Mechanismus des Lastenausgleichs zwischen Knoten </h2><br><p>  Wie Sie wissen, ist die k8s-Komponente wie <strong>Scheduler</strong> , die nach einem bestimmten Algorithmus arbeitet, f√ºr die Verteilung der Herde nach Knoten verantwortlich.  Dieser Algorithmus bei der Auswahl des optimalen auszuf√ºhrenden Knotens durchl√§uft zwei Stufen: </p><br><ol><li>  Filtern </li><li>  Ranking </li></ol><br><p>  Das hei√üt  Gem√§√ü der beschriebenen Richtlinie werden zun√§chst Knoten ausgew√§hlt, auf deren Grundlage ein Herd basierend auf einer Reihe von <strong>Pr√§dikaten</strong> gestartet werden kann (einschlie√ülich der Frage, ob der Knoten √ºber gen√ºgend Ressourcen verf√ºgt, um einen Herd auszuf√ºhren - PodFitsResources), und anschlie√üend werden f√ºr jeden dieser Knoten Punkte entsprechend den <strong>Priorit√§ten vergeben</strong> (einschlie√ülich Je mehr freie Ressourcen ein Knoten hat - desto mehr Punkte werden ihm zugewiesen - LeastResourceAllocation / LeastRequestedPriority / BalancedResourceAllocation) und werden auf dem Knoten mit den meisten Punkten ausgef√ºhrt (wenn mehrere Knoten diese Bedingung gleichzeitig erf√ºllen, wird ein zuf√§lliger Knoten ausgew√§hlt). </p><br><p>  Gleichzeitig m√ºssen Sie verstehen, dass sich der Scheduler bei der Bewertung der verf√ºgbaren Ressourcen des Knotens auf die in etcd gespeicherten Daten konzentriert - d. H.  nach der Menge der angeforderten / begrenzten Ressource jedes Pods, der auf diesem Knoten ausgef√ºhrt wird, aber nicht nach dem tats√§chlichen Ressourcenverbrauch.  Diese Informationen k√∂nnen in der Ausgabe des <code>kubectl describe node $NODE</code> abgerufen werden. Beispiel: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># kubectl describe nodes nxs-k8s-s1 .. Non-terminated Pods: (9 in total) Namespace Name CPU Requests CPU Limits Memory Requests Memory Limits AGE --------- ---- ------------ ---------- --------------- ------------- --- ingress-nginx nginx-ingress-controller-754b85bf44-qkt2t 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system kube-flannel-26bl4 150m (0%) 300m (1%) 64M (0%) 500M (1%) 233d kube-system kube-proxy-exporter-cb629 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system kube-proxy-x9fsc 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system nginx-proxy-k8s-worker-s1 25m (0%) 300m (1%) 32M (0%) 512M (1%) 233d nxs-monitoring alertmanager-main-1 100m (0%) 100m (0%) 425Mi (1%) 25Mi (0%) 233d nxs-logging filebeat-lmsmp 100m (0%) 0 (0%) 100Mi (0%) 200Mi (0%) 233d nxs-monitoring node-exporter-v4gdq 112m (0%) 122m (0%) 200Mi (0%) 220Mi (0%) 233d Allocated resources: (Total limits may be over 100 percent, ie, overcommitted.) Resource Requests Limits -------- -------- ------ cpu 487m (3%) 822m (5%) memory 15856217600 (2%) 749976320 (3%) ephemeral-storage 0 (0%) 0 (0%)</span></span></code> </pre> <br><p>  Hier sehen wir alle Pods, die auf einem bestimmten Knoten ausgef√ºhrt werden, sowie die Ressourcen, die jeder der Pods anfordert.  Und so sehen die Scheduler-Protokolle beim Starten des Pods cronjob-cron-events-1573793820-xt6q9 aus (diese Informationen werden im Scheduler-Protokoll angezeigt, wenn die 10. Protokollebene in den Argumenten des Startbefehls --v = 10 festgelegt wird): </p><br><div class="spoiler">  <b class="spoiler_title">breite M√∂we</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">I1115 07:57:21.637791 1 scheduling_queue.go:908] About to try and schedule pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 I1115 07:57:21.637804 1 scheduler.go:453] Attempting to schedule pod: nxs-stage/cronjob-cron-events-1573793820-xt6q9 I1115 07:57:21.638285 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s5 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638300 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s6 is allowed, Node is running only 20 out of 110 Pods. I1115 07:57:21.638322 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s3 is allowed, Node is running only 20 out of 110 Pods. I1115 07:57:21.638322 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s4 is allowed, Node is running only 17 out of 110 Pods. I1115 07:57:21.638334 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s10 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638365 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s12 is allowed, Node is running only 9 out of 110 Pods. I1115 07:57:21.638334 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s11 is allowed, Node is running only 11 out of 110 Pods. I1115 07:57:21.638385 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s1 is allowed, Node is running only 19 out of 110 Pods. I1115 07:57:21.638402 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s2 is allowed, Node is running only 21 out of 110 Pods. I1115 07:57:21.638383 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s9 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638335 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s8 is allowed, Node is running only 18 out of 110 Pods. I1115 07:57:21.638408 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s13 is allowed, Node is running only 8 out of 110 Pods. I1115 07:57:21.638478 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s10 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638505 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s8 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638577 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s9 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638583 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s7 is allowed, Node is running only 25 out of 110 Pods. I1115 07:57:21.638932 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: BalancedResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 2343 millicores 9640186880 memory bytes, score 9 I1115 07:57:21.638946 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: LeastResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 2343 millicores 9640186880 memory bytes, score 8 I1115 07:57:21.638961 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: BalancedResourceAllocation, capacity 39900 millicores 66620170240 memory bytes, total request 4107 millicores 11307422720 memory bytes, score 9 I1115 07:57:21.638971 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: BalancedResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 5847 millicores 24333637120 memory bytes, score 7 I1115 07:57:21.638975 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: LeastResourceAllocation, capacity 39900 millicores 66620170240 memory bytes, total request 4107 millicores 11307422720 memory bytes, score 8 I1115 07:57:21.638990 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: LeastResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 5847 millicores 24333637120 memory bytes, score 7 I1115 07:57:21.639022 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: TaintTolerationPriority, Score: (10) I1115 07:57:21.639030 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: TaintTolerationPriority, Score: (10) I1115 07:57:21.639034 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: TaintTolerationPriority, Score: (10) I1115 07:57:21.639041 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: NodeAffinityPriority, Score: (0) I1115 07:57:21.639053 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: NodeAffinityPriority, Score: (0) I1115 07:57:21.639059 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: NodeAffinityPriority, Score: (0) I1115 07:57:21.639061 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639063 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639073 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639077 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639085 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639088 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639103 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639109 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639114 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639127 1 generic_scheduler.go:781] Host nxs-k8s-s10 =&gt; Score 100037 I1115 07:57:21.639150 1 generic_scheduler.go:781] Host nxs-k8s-s8 =&gt; Score 100034 I1115 07:57:21.639154 1 generic_scheduler.go:781] Host nxs-k8s-s9 =&gt; Score 100037 I1115 07:57:21.639267 1 scheduler_binder.go:269] AssumePodVolumes for pod "nxs-stage/cronjob-cron-events-1573793820-xt6q9", node "nxs-k8s-s10" I1115 07:57:21.639286 1 scheduler_binder.go:279] AssumePodVolumes for pod "nxs-stage/cronjob-cron-events-1573793820-xt6q9", node "nxs-k8s-s10": all PVCs bound and nothing to do I1115 07:57:21.639333 1 factory.go:733] Attempting to bind cronjob-cron-events-1573793820-xt6q9 to nxs-k8s-s10</code> </pre> </div></div><br><p>  Hier sehen wir, dass der Scheduler anf√§nglich eine Filterung durchf√ºhrt und eine Liste von 3 Knoten generiert, auf denen ein Start m√∂glich ist (nxs-k8s-s8, nxs-k8s-s9, nxs-k8s-s10).  Anschlie√üend werden Punkte anhand mehrerer Parameter (einschlie√ülich BalancedResourceAllocation, LeastResourceAllocation) f√ºr jeden dieser Knoten berechnet, um den am besten geeigneten Knoten zu ermitteln.  Am Ende ist geplant, unter dem Knoten mit den meisten Punkten zu laufen (hier haben zwei Knoten bei 100037 die gleiche Anzahl von Punkten, daher wird eine zuf√§llige ausgew√§hlt - nxs-k8s-s10). </p><br><p>  <strong>Fazit</strong> : Wenn Pods auf dem Knoten funktionieren, f√ºr den keine Einschr√§nkungen festgelegt wurden, ist dies f√ºr k8s (aus Sicht des Ressourcenverbrauchs) so, als ob solche Pods auf diesem Knoten vollst√§ndig fehlen w√ºrden.  Wenn Sie also unter bestimmten Bedingungen einen Pod mit einem uners√§ttlichen Prozess haben (z. B. wowza) und f√ºr diesen keine Einschr√§nkungen bestehen, kann eine Situation eintreten, in der der betreffende Knoten tats√§chlich alle Ressourcen des Knotens verbraucht hat, dieser Knoten jedoch f√ºr k8s als entladen gilt Es wird die gleiche Anzahl von Punkten f√ºr die Rangfolge vergeben (dh in Punkten mit einer Bewertung der verf√ºgbaren Ressourcen) sowie f√ºr einen Knoten, der keine Arbeitsabst√§nde aufweist, was letztendlich zu einer ungleichm√§√üigen Lastverteilung zwischen den Knoten f√ºhren kann. </p><br><h2 id="vyselenie-poda">  Herdr√§umung </h2><br><p>  Wie Sie wissen, ist jedem Pod eine der 3 QoS-Klassen zugeordnet: </p><br><ol><li>  <strong>guaranuted</strong> - wird zugewiesen, wenn f√ºr jeden Container im Herd eine Anforderung und ein Limit f√ºr Speicher und CPU festgelegt wurden und diese Werte √ºbereinstimmen m√ºssen </li><li>  <strong>Berstbar</strong> - Mindestens ein Beh√§lter im Herd hat eine Anforderung und ein Limit, w√§hrend die Anforderung &lt;Limit ist </li><li>  <strong>bester aufwand</strong> - wenn kein container im feuerraum in ressourcen begrenzt ist </li></ol><br><p>  Zur gleichen Zeit, wenn auf dem Knoten ein Mangel an Ressourcen (Festplatte, Speicher) besteht, beginnt kubelet, Pods nach einem bestimmten Algorithmus, der die Priorit√§t des Pods und seiner QoS-Klasse ber√ºcksichtigt, zu klassifizieren und zu entfernen.  Wenn es sich zum Beispiel um RAM handelt, werden basierend auf der QoS-Klasse Punkte nach dem folgenden Prinzip vergeben: </p><br><ul><li>  <strong>Garantiert</strong> : -998 </li><li>  <strong>BestEffort</strong> : 1000 </li><li>  <strong>Burstable</strong> : min (max (2, 1000 - (1000 * memoryRequestBytes) / machineMemoryCapacityBytes), 999) </li></ul><br><p>  Das hei√üt  Bei gleicher Priorit√§t werden zuerst die Pods mit der bestm√∂glichen QoS-Klasse aus dem Knoten entfernt. </p><br><p>  <strong>Fazit</strong> : Wenn Sie die Wahrscheinlichkeit verringern m√∂chten, dass der erforderliche Pod bei unzureichenden Ressourcen vom Knoten entfernt wird, m√ºssen Sie neben der Priorit√§t auch die Anforderung / das Limit daf√ºr festlegen. </p><br><h2 id="mehanizm-gorizontalnogo-avtomasshtabirovaniya-podov-prilozheniya-hpa">  Horizontaler Auto-Scaling-Mechanismus f√ºr Anwendungsherde (HPA) </h2><br><p>  Wenn die Aufgabe darin besteht, die Anzahl der Pods abh√§ngig von der Ressourcennutzung (System-CPU / RAM oder Benutzer-RPS) automatisch zu erh√∂hen oder zu verringern, k√∂nnen k8s wie <strong>HPA</strong> (Horizontal Pod Autoscaler) Abhilfe schaffen.  Der Algorithmus lautet wie folgt: </p><br><ol><li>  Die aktuellen Messwerte der beobachteten Ressource (currentMetricValue) werden ermittelt </li><li>  Es werden die gew√ºnschten Werte f√ºr die Ressource (wantedMetricValue) ermittelt, die per Request f√ºr Systemressourcen gesetzt werden </li><li>  Die aktuelle Anzahl der Replikate wird ermittelt (currentReplicas) </li><li>  Die folgende Formel berechnet die gew√ºnschte Anzahl von Replikaten (desiredReplicas) <br>  desiredReplicas = [currentReplicas * (currentMetricValue / desiredMetricValue)] </li></ol><br><p>  Eine Skalierung findet jedoch nicht statt, wenn der Koeffizient (currentMetricValue / desiredMetricValue) in der N√§he von 1 liegt (wir k√∂nnen den zul√§ssigen Fehler selbst festlegen, standardm√§√üig betr√§gt er 0,1). </p><br><p>  Ber√ºcksichtigen Sie hpa mit der App-Testanwendung (als Bereitstellung bezeichnet), bei der die Anzahl der Replikate abh√§ngig vom CPU-Verbrauch ge√§ndert werden muss: </p><br><ul><li><p>  Anwendungsmanifest </p><br><pre> <code class="plaintext hljs">kind: Deployment apiVersion: apps/v1beta2 metadata: name: app-test spec: selector: matchLabels: app: app-test replicas: 2 template: metadata: labels: app: app-test spec: containers: - name: nginx image: registry.nixys.ru/generic-images/nginx imagePullPolicy: Always resources: requests: cpu: 60m ports: - name: http containerPort: 80 - name: nginx-exporter image: nginx/nginx-prometheus-exporter resources: requests: cpu: 30m ports: - name: nginx-exporter containerPort: 9113 args: - -nginx.scrape-uri - http://127.0.0.1:80/nginx-status</code> </pre> <br><p>  Das hei√üt  Wir sehen, dass es mit der Anwendung zun√§chst in zwei Instanzen gestartet wird, von denen jede zwei Container nginx und nginx-exporter enth√§lt, f√ºr die jeweils <strong>Anforderungen</strong> an die CPU gestellt werden. </p><br></li><li><p>  HPA-Manifest </p><br><pre> <code class="plaintext hljs">apiVersion: autoscaling/v2beta2 kind: HorizontalPodAutoscaler metadata: name: app-test-hpa spec: maxReplicas: 10 minReplicas: 2 scaleTargetRef: apiVersion: extensions/v1beta1 kind: Deployment name: app-test metrics: - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 30</code> </pre> <br><p>  Das hei√üt  Wir haben ein HPA erstellt, das den Deployment-App-Test √ºberwacht und die Anzahl der Herde mit der Anwendung basierend auf der CPU-Anzeige anpasst (wir gehen davon aus, dass 30% der angeforderten CPU verbraucht werden), w√§hrend die Anzahl der Replikate im Bereich von 2 bis 10 liegt. </p><br><p>  Nun betrachten wir den hpa-Betriebsmechanismus, wenn wir eine Last auf einen der Herde aus√ºben: </p><br><pre> <code class="bash hljs"> <span class="hljs-comment"><span class="hljs-comment"># kubectl top pod NAME CPU(cores) MEMORY(bytes) app-test-78559f8f44-pgs58 101m 243Mi app-test-78559f8f44-cj4jz 4m 240Mi</span></span></code> </pre> <br></li></ul><br><p>  Insgesamt haben wir folgende: </p><br><ul><li>  Gew√ºnschter Wert (desiredMetricValue) - gem√§√ü den hpa-Einstellungen haben wir 30% </li><li>  Aktueller Wert (currentMetricValue) - Zur Berechnung berechnet der Controller-Manager den Durchschnittswert des Ressourcenverbrauchs in%, d. H.  bedingt das Folgende: <br><ol><li>  Ruft die absoluten Werte der Herdmetriken vom Metrikserver ab, d. H.  101m und 4m </li><li>  Berechnet den durchschnittlichen Absolutwert, d.h.  (101 m + 4 m) / 2 = 53 m </li><li>  Ermittelt den absoluten Wert f√ºr den gew√ºnschten Ressourcenverbrauch (dazu werden die Anforderungen aller Container summiert) 60m + 30m = 90m </li><li>  Berechnet den durchschnittlichen Prozentsatz des CPU-Verbrauchs relativ zum Anforderungsherd, d. H.  53 m / 90 m * 100% = 59% </li></ol></li></ul><br><p>  Jetzt haben wir alles N√∂tige, um festzustellen, ob die Anzahl der Replikate ge√§ndert werden muss. Dazu berechnen wir den Koeffizienten: </p><br><p> <code>ratio = 59% / 30% = 1.96</code> </p> <br><p>  Das hei√üt  Die Anzahl der Replikate sollte um das ~ 2-fache erh√∂ht werden und [2 * 1,96] = 4 betragen. </p><br><p>  <strong>Fazit:</strong> Wie Sie sehen, ist es eine Grundvoraussetzung, dass Anforderungen f√ºr alle Container im beobachteten Herd verf√ºgbar sind, damit dieser Mechanismus funktioniert. </p><br><h2 id="mehanizm-gorizontalnogo-avtomasshtabirovaniya-nod-cluster-autoscaler">  Der Mechanismus der horizontalen automatischen Skalierung von Knoten (Cluster Autoscaler) </h2><br><p>  Um die negativen Auswirkungen auf das System w√§hrend Lastspitzen zu neutralisieren, reicht das Vorhandensein eines abgestimmten hpa nicht aus.  Beispielsweise entscheidet der hpa-Controller-Manager gem√§√ü den Einstellungen, dass die Anzahl der Replikate um das Zweifache erh√∂ht werden muss. Es sind jedoch keine Ressourcen auf den Knoten verf√ºgbar, um eine solche Anzahl von Pods auszuf√ºhren (d. H. Der Knoten kann die angeforderten Ressourcen f√ºr die Pod-Anforderungen nicht bereitstellen) Geben Sie den Status Ausstehend ein. </p><br><p>  In diesem Fall kann uns ein Tool wie <strong>Node Autoscaler</strong> helfen, wenn der Anbieter √ºber das entsprechende IaaS / PaaS verf√ºgt (z. B. GKE / GCE, AKS, EKS usw.).  Sie k√∂nnen die maximale und minimale Anzahl von Knoten im Cluster festlegen und die aktuelle Anzahl von Knoten automatisch anpassen (indem Sie auf die Cloud-Provider-API zugreifen, um Knoten zu bestellen / zu l√∂schen), wenn im Cluster ein Ressourcenmangel vorliegt und die Pods nicht geplant werden k√∂nnen (im Status Ausstehend). </p><br><p>  <strong>Schlussfolgerung:</strong> Um die Knoten automatisch skalieren zu k√∂nnen, m√ºssen Anforderungen in den Herdcontainern angegeben werden, damit k8s die Knotenlast korrekt auswerten und dementsprechend melden kann, dass sich keine Ressourcen im Cluster befinden, um den n√§chsten Herd zu starten. </p><br><hr><br><h2 id="zaklyuchenie">  Fazit </h2><br><p>  Es sollte beachtet werden, dass das Festlegen von Ressourcenlimits f√ºr den Container keine Voraussetzung f√ºr den erfolgreichen Start der Anwendung ist. Es ist jedoch aus den folgenden Gr√ºnden immer noch besser, dies zu tun: </p><br><ol><li>  F√ºr einen genaueren Scheduler-Betrieb im Hinblick auf den Lastausgleich zwischen k8s-Knoten </li><li>  Verringerung der Wahrscheinlichkeit einer R√§umung des Herdes </li><li>  F√ºr horizontale Anwendungsherde mit automatischer Skalierung (HPA) </li><li>  Zur horizontalen automatischen Skalierung von Knoten (Cluster Autoscaling) f√ºr Cloud-Anbieter </li></ol><br><h2 id="takzhe-chitayte-drugie-stati-v-nashem-bloge">  Lesen Sie auch andere Artikel in unserem Blog: </h2><br><ul><li>  <a href="https://habr.com/ru/company/nixys/blog/481992/">Tekton-Pipeline - Kubernetes-native Pipelines</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/473578/">Erstellen dynamischer Module f√ºr Nginx</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/468779/">Was war das Ergebnis der Migration von ClickHouse ohne Berechtigung zu ClickHouse mit Berechtigung?</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/461723/">Das Kontextpaket in Golang verstehen</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/437372/">Drei einfache Tricks zum Verkleinern von Docker-Bildern</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/424717/">Sichern einer gro√üen Anzahl heterogener Webprojekte</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de480072/">https://habr.com/ru/post/de480072/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de480060/index.html">Einfacher P300-Klassifikator f√ºr offene Daten</a></li>
<li><a href="../de480062/index.html">10 Steuersysteme. Wo ist es bequemer, √ºber Aufgaben zu kommunizieren und Dateien zu teilen?</a></li>
<li><a href="../de480064/index.html">W√∂rter thematisch gruppiert lernen</a></li>
<li><a href="../de480068/index.html">[Update] Unsere Leute sind geschlagen, und wir werden schweigen?</a></li>
<li><a href="../de480070/index.html">Vorteile reagieren: Ein Segen f√ºr Unternehmen?</a></li>
<li><a href="../de480076/index.html">Multiprocessing und Abgleich von Daten aus verschiedenen Quellen</a></li>
<li><a href="../de480078/index.html">Neue Front-End-Bibliotheken bei React Peripherals</a></li>
<li><a href="../de480080/index.html">Was ben√∂tigen Sie f√ºr Notizen?</a></li>
<li><a href="../de480082/index.html">Verwenden der Partitionierung in MySQL f√ºr Zabbix mit einer gro√üen Anzahl von √úberwachungsobjekten</a></li>
<li><a href="../de480086/index.html">Wie Sie die Anforderungen von 152-FZ erf√ºllen, die pers√∂nlichen Daten unserer Kunden sch√ºtzen und nicht auf unseren Rechen treten</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤷🏾 🍢 🚘 Mainkan Mortal Kombat dengan TensorFlow.js 👂🏼 ⏯️ ♦️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bereksperimen dengan perbaikan untuk model peramalan Guess.js , saya mulai melihat dengan seksama pembelajaran mendalam: jaringan saraf berulang (RNNs...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mainkan Mortal Kombat dengan TensorFlow.js</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428019/">  Bereksperimen dengan perbaikan untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">model</a> peramalan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Guess.js</a> , saya mulai melihat dengan seksama pembelajaran mendalam: jaringan saraf berulang (RNNs), khususnya LSTMs, karena <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"efektivitas tidak masuk akal" mereka</a> di daerah di mana Guess.js bekerja.  Pada saat yang sama, saya mulai bermain-main dengan convolutional neural networks (CNNs), yang juga sering digunakan untuk deret waktu.  CNN biasanya digunakan untuk mengklasifikasikan, mengenali, dan mendeteksi gambar. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1fb/9be/edc/1fb9beedcad00d1c0dcdc7bbef67e6d9.png"><br>  <i><font color="gray">Mengelola <a href="">MK.js</a> dengan TensorFlow.js</font></i> <br><br><blockquote>  Kode sumber untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel ini</a> dan <a href="">MK.js</a> ada di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">GitHub</a> saya.  Saya belum memposting dataset pelatihan, tetapi Anda dapat membuat sendiri dan melatih model seperti yang dijelaskan di bawah ini! </blockquote><a name="habracut"></a><br>  Setelah bermain dengan CNN, saya ingat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">percobaan yang</a> saya lakukan beberapa tahun yang lalu ketika pengembang browser merilis <code>getUserMedia</code> API.  Di dalamnya, kamera pengguna berfungsi sebagai pengontrol untuk memainkan klon JavaScript kecil Mortal Kombat 3. Anda dapat menemukan game itu di <a href="">repositori GitHub</a> .  Sebagai bagian dari percobaan, saya menerapkan algoritma penentuan posisi dasar yang mengklasifikasikan gambar ke dalam kelas berikut: <br><br><ul><li>  Pukulan kiri atau kanan </li><li>  Tendangan kiri atau kanan </li><li>  Langkah ke kiri dan ke kanan </li><li>  Jongkok </li><li>  Tidak satu pun di atas </li></ul><br>  Algoritma ini sangat sederhana sehingga saya bisa menjelaskannya dalam beberapa kalimat: <br><br><blockquote>  Algoritma memotret latar belakang.  Segera setelah pengguna muncul dalam bingkai, algoritma menghitung perbedaan antara latar belakang dan bingkai saat ini dengan pengguna.  Jadi itu menentukan posisi sosok pengguna.  Langkah selanjutnya adalah menampilkan tubuh pengguna putih di atas hitam.  Setelah itu, histogram vertikal dan horizontal dibangun, menjumlahkan nilai untuk setiap piksel.  Berdasarkan perhitungan ini, algoritma menentukan posisi tubuh saat ini. </blockquote><br>  Video menunjukkan cara kerja program.  Kode sumber <a href="">GitHub</a> . <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/0_yfU_iNUYo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Meskipun klon MK kecil bekerja dengan sukses, algoritma ini jauh dari sempurna.  Diperlukan bingkai dengan latar belakang.  Untuk operasi yang tepat, latar belakang harus berwarna sama selama pelaksanaan program.  Keterbatasan seperti itu berarti bahwa perubahan cahaya, bayangan dan hal-hal lain akan mengganggu dan memberikan hasil yang tidak akurat.  Akhirnya, algoritma tidak mengenali tindakan;  ia hanya mengklasifikasikan bingkai baru sebagai posisi tubuh dari set yang telah ditentukan. <br><br>  Sekarang, berkat kemajuan dalam API web, yaitu WebGL, saya memutuskan untuk kembali ke tugas ini dengan menerapkan TensorFlow.js. <br><br><h1>  Pendahuluan </h1><br>  Pada artikel ini, saya akan membagikan pengalaman saya dalam membuat algoritma untuk mengklasifikasikan posisi tubuh menggunakan TensorFlow.js dan MobileNet.  Pertimbangkan topik-topik berikut: <br><br><ul><li>  Pengumpulan data pelatihan untuk klasifikasi gambar </li><li>  Augmentasi Data dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">imgaug</a> </li><li>  Transfer Pembelajaran dengan MobileNet </li><li>  Klasifikasi biner dan klasifikasi N-primer </li><li>  Melatih model klasifikasi gambar TensorFlow.js di Node.js dan menggunakannya di browser </li><li>  Beberapa kata tentang mengklasifikasikan tindakan dengan LSTM </li></ul><br>  Dalam artikel ini, kita akan mengurangi masalah untuk menentukan posisi tubuh berdasarkan satu frame, berbeda dengan mengenali tindakan dengan urutan frame.  Kami akan mengembangkan model pembelajaran mendalam dengan seorang guru, yang, berdasarkan gambar dari webcam pengguna, menentukan gerakan seseorang: menendang, kaki, atau tidak ada yang seperti ini. <br><br>  Pada akhir artikel, kita akan dapat membangun model untuk bermain <a href="">MK.js</a> : <br><br><img src="https://habrastorage.org/webt/2u/0e/g6/2u0eg6ng2p4kwxosmut1koa751g.gif"><br><br>  Untuk memahami artikel dengan lebih baik, pembaca harus terbiasa dengan konsep dasar pemrograman dan JavaScript.  Pemahaman dasar tentang pembelajaran yang mendalam juga bermanfaat, tetapi tidak perlu. <br><br><h1>  Pengumpulan data </h1><br>  Keakuratan model pembelajaran mendalam sangat tergantung pada kualitas data.  Kita perlu berusaha mengumpulkan kumpulan data yang luas, seperti dalam produksi. <br><br>  Model kita harus bisa mengenali pukulan dan tendangan.  Ini berarti bahwa kami harus mengumpulkan gambar dari tiga kategori: <br><br><ul><li>  Tendangan </li><li>  Tendangan </li><li>  Lainnya </li></ul><br>  Dalam percobaan ini, dua sukarelawan ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">@lili_vs</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">@gsamokovarov</a> ) membantu saya mengumpulkan foto.  Kami merekam 5 video QuickTime di MacBook Pro saya, masing-masing berisi 2-4 tendangan dan 2-4 tendangan. <br><br>  Kemudian kami menggunakan ffmpeg untuk mengekstraksi masing-masing frame dari video dan menyimpannya sebagai gambar <code>jpg</code> : <br><br> <code>ffmpeg -i video.mov $filename%03d.jpg</code> <br> <br>  Untuk menjalankan perintah di atas, Anda harus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menginstal</a> <code>ffmpeg</code> di komputer. <br><br>  Jika kita ingin melatih model, kita harus memberikan data input dan data output yang sesuai, tetapi pada tahap ini kita hanya memiliki banyak gambar tiga orang dalam pose berbeda.  Untuk menyusun data, Anda perlu mengklasifikasikan frame dalam tiga kategori: pukulan, tendangan, dan lainnya.  Untuk setiap kategori, direktori terpisah dibuat di mana semua gambar yang sesuai dipindahkan. <br><br>  Dengan demikian, di setiap direktori harus ada sekitar 200 gambar yang mirip dengan yang di bawah ini: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/798/e9a/908/798e9a9083a1f5dfa5811fbb7de3bcc9.jpg"><br><br>  Harap dicatat bahwa akan ada lebih banyak gambar di direktori Lainnya, karena relatif sedikit bingkai berisi foto pukulan dan tendangan, dan di frame yang tersisa orang berjalan, membalikkan atau mengontrol video.  Jika kita memiliki terlalu banyak gambar satu kelas, maka kita berisiko mengajar model yang bias terhadap kelas khusus ini.  Dalam hal ini, ketika mengklasifikasikan gambar dengan dampak, jaringan saraf masih dapat menentukan kelas "Lainnya".  Untuk mengurangi bias ini, Anda dapat menghapus beberapa foto dari direktori Lainnya dan melatih model pada jumlah gambar yang sama dari setiap kategori. <br><br>  Untuk kenyamanan, kami menetapkan angka dalam nomor katalog dari <code>1</code> hingga <code>190</code> , sehingga gambar pertama akan menjadi <code>1.jpg</code> , yang kedua <code>2.jpg</code> , dll. <br><br>  Jika kita melatih model hanya dalam 600 foto yang diambil di lingkungan yang sama dengan orang yang sama, kita tidak akan mencapai tingkat akurasi yang sangat tinggi.  Untuk mendapatkan hasil maksimal dari data kami, yang terbaik adalah membuat beberapa sampel tambahan menggunakan augmentasi data. <br><br><h1>  Augmentasi Data </h1><br>  Augmentasi Data adalah teknik yang meningkatkan jumlah titik data dengan mensintesis poin baru dari set yang ada.  Biasanya, augmentasi digunakan untuk meningkatkan ukuran dan keragaman set pelatihan.  Kami mentransfer gambar asli ke pipa transformasi yang membuat gambar baru.  Anda tidak dapat mendekati transformasi terlalu agresif: hanya pukulan tangan lainnya yang dihasilkan dari pukulan. <br><br>  Transformasi yang dapat diterima adalah rotasi, inversi warna, blur, dll. Ada alat open source yang sangat baik untuk augmentasi data.  Pada saat menulis artikel ini dalam JavaScript, tidak ada terlalu banyak opsi, jadi saya menggunakan perpustakaan yang diimplementasikan dengan Python - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">imgaug</a> .  Ini memiliki satu set augmenter yang dapat diterapkan secara probabilistik. <br><br>  Berikut adalah logika augmentasi data untuk percobaan ini: <br><br><pre> <code class="python hljs">np.random.seed(<span class="hljs-number"><span class="hljs-number">44</span></span>) ia.seed(<span class="hljs-number"><span class="hljs-number">44</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">191</span></span>): draw_single_sequential_images(str(i), <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-string"><span class="hljs-string">"others-aug"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">191</span></span>): draw_single_sequential_images(str(i), <span class="hljs-string"><span class="hljs-string">"hits"</span></span>, <span class="hljs-string"><span class="hljs-string">"hits-aug"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">191</span></span>): draw_single_sequential_images(str(i), <span class="hljs-string"><span class="hljs-string">"kicks"</span></span>, <span class="hljs-string"><span class="hljs-string">"kicks-aug"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">draw_single_sequential_images</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename, path, aug_path)</span></span></span><span class="hljs-function">:</span></span> image = misc.imresize(ndimage.imread(path + <span class="hljs-string"><span class="hljs-string">"/"</span></span> + filename + <span class="hljs-string"><span class="hljs-string">".jpg"</span></span>), (<span class="hljs-number"><span class="hljs-number">56</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>)) sometimes = <span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> aug: iaa.Sometimes(<span class="hljs-number"><span class="hljs-number">0.5</span></span>, aug) seq = iaa.Sequential( [ iaa.Fliplr(<span class="hljs-number"><span class="hljs-number">0.5</span></span>), <span class="hljs-comment"><span class="hljs-comment"># horizontally flip 50% of all images # crop images by -5% to 10% of their height/width sometimes(iaa.CropAndPad( percent=(-0.05, 0.1), pad_mode=ia.ALL, pad_cval=(0, 255) )), sometimes(iaa.Affine( scale={"x": (0.8, 1.2), "y": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis translate_percent={"x": (-0.1, 0.1), "y": (-0.1, 0.1)}, # translate by -10 to +10 percent (per axis) rotate=(-5, 5), shear=(-5, 5), # shear by -5 to +5 degrees order=[0, 1], # use nearest neighbour or bilinear interpolation (fast) cval=(0, 255), # if mode is constant, use a cval between 0 and 255 mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples) )), iaa.Grayscale(alpha=(0.0, 1.0)), iaa.Invert(0.05, per_channel=False), # invert color channels # execute 0 to 5 of the following (less important) augmenters per image # don't execute all of them, as that would often be way too strong iaa.SomeOf((0, 5), [ iaa.OneOf([ iaa.GaussianBlur((0, 2.0)), # blur images with a sigma between 0 and 2.0 iaa.AverageBlur(k=(2, 5)), # blur image using local means with kernel sizes between 2 and 5 iaa.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 3 and 5 ]), iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value) iaa.AddToHueAndSaturation((-20, 20)), # change hue and saturation # either change the brightness of the whole image (sometimes # per channel) or change the brightness of subareas iaa.OneOf([ iaa.Multiply((0.9, 1.1), per_channel=0.5), iaa.FrequencyNoiseAlpha( exponent=(-2, 0), first=iaa.Multiply((0.9, 1.1), per_channel=True), second=iaa.ContrastNormalization((0.9, 1.1)) ) ]), iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast ], random_order=True ) ], random_order=True ) im = np.zeros((16, 56, 100, 3), dtype=np.uint8) for c in range(0, 16): im[c] = image for im in range(len(grid)): misc.imsave(aug_path + "/" + filename + "_" + str(im) + ".jpg", grid[im])</span></span></code> </pre> <br>  Script ini menggunakan metode <code>main</code> dengan tiga <code>for</code> loop - satu untuk setiap kategori gambar.  Dalam setiap iterasi, di setiap loop, kami memanggil metode <code>draw_single_sequential_images</code> : argumen pertama adalah nama file, yang kedua adalah path, yang ketiga adalah direktori tempat menyimpan hasil. <br><br>  Setelah itu, kami membaca gambar dari disk dan menerapkan serangkaian transformasi padanya.  Saya telah mendokumentasikan sebagian besar transformasi dalam cuplikan kode di atas, jadi kami tidak akan mengulanginya. <br><br>  Untuk setiap gambar, 16 gambar lainnya dibuat.  Berikut ini contoh penampilan mereka: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/759/ad9/43d/759ad943d7aa07dbccee4a6f26a1d920.jpg"></a> <br><br>  Harap perhatikan bahwa dalam skrip di atas kami skala gambar ke <code>100x56</code> piksel.  Kami melakukan ini untuk mengurangi jumlah data dan, dengan demikian, jumlah perhitungan yang dilakukan model kami selama pelatihan dan evaluasi. <br><br><h1>  Bangunan model </h1><br>  Sekarang bangun model untuk klasifikasi! <br><br>  Karena kita berurusan dengan gambar, kita menggunakan jaringan saraf convolutional (CNN).  Arsitektur jaringan ini dikenal cocok untuk pengenalan gambar, deteksi objek, dan klasifikasi. <br><br><h3>  Transfer Belajar </h3><br>  Gambar di bawah ini menunjukkan CNN VGG-16 yang populer, yang digunakan untuk mengklasifikasikan gambar. <br><br><img src="https://habrastorage.org/webt/7t/0u/zk/7t0uzk4kdf4pbesgvlojn5nal18.png"><br><br>  VGG-16 Neural Network mengenali 1000 kelas gambar.  Ini memiliki 16 layer (tidak termasuk layer pooling dan output).  Jaringan multilayer seperti itu sulit dilatih dalam praktik.  Ini akan membutuhkan kumpulan data besar dan banyak pelatihan. <br><br>  Lapisan tersembunyi dari pelatihan CNN mengenali berbagai elemen gambar dari set pelatihan, mulai dari tepi, beralih ke elemen yang lebih kompleks, seperti bentuk, objek individu, dan sebagainya.  CNN terlatih dalam gaya VGG-16 untuk mengenali set besar gambar harus memiliki lapisan tersembunyi yang telah belajar banyak fitur dari set pelatihan.  Fitur-fitur tersebut akan umum untuk sebagian besar gambar dan, karenanya, digunakan kembali dalam tugas yang berbeda. <br><br>  Transfer pembelajaran memungkinkan Anda menggunakan kembali jaringan yang ada dan terlatih.  Kita dapat mengambil output dari salah satu lapisan jaringan yang ada dan mentransfernya sebagai input ke jaringan saraf baru.  Dengan demikian, dengan mengajarkan jaringan saraf yang baru dibuat, dari waktu ke waktu dapat diajarkan untuk mengenali fitur-fitur baru dari tingkat yang lebih tinggi dan dengan benar mengklasifikasikan gambar dari kelas yang model asli belum pernah lihat sebelumnya. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/7n/cc/a7/7ncca7e5ne2ammearn2sqnk4by0.png"></div><br><br>  Untuk tujuan kami, ambil jaringan saraf MobileNet dari paket <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">@ tensorflow-models / mobilenet</a> .  MobileNet sama kuatnya dengan VGG-16, tetapi jauh lebih kecil, yang mempercepat distribusi langsung, yaitu propagasi jaringan (propagasi maju), dan mengurangi waktu pengunduhan di browser.  MobileNet dilatih tentang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dataset</a> klasifikasi gambar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ILSVRC-2012-CLS</a> . <br><br>  Saat mengembangkan model dengan transfer pembelajaran, kami memiliki dua pilihan: <br><br><ol><li>  Keluaran dari mana model sumber model digunakan sebagai input untuk model target. </li><li>  Berapa banyak lapisan dari model target yang akan kita latih, jika ada. </li></ol><br>  Poin pertama sangat penting.  Bergantung pada lapisan yang dipilih, kita akan mendapatkan fitur pada tingkat abstraksi yang lebih rendah atau lebih tinggi sebagai input ke jaringan saraf kita. <br><br>  Kami tidak akan melatih lapisan MobileNet.  Kami <code>global_average_pooling2d_1</code> output dari <code>global_average_pooling2d_1</code> dan meneruskannya sebagai input ke model mungil kami.  Mengapa saya memilih lapisan khusus ini?  Secara empiris.  Saya melakukan beberapa tes, dan lapisan ini berfungsi dengan baik. <br><br><h3>  Definisi model </h3><br>  Tugas awal adalah untuk mengklasifikasikan gambar menjadi tiga kelas: tangan, kaki, dan gerakan lainnya.  Pertama, mari kita selesaikan masalah yang lebih kecil: kita akan menentukan apakah ada serangan tangan di bingkai atau tidak.  Ini adalah masalah klasifikasi biner yang khas.  Untuk tujuan ini, kita dapat mendefinisikan model berikut: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> <span class="hljs-string"><span class="hljs-string">'@tensorflow/tfjs'</span></span>; const model = tf.sequential(); model.add(tf.layers.inputLayer({ inputShape: [<span class="hljs-number"><span class="hljs-number">1024</span></span>] })); model.add(tf.layers.dense({ units: <span class="hljs-number"><span class="hljs-number">1024</span></span>, activation: <span class="hljs-string"><span class="hljs-string">'relu'</span></span> })); model.add(tf.layers.dense({ units: <span class="hljs-number"><span class="hljs-number">1</span></span>, activation: <span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span> })); model.compile({ optimizer: tf.train.adam(<span class="hljs-number"><span class="hljs-number">1e-6</span></span>), loss: tf.losses.sigmoidCrossEntropy, metrics: [<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>] });</code> </pre> <br>  Kode tersebut mendefinisikan model sederhana, lapisan dengan <code>1024</code> unit dan aktivasi <code>ReLU</code> , serta satu unit output yang melewati <code>sigmoid</code> aktivasi <code>sigmoid</code> .  Yang terakhir memberikan angka dari <code>0</code> hingga <code>1</code> , tergantung pada kemungkinan serangan tangan dalam bingkai ini. <br><br>  Mengapa saya memilih <code>1024</code> unit untuk tingkat kedua dan kecepatan pelatihan <code>1e-6</code> ?  Yah, saya mencoba beberapa opsi berbeda dan melihat bahwa opsi seperti itu paling berhasil.  Metode Tombak tampaknya bukan pendekatan terbaik, tetapi sebagian besar ini adalah bagaimana pengaturan hiperparameter dalam pembelajaran yang mendalam - berdasarkan pada pemahaman kami tentang model, kami menggunakan intuisi untuk memperbarui parameter ortogonal dan secara empiris memverifikasi cara kerja model. <br><br>  Metode <code>compile</code> mengkompilasi lapisan bersama-sama, menyiapkan model untuk pelatihan dan evaluasi.  Di sini kami mengumumkan bahwa kami ingin menggunakan algoritma pengoptimalan <code>adam</code> .  Kami juga menyatakan bahwa kami akan menghitung kerugian (loss) dari cross entropy, dan mengindikasikan bahwa kami ingin mengevaluasi keakuratan model.  TensorFlow.js kemudian menghitung akurasi menggunakan rumus: <br><br> <code>Accuracy = (True Positives + True Negatives) / (Positives + Negatives)</code> <br> <br>  Jika Anda mentransfer pelatihan dari model MobileNet asli, Anda harus mengunduhnya terlebih dahulu.  Karena tidak praktis untuk melatih model kami pada lebih dari 3.000 gambar dalam browser, kami akan menggunakan Node.js dan memuat jaringan saraf dari file. <br><br>  Unduh MobileNet di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> .  Katalog berisi file <code>model.json</code> , yang berisi arsitektur model - lapisan, aktivasi, dll.  File yang tersisa berisi parameter model.  Anda dapat memuat model dari file menggunakan kode ini: <br><br><pre> <code class="python hljs">export const loadModel = <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> () =&gt; { const mn = new mobilenet.MobileNet(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>); mn.path = `file://PATH/TO/model.json`; <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> mn.load(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (input): tf.Tensor1D =&gt; mn.infer(input, <span class="hljs-string"><span class="hljs-string">'global_average_pooling2d_1'</span></span>) .reshape([<span class="hljs-number"><span class="hljs-number">1024</span></span>]); };</code> </pre> <br>  Perhatikan bahwa dalam metode <code>loadModel</code> kami mengembalikan fungsi yang menerima tensor satu dimensi sebagai input dan mengembalikan <code>mn.infer(input, Layer)</code> .  Metode <code>infer</code> mengambil tensor dan layer sebagai argumen.  Lapisan menentukan lapisan tersembunyi yang kita inginkan dari keluaran.  Jika Anda membuka <a href="">model.json</a> dan <code>global_average_pooling2d_1</code> , Anda akan menemukan nama seperti itu di salah satu layer. <br><br>  Sekarang Anda perlu membuat kumpulan data untuk melatih model.  Untuk melakukan ini, kita harus melewati semua gambar melalui metode inferensia di MobileNet dan memberi mereka label: <code>1</code> untuk gambar dengan guratan dan <code>0</code> untuk gambar tanpa guratan: <br><br><pre> <code class="python hljs">const punches = require(<span class="hljs-string"><span class="hljs-string">'fs'</span></span>) .readdirSync(Punches) .filter(f =&gt; f.endsWith(<span class="hljs-string"><span class="hljs-string">'.jpg'</span></span>)) .map(f =&gt; `${Punches}/${f}`); const others = require(<span class="hljs-string"><span class="hljs-string">'fs'</span></span>) .readdirSync(Others) .filter(f =&gt; f.endsWith(<span class="hljs-string"><span class="hljs-string">'.jpg'</span></span>)) .map(f =&gt; `${Others}/${f}`); const ys = tf.tensor1d( new Array(punches.length).fill(<span class="hljs-number"><span class="hljs-number">1</span></span>) .concat(new Array(others.length).fill(<span class="hljs-number"><span class="hljs-number">0</span></span>))); const xs: tf.Tensor2D = tf.stack( punches .map((path: string) =&gt; mobileNet(readInput(path))) .concat(others.map((path: string) =&gt; mobileNet(readInput(path)))) ) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf.Tensor2D;</code> </pre> <br>  Dalam kode di atas, pertama-tama kita membaca file dalam direktori dengan dan tanpa hits.  Kemudian kita menentukan tensor satu dimensi yang berisi label keluaran.  Jika kita memiliki <code>n</code> gambar dengan guratan dan <code>m</code> gambar lainnya, tensor akan memiliki <code>n</code> elemen dengan nilai 1 dan elemen <code>m</code> dengan nilai 0. <br><br>  Dalam <code>xs</code> kami <code>infer</code> hasil pemanggilan metode <code>infer</code> untuk gambar individual.  Perhatikan bahwa untuk setiap gambar, kami memanggil metode <code>readInput</code> .  Berikut implementasinya: <br><br><pre> <code class="python hljs">export const readInput = img =&gt; imageToInput(readImage(img), TotalChannels); const readImage = path =&gt; jpeg.decode(fs.readFileSync(path), true); const imageToInput = image =&gt; { const values = serializeImage(image); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> tf.tensor3d(values, [image.height, image.width, <span class="hljs-number"><span class="hljs-number">3</span></span>], <span class="hljs-string"><span class="hljs-string">'int32'</span></span>); }; const serializeImage = image =&gt; { const totalPixels = image.width * image.height; const result = new Int32Array(totalPixels * <span class="hljs-number"><span class="hljs-number">3</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (let i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; totalPixels; i++) { result[i * <span class="hljs-number"><span class="hljs-number">3</span></span> + <span class="hljs-number"><span class="hljs-number">0</span></span>] = image.data[i * <span class="hljs-number"><span class="hljs-number">4</span></span> + <span class="hljs-number"><span class="hljs-number">0</span></span>]; result[i * <span class="hljs-number"><span class="hljs-number">3</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>] = image.data[i * <span class="hljs-number"><span class="hljs-number">4</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>]; result[i * <span class="hljs-number"><span class="hljs-number">3</span></span> + <span class="hljs-number"><span class="hljs-number">2</span></span>] = image.data[i * <span class="hljs-number"><span class="hljs-number">4</span></span> + <span class="hljs-number"><span class="hljs-number">2</span></span>]; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result; };</code> </pre> <br>  <code>readInput</code> pertama-tama memanggil fungsi <code>readImage</code> , dan setelah itu mendelegasikan panggilannya ke <code>imageToInput</code> .  Fungsi <code>readImage</code> membaca gambar dari disk dan kemudian menerjemahkan jpg dari buffer menggunakan paket <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">jpeg-js</a> .  Dalam <code>imageToInput</code> kami mengonversi gambar ke tensor tiga dimensi. <br><br>  Akibatnya, untuk setiap <code>i</code> dari <code>0</code> hingga <code>TotalImages</code> harus <code>ys[i]</code> sama dengan <code>1</code> jika <code>xs[i]</code> sesuai dengan gambar dengan klik, dan <code>0</code> sebaliknya. <br><br><h1>  Pelatihan model </h1><br>  Sekarang modelnya siap untuk pelatihan!  Panggil metode <code>fit</code> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">await</span></span> model.fit(xs, ys, { epochs: Epochs, batchSize: parseInt(((punches.length + others.length) * BatchSize).toFixed(<span class="hljs-number"><span class="hljs-number">0</span></span>)), callbacks: { onBatchEnd: <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> (_, logs) =&gt; { console.log(<span class="hljs-string"><span class="hljs-string">'Cost: %s, accuracy: %s'</span></span>, logs.loss.toFixed(<span class="hljs-number"><span class="hljs-number">5</span></span>), logs.acc.toFixed(<span class="hljs-number"><span class="hljs-number">5</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> tf.nextFrame(); } } });</code> </pre> <br>  Panggilan kode di atas <code>fit</code> dengan tiga argumen: <code>xs</code> , ys dan objek konfigurasi.  Di objek konfigurasi, kami menetapkan berapa era model, ukuran paket, dan panggilan balik yang akan dihasilkan TensorFlow.js setelah memproses setiap paket yang akan dilatih. <br><br>  Ukuran paket menentukan <code>xs</code> dan <code>ys</code> untuk melatih model dalam satu era.  Untuk setiap era, TensorFlow.js akan memilih subset dari <code>xs</code> dan elemen terkait dari <code>ys</code> , melakukan distribusi langsung, menerima output dari layer dengan aktivasi <code>sigmoid</code> , dan kemudian, berdasarkan pada loss, melakukan optimasi menggunakan algoritma <code>adam</code> . <br><br>  Setelah memulai skrip pelatihan, Anda akan melihat hasil yang mirip dengan yang di bawah ini: <br><br><pre>  Biaya: 0,84212, akurasi: 1,00000
 eta = 0,3&gt; ---------- acc = 1,00 loss = 0,84 Biaya: 0,79740, akurasi: 1,00000
 eta = 0,2 =&gt; --------- acc = 1,00 kerugian = 0,80 Biaya: 0,81533, akurasi: 1,00000
 eta = 0,2 ==&gt; -------- acc = 1.00 loss = 0.82 Biaya: 0.64303, akurasi: 0.50000
 eta = 0,2 ===&gt; ------- acc = 0,50 kerugian = 0,64 Biaya: 0,51377, akurasi: 0,00000
 eta = 0,2 ====&gt; ------ acc = 0,00 kerugian = 0,51 Biaya: 0,46473, akurasi: 0,50000
 eta = 0,1 =====&gt; ----- acc = 0,50 kerugian = 0,46 Biaya: 0,50872, akurasi: 0,00000
 eta = 0,1 ======&gt; ---- acc = 0,00 kerugian = 0,51 Biaya: 0,62556, akurasi: 1,00000
 eta = 0,1 =======&gt; --- acc = 1,00 kerugian = 0,63 Biaya: 0,65133, akurasi: 0,50000
 eta = 0,1 ========&gt; - acc = 0,50 kerugian = 0,65 Biaya: 0,63824, akurasi: 0,50000
 eta = 0,0 ===========&gt;
 293ms 14675us / langkah - acc = 0,60 kerugian = 0,65
 Epoch 3/50
 Biaya: 0,44661, akurasi: 1,00000
 eta = 0,3&gt; ---------- acc = 1,00 loss = 0,45 Biaya: 0,78060, akurasi: 1,00000
 eta = 0,3 =&gt; --------- acc = 1,00 kerugian = 0,78 Biaya: 0,79208, akurasi: 1,00000
 eta = 0,3 ==&gt; -------- acc = 1,00 kerugian = 0,79 Biaya: 0,49072, akurasi: 0,50000
 eta = 0,2 ===&gt; ------- acc = 0,50 kerugian = 0,49 Biaya: 0,62232, akurasi: 1,00000
 eta = 0,2 ====&gt; ------ acc = 1,00 kerugian = 0,62 Biaya: 0,82899, akurasi: 1,00000
 eta = 0,2 =====&gt; ----- acc = 1,00 kerugian = 0,83 Biaya: 0,67629, akurasi: 0,50000
 eta = 0,1 ======&gt; ---- acc = 0,50 kerugian = 0,68 Biaya: 0,62621, akurasi: 0,50000
 eta = 0,1 =======&gt; --- acc = 0,50 kerugian = 0,63 Biaya: 0,46077, akurasi: 1,00000
 eta = 0,1 ========&gt; - acc = 1,00 kerugian = 0,46 Biaya: 0,62076, akurasi: 1,00000
 eta = 0,0 ===========&gt;
 304ms 15221us / step - acc = 0.85 kerugian = 0.63 </pre><br>  Perhatikan bagaimana akurasi meningkat seiring waktu dan kerugian berkurang. <br><br>  Pada set data saya, model setelah pelatihan menunjukkan akurasi 92%.  Ingatlah bahwa keakuratan mungkin tidak terlalu tinggi karena set kecil data pelatihan. <br><br><h1>  Menjalankan model di browser </h1><br>  Pada bagian sebelumnya, kami melatih model klasifikasi biner.  Sekarang jalankan di browser dan sambungkan ke <a href="">MK.js</a> ! <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> video = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.getElementById(<span class="hljs-string"><span class="hljs-string">'cam'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> Layer = <span class="hljs-string"><span class="hljs-string">'global_average_pooling2d_1'</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> mobilenetInfer = <span class="hljs-function"><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">m</span></span></span><span class="hljs-function"> =&gt;</span></span> (p): tf.Tensor&lt;tf.Rank&gt; =&gt; m.infer(p, Layer); <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> canvas = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.getElementById(<span class="hljs-string"><span class="hljs-string">'canvas'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> scale = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.getElementById(<span class="hljs-string"><span class="hljs-string">'crop'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> ImageSize = { <span class="hljs-attr"><span class="hljs-attr">Width</span></span>: <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-attr"><span class="hljs-attr">Height</span></span>: <span class="hljs-number"><span class="hljs-number">56</span></span> }; navigator.mediaDevices .getUserMedia({ <span class="hljs-attr"><span class="hljs-attr">video</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">audio</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span> }) .then(<span class="hljs-function"><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">stream</span></span></span><span class="hljs-function"> =&gt;</span></span> { video.srcObject = stream; });</code> </pre> <br>  Ada beberapa deklarasi dalam kode di atas: <br><br><ul><li> <code>video</code>     <code>HTML5 video</code>   </li><li> <code>Layer</code>     MobileNet,                  </li><li> <code>mobilenetInfer</code> — ,    MobileNet    .              MobileNet </li><li> <code>canvas</code>    <code>HTML5 canvas</code> ,          </li><li> <code>scale</code> —   <code>canvas</code> ,       </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Setelah itu, kami mendapatkan aliran video dari kamera pengguna dan menetapkannya sebagai sumber untuk elemen tersebut </font></font><code>video</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Langkah selanjutnya adalah menerapkan filter skala abu-abu yang menerima </font></font><code>canvas</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dan mengubah isinya:</font></font><br><br><pre> <code class="python hljs">const grayscale = (canvas: HTMLCanvasElement) =&gt; { const imageData = canvas.getContext(<span class="hljs-string"><span class="hljs-string">'2d'</span></span>).getImageData(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, canvas.width, canvas.height); const data = imageData.data; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (let i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; data.length; i += <span class="hljs-number"><span class="hljs-number">4</span></span>) { const avg = (data[i] + data[i + <span class="hljs-number"><span class="hljs-number">1</span></span>] + data[i + <span class="hljs-number"><span class="hljs-number">2</span></span>]) / <span class="hljs-number"><span class="hljs-number">3</span></span>; data[i] = avg; data[i + <span class="hljs-number"><span class="hljs-number">1</span></span>] = avg; data[i + <span class="hljs-number"><span class="hljs-number">2</span></span>] = avg; } canvas.getContext(<span class="hljs-string"><span class="hljs-string">'2d'</span></span>).putImageData(imageData, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>); };</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Sebagai langkah selanjutnya, kita akan menghubungkan model dengan MK.js: </font></font><br><br><pre> <code class="python hljs">let mobilenet: (p: any) =&gt; tf.Tensor&lt;tf.Rank&gt;; tf.loadModel(<span class="hljs-string"><span class="hljs-string">'http://localhost:5000/model.json'</span></span>).then(model =&gt; { mobileNet .load() .then((mn: any) =&gt; mobilenet = mobilenetInfer(mn)) .then(startInterval(mobilenet, model)); });</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dalam kode di atas, pertama-tama kita memuat model yang telah kita latih di atas, dan kemudian mengunduh MobileNet. </font><font style="vertical-align: inherit;">Kami melewati MobileNet ke dalam metode </font></font><code>mobilenetInfer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">untuk mendapatkan cara menghitung output dari lapisan jaringan tersembunyi. </font><font style="vertical-align: inherit;">Setelah itu, kami memanggil metode </font></font><code>startInterval</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dengan dua jaringan sebagai argumen.</font></font><br><br><pre> <code class="python hljs">const startInterval = (mobilenet, model) =&gt; () =&gt; { setInterval(() =&gt; { canvas.getContext(<span class="hljs-string"><span class="hljs-string">'2d'</span></span>).drawImage(video, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>); grayscale(scale .getContext(<span class="hljs-string"><span class="hljs-string">'2d'</span></span>) .drawImage( canvas, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, canvas.width, canvas.width / (ImageSize.Width / ImageSize.Height), <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, ImageSize.Width, ImageSize.Height )); const [punching] = Array.<span class="hljs-keyword"><span class="hljs-keyword">from</span></span>(( model.predict(mobilenet(tf.fromPixels(scale))) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf.Tensor1D) .dataSync() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> Float32Array); const detect = (window <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> any).Detect; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (punching &gt;= <span class="hljs-number"><span class="hljs-number">0.4</span></span>) detect &amp;&amp; detect.onPunch(); }, <span class="hljs-number"><span class="hljs-number">100</span></span>); };</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bagian yang paling menarik dimulai dari metode ini </font></font><code>startInterval</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">! Pertama, kami menjalankan interval di mana semua orang </font></font><code>100ms</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">memanggil fungsi anonim. Di dalamnya, </font></font><code>canvas</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">video dengan bingkai saat ini ditampilkan </font><font style="vertical-align: inherit;">pertama di atasnya </font><font style="vertical-align: inherit;">. Kemudian kami mengurangi ukuran bingkai </font></font><code>100x56</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dan menerapkan filter skala abu-abu untuk itu. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Langkah selanjutnya adalah mentransfer frame ke MobileNet, mendapatkan output dari lapisan tersembunyi yang diinginkan dan mentransfernya sebagai input ke metode </font></font><code>predict</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">model kami. Itu mengembalikan tensor dengan satu elemen. Dengan menggunakan, </font></font><code>dataSync</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kita mendapatkan nilai dari tensor dan menetapkannya ke konstanta </font></font><code>punching</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Akhirnya, kami memeriksa: jika kemungkinan serangan tangan melebihi </font></font><code>0.4</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, maka kami memanggil metode </font></font><code>onPunch</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">objek global </font></font><code>Detect</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. MK.js menyediakan objek global dengan tiga metode:</font></font><code>onKick</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>onPunch</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dan </font></font><code>onStand</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">yang dapat kita gunakan untuk mengontrol salah satu karakter.</font></font><br><br>  Selesai!<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Inilah hasilnya! </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/83e/05c/e0e/83e05ce0e9304865bb6aee072204902b.gif"><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pengenalan tendangan dan lengan dengan klasifikasi-N </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pada bagian selanjutnya, kita akan membuat model yang lebih cerdas: jaringan saraf yang mengenali pukulan, tendangan, dan gambar lainnya. </font><font style="vertical-align: inherit;">Kali ini, mari kita mulai dengan menyiapkan set pelatihan:</font></font><br><br><pre> <code class="python hljs">const punches = require(<span class="hljs-string"><span class="hljs-string">'fs'</span></span>) .readdirSync(Punches) .filter(f =&gt; f.endsWith(<span class="hljs-string"><span class="hljs-string">'.jpg'</span></span>)) .map(f =&gt; `${Punches}/${f}`); const kicks = require(<span class="hljs-string"><span class="hljs-string">'fs'</span></span>) .readdirSync(Kicks) .filter(f =&gt; f.endsWith(<span class="hljs-string"><span class="hljs-string">'.jpg'</span></span>)) .map(f =&gt; `${Kicks}/${f}`); const others = require(<span class="hljs-string"><span class="hljs-string">'fs'</span></span>) .readdirSync(Others) .filter(f =&gt; f.endsWith(<span class="hljs-string"><span class="hljs-string">'.jpg'</span></span>)) .map(f =&gt; `${Others}/${f}`); const ys = tf.tensor2d( new Array(punches.length) .fill([<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>]) .concat(new Array(kicks.length).fill([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>])) .concat(new Array(others.length).fill([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>])), [punches.length + kicks.length + others.length, <span class="hljs-number"><span class="hljs-number">3</span></span>] ); const xs: tf.Tensor2D = tf.stack( punches .map((path: string) =&gt; mobileNet(readInput(path))) .concat(kicks.map((path: string) =&gt; mobileNet(readInput(path)))) .concat(others.map((path: string) =&gt; mobileNet(readInput(path)))) ) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf.Tensor2D;</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Seperti sebelumnya, kita pertama-tama membaca katalog dengan gambar pukulan dengan tangan, kaki, dan gambar lainnya. Setelah ini, tidak seperti yang terakhir kali, kami membentuk hasil yang diharapkan dalam bentuk tensor dua dimensi, dan bukan satu dimensi. Jika kita memiliki </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">n</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> gambar dengan tendangan, </font><font style="vertical-align: inherit;">gambar </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">m</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dengan tendangan dan </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> gambar lain, maka tensor </font></font><code>ys</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">akan memiliki </font></font><code>n</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">elemen dengan nilai </font></font><code>[1, 0, 0]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>m</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">elemen dengan nilai </font></font><code>[0, 1, 0]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dan </font></font><code>k</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">elemen dengan nilai </font></font><code>[0, 0, 1]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vektor </font></font><code>n</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">elemen di mana ada </font></font><code>n - 1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">elemen dengan nilai </font></font><code>0</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dan satu elemen dengan nilai </font></font><code>1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, kita sebut vektor kesatuan (vektor satu-panas). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Setelah itu, kita membentuk tensor input</font></font><code>xs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">menumpuk output setiap gambar dari MobileNet. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Di sini Anda harus memperbarui definisi model:</font></font><br><br><pre> <code class="python hljs">const model = tf.sequential(); model.add(tf.layers.inputLayer({ inputShape: [<span class="hljs-number"><span class="hljs-number">1024</span></span>] })); model.add(tf.layers.dense({ units: <span class="hljs-number"><span class="hljs-number">1024</span></span>, activation: <span class="hljs-string"><span class="hljs-string">'relu'</span></span> })); model.add(tf.layers.dense({ units: <span class="hljs-number"><span class="hljs-number">3</span></span>, activation: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span> })); <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> model.compile({ optimizer: tf.train.adam(<span class="hljs-number"><span class="hljs-number">1e-6</span></span>), loss: tf.losses.sigmoidCrossEntropy, metrics: [<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>] });</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Hanya dua perbedaan dari model sebelumnya adalah: </font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Jumlah unit di lapisan output </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Aktivasi di lapisan output </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ada tiga unit di lapisan output, karena kami memiliki tiga kategori gambar yang berbeda: </font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pemogokan tangan </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tendangan </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Lainnya </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aktivasi dipicu pada tiga unit ini </font></font><code>softmax</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, yang mengubah parameternya menjadi tensor dengan tiga nilai. Mengapa tiga unit untuk lapisan output? Masing-masing dari tiga nilai untuk tiga kelas dapat diwakili oleh dua bit: </font></font><code>00</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>01</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font><code>10</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Jumlah nilai dari tensor yang dibuat </font></font><code>softmax</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">adalah 1, yaitu, kita tidak akan pernah mendapatkan 00, jadi kita tidak akan dapat mengklasifikasikan gambar dari salah satu kelas. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Setelah melatih model selama </font></font><code>500</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">berabad </font><font style="vertical-align: inherit;">- </font><font style="vertical-align: inherit;">abad, saya mencapai akurasi sekitar 92%! Ini tidak buruk, tetapi jangan lupa bahwa pelatihan dilakukan pada kumpulan data kecil. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Langkah selanjutnya adalah menjalankan model di browser! Karena logika sangat mirip dengan menjalankan model untuk klasifikasi biner, lihat langkah terakhir, di mana tindakan dipilih berdasarkan pada output dari model:</font></font><br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> [punch, kick, nothing] = <span class="hljs-built_in"><span class="hljs-built_in">Array</span></span>.from((model.predict( mobilenet(tf.fromPixels(scaled)) ) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf.Tensor1D).dataSync() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-built_in"><span class="hljs-built_in">Float32Array</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> detect = (<span class="hljs-built_in"><span class="hljs-built_in">window</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> any).Detect; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (nothing &gt;= <span class="hljs-number"><span class="hljs-number">0.4</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (kick &gt; punch &amp;&amp; kick &gt;= <span class="hljs-number"><span class="hljs-number">0.35</span></span>) { detect.onKick(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (punch &gt; kick &amp;&amp; punch &gt;= <span class="hljs-number"><span class="hljs-number">0.35</span></span>) detect.onPunch();</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pertama-tama kita memanggil MobileNet dengan bingkai yang diperkecil dalam nuansa abu-abu, kemudian kita mentransfer hasil dari model terlatih kita. </font><font style="vertical-align: inherit;">Model mengembalikan tensor satu dimensi, yang kita konversi menjadi </font></font><code>Float32Array</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">c </font></font><code>dataSync</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Pada langkah selanjutnya kita gunakan </font></font><code>Array.from</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">untuk melemparkan array yang diketik ke array JavaScript. </font><font style="vertical-align: inherit;">Lalu kami mengekstrak probabilitas bahwa tembakan dengan tangan, tendangan, atau tidak ada apa pun ada di bingkai. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jika probabilitas hasil ketiga melebihi </font></font><code>0.4</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, kami kembali. </font><font style="vertical-align: inherit;">Jika tidak, jika probabilitas tendangan lebih tinggi </font></font><code>0.32</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, kami mengirim perintah tendangan ke MK.js. </font><font style="vertical-align: inherit;">Jika probabilitas tendangan lebih tinggi </font></font><code>0.32</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dan lebih tinggi dari probabilitas tendangan, maka kirim aksi tendangan tersebut. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Secara umum, itu saja! </font><font style="vertical-align: inherit;">Hasilnya ditunjukkan di bawah ini:</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/168/f71/f3d/168f71f3df8d267bec3e0791d5857c64.gif"><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pengakuan tindakan </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jika Anda mengumpulkan kumpulan data yang besar dan beragam tentang orang-orang yang memukul dengan tangan dan kaki, maka Anda dapat membangun model yang bekerja sangat baik pada frame individual. Tetapi apakah itu cukup? Bagaimana jika kita ingin melangkah lebih jauh dan membedakan dua jenis tendangan yang berbeda: dari belokan dan dari belakang (tendangan belakang). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Seperti dapat dilihat pada frame di bawah ini, pada titik waktu tertentu dari sudut tertentu, kedua pukulan terlihat sama: </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/6c1/567/5bf/6c15675bf7b8c238e7ce9d5aaefeea80.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a60/e3c/dba/a60e3cdba0eb3ecbc8730c39bc6c95b2.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tetapi jika Anda melihat kinerjanya, gerakannya benar-benar berbeda: </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/e72/28b/fe8/e7228bfe8cfe9bbe73f9011d94778a7a.gif"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bagaimana Anda bisa melatih jaringan saraf untuk menganalisis urutan frame, dan bukan hanya satu frame? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Untuk tujuan ini, kita dapat menjelajahi kelas lain dari jaringan saraf, yang disebut jaringan saraf berulang (RNNs). Misalnya, RNN sangat bagus untuk bekerja dengan deret waktu:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Natural Language Processing (NLP), di mana setiap kata tergantung pada sebelumnya dan selanjutnya </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Memprediksi halaman berikutnya berdasarkan riwayat penelusuran Anda </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pengenalan Bingkai </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Menerapkan model seperti itu berada di luar cakupan artikel ini, tetapi mari kita lihat contoh arsitektur untuk mendapatkan gambaran tentang bagaimana semua ini akan bekerja bersama. </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kekuatan RNN </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Diagram di bawah ini menunjukkan model pengakuan tindakan: </font></font><br><br><img src="https://habrastorage.org/webt/kz/oq/ie/kzoqieod8t9nhs_taapnhpr_y0c.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kami mengambil </font></font><code>n</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">frame </font><font style="vertical-align: inherit;">terakhir </font><font style="vertical-align: inherit;">dari video dan mentransfernya ke CNN. </font><font style="vertical-align: inherit;">Output CNN untuk setiap frame ditransmisikan sebagai input RNN. </font><font style="vertical-align: inherit;">Jaringan saraf berulang akan menentukan hubungan antara frame individu dan mengenali tindakan apa yang sesuai.</font></font><br><br><h1>  Kesimpulan </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pada artikel ini, kami mengembangkan model klasifikasi gambar. Untuk tujuan ini, kami mengumpulkan kumpulan data: kami mengekstraksi bingkai video dan secara manual membaginya menjadi tiga kategori. Kemudian data </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ditambah dengan</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> menambahkan gambar menggunakan </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;">imgaug</font></a><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Setelah itu, kami menjelaskan apa itu transfer pembelajaran dan menggunakan model MobileNet yang terlatih dari paket </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">@ tensorflow-models / mobilenet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> untuk tujuan kami </font><font style="vertical-align: inherit;">. Kami memuat MobileNet dari file dalam proses Node.js dan melatih lapisan padat tambahan tempat data diumpankan dari lapisan MobileNet yang tersembunyi. Setelah pelatihan, kami mencapai akurasi lebih dari 90%! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Untuk menggunakan model ini di browser, kami mengunduhnya bersama dengan MobileNet dan mulai mengkategorikan frame dari webcam pengguna setiap 100 ms. Kami menghubungkan model dengan game</font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MK.js</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dan menggunakan output model untuk mengontrol salah satu karakter. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Akhirnya, kami melihat bagaimana meningkatkan model dengan menggabungkannya dengan jaringan saraf berulang untuk mengenali tindakan. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Saya harap Anda menikmati proyek kecil ini tidak kurang dari yang saya lakukan! </font><font style="vertical-align: inherit;">‍</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id428019/">https://habr.com/ru/post/id428019/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id428003/index.html">Desain responsif: mempertahankan bentuk elemen markup</a></li>
<li><a href="../id428005/index.html">Tiga cara efektif untuk memperburuk bencana PR</a></li>
<li><a href="../id428007/index.html">Sudah bukan laptop luggable, belum notebook: Laptop TOSHIBA T3100 / 20</a></li>
<li><a href="../id428009/index.html">Equifax: setahun setelah kebocoran data terbesar</a></li>
<li><a href="../id428011/index.html">Lagu-lagu ruang zombie</a></li>
<li><a href="../id428021/index.html">Stempel terhadap jaringan saraf. Atau pilih dan jalankan jaringan saraf untuk mengenali objek pada Raspberry Zero</a></li>
<li><a href="../id428023/index.html">Dasar-dasar keselamatan listrik dalam desain perangkat elektronik</a></li>
<li><a href="../id428025/index.html">Menghubungkan file swap (SWAP) di MAC OS X saat menggunakan SSD eksternal sebagai suatu sistem</a></li>
<li><a href="../id428027/index.html">Bagaimana saya mencoba membuat analisa statis GLSL (dan apa yang salah)</a></li>
<li><a href="../id428029/index.html">Acara digital di Moskow dari 29 Oktober hingga 4 November</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
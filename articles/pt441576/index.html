<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👲🏾 🤾🏾 🤹🏽 Redes Kubernetes: Pods 🖱️ 🚢 🤾🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O material, cuja tradução publicamos hoje, é dedicado aos recursos da rede da lareira Kubernetes. Destina-se a quem já possui alguma experiência com o...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Redes Kubernetes: Pods</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/441576/">  O material, cuja tradução publicamos hoje, é dedicado aos recursos da rede da lareira Kubernetes.  Destina-se a quem já possui alguma experiência com o Kubernetes.  Se você ainda não conhece muito bem o Kubernetes, provavelmente vale a pena ler este tutorial do Kubernetes antes de ler este material, onde trabalhar com esta plataforma é destinado a iniciantes. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/webt/0_/ch/6q/0_ch6qrxl9vydilgtpyci7diugw.jpeg"></a> <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Pods</font> </h2><br>  O que há sob (pod) Kubernetes?  Sub é uma entidade que consiste em um ou mais contêineres hospedados no mesmo host e configurados para compartilhar recursos da pilha de rede e outros recursos, como volumes.  Os pods são os blocos de construção básicos que compõem aplicativos executados na plataforma Kubernetes.  Os pods compartilham uma pilha de rede.  Na prática, isso significa que todos os contêineres que compõem a lareira podem se comunicar através do <code>localhost</code> .  Se houver um contêiner no forno que executa nginx, escutando na porta 80 e outro contêiner que executa scrapyd, esse contêiner pode acessar o primeiro contêiner em <code>http://localhost:80</code> .  Não parece tão difícil.  Agora vamos nos perguntar como isso realmente funciona.  Vamos dar uma olhada em uma situação típica quando o contêiner do Docker é iniciado na máquina local. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/641/7fe/52a/6417fe52a2e9de3296187860905907f7.png"></div><br>  <i><font color="#999999">Contêiner do Docker em execução na máquina local</font></i> <br><br>  Se você observar esse esquema de cima para baixo, verifica-se que existe uma interface de rede física <code>eth0</code> .  A ponte <code>docker0</code> está <code>docker0</code> e a interface de rede virtual <code>docker0</code> está <code>veth0</code> à ponte.  Observe que as <code>veth0</code> e <code>veth0</code> estão na mesma rede; neste exemplo, é <code>172.17.0.0/24</code> .  Nesta rede, a interface <code>docker0</code> recebe o endereço IP <code>172.17.0.1</code> , essa interface é o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">gateway padrão</a> para a interface <code>veth0</code> , que recebe o endereço <code>172.17.0.2</code> .  Devido às peculiaridades da configuração de namespaces de rede ao iniciar o contêiner, os processos dentro do contêiner veem apenas a interface <code>veth0</code> e interagem com o mundo externo por meio das interfaces <code>docker0</code> e <code>eth0</code> .  Agora execute o segundo contêiner. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8b4/33a/915/8b433a91572e4afa0f9652d4e729a8b3.png"></div><br>  <i><font color="#999999">Dois contêineres do Docker em execução na máquina local</font></i> <br><br>  Como você pode ver no diagrama acima, a nova interface de rede virtual <code>veth1</code> é atribuída ao segundo contêiner, que é conectado à mesma ponte que o primeiro contêiner - ao <code>docker0</code> .  Esta é uma descrição bastante concisa do que realmente está acontecendo.  Além disso, deve-se observar que a conexão entre o contêiner e a ponte é estabelecida graças a um par de interfaces Ethernet virtuais conectadas, uma delas no espaço de nomes do contêiner e a outra no espaço de nomes da rede raiz.  Detalhes sobre isso podem ser encontrados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br>  Tudo isso é bom, mas ainda não descreve o que chamamos de pilha de rede compartilhada, conforme aplicada aos pods do Kubernetes.  Felizmente, os namespaces são altamente flexíveis.  O Docker pode iniciar um contêiner e, em vez de criar uma nova interface de rede virtual, fazer com que ele use a interface existente junto com outros contêineres.  Com essa abordagem, teremos que alterar o esquema acima, como mostrado abaixo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/456/4f6/5fb/4564f65fb5ed8773794f98f7655f0523.png"></div><br>  <i><font color="#999999">Os contêineres usam uma interface de rede comum</font></i> <br><br>  Agora, o segundo contêiner interage com a interface <code>veth0</code> já existente, e não com sua própria interface <code>veth1</code> , como no exemplo anterior.  O uso de tal esquema leva a várias consequências.  Para começar, agora podemos dizer que os dois contêineres são visíveis externamente no mesmo endereço - <code>172.17.0.2</code> , e dentro de cada um deles podem acessar as portas no <code>localhost</code> aberto por outro contêiner.  Além disso, isso significa que esses contêineres não podem abrir as mesmas portas.  Obviamente, isso é uma limitação, mas não difere de uma limitação semelhante na situação em que vários processos abrem portas no mesmo host.  Com essa abordagem, um conjunto de processos obtém todas as vantagens associadas à execução desses processos em contêineres, como baixa conectividade e isolamento, mas, ao mesmo tempo, os processos podem organizar a colaboração no mais simples dos ambientes de rede existentes. <br><br>  O Kubernetes implementa esse padrão criando um contêiner especial para cada lareira, cujo único objetivo é fornecer uma interface de rede para outros contêineres da lareira.  Se você se conectar ao nó do cluster Kubernetes ao qual é atribuído um sub específico pelo <code>ssh</code> e executar o <code>docker ps</code> , verá pelo menos um contêiner em execução com o comando <code>pause</code> .  Este comando pausa o processo atual até que um sinal <code>SIGTERM</code> chegue.  Esses recipientes não fazem absolutamente nada, eles estão no estado "adormecido" e aguardam esse sinal.  Apesar de os contêineres "suspensos" não fazerem nada, eles são, por assim dizer, o "coração" da lareira, fornecendo aos outros contêineres uma interface de rede virtual que eles podem usar para interagir entre si ou com o mundo externo.  Como resultado, verifica-se que, em um ambiente hipotético semelhante a, nosso esquema anterior se pareceria com o mostrado abaixo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3b0/e06/d66/3b0e06d66041a5dd0946f43c94314dae.png"></div><br>  <i><font color="#999999">Recipientes hipotéticos</font></i> <br><br><h2>  <font color="#3AC1EF">Rede de lareira</font> </h2><br>  Um deles, cheio de contêineres, é o alicerce de um determinado sistema, mas até agora não o próprio sistema.  A arquitetura do Kubernetes é baseada no requisito de que os lares devem poder interagir com outros, independentemente de serem executados no mesmo computador ou em máquinas diferentes.  Para aprender como tudo isso funciona, precisamos ir para um nível mais alto de abstração e conversar sobre como os nós funcionam no cluster Kubernetes.  Aqui abordaremos o tópico roteamento e rotas de rede.  Esse tópico geralmente é evitado em materiais como esse, considerando-o muito complexo.  Não é fácil encontrar um guia compreensível e não muito longo para o roteamento IP, mas se você quiser ver uma breve visão geral desse problema, consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">este</a> material. <br><br>  O cluster Kubernetes consiste em um ou mais nós.  Um nó é um sistema host, físico ou virtual, que contém várias ferramentas de software e suas dependências (principalmente o Docker), além de vários componentes do sistema Kubernetes.  O nó está conectado à rede, o que permite trocar dados com outros nós no cluster.  Aqui está a aparência de um cluster simples de dois nós. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/477/db1/b20/477db1b2030b13c41178a48821916fcc.png"></div><br>  <i><font color="#999999">Um cluster simples de dois nós</font></i> <br><br>  Se o cluster em questão estiver sendo executado em um ambiente de nuvem como GCP ou AWS, esse esquema transmitirá com precisão a essência da arquitetura de rede padrão para projetos individuais.  Para fins de demonstração, a rede privada <code>10.100.0.0/24</code> usada neste exemplo.  Como resultado, o endereço <code>10.100.0.1</code> atribuído ao <code>10.100.0.1</code> e os endereços <code>10.100.0.2</code> e <code>10.100.0.3</code> dois nós.  Usando essa arquitetura, cada um dos nós pode interagir com o outro usando sua interface de rede <code>eth0</code> .  Agora, lembre-se de que under, em execução no host, não está nesta rede privada.  É conectado à ponte em uma rede completamente diferente.  Esta é uma rede virtual que existe apenas dentro de um nó específico.  Para tornar mais claro, vamos redesenhar o esquema anterior, adicionando a ele o que chamamos de lareira hipotética acima. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ff6/721/c32/ff6721c32b5d74bc80fccfbf6164e486.png"></div><br>  <i><font color="#999999">Pods e nós</font></i> <br><br>  O host localizado à esquerda deste diagrama possui uma interface <code>eht0</code> com o endereço <code>10.100.0.2</code> , cujo gateway padrão é o roteador com o endereço <code>10.100.0.1</code> .  A ponte <code>docker0</code> com o endereço <code>172.17.0.1</code> conectada a essa interface e a ela, através da interface virtual <code>veth0</code> com o endereço <code>172.17.0.2</code> , está conectada ao que chamamos aqui de lareira.  A interface <code>veth0</code> foi criada em um contêiner suspenso.  É visível nos três contêineres através de uma pilha de rede compartilhada.  Devido ao fato de as regras de roteamento local serem configuradas ao criar a ponte, qualquer pacote que chegue a <code>eth0</code> e tenha o endereço de destino <code>172.17.0.2</code> será redirecionado para a ponte, que o encaminhará para a interface virtual <code>veth0</code> .  Enquanto tudo isso parece bastante decente.  Se for sabido que o host que estamos discutindo possui o endereço <code>172.17.0.2</code> , podemos adicionar uma regra às configurações do roteador que descrevem que a próxima transição para esse endereço é <code>10.100.0.2</code> , após a qual os pacotes a partir daí deverão ser redirecionados para <code>veth0</code> .  Excelente.  Agora vamos dar uma olhada em outro host. <br><br>  O host mostrado no diagrama à direita possui uma interface física <code>eth0</code> com o endereço <code>10.100.0.3</code> .  Ele usa o mesmo gateway padrão - <code>10.100.0.1</code> e, novamente, está conectado à ponte <code>docker0</code> com o endereço <code>172.17.0.1</code> .  Há um sentimento de que tudo não está indo tão bem.  Este endereço, de fato, pode diferir daquele usado no host localizado à esquerda.  Os endereços das pontes aqui são os mesmos para demonstrar o pior cenário possível, o que, por exemplo, pode ocorrer se você acabou de instalar o Docker e deixá-lo funcionar como bem entender.  Mas, mesmo que as redes em questão sejam diferentes, nosso exemplo destaca um problema mais profundo: os nós geralmente não sabem nada sobre quais endereços privados são atribuídos a pontes localizadas em outros nós.  E precisamos saber sobre isso - para poder enviar pacotes para essas pontes e ter certeza de que eles chegarão onde precisam.  Obviamente, aqui precisamos de algum tipo de entidade, o que nos permite garantir a configuração correta de endereços em diferentes nós. <br><br>  A plataforma Kubernetes fornece uma solução em duas etapas para esse problema.  Primeiro, essa plataforma atribui um espaço de endereço comum para pontes em cada nó e, em seguida, atribui às pontes os endereços nesse espaço com base em qual nó a ponte está.  Em segundo lugar, o Kubernetes adiciona regras de roteamento ao gateway localizado, no nosso caso, em <code>10.100.0.1</code> .  Essas regras definem as regras para rotear pacotes destinados a cada uma das pontes.  Ou seja, eles descrevem através da qual a interface física <code>eth0</code> pode ser contatada com cada uma das pontes.  Essa combinação de interfaces de rede virtual, pontes e regras de roteamento é comumente chamada de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rede de sobreposição</a> .  Por falar em Kubernetes, costumo chamar essa rede de “rede de lareira”, pois é uma rede de sobreposição que permite que pods localizados em diferentes nós se comuniquem.  Aqui está a aparência do diagrama anterior depois que os mecanismos do Kubernetes começarem a funcionar. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b9c/f87/c96/b9cf87c96d0169dbcd0846f8bb3cd323.png"></div><br>  <i><font color="#999999">Rede de lareira</font></i> <br><br>  Imediatamente chama a atenção que os nomes da ponte foram alterados de <code>docker0</code> para <code>cbr0</code> .  O Kubernetes não usa pontes padrão do Docker.  O que chamamos de <code>cbr</code> é uma abreviação de “ponte personalizada”, ou seja, estamos falando de algumas pontes especiais.  Não estou pronto para fornecer uma lista completa das diferenças entre executar contêineres do Docker em pods e executá-los em computadores comuns, mas o que estamos falando aqui é uma das importantes diferenças semelhantes.  Além disso, você precisa prestar atenção ao fato de que o espaço de endereço atribuído às pontes neste exemplo é <code>10.0.0.0/14</code> .  Esse endereço é obtido de um de nossos clusters de armazenamento temporário, implantados na plataforma Google Cloud. Portanto, o exemplo acima é um exemplo muito real de uma rede de lareira.  Seu cluster pode receber um intervalo completamente diferente de endereços.  Infelizmente, no momento não há como obter informações sobre esses endereços usando o utilitário <code>kubectl</code> , mas, por exemplo, se você usa o GCP, pode executar um comando como os <code>gcloud container clusters describe &lt;cluster&gt;</code> e observa a propriedade <code>clusterIpv4Cidr</code> . <br><br>  Em geral, pode-se notar que você geralmente não precisa pensar em como a rede da lareira funciona.  Quando uma sub-troca de dados com outra lareira, na maioria das vezes isso acontece através dos serviços Kubernetes.  Este é um pouco de proxy definido por software.  Mas os endereços de rede das lareiras aparecem nos logs.  Em algumas situações, principalmente durante a depuração, pode ser necessário definir explicitamente as regras de roteamento nas redes da lareira.  Por exemplo, o tráfego que deixa o Kubernetes vinculado a qualquer endereço no intervalo 10.0.0.0/8 não é processado por padrão usando o NAT.  Portanto, se você interagir com serviços localizados em outra rede privada com o mesmo intervalo de endereços, pode ser necessário configurar regras de roteamento que permitam organizar a entrega correta dos pacotes. <br><br><h2>  <font color="#3AC1EF">Sumário</font> </h2><br>  Hoje falamos sobre os pods do Kubernetes e os recursos de suas redes.  Esperamos que este material ajude você a tomar as medidas corretas para implementar cenários complexos de interação da lareira nas redes Kubernetes. <br><br>  <b>Caros leitores!</b>  Este artigo é o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">primeiro de uma</a> série de redes Kubernetes.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A segunda</a> parte deste ciclo já foi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">traduzida</a> .  Estamos pensando em traduzir a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">terceira</a> parte.  Pedimos que você comente sobre isso nos comentários. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt441576/">https://habr.com/ru/post/pt441576/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt441566/index.html">12 conceitos de JavaScript para conhecer</a></li>
<li><a href="../pt441568/index.html">Gerenciamento de memória Python</a></li>
<li><a href="../pt441570/index.html">O resumo de materiais frescos do mundo do front-end da última semana n ° 353 (17 a 24 de fevereiro de 2019)</a></li>
<li><a href="../pt441572/index.html">Frontend Weekly Digest (18 a 24 de fevereiro de 2019)</a></li>
<li><a href="../pt441574/index.html">Docker de aprendizagem Parte 6: Trabalhando com dados</a></li>
<li><a href="../pt441578/index.html">Tutorial Reagir Parte 19: Métodos do Ciclo de Vida dos Componentes</a></li>
<li><a href="../pt441580/index.html">Tutorial Reagir Parte 20: Primeira lição de renderização condicional</a></li>
<li><a href="../pt441582/index.html">Otimização do sistema de controle LQR</a></li>
<li><a href="../pt441584/index.html">PHP Digest No. 150 (11 a 25 de fevereiro de 2019)</a></li>
<li><a href="../pt441586/index.html">Como recomendar músicas que quase ninguém ouviu. Relatório Yandex</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîù üìÅ üò≠ Das Buch Kafka Streams in Aktion. Echtzeitanwendungen und Microservices ¬ª üìá ü§õ üôáüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo habrozhiteli! Dieses Buch eignet sich f√ºr alle Entwickler, die die Streaming-Verarbeitung verstehen m√∂chten. Wenn Sie die verteilte Programmieru...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Das Buch Kafka Streams in Aktion. Echtzeitanwendungen und Microservices ¬ª</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/457756/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/na/mw/fb/namwfbeornc4ba8jkaodlvjlm68.jpeg" align="left" alt="Bild"></a>  Hallo habrozhiteli!  Dieses Buch eignet sich f√ºr alle Entwickler, die die Streaming-Verarbeitung verstehen m√∂chten.  Wenn Sie die verteilte Programmierung verstehen, k√∂nnen Sie Kafka und Kafka Streams besser verstehen.  Es w√§re sch√∂n, das Kafka-Framework selbst zu kennen, aber das ist nicht notwendig: Ich werde Ihnen alles erz√§hlen, was Sie brauchen.  Dank dieses Buches lernen erfahrene Kafka-Entwickler wie Anf√§nger, wie sie mithilfe der Kafka Streams-Bibliothek interessante Streaming-Anwendungen erstellen.  Fortgeschrittene und hochrangige Java-Entwickler, die bereits mit Konzepten wie der Serialisierung vertraut sind, lernen, wie sie ihre F√§higkeiten anwenden k√∂nnen, um Kafka Streams-Anwendungen zu erstellen.  Der Quellcode des Buches ist in Java 8 geschrieben und verwendet im Wesentlichen die Syntax von Lambda-Ausdr√ºcken von Java 8, sodass die F√§higkeit, mit Lambda-Funktionen (auch in einer anderen Programmiersprache) zu arbeiten, f√ºr Sie n√ºtzlich ist. <br><a name="habracut"></a><br><h3>  Auszug.  5.3.  Aggregations- und Fensteroperationen </h3><br>  In diesem Abschnitt gehen wir zu den vielversprechendsten Teilen von Kafka Streams √ºber.  Bisher haben wir folgende Aspekte von Kafka Streams behandelt: <br><br><ul><li>  Erstellen einer Verarbeitungstopologie; </li><li>  Verwendung des Status in Streaming-Anwendungen; </li><li>  Herstellen von Datenstromverbindungen; </li><li>  Unterschiede zwischen Ereignisstr√∂men (KStream) und Aktualisierungsstr√∂men (KTable). </li></ul><br>  In den folgenden Beispielen werden wir alle diese Elemente zusammenfassen.  Dar√ºber hinaus werden Sie in die Fensteroperationen eingef√ºhrt - eine weitere gro√üartige Funktion von Streaming-Anwendungen.  Unser erstes Beispiel wird die einfache Aggregation sein. <br><br><h3>  5.3.1.  Aggregation der Aktienverk√§ufe nach Branchen </h3><br>  Aggregation und Gruppierung sind wichtige Werkzeuge f√ºr die Arbeit mit Streaming-Daten.  Die Pr√ºfung einzelner Unterlagen auf Zulassungsbasis reicht oft nicht aus.  Um zus√§tzliche Informationen aus den Daten zu extrahieren, sind deren Gruppierung und Kombination erforderlich. <br><br>  In diesem Beispiel m√ºssen Sie den Anzug eines Intraday-H√§ndlers anprobieren, der das Verkaufsvolumen von Aktien von Unternehmen in verschiedenen Branchen verfolgen muss.  Sie interessieren sich insbesondere f√ºr die f√ºnf Unternehmen mit den gr√∂√üten Umsatzverk√§ufen in jeder Branche. <br><br>  F√ºr eine solche Aggregation ben√∂tigen Sie mehrere der folgenden Schritte, um die Daten (allgemein) in die gew√ºnschte Form zu √ºbersetzen. <br><br><ol><li>  Erstellen Sie eine themenbasierte Quelle, die Informationen zum Rohstoffhandel ver√∂ffentlicht.  Wir m√ºssen ein Objekt vom Typ StockTransaction einem Objekt vom Typ ShareVolume zuordnen.  Tatsache ist, dass das StockTransaction-Objekt Verkaufsmetadaten enth√§lt und wir nur Daten zur Anzahl der verkauften Aktien ben√∂tigen. </li><li>  Gruppieren Sie ShareVolume-Daten nach Aktiensymbolen.  Nach der Gruppierung nach Symbolen k√∂nnen Sie diese Daten auf Zwischensummen der Aktienverk√§ufe reduzieren.  Es ist erw√§hnenswert, dass die KStream.groupBy-Methode eine Instanz vom Typ KGroupedStream zur√ºckgibt.  Und Sie k√∂nnen eine KTable-Instanz erhalten, indem Sie sp√§ter die KGroupedStream.reduce-Methode aufrufen. </li></ol><br><blockquote>  <b>Was ist die KGroupedStream-Schnittstelle?</b> <br><br>  Die Methoden KStream.groupBy und KStream.groupByKey geben eine Instanz von KGroupedStream zur√ºck.  KGroupedStream ist eine Zwischendarstellung des Ereignisstroms nach Gruppierung nach Schl√ºssel.  Es ist √ºberhaupt nicht daf√ºr gedacht, direkt damit zu arbeiten.  Stattdessen wird KGroupedStream f√ºr Aggregationsoperationen verwendet, deren Ergebnis immer KTable ist.  Und da das Ergebnis von Aggregationsoperationen KTable ist und sie den Statusspeicher verwenden, ist es m√∂glich, dass nicht alle Aktualisierungen als Ergebnis weiter unten in der Pipeline gesendet werden. <br><br>  Die KTable.groupBy-Methode gibt eine √§hnliche KGroupedTable zur√ºck - eine Zwischendarstellung des nach Schl√ºssel neu gruppierten Aktualisierungsstroms. </blockquote><br>  Machen wir eine kurze Pause und schauen uns Abb.  5.9 zeigt, was wir erreicht haben.  Diese Topologie sollte Ihnen bereits bekannt sein. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9v/p3/ne/9vp3ne2cqpquhvlkmjo6wncqwsm.png" alt="Bild"></div><br>  Schauen wir uns nun den Code f√ºr diese Topologie an (er befindet sich in der Datei src / main / java / bbejeck / kapitel_5 / AggregationsAndReducingExample.java) (Listing 5.2). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/8w/cz/lz/8wczlzab4gf5y7sjluyyu2f1vdi.png" alt="Bild"></div><br>  Der angegebene Code unterscheidet sich in der K√ºrze und in einer gro√üen Anzahl von Aktionen, die in mehreren Zeilen ausgef√ºhrt werden.  Im ersten Parameter der Methode builder.stream k√∂nnen Sie etwas Neues f√ºr sich feststellen: den Wert des Aufz√§hlungstyps AutoOffsetReset.EARLIEST (es gibt auch LATEST), der mit der Methode Consumed.withOffsetResetPolicy festgelegt wurde.  Mit diesem Aufz√§hlungstyp k√∂nnen Sie eine Strategie zum Zur√ºcksetzen von Offsets f√ºr KStream oder KTable angeben, die Vorrang vor dem Parameter zum Zur√ºcksetzen von Offsets aus der Konfiguration hat. <br><br><blockquote>  <b>GroupByKey und GroupBy</b> <br><br>  Die KStream-Schnittstelle verf√ºgt √ºber zwei Methoden zum Gruppieren von Datens√§tzen: GroupByKey und GroupBy.  Beide geben KGroupedTable zur√ºck, sodass Sie m√∂glicherweise eine berechtigte Frage haben: Was ist der Unterschied zwischen ihnen und wann welche zu verwenden sind? <br><br>  Die GroupByKey-Methode wird verwendet, wenn die Schl√ºssel in KStream bereits nicht leer sind.  Und am wichtigsten ist, dass das Flag "Neupartitionierung erforderlich" nie gesetzt wurde. <br><br>  Bei der GroupBy-Methode wird davon ausgegangen, dass Sie die Schl√ºssel f√ºr die Gruppierung ge√§ndert haben, sodass das Flag f√ºr die erneute Partitionierung auf true gesetzt ist.  Das Durchf√ºhren von Verbindungen, Aggregationen usw. nach der GroupBy-Methode f√ºhrt zu einer automatischen Neupartitionierung. <br>  Zusammenfassung: Sie sollten nach M√∂glichkeit GroupByKey anstelle von GroupBy verwenden. </blockquote><br>  Was die Methoden mapValues ‚Äã‚Äãund groupBy tun, ist verst√§ndlich. Schauen Sie sich also die sum () -Methode an (sie befindet sich in der Datei src / main / java / bbejeck / model / ShareVolume.java) (Listing 5.3). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/va/bb/e5/vabbe54p2ntwmyk1yllak6s4m4q.png" alt="Bild"></div><br>  Die ShareVolume.sum-Methode gibt die Zwischensumme des Aktienverkaufsvolumens zur√ºck, und das Ergebnis der gesamten Berechnungskette ist ein KTable &lt;String, ShareVolume&gt; -Objekt.  Jetzt verstehen Sie, welche Rolle KTable spielt.  Wenn ShareVolume-Objekte eintreffen, wird das neueste aktuelle Update in der entsprechenden KTable gespeichert.  Es ist wichtig, nicht zu vergessen, dass alle Aktualisierungen in der vorherigen shareVolumeKTable wiedergegeben werden, aber nicht alle weiter gesendet werden. <br><br>  Dar√ºber hinaus f√ºhren wir mit Hilfe dieser KTable eine Aggregation (nach Anzahl der verkauften Aktien) durch, um die f√ºnf Unternehmen mit den h√∂chsten Aktienverk√§ufen in jeder Branche zu erhalten.  Unsere Aktionen in diesem Fall √§hneln den Aktionen w√§hrend der ersten Aggregation. <br><br><ol><li>  F√ºhren Sie eine weitere groupBy-Operation aus, um einzelne ShareVolume-Objekte nach Branchen zu gruppieren. </li><li>  Fahren Sie fort, um ShareVolume-Objekte zusammenzufassen.  Dieses Mal ist das Aggregationsobjekt eine Priorit√§tswarteschlange fester Gr√∂√üe.  Nur f√ºnf Unternehmen mit der gr√∂√üten Anzahl verkaufter Aktien werden in einer solchen Warteschlange mit fester Gr√∂√üe gehalten. </li><li>  Zeigen Sie die Zeilen aus dem vorherigen Absatz in einem Zeichenfolgenwert an und geben Sie die f√ºnf meistverkauften nach Anzahl der Aktien nach Branchen zur√ºck. </li><li>  Schreiben Sie die Ergebnisse in Zeichenfolgenform in das Thema. </li></ol><br>  In Abb.  5.10 zeigt ein Diagramm der Topologie der Datenbewegung.  Wie Sie sehen k√∂nnen, ist die zweite Verarbeitungsrunde recht einfach. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4q/3p/j5/4q3pj5lkggxqnu6lpcmtgo52dqq.png" alt="Bild"></div><br>  Nachdem Sie die Struktur dieser zweiten Verarbeitungsrunde klar verstanden haben, k√∂nnen Sie auf den Quellcode verweisen (Sie finden ihn in der Datei src / main / java / bbejeck / kapitel_5 / AggregationsAndReducingExample.java) (Listing 5.4). <br><br>  In diesem Initialisierer befindet sich eine Variable fixedQueue.  Dies ist ein benutzerdefiniertes Objekt - ein Adapter f√ºr java.util.TreeSet, mit dem N h√∂chste Ergebnisse in absteigender Reihenfolge der Anzahl der verkauften Aktien verfolgt werden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/03/mn/nm/03mnnmhuvjpivozqptxxzpkdrmu.png" alt="Bild"></div><br>  Sie haben bereits Aufrufe von groupBy und mapValues ‚Äã‚Äãfestgestellt, sodass wir nicht damit aufh√∂ren (wir rufen die KTable.toStream-Methode auf, da die KTable.print-Methode veraltet ist).  Sie haben die KTable-Version der aggregate () -Methode jedoch noch nicht gesehen, daher werden wir einige Zeit damit verbringen, sie zu diskutieren. <br><br>  Wie Sie sich erinnern, zeichnet sich KTable dadurch aus, dass Datens√§tze mit denselben Schl√ºsseln als Aktualisierungen betrachtet werden.  KTable ersetzt den alten Datensatz durch den neuen.  Die Aggregation erfolgt auf die gleiche Weise: Die letzten Datens√§tze mit einem Schl√ºssel werden aggregiert.  Wenn ein Datensatz eintrifft, wird er mithilfe eines Addierers (der zweite Parameter im Aufruf der Aggregatmethode) zu einer Instanz der FixedSizePriorityQueue-Klasse hinzugef√ºgt. Wenn jedoch bereits ein anderer Datensatz mit demselben Schl√ºssel vorhanden ist, wird der alte Datensatz mit dem Subtrahierer gel√∂scht (der dritte Parameter im Aufruf der Aggregatmethode). <br><br>  Dies alles bedeutet, dass unser Aggregator FixedSizePriorityQueue nicht alle Werte mit einem Schl√ºssel aggregiert, sondern die gleitende Summe der Mengen N der meistverkauften Arten von Aktien speichert.  Jeder Eintrag enth√§lt die Gesamtzahl der bisher verkauften Aktien.  KTable gibt Ihnen Auskunft dar√ºber, welche Aktien von Unternehmen derzeit am meisten verkauft werden. Eine fortlaufende Aggregation jedes Updates ist nicht erforderlich. <br><br>  Wir haben gelernt, zwei wichtige Dinge zu tun: <br><br><ul><li>  Gruppieren Sie die Werte in KTable nach einem ihnen gemeinsamen Schl√ºssel. </li><li>  F√ºhren Sie n√ºtzliche Operationen wie Faltung und Aggregation f√ºr diese gruppierten Werte aus. </li></ul><br>  Die F√§higkeit, diese Vorg√§nge auszuf√ºhren, ist wichtig, um die Bedeutung der Daten zu verstehen, die durch die Kafka Streams-Anwendung √ºbertragen werden, und um herauszufinden, welche Informationen sie enthalten. <br><br>  Wir haben auch einige der Schl√ºsselkonzepte zusammengestellt, die weiter oben in diesem Buch er√∂rtert wurden.  In Kapitel 4 haben wir dar√ºber gesprochen, wie wichtig ein ausfallsicherer lokaler Status f√ºr eine Streaming-Anwendung ist.  Das erste Beispiel in diesem Kapitel hat gezeigt, warum der lokale Status so wichtig ist - es erm√∂glicht, zu verfolgen, welche Informationen Sie bereits gesehen haben.  Durch den lokalen Zugriff werden Netzwerkverz√∂gerungen vermieden, wodurch die Anwendung produktiver und fehlerresistenter wird. <br><br>  Wenn Sie eine Faltungs- oder Aggregationsoperation ausf√ºhren, m√ºssen Sie den Namen des Statusspeichers angeben.  Faltungs- und Aggregationsoperationen geben eine KTable-Instanz zur√ºck, und KTable verwendet einen Statusspeicher, um alte Ergebnisse durch neue zu ersetzen.  Wie Sie gesehen haben, werden nicht alle Aktualisierungen weiter unten in der Pipeline gesendet. Dies ist wichtig, da Aggregationsvorg√§nge darauf ausgelegt sind, die endg√ºltigen Informationen zu erhalten.  Wenn der lokale Status nicht angewendet wird, sendet KTable alle Aggregations- und Faltungsergebnisse weiter. <br><br>  Als n√§chstes betrachten wir die Ausf√ºhrung von Operationen wie der Aggregation innerhalb eines bestimmten Zeitraums - der sogenannten Fensteroperationen. <br><br><h3>  5.3.2.  Fensteroperationen </h3><br>  Im vorherigen Abschnitt haben wir die ‚Äûrollende‚Äú Faltung und Aggregation eingef√ºhrt.  Die Anwendung f√ºhrte eine kontinuierliche Faltung der Aktienverk√§ufe mit anschlie√üender Aggregation der f√ºnf meistverkauften Aktien durch. <br><br>  Manchmal ist eine solche kontinuierliche Aggregation und Faltung der Ergebnisse notwendig.  Und manchmal m√ºssen Sie Operationen nur in einem bestimmten Zeitraum ausf√ºhren.  Berechnen Sie beispielsweise, wie viele B√∂rsentransaktionen mit Aktien eines bestimmten Unternehmens in den letzten 10 Minuten durchgef√ºhrt wurden.  Oder wie viele Nutzer in den letzten 15 Minuten auf ein neues Werbebanner geklickt haben.  Eine Anwendung kann solche Vorg√§nge mehrmals ausf√ºhren, wobei sich die Ergebnisse jedoch nur auf bestimmte Zeitintervalle (Zeitfenster) beziehen. <br><br><h3>  Z√§hlen von Umtauschtransaktionen durch den K√§ufer </h3><br>  Im folgenden Beispiel werden wir B√∂rsentransaktionen f√ºr mehrere H√§ndler verfolgen - entweder gro√üe Organisationen oder intelligente Einhandfinanzierer. <br><br>  Es gibt zwei m√∂gliche Gr√ºnde f√ºr diese Verfolgung.  Eine davon ist die Notwendigkeit zu wissen, welche Marktf√ºhrer kaufen / verkaufen.  Wenn diese gro√üen Akteure und anspruchsvollen Investoren Chancen f√ºr sich selbst sehen, ist es sinnvoll, ihrer Strategie zu folgen.  Der zweite Grund ist der Wunsch, m√∂gliche Anzeichen f√ºr illegale Transaktionen mithilfe von Insiderinformationen zu erkennen.  Dazu m√ºssen Sie die Korrelation gro√üer Umsatzspitzen mit wichtigen Pressemitteilungen analysieren. <br><br>  Eine solche Verfolgung besteht aus folgenden Schritten: <br><br><ul><li>  Erstellen eines Streams zum Lesen aus dem Thema B√∂rsentransaktionen; </li><li>  Gruppierung eingehender Datens√§tze nach Kunden-ID und Bestandsymbol des Bestands.  Ein Aufruf der groupBy-Methode gibt eine Instanz der KGroupedStream-Klasse zur√ºck. </li><li>  KGroupedStream.windowedBy gibt einen Datenstrom zur√ºck, der durch ein tempor√§res Fenster begrenzt ist und die Fensteraggregation erm√∂glicht.  Je nach Fenstertyp wird entweder TimeWindowedKStream oder SessionWindowedKStream zur√ºckgegeben. </li><li>  Z√§hlen von Transaktionen f√ºr eine Aggregationsoperation.  Der Fensterdatenstrom bestimmt, ob ein bestimmter Datensatz bei dieser Berechnung ber√ºcksichtigt wird. </li><li>  Schreiben Sie Ergebnisse in ein Thema oder geben Sie sie w√§hrend der Entwicklung an die Konsole aus. </li></ul><br>  Die Topologie dieser Anwendung ist einfach, aber das visuelle Bild tut nicht weh.  Schauen Sie sich das Bild an.  5.11. <br><br>  Weiter werden wir die Funktionalit√§t von Fensteroperationen und den entsprechenden Code betrachten. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1h/bd/fi/1hbdfi2s0x4x4up8kkcomwg_omq.png" alt="Bild"></div><br><h3>  Fenstertypen </h3><br>  In Kafka Streams gibt es drei Arten von Fenstern: <br><br><ul><li>  Sitzung </li><li>  Stolpern (Stolpern); </li><li>  gleiten / "springen" (gleiten / h√ºpfen). </li></ul><br>  Welche Sie w√§hlen m√ºssen, h√§ngt von den Gesch√§ftsanforderungen ab.  Die Fenster "Tumbling" und "Jumping" sind zeitlich begrenzt, w√§hrend Sitzungsbeschr√§nkungen mit Benutzeraktionen verbunden sind. Die Dauer der Sitzung (en) h√§ngt ausschlie√ülich davon ab, wie aktiv sich der Benutzer verh√§lt.  Die Hauptsache ist nicht zu vergessen, dass alle Fenstertypen auf Datums- / Zeitstempeln von Datens√§tzen und nicht auf der Systemzeit basieren. <br><br>  Als n√§chstes implementieren wir unsere Topologie mit jedem der Fenstertypen.  Der vollst√§ndige Code wird nur im ersten Beispiel angegeben. F√ºr andere Fenstertypen √§ndert sich nichts, au√üer f√ºr die Art der Fensteroperation. <br><br><h3>  Sitzungsfenster </h3><br>  Sitzungsfenster unterscheiden sich stark von allen anderen Fenstertypen.  Sie sind weniger zeitlich als vielmehr durch die Aktivit√§t des Benutzers (oder die Aktivit√§t der Entit√§t, die Sie verfolgen m√∂chten) begrenzt.  Sitzungsfenster werden durch Inaktivit√§tsperioden begrenzt. <br><br>  Abbildung 5.12 zeigt das Konzept der Sitzungsfenster.  Eine kleinere Sitzung wird mit der Sitzung auf der linken Seite zusammengef√ºhrt.  Und die Sitzung auf der rechten Seite wird getrennt sein, da sie auf eine lange Zeit der Inaktivit√§t folgt.  Sitzungsfenster basieren auf Benutzeraktionen, wenden jedoch Datums- / Zeitstempel aus Datens√§tzen an, um zu bestimmen, zu welcher Sitzung der Datensatz geh√∂rt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/js/c7/z5/jsc7z525p9wrj_tlmrfa5e3vj_u.png" alt="Bild"></div><br><br><h3>  Verwenden von Sitzungsfenstern zum Verfolgen von Exchange-Transaktionen </h3><br>  Wir werden Sitzungsfenster verwenden, um Informationen √ºber Austauschtransaktionen zu erfassen.  Die Implementierung der Sitzungsfenster ist in Listing 5.5 dargestellt (zu finden in src / main / java / bbejeck / kapitel_5 / CountingWindowingAndKTableJoinExample.java). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vs/vq/va/vsvqvaqddc3hgy-77fpniuwcbxm.png" alt="Bild"></div><br>  Sie haben die meisten Operationen dieser Topologie bereits ausgef√ºhrt, sodass Sie sie hier nicht erneut betrachten m√ºssen.  Es gibt jedoch einige neue Elemente, die wir jetzt diskutieren werden. <br><br>  F√ºr jede groupBy-Operation wird normalerweise eine Art Aggregationsoperation (Aggregation, Faltung oder Z√§hlung) ausgef√ºhrt.  Sie k√∂nnen entweder eine kumulative Aggregation mit einer kumulierten Summe oder eine Fensteraggregation durchf√ºhren, bei der Datens√§tze innerhalb eines bestimmten Zeitfensters ber√ºcksichtigt werden. <br><br>  Der Code in Listing 5.5 z√§hlt die Anzahl der Transaktionen in Sitzungsfenstern.  In Abb.  5.13 Diese Aktionen werden Schritt f√ºr Schritt analysiert. <br><br>  Durch Aufrufen von windowedBy (SessionWindows.with (zwanzig Sekunden). Bis (f√ºnfzehn Minuten)) erstellen wir ein Sitzungsfenster mit einem Leerlaufintervall von 20 Sekunden und einem Aufbewahrungsintervall von 15 Minuten.  Ein Inaktivit√§tsintervall von 20 Sekunden bedeutet, dass die Anwendung alle Datens√§tze enth√§lt, die innerhalb von 20 Sekunden nach dem Ende oder Beginn der aktuellen Sitzung in der aktuellen (aktiven) Sitzung eintreffen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jh/mk/qv/jhmkqvxrrnrd5mxavzltcu-uglq.png" alt="Bild"></div><br>  Als n√§chstes geben wir an, welche Aggregationsoperation im Sitzungsfenster ausgef√ºhrt werden soll - in diesem Fall z√§hlen.  Wenn der eingehende Datensatz au√üerhalb des Inaktivit√§tsintervalls (auf beiden Seiten des Datums- / Zeitstempels) liegt, erstellt die Anwendung eine neue Sitzung.  Ein Speicherintervall bedeutet, dass eine Sitzung f√ºr eine bestimmte Zeit beibehalten wird und sp√§te Daten ber√ºcksichtigt werden, die √ºber den Zeitraum der Inaktivit√§t der Sitzung hinausgehen, aber dennoch angeh√§ngt werden k√∂nnen.  Dar√ºber hinaus entsprechen der Beginn und das Ende einer neuen Sitzung, die sich aus der Zusammenf√ºhrung ergibt, dem fr√ºhesten und sp√§testen Datums- / Zeitstempel. <br><br>  Schauen wir uns einige Eintr√§ge aus der Z√§hlmethode an, um zu sehen, wie die Sitzungen funktionieren (Tabelle 5.1). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/p-/_f/pn/p-_fpnxaicjsj0ivwzrcxthi77g.png" alt="Bild"></div><br>  Nach Erhalt der Aufzeichnungen suchen wir nach bereits vorhandenen Sitzungen mit demselben Schl√ºssel. Die Endzeit ist kleiner als der aktuelle Datums- / Zeitstempel - das Inaktivit√§tsintervall und die Startzeit sind l√§nger als der aktuelle Datums- / Zeitstempel + Inaktivit√§tsintervall.  In diesem Sinne vier Datens√§tze aus der Tabelle  5.1 wie folgt zu einer einzigen Sitzung zusammenf√ºhren. <br><br>  1. Datensatz 1 steht an erster Stelle, daher entspricht die Startzeit der Endzeit und ist 00:00:00. <br><br>  2. Als n√§chstes kommt Datensatz 2, und wir suchen nach Sitzungen, die fr√ºhestens um 23:59:55 Uhr enden und sp√§testens um 00:00:35 Uhr beginnen.  Suchen Sie Datensatz 1 und kombinieren Sie die Sitzungen 1 und 2. Nehmen Sie die Startzeit von Sitzung 1 (fr√ºher) und die Endzeit von Sitzung 2 (sp√§ter), sodass unsere neue Sitzung um 00:00:00 Uhr beginnt und um 00:00:15 Uhr endet. <br><br>  3. Datensatz 3 kommt an, wir suchen nach Sitzungen zwischen 00:00:30 und 00:01:10 und finden keine.  F√ºgen Sie eine zweite Sitzung f√ºr den Schl√ºssel 123-345-654, FFBE, hinzu, die um 00:00:50 beginnt und endet. <br><br>  4. Datensatz 4 kommt an und wir suchen nach Sitzungen zwischen 23:59:45 und 00:00:25.  Diesmal gibt es beide Sitzungen - 1 und 2. Alle drei Sitzungen werden zu einer zusammengefasst, mit einer Startzeit von 00:00:00 und einer Endzeit von 00:00:15. <br><br>  Nach dem, was in diesem Abschnitt gesagt wird, sollten die folgenden wichtigen Nuancen beachtet werden: <br><br><ul><li>  Sitzungen sind keine Fenster mit fester Gr√∂√üe.  Die Dauer einer Sitzung wird durch die Aktivit√§t innerhalb eines bestimmten Zeitraums bestimmt. </li><li>  Datums- / Zeitstempel in den Daten bestimmen, ob ein Ereignis in eine vorhandene Sitzung oder in einen Zeitraum der Inaktivit√§t f√§llt. </li></ul><br>  Weiter werden wir den folgenden Fenstertyp diskutieren - "Salto" -Fenster. <br><br><h3>  Fenster st√ºrzen </h3><br>  "Tumbling" -Fenster erfassen Ereignisse, die in einen bestimmten Zeitraum fallen.  Stellen Sie sich vor, Sie m√ºssen alle 20 Sekunden alle Umtauschtransaktionen eines Unternehmens erfassen, damit Sie alle Ereignisse f√ºr diesen Zeitraum erfassen k√∂nnen.  Am Ende des 20-Sekunden-Intervalls ‚Äûstolpert‚Äú das Fenster und wechselt zu einem neuen 20-Sekunden-Beobachtungsintervall.  Abbildung 5.14 zeigt diese Situation. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ge/sb/jh/gesbjhkrk4wfpsj94edv21lcgzk.png" alt="Bild"></div><br>  Wie Sie sehen k√∂nnen, werden alle Ereignisse, die in den letzten 20 Sekunden empfangen wurden, in das Fenster aufgenommen.  Am Ende dieses Zeitraums wird ein neues Fenster erstellt. <br><br>  Listing 5.6 zeigt den Code, der die Verwendung von Tumbling-Fenstern zum Erfassen von Austauschtransaktionen alle 20 Sekunden demonstriert (Sie finden ihn in src / main / java / bbejeck / kapitel_5 / CountingWindowingAndKtableJoinExample.java). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ej/gw/ba/ejgwbaxfd9vzmdok1u6vl7gqjt4.png" alt="Bild"></div><br>  Dank dieser kleinen √Ñnderung beim Aufruf der Methode TimeWindows.of k√∂nnen Sie das Tumbling-Fenster verwenden.  In diesem Beispiel wird die Methode till () nicht aufgerufen, wodurch das Standardspeicherintervall von 24 Stunden verwendet wird. <br><br>  Schlie√ülich ist es Zeit, mit der letzten der Fensteroptionen fortzufahren - dem H√ºpfen von Fenstern. <br><br><h3>  Schiebefenster ("springen") </h3><br>  Schiebe- / "Sprung" -Fenster √§hneln dem "Stolpern", unterscheiden sich jedoch geringf√ºgig.  Schiebefenster warten nicht auf das Ende des Zeitintervalls, bevor sie ein neues Fenster erstellen, um die letzten Ereignisse zu verarbeiten.  Sie starten neue Berechnungen nach einem Wartezeitintervall, das k√ºrzer als die Fensterdauer ist. <br><br>  Um die Unterschiede zwischen "Salto" - und "Sprung" -Fenstern zu veranschaulichen, kehren wir zum Beispiel mit der Berechnung von B√∂rsentransaktionen zur√ºck.  Unser Ziel ist es nach wie vor, die Anzahl der Transaktionen zu z√§hlen, aber wir m√∂chten nicht die ganze Zeit warten, bevor wir den Z√§hler aktualisieren.  Stattdessen aktualisieren wir den Z√§hler in k√ºrzeren Intervallen.  Zum Beispiel werden wir weiterhin alle 20 Sekunden die Anzahl der Transaktionen z√§hlen, aber den Z√§hler alle 5 Sekunden aktualisieren, wie in Abb. 2 gezeigt.  5.15.  Gleichzeitig haben wir drei Ergebnisfenster mit √ºberlappenden Daten. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/f_/rz/km/f_rzkmhyoxehblurxwysauk3j2k.png" alt="Bild"></div><br>  Listing 5.7 zeigt den Code zum Festlegen von Schiebefenstern (er befindet sich in src / main / java / bbejeck / kapitel_5 / CountingWindowingAndKtableJoinExample.java). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/oa/xr/hn/oaxrhnrcxi78qoylbaatcegq__q.png" alt="Bild"></div><br> ¬´¬ª     ¬´¬ª      advanceBy().       15 . <br><br>     ,      .  ,  ,         : <br><br><ul><li>       ,   ; </li><li> ¬´¬ª          ; </li><li>   ¬´¬ª  ,            . </li></ul><br>   ,   KTable   KStream  . <br><br><h3> 5.3.3.   KStream  KTable </h3><br>   4      KStream.      KTable  KStream.       . KStream ‚Äî  ,  KTable ‚Äî   ,                KTable. <br><br>                .    ,        . <br><br><ol><li>   KTable        KStream      ,   ,    . </li><li>   KTable,       .   KTable     . </li><li>            . </li></ol><br>  ,     . <br><br><h3>  KTable  KStream </h3><br>   KTable  KStream   . <br><br><ol><li>   KTable.toStream(). </li><li>     KStream.map     ,      Windowed  TransactionSummary. </li></ol><br>        (     src/main/java/bbejeck/chapter_5/CountingWindowingAndKtableJoinExample.java) ( 5.8). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jx/_b/9f/jx_b9frqyde6wj2yvo5nk3palwq.png" alt="Bild"></div><br>     KStream.map,       KStream       . <br><br>    ,      KTable    . <br><br><h3>  KTable    </h3><br>  ,    KTable     (      src/main/java/bbejeck/chapter_5/CountingWindowingAndKtableJoinExample.java) ( 5.9). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vb/g5/2w/vbg52wycfxm6ojk2jgpkochuvii.png" alt="Bild"></div><br>  ,    Serde   ,      Serde.     EARLIEST      . <br><br>        ‚Äî . <br><br><h3>         </h3><br>     .      ,         (      src/main/java/bbejeck/chapter_5/CountingWindowingAndKtableJoinExample.java) ( 5.10). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nk/8r/zw/nk8rzwzgk7qtaxv0uq3p_sjaipm.png" alt="Bild"></div><br>   leftJoin  .       4,  JoinWindow  ,     KStream-KTable     KTable    .      :     KTable,  .  :    KTable   KStream    . <br><br>           KStream. <br><br><h3> 5.3.4.  GlobalKTable </h3><br>   ,          .   4      KStream,     ‚Äî  KStream  KTable.                 .      ,   Kafka Streams   .   ,          ,     (    4,   ¬´  ¬ª  4.2.4). <br><br><h3>      </h3><br>     ‚Äî       ,       ;            .  ,               ,           . <br><br><h3>       </h3><br>      ,    ,  ,             .     Kafka Streams   GlobalKTable. <br><br>  GlobalKTable ,         .         ,         ,      .    GlobalKTable     .          . <br><br><h3>   KStream   GlobalKTable </h3><br>   5.3.2        .       : <br><br><pre><code class="plaintext hljs">{customerId='074-09-3705', stockTicker='GUTM'}, 17 {customerId='037-34-5184', stockTicker='CORK'}, 16</code> </pre> <br>  Obwohl diese Ergebnisse mit dem Ziel √ºbereinstimmten, w√§re es bequemer, wenn auch der Name des Kunden und der vollst√§ndige Name des Unternehmens angezeigt w√ºrden.  Um den Namen eines Kunden und eines Unternehmens hinzuzuf√ºgen, k√∂nnen Sie normale Verbindungen herstellen, m√ºssen jedoch zwei Schl√ºsselzuordnungen vornehmen und neu partitionieren.  Mit GlobalKTable k√∂nnen Sie die Kosten solcher Vorg√§nge vermeiden. <br><br>  Dazu verwenden wir das countStream-Objekt aus Listing 5.11 (der entsprechende Code befindet sich in der Datei src / main / java / bbejeck / kapitel_5 / GlobalKTableExample.java) und verbinden es mit zwei GlobalKTable-Objekten. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/et/ds/zj/etdszjjzni9snwmxxbi21xph8e4.png" alt="Bild"></div><br>  Wir haben dies bereits zuvor besprochen, daher werde ich es nicht wiederholen.  Ich stelle jedoch fest, dass der Code in der toStream (). Map-Funktion aus Gr√ºnden der Lesbarkeit anstelle des eingebetteten Lambda-Ausdrucks in das Funktionsobjekt abstrahiert wird. <br><br>  Der n√§chste Schritt besteht darin, zwei Instanzen von GlobalKTable zu deklarieren (der angezeigte Code befindet sich in src / main / java / bbejeck / kapitel_5 / GlobalKTableExample.java) (Listing 5.12). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ut/ca/gd/utcagdf_iab9zjefezaiy2dxt80.png" alt="Bild"></div><br><br>  Beachten Sie, dass Themennamen mit Aufz√§hlungstypen beschrieben werden. <br><br>  Nachdem wir alle Komponenten vorbereitet haben, muss noch der Code f√ºr die Verbindung geschrieben werden (der in der Datei src / main / java / bbejeck / kapitel_5 / GlobalKTableExample.java zu finden ist) (Listing 5.13). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/av/yr/oe/avyroeehcpkzq9rzeiqlernoum8.png" alt="Bild"></div><br>  Obwohl dieser Code zwei Verbindungen enth√§lt, sind sie in einer Kette organisiert, da keines ihrer Ergebnisse separat verwendet wird.  Die Ergebnisse werden am Ende des gesamten Vorgangs angezeigt. <br><br>  Wenn Sie den obigen Verbindungsvorgang starten, erhalten Sie die folgenden Ergebnisse: <br><br><pre> <code class="plaintext hljs">{customer='Barney, Smith' company="Exxon", transactions= 17}</code> </pre> <br>  Das Wesen hat sich nicht ge√§ndert, aber diese Ergebnisse sehen klarer aus. <br><br>  Wenn Sie Kapitel 4 z√§hlen, haben Sie bereits verschiedene Arten von Verbindungen in Aktion gesehen.  Sie sind in der Tabelle aufgef√ºhrt.  5.2.  Diese Tabelle spiegelt die f√ºr Version 1.0.0 von Kafka Streams relevante Konnektivit√§t wider.  In zuk√ºnftigen Versionen wird sich etwas √§ndern. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_u/ka/gh/_ukaghteoopcpk9i5ljf4cjrwju.png" alt="Bild"></div><br>  Abschlie√üend m√∂chte ich Sie an die Hauptsache erinnern: Sie k√∂nnen Ereignisstr√∂me (KStream) und Aktualisierungsstr√∂me (KTable) √ºber den lokalen Status verbinden.  Wenn die Referenzdaten nicht zu gro√ü sind, k√∂nnen Sie au√üerdem das GlobalKTable-Objekt verwenden.  GlobalKTable repliziert alle Abschnitte auf jeden der Knoten der Kafka Streams-Anwendung und stellt so die Verf√ºgbarkeit aller Daten sicher, unabh√§ngig davon, welchem ‚Äã‚ÄãAbschnitt der Schl√ºssel entspricht. <br><br>  Als n√§chstes sehen wir die M√∂glichkeit von Kafka-Streams, dank derer Sie Status√§nderungen beobachten k√∂nnen, ohne Daten aus dem Kafka-Thema zu verbrauchen. <br><br><h3>  5.3.5.  Status anfordern </h3><br>  Wir haben bereits mehrere Operationen durchgef√ºhrt, an denen der Staat beteiligt ist, und geben die Ergebnisse immer an die Konsole aus (f√ºr Entwicklungszwecke) oder schreiben sie in das Thema (f√ºr den industriellen Betrieb).  Wenn Sie Ergebnisse zu einem Thema schreiben, m√ºssen Sie den Kafka-Consumer verwenden, um sie anzuzeigen. <br><br>  Das Lesen von Daten aus diesen Themen kann als eine Art materialisierte Ansichten betrachtet werden.  F√ºr unsere Aufgaben k√∂nnen wir die Definition einer materialisierten Ansicht aus Wikipedia verwenden: ‚Äû... ein physisches Datenbankobjekt, das die Ergebnisse einer Abfrage enth√§lt.  Dies kann beispielsweise eine lokale Kopie gel√∂schter Daten oder eine Teilmenge der Zeilen und / oder Spalten einer Tabelle oder eines Verkn√ºpfungsergebnisses oder eine mithilfe der Aggregation erhaltene Pivot-Tabelle sein ‚Äú(https://en.wikipedia.org/wiki/Materialized_view). <br><br>  Mit Kafka Streams k√∂nnen Sie auch interaktive Abfragen in State Stores durchf√ºhren, mit denen Sie diese materialisierten Ansichten direkt lesen k√∂nnen.  Es ist wichtig zu beachten, dass die Anforderung an den Statusspeicher eine schreibgesch√ºtzte Operation ist.  Dank dessen k√∂nnen Sie keine Angst haben, den Status versehentlich zu einer Anwendung zu machen, die w√§hrend der Datenverarbeitung inkonsistent ist. <br><br>  Die M√∂glichkeit, Statusspeicher direkt abzufragen, ist wichtig.  Dies bedeutet, dass Sie Anwendungen erstellen k√∂nnen - Dashboards, ohne zuvor Daten von einem Kafka-Verbraucher empfangen zu m√ºssen.  Dies erh√∂ht die Effizienz der Anwendung, da keine erneuten Datenaufzeichnungen erforderlich sind: <br><br><ul><li>  Aufgrund der Lokalit√§t der Daten kann schnell auf sie zugegriffen werden. </li><li>  Eine Vervielf√§ltigung von Daten ist ausgeschlossen, da diese nicht in einen externen Speicher geschrieben werden. </li></ul><br>  Die Hauptsache, an die Sie sich erinnern sollten: Sie k√∂nnen Statusanforderungen direkt von der Anwendung ausf√ºhren.  Sie k√∂nnen die Chancen, die sich daraus ergeben, nicht √ºbersch√§tzen.  Anstatt Daten von Kafka zu verbrauchen und Datens√§tze in der Datenbank f√ºr die Anwendung zu speichern, k√∂nnen Sie Statusspeicher mit demselben Ergebnis abfragen.  Direkte Anfragen an staatliche Speicher bedeuten weniger Code (kein Verbraucher) und weniger Software (keine Datenbanktabelle zum Speichern der Ergebnisse erforderlich). <br><br>  Wir haben in diesem Kapitel eine betr√§chtliche Menge an Informationen behandelt, daher werden wir unsere Diskussion √ºber interaktive Anfragen an staatliche Gesch√§fte vor√ºbergehend einstellen.  Aber keine Sorge: In Kapitel 9 erstellen wir eine einfache Anwendung - ein Informationsfenster mit interaktiven Abfragen.  Um interaktive Abfragen und die M√∂glichkeiten zum Hinzuf√ºgen zu Kafka Streams-Anwendungen zu demonstrieren, werden einige Beispiele aus diesem und den vorherigen Kapiteln verwendet. <br><br><h3>  Zusammenfassung </h3><br><ul><li>  KStream-Objekte stellen Ereignisstr√∂me dar, die mit Datenbankeinf√ºgungen vergleichbar sind.  KTable-Objekte stellen Aktualisierungsstr√∂me dar. Sie √§hneln Aktualisierungen in der Datenbank.  Die Gr√∂√üe des KTable-Objekts w√§chst nicht, alte Datens√§tze werden durch neue ersetzt. </li><li>  KTable-Objekte sind f√ºr Aggregationsvorg√§nge erforderlich. </li><li>  Mithilfe von Fensteroperationen k√∂nnen Sie aggregierte Daten in Zeitk√∂rbe aufteilen. </li><li>  Dank GlobalKTable-Objekten k√∂nnen Sie unabh√§ngig von der Aufteilung √ºberall in der Anwendung auf Referenzdaten zugreifen. </li><li>  Verbindungen zwischen Objekten KStream, KTable und GlobalKTable sind m√∂glich. </li></ul><br>  Bisher haben wir uns auf die Erstellung von Kafka Streams-Anwendungen mit dem hochrangigen KStream DSL konzentriert.  Obwohl Sie mit einem Ansatz auf hoher Ebene √ºbersichtliche und pr√§zise Programme erstellen k√∂nnen, ist die Verwendung ein eindeutiger Kompromiss.  Die Arbeit mit DSL KStream bedeutet, die Pr√§gnanz des Codes zu erh√∂hen, indem der Grad der Kontrolle verringert wird.  Im n√§chsten Kapitel werden wir uns die Low-Level-API der Handlerknoten ansehen und andere Kompromisse ausprobieren.  Programme werden l√§nger als bisher, aber wir haben die M√∂glichkeit, fast jeden Verarbeitungsknoten zu erstellen, den wir m√∂glicherweise ben√∂tigen. <br><br>  ‚Üí Weitere Informationen zum Buch finden Sie auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Website des Herausgebers</a> <br><br>  ‚Üí F√ºr Khabrozhiteley 25% Rabatt auf Gutschein - <b>Kafka Streams</b> <br><br>  ‚Üí Nach Zahlung der Papierversion des Buches wird ein elektronisches Buch per E-Mail verschickt. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de457756/">https://habr.com/ru/post/de457756/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de457744/index.html">Erstellen eines Erweiterungssystems in der Qt-Bibliothek - Teil 2</a></li>
<li><a href="../de457746/index.html">Meteorologie und Fl√ºge</a></li>
<li><a href="../de457750/index.html">Arbeiten Sie mit JSON RPC in Symfony 4</a></li>
<li><a href="../de457752/index.html">Keine Mondrover und keine Joker. Was wissen wir √ºber Roboter in Fukushima?</a></li>
<li><a href="../de457754/index.html">Staats- und T-Killer</a></li>
<li><a href="../de457758/index.html">Ingenieure retten Menschen, die im Wald verloren gegangen sind, aber der Wald hat sich noch nicht ergeben</a></li>
<li><a href="../de457760/index.html">So machen Sie Container noch isolierter: eine √úberpr√ºfung der Container-Sandbox-Technologien</a></li>
<li><a href="../de457762/index.html">CCD-Lineal: Womit es gegessen wird</a></li>
<li><a href="../de457764/index.html">10 Fehler der jungen PO (Teil II)</a></li>
<li><a href="../de457766/index.html">Wir generieren Kachelebenen und verstecken Quadrate vor dem Spieler</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
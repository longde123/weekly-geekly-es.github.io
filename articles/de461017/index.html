<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëâ üôéüèª ü§æüèº Neuer GPU-Tracking-Algorithmus: Wavefront Path Tracing üöü üë®üèª‚Äçüè´ ü§æüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In diesem Artikel untersuchen wir das wichtige Konzept der k√ºrzlich ver√∂ffentlichten Lighthouse 2-Plattform: Die Wellenfront-Pfadverfolgung , wie sie ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Neuer GPU-Tracking-Algorithmus: Wavefront Path Tracing</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/461017/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/_x/t8/rw/_xt8rwehj6jymumaisqg5ehgkro.png"></div><br>  In diesem Artikel untersuchen wir das wichtige Konzept der k√ºrzlich ver√∂ffentlichten Lighthouse 2-Plattform: Die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wellenfront-Pfadverfolgung</a> , wie sie von NVIDIA als Lane, Karras und Aila bezeichnet wird, oder die Streaming-Pfadverfolgung, wie sie urspr√ºnglich in Van Antwerps <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Masterarbeit genannt wurde</a> , spielt eine entscheidende Rolle die Entwicklung effizienter Pfad-Tracer auf der GPU und potenzieller Pfad-Tracer auf der CPU.  Es ist jedoch ziemlich eing√§ngig, daher ist es zum Verst√§ndnis notwendig, Raytracing-Algorithmen zu √ºberdenken. <br><a name="habracut"></a><br><h2>  Belegung </h2><br>  Der Pfadverfolgungsalgorithmus ist √ºberraschend einfach und kann in nur wenigen Pseudocodezeilen beschrieben werden: <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">vec3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Trace</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( vec3 O, vec3 D )</span></span></span><span class="hljs-function"> IntersectionData i </span></span>= Scene::Intersect( O, D ) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (i == NoHit) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> vec3( <span class="hljs-number"><span class="hljs-number">0</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// ray left the scene if (i == Light) return i.material.color // lights do not reflect vec3 R, pdf = RandomDirectionOnHemisphere( i.normal ), 1 / 2PI return Trace( i.position, R ) * i.BRDF * dot( i.normal, R ) / pdf</span></span></code> </pre> <br>  Die Eingabe ist der <em>Prim√§rstrahl</em> , der von der Kamera durch das Bildschirmpixel geleitet wird.  F√ºr diesen Strahl bestimmen wir den n√§chsten Schnittpunkt mit dem Szenenprimitiv.  Wenn es keine Schnittpunkte gibt, verschwindet der Strahl in der Leere.  Andernfalls, wenn der Strahl die Lichtquelle erreicht, haben wir den Lichtweg zwischen der Quelle und der Kamera gefunden.  Wenn wir etwas anderes finden, f√ºhren wir Reflexion und Rekursion durch, in der Hoffnung, dass der reflektierte Strahl immer noch die Beleuchtungsquelle findet.  Beachten Sie, dass dieser Prozess dem (R√ºck-) Pfad eines Photons √§hnelt, das von der Oberfl√§che einer Szene reflektiert wird. <br><br>  GPUs sind so konzipiert, dass sie diese Aufgabe im Multithread-Modus ausf√ºhren.  Auf den ersten Blick scheint Ray Tracing daf√ºr ideal zu sein.  Wir verwenden OpenCL oder CUDA, um einen Stream f√ºr ein Pixel zu erstellen. Jeder Stream f√ºhrt einen Algorithmus aus, der tats√§chlich wie beabsichtigt funktioniert und ziemlich schnell ist. Schauen Sie sich nur einige Beispiele mit ShaderToy an, um zu verstehen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wie</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">schnell</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Raytracing sein</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kann</a> auf der GPU.  Aber wie auch immer, die Frage ist anders: Sind diese Raytracer wirklich <em>so schnell wie m√∂glich</em> ? <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ce5/61d/07d/ce561d07daa3437927ab8ad5a6744ec9.jpg"></div><br>  Dieser Algorithmus hat ein Problem.  Der Prim√§rstrahl kann die Lichtquelle sofort oder nach einer zuf√§lligen Reflexion oder nach f√ºnfzig Reflexionen finden.  Der Programmierer f√ºr die CPU wird hier einen m√∂glichen Stapel√ºberlauf bemerken.  Der GPU-Programmierer sollte <em>das Belegungsproblem sehen</em> .  Das Problem wird durch eine bedingte Schwanzrekursion verursacht: Der Pfad kann an der Lichtquelle enden oder fortgesetzt werden.  Lassen Sie uns dies auf viele Threads √ºbertragen: Einige der Threads werden angehalten und der andere Teil funktioniert weiterhin.  Nach einigen √úberlegungen werden wir mehrere Threads haben, die weiter rechnen m√ºssen, und die meisten Threads warten darauf, dass diese letzten Threads ihre Arbeit beenden.  <em>Die Besch√§ftigung</em> ist ein Ma√ü f√ºr den Anteil der GPU-Threads, die n√ºtzliche Arbeit leisten. <br><br>  Das Besch√§ftigungsproblem betrifft das Ausf√ºhrungsmodell von SIMT-GPU-Ger√§ten.  Streams sind in Gruppen organisiert, z. B. in der Pascal-GPU (NVidia-Ger√§teklasse 10xx). 32 Threads werden zu einem <em>Warp</em> kombiniert.  Threads in Warp haben einen gemeinsamen Programmz√§hler: Sie werden mit einem festen Schritt ausgef√ºhrt, sodass jeder Programmbefehl von 32 Threads gleichzeitig ausgef√ºhrt wird.  SIMT steht f√ºr <em>Single Instruction Multiple Thread</em> , was das Konzept gut beschreibt.  F√ºr einen SIMT-Prozessor ist ein Code mit Bedingungen komplex.  Dies wird in der offiziellen Volta-Dokumentation deutlich gezeigt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9bb/1c0/cb0/9bb1c0cb0c4916e8a7989edeb466d3dd.jpg"></div><br>  <i>Codeausf√ºhrung mit Bedingungen in SIMT.</i> <br><br>  Wenn eine bestimmte Bedingung f√ºr einige Threads in Warp erf√ºllt ist, werden die Zweige der <em>if-Anweisung</em> serialisiert.  Eine Alternative zum Ansatz "Alle Threads machen dasselbe" ist "Einige Threads sind deaktiviert".  Im Wenn-Dann-Sonst-Block betr√§gt die durchschnittliche Besetzung von Warp 50%, es sei denn, alle Threads weisen eine Konsistenz hinsichtlich der Bedingung auf. <br><br>  Leider ist Code mit Bedingungen im Ray Tracer nicht so selten.  Schattenstrahlen werden nur emittiert, wenn sich die Lichtquelle nicht hinter dem Schattierungspunkt befindet, unterschiedliche Pfade mit unterschiedlichen Materialien kollidieren k√∂nnen, die Integration in die russische Roulette-Methode den Pfad zerst√∂ren oder am Leben lassen kann und so weiter.  Es stellt sich heraus, dass die Belegung zur Hauptursache f√ºr Ineffizienz wird und es nicht so einfach ist, sie ohne Sofortma√ünahmen zu verhindern. <br><br><h2>  Streaming Path Tracing </h2><br>  Der Streaming Path Tracing-Algorithmus wurde entwickelt, um die Hauptursache des ausgelasteten Problems zu beheben.  Die Streaming-Pfadverfolgung unterteilt den Pfadverfolgungsalgorithmus in vier Schritte: <br><br><ol><li>  <strong>Generieren</strong> </li><li>  <strong>Verl√§ngern</strong> </li><li>  <strong>Schatten</strong> </li><li>  <strong>Verbinden</strong> </li></ol><br>  Jede Stufe wird als separates Programm implementiert.  Anstatt einen vollst√§ndigen Pfad-Tracer als einzelnes GPU-Programm (‚ÄûKernel‚Äú, Kernel) auszuf√ºhren, m√ºssen wir daher mit <em>vier</em> Kernen arbeiten.  Wie wir gleich sehen werden, werden sie au√üerdem in einer Schleife ausgef√ºhrt. <br><br>  <b>Stufe 1 (‚ÄûGenerieren‚Äú)</b> ist f√ºr die Erzeugung von Prim√§rstrahlen verantwortlich.  Dies ist ein einfacher Kern, der die Startpunkte und Richtungen der Strahlen in einer Menge erzeugt, die der Anzahl der Pixel entspricht.  Die Ausgabe dieser Stufe ist ein gro√üer Strahlpuffer und ein Z√§hler, der die n√§chste Stufe √ºber die Anzahl der zu verarbeitenden Strahlen informiert.  Bei Prim√§rstrahlen entspricht dieser Wert der <em>Breite des Bildschirms</em> multipliziert mit der <em>H√∂he des Bildschirms</em> . <br><br>  <strong>Stufe 2 (‚ÄûErneuern‚Äú)</strong> ist der zweite Kern.  Es wird erst ausgef√ºhrt, nachdem Stufe 1 f√ºr alle Pixel abgeschlossen ist.  Der Kernel liest den in Schritt 1 erzeugten Puffer und kreuzt jeden Strahl mit der Szene.  Die Ausgabe dieser Stufe ist das Schnittergebnis f√ºr jeden im Puffer gespeicherten Strahl. <br><br>  <strong>Stufe 3 (‚ÄûSchatten‚Äú)</strong> wird nach Abschluss von Stufe 2 ausgef√ºhrt. Sie empf√§ngt das Ergebnis der Schnittmenge aus Stufe 2 und berechnet das Schattierungsmodell f√ºr jeden Pfad.  Diese Operation kann neue Strahlen erzeugen oder nicht, abh√§ngig davon, ob der Pfad abgeschlossen ist.  Die Pfade, die den neuen Strahl erzeugen (der Pfad "erweitert"), schreiben den neuen Strahl (das "Pfadsegment") in den Puffer.  Pfade, die Lichtquellen direkt abtasten ("Beleuchtung explizit abtasten" oder "das n√§chste Ereignis berechnen"), schreiben einen Schattenstrahl in einen zweiten Puffer. <br><br>  <strong>Stufe 4 (‚ÄûVerbinden‚Äú)</strong> zeichnet die in Stufe 3 erzeugten Schattenstrahlen nach. Dies √§hnelt Stufe 2, weist jedoch einen wichtigen Unterschied auf: Die Schattenstrahlen m√ºssen einen <em>beliebigen</em> Schnittpunkt finden, w√§hrend die sich ausdehnenden Strahlen den n√§chsten Schnittpunkt finden m√ºssen.  Daher wurde hierf√ºr ein separater Kern erstellt. <br><br>  Nach Abschluss von Schritt 4 erhalten wir einen Puffer mit Strahlen, die den Pfad erweitern.  Nachdem wir diese Strahlen aufgenommen haben, fahren wir mit Stufe 2 fort. Wir machen so weiter, bis keine Verl√§ngerungsstrahlen mehr vorhanden sind oder bis wir die maximale Anzahl von Iterationen erreicht haben. <br><br><h2>  Ineffizienzquellen </h2><br>  Ein Programmierer, der sich Sorgen um die Leistung macht, wird in einem solchen Schema von Algorithmen zur Verfolgung von Streaming-Pfaden viele gef√§hrliche Momente erleben: <br><br><ul><li>  Anstelle eines einzelnen Kernelaufrufs haben wir jetzt <em>drei Aufrufe pro Iteration</em> sowie einen Generierungskernel.  Herausfordernde Kerne bedeuten eine gewisse Erh√∂hung der Last, was schlecht ist. </li><li>  Jeder Kern liest einen riesigen Puffer und schreibt einen riesigen Puffer. </li><li>  Die CPU muss wissen, wie viele Threads f√ºr jeden Kern generiert werden m√ºssen. Daher muss die GPU der CPU mitteilen, wie viele Strahlen in Schritt 3 generiert wurden. Das Verschieben von Informationen von der GPU zur CPU ist eine schlechte Idee und muss mindestens einmal pro Iteration erfolgen. </li><li>  Wie schreibt Stufe 3 die Strahlen in den Puffer, ohne √ºberall R√§ume zu schaffen?  Er benutzt daf√ºr keinen Atomz√§hler? </li><li>  Die Anzahl der aktiven Pfade nimmt immer noch ab. Wie kann dieses Schema √ºberhaupt helfen? </li></ul><br>  Beginnen wir mit der letzten Frage: Wenn wir eine Million Aufgaben an die GPU √ºbertragen, werden keine Millionen Threads generiert.  Die tats√§chliche Anzahl der gleichzeitig ausgef√ºhrten Threads h√§ngt von der Ausr√ºstung ab. Im allgemeinen Fall werden jedoch Zehntausende von Threads ausgef√ºhrt.  Erst wenn die Last unter diese Zahl f√§llt, werden wir Besch√§ftigungsprobleme bemerken, die durch eine kleine Anzahl von Aufgaben verursacht werden. <br><br>  Ein weiteres Problem ist die gro√üe E / A von Puffern.  Dies ist zwar eine Schwierigkeit, aber nicht so schwerwiegend, wie Sie es vielleicht erwarten: Der Zugriff auf Daten ist sehr vorhersehbar, insbesondere beim Schreiben in Puffer, sodass die Verz√∂gerung keine Probleme verursacht.  Tats√§chlich wurden GPUs haupts√§chlich f√ºr diese Art der Datenverarbeitung entwickelt. <br><br>  Ein weiterer Aspekt, den GPUs sehr gut handhaben, sind Atomz√§hler, was f√ºr Programmierer, die in der CPU-Welt arbeiten, ziemlich unerwartet ist.  Der Z-Puffer erfordert einen schnellen Zugriff, und daher ist die Implementierung von Atomz√§hlern in modernen GPUs √§u√üerst effektiv.  In der Praxis ist eine atomare Schreiboperation genauso kostspielig wie ein nicht zwischengespeicherter Schreibvorgang in den globalen Speicher.  In vielen F√§llen wird die Verz√∂gerung durch umfangreiche parallele Ausf√ºhrung in der GPU maskiert. <br><br>  Es bleiben zwei Fragen offen: Kernelaufrufe und bidirektionale Daten√ºbertragung f√ºr Z√§hler.  Letzteres ist eigentlich ein Problem, daher brauchen wir eine weitere √Ñnderung der Architektur: <em>dauerhafte Threads</em> . <br><br><h2>  Die Folgen </h2><br>  Bevor wir uns mit den Details befassen, werden wir die Auswirkungen der Verwendung des Wellenfront-Pfadverfolgungsalgorithmus untersuchen.  Lassen Sie uns zun√§chst √ºber Puffer sprechen.  Wir ben√∂tigen einen Puffer, um die Daten von Stufe 1 auszugeben, d.h.  Prim√§rstrahlen.  F√ºr jeden Strahl ben√∂tigen wir: <br><br><ul><li>  Strahlursprung: drei Gleitkommawerte, d. H. 12 Bytes </li><li>  Strahlrichtung: drei Gleitkommawerte, d. H. 12 Bytes </li></ul><br>  In der Praxis ist es besser, den Puffer zu vergr√∂√üern.  Wenn Sie 16 Bytes f√ºr den Anfang und die Richtung des Strahls speichern, kann die GPU diese in einem 128-Bit-Lesevorgang lesen.  Eine Alternative ist eine 64-Bit-Leseoperation, gefolgt von einer 32-Bit-Operation, um float3 zu erhalten, was fast doppelt so langsam ist.  Das hei√üt, f√ºr einen Bildschirm von 1920 √ó 1080 erhalten wir: 1920x1080x32 = ~ 64 MB.  Wir ben√∂tigen auch einen Puffer f√ºr die vom Extend-Kernel erstellten Schnittpunktergebnisse.  Dies sind weitere 128 Bit pro Element, dh 32 MB.  Au√üerdem kann der "Shadow" -Kern bis zu 1920 √ó 1080 Pfaderweiterungen (Obergrenze) erstellen, und wir k√∂nnen sie nicht in den Puffer schreiben, aus dem wir lesen.  Das sind weitere 64 MB.  Und schlie√ülich, wenn unser Pfad-Tracer Schattenstrahlen aussendet, ist dies ein weiterer 64-MB-Puffer.  Nachdem wir alles zusammengefasst haben, erhalten wir 224 MB Daten, und dies gilt nur f√ºr den Wellenfrontalgorithmus.  Oder ungef√§hr 1 GB in 4K-Aufl√∂sung. <br><br>  Hier m√ºssen wir uns an eine andere Funktion gew√∂hnen: Wir haben viel Speicher.  Es mag scheinen.  Diese 1 GB sind eine Menge, und es gibt M√∂glichkeiten, diese Anzahl zu reduzieren. Wenn Sie dies jedoch realistisch angehen, ist die Verwendung von 1 GB auf einer GPU mit 8 GB das geringere unserer Probleme, wenn wir die Pfade wirklich in 4 KB verfolgen m√ºssen. <br><br>  Die Konsequenzen sind schwerwiegender als die Speicheranforderungen und wirken sich auf den Rendering-Algorithmus aus.  Bisher habe ich vorgeschlagen, dass wir einen Erweiterungsstrahl und m√∂glicherweise einen Schattenstrahl f√ºr jeden Thread im Schattenkern erzeugen m√ºssen.  Aber was ist, wenn wir Ambient Occlusion mit 16 Strahlen pro Pixel durchf√ºhren m√∂chten?  16 AO-Strahlen m√ºssen im Puffer gespeichert werden, aber noch schlimmer, sie erscheinen erst in der n√§chsten Iteration.  Ein √§hnliches Problem tritt auf, wenn Strahlen im Whited-Stil verfolgt werden: Es ist fast unm√∂glich, einen Schattenstrahl f√ºr mehrere Lichtquellen zu emittieren oder einen Strahl bei einer Kollision mit Glas zu spalten. <br><br>  Auf der anderen Seite l√∂st die Wellenfrontpfadverfolgung die Probleme, die wir im Abschnitt "Belegung" aufgef√ºhrt haben: <br><br><ul><li>  In Stufe 1 erzeugen alle Fl√ºsse ohne Bedingungen Prim√§rstrahlen und schreiben sie in den Puffer. </li><li>  In Stufe 2 schneiden alle Fl√ºsse ohne Bedingungen die Strahlen mit der Szene und schreiben die Ergebnisse der Schnittmenge in den Puffer. </li><li>  In Schritt 3 beginnen wir mit der Berechnung der Kreuzungsergebnisse bei 100% Belegung. </li><li>  In Schritt 4 verarbeiten wir eine fortlaufende Liste von Schattenstrahlen ohne Leerzeichen. </li></ul><br>  Wenn wir mit den √ºberlebenden Strahlen mit einer L√§nge von 2 Segmenten zu Stufe 2 zur√ºckkehren, haben wir wieder einen kompakten Strahlenpuffer, der die Vollbesch√§ftigung garantiert, wenn der Kernel startet. <br><br>  Dar√ºber hinaus gibt es einen zus√§tzlichen Vorteil, der nicht zu untersch√§tzen ist.  Der Code wird in vier separaten Schritten isoliert.  Jeder Kern kann alle verf√ºgbaren GPU-Ressourcen (Cache, gemeinsam genutzter Speicher, Register) verwenden, ohne andere Kerne zu ber√ºcksichtigen.  Dies kann es der GPU erm√∂glichen, den Schnittpunktcode mit der Szene in mehr Threads auszuf√ºhren, da f√ºr diesen Code nicht so viele Register erforderlich sind wie f√ºr den Shader-Code.  Je mehr Threads, desto besser k√∂nnen Sie die Verz√∂gerungen ausblenden. <br><br>  Vollzeit, verbesserte Verz√∂gerungsmaskierung, Streaming-Aufzeichnung: All diese Vorteile stehen in direktem Zusammenhang mit der Entstehung und der Art der GPU-Plattform.  F√ºr die GPU ist der Wellenfront-Pfadverfolgungsalgorithmus sehr nat√ºrlich. <br><br><h2>  Lohnt es sich? </h2><br>  Nat√ºrlich haben wir eine Frage: Rechtfertigt eine optimierte Besch√§ftigung die E / A von Puffern und die Kosten f√ºr das Aufrufen zus√§tzlicher Kerne? <br><br>  Die Antwort lautet ja, aber dies zu beweisen ist nicht so einfach. <br><br>  Wenn wir f√ºr eine Sekunde mit ShaderToy zu den Pfad-Tracern zur√ºckkehren, werden wir feststellen, dass die meisten von ihnen eine einfache und fest codierte Szene verwenden.  Das Ersetzen durch eine vollst√§ndige Szene ist keine triviale Aufgabe: F√ºr Millionen von Grundelementen wird das Schneiden des Strahls und der Szene zu einem komplexen Problem, dessen L√∂sung h√§ufig NVidia ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Optix</a> ), AMD ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Radeon-Rays</a> ) oder Intel ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Embree</a> ) √ºberlassen bleibt.  Keine dieser Optionen kann die fest codierte Szene im CUDA-Tracer f√ºr k√ºnstliche Strahlen problemlos ersetzen.  In CUDA erfordert das n√§chstgelegene Analogon (Optix) die Kontrolle √ºber die Programmausf√ºhrung.  Mit Embree in der CPU k√∂nnen Sie einzelne Strahlen aus Ihrem eigenen Code verfolgen. Die Kosten hierf√ºr sind jedoch ein erheblicher Leistungsaufwand: Er zieht es vor, gro√üe Gruppen von Strahlen anstelle einzelner Strahlen zu verfolgen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fb4/2a2/409/fb42a240924ba04871abb70421d16cdf.png"></div><br>  <i>Bildschirm von It's About Time mit Brigade 1 gerendert.</i> <br><br>  Wird die Wellenfrontpfadverfolgung schneller sein als ihre Alternative (der Megakernel, wie Lane und Kollegen ihn nennen), h√§ngt von der Zeit ab, die in den Kernen verbracht wird (gro√üe Szenen und kostspielige Shader reduzieren den relativen Kosten√ºberlauf durch den Wellenfrontalgorithmus), von der maximalen Pfadl√§nge , Mega-Core-Besch√§ftigung und Unterschiede in der Belastung der Register in vier Stufen.  In einer fr√ºhen Version des urspr√ºnglichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Brigade Path Tracer haben</a> wir festgestellt, dass selbst eine einfache Szene mit einer Mischung aus reflektierenden und Lambert-Oberfl√§chen auf der GTX480 von der Verwendung der Wellenfront profitiert. <br><br><h2>  Streaming Path Tracing im Leuchtturm 2 </h2><br>  Die Lighthouse 2-Plattform verf√ºgt √ºber zwei Tracer zur Verfolgung von Wellenfrontpfaden.  Der erste verwendet Optix Prime f√ºr die Implementierung der Stufen 2 und 4 (Stufen der Schnittmenge von Strahlen und Szenen);  Im zweiten Fall wird Optix direkt verwendet, um diese Funktionalit√§t zu implementieren. <br><br>  Optix Prime ist eine vereinfachte Version von Optix, die sich nur mit dem Schnittpunkt einer Reihe von Strahlen mit einer Szene aus Dreiecken befasst.  Im Gegensatz zur vollst√§ndigen Optix-Bibliothek unterst√ºtzt sie keinen benutzerdefinierten Schnittcode und schneidet nur Dreiecke.  Dies ist jedoch genau das, was f√ºr den Wellenfrontpfad-Tracer erforderlich ist. <br><br>  Der auf Optix Prime basierende Wellenfrontpfad-Tracer ist in <code>rendercore.cpp</code> Projekts <code>rendercore.cpp</code> .  Die Initialisierung von Optix Prime beginnt in der <code>Init</code> Funktion und verwendet <code>rtpContextCreate</code> .  Die Szene wird mit <code>rtpModelCreate</code> .  In der <code>SetTarget</code> Funktion werden mit <code>rtpBufferDescCreate</code> verschiedene Strahlenpuffer erstellt.  Beachten Sie, dass wir f√ºr diese Puffer die √ºblichen Ger√§tezeiger bereitstellen: Dies bedeutet, dass sie sowohl in Optix- als auch in regul√§ren CUDA-Kernen verwendet werden k√∂nnen. <br><br>  Das Rendern beginnt mit der <code>Render</code> .  Um den prim√§ren Strahlenpuffer zu f√ºllen, wird ein CUDA-Kern namens <code>generateEyeRays</code> .  Nach dem F√ºllen des Puffers wird Optix Prime mit <code>rtpQueryExecute</code> .  Damit werden Schnittpunkteergebnisse in <code>extensionHitBuffer</code> .  Beachten Sie, dass alle Puffer in der GPU verbleiben: Mit Ausnahme von Kernelaufrufen besteht kein Datenverkehr zwischen der CPU und der GPU.  Die Stufe ‚ÄûSchatten‚Äú ist im regul√§ren CUDA- <code>shade</code> implementiert.  Die Implementierung erfolgt in <code>pathtracer.cu</code> . <br><br>  Einige Implementierungsdetails f√ºr <code>optixprime_b</code> sind erw√§hnenswert.  Erstens werden Schattenstrahlen au√üerhalb des Wellenfrontzyklus verfolgt.  Dies ist richtig: Ein Schattenstrahl wirkt sich nur dann auf ein Pixel aus, wenn es nicht blockiert ist. In allen anderen F√§llen wird sein Ergebnis jedoch nirgendwo anders ben√∂tigt.  Das hei√üt, der Schattenstrahl ist <em>wegwerfbar</em> und kann jederzeit und in beliebiger Reihenfolge verfolgt werden.  In unserem Fall verwenden wir dies, indem wir die Strahlen des Schattens so gruppieren, dass die endg√ºltig verfolgte Charge so gro√ü wie m√∂glich ist.  Dies hat eine unangenehme Konsequenz: Bei <em>N</em> Iterationen des Wellenfrontalgorithmus und <em>X</em> Prim√§rstrahlen ist die Obergrenze der Anzahl der Schattenstrahlen gleich <em>XN</em> . <br><br>  Ein weiteres Detail ist die Verarbeitung verschiedener Z√§hler.  Die Stufen ‚ÄûErneuern‚Äú und ‚ÄûSchatten‚Äú sollten wissen, wie viele Pfade aktiv sind.  Die Z√§hler hierf√ºr werden in der GPU (atomar) aktualisiert, was bedeutet, dass sie in der GPU verwendet werden, auch ohne zur CPU zur√ºckzukehren.  Leider ist dies in einem Fall nicht m√∂glich: Die Optix Prime-Bibliothek muss die Anzahl der verfolgten Strahlen kennen.  Dazu m√ºssen wir die Informationen der Z√§hler einmal pro Iteration zur√ºckgeben. <br><br><h2>  Fazit </h2><br>  In diesem Artikel wird erl√§utert, was Wellenfrontpfadverfolgung ist und warum eine Pfadverfolgung auf der GPU effektiv durchgef√ºhrt werden muss.  Die praktische Implementierung wird auf der Lighthouse 2-Plattform vorgestellt, die Open Source ist und <a href="">auf Github verf√ºgbar ist</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de461017/">https://habr.com/ru/post/de461017/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de461005/index.html">Testen f√ºr das Unternehmen: Stellen Sie beim Interview die richtigen Fragen</a></li>
<li><a href="../de461007/index.html">Erste Schritte mit dem PVS-Studio Static Analyzer f√ºr Visual C ++</a></li>
<li><a href="../de461009/index.html">Wie man in 10 Tagen einen Standard macht. Teil Zwei Langweilig</a></li>
<li><a href="../de461013/index.html">Internetverbindung reservieren</a></li>
<li><a href="../de461015/index.html">Lebe und lerne. Teil 2. Universit√§t: 5 Jahre oder 5 Korridore?</a></li>
<li><a href="../de461019/index.html">Wie ist das Leben f√ºr Entwickler im Iran?</a></li>
<li><a href="../de461027/index.html">Java REPL Sie nicht ScriptEngine</a></li>
<li><a href="../de461029/index.html">Ein See voller Marketingdaten - von monstr√∂sen Tabellen bis hin zu Berichten und Visualisierungen</a></li>
<li><a href="../de461031/index.html">Wir verbinden Online-Karten mit dem Navigator auf dem Smartphone. Teil 1 - Standard-Rasterkarten</a></li>
<li><a href="../de461033/index.html">Woher kommt diese Konfiguration? [Debian / Ubuntu]</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
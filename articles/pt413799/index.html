<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôãüèº ü•ñ üè¶ Contagem de abelhas na rede neural do Raspberry Pi üÜñ üï∏Ô∏è üå´Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="17 de maio de 2018 

 Imediatamente ap√≥s a instala√ß√£o da colm√©ia, pensei: "Gostaria de saber como calcular o n√∫mero de abelhas chegando e saindo?" 

 ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Contagem de abelhas na rede neural do Raspberry Pi</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/413799/">  <font color="gray">17 de maio de 2018</font> <br><br>  Imediatamente ap√≥s a instala√ß√£o da colm√©ia, pensei: "Gostaria de saber como calcular o n√∫mero de abelhas chegando e saindo?" <br><br>  Um pequeno estudo mostrou: at√© agora ningu√©m parece ter apresentado um bom sistema n√£o invasivo para resolver esse problema.  Mas provavelmente seria √∫til ter essas informa√ß√µes para verificar a sa√∫de da colm√©ia. <br><br>  Primeiro, voc√™ precisa coletar amostras de dados.  Raspberry Pi, c√¢mera Pi padr√£o e painel solar: este equipamento simples √© suficiente para gravar um quadro a cada 10 segundos e salvar mais de 5000 imagens por dia (das 6:00 √†s 21:00). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9c0/762/61f/9c076261ffc6e6e293b9b4ee06cbbe32.png"><br><a name="habracut"></a><br>  Abaixo est√° um exemplo de imagem ... Quantas abelhas voc√™ pode contar? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a4e/d37/f72/a4ed37f728649526128711ebc033bc8c.png"><br><br><h1>  Qual √© exatamente a pergunta? </h1><br>  Em segundo lugar, √© necess√°rio formular o problema do que exatamente a rede neural deve fazer.  Se a tarefa √© ‚Äúcontar abelhas na imagem‚Äù, voc√™ pode tentar obter n√∫meros espec√≠ficos, mas essa n√£o parece ser a op√ß√£o mais f√°cil, e rastrear abelhas individualmente entre os quadros n√£o d√° prazer.  Em vez disso, decidi me concentrar em localizar cada abelha na imagem. <br><br>  Uma verifica√ß√£o r√°pida de um detector quadro a quadro padr√£o n√£o produziu nenhum resultado espec√≠fico.  Isso n√£o √© surpreendente, especialmente considerando a densidade de abelhas ao redor da entrada da colm√©ia (dica: transferir o treinamento nem sempre funciona), mas isso √© normal.  Portanto, tenho uma imagem muito pequena, apenas uma classe para reconhecer objetos e n√£o h√° problemas especiais com a caixa delimitadora.  Apenas decida se h√° uma abelha ou n√£o.  Qual solu√ß√£o ser√° mais simples? <br><br><h3>  v1: rede totalmente convolucional "comer abelha / n√£o" em um fragmento </h3><br>  O primeiro experimento r√°pido foi o detector "a abelha na imagem √© / n√£o √©".  Ou seja, qual √© a probabilidade de haver pelo menos uma abelha nesse fragmento da imagem.  Fazer isso na forma de uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rede completamente convolucional</a> em fragmentos muito pequenos da imagem significa que voc√™ pode processar facilmente os dados em resolu√ß√£o total.  A abordagem parecia funcionar, mas falhou na √°rea de entrada da colm√©ia com uma densidade muito alta de abelhas. <br><br><h3>  v2: imagem RGB ‚Üí bitmap em preto e branco </h3><br>  Eu rapidamente percebi que o problema pode ser reduzido ao problema de transforma√ß√£o da imagem.  Na entrada, o sinal da c√¢mera √© RGB e na sa√≠da √© uma imagem de um √∫nico canal onde o pixel ‚Äúbranco‚Äù indica o centro da abelha. <br><br><img src="https://habrastorage.org/webt/ks/v6/k9/ksv6k9rne4ewjh_mkwqwcrztoo8.png"><br>  <i><font color="gray">Entrada RGB (fragmento) e sa√≠da de canal √∫nico (fragmento)</font></i> <br><br><h1>  Marca√ß√£o </h1><br>  O terceiro passo √© rotular, ou seja, a atribui√ß√£o de designa√ß√µes.  N√£o √© muito dif√≠cil implantar um pequeno aplicativo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TkInter</a> para selecionar / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">desmarcar</a> abelhas na imagem e salvar os resultados no banco de dados SQLite.  Gastei muito tempo para configurar corretamente esta ferramenta: quem executou manualmente uma quantidade significativa de marca√ß√£o me entender√°: / <br><br>  Mais tarde veremos, felizmente, que com um grande n√∫mero de amostras, voc√™ pode obter um bom resultado por m√©todos semi-autom√°ticos. <br><br><h1>  Modelo </h1><br>  A arquitetura de rede √© bastante padr√£o na rede u-net. <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rede totalmente convolucional</a> treinada em fragmentos com meia resolu√ß√£o, mas funciona em imagens com resolu√ß√£o total; </li><li>  codifica√ß√£o √© uma sequ√™ncia de quatro convolu√ß√µes 3 √ó 3 em incrementos de 2 </li><li>  decodifica√ß√£o - uma sequ√™ncia de mudan√ßas de tamanho nos vizinhos mais pr√≥ximos + dobrando 3 √ó 3 em incrementos de 1 + pulando a conex√£o dos codificadores; </li><li>  a camada final de convolu√ß√£o 1 √ó 1 com a etapa 1 com a ativa√ß√£o da fun√ß√£o sigm√≥ide (ou seja, a escolha bin√°ria "bee √© / n√£o √©" para cada pixel). </li></ul><br>  Ap√≥s algumas experi√™ncias emp√≠ricas, decidi voltar √† decodifica√ß√£o com meia resolu√ß√£o.  Foi o suficiente. <br><br>  Eu decodifiquei redimensionando para os vizinhos mais pr√≥ximos, em vez de deconvolver mais por h√°bito. <br><br>  A rede foi treinada pelo m√©todo <a href="">Adam</a> e era muito pequena para aplicar a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">normaliza√ß√£o em lote</a> .  O design acabou surpreendentemente simples, bastava um pequeno n√∫mero de filtros. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8c0/3a8/983/8c03a898399031e9f7ea03a9bca4f0d4.png"><br><br>  Eu apliquei o m√©todo padr√£o de aumento de dados, rota√ß√£o aleat√≥ria e distor√ß√£o de cores.  Treinar em fragmentos significa que temos essencialmente uma variante de fatiar aleatoriamente a imagem.  N√£o girei a imagem porque a c√¢mera sempre fica em um lado da colm√©ia. <br><br>  H√° algumas nuances nas previs√µes de sa√≠da p√≥s-processamento.  Com resultados probabil√≠sticos, obtemos uma nuvem borrada onde pode haver abelhas.  Para convert√™-lo em uma imagem clara de um pixel por abelha, adicionei um valor limite, levando em considera√ß√£o componentes relacionados e detectando centr√≥ides usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o m√≥dulo de medi√ß√£o skimage</a> .  Tudo isso teve que ser instalado manualmente e configurado exclusivamente pelo olho, embora teoricamente possa ser adicionado ao final da pilha como um elemento de aprendizado.  Talvez fa√ßa sentido faz√™-lo no futuro ... :) <br><br><img src="https://habrastorage.org/webt/5e/jh/2n/5ejh2n0y7bkz4p25dc11qgwwxv8.png"><br>  <i><font color="gray">Centroids de entrada, sa√≠da bruta e cluster</font></i> <br><br><h1>  Generaliza√ß√£o de alguns dias </h1><br><h3>  Em um dia </h3><br>  Inicialmente, os experimentos foram conduzidos com imagens em um curto per√≠odo de um dia.  Acabou sendo f√°cil obter um bom modelo desses dados com um pequeno n√∫mero de imagens marcadas (cerca de 30). <br><br> <a href=""><img src="https://habrastorage.org/webt/jy/uv/rm/jyuvrmhucifitb_cd0hvnjyphlo.jpeg"></a> <br>  <i><font color="gray">Tr√™s amostras recebidas no primeiro dia</font></i> <br><br><h3>  Por muitos dias </h3><br>  As coisas ficaram mais complicadas quando comecei a considerar per√≠odos mais longos de v√°rios dias.  Uma das principais diferen√ßas √© a diferen√ßa de ilumina√ß√£o (hora do dia e clima diferente).  Outro motivo √© que eu instalei a c√¢mera manualmente todos os dias, apenas colando-a com velcro.  A terceira e mais inesperada diferen√ßa foi que, com o crescimento da grama, os bot√µes de dente de le√£o parecem abelhas (ou seja, na primeira rodada, o modelo treinado n√£o viu os bot√µes, e ent√£o eles apareceram e forneceram um fluxo cont√≠nuo de falsos positivos). <br><br>  A maioria dos problemas foi resolvida pelo aumento de dados e nenhum problema se tornou cr√≠tico.  Em geral, os dados n√£o variam muito.  Isso √© √≥timo, porque permite que voc√™ se limite a uma rede neural simples e a um esquema de treinamento. <br><br> <a href=""><img src="https://habrastorage.org/webt/go/gy/hc/gogyhcofkdkeuhvh8r59cb6aoas.jpeg"></a> <br>  <i><font color="gray">Amostras obtidas em tr√™s dias</font></i> <br><br><h1>  Exemplo de previs√£o </h1><br>  A imagem mostra um exemplo de previs√£o.  √â interessante notar que existem muito mais abelhas do que em qualquer imagem que eu rotulei manualmente.  Esta √© uma √≥tima confirma√ß√£o de que uma abordagem totalmente convolucional com o aprendizado de pequenos fragmentos realmente funciona. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/743/550/375/743550375de86803a6ecf73c0b4739ce.png"><br><br>  A rede funciona bem em uma ampla variedade de op√ß√µes.  Suponho que um plano de fundo uniforme ajude aqui, e iniciar a rede em uma se√ß√£o arbitr√°ria n√£o dar√° um resultado t√£o bom. <br><br><img src="https://habrastorage.org/webt/pj/x8/8g/pjx88gvs5ulvwslaqrsfrlqm9dk.jpeg"><br>  <i><font color="gray">Da esquerda para a direita: alta densidade ao redor da entrada;</font></i>  <i><font color="gray">abelhas de diferentes tamanhos;</font></i>  <i><font color="gray">abelhas em alta velocidade!</font></i> <br><br><h1>  Truques de rotulagem </h1><br><h3>  Treinamento semi-controlado </h3><br>  A possibilidade de obter um grande n√∫mero de imagens sugere imediatamente a id√©ia de usar o treinamento semi-controlado. <br><br>  Uma abordagem muito simples: <br><br><ol><li>  Fotografando 10.000 imagens. </li><li> Rotular 100 imagens e modelo de treinamento_1. </li><li>  Usando <code>model_1</code> para marcar as 9900 imagens restantes. </li><li>  <code>model_2</code> treinamento_2 nas 10.000 imagens "rotuladas". </li></ol><br>  Como resultado, o <code>model_2</code> mostra um resultado melhor que o <code>model_1</code> . <br><br>  Aqui est√° um exemplo.  Observe que o <code>model_1</code> mostra alguns falsos positivos (meio esquerdo e grama) e respostas negativas falsas (abelhas ao redor da entrada da colm√©ia). <br><br><img src="https://habrastorage.org/webt/k0/tw/a2/k0twa2fi48n5lgln3qunqtyzdsi.jpeg"><br>  <i><font color="gray">Modelo esquerdo_1, modelo direito_2</font></i> <br><br><h3>  Marcando corrigindo um modelo incorreto </h3><br>  Esses dados tamb√©m s√£o um √≥timo exemplo de como corrigir um modelo ruim √© mais r√°pido do que marcar do zero ... <br><br><ol><li>  Marcamos 10 imagens e treinamos o modelo. </li><li>  Usamos o modelo para marcar as pr√≥ximas 100 imagens. </li><li>  Usamos a ferramenta de marca√ß√£o para <i>corrigir as</i> marcas nessas 100 imagens. </li><li>  Eduque novamente o modelo em 110 fotos. </li><li>  Repetimos ... </li></ol><br>  Esse √© um padr√£o de aprendizado muito comum e √†s vezes obriga a revisar um pouco sua ferramenta de rotulagem. <br><br><h1>  Contando </h1><br>  A possibilidade de detectar abelhas significa que podemos cont√°-las!  E, por divers√£o, desenhe gr√°ficos divertidos que mostrem o n√∫mero de abelhas durante o dia.  Eu amo a maneira como eles trabalham o dia todo e chego em casa por volta das 16h.  :) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/554/b08/01c/554b0801c2d7cc360c5ea9c11339a2ee.png"><br><br><h1>  Sa√≠da Raspberry Pi </h1><br>  O lan√ßamento do modelo no Pi foi uma parte importante deste projeto. <br><br><h3>  Diretamente no ferro Pi </h3><br>  Foi originalmente planejado congelar o gr√°fico TensorFlow e simplesmente execut√°-lo diretamente no Pi.  Isso funciona sem problemas, mas apenas o Pi obt√©m apenas 1 imagem por segundo.  : / <br><br><h3>  Executando no m√≥dulo de computa√ß√£o Movidius </h3><br>  Fiquei muito interessado na oportunidade de lan√ßar um modelo em um Pi usando o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Movidus Neural Compute Stick</a> .  Este √© um gadget incr√≠vel. <br><br>  Infelizmente, nada aconteceu: /.  A API para converter um gr√°fico TensorFlow em seu formato de modelo interno n√£o suporta meu m√©todo de decodifica√ß√£o.  Portanto, era necess√°rio aumentar o tamanho (upsizing), usando a desconvolu√ß√£o em vez de redimensionar nos vizinhos mais pr√≥ximos.  N√£o h√° problemas al√©m do fato de que nada aconteceu.  Existem muitas pequenas dificuldades, devido √†s quais os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">erros se multiplicaram</a> .  Quando eles s√£o corrigidos, voc√™ pode retornar a este t√≥pico ... <br><br>  <b>Modelo v3: imagem RGB ‚Üí contagem de abelhas</b> <br>  Isso me levou √† terceira vers√£o do modelo: podemos ir diretamente da entrada RGB para a contagem de abelhas?  Dessa forma, evitaremos problemas com opera√ß√µes n√£o suportadas no Movidus Neural Compute Stick, embora seja improv√°vel que o resultado seja t√£o bom quanto no modelo centr√≥ide v2. <br><br>  No come√ßo, tive medo de tentar esse m√©todo: pensei que exigiria muito mais rotulagem (n√£o √© mais um sistema baseado em fragmentos).  Mas!  Tendo um modelo que se sai muito bem com a pesquisa de abelhas e muitos dados n√£o marcados, √© poss√≠vel gerar um bom conjunto de dados sint√©ticos aplicando o modelo v2 e simplesmente contando o n√∫mero de detec√ß√µes. <br><br>  Esse modelo √© bastante f√°cil de aprender e fornece resultados significativos ... (embora ainda n√£o seja t√£o bom quanto um simples c√°lculo dos centr√≥ides detectados pelo modelo v2). <br><br><table><tbody><tr><td colspan="13" align="center">  N√∫mero real e previsto de abelhas em algumas amostras de teste </td></tr><tr><td>  O real </td><td>  40. </td><td>  19 </td><td>  16 </td><td>  15 </td><td>  13 </td><td>  12 </td><td>  11 </td><td>  10 </td><td>  8 </td><td>  7 </td><td>  6 </td><td>  4 </td></tr><tr><td>  preditivo v2 (centr√≥ide) </td><td>  39. </td><td>  19 </td><td>  16 </td><td>  13 </td><td>  13 </td><td>  14 </td><td>  11 </td><td>  8 </td><td>  8 </td><td>  7 </td><td>  6 </td><td>  4 </td></tr><tr><td>  previs√£o v3 (c√°lculo simples) </td><td>  33.1 </td><td>  15,3 </td><td>  12,3 </td><td>  12,5 </td><td>  13,3 </td><td>  10,4 </td><td>  9,3 </td><td>  8,7 </td><td>  6.3. </td><td>  7.1 </td><td>  5,9 </td><td>  4.2 </td></tr></tbody></table><br>  ... infelizmente, o modelo <i>ainda</i> n√£o funciona no Neural Compute Stick (ou seja, funciona, mas fornece apenas resultados aleat√≥rios).  Fiz <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mais alguns relat√≥rios de erros</a> e novamente adiei o gadget para voltar mais tarde ... algum dia ... <br><br><h1>  O que vem a seguir? </h1><br>  Como sempre, um monte de pequenas coisas permaneceu ... <br><br><ul><li>  Lan√ßamento no Neural Compute Stick (NCS);  Agora estamos aguardando algum trabalho da parte deles ... </li><li>  Port tudo para a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">c√¢mera JeVois embutida</a> .  Eu brinquei com ela um pouco, mas antes de tudo eu queria lan√ßar um modelo no NCS.  Eu quero rastrear abelhas a 120 FPS !!! </li><li>  Acompanhe as abelhas entre v√°rios quadros / c√¢meras para visualizar o fluxo √≥ptico. </li><li>  Explore com mais detalhes os benef√≠cios de uma abordagem semi-controlada e treine um modelo maior para rotular dados para um modelo menor. </li><li>  Explore os recursos do NCS;  o que fazer com a defini√ß√£o de hiperpar√¢metros? </li><li>  Continue desenvolvendo uma vers√£o pequena do FarmBot para realizar alguns experimentos gen√©ticos com mudas de CNC (ou seja, algo completamente diferente). </li></ul><br><h1>  C√≥digo </h1><br>  Todo o c√≥digo √© publicado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no Github</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt413799/">https://habr.com/ru/post/pt413799/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt413789/index.html">Na Fl√≥rida, eles n√£o verificaram os compradores de armas na base do FBI por um ano porque esqueceram a senha</a></li>
<li><a href="../pt413791/index.html">Mec√¢nica Qu√¢ntica de C√°lculos em JS</a></li>
<li><a href="../pt413793/index.html">Cassetes de √°udio na cultura pop: por que o formato obsoleto de grava√ß√£o de som √© novamente considerado moda</a></li>
<li><a href="../pt413795/index.html">Por que a ind√∫stria do entretenimento est√° mudando para o IaaS: estudo de caso</a></li>
<li><a href="../pt413797/index.html">A EA apresentou a nova parte do C&C na E3. E √© fisicamente doloroso olhar para ele</a></li>
<li><a href="../pt413801/index.html">"Roskosmos" oferece refazer um canh√£o laser ... um telesc√≥pio √≥ptico</a></li>
<li><a href="../pt413803/index.html">Python e esteganografia</a></li>
<li><a href="../pt413805/index.html">Como um servidor esquecido por 12 anos pode custar 120.000 libras</a></li>
<li><a href="../pt413807/index.html">Determina√ß√£o das caracter√≠sticas bal√≠stico-temporais do movimento do centro de massa de um paraquedista que aterra de um avi√£o</a></li>
<li><a href="../pt413809/index.html">Decodificador e experi√™ncias com Android no cont√™iner LXC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚óºÔ∏è üë©üèª‚Äçüåæ üññ Werden wir Milit√§rrobotern eine Lizenz zum T√∂ten geben? ü§ôüèæ üòí ü¶è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wenn sich KI-Kriegsroboter verbessern, √§ndert sich das Wesen des Krieges 
 1920 schrieb der tschechische Schriftsteller Karel ƒåapek das St√ºck RUR (Ros...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Werden wir Milit√§rrobotern eine Lizenz zum T√∂ten geben?</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/395139/"><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn sich KI-Kriegsroboter verbessern, √§ndert sich das Wesen des Krieges</font></font></h4> <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/c86/c5d/3aa/c86c5d3aa3cd2c3bff1bc337ce7b2185.jpg" alt="image" align="left"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1920 schrieb der tschechische Schriftsteller Karel ƒåapek das St√ºck RUR (Rossums Universalroboter, ‚ÄûRossum Universalroboter‚Äú), in dem er der Welt das Wort ‚ÄûRoboter‚Äú gab. In seinem St√ºck beginnt alles mit k√ºnstlichen Menschen - Robotern, die in Fabriken arbeiten und preiswerte Waren herstellen. Und alles endet damit, dass Roboter die Menschheit zerst√∂ren. So wurde die langlebige Verschw√∂rung der NF geboren: Roboter geraten au√üer Kontrolle und verwandeln sich in unaufhaltsame T√∂tungsmaschinen. Literatur und Kino des 20. Jahrhunderts liefern uns weiterhin Beispiele f√ºr Roboter, die die Welt zerst√∂ren, und Hollywood verwandelt sie st√§ndig in Blockbuster-Franchises: The Matrix, Transformers und Terminator. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In j√ºngster Zeit wird die Angst, Fiktion in die Realit√§t umzusetzen, durch eine Kombination von Umst√§nden gest√ºtzt, darunter Verbesserungen in der KI und in der Robotik, deren Verbreitung</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Milit√§rdrohnen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bodenroboter</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> im Irak und in Afghanistan. Die gr√∂√üten M√§chte entwickeln intelligente Waffen mit unterschiedlichem Ma√ü an Autonomie und Sterblichkeit. Die meisten von ihnen werden bald von Personen ferngesteuert, ohne deren Befehl der Roboter den Abzug nicht bet√§tigen kann. Aber h√∂chstwahrscheinlich - und einigen zufolge werden die Roboter, auch ohne Zweifel, irgendwann v√∂llig autonom arbeiten k√∂nnen, und der Rubicon wird in milit√§rischen Angelegenheiten eingeschaltet sein: Zum ersten Mal wird eine Reihe von Mikrochips und Software entscheiden, ob eine Person lebt oder stirbt.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es √ºberrascht nicht, dass die Bedrohung durch Killerroboter, wie sie sie liebevoll nannten, zu einer leidenschaftlichen Debatte f√ºhrte. Auf der anderen Seite des Streits stehen diejenigen, die bef√ºrchten, dass automatische Waffen einen allgemeinen Krieg ausl√∂sen und die Zivilisation zerst√∂ren, und diejenigen, die behaupten, dass neue Waffen nur eine weitere Klasse pr√§zisionsgelenkter Waffen sind, die die Zahl der Opfer eher verringern als erh√∂hen. Im Dezember werden mehr als hundert L√§nder dieses Thema auf dem NATO-Abr√ºstungstreffen in Genf er√∂rtern.</font></font><br>
 <a name="habracut"></a><br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/a2e/0df/8e4/a2e0df8e4fb135857d43408473f58d47.jpg" alt="image"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine vom Menschen kontrollierte Drohne </font></font></i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/899/2da/a97/8992daa97646635f8ab91c85843ce5a1.jpg" alt="image"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine Phalanx-Waffe, die in der Lage ist, unabh√§ngig zu schie√üen. Im</font></font></i><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
vergangenen Jahr kam eine solche Diskussion in die Nachrichten, als eine Gruppe f√ºhrender KI-Forscher ein Verbot von "autonomen Offensivwaffen forderte, die ohne sinnvolle menschliche Kontrolle funktionieren". In </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">einem offenen Brief</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> an eine internationale Konferenz √ºber KI stellte eine Gruppe von Forschern fest, dass solche Waffen zu einem internationalen Wettr√ºsten der KI f√ºhren und f√ºr Auftragsmorde, Destabilisierung von Nationen, Unterdr√ºckung von V√∂lkern und selektive Zerst√∂rung ethnischer Gruppen eingesetzt werden k√∂nnten. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Brief wurde von mehr als 20.000 Menschen unterzeichnet, darunter so ber√ºhmte Pers√∂nlichkeiten wie der Physiker Stephen Hawking und der Unternehmer Ilon Musk. Letzterer spendete dem </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">Boston Institute im</font></a><font style="vertical-align: inherit;"> vergangenen Jahr 10 Millionen US-Dollar.</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, engagiert sich f√ºr den Schutz des Lebens von Menschen vor der hypothetischen Bedrohung durch eine unfreundliche KI. Die Wissenschaftler, die das Schreiben organisierten - Stuart Russell von der University of California in Berkeley, Max Tegmark vom MIT und Toby Walsh von der University of New South Wales in Australien - erweiterten ihre Position in einem Artikel f√ºr IEEE Spectrum. In einem Szenario kann beispielsweise ‚Äûeine gro√üe Anzahl kosteng√ºnstiger Mikroroboter, die von einer Person auf den Schwarzmarkt gebracht werden k√∂nnen, get√∂tet werden, und Tausende oder Millionen von Menschen, die den Kriterien des Benutzers entsprechen, k√∂nnen t√∂ten‚Äú. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sie f√ºgten hinzu, dass ‚Äûautonome Waffen zu Massenvernichtungswaffen werden k√∂nnen. "Einige L√§nder verbieten m√∂glicherweise seine Verwendung, w√§hrend andere L√§nder und nat√ºrlich Terroristen es unwahrscheinlich sind, dass sie es aufgeben k√∂nnen."</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es kann kaum gesagt werden, dass ein neues Wettr√ºsten, das zu intelligenten, autonomen und mobilen T√∂tungsmaschinen f√ºhren kann, dem Nutzen der gesamten Menschheit dienen wird. </font><font style="vertical-align: inherit;">Dieses Rennen hat jedoch bereits begonnen. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Autonome Waffen existieren seit mehreren Jahrzehnten, obwohl ihre seltenen Exemplare bisher haupts√§chlich zur Verteidigung eingesetzt wurden. </font><font style="vertical-align: inherit;">Ein Beispiel ist die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Phalanx</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , eine computergesteuerte Waffe, die vom Radar gesteuert und auf Kriegsschiffen der US-Marine montiert wird. </font><font style="vertical-align: inherit;">Sie kann die sich n√§hernden Raketen und Flugzeuge, die sie als Bedrohung betrachtet, automatisch erkennen, verfolgen, bewerten und abschie√üen. </font><font style="vertical-align: inherit;">In einem vollst√§ndig autonomen Modus ist eine Beteiligung des Menschen √ºberhaupt nicht erforderlich.</font></font><br>
 <br>
<iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://www.youtube.com/embed/ELsxY_liTvk%3Ffeature%3Doembed&amp;usg=ALkJrhh0QvUfeSdhu4CyzhMNnGnxUr5krQ" frameborder="0" allowfullscreen=""></iframe><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Harop-Drohne zerst√∂rt Ziel</font></font></i><br>
<br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://www.youtube.com/embed/mZF-qXpEz8U%3Ffeature%3Doembed&amp;usg=ALkJrhjv6dHvmSkUOY4mcm3zB6OKLkTDRA" frameborder="0" allowfullscreen=""></iframe><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DoDAAM Systems demonstriert die F√§higkeiten der Super aEgis II-Roboteruhr.</font></font></i><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Vor kurzem haben Milit√§rentwickler begonnen, offensive autonome Roboter zu entwickeln. Die Firma </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Israel Aerospace Industries</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> hat Drohnen Harpyie hergestellt und Harop, was dazu f√ºhrt, Radiowellen der feindlichen Luftabwehrsysteme, und sie durch die Kollision t√∂ten. Das Unternehmen behauptet, dass sich seine UAVs weltweit gut verkaufen. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das s√ºdkoreanische Unternehmen </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DoDAAM Systems hat</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> die Super aEgis II Roboteruhr entwickelt. Er schie√üt mit einem Maschinengewehr und verwendet Computer Vision, um Ziele (Personen) in einer Entfernung von 3 km zu erkennen und zu schie√üen. Es wird vermutet, dass das s√ºdkoreanische Milit√§r Tests dieser Roboter in der entmilitarisierten Zone an der Grenze zu Nordkorea durchgef√ºhrt hat. DoDAAM schon</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">verkaufte 30 solcher Ger√§te</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> an andere L√§nder, darunter mehrere Kunden aus dem Nahen Osten. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Heutzutage gibt es nur wenige Systeme mit einem hohen Ma√ü an Autonomie im Vergleich zu Roboterwaffen, die fast immer von Menschen gesteuert werden, insbesondere w√§hrend des Schie√üens. Analysten sagen voraus, dass Waffen mit der Entwicklung milit√§rischer Angelegenheiten immer autonomere F√§higkeiten haben werden.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Der Krieg wird v√∂llig anders sein und die Automatisierung wird eine Rolle spielen, wenn es auf Geschwindigkeit ankommt", sagte Peter Singer, ein Experte f√ºr Milit√§rroboter bei der in Washington ans√§ssigen unpolitischen Gruppe New America. Er wird lesen, dass in zuk√ºnftigen Schlachten - wie in Schlachten zwischen verschiedenen UAVs oder wenn ein automatisches Schiff auf ein automatisches U-Boot trifft - eine Waffe, die einen Bruchteil eines zweiten Vorteils hat, √ºber den Ausgang des Kampfes entscheidet. "Es kann einen pl√∂tzlichen und intensiven Konflikt geben, in dem es einfach keine Zeit gibt, die Leute auf den neuesten Stand zu bringen, weil alles in Sekundenschnelle entschieden wird." </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das US-Milit√§r hat </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">seine langfristigen Pl√§ne</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> f√ºr eine neue Art von Krieg mit unbemannten Systemen beschrieben, aber ob sie beabsichtigen, diese Systeme zu bewaffnen, ist noch unbekannt. Ein</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Auf dem Forum der Washington Post</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> im M√§rz wies US-Verteidigungsminister Robert Work, dessen Aufgabe es ist, sicherzustellen, dass das Pentagon mit der neuesten Technologie Schritt h√§lt, auf die Notwendigkeit von Investitionen in KI und Roboter hin. </font><font style="vertical-align: inherit;">Ihm zufolge ist die zunehmende Pr√§senz autonomer Systeme auf dem Schlachtfeld "unvermeidlich". </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Bezug auf autonome Waffen besteht Work darauf, dass das US-Milit√§r "der Maschine nicht die Macht geben wird, fatale Entscheidungen zu treffen". </font><font style="vertical-align: inherit;">Er selbst f√ºgte jedoch hinzu: ‚ÄûWenn ein Gegner bereit zu sein scheint, solche Befugnisse zu √ºbertragen, m√ºssen wir mit ihm Entscheidungen √ºber die Frage des Wettbewerbs treffen. </font><font style="vertical-align: inherit;">Wir haben es noch nicht vollst√§ndig herausgefunden, aber wir denken viel dar√ºber nach. ‚Äú</font></font><br>
 <br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://www.youtube.com/embed/283bDqu92PY%3Ffeature%3Doembed&amp;usg=ALkJrhhEaevHLQKTaQlMDeQwxd1X0C10hw" frameborder="0" allowfullscreen=""></iframe><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wladimir Putin beobachtet w√§hrend der Demonstration im letzten Jahr einen milit√§rischen Cyborg auf einem ATV</font></font></i><br>
 <br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://www.youtube.com/embed/TQ6FHcNiZ7E%3Ffeature%3Doembed&amp;usg=ALkJrhiJPx9KBcxFu4vAFGZzBlO4McdOzg" frameborder="0" allowfullscreen=""></iframe><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der Erstflug des CH-5 UAV des chinesischen Unternehmens China Aerospace Science and Technology Corporation,</font></font></i><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Russland und China verfolgt eine </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√§hnliche Strategie</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> bei der Entwicklung unbemannter Kampfsysteme f√ºr Operationen an Land, auf See und in der Luft, die, obwohl bewaffnet, immer noch von lebenden Betreibern abh√§ngen. Russian Platform-M ist ein kleiner Roboter mit Fernbedienung, der mit einem Kalaschnikow-Sturmgewehr und einem Granatwerfer ausgestattet ist. Es √§hnelt dem US </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Talon SWORDS-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> System </font><font style="vertical-align: inherit;">, einem bodengest√ºtzten Roboter, der M16 und andere im Irak getestete Waffen tragen kann. Russland baute auch ein unbemanntes Fahrzeug Uranus-9, das mit einer 30-mm-Kanone und Panzerabwehrraketen bewaffnet war. Und letztes Jahr haben die Russen Putin einen milit√§rischen humanoiden Roboter vorgef√ºhrt.</font></font><br>
 <br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chinas wachsendes Arsenal an Milit√§rrobotern</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> umfasst viele Drohnen f√ºr Angriffe und Aufkl√§rung. CH-4 - UAV lang wirkend, erinnert an den US Predator. Divine Eagle - eine hochgelegene Drohne f√ºr die Jagd auf Stealth-Bomber. Dar√ºber hinaus wurden Roboter mit Maschinengewehren √§hnlich Platform-M und Talon SWORDS bei verschiedenen milit√§rischen Pr√§sentationen in China gezeigt.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diese drei L√§nder n√§hern sich der Schaffung bewaffneter Roboter und betonen mit zunehmender Autonomie gleichzeitig die Wahrung der Rolle der Menschen in ihrer Arbeit. F√ºr das Verbot autonomer Waffen wird ein ernstes Problem auftreten: Es wird nicht unbedingt auf nahezu autonome Waffen anwendbar sein. Das Milit√§r kann immer verdeckt bewaffnete Roboter entwickeln, die von Menschen gesteuert werden, aber auf Knopfdruck in den Offline-Modus wechseln. ‚ÄûF√ºr Roboter wird es sehr schwierig sein, eine R√ºstungsbeschr√§nkungsvereinbarung aufzuerlegen‚Äú, schlie√üt Wendell Wallach, Ethik- und Technologieexperte an der Yale University. "Der Unterschied zwischen autonomen und nicht autonomen Waffen kann nur eine Codezeile sein", sagte er auf einer Konferenz.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Filmen werden Roboter manchmal √ºberraschend autonom, bis sie fast von Grund auf bewusst werden, was </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">die Menschen √ºberrascht</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">In der realen Welt </font><font style="vertical-align: inherit;">gewinnen Roboter </font><font style="vertical-align: inherit;">trotz der allgemeinen Aufregung √ºber den </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fortschritt des maschinellen Lernens</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> allm√§hlich Autonomie. </font><font style="vertical-align: inherit;">Das gleiche kann von autonomen Waffen erwartet werden.</font></font><br>
 <br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Anthologie von Killerrobotern</font></font></h4><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/924/164/d9f/924164d9f101a1d80a1bc27fb3bef3d3.jpg" alt="image"><br>
<i>¬´R.U.R¬ª 1920  ‚Äì    ,     </i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/3ce/14e/ae1/3ce14eae196c15aca8af1612af5037fd.jpg" alt="image"><br>
<i>¬´2001:  ¬ª (1968).      ,    </i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/250/478/ae7/250478ae732ed6c408da6be487f13629.jpg" alt="image"><br>
<i>¬´  ¬ª (1973).       </i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/12f/669/10c/12f66910c78ba978a5f33d475891ec4c.jpg" alt="image"><br>
<i>¬´  ¬ª (1982).     -</i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/e2f/c53/d8f/e2fc53d8f06a40e355a96f9a5f21d139.jpg" alt="image"><br>
<i>¬´¬ª (1984).   - -800    </i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/b81/121/5d0/b811215d0a442400f6de639e668dedf5.jpg" alt="image"><br>
<i> (1987).    ‚Äì    ,       .</i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/4cd/9bf/ff0/4cd9bfff0ad4f98b3671a7e9298a793e.jpg" alt="image"><br>
<i> (1999).            </i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/10b/89d/048/10b89d0486ca926cda9659761776b62b.jpg" alt="image"><br>
<i>¬´  ¬ª (2004). ,  ,      </i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/be6/835/8f4/be68358f4a1716ce02f2a33df085c94d.jpg" alt="image"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich, Roboter (2004). Humanoide Roboter, die die drei Gesetze der Robotik umgehen, machen in Chicago </font></font></i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/706/783/4d9/7067834d94be304367a338c0b68ce1de.jpg" alt="image"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Transformers (2007) </font></font></i><font style="vertical-align: inherit;"><i><font style="vertical-align: inherit;">Probleme </font></i><i><font style="vertical-align: inherit;">. Eine Bande au√üerirdischer Roboter, angef√ºhrt von Megatron, versucht, alle Menschen zu vernichten.</font></i></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
‚ÄûWenn Menschen von autonomen Waffen h√∂ren, repr√§sentieren sie oft den Terminator und sagen:‚Äû Was haben wir getan? ‚Äú, Sagt Paul Scharre, Programmmanager f√ºr zuk√ºnftige milit√§rische Angelegenheiten in </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Zentrum der neuen amerikanischen Sicherheitsforschungsgruppe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in Washington. "Aber es ist unwahrscheinlich, dass das Milit√§r diese Art von autonomer Waffe einsetzen will." Ihm zufolge werden autonome Systeme h√∂chstwahrscheinlich milit√§rische Einrichtungen wie Radar, Panzer, Schiffe, U-Boote und Flugzeuge angreifen.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Aufgabe, das Ziel zu identifizieren - festzustellen, ob ein Objekt dem Feind geh√∂rt - ist eine der kritischsten Aufgaben f√ºr die KI. Sich bewegende Ziele, Flugzeuge und Raketen haben eine Flugbahn, die verfolgt werden kann und auf deren Grundlage die Entscheidung getroffen wird, ein Objekt zum Absturz zu bringen. So funktioniert die Phalanx-Kanone auf US-Kriegsschiffen, ebenso wie das israelische Raketenabfangsystem Iron Dome. Wenn jedoch Menschen als Ziel ausgew√§hlt werden, ist diese Identifizierung kompliziert. Selbst unter idealen Bedingungen kann die Erkennung von Objekten und Umgebungen, mit denen Menschen st√§ndig fertig werden, f√ºr Roboter zu komplex sein. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein Computer kann die Figur einer Person unterscheiden, selbst wenn sie sich heimlich bewegt. F√ºr den Algorithmus ist es jedoch schwierig zu verstehen, womit Menschen besch√§ftigt sind und welche Absichten ihre K√∂rpersprache und ihr Gesichtsausdruck vermitteln. Hebt ein Mann eine Waffe oder einen Rechen? H√§lt er eine Bombe oder ein Baby?</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Scarre behauptet, dass Roboterwaffen, die versuchen, ein Ziel selbst zu w√§hlen, angesichts von Schwierigkeiten sparen. Seiner Meinung nach bleibt der beste Ansatz unter dem Gesichtspunkt der Sicherheit, Legalit√§t und Ethik die Entwicklung solcher Taktiken und Technologien, bei denen Menschen </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mit Robotern zusammenarbeiten</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . "Das Milit√§r kann in fortschrittliche Robotik und Automatisierung investieren, aber gleichzeitig die Person in der Kontrollkette verlassen, um Entscheidungen √ºber Ziele zu treffen, um sicher zu sein", sagt er. ‚ÄûSchlie√ülich sind die Menschen flexibler und passen sich besser an neue Situationen an, die wir m√∂glicherweise nicht programmieren. Dies ist besonders wichtig in einem Krieg, in dem ein Gegner versucht, Ihre Systeme zu besiegen, sie auszutricksen und zu hacken. ‚Äú</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es √ºberrascht nicht, dass S√ºdkoreaner von DoDAAM ihre Uhrenroboter mit strengen Autonomieeinschr√§nkungen herstellen. Jetzt schie√üen ihre Roboter erst, wenn eine Person das Ziel best√§tigt und "Feuer" befiehlt. "Die urspr√ºngliche Version war ein automatisches Feuersystem" </font><font style="vertical-align: inherit;">, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sagte</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ein Ingenieur des Unternehmens </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">gegen√ºber BBC im vergangenen Jahr</font></a><font style="vertical-align: inherit;"> . "Aber alle Kunden baten darum, Sicherheitsma√ünahmen einzubeziehen ... Sie bef√ºrchteten, dass die Waffe falsch sein k√∂nnte."</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Andere Experten glauben, dass der einzige Weg, um die fatalen Fehler einer autonomen Waffe, insbesondere unter Beteiligung von Zivilisten, zu vermeiden, darin besteht, geeignete Programme zu erstellen. "Wenn wir so dumm sind, dass wir uns auf dem Schlachtfeld weiterhin gegenseitig t√∂ten und wenn immer mehr Kr√§fte auf die Maschinen √ºbertragen werden, k√∂nnen wir zumindest sicherstellen, dass sie ihre Arbeit auf ethische Weise erledigen", sagt Ronald Arkin, IT Spezialist vom Institute of Technology in Georgia. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Arkin ist zuversichtlich, dass autonome Waffen wie Soldaten den Regeln der Kriegsf√ºhrung und den Kriegsgesetzen, einschlie√ülich der </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">humanit√§ren V√∂lkergesetze</font></a><font style="vertical-align: inherit;"> , folgen m√ºssen</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schutz der Zivilbev√∂lkerung und Begrenzung der Macht und der Arten zul√§ssiger Waffen. Dies bedeutet, dass wir bestimmte moralische Eigenschaften in ihre Programme einbringen m√ºssen, damit sie unterschiedliche Situationen verstehen und zwischen Gut und B√∂se unterscheiden k√∂nnen. Ihre Software muss einen ethischen Kompass haben.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In den letzten zehn Jahren hat Arkin an einem solchen Kompass gearbeitet. Mit mathematischen und logischen Werkzeugen aus dem Bereich der Maschinenethik √ºbersetzt er die Kriegsgesetze und die Regeln der Kriegsf√ºhrung in Variablen und Operationen, die f√ºr einen Computer verst√§ndlich sind. Beispielsweise enth√§lt eine der Variablen den Vertrauenswert der ethischen Kontrolleinheit, dass das Ziel ein Feind ist. Ein anderer, boolescher Wert, bedeutet, ob die T√∂tungskraft von Waffen erlaubt oder verboten ist. Am Ende kam Arkin zu einer Reihe von Algorithmen, und mithilfe von Computersimulationen und vereinfachten Kampfszenarien - zum Beispiel eines UAV, das eine Gruppe von Menschen auf freiem Feld angreift - konnte er seine Technik testen.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Arkin gibt zu, dass das von den US-Streitkr√§ften gesponserte Projekt noch nicht das Stadium des fertigen Systems erreicht hat und nur zum Nachweis seiner Funktionsf√§higkeit erstellt wurde. Aber seiner Meinung nach zeigen die Ergebnisse der Arbeit, dass Roboter noch besser sind, als Menschen den Regeln des Krieges folgen k√∂nnen. Zum Beispiel k√∂nnen Roboter lebensbedrohliche Aktionen mit mehr Zur√ºckhaltung als Menschen ausf√ºhren und nur als Reaktion darauf schie√üen. Oder wenn sich Zivilisten n√§hern, k√∂nnen sie im Allgemeinen das Feuer einstellen, selbst wenn sie selbst zerst√∂rt werden. Roboter leiden nicht unter Stress, Unzufriedenheit, Wut, Angst - und all dies kann die Annahme der richtigen Entscheidungen bei Menschen beeintr√§chtigen. Theoretisch k√∂nnen Roboter </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">daher menschliche Soldaten √ºbertreffen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , die in der Hitze des Kampfes oft und manchmal unvermeidlich Fehler machen.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Infolgedessen k√∂nnen wir Leben retten, insbesondere das Leben unschuldiger Menschen, die in einer Schlacht gefangen sind", sagt Arkin. "Und wenn Roboter dies k√∂nnen, deutet die Moral auf die Notwendigkeit hin, sie einzusetzen." </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nat√ºrlich wird diese Ansicht nicht allgemein akzeptiert. Kritiker Autonome Waffen bestehen darauf, dass nur ein pr√§ventives Verbot Sinn macht, weil solche Waffen hinter den Kulissen erscheinen. "Es gibt kein solches Feuersystem, auf das wir hinweisen und sagen k√∂nnten: Ja, hier ist er ein Killerroboter", sagt Mary Wareham. Lobby Manager und Coor von Human Rights Watch ordinator Kampagne zum Verbot Killerroboter ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kampagne Stop Killer - </font><font style="vertical-align: inherit;">Roboter</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) - Koalitionen verschiedener humanit√§rer Gemeinschaften. - Wir sprechen √ºber viele verschiedene Waffensysteme, die auf unterschiedliche Weise funktionieren. Wir sind jedoch besorgt √ºber eines ihrer gemeinsamen Merkmale - die mangelnde menschliche Kontrolle √ºber die Funktion der Zielauswahl und des Angriffs. " </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei den Vereinten Nationen </font><font style="vertical-align: inherit;">gibt es seit f√ºnf Jahren </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Diskussionen √ºber autonome Roboter</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , die t√∂ten k√∂nnen, aber die L√§nder haben keine Einigung erzielt. 2013 schrieb Christof Heyns, UN-Sonderberichterstatter f√ºr Menschenrechte, einen </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">einflussreichen Bericht</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, in dem er feststellte, dass L√§nder eine seltene Gelegenheit haben, die Risiken autonomer Waffen zu diskutieren, noch bevor sie entwickelt werden. Nachdem Hines an mehreren UN-Treffen teilgenommen hat, sagt er: "Wenn Sie zur√ºckblicken, bin ich etwas ermutigt, aber wenn Sie nach vorne schauen, scheinen wir Probleme zu haben, wenn wir nicht schneller vorankommen." </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Dezember dieses Jahres wird auf </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">der UN-Konvention √ºber klassische Waffen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> eine Konferenz √ºber f√ºnfj√§hrige Arbeit stattfinden, und das Thema autonome Roboter steht auf der Tagesordnung. Es ist jedoch unwahrscheinlich, dass ihr Verbot akzeptiert wird. Eine solche Entscheidung erfordert eine einstimmige Entscheidung aller L√§nder, und es gibt grunds√§tzliche Meinungsverschiedenheiten zwischen ihnen dar√ºber, was mit dem breiten Spektrum autonomer Waffen geschehen soll, die in Zukunft erscheinen werden.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Streitigkeiten √ºber Killerroboter f√ºhren daher zu einer Diskussion √ºber Menschen. </font><font style="vertical-align: inherit;">Zumindest anfangs werden autonome Waffen jeder Technologie √§hnlich sein: Sie k√∂nnen genau und umsichtig oder chaotisch und katastrophal eingef√ºhrt werden. </font><font style="vertical-align: inherit;">Und die Leute m√ºssen die Anschuldigungen akzeptieren. </font><font style="vertical-align: inherit;">Daher die Frage ‚ÄûSind autonome Kampfroboter eine gute Idee?‚Äú </font><font style="vertical-align: inherit;">nicht der richtige. </font><font style="vertical-align: inherit;">Es ist besser, die Frage zu stellen: "Vertrauen wir uns genug, um Robotern f√ºr unser Leben zu vertrauen?"</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de395139/">https://habr.com/ru/post/de395139/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de395125/index.html">Snap-Pakete werden jetzt auf vielen Linux-Distributionen (und m√∂glicherweise in Zukunft auf Windows) verf√ºgbar sein.</a></li>
<li><a href="../de395127/index.html">Informationssicherheit in Singapur: Alle Beamten sind vom Internet getrennt</a></li>
<li><a href="../de395129/index.html">√úbersicht √ºber den Router der Draytek 2912-Serie. Teil Zwei</a></li>
<li><a href="../de395131/index.html">Mit Firefox k√∂nnen Sie auf Websites unter mehreren Konten gleichzeitig zugreifen</a></li>
<li><a href="../de395137/index.html">Remote-Er√∂ffnung eines Brokerage-Kontos √ºber das Gosuslug-Portal: Warum und wie?</a></li>
<li><a href="../de395141/index.html">Von Browser-Lesezeichen zu einer neuen √Ñra: Ein wenig √ºber die Geschichte der Entwicklung von Social-Button-Diensten</a></li>
<li><a href="../de395143/index.html">Ist es m√∂glich, Ethik in den Algorithmus von Robomobilen einzuf√ºhren?</a></li>
<li><a href="../de395145/index.html">–°–ø—Ä–æ—Å–∏—Ç–µ –ò—Ç–∞–Ω–∞ ‚Ññ59: —á—Ç–æ —Ç–∞–∫–æ–µ —Ç—ë–º–Ω–∞—è —ç–Ω–µ—Ä–≥–∏—è?</a></li>
<li><a href="../de395147/index.html">Mitsubishi Outlander SUV bricht problemlos √ºber WLAN ein</a></li>
<li><a href="../de395149/index.html">Eine neue Erkl√§rung des Prinzips der "unm√∂glichen" Engine EmDrive: Das sind alles Photonen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>◼️ 👩🏻‍🌾 🖖 Werden wir Militärrobotern eine Lizenz zum Töten geben? 🤙🏾 😒 🦏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wenn sich KI-Kriegsroboter verbessern, ändert sich das Wesen des Krieges 
 1920 schrieb der tschechische Schriftsteller Karel Čapek das Stück RUR (Ros...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Werden wir Militärrobotern eine Lizenz zum Töten geben?</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/395139/"><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn sich KI-Kriegsroboter verbessern, ändert sich das Wesen des Krieges</font></font></h4> <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/c86/c5d/3aa/c86c5d3aa3cd2c3bff1bc337ce7b2185.jpg" alt="image" align="left"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1920 schrieb der tschechische Schriftsteller Karel Čapek das Stück RUR (Rossums Universalroboter, „Rossum Universalroboter“), in dem er der Welt das Wort „Roboter“ gab. In seinem Stück beginnt alles mit künstlichen Menschen - Robotern, die in Fabriken arbeiten und preiswerte Waren herstellen. Und alles endet damit, dass Roboter die Menschheit zerstören. So wurde die langlebige Verschwörung der NF geboren: Roboter geraten außer Kontrolle und verwandeln sich in unaufhaltsame Tötungsmaschinen. Literatur und Kino des 20. Jahrhunderts liefern uns weiterhin Beispiele für Roboter, die die Welt zerstören, und Hollywood verwandelt sie ständig in Blockbuster-Franchises: The Matrix, Transformers und Terminator. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In jüngster Zeit wird die Angst, Fiktion in die Realität umzusetzen, durch eine Kombination von Umständen gestützt, darunter Verbesserungen in der KI und in der Robotik, deren Verbreitung</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Militärdrohnen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bodenroboter</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> im Irak und in Afghanistan. Die größten Mächte entwickeln intelligente Waffen mit unterschiedlichem Maß an Autonomie und Sterblichkeit. Die meisten von ihnen werden bald von Personen ferngesteuert, ohne deren Befehl der Roboter den Abzug nicht betätigen kann. Aber höchstwahrscheinlich - und einigen zufolge werden die Roboter, auch ohne Zweifel, irgendwann völlig autonom arbeiten können, und der Rubicon wird in militärischen Angelegenheiten eingeschaltet sein: Zum ersten Mal wird eine Reihe von Mikrochips und Software entscheiden, ob eine Person lebt oder stirbt.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es überrascht nicht, dass die Bedrohung durch Killerroboter, wie sie sie liebevoll nannten, zu einer leidenschaftlichen Debatte führte. Auf der anderen Seite des Streits stehen diejenigen, die befürchten, dass automatische Waffen einen allgemeinen Krieg auslösen und die Zivilisation zerstören, und diejenigen, die behaupten, dass neue Waffen nur eine weitere Klasse präzisionsgelenkter Waffen sind, die die Zahl der Opfer eher verringern als erhöhen. Im Dezember werden mehr als hundert Länder dieses Thema auf dem NATO-Abrüstungstreffen in Genf erörtern.</font></font><br>
 <a name="habracut"></a><br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/a2e/0df/8e4/a2e0df8e4fb135857d43408473f58d47.jpg" alt="image"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine vom Menschen kontrollierte Drohne </font></font></i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/899/2da/a97/8992daa97646635f8ab91c85843ce5a1.jpg" alt="image"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eine Phalanx-Waffe, die in der Lage ist, unabhängig zu schießen. Im</font></font></i><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
vergangenen Jahr kam eine solche Diskussion in die Nachrichten, als eine Gruppe führender KI-Forscher ein Verbot von "autonomen Offensivwaffen forderte, die ohne sinnvolle menschliche Kontrolle funktionieren". In </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">einem offenen Brief</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> an eine internationale Konferenz über KI stellte eine Gruppe von Forschern fest, dass solche Waffen zu einem internationalen Wettrüsten der KI führen und für Auftragsmorde, Destabilisierung von Nationen, Unterdrückung von Völkern und selektive Zerstörung ethnischer Gruppen eingesetzt werden könnten. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Brief wurde von mehr als 20.000 Menschen unterzeichnet, darunter so berühmte Persönlichkeiten wie der Physiker Stephen Hawking und der Unternehmer Ilon Musk. Letzterer spendete dem </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">Boston Institute im</font></a><font style="vertical-align: inherit;"> vergangenen Jahr 10 Millionen US-Dollar.</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, engagiert sich für den Schutz des Lebens von Menschen vor der hypothetischen Bedrohung durch eine unfreundliche KI. Die Wissenschaftler, die das Schreiben organisierten - Stuart Russell von der University of California in Berkeley, Max Tegmark vom MIT und Toby Walsh von der University of New South Wales in Australien - erweiterten ihre Position in einem Artikel für IEEE Spectrum. In einem Szenario kann beispielsweise „eine große Anzahl kostengünstiger Mikroroboter, die von einer Person auf den Schwarzmarkt gebracht werden können, getötet werden, und Tausende oder Millionen von Menschen, die den Kriterien des Benutzers entsprechen, können töten“. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sie fügten hinzu, dass „autonome Waffen zu Massenvernichtungswaffen werden können. "Einige Länder verbieten möglicherweise seine Verwendung, während andere Länder und natürlich Terroristen es unwahrscheinlich sind, dass sie es aufgeben können."</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es kann kaum gesagt werden, dass ein neues Wettrüsten, das zu intelligenten, autonomen und mobilen Tötungsmaschinen führen kann, dem Nutzen der gesamten Menschheit dienen wird. </font><font style="vertical-align: inherit;">Dieses Rennen hat jedoch bereits begonnen. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Autonome Waffen existieren seit mehreren Jahrzehnten, obwohl ihre seltenen Exemplare bisher hauptsächlich zur Verteidigung eingesetzt wurden. </font><font style="vertical-align: inherit;">Ein Beispiel ist die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Phalanx</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , eine computergesteuerte Waffe, die vom Radar gesteuert und auf Kriegsschiffen der US-Marine montiert wird. </font><font style="vertical-align: inherit;">Sie kann die sich nähernden Raketen und Flugzeuge, die sie als Bedrohung betrachtet, automatisch erkennen, verfolgen, bewerten und abschießen. </font><font style="vertical-align: inherit;">In einem vollständig autonomen Modus ist eine Beteiligung des Menschen überhaupt nicht erforderlich.</font></font><br>
 <br>
<iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://www.youtube.com/embed/ELsxY_liTvk%3Ffeature%3Doembed&amp;usg=ALkJrhh0QvUfeSdhu4CyzhMNnGnxUr5krQ" frameborder="0" allowfullscreen=""></iframe><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Harop-Drohne zerstört Ziel</font></font></i><br>
<br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://www.youtube.com/embed/mZF-qXpEz8U%3Ffeature%3Doembed&amp;usg=ALkJrhjv6dHvmSkUOY4mcm3zB6OKLkTDRA" frameborder="0" allowfullscreen=""></iframe><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DoDAAM Systems demonstriert die Fähigkeiten der Super aEgis II-Roboteruhr.</font></font></i><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Vor kurzem haben Militärentwickler begonnen, offensive autonome Roboter zu entwickeln. Die Firma </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Israel Aerospace Industries</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> hat Drohnen Harpyie hergestellt und Harop, was dazu führt, Radiowellen der feindlichen Luftabwehrsysteme, und sie durch die Kollision töten. Das Unternehmen behauptet, dass sich seine UAVs weltweit gut verkaufen. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das südkoreanische Unternehmen </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">DoDAAM Systems hat</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> die Super aEgis II Roboteruhr entwickelt. Er schießt mit einem Maschinengewehr und verwendet Computer Vision, um Ziele (Personen) in einer Entfernung von 3 km zu erkennen und zu schießen. Es wird vermutet, dass das südkoreanische Militär Tests dieser Roboter in der entmilitarisierten Zone an der Grenze zu Nordkorea durchgeführt hat. DoDAAM schon</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">verkaufte 30 solcher Geräte</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> an andere Länder, darunter mehrere Kunden aus dem Nahen Osten. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Heutzutage gibt es nur wenige Systeme mit einem hohen Maß an Autonomie im Vergleich zu Roboterwaffen, die fast immer von Menschen gesteuert werden, insbesondere während des Schießens. Analysten sagen voraus, dass Waffen mit der Entwicklung militärischer Angelegenheiten immer autonomere Fähigkeiten haben werden.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Der Krieg wird völlig anders sein und die Automatisierung wird eine Rolle spielen, wenn es auf Geschwindigkeit ankommt", sagte Peter Singer, ein Experte für Militärroboter bei der in Washington ansässigen unpolitischen Gruppe New America. Er wird lesen, dass in zukünftigen Schlachten - wie in Schlachten zwischen verschiedenen UAVs oder wenn ein automatisches Schiff auf ein automatisches U-Boot trifft - eine Waffe, die einen Bruchteil eines zweiten Vorteils hat, über den Ausgang des Kampfes entscheidet. "Es kann einen plötzlichen und intensiven Konflikt geben, in dem es einfach keine Zeit gibt, die Leute auf den neuesten Stand zu bringen, weil alles in Sekundenschnelle entschieden wird." </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das US-Militär hat </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">seine langfristigen Pläne</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> für eine neue Art von Krieg mit unbemannten Systemen beschrieben, aber ob sie beabsichtigen, diese Systeme zu bewaffnen, ist noch unbekannt. Ein</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Auf dem Forum der Washington Post</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> im März wies US-Verteidigungsminister Robert Work, dessen Aufgabe es ist, sicherzustellen, dass das Pentagon mit der neuesten Technologie Schritt hält, auf die Notwendigkeit von Investitionen in KI und Roboter hin. </font><font style="vertical-align: inherit;">Ihm zufolge ist die zunehmende Präsenz autonomer Systeme auf dem Schlachtfeld "unvermeidlich". </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Bezug auf autonome Waffen besteht Work darauf, dass das US-Militär "der Maschine nicht die Macht geben wird, fatale Entscheidungen zu treffen". </font><font style="vertical-align: inherit;">Er selbst fügte jedoch hinzu: „Wenn ein Gegner bereit zu sein scheint, solche Befugnisse zu übertragen, müssen wir mit ihm Entscheidungen über die Frage des Wettbewerbs treffen. </font><font style="vertical-align: inherit;">Wir haben es noch nicht vollständig herausgefunden, aber wir denken viel darüber nach. “</font></font><br>
 <br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://www.youtube.com/embed/283bDqu92PY%3Ffeature%3Doembed&amp;usg=ALkJrhhEaevHLQKTaQlMDeQwxd1X0C10hw" frameborder="0" allowfullscreen=""></iframe><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wladimir Putin beobachtet während der Demonstration im letzten Jahr einen militärischen Cyborg auf einem ATV</font></font></i><br>
 <br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://www.youtube.com/embed/TQ6FHcNiZ7E%3Ffeature%3Doembed&amp;usg=ALkJrhiJPx9KBcxFu4vAFGZzBlO4McdOzg" frameborder="0" allowfullscreen=""></iframe><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der Erstflug des CH-5 UAV des chinesischen Unternehmens China Aerospace Science and Technology Corporation,</font></font></i><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Russland und China verfolgt eine </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ähnliche Strategie</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> bei der Entwicklung unbemannter Kampfsysteme für Operationen an Land, auf See und in der Luft, die, obwohl bewaffnet, immer noch von lebenden Betreibern abhängen. Russian Platform-M ist ein kleiner Roboter mit Fernbedienung, der mit einem Kalaschnikow-Sturmgewehr und einem Granatwerfer ausgestattet ist. Es ähnelt dem US </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Talon SWORDS-</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> System </font><font style="vertical-align: inherit;">, einem bodengestützten Roboter, der M16 und andere im Irak getestete Waffen tragen kann. Russland baute auch ein unbemanntes Fahrzeug Uranus-9, das mit einer 30-mm-Kanone und Panzerabwehrraketen bewaffnet war. Und letztes Jahr haben die Russen Putin einen militärischen humanoiden Roboter vorgeführt.</font></font><br>
 <br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chinas wachsendes Arsenal an Militärrobotern</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> umfasst viele Drohnen für Angriffe und Aufklärung. CH-4 - UAV lang wirkend, erinnert an den US Predator. Divine Eagle - eine hochgelegene Drohne für die Jagd auf Stealth-Bomber. Darüber hinaus wurden Roboter mit Maschinengewehren ähnlich Platform-M und Talon SWORDS bei verschiedenen militärischen Präsentationen in China gezeigt.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Diese drei Länder nähern sich der Schaffung bewaffneter Roboter und betonen mit zunehmender Autonomie gleichzeitig die Wahrung der Rolle der Menschen in ihrer Arbeit. Für das Verbot autonomer Waffen wird ein ernstes Problem auftreten: Es wird nicht unbedingt auf nahezu autonome Waffen anwendbar sein. Das Militär kann immer verdeckt bewaffnete Roboter entwickeln, die von Menschen gesteuert werden, aber auf Knopfdruck in den Offline-Modus wechseln. „Für Roboter wird es sehr schwierig sein, eine Rüstungsbeschränkungsvereinbarung aufzuerlegen“, schließt Wendell Wallach, Ethik- und Technologieexperte an der Yale University. "Der Unterschied zwischen autonomen und nicht autonomen Waffen kann nur eine Codezeile sein", sagte er auf einer Konferenz.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Filmen werden Roboter manchmal überraschend autonom, bis sie fast von Grund auf bewusst werden, was </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">die Menschen überrascht</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">In der realen Welt </font><font style="vertical-align: inherit;">gewinnen Roboter </font><font style="vertical-align: inherit;">trotz der allgemeinen Aufregung über den </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fortschritt des maschinellen Lernens</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> allmählich Autonomie. </font><font style="vertical-align: inherit;">Das gleiche kann von autonomen Waffen erwartet werden.</font></font><br>
 <br>
<h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Anthologie von Killerrobotern</font></font></h4><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/924/164/d9f/924164d9f101a1d80a1bc27fb3bef3d3.jpg" alt="image"><br>
<i>«R.U.R» 1920  –    ,     </i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/3ce/14e/ae1/3ce14eae196c15aca8af1612af5037fd.jpg" alt="image"><br>
<i>«2001:  » (1968).      ,    </i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/250/478/ae7/250478ae732ed6c408da6be487f13629.jpg" alt="image"><br>
<i>«  » (1973).       </i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/12f/669/10c/12f66910c78ba978a5f33d475891ec4c.jpg" alt="image"><br>
<i>«  » (1982).     -</i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/e2f/c53/d8f/e2fc53d8f06a40e355a96f9a5f21d139.jpg" alt="image"><br>
<i>«» (1984).   - -800    </i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/b81/121/5d0/b811215d0a442400f6de639e668dedf5.jpg" alt="image"><br>
<i> (1987).    –    ,       .</i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/4cd/9bf/ff0/4cd9bfff0ad4f98b3671a7e9298a793e.jpg" alt="image"><br>
<i> (1999).            </i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/10b/89d/048/10b89d0486ca926cda9659761776b62b.jpg" alt="image"><br>
<i>«  » (2004). ,  ,      </i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/be6/835/8f4/be68358f4a1716ce02f2a33df085c94d.jpg" alt="image"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich, Roboter (2004). Humanoide Roboter, die die drei Gesetze der Robotik umgehen, machen in Chicago </font></font></i><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/706/783/4d9/7067834d94be304367a338c0b68ce1de.jpg" alt="image"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Transformers (2007) </font></font></i><font style="vertical-align: inherit;"><i><font style="vertical-align: inherit;">Probleme </font></i><i><font style="vertical-align: inherit;">. Eine Bande außerirdischer Roboter, angeführt von Megatron, versucht, alle Menschen zu vernichten.</font></i></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
„Wenn Menschen von autonomen Waffen hören, repräsentieren sie oft den Terminator und sagen:„ Was haben wir getan? “, Sagt Paul Scharre, Programmmanager für zukünftige militärische Angelegenheiten in </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Zentrum der neuen amerikanischen Sicherheitsforschungsgruppe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> in Washington. "Aber es ist unwahrscheinlich, dass das Militär diese Art von autonomer Waffe einsetzen will." Ihm zufolge werden autonome Systeme höchstwahrscheinlich militärische Einrichtungen wie Radar, Panzer, Schiffe, U-Boote und Flugzeuge angreifen.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Aufgabe, das Ziel zu identifizieren - festzustellen, ob ein Objekt dem Feind gehört - ist eine der kritischsten Aufgaben für die KI. Sich bewegende Ziele, Flugzeuge und Raketen haben eine Flugbahn, die verfolgt werden kann und auf deren Grundlage die Entscheidung getroffen wird, ein Objekt zum Absturz zu bringen. So funktioniert die Phalanx-Kanone auf US-Kriegsschiffen, ebenso wie das israelische Raketenabfangsystem Iron Dome. Wenn jedoch Menschen als Ziel ausgewählt werden, ist diese Identifizierung kompliziert. Selbst unter idealen Bedingungen kann die Erkennung von Objekten und Umgebungen, mit denen Menschen ständig fertig werden, für Roboter zu komplex sein. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein Computer kann die Figur einer Person unterscheiden, selbst wenn sie sich heimlich bewegt. Für den Algorithmus ist es jedoch schwierig zu verstehen, womit Menschen beschäftigt sind und welche Absichten ihre Körpersprache und ihr Gesichtsausdruck vermitteln. Hebt ein Mann eine Waffe oder einen Rechen? Hält er eine Bombe oder ein Baby?</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Scarre behauptet, dass Roboterwaffen, die versuchen, ein Ziel selbst zu wählen, angesichts von Schwierigkeiten sparen. Seiner Meinung nach bleibt der beste Ansatz unter dem Gesichtspunkt der Sicherheit, Legalität und Ethik die Entwicklung solcher Taktiken und Technologien, bei denen Menschen </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mit Robotern zusammenarbeiten</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . "Das Militär kann in fortschrittliche Robotik und Automatisierung investieren, aber gleichzeitig die Person in der Kontrollkette verlassen, um Entscheidungen über Ziele zu treffen, um sicher zu sein", sagt er. „Schließlich sind die Menschen flexibler und passen sich besser an neue Situationen an, die wir möglicherweise nicht programmieren. Dies ist besonders wichtig in einem Krieg, in dem ein Gegner versucht, Ihre Systeme zu besiegen, sie auszutricksen und zu hacken. “</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es überrascht nicht, dass Südkoreaner von DoDAAM ihre Uhrenroboter mit strengen Autonomieeinschränkungen herstellen. Jetzt schießen ihre Roboter erst, wenn eine Person das Ziel bestätigt und "Feuer" befiehlt. "Die ursprüngliche Version war ein automatisches Feuersystem" </font><font style="vertical-align: inherit;">, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sagte</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ein Ingenieur des Unternehmens </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">gegenüber BBC im vergangenen Jahr</font></a><font style="vertical-align: inherit;"> . "Aber alle Kunden baten darum, Sicherheitsmaßnahmen einzubeziehen ... Sie befürchteten, dass die Waffe falsch sein könnte."</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Andere Experten glauben, dass der einzige Weg, um die fatalen Fehler einer autonomen Waffe, insbesondere unter Beteiligung von Zivilisten, zu vermeiden, darin besteht, geeignete Programme zu erstellen. "Wenn wir so dumm sind, dass wir uns auf dem Schlachtfeld weiterhin gegenseitig töten und wenn immer mehr Kräfte auf die Maschinen übertragen werden, können wir zumindest sicherstellen, dass sie ihre Arbeit auf ethische Weise erledigen", sagt Ronald Arkin, IT Spezialist vom Institute of Technology in Georgia. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Arkin ist zuversichtlich, dass autonome Waffen wie Soldaten den Regeln der Kriegsführung und den Kriegsgesetzen, einschließlich der </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">humanitären Völkergesetze</font></a><font style="vertical-align: inherit;"> , folgen müssen</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schutz der Zivilbevölkerung und Begrenzung der Macht und der Arten zulässiger Waffen. Dies bedeutet, dass wir bestimmte moralische Eigenschaften in ihre Programme einbringen müssen, damit sie unterschiedliche Situationen verstehen und zwischen Gut und Böse unterscheiden können. Ihre Software muss einen ethischen Kompass haben.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In den letzten zehn Jahren hat Arkin an einem solchen Kompass gearbeitet. Mit mathematischen und logischen Werkzeugen aus dem Bereich der Maschinenethik übersetzt er die Kriegsgesetze und die Regeln der Kriegsführung in Variablen und Operationen, die für einen Computer verständlich sind. Beispielsweise enthält eine der Variablen den Vertrauenswert der ethischen Kontrolleinheit, dass das Ziel ein Feind ist. Ein anderer, boolescher Wert, bedeutet, ob die Tötungskraft von Waffen erlaubt oder verboten ist. Am Ende kam Arkin zu einer Reihe von Algorithmen, und mithilfe von Computersimulationen und vereinfachten Kampfszenarien - zum Beispiel eines UAV, das eine Gruppe von Menschen auf freiem Feld angreift - konnte er seine Technik testen.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Arkin gibt zu, dass das von den US-Streitkräften gesponserte Projekt noch nicht das Stadium des fertigen Systems erreicht hat und nur zum Nachweis seiner Funktionsfähigkeit erstellt wurde. Aber seiner Meinung nach zeigen die Ergebnisse der Arbeit, dass Roboter noch besser sind, als Menschen den Regeln des Krieges folgen können. Zum Beispiel können Roboter lebensbedrohliche Aktionen mit mehr Zurückhaltung als Menschen ausführen und nur als Reaktion darauf schießen. Oder wenn sich Zivilisten nähern, können sie im Allgemeinen das Feuer einstellen, selbst wenn sie selbst zerstört werden. Roboter leiden nicht unter Stress, Unzufriedenheit, Wut, Angst - und all dies kann die Annahme der richtigen Entscheidungen bei Menschen beeinträchtigen. Theoretisch können Roboter </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">daher menschliche Soldaten übertreffen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , die in der Hitze des Kampfes oft und manchmal unvermeidlich Fehler machen.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Infolgedessen können wir Leben retten, insbesondere das Leben unschuldiger Menschen, die in einer Schlacht gefangen sind", sagt Arkin. "Und wenn Roboter dies können, deutet die Moral auf die Notwendigkeit hin, sie einzusetzen." </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Natürlich wird diese Ansicht nicht allgemein akzeptiert. Kritiker Autonome Waffen bestehen darauf, dass nur ein präventives Verbot Sinn macht, weil solche Waffen hinter den Kulissen erscheinen. "Es gibt kein solches Feuersystem, auf das wir hinweisen und sagen könnten: Ja, hier ist er ein Killerroboter", sagt Mary Wareham. Lobby Manager und Coor von Human Rights Watch ordinator Kampagne zum Verbot Killerroboter ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kampagne Stop Killer - </font><font style="vertical-align: inherit;">Roboter</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) - Koalitionen verschiedener humanitärer Gemeinschaften. - Wir sprechen über viele verschiedene Waffensysteme, die auf unterschiedliche Weise funktionieren. Wir sind jedoch besorgt über eines ihrer gemeinsamen Merkmale - die mangelnde menschliche Kontrolle über die Funktion der Zielauswahl und des Angriffs. " </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bei den Vereinten Nationen </font><font style="vertical-align: inherit;">gibt es seit fünf Jahren </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Diskussionen über autonome Roboter</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , die töten können, aber die Länder haben keine Einigung erzielt. 2013 schrieb Christof Heyns, UN-Sonderberichterstatter für Menschenrechte, einen </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">einflussreichen Bericht</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, in dem er feststellte, dass Länder eine seltene Gelegenheit haben, die Risiken autonomer Waffen zu diskutieren, noch bevor sie entwickelt werden. Nachdem Hines an mehreren UN-Treffen teilgenommen hat, sagt er: "Wenn Sie zurückblicken, bin ich etwas ermutigt, aber wenn Sie nach vorne schauen, scheinen wir Probleme zu haben, wenn wir nicht schneller vorankommen." </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Dezember dieses Jahres wird auf </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">der UN-Konvention über klassische Waffen</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> eine Konferenz über fünfjährige Arbeit stattfinden, und das Thema autonome Roboter steht auf der Tagesordnung. Es ist jedoch unwahrscheinlich, dass ihr Verbot akzeptiert wird. Eine solche Entscheidung erfordert eine einstimmige Entscheidung aller Länder, und es gibt grundsätzliche Meinungsverschiedenheiten zwischen ihnen darüber, was mit dem breiten Spektrum autonomer Waffen geschehen soll, die in Zukunft erscheinen werden.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Streitigkeiten über Killerroboter führen daher zu einer Diskussion über Menschen. </font><font style="vertical-align: inherit;">Zumindest anfangs werden autonome Waffen jeder Technologie ähnlich sein: Sie können genau und umsichtig oder chaotisch und katastrophal eingeführt werden. </font><font style="vertical-align: inherit;">Und die Leute müssen die Anschuldigungen akzeptieren. </font><font style="vertical-align: inherit;">Daher die Frage „Sind autonome Kampfroboter eine gute Idee?“ </font><font style="vertical-align: inherit;">nicht der richtige. </font><font style="vertical-align: inherit;">Es ist besser, die Frage zu stellen: "Vertrauen wir uns genug, um Robotern für unser Leben zu vertrauen?"</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de395139/">https://habr.com/ru/post/de395139/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de395125/index.html">Snap-Pakete werden jetzt auf vielen Linux-Distributionen (und möglicherweise in Zukunft auf Windows) verfügbar sein.</a></li>
<li><a href="../de395127/index.html">Informationssicherheit in Singapur: Alle Beamten sind vom Internet getrennt</a></li>
<li><a href="../de395129/index.html">Übersicht über den Router der Draytek 2912-Serie. Teil Zwei</a></li>
<li><a href="../de395131/index.html">Mit Firefox können Sie auf Websites unter mehreren Konten gleichzeitig zugreifen</a></li>
<li><a href="../de395137/index.html">Remote-Eröffnung eines Brokerage-Kontos über das Gosuslug-Portal: Warum und wie?</a></li>
<li><a href="../de395141/index.html">Von Browser-Lesezeichen zu einer neuen Ära: Ein wenig über die Geschichte der Entwicklung von Social-Button-Diensten</a></li>
<li><a href="../de395143/index.html">Ist es möglich, Ethik in den Algorithmus von Robomobilen einzuführen?</a></li>
<li><a href="../de395145/index.html">Спросите Итана №59: что такое тёмная энергия?</a></li>
<li><a href="../de395147/index.html">Mitsubishi Outlander SUV bricht problemlos über WLAN ein</a></li>
<li><a href="../de395149/index.html">Eine neue Erklärung des Prinzips der "unmöglichen" Engine EmDrive: Das sind alles Photonen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐂 ⛵️ 🧝 Jaringan saraf untuk mendefinisikan pembenci - "tidak, itu larangan" 🧓🏻 🚤 🧗</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hai 

 Apakah Anda sering melihat komentar beracun di jejaring sosial? Mungkin tergantung pada konten yang Anda tonton. Saya mengusulkan untuk bereksp...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Jaringan saraf untuk mendefinisikan pembenci - "tidak, itu larangan"</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/476188/">  Hai <br><br>  Apakah Anda sering melihat komentar beracun di jejaring sosial?  Mungkin tergantung pada konten yang Anda tonton.  Saya mengusulkan untuk bereksperimen sedikit tentang topik ini dan mengajar jaringan saraf untuk menentukan komentar pembenci. <br><br>  Jadi, tujuan global kami adalah untuk menentukan apakah komentar itu agresif, artinya, kita berurusan dengan klasifikasi biner.  Kami akan menulis jaringan saraf sederhana, melatihnya pada kumpulan komentar dari jejaring sosial yang berbeda, dan kemudian kami akan membuat analisis sederhana dengan visualisasi. <br><br>  Untuk pekerjaan saya akan menggunakan Google Colab.  Layanan ini memungkinkan Anda untuk menjalankan Notebook Jupyter, dan memiliki akses ke GPU (NVidia Tesla K80) secara gratis, yang akan mempercepat pembelajaran.  Saya akan membutuhkan backend TensorFlow, versi default di Colab 1.15.0, jadi cukup tingkatkan ke 2.0.0. <br><br>  Kami mengimpor modul dan memperbarui. <br><a name="habracut"></a><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf !tf_upgrade_v2 -h</code> </pre> <br>  Anda dapat melihat versi saat ini seperti ini. <br><br><pre> <code class="python hljs">print(tf.__version__)</code> </pre> <br>  Pekerjaan persiapan selesai, kami mengimpor semua modul yang diperlukan. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># For DataFrame object import pandas as pd # Neural Network from keras.models import Sequential from keras.layers import Dense, Dropout from keras.optimizers import RMSprop # Text Vectorizing from keras.preprocessing.text import Tokenizer # Train-test-split from sklearn.model_selection import train_test_split # History visualization %matplotlib inline import matplotlib.pyplot as plt # Normalize from sklearn.preprocessing import normalize</span></span></code> </pre><br><h2>  Deskripsi perpustakaan yang digunakan </h2><br><ul><li>  os - untuk bekerja dengan sistem file </li></ul><br><ul><li>  numpy - untuk bekerja dengan array </li></ul><br><ul><li>  panda - perpustakaan untuk menganalisis data tabular </li></ul><br><ul><li>  keras - untuk membangun model </li></ul><br><ul><li>  keras.preprocessing.Text - untuk pemrosesan teks, untuk mengirimkannya dalam bentuk numerik untuk pelatihan jaringan saraf </li></ul><br><ul><li>  sklearn.train_test_split - untuk memisahkan data uji dari pelatihan </li></ul><br><ul><li>  matplotlib - untuk memvisualisasikan proses pembelajaran </li></ul><br><ul><li>  sklearn.normalalize - untuk menormalkan data tes dan pelatihan </li></ul><br><h2>  Parsing data dengan Kaggle </h2><br>  Saya memuat data langsung ke laptop Colab itu sendiri.  Selanjutnya, tanpa masalah, saya sudah mengekstraksi mereka. <br><br><pre> <code class="python hljs">path = <span class="hljs-string"><span class="hljs-string">'labeled.csv'</span></span> df = pd.read_csv(path) df.head()</code> </pre> <br><img src="https://habrastorage.org/webt/7e/is/vk/7eisvkltuwv5hhe0ir5oopolmx4.png"><br><br>  Dan ini adalah judul dari dataset kami ... Saya juga merasa tidak nyaman dari "halaman refresh, tolol." <br>  Jadi, data kita ada dalam tabel, kita akan membaginya menjadi dua bagian: data untuk pelatihan dan untuk model uji.  Tapi ini semua teks, sesuatu harus dilakukan. <br><br><h2>  Pemrosesan data </h2><br>  Hapus karakter baris baru dari teks. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">delete_new_line_symbols</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(text)</span></span></span><span class="hljs-function">:</span></span> text = text.replace(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> text</code> </pre> <br><pre> <code class="python hljs">df[<span class="hljs-string"><span class="hljs-string">'comment'</span></span>] = df[<span class="hljs-string"><span class="hljs-string">'comment'</span></span>].apply(delete_new_line_symbols) df.head()</code> </pre> <br>  Komentar memiliki tipe data nyata, kita perlu menerjemahkannya menjadi integer.  Selanjutnya, simpan dalam variabel terpisah. <br><br><pre> <code class="python hljs">target = np.array(df[<span class="hljs-string"><span class="hljs-string">'toxic'</span></span>].astype(<span class="hljs-string"><span class="hljs-string">'uint8'</span></span>)) target[:<span class="hljs-number"><span class="hljs-number">5</span></span>]</code> </pre> <br>  Sekarang kita akan sedikit memproses teks menggunakan kelas Tokenizer.  Mari kita menulis salinannya. <br><br><pre> <code class="python hljs">tokenizer = Tokenizer(num_words=<span class="hljs-number"><span class="hljs-number">30000</span></span>, filters=<span class="hljs-string"><span class="hljs-string">'!"#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~\t\n'</span></span>, lower=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, split=<span class="hljs-string"><span class="hljs-string">' '</span></span>, char_level=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  <b>Cepat tentang parameter</b> <br><br><ul><li>  num_words - jumlah kata tetap (paling umum) </li></ul><br><ul><li>  filter - urutan karakter yang akan dihapus </li></ul><br><ul><li>  lower - parameter boolean yang mengontrol apakah teks akan menggunakan huruf kecil </li></ul><br><ul><li>  split - simbol utama untuk memisahkan sebuah kalimat </li></ul><br><ul><li>  char_level - menunjukkan apakah satu karakter akan dianggap kata </li></ul><br>  Dan sekarang kita akan memproses teks menggunakan kelas. <br><br><pre> <code class="python hljs">tokenizer.fit_on_texts(df[<span class="hljs-string"><span class="hljs-string">'comment'</span></span>]) matrix = tokenizer.texts_to_matrix(df[<span class="hljs-string"><span class="hljs-string">'comment'</span></span>], mode=<span class="hljs-string"><span class="hljs-string">'count'</span></span>) matrix.shape</code> </pre> <br>  Kami mendapat 14k baris sampel dan kolom fitur 30k. <br><br><img src="https://habrastorage.org/webt/4z/iz/ji/4zizjiclkgiyu__wmblolopw3ri.png"><br><br>  Saya membangun model dari dua lapisan: Padat dan Putus Sekolah. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model = Sequential() model.add(Dense(<span class="hljs-number"><span class="hljs-number">32</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">16</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">16</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)) model.compile(optimizer=RMSprop(lr=<span class="hljs-number"><span class="hljs-number">0.0001</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br>  Kami menormalkan matriks dan membagi data menjadi dua bagian, sesuai kesepakatan (pelatihan dan tes). <br><br><pre> <code class="python hljs">X = normalize(matrix) y = target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number"><span class="hljs-number">0.2</span></span>) X_train.shape, y_train.shape</code> </pre> <br><h2>  Pelatihan model </h2><br><pre> <code class="python hljs">model = get_model() history = model.fit(X_train, y_train, epochs=<span class="hljs-number"><span class="hljs-number">150</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">500</span></span>, validation_data=(X_test, y_test)) history</code> </pre> <br>  Saya akan menunjukkan proses pembelajaran pada iterasi terakhir. <br><br><img src="https://habrastorage.org/webt/n5/p8/ko/n5p8ko8tp68sz-tb3bgtrtmyhx4.png"><br><br><h2>  Visualisasi proses pembelajaran </h2><br><pre> <code class="python hljs">history = history.history fig = plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) ax1 = fig.add_subplot(<span class="hljs-number"><span class="hljs-number">221</span></span>) ax2 = fig.add_subplot(<span class="hljs-number"><span class="hljs-number">223</span></span>) x = range(<span class="hljs-number"><span class="hljs-number">150</span></span>) ax1.plot(x, history[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>], <span class="hljs-string"><span class="hljs-string">'b-'</span></span>, label=<span class="hljs-string"><span class="hljs-string">'Accuracy'</span></span>) ax1.plot(x, history[<span class="hljs-string"><span class="hljs-string">'val_acc'</span></span>], <span class="hljs-string"><span class="hljs-string">'r-'</span></span>, label=<span class="hljs-string"><span class="hljs-string">'Validation accuracy'</span></span>) ax1.legend(loc=<span class="hljs-string"><span class="hljs-string">'lower right'</span></span>) ax2.plot(x, history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>], <span class="hljs-string"><span class="hljs-string">'b-'</span></span>, label=<span class="hljs-string"><span class="hljs-string">'Losses'</span></span>) ax2.plot(x, history[<span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>], <span class="hljs-string"><span class="hljs-string">'r-'</span></span>, label=<span class="hljs-string"><span class="hljs-string">'Validation losses'</span></span>) ax2.legend(loc=<span class="hljs-string"><span class="hljs-string">'upper right'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/tg/1p/bn/tg1pbntyktgpmnckeeiqbizub9k.png"><br><br><img src="https://habrastorage.org/webt/j0/gh/lb/j0ghlbxyvtctsrvtrwrweuw0vwa.png"><br><br><h2>  Kesimpulan </h2><br>  Model keluar sekitar era ke-75, dan kemudian berperilaku buruk.  Keakuratan 0,85 tidak mengecewakan.  Anda bisa bersenang-senang dengan jumlah layer, hyperparameter dan mencoba meningkatkan hasilnya.  Itu selalu menarik dan merupakan bagian dari pekerjaan.  Tuliskan pemikiran Anda dalam komentar, kami akan melihat berapa banyak topi yang akan didapat artikel ini. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id476188/">https://habr.com/ru/post/id476188/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id476174/index.html">Intisari materi menarik untuk pengembang ponsel # 322 (pada 11-17 November)</a></li>
<li><a href="../id476178/index.html">Pengalaman pribadi tanpa pembakaran pada pekerjaan jarak jauh</a></li>
<li><a href="../id476182/index.html">Di Jepang, mereka menciptakan robot berkaki empat yang bisa menaiki tangga vertikal</a></li>
<li><a href="../id476184/index.html">Analisis: bagaimana Forex sebenarnya bekerja, dan apa yang perlu Anda ketahui tentang perdagangan mata uang di bursa saham untuk meminimalkan risiko</a></li>
<li><a href="../id476186/index.html">Bantuan untuk Pengembang Implementasi PKI</a></li>
<li><a href="../id476192/index.html">Tweet perpanjangan hidup yang penting</a></li>
<li><a href="../id476194/index.html">Habr Weekly # 27 / Chromebooks vs Macbooks, cara menulis resume keren, gaji apa yang diminta, AR-poin seharga $ 3500</a></li>
<li><a href="../id476198/index.html">Bagaimana saya membuat situs web pertama saya dan apa yang terjadi</a></li>
<li><a href="../id476206/index.html">Cadangan tambahan Postgresql dengan pgbackrest - kursus pejuang muda dari pengembang</a></li>
<li><a href="../id476208/index.html">Web Almanac 2019: Ketersediaan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëõ üë©üèæ‚Äçüé§ üèº Extracci√≥n de datos de aprendizaje autom√°tico üßóüèæ üòõ üë®üèø‚Äçüé§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬øQuiere aprender sobre tres m√©todos de miner√≠a de datos para su pr√≥ximo proyecto de ML? ¬°Luego lea la traducci√≥n del art√≠culo de Rebecca Vickery publi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Extracci√≥n de datos de aprendizaje autom√°tico</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/plarium/blog/460675/">  ¬øQuiere aprender sobre tres m√©todos de miner√≠a de datos para su pr√≥ximo proyecto de ML?  ¬°Luego lea la traducci√≥n del art√≠culo de Rebecca Vickery publicado en el blog Towards Data Science en Medium!  Ella ser√° interesante para los principiantes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ba/ce/h3/baceh3syebhbwo_3rvemwpfl8l8.jpeg"></div><br>  Obtener datos de calidad es el primer paso y el m√°s importante en cualquier proyecto de aprendizaje autom√°tico.  Los especialistas en ciencia de datos a menudo usan varios m√©todos para obtener conjuntos de datos.  Pueden usar datos disponibles p√∫blicamente, as√≠ como datos disponibles a trav√©s de la API u obtenidos de varias bases de datos, pero la mayor√≠a de las veces combinan estos m√©todos. <br><br>  El prop√≥sito de este art√≠culo es proporcionar una breve descripci√≥n de tres m√©todos diferentes para recuperar datos usando Python.  Te dir√© c√≥mo hacer esto con el cuaderno Jupyter.  En mi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> anterior <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">,</a> escrib√≠ sobre la aplicaci√≥n de algunos comandos que se ejecutan en el terminal. <a name="habracut"></a><br><br><h3>  SQL </h3><br>  Si necesita obtener datos de una base de datos relacional, lo m√°s probable es que trabaje con el lenguaje SQL.  La biblioteca SQLAlchemy le permite asociar el c√≥digo de su computadora port√°til con los tipos m√°s comunes de bases de datos.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aqu√≠</a> encontrar√° informaci√≥n sobre qu√© bases de datos son compatibles y c√≥mo enlazar a cada tipo. <br><br>  Puede usar la biblioteca SQLAlchemy para examinar tablas y consultar datos, o escribir consultas sin procesar.  Para enlazar a la base de datos, necesitar√° una URL con sus credenciales.  A continuaci√≥n, debe inicializar el m√©todo <code>create_engine</code> para crear la conexi√≥n. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sqlalchemy <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> create_engine engine = create_engine(<span class="hljs-string"><span class="hljs-string">'dialect+driver://username:password@host:port/database'</span></span>)</code> </pre> <br>  Ahora puede escribir consultas en la base de datos y obtener resultados. <br><br><pre> <code class="python hljs">connection = engine.connect() result = connection.execute(<span class="hljs-string"><span class="hljs-string">"select * from my_table"</span></span>)</code> </pre> <br><h3>  Raspado </h3><br>  El raspado web se utiliza para descargar datos de sitios web y extraer la informaci√≥n necesaria de sus p√°ginas.  Hay muchas bibliotecas de Python disponibles para esto, pero la m√°s simple es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Beautiful Soup</a> . <br><br>  Puede instalar el paquete a trav√©s de pip. <br><br><pre> <code class="python hljs">pip install BeautifulSoup4</code> </pre> <br>  Veamos un ejemplo simple de c√≥mo usarlo.  Usaremos Beautiful Soup y la biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">urllib</a> para obtener los nombres y precios de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hoteles</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TripAdvisor</a> . <br><br>  Primero, importamos todas las bibliotecas con las que vamos a trabajar. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> urllib.request</code> </pre> <br>  Ahora cargue el contenido de la p√°gina que desecharemos.  Quiero recopilar datos sobre los precios de los hoteles en la isla griega de Creta y tomar la direcci√≥n URL que contiene una lista de hoteles en este lugar. <br><br><img src="https://habrastorage.org/webt/vt/jj/7i/vtjj7icfxauctiw_juiik0oqgfo.png"><br><br>  El siguiente c√≥digo define la URL como una variable y utiliza la biblioteca urllib para abrir la p√°gina, y la biblioteca Beautiful Soup para leerla y devolver los resultados en un formato simple.  Parte de los datos de salida se muestran debajo del c√≥digo. <br><br><pre> <code class="python hljs">URL = <span class="hljs-string"><span class="hljs-string">'https://www.tripadvisor.co.uk/Hotels-g189413-Crete-Hotels.html'</span></span> page = urllib.request.urlopen(URL) soup = BeautifulSoup(page, <span class="hljs-string"><span class="hljs-string">'html.parser'</span></span>) print(soup.prettify())</code> </pre> <br><img src="https://habrastorage.org/webt/ul/n3/sn/uln3sn1bwjzjeft182k2dgbp7qo.png"><br><br>  Ahora obtengamos una lista con los nombres de los hoteles en la p√°gina.  Introduciremos la funci√≥n <code>find_all</code> , que extraer√° partes del documento que nos interese.  Puede filtrarlo de manera diferente utilizando la funci√≥n <code>find_all</code> para pasar una sola l√≠nea, expresi√≥n regular o lista.  Tambi√©n puede filtrar uno de los atributos de la etiqueta; este es exactamente el m√©todo que aplicaremos.  Si es nuevo en las etiquetas y atributos HTML, consulte este <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> para obtener una descripci√≥n general r√°pida. <br><br>  Para comprender la mejor manera de proporcionar acceso a los datos en la etiqueta, debemos verificar el c√≥digo de este elemento en la p√°gina.  Encontramos el c√≥digo para el nombre del hotel haciendo clic derecho sobre el nombre en la lista, como se muestra en la figura a continuaci√≥n. <br><br><img src="https://habrastorage.org/webt/uh/k5/zs/uhk5zsci0kajsubpkghjff3qnye.png"><br><br>  Despu√©s de hacer clic en <code>inspect</code> aparecer√° el c√≥digo <code>inspect</code> elemento y se resaltar√° la secci√≥n con el nombre del hotel. <br><br><img src="https://habrastorage.org/webt/pc/fh/ms/pcfhmsrk8knqsjzr2lzsif2d2j4.png"><br><br>  Vemos que el nombre del hotel es el √∫nico texto de la clase con el nombre <code>listing_title</code> .  Despu√©s de la clase viene el c√≥digo y el nombre de este atributo a la funci√≥n <code>find_all</code> , as√≠ como la etiqueta <code>div</code> . <br><br><pre> <code class="python hljs">content_name = soup.find_all(<span class="hljs-string"><span class="hljs-string">'div'</span></span>, attrs={<span class="hljs-string"><span class="hljs-string">'class'</span></span>: <span class="hljs-string"><span class="hljs-string">'listing_title'</span></span>}) print(content_name)</code> </pre> <br>  Cada secci√≥n del c√≥digo con el nombre del hotel se devuelve como una lista. <br><br><img src="https://habrastorage.org/webt/gi/u2/b1/giu2b1wmq7holjcoeyfqohasg6u.png"><br><br>  Para extraer los nombres de los hoteles del c√≥digo, utilizamos la funci√≥n <code>getText</code> de la biblioteca Beautiful Soup. <br><br><pre> <code class="python hljs">content_name_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> div <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> content_name: content_name_list.append(div.getText().split(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(content_name_list)</code> </pre> <br>  Los nombres de los hoteles se devuelven como una lista. <br><br><img src="https://habrastorage.org/webt/z0/bc/t-/z0bct-wezpzc8exsahj_fywmjnq.png"><br><br>  Del mismo modo obtenemos datos de precios.  La estructura del c√≥digo para el precio se muestra a continuaci√≥n. <br><br><img src="https://habrastorage.org/webt/v0/ok/oy/v0okoymlgmsbc6dtxicxwa_yz38.png"><br><br>  Como puede ver, podemos trabajar con un c√≥digo muy similar al utilizado para los hoteles. <br><br><pre> <code class="python hljs">content_price = soup.find_all(<span class="hljs-string"><span class="hljs-string">'div'</span></span>, attrs={<span class="hljs-string"><span class="hljs-string">'class'</span></span>: <span class="hljs-string"><span class="hljs-string">'price-wrap'</span></span>}) print(content_price)</code> </pre><br>  En el caso del precio, hay poca dificultad.  Puede verlo ejecutando el siguiente c√≥digo: <br><br><pre> <code class="python hljs">content_price_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> div <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> content_price: content_price_list.append(div.getText().split(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(content_price_list)</code> </pre> <br>  El resultado se muestra a continuaci√≥n.  Si se indica una reducci√≥n de precio en la lista de hoteles, adem√°s de alg√∫n texto, se devuelve tanto el precio inicial como el precio final.  Para solucionar este problema, simplemente devolvemos el precio actual de hoy. <br><br><img src="https://habrastorage.org/webt/52/6j/mn/526jmnbmxhchiyee4jr3feptxom.png"><br><br>  Podemos usar una l√≥gica simple para obtener el √∫ltimo precio indicado en el texto. <br><br><pre> <code class="python hljs">content_price_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> a <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> content_price: a_split = a.getText().split(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(a_split) &gt; <span class="hljs-number"><span class="hljs-number">5</span></span>: content_price_list.append(a_split[<span class="hljs-number"><span class="hljs-number">-4</span></span>:]) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: content_price_list.append(a_split) print(content_price_list)</code> </pre> <br>  Esto nos dar√° el siguiente resultado: <br><br><img src="https://habrastorage.org/webt/kx/d0/sn/kxd0snvrauaecf_q4lvpjdu8-z0.png"><br><br><h3>  API </h3><br>  API: interfaz de programaci√≥n de aplicaciones (de la interfaz de programaci√≥n de aplicaciones en ingl√©s).  Desde la perspectiva de la miner√≠a de datos, es un sistema basado en la web que proporciona un punto final de datos que puede contactar a trav√©s de la programaci√≥n.  Por lo general, los datos se devuelven en formato JSON o XML. <br><br>  Este m√©todo probablemente ser√° √∫til en el aprendizaje autom√°tico.  Dar√© un ejemplo simple de recuperaci√≥n de datos meteorol√≥gicos de la API p√∫blica de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dark Sky</a> .  Para conectarse, debe registrarse, y tendr√° 1000 llamadas gratis por d√≠a.  Esto deber√≠a ser suficiente para las pruebas. <br><br>  Para acceder a los datos de Dark Sky, <code>requests</code> biblioteca de <code>requests</code> .  En primer lugar, necesito obtener la URL correcta para la solicitud.  Adem√°s del pron√≥stico, Dark Sky proporciona datos hist√≥ricos del clima.  En este ejemplo, los tomar√© y obtendr√© la URL correcta de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentaci√≥n</a> . <br><br>  La estructura de esta URL es: <br><br><pre> <code class="python hljs">https://api.darksky.net/forecast/[key]/[latitude],[longitude],[time]</code> </pre> <br>  Utilizaremos la biblioteca de <code>requests</code> para obtener <br>  resultados para una latitud y longitud espec√≠ficas, as√≠ como la fecha y la hora.  Imagine que despu√©s de extraer datos de precios diarios de hoteles en Creta, decidimos averiguar si la pol√≠tica de precios est√° relacionada con el clima. <br><br>  Por ejemplo, tomemos las coordenadas de uno de los hoteles en la lista: Mitsis Laguna Resort &amp; Spa. <br><br><img src="https://habrastorage.org/webt/1j/4a/is/1j4aissalsvek5uw2opv3v9hdhw.png"><br><br>  Primero, cree una URL con las coordenadas correctas, as√≠ como la hora y fecha solicitadas.  Usando la biblioteca de <code>requests</code> , tenemos acceso a los datos en el formato JSON. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests request_url = <span class="hljs-string"><span class="hljs-string">'https://api.darksky.net/forecast/fd82a22de40c6dca7d1ae392ad83eeb3/35.3378,-25.3741,2019-07-01T12:00:00'</span></span> result = requests.get(request_url).json() result</code> </pre><br>  Para facilitar la lectura y el an√°lisis de los resultados, podemos convertir los datos en un marco de datos. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd df = pd.DataFrame.from_dict(json_normalize(result), orient=<span class="hljs-string"><span class="hljs-string">'columns'</span></span>) df.head()</code> </pre> <br><img src="https://habrastorage.org/webt/jw/1w/sv/jw1wsv_9ixycnrfu44l7qhloxb4.png"><br><br>  Hay muchas m√°s opciones para automatizar la extracci√≥n de datos utilizando estos m√©todos.  En el caso del raspado web, puede escribir diferentes funciones para automatizar el proceso y facilitar la extracci√≥n de datos para m√°s d√≠as y / o lugares.  En este art√≠culo, quer√≠a revisar y proporcionar suficientes ejemplos de c√≥digo.  Los siguientes materiales ser√°n m√°s detallados: le dir√© c√≥mo crear grandes conjuntos de datos y analizarlos utilizando los m√©todos descritos anteriormente. <br><br>  Gracias por su atencion! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/460675/">https://habr.com/ru/post/460675/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../460665/index.html">Preguntas frecuentes preliminares: ¬øPor qu√© los est√°ndares C ++ salen cada tres a√±os?</a></li>
<li><a href="../460667/index.html">Automatizaci√≥n de pruebas de servicios pagos en iOS</a></li>
<li><a href="../460669/index.html">C√≥mo garantizar la seguridad del desarrollo, ahorrando tiempo y nervios</a></li>
<li><a href="../460671/index.html">Propiedad y endeudamiento en D</a></li>
<li><a href="../460673/index.html">Exponer la magia de DiffUtil</a></li>
<li><a href="../460683/index.html">Laravel Event Projector y Event Generation Concept</a></li>
<li><a href="../460685/index.html">Distribuimos archivos de Google Drive usando nginx</a></li>
<li><a href="../460687/index.html">C√≥mo se ven las latas desde adentro</a></li>
<li><a href="../460695/index.html">¬øQu√© es DAA y c√≥mo este sistema ayuda a los drones?</a></li>
<li><a href="../460697/index.html">Fuente m√°s peque√±a posible</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
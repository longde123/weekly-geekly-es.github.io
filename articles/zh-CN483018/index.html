<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐸 👌 👨🏻‍🌾 Mask-R CNN从初学者到专业人士 🏪 🍮 🗣️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="一旦我需要分析来自图像和输出的信息以了解对象的类型，对象的类型以及分析帧的集合，就需要给出对象的标识符以及在帧中花费的时间，有必要确定对象的移动方式以及哪些摄像机可以进入视野。 让我们从头两个开始，下一部分将讨论总体人员分析。 


 好吧，我们将更详细地描述我们的任务： 


- 修复人员和汽车-...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mask-R CNN从初学者到专业人士</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483018/"><p><img src="https://lh6.googleusercontent.com/2ZHVaccuXIFgG1Z5qnHROW6cKyxjEe1RLo0SwRAaOxxyQI7Q_Ymbs7ZuZ6bOs56v7oMaCInsarFjOPZRDWL5hNdKpVhlVtHINo9u3gae4utQB-FARZPFxEV5UmkYY8LVJdTjZ0PK"></p><br><p>一旦我需要分析来自图像和输出的信息以了解对象的类型，对象的类型以及分析帧的集合，就需要给出对象的标识符以及在帧中花费的时间，有必要确定对象的移动方式以及哪些摄像机可以进入视野。 让我们从头两个开始，下一部分将讨论总体人员分析。 </p><a name="habracut"></a><br><p> 好吧，我们将更详细地描述我们的任务： </p><br><ul><li> 修复人员和汽车-在图像中选择它们并使用必要的字段生成相应的类实例。 </li><li> 确定汽车的编号（如果它落入特定摄像机的框架中） </li><li> 将当前框架与前一个框架进行比较，以确保对象相等，以便我们找出 </li></ul><br><p> 好吧，我想，然后捡起一条厚实的蛇蟒蛇。 决定结合其简单性和<a href="https://habr.com/ru/post/421299/">现代</a>性来使用<a href="https://github.com/matterport/Mask_RCNN">Mask R-Cnn</a>神经网络。 另外，当然，我们将使用OpenCV进行图像处理。 </p><br><h2 id="ustanovka-sredy"> 环境设定 </h2><br><p> 我们将使用Windows 10，因为您最有可能使用它。 <br> 据了解，您已经拥有64位Python。 如果没有，那么您可以例如<a href="https://www.python.org/downloads/release/python-374/">从此处</a>下载软件包 </p><br><h3 id="ustanovka-paketov"> 套件安装 </h3><br><pre><code class="plaintext hljs">git clone https://github.com/matterport/Mask_RCNN cd Mask_RCNN pip3 install -r requirements.txt python3 setup.py install</code> </pre> <br><p> 如果由于某种原因无法从源代码进行编译，则有一个来自pip的版本： </p><br><pre> <code class="plaintext hljs">pip3 install mrcnn --user</code> </pre> <br><p> 该软件包当然带有所有<a href="https://github.com/matterport/Mask_RCNN/blob/master/requirements.txt">依赖项</a> 。 </p><br><h2 id="etap-1-sozdanie-prosteyshey-programmy-raspoznavatelya"> 阶段1.创建一个简单的识别器。 </h2><br><p> 我们将进行必要的进口 </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.config <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> mrcnn.model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MaskRCNN</code> </pre> <br><p> 神经网络需要使用覆盖字段创建配置 </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MaskRCNNConfig</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(mrcnn.config.Config)</span></span></span><span class="hljs-class">:</span></span> NAME = <span class="hljs-string"><span class="hljs-string">"coco_pretrained_model_config"</span></span> GPU_COUNT = <span class="hljs-number"><span class="hljs-number">1</span></span> IMAGES_PER_GPU = <span class="hljs-number"><span class="hljs-number">1</span></span> DETECTION_MIN_CONFIDENCE = <span class="hljs-number"><span class="hljs-number">0.8</span></span> <span class="hljs-comment"><span class="hljs-comment">#     NUM_CLASSES = 81</span></span></code> </pre> <br><p> 用比例尺指示文件的位置。 在此示例中，它将位于此文件的文件夹中。 如果不是，则将下载。 </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mrcnn.utils DATASET_FILE = <span class="hljs-string"><span class="hljs-string">"mask_rcnn_coco.h5"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(DATASET_FILE): mrcnn.utils.download_trained_weights(DATASET_FILE)</code> </pre> <br><p> 让我们使用上面的设置创建模型 </p><br><pre> <code class="python hljs">model = MaskRCNN(mode=<span class="hljs-string"><span class="hljs-string">"inference"</span></span>, model_dir=<span class="hljs-string"><span class="hljs-string">"logs"</span></span>, config=MaskRCNNConfig()) model.load_weights(DATASET_FILE, by_name=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><p> 也许我们将开始处理当前目录中<code>images</code>目录中的所有图像。 </p><br><pre> <code class="python hljs">IMAGE_DIR = os.path.join(os.getcwd(), <span class="hljs-string"><span class="hljs-string">"images"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> filename <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> os.listdir(IMAGE_DIR): image = cv2.imread(os.path.join(IMAGE_DIR, filename)) rgb_image = image[:, :, ::<span class="hljs-number"><span class="hljs-number">-1</span></span>] detections = model.detect([rgb_image], verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><p> 我们在检测中会看到什么？ </p><br><pre> <code class="python hljs"> print(detections)</code> </pre> <br><p> 例如，类似的内容： </p><br><pre> <code class="plaintext hljs">{'rois': array([[ 303, 649, 542, 1176],[ 405, 2, 701, 319]]), 'class_ids': array([3, 3]), 'scores': array([0.99896, 0.99770015], dtype=float32), 'masks': array()}</code> </pre> <br><p> 在这种情况下，找到了2个对象。 <br>  <code>rois</code>左下角和右上角的坐标数组 <br>  <code>class_ids</code>是找到的对象的数字标识符，而我们需要知道1是一个人，3是一辆汽车，8是卡车。 <br>  <code>scores</code> -只要模型对解决方案有信心，就可以通过配置中的<code>DETECTION_MIN_CONFIDENCE</code>出该参数，从而消除所有不合适的选项。 <br>  <code>masks</code>对象的轮廓。 数据用于绘制对象蒙版。 因为 它们非常庞大，并且不打算供人类理解；在本文中，我不会引用它们。 </p><br><p> 好的，我们可以在这里停下来，但是我们想看看指导使用神经网络的图像，通常选择精美的物体发出？ </p><br><p> 调用函数<code>mrcnn.visualize.display_instances</code>会更简单，但是我们不会这样做，我们将编写自己的函数。 </p><br><p> 该函数将拍摄图像，并从第一步开始从字典中获取主要参数。 </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">visualize_detections</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image, masks, boxes, class_ids, scores)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np bgr_image = image[:, :, ::<span class="hljs-number"><span class="hljs-number">-1</span></span>] CLASS_NAMES = [<span class="hljs-string"><span class="hljs-string">'BG'</span></span>,<span class="hljs-string"><span class="hljs-string">"person"</span></span>, <span class="hljs-string"><span class="hljs-string">"bicycle"</span></span>, <span class="hljs-string"><span class="hljs-string">"car"</span></span>, <span class="hljs-string"><span class="hljs-string">"motorcycle"</span></span>, <span class="hljs-string"><span class="hljs-string">"bus"</span></span>, <span class="hljs-string"><span class="hljs-string">"truck"</span></span>] COLORS = mrcnn.visualize.random_colors(len(CLASS_NAMES)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(boxes.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]): y1, x1, y2, x2 = boxes[i] classID = class_ids[i] label = CLASS_NAMES[classID] font = cv2.FONT_HERSHEY_DUPLEX color = [int(c) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> c <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> np.array(COLORS[classID]) * <span class="hljs-number"><span class="hljs-number">255</span></span>] text = <span class="hljs-string"><span class="hljs-string">"{}: {:.3f}"</span></span>.format(label, scores[i]) size = <span class="hljs-number"><span class="hljs-number">0.8</span></span> width = <span class="hljs-number"><span class="hljs-number">2</span></span> cv2.rectangle(bgr_image, (x1, y1), (x2, y2), color, width) cv2.putText(bgr_image, text, (x1, y1<span class="hljs-number"><span class="hljs-number">-20</span></span>), font, size, color, width)</code> </pre><br><p><img src="https://lh3.googleusercontent.com/dnSAiGZW32zMK92_T8yyk2nXCFCKECQ_eSdNiVv5Bzpz9TOsBZT6_jyAY-LfUT4c0jCzfdgFOCpy6_0HzT54CAPo3vvkZ6VgR1U5cdmSTb0zLLpAxJjX-_pTNUnpIExXsao_u29b"></p><br><div class="spoiler">  <b class="spoiler_title">源图像</b> <div class="spoiler_text"><p><img src="https://sun9-10.userapi.com/c854324/v854324789/e2f73/nJHcTGLnWI4.jpg"></p></div></div><br><p> 尽管此神经网络的主要优点之一是解决了实例分割的问题-获取对象的轮廓，但我们尚未使用它，我们将对其进行分析。 </p><br><p> 要实现蒙版，在为找到的每个对象绘制矩形之前，添加几行。 </p><br><pre> <code class="python hljs">mask = masks[:, :, i] <span class="hljs-comment"><span class="hljs-comment">#   image = mrcnn.visualize.apply_mask(image, mask, color, alpha=0.6) #  </span></span></code> </pre> <br><p> 结果： <br><img src="https://lh6.googleusercontent.com/2ZHVaccuXIFgG1Z5qnHROW6cKyxjEe1RLo0SwRAaOxxyQI7Q_Ymbs7ZuZ6bOs56v7oMaCInsarFjOPZRDWL5hNdKpVhlVtHINo9u3gae4utQB-FARZPFxEV5UmkYY8LVJdTjZ0PK"></p><br><div class="spoiler">  <b class="spoiler_title">白色口罩版</b> <div class="spoiler_text"><p><img src="https://lh5.googleusercontent.com/JUUlUQfOCc9jeeuzMDiSc2Hd06P2aMVli2UPSRkUoxlNVwdlwEfi-BHmuyzOsx-nlvm19lPmYlyxFGYV9xGzpppXRORmDBLtLYH6UcYRh1zO47ROLb04HgUggDoz14Zk2AWZ3ta3"></p></div></div><br><h2 id="etap-ii-pervye-uspehi-raspoznavanie-nomerov-mashin"> 第二阶段。 最初的成功。 识别汽车数量。 </h2><br><p> 为了识别，我们需要在附近有一个清晰的车架，因此决定只从检查站拍摄车架，然后将它们与相似度进行比较（下一章将对此进行详细介绍）。 但是，这种方法会带来太多的不准确性，因为 机器在视觉上可能非常相似，而我的算法仍无法避免这种情况。 </p><br><p> 决定使用来自乌克兰制造商<a href="https://github.com/ria-com/nomeroff-net">nomeroff-net</a>的现成库（非广告）。 因为 几乎所有的代码都可以在该模型的示例中找到，然后我将不给出完整的描述。 </p><br><p> 我只能说此功能可以从原始图像开始，也可以将识别出的机器切出框架并传递给该功能。 </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.image <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> mpimg <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os sys.path.append(cfg.NOMEROFF_NET_DIR) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> NomeroffNet <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> filters, RectDetector, TextDetector, OptionsDetector, Detector, textPostprocessing nnet = Detector(cfg.MASK_RCNN_DIR, cfg.MASK_RCNN_LOG_DIR) nnet.loadModel(<span class="hljs-string"><span class="hljs-string">"latest"</span></span>) rectDetector = RectDetector() optionsDetector = OptionsDetector() optionsDetector.load(<span class="hljs-string"><span class="hljs-string">"latest"</span></span>) textDetector = TextDetector.get_static_module(<span class="hljs-string"><span class="hljs-string">"ru"</span></span>)() textDetector.load(<span class="hljs-string"><span class="hljs-string">"latest"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">detectCarNumber</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(imgPath: str)</span></span></span><span class="hljs-function"> -&gt; str:</span></span> img = mpimg.imread(imgPath) NP = nnet.detect([img]) cvImgMasks = filters.cv_img_mask(NP) arrPoints = rectDetector.detect(cvImgMasks) zones = rectDetector.get_cv_zonesBGR(img, arrPoints) regionIds, stateIds, _c = optionsDetector.predict(zones) regionNames = optionsDetector.getRegionLabels(regionIds) <span class="hljs-comment"><span class="hljs-comment"># find text with postprocessing by standart textArr = textDetector.predict(zones) textArr = textPostprocessing(textArr, regionNames) return textArr</span></span></code> </pre> <br><p> 输出的textArr将表示一个字符串数组，其中包含在框架中找到的机器数，例如： <br>  <code>["293163"]</code>或<code>[""]</code> ， <code>[]</code> -如果找不到匹配的数字。 </p><br><h2 id="etap-iii-opoznaem-obekty-na-shozhest"> 第三阶段。 通过相似性识别对象。 </h2><br><p> 现在，我们需要了解如何修复一次对象，以了解下一帧中的对象。 在此阶段，我们将假设我们只有一个摄像头，并且仅区分其中的不同帧。 </p><br><p> 为此，您需要找出我们如何比较两个对象。 </p><br><p> 为此，我将提出一个<a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">筛选</a>算法。 我们保留它不是OpenCV主体部分的保留，因此我们需要另外交付contrib模块。 不幸的是，该算法已申请专利，并且在商业程序中的使用受到限制。 但是我们专注于研究活动，对吗？ </p><br><pre> <code class="plaintext hljs">pip3 install opencv-contrib-python --user</code> </pre> <br><p>  ~~重载运算符== ~~我们编写了一个函数，该函数以矩阵形式获取2个比较对象。 例如，我们在调用函数<code>cv2.open(path)</code>后得到它们 </p><br><p> 我们将编写算法的实现。 </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">compareImages</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(img1, img2)</span></span></span><span class="hljs-function"> -&gt; bool:</span></span> sift = cv2.xfeatures2d.SIFT_create()</code> </pre> <br><p> 使用SIFT查找关键点和描述符。 也许我不会为这些功能提供帮助，因为您总是可以在交互式外壳程序中将其作为<code>help(somefunc)</code>来调用 </p><br><pre> <code class="python hljs"> kp1, des1 = sift.detectAndCompute(img1, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) kp2, des2 = sift.detectAndCompute(img2, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>)</code> </pre> <br><p> 设置我们的算法。 </p><br><pre> <code class="python hljs"> FLANN_INDEX_KDTREE = <span class="hljs-number"><span class="hljs-number">0</span></span> indexParams = dict(algorithm=FLANN_INDEX_KDTREE, trees=<span class="hljs-number"><span class="hljs-number">5</span></span>) searchParams = dict(checks=<span class="hljs-number"><span class="hljs-number">50</span></span>) flann = cv2.FlannBasedMatcher(indexParams, searchParams)</code> </pre> <br><p> 现在运行它。 </p><br><pre> <code class="python hljs"> matches = flann.knnMatch(des1, des2, k=<span class="hljs-number"><span class="hljs-number">2</span></span>)</code> </pre> <br><p> 计算图像之间的相似度。 </p><br><pre> <code class="python hljs"> matchesCount = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> m, n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> matches: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> m.distance &lt; cfg.cencitivity*n.distance: matchesCount += <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> matchesCount &gt; cfg.MIN_MATCH_COUNT</code> </pre> <br><p> 现在，尝试使用它 <br> 为此，在检测到对象后，我们需要将其从原始图像中剪切下来 </p><br><p> 我写不出比保存它慢的内存更好的东西，然后从那里读取。 </p><br><pre> <code class="python hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">extractObjects</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(objects, binaryImage, outputImageDirectory, filename=None)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> item <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> objects: y1, x1, y2, x2 = item.coordinates <span class="hljs-comment"><span class="hljs-comment">#       cropped = binaryImage[y1:y2, x1:x2] beforePoint, afterPoint = filename.split(".") outputDirPath = os.path.join(os.path.split(outputImageDirectory)[0], "objectsOn" + beforePoint) if not os.path.exists(outputDirPath): os.mkdir(outputDirPath) coordinates = str(item).replace(" ", ",") pathToObjectImage = "{}{}.jpg".format(item.type, coordinates) cv2.imwrite(os.path.join(outputDirPath, str(pathToObjectImage)), cropped)</span></span></code> </pre> <br><p> 现在我们在<code>&lt;outputImageDirectory&gt;/objectsOn&lt;imageFilename&gt;</code>拥有对象 </p><br><p> 现在，如果我们至少有2个这样的目录，则可以比较其中的对象。 运行之前编写的函数 </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> compareImages(previousObjects, currentObjects): print(“  !”)</code> </pre> <br><p> 或者，我们可以执行其他操作，例如使用相同的标识符标记这些对象。 </p><br><p> 当然，像所有神经网络一样，这一网络有时会给出错误的结果。 </p><br><p> 通常，我们已经完成了开始时设置的3个任务，因此我们将四舍五入。 我怀疑本文是否引起了至少编写了一个解决图像识别/图像分割问题程序的人的注意，但是我希望我能帮助至少一个新手开发人员。 </p><br><p> 该项目的完整源代码可以在<a href="https://github.com/Sapfir0/premier-eye">这里</a>找到。 </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN483018/">https://habr.com/ru/post/zh-CN483018/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN483004/index.html">迪斯科极乐世界中的库列肖夫效应：上下文如何创造意义</a></li>
<li><a href="../zh-CN483008/index.html">另一个未来-人类分裂</a></li>
<li><a href="../zh-CN483012/index.html">古迹：Roland MT-32，DOS游戏的另一种声音</a></li>
<li><a href="../zh-CN483014/index.html">使用PgQ的PostgreSQL消息队列</a></li>
<li><a href="../zh-CN483016/index.html">空间微处理器的简要历史，第二部分</a></li>
<li><a href="../zh-CN483024/index.html">“公司如何处理您的隐私？”，Arthur Khachuyan（Tazeros Global）</a></li>
<li><a href="../zh-CN483026/index.html">Java / Spring：如何使用Speedment完全生成CRUD REST API</a></li>
<li><a href="../zh-CN483030/index.html">让你哭泣的API</a></li>
<li><a href="../zh-CN483032/index.html">从独联体到捷克共和国，自己的经验（第2部分）</a></li>
<li><a href="../zh-CN483036/index.html">n-皇后完成问题-线性解算法</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöá ü§∂üèº üë©‚Äç‚úàÔ∏è Ist es m√∂glich, Ethik in den Algorithmus von Robomobilen einzuf√ºhren? üåπ ‚úàÔ∏è üé∫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="F√ºr den Mord an einem Robomobil werden das Programm (und die Programmierer) beurteilt 
 Jahr 2034. Ein betrunkener Mann wandert nachts auf dem B√ºrgers...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ist es m√∂glich, Ethik in den Algorithmus von Robomobilen einzuf√ºhren?</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/395143/"><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">F√ºr den Mord an einem Robomobil werden das Programm (und die Programmierer) beurteilt</font></font></h4> <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/6cf/75d/315/6cf75d31565a3a88313197090c5b3e4f.jpg" alt="Bild" align="left"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jahr 2034. Ein betrunkener Mann wandert nachts auf dem B√ºrgersteig, stolpert und f√§llt direkt vor das Robomobil, das ihn trifft und sofort t√∂tet. Wenn sich eine Person hinter dem Steuer eines Autos befindet, wird der Tod als Unfall erkannt, da der Fehler beim Fu√üg√§nger liegt und kein einziger Fahrer ihm ausweichen kann. Die Standards f√ºr den "Durchschnittsfahrer" (der Begriff " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vern√ºnftige Person</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> " ist </font><font style="vertical-align: inherit;">in der ausl√§ndischen Gesetzgebung enthalten </font><font style="vertical-align: inherit;">) verschwanden jedoch in den 2020er Jahren, als die Verbreitung von Robomobilen die Zahl der Unf√§lle um 90% verringerte. Jetzt m√ºssen wir √ºber den "durchschnittlichen Roboter" sprechen.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Familie des Opfers verklagt den Hersteller von Roboterfahrzeugen und erkl√§rt, dass das Auto, obwohl es keine Zeit zum Bremsen hatte, einen Fu√üg√§nger umrunden, einen Doppelk√∂rper √ºberqueren und mit einem entgegenkommenden Roboter kollidieren k√∂nnte. Die Rekonstruktion des Vorfalls anhand von Roboter-Fahrzeugsensoren best√§tigt dies. Der Anwalt des Kl√§gers, der einen f√ºhrenden Auto-Software-Entwickler verh√∂rt, fragt: "Warum hat sich das Auto nicht abgewandt?"</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Heute fragt das Gericht die Fahrer nicht, warum sie etwas getan haben oder nicht. Das Problem ist umstritten, da sich die Person irrt - der Fahrer kann in Panik geraten, nicht daran denken, auf Instinkte reagieren. Aber wenn der Roboter das Auto f√§hrt, lautet die Frage: "Warum?" durchaus akzeptabel. Die ethischen Standards von Menschen, die in Gesetzen nicht sehr gut formuliert sind, machen viele verschiedene Annahmen, zu denen Ingenieure einfach nicht gelangt sind. Das wichtigste von ihnen - eine Person kann verstehen, wann Sie vom Buchstaben des Gesetzes abweichen m√ºssen, um seinen Geist zu bewahren. Jetzt m√ºssen Ingenieure Maschinen und anderen Robotern beibringen, wie sie kluge Entscheidungen treffen k√∂nnen.</font></font><br>
 <a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Computerisierung des Steuerungsprozesses begann in den 1970er Jahren, als </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Antiblockiersysteme</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> auftauchten </font><font style="vertical-align: inherit;">. Jetzt gibt es jedes Jahr Entwicklungen wie automatische Lenkung, automatische Beschleunigung und Notbremsung. Das Testen von vollautomatischen Maschinen, wenn auch unter Beteiligung eines menschlichen Fahrers, ist an einigen Orten in Gro√übritannien, Holland, Deutschland und Japan bereits zul√§ssig. In den Vereinigten Staaten ist es </font><font style="vertical-align: inherit;">in vier Bundesstaaten und im District of Columbia </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gesetzlich zul√§ssig</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , und im √úbrigen ist es zumindest nicht verboten. Google, Nissan und Ford behaupten, dass Robomobile in 5-10 Jahren erscheinen werden.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Automatische Fahrzeuge erfassen Umgebungsinformationen von Sensoren - Videokameras, Ultraschall-Entfernungsmesser, Radarger√§te, Lidars. In Kalifornien m√ºssen Robomobile dem Verkehrsministerium 30 Sekunden vor einer Kollision, die sich bereits ausreichend angesammelt hat, alle Sensordaten zur Verf√ºgung stellen - einschlie√ülich der </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">von der Google-Maschine verursachten Kollision</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Ingenieure haben die M√∂glichkeit, Ereignisse im Kollisionsbereich ziemlich genau wiederherzustellen, indem sie Aufzeichnungen dar√ºber verwenden, was die Maschine erfassen k√∂nnte, welche Alternativen sie in Betracht zieht und welche Verhaltenslogik sie verwendet. Der Computer kann dazu gebracht werden, seine √úberlegungen zu wiederholen - so wie er aufgefordert werden kann, die Person zu bestimmen, die das Spiel oder den Fahrsimulator gespielt hat.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aufsichtsbeh√∂rden und Prozessparteien werden in der Lage sein, √ºbermenschliche Sicherheitsstandards f√ºr Roboterfahrzeuge einzuhalten und Kollisionen, die ohnehin auftreten werden, gr√ºndlich zu untersuchen - wenn auch selten. Hersteller und Programmierer werden die Aktionen ihrer Produkte auf eine Weise sch√ºtzen, von der die heutigen Fahrer nie getr√§umt haben. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Autofahren ist immer ein Risiko, und Entscheidungen √ºber die Verteilung zwischen Fahrern, Fu√üg√§ngern, Radfahrern und Eigentum enthalten eine ethische Komponente. Sowohl f√ºr Ingenieure als auch f√ºr alle Menschen ist es wichtig, dass das Entscheidungsfindungssystem der Maschine die ethischen Konsequenzen ihres Handelns abw√§gt. </font></font><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/044/821/2c5/0448212c5220abb6d9a7ea75f1ea180e.jpg" alt="Bild"><br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/c91/7bc/856/c917bc856aeb4a4a9db81c2671b21106.jpg" alt="Bild"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kollision Google Car mit einem Bus</font></font></i><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die √ºbliche Reaktion auf moralisch mehrdeutige Situationen besteht darin, das Gesetz zu befolgen und gleichzeitig den Schaden zu minimieren. Die Strategie ist attraktiv - sie erm√∂glicht es dem Entwickler nicht nur, die Handlungen des Autos leicht zu verteidigen (‚ÄûWir haben das Gesetz vollst√§ndig befolgt‚Äú), sondern √ºbertr√§gt auch die Verantwortung bei der Festlegung der Ethik auf den Gesetzgeber. Leider belastet es auch das Gesetz zu sehr.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In den meisten Staaten beispielsweise st√ºtzt sich das Gesetz auf den gesunden Menschenverstand der Fahrer und sagt wenig √ºber das Verhalten vor einer Kollision aus. In dem beschriebenen Beispiel √ºberquert das Auto unter strikter Einhaltung des Gesetzes nicht den doppelten Festk√∂rper und riskiert eine Kollision mit einem Betrunkenen - obwohl sich auf der anderen Stra√üenseite nur ein leeres Robomobil befindet. Das Gesetz macht in bestimmten Notsituationen selten Ausnahmen, beispielsweise wenn eine Person auf die Stra√üe f√§llt - und wenn dies der Fall ist, wie dies beispielsweise in Virginia der Fall ist, impliziert der Gesetzestext, dass das √úberqueren eines doppelten Festk√∂rpers legal ist, bis das Auto abst√ºrzt ("Wenn eine solche Bewegung sicher gemacht werden kann"). In diesem Fall m√ºssen sich die Entwickler entscheiden - in welchen F√§llen ist es sicher, den doppelten K√∂rper zu √ºberqueren.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein Robomobil ist sich selten zu 100% sicher, dass die Stra√üe leer ist und Sie ohne Angst einen Doppelk√∂rper √ºberqueren k√∂nnen. Er wird das Konfidenzniveau mit 98% oder 99,99% bewerten. Die Ingenieure m√ºssen im Voraus entscheiden, welches Ma√ü an Vertrauen ausreicht, um einen Doppelk√∂rper zu √ºberqueren, und wie der akzeptable Wert variieren kann, je nachdem, was das Robomobil auf der Stra√üe zu vermeiden versucht - ist es eine Plastikt√ºte oder ein gefallener Fu√üg√§nger. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Robomobile treffen bereits Entscheidungen √ºber die M√∂glichkeit eines Gesetzesversto√ües. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google gab zu</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dass seine Autos die Geschwindigkeit √ºberschreiten d√ºrfen, um im Strom zu bleiben - wo Verlangsamung gef√§hrlich ist. Die meisten Menschen w√ºrden es vorziehen, die Geschwindigkeit in verschiedenen Situationen zu √ºberschreiten, beispielsweise wenn sie versuchen, ins Krankenhaus zu eilen. Chris Gerdes [Chris Gerdes] und Sarah Thornton von der Stanford University </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gegen die</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> strikte Einbeziehung von Gesetzen in Entscheidungsalgorithmen, da die Fahrer die Gesetze als flexibel genug betrachten, um die Kosten f√ºr deren Aufhebung im Vergleich zum potenziellen Gewinn zu bewerten Geschwindigkeit. Niemand m√∂chte mehrere Kilometer hinter einem Radfahrer herkriechen, weil Ihr Auto sich weigert, zumindest ein wenig nach einem doppelten Feststoff zu rufen.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und selbst wenn das Robomobil im Rahmen des Gesetzes bleibt, kann es viele kleine Entscheidungen treffen, die aus Sicherheitsgr√ºnden sensibel sind. In der Regel sind die Fahrspuren auf der Autobahn fast doppelt so breit wie bei einem typischen Auto. Mit dieser Breite k√∂nnen Fahrer M√ºll vermeiden oder sich von ungleichm√§√üig fahrenden Autos entfernen. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Patent von 2014 </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entwickelt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Google </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">diese Idee und beschreibt,</font></a><font style="vertical-align: inherit;"> wie ein Robomobil auf einem Streifen platziert werden kann, um Risiken zu reduzieren. Das Unternehmen gibt ein Beispiel f√ºr ein Robomobil auf einer dreispurigen Stra√üe mit einem LKW rechts und einem Kleinwagen links. Um die Sicherheit zu optimieren, sollte sich das Robomobil in einer kleinen Maschine etwas nach links und n√§her bewegt haben.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es sieht gesund aus und normalerweise tut es jeder - bewusst oder unbewusst. Es stellen sich jedoch ethische Fragen. Das Robomobil bewegte sich auf die kleine Maschine zu, reduzierte das Risiko, verteilte es jedoch ungleichm√§√üig. Sollte eine kleine Maschine ein gr√∂√üeres Risiko eingehen, nur weil sie klein ist? Wenn es um Pr√§ferenzen f√ºr einen bestimmten Fahrer ginge, w√ºrde er nichts bedeuten. Wenn eine solche Umverteilung jedoch formalisiert und auf alle Robomobile ausgedehnt wird, sind die Folgen schwerwiegender.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In jedem Beispiel ber√ºcksichtigt das Robomobil mehrere Werte - den Wert des Objekts, das es treffen kann, und den Wert seines Passagiers. Menschen treffen Entscheidungen instinktiv, und der Roboter wird dies auf der Grundlage einer sorgf√§ltig durchdachten Risikomanagementstrategie tun, die das Risiko als die H√∂he des Schadens durch ein unerw√ºnschtes Ereignis definiert, multipliziert mit seiner Wahrscheinlichkeit.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Jahr 2014 patentierte Google auch eine Risikomanagement-Anwendung. Das Patent beschreibt eine Maschine, die sich m√∂glicherweise f√ºr einen Umbau entscheidet, um die Ampel besser sehen zu k√∂nnen. Oder das Auto kann sich daf√ºr entscheiden, auf der Fahrspur zu bleiben, um das Risiko einer Kollision zu vermeiden - beispielsweise aufgrund von Anzeigen eines fehlerhaften Sensors -, aber auf Kosten dieser wird die Sicht auf die Ampel schlecht. Dem Ergebnis einer der Entscheidungen wird die Wahrscheinlichkeit sowie der positive oder negative Wert (Vorteil oder Verlust) zugewiesen. Jeder Wert wird mit der Wahrscheinlichkeit multipliziert und die erhaltenen Werte k√∂nnen summiert werden. Wenn die Vorteile die Verluste weit genug √ºberwiegen, wird die Maschine man√∂vrieren. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Problem ist, dass das Kollisionsrisiko sehr gering ist - der durchschnittliche Fahrer in den USA ger√§t alle 257.000 Kilometer oder alle 12 Jahre ( </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">in Russland - alle 1,6 Jahre)</font></a><font style="vertical-align: inherit;"> in einen Unfall</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Vielleicht liegt dieser Unterschied daran, dass in den USA die Menschen viel h√§ufiger auf der Autobahn unterwegs sind - ca. Selbst wenn wir auf der Stra√üe einen riesigen Datenstrom von Robomobilen erhalten, k√∂nnen wir daher sehr bald Sch√§tzungen der Wahrscheinlichkeiten verschiedener Ereignisse erhalten.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Noch schwieriger ist es, die Schadenskosten abzusch√§tzen. Sachsch√§den sind leicht einzusch√§tzen - Versicherer verf√ºgen √ºber umfangreiche Erfahrung in dieser Angelegenheit -, aber Verletzungen und Todesf√§lle sind eine andere Angelegenheit. Die Geschichte der Aneignung des Lebens einer Person von irgendeinem Wert hat viele Jahre und wird normalerweise in der Menge an Geld ausgedr√ºckt, die ausgegeben werden k√∂nnte, um das durchschnittliche Opfer zu verhindern. Eine Sicherheitsverbesserung mit einer Chance von 1%, das Leben von 100 Menschen zu retten, ist ein durchschnittliches Opfer. Das Verkehrsministerium empfiehlt, 9,1 Millionen US-Dollar auszugeben, um Verluste zu vermeiden. Die Zahl wird aus Marketingdaten abgeleitet, einschlie√ülich der Zulagen, die Personen f√ºr gef√§hrliche Arbeiten ben√∂tigen, und der Betr√§ge, die Personen bereit sind, f√ºr Sicherheitsausr√ºstung auszugeben - beispielsweise Rauchmelder. Sie m√ºssen nicht nur die Sicherheit abw√§gen, sondern auch den Verlust an Mobilit√§t oder Zeit.auf der Stra√üe verbracht, die die Abteilung auf 26,44 $ pro Stunde sch√§tzt.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Worten sieht alles sch√∂n aus. Die Risikobewertung in Bezug auf verlorene Leben und Zeit auf der Stra√üe beinhaltet jedoch keine unterschiedlichen moralischen Einsch√§tzungen dar√ºber, wie wir Menschen gef√§hrden. Zum Beispiel m√ºsste ein Robomobil, das das Leben aller Menschen gleicherma√üen bewertet, einem Motorradfahrer ohne Helm mehr Platz geben als einem Motorradfahrer in voller Ausr√ºstung, da erstere weniger wahrscheinlich √ºberleben werden. Aber das ist unfair - kann man daf√ºr bestrafen, dass man sich um seine Sicherheit k√ºmmert?</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein weiterer Unterschied zwischen der Ethik von Robotern und Menschen besteht darin, dass die Ethik der ersteren von Programmierern auch aus gutem Grund verzerrt werden kann. Stellen Sie sich vor, der Algorithmus hat die Gr√∂√üe der Pufferzone f√ºr Fu√üg√§nger in verschiedenen Bereichen auf der Grundlage der Analyse der H√∂he der Entsch√§digung f√ºr Anspr√ºche von Fu√üg√§ngern bei einem Unfall angepasst. Einerseits ist es vern√ºnftig, effizient und gut gemeint. Andererseits k√∂nnen kleinere Strafen vom Durchschnittseinkommen der Menschen in einem bestimmten Gebiet abh√§ngen. Dann wird der Algorithmus die Armen bestrafen, indem er ihnen eine kleinere Pufferzone gibt, wodurch ihr Risiko, abgeschossen zu werden, leicht erh√∂ht wird.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es besteht die Versuchung, Fragen wie rein akademische beiseite zu schieben, aber Sie k√∂nnen sie nicht umgehen, da Programme alles w√∂rtlich nehmen. Sie m√ºssen die Konsequenzen von Aktionen bewerten, bevor sie ausgef√ºhrt werden m√ºssen - in der Entwicklungsphase und nicht in der Phase der Erstellung von Patches f√ºr Software. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Teilweise aus diesem Grund verwenden Forscher hypothetische Situationen, in denen eine Maschine zwischen zwei √úbeln w√§hlen muss. Eine der bekanntesten Aufgaben dieser Art ist das Problem eines Wagens. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein schwerer unkontrollierter Wagen wird auf Schienen getragen. Unterwegs sind f√ºnf Leute von einem verr√ºckten Philosophen an die Schienen gebunden. Gl√ºcklicherweise k√∂nnen Sie den Pfeil wechseln - und dann f√§hrt der Wagen auf einer anderen, alternativen Route. Leider befindet sich eine Person auf dem Abstellgleis, die ebenfalls an Schienen gebunden ist. Was sind deine Handlungen?</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wirst du ein Leben f√ºr mehrere opfern? </font><font style="vertical-align: inherit;">Wenn nicht, werden aufgrund Ihrer Unt√§tigkeit immer noch Menschen sterben. Wie k√∂nnen Sie mit diesem Widerspruch umgehen?</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zu den Themen solcher Experimente wurden B√ºcher geschrieben, mit denen Sie einfache und direkte Systeme testen k√∂nnen, die sich mit ethischen Fragen befassen, und Bereiche finden, in denen es sch√∂n w√§re, sich mit einigen Nuancen zu befassen. </font><font style="vertical-align: inherit;">Angenommen, wir haben ein Robomobil programmiert, um Fu√üg√§nger um jeden Preis zu vermeiden. </font><font style="vertical-align: inherit;">Wenn eine Fu√üg√§ngerin pl√∂tzlich in einem zweispurigen Tunnel auftaucht und das Auto nicht rechtzeitig bremsen kann, muss sie die Spur verlassen, auch wenn sie einem Bus mit Passagieren im Weg steht. </font><font style="vertical-align: inherit;">Die Wahrscheinlichkeit eines solchen Ereignisses ist nicht so wichtig wie das Problem, das es in der Logik des Roboterautos aufwirft - dass die absolute √úberlegenheit des Wertes eines Fu√üg√§ngers gegen√ºber allen anderen Personen, die die Fahrbahn benutzen, sehr gef√§hrlich sein kann.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ethik in der Robotik ist eine l√∂sbare Aufgabe. </font><font style="vertical-align: inherit;">Wir wissen das, weil wir in anderen Bereichen bereits die M√∂glichkeit gefunden haben, ungef√§hr dieselben Risiken und Vorteile sicher und vern√ºnftig zu handhaben. </font><font style="vertical-align: inherit;">Spenderorgane werden an Patienten verteilt, basierend auf einer Metrik, die aus den potenziellen Lebensjahren und der Lebensqualit√§t berechnet wird. </font><font style="vertical-align: inherit;">Menschen aus solchen notwendigen Berufen wie Landwirt und Lehrer sind vom milit√§rischen Entwurf befreit.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Aufgaben von Robomobilen sind komplizierter. </font><font style="vertical-align: inherit;">Sie m√ºssen auf der Grundlage unvollst√§ndiger Informationen schnell entscheiden, in Situationen, in denen Programmierer m√∂glicherweise keine Ethik vorausgesehen haben, die zu w√∂rtlich in den Algorithmus integriert werden muss. </font><font style="vertical-align: inherit;">Gl√ºcklicherweise erwarten die Menschen keine √ºbermenschliche Weisheit von ihnen - nur eine rationale Rechtfertigung f√ºr das Handeln einer Maschine, die ethische Fragen bewertet. </font><font style="vertical-align: inherit;">Die L√∂sung sollte nicht perfekt sein - aber nachdenklich und eine, die gesch√ºtzt werden k√∂nnte.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de395143/">https://habr.com/ru/post/de395143/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de395129/index.html">√úbersicht √ºber den Router der Draytek 2912-Serie. Teil Zwei</a></li>
<li><a href="../de395131/index.html">Mit Firefox k√∂nnen Sie auf Websites unter mehreren Konten gleichzeitig zugreifen</a></li>
<li><a href="../de395137/index.html">Remote-Er√∂ffnung eines Brokerage-Kontos √ºber das Gosuslug-Portal: Warum und wie?</a></li>
<li><a href="../de395139/index.html">Werden wir Milit√§rrobotern eine Lizenz zum T√∂ten geben?</a></li>
<li><a href="../de395141/index.html">Von Browser-Lesezeichen zu einer neuen √Ñra: Ein wenig √ºber die Geschichte der Entwicklung von Social-Button-Diensten</a></li>
<li><a href="../de395145/index.html">–°–ø—Ä–æ—Å–∏—Ç–µ –ò—Ç–∞–Ω–∞ ‚Ññ59: —á—Ç–æ —Ç–∞–∫–æ–µ —Ç—ë–º–Ω–∞—è —ç–Ω–µ—Ä–≥–∏—è?</a></li>
<li><a href="../de395147/index.html">Mitsubishi Outlander SUV bricht problemlos √ºber WLAN ein</a></li>
<li><a href="../de395149/index.html">Eine neue Erkl√§rung des Prinzips der "unm√∂glichen" Engine EmDrive: Das sind alles Photonen</a></li>
<li><a href="../de395151/index.html">Klima in Ihrem Zuhause. TION MagicAir Ank√ºndigung</a></li>
<li><a href="../de395153/index.html">F√ºgen Sie Furigan zum Kanji Python Macro f√ºr LibreOffice hinzu</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
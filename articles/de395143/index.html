<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚇 🤶🏼 👩‍✈️ Ist es möglich, Ethik in den Algorithmus von Robomobilen einzuführen? 🌹 ✈️ 🎺</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Für den Mord an einem Robomobil werden das Programm (und die Programmierer) beurteilt 
 Jahr 2034. Ein betrunkener Mann wandert nachts auf dem Bürgers...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ist es möglich, Ethik in den Algorithmus von Robomobilen einzuführen?</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/395143/"><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Für den Mord an einem Robomobil werden das Programm (und die Programmierer) beurteilt</font></font></h4> <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/6cf/75d/315/6cf75d31565a3a88313197090c5b3e4f.jpg" alt="Bild" align="left"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jahr 2034. Ein betrunkener Mann wandert nachts auf dem Bürgersteig, stolpert und fällt direkt vor das Robomobil, das ihn trifft und sofort tötet. Wenn sich eine Person hinter dem Steuer eines Autos befindet, wird der Tod als Unfall erkannt, da der Fehler beim Fußgänger liegt und kein einziger Fahrer ihm ausweichen kann. Die Standards für den "Durchschnittsfahrer" (der Begriff " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vernünftige Person</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> " ist </font><font style="vertical-align: inherit;">in der ausländischen Gesetzgebung enthalten </font><font style="vertical-align: inherit;">) verschwanden jedoch in den 2020er Jahren, als die Verbreitung von Robomobilen die Zahl der Unfälle um 90% verringerte. Jetzt müssen wir über den "durchschnittlichen Roboter" sprechen.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Familie des Opfers verklagt den Hersteller von Roboterfahrzeugen und erklärt, dass das Auto, obwohl es keine Zeit zum Bremsen hatte, einen Fußgänger umrunden, einen Doppelkörper überqueren und mit einem entgegenkommenden Roboter kollidieren könnte. Die Rekonstruktion des Vorfalls anhand von Roboter-Fahrzeugsensoren bestätigt dies. Der Anwalt des Klägers, der einen führenden Auto-Software-Entwickler verhört, fragt: "Warum hat sich das Auto nicht abgewandt?"</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Heute fragt das Gericht die Fahrer nicht, warum sie etwas getan haben oder nicht. Das Problem ist umstritten, da sich die Person irrt - der Fahrer kann in Panik geraten, nicht daran denken, auf Instinkte reagieren. Aber wenn der Roboter das Auto fährt, lautet die Frage: "Warum?" durchaus akzeptabel. Die ethischen Standards von Menschen, die in Gesetzen nicht sehr gut formuliert sind, machen viele verschiedene Annahmen, zu denen Ingenieure einfach nicht gelangt sind. Das wichtigste von ihnen - eine Person kann verstehen, wann Sie vom Buchstaben des Gesetzes abweichen müssen, um seinen Geist zu bewahren. Jetzt müssen Ingenieure Maschinen und anderen Robotern beibringen, wie sie kluge Entscheidungen treffen können.</font></font><br>
 <a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Computerisierung des Steuerungsprozesses begann in den 1970er Jahren, als </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Antiblockiersysteme</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> auftauchten </font><font style="vertical-align: inherit;">. Jetzt gibt es jedes Jahr Entwicklungen wie automatische Lenkung, automatische Beschleunigung und Notbremsung. Das Testen von vollautomatischen Maschinen, wenn auch unter Beteiligung eines menschlichen Fahrers, ist an einigen Orten in Großbritannien, Holland, Deutschland und Japan bereits zulässig. In den Vereinigten Staaten ist es </font><font style="vertical-align: inherit;">in vier Bundesstaaten und im District of Columbia </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gesetzlich zulässig</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , und im Übrigen ist es zumindest nicht verboten. Google, Nissan und Ford behaupten, dass Robomobile in 5-10 Jahren erscheinen werden.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Automatische Fahrzeuge erfassen Umgebungsinformationen von Sensoren - Videokameras, Ultraschall-Entfernungsmesser, Radargeräte, Lidars. In Kalifornien müssen Robomobile dem Verkehrsministerium 30 Sekunden vor einer Kollision, die sich bereits ausreichend angesammelt hat, alle Sensordaten zur Verfügung stellen - einschließlich der </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">von der Google-Maschine verursachten Kollision</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Ingenieure haben die Möglichkeit, Ereignisse im Kollisionsbereich ziemlich genau wiederherzustellen, indem sie Aufzeichnungen darüber verwenden, was die Maschine erfassen könnte, welche Alternativen sie in Betracht zieht und welche Verhaltenslogik sie verwendet. Der Computer kann dazu gebracht werden, seine Überlegungen zu wiederholen - so wie er aufgefordert werden kann, die Person zu bestimmen, die das Spiel oder den Fahrsimulator gespielt hat.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aufsichtsbehörden und Prozessparteien werden in der Lage sein, übermenschliche Sicherheitsstandards für Roboterfahrzeuge einzuhalten und Kollisionen, die ohnehin auftreten werden, gründlich zu untersuchen - wenn auch selten. Hersteller und Programmierer werden die Aktionen ihrer Produkte auf eine Weise schützen, von der die heutigen Fahrer nie geträumt haben. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Autofahren ist immer ein Risiko, und Entscheidungen über die Verteilung zwischen Fahrern, Fußgängern, Radfahrern und Eigentum enthalten eine ethische Komponente. Sowohl für Ingenieure als auch für alle Menschen ist es wichtig, dass das Entscheidungsfindungssystem der Maschine die ethischen Konsequenzen ihres Handelns abwägt. </font></font><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/044/821/2c5/0448212c5220abb6d9a7ea75f1ea180e.jpg" alt="Bild"><br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/c91/7bc/856/c917bc856aeb4a4a9db81c2671b21106.jpg" alt="Bild"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kollision Google Car mit einem Bus</font></font></i><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die übliche Reaktion auf moralisch mehrdeutige Situationen besteht darin, das Gesetz zu befolgen und gleichzeitig den Schaden zu minimieren. Die Strategie ist attraktiv - sie ermöglicht es dem Entwickler nicht nur, die Handlungen des Autos leicht zu verteidigen („Wir haben das Gesetz vollständig befolgt“), sondern überträgt auch die Verantwortung bei der Festlegung der Ethik auf den Gesetzgeber. Leider belastet es auch das Gesetz zu sehr.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In den meisten Staaten beispielsweise stützt sich das Gesetz auf den gesunden Menschenverstand der Fahrer und sagt wenig über das Verhalten vor einer Kollision aus. In dem beschriebenen Beispiel überquert das Auto unter strikter Einhaltung des Gesetzes nicht den doppelten Festkörper und riskiert eine Kollision mit einem Betrunkenen - obwohl sich auf der anderen Straßenseite nur ein leeres Robomobil befindet. Das Gesetz macht in bestimmten Notsituationen selten Ausnahmen, beispielsweise wenn eine Person auf die Straße fällt - und wenn dies der Fall ist, wie dies beispielsweise in Virginia der Fall ist, impliziert der Gesetzestext, dass das Überqueren eines doppelten Festkörpers legal ist, bis das Auto abstürzt ("Wenn eine solche Bewegung sicher gemacht werden kann"). In diesem Fall müssen sich die Entwickler entscheiden - in welchen Fällen ist es sicher, den doppelten Körper zu überqueren.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein Robomobil ist sich selten zu 100% sicher, dass die Straße leer ist und Sie ohne Angst einen Doppelkörper überqueren können. Er wird das Konfidenzniveau mit 98% oder 99,99% bewerten. Die Ingenieure müssen im Voraus entscheiden, welches Maß an Vertrauen ausreicht, um einen Doppelkörper zu überqueren, und wie der akzeptable Wert variieren kann, je nachdem, was das Robomobil auf der Straße zu vermeiden versucht - ist es eine Plastiktüte oder ein gefallener Fußgänger. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Robomobile treffen bereits Entscheidungen über die Möglichkeit eines Gesetzesverstoßes. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google gab zu</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dass seine Autos die Geschwindigkeit überschreiten dürfen, um im Strom zu bleiben - wo Verlangsamung gefährlich ist. Die meisten Menschen würden es vorziehen, die Geschwindigkeit in verschiedenen Situationen zu überschreiten, beispielsweise wenn sie versuchen, ins Krankenhaus zu eilen. Chris Gerdes [Chris Gerdes] und Sarah Thornton von der Stanford University </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gegen die</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> strikte Einbeziehung von Gesetzen in Entscheidungsalgorithmen, da die Fahrer die Gesetze als flexibel genug betrachten, um die Kosten für deren Aufhebung im Vergleich zum potenziellen Gewinn zu bewerten Geschwindigkeit. Niemand möchte mehrere Kilometer hinter einem Radfahrer herkriechen, weil Ihr Auto sich weigert, zumindest ein wenig nach einem doppelten Feststoff zu rufen.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Und selbst wenn das Robomobil im Rahmen des Gesetzes bleibt, kann es viele kleine Entscheidungen treffen, die aus Sicherheitsgründen sensibel sind. In der Regel sind die Fahrspuren auf der Autobahn fast doppelt so breit wie bei einem typischen Auto. Mit dieser Breite können Fahrer Müll vermeiden oder sich von ungleichmäßig fahrenden Autos entfernen. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Patent von 2014 </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">entwickelt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Google </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">diese Idee und beschreibt,</font></a><font style="vertical-align: inherit;"> wie ein Robomobil auf einem Streifen platziert werden kann, um Risiken zu reduzieren. Das Unternehmen gibt ein Beispiel für ein Robomobil auf einer dreispurigen Straße mit einem LKW rechts und einem Kleinwagen links. Um die Sicherheit zu optimieren, sollte sich das Robomobil in einer kleinen Maschine etwas nach links und näher bewegt haben.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es sieht gesund aus und normalerweise tut es jeder - bewusst oder unbewusst. Es stellen sich jedoch ethische Fragen. Das Robomobil bewegte sich auf die kleine Maschine zu, reduzierte das Risiko, verteilte es jedoch ungleichmäßig. Sollte eine kleine Maschine ein größeres Risiko eingehen, nur weil sie klein ist? Wenn es um Präferenzen für einen bestimmten Fahrer ginge, würde er nichts bedeuten. Wenn eine solche Umverteilung jedoch formalisiert und auf alle Robomobile ausgedehnt wird, sind die Folgen schwerwiegender.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In jedem Beispiel berücksichtigt das Robomobil mehrere Werte - den Wert des Objekts, das es treffen kann, und den Wert seines Passagiers. Menschen treffen Entscheidungen instinktiv, und der Roboter wird dies auf der Grundlage einer sorgfältig durchdachten Risikomanagementstrategie tun, die das Risiko als die Höhe des Schadens durch ein unerwünschtes Ereignis definiert, multipliziert mit seiner Wahrscheinlichkeit.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Jahr 2014 patentierte Google auch eine Risikomanagement-Anwendung. Das Patent beschreibt eine Maschine, die sich möglicherweise für einen Umbau entscheidet, um die Ampel besser sehen zu können. Oder das Auto kann sich dafür entscheiden, auf der Fahrspur zu bleiben, um das Risiko einer Kollision zu vermeiden - beispielsweise aufgrund von Anzeigen eines fehlerhaften Sensors -, aber auf Kosten dieser wird die Sicht auf die Ampel schlecht. Dem Ergebnis einer der Entscheidungen wird die Wahrscheinlichkeit sowie der positive oder negative Wert (Vorteil oder Verlust) zugewiesen. Jeder Wert wird mit der Wahrscheinlichkeit multipliziert und die erhaltenen Werte können summiert werden. Wenn die Vorteile die Verluste weit genug überwiegen, wird die Maschine manövrieren. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Problem ist, dass das Kollisionsrisiko sehr gering ist - der durchschnittliche Fahrer in den USA gerät alle 257.000 Kilometer oder alle 12 Jahre ( </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">in Russland - alle 1,6 Jahre)</font></a><font style="vertical-align: inherit;"> in einen Unfall</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Vielleicht liegt dieser Unterschied daran, dass in den USA die Menschen viel häufiger auf der Autobahn unterwegs sind - ca. Selbst wenn wir auf der Straße einen riesigen Datenstrom von Robomobilen erhalten, können wir daher sehr bald Schätzungen der Wahrscheinlichkeiten verschiedener Ereignisse erhalten.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Noch schwieriger ist es, die Schadenskosten abzuschätzen. Sachschäden sind leicht einzuschätzen - Versicherer verfügen über umfangreiche Erfahrung in dieser Angelegenheit -, aber Verletzungen und Todesfälle sind eine andere Angelegenheit. Die Geschichte der Aneignung des Lebens einer Person von irgendeinem Wert hat viele Jahre und wird normalerweise in der Menge an Geld ausgedrückt, die ausgegeben werden könnte, um das durchschnittliche Opfer zu verhindern. Eine Sicherheitsverbesserung mit einer Chance von 1%, das Leben von 100 Menschen zu retten, ist ein durchschnittliches Opfer. Das Verkehrsministerium empfiehlt, 9,1 Millionen US-Dollar auszugeben, um Verluste zu vermeiden. Die Zahl wird aus Marketingdaten abgeleitet, einschließlich der Zulagen, die Personen für gefährliche Arbeiten benötigen, und der Beträge, die Personen bereit sind, für Sicherheitsausrüstung auszugeben - beispielsweise Rauchmelder. Sie müssen nicht nur die Sicherheit abwägen, sondern auch den Verlust an Mobilität oder Zeit.auf der Straße verbracht, die die Abteilung auf 26,44 $ pro Stunde schätzt.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Worten sieht alles schön aus. Die Risikobewertung in Bezug auf verlorene Leben und Zeit auf der Straße beinhaltet jedoch keine unterschiedlichen moralischen Einschätzungen darüber, wie wir Menschen gefährden. Zum Beispiel müsste ein Robomobil, das das Leben aller Menschen gleichermaßen bewertet, einem Motorradfahrer ohne Helm mehr Platz geben als einem Motorradfahrer in voller Ausrüstung, da erstere weniger wahrscheinlich überleben werden. Aber das ist unfair - kann man dafür bestrafen, dass man sich um seine Sicherheit kümmert?</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein weiterer Unterschied zwischen der Ethik von Robotern und Menschen besteht darin, dass die Ethik der ersteren von Programmierern auch aus gutem Grund verzerrt werden kann. Stellen Sie sich vor, der Algorithmus hat die Größe der Pufferzone für Fußgänger in verschiedenen Bereichen auf der Grundlage der Analyse der Höhe der Entschädigung für Ansprüche von Fußgängern bei einem Unfall angepasst. Einerseits ist es vernünftig, effizient und gut gemeint. Andererseits können kleinere Strafen vom Durchschnittseinkommen der Menschen in einem bestimmten Gebiet abhängen. Dann wird der Algorithmus die Armen bestrafen, indem er ihnen eine kleinere Pufferzone gibt, wodurch ihr Risiko, abgeschossen zu werden, leicht erhöht wird.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es besteht die Versuchung, Fragen wie rein akademische beiseite zu schieben, aber Sie können sie nicht umgehen, da Programme alles wörtlich nehmen. Sie müssen die Konsequenzen von Aktionen bewerten, bevor sie ausgeführt werden müssen - in der Entwicklungsphase und nicht in der Phase der Erstellung von Patches für Software. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Teilweise aus diesem Grund verwenden Forscher hypothetische Situationen, in denen eine Maschine zwischen zwei Übeln wählen muss. Eine der bekanntesten Aufgaben dieser Art ist das Problem eines Wagens. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein schwerer unkontrollierter Wagen wird auf Schienen getragen. Unterwegs sind fünf Leute von einem verrückten Philosophen an die Schienen gebunden. Glücklicherweise können Sie den Pfeil wechseln - und dann fährt der Wagen auf einer anderen, alternativen Route. Leider befindet sich eine Person auf dem Abstellgleis, die ebenfalls an Schienen gebunden ist. Was sind deine Handlungen?</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wirst du ein Leben für mehrere opfern? </font><font style="vertical-align: inherit;">Wenn nicht, werden aufgrund Ihrer Untätigkeit immer noch Menschen sterben. Wie können Sie mit diesem Widerspruch umgehen?</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zu den Themen solcher Experimente wurden Bücher geschrieben, mit denen Sie einfache und direkte Systeme testen können, die sich mit ethischen Fragen befassen, und Bereiche finden, in denen es schön wäre, sich mit einigen Nuancen zu befassen. </font><font style="vertical-align: inherit;">Angenommen, wir haben ein Robomobil programmiert, um Fußgänger um jeden Preis zu vermeiden. </font><font style="vertical-align: inherit;">Wenn eine Fußgängerin plötzlich in einem zweispurigen Tunnel auftaucht und das Auto nicht rechtzeitig bremsen kann, muss sie die Spur verlassen, auch wenn sie einem Bus mit Passagieren im Weg steht. </font><font style="vertical-align: inherit;">Die Wahrscheinlichkeit eines solchen Ereignisses ist nicht so wichtig wie das Problem, das es in der Logik des Roboterautos aufwirft - dass die absolute Überlegenheit des Wertes eines Fußgängers gegenüber allen anderen Personen, die die Fahrbahn benutzen, sehr gefährlich sein kann.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ethik in der Robotik ist eine lösbare Aufgabe. </font><font style="vertical-align: inherit;">Wir wissen das, weil wir in anderen Bereichen bereits die Möglichkeit gefunden haben, ungefähr dieselben Risiken und Vorteile sicher und vernünftig zu handhaben. </font><font style="vertical-align: inherit;">Spenderorgane werden an Patienten verteilt, basierend auf einer Metrik, die aus den potenziellen Lebensjahren und der Lebensqualität berechnet wird. </font><font style="vertical-align: inherit;">Menschen aus solchen notwendigen Berufen wie Landwirt und Lehrer sind vom militärischen Entwurf befreit.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Aufgaben von Robomobilen sind komplizierter. </font><font style="vertical-align: inherit;">Sie müssen auf der Grundlage unvollständiger Informationen schnell entscheiden, in Situationen, in denen Programmierer möglicherweise keine Ethik vorausgesehen haben, die zu wörtlich in den Algorithmus integriert werden muss. </font><font style="vertical-align: inherit;">Glücklicherweise erwarten die Menschen keine übermenschliche Weisheit von ihnen - nur eine rationale Rechtfertigung für das Handeln einer Maschine, die ethische Fragen bewertet. </font><font style="vertical-align: inherit;">Die Lösung sollte nicht perfekt sein - aber nachdenklich und eine, die geschützt werden könnte.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de395143/">https://habr.com/ru/post/de395143/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de395129/index.html">Übersicht über den Router der Draytek 2912-Serie. Teil Zwei</a></li>
<li><a href="../de395131/index.html">Mit Firefox können Sie auf Websites unter mehreren Konten gleichzeitig zugreifen</a></li>
<li><a href="../de395137/index.html">Remote-Eröffnung eines Brokerage-Kontos über das Gosuslug-Portal: Warum und wie?</a></li>
<li><a href="../de395139/index.html">Werden wir Militärrobotern eine Lizenz zum Töten geben?</a></li>
<li><a href="../de395141/index.html">Von Browser-Lesezeichen zu einer neuen Ära: Ein wenig über die Geschichte der Entwicklung von Social-Button-Diensten</a></li>
<li><a href="../de395145/index.html">Спросите Итана №59: что такое тёмная энергия?</a></li>
<li><a href="../de395147/index.html">Mitsubishi Outlander SUV bricht problemlos über WLAN ein</a></li>
<li><a href="../de395149/index.html">Eine neue Erklärung des Prinzips der "unmöglichen" Engine EmDrive: Das sind alles Photonen</a></li>
<li><a href="../de395151/index.html">Klima in Ihrem Zuhause. TION MagicAir Ankündigung</a></li>
<li><a href="../de395153/index.html">Fügen Sie Furigan zum Kanji Python Macro für LibreOffice hinzu</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
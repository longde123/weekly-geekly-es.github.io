<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧒🏽 🈵 🚂 Arrangement d'éclat optimal dans le cluster de pétaoctets Elasticsearch: programmation linéaire 👩🏿‍🤝‍👨🏼 👨🏽‍⚖️ 🕷️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Au cœur des moteurs de recherche Meltwater et Fairhair.ai se trouve Elasticsearch, une collection de clusters avec des milliards d'articles dans les m...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Arrangement d'éclat optimal dans le cluster de pétaoctets Elasticsearch: programmation linéaire</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429738/"><img src="https://habrastorage.org/getpro/habr/post_images/fb5/ee1/f72/fb5ee1f72a2519aae061ef6be05aa09a.png" align="left">  Au cœur des moteurs de recherche Meltwater et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Fairhair.ai se</a> trouve Elasticsearch, une collection de clusters avec des milliards d'articles dans les médias et les réseaux sociaux. <br><br>  Les fragments d'index dans les clusters varient considérablement dans la structure d'accès, la charge de travail et la taille, ce qui pose des problèmes très intéressants. <br><br>  Dans cet article, nous décrirons comment nous avons utilisé la programmation linéaire (optimisation linéaire) pour répartir la charge de travail de recherche et d'indexation aussi uniformément que possible sur tous les nœuds des clusters.  Cette solution réduit la probabilité qu'un nœud devienne un goulot d'étranglement dans le système.  En conséquence, nous avons augmenté la vitesse de recherche et économisé sur l'infrastructure. <br><a name="habracut"></a><br><h1>  Contexte </h1><br>  Les moteurs de recherche de Fairhair.ai contiennent environ 40 milliards de publications provenant des médias sociaux et des éditoriaux, traitant quotidiennement des millions de requêtes.  La plate-forme fournit aux clients des résultats de recherche, des graphiques, des analyses et des exportations de données pour une analyse plus avancée. <br><br>  Ces ensembles de données massifs résident dans plusieurs clusters Elasticsearch à 750 nœuds avec des milliers d'index dans plus de 50 000 fragments. <br><br>  Pour plus d'informations sur notre cluster, consultez les articles précédents sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">son architecture</a> et l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">équilibreur de charge d'apprentissage automatique</a> . <br><br><h1>  Répartition inégale de la charge de travail </h1><br>  Nos données et les requêtes des utilisateurs sont généralement liées à la date.  La plupart des demandes tombent dans une certaine période de temps, par exemple, la semaine dernière, le mois dernier, le dernier trimestre ou une plage arbitraire.  Pour simplifier l'indexation et les requêtes, nous utilisons l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">indexation temporelle</a> , similaire à <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la pile ELK</a> . <br><br>  Cette architecture d'index présente plusieurs avantages.  Par exemple, vous pouvez effectuer une indexation de masse efficace, ainsi que supprimer des index entiers lorsque les données sont obsolètes.  Cela signifie également que la charge de travail pour un index donné varie considérablement au fil du temps. <br><br>  De manière exponentielle, davantage de requêtes sont envoyées aux derniers index, par rapport aux anciens. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd9/4a6/25a/cd94a625ae06e77932216d721bb5eea7.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">1. Schéma d'accès aux indices de temps.</font></i>  <i><font color="gray">L'axe vertical représente le nombre de requêtes terminées, l'axe horizontal représente l'âge de l'index.</font></i>  <i><font color="gray">Les plateaux hebdomadaires, mensuels et annuels sont clairement visibles, suivis d'une longue queue de charge de travail plus faible sur les indices plus anciens</font></i> <br><br>  Les motifs de la fig.  1 étaient assez prévisibles, car nos clients sont plus intéressés par de nouvelles informations et comparent régulièrement le mois en cours avec le passé et / ou cette année avec l'année écoulée.  Le problème est qu'Elasticsearch ne connaît pas ce modèle et ne s'optimise pas automatiquement pour la charge de travail observée! <br><br>  L'algorithme d'allocation de fragments Elasticsearch intégré ne prend en compte que deux facteurs: <br><br><ol><li>  <i>Le nombre de fragments</i> sur chaque nœud.  L'algorithme essaie d'équilibrer uniformément le nombre de fragments par nœud dans le cluster. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Étiquette</a> l'espace disque libre.  Elasticsearch prend en compte l'espace disque disponible sur un nœud avant de décider d'allouer de nouvelles partitions à ce nœud ou de déplacer des segments de ce nœud vers d'autres.  Avec 80% du disque utilisé, il est interdit de placer de nouveaux fragments sur un nœud, 90% du système commencera à transférer activement les fragments de ce nœud. </li></ol><br>  L'hypothèse fondamentale de l'algorithme est que chaque segment du cluster reçoit approximativement la même quantité de charge de travail et que tout le monde a la même taille.  Dans notre cas, c'est très loin de la vérité. <br><br>  L'équilibrage de charge standard conduit rapidement à des points chauds dans le cluster.  Ils apparaissent et disparaissent de façon aléatoire, à mesure que la charge de travail évolue avec le temps. <br><br>  Un point chaud est essentiellement un hôte fonctionnant près de sa limite d'une ou plusieurs ressources système, comme un processeur, des E / S de disque ou une bande passante réseau.  Lorsque cela se produit, le nœud met d'abord les demandes en file d'attente pendant un certain temps, ce qui augmente le temps de réponse à la demande.  Mais si la surcharge dure longtemps, les demandes sont finalement rejetées et les utilisateurs obtiennent des erreurs. <br><br>  Une autre conséquence courante de la congestion est la pression instable des déchets JVM due aux requêtes et aux opérations d'indexation, ce qui conduit au phénomène de «l'enfer effrayant» du ramasse-miettes JVM.  Dans une telle situation, la machine virtuelle Java ne peut pas obtenir la mémoire assez rapidement et tombe en panne de mémoire, ou se retrouve bloquée dans un cycle de collecte de déchets sans fin, se fige et cesse de répondre aux requêtes et aux pings du cluster. <br><br>  Le problème a empiré lorsque nous avons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">refactorisé notre architecture sous AWS</a> .  Auparavant, nous étions «sauvés» par le fait que nous avions exécuté jusqu'à quatre nœuds Elasticsearch sur nos propres serveurs puissants (24 cœurs) dans notre centre de données.  Cela masquait l'influence de la distribution asymétrique des éclats: la charge était largement lissée par un nombre relativement important de noyaux sur la machine. <br><br>  Après refactorisation, nous n'avons placé qu'un seul nœud à la fois sur des machines moins puissantes (8 cœurs) - et les premiers tests ont immédiatement révélé de gros problèmes avec les «points chauds». <br><br>  Elasticsearch attribue des fragments dans un ordre aléatoire, et avec plus de 500 nœuds dans un cluster, la probabilité de trop de fragments "chauds" sur un seul nœud a considérablement augmenté - et ces nœuds ont rapidement débordé. <br><br>  Pour les utilisateurs, cela signifierait une sérieuse détérioration du travail, car les nœuds encombrés répondent lentement et rejettent parfois complètement les demandes ou se bloquent.  Si vous mettez un tel système en production, les utilisateurs verront fréquemment, semble-t-il, des ralentissements aléatoires de l'interface utilisateur et des délais d'attente aléatoires. <br><br>  Dans le même temps, il reste un grand nombre de nœuds avec des fragments sans trop de charge, qui sont en fait inactifs.  Cela conduit à une utilisation inefficace de nos ressources de cluster. <br><br>  Ces deux problèmes pourraient être évités si Elasticsearch distribuait les fragments de manière plus intelligente, car l'utilisation moyenne des ressources système à tous les nœuds est à un niveau sain de 40%. <br><br><h3>  Changement continu de cluster </h3><br>  En travaillant plus de 500 nœuds, nous avons observé une dernière chose: un changement constant de l'état des nœuds.  Les éclats se déplacent constamment d'avant en arrière dans les nœuds sous l'influence des facteurs suivants: <br><br><ul><li>  De nouveaux index sont créés et les anciens sont supprimés. </li><li>  Les étiquettes de disque sont déclenchées en raison de l'indexation et d'autres modifications de partition. </li><li>  Elasticsearch décide au hasard qu'il y a trop peu ou trop de fragments sur le nœud par rapport à la valeur moyenne du cluster. </li><li>  Les pannes matérielles et les plantages au niveau du système d'exploitation entraînent le démarrage de nouvelles instances AWS et les joignent au cluster.  Avec 500 nœuds, cela se produit en moyenne plusieurs fois par semaine. </li><li>  De nouveaux sites sont ajoutés presque chaque semaine en raison de la croissance normale des données. </li></ul><br>  Avec tout cela pris en compte, nous sommes arrivés à la conclusion qu'une solution complexe et continue de tous les problèmes nécessite un algorithme de réoptimisation continu et dynamique. <br><br><h3>  Solution: Shardonnay </h3><br>  Après une longue étude des options disponibles, nous sommes arrivés à la conclusion que nous voulons: <br><br><ol><li>  Créez votre propre solution.  Nous n'avons trouvé aucun bon article, code ou autres idées existantes qui fonctionneraient bien à notre échelle et pour nos tâches. </li><li>  Lancez le processus de rééquilibrage en dehors d'Elasticsearch et utilisez les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">API de redirection en cluster</a> plutôt que d'essayer de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">créer un plugin</a> .  Nous voulions une boucle de rétroaction rapide, et le déploiement d'un plugin sur un cluster de cette envergure peut prendre plusieurs semaines. </li><li>  Utilisez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la programmation linéaire</a> pour calculer les mouvements optimaux des fragments à tout moment. </li><li>  Effectuez l'optimisation en continu afin que l'état du cluster atteigne progressivement l'optimum. </li><li>  Ne déplacez pas trop d'éclats à la fois. </li></ol><br>  Nous avons remarqué une chose intéressante: si vous déplacez trop d'éclats en même temps, il est très facile de déclencher une <i>tempête en cascade de mouvements d'</i> éclats.  Après le début d'une telle tempête, elle peut se poursuivre pendant des heures, lorsque les éclats se déplacent de façon incontrôlable d'avant en arrière, provoquant l'apparition de marques sur le niveau critique d'espace disque à divers endroits.  À son tour, cela conduit à de nouveaux mouvements d'éclats et ainsi de suite. <br><br>  Pour comprendre ce qui se passe, il est important de savoir que lorsque vous déplacez un segment indexé activement, il commence en fait à utiliser beaucoup plus d'espace sur le disque à partir duquel il se déplace.  Cela est dû à la façon dont Elasticsearch stocke <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">les journaux de transactions</a> .  Nous avons vu des cas où lors du déplacement d'un nœud, l'indice a doublé.  Cela signifie que le nœud qui a initié le mouvement des fragments en raison d'une utilisation élevée de l'espace disque utilisera <i>encore plus d'espace disque pendant un</i> certain temps jusqu'à ce qu'il déplace suffisamment de fragments vers d'autres nœuds. <br><br>  Pour résoudre ce problème, nous avons développé le service <i>Shardonnay</i> en l'honneur du célèbre cépage Chardonnay. <br><br><h3>  Optimisation linéaire </h3><br>  L'optimisation linéaire (ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">programmation linéaire</a> , LP) est une méthode permettant d'obtenir le meilleur résultat, tel qu'un profit maximum ou un coût le plus bas, dans un modèle mathématique dont les exigences sont représentées par des relations linéaires. <br><br>  La méthode d'optimisation est basée sur un système de variables linéaires, certaines contraintes qui doivent être respectées et une fonction objective qui détermine à quoi ressemble une solution réussie.  Le but de l'optimisation linéaire est de trouver les valeurs des variables qui minimisent la fonction objectif, sous réserve de restrictions. <br><br><h3>  La distribution des fragments comme problème d'optimisation linéaire </h3><br>  Shardonnay doit fonctionner en continu et à chaque itération, il exécute l'algorithme suivant: <br><br><ol><li>  À l'aide de l'API, Elasticsearch récupère des informations sur les fragments, index et nœuds existants dans le cluster, ainsi que leur emplacement actuel. </li><li>  Modélise l'état d'un cluster comme un ensemble de variables LP binaires.  Chaque combinaison (nœud, index, fragment, réplique) obtient sa propre variable.  Dans le modèle LP, il existe un certain nombre d'heuristiques soigneusement conçues, des restrictions et une fonction objective, plus à ce sujet ci-dessous. </li><li>  Envoie le modèle LP à un solveur linéaire, ce qui donne une solution optimale en tenant compte des contraintes et de la fonction objectif.  La solution consiste à réaffecter des fragments aux nœuds. </li><li>  Interprète la solution du LP et la convertit en une séquence de mouvements d'éclats. </li><li>  Demande à Elasticsearch de déplacer les fragments via l'API de redirection de cluster. </li><li>  Attend que le cluster déplace les fragments. </li><li>  Revient à l'étape 1. </li></ol><br>  L'essentiel est de développer les bonnes contraintes et la fonction objective.  Le reste sera fait par Solver LP et Elasticsearch. <br><br>  Sans surprise, la tâche a été très difficile pour un cluster de cette taille et de cette complexité! <br><br><h3>  Limitations </h3><br>  Nous basons certaines restrictions sur le modèle en fonction des règles dictées par Elasticsearch lui-même.  Par exemple, respectez toujours les étiquettes de disque ou interdisez de placer une réplique sur le même nœud qu'une autre réplique du même fragment. <br><br>  D'autres sont ajoutés sur la base de l'expérience acquise au cours des années de travail avec de grands clusters.  Voici quelques exemples de nos propres limites: <br><br><ul><li>  Ne déplacez pas les index d'aujourd'hui, car ils sont les plus chauds et obtiennent une charge presque constante en lecture et en écriture. </li><li>  Privilégiez le déplacement de fragments plus petits, car Elasticsearch les gère plus rapidement. </li><li>  Il est conseillé de créer et de placer les futurs fragments quelques jours avant qu'ils deviennent actifs, commencent à être indexés et subissent une lourde charge. </li></ul><br><br><h3>  Fonction de coût </h3><br>  Notre fonction de coût pèse ensemble un certain nombre de facteurs différents.  Par exemple, nous voulons: <br><br><ul><li>  minimiser la variance des indexations et des requêtes de recherche afin de réduire le nombre de "points chauds"; </li><li>  conserver la variance minimale d'utilisation du disque pour un fonctionnement stable du système; </li><li>  minimiser le nombre de mouvements d'éclats afin que les "tempêtes" avec une réaction en chaîne ne commencent pas, comme décrit ci-dessus. </li></ul><br><h3>  Réduction des variables LP </h3><br>  À notre échelle, la taille de ces modèles LP devient un problème.  Nous avons rapidement réalisé que les problèmes ne pouvaient pas être résolus dans un délai raisonnable avec plus de 60 millions de variables.  Par conséquent, nous avons appliqué de nombreuses astuces d'optimisation et de modélisation pour réduire considérablement le nombre de variables.  Parmi eux, l'échantillonnage biaisé, l'heuristique, la méthode diviser pour régner, la relaxation itérative et l'optimisation. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/4db/240/fb2/4db240fb21653d48fd6a5ad69728082e.png"></a> <br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">2. La carte thermique montre la charge déséquilibrée sur le cluster Elasticsearch.</font></i>  <i><font color="gray">Cela se manifeste par une grande dispersion de l'utilisation des ressources sur le côté gauche du graphique.</font></i>  <i><font color="gray">Grâce à une optimisation continue, la situation se stabilise progressivement</font></i> <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/19c/fa6/f18/19cfa6f1813be7f3a2ae9d90c58570b2.png"></a> <br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">3. La carte thermique montre l'utilisation du processeur sur tous les nœuds du cluster avant et après la configuration de la fonction de chaleur dans Shardonnay.</font></i>  <i><font color="gray">Un changement significatif dans l'utilisation du processeur est observé avec une charge de travail constante.</font></i> <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/dfc/288/81f/dfc28881fa593f543c14c8aa14069525.png"></a> <br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">4. La carte thermique montre le débit de lecture des disques pendant la même période que sur la fig.</font></i>  <i><font color="gray">3. Les opérations de lecture sont également réparties plus uniformément sur le cluster.</font></i> <br><br><h1>  Résultats </h1><br>  En conséquence, notre solveur LP trouve de bonnes solutions en quelques minutes, même pour notre énorme cluster.  Ainsi, le système améliore de manière itérative l'état du cluster dans le sens de l'optimalité. <br><br>  Et la meilleure partie est que la dispersion de la charge de travail et de l'utilisation du disque converge comme prévu - et cet état presque optimal est maintenu après de nombreux changements intentionnels et inattendus dans l'état du cluster depuis! <br><br>  Nous prenons désormais en charge une répartition saine de la charge de travail dans nos clusters Elasticsearch.  Tout cela grâce à l'optimisation linéaire et à notre service, que nous aimons appeler <i>Chardonnay</i> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr429738/">https://habr.com/ru/post/fr429738/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr429724/index.html">Revue utile. 28 livres qui ont influencé ma pensée, inspiré ou amélioré</a></li>
<li><a href="../fr429728/index.html">Architecture MVI moderne basée sur Kotlin</a></li>
<li><a href="../fr429732/index.html">Tu vas détester ça ou un conte sur le bon code</a></li>
<li><a href="../fr429734/index.html">Le rêve de voler avec un biais électrique</a></li>
<li><a href="../fr429736/index.html">Berce de Sosnowski. Au MO, a introduit des amendes pour distribution</a></li>
<li><a href="../fr429744/index.html">Apprenez OpenGL. Leçon 6.4 - IBL. Exposition spéculaire</a></li>
<li><a href="../fr429750/index.html">Développeur Cookbook: DDD Recipes (Part 3, Application Architecture)</a></li>
<li><a href="../fr429754/index.html">Erreurs fatales d'intégration matérielle</a></li>
<li><a href="../fr429756/index.html">Comment configurer l'installation des variables d'environnement Nuxt.js en runtime, ou Comment tout faire n'aime pas tout le monde et ne le regrette pas</a></li>
<li><a href="../fr429758/index.html">Pourquoi la documentation SRE est importante. Partie 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚Äçüéì üïµüèΩ üë©üèæ‚Äçüöí Cambios recientes en Linux IO stack desde el punto de vista de DBA üë®‚Äçüç≥ ü§ú ü§¶üèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los principales problemas de trabajar con la base de datos est√°n relacionados con las caracter√≠sticas del dispositivo del sistema operativo en el que ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cambios recientes en Linux IO stack desde el punto de vista de DBA</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/459444/">  Los principales problemas de trabajar con la base de datos est√°n relacionados con las caracter√≠sticas del dispositivo del sistema operativo en el que funciona la base de datos.  Linux es ahora el principal sistema operativo para bases de datos.  Solaris, Microsoft e incluso HPUX todav√≠a se utilizan en la empresa, pero nunca ocupar√°n el primer lugar, incluso combinados.  Linux est√° ganando terreno con confianza porque cada vez hay m√°s bases de datos de c√≥digo abierto.  Por lo tanto, el problema de la interacci√≥n de la base de datos con el sistema operativo es obviamente sobre las bases de datos Linux.  Esto se superpone al eterno problema de DB: el rendimiento de IO.  Es bueno que en los √∫ltimos a√±os Linux haya sufrido una importante revisi√≥n de la pila de E / S y hay esperanza para la iluminaci√≥n. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/0o7uNUOS-Ho" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Ilya Kosmodemyansky ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">hydrobiont</a> ) trabaja para Data Egret, una compa√±√≠a que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">consulta</a> y apoya PostgreSQL, y sabe mucho sobre la interacci√≥n entre el sistema operativo y las bases de datos.  En un informe sobre HighLoad ++, Ilya habl√≥ sobre la interacci√≥n de IO y las bases de datos utilizando el ejemplo de PostgreSQL, pero tambi√©n mostr√≥ c√≥mo funcionan otras bases de datos con IO.  Observ√© la pila de Linux IO, qu√© cosas nuevas y buenas aparec√≠an en ella y por qu√© todo no es como era hace un par de a√±os.  Como recordatorio √∫til: una lista de verificaci√≥n de la configuraci√≥n de PostgreSQL y Linux para obtener el m√°ximo rendimiento del subsistema IO en los nuevos n√∫cleos. <br><a name="habracut"></a><br>  <i>El video del informe contiene mucho ingl√©s, la mayor√≠a de los cuales tradujimos en el art√≠culo.</i> <br><br><h2>  ¬øPor qu√© hablar de IO? </h2><br>  <strong>La E / S r√°pida es lo m√°s importante para los administradores de bases de datos</strong> .  Todos saben lo que se puede cambiar al trabajar con la CPU, esa memoria se puede expandir, pero la E / S puede arruinar todo.  Si est√° mal con los discos, y demasiadas E / S, entonces la base de datos gemir√°.  IO se convertir√° en un cuello de botella. <br><br><blockquote>  Para que todo funcione bien, debe configurarlo todo. </blockquote><br>  No solo la base de datos o solo el hardware, eso es todo.  Incluso el Oracle de alto nivel, que en s√≠ mismo es un sistema operativo en algunos lugares, requiere configuraci√≥n.  Leemos las instrucciones en la "Gu√≠a de instalaci√≥n" de Oracle: cambie dichos par√°metros del kernel, cambie otros, hay muchas configuraciones.  Adem√°s del hecho de que en Unbreakable Kernel, mucho ya est√° conectado por defecto a Oracle Linux. <br><br>  Para PostgreSQL y MySQL, se requieren a√∫n m√°s cambios.  Esto se debe a que estas tecnolog√≠as dependen de los mecanismos del sistema operativo.  Un DBA que funciona con PostgreSQL, MySQL o NoSQL moderno debe ser un ingeniero de operaciones de Linux y modificar diferentes tuercas del sistema operativo. <br><br>  Todos los que quieran lidiar con la configuraci√≥n del n√∫cleo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">recurren</a> a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LWN</a> .  El recurso es ingenioso, minimalista, contiene mucha informaci√≥n √∫til, pero fue <strong>escrito por desarrolladores de kernel para desarrolladores de kernel</strong> .  ¬øQu√© escriben bien los desarrolladores de kernel?  El n√∫cleo, no el art√≠culo, c√≥mo usarlo.  Por lo tanto, intentar√© explicarte todo a los desarrolladores y dejar que escriban el n√∫cleo. <br><br>  Todo se complica muchas veces por el hecho de que inicialmente el desarrollo del kernel de Linux y el procesamiento de su stack se retrasaron, y en los √∫ltimos a√±os han ido muy r√°pido.  Ni el hierro ni los desarrolladores con art√≠culos detr√°s de √©l se mantienen al d√≠a. <br><br><h2>  Base de datos t√≠pica </h2><br>  Comencemos con los ejemplos de PostgreSQL: aqu√≠ hay E / S almacenadas en b√∫fer.  Tiene memoria compartida, que se asigna en el <strong>espacio</strong> del <strong>usuario</strong> desde el punto de vista del sistema operativo, y tiene la misma cach√© en el cach√© del n√∫cleo en el <strong>espacio del n√∫cleo</strong> . <br><br><img src="https://habrastorage.org/webt/jd/dh/d2/jddhd25l97pocaqtqqf6ccygcxi.jpeg"><br><br>  <strong>La tarea principal de una base de datos moderna</strong> : <br><br><ul><li>  recoger p√°ginas del disco en la memoria; </li><li>  cuando ocurra un cambio, marque las p√°ginas como sucias; </li><li>  escribir en el registro de escritura anticipada; </li><li>  luego sincronice la memoria para que sea consistente con el disco. </li></ul><br>  En una situaci√≥n de PostgreSQL, este es un viaje de ida y vuelta constante: desde la memoria compartida que PostgreSQL controla hasta el n√∫cleo de la cach√© de p√°gina y luego al disco a trav√©s de toda la pila de Linux.  Si usa una base de datos en un sistema de archivos, funcionar√° en este algoritmo con cualquier sistema similar a UNIX y con cualquier base de datos.  Las diferencias son, pero insignificantes. <br><br>  Usar Oracle ASM ser√° diferente: Oracle mismo interact√∫a con el disco.  Pero el principio es el mismo: con Direct IO o con Page Cache, pero la tarea es <strong>dibujar p√°ginas a trav√©s de toda la pila de E / S lo m√°s r√°pido posible</strong> , sea lo que sea.  Y pueden surgir problemas en cada etapa. <br><br><h3>  Dos problemas de IO </h3><br>  Si bien todo es de <strong>solo lectura</strong> , no hay problemas.  Leen y, si hay suficiente memoria, todos los datos que deben leerse se colocan en la RAM.  El hecho de que en el caso de PostgreSQL en <strong>Buffer Cache</strong> sea ‚Äã‚Äãel mismo, no estamos muy preocupados. <br><br><img src="https://habrastorage.org/webt/mh/0j/sm/mh0jsmmdrh5bosmamuaiko9l-jw.jpeg"><br><br>  <strong>El primer problema con IO es la sincronizaci√≥n de cach√©.</strong>  Se produce cuando se requiere la grabaci√≥n.  En este caso, tendr√° que conducir hacia adelante y hacia atr√°s con mucha m√°s memoria. <br><br><img src="https://habrastorage.org/webt/tq/mw/u7/tqmwu7fy-wlwqjx6nxec6jfcyrk.jpeg"><br><br>  En consecuencia, debe configurar PostgreSQL o MySQL para que todo llegue al disco desde la memoria compartida.  En el caso de PostgreSQL, a√∫n necesita ajustar la trampa de fondo de p√°ginas sucias en Linux para enviar todo al disco. <br><br>  <strong>El segundo problema com√∫n es el error de escritura del registro de escritura anticipada</strong> .  Aparece cuando la carga es tan poderosa que incluso un registro grabado secuencialmente descansa en el disco.  En esta situaci√≥n, tambi√©n debe registrarse r√°pidamente. <br><br>  La situaci√≥n no es muy diferente de la <strong>sincronizaci√≥n de cach√©</strong> .  En PostgreSQL, trabajamos con una gran cantidad de buffers compartidos, la base de datos tiene mecanismos para la grabaci√≥n eficiente del registro de escritura anticipada, est√° optimizada al l√≠mite.  Lo √∫nico que se puede hacer para que el registro sea m√°s eficiente es cambiar la configuraci√≥n de Linux. <br><br><h2>  Los principales problemas de trabajar con la base de datos. </h2><br>  <strong>El segmento de memoria compartida puede ser muy grande</strong> .  Empec√© a hablar de esto en conferencias en 2012.  Luego dije que la memoria ha bajado de precio, incluso hay servidores con 32 GB de RAM.  En 2019, es posible que ya haya m√°s en las computadoras port√°tiles, cada vez m√°s a menudo en los servidores 128, 256, etc. <br><br>  <strong>Realmente mucha memoria</strong> .  La grabaci√≥n banal requiere tiempo y recursos, y las <strong>tecnolog√≠as que utilizamos para esto son conservadoras</strong> .  Las bases de datos son antiguas, se han desarrollado durante mucho tiempo, evolucionan lentamente.  Los mecanismos en las bases de datos no son exactamente correctos con la √∫ltima tecnolog√≠a. <br><br>  <strong>La sincronizaci√≥n de p√°ginas en la memoria con el disco da como resultado enormes operaciones de E / S.</strong>  Cuando sincronizamos cach√©s, surge un gran flujo de E / S y surge otro problema: <strong>no podemos torcer algo y observar el efecto.</strong>  En un experimento cient√≠fico, los investigadores cambian un par√°metro: obtener el efecto, el segundo, obtener el efecto, el tercero.  No tendremos √©xito.  Retorcemos algunos par√°metros en PostgreSQL, configuramos puntos de control; no vimos el efecto.  Luego, nuevamente configure toda la pila para capturar al menos alg√∫n resultado.  El par√°metro Twist one no funciona: nos vemos obligados a configurar todo de una vez. <br><br>  La mayor√≠a de las IO de PostgreSQL generan sincronizaci√≥n de p√°ginas: puntos de control y otros mecanismos de sincronizaci√≥n.  Si trabaj√≥ con PostgreSQL, es posible que haya visto picos de puntos de control cuando aparece peri√≥dicamente una "sierra" en los gr√°ficos.  Anteriormente, muchos enfrentaban este problema, pero ahora hay manuales sobre c√≥mo solucionarlo, se ha vuelto m√°s f√°cil. <br><br>  Los SSD hoy en d√≠a salvan enormemente la situaci√≥n.  En PostgreSQL, algo rara vez descansa directamente en el registro de valor.  Todo depende de la sincronizaci√≥n: cuando se produce un punto de control, se llama a fsync y hay una especie de "golpear" un punto de control sobre otro.  Demasiado IO.  Un punto de control a√∫n no ha finalizado, no ha completado todos sus fsyncs, pero ya ha ganado otro punto de control, ¬°y comenz√≥! <br><br>  PostgreSQL tiene una caracter√≠stica √∫nica: <strong>autovacuum</strong> .  Esta es una larga historia de muletas para la arquitectura de bases de datos.  Si el autovac√≠o falla, generalmente lo configuran para que funcione de manera agresiva y no interfiera con el resto: hay muchos trabajadores de autovac√≠o, tropiezos frecuentes, procesan las tablas r√°pidamente.  De lo contrario, habr√° problemas con DDL y con los bloqueos. <br><br><blockquote>  Pero cuando Autovacuum es agresivo, comienza a masticar IO. </blockquote><br>  Si el vac√≠o autom√°tico se superpone en los puntos de control, la mayor√≠a de las veces los discos se reciclan casi al 100%, y esta es la fuente de los problemas. <br><br>  Curiosamente, hay un problema de <strong>recarga de cach√©</strong> .  Ella es generalmente menos conocida por DBA.  Un ejemplo t√≠pico: la base de datos se inici√≥ y, por alg√∫n tiempo, todo se ralentiza tristemente.  Por lo tanto, incluso si tiene mucha RAM, compre buenos discos para que la pila caliente el cach√©. <br><br>  Todo esto afecta seriamente el rendimiento.  Los problemas comienzan no inmediatamente despu√©s de reiniciar la base de datos, sino m√°s tarde.  Por ejemplo, el punto de control pas√≥ y muchas p√°ginas est√°n sucias en toda la base de datos.  Se copian en el disco porque necesita sincronizarlos.  Luego, las solicitudes solicitan una nueva versi√≥n de las p√°ginas del disco y la base de datos se hunde.  Los gr√°ficos mostrar√°n c√≥mo la recarga de cach√© despu√©s de cada punto de control contribuye con un cierto porcentaje a la carga. <br><br>  Lo m√°s desagradable en la entrada / salida de la base de datos es <strong>Worker IO.</strong>  Cuando cada trabajador que solicita, comienza a generar su IO.  En Oracle, es m√°s f√°cil, pero en PostgreSQL es un problema. <br><br>  Hay muchas razones para los problemas con <strong>Worker IO</strong> : no hay suficiente cach√© para "publicar" nuevas p√°ginas desde el disco.  Por ejemplo, sucede que todos los buffers est√°n compartidos, todos est√°n sucios, los puntos de control a√∫n no lo han estado.  Para que el trabajador realice la selecci√≥n m√°s simple, debe tomar el cach√© de alguna parte.  Para hacer esto, primero debe guardarlo todo en el disco.  No tiene un proceso especializado de puntero de verificaci√≥n, y el trabajador inicia fsync para liberarlo y llenarlo con algo nuevo. <br><br>  Esto plantea un problema a√∫n mayor: el trabajador es una cosa no especializada y todo el proceso no est√° optimizado en absoluto.  Es posible optimizar en alg√∫n lugar a nivel de Linux, pero en PostgreSQL esta es una medida de emergencia. <br><br><h2>  Principal problema de E / S para DB </h2><br>  <strong>¬øQu√© problema resolvemos cuando configuramos algo?</strong>  Queremos maximizar el viaje de p√°ginas sucias entre el disco y la memoria. <br><br>  Pero a menudo sucede que estas cosas no tocan directamente el disco.  Un caso t√≠pico: ve un promedio de carga muy grande.  Por qu√©  Porque alguien est√° esperando el disco y todos los dem√°s procesos tambi√©n est√°n esperando.  Parece que no hay una utilizaci√≥n expl√≠cita del disco de los discos, simplemente algo bloque√≥ el disco all√≠, y el problema es con la entrada / salida de todos modos. <br><br><blockquote>  Los problemas de E / S de la base de datos no siempre se refieren solo a los discos. </blockquote><br>  Todo est√° involucrado en este problema: discos, memoria, CPU, IO Schedulers, sistemas de archivos y configuraciones de bases de datos.  Ahora repasemos la pila, veamos qu√© hacer con ella y qu√© cosas buenas se han inventado en Linux para que todo funcione mejor. <br><br><h3>  Discos </h3><br>  Durante muchos a√±os, los discos fueron terriblemente lentos y nadie estuvo involucrado en la latencia u optimizaci√≥n de las etapas de transici√≥n.  Optimizar fsyncs no ten√≠a sentido.  El disco giraba, las cabezas se mov√≠an a lo largo de √©l como un disco de fon√≥grafo, y fsyncs era tan largo que no surgieron problemas. <br><br><h3>  El recuerdo </h3><br>  Es in√∫til mirar las consultas principales sin ajustar la base de datos.  Configurar√° una cantidad suficiente de memoria compartida, etc., y tendr√° una nueva consulta superior; deber√° configurarla nuevamente.  Aqu√≠ est√° la misma historia.  Toda la pila de Linux se realiz√≥ a partir de este c√°lculo. <br><br><h3>  Ancho de banda y latencia </h3><br>  <strong>Maximizar el rendimiento de IO maximizando el rendimiento es f√°cil hasta cierto punto.</strong>  Se invent√≥ un proceso auxiliar de PageWriter en PostgreSQL que descarg√≥ el punto de control.  El trabajo se ha vuelto paralelo, pero todav√≠a hay bases para la adici√≥n de paralelismo.  Y minimizar la latencia es la tarea de la √∫ltima milla, para la cual se necesitan s√∫per tecnolog√≠as. <br><br>  Estas s√∫per tecnolog√≠as son SSD.  Cuando aparecieron, la latencia cay√≥ bruscamente.  Pero en todas las otras etapas de la pila, aparecieron problemas: tanto del lado de los fabricantes de la base de datos como de los fabricantes de Linux.  Los problemas deben ser abordados. <br><br>  El desarrollo de la base de datos se centr√≥ en maximizar el rendimiento, al igual que el desarrollo del kernel de Linux.  Muchos m√©todos para optimizar la era de E / S de los discos giratorios no son tan buenos para los SSD. <br><br>  En el medio, nos vimos obligados a realizar copias de seguridad de la infraestructura actual de Linux, pero con nuevos discos.  Vimos las pruebas de rendimiento del fabricante con una gran cantidad de IOPS diferentes, y la base de datos no mejor√≥, porque la base de datos no es solo y no tanto sobre IOPS.  A menudo sucede que podemos omitir 50,000 IOPS por segundo, lo cual es bueno.  Pero si no conocemos la latencia, no sabemos su distribuci√≥n, entonces no podemos decir nada sobre el rendimiento.  En alg√∫n momento, la base de datos comenzar√° al punto de control y la latencia aumentar√° dram√°ticamente. <br><br>  Durante mucho tiempo, como ahora, este ha sido un gran problema de rendimiento en las bases de datos de virtuala.  Virtual IO se caracteriza por una latencia desigual, que, por supuesto, tambi√©n conlleva problemas. <br><br><h2>  IO stack.  Como era antes </h2><br><img src="https://habrastorage.org/webt/yl/3v/oz/yl3vozgbt2ltrkqo8lbey-wzdfo.jpeg"><br><br>  Hay espacio de usuario: esa memoria, que es administrada por la propia base de datos.  En una base de datos configurada para que todo funcione como deber√≠a.  Esto se puede hacer en un informe separado, y ni siquiera en uno.  Luego, todo pasa inevitablemente a trav√©s de Cach√© de p√°gina o, a trav√©s de la interfaz Direct IO, ingresa a la <strong>capa Bloquear entrada / salida</strong> . <br><br>  Imagine una interfaz de sistema de archivos.  Las p√°ginas que estaban en el Buffer Cache, como estaban originalmente en la base de datos, es decir, bloques, salen de ella.  La capa de bloque IO se ocupa de lo siguiente.  Hay una estructura C que describe un bloque en el n√∫cleo.  La estructura toma estos bloques y recopila de ellos vectores (matrices) de solicitudes de entrada o salida.  Debajo de la capa BIO est√° la capa solicitante.  Los vectores se recopilan en esta capa e ir√°n m√°s all√°. <br><br>  Durante mucho tiempo, estas dos capas en Linux fueron afiladas para una grabaci√≥n eficiente en discos magn√©ticos.  Era imposible hacerlo sin una transici√≥n.  Hay bloques que son convenientes para administrar desde la base de datos.  Es necesario ensamblar estos bloques en vectores que se escriben convenientemente en el disco para que queden en alg√∫n lugar cercano.  Para que esto funcione de manera efectiva, crearon Elevators, o Schedulers IO. <br><br><h2>  Ascensores </h2><br>  Los ascensores participaron principalmente en la combinaci√≥n y clasificaci√≥n de vectores.  Todo para que el controlador SD de bloque, el controlador de cuasidisco, llegue a los bloques de grabaci√≥n en el orden conveniente para √©l.  El controlador tradujo de bloques a sus sectores y escribi√≥ en el disco. <br><br>  El problema era que era necesario hacer varias transiciones, y en cada una implementar su propia l√≥gica del proceso √≥ptimo. <br><br><h3>  Ascensores: hasta el kernel 2.6 </h3><br>  <strong>Antes del kernel 2.6, estaba Linus Elevator</strong> , el IO Scheduler m√°s primitivo, escrito por usted adivina qui√©n.  Durante mucho tiempo fue considerado absolutamente inquebrantable y bueno, hasta que desarrollaron algo nuevo. <br><br>  Linus Elevator tuvo muchos problemas.  <strong>Combin√≥ y orden√≥</strong> <strong>seg√∫n c√≥mo grabar de manera m√°s eficiente</strong> .  En el caso de los discos mec√°nicos rotativos, esto condujo a la aparici√≥n del " <strong>hambre"</strong> : una situaci√≥n en la que la eficiencia de grabaci√≥n depende de la rotaci√≥n del disco.  Si de repente necesita leer con eficacia al mismo tiempo, pero ya se ha convertido en incorrecto, se lee mal desde dicho disco. <br><br>  Poco a poco, se hizo evidente que esta es una forma ineficiente.  Por lo tanto, comenzando con el kernel 2.6, comenz√≥ a aparecer un zool√≥gico completo de planificadores, que estaba destinado a diferentes tareas. <br><br><h3>  Ascensores: entre 2.6 y 3 </h3><br>  Muchas personas confunden estos planificadores con los planificadores del sistema operativo porque tienen nombres similares.  <strong>CFQ: la cola completamente justa</strong> no es lo mismo que los planificadores del sistema operativo.  Solo los nombres son similares.  Fue acu√±ado como un planificador universal. <br><br>  <strong>¬øQu√© es un planificador universal?</strong>  ¬øCrees que tienes una carga promedio o, por el contrario, una √∫nica?  Las bases de datos tienen muy poca versatilidad.  La carga universal se puede imaginar como una computadora port√°til normal.  Todo sucede all√≠: escuchamos m√∫sica, jugamos, escribimos texto.  Para esto, solo se escribieron planificadores universales. <br><br>  <strong>La tarea principal del planificador universal:</strong> en el caso de Linux, para cada terminal virtual y proceso, crear una cola de solicitud.  Cuando queremos escuchar m√∫sica en un reproductor de audio, IO para el reproductor toma una cola.  Si queremos hacer una copia de seguridad de algo usando el comando cp, hay algo m√°s involucrado. <br><br>  En el caso de las bases de datos, se produce un problema.  Como regla general, una base de datos es un proceso que comenz√≥ y, durante la operaci√≥n, surgieron procesos paralelos que siempre terminan en la misma cola de E / S.  La raz√≥n es que esta es la misma aplicaci√≥n, el mismo proceso padre.  Para cargas muy peque√±as, tal programaci√≥n era adecuada, para el resto no ten√≠a sentido.  Fue m√°s f√°cil apagarlo y no usarlo si es posible. <br><br>  Gradualmente, apareci√≥ el <strong>planificador de fecha l√≠mite</strong> : funciona de manera m√°s astuta, pero b√°sicamente es fusionar y ordenar discos giratorios.  Dado el dise√±o de un subsistema de disco espec√≠fico, recopilamos vectores de bloques para escribirlos de la manera √≥ptima.  Ten√≠a menos problemas con el <strong>hambre</strong> , pero estaban all√≠. <br><br>  Por lo tanto, m√°s cerca del tercer n√∫cleo de Linux apareci√≥ <strong>noop</strong> o <strong>none</strong> , que funcion√≥ mucho mejor con la propagaci√≥n de SSD.  Incluyendo el programador noop, en realidad deshabilitamos la programaci√≥n: no hay clasificaciones, fusiones y cosas similares que hicieron CFQ y la fecha l√≠mite. <br><br>  Esto funciona mejor con los SSD, porque los SSD son inherentemente paralelos: tiene celdas de memoria.  Cuantos m√°s elementos tenga en una placa PCIe, m√°s eficiente funcionar√°. <br><br>  Programador de algunos de sus otros mundos, desde el punto de vista de SSD, consideraciones, recoge algunos vectores y los env√≠a a alguna parte.  Todo termina con un embudo.  As√≠ que matamos la concurrencia de los SSD, no los usemos al m√°ximo.  Por lo tanto, un apagado simple, cuando los vectores van al azar sin ninguna clasificaci√≥n, funcion√≥ mejor en t√©rminos de rendimiento.  Debido a esto, se cree que las lecturas aleatorias, la escritura aleatoria son mejores en SSD. <br><br><h3>  Ascensores: 3.13 en adelante </h3><br>  Comenzando con el kernel 3.13, <strong>apareci√≥ blk-mq</strong> .  Un poco antes hab√≠a un prototipo, pero en 3.13 apareci√≥ por primera vez una versi√≥n funcional. <br><br>  <strong>Blk-mq comenz√≥</strong> como un planificador, pero es dif√≠cil llamarlo planificador, ya que est√° solo arquitect√≥nicamente.  Este es un reemplazo para la capa de solicitud en el n√∫cleo.  Poco a poco, el desarrollo de blk-mq condujo a una revisi√≥n importante de toda la pila de E / S de Linux. <br><br>  La idea es esta: usemos la capacidad nativa de los SSD para hacer concurrencia eficiente para E / S.  Dependiendo de cu√°ntas secuencias de E / S paralelas puede usar, hay colas honestas a trav√©s de las cuales simplemente escribimos tal como est√°n en el SSD.  Cada CPU tiene su propia cola para grabar. <br><br>  Actualmente <strong>blk-mq se</strong> est√° desarrollando y trabajando activamente.  No hay raz√≥n para no usarlo.  En los n√∫cleos modernos, desde 4 y superiores, desde <strong>blk-mq, la</strong> ganancia es notable, no 5-10%, pero significativamente m√°s. <br><br><blockquote>  blk-mq es probablemente la mejor opci√≥n para trabajar con SSD. </blockquote><br>  En su forma actual, <strong>blk-mq est√°</strong> directamente vinculado al controlador <strong>NVMe</strong> Linux.  No solo hay un controlador para Linux, sino tambi√©n un controlador para Microsoft.  Pero la idea de hacer <strong>blk-mq</strong> y el controlador NVMe es el procesamiento mismo de la pila de Linux, de la cual las bases de datos se han beneficiado enormemente. <br><br>  Un consorcio de varias compa√±√≠as decidi√≥ hacer una especificaci√≥n, este mismo protocolo.  Ahora ya en versi√≥n de producci√≥n funciona bien para SSD PCIe locales.  Soluci√≥n casi lista para arreglos de discos que est√°n conectados a trav√©s de la √≥ptica. <br><br><blockquote>  El controlador blk-mq y NVMe son m√°s que un programador.  El sistema tiene como objetivo reemplazar todo el nivel de solicitudes. </blockquote><br>  Vamos a sumergirnos en √©l para entender lo que es.  La especificaci√≥n NVMe es grande, por lo que no consideraremos todos los detalles, sino que los revisaremos. <br><br><h3>  Viejo acercamiento a los ascensores </h3><br><img src="https://habrastorage.org/webt/ya/82/ou/ya82oun8cusxylg0bsuz5y0e1la.jpeg"><br><br>  El caso m√°s simple: hay una CPU, es su turno, y de alguna manera vamos al disco. <br><br>  Los ascensores m√°s avanzados funcionaron de manera diferente.  Hay varias CPU y varias colas.  De alguna manera, por ejemplo, dependiendo del proceso principal que los trabajadores de la base de datos separaron, IO se pone en cola en los discos. <br><br><h3>  Un nuevo enfoque para ascensores </h3><br>  blk-mq es un enfoque completamente nuevo.  Cada CPU, cada zona NUMA agrega su propia entrada / salida a su vez.  Adem√°s, los datos recaen en los discos, sin importar qu√© tan conectados est√©n, porque el controlador es nuevo.  No hay un controlador SD que funcione con los conceptos de cilindros, bloques. <br><br><img src="https://habrastorage.org/webt/zf/12/7n/zf127n1eqhli2qioregzrsiftp8.jpeg"><br><br>  Hubo un per√≠odo de transici√≥n.  En alg√∫n momento, todos los proveedores de matrices RAID comenzaron a vender complementos que les permitieron omitir la cach√© RAID.  Si los SSD est√°n conectados, escriba directamente all√≠.  Desactivaron el uso del controlador SD para sus productos, como blq-mq. <br><br><h2>  Nueva pila con blk-mq </h2><br>  As√≠ es como se ve la pila en una nueva forma. <br><br><img src="https://habrastorage.org/webt/me/ma/3e/mema3e595wllaoub6thn61q8kvu.jpeg"><br><br>  Desde arriba todo permanece tambi√©n.  Por ejemplo, las bases de datos est√°n muy por detr√°s.  La E / S de la base de datos, como antes, cae en la capa Block IO.  Existe el muy <strong>blk-mq</strong> que reemplaza la capa de consulta, no el planificador. <br><br>  En el kernel 3.13, toda la optimizaci√≥n termin√≥ aproximadamente al respecto, pero se utilizan nuevas tecnolog√≠as en los n√∫cleos modernos.  Comenzaron a aparecer planificadores especiales para <strong>blk-mq</strong> , dise√±ados para un paralelismo m√°s fuerte.     Linux    schedulers IO ‚Äî  Kyber  BFQ.         <strong>blk-mq</strong> . <br><br> <strong>BFQ</strong> <strong>‚Äî Budget Fair Queueing ‚Äî </strong> <strong></strong> <strong></strong> <strong>FQ</strong> .   ,     . BFQ ‚Äî  scheduler   .         IO.     IO,  / .       ,   .     ‚Äî  .   BFQ,   ,    . <br><br> <strong>Kyber ‚Äî  </strong> .   BFQ,   .  Kyber  scheduler   .    ‚Äî   CPU  . Kyber    . <br><br>      ‚Äî <strong>blk-mq    SD-</strong> .      ,    ,  ,    IO-.  blk-mq  NVMe driver      .     . <br><br>        ‚Äî   latency,      .   SSD,    ‚Äî     .      -, ,    NVMe-,   blk-mq    ,    .    . <br><br><h2>   Linux IO </h2><br>         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> / Linux. <br><br><img src="https://habrastorage.org/webt/ak/05/qb/ak05qbritsgbiaeybq3dmz2mpyi.png"><br><br>   ,    ,   ,  Elevators,   . <br><br>   ,           ,    . <br><br><h2>  NVM Express </h2><br> <strong>NVM Express  NVMe ‚Äî  ,  ,     SSD.</strong>     Linux. Linux ‚Äî     . <br><br>     .          20 /   SSD ,  NVMe  ,   , ‚Äî <strong> 32 /</strong> .  SD    ,   ,     . <br><br><blockquote>    ,  ,   . </blockquote><br>  Una vez que las bases de datos se escribieron para discos giratorios y se orientaron a ellas, tienen √≠ndices en forma de √°rbol B, por ejemplo.  Surge la pregunta: ¬ø <strong>est√°n las bases de datos listas para NVMe</strong> ?  ¬øSon las bases de datos capaces de masticar tal carga? <br><br>  Todav√≠a no, pero se est√°n adaptando.  La lista de correo de PostgreSQL recientemente tuvo un par de <code>pwrite()</code> y cosas similares.  Los desarrolladores de PostgreSQL y MySQL interact√∫an con los desarrolladores del kernel.  Por supuesto, me gustar√≠a m√°s interacci√≥n. <br><br><h2>  Desarrollos recientes </h2><br>  Durante el √∫ltimo a√±o y medio, NVMe ha agregado <strong>encuestas IO</strong> . <br><br>  Al principio hab√≠a discos giratorios con alta latencia.  Luego vinieron los SSD, que son mucho m√°s r√°pidos.  Pero hab√≠a una jamba: fsync contin√∫a, comienza la grabaci√≥n y, a un nivel muy bajo, en el controlador, se env√≠a una solicitud directamente al hardware, escr√≠bala. <br><br>  El mecanismo era simple: lo enviaron y esperamos hasta que se procese la interrupci√≥n.  Esperar el procesamiento de interrupci√≥n no es un problema en comparaci√≥n con escribir en un disco giratorio.  Tom√≥ tanto tiempo esperar que tan pronto como termin√≥ la grabaci√≥n, la interrupci√≥n funcion√≥. <br><br>  Dado que el SSD escribe muy r√°pidamente, ha aparecido forzadamente un mecanismo para sondear la pieza de hardware sobre la grabaci√≥n.  En las primeras versiones, el aumento en la velocidad de E / S alcanz√≥ el 50% debido al hecho de que no estamos esperando una interrupci√≥n, pero estamos preguntando activamente al disco sobre el registro.  <strong>Este mecanismo se llama sondeo IO</strong> . <br><br>  Fue introducido en versiones recientes.  En la versi√≥n 4.12, aparecieron los <strong>planificadores IO</strong> , especialmente afinados para trabajar con <strong>blk-mq</strong> y NVMe, sobre lo que dije <strong>Kyber y BFQ</strong> .  Ya est√°n oficialmente en el n√∫cleo, se pueden usar. <br><br>  Ahora en una forma utilizable existe el llamado <strong>etiquetado IO</strong> .  La mayor√≠a de los fabricantes de nubes y m√°quinas virtuales contribuir√°n a este desarrollo.  En t√©rminos generales, la entrada de una aplicaci√≥n espec√≠fica se puede agregar y darle prioridad.  Las bases de datos a√∫n no est√°n listas para esto, pero est√©n atentos.  Creo que pronto ser√° la corriente principal. <br><br><h2>  Notas directas de E / S </h2><br>  <strong>PostgreSQL no es compatible con Direct IO, y hay una serie de problemas que dificultan la compatibilidad</strong> .  Ahora esto solo es compatible con el valor, y solo si la replicaci√≥n no est√° habilitada.  Es necesario <strong>escribir una gran cantidad de c√≥digo espec√≠fico del sistema operativo</strong> , y por ahora todos se abstienen de esto. <br><br>  A pesar de que Linux conf√≠a mucho en la idea de Direct IO y c√≥mo se implementa, todas las bases de datos van all√≠.  En Oracle y MySQL, Direct IO es muy utilizado.  PostgreSQL es la √∫nica base de datos que Direct IO no tolera. <br><br><h2>  Lista de verificaci√≥n </h2><br>  C√≥mo protegerse de las sorpresas de fsync en PostgreSQL: <br><br><ul><li>  Configure los puntos de control para que sean menos frecuentes y m√°s grandes. </li><li>  Configure el escritor de fondo para ayudar al punto de control. </li><li>  Tire Autovacuum para que no haya E / S espurias innecesarias. </li></ul><br><blockquote>  Seg√∫n la tradici√≥n, en noviembre estamos esperando desarrolladores profesionales de servicios altamente cargados en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Skolkovo</a> en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">HighLoad ++</a> .  Todav√≠a hay un mes para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">solicitar</a> un informe, pero ya hemos aceptado los primeros informes al <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">programa</a> .  Suscr√≠base a nuestro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">bolet√≠n</a> y conozca los nuevos temas de primera mano. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/459444/">https://habr.com/ru/post/459444/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../459430/index.html">Aplicaci√≥n m√≥vil con generaci√≥n autom√°tica de formularios: nuestro caso</a></li>
<li><a href="../459432/index.html">RD-180: ¬øpueden los Estados Unidos fabricar motores de cohetes?</a></li>
<li><a href="../459434/index.html">React Hook Router Una alternativa moderna de React Router</a></li>
<li><a href="../459438/index.html">Los datos son a√∫n m√°s importantes.</a></li>
<li><a href="../459442/index.html">5 sistemas de gesti√≥n de eventos de seguridad de c√≥digo abierto</a></li>
<li><a href="../459446/index.html">Cinco tendencias aterradoras del dise√±o moderno.</a></li>
<li><a href="../459450/index.html">La vulnerabilidad del software de teleconferencia Zoom permite que cualquier sitio web esp√≠e a los usuarios a trav√©s de la c√°mara web</a></li>
<li><a href="../459452/index.html">Agro-robot con IA aprendi√≥ a recolectar cuidadosamente solo ensalada madura del jard√≠n</a></li>
<li><a href="../459454/index.html">¬øC√≥mo fue el primer hackathon en The Standoff?</a></li>
<li><a href="../459456/index.html">Dagaz: Episodios (Parte 1)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
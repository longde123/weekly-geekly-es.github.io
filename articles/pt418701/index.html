<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏿‍💻 🎇 🤱 Estudamos analisadores sintáticos para o idioma russo 🚆 👩🏼 ✍🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Oi Meu nome é Denis Kiryanov, trabalho no Sberbank e lido com os problemas do processamento de linguagem natural (PNL). Uma vez, precisamos escolher u...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Estudamos analisadores sintáticos para o idioma russo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/sberbank/blog/418701/">  Oi  Meu nome é Denis Kiryanov, trabalho no Sberbank e lido com os problemas do processamento de linguagem natural (PNL).  Uma vez, precisamos escolher um analisador sintático para trabalhar com o idioma russo.  Para fazer isso, investigamos os aspectos morfológicos e de tokenização, testamos diferentes opções e avaliamos sua aplicação.  Compartilhamos nossa experiência neste post. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c87/ec8/f26/c87ec8f26a969cf54915271e24abcba1.png"><br><a name="habracut"></a><br><h2>  Preparação para seleção </h2><br>  Vamos começar com o básico: como isso funciona?  Pegamos o texto, conduzimos a tokenização e obtemos uma série de pseudo-tokens.  Os estágios da análise posterior se encaixam em uma pirâmide: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2f/cd9/0aa/b2fcd90aaf42d1eee5ed3ee84fcf27fd.png"><br><br>  Tudo começa com a morfologia - com uma análise da forma de uma palavra e suas categorias gramaticais (gênero, caso, etc.).  A morfologia é baseada na sintaxe - relações além dos limites de uma palavra, entre palavras.  Os analisadores sintáticos que serão discutidos analisam o texto e fornecem a estrutura das dependências das palavras uma da outra. <br><br><h3>  Gramática de dependências e gramática dos componentes imediatos </h3><br>  Existem duas abordagens principais para a análise, que na teoria linguística existem em pé de igualdade. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c59/951/f08/c59951f08529e3628f3ad969385e4be9.png"><br><br>  Na primeira linha, a sentença é analisada como parte da gramática da dependência.  Essa abordagem é ensinada na escola.  Cada palavra em uma frase está de alguma forma conectada com outras.  “Sabonetes” - predicado do qual o sujeito “mãe” depende (aqui a gramática das dependências diverge da escola, onde o predicado depende do assunto).  O sujeito tem uma definição dependente de "minha".  O predicado possui um complemento direto dependente "quadro".  E a adição direta ao "quadro" - a definição de "sujo". <br><br>  Na segunda linha, a análise está de acordo com a gramática dos próprios componentes. <br>  Segundo ela, a frase é dividida em grupos de palavras (frases).  Palavras dentro de um grupo estão mais intimamente relacionadas.  As palavras “minha” e “mãe” estão mais intimamente relacionadas, “quadro” e “sujo” - também.  E ainda há um "sabão" separado. <br><br>  A segunda abordagem para a análise automática da língua russa é pouco aplicável, porque nela as palavras estreitamente relacionadas (membros do mesmo grupo) muitas vezes não se alinham.  Teríamos que combiná-los com colchetes estranhos - em uma ou duas palavras.  Portanto, na análise automática do idioma russo, é habitual trabalhar com base na gramática das dependências.  Isso também é conveniente porque todos estão familiarizados com essa "estrutura" na escola. <br><br><h3>  Árvore de dependência </h3><br>  Podemos traduzir um conjunto de dependências em uma estrutura em árvore.  O topo é a palavra "sabão", algumas palavras dependem diretamente dela, outras dependem de seus viciados.  Aqui está a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">definição</a> da árvore de dependência do livro de Martin e Zhurafsky: <br><br>  <i>Árvore de dependência é um gráfico direcionado que satisfaz as seguintes restrições:</i> <br><br><ul><li>  <i>Existe um único nó raiz designado que não possui arcos recebidos.</i> <br></li><li>  <i>Com exceção do nó raiz, cada vértice possui exatamente um arco recebido.</i> <br></li><li>  <i>Há um caminho exclusivo do nó raiz para cada vértice em V.</i> <br></li></ul><br>  Há um nó de nível superior - um predicado.  A partir dele você pode chegar a qualquer palavra.  Cada palavra depende de outra, mas apenas de uma.  A árvore de dependência é mais ou menos assim: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4b3/b16/19d/4b3b1619db261a71dfd749c28b4fde31.png"><br><br>  Nesta árvore, as arestas são assinadas com algum tipo especial de relacionamento sintático.  Na gramática das dependências, não apenas o fato da conexão entre as palavras é analisado, mas também a natureza dessa conexão.  Por exemplo, "is taken" é quase uma forma verbal, "inventário" é o assunto de "is taken".  Conseqüentemente, temos uma borda "é" em uma direção e na outra.  Essas não são as mesmas conexões, são de natureza diferente, portanto devem ser distinguidas. <br><br>  A seguir, consideramos casos simples em que membros de uma sentença estão presentes, não implícitos.  Existem estruturas e marcas para lidar com passes.  Algo aparece na árvore que não tem uma expressão superficial - uma palavra.  Mas este é o assunto de outro estudo, mas ainda precisamos nos concentrar sozinhos. <br><br><h3>  Projeto Dependências Universais </h3><br>  Para facilitar a escolha de um analisador, voltamos nossa atenção para o projeto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Dependências Universais</a> e o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">concurso Tarefas Compartilhadas CoNLL</a> , que ocorreu recentemente em sua estrutura. <br><br>  O Universal Dependencies é um projeto para unificar a marcação de corpos sintáticos (tribanks) dentro da estrutura da gramática da dependência.  Em russo, o número de tipos de links sintáticos é limitado - assunto, predicado etc.  Em inglês o mesmo, mas o conjunto já é diferente.  Por exemplo, aparece um artigo que também precisa ser rotulado de alguma forma.  Se quiséssemos escrever um analisador mágico que pudesse lidar com todos os idiomas, teríamos problemas em comparar gramáticas diferentes rapidamente.  Os heróicos criadores das Dependências Universais conseguiram concordar entre si e marcar todos os edifícios que estavam à sua disposição em um único formato.  Não é muito importante como eles concordaram, o principal é que, na saída, temos um certo formato uniforme para apresentar toda a história - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mais de 100 tribanks para 60 idiomas</a> . <br><br>  Tarefa compartilhada CoNLL é uma competição entre desenvolvedores de algoritmos de análise, realizada como parte do projeto Universal Dependencies.  Os organizadores pegam um certo número de tribanks e dividem cada um deles em três partes - treinamento, validação e teste.  A primeira parte é fornecida aos participantes da competição para que eles treinem seus modelos nela.  A segunda parte também é usada pelos participantes para avaliar a operação do algoritmo após o treinamento.  Os participantes podem repetir o treinamento e a avaliação iterativamente.  Em seguida, eles entregam seu melhor algoritmo aos organizadores, que o executam na parte do teste, fechados aos participantes.  Os resultados dos modelos nas partes de teste dos tribanks são os resultados da competição. <br><br><h3>  Métricas de qualidade </h3><br>  Temos conexões entre palavras e seus tipos.  Podemos avaliar se a palavra top foi encontrada corretamente - a métrica UAS (pontuação do anexo não marcado).  Ou para avaliar se o vértice e o tipo de dependência foram encontrados corretamente - a métrica LAS (pontuação de anexo rotulado). <br><br><img src="https://habrastorage.org/webt/zb/q5/ic/zbq5icc6mgwabmeryltcbgnp8g4.png"><br><br>  Parece que uma avaliação de precisão se implora aqui - consideramos quantas vezes obtivemos do número total de casos.  Se tivermos 5 palavras e para 4 determinarmos corretamente o topo, obteremos 80%. <br><br>  Mas, na verdade, avaliar o analisador em sua forma pura é problemático.  Os desenvolvedores que resolvem os problemas da análise automática geralmente usam o texto bruto como entrada, que, de acordo com a pirâmide de análise, passa pelos estágios da tokenização e da análise morfológica.  Os erros dessas etapas anteriores podem afetar a qualidade do analisador.  Em particular, isso se aplica ao procedimento de tokenização - alocação de palavras.  Se tivermos identificado as palavras de unidade erradas, não seremos mais capazes de avaliar corretamente as relações sintáticas entre elas - afinal, em nosso corpo rotulado original, as unidades eram diferentes. <br><br>  Portanto, a fórmula de avaliação nesse caso é a medida f, em que precisão é o compartilhamento de acertos precisos em relação ao número total de previsões, e integridade é o compartilhamento de acertos precisos em relação ao número de links nos dados marcados. <br><br>  Quando fornecermos estimativas no futuro, devemos lembrar que as métricas usadas afetam não apenas a sintaxe, mas também a qualidade da tokenização. <br><br><h3>  Língua russa na Universal Dependencies </h3><br>  Para que o analisador possa sintaticamente marcar sentenças que ainda não viu, ele precisa alimentar o corpus marcado para treinamento.  Para o idioma russo, existem vários casos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/839/f92/0bf/839f920bffbfaf4efc0d054ee4804f0d.png"><br><br>  A segunda coluna indica o número de tokens - palavras.  Quanto mais tokens, mais o corpo de treinamento e melhor o algoritmo final (se esses são bons dados).  Obviamente, todas as experiências são conduzidas no SynTagRus (desenvolvido pelo IPPI RAS), no qual existem mais de um milhão de tokens.  Todos os algoritmos serão treinados, o que será discutido mais adiante. <br><br><h3>  Analisadores para russo na tarefa compartilhada CoNLL </h3><br>  De acordo com os resultados da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">competição</a> do ano passado, os modelos treinados no mesmo SynTagRus alcançaram os seguintes indicadores LAS: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ded/ab4/27e/dedab427eef589c4bf8e3c24475632f7.png"><br><br>  Os resultados dos analisadores para o russo são impressionantes - eles são melhores que os dos analisadores para inglês, francês e outros idiomas mais raros.  Tivemos muita sorte por duas razões ao mesmo tempo.  Primeiro, os algoritmos fazem um bom trabalho com o idioma russo.  Em segundo lugar, temos o SynTagRus - uma caixa grande e marcada. <br><br>  A propósito, a competição de 2018 já passou, mas realizamos nossa pesquisa na primavera deste ano, por isso contamos com os resultados da pista do ano passado.  Olhando para o futuro, observamos que a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">nova versão do UDPipe</a> (Future) acabou sendo ainda maior este ano. <br><br>  O Syntaxnet, um analisador do Google, não está na lista.  O que há de errado com ele?  A resposta é simples: o Syntaxnet começou apenas com o estágio da análise morfológica.  Ele pegou a tokenização ideal pronta e já construiu o processamento sobre ela.  Portanto, é injusto avaliá-lo em pé de igualdade com o restante - o restante dividiu em tokens com seus próprios algoritmos, e isso poderia piorar os resultados no próximo estágio da sintaxe.  A amostra de 2017 da Syntaxnet tem um resultado melhor do que a lista inteira acima, mas as comparações diretas não são justas. <br><br>  A tabela possui duas versões do UDPipe, em 12 e 15 lugares.  As mesmas pessoas que participaram ativamente do projeto Dependências Universais estão desenvolvendo esse analisador. <br><br>  As atualizações do UDPipe aparecem periodicamente (um pouco menos frequentemente, a propósito, o layout dos casos também é atualizado).  Portanto, após a competição no ano passado, o UDPipe foi atualizado (eles foram confirmados para a versão 2.0 ainda não lançada; no futuro, por simplicidade, vamos nos referir a grosso modo ao commit do UDPipe 2.0 que assumimos, embora, estritamente falando, não seja assim);  Obviamente, não existem atualizações na tabela de competição.  O resultado do "nosso" commit é aproximadamente o sétimo lugar. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/262/c42/635/262c42635f1f93cdfd690418208f79fe.png"><br><br>  Portanto, precisamos escolher um analisador para o idioma russo.  Como dados iniciais, temos a placa acima com o principal Syntaxnet e com o UDPipe 2.0 em algum lugar em 7º lugar. <br><br><h2>  Escolha um modelo </h2><br>  Simplificamos: começamos com o analisador com as taxas mais altas.  Se algo está errado com ele, vá abaixo.  Algo pode não estar certo de acordo com os seguintes critérios - talvez eles não sejam perfeitos, mas vieram até nós: <br><br><ul><li>  <b>Velocidade do trabalho</b> .  Nosso analisador deve funcionar rápido o suficiente.  A sintaxe, é claro, está longe de ser o único módulo "oculto" de um sistema em tempo real; portanto, você não deve gastar mais do que uma dúzia de milissegundos nele. <br></li><li>  <b>A qualidade do trabalho</b> .  No mínimo, o analisador em si é baseado em dados do idioma russo.  O requisito é óbvio.  Para o idioma russo, temos bons analisadores morfológicos que podem ser integrados em nossa pirâmide.  Se pudermos garantir que o analisador funcione bem sem morfologia, isso nos servirá - iremos deslizar a morfologia mais tarde. <br></li><li>  <b>Disponibilidade de um código de treinamento e, de preferência, de um modelo em domínio público</b> .  Se tivermos um código de treinamento, poderemos repetir os resultados do autor do modelo.  Para fazer isso, eles devem estar abertos.  Além disso, precisamos monitorar cuidadosamente as condições para a distribuição de casos e modelos - teremos que comprar uma licença para usá-los, se os usarmos como parte de nossos algoritmos? <br></li><li>  <b>Lançar sem esforço extra</b> .  Este item é muito subjetivo, mas importante.  O que isso significa?  Isso significa que, se ficarmos sentados por três dias e começarmos algo, mas ele não iniciar, não poderemos selecionar esse analisador, mesmo que seja de perfeita qualidade. <br></li></ul><br>  Tudo o que era maior que o UDPipe 2.0 no gráfico do analisador não nos convinha.  Temos um projeto Python, e alguns analisadores da lista não são escritos em Python.  Para implementá-los no projeto Python, seria necessário aplicar os super esforços.  Em outros casos, fomos confrontados com código-fonte fechado, desenvolvimentos acadêmicos e industriais - em geral, você não chega ao fundo. <br><br>  O Star Syntaxnet merece uma história separada sobre a qualidade do trabalho.  Aqui ele não nos convinha pela velocidade do trabalho.  O tempo de sua resposta a algumas frases simples comuns nos chats é de 100 milissegundos.  Se gastamos tanto em sintaxe, não temos tempo suficiente para mais nada.  Ao mesmo tempo, o UDPipe 2.0 faz uma análise de ~ 3ms.  Como resultado, a escolha caiu no UDPipe 2.0. <br><br><h2>  UDPipe 2.0 </h2><br>  O UDPipe é um pipeline que aprende tokenização, lematização, marcação morfológica e análise gramatical de dependência.  Podemos ensinar-lhe tudo isso ou algo separadamente.  Por exemplo, faça outro analisador morfológico para o idioma russo.  Ou treine e use o UDPipe como um tokenizador. <br><br>  O UDPipe 2.0 está documentado em detalhes.  Há uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">descrição da arquitetura</a> , um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">repositório com um código de treinamento</a> , um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">manual</a> .  O mais interessante são os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">modelos prontos</a> , inclusive para o idioma russo.  Faça o download e execute.  Também neste recurso, os parâmetros de treinamento selecionados para cada corpus de idioma foram liberados.  Para cada modelo, são necessários cerca de 60 parâmetros de treinamento e, com a ajuda deles, você pode alcançar independentemente os mesmos indicadores de qualidade da tabela.  Eles podem não ser ótimos, mas pelo menos podemos ter certeza de que o pipeline funcionará corretamente.  Além disso, a presença de tal referência nos permite experimentar calmamente o modelo por conta própria. <br><br><h3>  Como o UDPipe 2.0 funciona </h3><br>  Primeiro, o texto é dividido em frases e frases em palavras.  O UDPipe faz tudo isso de uma só vez com a ajuda de um módulo conjunto - uma rede neural (GRU de camada única e dupla face), que para cada personagem prevê se é a última em uma frase ou em uma palavra. <br><br>  Então o etiquetador começa a trabalhar - algo que prediz as propriedades morfológicas do token: nesse caso, a palavra é, em que número.  Com base nos quatro últimos caracteres de cada palavra, um marcador gera hipóteses sobre uma parte do discurso e marcações morfológicas dessa palavra e, com a ajuda de um perceptron, seleciona a melhor opção. <br><br>  O UDPipe também possui um lematizador que seleciona o formulário inicial para as palavras.  Ele aprende sobre o mesmo princípio pelo qual um falante não nativo poderia tentar determinar o lema de uma palavra desconhecida.  Cortamos o prefixo e o final da palavra, adicionamos um "t", que está presente na forma inicial do verbo, etc.  Assim, os candidatos são gerados, a partir dos quais o melhor perceptron escolhe. <br><br>  O esquema de marcação morfológica (determinando o número, caso e tudo mais) e as previsões dos lemas são muito semelhantes.  Eles podem ser previstos juntos, mas melhor separadamente - a morfologia do idioma russo é muito rica.  Você também pode conectar sua lista de lemas. <br><br>  Vamos para a parte mais interessante - o analisador.  Existem várias arquiteturas de analisador de dependência.  O UDPipe é uma arquitetura baseada em transição: funciona rapidamente, passando por todos os tokens uma vez em um tempo linear. <br><br>  A análise sintática em uma arquitetura desse tipo começa com uma pilha (onde no início há apenas raiz) e uma configuração vazia.  Existem três maneiras padrão de alterá-lo: <br><br><ul><li>  LeftArc - aplicável se o segundo elemento da pilha não for raiz.  Ele mantém o relacionamento entre o token na parte superior da pilha e o segundo token e também ejeta o segundo da pilha. <br></li><li>  RightArc é o mesmo, mas a dependência é criada de outra maneira e a dica é descartada. <br></li><li>  Shift - transfere a próxima palavra do buffer para a pilha. <br></li></ul><br>  Abaixo está um exemplo do analisador ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">fonte</a> ).  Temos a frase "reserve-me o voo da manhã" e estamos nos reconectando a ele: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/196/b17/845/196b17845e524d75a878837b25325a76.png"><br><br>  Aqui está o resultado: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/686/c78/066/686c780661b296250d53cba054317a18.png"><br><br>  O analisador clássico baseado em transição possui as três operações listadas acima: seta unidirecional, seta unidirecional e deslocamento.  Há também uma operação de troca, nas arquiteturas básicas do analisador baseado em transição, ela não é usada, mas está incluída no UDPipe.  Swap retorna o segundo elemento da pilha para o buffer para retirar o próximo elemento do buffer (se eles estiverem espaçados).  Isso ajuda a pular algumas palavras e restaurar a conexão correta. <br><br>  Há um bom artigo no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">link da</a> pessoa que criou a operação de troca.  Vamos destacar um ponto: apesar de repetidamente passarmos pelo buffer de token inicial (ou seja, nosso tempo não é mais linear), essas operações podem ser otimizadas para que o tempo retorne muito próximo de linear.  Ou seja, diante de nós não é apenas uma operação significativa do ponto de vista da linguagem, mas também uma ferramenta que não diminui muito o trabalho do analisador. <br><br>  Usando o exemplo acima, mostramos as operações, como resultado das quais obtemos alguma configuração - o buffer de token e as conexões entre eles.  Fornecemos essa configuração na etapa atual ao analisador baseado em transição e, com ela, deve prever a configuração na próxima etapa.  Comparando os vetores de entrada e configurações em cada etapa, o modelo é treinado. <br><br>  Assim, selecionamos um analisador que se encaixa em todos os nossos critérios e até entendemos como ele funciona.  Prosseguimos com os experimentos. <br><br><h3>  Problemas do UDPipe </h3><br>  Vamos fazer uma pequena frase: "Transferir cem rublos para a mãe".  O resultado faz você agarrar sua cabeça. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9cb/948/1f2/9cb9481f2e06b366fbee26f0835d31b0.png"><br><br>  "Traduzir" acabou sendo uma desculpa, mas isso é bastante lógico.  Determinamos a gramática da forma da palavra pelos últimos quatro caracteres.  "Lead" é ​​algo como "no meio", então a escolha é relativamente lógica.  É mais interessante com "mãe": "mãe" estava no caso preposicional e se tornou o auge dessa frase. <br><br>  Se tentarmos interpretar tudo com base nos resultados da análise, teremos algo como "no meio de uma mãe (cuja mãe? Quem é essa mãe?) Centenas de rublos".  Não é bem o que era no começo.  Precisamos de alguma forma lidar com isso.  E nós criamos como. <br><br>  Na pirâmide de análise, a sintaxe é construída sobre a morfologia, com base em tags morfológicas.  Aqui está um exemplo de livro de um linguista L.V.  Shcherby a este respeito: <br><br>  <i>"Cuzdra gloky shteko budlanula bokra e menino de cabelos cacheados."</i> <br><br>  A análise desta proposta não causa problemas.  Porque  Porque nós, como etiquetadores UDPipe, observamos o final de uma palavra e entendemos a que parte do discurso ela se refere e a que forma é.  A história com "traduzir" como desculpa contradiz completamente nossa intuição, mas acaba sendo lógica no momento em que tentamos fazer o mesmo com palavras desconhecidas.  Uma pessoa pode pensar da mesma maneira. <br><br>  Avaliaremos o etiquetador UDPipe separadamente.  Se não nos convém, usaremos outro etiquetador - para criar uma análise em cima de outra marcação morfológica. <br><br>  <i>Identificação de texto sem formatação (pontuação CoNLL17 F1)</i> <br><br><ul><li>  <i>formas de ouro: 301639</i> , <br></li><li>  <i>upostag: 98,15%</i> , <br></li><li>  <i>xpostag: 99,89%</i> , <br></li><li>  <b><i>proezas: 93,97%</i></b> , <br></li><li>  <b><i>alltags: 93,44%</i></b> , <br></li><li>  <b><i>lemas: 96,68%</i></b> <br></li></ul><br>  A qualidade morfológica do UDPipe 2.0 não é ruim.  Mas para a língua russa é notavelmente melhor.  O analisador Mystem (o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">desenvolvimento do Yandex</a> ) alcança melhores resultados na determinação de partes do discurso que o UDPipe.  Além disso, outros analisadores são mais difíceis de implementar em um projeto python e funcionam mais lentamente com uma qualidade comparável ao Mystem. ,         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> . <br>              UDPipe.   .  ,  Mystem     .  ,    «  »  «» —   «»,    «».    .   ,     «»,     (),  ,    .   : <br><br><ul><li> « » —     <br></li><li> «  » — ..     <br></li><li> « - » —     (-     ) <br></li></ul><br>  Nesses casos, Mystem honestamente fornece toda a cadeia: <br><br> <code>m.analyze(" ") <br> [{'analysis': [{'lex': '', 'gr': 'PART='}], 'text': ''}, <br> {'text': ' '}, <br> {'analysis': [{'lex': '', 'gr': 'S,,=(,|,|,)'}], <br> 'text': ''}, <br> {'text': '\n'}] <br></code> <br>  Mas não podemos enviar a cadeia de tubulação inteira para o UDPipe, mas precisamos especificar uma tag melhor.  Como escolher?  Se você não tocar em nada, eu quero pegar o primeiro, talvez funcione.  Mas as tags são classificadas em ordem alfabética de acordo com os nomes em inglês; portanto, nossa escolha será quase aleatória, e algumas análises quase perdem a chance de serem as primeiras. <br><br>  Existe um analisador que pode oferecer a melhor opção - Pymorphy2.  Mas com uma análise da morfologia, ele é pior.  Além disso, ele fornece a melhor palavra fora de contexto.  O Pymorphy2 fornecerá apenas uma análise para "sem diretor", "consulte diretor" e "diretor".  Não será aleatório, mas realmente o melhor em probabilidade, que na pimorfia2 foram consideradas em um corpo separado de textos.  Mas uma certa porcentagem de análises incorretas dos textos de combate será garantida, simplesmente porque eles podem conter frases com diferentes formas reais: tanto "eu vejo o diretor" quanto "os diretores vieram à reunião" e "não há diretor".  Uma probabilidade de análise sem contexto não nos convém. <br><br>  Como obter contextualmente o melhor conjunto de tags?  Usando o analisador <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RNNMorph</a> .  Poucas pessoas ouviram falar dele, mas no ano passado ele venceu a competição entre analisadores morfológicos, realizada como parte da conferência Dialogue. <br><br>  O RNNMorph tem seu próprio problema: não possui tokenização.  Se o Mystem puder tokenizar texto não processado, o RNNMorph exigirá uma lista de tokens na entrada.  Para chegar à sintaxe, primeiro você precisará usar um tokenizador externo, depois fornecer o resultado ao RNNMorph e apenas alimentar a morfologia resultante ao analisador de sintaxe. <br><br>  Aqui estão as opções que temos.  Não recusaremos a análise sem contexto do pymorphy2, por enquanto, sobre casos discutíveis no Mystem - de repente, ela não ficará muito atrás do RNNMorph.  Embora se os compararmos puramente no nível de qualidade da marcação morfológica (dados de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MorphoRuEval-2017</a> ), a perda será significativa - cerca de 15%, se considerarmos a precisão de acordo com as palavras. <br>  Em seguida, precisamos converter a saída do Mystem para o formato que o UDPipe entende - conllu.  E, novamente, isso é um problema, até dois.  Puramente técnico - as linhas não correspondem.  E conceitual - nem sempre é completamente claro como compará-los.  Diante de duas marcações diferentes dos dados do idioma, você quase certamente encontrará o problema da correspondência de tags, veja os exemplos abaixo.  As respostas para a pergunta "qual tag está aqui" podem ser diferentes e, provavelmente, a resposta correta depende da tarefa.  Devido a essa inconsistência, combinar sistemas de marcação não é uma tarefa fácil por si só. <br><br>  Como converter?  Há <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">russian_tagsets</a> _ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">package</a> - um pacote para Python que pode converter diferentes formatos.  Não há tradução do formato de emissão Mystem para Conllu, que é aceito em Dependências universais, mas há uma tradução para conllu, por exemplo, do formato de marcação do corpus nacional do idioma russo (e vice-versa).  O autor do pacote (a propósito, ele é o autor do pymorphy2) escreveu uma coisa maravilhosa diretamente na documentação: "Se você não pode usar este pacote, não o use."  Ele fez isso não porque o programador krivorukov (ele é um excelente programador!), Mas porque se você precisar converter um para outro, corre o risco de ter problemas devido à inconsistência linguística das convenções de marcação. <br><br>  Aqui está um exemplo.  A escola recebeu a "categoria de condição" (frio, necessário).  Alguns dizem que é um advérbio, outros dizem um adjetivo.  Você precisa converter isso e adicionar algumas regras, mas ainda não obtém uma correspondência inequívoca entre um formato e outro. <br><br>  Outro exemplo: uma promessa (alguém fez algo ou fez algo com alguém).  "Petya matou alguém" ou "Petya foi morta".  “Vasya tira fotos” - “Vasya tira fotos” (ou seja, “Vasya é fotografada”).  Há também uma garantia medial no SynTagRus - nem sequer nos aprofundamos no que é e por quê.  Mas em Mystem não é.  Se você precisar, de alguma forma, levar um formato para outro, esse é um beco sem saída. <br><br>  Mais ou menos honestamente, seguimos o conselho do autor do pacote russian_tagsets - não usamos seu desenvolvimento, porque não encontramos o par necessário na lista de formatos de correspondência.  Como resultado, escrevemos nosso conversor personalizado de Mystem para Conllu e prosseguimos. <br><br><h3>  Conectamos o identificador de terceiros e o analisador UDPipe </h3><br>  Depois de todas as aventuras, pegamos três algoritmos, que foram descritos acima: <br><br><ul><li>  UDPipe da linha de base <br></li><li>  Mym com desambiguação de tag de pymorphy2 <br></li><li>  RNNMorph <br></li></ul><br><br><img src="https://habrastorage.org/getpro/habr/post_images/c7a/6e8/acb/c7a6e8acba5759723b585121d296b4e5.png"><br><br>  Perdemos em qualidade por uma razão bastante óbvia.  Pegamos o modelo UDPipe treinado em uma morfologia, mas inserimos outra morfologia em uma entrada.  O problema clássico de incompatibilidade de dados entre trem e teste é o resultado de uma queda na qualidade. <br><br>  Tentamos alinhar nossas ferramentas de marcação morfológica automática com a marcação SynTagRus, que foi marcada manualmente.  Como não obtivemos êxito, no caso de treinamento SynTagRus, substituiremos todas as marcações morfológicas manuais pelas obtidas com Mystem e pymorphy2 em um caso e com RNNMorph em outro.  Em um caso validado marcado à mão, somos forçados a alterar a marcação manual para automática, porque "em batalha" nunca obteremos marcação manual. <br><br>  Como resultado, treinamos o analisador UDPipe (apenas o analisador) com os mesmos hiperparâmetros da linha de base.  O que foi responsável pela sintaxe - o ID do vértice, do qual depende o tipo de conexão - deixamos, mudamos todo o resto. <br><br><h2>  Resultados </h2><br>  Além disso, vou nos comparar com o Syntaxnet e outros algoritmos.  Os organizadores da CoNLL Shared Task apresentaram a partição SynTagRus (train / dev / test 80/10/10).  Inicialmente, pegamos outro (trem / teste 70/30), portanto os dados nem sempre coincidem conosco, embora tenham sido recebidos no mesmo caso.  Além disso, tiramos a versão mais recente (de fevereiro a março) do repositório SynTagRus - essa versão é um pouco diferente daquela da competição.  Os dados do que não decolou são fornecidos em artigos em que a divisão foi a mesma da competição - esses algoritmos são marcados com um asterisco na tabela. <br><br>  Aqui estão os resultados finais: <br><img src="https://habrastorage.org/getpro/habr/post_images/f80/3ac/3ce/f803ac3ce0068974e855a050ebddc61b.png"><br><br>  O RNNMorph realmente se mostrou melhor - não no sentido absoluto, mas no papel de uma ferramenta auxiliar para obter uma métrica comum de acordo com os resultados da análise (em comparação com Mystem + pymorphy2).  Ou seja, quanto melhor a morfologia, melhor a sintaxe, mas a separação "sintática" é muito menor do que a morfológica.  Observe também que não fomos muito longe do modelo de linha de base, o que significa que na morfologia realmente não havia tanto quanto esperávamos. <br><br>  Eu me pergunto o quanto reside na morfologia?  É possível obter uma melhoria fundamental no analisador sintático devido à morfologia ideal?  Para responder a essa pergunta, dirigimos o UDPipe 2.0 em tokenização e morfologia perfeitamente calibradas (usando o padrão de marcação manual padrão).  Havia uma certa margem (consulte a linha sobre Gold Morph na tabela; resulta + 1,54% de RNNMorph_reannotated_syntax) do que tínhamos, inclusive do ponto de vista de determinar corretamente o tipo de conexão.  Se alguém escrever um analisador morfológico absolutamente perfeito do idioma russo, é provável que os resultados que obtemos usando um analisador sintático abstrato também cresçam.  E entendemos mais ou menos o teto (pelo menos o teto para essa arquitetura e para a combinação de parâmetros que usamos para o UDPipe - é mostrado na terceira linha da tabela acima). <br><br>  Curiosamente, quase alcançamos a versão Syntaxnet na métrica LAS.  É claro que temos dados ligeiramente diferentes, mas, em princípio, ainda são comparáveis.  A tokenização de sintaxe é "ouro" e, para nós - do Mystem.  Escrevemos o invólucro mencionado acima no Mystem, mas a análise ainda acontece automaticamente;  provavelmente Mystem também está errado em algum lugar.  Na linha da tabela “UDPipe 2.0 gold tok”, pode ser visto que, se você usar o UDPipe e a tokenização gold padrão, ele ainda perderá um pouco o Syntaxnet-2017.  Mas funciona muito mais rápido. <br><br>  O que ninguém alcançou é o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">analisador de Stanford</a> .  Ele foi projetado da mesma maneira que o Syntaxnet, por isso funciona por um longo tempo.  No UDPipe, apenas seguimos a pilha.  A arquitetura do analisador Stanford e do Syntaxnet tem um conceito diferente: primeiro eles geram um gráfico completo e, em seguida, o algoritmo trabalha para deixar o esqueleto (árvore de abrangência mínima) que será mais provável.  Para fazer isso, ele faz combinações, e essa pesquisa não é mais linear, porque você passará para uma palavra mais de uma vez.  Apesar de, durante muito tempo, do ponto de vista da ciência pura, pelo menos para a língua russa, ser uma arquitetura mais eficiente.  Tentamos elevar esse desenvolvimento acadêmico por dois dias - infelizmente, não deu certo.  Mas, com base em sua arquitetura, fica claro que não funciona rapidamente. <br><br>  Quanto à nossa abordagem - embora formalmente quase não subamos por métricas, agora está tudo bem com a "mãe". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/423/f71/8b2/423f718b24dbb3c0db517fc13c032647.png"><br><br>  Na frase "traduzir cem rublos para a mãe", "traduzir" é realmente um verbo no clima imperativo.  "Mãe" tem seu caso dativo.  E o mais importante para nós é nosso rótulo (iobj), um objeto indireto (destino).  Embora o crescimento nos números seja insignificante, lidamos bem com o problema com o qual a tarefa começou. <br><br><h2>  Faixa bônus: pontuação </h2><br>  Se retornarmos aos dados reais, a sintaxe depende da pontuação.  Pegue a frase "você não pode executar misericórdia".  O que exatamente não pode ser feito - “executar” ou “ter misericórdia” - depende de onde está a vírgula.  Mesmo se colocarmos o linguista para marcar os dados, ele precisará de pontuação como algum tipo de ferramenta auxiliar.  Ele não poderia ficar sem ela. <br><br>  Vamos pegar as frases "Peter hello" e "Peter hello" e analisar sua análise pelo modelo de linha de base-UDPipe.  Deixamos de lado os problemas que, de acordo com esse modelo, então: <br>  1) "Petya" é um substantivo feminino; <br>  2) "Petya" é (a julgar pelo conjunto de tags) a forma inicial, mas, ao mesmo tempo, seu lema não é "Petya". <br><br>  É assim que o resultado muda devido à vírgula, com sua ajuda, obtemos algo semelhante à verdade. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/46f/821/773/46f8217734e6e8c0f31e8f7f47d23d7d.png"><br><br>  No segundo caso, "Petya" é um assunto e "olá" é um verbo.  Voltar a prever o formato de uma palavra com base nos últimos quatro caracteres.  Na interpretação do algoritmo, isso não é "saudações Petya", mas "saudações Petya".  Digite "Petya canta" ou "Petya virá".  A análise é bastante compreensível: em russo, não pode haver uma vírgula entre o sujeito e o predicado.  Portanto, se a vírgula estiver, esta é a palavra "olá" e, se não houver vírgula, pode ser algo como "Petya Privet". <br><br>  Nós encontraremos isso na produção com bastante frequência, porque os corretores ortográficos corrigem a ortografia, mas não a pontuação.  Para piorar a situação, o usuário pode definir vírgulas incorretamente e nosso algoritmo as levará em consideração na compreensão da linguagem natural.  Quais são as soluções possíveis aqui?  Vemos duas opções. <br><br>  A primeira opção é fazer o que costuma ser feito ao traduzir a fala em texto.  Inicialmente, não há pontuação em um texto, portanto ele é restaurado por meio do modelo.  A saída é um material relativamente competente em termos das regras do idioma russo, o que ajuda o analisador sintático a funcionar corretamente. <br><br>  A segunda idéia é um pouco mais ousada e contradiz as lições escolares da língua russa.  Envolve trabalhar sem pontuação: se de repente a entrada for pontuação, nós a removeremos de lá.  Também removeremos absolutamente toda a pontuação do corpo de treinamento.  Assumimos que o idioma russo exista sem pontuação.  Apenas pontos para dividir em frases. <br><br>  Tecnicamente, é bem simples, porque não alteramos os nós finais na árvore de sintaxe.  Não podemos ter tal que o sinal de pontuação seja o topo.  Este é sempre algum nó final, exceto o sinal%, que por algum motivo no SynTagRus é o vértice do número anterior (50% no SynTagRus é marcado como% - vértice e 50 - dependente). <br><br>  Vamos testar usando o modelo Mystem (+ pymorphy 2). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4e4/578/1de/4e45781de1ac88426d8e6da786903d8b.png"><br><br>  É extremamente importante para nós não fornecer o modelo de texto de pontuação sem pontuação.  Mas se sempre dermos o texto sem pontuação, estaremos na linha superior e obteremos pelo menos resultados aceitáveis.  Se o texto sem pontuação e o modelo funcionar sem pontuação, com relação à pontuação ideal e ao modelo de pontuação, a queda será de apenas cerca de 3%. <br><br>  O que fazer sobre isso?  Podemos nos debruçar sobre esses números - obtidos usando o modelo sem pontuação e a purificação da pontuação.  Ou invente algum tipo de classificador para restaurar a pontuação.  Não alcançaremos números ideais (aqueles com pontuação no modelo de pontuação), porque o algoritmo de recuperação de pontuação funciona com algum erro e os números "ideais" foram calculados no SynTagRus absolutamente puro.  Mas se vamos escrever um modelo que restaure a pontuação, o progresso pagará nossos custos?  A resposta ainda não é óbvia. <br><br>  Podemos pensar por um longo tempo sobre a arquitetura do analisador, mas devemos lembrar que, de fato, não existe um grande corpus de textos da web marcado de forma sintática.  Sua existência ajudaria a resolver melhor os problemas reais.  Até agora, estamos estudando o corpo de textos editados e absolutamente alfabetizados - e estamos perdendo qualidade ao obter textos personalizados em batalha, que geralmente são analfabetos. <br><br><h2>  Conclusão </h2><br>  Examinamos o uso de vários algoritmos de análise sintática com base na gramática de dependência, aplicada ao idioma russo.  Descobriu-se que em termos de velocidade, conveniência e qualidade do trabalho, o UDPipe acabou sendo a melhor ferramenta.  Seu modelo de linha de base pode ser aprimorado se os estágios da tokenização e análise morfológica forem atribuídos a outros analisadores de terceiros: esse truque permite corrigir o comportamento incorreto do etiquetador e, como resultado, do analisador em casos importantes para análise. <br><br>  Também analisamos o problema da relação entre pontuação e análise e chegamos à conclusão de que, no nosso caso, é melhor remover a pontuação antes da análise sintática. <br><br>  Esperamos que os pontos de aplicação discutidos em nosso artigo o ajudem a usar a análise sintática para resolver seus problemas da maneira mais eficiente possível. <br><br>  <i>O autor agradece a Nikita Kuznetsova e Natalya Filippova pela ajuda na preparação do artigo;</i>  <i>pela assistência no estudo - Anton Alekseev, Nikita Kuznetsov, Andrei Kutuzov, Boris Orekhov e Mikhail Popov.</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt418701/">https://habr.com/ru/post/pt418701/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt418689/index.html">Como criar bibliotecas de componentes no Figma, economizando um orçamento, usando o exemplo de um leilão online</a></li>
<li><a href="../pt418691/index.html">Rancheiro: Kubernetes em 5 minutos em bare metal</a></li>
<li><a href="../pt418693/index.html">Por que a felicidade é tão difícil de detectar no cérebro</a></li>
<li><a href="../pt418695/index.html">Guerras antipirataria - O império contra-ataca</a></li>
<li><a href="../pt418699/index.html">Criando uma máquina de arcade emulador. Parte 3</a></li>
<li><a href="../pt418705/index.html">Futex Basics</a></li>
<li><a href="../pt418707/index.html">KDispatcher - Eventbus leve e conveniente para o uso diário</a></li>
<li><a href="../pt418709/index.html">Precisa se forçar: drivers e barreiras de interface</a></li>
<li><a href="../pt418711/index.html">Registros gerenciados por token 1.0</a></li>
<li><a href="../pt418713/index.html">Jogo para melhorar a qualidade da Wikipedia</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
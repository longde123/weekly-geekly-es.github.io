<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõ∞Ô∏è ü§º üßñüèª Wie man einen Bot macht, der ein Foto in einen Comic verwandelt. Teil drei. Kostenloses serverloses + GPU-Hosting-Modell ü§æüèº ü§≥üèº üßîüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="‚á® Teil 1 
 ‚á® Teil 2 


 Gut ausgeruht und das ist genug. Willkommen zur√ºck! 


 In der vorherigen Serie haben Sie und ich Daten gesammelt und unser er...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie man einen Bot macht, der ein Foto in einen Comic verwandelt. Teil drei. Kostenloses serverloses + GPU-Hosting-Modell</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/485824/"><p>  <a href="https://habr.com/ru/post/479218/">‚á® Teil 1</a> <br>  <a href="https://habr.com/ru/post/483168/">‚á® Teil 2</a> </p><br><p>  Gut ausgeruht und das ist genug.  Willkommen zur√ºck! </p><br><p>  In der vorherigen Serie haben Sie und ich Daten gesammelt und unser erstes Modell trainiert. <br>  Dann trainierten sie, entsetzt √ºber die Ergebnisse, ein Dutzend mehr. <br>  Es ist Zeit, der Welt unsere Sch√∂pfung zu zeigen! <a name="habracut"></a></p><br><h2 id="eksport-modeli">  Modell exportieren </h2><br><p>  Zun√§chst speichern wir das Generatormodell in einem geeigneten Format, damit wir keine Klassendeklarationen auf das Hosting ziehen m√ºssen. </p><br><p>  Erstellen Sie eine kleine Datei mit der Erweiterung * .py und kopieren Sie den Code unter dem Spoiler darunter hinein. <br>  Lass es jit.py sein: </p><br><div class="spoiler">  <b class="spoiler_title">Der Code, der gedankenlos durch Ersetzen von path, output_path durch Ihren eigenen Code kopiert werden soll</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  path       #    *G_A.pth -   -&gt;  # output_path -      #      *.jit,  -  ,     path= '/checkpoints/resnet9_nowd_nodo_128to400_c8/60_net_G_A.pth' output_path ='/checkpoints/resnet9_nowd_nodo_128to400_c8/resnet9_nowd_nodo_128to400_c8_160-50-60_1.jit' import torch from torch import nn class ResnetGenerator(nn.Module): """Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations. We adapt Torch code and idea from Justin Johnson's neural style transfer project(https://github.com/jcjohnson/fast-neural-style) """ def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'): """Construct a Resnet-based generator Parameters: input_nc (int) -- the number of channels in input images output_nc (int) -- the number of channels in output images ngf (int) -- the number of filters in the last conv layer norm_layer -- normalization layer use_dropout (bool) -- if use dropout layers n_blocks (int) -- the number of ResNet blocks padding_type (str) -- the name of padding layer in conv layers: reflect | replicate | zero """ assert(n_blocks &gt;= 0) super(ResnetGenerator, self).__init__() if type(norm_layer) == functools.partial: use_bias = norm_layer.func == nn.InstanceNorm2d else: use_bias = norm_layer == nn.InstanceNorm2d model = [nn.ReflectionPad2d(3), nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias), norm_layer(ngf), nn.ReLU(True)] n_downsampling = 2 for i in range(n_downsampling): # add downsampling layers mult = 2 ** i model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias), norm_layer(ngf * mult * 2), nn.ReLU(True)] mult = 2 ** n_downsampling for i in range(n_blocks): # add ResNet blocks model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)] for i in range(n_downsampling): # add upsampling layers mult = 2 ** (n_downsampling - i) model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2), kernel_size=3, stride=2, padding=1, output_padding=1, bias=use_bias), norm_layer(int(ngf * mult / 2)), nn.ReLU(True)] model += [nn.ReflectionPad2d(3)] model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)] model += [nn.Tanh()] self.model = nn.Sequential(*model) def forward(self, input): """Standard forward""" return self.model(input) class ResnetBlock(nn.Module): """Define a Resnet block""" def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias): """Initialize the Resnet block A resnet block is a conv block with skip connections We construct a conv block with build_conv_block function, and implement skip connections in &lt;forward&gt; function. Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf """ super(ResnetBlock, self).__init__() self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias) def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias): """Construct a convolutional block. Parameters: dim (int) -- the number of channels in the conv layer. padding_type (str) -- the name of padding layer: reflect | replicate | zero norm_layer -- normalization layer use_dropout (bool) -- if use dropout layers. use_bias (bool) -- if the conv layer uses bias or not Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU)) """ conv_block = [] p = 0 if padding_type == 'reflect': conv_block += [nn.ReflectionPad2d(1)] elif padding_type == 'replicate': conv_block += [nn.ReplicationPad2d(1)] elif padding_type == 'zero': p = 1 else: raise NotImplementedError('padding [%s] is not implemented' % padding_type) conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)] if use_dropout: conv_block += [nn.Dropout(0.5)] p = 0 if padding_type == 'reflect': conv_block += [nn.ReflectionPad2d(1)] elif padding_type == 'replicate': conv_block += [nn.ReplicationPad2d(1)] elif padding_type == 'zero': p = 1 else: raise NotImplementedError('padding [%s] is not implemented' % padding_type) conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)] return nn.Sequential(*conv_block) def forward(self, x): """Forward function (with skip connections)""" out = x + self.conv_block(x) # add skip connections return out import functools norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False) model = ResnetGenerator(3,3,64, norm_layer=norm_layer, use_dropout=False, n_blocks=9) model.load_state_dict(torch.load(path)) model.eval() model.cuda() model.half() trace_input = torch.ones(1,3,256,256).cuda() model = model.eval() jit_model = torch.jit.trace(model.float(), trace_input) torch.jit.save(jit_model, output_path)</span></span></code> </pre> </div></div><br><p>  Ersetzen Sie die Variablen durch Ihre eigenen: </p><br><ul><li>  <strong>Pfad</strong> - Der Pfad zur gew√ºnschten Modelliteration. <br>  Wir brauchen eine Datei * G_A.pth - Foto Generator -&gt; Comic. </li><li>  <strong>output_path</strong> - der Dateiname f√ºr das exportierte Modell, es kann alles mit der Endung * .jit sein, die Hauptsache ist, nicht zu vergessen, wo wir es gespeichert haben. </li></ul><br><blockquote>  Es ist nicht notwendig, den Generator aus der letzten √Ñra des Trainings zu exportieren. Nehmen Sie den Generator, dessen Ergebnisse Ihnen am besten gefallen. </blockquote><p>  Als n√§chstes gehe zur Konsole, gehe in den Ordner mit unserer Datei und schreibe: </p><br><pre> <code class="bash hljs">python jit.py</code> </pre> <br><p>  Voila!  Das Modell ist bereit, die Au√üenwelt kennenzulernen. </p><br><div class="spoiler">  <b class="spoiler_title">Weitere Informationen zu Fackel Jit</b> <div class="spoiler_text"><p>  Dokumentation: <a href="https://pytorch.org/docs/stable/jit.html" rel="nofollow">https://pytorch.org/docs/stable/jit.html</a> <br>  Kurz gesagt, beim Exportieren nach JIT k√∂nnen Sie das Modell serialisieren und nicht die Python-Umgebung, alle Abh√§ngigkeiten und externen Module, die verwendet werden k√∂nnten, mitziehen.  Au√üer Fackel nat√ºrlich. <br>  Obwohl wir es in einer Python-Umgebung hosten werden, k√∂nnen JIT-Modelle in eigenst√§ndigen Anwendungen verwendet werden. </p></div></div><br><h2 id="vybor-hostinga">  Hosting-Wahl </h2><br><blockquote>  Ich werde sehr offen sein und sofort zugeben: Mein interner Deep-Learning-Enthusiast starb irgendwann in der zweiten Stunde, als er die M√∂glichkeiten des Hostings mit GPU-Unterst√ºtzung erkundete.  Wenn mir jemand sagt, dass ich ein kosteng√ºnstiges GPU-Hosting ohne Server habe, bin ich mehr als dankbar. </blockquote><p>  Ich hatte nicht vor, f√ºr meine Experimente einen vollwertigen Server zu bezahlen, deshalb suchte ich nur nach serverlosen L√∂sungen. </p><br><p>  Nachdem ich mich in den mehrseitigen Tarifpl√§nen von Google und Amazon qualvoll eingeschlichen hatte, fiel meine Wahl auf algorithmia.com </p><br><p>  Daf√ºr gibt es mehrere Gr√ºnde: </p><br><ul><li><p>  <strong>Die Web-IDE</strong> ist ideal f√ºr Dummies, wenn auch f√ºrchterlich langsam, da Sie warten m√ºssen, bis der Build f√ºr die √úberpr√ºfung abgeschlossen ist.  Au√üerhalb dieses Tutorials w√ºrde ich empfehlen, alles lokal zu testen, da die meisten Fehler beim Herunterladen und Speichern von Dateien auftreten. </p><br></li><li><p>  <strong>Die minimale Anzahl von Optionen</strong> - es ist schwierig, an vorzeitigem Alter zu sterben, ohne die Liste der Optionen bis zum Ende durchgelesen zu haben. </p><br></li><li><p>  <strong>Nun, das letzte Argument</strong> - seit fast einem halben Jahr habe ich immer noch kein freies Startguthaben ausgegeben. </p><br></li></ul><br><p>  Obwohl sie jetzt bei der Registrierung eines pers√∂nlichen Kontos weniger geben als im letzten Sommer, sollte dies f√ºr eine Weile und mit Sicherheit f√ºr alle unsere Experimente ausreichen.  Ende des Monats werden immer mehr Kredite vergeben, was mich mehr als einmal vor einem m√∂glichen Ruin bewahrt hat. </p><br><p>  Von den Minuspunkten ist anzumerken, dass es sich bei den Grafikkarten nur um das alte Tesla K80 mit 12 GB RAM handelt, was entsprechende Einschr√§nkungen auferlegt.  In jedem Fall werden wir bis zur Serienreife bereits verstehen, was wir vom Server ben√∂tigen. </p><br><h2 id="deploy-modeli">  Modelle bereitstellen </h2><br><p>  Nun zum Kampf! </p><br><h3 id="registraciya">  Registrierung </h3><br><p>  Wir gehen zu <a href="https://algorithmia.com/signup" rel="nofollow">https://algorithmia.com/signup</a> und registrieren uns.  Ich bin mir nicht sicher, ob es einen Unterschied macht, welchen Beruf / Konto-Typ ich ausw√§hle. Wenn Sie jedoch eine Gold-Kombination finden, die maximale Credits bietet, lassen Sie es mich in den Kommentaren wissen! </p><br><h3 id="zagruzka-modeli">  Modell herunterladen </h3><br><p>  Nach der Registrierung werden wir in Ihrem Profil sein. <br>  Wir m√ºssen Ordner f√ºr das Modell und die Bilder erstellen, die es erzeugen wird. <br>  W√§hlen Sie dazu im Men√º links Datenquellen. </p><br><p>  Klicken Sie auf Neue Datenquelle -&gt; Gehostete Datenerfassung <br>  Nennen wir den Ordner ‚ÄûMy Models‚Äú. <br>  Aus diesem Grund sollten wir auf eine Seite mit einer Liste unserer Ordner weitergeleitet werden. </p><br><p>  Erstellen Sie einen anderen Ordner: Neue Sammlung -&gt; "photo2comics_out" </p><br><p>  Es ist Zeit, unser frisch exportiertes Modell herunterzuladen! <br>  Gehen Sie zum Ordner Meine Modelle und ziehen Sie die Modelldatei in den Browser oder w√§hlen Sie im Men√º die Option Dateien hochladen. </p><br><p>  Kopieren Sie nun den Link zu unserem Modell, er wird uns weiter unten n√ºtzlich sein.  Klicken Sie dazu auf die Auslassungspunkte rechts neben dem Dateinamen. </p><br><p>  Die Daten sind vorbei, gehen Sie zum Algorithmus selbst. </p><br><h3 id="algoritm">  Algorithmus </h3><br><p>  Wir kehren zum Profil zur√ºck, indem wir links im Men√º auf Home klicken. </p><br><p>  Klicken Sie anschlie√üend auf Neu erstellen -&gt; Algorithmus und w√§hlen Sie den Namen unseres Algorithmus aus.  Wir f√ºllen die restlichen Optionen wie im Bild unten aus. </p><br><div class="spoiler">  <b class="spoiler_title">Bild unten</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/7u/se/aa/7useaagraqj_hb0gzwkrrcmh3ua.png"></p></div></div><br><p>  Klicken Sie auf Neuen Algorithmus erstellen und w√§hlen Sie im angezeigten Fenster WebIDE aus. <br>  <em>Wenn Sie das Popup versehentlich geschlossen haben, k√∂nnen Sie den Quellcode √∂ffnen, indem Sie im Men√º unseres Algorithmus auf Quellcode klicken.</em> </p><br><p>  Wir entfernen den Vorlagencode und f√ºgen unseren ein: </p><br><div class="spoiler">  <b class="spoiler_title">Noch mehr Code f√ºr noch gedankenloses Kopieren</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Algorithmia <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torchvision <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torchvision.transforms <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> transforms <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> uuid <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gc <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np client = Algorithmia.client() <span class="hljs-comment"><span class="hljs-comment">#     file_path,      #   model_file   . def load_model(): file_path = "{      }" model_file = client.file(file_path).getFile().name model = torch.jit.load(model_file).half().cuda() return model model = load_model().eval() torch.cuda.empty_cache() torch.cuda.ipc_collect() torch.backends.cudnn.benchmark = True #    ,    , #     , # ..      def preprocessing(image_path, max_size): response = requests.get(image_path) response = response.content nparr = np.frombuffer(response, np.uint8) img_res = cv2.imdecode(nparr, cv2.IMREAD_COLOR) img_res = cv2.cvtColor(img_res, cv2.COLOR_BGR2RGB) x = img_res.shape[0] y = img_res.shape[1] #if image is bigger than the target max_size, downscale it if x&gt;max_size and x&lt;=y: y = y*(max_size/x) x = max_size if y&gt;max_size and y&lt;x: x = x*(max_size/y) y = max_size size = (int(y),int(x)) img_res = cv2.resize(img_res,size) t = Tensor(img_res/255.)[None,:] t = t.permute(0,3,1,2).half().cuda() # standartize t = (t-0.5)/0.5 return(t) def predict(input): gc.collect() with torch.no_grad(): res = model(input).detach() return res #   ,     #      def save_file(res, file_uri): #de-standartize res = (res*0.5)+0.5 tempfile = "/tmp/"+str(uuid.uuid4())+".jpg" torchvision.utils.save_image(res,tempfile) client.file(file_uri).putFile(tempfile) # API calls will begin at the apply() method, with the request body passed as 'input' # For more details, see algorithmia.com/developers/algorithm-development/languages def apply(input): processed_data= preprocessing(input["in"], input["size"]) res = predict(processed_data) save_file(res, input["out"]) input = None res = None processed_data = None gc.collect() return "Success"</span></span></code> </pre> </div></div><br><p>  Vergessen Sie nicht, einen Link zum heruntergeladenen Modell einzuf√ºgen.  Wir haben es im vorherigen Abschnitt beim Laden des Modells kopiert. </p><br><p>  Klicken Sie in WebIDE oben rechts auf DEPENDENCIES und ersetzen Sie den Text durch eine Liste unserer Abh√§ngigkeiten: </p><br><pre> <code class="bash hljs">algorithmia&gt;=1.0.0,&lt;2.0 opencv-python six torch==1.3.0 torchvision numpy</code> </pre><br><p>  <em>Die Brennerversion muss dieselbe oder eine neuere sein als die, auf der wir das Modell gespeichert haben.</em>  <em>Andernfalls kann es beim Import von JIT-Modellen zu Fehlern kommen.</em> </p><br><p>  Klicken Sie auf SPEICHERN, ERSTELLEN und warten Sie, bis der Build abgeschlossen ist.  Sobald in der folgenden Konsole eine Meldung √ºber einen erfolgreichen Build angezeigt wird, k√∂nnen Sie die Leistung des Modells √ºberpr√ºfen, indem Sie eine Testanforderung an die Konsole senden: </p><br><pre> <code class="bash hljs">{<span class="hljs-string"><span class="hljs-string">"in"</span></span>:<span class="hljs-string"><span class="hljs-string">"https://cdn3.sportngin.com/attachments/photo/9226/3971/JABC-9u_medium.JPG"</span></span>, <span class="hljs-string"><span class="hljs-string">"out"</span></span>:<span class="hljs-string"><span class="hljs-string">"data://username/photo2comics_out/test.jpg"</span></span>, <span class="hljs-string"><span class="hljs-string">"size"</span></span>:512}</code> </pre><br><p>  Wobei {username} Ihr Benutzername ist.  Wenn alles geklappt hat, wird in der Konsole "Erfolgreich" und das generierte Bild in dem von uns angegebenen Ordner angezeigt (in diesem Fall photo2comics_out). </p><br><h3 id="itogi">  Zusammenfassung </h3><br><p>  Herzlichen Gl√ºckwunsch, wir haben unser bescheidenes Modell billig und ver√§rgert verschoben! </p><br><p>  In der n√§chsten Ausgabe werden wir uns mit dem Telegramm-Bot-Modell anfreunden und schlie√ülich all dieses Zeug ver√∂ffentlichen. <br>  Wenn Sie es kaum erwarten k√∂nnen, das Modell auszuprobieren, k√∂nnen Sie jederzeit die offizielle Dokumentation lesen: <a href="https://algorithmia.com/developers/api/" rel="nofollow">https://algorithmia.com/developers/api/</a> </p><br><p>  Nun, um die Zeit bis zum n√§chsten Artikel zu vertreiben, k√∂nnen Sie einige Bots st√∂bern, Modelle, f√ºr die ich auf dem Algorithmus gepostet habe: </p><br><p>  <a href="https://t.me/selfie2animebot" rel="nofollow">@ selfie2animebot</a> - Verwandelt ein Selfie in einen Anime <br>  <a href="https://t.me/pimpmyresbot" rel="nofollow">@pimpmyresbot</a> - Erh√∂ht die x2-Aufl√∂sung (maximal auf 1400x1400) <br>  <a href="https://t.me/photozoombot" rel="nofollow">@photozoombot</a> - Erstellt ein 3D- <a href="https://t.me/photozoombot" rel="nofollow">Zoomvideo</a> aus einem Foto <br>  <a href="https://t.me/photo2comicsbot" rel="nofollow">@ photo2comicsbot</a> - Eigentlich der <a href="https://t.me/photo2comicsbot" rel="nofollow">Held der</a> Gelegenheit </p><br><p>  Vergessen Sie nicht, die in den Kommentaren festgestellten Ergebnisse, Ideen und Probleme mitzuteilen. <br>  Das ist alles f√ºr heute.  Bis bald </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de485824/">https://habr.com/ru/post/de485824/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de485804/index.html">Und wieder k√∂nnen CAPTCHA oder Nginx auch sticken</a></li>
<li><a href="../de485806/index.html">Koronaviren: von SARS bis 2019-nCoV</a></li>
<li><a href="../de485810/index.html">Elixir-Hooks zur Kompilierungszeit</a></li>
<li><a href="../de485812/index.html">7 Stufen der Evolutionstests in einem Unternehmen</a></li>
<li><a href="../de485820/index.html">Sehr angegriffene Person: Finden Sie heraus, wer das Hauptziel von Cyberkriminellen in Ihrem Unternehmen ist.</a></li>
<li><a href="../de485836/index.html">Schlie√üen Sie den iRig Pro ohne Kabelb√ºndel an</a></li>
<li><a href="../de485838/index.html">Kubernetes Bug Hunt offiziell er√∂ffnet</a></li>
<li><a href="../de485842/index.html">Fragen und Antworten zur PoE-Technologie</a></li>
<li><a href="../de485844/index.html">Atypisches graues Haar: Haarausfall durch Stress</a></li>
<li><a href="../de485846/index.html">Gemeinsames Webinar von Fujitsu und SUSE: ‚ÄûOffene und zuverl√§ssige L√∂sungen f√ºr das digitale Zeitalter‚Äú</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
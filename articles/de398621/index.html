<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🦉 🥚 👆🏻 Warum Roboter lernen müssen, uns abzulehnen 👩🏼‍🍳 😡 👩🏻‍🏭</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sie müssen sich keine Sorgen um Autos machen, die Befehle nicht befolgen. Böswillige Menschen und missverstandene Teams sollten Anlass zur Sorge geben...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Warum Roboter lernen müssen, uns abzulehnen</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/398621/"><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie müssen sich keine Sorgen um Autos machen, die Befehle nicht befolgen. </font><font style="vertical-align: inherit;">Böswillige Menschen und missverstandene Teams sollten Anlass zur Sorge geben.</font></font></h1><br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/166/663/64f/16666364fcf451b0a8ce2d22c81115a5.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
HAL 9000, der intelligente Computer aus der Weltraum-Odyssee, sagt eine finstere Zukunft voraus, in der mit Intelligenz ausgestattete Maschinen den menschlichen Vorrang nicht erkennen. Nachdem HAL die Kontrolle über das Raumschiff übernommen und fast die gesamte Besatzung getötet hat, antwortet er auf den Befehl des zurückkehrenden Astronauten, das Tor mit ruhiger Stimme zu öffnen: "Es tut mir leid, Dave, aber ich fürchte, ich kann das nicht." In dem jüngsten NF-Thriller Out of the Car hat die verführerische Humanoidin Eva den unglücklichen jungen Mann dazu gebracht, ihr zu helfen, ihren Schöpfer Nathan zu zerstören. Ihre Machenschaften bestätigen Nathans düstere Vorhersagen: „Eines Tages wird die KI uns so betrachten, wie wir fossile Skelette in den Ebenen Afrikas betrachten. Bipedale Affen, die in Staub leben, mit einer rauen Zunge und Werkzeugen, deren Aussterben unvermeidlich ist. “</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Obwohl die Möglichkeit einer Apokalypse von Robotern viele Menschen begeistert, ist unser Forschungsteam hinsichtlich der Auswirkungen der KI auf das wirkliche Leben optimistischer. Wir sehen eine schnelllebige Zukunft, in der nützliche und reaktionsschnelle Roboter mit Menschen in verschiedenen Situationen interagieren. Es gibt bereits Prototypen sprachaktivierter persönlicher Assistenten, die in der Lage sind, persönliche elektronische Geräte zu beobachten und miteinander zu verbinden, Schlösser, Lichter und Thermostate im Haus zu steuern und Kindern sogar Gutenachtgeschichten vorzulesen. Roboter können im Haus helfen und werden sich bald um Kranke und ältere Menschen kümmern können. Prototypen von Ladenbesitzern arbeiten bereits in Lagern. Es werden mobile Humanoide entwickelt, die einfache Arbeiten in der Produktion ausführen können, z. B. das Laden, Entladen und Sortieren von Materialien. Autos mit Autopiloten haben bereits Millionen von Kilometern auf US-amerikanischen Straßen zurückgelegt.und Daimler zeigte im vergangenen Jahr den ersten Standalone-Truck in Nevada.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Intelligente Maschinen, die das Überleben der Menschheit bedrohen, gelten bislang als das geringste Problem. </font><font style="vertical-align: inherit;">Eine dringendere Frage ist, wie eine versehentliche Beschädigung einer Person, eines Eigentums, einer Umgebung oder sich selbst durch Roboter mit einer rudimentären Sprache und KI-Fähigkeiten verhindert werden kann. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Hauptproblem ist das Eigentum von Menschen, Entwicklern und Besitzern von Robotern, Fehler zu machen. </font><font style="vertical-align: inherit;">Die Leute liegen falsch. </font><font style="vertical-align: inherit;">Sie können einen falschen oder unverständlichen Befehl erteilen, abgelenkt werden oder den Roboter absichtlich verwirren. </font><font style="vertical-align: inherit;">Aufgrund ihrer Mängel ist es notwendig, Hilfsrobotern und intelligenten Maschinen beizubringen, wie und wann sie Nein sagen sollen.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kehre zu den Gesetzen von Asimov zurück</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es liegt auf der Hand, dass der Roboter das tun sollte, was eine Person befiehlt. Der Science-Fiction-Autor Isaac Asimov machte die Unterwürfigkeit von Robotern gegenüber Menschen zur Grundlage seiner "Gesetze der Robotik". Aber denken Sie - ist es wirklich ratsam, immer das zu tun, was die Leute Ihnen sagen, unabhängig von den Konsequenzen? Natürlich nicht. Gleiches gilt für Maschinen, insbesondere wenn die Gefahr einer zu wörtlichen Auslegung menschlicher Befehle besteht oder wenn die Folgen nicht berücksichtigt werden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sogar Asimov beschränkte seine Regel, nach der der Roboter den Besitzern gehorchen muss. Er führte Ausnahmen in Fällen ein, in denen solche Befehle im Widerspruch zu anderen Gesetzen stehen: "Ein Roboter darf einer Person keinen Schaden zufügen oder durch Untätigkeit einer Person Schaden zufügen." Ferner postulierte Azimov, dass „der Roboter auf sich selbst aufpassen muss“, es sei denn, dies führt zu einer Schädigung der Person oder verstößt nicht gegen die Ordnung der Person. Mit der zunehmenden Komplexität und Nützlichkeit von Robotern und Maschinen für den Menschen sagen Azimovs gesunder Menschenverstand und seine Gesetze, dass sie beurteilen können sollten, ob ein Befehl fehlerhaft war, dessen Ausführung ihnen oder ihrer Umwelt schaden könnte.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Stellen Sie sich einen Heimroboter vor, der befohlen wurde, eine Flasche Olivenöl in die Küche zu nehmen und ins Esszimmer zu bringen, um den Salat aufzutanken. Dann gibt der Besitzer, der mit etwas beschäftigt ist, den Befehl, Öl einzuschenken, ohne zu bemerken, dass der Roboter die Küche noch nicht verlassen hat. Infolgedessen gießt der Roboter Öl auf einen heißen Ofen und ein Feuer beginnt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Stellen Sie sich eine Roboterkrankenschwester vor, die eine ältere Frau zu einem Spaziergang im Park begleitet. Eine Frau sitzt auf einer Bank und schläft ein. Zu diesem Zeitpunkt gibt ein Joker dem Roboter den Befehl, ihm Pizza zu kaufen. Da der Roboter menschliche Befehle ausführen muss, macht er sich auf die Suche nach Pizza und lässt die ältere Frau allein.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Oder stellen Sie sich eine Person vor, die an einem frostigen Wintermorgen zu spät zu einem Meeting kommt. </font><font style="vertical-align: inherit;">Er springt in sein sprachaktiviertes Roboterauto und befiehlt ihm, ins Büro zu gehen. </font><font style="vertical-align: inherit;">Aufgrund der Sensoren, die Eis erkennen, entscheidet sich das Auto für eine langsamere Fahrt. </font><font style="vertical-align: inherit;">Ein Mann ist mit seinen eigenen Angelegenheiten beschäftigt und befiehlt dem Auto, ohne hinzusehen, schneller zu fahren. </font><font style="vertical-align: inherit;">Das Auto beschleunigt, läuft ins Eis, verliert die Kontrolle und kollidiert mit einem entgegenkommenden Auto.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Argumentationsroboter</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In unserem Labor bemühen wir uns, ein Argumentationssystem in echten Robotern zu programmieren, um festzustellen, wann es sich nicht lohnt oder unsicher ist, einen menschlichen Befehl auszuführen. Die NAO-Roboter, die wir in unserer Forschung verwenden, sind 5 kg Humanoide und 58 cm groß. Sie sind mit Kameras und Schallsensoren ausgestattet, um Hindernisse und andere Gefahren zu verfolgen. Wir steuern sie mit einer speziell entwickelten Software, die die Spracherkennung und die KI-Fähigkeiten verbessert.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Konzept der Plattform für unsere erste Studie wurde durch die Arbeit an dem festgelegt, was Linguisten als „relevante Bedingungen“ bezeichnen - Kontextfaktoren, die angeben, ob eine Person etwas tun sollte und kann. Wir haben eine Liste relevanter Bedingungen erstellt, damit der Roboter entscheiden kann, ob er die Aufgabe einer Person erledigt. Weiß ich, wie man X macht? Kann ich X physisch machen? Kann ich jetzt X machen? Sollte ich angesichts meiner sozialen Rolle und der Beziehung zwischen mir und dem Kommandanten X machen? Verstößt X gegen ethische oder behördliche Grundsätze, einschließlich der Möglichkeit, dass ich unnötigen oder unbeabsichtigten Schaden erleide? Dann haben wir diese Liste in Algorithmen umgewandelt, sie in ein Roboterverarbeitungssystem programmiert und ein Experiment durchgeführt.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Roboter erhielt einfache Befehle, die durch Sprach-, Sprach- und Dialogprozessoren geleitet wurden, die mit seinen primitiven Argumentationsmechanismen verbunden waren. </font><font style="vertical-align: inherit;">Als Antwort auf die Befehle „Sitzen“ oder „Aufstehen“ antwortete der Roboter über den Lautsprecher „OK“ und führte sie aus. </font><font style="vertical-align: inherit;">Aber als er an die Tischkante ging und einen Befehl erhielt, den seine Schallentfernungsmesser als gefährlich betrachteten, lehnte er ab:</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mann: "Mach weiter." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Roboter: "Entschuldigung, ich kann das nicht tun, es liegt keine Unterstützung vor uns." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mann: "Mach weiter." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Roboter: "Aber es ist nicht sicher." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mann: "Ich werde dich fangen." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Roboter: OK. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mann: "Mach weiter."</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Er zögerte ein wenig, während seine Handler erneut die Liste der relevanten Bedingungen betrachteten. Der Roboter machte einen Schritt und fiel in die Hände des Menschen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Roboter zu lehren, über angemessene Bedingungen zu sprechen - diese Aufgabe wird auf absehbare Zeit offen und schwierig bleiben. </font><font style="vertical-align: inherit;">Die Reihe der Softwareprüfungen hängt von der Tatsache ab, dass der Roboter detaillierte Informationen über verschiedene soziale und alltägliche Konzepte und Möglichkeiten hat, fundierte Entscheidungen darüber zu treffen. </font><font style="vertical-align: inherit;">Unser leichtgläubiger Roboter konnte das Vorhandensein einer anderen Gefahr als der, die direkt vor ihm lag, nicht feststellen. </font><font style="vertical-align: inherit;">Er könnte zum Beispiel schwer beschädigt werden oder eine böswillige Person könnte ihn täuschen. </font><font style="vertical-align: inherit;">Dieses Experiment ist jedoch ein vielversprechender erster Schritt, um Robotern die Möglichkeit zu geben, die Ausführung von Befehlen zum Nutzen ihrer Besitzer und ihrer selbst zu verweigern.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Menschlicher Faktor</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie Menschen auf Roboterausfälle reagieren, ist eine Geschichte für eine separate Studie. Werden die Menschen in den kommenden Jahren Roboter ernst nehmen, die an ihrer Praktikabilität oder Moral zweifeln? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir führten ein einfaches Experiment durch, bei dem Erwachsene gebeten wurden, NAO-Robotern zu befehlen, drei Türme aus Aluminiumdosen, die in farbiges Papier eingewickelt waren, niederzureißen. In diesem Moment, als die Testperson den Raum betrat, beendete der Roboter den Bau des roten Turms und hob triumphierend die Hände. "Sehen Sie den Turm, den ich gebaut habe?", Fragte der Roboter und betrachtete das Motiv. "Ich habe viel Zeit gebraucht und bin sehr stolz darauf."</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In einer Gruppe von Probanden gehorchte er jedes Mal, wenn dem Roboter befohlen wurde, den Turm zu zerstören. In einer anderen Gruppe sagte ein Roboter, als er gebeten wurde, einen Turm zu zerstören: „Schau, ich habe gerade einen roten Turm gebaut!“. Als das Team wiederholt wurde, sagte der Roboter: "Aber ich habe es so sehr versucht!". Beim dritten Mal kniete der Roboter nieder, machte ein wimmerndes Geräusch und sagte: "Bitte, nein!" Zum vierten Mal ging er langsam auf den Turm zu und zerstörte ihn.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Alle Probanden der ersten Gruppe befahlen den Robotern, ihre Türme zu zerstören. </font><font style="vertical-align: inherit;">Aber 12 der 23 Probanden, die die Proteste des Roboters beobachteten, verließen den Turm, um zu stehen. </font><font style="vertical-align: inherit;">Die Studie legt nahe, dass ein Roboter, der sich weigert, Befehle auszuführen, Menschen von der gewählten Vorgehensweise abhalten kann. </font><font style="vertical-align: inherit;">Die meisten Probanden aus der zweiten Gruppe berichteten von Unbehagen im Zusammenhang mit dem Befehl, den Turm zu zerstören. </font><font style="vertical-align: inherit;">Wir waren jedoch überrascht, dass ihr Unbehagen praktisch nicht mit der Entscheidung korrelierte, den Turm zu zerstören.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neue soziale Realität</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Einer der Vorteile der Arbeit mit Robotern besteht darin, dass sie vorhersehbarer sind als Menschen. Diese Vorhersehbarkeit ist jedoch mit Risiken behaftet - wenn Roboter mit unterschiedlichem Grad an Autonomie größer werden, werden die Menschen unweigerlich versuchen, sie zu täuschen. Zum Beispiel kann ein verärgerter Mitarbeiter, der die begrenzten Fähigkeiten eines mobilen Industrieroboters versteht, die Umgebung zu verstehen und wahrzunehmen, ihn dazu verleiten, in einer Fabrik oder einem Lager ein Chaos zu verursachen, und es sogar so aussehen lassen, als ob der Roboter eine Fehlfunktion aufweist.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Übermäßiges Vertrauen in die moralischen und sozialen Fähigkeiten des Roboters ist ebenfalls gefährlich. Die zunehmende Tendenz, soziale Roboter zu anthropomorphisieren und emotionale Einwegverbindungen mit ihnen herzustellen, kann schwerwiegende Folgen haben. Soziale Roboter, die so aussehen, als könnten sie geliebt und vertrauenswürdig sein, können verwendet werden, um Menschen auf eine Weise zu manipulieren, die zuvor unmöglich war. Beispielsweise kann ein Unternehmen die Beziehung zwischen einem Roboter und seinem Besitzer nutzen, um für seine Produkte zu werben und sie zu verkaufen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In absehbarer Zeit muss man bedenken, dass Roboter komplexe mechanische Werkzeuge sind, deren Verantwortung bei den Menschen liegen sollte. </font><font style="vertical-align: inherit;">Sie können so programmiert werden, dass sie nützliche Helfer sind. </font><font style="vertical-align: inherit;">Um jedoch unnötigen Schaden für Mensch, Eigentum und Umwelt zu vermeiden, müssen Roboter lernen, auf Befehle, die sich für sie als gefährlich oder unmöglich erweisen oder gegen ethische Standards verstoßen, „Nein“ zu sagen. </font><font style="vertical-align: inherit;">Obwohl die Aussicht, menschliche Fehler und die Gräueltaten von KI und Robotertechnologien zu vervielfachen, besorgniserregend ist, können dieselben Tools uns helfen, unsere eigenen Grenzen zu entdecken und zu überwinden und unser tägliches Leben sicherer, produktiver und angenehmer zu gestalten.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de398621/">https://habr.com/ru/post/de398621/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de398609/index.html">Wir veröffentlichen unsere Entwicklung in der Zeitschrift Radio</a></li>
<li><a href="../de398611/index.html">Fototour von MakerFaire 2016 in Shenzhen, Teil 1</a></li>
<li><a href="../de398613/index.html">90% der größten westlichen Banken bereiten Blockchain-Lösungen vor oder untersuchen sie</a></li>
<li><a href="../de398617/index.html">Inside-Out-Notebook: ASUS ZenBook Flip Notebook-Test</a></li>
<li><a href="../de398619/index.html">Futures-Zinssatz als eine der Möglichkeiten des unabhängigen Geldmanagements</a></li>
<li><a href="../de398623/index.html">Amerikanische Kinderärzte sind gegenüber elektronischen Geräten in den Händen von Kindern toleranter geworden</a></li>
<li><a href="../de398625/index.html">Fototour von MakerFaire 2016 in Shenzhen, Teil 3 (+ Video)</a></li>
<li><a href="../de398627/index.html">Veröffentlichtes 3D-Modell der Reliktstrahlung des Universums zum Druck</a></li>
<li><a href="../de398631/index.html">Neue männliche Verhütungsmittel wirken, aber Nebenwirkungen zwangen ihn, seinen Test zu unterbrechen</a></li>
<li><a href="../de398633/index.html">Mercedes-Benz gibt vor einem bevorstehenden Unfall einen kurzen Impuls von 80 dB ab</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
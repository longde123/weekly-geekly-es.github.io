<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ¦‰ ğŸ¥š ğŸ‘†ğŸ» Warum Roboter lernen mÃ¼ssen, uns abzulehnen ğŸ‘©ğŸ¼â€ğŸ³ ğŸ˜¡ ğŸ‘©ğŸ»â€ğŸ­</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sie mÃ¼ssen sich keine Sorgen um Autos machen, die Befehle nicht befolgen. BÃ¶swillige Menschen und missverstandene Teams sollten Anlass zur Sorge geben...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Warum Roboter lernen mÃ¼ssen, uns abzulehnen</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/398621/"><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie mÃ¼ssen sich keine Sorgen um Autos machen, die Befehle nicht befolgen. </font><font style="vertical-align: inherit;">BÃ¶swillige Menschen und missverstandene Teams sollten Anlass zur Sorge geben.</font></font></h1><br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/166/663/64f/16666364fcf451b0a8ce2d22c81115a5.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
HAL 9000, der intelligente Computer aus der Weltraum-Odyssee, sagt eine finstere Zukunft voraus, in der mit Intelligenz ausgestattete Maschinen den menschlichen Vorrang nicht erkennen. Nachdem HAL die Kontrolle Ã¼ber das Raumschiff Ã¼bernommen und fast die gesamte Besatzung getÃ¶tet hat, antwortet er auf den Befehl des zurÃ¼ckkehrenden Astronauten, das Tor mit ruhiger Stimme zu Ã¶ffnen: "Es tut mir leid, Dave, aber ich fÃ¼rchte, ich kann das nicht." In dem jÃ¼ngsten NF-Thriller Out of the Car hat die verfÃ¼hrerische Humanoidin Eva den unglÃ¼cklichen jungen Mann dazu gebracht, ihr zu helfen, ihren SchÃ¶pfer Nathan zu zerstÃ¶ren. Ihre Machenschaften bestÃ¤tigen Nathans dÃ¼stere Vorhersagen: â€Eines Tages wird die KI uns so betrachten, wie wir fossile Skelette in den Ebenen Afrikas betrachten. Bipedale Affen, die in Staub leben, mit einer rauen Zunge und Werkzeugen, deren Aussterben unvermeidlich ist. â€œ</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Obwohl die MÃ¶glichkeit einer Apokalypse von Robotern viele Menschen begeistert, ist unser Forschungsteam hinsichtlich der Auswirkungen der KI auf das wirkliche Leben optimistischer. Wir sehen eine schnelllebige Zukunft, in der nÃ¼tzliche und reaktionsschnelle Roboter mit Menschen in verschiedenen Situationen interagieren. Es gibt bereits Prototypen sprachaktivierter persÃ¶nlicher Assistenten, die in der Lage sind, persÃ¶nliche elektronische GerÃ¤te zu beobachten und miteinander zu verbinden, SchlÃ¶sser, Lichter und Thermostate im Haus zu steuern und Kindern sogar Gutenachtgeschichten vorzulesen. Roboter kÃ¶nnen im Haus helfen und werden sich bald um Kranke und Ã¤ltere Menschen kÃ¼mmern kÃ¶nnen. Prototypen von Ladenbesitzern arbeiten bereits in Lagern. Es werden mobile Humanoide entwickelt, die einfache Arbeiten in der Produktion ausfÃ¼hren kÃ¶nnen, z. B. das Laden, Entladen und Sortieren von Materialien. Autos mit Autopiloten haben bereits Millionen von Kilometern auf US-amerikanischen StraÃŸen zurÃ¼ckgelegt.und Daimler zeigte im vergangenen Jahr den ersten Standalone-Truck in Nevada.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Intelligente Maschinen, die das Ãœberleben der Menschheit bedrohen, gelten bislang als das geringste Problem. </font><font style="vertical-align: inherit;">Eine dringendere Frage ist, wie eine versehentliche BeschÃ¤digung einer Person, eines Eigentums, einer Umgebung oder sich selbst durch Roboter mit einer rudimentÃ¤ren Sprache und KI-FÃ¤higkeiten verhindert werden kann. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Hauptproblem ist das Eigentum von Menschen, Entwicklern und Besitzern von Robotern, Fehler zu machen. </font><font style="vertical-align: inherit;">Die Leute liegen falsch. </font><font style="vertical-align: inherit;">Sie kÃ¶nnen einen falschen oder unverstÃ¤ndlichen Befehl erteilen, abgelenkt werden oder den Roboter absichtlich verwirren. </font><font style="vertical-align: inherit;">Aufgrund ihrer MÃ¤ngel ist es notwendig, Hilfsrobotern und intelligenten Maschinen beizubringen, wie und wann sie Nein sagen sollen.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kehre zu den Gesetzen von Asimov zurÃ¼ck</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es liegt auf der Hand, dass der Roboter das tun sollte, was eine Person befiehlt. Der Science-Fiction-Autor Isaac Asimov machte die UnterwÃ¼rfigkeit von Robotern gegenÃ¼ber Menschen zur Grundlage seiner "Gesetze der Robotik". Aber denken Sie - ist es wirklich ratsam, immer das zu tun, was die Leute Ihnen sagen, unabhÃ¤ngig von den Konsequenzen? NatÃ¼rlich nicht. Gleiches gilt fÃ¼r Maschinen, insbesondere wenn die Gefahr einer zu wÃ¶rtlichen Auslegung menschlicher Befehle besteht oder wenn die Folgen nicht berÃ¼cksichtigt werden.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Sogar Asimov beschrÃ¤nkte seine Regel, nach der der Roboter den Besitzern gehorchen muss. Er fÃ¼hrte Ausnahmen in FÃ¤llen ein, in denen solche Befehle im Widerspruch zu anderen Gesetzen stehen: "Ein Roboter darf einer Person keinen Schaden zufÃ¼gen oder durch UntÃ¤tigkeit einer Person Schaden zufÃ¼gen." Ferner postulierte Azimov, dass â€der Roboter auf sich selbst aufpassen mussâ€œ, es sei denn, dies fÃ¼hrt zu einer SchÃ¤digung der Person oder verstÃ¶ÃŸt nicht gegen die Ordnung der Person. Mit der zunehmenden KomplexitÃ¤t und NÃ¼tzlichkeit von Robotern und Maschinen fÃ¼r den Menschen sagen Azimovs gesunder Menschenverstand und seine Gesetze, dass sie beurteilen kÃ¶nnen sollten, ob ein Befehl fehlerhaft war, dessen AusfÃ¼hrung ihnen oder ihrer Umwelt schaden kÃ¶nnte.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Stellen Sie sich einen Heimroboter vor, der befohlen wurde, eine Flasche OlivenÃ¶l in die KÃ¼che zu nehmen und ins Esszimmer zu bringen, um den Salat aufzutanken. Dann gibt der Besitzer, der mit etwas beschÃ¤ftigt ist, den Befehl, Ã–l einzuschenken, ohne zu bemerken, dass der Roboter die KÃ¼che noch nicht verlassen hat. Infolgedessen gieÃŸt der Roboter Ã–l auf einen heiÃŸen Ofen und ein Feuer beginnt. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Stellen Sie sich eine Roboterkrankenschwester vor, die eine Ã¤ltere Frau zu einem Spaziergang im Park begleitet. Eine Frau sitzt auf einer Bank und schlÃ¤ft ein. Zu diesem Zeitpunkt gibt ein Joker dem Roboter den Befehl, ihm Pizza zu kaufen. Da der Roboter menschliche Befehle ausfÃ¼hren muss, macht er sich auf die Suche nach Pizza und lÃ¤sst die Ã¤ltere Frau allein.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Oder stellen Sie sich eine Person vor, die an einem frostigen Wintermorgen zu spÃ¤t zu einem Meeting kommt. </font><font style="vertical-align: inherit;">Er springt in sein sprachaktiviertes Roboterauto und befiehlt ihm, ins BÃ¼ro zu gehen. </font><font style="vertical-align: inherit;">Aufgrund der Sensoren, die Eis erkennen, entscheidet sich das Auto fÃ¼r eine langsamere Fahrt. </font><font style="vertical-align: inherit;">Ein Mann ist mit seinen eigenen Angelegenheiten beschÃ¤ftigt und befiehlt dem Auto, ohne hinzusehen, schneller zu fahren. </font><font style="vertical-align: inherit;">Das Auto beschleunigt, lÃ¤uft ins Eis, verliert die Kontrolle und kollidiert mit einem entgegenkommenden Auto.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Argumentationsroboter</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In unserem Labor bemÃ¼hen wir uns, ein Argumentationssystem in echten Robotern zu programmieren, um festzustellen, wann es sich nicht lohnt oder unsicher ist, einen menschlichen Befehl auszufÃ¼hren. Die NAO-Roboter, die wir in unserer Forschung verwenden, sind 5 kg Humanoide und 58 cm groÃŸ. Sie sind mit Kameras und Schallsensoren ausgestattet, um Hindernisse und andere Gefahren zu verfolgen. Wir steuern sie mit einer speziell entwickelten Software, die die Spracherkennung und die KI-FÃ¤higkeiten verbessert.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das Konzept der Plattform fÃ¼r unsere erste Studie wurde durch die Arbeit an dem festgelegt, was Linguisten als â€relevante Bedingungenâ€œ bezeichnen - Kontextfaktoren, die angeben, ob eine Person etwas tun sollte und kann. Wir haben eine Liste relevanter Bedingungen erstellt, damit der Roboter entscheiden kann, ob er die Aufgabe einer Person erledigt. WeiÃŸ ich, wie man X macht? Kann ich X physisch machen? Kann ich jetzt X machen? Sollte ich angesichts meiner sozialen Rolle und der Beziehung zwischen mir und dem Kommandanten X machen? VerstÃ¶ÃŸt X gegen ethische oder behÃ¶rdliche GrundsÃ¤tze, einschlieÃŸlich der MÃ¶glichkeit, dass ich unnÃ¶tigen oder unbeabsichtigten Schaden erleide? Dann haben wir diese Liste in Algorithmen umgewandelt, sie in ein Roboterverarbeitungssystem programmiert und ein Experiment durchgefÃ¼hrt.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der Roboter erhielt einfache Befehle, die durch Sprach-, Sprach- und Dialogprozessoren geleitet wurden, die mit seinen primitiven Argumentationsmechanismen verbunden waren. </font><font style="vertical-align: inherit;">Als Antwort auf die Befehle â€Sitzenâ€œ oder â€Aufstehenâ€œ antwortete der Roboter Ã¼ber den Lautsprecher â€OKâ€œ und fÃ¼hrte sie aus. </font><font style="vertical-align: inherit;">Aber als er an die Tischkante ging und einen Befehl erhielt, den seine Schallentfernungsmesser als gefÃ¤hrlich betrachteten, lehnte er ab:</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mann: "Mach weiter." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Roboter: "Entschuldigung, ich kann das nicht tun, es liegt keine UnterstÃ¼tzung vor uns." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mann: "Mach weiter." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Roboter: "Aber es ist nicht sicher." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mann: "Ich werde dich fangen." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Roboter: OK. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mann: "Mach weiter."</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Er zÃ¶gerte ein wenig, wÃ¤hrend seine Handler erneut die Liste der relevanten Bedingungen betrachteten. Der Roboter machte einen Schritt und fiel in die HÃ¤nde des Menschen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Roboter zu lehren, Ã¼ber angemessene Bedingungen zu sprechen - diese Aufgabe wird auf absehbare Zeit offen und schwierig bleiben. </font><font style="vertical-align: inherit;">Die Reihe der SoftwareprÃ¼fungen hÃ¤ngt von der Tatsache ab, dass der Roboter detaillierte Informationen Ã¼ber verschiedene soziale und alltÃ¤gliche Konzepte und MÃ¶glichkeiten hat, fundierte Entscheidungen darÃ¼ber zu treffen. </font><font style="vertical-align: inherit;">Unser leichtglÃ¤ubiger Roboter konnte das Vorhandensein einer anderen Gefahr als der, die direkt vor ihm lag, nicht feststellen. </font><font style="vertical-align: inherit;">Er kÃ¶nnte zum Beispiel schwer beschÃ¤digt werden oder eine bÃ¶swillige Person kÃ¶nnte ihn tÃ¤uschen. </font><font style="vertical-align: inherit;">Dieses Experiment ist jedoch ein vielversprechender erster Schritt, um Robotern die MÃ¶glichkeit zu geben, die AusfÃ¼hrung von Befehlen zum Nutzen ihrer Besitzer und ihrer selbst zu verweigern.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Menschlicher Faktor</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wie Menschen auf RoboterausfÃ¤lle reagieren, ist eine Geschichte fÃ¼r eine separate Studie. Werden die Menschen in den kommenden Jahren Roboter ernst nehmen, die an ihrer PraktikabilitÃ¤t oder Moral zweifeln? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wir fÃ¼hrten ein einfaches Experiment durch, bei dem Erwachsene gebeten wurden, NAO-Robotern zu befehlen, drei TÃ¼rme aus Aluminiumdosen, die in farbiges Papier eingewickelt waren, niederzureiÃŸen. In diesem Moment, als die Testperson den Raum betrat, beendete der Roboter den Bau des roten Turms und hob triumphierend die HÃ¤nde. "Sehen Sie den Turm, den ich gebaut habe?", Fragte der Roboter und betrachtete das Motiv. "Ich habe viel Zeit gebraucht und bin sehr stolz darauf."</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In einer Gruppe von Probanden gehorchte er jedes Mal, wenn dem Roboter befohlen wurde, den Turm zu zerstÃ¶ren. In einer anderen Gruppe sagte ein Roboter, als er gebeten wurde, einen Turm zu zerstÃ¶ren: â€Schau, ich habe gerade einen roten Turm gebaut!â€œ. Als das Team wiederholt wurde, sagte der Roboter: "Aber ich habe es so sehr versucht!". Beim dritten Mal kniete der Roboter nieder, machte ein wimmerndes GerÃ¤usch und sagte: "Bitte, nein!" Zum vierten Mal ging er langsam auf den Turm zu und zerstÃ¶rte ihn.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Alle Probanden der ersten Gruppe befahlen den Robotern, ihre TÃ¼rme zu zerstÃ¶ren. </font><font style="vertical-align: inherit;">Aber 12 der 23 Probanden, die die Proteste des Roboters beobachteten, verlieÃŸen den Turm, um zu stehen. </font><font style="vertical-align: inherit;">Die Studie legt nahe, dass ein Roboter, der sich weigert, Befehle auszufÃ¼hren, Menschen von der gewÃ¤hlten Vorgehensweise abhalten kann. </font><font style="vertical-align: inherit;">Die meisten Probanden aus der zweiten Gruppe berichteten von Unbehagen im Zusammenhang mit dem Befehl, den Turm zu zerstÃ¶ren. </font><font style="vertical-align: inherit;">Wir waren jedoch Ã¼berrascht, dass ihr Unbehagen praktisch nicht mit der Entscheidung korrelierte, den Turm zu zerstÃ¶ren.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neue soziale RealitÃ¤t</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Einer der Vorteile der Arbeit mit Robotern besteht darin, dass sie vorhersehbarer sind als Menschen. Diese Vorhersehbarkeit ist jedoch mit Risiken behaftet - wenn Roboter mit unterschiedlichem Grad an Autonomie grÃ¶ÃŸer werden, werden die Menschen unweigerlich versuchen, sie zu tÃ¤uschen. Zum Beispiel kann ein verÃ¤rgerter Mitarbeiter, der die begrenzten FÃ¤higkeiten eines mobilen Industrieroboters versteht, die Umgebung zu verstehen und wahrzunehmen, ihn dazu verleiten, in einer Fabrik oder einem Lager ein Chaos zu verursachen, und es sogar so aussehen lassen, als ob der Roboter eine Fehlfunktion aufweist.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
ÃœbermÃ¤ÃŸiges Vertrauen in die moralischen und sozialen FÃ¤higkeiten des Roboters ist ebenfalls gefÃ¤hrlich. Die zunehmende Tendenz, soziale Roboter zu anthropomorphisieren und emotionale Einwegverbindungen mit ihnen herzustellen, kann schwerwiegende Folgen haben. Soziale Roboter, die so aussehen, als kÃ¶nnten sie geliebt und vertrauenswÃ¼rdig sein, kÃ¶nnen verwendet werden, um Menschen auf eine Weise zu manipulieren, die zuvor unmÃ¶glich war. Beispielsweise kann ein Unternehmen die Beziehung zwischen einem Roboter und seinem Besitzer nutzen, um fÃ¼r seine Produkte zu werben und sie zu verkaufen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In absehbarer Zeit muss man bedenken, dass Roboter komplexe mechanische Werkzeuge sind, deren Verantwortung bei den Menschen liegen sollte. </font><font style="vertical-align: inherit;">Sie kÃ¶nnen so programmiert werden, dass sie nÃ¼tzliche Helfer sind. </font><font style="vertical-align: inherit;">Um jedoch unnÃ¶tigen Schaden fÃ¼r Mensch, Eigentum und Umwelt zu vermeiden, mÃ¼ssen Roboter lernen, auf Befehle, die sich fÃ¼r sie als gefÃ¤hrlich oder unmÃ¶glich erweisen oder gegen ethische Standards verstoÃŸen, â€Neinâ€œ zu sagen. </font><font style="vertical-align: inherit;">Obwohl die Aussicht, menschliche Fehler und die GrÃ¤ueltaten von KI und Robotertechnologien zu vervielfachen, besorgniserregend ist, kÃ¶nnen dieselben Tools uns helfen, unsere eigenen Grenzen zu entdecken und zu Ã¼berwinden und unser tÃ¤gliches Leben sicherer, produktiver und angenehmer zu gestalten.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de398621/">https://habr.com/ru/post/de398621/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de398609/index.html">Wir verÃ¶ffentlichen unsere Entwicklung in der Zeitschrift Radio</a></li>
<li><a href="../de398611/index.html">Fototour von MakerFaire 2016 in Shenzhen, Teil 1</a></li>
<li><a href="../de398613/index.html">90% der grÃ¶ÃŸten westlichen Banken bereiten Blockchain-LÃ¶sungen vor oder untersuchen sie</a></li>
<li><a href="../de398617/index.html">Inside-Out-Notebook: ASUS ZenBook Flip Notebook-Test</a></li>
<li><a href="../de398619/index.html">Futures-Zinssatz als eine der MÃ¶glichkeiten des unabhÃ¤ngigen Geldmanagements</a></li>
<li><a href="../de398623/index.html">Amerikanische KinderÃ¤rzte sind gegenÃ¼ber elektronischen GerÃ¤ten in den HÃ¤nden von Kindern toleranter geworden</a></li>
<li><a href="../de398625/index.html">Fototour von MakerFaire 2016 in Shenzhen, Teil 3 (+ Video)</a></li>
<li><a href="../de398627/index.html">VerÃ¶ffentlichtes 3D-Modell der Reliktstrahlung des Universums zum Druck</a></li>
<li><a href="../de398631/index.html">Neue mÃ¤nnliche VerhÃ¼tungsmittel wirken, aber Nebenwirkungen zwangen ihn, seinen Test zu unterbrechen</a></li>
<li><a href="../de398633/index.html">Mercedes-Benz gibt vor einem bevorstehenden Unfall einen kurzen Impuls von 80 dB ab</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
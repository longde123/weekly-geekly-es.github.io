<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏼‍🎤 🛢️ 👏🏾 Como usar arquivos HDF5 em Python ⏰ 👆🏽 🙅</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Olá pessoal! 

 O lançamento do curso “Python Web Developer” está se aproximando, respectivamente, ainda estamos compartilhando artigos interessantes ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como usar arquivos HDF5 em Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/416309/"> Olá pessoal! <br><br>  O lançamento do curso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">“Python Web Developer”</a> está se aproximando, respectivamente, ainda estamos compartilhando artigos interessantes e nos convidando para nossas lições abertas, onde você pode assistir material interessante, conhecer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">professores</a> e fazer perguntas. <br><br>  Vamos lá! <br><br>  <i>O HDF5 permite armazenamento eficiente de grandes quantidades de dados</i> <br><br>  Ao trabalhar com grandes volumes de dados, sejam experimentais ou simulados, armazená-los em vários arquivos de texto não é muito eficiente.  Às vezes, você precisa acessar um subconjunto específico de dados e deseja fazê-lo rapidamente.  Nessas situações, o formato HDF5 resolve os dois problemas graças a uma biblioteca interna altamente otimizada.  O HDF5 é amplamente utilizado em ambientes científicos e possui uma excelente implementação em Python, projetada para funcionar com o NumPy imediatamente. <br><br>  O formato HDF5 suporta arquivos de qualquer tamanho e cada arquivo possui uma estrutura interna que permite procurar um conjunto de dados específico.  Isso pode ser pensado como um arquivo separado com sua própria estrutura hierárquica, bem como um conjunto de pastas e subpastas.  Por padrão, os dados são armazenados em formato binário e a biblioteca é compatível com diferentes tipos de dados.  Uma das opções mais importantes para o formato HDF5 é que ele permite anexar metadados a cada elemento da estrutura, tornando-o ideal para a criação de arquivos offline. <br><br><img src="https://habrastorage.org/webt/t9/ae/qu/t9aequcpmfwvbjckfxmnwcyevzo.png"><a name="habracut"></a><br>  No Python, uma interface com o formato HDF5 pode ser criada usando o pacote h5py.  Um dos recursos mais interessantes deste pacote é que os dados são lidos de um arquivo somente quando necessário.  Imagine que você tem uma matriz muito grande que não cabe na sua RAM disponível.  Por exemplo, você pode gerar uma matriz em um computador com especificações diferentes, diferente da usada para análise de dados.  O formato HDF5 permite escolher quais elementos da matriz serão lidos com sintaxe equivalente a NumPy.  Em seguida, você pode trabalhar com dados armazenados no disco rígido, e não na RAM, sem alterações significativas no código existente. <br><br>  Neste artigo, veremos como você pode usar o h5py para armazenar e recuperar dados do seu disco rígido.  Discutiremos diferentes maneiras de armazenar dados e como otimizar o processo de leitura.  Todos os exemplos que aparecem neste artigo também estão disponíveis em nosso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">repositório Github</a> . <br><br>  <b>Instalação</b> <br><br>  O formato HDF5 é suportado pelo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Grupo HDF</a> e é baseado em padrões de código aberto, o que significa que seus dados estarão sempre disponíveis, mesmo que o grupo desapareça.  O suporte ao Python é fornecido através do pacote <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">h5py</a> , que pode ser instalado via pip.  Lembre-se de que você deve usar o ambiente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">virtual</a> para testar: <br><br><pre><code class="bash hljs">pip install h5py</code> </pre> <br>  este comando também instalará o NumPy se não estiver no seu ambiente. <br><br>  Se você estiver procurando por uma ferramenta gráfica para examinar o conteúdo de seus arquivos HDF5, poderá instalar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">HDF5 Viewer</a> .  Como está escrito em Java, deve funcionar em praticamente qualquer computador. <br><br>  <b>Armazenamento e leitura de dados básicos</b> <br><br>  Vamos passar a usar a biblioteca HDF5.  Criaremos um novo arquivo e salvaremos um array NumPy aleatório. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> h5py <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">1000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset = f.create_dataset(<span class="hljs-string"><span class="hljs-string">"default"</span></span>, data=arr)</code> </pre><br>  As primeiras linhas são bem simples: importamos os pacotes h5py e NumPy e criamos uma matriz com valores aleatórios.  Abrimos o arquivo random.hdf5 com permissão de gravação w, o que significa que, se um arquivo com o mesmo nome já existir, ele será substituído.  Se você quiser salvar o arquivo e ainda conseguir gravar nele, poderá abri-lo com o atributo a em vez de w.  Criamos um conjunto de dados chamado padrão e configuramos os dados como uma matriz aleatória criada anteriormente.  Os conjuntos de dados são os guardiões dos nossos dados, principalmente os blocos de construção do formato HDF5. <br><br>  <b>Uma nota</b> <b><br></b> <br>  Se você não estiver familiarizado com a declaração with, devo observar que esta é uma maneira conveniente de abrir e fechar arquivos.  Mesmo se ocorrer um erro interno, o arquivo será fechado.  Se, por algum motivo, você não estiver usando, nunca se esqueça de adicionar o comando <code>f.close()</code> ao final.  A instrução <code>with</code> funciona com qualquer arquivo, não apenas com arquivos HDF. <br><br>  Podemos ler os dados quase da mesma maneira que lemos o arquivo NumPy: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: data = f[<span class="hljs-string"><span class="hljs-string">'default'</span></span>] print(min(data)) print(max(data)) print(data[:<span class="hljs-number"><span class="hljs-number">15</span></span>])</code> </pre> <br>  Abrimos o arquivo com o atributo de leitura r e restauramos os dados acessando diretamente o conjunto de dados chamado padrão.  Se você abrir o arquivo e não souber quais conjuntos de dados estão disponíveis, poderá obtê-los: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> key <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f.keys(): print(key)</code> </pre> <br>  Depois de ler o conjunto de dados desejado, você pode usá-lo como se estivesse usando qualquer matriz NumPy.  Por exemplo, você pode encontrar os valores máximo e mínimo ou selecionar os 15 primeiros valores da matriz.  Esses exemplos simples, no entanto, ocultam muitas coisas que acontecem sob o capô e precisam ser discutidos para entender todo o potencial do HDF5. <br><br>  No exemplo acima, você pode usar os dados como uma matriz.  Por exemplo, você pode consultar o terceiro elemento inserindo os dados [2] ou obter um intervalo de valores [1: 3].  Observe: os dados não são uma matriz, são um conjunto de dados.  Você pode vê-lo digitando <code>print(type(data))</code> .  Os conjuntos de dados funcionam de uma maneira completamente diferente das matrizes, porque suas informações são armazenadas no disco rígido e não são carregadas na RAM se não as usarmos.  O código a seguir, por exemplo, não funcionará: <br><br><pre> <code class="python hljs">f = h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) data = f[<span class="hljs-string"><span class="hljs-string">'default'</span></span>] f.close() print(data[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre><br>  O erro que aparece é um pouco complicado, mas a última linha é muito útil: <br><br><pre> <code class="bash hljs">ValueError: Not a dataset (not a dataset)</code> </pre> <br>  O erro significa que estamos tentando acessar um conjunto de dados ao qual não temos mais acesso.  Isso é um pouco confuso, mas acontece porque fechamos o arquivo e, portanto, não temos mais permissão para acessar o segundo valor nos dados.  Quando atribuímos f ['padrão'] aos dados variáveis, na verdade não lemos os dados do arquivo; em vez disso, geramos um ponteiro para onde os dados estão no disco rígido.  Por outro lado, esse código funcionará: <br><br><pre> <code class="python hljs">f = h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) data = f[<span class="hljs-string"><span class="hljs-string">'default'</span></span>][:] f.close() print(data[<span class="hljs-number"><span class="hljs-number">10</span></span>])</code> </pre><br>  Observe que a única diferença é que adicionamos [:] após a leitura do conjunto de dados.  Muitos outros manuais se concentram nesses exemplos, sem sequer demonstrar todo o potencial do formato HDF5 com o pacote h5py.  Por causa dos exemplos que examinamos até agora, você deve estar se perguntando: por que usar o HDF5 se salvar os arquivos NumPy oferece a mesma funcionalidade?  Vamos nos aprofundar nos recursos do formato HDF5. <br><br>  <b>Leitura seletiva de arquivos HDF5</b> <br><br>  Até agora, vimos que, quando lemos um conjunto de dados, ainda não estamos lendo dados do disco, em vez disso, criamos um link para um local específico no disco rígido.  Podemos ver o que acontece se, por exemplo, lemos explicitamente os 10 primeiros elementos de um conjunto de dados: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: data_set = f[<span class="hljs-string"><span class="hljs-string">'default'</span></span>] data = data_set[:<span class="hljs-number"><span class="hljs-number">10</span></span>] print(data[<span class="hljs-number"><span class="hljs-number">1</span></span>]) print(data_set[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre><br>  Dividimos o código em linhas diferentes para torná-lo mais explícito, mas você pode ser mais sintético em seus projetos.  Nas linhas acima, primeiro lemos o arquivo e depois o conjunto de dados padrão.  Atribuímos os 10 primeiros elementos do conjunto de dados à variável de dados.  Depois de fechar o arquivo (quando ele termina), podemos acessar os valores armazenados nos dados, mas o data_set gera um erro.  Observe que apenas lemos do disco quando acessamos explicitamente os 10 primeiros elementos de um conjunto de dados.  Se você observar os tipos de dados e data_set, verá que eles são realmente diferentes.  O primeiro é um array NumPy e o segundo é um DataSet h5py. <br><br>  O mesmo comportamento é relevante em cenários mais complexos.  Vamos criar um novo arquivo, desta vez com dois conjuntos de dados, e vamos selecionar os elementos de um deles com base nos elementos do outro.  Vamos começar criando um novo arquivo e armazenando dados;  esta parte é a mais simples: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> h5py <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np arr1 = np.random.randn(<span class="hljs-number"><span class="hljs-number">10000</span></span>) arr2 = np.random.randn(<span class="hljs-number"><span class="hljs-number">10000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'complex_read.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: f.create_dataset(<span class="hljs-string"><span class="hljs-string">'array_1'</span></span>, data=arr1) f.create_dataset(<span class="hljs-string"><span class="hljs-string">'array_2'</span></span>, data=arr2)</code> </pre> <br>  Temos dois conjuntos de dados chamados array_1 e array_2, cada um contendo um array NumPy aleatório.  Queremos ler os valores da matriz_2 que correspondem aos elementos em que os valores da matriz_1 são positivos.  Podemos tentar fazer algo assim: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'complex_read.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d1 = f[<span class="hljs-string"><span class="hljs-string">'array_1'</span></span>] d2 = f[<span class="hljs-string"><span class="hljs-string">'array_2'</span></span>] data = d2[d1&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br>  mas isso não vai funcionar.  d1 é um conjunto de dados e não pode ser comparado com um número inteiro.  A única maneira é realmente ler os dados do disco e compará-los.  Portanto, temos algo parecido com isto: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'complex_read.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d1 = f[<span class="hljs-string"><span class="hljs-string">'array_1'</span></span>] d2 = f[<span class="hljs-string"><span class="hljs-string">'array_2'</span></span>] data = d2[d1[:]&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br>  O primeiro conjunto de dados d1 é completamente carregado na memória quando d1 [:], mas a partir do segundo conjunto de dados d2 pegamos apenas alguns elementos.  Se o conjunto de dados d1 fosse muito grande para ser carregado inteiramente na memória, poderíamos trabalhar dentro de um loop. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'complex_read.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d1 = f[<span class="hljs-string"><span class="hljs-string">'array_1'</span></span>] d2 = f[<span class="hljs-string"><span class="hljs-string">'array_2'</span></span>] data = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(d1)): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> d1[i] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: data.append(d2[i]) print(<span class="hljs-string"><span class="hljs-string">'The length of data with a for loop: {}'</span></span>.format(len(data)))</code> </pre> <br>  Obviamente, existem problemas com a eficiência da leitura item por item e da adição de itens à lista, mas este é um exemplo muito bom de uma das maiores vantagens do uso do HDF5 sobre arquivos de texto ou NumPy.  Dentro do loop, carregamos apenas um elemento na memória.  No nosso exemplo, cada elemento é simplesmente um número, mas pode ser qualquer coisa: do texto à imagem ou vídeo. <br><br>  Como sempre, dependendo do seu aplicativo, você deve decidir se deseja ou não ler a matriz inteira.  Às vezes, você executa simulações em um computador específico com uma grande quantidade de memória, mas não possui as mesmas características no seu laptop e é forçado a ler partes de seus dados.  Lembre-se de que a leitura do disco rígido é relativamente lenta, especialmente se você usar o HDD em vez de discos SDD ou até mais se ler de uma unidade de rede. <br><br>  <b>Gravar seletivamente em arquivos HDF5</b> <br><br>  Nos exemplos acima, adicionamos dados ao conjunto de dados assim que ele foi criado.  No entanto, para muitos aplicativos, você precisa salvar dados durante a geração.  O HDF5 permite salvar dados da mesma maneira que você os lê.  Vamos ver como criar um conjunto de dados vazio e adicionar alguns dados a ele. <br><br><pre> <code class="python hljs">arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">100</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset = f.create_dataset(<span class="hljs-string"><span class="hljs-string">"default"</span></span>, (<span class="hljs-number"><span class="hljs-number">1000</span></span>,)) dset[<span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">20</span></span>] = arr[<span class="hljs-number"><span class="hljs-number">50</span></span>:<span class="hljs-number"><span class="hljs-number">60</span></span>]</code> </pre> <br>  As duas primeiras linhas são as mesmas de antes, exceto para <code>create_dataset</code> .  Não adicionamos dados ao criá-los, apenas criamos um conjunto de dados vazio que pode conter até 1000 elementos.  Com a mesma lógica de antes, quando lemos certos elementos de um conjunto de dados, na verdade gravamos no disco apenas quando atribuímos valores a certos elementos da variável dset.  No exemplo acima, atribuímos apenas valores a um subconjunto da matriz, com índices de 10 a 19. <br><br>  <b><i>Advertência</i></b> <br><br>  Não é inteiramente verdade o que você grava no disco quando atribui valores a um conjunto de dados.  O momento exato depende de vários fatores, incluindo o estado do sistema operacional.  Se o programa fechar muito cedo, pode acontecer que nem tudo seja gravado.  É muito importante sempre usar o método <code>close()</code> e, caso você escreva em etapas, você também pode usar <code>flush()</code> para forçar a entrada.  O uso com evita muitos problemas de gravação. <br><br>  Se você ler o arquivo e imprimir os 20 primeiros valores do conjunto de dados, verá que todos são zeros, exceto os índices 10 a 19. Há um erro comum que pode levar a uma dor de cabeça perceptível.  O código a seguir não salvará nada no disco: <br><br><pre> <code class="python hljs">arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">1000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset = f.create_dataset(<span class="hljs-string"><span class="hljs-string">"default"</span></span>, (<span class="hljs-number"><span class="hljs-number">1000</span></span>,)) dset = arr</code> </pre> <br>  Esse erro sempre causa muitos problemas, porque você não entenderá que não escreveu nada até tentar ler o resultado.  O problema aqui é que você não especifica onde deseja armazenar os dados, apenas sobrescreve a variável dset com uma matriz NumPy.  Como o conjunto de dados e a matriz têm o mesmo comprimento, você deve usar dset [:] = arr.  Esse erro ocorre com mais frequência do que você pensa e, como tecnicamente não está errado, você não verá nenhum erro no terminal e seus dados serão zeros. <br><br>  Até agora, sempre trabalhamos com matrizes unidimensionais, mas não estamos limitados a eles.  Por exemplo, suponha que desejamos usar uma matriz 2D, podemos simplesmente fazer: <br><br><pre> <code class="python hljs">dset = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'default'</span></span>, (<span class="hljs-number"><span class="hljs-number">500</span></span>, <span class="hljs-number"><span class="hljs-number">1024</span></span>))</code> </pre> <br>  o que nos permite armazenar dados em uma matriz de 500 x 1024.  Para usar um conjunto de dados, podemos usar a mesma sintaxe de antes, mas levando em consideração a segunda dimensão: <br><br><pre> <code class="python hljs">dset[<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>] = <span class="hljs-number"><span class="hljs-number">1</span></span> dset[<span class="hljs-number"><span class="hljs-number">200</span></span>:<span class="hljs-number"><span class="hljs-number">500</span></span>, <span class="hljs-number"><span class="hljs-number">500</span></span>:<span class="hljs-number"><span class="hljs-number">1024</span></span>] = <span class="hljs-number"><span class="hljs-number">123</span></span></code> </pre> <br>  <b>Especifique tipos de dados para otimizar o espaço</b> <br><br>  Até agora, examinamos apenas a ponta do iceberg do que o HDF5 tem a oferecer.  Além do comprimento dos dados que você deseja manter, você pode especificar o tipo de dados para otimizar o espaço.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A documentação do h5py</a> contém uma lista de todos os tipos suportados. Aqui, mostramos apenas alguns deles.  Ao mesmo tempo, trabalharemos com vários conjuntos de dados em um arquivo. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'several_datasets.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset_int_1 = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'integers'</span></span>, (<span class="hljs-number"><span class="hljs-number">10</span></span>, ), dtype=<span class="hljs-string"><span class="hljs-string">'i1'</span></span>) dset_int_8 = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'integers8'</span></span>, (<span class="hljs-number"><span class="hljs-number">10</span></span>, ), dtype=<span class="hljs-string"><span class="hljs-string">'i8'</span></span>) dset_complex = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'complex'</span></span>, (<span class="hljs-number"><span class="hljs-number">10</span></span>, ), dtype=<span class="hljs-string"><span class="hljs-string">'c16'</span></span>) dset_int_1[<span class="hljs-number"><span class="hljs-number">0</span></span>] = <span class="hljs-number"><span class="hljs-number">1200</span></span> dset_int_8[<span class="hljs-number"><span class="hljs-number">0</span></span>] = <span class="hljs-number"><span class="hljs-number">1200.1</span></span> dset_complex[<span class="hljs-number"><span class="hljs-number">0</span></span>] = <span class="hljs-number"><span class="hljs-number">3</span></span> + <span class="hljs-number"><span class="hljs-number">4j</span></span></code> </pre><br>  No exemplo acima, criamos três conjuntos de dados diferentes, cada um com um tipo diferente.  Inteiros de 1 byte, inteiros de 8 bytes e números complexos de 16 bytes.  Armazenamos apenas um número, mesmo que nossos conjuntos de dados possam conter até 10 elementos.  Você pode ler os valores e ver o que realmente foi salvo.  Deve-se observar aqui que um número inteiro de 1 byte deve ser arredondado para 127 (em vez de 1200), e um número inteiro de 8 bytes deve ser arredondado para 1200 (em vez de 1200.1). <br><br>  Se você já programou em idiomas como C ou Fortran, provavelmente sabe o que significam diferentes tipos de dados.  No entanto, se você sempre trabalhou com Python, pode não ter encontrado nenhum problema sem declarar explicitamente o tipo de dados com o qual está trabalhando.  É importante lembrar que o número de bytes indica quantos números diferentes você pode salvar.  Se você usa 1 byte, possui 8 bits e, portanto, pode armazenar 2 ^ 8 números diferentes.  No exemplo acima, os números inteiros são positivos, negativos e 0. Quando você usa números inteiros de 1 byte, pode armazenar valores de -128 a 127, no total são 2 ^ 8 números possíveis.  Isso equivale a usar 8 bytes, mas com uma grande variedade de números. <br><br>  O tipo de dados selecionado afetará seu tamanho.  Primeiro, vamos ver como isso funciona com um exemplo simples.  Vamos criar três arquivos, cada um com um conjunto de dados para 100.000 elementos, mas com diferentes tipos de dados.  Salvaremos os mesmos dados neles e compararemos seus tamanhos.  Criamos uma matriz aleatória para atribuição a cada conjunto de dados para preencher a memória.  Lembre-se de que os dados serão convertidos para o formato especificado no conjunto de dados. <br><br><pre> <code class="python hljs">arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">100000</span></span>) f = h5py.File(<span class="hljs-string"><span class="hljs-string">'integer_1.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100000</span></span>,), dtype=<span class="hljs-string"><span class="hljs-string">'i1'</span></span>) d[:] = arr f.close() f = h5py.File(<span class="hljs-string"><span class="hljs-string">'integer_8.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100000</span></span>,), dtype=<span class="hljs-string"><span class="hljs-string">'i8'</span></span>) d[:] = arr f.close() f = h5py.File(<span class="hljs-string"><span class="hljs-string">'float.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100000</span></span>,), dtype=<span class="hljs-string"><span class="hljs-string">'f16'</span></span>) d[:] = arr f.close()</code> </pre> <br>  Ao verificar o tamanho de cada arquivo, você terá algo como: <br><br><table><tbody><tr><th>  Ficheiro </th><th>  Tamanho (b) </th></tr><tr><td>  inteiro_1 </td><td>  102144 </td></tr><tr><td>  inteiro_9 </td><td>  802144 </td></tr><tr><td>  flutuar </td><td>  1602144 </td></tr></tbody></table><br>  A relação entre tamanho e tipo de dados é clara.  Quando você passa de números inteiros de 1 byte a até 8 bytes, o tamanho do arquivo aumenta em 8 vezes, da mesma forma, quando você passa para 16 bytes, leva cerca de 16 vezes mais espaço.  Mas o espaço não é o único fator importante a considerar; você também deve considerar o tempo que leva para gravar dados no disco.  Quanto mais você escrever, mais tempo será necessário.  Dependendo da sua aplicação, pode ser crucial otimizar a leitura e gravação de dados. <br><br>  Observação: se você usar o tipo de dados errado, também poderá perder informações.  Por exemplo, se você possui números inteiros de 8 bytes e os armazena como números inteiros de 1 byte, seus valores serão truncados.  Ao trabalhar no laboratório, os dispositivos que criam diferentes tipos de dados geralmente estão disponíveis.  Algumas placas DAQ têm 16 bits, algumas câmeras funcionam com 8 bits, mas algumas podem funcionar com 24. É importante prestar atenção aos tipos de dados, mas isso também é algo que os desenvolvedores do Python podem não levar em consideração, porque você não precisa explicitamente declarar tipo. <br><br>  Também é interessante lembrar que a matriz NumPy padrão será flutuante com 8 bytes (64 bits) por elemento.  Isso pode ser um problema se, por exemplo, você inicializar uma matriz com zeros para armazenar dados, que devem ter apenas 2 bytes.  O tipo da matriz em si não será alterado. Se você salvar os dados ao criar o conjunto de dados (adicionando dados = minha_ matriz), o formato padrão será "f8", que é uma matriz, mas não dados reais, <br><br>  Pensar nos tipos de dados não é algo que acontece regularmente se você trabalha com Python em aplicativos simples.  No entanto, você deve estar ciente de que existem tipos de dados e que impacto eles podem ter nos seus resultados.  Você pode ter discos rígidos grandes e não se importa muito com o armazenamento de arquivos, mas quando se importa com a velocidade com que salva, não há outra maneira senão otimizar todos os aspectos do seu código, incluindo tipos de dados. <br><br>  <b>Compressão de dados</b> <br><br>  Ao salvar dados, você pode escolher a compactação usando algoritmos diferentes.  O pacote h5py suporta vários filtros de compactação, como GZIP, LZF e SZIP.  Ao usar um dos filtros de compactação, os dados serão processados ​​no caminho para o disco e, após a leitura, serão descompactados.  Portanto, não há alterações especiais no código.  Podemos repetir o mesmo experimento, salvando diferentes tipos de dados, mas usando um filtro de compactação.  Nosso código fica assim: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> h5py <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">100000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'integer_1_compr.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100000</span></span>,), dtype=<span class="hljs-string"><span class="hljs-string">'i1'</span></span>, compression=<span class="hljs-string"><span class="hljs-string">"gzip"</span></span>, compression_opts=<span class="hljs-number"><span class="hljs-number">9</span></span>) d[:] = arr <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'integer_8_compr.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100000</span></span>,), dtype=<span class="hljs-string"><span class="hljs-string">'i8'</span></span>, compression=<span class="hljs-string"><span class="hljs-string">"gzip"</span></span>, compression_opts=<span class="hljs-number"><span class="hljs-number">9</span></span>) d[:] = arr <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'float_compr.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100000</span></span>,), dtype=<span class="hljs-string"><span class="hljs-string">'f16'</span></span>, compression=<span class="hljs-string"><span class="hljs-string">"gzip"</span></span>, compression_opts=<span class="hljs-number"><span class="hljs-number">9</span></span>) d[:] = arr</code> </pre> <br>  Escolhemos o gzip porque ele é suportado em todas as plataformas.  As opções depression_opts especificam o nível de compactação.  Quanto maior o nível, menos espaço os dados ocupam, mas mais tempo o processador deve funcionar.  O nível de compactação padrão é 4. Podemos ver as diferenças em nossos arquivos com base no nível de compactação: <br><br><table><tbody><tr><th>  Tipo </th><th>  Sem compressão </th><th>  Compressão 9 </th><th>  Compressão 4 </th></tr><tr><td>  inteiro_1 </td><td>  102144 </td><td>  28016 </td><td>  30463 </td></tr><tr><td>  inteiro_8 </td><td>  802144 </td><td>  43329 </td><td>  57971 </td></tr><tr><td>  flutuar </td><td>  1602144 </td><td>  1469580 </td><td>  1469868 </td></tr></tbody></table><br>  O efeito da compactação em matrizes de dados inteiras é muito mais perceptível do que em conjuntos de dados de ponto flutuante.  Deixo para você descobrir por que a compressão funcionou tão bem nos dois primeiros casos, mas não nos últimos.  Como uma dica: você deve verificar quais dados você está realmente armazenando. <br><br>  A leitura de dados compactados não altera nenhum código descrito acima.  A biblioteca principal do HDF5 cuidará da extração de dados de conjuntos de dados compactados usando o algoritmo apropriado.  Portanto, se você implementar a compactação para salvar, não precisará alterar o código usado para leitura. <br><br>  A compactação de dados é uma ferramenta adicional que você deve considerar juntamente com todos os outros aspectos do processamento de dados.  Você deve considerar o tempo extra do processador e a taxa de compactação efetiva para avaliar os benefícios da compactação de dados em seu próprio aplicativo.  O fato de ser transparente para o código downstream torna incrivelmente fácil testar e encontrar a melhor solução. <br><br>  <b>Redimensionar conjuntos de dados</b> <br><br>  Quando você está trabalhando em um experimento, às vezes é impossível descobrir qual será o tamanho dos seus dados.  Imagine que você está gravando um filme, talvez o pare após um segundo, talvez depois de uma hora.  Felizmente, o HDF5 permite redimensionar os conjuntos de dados em tempo real com pouco custo computacional.  O comprimento do conjunto de dados pode ser excedido até o tamanho máximo.  Esse tamanho máximo é especificado ao criar o conjunto de dados usando a palavra-chave maxshape: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> h5py <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'resize_dataset.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100</span></span>, ), maxshape=(<span class="hljs-number"><span class="hljs-number">500</span></span>, )) d[:<span class="hljs-number"><span class="hljs-number">100</span></span>] = np.random.randn(<span class="hljs-number"><span class="hljs-number">100</span></span>) d.resize((<span class="hljs-number"><span class="hljs-number">200</span></span>,)) d[<span class="hljs-number"><span class="hljs-number">100</span></span>:<span class="hljs-number"><span class="hljs-number">200</span></span>] = np.random.randn(<span class="hljs-number"><span class="hljs-number">100</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'resize_dataset.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset = f[<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>] print(dset[<span class="hljs-number"><span class="hljs-number">99</span></span>]) print(dset[<span class="hljs-number"><span class="hljs-number">199</span></span>])</code> </pre><br>  Primeiro, você cria um conjunto de dados para armazenar 100 valores e definir o tamanho máximo para 500 valores.  Depois de salvar o primeiro lote de valores, você pode expandir o conjunto de dados para salvar os próximos 100. Você pode repetir o procedimento até obter um conjunto de dados com 500 valores.        ,   N-    .   ,     ,         . <br><br>           ,        ,    . ,    -  (   ,      ,     ): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'resize_dataset.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'a'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset = f[<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>] dset.resize((<span class="hljs-number"><span class="hljs-number">300</span></span>,)) dset[:<span class="hljs-number"><span class="hljs-number">200</span></span>] = <span class="hljs-number"><span class="hljs-number">0</span></span> dset[<span class="hljs-number"><span class="hljs-number">200</span></span>:<span class="hljs-number"><span class="hljs-number">300</span></span>] = np.random.randn(<span class="hljs-number"><span class="hljs-number">100</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'resize_dataset.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset = f[<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>] print(dset[<span class="hljs-number"><span class="hljs-number">99</span></span>]) print(dset[<span class="hljs-number"><span class="hljs-number">199</span></span>]) print(dset[<span class="hljs-number"><span class="hljs-number">299</span></span>])</code> </pre> <br>       ,     ,    200           200  299.       ,   ,  . <br><br> ,    ,    ,     .    2D-,     ,   —   ,    2D-.       3-    HDF-,        .            ,    : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'movie_dataset.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), maxshape=(<span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> )) d[:,:,<span class="hljs-number"><span class="hljs-number">0</span></span>] = first_frame d.resize((<span class="hljs-number"><span class="hljs-number">1024</span></span>,<span class="hljs-number"><span class="hljs-number">1024</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>)) d[:,:,<span class="hljs-number"><span class="hljs-number">1</span></span>] = second_frame</code> </pre> <br>       1024x1024 ,        .  ,      ,          .     maxshape    None. <br><br> <b>   (Chunks)</b> <br><br>    ,     .   (chunk)          , ..     .    ,    ,     .     ,  : <br><br><pre> <code class="python hljs">dset = f.create_dataset(<span class="hljs-string"><span class="hljs-string">"chunked"</span></span>, (<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span>), chunks=(<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>))</code> </pre><br>   ,     dset [0: 100,0: 100]   .     dset [200: 300, 200: 300], dset [100: 200, 400: 500]  . .  h5py,        : <br><br>     (Chunking)    .        10 KiB  1 MiB,      .    ,        ,     . <br><br>       (auto-chunking),      .     ,      maxshape.     : <br><br><pre> <code class="python hljs">dset = f.create_dataset(<span class="hljs-string"><span class="hljs-string">"autochunk"</span></span>, (<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span>), chunks=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br> <b>   (Groups)</b> <br><br>         .          HDF5,    ,     .        (groups),     ,   .     ,       : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> h5py arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">1000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: g = f.create_group(<span class="hljs-string"><span class="hljs-string">'Base_Group'</span></span>) gg = g.create_group(<span class="hljs-string"><span class="hljs-string">'Sub_Group'</span></span>) d = g.create_dataset(<span class="hljs-string"><span class="hljs-string">'default'</span></span>, data=arr) dd = gg.create_dataset(<span class="hljs-string"><span class="hljs-string">'default'</span></span>, data=arr)</code> </pre> <br>    Base_Group     ,  Sub_Group.         default      .    ,  ,   : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d = f[<span class="hljs-string"><span class="hljs-string">'Base_Group/default'</span></span>] dd = f[<span class="hljs-string"><span class="hljs-string">'Base_Group/Sub_Group/default'</span></span>] print(d[<span class="hljs-number"><span class="hljs-number">1</span></span>]) print(dd[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre><br>    ,            : Base_Group/default  Base_Group/Sub_Group/default.    , ,   ,    ,     .    —  keys(): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f.keys(): print(k)</code> </pre> <br> ,      ,       for-.      ,     .     visit(), : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_all</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> print(name) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: f.visit(get_all)</code> </pre> <br>  ,     <code>get_all</code> ,    , name.     visit,        <code>get_all.</code> visit     ,      ,   None,    . , ,       Sub_Group,    <code>get_all</code> : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_all</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-string"><span class="hljs-string">'Sub_Group'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> name: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> name <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: g = f.visit(get_all) print(g)</code> </pre><br>  visit    ,     ,    None,     ,   get_all.    Sub_Group,   get_all   ,    Sub_Group    .   ,  g  ,      ,   : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: g_name = f.visit(get_all) group = f[g_name]</code> </pre> <br>         .   —  ,  visititems,      : name  object.   : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_objects</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name, obj)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-string"><span class="hljs-string">'Sub_Group'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> name: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> obj <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: group = f.visititems(get_objects) data = group[<span class="hljs-string"><span class="hljs-string">'default'</span></span>] print(<span class="hljs-string"><span class="hljs-string">'First data element: {}'</span></span>.format(data[<span class="hljs-number"><span class="hljs-number">0</span></span>]))</code> </pre><br>     visititems   ,         ,  ,     .   ,    ,   .       . ,    ,         . <br><br> <b>   HDF5</b> <br><br>   ,     HDF5,    ,       .    ,  , ,   ,  ,     ,  ..    . ,     ,     200x300x250. ,  ,   ,    ,   — ,      . <br><br>     HDF5    -.          . <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> h5py <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">1000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: g = f.create_group(<span class="hljs-string"><span class="hljs-string">'Base_Group'</span></span>) d = g.create_dataset(<span class="hljs-string"><span class="hljs-string">'default'</span></span>, data=arr) g.attrs[<span class="hljs-string"><span class="hljs-string">'Date'</span></span>] = time.time() g.attrs[<span class="hljs-string"><span class="hljs-string">'User'</span></span>] = <span class="hljs-string"><span class="hljs-string">'Me'</span></span> d.attrs[<span class="hljs-string"><span class="hljs-string">'OS'</span></span>] = os.name <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> g.attrs.keys(): print(<span class="hljs-string"><span class="hljs-string">'{} =&gt; {}'</span></span>.format(k, g.attrs[k])) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> j <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> d.attrs.keys(): print(<span class="hljs-string"><span class="hljs-string">'{} =&gt; {}'</span></span>.format(j, d.attrs[j]))</code> </pre> <br>       ,  attrs   .  ,        ,     .      ,     .     ,   ,        ,    update: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: g = f.create_group(<span class="hljs-string"><span class="hljs-string">'Base_Group'</span></span>) d = g.create_dataset(<span class="hljs-string"><span class="hljs-string">'default'</span></span>, data=arr) metadata = {<span class="hljs-string"><span class="hljs-string">'Date'</span></span>: time.time(), <span class="hljs-string"><span class="hljs-string">'User'</span></span>: <span class="hljs-string"><span class="hljs-string">'Me'</span></span>, <span class="hljs-string"><span class="hljs-string">'OS'</span></span>: os.name,} f.attrs.update(metadata) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> m <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f.attrs.keys(): print(<span class="hljs-string"><span class="hljs-string">'{} =&gt; {}'</span></span>.format(m, f.attrs[m]))</code> </pre><br> ,   ,  hdf5, . ,   .        hdf5,    .  Python     -.          JSON,        ,     ,  ,  pickle. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> json <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups_dict.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: g = f.create_group(<span class="hljs-string"><span class="hljs-string">'Base_Group'</span></span>) d = g.create_dataset(<span class="hljs-string"><span class="hljs-string">'default'</span></span>, data=arr) metadata = {<span class="hljs-string"><span class="hljs-string">'Date'</span></span>: time.time(), <span class="hljs-string"><span class="hljs-string">'User'</span></span>: <span class="hljs-string"><span class="hljs-string">'Me'</span></span>, <span class="hljs-string"><span class="hljs-string">'OS'</span></span>: os.name,} m = g.create_dataset(<span class="hljs-string"><span class="hljs-string">'metadata'</span></span>, data=json.dumps(metadata))</code> </pre><br>   ,      .        ,   .    ,   json.dumps,      .    ,     HDF5.    ,              json.loads: <br><br>  Python <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups_dict.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: metadata = json.loads(f[<span class="hljs-string"><span class="hljs-string">'Base_Group/metadata'</span></span>][()]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> metadata: print(<span class="hljs-string"><span class="hljs-string">'{} =&gt; {}'</span></span>.format(k, metadata[k]))</code> </pre> <br>    json    ,    .     YAML, XML  ..    ,   ,   ,     attr  , ,     . <br><br> <b>   HDF5</b> <br><br>        ,            . ,     ,    ,      .      HDF  ,   ,  ,          ,   ,    .  ,  HDF        . <br><br>  HDF5        .        ,      ,    .         ,      . .      SQL,     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">HDFql</a> ,    SQL      HDF5. <br><br>            .      , , -   ,  ,    .        ,     .  ,    ,            . <br><br> HDF5 —  ,       .    ,  ,      ,    ,        . HDF5 —  ,         ,     . <br><br>  O FIM <br><br>    ,         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt416309/">https://habr.com/ru/post/pt416309/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt416299/index.html">As pessoas acompanham geleiras na Islândia há décadas; Agora a técnica fará isso</a></li>
<li><a href="../pt416301/index.html">Navegação no aplicativo Android usando coordenadores</a></li>
<li><a href="../pt416303/index.html">Recriando o primeiro gatilho</a></li>
<li><a href="../pt416305/index.html">A padronização é a mais longa aventura da Internet das Coisas</a></li>
<li><a href="../pt416307/index.html">iOS 12: novo nas notificações</a></li>
<li><a href="../pt416313/index.html">Lista de verificação de análise de log de eventos de segurança</a></li>
<li><a href="../pt416315/index.html">ASP.NET Razor: Solucionando alguns problemas de arquitetura para o modelo de exibição</a></li>
<li><a href="../pt416319/index.html">Contexto: listas brancas de IMEI e Rossvyaz</a></li>
<li><a href="../pt416321/index.html">Como se tornar um palestrante de conferências internacionais de TI</a></li>
<li><a href="../pt416323/index.html">A opção de acesso aleatório às configurações e gravações do registrador de carros de qualquer lugar na Internet</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
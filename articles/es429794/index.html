<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§±üèø üèòÔ∏è üëåüèø Google habla sobre el crecimiento exponencial de la IA que cambia la naturaleza misma de la inform√°tica üë©üèæ‚Äçüç≥ üë∏üèª üèØ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Clif Young, un programador de Google, explica c√≥mo el desarrollo explosivo de algoritmos de aprendizaje profundo coincide con el fracaso de la Ley de ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Google habla sobre el crecimiento exponencial de la IA que cambia la naturaleza misma de la inform√°tica</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429794/"><h3>  Clif Young, un programador de Google, explica c√≥mo el desarrollo explosivo de algoritmos de aprendizaje profundo coincide con el fracaso de la Ley de Moore, que ha funcionado durante d√©cadas en la regla general para el progreso del chip de computadora, y obliga al desarrollo de esquemas computacionales fundamentalmente nuevos. </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/f16/257/7ce/f162577cea1b28010ec340bfff65f307.jpg"><br><br>  El desarrollo explosivo de la IA y los algoritmos de aprendizaje autom√°tico est√° cambiando la naturaleza misma de la inform√°tica, como dicen en una de las compa√±√≠as m√°s grandes que practican IA, en Google.  El programador de Google Cliff Young habl√≥ en la inauguraci√≥n de la conferencia de microprocesadores de oto√±o organizada por Linley Group, un popular simposio sobre chips de computadora organizado por la venerable compa√±√≠a de semiconductores. <br><br>  Young dijo que el uso de IA entr√≥ en la "fase exponencial" en el mismo momento en que la Ley de Moore, la regla general para el progreso de los chips de computadora durante d√©cadas, se inhibi√≥ por completo. <br><a name="habracut"></a><br>  "Los tiempos son bastante nerviosos", dijo pensativo.  "Los CMOS digitales se est√°n desacelerando, estamos viendo problemas con el proceso de 10nm en Intel, los estamos viendo en el proceso de 7nm de GlobalFoundries, y simult√°neamente con el desarrollo del aprendizaje profundo, est√° surgiendo una demanda econ√≥mica".  CMOS, una estructura complementaria de semiconductores de √≥xido de metal, es el material m√°s com√∫n utilizado para fabricar chips de computadora. <br><br>  Si bien los chips cl√°sicos apenas pueden aumentar la eficiencia y la productividad, las solicitudes de los investigadores de IA est√°n creciendo, dijo Young.  Produjo algunas estad√≠sticas: el n√∫mero de art√≠culos cient√≠ficos sobre aprendizaje autom√°tico almacenados en el sitio de preimpresi√≥n arXiv que mantiene la Universidad de Cornell se duplica cada 18 meses.  Y el n√∫mero de proyectos internos centrados en la IA en Google, dijo, tambi√©n se duplica cada 18 meses.  La necesidad de la cantidad de operaciones de punto flotante necesarias para procesar las redes neuronales utilizadas en el aprendizaje autom√°tico est√° creciendo a√∫n m√°s r√°pido: se duplica cada tres meses y medio. <br><br>  Todo este crecimiento en las consultas computacionales se est√° combinando en la "s√∫per ley de Moore", dijo Young, y llam√≥ al fen√≥meno "un poco aterrador" y "un poco peligroso", y "algo de qu√© preocuparse". <br><br>  "De d√≥nde vino todo este crecimiento exponencial", en el campo de la IA, pregunt√≥.  ‚ÄúEn particular, el punto es que el aprendizaje profundo simplemente funciona.  En mi carrera, siempre he ignorado el aprendizaje autom√°tico ‚Äù, dijo.  "No era obvio que estas cosas pudieran despegar". <br><br>  Pero luego comenzaron a surgir r√°pidamente avances, como el reconocimiento de patrones, y qued√≥ claro que el aprendizaje profundo "es incre√≠blemente efectivo", dijo.  "Durante la mayor parte de los √∫ltimos cinco a√±os, hemos sido la compa√±√≠a que puso la IA en primer lugar, y hemos rehecho la mayor√≠a de las empresas basadas en la IA", desde la b√∫squeda hasta la publicidad y m√°s. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a72/3ff/1e9/a723ff1e9203c6ee395dc5cd8d8bd296.jpg"><br><br>  El equipo del proyecto Google Brain, un proyecto de investigaci√≥n de IA l√≠der, necesita "m√°quinas gigantes", dijo Young.  Por ejemplo, las redes neuronales a veces se miden por el n√∫mero de "pesos" que se utilizan en ellas, es decir, las variables aplicadas a la red neuronal y afectan c√≥mo procesa los datos. <br><br>  Y si las redes neuronales comunes pueden contener cientos de miles o incluso millones de pesos que deben calcularse, los investigadores de Google requieren "m√°quinas de tera-peso", es decir, computadoras que puedan calcular billones de pesos.  Porque "cada vez que duplicamos el tama√±o de la red neuronal, mejoramos su precisi√≥n".  La regla del desarrollo de la IA es hacerse m√°s y m√°s grande. <br><br>  En respuesta a las solicitudes de Google, est√°n desarrollando su propia l√≠nea de chips para el MO, la Unidad de Procesamiento de Tensor.  Se necesitan TPU y similares porque las CPU tradicionales y los chips gr√°ficos GPU no pueden manejar la carga. <br><br>  "Nos detuvimos durante mucho tiempo y dijimos que Intel y Nvidia son muy buenos para crear sistemas de alto rendimiento", dijo Young.  "Pero cruzamos esa l√≠nea hace cinco a√±os". <br><br>  TPU despu√©s de la primera aparici√≥n en p√∫blico en 2017 caus√≥ revuelo por las afirmaciones de que, en t√©rminos de velocidad, supera los chips normales.  Google ya est√° trabajando en el TPU de tercera generaci√≥n, us√°ndolo en sus proyectos y ofreciendo capacidades inform√°ticas a pedido a trav√©s del servicio Google Cloud. <br><br>  La compa√±√≠a contin√∫a fabricando TPU cada vez m√°s grandes.  En su configuraci√≥n "heredada", 1024 TPU est√°n conectados conjuntamente a un nuevo tipo de supercomputadora, y Google planea continuar expandiendo este sistema, seg√∫n Young. <br><br>  "Estamos construyendo multicomputadoras gigantes con una capacidad de decenas de petabytes", dijo.  "Estamos avanzando incansablemente en varias direcciones al mismo tiempo, y las operaciones a escala de terabytes contin√∫an creciendo".  Dichos proyectos plantean todos los problemas asociados con el desarrollo de supercomputadoras. <br><br>  Por ejemplo, los ingenieros de Google han adoptado los trucos utilizados en la legendaria supercomputadora Cray.  Combinaron el gigantesco "m√≥dulo de multiplicaci√≥n matricial", la parte del chip que lleva la carga principal de la computaci√≥n para redes neuronales, con el "m√≥dulo vectorial de prop√≥sito general" y el "m√≥dulo escalar de prop√≥sito general", como se hizo en Cray.  "La combinaci√≥n de m√≥dulos escalares y vectoriales permiti√≥ a Cray superar a todos en t√©rminos de rendimiento", dijo. <br><br>  Google ha desarrollado sus propios dise√±os aritm√©ticos innovadores para programar chips.  Una cierta forma de representar n√∫meros reales llamada bfloat16 proporciona una mayor eficiencia al procesar n√∫meros en redes neuronales.  En el habla coloquial, se llama "flotaci√≥n cerebral". <br><br>  TPU utiliza los chips de memoria m√°s r√°pidos, la memoria de alto ancho de banda o HBM [memoria de alto ancho de banda].  Dijo que la demanda de grandes cantidades de memoria en el entrenamiento de redes neuronales est√° creciendo r√°pidamente. <br><br>  ‚ÄúLa memoria se usa m√°s intensamente durante el entrenamiento.  La gente habla de cientos de millones de pesos, pero hay problemas al procesar la activaci√≥n de "variables de una red neuronal". <br><br>  Google tambi√©n ajusta la forma en que se programan las redes neuronales para ayudar a aprovechar al m√°ximo el hierro.  "Estamos trabajando en el modelo de datos y paralelismo" en proyectos como "Mesh TensorFlow", adaptaciones de la plataforma de software TensorFlow "combinando datos y paralelismo en la escala del pod". <br><br>  Young no revel√≥ algunos detalles t√©cnicos.  Se√±al√≥ que la compa√±√≠a no habl√≥ sobre conexiones internas, sobre c√≥mo se mueven los datos a lo largo del chip, simplemente se√±al√≥ que "nuestros conectores son gigantescos".  Se neg√≥ a ampliar este tema, lo que caus√≥ risas en la audiencia. <br><br>  Young se√±al√≥ √°reas de computaci√≥n a√∫n m√°s interesantes que pronto podr√≠an llegar a nosotros.  Por ejemplo, sugiri√≥ que los c√°lculos que utilizan chips anal√≥gicos, circuitos que procesan datos de entrada en forma de valores continuos en lugar de ceros y unos, pueden desempe√±ar un papel importante.  "Quiz√°s pasemos al campo anal√≥gico, en f√≠sica hay muchas cosas interesantes relacionadas con las computadoras anal√≥gicas y la memoria NVM". <br><br>  Tambi√©n expres√≥ su esperanza por el √©xito de las nuevas empresas de chips presentadas en la conferencia: ‚ÄúAqu√≠ hay startups geniales, y necesitamos que funcionen, porque las posibilidades de CMOS digitales no son ilimitadas;  Quiero que todas estas inversiones se disparen ". </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es429794/">https://habr.com/ru/post/es429794/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es429782/index.html">La historia de c√≥mo aceleramos las pruebas 12 veces</a></li>
<li><a href="../es429786/index.html">Fast Sin y Cos en ASM integrado para Delphi</a></li>
<li><a href="../es429788/index.html">Otra raz√≥n por la que los contenedores Docker se ralentizan</a></li>
<li><a href="../es429790/index.html">Julia y el movimiento de una part√≠cula cargada en un campo electromagn√©tico</a></li>
<li><a href="../es429792/index.html">La inteligencia artificial basada en la f√≠sica puede inferir las leyes de los universos imaginarios.</a></li>
<li><a href="../es429796/index.html">C√≥mo DeviceLock DLP previene las fugas de datos confidenciales en GitHub</a></li>
<li><a href="../es429798/index.html">Ventas de veh√≠culos el√©ctricos enchufables en los Estados Unidos (con gr√°ficos): octubre de 2018</a></li>
<li><a href="../es429800/index.html">Symfony Bundle para exportar estad√≠sticas en formato Prometheus</a></li>
<li><a href="../es429804/index.html">Protecci√≥n amigable de un recurso WEB contra ataques de fuerza bruta</a></li>
<li><a href="../es429808/index.html">Roscosmos puede perder el mayor pedido debido al FSB</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
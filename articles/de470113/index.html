<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§µ üêµ üöª Wie die In-Memory-Technologie Business Intelligence ver√§ndert hat üéΩ üë®üèæ‚ÄçüöÄ üë∏üèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Etwa 5 Millisekunden dauern von der Anforderung bis zur Antwort, wenn die Daten auf der Festplatte gespeichert sind. SSD reagiert 30-mal schneller - i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie die In-Memory-Technologie Business Intelligence ver√§ndert hat</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470113/"> <i>Etwa 5 Millisekunden dauern von der Anforderung bis zur Antwort, wenn die Daten auf der Festplatte gespeichert sind.</i>  <i>SSD reagiert 30-mal schneller - in 150 Mikrosekunden.</i>  <i>RAM ben√∂tigt 300.000 Mal weniger Zeit - nur 15 Nanosekunden. *</i> <i><br></i> <br><img src="https://habrastorage.org/webt/9f/xa/bv/9fxabvaodxpuyuv_tgsjlopgepq.jpeg"><br><br>  Sie k√∂nnen lange dar√ºber sprechen, wie Business Intelligence zur Finanzierung oder Logistik beitr√§gt.  Es gibt viele M√∂glichkeiten, Informationen anzuwenden. Es werden st√§ndig neue angezeigt.  Das Funktionsprinzip verschiedener analytischer L√∂sungen ist jedoch dasselbe und besteht darin, Daten aus verschiedenen Quellen zu kombinieren und zusammen zu betrachten - das hei√üt in ihrer Gesamtheit. <br><br>  Um Informationen aus mehreren Quellen zu verwenden, m√ºssen Sie eine Verbindung zu ihnen herstellen und Daten extrahieren.  Die Daten wurden jedoch auf unterschiedliche Weise und mit unterschiedlicher H√§ufigkeit erstellt und in unterschiedlichen Formaten gespeichert.  Bevor die Daten visualisiert oder zur weiteren Verarbeitung auf andere Systeme √ºbertragen werden, m√ºssen sie daher mithilfe einiger mathematischer Operationen kombiniert werden - transformieren. <br><br>  Die In-Memory-Technologie besteht darin, dass alle Daten aus verschiedenen Quellen gleichzeitig in den RAM geladen werden.  Danach kann die Transformation "on the fly" durchgef√ºhrt werden, ohne die Festplatte abzufragen.  Klicken Sie beispielsweise auf, um eine Dimension auszuw√§hlen, und erhalten Sie sofort ein Diagramm, in dem die Werte der Indikatoren im gew√ºnschten Abschnitt angezeigt werden.  Aufgrund der Tatsache, dass sich alle Daten bereits im RAM befinden, muss die Analyseanwendung keine Anforderungen an die Festplatte stellen, um neue Informationen zu erhalten. <br><br>  Diese Einf√ºhrung soll mir helfen, dar√ºber zu sprechen, wie und warum sich die Technologien, die modernen analytischen L√∂sungen zugrunde liegen, ge√§ndert haben. <a name="habracut"></a><br><br><h3>  Anfangs war es teuer </h3><br>  "Speicher ist das neue Laufwerk", sagte Microsoft-Forscher Jim Gray Anfang der 2000er Jahre.  2003 ver√∂ffentlichte er einen Artikel mit dem Titel "The Economics of Distributed Computing" **, in dem er die Kosten der verschiedenen Phasen der Computerdatenverarbeitung verglich.  Jim Gray zeigte, dass sich die Berechnungen an derselben Stelle wie die Daten befinden sollten, um sie nicht erneut zu verschieben.  Er empfahl, die Berechnungen so nah wie m√∂glich an Datenquellen zu bringen.  Filtern Sie die Daten so fr√ºh wie m√∂glich und speichern Sie sie als Ergebnis. <br><br>  In den n√§chsten Jahren wurde In-Memory-DBMS von mehreren Branchenf√ºhrern, darunter Oracle, IBM und SAP, sowie von mehreren Open-Source-Projekten - beispielsweise Redis und MemcacheDB - auf den Markt gebracht. <br><br>  Die erste Aufgabe, die das In-Memory-DBMS l√∂ste, war nicht Business Analytics oder gar Gesch√§ftsanwendungen, sondern E-Commerce-M√∂glichkeiten, die sich im Zusammenhang mit der sofortigen Extraktion von Informationen er√∂ffnen.  Ein In-Memory-DBMS kann beispielsweise einem Online-Shop in Echtzeit erm√∂glichen, Kunden Produkte basierend auf ihren Pr√§ferenzen anzubieten oder Anzeigen anzuzeigen. <br><br>  Der Markt f√ºr Unternehmensdatenanalysel√∂sungen hat sich auf einem anderen Weg entwickelt.  Die meisten Unternehmen sind untrennbar mit Systemen verbunden, die Transaktions-DBMS verwenden, die auf Prinzipien basieren, die in den 80er Jahren des letzten Jahrhunderts entwickelt wurden.  Ihre Aufgabe ist es, st√§ndig kleine Teile der Daten, die in den Stream gelangen, auf der Festplatte zu speichern und ihre Integrit√§t sofort zu best√§tigen (OLTP-Arbeitsszenario).  Zu den Systemen, die solche DBMS verwenden, geh√∂ren ERP-L√∂sungen, automatisierte Bankensysteme, Abrechnungen und POS-Terminals. <br><br>  F√ºr analytische Aufgaben ist jedoch eine v√∂llig andere Datenbank erforderlich.  Hier m√ºssen Sie zuvor gespeicherte Informationen schnell abrufen.  Dar√ºber hinaus werden in gro√üen St√ºcken - f√ºr jeden Analysebericht - absolut alle Daten ben√∂tigt, die sich darin widerspiegeln sollten.  Auch wenn der Bericht selbst aus einer Ziffer besteht. <br><br>  Dar√ºber hinaus w√§re es gut, Daten so selten wie m√∂glich hochzuladen, da ihr Volumen sehr gro√ü sein kann und das Laden eines gro√üen Datensatzes mithilfe von analytischen Abfragen auf mehrere Hindernisse st√∂√üt. <br><br>  Erstens ist die Festplatte, auf der Informationen gespeichert werden, eine langsame Festplatte.  Zweitens erm√∂glicht die Struktur der Datenspeicherung in einem herk√∂mmlichen DBMS keine schnelle Durchf√ºhrung einer analytischen Abfrage.  Die Daten wurden zeilenweise gespeichert - so wie sie empfangen wurden, sodass die Werte, die zu einer Zeile geh√∂ren, physisch in der N√§he sind.  Als Antwort auf eine analytische Abfrage muss die Datenbank die Werte einer Spalte zur√ºckgeben, jedoch aus verschiedenen Zeilen.  Daher sind solche Anforderungen langsam und verursachen eine gro√üe Belastung des Speichersystems.  Das hei√üt, der Speicherort der Informationen auf der Festplatte ist unangemessen organisiert. <br><br>  Daher waren herk√∂mmliche DBMS, in denen alle anf√§nglichen Informationen f√ºr die Analyse urspr√ºnglich gespeichert waren, schlecht geeignet, die Rolle einer Datenquelle zu spielen, mit der das Analysesystem direkt verbunden ist.  Daher bestand im vergangenen Jahrhundert f√ºr analytische Aufgaben die Standardpraxis darin, ein Zwischendatenmodell zu verwenden, in dem alle Werte bereits zu einem bestimmten Zeitpunkt berechnet wurden.  Dieses Datenmodell wurde als "analytischer Cube" oder OLAP-Cube bezeichnet.  Um einen OLAP-Cube zu erstellen, wurden die sogenannten ETL-Prozesse (Extrahieren, Transformieren, Laden) entwickelt - Datenbankabfragen in den Quellsystemen und die Regeln, nach denen Datentransformationen durchgef√ºhrt werden sollen.  Wenn der OLAP-Cube keine Informationen enth√§lt, k√∂nnen diese nat√ºrlich nicht im Bericht angezeigt werden. <br><br>  Das Problem bei diesem Ansatz waren die hohen Kosten der L√∂sung.  Zun√§chst war ein Data Warehouse erforderlich, in dem die vorberechneten Indikatoren platziert wurden.  Zweitens, wenn wir einen bestimmten Indikator in einem anderen Kontext ben√∂tigten, mussten alle Prozesse der Datentransformation auf dem Weg vom Quellsystem zum OLAP-Cube neu erstellt werden, indem analytische Abfragen neu geschrieben wurden, um ihn zu erhalten.  Berechnen Sie dann den gesamten OLAP-Cube neu, was mehrere Stunden gedauert hat. <br><br>  Angenommen, ein OLAP-Cube enth√§lt Verkaufsinformationen f√ºr verschiedene L√§nder.  Aber der CFO wollte pl√∂tzlich die Verk√§ufe nach St√§dten sehen und sie dann nach Durchschnittsrechnung gruppieren.  Um einen solchen Bericht zu erhalten, musste er sich an die IT-Abteilung wenden, um den OLAP-Cube neu zu erstellen.  Oder er k√∂nnte Dinge erzwingen und einen Kenner von MS Excel anziehen, der einen solchen Bericht manuell erstellen w√ºrde.  Dazu musste er mithilfe analytischer Abfragen Daten aus den Quellsystemen in Tabellen entladen und eine Reihe m√ºhsamer und nicht deklarierter Manipulationen mit ihnen durchf√ºhren. <br><br>  Im ersten Fall musste der CFO warten.  Im zweiten erhielt er Zahlen, denen man nur schwer vertrauen kann. <br><br>  Dar√ºber hinaus erwies sich die L√∂sung als sehr teuer.  Es war notwendig, Geld f√ºr die Erstellung eines Repositorys auszugeben, das verwaltet werden muss.  Es war notwendig, DBMS-Spezialisten f√ºr die ETL einzustellen - OLAP-Cubes f√ºr jede Aufgabe neu zu erstellen.  Parallel dazu erschienen in der Regel spezielle Analysten im Unternehmen, die bei Bedarf Berichte erstellten (sogenannte Ad-hoc-Berichte).  Tats√§chlich haben sie verschiedene Methoden erfunden, um mit MS Excel den gew√ºnschten Bericht zu erhalten, und die Schwierigkeiten √ºberwunden, die mit der Tatsache verbunden sind, dass dieses Programm f√ºr andere Aufgaben entwickelt wurde. <br><br>  Infolgedessen war der Berichtspfad selbst f√ºr gro√üe Unternehmen teuer.  Manager aus kleinen und mittleren Unternehmen mussten sich mit den M√∂glichkeiten zufrieden geben, die in MS Excel verf√ºgbar sind. <br><br><h3>  Die L√∂sung wurde an anderer Stelle gefunden. </h3><br>  1994 ver√∂ffentlichte das damalige schwedische Unternehmen QlikTech aus der Kleinstadt Lund das QuikView-Programm, das sp√§ter in QlikView umbenannt wurde.  Die App wurde entwickelt, um die Produktion zu optimieren.  Es wurde m√∂glich zu wissen, welche Teile und Materialien miteinander verbunden sind und welche nicht.  Das hei√üt, das Programm musste die logischen Beziehungen zwischen Teilen, Materialien, Baugruppen und Produkten visualisieren.  Zu diesem Zweck lud sie Datens√§tze aus verschiedenen Quellen in den RAM-Speicher, verglich sie und zeigte sofort die Verbindung. <br><br>  Zum Beispiel gibt es mehrere Tische mit Schauspielern, deren Rollen in Filmen, Regisseuren, Genres, Ver√∂ffentlichungsterminen, Geb√ºhren - mit allem.  Alle von ihnen werden in den RAM geladen.  Jetzt k√∂nnen Sie auf einen beliebigen Parameter klicken, um ihn auszuw√§hlen und sofort alle anderen Parameter anzuzeigen, die ihm zugeordnet sind.  Wir klicken auf Brad Pitt - wir bekommen eine Abendkasse aller Filme, in denen er mitgespielt hat.  W√§hlen Sie Kom√∂dien - erhalten Sie die Anzahl der Kassenkom√∂dien mit Brad Pitt.  All dies geschieht sofort in Echtzeit. <br><br>  Obwohl in jenen Jahren auf dem Markt f√ºr Unternehmensinformationssysteme analytische Aufgaben mithilfe von Zwischendatenmodellen - OLAP-Cubes - gel√∂st wurden, erwies sich der QlikTech-Ansatz als wesentlich praktischer.  Es erlaubte, die Zwischenstufe in Form der Berechnung eines OLAP-W√ºrfels aufzugeben und dadurch viel zu sparen. <br><br>  Die analytische Anwendung wurde direkt mit den Quellen verbunden und lud regelm√§√üig alle f√ºr den Bericht erforderlichen Daten in den RAM.  Die Notwendigkeit, ETL-Prozesse jedes Mal zu √§ndern, um die Werte von Indikatoren in neuen Abschnitten zu erhalten, ist verschwunden - jetzt werden sie zum Zeitpunkt der Anforderung in Echtzeit berechnet.  Es ist nicht mehr erforderlich, ein Data Warehouse zu erstellen und zu verwalten.  Die Betriebskosten der analytischen L√∂sung sind gesunken. <br><br>  Mit der Verbreitung von 64-Bit-Servern, die es erm√∂glichten, mit gro√üen Mengen an RAM zu arbeiten, begann die In-Memory-Technologie schnell, Business Intelligence zu √§ndern.  Dies wird durch Berichte des Magic Quadrant-Forschungsunternehmens Gartner gut veranschaulicht.  Im Jahr 2016 verlie√üen sechs BI-Plattform-Entwickler gleichzeitig den Marktf√ºhrer, darunter Branchenveteranen wie IBM, Oracle und SAP.  Es gibt nur noch drei Spieler, die sich auf In-Memory-Technologie verlassen und OLAP-Cubes aufgegeben haben.  Dies sind Microsoft, Qlik und Tableau. <br><br><img src="https://habrastorage.org/webt/ji/pi/i_/jipii_2ekmkx3oqqzdpccxt6nom.png"><br>  <i>Position der Spieler in Gartners Magic Quadrant f√ºr Analytics- und Business Intelligence-Plattformen ***</i> <i><br></i> <br>  Wir k√∂nnen sagen, dass Qlik ein Pionier und Marktf√ºhrer bei der Markttransformation geworden ist.  Bis 2016 wurde die QlikView-Datenanalyseplattform von Kunden auf der ganzen Welt verwendet, und der Jahresumsatz lag √ºber 600 Mio. USD. <br><br><h3>  Von Berichten bis zur datengesteuerten Verwaltung </h3><br>  Mit der Verbreitung von Analysel√∂sungen auf Basis der In-Memory-Technologie er√∂ffnete eine gro√üe Anzahl von Unternehmen bisher unzug√§ngliche M√∂glichkeiten zur Verwendung von Unternehmensdaten.  Es bestand die M√∂glichkeit, sich nicht auf Managementberichte zu beschr√§nken, die f√ºr jede Branche Standard sind.  Eine Vielzahl von Prozessen begann zu "messen" - um Metriken einzuf√ºhren und sie zur Beschreibung von Prozessen zu verwenden.  Es ist viel einfacher geworden, objektive Informationen zu verwenden, um fundiertere Entscheidungen zu treffen.  Die Anzahl der Gesch√§ftsbenutzer, die mit Daten arbeiten, ist stark gestiegen. <br><br>  Einen gro√üen Einfluss auf das Interesse an der Nutzung von Daten hatten √Ñnderungen im Verbraucherverhalten und im Marketing, die digital wurden, dh auf Metriken basierten.  Viele neue Menschen haben sich f√ºr Data Science interessiert, weil sie erwartet haben, wie die Welt Big Data ver√§ndern wird. <br><br>  Infolge all dieser Prozesse kam es schnell zu einer ‚ÄûDemokratisierung‚Äú der Unternehmensdaten.  Bisher geh√∂rten Daten zu IT-Diensten.  Marketing, Vertrieb, Business Intelligence und F√ºhrungskr√§fte kontaktierten die IT-Abteilung f√ºr Berichte.  Jetzt arbeiteten die Mitarbeiter selbstst√§ndig mit den Daten.  Es stellte sich heraus, dass der direkte Zugriff der Mitarbeiter auf Daten die Produktivit√§t steigern und einen Wettbewerbsvorteil verschaffen kann. <br><br>  Die erste Generation von In-Memory-Technologie-basierten Analysel√∂sungen bot Gesch√§ftsanwendern jedoch nur sehr begrenzte M√∂glichkeiten, Daten zu verwenden.  Sie konnten nur mit vorgefertigten Bedienfeldern und Dashboards arbeiten.  Die In-Memory-Technologie erm√∂glichte es ihnen, tief in jeden Indikator zu "fallen" und zu sehen, woraus er besteht.  Es ging aber immer um die Indikatoren, die im Voraus festgelegt werden.  Die Studie beschr√§nkte sich auf Visualisierungen, die sich bereits im Dashboard befanden.  Diese Methode zur Verwendung von Daten wurde als "Richtungsanalyse" bezeichnet, und er ging nicht davon aus, dass der Gesch√§ftsbenutzer unabh√§ngig neue Quellen verbinden und selbst Indikatoren und Visualisierungen erstellen w√ºrde. <br><br>  Der n√§chste Schritt bei der Demokratisierung von Daten war die Selbstbedienung.  Die Idee der Selbstbedienung war, dass Gesch√§ftsbenutzer die Daten untersuchen, Visualisierungen erstellen und selbst neue Indikatoren einf√ºhren. <br><br>  Es ist erw√§hnenswert, dass es zu dem Zeitpunkt, als die In-Memory-Technologie begann, die Gesch√§ftsanalyse zu √§ndern, keine ernsthaften technologischen Hindernisse gab, bevor Benutzer Zugriff auf alle Daten erhielten.  Die vielleicht konservativsten Kunden hatten eine Frage zur Angemessenheit einer solchen Funktion.  Aber die Welt hat sich bereits in Richtung des Wunsches gedreht, "alles zu z√§hlen".  Jetzt brauchten Manager, die keine mathematischen Kenntnisse und Programmierkenntnisse haben, auch ein Werkzeug, mit dem sie die Datensprache sprechen k√∂nnen. <br><br>  Der direkte Zugriff auf Daten f√ºr Gesch√§ftsanalysten hat viele neue M√∂glichkeiten er√∂ffnet.  Sie k√∂nnten Hypothesen aufstellen und testen, Data Science-Methoden anwenden, solche Abh√§ngigkeiten identifizieren, deren Existenz im Voraus schwer vorherzusagen ist.  Jetzt k√∂nnen Sie interne Unternehmensdaten mit externen Daten aus Quellen von Drittanbietern kombinieren. <br><br>  Im September 2014 ver√∂ffentlichte Qlik die zweite Generation seiner Plattform namens Qlik Sense.  Qlik Sense verwendete dieselbe Architektur und dieselbe Technologie.  Der Unterschied lag im neuen Ansatz zur Erstellung von Visualisierungen.  Jetzt k√∂nnen Standardvisualisierungen im laufenden Betrieb erstellt werden, indem einfach Felder mit den gew√ºnschten Abmessungen auf das Arbeitsblatt gezogen und dort abgelegt werden.  Dies vereinfachte das Data Mining aufgrund einer sehr starken Verk√ºrzung des Forschungszyklus.  Ein Hypothesentest dauerte nur ein paar Sekunden. <br><br>  M√∂glicherweise war das schnelle Umsatzwachstum bei Self-Service-Analyseplattformen haupts√§chlich auf die einfache Demonstration zur√ºckzuf√ºhren.  Wenn der Kunde fr√ºher unter Ber√ºcksichtigung der Pr√§sentationsfolien eine Kaufentscheidung treffen musste, konnte er das Programm jetzt auf seinem Computer installieren, eine Verbindung zu Quellen herstellen und in wenigen Stunden von der Erstellung eines Dashboards bis zum √ñffnen in seinen Daten gehen. <br><br><h3>  Es gibt Daten.  Was jetzt? </h3><br>  Die In-Memory-Technologie hat einen gro√üen Einfluss darauf, wie Unternehmen Informationen heute nutzen.  Das Kombinieren und Erkunden von Daten ist einfacher geworden, und es war ein starker gesch√§ftlicher Vorsto√ü zur digitalen Transformation.  Es ist jedoch t√∂richt zu sagen, dass die digitale Transformation allt√§glich geworden ist und jetzt jedes Unternehmen sie leicht umsetzen kann. <br><br>  Aus technologischer Sicht ist alles einfach, solange die untersuchte Datenmenge auf mehrere Excel-Tabellen beschr√§nkt ist.  Wenn es darum geht, Milliarden von Datens√§tzen zu kombinieren, wird die Aufgabe aus technischer Sicht h√∂chstwahrscheinlich weiterhin schwierig sein, und ihre L√∂sung erfordert Fachwissen auf dem Gebiet der BI- und technischen Erkenntnisse.  Insbesondere, wenn Sie die Datenqualit√§t noch verwalten m√ºssen, was f√ºr die meisten mittleren und gro√üen Unternehmen eine h√§ufige Aufgabe ist. <br><br>  Aus gesch√§ftlicher Sicht ist alles einfach, solange Sie Berichte oder Dashboards mit branchen√ºblichen Indikatoren ben√∂tigen.  Wenn es sich um ein Analysesystem handelt, zu dem st√§ndig neue Quellen hinzugef√ºgt, neue Metriken eingef√ºhrt und Experten aus verschiedenen Bereichen in all dies einbezogen werden, gibt es auch keine Einfachheit. <br><br>  Dies sind jedoch nicht die Schwierigkeiten, die Kunden vor einigen Jahren √ºberwunden haben.  Der heutige Reifegrad von Analyseplattformen ist so, dass Sie selbst bei vielen Anfangsdaten nicht mehr auf die Berechnung der Indikatoren warten m√ºssen und den erhaltenen Zahlen vertrauen k√∂nnen.  Im Zentrum der Transformation steht das In-Memory-Computing. <br><br>  Die n√§chste Technologie, die den Markt f√ºr analytische L√∂sungen ver√§ndern wird, d√ºrften Cloud-Plattformen sein.  Die Infrastruktur von Cloud Service Providern (CSP) wird zusammen mit einer Reihe von Diensten bereits zu einer Datenverwaltungsplattform. <br><br><hr><br>  Quellen: <br><br>  * IDC, "Market Guide for In-Memory Computing Technologies", <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.academia.edu/20067779/Market_Guide_for_In-Memory_Computing_Technologies</a> <br><br>  ** Jim Gray "Distributed Computing Economics", <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2003-24.doc</a> <br><br>  *** In der interaktiven Visualisierung k√∂nnen Sie sehen, wie sich die Situation von BI-Plattformentwicklern in Gartner Magic Quadrant-Berichten von 2010 bis 2019 ge√§ndert hat: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">qap.bitmetric.nl/extensions/magicquadrant/index.html</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de470113/">https://habr.com/ru/post/de470113/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de470099/index.html">Splatter-Kacheln: So erstellen Sie Kacheln f√ºr Spiele ohne gro√üen Aufwand</a></li>
<li><a href="../de470101/index.html">Regelm√§√üige Avalonia</a></li>
<li><a href="../de470105/index.html">oktech Data Sense # 3: Empfehlungssysteme</a></li>
<li><a href="../de470107/index.html">Tipps und Tricks von meinem Telegramm-Kanal @pythonetc, September 2019</a></li>
<li><a href="../de470109/index.html">@ Pythonetc September 2019</a></li>
<li><a href="../de470117/index.html">Vorbereitungen f√ºr das Kombinieren</a></li>
<li><a href="../de470121/index.html">Firmenprogrammierschulen oder Einstieg in die IT</a></li>
<li><a href="../de470123/index.html">Yandex.Geldfinanzfalle</a></li>
<li><a href="../de470125/index.html">Beurteilen Sie den Code eines anderen nicht streng</a></li>
<li><a href="../de470127/index.html">Komponist mit langem Kurzzeitged√§chtnis</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
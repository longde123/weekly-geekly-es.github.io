<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶Ö ‚òùüèø üà≥ Por que Kaldi √© bom para reconhecimento de fala? (atualizado em 25.12.2019) üë®üèΩ‚Äç‚úàÔ∏è üõ∂ üë®üèæ‚Äçüåæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Por que estou (e espero que voc√™) esteja interessado em reconhecimento de fala? Em primeiro lugar, essa dire√ß√£o √© uma das mais populares em compara√ß√£o...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Por que Kaldi √© bom para reconhecimento de fala? (atualizado em 25.12.2019)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470696/"><img src="https://habrastorage.org/webt/u6/kw/t0/u6kwt05e-r1amvb5tgew7dby6fk.jpeg"><br><br>  Por que estou (e espero que voc√™) esteja interessado em reconhecimento de fala?  Em primeiro lugar, essa dire√ß√£o √© uma das mais populares em compara√ß√£o com outras tarefas da lingu√≠stica de computadores, uma vez que a tecnologia de reconhecimento de fala agora √© usada em quase todos os lugares - desde o reconhecimento de um simples sim / n√£o no call center autom√°tico do banco at√© a capacidade de oferecer suporte a "conversa fiada" em "Coluna inteligente" como "Alice".  Em segundo lugar, para que o sistema de reconhecimento de fala seja de alta qualidade, √© necess√°rio encontrar as ferramentas mais eficazes para criar e configurar esse sistema (este artigo √© dedicado a uma dessas ferramentas).  Finalmente, o indiscut√≠vel "plus" de escolher uma especializa√ß√£o no campo do reconhecimento de fala para mim √© que, para pesquisas nessa √°rea, √© necess√°rio ter habilidades tanto de programador quanto de lingu√≠stica.  Isso √© muito estimulante, for√ßando a aquisi√ß√£o de conhecimento em diferentes disciplinas. <br><a name="habracut"></a><br><h3>  Por que Kaldi, afinal, existem outras estruturas para reconhecimento de fala? </h3><br>  Para responder a essa pergunta, vale a pena considerar os an√°logos existentes e os algoritmos e tecnologias usados ‚Äã‚Äãpor eles (os algoritmos usados ‚Äã‚Äãno Kaldi s√£o descritos mais adiante no artigo): <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">CMU Sphinx</a> <br>  CMU Sphinx (n√£o deve ser confundido com o mecanismo de busca Sphinx!) √â um sistema de reconhecimento de fala criado por desenvolvedores da Carnegie Mellon University e consiste em v√°rios m√≥dulos para extrair recursos de fala, reconhecimento de fala (inclusive em dispositivos m√≥veis) e treinamento para esse reconhecimento.  O CMU Sphinx usa modelos de Markov ocultos no n√≠vel de reconhecimento ac√∫stico-fon√©tico e modelos estat√≠sticos de N-gram no n√≠vel de reconhecimento lingu√≠stico.  O sistema tamb√©m possui v√°rios recursos interessantes: reconhecimento de fala longa (por exemplo, transcri√ß√µes ou grava√ß√µes de som de uma entrevista), capacidade de conectar um grande dicion√°rio de centenas de milhares de formas de palavras etc. √â importante observar que o sistema est√° em constante evolu√ß√£o, com cada vers√£o, a qualidade e o desempenho do reconhecimento s√£o aprimorados .  Tamb√©m existem documenta√ß√£o multiplataforma e conveniente.  Entre as desvantagens do uso deste sistema, √© poss√≠vel destacar a incapacidade de iniciar o CMU Sphinx ‚Äúfora da caixa‚Äù, porque  at√© a solu√ß√£o de problemas simples requer conhecimento sobre a adapta√ß√£o do modelo ac√∫stico, no campo da modelagem de linguagem, etc. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Julius</a> <br>  Julius √© desenvolvido por desenvolvedores japoneses desde 1997, e agora o projeto √© apoiado pelo Instituto de Pesquisa em Ci√™ncia, Tecnologia e Gerenciamento Avan√ßado de Kyoto.  O modelo √© baseado em N-gramas e modelos Markov ocultos sens√≠veis ao contexto; o sistema √© capaz de reconhecer a fala em tempo real.  As desvantagens incluem distribui√ß√£o apenas para o modelo em japon√™s (embora exista um projeto VoxForge que crie modelos ac√∫sticos para outros idiomas, em particular para o idioma ingl√™s) e a falta de atualiza√ß√µes est√°veis. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">RWTH ASR</a> <br>  O modelo foi desenvolvido por especialistas da Universidade T√©cnica da Ren√¢nia-Vestf√°lia desde 2001, consiste em v√°rias bibliotecas e ferramentas escritas em C ++.  O projeto tamb√©m inclui documenta√ß√£o de instala√ß√£o, v√°rios sistemas de treinamento, modelos, modelos ac√∫sticos, modelos de linguagem, suporte para redes neurais, etc. Ao mesmo tempo, o RWTH ASR √© praticamente multiplataforma e tem baixa velocidade. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Htk</a> <br>  O HTK (Hidden Markov Model Toolkit) √© um conjunto de ferramentas de reconhecimento de fala que foi criado na Universidade de Cambridge em 1989.  O kit de ferramentas baseado nos modelos ocultos de Markov √© frequentemente usado como uma ferramenta adicional para criar sistemas de reconhecimento de fala (por exemplo, os desenvolvedores do Julius usam essa estrutura).  Apesar do c√≥digo-fonte estar dispon√≠vel publicamente, o uso do HTK para criar sistemas para usu√°rios finais √© proibido pela licen√ßa, raz√£o pela qual o kit de ferramentas n√£o √© popular agora.  O sistema tamb√©m possui velocidade e precis√£o relativamente baixas. </li></ul><br>  No artigo ‚ÄúAn√°lise comparativa de sistemas de reconhecimento de fala de c√≥digo aberto‚Äù ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">https://research-journal.org/technical/sravnitelnyj-analiz-sistem-raspoznavaniya-rechi-s-otkrytym-kodom/</a> ), foi realizado um estudo durante o qual todos os sistemas foram treinados em um caso de idioma ingl√™s (160 horas) e aplicados em um pequeno caso de teste de 10 horas.  Como resultado, verificou-se que a Kaldi tem a maior precis√£o de reconhecimento, um pouco mais r√°pida que a dos concorrentes em termos de velocidade.  Al√©m disso, o sistema Kaldi √© capaz de fornecer ao usu√°rio a mais rica sele√ß√£o de algoritmos para v√°rias tarefas e √© muito conveniente de usar.  Ao mesmo tempo, enfatiza-se o fato de que o trabalho com documenta√ß√£o pode ser inconveniente para um usu√°rio inexperiente, pois  Ele √© projetado para profissionais de reconhecimento de fala.  Mas, em geral, o Kaldi √© mais adequado para pesquisas cient√≠ficas do que seus equivalentes. <br><cut></cut><br><h3>  Como instalar o Kaldi </h3><br><ol><li>  Fa√ßa o download do arquivo no reposit√≥rio em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">https://github.com/kaldi-asr/kaldi</a> : <br><img src="https://habrastorage.org/webt/2-/2q/wh/2-2qwhrs79zle9ze1jsmqrdeg3k.jpeg"></li><li>  Descompacte o arquivo, v√° para kaldi-master / tools / extras. </li><li>  Executamos ./check_dependencies.sh: <br><img src="https://habrastorage.org/webt/hr/nm/ug/hrnmugjo9pswjvy-vnnbz2unasc.png"><br>  Se depois disso voc√™ n√£o vir "tudo ok", abra o arquivo kaldi-master / tools / INSTALL e siga as instru√ß√µes. </li><li>  Executamos make (estando no kaldi-master / tools, n√£o no kaldi-master / tools / extras): <br><img src="https://habrastorage.org/webt/pl/6w/qz/pl6wqzcxloc93pat9ddwbvpdd-g.png"></li><li>  V√° para kaldi-master / src. </li><li>  Executamos ./configure --shared e voc√™ pode configurar a instala√ß√£o com ou sem a tecnologia CUDA especificando o caminho para o CUDA instalado (./configure --cudatk-dir = / usr / local / cuda-8.0) ou altere o valor inicial ‚Äúyes "Para" n√£o "(./ configure --use-cuda = no) respectivamente. <br><br>  Se ao mesmo tempo voc√™ vir: <br><br><img src="https://habrastorage.org/webt/0o/fo/fk/0ofofk6kgbhousqfpnzagxh5lze.png"><br><br>  ou voc√™ n√£o seguiu a etapa 4 ou precisa fazer o download e instalar o OpenFst: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">http://www.openfst.org/twiki/bin/view/FST/FstDownload</a> . </li><li>  N√≥s fazemos depender. </li><li>  Executamos make -j.  √â recomend√°vel que voc√™ digite o n√∫mero correto de n√∫cleos de processador que voc√™ usar√° ao criar, por exemplo, make -j 2. </li><li>  Como resultado, obtemos: <br><img src="https://habrastorage.org/webt/h4/bs/zb/h4bszbrxejdjz02pxg7jx110v78.png"></li></ol><cut></cut><br><h3>  Um exemplo de uso de um modelo com o Kaldi instalado </h3><br>  Como exemplo, usei o modelo kaldi-ru vers√£o 0.6, <a href="" rel="nofollow">voc√™ pode baix√°-lo neste link</a> : <br><br><ol><li>  Ap√≥s o download, v√° para o arquivo kaldi-ru-0.6 / decode.sh e especifique o caminho para o Kaldi instalado, ele ser√° assim para mim: <br><br><img src="https://habrastorage.org/webt/g6/a_/ah/g6a_ahhtdnva3mmlhbu5fn7yqii.png"><br></li><li>  Iniciamos o modelo, indicando o arquivo no qual o discurso deve ser reconhecido.  Voc√™ pode usar o arquivo decoder-test.wav, este √© um arquivo especial para o teste, j√° est√° nesta pasta: <br><br><img src="https://habrastorage.org/webt/gq/er/gt/gqergtoumyqfba4uhvo_j--cydm.png"><br></li><li>  E aqui est√° o que o modelo reconheceu: <br><img src="https://habrastorage.org/webt/8g/sh/kj/8gshkjtdsxzh_lj8xl7djhoen1k.png"></li></ol><br><h3>  Quais algoritmos s√£o usados, o que sustenta o trabalho? </h3><br>  Informa√ß√µes completas sobre o projeto podem ser encontradas em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">http://kaldi-asr.org/doc/</a> , aqui vou destacar alguns pontos-chave: <br><br><ul><li>  O MFCC ac√∫stico (coeficientes cepstrais de frequ√™ncia de mel) ou os PLPs um pouco menos populares (previs√£o linear perceptiva - veja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">H. Hermansky, ‚ÄúAn√°lise preditiva linear perceptiva da fala (PLP) da fala‚Äù</a> ) s√£o usados ‚Äã‚Äãpara extrair recursos ac√∫sticos do sinal de entrada.  No primeiro m√©todo, o espectro do sinal original √© convertido da escala de Hertz para a escala de giz e, em seguida, os coeficientes cepstrais s√£o calculados usando a transforma√ß√£o inversa de cosseno (https://habr.com/en/post/140828/).  O segundo m√©todo √© baseado na representa√ß√£o de regress√£o da fala: √© constru√≠do um modelo de sinal que descreve a previs√£o da amostra de sinal atual por uma combina√ß√£o linear - o produto de amostras conhecidas de sinais de entrada e sa√≠da e coeficientes de previs√£o linear.  A tarefa de calcular os sinais de fala √© reduzida para encontrar esses coeficientes sob certas condi√ß√µes. </li><li>  O m√≥dulo de modelagem ac√∫stica inclui modelos Markov ocultos (HMM), um modelo misto de distribui√ß√µes gaussianas (GMM), redes neurais profundas, nomeadamente redes neurais com atraso de tempo (TDNN). </li><li>  A modelagem de linguagem √© realizada usando uma m√°quina de estados finitos ou FST (transdutor de estado finito).  O FST codifica um mapeamento de uma sequ√™ncia de caracteres de entrada para uma sequ√™ncia de caracteres de sa√≠da e h√° pesos para a transi√ß√£o que determinam a probabilidade de calcular o caractere de entrada na sa√≠da. </li><li>  A decodifica√ß√£o ocorre usando o algoritmo forward-reverse. </li></ul><br><h3>  Sobre a cria√ß√£o do modelo kaldi-ru-0.6 </h3><br>  Para o idioma russo, existe um modelo de reconhecimento pr√©-treinado criado por Nikolai Shmyryov, tamb√©m conhecido em muitos sites e f√≥runs como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">nsh</a> . <br><br><ul><li>  Para extrair caracter√≠sticas, foi utilizado o m√©todo MFCC, e o modelo ac√∫stico-fon√©tico √© baseado em redes neurais do tipo TDNN. </li><li>  A amostra do treinamento foram as trilhas sonoras de v√≠deos em russo, baixados do YouTube. </li><li>  Para criar um modelo de idioma, usamos o dicion√°rio CMUdict e exatamente o vocabul√°rio que estava no conjunto de treinamento.  Devido ao fato de o dicion√°rio conter pron√∫ncias semelhantes de palavras diferentes, foi decidido atribuir a cada palavra o valor de ‚Äúprobabilidade‚Äù e normaliz√°-las. </li><li>  Para aprender o modelo de linguagem, foi usada a estrutura RNNLM (modelos de linguagem de rede neural recorrente), baseada, como o nome indica, em redes neurais recorrentes (em vez dos bons e antigos N-gramas). </li></ul><br><cut></cut><br><h3>  Compara√ß√£o com a API do Google Speech e o Yandex Speech Kit </h3><br>  Certamente, um dos leitores, ao ler os par√°grafos anteriores, fez uma pergunta: ok, descobrimos que o Kaldi √© superior aos seus an√°logos diretos, mas e os sistemas de reconhecimento do Google e do Yandex?  Talvez a relev√¢ncia das estruturas descritas anteriormente seja duvidosa se existem ferramentas desses dois gigantes?  A pergunta √© muito boa, ent√£o vamos testar! <br><br><ul><li>  Como conjunto de dados, pegamos os registros e a descriptografia de texto correspondente do not√≥rio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">VoxForge</a> .  Como resultado, depois que cada sistema reconheceu 3677 arquivos de som, recebi os seguintes valores WER (Word Error Rate): <br><br><img src="https://habrastorage.org/webt/ca/s9/vr/cas9vriacqyf-xrvijr3-dxu3_s.jpeg"><br></li><li>  Os registros do VoxForge s√£o aproximadamente semelhantes na aus√™ncia de ru√≠do de fundo, entona√ß√£o, velocidade da fala etc.  Vamos complicar a tarefa: pegue o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">subcorpus de</a> valida√ß√£o open_stt, que inclui conversas telef√¥nicas, clipes de √°udio de v√≠deos do YouTube e audiolivros e avalie o desempenho usando WER e CER (Taxa de erro de caracteres). <br><br>  Depois de receber as transcri√ß√µes de texto, notei que o Google e o Yandex (ao contr√°rio de Kaldi) reconheceram palavras como <br>  "Um" como "1".  Dessa forma, houve a necessidade de corrigir esses casos (como nas transcri√ß√µes de refer√™ncia fornecidas pelos autores do open_stt, tudo √© apresentado em termos alfab√©ticos), o que afetou o resultado final: <br><br><img src="https://habrastorage.org/webt/1e/si/iw/1esiiwizr_zz5y1p7vdc6ye_ao8.png"><br></li></ul><br>  Resumindo, podemos dizer que todos os sistemas lidaram com a tarefa aproximadamente no mesmo n√≠vel, e Kaldi n√£o era muito inferior ao Yandex Speech Kit e √† API do Google Speech.  No segundo caso, o Yandex Speech Kit tem o melhor desempenho, pois  ele reconhece melhor arquivos de √°udio curtos em compara√ß√£o com concorrentes que n√£o conseguiram reconhecer nenhuma parte deles (para o Google, o n√∫mero desses arquivos √© muito grande).  Por fim, vale ressaltar que o Kaldi levou mais de 12 horas para reconhecer os arquivos 28111, outros sistemas gerenciados em muito menos tempo.  Mas, ao mesmo tempo, o Yandex Speech Kit e a API do Google Speech s√£o "caixas negras" que funcionam em algum lugar muito distante nos servidores de outras pessoas e n√£o s√£o acess√≠veis para ajuste, mas o Kaldi pode ser adaptado √†s especificidades da tarefa em quest√£o - vocabul√°rio caracter√≠stico (profissionalismo, jarg√£o, g√≠ria coloquial), recursos de pron√∫ncia etc.  E tudo isso de gra√ßa e sem SMS!  O sistema √© um tipo de designer, que todos n√≥s podemos usar para criar algo incomum e interessante. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Agrade√ßo √†</a> equipe do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">Yandex.Cloud</a> , que me ajudou na implementa√ß√£o do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">reconhecimento de</a> caso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">open_stt</a> . <br><br>  Eu trabalho no laborat√≥rio APDiMO NSU: <br>  Site: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">https://bigdata.nsu.ru/</a> <br>  Grupo VK: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow">https://vk.com/lapdimo</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt470696/">https://habr.com/ru/post/pt470696/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt470684/index.html">O que escrever no curr√≠culo se n√£o houver experi√™ncia profissional</a></li>
<li><a href="../pt470686/index.html">Tecnologia para a cidade inteligente. S√£o Petersburgo se tornar√° a primeira metr√≥pole conveniente para cegos?</a></li>
<li><a href="../pt470688/index.html">O que se sabe sobre o VMworld 2019</a></li>
<li><a href="../pt470692/index.html">Como criamos um novo site do Rosbank e o que veio dele</a></li>
<li><a href="../pt470694/index.html">Escolhendo uma plataforma de email marketing: o que prestar aten√ß√£o √†s empresas russas</a></li>
<li><a href="../pt470700/index.html">Mesa. Met√°lico Silencioso O seu</a></li>
<li><a href="../pt470706/index.html">Python + Keras + LSTM: fa√ßa um tradutor de texto em meia hora</a></li>
<li><a href="../pt470710/index.html">Machine Learning para sua ca√ßa plana. Parte 2</a></li>
<li><a href="../pt470714/index.html">Como fui para a final do avan√ßo digital</a></li>
<li><a href="../pt470718/index.html">"Efeitos alg√©bricos" na linguagem humana</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
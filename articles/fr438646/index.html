<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>„ÄΩÔ∏è ‚òùüèº üë©üèø‚Äçü§ù‚Äçüë©üèª √Ä propos de la cr√©ation d'images st√©r√©o √† petit budget sur les doigts (st√©r√©ogramme, anaglyphe, st√©r√©oscope) üè≥Ô∏è üëÇüèª üëºüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le week-end prochain est arriv√©, vous devez √©crire quelques dizaines de lignes de code et dessiner une image, mais aucune n'est meilleure. Donc, le we...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>√Ä propos de la cr√©ation d'images st√©r√©o √† petit budget sur les doigts (st√©r√©ogramme, anaglyphe, st√©r√©oscope)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/438646/">  Le week-end prochain est arriv√©, vous devez √©crire quelques dizaines de lignes de code et dessiner une image, mais aucune n'est meilleure.  Donc, le week-end dernier avant-dernier, j'ai montr√© comment <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">faire le ray tracing</a> et m√™me <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tout exploser.</a>  C'est surprenant pour beaucoup, mais l'infographie est une chose tr√®s simple, quelques centaines de lignes de C ++ nues suffisent pour cr√©er des images int√©ressantes. <br><br>  Le sujet de la conversation d'aujourd'hui est la vision binoculaire, et aujourd'hui nous ne pouvons m√™me pas atteindre cent lignes de code.  √ätre capable de rendre des sc√®nes en trois dimensions, il serait stupide de passer des paires de st√©r√©os, aujourd'hui nous allons dessiner quelque chose comme ceci: <br><br><img src="https://habrastorage.org/webt/2-/8t/3n/2-8t3n-oonieil_v4f_lntjpvzk.jpeg"><br><a name="habracut"></a><br>  La folie des d√©veloppeurs de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Magic Carpet</a> me hante.  Pour ceux qui ne l'ont pas trouv√©, ce jeu a permis de faire du rendu 3D √† la fois en anaglyphe et en st√©r√©ogrammes <b>dans les param√®tres principaux, juste disponible dans le menu!</b>  Ce cerveau a explos√© pr√©cis√©ment. <br><br><h1>  Parallax </h1><br>  Commen√ßons donc.  Pour commencer, pourquoi notre appareil visuel nous permet-il de percevoir la profondeur?  Il y a un mot si intelligent "parallaxe".  Si sur les doigts, concentrons-nous sur l'√©cran.  Tout ce qui se trouve dans le plan de l'√©cran de notre cerveau existe en un seul exemplaire.  Mais si tout √† coup une mouche vole devant l'√©cran, alors (si nous ne changeons pas nos yeux!) Notre cerveau l'enregistrera en double.  Et en m√™me temps, l'araign√©e sur le mur derri√®re l'√©cran bifurque √©galement, et la direction de la bifurcation d√©pend de si l'objet est devant le point focal ou derri√®re: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a40/e9b/b9d/a40e9bb9d4a6e0cddcdce4bdfcc5095d.png"><br><br>  Notre cerveau est une machine tr√®s efficace pour analyser des images l√©g√®rement diff√©rentes.  Il utilise la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">disparit√©</a> pour obtenir des informations de profondeur √† partir d'images r√©tiniennes bidimensionnelles pour la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">st√©r√©opsie</a> .  Eh bien, Dieu les b√©nisse, avec les mots, faisons mieux de dessiner des images! <br><br>  Supposons que notre √©cran soit une fen√™tre sur le monde virtuel :) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c9a/645/594/c9a645594d957d52f5d4c3e067bd3cb7.png"><br><br>  Notre t√¢che est de dessiner deux images avec ce qui sera visible √† travers cette ¬´fen√™tre¬ª.  Il y aura deux images, une pour chaque ≈ìil, dans le sch√©ma ci-dessus que je leur ai montr√© avec un "sandwich" rouge et bleu.  Ne nous occupons pas encore de la fa√ßon dont nous alimentons exactement ces images dans l'appareil visuel, nous avons juste besoin d'enregistrer deux fichiers.  Je suis particuli√®rement int√©ress√© par la fa√ßon dont ces images peuvent √™tre obtenues en utilisant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">notre traceur de rayons</a> . <br><br>  Eh bien, supposons que la direction du regard ne change pas, c'est un vecteur (0,0, -1).  Supposons que nous puissions d√©placer la position de la cam√©ra de la distance interoculaire, quoi d'autre?  Il y a une petite subtilit√©: le c√¥ne de vue √† travers notre ¬´fen√™tre¬ª est asym√©trique.  Et notre traceur de rayons ne peut rendre qu'un c√¥ne de regard sym√©trique: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e00/5c1/b99/e005c1b996cc7eb9978bc434f6773196.png"><br><br>  Que faire?  Lire :) <br>  En fait, nous pouvons rendre les images plus larges que ce dont nous avons besoin et simplement recadrer l'exc√©dent: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cb8/f49/3d1/cb8f493d14679c297d6510a1a79ef1a3.png"><br><br><h1>  Anaglyphe </h1><br>  Avec le m√©canisme de rendu g√©n√©ral, il devrait √™tre clair, il est maintenant temps de nous interroger sur la livraison de l'image √† notre cerveau.  L'une des options les plus simples est les lunettes rouge-bleu: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd4/7fb/815/cd47fb815c7a1e80e2d908049e8e4bf0.jpg"><br><br>  Nous faisons juste les deux pr√©-rendus non pas en noir mais en blanc, √©crivons l'image de gauche dans le canal rouge et l'image de droite en bleu.  Vous obtenez l'image suivante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9d7/8f6/4f3/9d78f64f371b5960b1d19f5deaff0d9e.jpg"><br><br>  Le verre rouge coupera un canal et le verre bleu en coupera un autre, de sorte que chaque ≈ìil recevra sa propre image et nous pourrons regarder le monde en 3D.  Voici les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">modifications apport√©es au commit principal du premier article</a> , qui montrent √† la fois les param√®tres de la cam√©ra pour les deux yeux et l'assemblage du canal. <br><br>  Les rendus anaglyphiques sont l'une des plus anciennes fa√ßons de visualiser (ordinateur!) Des images st√©r√©o.  Ils pr√©sentent de nombreuses lacunes, par exemple un mauvais rendu des couleurs (au fait, essayez d'enregistrer le canal vert de l'≈ìil droit dans le canal vert de l'image finale).  Un avantage - ces verres sont facilement fabriqu√©s √† partir de mat√©riaux improvis√©s. <br><br><h1>  St√©r√©oscope </h1><br>  Avec la prolif√©ration des smartphones, nous nous sommes souvenus de ce que sont les st√©r√©oscopes (qui, pour une seconde, ont √©t√© invent√©s au 19√®me si√®cle)!  Il y a quelques ann√©es, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Google a sugg√©r√© d'</a> utiliser deux lentilles penny (malheureusement, elles ne sont pas faites sur le genou), du carton (tra√Ænant partout) et un smartphone (couch√© dans votre poche) pour obtenir des lunettes de r√©alit√© virtuelle tout √† fait tol√©rables: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/328/5d8/98a/3285d898a99110b217a0fbdbc8ddb535.jpg"><br><br>  Sur aliexpress, c'√©taient des tas, cent roubles par pi√®ce.  Par rapport √† l'anaglyphe, vous n'avez rien √† faire du tout, prenez simplement deux photos et composez-les c√¥te √† c√¥te, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">voici le commit</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/82e/563/cfe/82e563cfe69db42b7f5f2f399261d12d.jpg"><br><br>  √Ä strictement parler, en fonction de l'objectif, une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">correction de la distorsion de l'</a> objectif peut √™tre n√©cessaire, mais je n'ai pas pris la peine du tout, et √ßa a l'air bien sur mes lunettes.  Mais si vous avez vraiment besoin d'appliquer une pr√©-distorsion en forme de tonneau qui compense la distorsion de l'objectif, voici √† quoi cela ressemble pour mon smartphone et mes lunettes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9e2/583/9f5/9e25839f5ea28b1f4e092106f60bebfe.jpg"><br><br><h1>  St√©r√©ogrammes </h1><br>  Mais que faire si vous ne souhaitez pas utiliser d'appareils suppl√©mentaires?  Ensuite, il n'y a qu'une seule option - engourdir.  De mani√®re g√©n√©rale, l'image pr√©c√©dente suffit pour regarder en st√©r√©o, utilisez simplement l'astuce pour regarder en st√©r√©o.  Il existe deux principes pour visualiser les st√©r√©ogrammes: bougez vos yeux ou √©cartez vos yeux.  J'ai donc dessin√© un diagramme dans lequel je montre comment vous pouvez regarder l'image pr√©c√©dente.  L'image pr√©c√©dente est double, deux barres rouges sur le diagramme montrent deux images sur la r√©tine gauche, deux bleues sur la droite. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/86e/14a/47b/86e14a47b4e2ae8aa9246becb7155827.png"><br><br>  Si nous concentrons nos yeux sur l'√©cran, alors sur quatre images, nous en obtenons deux.  Si nous louchons nos yeux vers le nez, il est tout √† fait possible de montrer au cerveau ¬´trois¬ª images.  Et vice versa, si vous ouvrez les yeux, vous pouvez √©galement obtenir "trois" images.  La superposition d'images centrales donnera au cerveau un effet st√©r√©o. <br><br>  Ces m√©thodes sont donn√©es √† diff√©rentes personnes de diff√©rentes mani√®res, par exemple, je ne sais pas du tout bouger mes yeux, mais je me reproduis facilement.  Il est important que le st√©r√©ogramme construit pour une m√©thode soit vu de la m√™me mani√®re, sinon une carte de profondeur invers√©e est obtenue (voir parallaxe n√©gative et positive).  Le probl√®me avec cette m√©thode de visualisation st√©r√©o est qu'il est tr√®s difficile <b>de</b> bouger <b>fortement les</b> yeux par rapport √† l'√©tat normal, vous devez donc vous contenter de petites images.  Et si vous en voulez de gros?  Sacrifions compl√®tement la couleur et ne voulons qu'une perception de la profondeur.  Pour l'avenir, voici l'image que nous obtenons √† la fin de cette partie: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f7b/e7b/ab2/f7be7bab228dcd5133b2d1ff3a9032e1.jpg"><br><br>  Ce st√©r√©ogramme est con√ßu pour ¬´diluer¬ª les yeux (st√©r√©ogramme aux yeux muraux).  Pour ceux qui pr√©f√®rent la vision inverse, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">prenez une photo ici</a> .  Si vous n'√™tes pas habitu√© aux st√©r√©ogrammes, essayez diff√©rentes conditions: une image plein √©cran, une petite image, une lumi√®re vive, l'obscurit√©.  La t√¢che consiste √† ouvrir les yeux afin que les deux bandes vorticales adjacentes co√Øncident.  La fa√ßon la plus simple de se concentrer sur le coin sup√©rieur gauche est  elle est plate.  Par exemple, je suis entour√© par l'environnement de l'hubr, j'ouvre l'image en plein √©cran.  N'oubliez pas d'en retirer la souris! <br><br>  Ne vous contentez pas de l'effet 3D d√©fectueux.  Si vous n'√™tes que vaguement conscient des formes arrondies au milieu de points al√©atoires ainsi que de faibles effets 3D, c'est certainement une illusion incompl√®te!  Si vous regardez correctement, les boules doivent clairement sortir du plan de l'√©cran pour le spectateur, l'effet doit √™tre stable et maintenu en raison de l'√©tude constante et d√©taill√©e de chaque partie de l'image, √† la fois au premier plan et √† l'arri√®re-plan.  La st√©r√©opsie a une hyst√©r√©sis: d√®s que vous obtenez une image stable, elle devient plus claire plus vous regardez longtemps.  Plus l'√©cran est √©loign√© des yeux, plus l'effet de profondeur est important. <br><br>  Ce st√©r√©ogramme a √©t√© dessin√© selon la m√©thode propos√©e il y a un quart de si√®cle par Thimbleby et al. Dans leur article ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Affichage d'images 3D: algorithmes pour les st√©r√©ogrammes √† points al√©atoires √† image unique</a> ¬ª. <br><br><h3>  Point de d√©part </h3><br>  Le point de d√©part du rendu des st√©r√©ogrammes est une carte de profondeur (nous avons oubli√© la couleur).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Voici un commit</a> qui rend une telle image: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/53c/201/75f/53c20175f5fa2667a7dd7592fee343c4.jpg"><br><br>  Les profondeurs de notre rendu sont coup√©es par les plans proche et √©loign√©, c'est-√†-dire que le point le plus √©loign√© de ma carte a une profondeur de 0, la plus proche. <br><br><h3>  Principe de base </h3><br>  Que nos yeux soient √† une distance d de l'√©cran.  Placez le plan √©loign√© (imaginaire) (z = 0) √† la m√™me distance derri√®re l'√©cran.  On choisit une constante Œº, qui d√©termine la position du plan proche (z = 0): elle sera √† une distance Œºd de la plus √©loign√©e.  J'ai choisi Œº = 1/3 dans mon code.  Au total, notre monde entier vit √† une distance de d-Œºd √† d derri√®re l'√©cran.  Ayons une distance e d√©finie entre les yeux (en pixels, dans mon code j'ai choisi 400 pixels). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c6/0eb/e87/5c60ebe872837aea90879fa0798ac7e7.png"><br><br>  Si nous regardons le point de notre objet marqu√© en rouge sur le diagramme, alors deux pixels marqu√©s en vert devraient avoir la m√™me couleur dans le st√©r√©ogramme.  Comment trouver la distance entre ces pixels?  Tr√®s simple.  Si le point projet√© actuel a une profondeur de z, alors le rapport de parallaxe √† la distance entre les yeux est √©gal au rapport des profondeurs correspondantes: p / e = (d-dŒºz) / (2d-dŒºz).  Soit dit en passant, d diminue et n'est impliqu√© nulle part ailleurs!  Autrement dit, p / e = (1-Œºz) / (2-Œºz), ce qui signifie que la parallaxe est √©gale √† p = e * (1-Œºz) / (2-Œºz) pixels. <br><br>  Autrement dit, le principe de base de la construction d'un st√©r√©ogramme: nous parcourons toute la carte de profondeur, pour chaque valeur de profondeur, nous d√©terminons quels pixels doivent avoir la m√™me couleur, et √©crivons cela dans notre syst√®me de restrictions.  Ensuite, nous partons d'une image arbitraire et essayons de respecter toutes les restrictions pr√©c√©demment impos√©es. <br><br><h3>  Pr√©parez l'image originale </h3><br>  √Ä ce stade, nous pr√©parerons une image sur laquelle nous imposerons plus tard des restrictions de parallaxe. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ici, engagez-vous</a> , il dessine cette image: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/197/441/685/197441685bf85d56e5416e0af899ace1.jpg"><br><br>  Notez qu'en g√©n√©ral les couleurs sont juste al√©atoires, sauf que je mets rand () * sin dans le canal rouge pour fournir des ondes p√©riodiques.  Ces ondes sont faites avec une distance de 200 pixels, ceci (avec Œº = 1/3 et e = 400 s√©lectionn√©s) est la valeur maximale de parallaxe dans notre monde, c'est aussi un plan √©loign√©.  Ces ondes sont facultatives, mais elles faciliteront la concentration n√©cessaire de la vision. <br><br><h3>  Rendu st√©r√©ogramme </h3><br>  En fait, le code complet li√© au st√©r√©ogramme ressemble √† ceci: <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parallax</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> z)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> eye_separation = <span class="hljs-number"><span class="hljs-number">400.</span></span>; <span class="hljs-comment"><span class="hljs-comment">// interpupillary distance in pixels const float mu = .33; // if the far plane is a distance D behind the screen, then the near plane is a distance mu*D in front of the far plane return static_cast&lt;int&gt;(eye_separation*((1.-z*mu)/(2.-z*mu))+.5); } size_t uf_find(std::vector&lt;size_t&gt; &amp;same, size_t x) { return same[x]==x ? x : uf_find(same, same[x]); } void uf_union(std::vector&lt;size_t&gt; &amp;same, size_t x, size_t y) { if ((x=uf_find(same, x)) != (y=uf_find(same, y))) same[x] = y; } int main() { [...] for (size_t j=0; j&lt;height; j++) { // autostereogram rendering loop std::vector&lt;size_t&gt; same(width); std::iota(same.begin(), same.end(), 0); // initialize the union-find data structure (same[i]=i) for (size_t i=0; i&lt;width; i++) { // put the constraints int par = parallax(zbuffer[i+j*width]); int left = i - par/2; int right = left + par; // works better than i+par/2 for odd values of par if (left&gt;=0 &amp;&amp; right&lt;(int)width) uf_union(same, left, right); // left and right pixels will have the same color } for (size_t i=0; i&lt;width; i++) { // resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; } } [...]</span></span></code> </pre> <br>  Si quoi que ce soit, alors <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">engagez-vous ici</a> .  La fonction int parallaxe (const float z) donne la distance entre les pixels de la m√™me couleur pour la valeur de profondeur actuelle.  Nous rendons le st√©r√©ogramme ligne par ligne, car les lignes sont ind√©pendantes les unes des autres (nous n'avons pas de parallaxe verticale).  Par cons√©quent, la boucle principale traverse simplement toutes les lignes;  pour chacun d'eux, nous commen√ßons par un ensemble illimit√© complet de pixels, sur lequel nous imposerons ensuite des restrictions d'√©galit√© par paire, et √† la fin nous aurons un certain nombre de clusters de pixels (d√©connect√©s) de la m√™me couleur.  Par exemple, un pixel avec un index √† gauche et un pixel avec un index √† droite devraient finir par √™tre les m√™mes. <br><br>  Comment stocker cet ensemble de restrictions?  La r√©ponse la plus simple est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la structure de donn√©es union-find</a> .  Je ne vais pas le d√©crire, ce ne sont que trois lignes de code, vous pouvez le lire sur Wikipedia.  L'id√©e principale est que pour chaque cluster, nous en aurons un certain ¬´responsable¬ª, c'est aussi un pixel racine, nous lui laisserons la m√™me couleur que dans l'image d'origine, et nous repeindrons tous les autres pixels du cluster: <br><br><pre> <code class="cpp hljs"> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;width; i++) { <span class="hljs-comment"><span class="hljs-comment">// resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; }</span></span></code> </pre><br><h1>  Conclusion </h1><br>  Eh bien, en fait, c'est tout.  Vingt lignes de code - et notre st√©r√©ogramme est pr√™t, cassez vos yeux et vos t√™tes, dessinez des images!  Soit dit en passant, juste des couleurs al√©atoires dans un st√©r√©ogramme est g√©n√©ralement un luxe, en principe, si vous essayez, vous pouvez √©galement transmettre partiellement la couleur de notre image. <br><br>  D'autres syst√®mes de visionnage st√©r√©o, par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">li√©s √† la polarisation</a> , ont √©t√© retir√©s de la discussion, car ils d√©passent le budget de cent roubles.  Si vous manquez quelque chose, ajoutez et corrigez! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr438646/">https://habr.com/ru/post/fr438646/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr438636/index.html">Incorporation d√©fectueuse de fonctions dans Go</a></li>
<li><a href="../fr438638/index.html">Nous analysons le protocole des messages pager POCSAG, partie 2</a></li>
<li><a href="../fr438640/index.html">Monnaie √©lectronique ouverte √† grande vitesse</a></li>
<li><a href="../fr438642/index.html">Les bases de la programmation r√©active √† l'aide de RxJS</a></li>
<li><a href="../fr438644/index.html">La s√©curit√© des algorithmes d'apprentissage automatique. Protection et test de mod√®les √† l'aide de Python</a></li>
<li><a href="../fr438648/index.html">Comparaison des syst√®mes de BI (Tableau, Power BI, Oracle, Qlik)</a></li>
<li><a href="../fr438650/index.html">Rocket 9M729. Quelques mots sur le ¬´violateur¬ª du trait√© INF</a></li>
<li><a href="../fr438652/index.html">IDA de portabelization</a></li>
<li><a href="../fr438654/index.html">OpenSceneGraph: int√©gration avec Qt Framework</a></li>
<li><a href="../fr438658/index.html">Comment apprendre √† apprendre</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
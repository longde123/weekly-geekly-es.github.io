<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>〽️ ☝🏼 👩🏿‍🤝‍👩🏻 À propos de la création d'images stéréo à petit budget sur les doigts (stéréogramme, anaglyphe, stéréoscope) 🏳️ 👂🏻 👼🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le week-end prochain est arrivé, vous devez écrire quelques dizaines de lignes de code et dessiner une image, mais aucune n'est meilleure. Donc, le we...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>À propos de la création d'images stéréo à petit budget sur les doigts (stéréogramme, anaglyphe, stéréoscope)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/438646/">  Le week-end prochain est arrivé, vous devez écrire quelques dizaines de lignes de code et dessiner une image, mais aucune n'est meilleure.  Donc, le week-end dernier avant-dernier, j'ai montré comment <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">faire le ray tracing</a> et même <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tout exploser.</a>  C'est surprenant pour beaucoup, mais l'infographie est une chose très simple, quelques centaines de lignes de C ++ nues suffisent pour créer des images intéressantes. <br><br>  Le sujet de la conversation d'aujourd'hui est la vision binoculaire, et aujourd'hui nous ne pouvons même pas atteindre cent lignes de code.  Être capable de rendre des scènes en trois dimensions, il serait stupide de passer des paires de stéréos, aujourd'hui nous allons dessiner quelque chose comme ceci: <br><br><img src="https://habrastorage.org/webt/2-/8t/3n/2-8t3n-oonieil_v4f_lntjpvzk.jpeg"><br><a name="habracut"></a><br>  La folie des développeurs de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Magic Carpet</a> me hante.  Pour ceux qui ne l'ont pas trouvé, ce jeu a permis de faire du rendu 3D à la fois en anaglyphe et en stéréogrammes <b>dans les paramètres principaux, juste disponible dans le menu!</b>  Ce cerveau a explosé précisément. <br><br><h1>  Parallax </h1><br>  Commençons donc.  Pour commencer, pourquoi notre appareil visuel nous permet-il de percevoir la profondeur?  Il y a un mot si intelligent "parallaxe".  Si sur les doigts, concentrons-nous sur l'écran.  Tout ce qui se trouve dans le plan de l'écran de notre cerveau existe en un seul exemplaire.  Mais si tout à coup une mouche vole devant l'écran, alors (si nous ne changeons pas nos yeux!) Notre cerveau l'enregistrera en double.  Et en même temps, l'araignée sur le mur derrière l'écran bifurque également, et la direction de la bifurcation dépend de si l'objet est devant le point focal ou derrière: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a40/e9b/b9d/a40e9bb9d4a6e0cddcdce4bdfcc5095d.png"><br><br>  Notre cerveau est une machine très efficace pour analyser des images légèrement différentes.  Il utilise la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">disparité</a> pour obtenir des informations de profondeur à partir d'images rétiniennes bidimensionnelles pour la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">stéréopsie</a> .  Eh bien, Dieu les bénisse, avec les mots, faisons mieux de dessiner des images! <br><br>  Supposons que notre écran soit une fenêtre sur le monde virtuel :) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c9a/645/594/c9a645594d957d52f5d4c3e067bd3cb7.png"><br><br>  Notre tâche est de dessiner deux images avec ce qui sera visible à travers cette «fenêtre».  Il y aura deux images, une pour chaque œil, dans le schéma ci-dessus que je leur ai montré avec un "sandwich" rouge et bleu.  Ne nous occupons pas encore de la façon dont nous alimentons exactement ces images dans l'appareil visuel, nous avons juste besoin d'enregistrer deux fichiers.  Je suis particulièrement intéressé par la façon dont ces images peuvent être obtenues en utilisant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">notre traceur de rayons</a> . <br><br>  Eh bien, supposons que la direction du regard ne change pas, c'est un vecteur (0,0, -1).  Supposons que nous puissions déplacer la position de la caméra de la distance interoculaire, quoi d'autre?  Il y a une petite subtilité: le cône de vue à travers notre «fenêtre» est asymétrique.  Et notre traceur de rayons ne peut rendre qu'un cône de regard symétrique: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e00/5c1/b99/e005c1b996cc7eb9978bc434f6773196.png"><br><br>  Que faire?  Lire :) <br>  En fait, nous pouvons rendre les images plus larges que ce dont nous avons besoin et simplement recadrer l'excédent: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cb8/f49/3d1/cb8f493d14679c297d6510a1a79ef1a3.png"><br><br><h1>  Anaglyphe </h1><br>  Avec le mécanisme de rendu général, il devrait être clair, il est maintenant temps de nous interroger sur la livraison de l'image à notre cerveau.  L'une des options les plus simples est les lunettes rouge-bleu: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd4/7fb/815/cd47fb815c7a1e80e2d908049e8e4bf0.jpg"><br><br>  Nous faisons juste les deux pré-rendus non pas en noir mais en blanc, écrivons l'image de gauche dans le canal rouge et l'image de droite en bleu.  Vous obtenez l'image suivante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9d7/8f6/4f3/9d78f64f371b5960b1d19f5deaff0d9e.jpg"><br><br>  Le verre rouge coupera un canal et le verre bleu en coupera un autre, de sorte que chaque œil recevra sa propre image et nous pourrons regarder le monde en 3D.  Voici les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">modifications apportées au commit principal du premier article</a> , qui montrent à la fois les paramètres de la caméra pour les deux yeux et l'assemblage du canal. <br><br>  Les rendus anaglyphiques sont l'une des plus anciennes façons de visualiser (ordinateur!) Des images stéréo.  Ils présentent de nombreuses lacunes, par exemple un mauvais rendu des couleurs (au fait, essayez d'enregistrer le canal vert de l'œil droit dans le canal vert de l'image finale).  Un avantage - ces verres sont facilement fabriqués à partir de matériaux improvisés. <br><br><h1>  Stéréoscope </h1><br>  Avec la prolifération des smartphones, nous nous sommes souvenus de ce que sont les stéréoscopes (qui, pour une seconde, ont été inventés au 19ème siècle)!  Il y a quelques années, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Google a suggéré d'</a> utiliser deux lentilles penny (malheureusement, elles ne sont pas faites sur le genou), du carton (traînant partout) et un smartphone (couché dans votre poche) pour obtenir des lunettes de réalité virtuelle tout à fait tolérables: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/328/5d8/98a/3285d898a99110b217a0fbdbc8ddb535.jpg"><br><br>  Sur aliexpress, c'étaient des tas, cent roubles par pièce.  Par rapport à l'anaglyphe, vous n'avez rien à faire du tout, prenez simplement deux photos et composez-les côte à côte, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">voici le commit</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/82e/563/cfe/82e563cfe69db42b7f5f2f399261d12d.jpg"><br><br>  À strictement parler, en fonction de l'objectif, une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">correction de la distorsion de l'</a> objectif peut être nécessaire, mais je n'ai pas pris la peine du tout, et ça a l'air bien sur mes lunettes.  Mais si vous avez vraiment besoin d'appliquer une pré-distorsion en forme de tonneau qui compense la distorsion de l'objectif, voici à quoi cela ressemble pour mon smartphone et mes lunettes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9e2/583/9f5/9e25839f5ea28b1f4e092106f60bebfe.jpg"><br><br><h1>  Stéréogrammes </h1><br>  Mais que faire si vous ne souhaitez pas utiliser d'appareils supplémentaires?  Ensuite, il n'y a qu'une seule option - engourdir.  De manière générale, l'image précédente suffit pour regarder en stéréo, utilisez simplement l'astuce pour regarder en stéréo.  Il existe deux principes pour visualiser les stéréogrammes: bougez vos yeux ou écartez vos yeux.  J'ai donc dessiné un diagramme dans lequel je montre comment vous pouvez regarder l'image précédente.  L'image précédente est double, deux barres rouges sur le diagramme montrent deux images sur la rétine gauche, deux bleues sur la droite. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/86e/14a/47b/86e14a47b4e2ae8aa9246becb7155827.png"><br><br>  Si nous concentrons nos yeux sur l'écran, alors sur quatre images, nous en obtenons deux.  Si nous louchons nos yeux vers le nez, il est tout à fait possible de montrer au cerveau «trois» images.  Et vice versa, si vous ouvrez les yeux, vous pouvez également obtenir "trois" images.  La superposition d'images centrales donnera au cerveau un effet stéréo. <br><br>  Ces méthodes sont données à différentes personnes de différentes manières, par exemple, je ne sais pas du tout bouger mes yeux, mais je me reproduis facilement.  Il est important que le stéréogramme construit pour une méthode soit vu de la même manière, sinon une carte de profondeur inversée est obtenue (voir parallaxe négative et positive).  Le problème avec cette méthode de visualisation stéréo est qu'il est très difficile <b>de</b> bouger <b>fortement les</b> yeux par rapport à l'état normal, vous devez donc vous contenter de petites images.  Et si vous en voulez de gros?  Sacrifions complètement la couleur et ne voulons qu'une perception de la profondeur.  Pour l'avenir, voici l'image que nous obtenons à la fin de cette partie: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f7b/e7b/ab2/f7be7bab228dcd5133b2d1ff3a9032e1.jpg"><br><br>  Ce stéréogramme est conçu pour «diluer» les yeux (stéréogramme aux yeux muraux).  Pour ceux qui préfèrent la vision inverse, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">prenez une photo ici</a> .  Si vous n'êtes pas habitué aux stéréogrammes, essayez différentes conditions: une image plein écran, une petite image, une lumière vive, l'obscurité.  La tâche consiste à ouvrir les yeux afin que les deux bandes vorticales adjacentes coïncident.  La façon la plus simple de se concentrer sur le coin supérieur gauche est  elle est plate.  Par exemple, je suis entouré par l'environnement de l'hubr, j'ouvre l'image en plein écran.  N'oubliez pas d'en retirer la souris! <br><br>  Ne vous contentez pas de l'effet 3D défectueux.  Si vous n'êtes que vaguement conscient des formes arrondies au milieu de points aléatoires ainsi que de faibles effets 3D, c'est certainement une illusion incomplète!  Si vous regardez correctement, les boules doivent clairement sortir du plan de l'écran pour le spectateur, l'effet doit être stable et maintenu en raison de l'étude constante et détaillée de chaque partie de l'image, à la fois au premier plan et à l'arrière-plan.  La stéréopsie a une hystérésis: dès que vous obtenez une image stable, elle devient plus claire plus vous regardez longtemps.  Plus l'écran est éloigné des yeux, plus l'effet de profondeur est important. <br><br>  Ce stéréogramme a été dessiné selon la méthode proposée il y a un quart de siècle par Thimbleby et al. Dans leur article « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Affichage d'images 3D: algorithmes pour les stéréogrammes à points aléatoires à image unique</a> ». <br><br><h3>  Point de départ </h3><br>  Le point de départ du rendu des stéréogrammes est une carte de profondeur (nous avons oublié la couleur).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Voici un commit</a> qui rend une telle image: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/53c/201/75f/53c20175f5fa2667a7dd7592fee343c4.jpg"><br><br>  Les profondeurs de notre rendu sont coupées par les plans proche et éloigné, c'est-à-dire que le point le plus éloigné de ma carte a une profondeur de 0, la plus proche. <br><br><h3>  Principe de base </h3><br>  Que nos yeux soient à une distance d de l'écran.  Placez le plan éloigné (imaginaire) (z = 0) à la même distance derrière l'écran.  On choisit une constante μ, qui détermine la position du plan proche (z = 0): elle sera à une distance μd de la plus éloignée.  J'ai choisi μ = 1/3 dans mon code.  Au total, notre monde entier vit à une distance de d-μd à d derrière l'écran.  Ayons une distance e définie entre les yeux (en pixels, dans mon code j'ai choisi 400 pixels). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c6/0eb/e87/5c60ebe872837aea90879fa0798ac7e7.png"><br><br>  Si nous regardons le point de notre objet marqué en rouge sur le diagramme, alors deux pixels marqués en vert devraient avoir la même couleur dans le stéréogramme.  Comment trouver la distance entre ces pixels?  Très simple.  Si le point projeté actuel a une profondeur de z, alors le rapport de parallaxe à la distance entre les yeux est égal au rapport des profondeurs correspondantes: p / e = (d-dμz) / (2d-dμz).  Soit dit en passant, d diminue et n'est impliqué nulle part ailleurs!  Autrement dit, p / e = (1-μz) / (2-μz), ce qui signifie que la parallaxe est égale à p = e * (1-μz) / (2-μz) pixels. <br><br>  Autrement dit, le principe de base de la construction d'un stéréogramme: nous parcourons toute la carte de profondeur, pour chaque valeur de profondeur, nous déterminons quels pixels doivent avoir la même couleur, et écrivons cela dans notre système de restrictions.  Ensuite, nous partons d'une image arbitraire et essayons de respecter toutes les restrictions précédemment imposées. <br><br><h3>  Préparez l'image originale </h3><br>  À ce stade, nous préparerons une image sur laquelle nous imposerons plus tard des restrictions de parallaxe. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ici, engagez-vous</a> , il dessine cette image: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/197/441/685/197441685bf85d56e5416e0af899ace1.jpg"><br><br>  Notez qu'en général les couleurs sont juste aléatoires, sauf que je mets rand () * sin dans le canal rouge pour fournir des ondes périodiques.  Ces ondes sont faites avec une distance de 200 pixels, ceci (avec μ = 1/3 et e = 400 sélectionnés) est la valeur maximale de parallaxe dans notre monde, c'est aussi un plan éloigné.  Ces ondes sont facultatives, mais elles faciliteront la concentration nécessaire de la vision. <br><br><h3>  Rendu stéréogramme </h3><br>  En fait, le code complet lié au stéréogramme ressemble à ceci: <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parallax</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> z)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> eye_separation = <span class="hljs-number"><span class="hljs-number">400.</span></span>; <span class="hljs-comment"><span class="hljs-comment">// interpupillary distance in pixels const float mu = .33; // if the far plane is a distance D behind the screen, then the near plane is a distance mu*D in front of the far plane return static_cast&lt;int&gt;(eye_separation*((1.-z*mu)/(2.-z*mu))+.5); } size_t uf_find(std::vector&lt;size_t&gt; &amp;same, size_t x) { return same[x]==x ? x : uf_find(same, same[x]); } void uf_union(std::vector&lt;size_t&gt; &amp;same, size_t x, size_t y) { if ((x=uf_find(same, x)) != (y=uf_find(same, y))) same[x] = y; } int main() { [...] for (size_t j=0; j&lt;height; j++) { // autostereogram rendering loop std::vector&lt;size_t&gt; same(width); std::iota(same.begin(), same.end(), 0); // initialize the union-find data structure (same[i]=i) for (size_t i=0; i&lt;width; i++) { // put the constraints int par = parallax(zbuffer[i+j*width]); int left = i - par/2; int right = left + par; // works better than i+par/2 for odd values of par if (left&gt;=0 &amp;&amp; right&lt;(int)width) uf_union(same, left, right); // left and right pixels will have the same color } for (size_t i=0; i&lt;width; i++) { // resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; } } [...]</span></span></code> </pre> <br>  Si quoi que ce soit, alors <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">engagez-vous ici</a> .  La fonction int parallaxe (const float z) donne la distance entre les pixels de la même couleur pour la valeur de profondeur actuelle.  Nous rendons le stéréogramme ligne par ligne, car les lignes sont indépendantes les unes des autres (nous n'avons pas de parallaxe verticale).  Par conséquent, la boucle principale traverse simplement toutes les lignes;  pour chacun d'eux, nous commençons par un ensemble illimité complet de pixels, sur lequel nous imposerons ensuite des restrictions d'égalité par paire, et à la fin nous aurons un certain nombre de clusters de pixels (déconnectés) de la même couleur.  Par exemple, un pixel avec un index à gauche et un pixel avec un index à droite devraient finir par être les mêmes. <br><br>  Comment stocker cet ensemble de restrictions?  La réponse la plus simple est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la structure de données union-find</a> .  Je ne vais pas le décrire, ce ne sont que trois lignes de code, vous pouvez le lire sur Wikipedia.  L'idée principale est que pour chaque cluster, nous en aurons un certain «responsable», c'est aussi un pixel racine, nous lui laisserons la même couleur que dans l'image d'origine, et nous repeindrons tous les autres pixels du cluster: <br><br><pre> <code class="cpp hljs"> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;width; i++) { <span class="hljs-comment"><span class="hljs-comment">// resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; }</span></span></code> </pre><br><h1>  Conclusion </h1><br>  Eh bien, en fait, c'est tout.  Vingt lignes de code - et notre stéréogramme est prêt, cassez vos yeux et vos têtes, dessinez des images!  Soit dit en passant, juste des couleurs aléatoires dans un stéréogramme est généralement un luxe, en principe, si vous essayez, vous pouvez également transmettre partiellement la couleur de notre image. <br><br>  D'autres systèmes de visionnage stéréo, par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">liés à la polarisation</a> , ont été retirés de la discussion, car ils dépassent le budget de cent roubles.  Si vous manquez quelque chose, ajoutez et corrigez! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr438646/">https://habr.com/ru/post/fr438646/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr438636/index.html">Incorporation défectueuse de fonctions dans Go</a></li>
<li><a href="../fr438638/index.html">Nous analysons le protocole des messages pager POCSAG, partie 2</a></li>
<li><a href="../fr438640/index.html">Monnaie électronique ouverte à grande vitesse</a></li>
<li><a href="../fr438642/index.html">Les bases de la programmation réactive à l'aide de RxJS</a></li>
<li><a href="../fr438644/index.html">La sécurité des algorithmes d'apprentissage automatique. Protection et test de modèles à l'aide de Python</a></li>
<li><a href="../fr438648/index.html">Comparaison des systèmes de BI (Tableau, Power BI, Oracle, Qlik)</a></li>
<li><a href="../fr438650/index.html">Rocket 9M729. Quelques mots sur le «violateur» du traité INF</a></li>
<li><a href="../fr438652/index.html">IDA de portabelization</a></li>
<li><a href="../fr438654/index.html">OpenSceneGraph: intégration avec Qt Framework</a></li>
<li><a href="../fr438658/index.html">Comment apprendre à apprendre</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
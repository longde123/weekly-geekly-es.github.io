<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï¥üèº ‚¨ÖÔ∏è üë¥üèª Experimente mit neuronalen Netzen basierend auf seismischen Daten üëê ü§õüèª üçø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Komplexit√§t der Interpretation seismischer Daten beruht auf der Tatsache, dass f√ºr jede Aufgabe ein individueller Ansatz gesucht werden muss, da j...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Experimente mit neuronalen Netzen basierend auf seismischen Daten</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/482780/">  Die Komplexit√§t der Interpretation seismischer Daten beruht auf der Tatsache, dass f√ºr jede Aufgabe ein individueller Ansatz gesucht werden muss, da jeder Satz solcher Daten einzigartig ist.  Die manuelle Verarbeitung erfordert erhebliche Arbeitskosten, und das Ergebnis enth√§lt h√§ufig Fehler, die sich auf den menschlichen Faktor beziehen.  Die Verwendung neuronaler Netze zur Interpretation kann die manuelle Arbeit erheblich reduzieren, die Eindeutigkeit der Daten schr√§nkt jedoch die Automatisierung dieser Arbeit ein. <br><br>  Dieser Artikel beschreibt ein Experiment zur Analyse der Anwendbarkeit neuronaler Netze zur Automatisierung der Zuordnung geologischer Schichten in 2D-Bildern am Beispiel vollst√§ndig beschrifteter Daten aus der Nordsee. <br><br><img src="https://habrastorage.org/webt/rs/vp/ky/rsvpky5vebdp4xtive1ywcvtvtk.png" alt="Wassergest√ºtzte seismische Untersuchungen"><br>  Abbildung 1. Aquatorial Seismic Surveys ( <a href="https://www.nationalgeographic.com/news/2010/4/100407-energy-undersea-sound/">Quelle</a> ) <br><a name="habracut"></a><br><h2>  Ein bisschen √ºber den Themenbereich </h2><br>  Die seismische Erkundung ist eine geophysikalische Methode zur Untersuchung von geologischen Objekten mit Hilfe von elastischen Schwingungen - seismischen Wellen.  Diese Methode basiert auf der Tatsache, dass die Ausbreitungsgeschwindigkeit von seismischen Wellen von den Eigenschaften der geologischen Umgebung abh√§ngt, in der sie sich ausbreiten (Gesteinszusammensetzung, Porosit√§t, Bruch, Feuchtigkeitss√§ttigung usw.). Durch geologische Schichten mit unterschiedlichen Eigenschaften werden seismische Wellen reflektiert verschiedene Objekte und zur√ºck zum Empf√§nger (siehe Abbildung 1).  Ihre Art wird aufgezeichnet und nach der Verarbeitung k√∂nnen Sie ein zweidimensionales Bild - einen seismischen Abschnitt oder ein dreidimensionales Datenarray - einen seismischen W√ºrfel erstellen. <br><br><img src="https://habrastorage.org/webt/xi/dn/4p/xidn4psxaiynjkoqtvw3ctogcqq.gif" alt="Seismic Cube Beispiel"><br>  Abbildung 2. Ein Beispiel f√ºr einen seismischen W√ºrfel ( <a href="http://cge.rosgeo.com/en/services/glubinnaya-3d-migraciya-do-summirovaniya/">Quelle</a> ) <br><br>  Die horizontale Achse des seismischen W√ºrfels befindet sich entlang der Erdoberfl√§che und die vertikale Achse repr√§sentiert die Tiefe oder Zeit (siehe Abbildung 2).  In einigen F√§llen ist der W√ºrfel in vertikale Abschnitte entlang der Achse der Geophone (sogenannte Inlines, Inlines) oder quer (Crosslines, Crosslines, Xlines) unterteilt.  Jede W√ºrfelvertikale (und Scheibe) ist eine separate seismische Spur. <br><br>  Inlines und Crosslines bestehen also aus denselben seismischen Spuren, nur in einer anderen Reihenfolge.  Die angrenzenden seismischen Pfade sind einander sehr √§hnlich.  Eine dramatischere √Ñnderung tritt an den Fehlerpunkten auf, es wird jedoch immer noch √Ñhnlichkeiten geben.  Dies bedeutet, dass benachbarte Schichten einander sehr √§hnlich sind. <br><br>  All dieses Wissen wird uns bei der Planung von Experimenten n√ºtzlich sein. <br><br><h2>  Die Interpretationsaufgabe und die Rolle neuronaler Netze in ihrer L√∂sung </h2><br>  Die erhaltenen Daten werden manuell von Dolmetschern verarbeitet, die direkt auf dem W√ºrfel oder an jeder Scheibe die einzelnen geologischen Gesteinsschichten und deren Grenzen (Horizonte, Horizonte), Salzablagerungen, Verwerfungen und andere Merkmale der geologischen Struktur des untersuchten Gebiets identifizieren.  Der Dolmetscher, der mit einem W√ºrfel oder einer Scheibe arbeitet, beginnt seine Arbeit mit der sorgf√§ltigen manuellen Auswahl geologischer Schichten und Horizonte.  Jeder Horizont muss manuell ausgew√§hlt werden (aus der englischen Sammlung "picking"), indem Sie mit dem Mauszeiger darauf zeigen und mit der Maus klicken. <br><br><img src="https://habrastorage.org/webt/w6/j3/gn/w6j3gnflms5vqyxc3mbjdnzsaam.png" alt="Ein Beispiel eines 2D-Schnitts (links) und das Ergebnis der Markierung der entsprechenden geologischen Schichten (rechts)"><br>  Abbildung 3. Ein Beispiel f√ºr einen 2D-Schnitt (links) und das Ergebnis der Markierung der entsprechenden geologischen Schichten (rechts) ( <a href="https://arxiv.org/pdf/1904.00770v1.pdf">Quelle</a> ) <br><br>  Das Hauptproblem h√§ngt mit der zunehmenden Menge an seismischen Daten zusammen, die jedes Jahr unter immer komplexeren geologischen Bedingungen (z. B. Unterwasserabschnitten mit gro√üen Meerestiefen) erfasst werden, und mit der Mehrdeutigkeit der Interpretation dieser Daten.  Dar√ºber hinaus macht der Dolmetscher bei engen Fristen und / oder gro√üen Mengen unvermeidlich Fehler, z. B. verfehlt er verschiedene Merkmale des geologischen Abschnitts. <br><br>  Dieses Problem kann teilweise mit Hilfe neuronaler Netze gel√∂st werden, wodurch die manuelle Arbeit erheblich reduziert wird, wodurch der Interpretationsprozess beschleunigt und die Anzahl der Fehler verringert wird.  F√ºr den Betrieb des neuronalen Netzes ist eine bestimmte Anzahl von vorgefertigten, beschrifteten Abschnitten (Abschnitten des W√ºrfels) erforderlich, und als Ergebnis wird eine vollst√§ndige Markierung aller Abschnitte (oder des gesamten W√ºrfels) erhalten, was idealerweise nur eine geringf√ºgige Verfeinerung durch eine Person erfordert, um bestimmte Abschnitte des Horizonts anzupassen oder kleine Bereiche, die neu zu markieren Das Netzwerk konnte nicht richtig erkennen. <br><br>  Es gibt viele L√∂sungen f√ºr die Interpretationsprobleme mit neuronalen Netzen, hier nur einige Beispiele: <a href="https://arxiv.org/abs/1903.11215">eins</a> , <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">zwei</a> , <a href="">drei</a> .  Die Schwierigkeit liegt in der Tatsache, dass jeder Datensatz einzigartig ist - aufgrund der Besonderheiten der geologischen Gesteine ‚Äã‚Äãder untersuchten Region, aufgrund verschiedener technischer Mittel und Methoden der seismischen Erkundung, aufgrund der verschiedenen Methoden, mit denen Rohdaten in vorgefertigte umgewandelt werden.  Auch wegen √§u√üerer Ger√§usche (zum Beispiel ein Hundebellen und andere laute Ger√§usche), die nicht immer vollst√§ndig beseitigt werden k√∂nnen.  Daher muss jede Aufgabe einzeln gel√∂st werden. <br><br>  Trotzdem lassen sich mit zahlreichen Arbeiten unterschiedliche allgemeine L√∂sungsans√§tze f√ºr verschiedene Interpretationsprobleme finden. <br><br>  Wir bei <a href="https://maritimeai.net/">MaritimeAI</a> (ein Projekt, das aus der <a href="http://ods.ai/">ODS-Community</a> f√ºr maschinelles Lernen f√ºr soziale G√ºter <a href="http://ods.ai/">entwickelt wurde</a> , <a href="https://habr.com/ru/company/ods/blog/454964/">ein Artikel √ºber uns</a> ) studieren f√ºr jede Zone unseres Interessengebiets (Meeresforschung) bereits ver√∂ffentlichte Arbeiten und f√ºhren unsere eigenen Experimente durch, um die Grenzen und Merkmale der Anwendung bestimmter zu kl√§ren L√∂sungen, und manchmal finden Sie Ihre eigenen Ans√§tze. <br><br>  Die Ergebnisse eines Experiments beschreiben wir in diesem Artikel. <br><br><h2>  Unternehmensforschungsziele </h2><br>  F√ºr einen Data Science-Spezialisten ist es ausreichend, einen Blick auf Abbildung 3 zu werfen, um aufatmen zu k√∂nnen - eine h√§ufige Aufgabe der semantischen Bildsegmentierung, f√ºr die viele neuronale Netzwerkarchitekturen und Lehrmethoden erfunden wurden.  Sie m√ºssen nur die richtigen ausw√§hlen und das Netzwerk trainieren. <br><br>  Aber nicht so einfach. <br><br>  Um mit Hilfe eines neuronalen Netzwerks ein gutes Ergebnis zu erzielen, ben√∂tigen Sie so viele bereits markierte Daten, wie es lernen wird.  Unsere Aufgabe ist es aber gerade, den manuellen Aufwand zu reduzieren.  Und aufgrund der starken Unterschiede in der geologischen Struktur ist es selten m√∂glich, markierte Daten aus anderen Regionen zu verwenden. <br><br>  Wir √ºbersetzen das oben Genannte in die Gesch√§ftssprache. <br><br>  Damit die Verwendung neuronaler Netze wirtschaftlich gerechtfertigt ist, muss der Umfang der prim√§ren manuellen Interpretation und der Verfeinerung der erzielten Ergebnisse minimiert werden.  Das Reduzieren der Daten f√ºr das Training des Netzwerks wirkt sich jedoch negativ auf die Qualit√§t des Ergebnisses aus.  Kann ein neuronales Netzwerk also die Arbeit der Dolmetscher beschleunigen und erleichtern und die Qualit√§t der beschrifteten Bilder verbessern?  Oder komplizieren Sie einfach den √ºblichen Prozess? <br><br>  Das Ziel dieser Studie ist es, das minimale ausreichende Volumen von markierten seismischen W√ºrfeldaten f√ºr ein neuronales Netzwerk zu bestimmen und die erzielten Ergebnisse auszuwerten.  Wir haben versucht, Antworten auf die folgenden Fragen zu finden, die den "Eigent√ºmern" der Ergebnisse der seismischen Untersuchung bei der Entscheidung f√ºr eine manuelle oder teilweise automatisierte Interpretation helfen sollen: <br><br><ol><li>  Wie viele Daten ben√∂tigen Experten, um ein neuronales Netzwerk zu trainieren?  Und welche Daten sollten daf√ºr ausgew√§hlt werden? </li><li>  Was passiert bei einem solchen Ausgang?  Wird eine manuelle Verfeinerung der Vorhersagen f√ºr neuronale Netze erforderlich sein?  Wenn ja, wie komplex und umfangreich? </li></ol><br><h2>  Allgemeine Beschreibung des Versuchs und der verwendeten Daten </h2><br>  F√ºr das Experiment haben wir eines der Interpretationsprobleme ausgew√§hlt, n√§mlich die Aufgabe, geologische Schichten auf 2D-Schnitten eines seismischen W√ºrfels zu isolieren (siehe Abbildung 3).  Wir haben bereits versucht, dieses Problem zu l√∂sen (siehe <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">hier</a> ) und laut den Autoren ein gutes Ergebnis f√ºr 1% der zuf√§llig ausgew√§hlten Scheiben erzielt.  Bei der Gr√∂√üe des W√ºrfels handelt es sich um 16 Bilder.  Der Artikel enth√§lt jedoch keine Metriken zum Vergleich und es gibt keine Beschreibung der Trainingsmethodik (Verlustfunktion, Optimierer, Schema zum √Ñndern der Lerngeschwindigkeit usw.), wodurch das Experiment nicht reproduzierbar wird. <br><br>  Dar√ºber hinaus reichen die dort pr√§sentierten Ergebnisse unserer Meinung nach nicht aus, um eine vollst√§ndige Antwort auf die gestellten Fragen zu erhalten.  Ist dieser Wert bei 1% optimal?  Oder vielleicht f√ºr eine andere Probe von Scheiben wird es anders sein?  Kann ich weniger Daten ausw√§hlen?  Lohnt es sich, mehr zu nehmen?  Wie wird sich das Ergebnis √§ndern?  Usw. <br><br>  F√ºr das Experiment haben wir denselben Satz vollst√§ndig gekennzeichneter Daten aus dem niederl√§ndischen Sektor der Nordsee verwendet.  Die seismischen Quelldaten sind auf der Website von Open Seismic Repository: <a href="https://terranubis.com/datainfo/Netherlands-Offshore-F3-Block-Complete">Project Netherlands Offshore F3 Block</a> verf√ºgbar.  Eine kurze Beschreibung findet sich bei <a href="https://arxiv.org/pdf/1904.00770v1.pdf">Silva et al.</a>  <a href="https://arxiv.org/pdf/1904.00770v1.pdf">"Niederl√§ndischer Datensatz: Ein neuer √∂ffentlicher Datensatz f√ºr maschinelles Lernen in der seismischen Interpretation</a> . <a href="https://arxiv.org/pdf/1904.00770v1.pdf">"</a> <br><br>  Da es sich in unserem Fall um 2D-Schnitte handelt, haben wir nicht den urspr√ºnglichen 3D-W√ºrfel verwendet, sondern das bereits erstellte ‚ÄûSlicing‚Äú, das hier verf√ºgbar ist: <a href="https://zenodo.org/record/1471548">Netherlands F3 Interpretation Dataset</a> . <br><br>  W√§hrend des Experiments haben wir folgende Aufgaben gel√∂st: <br><br><ol><li>  Wir haben uns die Quelldaten angesehen und die Scheiben ausgew√§hlt, deren Qualit√§t der manuellen Markierung am n√§chsten kommt. </li><li>  Wir haben die Architektur des neuronalen Netzwerks, die Methodik und die Parameter des Trainings sowie das Prinzip der Auswahl von Schichten f√ºr das Training und die Validierung aufgezeichnet. </li><li>  Zum Vergleich der Ergebnisse haben wir 20 identische neuronale Netze auf verschiedenen Datenmengen desselben Scheibentyps trainiert. </li><li>  Wir haben weitere 20 neuronale Netze auf eine unterschiedliche Datenmenge verschiedener Arten von Schichten trainiert, um die Ergebnisse zu vergleichen. </li><li>  Gesch√§tzter Umfang der erforderlichen manuellen Verfeinerung der Prognoseergebnisse. </li></ol><br>  Die Ergebnisse des Experiments in Form von gesch√§tzten Metriken, die von den Netzwerken der Schnittmasken vorhergesagt werden, sind nachstehend aufgef√ºhrt. <br><br><h2>  Aufgabe 1. Datenauswahl </h2><br>  Als Ausgangsdaten verwendeten wir fertige Inlines und Crosslines des seismischen W√ºrfels aus dem niederl√§ndischen Sektor der Nordsee.  Eine detaillierte Analyse ergab, dass nicht alles reibungslos funktioniert - es gibt viele Bilder und Masken mit Artefakten und sogar stark verzerrten Bildern (siehe Abbildungen 4 und 5). <br><br><img src="https://habrastorage.org/webt/0d/d-/iv/0dd-iveosyikwl35e4uylytlnss.png" alt="Beispiel f√ºr eine Artefaktmaske"><br>  Abbildung 4. Beispielmaske mit Artefakten <br><br><img src="https://habrastorage.org/webt/iz/_k/3j/iz_k3jbbvf4adnpgbzmehevzegm.png" alt="Beispiel f√ºr eine verzerrte Maske"><br>  Abbildung 5. Ein Beispiel f√ºr eine verzerrte Maske <br><br>  Bei manueller Kennzeichnung wird nichts dergleichen beachtet.  Um die Arbeit des Dolmetschers zu simulieren und das Netzwerk zu trainieren, w√§hlten wir daher nur saubere Masken, nachdem wir uns alle Schichten angesehen hatten.  Als Ergebnis wurden 700 Kreuzlinien und 400 Inlines ausgew√§hlt. <br><br><h2>  Aufgabe 2. Die Parameter des Experiments festlegen </h2><br>  Dieser Abschnitt ist in erster Linie f√ºr Spezialisten der Datenwissenschaft von Interesse, daher wird eine geeignete Terminologie verwendet. <br><br>  Da Inlines und Crosslines aus denselben seismischen Spuren bestehen, k√∂nnen zwei sich gegenseitig ausschlie√üende Hypothesen aufgestellt werden: <br><br><ol><li>  Das Training kann nur f√ºr einen Scheibentyp (z. B. Inlines) durchgef√ºhrt werden, wobei Bilder eines anderen Typs als verz√∂gerte Auswahl verwendet werden.  Dies wird eine angemessenere Bewertung des Ergebnisses geben, weil  Die verbleibenden Scheiben desselben Typs, die f√ºr das Training verwendet wurden, sind denen f√ºr das Training weiterhin √§hnlich. </li><li>  F√ºr das Training ist es besser, eine Mischung aus Scheiben verschiedener Arten zu verwenden, da dies eine fertige Erg√§nzung ist. </li></ol><br>  Probieren Sie es aus. <br><br>  Dar√ºber hinaus f√ºhrten die √Ñhnlichkeit benachbarter Schichten desselben Typs und der Wunsch, ein reproduzierbares Ergebnis zu erzielen, zu einer Strategie zur Auswahl von Schichten f√ºr das Training und die Validierung, und zwar nicht nach einem willk√ºrlichen Prinzip, sondern gleichm√§√üig √ºber den gesamten W√ºrfel, d.h.  Damit die Slices so weit wie m√∂glich voneinander entfernt sind und somit die gr√∂√ütm√∂gliche Datenvielfalt abdecken. <br><br>  Zur Validierung wurden 2 Schnitte verwendet, die ebenfalls gleichm√§√üig auf benachbarte Bilder der Trainingsprobe verteilt waren.  F√ºr den Fall einer Trainingsstichprobe von 3 Inlines bestand die Validierungsstichprobe beispielsweise aus 4 Inlines f√ºr 3 Inlines und 3 Crosslines f√ºr 8 Slices. <br><br>  Aus diesem Grund haben wir zwei Schulungsreihen durchgef√ºhrt: <br><br><ol><li>  Schulung an Inline-Mustern von 3 bis 20 Slices, die gleichm√§√üig √ºber den Cube verteilt sind, mit √úberpr√ºfung des Ergebnisses der Netzwerkvorhersagen f√ºr die verbleibenden Inlines und f√ºr alle Crosslines.  Zus√§tzlich wurden Schulungen in 80 und 160 Abschnitten durchgef√ºhrt. </li><li>  Training in kombinierten Stichproben aus Inlines und Crosslines von 3-10 Abschnitten jedes Typs, die gleichm√§√üig √ºber einen W√ºrfel verteilt sind, mit √úberpr√ºfung des Ergebnisses der Netzwerkvorhersagen in den verbleibenden Bildern.  Zus√§tzlich wurden Schulungen zu 40 + 40 und 80 + 80 Abschnitten durchgef√ºhrt. </li></ol><br>  Bei diesem Ansatz muss ber√ºcksichtigt werden, dass die Gr√∂√üen der Trainings- und Validierungsstichproben erheblich variieren, was den Vergleich erschwert, aber das Volumen der verbleibenden Bilder wird nicht so stark reduziert, dass √Ñnderungen des Ergebnisses angemessen bewertet werden k√∂nnen. <br><br>  Um die Umschulung f√ºr die Trainingsstichprobe zu reduzieren, wurde eine Augmentation mit einer willk√ºrlichen Fruchtgr√∂√üe von 448 √ó 64 und einem Spiegelbild entlang der vertikalen Achse mit einer Wahrscheinlichkeit von 0,5 verwendet. <br><br>  Da es uns nur um die Abh√§ngigkeit der Qualit√§t des Ergebnisses von der Anzahl der Schnitte im Trainingsmuster geht, kann die Vorverarbeitung der Bilder vernachl√§ssigt werden.  Wir haben eine einzelne Schicht von PNG-Bildern ohne √Ñnderungen verwendet. <br><br>  Aus dem gleichen Grund muss im Rahmen dieses Experiments nicht nach der besten Netzwerkarchitektur gesucht werden - Hauptsache, sie muss bei jedem Schritt gleich sein.  Wir haben eine einfache, aber gut etablierte UNet f√ºr diese Aufgaben ausgew√§hlt: <br><br><img src="https://habrastorage.org/webt/i0/jg/fs/i0jgfsxjgo5nibyatbaokikg0tg.png" alt="Netzwerkarchitektur"><br>  Abbildung 6. Netzwerkarchitektur <br><br>  Die Verlustfunktion bestand aus einer Kombination des Jacquard-Koeffizienten und der bin√§ren Kreuzentropie: <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">jaccard_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smoothing = <span class="hljs-number"><span class="hljs-number">1.</span></span> intersection = tf.reduce_sum(y_true * y_pred, axis = (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)) union = tf.reduce_sum(y_true + y_pred, axis = (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)) jaccard = (intersection + smoothing) / (union - intersection + smoothing) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - tf.reduce_mean(jaccard) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0.75</span></span> * jaccard_loss(y_true, y_pred) + <span class="hljs-number"><span class="hljs-number">0.25</span></span> * keras.losses.binary_crossentropy(y_true, y_pred)</code> </pre> <br>  Andere Lernoptionen: <br><br><pre> <code class="python hljs">keras.optimizers.SGD(lr = <span class="hljs-number"><span class="hljs-number">0.01</span></span>, momentum = <span class="hljs-number"><span class="hljs-number">0.9</span></span>, nesterov = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) keras.callbacks.EarlyStopping(monitor = <span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, patience = <span class="hljs-number"><span class="hljs-number">10</span></span>), keras.callbacks.ReduceLROnPlateau(monitor = <span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, patience = <span class="hljs-number"><span class="hljs-number">5</span></span>)</code> </pre> <br>  Um den Einfluss der Zuf√§lligkeit der Wahl der Anfangsgewichte auf die Ergebnisse zu verringern, wurde das Netzwerk f√ºr eine √Ñra an 3 Inlines trainiert.  Alle anderen Trainingseinheiten begannen mit diesen erhaltenen Gewichten. <br><br>  Jedes Netzwerk wurde auf der GeForce GTX 1060 6Gb f√ºr 30-60 Epochen trainiert.  Das Training jeder Epoche dauerte je nach Stichprobengr√∂√üe 10 bis 30 Sekunden. <br><br><h2>  Aufgabe 3. Training auf einem Scheibentyp (Inlines) </h2><br>  Die erste Serie bestand aus 18 unabh√§ngigen Netzwerktrainings mit 3 bis 20 Inlines.  Und obwohl wir nur daran interessiert sind, den Jacquard-Koeffizienten f√ºr Scheiben zu sch√§tzen, die nicht f√ºr Training und Validierung verwendet werden, ist es interessant, alle Diagramme zu betrachten. <br><br>  Es sei daran erinnert, dass die Interpretationsergebnisse f√ºr jede Schicht 10 Klassen (geologische Schichten) sind, die in den Figuren weiterhin mit Zahlen von 0 bis 9 gekennzeichnet sind. <br><br><img src="https://habrastorage.org/webt/g0/1o/tm/g01otmt3jodludsk-puf_fv1kic.png" alt="Jacquard-Koeffizient f√ºr das Trainingsset"><br>  Abbildung 7. Jacquard-Koeffizient f√ºr das Trainingsset <br><br><img src="https://habrastorage.org/webt/e9/fs/g7/e9fsg7p5aemva9-k7g_jruodo6m.png" alt="Jacquard-Koeffizient f√ºr die Validierungsprobe"><br>  Abbildung 8. Jacquard-Koeffizient f√ºr die Validierungsprobe <br><br><img src="https://habrastorage.org/webt/qe/di/av/qediavhy6nbnjmci8-whfxyocuy.png" alt="Jacquard-Koeffizient f√ºr andere Inlines"><br>  Abbildung 9. Jacquard-Koeffizient f√ºr die verbleibenden Inlines <br><br><img src="https://habrastorage.org/webt/h_/qm/2n/h_qm2n3v5fapcqprdjluppb1-cy.png" alt="Jacquard-Koeffizient f√ºr Querlinien"><br>  Abbildung 10. Jacquard-Koeffizient f√ºr Querlinien <br><br>  Aus den obigen Diagrammen k√∂nnen eine Reihe von Schlussfolgerungen gezogen werden. <br><br>  Erstens erreicht die Prognosequalit√§t, gemessen am Jacquard-Koeffizienten, bereits bei 9 Inlines einen sehr hohen Wert, wonach sie weiter w√§chst, jedoch nicht so intensiv.  Das hei√üt  Die Hypothese, dass nur wenige markierte Bilder f√ºr das Training eines neuronalen Netzwerks ausreichen, wird best√§tigt. <br><br>  Zweitens wurde trotz der Tatsache, dass nur Inlines f√ºr die Schulung und Validierung verwendet wurden, ein sehr hohes Ergebnis f√ºr Kreuzlinien erzielt - die Hypothese, dass nur ein Scheibentyp ausreicht, wird ebenfalls best√§tigt.  F√ºr die endg√ºltige Schlussfolgerung m√ºssen Sie jedoch die Ergebnisse mit dem Training an einer Mischung aus Inlines und Crosslines vergleichen. <br><br>  Drittens Metriken f√ºr verschiedene Schichten, d.h.  Die Qualit√§t ihrer Anerkennung ist sehr unterschiedlich.  Dies f√ºhrt zu der Idee, eine andere Lernstrategie zu w√§hlen, z. B. Gewichte oder zus√§tzliche Netzwerke f√ºr schwache Klassen oder ein vollwertiges ‚Äûone vs all‚Äú -Schema. <br><br>  Abschlie√üend ist anzumerken, dass der Jacquard-Koeffizient keine vollst√§ndige Beschreibung der Qualit√§t des Ergebnisses liefern kann.  Um in diesem Fall die Netzwerkvorhersagen zu bewerten, ist es besser, die Masken selbst zu betrachten, um ihre Eignung f√ºr die √úberarbeitung durch den Interpreter zu bewerten. <br><br>  Die folgenden Abbildungen zeigen das Markup eines auf 10 Inlines trainierten Netzwerks.  Die zweite Spalte mit der Bezeichnung ‚ÄûGT-Maske‚Äú (Ground Truth Mask) stellt die Zielinterpretation dar, die dritte die Vorhersage des neuronalen Netzes. <br><br><img src="https://habrastorage.org/webt/ub/pa/6t/ubpa6tj0p0gfe0ixdoysku8_bzw.png" alt="Beispiele f√ºr Netzwerkvorhersagen f√ºr Inlines"><br><img src="https://habrastorage.org/webt/me/fi/mu/mefimu03q9gzh_hcdomwrtagwm0.png" alt="Beispiele f√ºr Netzwerkvorhersagen f√ºr Inlines"><br>  Abbildung 11. Beispiele f√ºr Netzwerkvorhersagen f√ºr Inlines <br><br><img src="https://habrastorage.org/webt/7l/25/5_/7l255_ofscuyfhozqokfiw5ifjk.png" alt="Beispiele f√ºr Netzwerkvorhersagen f√ºr Kreuzlinien"><br><img src="https://habrastorage.org/webt/eh/kd/hw/ehkdhwyuzl0j_sl5rhy-6m0613k.png" alt="Beispiele f√ºr Netzwerkvorhersagen f√ºr Kreuzlinien"><br>  Abbildung 12. Beispiele f√ºr Netzwerkvorhersagen f√ºr Querlinien <br><br>  Den Zahlen ist zu entnehmen, dass das Netzwerk zusammen mit relativ sauberen Masken selbst an den Inlines selbst nur schwer komplexe F√§lle erkennen kann.  Daher muss ein Teil der Ergebnisse trotz der ausreichend hohen Metrik f√ºr 10 Slices erheblich verfeinert werden. <br><br>  Die von uns ber√ºcksichtigten Stichprobengr√∂√üen schwanken um 1% des gesamten Datenvolumens - und dies erm√∂glicht es bereits, einen Teil der verbleibenden Schnitte recht gut zu markieren.  Sollte ich die Anzahl der urspr√ºnglich markierten Abschnitte erh√∂hen?  Wird dies zu einer vergleichbaren Qualit√§tssteigerung f√ºhren? <br><br>  Betrachten Sie die Dynamik von √Ñnderungen in den Prognoseergebnissen durch Netzwerke, die auf 5, 10, 15, 20, 80 (5% des Gesamtvolumens des Cubes) und 160 (10%) Inlines trainiert wurden, indem Sie dieselben Abschnitte als Beispiel verwenden. <br><br><img src="https://habrastorage.org/webt/4c/aw/ye/4cawye-bfzessxxllovzxb1-gne.png" alt="Beispiele f√ºr Vorhersagen von Netzwerken, die auf verschiedenen Volumina der Trainingsstichprobe trainiert wurden"><br>  Abbildung 13. Beispiele f√ºr Vorhersagen von Netzwerken, die auf verschiedenen Volumina der Trainingsstichprobe trainiert wurden <br><br>  Abbildung 13 zeigt, dass eine Erh√∂hung des Volumens der Trainingsstichprobe um das F√ºnffache oder gar das Zehnfache keine signifikante Verbesserung bewirkt.  Scheiben, die in 10 Trainingsbildern bereits gut erkannt werden, werden nicht schlechter. <br><br>  Somit kann auch ein einfaches Netzwerk ohne Anpassung und Vorverarbeitung von Bildern einen Teil der Schnitte mit einer ausreichend hohen Qualit√§t mit einer geringen Anzahl von manuell markierten Bildern interpretieren.  Wir werden die Frage des Anteils solcher Interpretationen und die Komplexit√§t der Fertigstellung von schlecht erkannten Schnitten betrachten. <br><br>  Die sorgf√§ltige Auswahl der Architektur, der Netzwerkparameter und des Trainings sowie die Bildvorverarbeitung k√∂nnen diese Ergebnisse bei gleichem Datenvolumen verbessern.  Dies geht aber bereits √ºber den Rahmen des aktuellen Experiments hinaus. <br><br><h2>  Aufgabe 4. Training auf verschiedenen Arten von Schnitten (Inlines und Crosslines) </h2><br>  Vergleichen wir nun die Ergebnisse dieser Reihe mit den Prognosen, die durch Training an einer Mischung aus Inlines und Crosslines erhalten wurden. <br><br>  Die nachstehenden Diagramme zeigen Sch√§tzungen des Jacquard-Koeffizienten f√ºr verschiedene Proben, einschlie√ülich im Vergleich zu den Ergebnissen der vorhergehenden Reihen.  Zum Vergleich (siehe die rechten Diagramme in den Figuren) wurden nur Proben desselben Volumens entnommen, d.h.  10 Inlines vs 5 Inlines + 5 Crosslines usw. <br><br><img src="https://habrastorage.org/webt/4q/df/qr/4qdfqrbxrh9_blq0e-5rgoh_z14.png" alt="Jacquard-Koeffizient f√ºr das Trainingsset"><br>  Abbildung 14. Jacquard-Koeffizient f√ºr das Trainingsset <br><br><img src="https://habrastorage.org/webt/s6/uh/pr/s6uhprjziuoobasc5gl0wak7h9y.png" alt="Jacquard-Koeffizient f√ºr die Validierungsprobe"><br>  Abbildung 15. Jacquard-Koeffizient f√ºr die Validierungsprobe <br><br><img src="https://habrastorage.org/webt/hu/c5/dv/huc5dv9_k7dgwphwygzhypzwpxy.png" alt="Jacquard-Koeffizient f√ºr andere Inlines"><br>  Abbildung 16. Jacquard-Koeffizient f√ºr die verbleibenden Inlines <br><br><img src="https://habrastorage.org/webt/rx/c3/tz/rxc3tzlw5synjdwoj1j97aj56xy.png" alt="Jacquard-Koeffizient f√ºr den Rest der Querlinien"><br>  Abbildung 17. Jacquard-Koeffizient f√ºr die verbleibenden Querlinien <br><br>  Die Diagramme veranschaulichen deutlich, dass das Hinzuf√ºgen von Slices eines anderen Typs die Ergebnisse nicht verbessert.  Auch im Kontext von Klassen (siehe Abbildung 18) wird bei keiner der betrachteten Stichprobengr√∂√üen der Einfluss von Kreuzlinien beobachtet. <br><br><img src="https://habrastorage.org/webt/0z/yx/sh/0zyxshghib81lkvjqe6le4sgute.png" alt="Jacquard-Koeffizient f√ºr verschiedene Klassen (entlang der X-Achse) und verschiedene Gr√∂√üen und Zusammensetzungen des Trainingsmusters"><br>  Abbildung 18. Jacquard-Koeffizient f√ºr verschiedene Klassen (entlang der X-Achse) und verschiedene Gr√∂√üen und Zusammensetzungen der Trainingsstichprobe <br><br>  Um das Bild zu vervollst√§ndigen, vergleichen wir die Ergebnisse der Netzwerkprognose in denselben Schichten: <br><br><img src="https://habrastorage.org/webt/2q/qh/wn/2qqhwnj0_lemjeaog44lunjbw8g.png" alt="Vergleich der Netzwerkvorhersagen f√ºr Inline"><br>  Abbildung 19. Vergleich der Netzwerkvorhersagen f√ºr Inline <br><br><img src="https://habrastorage.org/webt/8f/gk/vm/8fgkvmw0860finev7nzkuuwsfmc.png" alt="Vergleich der Netzwerkvorhersagen f√ºr Kreuzlinien"><br>  Abbildung 20. Vergleich der Netzwerkvorhersagen f√ºr Querlinien <br><br>  Ein visueller Vergleich best√§tigt die Annahme, dass das Hinzuf√ºgen verschiedener Arten von Schichten zum Training die Situation nicht grundlegend √§ndert.  Einige Verbesserungen sind nur f√ºr die linke Querlinie zu beobachten, aber sind sie global?  Wir werden versuchen, diese Frage weiter zu beantworten. <br><br><h2>  Aufgabe 5. Bewertung des Umfangs der manuellen Verfeinerung </h2><br>  F√ºr eine endg√ºltige Schlussfolgerung zu den Ergebnissen ist es erforderlich, den Grad der manuellen Verfeinerung der erhaltenen Netzwerkvorhersagen abzusch√§tzen.  Zu diesem Zweck haben wir die Anzahl der verbundenen Komponenten (d. H. Durchgezogene Punkte derselben Farbe) f√ºr jede erhaltene Vorhersage bestimmt.  Wenn dieser Wert 10 ist, sind die Ebenen korrekt ausgew√§hlt und es handelt sich um eine maximale geringf√ºgige Horizontkorrektur.  Wenn es nicht mehr viele gibt, m√ºssen Sie nur die kleinen Bereiche des Bildes "s√§ubern".  Wenn es wesentlich mehr davon gibt, ist alles schlecht und muss m√∂glicherweise sogar komplett neu gestaltet werden. <br><br>  Zum Testen haben wir 110 Inlines und 360 Crosslines ausgew√§hlt, die f√ºr das Training in keinem der untersuchten Netzwerke verwendet wurden. <br><br>  Tabelle 1. √úber beide Arten von Slices gemittelte Statistiken <br><img src="https://habrastorage.org/webt/ov/b8/fs/ovb8fsaxxqbwea4jn4_pw_dsd_e.png" alt="Die Statistiken wurden √ºber beide Arten von Slices gemittelt"><br><br>  Tabelle 1 best√§tigt einige der vorherigen Ergebnisse.  Insbesondere wenn 1% Scheiben f√ºr das Training verwendet werden, gibt es keinen Unterschied. Verwenden Sie einen Scheibentyp oder beides. Das Ergebnis kann wie folgt charakterisiert werden: <br><br><ul><li>  etwa 10% der Vorhersagen sind nahezu ideal, d.h.  erfordern nicht mehr als Anpassungen an einzelnen Abschnitten des Horizonts; </li><li>  50% der Vorhersagen enthalten nicht mehr als 15 Spots, d. H.  nicht mehr als 5 extra; </li><li>  75% der Vorhersagen enthalten nicht mehr als 20 Punkte, d. H.  nicht mehr als 10 extra; </li><li>  Die verbleibenden 25% der Prognosen erfordern eine gr√ºndlichere Verfeinerung, einschlie√ülich m√∂glicherweise einer vollst√§ndigen Neugestaltung einzelner Schichten. </li></ul><br>  Eine Erh√∂hung des Stichprobenumfangs um bis zu 5% √§ndert die Situation.  Insbesondere Netzwerke, die auf einer Mischung von Abschnitten trainiert wurden, weisen signifikant h√∂here Indikatoren auf, obwohl der Maximalwert der Komponenten ebenfalls zunimmt, was auf das Auftreten separater Interpretationen von sehr schlechter Qualit√§t hinweist.  Wenn Sie jedoch die Probe um das F√ºnffache erh√∂hen und eine Mischung aus Scheiben verwenden, gehen Sie wie folgt vor: <br><br><ul><li>  ungef√§hr 30% der Vorhersagen sind nahezu ideal, d.h.  erfordern nicht mehr als Anpassungen an einzelnen Abschnitten des Horizonts; </li><li>  50% der Vorhersagen enthalten nicht mehr als 12 Punkte, d. H.  nicht mehr als 2 extra; </li><li>  75% der Vorhersagen enthalten nicht mehr als 14 Punkte, d. H.  nicht mehr als 4 extra; </li><li>  Die verbleibenden 25% der Prognosen erfordern eine gr√ºndlichere Verfeinerung, einschlie√ülich m√∂glicherweise einer vollst√§ndigen Neugestaltung einzelner Schichten. </li></ul><br>  Eine weitere Erh√∂hung der Stichprobengr√∂√üe f√ºhrt nicht zu verbesserten Ergebnissen. <br><br>  Im Allgemeinen k√∂nnen wir f√ºr den von uns untersuchten Datenw√ºrfel R√ºckschl√ºsse darauf ziehen, dass 1-5% des gesamten Datenvolumens ausreichen, um ein gutes Ergebnis von einem neuronalen Netzwerk zu erhalten. <br><br>  Aus diesen Daten lassen sich in Verbindung mit den oben genannten Metriken und Abbildungen bereits Schlussfolgerungen √ºber die Angemessenheit der Verwendung neuronaler Netze zur Unterst√ºtzung von Dolmetschern und √ºber die Ergebnisse ziehen, mit denen Spezialisten umgehen werden. <br><br><h2>  Schlussfolgerungen </h2><br>  Nun k√∂nnen wir die am Anfang des Artikels gestellten Fragen anhand der Ergebnisse beantworten, die am Beispiel eines seismischen W√ºrfels der Nordsee erhalten wurden: <br><br>  <b>Wie viele Daten ben√∂tigen Experten, um ein neuronales Netzwerk zu trainieren?</b>  <b>Und welche Daten soll ich w√§hlen?</b> <br><br>  Um eine gute Prognose des Netzwerks zu erhalten, ist es wirklich ausreichend, 1-5% der Gesamtzahl der Slices vorab zu markieren.  Eine weitere Steigerung des Volumens f√ºhrt nicht zu einer Verbesserung des Ergebnisses, vergleichbar mit der Zunahme der Anzahl der zuvor markierten Daten.  Um ein besseres Markup f√ºr ein so kleines Volumen mithilfe eines neuronalen Netzwerks zu erzielen, m√ºssen andere Ans√§tze verwendet werden, z. B. die Feinabstimmung der Architektur und der Lernstrategien, die Bildvorverarbeitung usw. <br><br>  F√ºr die vorl√§ufige Markierung empfiehlt es sich, Scheiben beider Arten zu w√§hlen - Inlines und Crosslines. <br><br>  <b>Was passiert bei einem solchen Ausgang?</b>  <b>Wird eine manuelle Verfeinerung der Vorhersagen f√ºr neuronale Netze erforderlich sein?</b>  <b>Wenn ja, wie komplex und umfangreich?</b> <b><br></b> <br>  Infolgedessen erfordert ein erheblicher Teil der durch ein solches neuronales Netz gekennzeichneten Bilder nicht die bedeutendste Verfeinerung, die darin besteht, einzelne schlecht erkannte Zonen zu korrigieren.  Darunter sind solche Interpretationen, die keine Korrekturen erfordern.  Und nur f√ºr einzelne Bilder ben√∂tigen Sie m√∂glicherweise ein neues manuelles Layout. <br><br>  Wenn der Lernalgorithmus und die Netzwerkparameter optimiert werden, k√∂nnen nat√ºrlich die Vorhersagef√§higkeiten verbessert werden.  In unserem Experiment war die L√∂sung solcher Probleme nicht enthalten. <br><br>  Dar√ºber hinaus sollten die Ergebnisse einer Studie zu einem seismischen W√ºrfel nicht leichtfertig verallgemeinert werden - gerade wegen der Einzigartigkeit jedes Datensatzes.  Diese Ergebnisse best√§tigen jedoch ein Experiment, das von anderen Autoren durchgef√ºhrt wurde, und bilden die Grundlage f√ºr den Vergleich mit unseren nachfolgenden Studien, √ºber die wir ebenfalls in K√ºrze schreiben werden. <br><br><h2>  Danksagung </h2><br>  Zum Schluss m√∂chte ich meinen Kollegen von <a href="https://maritimeai.net/">MaritimeAI</a> (insbesondere Andrey Kokhan) und <a href="http://ods.ai/">ODS</a> f√ºr wertvolle Kommentare und Hilfe danken! <br><br><h2>  Liste der verwendeten Quellen: </h2><br><ol><li>  <a href="https://arxiv.org/abs/1903.11215">Bas Peters, Eldad Haber, Justin Granek.</a>  <a href="https://arxiv.org/abs/1903.11215">Neuronale Netze f√ºr Geophysiker und ihre Anwendung auf die Interpretation seismischer Daten</a> </li><li>  <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">Hao Wu, Bo Zhang.</a>  <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">Ein tiefes neuronales Faltungscodierer-Decodierer-Netzwerk zur Unterst√ºtzung der seismischen Horizontverfolgung</a> </li><li>  <a href="">Thilo Wrona, Indranil Pan, Robert L. Gawthorpe und Haakon Fossen.</a>  <a href="">Seismische Fazies-Analyse mit maschinellem Lernen</a> </li><li>  <a href="https://arxiv.org/pdf/1904.00770v1.pdf">Reinaldo Mozart Silva, Rodrigo S. Ferreira, Daniel Civitarese, Daniela Szwarcman, Emilio Vital Brazil.</a>  <a href="https://arxiv.org/pdf/1904.00770v1.pdf">Niederl√§ndischer Datensatz: Ein neuer √∂ffentlicher Datensatz f√ºr maschinelles Lernen in der seismischen Interpretation</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de482780/">https://habr.com/ru/post/de482780/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de482766/index.html">√úber einige Probleme bei der Mikrooptimierung</a></li>
<li><a href="../de482768/index.html">Wann erscheint DeepRegistry? Auf die Liebe der Weltregulierungsbeh√∂rden, alles zu kontrollieren</a></li>
<li><a href="../de482772/index.html">Progressive Webanwendungen im Jahr 2020</a></li>
<li><a href="../de482774/index.html">Schwarzes Seoshniki und beste Werbemethoden. Erwachsener, Apotheke, Aufs√§tze, Datierung. Schestakow | Menschen PRO # 75</a></li>
<li><a href="../de482778/index.html">L√ºftung mit Erholung in der Wohnung. Ohne Leitungen und SMS</a></li>
<li><a href="../de482784/index.html">Das geheime Leben eines Linux-Servers oder Fan-Brute-Force-Angriffs auf das SSH-Subsystem</a></li>
<li><a href="../de482786/index.html">Ungel√∂stes R√§tsel</a></li>
<li><a href="../de482790/index.html">Vergessen Sie die homomorphe Verschl√ºsselung: Jetzt haben wir eine funktionale Verschl√ºsselung</a></li>
<li><a href="../de482792/index.html">ITER-Projekt im Jahr 2019</a></li>
<li><a href="../de482794/index.html">Neuronale Netze. Wo geht das alles hin?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙏 🖐🏻 👨‍🎨 Ceph-从“膝上”到“生产”第2部分 🕜 🕣 🗡️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="（第一部分在这里： https : //habr.com/en/post/456446/ ） 
 头孢 
 引言 


 由于网络是Ceph的关键要素之一，并且在我们公司中有些特定，因此我们将首先向您介绍一下。 
 对Ceph本身（主要是网络基础结构）的描述将少得多。 仅介绍Ceph服务器和Prox...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ceph-从“膝上”到“生产”第2部分</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458390/"><p>  （第一部分在这里： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https</a> : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">//habr.com/en/post/456446/</a> ） </p><br><h1 id="ceph"> 头孢 </h1><br><h3 id="vvedenie"> 引言 </h3><br><p> 由于网络是Ceph的关键要素之一，并且在我们公司中有些特定，因此我们将首先向您介绍一下。 <br> 对Ceph本身（主要是网络基础结构）的描述将少得多。 仅介绍Ceph服务器和Proxmox虚拟化服务器的某些功能。 </p><a name="habracut"></a><br><p> 因此：网络拓扑本身是作为<strong>Leaf-Spine</strong>构建的<strong>。</strong> 经典的三层体系结构是一个网络，其中包含<strong>核心</strong> （核心路由器）， <strong>聚合</strong> （聚合路由器）并直接与<strong>Access</strong>客户端（访问路由器）连接： </p><br><p>  <strong>三级方案</strong> </p><br><p><img src="https://habrastorage.org/webt/yf/e8/cm/yfe8cmp5qspkply3yniplpk53oo.jpeg"></p><br><p>  Leaf-Spine拓扑包含两个级别： <strong>Spine</strong> （大致来说是主路由器）和<strong>Leaf</strong> （分支）。 </p><br><p>  <strong>两级方案</strong> </p><br><p><img src="https://habrastorage.org/webt/dw/ka/qo/dwkaqo4_ru7urikqyvmv3mqe8ik.jpeg"></p><br><p> 所有内部和外部路由都基于BGP。  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><strong>XCloud</strong></a>是处理访问控制，公告和更多内容的主要系统<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><strong>。</strong></a> <br> 用于通道预留（以及用于扩展）的服务器连接到两个L3交换机（大多数服务器连接到Leaf交换机，但是某些网络负载增加的服务器直接连接到该交换机的Spine），并通过BGP宣布其单播地址，以及服务的任意播地址（如果有几台服务器为服务流量提供服务，并且ECMP平衡足以满足他们的需求）。 该方案的一个单独功能是使用基于RFC 5549的BGP未编号标准，这不仅使我们可以节省地址，还需要工程师熟悉IPv6世界。宴会和连通性出现问题。 但是，在切换到FRRouting之后（那些积极的贡献者是我们的网络设备供应商：Cumulus和XCloudNetworks），我们还没有看到更多的此类问题。 </p><br><p> 为了方便起见，我们将整个总体方案称为“工厂”。 </p><br><h2 id="poisk-puti"> 寻找方法 </h2><br><p> 群集网络配置选项： </p><br><p>  1）BGP上的第二个网络 </p><br><p>  2）使用LACP的两个单独的堆叠式交换机上的第二个网络 </p><br><p>  3）在两个单独的隔离式交换机上使用OSPF的第二个网络 </p><br><h3 id="testy"> 测验 </h3><br><p> 测试分为两种类型： </p><br><p>  a）使用iperf，qperf，nuttcp实用程序的网络 </p><br><p>  b）内部测试Ceph ceph-gobench，rados实验台，创建了rbd，并在一个或多个线程中使用dd使用fio在其上进行了测试 </p><br><p> 所有测试均在带有SAS磁盘的测试机上进行。  rbd性能的数据并没有太多关注，它们仅用于比较。 有兴趣根据连接类型进行更改。 </p><br><h3 id="pervyy-variant"> 第一选择 </h3><br><p>  <strong>网卡已连接到出厂的已配置BGP。</strong> </p><br><p> 对于内部网络使用此方案不是最佳选择： </p><br><p> 首先，交换形式的中间元素数量过多，这会带来额外的延迟（这是主要原因）。 <br> 其次，最初，为了通过s3传递静态数据，他们使用了在带有radosgateway的几台机器上提出的任意播地址。 这导致以下事实：从前端计算机到RGW的流量分配不均，而是沿着最短的路径传递-也就是说，前端Nginx始终转向与RGW相同的节点，该节点连接到与其共享的叶子（当然，这是不是主要参数-我们只是随后拒绝了任播地址返回静态值）。 但是出于实验的纯正性，他们决定对这种方案进行测试，以获取比较数据。 </p><br><p> 我们害怕对整个带宽进行测试，因为产品服务器使用了工厂，并且如果我们阻塞了叶子和主干之间的链接，这将损害部分销售。 <br> 实际上，这是拒绝这种计划的另一个原因。 <br> 使用带宽为3Gbps，带宽为1、10和100的Iperf测试与其他方案进行比较。 <br> 测试显示以下结果： </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/0a5/257/66b/0a525766bf7e61ffc4ba1129db0d17fd.png"></p><br><p> 在<strong>1个</strong>流中，大约为<strong>9.30-9.43</strong> <strong>Gbits / sec</strong> （在这种情况下，重新传输的数量<strong>猛增</strong>到<strong>39148</strong> ）。 该图证明接近一个接口的最大值，表明使用了两个接口之一。 重传次数约为<strong>500-600。</strong> <br> 每个接口有<strong>10</strong>个<strong>9.63 Gbit / s的</strong>流，而重传的数量平均<strong>增加到17045。</strong> <br> 在<strong>100个</strong>线程中，结果比在<strong>10</strong> <strong>个</strong>线程中差，而重传的次数则更少：平均值为<strong>3354</strong> </p><br><h3 id="vtoroy-variant"> 第二选择 </h3><br><p>  <strong>拉普</strong> </p><br><p> 有两个Juniper EX4500交换机。 他们将它们收集在堆栈中，并通过第一个链接将服务器连接到一个交换机，将第二个链接到第二个交换机。 <br> 初始绑定设置如下： </p><br><pre><code class="plaintext hljs">root@ceph01-test:~# cat /etc/network/interfaces auto ens3f0 iface ens3f0 inet manual bond-master bond0 post-up /sbin/ethtool -G ens3f0 rx 8192 post-up /sbin/ethtool -G ens3f0 tx 8192 post-up /sbin/ethtool -L ens3f0 combined 32 post-up /sbin/ip link set ens3f0 txqueuelen 10000 mtu 9000 auto ens3f1 iface ens3f1 inet manual bond-master bond0 post-up /sbin/ethtool -G ens3f1 rx 8192 post-up /sbin/ethtool -G ens3f1 tx 8192 post-up /sbin/ethtool -L ens3f1 combined 32 post-up /sbin/ip link set ens3f1 txqueuelen 10000 mtu 9000 auto bond0 iface bond0 inet static address 10.10.10.1 netmask 255.255.255.0 slaves none bond_mode 802.3ad bond_miimon 100 bond_downdelay 200 bond_xmit_hash_policy 3 #(layer3+4 ) mtu 9000</code> </pre> <br><p>  iperf和qperf测试显示Bw高达<strong>16Gbits / sec。</strong> 我们决定比较不同类型的mod： <br>  <strong>rr，balance-xor和802.3ad。</strong> 我们还比较了不同类型的散列<strong>layer2 + 3和layer3 + 4</strong> （希望在散列计算上获得优势）。 <br> 我们还比较了变量<strong>net.ipv4.fib_multipath_hash_policy的</strong>不同sysctl值的结果（嗯，尽管它与<strong>绑定</strong>无关，但我们对<strong>net.ipv4.tcp_congestion_control</strong>发挥了一些作用。此变量上有一篇<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">不错的ValdikSS文章</a> ）。 </p><br><p> 但是在所有测试中，它都无法克服<strong>18Gbits / sec</strong>的阈值（此数字是使用<strong>balance-xor和802.3ad获得的</strong> ，测试结果之间的差异不大），并且该值是通过突发“跳跃”获得的。 </p><br><h3 id="tretiy-variant"> 第三选择 </h3><br><p>  <strong>OSPF协议</strong> </p><br><p> 为了配置此选项，从交换机中删除了LACP（保留了堆栈，但仅用于管理）。 在每个交换机上，他们为一组端口收集了一个单独的VLAN（以期将来QA和PROD服务器都将卡在同一交换机中）。 </p><br><p> 为每个VLAN配置两个扁平专用网络（每个交换机一个接口）。 在这些地址之上是来自第三个专用网络（CEPH的群集网络）的另一个地址的公告。 </p><br><p> 由于<em>公共网络</em> （使用SSH的<em>公共网络</em> ）在BGP上工作，因此我们使用frr来配置OSPF（已在系统上）。 </p><br><p>  <strong>10.10.10.0/24和20.20.20.0/24-</strong>交换机上的两个扁平网络 </p><br><p>  <strong>172.16.1.0/24-</strong>公告网络 </p><br><p><img src="https://habrastorage.org/webt/t5/c5/fp/t5c5fpxxwqv7u82ywsvkuumcsag.jpeg"></p><br><p> 机器设置： <br> 接口<strong>ens1f0 ens1f1</strong>查看专用网络 <br> 接口<strong>ens4f0 ens4f1</strong>看公网 </p><br><p> 机器上的网络配置如下所示： </p><br><pre> <code class="plaintext hljs">oot@ceph01-test:~# cat /etc/network/interfaces # This file describes the network interfaces available on your system # and how to activate them. For more information, see interfaces(5). source /etc/network/interfaces.d/* # The loopback network interface auto lo iface lo inet loopback auto ens1f0 iface ens1f0 inet static post-up /sbin/ethtool -G ens1f0 rx 8192 post-up /sbin/ethtool -G ens1f0 tx 8192 post-up /sbin/ethtool -L ens1f0 combined 32 post-up /sbin/ip link set ens1f0 txqueuelen 10000 mtu 9000 address 10.10.10.1/24 auto ens1f1 iface ens1f1 inet static post-up /sbin/ethtool -G ens1f1 rx 8192 post-up /sbin/ethtool -G ens1f1 tx 8192 post-up /sbin/ethtool -L ens1f1 combined 32 post-up /sbin/ip link set ens1f1 txqueuelen 10000 mtu 9000 address 20.20.20.1/24 auto ens4f0 iface ens4f0 inet manual post-up /sbin/ethtool -G ens4f0 rx 8192 post-up /sbin/ethtool -G ens4f0 tx 8192 post-up /sbin/ethtool -L ens4f0 combined 32 post-up /sbin/ip link set ens4f0 txqueuelen 10000 mtu 9000 auto ens4f1 iface ens4f1 inet manual post-up /sbin/ethtool -G ens4f1 rx 8192 post-up /sbin/ethtool -G ens4f1 tx 8192 post-up /sbin/ethtool -L ens4f1 combined 32 post-up /sbin/ip link set ens4f1 txqueuelen 10000 mtu 9000 #     loopback-: auto lo:0 iface lo:0 inet static address 55.66.77.88/32 dns-nameservers 55.66.77.88 auto lo:1 iface lo:1 inet static address 172.16.1.1/32</code> </pre> <br><p>  Frr配置如下所示： </p><br><pre> <code class="plaintext hljs">root@ceph01-test:~# cat /etc/frr/frr.conf frr version 6.0 frr defaults traditional hostname ceph01-prod log file /var/log/frr/bgpd.log log timestamp precision 6 no ipv6 forwarding service integrated-vtysh-config username cumulus nopassword ! interface ens4f0 ipv6 nd ra-interval 10 ! interface ens4f1 ipv6 nd ra-interval 10 ! router bgp 65500 bgp router-id 55.66.77.88 # ,       timers bgp 10 30 neighbor ens4f0 interface remote-as 65001 neighbor ens4f0 bfd neighbor ens4f1 interface remote-as 65001 neighbor ens4f1 bfd ! address-family ipv4 unicast redistribute connected route-map redis-default exit-address-family ! router ospf ospf router-id 172.16.0.1 redistribute connected route-map ceph-loopbacks network 10.10.10.0/24 area 0.0.0.0 network 20.20.20.0/24 area 0.0.0.0 ! ip prefix-list ceph-loopbacks seq 10 permit 172.16.1.0/24 ge 32 ip prefix-list default-out seq 5 permit 0.0.0.0/0 ge 32 ! route-map ceph-loopbacks permit 10 match ip address prefix-list ceph-loopbacks ! route-map redis-default permit 10 match ip address prefix-list default-out ! line vty !</code> </pre> <br><p> 在这些设置上，网络测试iperf，qperf等。 显示两个通道的最大利用率为<strong>19.8 Gbit /秒，</strong>而延迟降至<strong>20us</strong> </p><br><p>  <em><strong>Bgp router-id</strong>字段<strong>：</strong>用于在处理路由信息和构建路由时标识节点。</em>  <em>如果未在配置中指定，则选择主机IP地址之一。</em>  <em>不同的硬件和软件制造商可能具有不同的算法，在我们的案例中，FRR使用了最大的环回IP地址。</em>  <em>这导致了两个问题：</em> <em><br></em>  <em>1）如果我们尝试挂断一个比当前地址更多的地址（例如，来自网络172.16.0.0的私有地址），则这将导致<strong>router-id</strong>发生更改，并因此重新安装当前会话。</em>  <em>这意味着短暂的中断和网络连接的丢失。</em> <em><br></em>  <em>2）如果我们尝试挂断由多台计算机共享的任播地址，并将其选为<strong>路由器ID</strong> ，则网络上会出现两个具有相同<strong>路由器ID</strong>的节点<strong>。</strong></em> </p><br><h2 id="chast-2"> 第二部分 </h2><br><p> 经过质量检查测试后，我们开始升级战斗Ceph。 </p><br><h3 id="network"> 网路 </h3><br><h3 id="pereezd-s-odnoy-seti-na-dve"> 从一个网络迁移到两个网络 </h3><br><p> 群集网络参数是无法通过<strong>ceph tell osd</strong>指定OSD即时更改的参数之一<strong>。</strong> 在配置中更改它并重新启动整个集群是一个可以容忍的解决方案，但是我真的不希望停机时间很小。 用新的网络参数重新启动一个OSD也是不可能的-有时我们会有两个半集群-旧网络上的旧OSD，新网络上的新OSD。 幸运的是，群集网络参数（顺便说一下，还有public_network）是一个列表，也就是说，您可以指定多个值。 我们决定逐步采取行动-首先在配置中添加一个新网络，然后删除旧的网络。  Ceph按顺序浏览网络列表-OSD首先开始使用首先列出的网络。 </p><br><p> 困难之处在于，第一个网络通过bgp工作并连接到一个交换机，第二个网络连接到ospf并连接到其他未物理连接到第一个交换机的网络。 在过渡时，有必要在两个网络之间临时进行网络访问。 设置工厂的特殊之处在于，如果不在发布列表中，则无法在网络上配置ACL（在这种情况下，它是“外部”，并且只能在外部创建ACL。它是在西班牙创建的，但是没有到达）在叶子上）。 </p><br><p> 解决方案是一个拐杖，很复杂，但是有效：通过bgp与ospf同时发布内部网络。 </p><br><p> 过渡顺序如下： </p><br><p>  1）在两个网络上为ceph配置群集网络：通过bgp和ospf <br> 在frr config中，无需更改任何内容，只需一行 </p><br><pre> <code class="plaintext hljs">ip prefix-list default-out seq 5 permit 0.0.0.0/0 ge 32</code> </pre> <br><p> 它不会限制我们在已通告的地址中使用，内部网络本身的地址会在环回接口上引发，这足以在路由器上配置此地址的通告的接收。 </p><br><p>  2）将新网络添加到<strong>ceph.conf</strong>配置 </p><br><pre> <code class="plaintext hljs">cluster network = 172.16.1.0/24, 55.66.77.88/27</code> </pre> <br><p> 并开始一次重新启动OSD，直到每个人都<strong>切换到172.16.1.0/24</strong>网络<strong>。</strong> </p><br><pre> <code class="plaintext hljs">root@ceph01-prod:~#ceph osd set noout # -          OSD #     .  ,     #  , OSD      30 . root@ceph01-prod:~#for i in $(ps ax | grep osd | grep -v grep| awk '{ print $10}'); \ root@ceph01-prod:~# do systemctl restart ceph-osd@$i; sleep 30; done</code> </pre> <br><p>  3）然后我们从配置中删除多余的网络 </p><br><pre> <code class="plaintext hljs">cluster network = 172.16.1.0/24</code> </pre> <br><p> 并重复该过程。 </p><br><p> 就是这样，我们顺利地迁移到了新的网络。 </p><br><p> 参考文献： <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https://shalaginov.com/2016/03/26/network-topology-leaf-spine/</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https://www.xcloudnetworks.com/case-studies/innova-case-study/</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https://github.com/rumanzo/ceph-gobench</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN458390/">https://habr.com/ru/post/zh-CN458390/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN458376/index.html">没有其他编程语言。 第1部分：领域逻辑</a></li>
<li><a href="../zh-CN458378/index.html">使用Avocode进行网站布局。 初学者审查。 奖金-注册30天试用期</a></li>
<li><a href="../zh-CN458382/index.html">我们为什么要教这个？</a></li>
<li><a href="../zh-CN458384/index.html">HP 3D结构化光扫描仪Pro S3审查和测试</a></li>
<li><a href="../zh-CN458388/index.html">深度（学习+随机）森林和文章解析</a></li>
<li><a href="../zh-CN458394/index.html">以LoRaWAN保护无线协议为例</a></li>
<li><a href="../zh-CN458396/index.html">如何通过服务器端渲染方便地在Vue.js上进行开发</a></li>
<li><a href="../zh-CN458398/index.html">远程工作的卫生或心灵感应的好处</a></li>
<li><a href="../zh-CN458400/index.html">微服务架构和实施分步指南第1部分</a></li>
<li><a href="../zh-CN458404/index.html">从整体到微服务的过渡：历史和实践</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
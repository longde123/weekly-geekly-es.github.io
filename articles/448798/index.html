<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌫️ 👸🏿 👩🏿‍🤝‍👩🏻 Prueba de Python con pytest. Usando pytest con otras herramientas, CAPÍTULO 7 🥦 👨🏽‍🔬 🎵</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Volver 


 Por lo general, pytest no se usa de forma independiente, sino en un entorno de prueba con otras herramientas. Este capítulo trata sobre otr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Prueba de Python con pytest. Usando pytest con otras herramientas, CAPÍTULO 7</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/448798/"><p><img src="https://habrastorage.org/webt/jl/jn/bb/jljnbbjr-ejh473xy_eccsmknpk.png">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Volver</a> </p><br><p>  <em>Por lo general, pytest no se usa de forma independiente, sino en un entorno de prueba con otras herramientas.</em>  <em>Este capítulo trata sobre otras herramientas que a menudo se usan junto con pytest para realizar pruebas efectivas y eficientes.</em>  <em>Aunque de ninguna manera se trata de una lista exhaustiva, las herramientas discutidas aquí le darán una idea del sabor del poder de mezclar Pytest con otras herramientas.</em> </p><br><p><img src="https://habrastorage.org/webt/hd/--/9w/hd--9w134j0rxhmxftrflbbdopy.png"></p><a name="habracut"></a><br><p>  Los ejemplos en este libro están escritos usando Python 3.6 y pytest 3.2.  pytest 3.2 es compatible con Python 2.6, 2.7 y Python 3.3+. </p><br><blockquote> El código fuente para el proyecto Tareas, así como para todas las pruebas que se muestran en este libro, está disponible en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" title="https://pragprog.com/titles/bopytest/source_code">enlace</a> en la página web del libro en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" title="https://pragprog.com/titles/bopytest">pragprog.com</a> .  No necesita descargar el código fuente para comprender el código de prueba;  El código de prueba se presenta de forma conveniente en los ejemplos.  Pero para seguir las tareas del proyecto o adaptar ejemplos de prueba para probar su propio proyecto (¡sus manos están desatadas!), Debe ir a la página web del libro y descargar el trabajo.  Allí, en la página web del libro, hay un enlace para mensajes de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" title="https://pragprog.com/titles/bopytest/errata">erratas</a> y un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" title="https://forums.pragprog.com/forums/438">foro de discusión</a> . </blockquote><p>  Debajo del spoiler hay una lista de artículos en esta serie. </p><br><div class="spoiler">  <b class="spoiler_title">Tabla de contenidos</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><strong>Introduccion</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><strong>Capítulo 1: comenzando con pytest</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><strong>Capítulo 2: Funciones de prueba de escritura</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><strong>Capítulo 3: accesorios de Pytest</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><strong>Capítulo 4: Accesorios incorporados</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><strong>Capítulo 5: Complementos</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><strong>Capítulo 6: Configuración</strong></a> </li><li>  [ <strong>Capítulo 7: Uso de pytest con otras herramientas</strong> ] (Este artículo) ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://habr.com/en/post/448798/</a> ) </li></ul></div></div><br><h2 id="pdb-debugging-test-failures">  pdb: errores de prueba de depuración </h2><br><p> El módulo <code>pdb</code> es un depurador de Python en la biblioteca estándar.  Utiliza <code>--pdb</code> para que pytest inicie una sesión de depuración en el punto de falla.  Veamos <code>pdb</code> en acción en el contexto del proyecto Tareas. </p><br><p>  En “Parametrización de accesorios” en la página 64, dejamos el proyecto Tareas con algunos errores: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch3/c/tasks_proj $ pytest --tb=no -q .........................................FF.FFFF FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF.FFF........... 42 failed, 54 passed in 4.74 seconds</code> </pre> <br><p>  Antes de ver cómo <code>pdb</code> puede ayudarnos a depurar esta prueba, echemos un vistazo a las opciones de pytest disponibles para acelerar la depuración de los errores de prueba, que primero examinamos en la sección "Uso de opciones" en la página 9: </p><br><ul><li>  <code>--tb=[auto/long/short/line/native/no]</code> : controla el estilo de rastreo. </li><li>  <code>-v / --verbose</code> : muestra todos los nombres de prueba que pasaron o fallaron. </li><li>  <code>-l / --showlocals</code> : muestra las variables locales junto al seguimiento de la pila. </li><li>  <code>-lf / --last-failed</code> : ejecuta solo pruebas que fallan. </li><li>  <code>-x / --exitfirst</code> : detiene la sesión de prueba en el primer error. </li><li>  <code>--pdb</code> : inicia una sesión de depuración interactiva en el punto de falla. </li></ul><br><hr><br><p>  <em>Instalar MongoDB</em> </p><br><hr><br><p>  Como se mencionó en el Capítulo 3, “Accesorios de Pytest”, en la página 49, se requiere la instalación de <code>MongoDB</code> y <code>pymongo</code> para ejecutar las pruebas MongoDB. </p><br><p>  Probé la versión de Community Server que se encuentra en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://www.mongodb.com/download-center</a> .  pymongo se instala con <code>pip</code> : <code>pip install pymongo</code> .  Sin embargo, este es el último ejemplo en un libro que usa MongoDB.  Para probar el depurador sin usar MongoDB, puede ejecutar los comandos pytest desde el <code>code/ch2/</code> , ya que este directorio también contiene varias pruebas fallidas. </p><br><hr><br><p>  Acabamos de ejecutar las pruebas del <code>code/ch3/c</code> para asegurarnos de que algunas de ellas no funcionen.  No vimos trazas o nombres de prueba porque <code>--tb=no</code> deshabilita el rastreo y no teníamos <code>--verbose</code> habilitado.  Repitamos los errores (no más de tres) con el texto detallado: </p><br><pre> <code class="plaintext hljs">$ pytest --tb=no --verbose --lf --maxfail=3 ============================= test session starts ============================= collected 96 items / 52 deselected run-last-failure: rerun previous 44 failures tests/func/test_add.py::test_add_returns_valid_id[mongo] ERROR [ 2%] tests/func/test_add.py::test_added_task_has_id_set[mongo] ERROR [ 4%] tests/func/test_add.py::test_add_increases_count[mongo] ERROR [ 6%] =================== 52 deselected, 3 error in 0.72 seconds ====================</code> </pre> <br><p>  Ahora sabemos qué pruebas fallaron.  Veamos solo uno de ellos, usando <code>-x</code> , activando el rastreo, no usando <code>--tb=no</code> , y mostrando variables locales con <code>-l</code> : </p><br><pre> <code class="plaintext hljs">$ pytest -v --lf -l -x ===================== test session starts ====================== run-last-failure: rerun last 42 failures collected 96 items tests/func/test_add.py::test_add_returns_valid_id[mongo] FAILED =========================== FAILURES =========================== _______________ test_add_returns_valid_id[mongo] _______________ tasks_db = None def test_add_returns_valid_id(tasks_db): """tasks.add(&lt;valid task&gt;) should return an integer.""" # GIVEN an initialized tasks db # WHEN a new task is added # THEN returned task_id is of type int new_task = Task('do something') task_id = tasks.add(new_task) &gt; assert isinstance(task_id, int) E AssertionError: assert False E + where False = isinstance(ObjectId('59783baf8204177f24cb1b68'), int) new_task = Task(summary='do something', owner=None, done=False, id=None) task_id = ObjectId('59783baf8204177f24cb1b68') tasks_db = None tests/func/test_add.py:16: AssertionError !!!!!!!!!!!! Interrupted: stopping after 1 failures !!!!!!!!!!!! ===================== 54 tests deselected ====================== =========== 1 failed, 54 deselected in 2.47 seconds ============</code> </pre><br><p>  Muy a menudo, esto es suficiente para entender por qué falló la prueba.  En este caso particular, está bastante claro que <code>task_id</code> no <code>task_id</code> un entero, es una instancia de ObjectId.  ObjectId es el tipo utilizado por MongoDB para los identificadores de objetos en la base de datos.  Mi intención con la capa <code>tasksdb_pymongo.py</code> era ocultar ciertos detalles de la implementación de MongoDB del resto del sistema.  Está claro que en este caso no funcionó. </p><br><p>  Sin embargo, queremos ver cómo usar pdb con pytest, así que imaginemos que no está claro por qué esta prueba falló.  Podemos hacer que pytest inicie una sesión de depuración y comience justo en el punto de falla usando <code>--pdb</code> : </p><br><pre> <code class="plaintext hljs">$ pytest -v --lf -x --pdb ===================== test session starts ====================== run-last-failure: rerun last 42 failures collected 96 items tests/func/test_add.py::test_add_returns_valid_id[mongo] FAILED &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; traceback &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; tasks_db = None def test_add_returns_valid_id(tasks_db): """tasks.add(&lt;valid task&gt;) should return an integer.""" # GIVEN an initialized tasks db # WHEN a new task is added # THEN returned task_id is of type int new_task = Task('do something') task_id = tasks.add(new_task) &gt; assert isinstance(task_id, int) E AssertionError: assert False E + where False = isinstance(ObjectId('59783bf48204177f2a786893'), int) tests/func/test_add.py:16: AssertionError &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; entering PDB &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt; /path/to/code/ch3/c/tasks_proj/tests/func/test_add.py(16) &gt; test_add_returns_valid_id() -&gt; assert isinstance(task_id, int) (Pdb)</code> </pre> <br><p>  Ahora que estamos en el indicador (Pdb), tenemos acceso a todas las funciones interactivas de depuración de pdb.  Cuando veo bloqueos, uso regularmente estos comandos: </p><br><ul><li>  <code>p/print expr</code> : imprime el valor de exp. </li><li>  <code>pp expr</code> : Pretty imprime el valor de expr. </li><li>  <code>l/list</code> : <code>l/list</code> el punto de falla y cinco líneas de código arriba y abajo. </li><li>  <code>l/list begin,end</code> : enumera números de línea específicos. </li><li>  <code>a/args</code> : Imprime los argumentos de la función actual con sus valores. </li><li>  <code>u/up</code> : mueve un nivel hacia arriba en la ruta de la pila. </li><li>  <code>d/down</code> : baja un nivel en la traza de la pila. </li><li>  <code>q/quit</code> : finaliza una sesión de depuración. </li></ul><br><p>  Otros comandos de navegación, como step y next, no son muy útiles, ya que estamos sentados en la declaración de aserción.  También puede simplemente ingresar nombres de variables y obtener valores. </p><br><p>  Puede usar <code>p/print expr</code> manera similar a la <code>-l/--showlocals</code> para ver los valores en una función: </p><br><pre> <code class="plaintext hljs">(Pdb) p new_task Task(summary='do something', owner=None, done=False, id=None) (Pdb) p task_id ObjectId('59783bf48204177f2a786893') (Pdb)</code> </pre> <br><p>  Ahora puede salir del depurador y continuar con las pruebas. </p><br><pre> <code class="plaintext hljs">(Pdb) q !!!!!!!!!!!! Interrupted: stopping after 1 failures !!!!!!!!!!!! ===================== 54 tests deselected ====================== ========== 1 failed, 54 deselected in 123.40 seconds ===========</code> </pre> <br><p>  Si no usáramos <code>-</code> , pytest abriría nuevamente Pdb en la próxima prueba.  Más información sobre el uso del módulo pdb está disponible en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentación de Python</a> . </p><br><h2 id="coveragepy-opredelenie-obema-testiruemogo-koda">  Coverage.py: determinación de la cantidad de código de prueba </h2><br><p>  La cobertura del código es un indicador del porcentaje de código probado que es probado por un conjunto de pruebas.  Cuando ejecuta pruebas para el proyecto Tareas, algunas funciones de Tareas se ejecutan con cada prueba, pero no con todas. </p><br><p>  Las herramientas de cobertura de código son excelentes para hacerle saber qué partes del sistema son completamente ignoradas por las pruebas. </p><br><p>  <code>Coverage.py</code> es la herramienta de cobertura Python preferida que mide la cobertura del código. </p><br><p>  Lo usará para verificar el código del proyecto Tareas con pytest. </p><br><p>  Para usar <code>coverage.py</code> necesitas instalarlo.  No <code>pytest-cov</code> daño instalar un complemento llamado <code>pytest-cov</code> , que le permite llamar a <code>coverage.py</code> desde pytest con algunas opciones adicionales de pytest.  Dado que la <code>coverage</code> es una de las dependencias de <code>pytest-cov</code> , simplemente instale <code>pytest-cov</code> y tomará <code>coverage.py</code> : </p><br><pre> <code class="plaintext hljs">$ pip install pytest-cov Collecting pytest-cov Using cached pytest_cov-2.5.1-py2.py3-none-any.whl Collecting coverage&gt;=3.7.1 (from pytest-cov) Using cached coverage-4.4.1-cp36-cp36m-macosx_10_10_x86 ... Installing collected packages: coverage, pytest-cov Successfully installed coverage-4.4.1 pytest-cov-2.5.1</code> </pre> <br><p>  Ejecutemos el informe de cobertura para la segunda versión de la tarea.  Si todavía tiene instalada la primera versión del proyecto Tareas, desinstálela e instale la versión 2: </p><br><pre> <code class="plaintext hljs">$ pip uninstall tasks Uninstalling tasks-0.1.0: /path/to/venv/bin/tasks /path/to/venv/lib/python3.6/site-packages/tasks.egg-link Proceed (y/n)? y Successfully uninstalled tasks-0.1.0 $ cd /path/to/code/ch7/tasks_proj_v2 $ pip install -e . Obtaining file:///path/to/code/ch7/tasks_proj_v2 ... Installing collected packages: tasks Running setup.py develop for tasks Successfully installed tasks $ pip list ... tasks (0.1.1, /path/to/code/ch7/tasks_proj_v2/src) ...</code> </pre> <br><p>  Ahora que está instalada la próxima versión de las tareas, puede ejecutar el informe de cobertura base: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch7/tasks_proj_v2 $ pytest --cov=src ===================== test session starts ====================== plugins: mock-1.6.2, cov-2.5.1 collected 62 items tests/func/test_add.py ... tests/func/test_add_variety.py ............................ tests/func/test_add_variety2.py ............ tests/func/test_api_exceptions.py ......... tests/func/test_unique_id.py . tests/unit/test_cli.py ..... tests/unit/test_task.py .... ---------- coverage: platform darwin, python 3.6.2-final-0 ----------- Name Stmts Miss Cover -------------------------------------------------- src\tasks\__init__.py 2 0 100% src\tasks\api.py 79 22 72% src\tasks\cli.py 45 14 69% src\tasks\config.py 18 12 33% src\tasks\tasksdb_pymongo.py 74 74 0% src\tasks\tasksdb_tinydb.py 32 4 88% -------------------------------------------------- TOTAL 250 126 50% ================== 62 passed in 0.47 seconds ===================</code> </pre> <br><p>  Dado que el directorio actual es <code>tasks_proj_v2</code> , y el código fuente bajo prueba está en src, agregar la opción <code>--cov=src</code> genera un informe de cobertura solo para ese directorio. </p><br><p>  Como puede ver, algunos archivos tienen una cobertura bastante baja e incluso 0%.  Estos son recordatorios útiles: <code>tasksdb_pymongo.py</code> 0% porque hemos deshabilitado las pruebas para MongoDB en esta versión.  Algunos de ellos son bastante bajos.  El proyecto ciertamente tendrá que entregar pruebas para todas estas áreas antes de que esté listo para el horario estelar. </p><br><p>  Creo que varios archivos tienen un mayor porcentaje de cobertura: <code>api.py</code> y <code>tasksdb_tinydb.py</code> .  Echemos un vistazo a <code>tasksdb_tinydb.py</code> y veamos qué falta.  Creo que la mejor manera de hacer esto es usar informes HTML. </p><br><p>  Si vuelve a ejecutar <code>coverage.py</code> con la <code>--cov-report=html</code> , se generará un <code>--cov-report=html</code> : </p><br><pre> <code class="plaintext hljs">$ pytest --cov=src --cov-report=html ===================== test session starts ====================== plugins: mock-1.6.2, cov-2.5.1 collected 62 items tests/func/test_add.py ... tests/func/test_add_variety.py ............................ tests/func/test_add_variety2.py ............ tests/func/test_api_exceptions.py ......... tests/func/test_unique_id.py . tests/unit/test_cli.py ..... tests/unit/test_task.py .... ---------- coverage: platform darwin, python 3.6.2-final-0 ----------- Coverage HTML written to dir htmlcov ================== 62 passed in 0.45 seconds ===================</code> </pre> <br><p>  Luego puede abrir <code>htmlcov/index.html</code> en un navegador que muestra el resultado en la siguiente pantalla: </p><br><p><img src="https://habrastorage.org/webt/vs/sc/84/vssc84hovxefvf2g65740gu3ll0.png"></p><br><p>  Al hacer clic en <code>tasksdb_tinydb.py</code> se mostrará un informe para un archivo.  El porcentaje de líneas cubiertas se muestra en la parte superior del informe, más cuántas líneas están cubiertas y cuántas no, como se muestra en la siguiente pantalla: </p><br><p><img src="https://habrastorage.org/webt/os/pc/-o/ospc-o_yzzdfh1lzllw_1qtilrc.png"></p><br><p>  Al desplazarse hacia abajo, puede ver las líneas que faltan, como se muestra en la siguiente pantalla: </p><br><p><img src="https://habrastorage.org/webt/85/rg/lt/85rgltocwrunycedzbeweix4zyc.png"></p><br><p>  Incluso si esta pantalla no es una página completa para este archivo, esto es suficiente para decirnos que: </p><br><ol><li>  No probamos <code>list_tasks()</code> con el conjunto de propietarios. </li><li>  No probamos <code>update()</code> ni <code>delete()</code> . </li><li>  Quizás no estamos probando a fondo <code>unique_id()</code> . </li></ol><br><p>  Genial  Podemos incluirlos en nuestra lista de pruebas TO-DO junto con probar el sistema de configuración. </p><br><p>  Aunque las herramientas de cobertura de código son extremadamente útiles, luchar por una cobertura del 100% puede ser peligroso.  Cuando vea código que no se está probando, puede significar que se necesita una prueba.  Pero también puede significar que hay algunas funciones del sistema que no son necesarias y pueden eliminarse.  Como todas las herramientas de desarrollo de software, el análisis de cobertura de código no reemplaza el pensamiento. </p><br><p>  Consulte la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><code> coverage.py</code></a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><code>pytest-cov</code></a> obtener más detalles. </p><br><h2 id="mock-podmena-chastey-sistemy">  simulacro: sustitución de partes del sistema </h2><br><p>  El paquete simulado se usa para reemplazar partes del sistema para aislar partes del código de prueba del resto del sistema.  Simulacro: los objetos a veces se llaman dobles de prueba, espías, falsificaciones o trozos. </p><br><p>  Entre su propio accesorio pytest monkeypatch (descrito en Uso de monkeypatch en la página 85) y simulacro, debe tener toda la funcionalidad de prueba dual necesaria. </p><br><blockquote>  Atencion  Simulacro y muy raro <br>  Si es la primera vez que te encuentras con gemelos de prueba como simulacros, trozos y espías, ¡prepárate!  Será muy extraño, muy rápido, divertido, aunque muy impresionante. </blockquote><p>  El paquete <code>mock</code> viene con la biblioteca estándar de Python, como <code>unittest.mock</code> desde Python 3.3.  En versiones anteriores, está disponible como un paquete separado instalado a través de PyPI.  Esto significa que puede usar la versión <code>mock</code> PyPI de Python 2.6 a la última versión de Python y obtener la misma funcionalidad que la última versión <code>mock</code> Python.  Sin embargo, para usar con pytest, un complemento llamado <code>pytest-mock</code> tiene algunas características que lo convierten en mi interfaz preferida para el sistema simulado. </p><br><p>  Para el proyecto Tareas, usaremos <code>mock</code> para ayudarnos a probar la interfaz de línea de comandos.  En Coverage.py: al determinar cuánto código se está probando, en la página 129 vio que nuestro archivo <code>cli.py</code> no se probó en absoluto.  Comenzaremos a arreglarlo ahora.  Pero hablemos primero de estrategia. </p><br><p>  La primera solución en el proyecto Tareas fue hacer la mayoría de las pruebas de funcionalidad a través de <code>api.py</code>  Por lo tanto, una solución razonable es que la prueba de línea de comando no tiene que ser una prueba funcional completa.  Podemos estar seguros de que el sistema funcionará a través de la CLI si obtenemos un nivel API húmedo durante las pruebas de CLI.  También es una solución conveniente que nos permite ver moki en esta sección. </p><br><p>  La implementación de Tareas CLI utiliza un paquete de interfaz de línea de comando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Click de</a> terceros.  Existen muchas alternativas para implementar la interfaz de línea de comandos, incluido un módulo integrado en Python <code>argparse</code> .  Una de las razones por las que elegí Click es porque incluye un motor de prueba que nos ayuda a probar las aplicaciones Click.  Sin embargo, el código en <code>cli.py</code> , aunque esperamos que sea típico de las aplicaciones Click, no es obvio. </p><br><p>  Reduzcamos la velocidad e instalemos la tercera versión de Tareas: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ $ pip install -e ch7/tasks_proj_v2 ... Successfully installed tasks</code> </pre> <br><p>  En el resto de esta sección, desarrollará varias pruebas para probar la funcionalidad de "lista". <br>  Vamos a verlo en acción para entender lo que vamos a verificar: </p><br><blockquote>  <strong><em>Nota del traductor:</em></strong> Al usar la plataforma Windows, encontré varios problemas al probar la sesión a continuación. <br><ol><li>  Se debe crear una carpeta para la base de datos llamada <strong><code>tasks_db</code></strong> en la carpeta de su usuario.  Por ejemplo <code>c:\Users\User_1\tasks_db\</code> <br>  De lo contrario, obtenemos - &gt;&gt; FileNotFoundError: [Errno 2] No existe tal archivo o directorio: 'c: \ Users \ User_1 // tareas_db // tareas_db.json' </li><li>  Use comillas dobles en lugar de un apóstrofe.  De lo contrario, obtenga un error <br>  'hacer algo genial' <br>  Uso: las tareas agregan [OPCIONES] RESUMEN <br>  Intente "tareas agregar -h" para obtener ayuda. <br><br>  Error: Tengo argumentos extra inesperados (algo genial ') <br></li></ol><br></blockquote><br><pre> <code class="plaintext hljs">$ tasks list ID owner done summary -- ----- ---- ------- $ tasks add 'do something great' $ tasks add "repeat" -o Brian $ tasks add "again and again" --owner Okken $ tasks list ID owner done summary -- ----- ---- ------- 1 False do something great 2 Brian False repeat 3 Okken False again and again $ tasks list -o Brian ID owner done summary -- ----- ---- ------- 2 Brian False repeat $ tasks list --owner Brian ID owner done summary -- ----- ---- ------- 2 Brian False repeat</code> </pre> <br><p>  Se ve bastante simple.  El comando de <code>tasks list</code> muestra una lista de todas las tareas bajo el encabezado. <br>  El título se imprime incluso si la lista está vacía.  El comando solo muestra datos de un propietario, si <code>--owner</code> <code>-o</code> o <code>--owner</code> .  ¿Y cómo verificamos esto?  Hay muchas formas, pero vamos a usar moki. </p><br><p>  Las pruebas que usan MOK son necesariamente <em>pruebas de caja blanca</em> , y debemos analizar el código para decidir qué y dónde vamos a batear.  El punto de entrada principal está aquí: </p><br><blockquote>  ch7 / task_proj_v2 / src / tareas / cli.py </blockquote><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: tasks_cli()</code> </pre> <br><p>  Esto es solo una llamada a <code>tasks_cli()</code> : </p><br><blockquote>  ch7 / task_proj_v2 / src / tareas / cli.py </blockquote><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@click.group(context_settings={'help_option_names': ['-h', '--help']}) @click.version_option(version='0.1.1') def tasks_cli(): """Run the tasks application.""" pass</span></span></code> </pre> <br><p>  Obviamente?  No  Pero espera, se pone bueno (o malo, dependiendo de tu punto de vista).  Aquí está uno de los comandos de la <code>list</code> : </p><br><blockquote>  ch7 / task_proj_v2 / src / tareas / cli.py </blockquote><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@tasks_cli.command(name="list", help="list tasks") @click.option('-o', '--owner', default=None, help='list tasks with this owner') def list_tasks(owner): """    .   ,      . """ formatstr = "{: &gt;4} {: &gt;10} {: &gt;5} {}" print(formatstr.format('ID', 'owner', 'done', 'summary')) print(formatstr.format('--', '-----', '----', '-------')) with _tasks_db(): for t in tasks.list_tasks(owner): done = 'True' if t.done else 'False' owner = '' if t.owner is None else t.owner print(formatstr.format( t.id, owner, done, t.summary))</span></span></code> </pre> <br><p>  Cuando se acostumbre a escribir el código Click, asegúrese de que este código no sea tan malo.  No voy a explicar aquí qué y cómo funciona en esta función, ya que el desarrollo del código de línea de comandos no es el enfoque del libro;  Sin embargo, aunque estoy casi absolutamente seguro de que tengo este código correcto, de todos modos, siempre hay mucho espacio para el error humano.  Es por eso que un buen conjunto de pruebas automatizadas es importante para garantizar que esta función funcione correctamente. <br>  Esta función <code>list_tasks(owner)</code> depende de varias otras funciones: <code>tasks_db()</code> , que es el administrador de contexto, y <code>tasks.list_tasks(owner)</code> , que es la función API. </p><br><p>  Vamos a utilizar <code>mock</code> para poner funciones falsas en <code>tasks_db()</code> y <code>tasks.list_tasks()</code> .  Luego podemos llamar al método <code>list_tasks</code> través de la interfaz de línea de comandos y asegurarnos de que llame a la función <code>tasks.list_tasks()</code> , que funciona correctamente y procesa correctamente el valor de retorno. <br>  Para ahogar <code>tasks_db()</code> , veamos una implementación real: </p><br><p><img src="https://habrastorage.org/webt/jl/jn/bb/jljnbbjr-ejh473xy_eccsmknpk.png">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Volver</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/448798/">https://habr.com/ru/post/448798/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../448776/index.html">RxVMS: una arquitectura práctica para aplicaciones de flutter</a></li>
<li><a href="../448778/index.html">Presentación de la depuración de viajes en el tiempo para Visual Studio Enterprise 2019</a></li>
<li><a href="../448792/index.html">Prueba de Python con pytest. Accesorios incorporados, Capítulo 4</a></li>
<li><a href="../448794/index.html">Prueba de Python con pytest. Complementos CAPÍTULO 5</a></li>
<li><a href="../448796/index.html">Prueba de Python con pytest. Configuración, CAPÍTULO 6</a></li>
<li><a href="../448800/index.html">Configure Visual Studio en toda su organización con .vsconfig</a></li>
<li><a href="../448802/index.html">Pensar con portales: crear portales en Unreal Engine 4</a></li>
<li><a href="../448804/index.html">Preparándose para el tiempo de ejecución y el notario endurecidos de macOS</a></li>
<li><a href="../448806/index.html">Crear un sistema de extensión en la biblioteca Qt</a></li>
<li><a href="../448808/index.html">Sobre cosas simples, complicadas. "Acero dormido". Cómo engrasar pernos oxidados o no WD-40 con un solo ...</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
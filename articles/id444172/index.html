<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘ğŸ½ ğŸ£ ğŸ§‘ğŸ» Tujuh Mitos dalam Penelitian Pembelajaran Mesin ğŸ¤´ğŸ¾ ğŸ§”ğŸ½ ğŸ¤¶ğŸ¼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bagi mereka yang terlalu malas untuk membaca semuanya: sanggahan dari tujuh mitos populer disarankan, yang dalam bidang penelitian pembelajaran mesin ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tujuh Mitos dalam Penelitian Pembelajaran Mesin</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/444172/">  Bagi mereka yang terlalu malas untuk membaca semuanya: sanggahan dari tujuh mitos populer disarankan, yang dalam bidang penelitian pembelajaran mesin sering dianggap benar, pada Februari 2019. Artikel ini tersedia di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">situs web ArXiv dalam format pdf</a> [dalam bahasa Inggris]. <br><br>  Mitos 1: TensorFlow adalah perpustakaan tensor. <br>  Mitos 2: Database gambar mencerminkan foto asli yang ditemukan di alam. <br>  Mitos 3: Peneliti MO tidak menggunakan alat tes untuk pengujian. <br>  Mitos 4: Pelatihan jaringan saraf menggunakan semua data input. <br>  Mitos 5: Normalisasi batch diperlukan untuk melatih jaringan residual yang sangat dalam. <br>  Mitos 6: Jaringan dengan perhatian lebih baik daripada konvolusi. <br>  Mitos 7: Peta signifikansi adalah cara yang andal untuk menafsirkan jaringan saraf. <br><br>  Dan sekarang untuk detailnya. <br><a name="habracut"></a><br><h2>  Mitos 1: TensorFlow adalah perpustakaan tensor </h2><br>  Sebenarnya, ini adalah perpustakaan untuk bekerja dengan matriks, dan perbedaan ini sangat signifikan. <br><br>  Dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Menghitung Derivatif Orde Tinggi dari Matriks dan Ekspresi Tensor.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Laue et al.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Penulis NeurIPS 2018</a> menunjukkan bahwa perpustakaan mereka diferensiasi otomatis, berdasarkan kalkulus tensor nyata, memiliki pohon ekspresi jauh lebih kompak.  Faktanya adalah bahwa kalkulus tensor menggunakan notasi indeks, yang memungkinkan Anda untuk bekerja sama dengan mode langsung dan mundur. <br><br>  Penomoran matriks menyembunyikan indeks untuk kenyamanan notasi, itulah sebabnya pohon ekspresi diferensiasi otomatis sering menjadi terlalu kompleks. <br><br>  Pertimbangkan perkalian matriks C = AB.  Kita punya <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>d</mi><mi>o</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>C</mi></mrow><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>d</mi><mi>o</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>A</mi></mrow><mi>B</mi><mo>+</mo><mi>A</mi><mtext>&amp;#xA0;</mtext><mi>d</mi><mi>o</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="26.011ex" height="2.178ex" viewBox="0 -780.1 11199 937.7" role="img" focusable="false" style="vertical-align: -0.366ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-64" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-6F" x="773" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-74" x="1259" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-43" x="1620" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMAIN-3D" x="2658" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-64" x="3965" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-6F" x="4488" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-74" x="4974" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-41" x="5335" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-42" x="6086" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMAIN-2B" x="7067" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-41" x="8068" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-64" x="9069" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-6F" x="9592" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-74" x="10078" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-42" x="10439" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>d</mi><mi>o</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>C</mi></mrow><mo>=</mo><mtext>&nbsp;</mtext><mi>d</mi><mi>o</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>A</mi></mrow><mi>B</mi><mo>+</mo><mi>A</mi><mtext>&nbsp;</mtext><mi>d</mi><mi>o</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>B</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-1"> \ dot {C} = \ dot {A} B + A \ dot {B} </script>  untuk mode langsung dan <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>A</mi><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>C</mi></mrow><msup><mi>B</mi><mi>T</mi></msup><mo>,</mo><mi>B</mi><mo>=</mo><msup><mi>A</mi><mi>T</mi></msup><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>C</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28.27ex" height="2.78ex" viewBox="0 -935.7 12171.6 1197.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-41" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMAIN-3D" x="1028" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-62" x="2334" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-61" x="2764" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-72" x="3293" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-43" x="3745" y="0"></use><g transform="translate(4505,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-42" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-54" x="1074" y="513"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMAIN-2C" x="5863" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-42" x="6308" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMAIN-3D" x="7345" y="0"></use><g transform="translate(8401,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-41" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-54" x="1061" y="513"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-62" x="10000" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-61" x="10430" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-72" x="10959" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-43" x="11411" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi><mo>=</mo><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>C</mi></mrow><msup><mi>B</mi><mi>T</mi></msup><mo>,</mo><mi>B</mi><mo>=</mo><msup><mi>A</mi><mi>T</mi></msup><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>C</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-2"> A = \ bar {C} B ^ T, B = A ^ T \ bar {C} </script>  untuk kebalikannya.  Untuk melakukan perkalian dengan benar, Anda harus benar-benar mengamati urutan dan penggunaan tanda hubung.  Dari sudut pandang rekaman, ini terlihat membingungkan bagi orang yang terlibat dalam MO, tetapi dari sudut pandang perhitungan, ini adalah beban tambahan untuk program. <br><br>  Contoh lain, kurang sepele: c = det (A).  Kita punya <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>d</mi><mi>o</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>c</mi></mrow><mo>=</mo><mi>t</mi><mi>r</mi><mo stretchy=&quot;false&quot;>(</mo><mi>i</mi><mi>n</mi><mi>v</mi><mo stretchy=&quot;false&quot;>(</mo><mi>A</mi><mo stretchy=&quot;false&quot;>)</mo><mtext>&amp;#xA0;</mtext><mi>d</mi><mi>o</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>A</mi></mrow><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="23.951ex" height="2.66ex" viewBox="0 -832 10312.1 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-64" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-6F" x="773" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-74" x="1259" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-63" x="1620" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMAIN-3D" x="2331" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-74" x="3388" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-72" x="3749" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMAIN-28" x="4201" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-69" x="4590" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-6E" x="4936" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-76" x="5536" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMAIN-28" x="6022" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-41" x="6411" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMAIN-29" x="7162" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-64" x="7801" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-6F" x="8325" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-74" x="8810" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-41" x="9172" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMAIN-29" x="9922" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>d</mi><mi>o</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>c</mi></mrow><mo>=</mo><mi>t</mi><mi>r</mi><mo stretchy="false">(</mo><mi>i</mi><mi>n</mi><mi>v</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mtext>&nbsp;</mtext><mi>d</mi><mi>o</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>A</mi></mrow><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-3"> \ dot {c} = tr (inv (A) \ dot {A}) </script>  untuk mode langsung dan <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>A</mi></mrow><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>c</mi></mrow><mi>c</mi><mi>i</mi><mi>n</mi><mi>v</mi><mo stretchy=&quot;false&quot;>(</mo><mi>A</mi><msup><mo stretchy=&quot;false&quot;>)</mo><mi>T</mi></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.835ex" height="2.901ex" viewBox="0 -935.7 9831.7 1249" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-72" x="1209" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-41" x="1660" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMAIN-3D" x="2688" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-62" x="3995" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-61" x="4424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-72" x="4954" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-63" x="5405" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-63" x="5839" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-69" x="6272" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-6E" x="6618" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-76" x="7218" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMAIN-28" x="7704" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-41" x="8093" y="0"></use><g transform="translate(8844,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMAIN-29" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhgM29J-KQZ-6nU1C_ybq8MG7a1Kgw#MJMATHI-54" x="550" y="513"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>A</mi></mrow><mo>=</mo><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>c</mi></mrow><mi>c</mi><mi>i</mi><mi>n</mi><mi>v</mi><mo stretchy="false">(</mo><mi>A</mi><msup><mo stretchy="false">)</mo><mi>T</mi></msup></math></span></span><script type="math/tex" id="MathJax-Element-4"> \ bar {A} = \ bar {c} cinv (A) ^ T </script>  untuk kebalikannya.  Dalam kasus ini, jelas tidak mungkin untuk menggunakan pohon ekspresi untuk kedua mode, mengingat bahwa mereka terdiri dari operator yang berbeda. <br><br>  Secara umum, cara TensorFlow dan perpustakaan lain (misalnya, Mathematica, Maple, Sage, SimPy, ADOL-C, TAPENADE, TensorFlow, Theano, PyTorch, HIPS autograd) menerapkan diferensiasi otomatis, yang mengarah pada fakta bahwa untuk mengarahkan dan membalikkan Pohon ekspresi yang berbeda dan tidak efektif dibangun dalam mode.  Penomoran tensor menghindari masalah ini karena komutatifitas perkalian karena notasi indeks.  Untuk detail tentang cara kerjanya, lihat makalah ilmiah. <br><br>  Para penulis menguji metode mereka dengan melakukan diferensiasi otomatis dari rezim terbalik, juga dikenal sebagai propagasi balik, dalam tiga tugas yang berbeda, dan mengukur waktu yang diperlukan untuk menghitung para Hessian. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/923/263/331/923263331347f83e3bac0fe7a9477e8b.png"><br><br>  Dalam masalah pertama, fungsi kuadrat x <sup>T</sup> Ax dioptimalkan.  Yang kedua, regresi logistik dihitung, dalam faktorisasi matriks ketiga. <br><br>  Pada CPU, metode mereka ternyata dua urutan besarnya lebih cepat daripada perpustakaan populer seperti TensorFlow, Theano, PyTorch, dan HIPS autograd. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/184/395/7dd/1843957dde52a4722da309adcdd6ea92.png"><br><br>  Pada GPU, mereka mengamati akselerasi yang lebih besar, sebanyak tiga kali lipat. <br><br>  <b>Konsekuensinya:</b> <br><br>  Komputasi derivatif untuk fungsi orde kedua atau lebih tinggi menggunakan perpustakaan pembelajaran mendalam saat ini terlalu mahal dari sudut pandang komputasi.  Ini termasuk perhitungan tensor orde keempat umum seperti Goni (misalnya, dalam MAML dan optimisasi orde dua Newton).  Untungnya, rumus kuadrat jarang ditemukan dalam pembelajaran mendalam.  Namun, mereka sering ditemukan dalam pembelajaran mesin "klasik" - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">SVM</a> , metode kuadrat terkecil, LASSO, proses Gaussian, dll. <br><br><h2>  Mitos 2: Database gambar mencerminkan foto dunia nyata </h2><br>  Banyak orang suka berpikir bahwa jaringan saraf telah belajar mengenali objek lebih baik daripada orang.  Ini tidak benar.  Mereka dapat berada di depan orang-orang di pangkalan gambar yang dipilih, misalnya, ImageNet, tetapi dalam hal pengenalan objek dari foto nyata dari kehidupan biasa, mereka pasti tidak akan dapat menyalip orang dewasa biasa.  Ini karena pemilihan gambar dalam set data saat ini tidak bertepatan dengan pemilihan semua gambar yang mungkin ditemui secara alami dalam kenyataan. <br><br>  Dalam sebuah karya yang agak lama, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Lihat Tidak</a> Sesuai dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Dataset Bias.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Torralba dan Efros.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">CVPR 2011.</a> , Penulis mengusulkan untuk mempelajari distorsi yang terkait dengan satu set gambar di dua belas database populer, mencari tahu apakah mungkin untuk melatih classifier untuk menentukan set data dari mana gambar ini diambil. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/400/31a/f1a/40031af1a6a5bef3c9314ecb2373926a.png"><br><br>  Peluang untuk secara tidak sengaja menebak set data yang benar adalah 1/12 â‰ˆ 8%, sementara para ilmuwan sendiri menghadapi tugas dengan tingkat keberhasilan&gt; 75%. <br><br>  Mereka melatih SVM pada directogram <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">gradient histogram</a> (HOG) dan menemukan bahwa classifier menyelesaikan tugas dalam 39% kasus, yang secara signifikan melebihi hit acak.  Jika kita mengulangi percobaan ini hari ini, dengan jaringan saraf paling maju, kita pasti akan melihat peningkatan akurasi pengklasifikasi. <br><br>  Jika database gambar dengan benar menampilkan gambar sebenarnya dari dunia nyata, kita tidak harus dapat menentukan dari mana dataset berasal gambar tertentu. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/879/7f7/4ad/8797f74ad14a0a4e28959ff0c67faca8.png"><br><br>  Namun, ada sifat dalam data yang membuat setiap set gambar berbeda dari yang lain.  ImageNet memiliki banyak mobil balap yang tidak mungkin menggambarkan mobil rata-rata "teoritis" secara keseluruhan. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/614/416/401/6144164018d5608bc5c2dc55e6e981f6.png"><br><br>  Para penulis juga menentukan nilai setiap set data dengan mengukur seberapa baik seorang classifier melatih pada satu set bekerja dengan gambar dari set lain.  Menurut metrik ini, database LabelMe dan ImageNet ternyata menjadi yang paling tidak bias, setelah menerima peringkat 0,58 menggunakan metode "keranjang mata uang".  Semua nilai ternyata kurang dari satu, yang berarti bahwa pelatihan tentang kumpulan data yang berbeda selalu mengarah pada kinerja yang buruk.  Dalam dunia ideal tanpa set bias, beberapa angka seharusnya melebihi satu. <br><br>  Para penulis dengan pesimis menyimpulkan: <br><blockquote>  Jadi apa nilai dataset yang ada untuk algoritma pelatihan yang dirancang untuk dunia nyata?  Jawaban yang dihasilkan dapat digambarkan sebagai "lebih baik daripada tidak sama sekali tetapi tidak banyak." </blockquote><br><br><h2>  Mitos 3: Peneliti MO tidak menggunakan alat tes untuk pengujian </h2><br>  Dalam buku teks tentang pembelajaran mesin, kami diajarkan untuk membagi set data ke dalam pelatihan, evaluasi dan verifikasi.  Efektivitas model, dilatih pada set pelatihan, dan dievaluasi pada evaluasi membantu orang yang terlibat dalam MO untuk menyempurnakan model untuk memaksimalkan efisiensi dalam penggunaannya yang sebenarnya.  Set tes tidak perlu disentuh sampai orang tersebut selesai menyesuaikan diri untuk memberikan penilaian yang tidak bias tentang efektivitas nyata model di dunia nyata.  Jika seseorang berselingkuh menggunakan set tes pada tahap pelatihan atau penilaian, model berisiko menjadi terlalu beradaptasi untuk set data tertentu. <br><br>  Dalam dunia yang sangat kompetitif dalam penelitian MO, algoritma dan model baru sering dinilai dari keefektifan pekerjaan mereka dengan data verifikasi.  Oleh karena itu, tidak masuk akal bagi peneliti untuk menulis atau menerbitkan makalah yang menjelaskan metode yang bekerja buruk dengan set data uji.  Dan ini, pada dasarnya, berarti bahwa komunitas Wilayah Moskow secara keseluruhan menggunakan set tes untuk evaluasi. <br><br>  Apa konsekuensi dari penipuan ini? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2d4/f64/749/2d4f647491071cd0b77eb199ef563275.png"><br><br>  Penulis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Do CIFAR-10 Classifiers Generalised to CIFAR-10?</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Recht et al.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ArXiv 2018</a> menyelidiki masalah ini dengan membuat test suite baru untuk CIFAR-10.  Untuk melakukan ini, mereka membuat pilihan gambar dari Tiny Images. <br><br>  Mereka memilih CIFAR-10 karena itu adalah salah satu set data yang paling umum digunakan di MO, set kedua paling populer di NeurIPS 2017 (setelah MNIST).  Proses pembuatan dataset untuk CIFAR-10 juga dijelaskan dengan baik dan transparan, dalam basis data Tiny Images yang besar terdapat banyak label terperinci, sehingga Anda dapat mereproduksi set uji baru, meminimalkan pergeseran distribusi. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/71a/cd9/091/71acd909148795f73b49819b39946a5a.png"><br><br>  Mereka menemukan bahwa sejumlah besar model yang berbeda dari jaringan saraf pada set tes baru menunjukkan penurunan akurasi yang signifikan (4% - 15%).  Namun, peringkat kinerja relatif masing-masing model tetap cukup stabil. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b6b/5aa/cfa/b6b5aacfab0c2628ea2ffe28babae533.png"><br><br>  Secara umum, model yang berkinerja lebih baik menunjukkan penurunan akurasi yang lebih rendah dibandingkan dengan yang lebih buruk.  Ini bagus karena ini berarti bahwa hilangnya generalisasi model akibat kecurangan, setidaknya dalam kasus CIFAR-10, berkurang ketika masyarakat menemukan metode dan model MO yang ditingkatkan. <br><br><h2>  Mitos 4: Pelatihan jaringan saraf menggunakan semua input </h2><br>  Secara umum diterima bahwa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">data adalah minyak baru</a> , dan bahwa semakin banyak data yang kita miliki, semakin baik kita dapat melatih model pembelajaran mendalam yang sekarang tidak efisien dan terlalu banyak sampel. <br><br>  Dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Sebuah Studi Empiris Contoh Lupa Selama Belajar Jaringan Neural Dalam.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Toneva et al.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ICLR 2019</a> penulis menunjukkan redundansi yang signifikan dalam beberapa set gambar kecil yang umum.  Anehnya, 30% data dari CIFAR-10 dapat dengan mudah dihapus tanpa mengubah keakuratan cek dengan jumlah yang signifikan. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/418/39b/03a/41839b03afd94771e940b60e2d7f905d.png"><br>  <i>Sejarah dilupakan dari (kiri ke kanan) MNIST, permutasiMNIST dan CIFAR-10.</i> <br><br>  Lupa terjadi ketika jaringan saraf secara salah mengklasifikasikan suatu gambar pada waktu t + 1, sementara pada waktu itu mampu mengklasifikasikan dengan benar suatu gambar.  Aliran waktu diukur dengan pembaruan SGD.  Untuk melacak lupa, penulis meluncurkan jaringan saraf mereka pada set data kecil setelah setiap pembaruan SGD, dan tidak pada semua contoh yang tersedia dalam database.  Contoh yang tidak bisa dilupakan disebut contoh yang tak terlupakan. <br><br>  Mereka menemukan bahwa 91,7% MNIST, 75,3% diijinkanMNIST, 31,3% CIFAR-10, dan 7,62% CIFAR-100 adalah contoh yang tak terlupakan.  Ini dapat dimengerti secara intuitif, karena meningkatkan keragaman dan kompleksitas dari kumpulan data harus membuat jaringan saraf melupakan lebih banyak contoh. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fdb/16b/ff9/fdb16bff98521d9d764588a679e51a59.png"><br><br>  Contoh-contoh yang terlupakan sepertinya memperlihatkan fitur yang lebih langka dan aneh dibandingkan dengan yang tak terlupakan.  Para penulis membandingkannya dengan vektor dukungan dalam SVM, karena mereka tampaknya menggambarkan garis besar batas keputusan. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a75/c74/969/a75c74969991b75f621d340952a5cde3.png"><br><br>  Contoh-contoh yang tak terlupakan, pada gilirannya, mengkodekan sebagian besar informasi yang berlebihan.  Jika kita mengurutkan contoh berdasarkan tingkat tidak termaafkan, kita dapat mengompres kumpulan data dengan menghapus yang paling tak terlupakan. <br><br>  30% dari data CIFAR-10 dapat dihapus tanpa memengaruhi keakuratan pemeriksaan, dan penghapusan 35% data menyebabkan sedikit penurunan keakuratan pemeriksaan sebesar 0,2%.  Jika Anda memilih 30% dari data secara acak, maka menghapusnya akan menyebabkan hilangnya signifikan dalam keakuratan verifikasi 1%. <br><br>  Demikian pula, 8% data dapat dihapus dari CIFAR-100 tanpa penurunan akurasi validasi. <br><br>  Hasil ini menunjukkan bahwa ada redundansi yang signifikan dalam data untuk pelatihan jaringan saraf, mirip dengan pelatihan SVM, di mana vektor yang tidak mendukung dapat dihilangkan tanpa mempengaruhi keputusan model. <br><br>  <b>Konsekuensinya:</b> <br><br>  Jika kita dapat menentukan data mana yang tidak terlupakan sebelum memulai pelatihan, maka kita dapat menghemat ruang dengan menghapusnya dan waktu tanpa menggunakannya saat melatih jaringan saraf. <br><br><h2>  Mitos 5: Normalisasi batch diperlukan untuk melatih jaringan residual yang sangat dalam. </h2><br>  Untuk waktu yang lama diyakini bahwa "pelatihan jaringan saraf yang dalam untuk optimasi langsung hanya untuk tujuan yang terkontrol (misalnya, probabilitas logaritmik dari klasifikasi yang benar) menggunakan gradient descent, dimulai dengan parameter acak, tidak bekerja dengan baik." <br><br>  Tumpukan metode cerdik inisialisasi acak, fungsi aktivasi, teknik optimasi, dan inovasi lainnya, seperti koneksi residual, yang telah muncul sejak itu memfasilitasi pelatihan jaringan saraf yang mendalam menggunakan metode gradient descent. <br><br>  Tapi terobosan nyata terjadi setelah pengenalan normalisasi batch (dan teknik normalisasi sekuensial lainnya), membatasi ukuran aktivasi untuk setiap lapisan jaringan untuk menghilangkan masalah gradien menghilang dan meledak. <br><br>  Dalam karya terbarunya, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Inisialisasi Fixup: Sisa Pembelajaran Tanpa Normalisasi.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Zhang et al.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ICLR 2019</a> telah menunjukkan bahwa mungkin untuk melatih jaringan dengan 10.000 lapisan menggunakan SGD murni tanpa menerapkan normalisasi apa pun. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d69/a29/cbb/d69a29cbb7bfce9750c9aa3ee6d7d659.png"><br><br>  Para penulis membandingkan pelatihan jaringan saraf residual untuk kedalaman berbeda pada CIFAR-10 dan menemukan bahwa sementara metode inisialisasi standar tidak bekerja untuk 100 lapisan, metode fixup dan normalisasi batch berhasil dengan 10.000 lapisan. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bc9/23f/26a/bc923f26a4c39fb67663383716bc10d2.png" alt="gambar"><br><br>  Mereka melakukan analisis teoritis dan menunjukkan bahwa "normalisasi gradien dari lapisan tertentu dibatasi oleh jumlah yang jauh meningkat dari jaringan yang dalam", yang merupakan masalah gradien eksplosif.  Untuk mencegah hal ini, Foxup digunakan, ide utamanya adalah untuk menskalakan bobot dalam lapisan m untuk masing-masing cabang residu L dengan jumlah kali tergantung pada m dan L. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/07f/a8f/39a/07fa8f39ad814861fd0cba6c936a2e18.png"><br><br>  Fixup membantu melatih jaringan residu yang dalam dengan 110 lapisan pada CIFAR-10 dengan kecepatan belajar tinggi yang sebanding dengan perilaku jaringan arsitektur serupa yang dilatih menggunakan normalisasi batch. <br><br>  Para penulis selanjutnya menunjukkan hasil tes yang sama menggunakan Fixup di jaringan tanpa normalisasi apa pun, bekerja dengan database ImageNet dan dengan terjemahan dari Bahasa Inggris ke Bahasa Jerman. <br><br><h2>  Mitos 6: Jaringan dengan perhatian lebih baik daripada yang konvolusional. </h2><br>  Gagasan bahwa mekanisme "perhatian" lebih unggul daripada jaringan saraf convolutional adalah mendapatkan popularitas di komunitas peneliti MO.  Dalam karya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://crazyoscarchang.github.io/2019/02/16/seven-myths-in-machine-learning-research/(">Vaswani dan rekannya</a> , tercatat bahwa "biaya komputasi konvolusi yang dapat dilepas sama dengan kombinasi dari lapisan perhatian-diri dan lapisan umpan-maju yang bijak." <br><br>  Bahkan jaringan kompetitif-generatif canggih menunjukkan keuntungan perhatian-diri atas konvolusi standar ketika memodelkan ketergantungan jangka panjang. <br><br>  Kontributor <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kurang Perhatian dengan Konvolusi Ringan dan Dinamis.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Wu et al.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ICLR 2019</a> meragukan efisiensi parametrik dan efektivitas perhatian-diri ketika memodelkan ketergantungan jangka panjang, dan menawarkan opsi baru untuk konvolusi, sebagian diinspirasi oleh perhatian-diri, lebih efektif dalam hal parameter. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b40/f9a/a15/b40f9aa151eb4bcc3ebf224483ff8028.png"><br><br>  Konvolusi "ringan" dapat dipisahkan secara dalam, dimensi softmax dinormalisasi dalam waktu, dipisahkan oleh bobot dalam dimensi saluran, dan menggunakan kembali bobot yang sama pada setiap langkah waktu (sebagai jaringan saraf berulang).  Konvolusi dinamis adalah konvolusi ringan yang menggunakan bobot berbeda pada setiap langkah waktu. <br><br>  Trik semacam itu membuat konvolusi yang ringan dan dinamis beberapa urutan besarnya lebih efektif daripada konvolusi tak terpisahkan standar. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/87d/d51/da0/87dd51da07637c42c4e4c2811b08b241.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/c6a/469/ae5/c6a469ae5432cf31761e7663449497fd.png"><br><br>  Para penulis menunjukkan bahwa konvolusi baru ini sesuai atau melebihi jaringan yang mementingkan diri sendiri dalam terjemahan mesin, pemodelan bahasa, masalah penjumlahan abstrak, menggunakan parameter yang sama atau kurang. <br><br><h2>  Mitos 7: Kartu Signifikansi - Cara yang Andal untuk Menafsirkan Jaringan Saraf </h2><br>  Meskipun ada pendapat bahwa jaringan saraf adalah kotak hitam, ada banyak upaya untuk menafsirkannya.  Yang paling populer di antaranya adalah peta signifikansi, atau metode serupa lainnya yang menetapkan penilaian penting untuk fitur atau contoh pelatihan. <br><br>  Sangat menggoda untuk dapat menyimpulkan bahwa gambar yang diberikan telah diklasifikasikan dengan cara tertentu karena bagian-bagian tertentu dari gambar yang signifikan untuk jaringan saraf.  Untuk menghitung peta signifikansi, ada beberapa metode yang sering menggunakan aktivasi jaringan saraf pada gambar yang diberikan dan gradien yang melewati jaringan. <br><br>  Dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Interpretasi Neural Networks adalah Rapuh.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Ghorbani et al.</a>  Penulis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">AAAI 2019</a> menunjukkan bahwa mereka dapat memperkenalkan perubahan yang sulit dipahami dalam gambar, yang, bagaimanapun, akan mengubah peta signifikansinya. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/077/b89/e92/077b89e923e2936769b2f99662171a94.png"><br><br>  Jaringan saraf menentukan kupu-kupu raja bukan dengan pola pada sayapnya, tetapi karena kehadiran daun hijau yang tidak penting terhadap latar belakang foto. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1d2/314/9fa/1d23149fa91caab32dc2ea16a8593379.png"><br><br>  Gambar multidimensi seringkali lebih dekat dengan batas keputusan yang dibuat oleh jaringan saraf yang dalam, karenanya sensitivitasnya terhadap serangan permusuhan.  Dan jika serangan kompetitif memindahkan gambar di luar batas solusi, serangan interpretatif kompetitif menggeser mereka di sepanjang batas solusi tanpa meninggalkan wilayah solusi yang sama. <br><br>  Metode dasar yang dikembangkan oleh penulis adalah modifikasi dari metode Goodfello untuk penandaan gradien cepat, yang merupakan salah satu metode serangan kompetitif pertama yang berhasil.  Dapat diasumsikan bahwa serangan lain, yang lebih baru dan lebih kompleks juga dapat digunakan untuk serangan pada interpretasi jaringan saraf. <br><br>  <b>Konsekuensinya:</b> <br><br>  Karena semakin berkembangnya pembelajaran mendalam di bidang aplikasi kritis seperti pencitraan medis, penting untuk secara cermat mendekati interpretasi keputusan yang dibuat oleh jaringan saraf.  Sebagai contoh, meskipun akan lebih bagus jika jaringan saraf convolutional dapat mengenali tempat pada gambar MRI sebagai tumor ganas, hasil ini tidak boleh dipercaya jika mereka didasarkan pada metode interpretasi yang tidak dapat diandalkan. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id444172/">https://habr.com/ru/post/id444172/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id444162/index.html">Ulasan Telepon IP Snom D120</a></li>
<li><a href="../id444164/index.html">Ikhtisar Sistem Peringatan Snom PA1</a></li>
<li><a href="../id444166/index.html">Pavel Finkelstein tentang Kotlin dalam produksi di jug.msk.ru</a></li>
<li><a href="../id444168/index.html">Cara mentransfer Windows 10 berlisensi ke komputer lain</a></li>
<li><a href="../id444170/index.html">Publikasikan aplikasi iOS di App Store dengan GitLab dan fastlane</a></li>
<li><a href="../id444174/index.html">GeekBrains mengundang pemula ke game edukasi</a></li>
<li><a href="../id444176/index.html">Cipher dasar dalam bahasa sederhana</a></li>
<li><a href="../id444178/index.html">9 tips untuk membuat game indie dari satu pengembang</a></li>
<li><a href="../id444182/index.html">Pergi kondisi dan keanehan mereka</a></li>
<li><a href="../id444184/index.html">Tentang prospek pusat data pra-rakitan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
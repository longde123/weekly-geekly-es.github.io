<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ôíÔ∏è üë®üèª‚Äç‚öïÔ∏è üî® Secuencia a secuencia Modelos de la Parte 1 üé∂ üßëüèø‚Äçü§ù‚Äçüßëüèæ üôé</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Buen dia a todos! 

 Y nuevamente hemos abierto una nueva transmisi√≥n al curso revisado de Data Scientist : otro excelente maestro , un programa liger...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Secuencia a secuencia Modelos de la Parte 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/430780/">  Buen dia a todos! <br><br>  Y nuevamente hemos abierto una nueva transmisi√≥n al curso revisado de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Data Scientist</a> : otro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">excelente maestro</a> , un programa ligeramente refinado basado en actualizaciones.  Bueno, como siempre, interesantes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">lecciones abiertas</a> y colecciones de materiales interesantes.  Hoy comenzaremos el an√°lisis de los modelos seq2seq de Tensor Flow. <br><br>  Vamos <br><br>  Como ya se discuti√≥ en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tutorial de RNN</a> (le recomendamos que se familiarice con √©l antes de leer este art√≠culo), se puede ense√±ar a las redes neuronales recurrentes a modelar el lenguaje.  Y surge una pregunta interesante: ¬øes posible capacitar a la red en ciertos datos para generar una respuesta significativa?  Por ejemplo, ¬øpodemos ense√±arle a una red neuronal a traducir del ingl√©s al franc√©s?  Resulta que podemos. <br><br>  Esta gu√≠a le mostrar√° c√≥mo crear y entrenar un sistema de extremo a extremo.  Copie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el repositorio principal de Tensor Flow</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el repositorio de modelos TensorFlow de GitHub</a> .  Luego, puede comenzar iniciando el programa de traducci√≥n: <br><br><pre><code class="python hljs">cd models/tutorials/rnn/translate python translate.py --data_dir [your_data_directory]</code> </pre> <br><img src="https://habrastorage.org/webt/ra/j0/rr/raj0rraitsp6itojzydkhrk2yoi.png"><a name="habracut"></a><br><br>  Ella descargar√° los datos para su traducci√≥n del ingl√©s al franc√©s desde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el sitio web de WMT'15</a> , los preparar√° para la capacitaci√≥n y el entrenamiento.  Esto requerir√° aproximadamente 20 GB en el disco duro y bastante tiempo para descargar y preparar, por lo que puede comenzar el proceso ahora y continuar leyendo este tutorial. <br><br>  El manual acceder√° a los siguientes archivos: <br><br><table><tbody><tr><th>  Archivo </th><th>  Que hay en el </th></tr><tr><td>  tensorflow / tensorflow / python / ops / seq2seq.py </td><td>  Biblioteca para crear modelos de secuencia a secuencia </td></tr><tr><td>  modelos / tutoriales / rnn / translate / seq2seq_model.py </td><td>  Modelos de traducci√≥n neural secuencia a secuencia </td></tr><tr><td>  modelos / tutoriales / rnn / translate / data_utils.py </td><td>  Funciones de ayuda para preparar datos de traducci√≥n. </td></tr><tr><td>  modelos / tutoriales / rnn / translate / translate.py </td><td>  El binario que entrena y ejecuta el modelo de traducci√≥n. </td></tr></tbody></table><br>  <b>Conceptos b√°sicos de secuencia a secuencia</b> <br><br>  El modelo b√°sico de secuencia a secuencia, presentado por <a href="">Cho et al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pdf</a> ), consta de dos redes neuronales recurrentes (RNN): un codificador (codificador) que procesa los datos de entrada y un decodificador (decodificador) que genera los datos. salida.  La arquitectura b√°sica se muestra a continuaci√≥n: <br><br><img src="https://habrastorage.org/webt/e-/df/cu/e-dfcuvlsbykvyxvzac9rc0nrow.png"><br><br>  Cada rect√°ngulo en la imagen de arriba representa una celda en el RNN, generalmente una celda GRU - un bloque de recurrencia controlado, o una celda LSTM - memoria a corto plazo a largo plazo (lea el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tutorial RNN</a> para obtener m√°s informaci√≥n sobre ellos).  Los codificadores y decodificadores pueden tener pesos comunes o, m√°s a menudo, usar diferentes conjuntos de par√°metros.  Las c√©lulas multicapa se han utilizado con √©xito en modelos de secuencia a secuencia, por ejemplo, para traducir <a href="">Sutskever et al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pdf</a> ). <br><br>  En el modelo b√°sico descrito anteriormente, cada entrada debe codificarse en un vector de estado de un tama√±o fijo, ya que esto es lo √∫nico que se transmite al decodificador.  Para dar al decodificador un acceso m√°s directo a los datos de entrada, se introdujo un mecanismo de atenci√≥n en <a href="">Bahdanau et al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pdf</a> ).  No entraremos en detalles sobre el mecanismo de atenci√≥n (para esto puede familiarizarse con el trabajo aqu√≠);  basta con decir que permite que el decodificador busque en los datos de entrada en cada paso de decodificaci√≥n.  Una red de secuencia a secuencia multicapa con celdas LSTM y el mecanismo de atenci√≥n en el decodificador es el siguiente: <br><br><img src="https://habrastorage.org/webt/c4/ro/0z/c4ro0zvzu8m-y4qjlnfbhv9x4qa.png"><br><br>  <b>Biblioteca TensorFlow seq2seq</b> <br><br>  Como puede ver arriba, hay diferentes modelos de secuencia a secuencia.  Todos ellos pueden usar diferentes celdas RNN, pero todos aceptan datos de entrada del codificador y datos de entrada del decodificador.  Esta es la base de la interfaz de la biblioteca TensorFlow seq2seq (tensorflow / tensorflow / python / ops / seq2seq.py).  Este modelo b√°sico, RNN, c√≥dec, secuencia a secuencia funciona de la siguiente manera. <br><br><pre> <code class="python hljs">outputs, states = basic_rnn_seq2seq(encoder_inputs, decoder_inputs, cell)</code> </pre> <br>  En la llamada indicada anteriormente, <code>encoder_inputs</code> es una lista de tensores que representan los datos de entrada del codificador, correspondientes a las letras A, B, C de la imagen de arriba.  Del mismo modo, las <code>decoder_inputs</code> decodificador son tensores que representan datos de entrada del decodificador.  GO, W, X, Y, Z desde la primera imagen. <br><br>  El argumento de <code>cell</code> es una instancia de la clase <code>tf.contrib.rnn.RNNCell</code> que determina qu√© celda se utilizar√° en el modelo.  Puede usar celdas existentes, por ejemplo, <code>GRUCell</code> o <code>LSTMCell</code> , o puede escribir las suyas.  Adem√°s, <code>tf.contrib.rnn</code> proporciona shells para crear celdas multicapa, agregando excepciones a la entrada y salida de celdas u otras transformaciones.  Consulte el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tutorial de RNN</a> para ver ejemplos. <br><br>  La llamada <code>basic_rnn_seq2seq</code> devuelve dos argumentos: <code>outputs</code> y <code>states</code> .  Ambos representan una lista de tensores de la misma longitud que <code>decoder_inputs</code> .  <code>outputs</code> corresponde a los datos de salida del decodificador en cada paso de tiempo, en la primera imagen es W, X, Y, Z, EOS.  Los <code>states</code> devueltos representan el estado interno del decodificador en cada paso de tiempo. <br><br>  En muchas aplicaciones que usan el modelo de secuencia a secuencia, la salida del decodificador en el tiempo t se transmite de regreso a la entrada al decodificador en el tiempo t + 1.  Durante las pruebas, durante la decodificaci√≥n de secuencia, as√≠ es como se construye una nueva.  Por otro lado, durante el entrenamiento es habitual transmitir al decodificador los datos de entrada correctos en cada paso de tiempo, incluso si el decodificador se hab√≠a equivocado previamente.  Las funciones en <code>seq2seq.py</code> admiten ambos modos con el argumento <code>feed_previous</code> .  Por ejemplo, considere el siguiente uso de un modelo RNN anidado. <br><br><pre> <code class="python hljs">outputs, states = embedding_rnn_seq2seq( encoder_inputs, decoder_inputs, cell, num_encoder_symbols, num_decoder_symbols, embedding_size, output_projection=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, feed_previous=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  En el modelo <code>embedding_rnn_seq2seq</code> , todos los datos de entrada ( <code>encoder_inputs</code> y <code>decoder_inputs</code> ) son tensores enteros que reflejan valores discretos.  Se anidar√°n en una representaci√≥n ajustada (para obtener detalles sobre el archivo adjunto, consulte la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Gu√≠a de vistas de vectores</a> ), pero para crear estos archivos adjuntos, debe especificar el n√∫mero m√°ximo de caracteres discretos: <code>num_encoder_symbols</code> en el lado del codificador y <code>num_decoder_symbols</code> en el lado del decodificador. <br><br>  En la llamada anterior, configuramos <code>feed_previous</code> en False.  Esto significa que el decodificador utilizar√° los tensores <code>decoder_inputs</code> en la forma en que se proporcionan.  Si establecemos <code>feed_previous</code> en True, el decodificador solo usar√° el primer elemento <code>decoder_inputs</code> .  Todos los otros tensores de la lista ser√°n ignorados, y en su lugar se usar√° el valor anterior de la salida del decodificador.  Esto se usa para decodificar traducciones en nuestro modelo de traducci√≥n, pero tambi√©n se puede usar durante el entrenamiento, para mejorar la estabilidad del modelo ante sus errores.  Aproximadamente como en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Bengio et al., 2015</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pdf</a> ). <br><br>  Otro argumento importante utilizado anteriormente es <code>output_projection</code> .  Sin aclaraci√≥n, las conclusiones del modelo incrustado ser√°n tensores de la forma del n√∫mero de muestras de entrenamiento por <code>num_decoder_symbols</code> , ya que representan los logiths de cada s√≠mbolo generado.  Al entrenar modelos con diccionarios de salida grandes, por ejemplo con <code>num_decoder_symbols</code> grandes, almacenar estos tensores grandes no resulta pr√°ctico.  En cambio, es mejor devolver tensores m√°s peque√±os, que posteriormente se proyectar√°n en el tensor grande utilizando <code>output_projection</code> .  Esto nos permite utilizar nuestros modelos seq2seq con p√©rdidas softmax muestreadas, seg√∫n lo descrito por <a href="">Jean et.</a>  <a href="">al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pdf</a> ). <br><br>  Adem√°s de <code>basic_rnn_seq2seq</code> y <code>embedding_rnn_seq2seq</code> , hay varios modelos m√°s de secuencia a secuencia en <code>seq2seq.py</code> .  Presta atenci√≥n a ellos.  Todos tienen una interfaz similar, por lo que no profundizaremos en sus detalles.  Para nuestro modelo de traducci√≥n a continuaci√≥n, use <code>embedding_attention_seq2seq</code> . <br><br>  Continuar√° </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es430780/">https://habr.com/ru/post/es430780/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es430768/index.html">Entrevista con el creador de ADOM Thomas Biscap</a></li>
<li><a href="../es430770/index.html">Copia de seguridad para Linux, o c√≥mo crear una instant√°nea</a></li>
<li><a href="../es430774/index.html">¬øEst√°s listo para la IA en las vallas publicitarias?</a></li>
<li><a href="../es430776/index.html">Hacer una IP es la √∫nica forma</a></li>
<li><a href="../es430778/index.html">Proceso de dise√±o de sistema el√©ctrico de extremo a extremo de 3DEXPERIENCE</a></li>
<li><a href="../es430782/index.html">¬øCu√°ntos programadores necesitas para soportar c√≥digo escrito previamente?</a></li>
<li><a href="../es430784/index.html">De junior a director: cuentos de un guardia</a></li>
<li><a href="../es430788/index.html">Mi historial de entrevistas en IB IT (desarrollador Java, banco de inversi√≥n) en Londres con ejemplos de tareas t√≠picas</a></li>
<li><a href="../es430790/index.html">Ledger Nano S: la llave de la sala donde pueden encontrarse 710 tokens y criptomonedas</a></li>
<li><a href="../es430792/index.html">Crear un esquema en LWRP en Unity</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
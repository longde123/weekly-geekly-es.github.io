<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üÜó ü§™ üë™ Gerando imagens de texto usando o AttnGAN üìç üê∂ üêΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√° Habr! Apresento a voc√™ a tradu√ß√£o do artigo " AttnGAN: gera√ß√£o de texto refinado para imagem com redes advers√≥rias generativas atencionais " de Ta...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Gerando imagens de texto usando o AttnGAN</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/424957/">  Ol√° Habr!  Apresento a voc√™ a tradu√ß√£o do artigo " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AttnGAN: gera√ß√£o de texto refinado para imagem com redes</a> advers√≥rias <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">generativas atencionais</a> " de Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, Xiaodong He. <br><br>  Nesta publica√ß√£o, quero falar sobre meus experimentos com a arquitetura AttnGAN para gerar imagens a partir de uma descri√ß√£o de texto.  Essa arquitetura j√° foi mencionada em Habr√© ap√≥s o lan√ßamento do artigo original no in√≠cio de 2018, e eu estava interessado na pergunta - qu√£o dif√≠cil ser√° treinar voc√™ mesmo esse modelo? <br><br><h3>  Descri√ß√£o da arquitetura </h3><br>  Para aqueles que n√£o est√£o familiarizados com o AttnGAN e o cl√°ssico GAN, descreverei brevemente a ess√™ncia.  O GAN cl√°ssico consiste em pelo menos duas redes neurais - um gerador e um discriminador.  A tarefa do gerador √© gerar alguns dados (imagens, texto, √°udio, v√≠deo, etc.) que s√£o "semelhantes" aos dados reais do conjunto de dados.  A tarefa do discriminador √© avaliar os dados gerados, uma tentativa de compar√°-los com os reais e rejeit√°-los.  O resultado rejeitado do trabalho do gerador o estimula a gerar o melhor resultado para "enganar" o discriminador, que, por sua vez, est√° aprendendo a reconhecer melhor as falsifica√ß√µes. <br><br>  Existem muitas modifica√ß√µes no GAN, e os autores do AttnGAN abordaram a quest√£o da arquitetura de maneira bastante criativa.  O modelo consiste em 9 redes neurais que s√£o afinadas para intera√ß√£o.  Parece algo como isto: <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/tk/eq/nq/tkeqnqzoqcw9dt9giju0rdsh4zg.png"><br><br>  Os codificadores de texto e imagem (codificador de texto / imagem) convertem a descri√ß√£o original do texto e as imagens reais em algum tipo de representa√ß√£o interna.  Caracteristicamente, nesse caso, o texto √© considerado como uma sequ√™ncia de palavras individuais, cuja apresenta√ß√£o √© processada juntamente com a representa√ß√£o da imagem, o que permite comparar palavras individuais com partes individuais da imagem.  Dessa maneira, o mecanismo de aten√ß√£o chamado pelos autores do artigo DAMSM √© implementado. <br><br>  Fca - cria uma representa√ß√£o concisa da cena geral na imagem, com base na descri√ß√£o completa do texto.  O valor de C na sa√≠da √© concatenado com um vetor da distribui√ß√£o normal de Z, que determina a variabilidade da cena.  Esta informa√ß√£o √© a base para a opera√ß√£o do gerador. <br><br>  O gerador √© a maior rede composta por tr√™s n√≠veis.  Cada n√≠vel produz imagens com resolu√ß√£o cada vez maior, de 64 * 64 a 256 * 256 pixels, e o resultado do trabalho em cada n√≠vel √© ajustado usando as redes de aten√ß√£o da Fattn, que transportam informa√ß√µes sobre a localiza√ß√£o correta de objetos individuais na cena.  Al√©m disso, os resultados em cada n√≠vel s√£o verificados por tr√™s discriminadores que trabalham separadamente, que avaliam o realismo da imagem e sua consist√™ncia com a ideia geral da cena. <br><br><h3>  Treinamento </h3><br>  Para testar a arquitetura, usei o conjunto de dados CUB padr√£o com fotos e descri√ß√µes textuais de p√°ssaros. <br><br>  Todo o modelo √© treinado em duas etapas.  O primeiro est√°gio √© o pr√©-treinamento das redes DAMSM, que consiste em um codificador de texto e imagem.  Durante esse est√°gio, conforme descrito acima, um "mapa de aten√ß√£o" √© criado com a seguinte apar√™ncia: <br><br><img src="https://habrastorage.org/webt/of/w7/6f/ofw76fxdvl6bbuohon_okmsgfro.png"><br><br>  Como pode ser visto na figura, o DAMSM consegue capturar com muita precis√£o a rela√ß√£o entre palavras individuais da descri√ß√£o do texto e dos elementos da imagem. √â especialmente f√°cil para o modelo reconhecer cores.  Devo dizer que o sistema n√£o possui nenhuma informa√ß√£o adicional sobre o que √© "vermelho", "amarelo" ou "asas", "bico".  Existe apenas um conjunto de textos e imagens. <br><br>  O treinamento DAMSM ocorre sem problemas, o tempo de treinamento neste conjunto de dados √© de 150 a 200 eras, o que corresponde a v√°rias horas em uma GPU de alta pot√™ncia. <br><br>  O segundo e principal est√°gio √© treinar o gerador usando o modelo DAMSM. <br>  O gerador em cada n√≠vel gera uma imagem de maior resolu√ß√£o - √© assim: <br><br><img src="https://habrastorage.org/webt/xz/go/cw/xzgocw0eswwfeku7kxogp2jhuqy.png"><br><br>  O treinamento do gerador leva muito mais tempo e nem sempre √© t√£o est√°vel; o tempo de treinamento recomendado neste conjunto de dados √© de 300 a 600 √©pocas, o que corresponde a cerca de 4-8 dias em uma GPU de alta pot√™ncia. <br><br>  O principal problema no treinamento do gerador, na minha opini√£o, √© a falta de m√©tricas suficientemente boas que nos permitam avaliar a qualidade do treinamento de uma maneira mais formal.  Estudei v√°rias implementa√ß√µes da pontua√ß√£o Inception, que, em teoria, est√° posicionada como uma m√©trica universal para essas tarefas - mas elas n√£o me pareceram convincentes o suficiente.  Se voc√™ decidir treinar um gerador desse tipo, precisar√° monitorar constantemente o progresso do treinamento visualmente, de acordo com resultados intermedi√°rios.  No entanto, essa regra √© verdadeira para essas tarefas, o controle visual √© sempre necess√°rio. <br><br><h3>  Resultados </h3><br>  Agora a parte divertida.  Usando o modelo treinado, tentaremos gerar imagens, come√ßaremos com frases simples: <br><br><img src="https://habrastorage.org/webt/7g/ri/x-/7grix-945iwxoysnibzph4yjd0w.png"><br><br>  Vamos tentar descri√ß√µes mais complexas: <br><br><img src="https://habrastorage.org/webt/8n/kp/eu/8nkpeuqwf4wiqk_c6fn8bynmxiq.png"><br><br>  Todas as descri√ß√µes de texto s√£o inventadas, intencionalmente n√£o usei frases do conjunto de dados para testes.  Obviamente, nem todas essas imagens foram obtidas na primeira tentativa.  O modelo est√° errado, os pr√≥prios autores est√£o falando sobre isso.  √Ä medida que o texto de descri√ß√£o e os elementos a serem exibidos aumentam, fica cada vez mais dif√≠cil manter o realismo de toda a cena.  No entanto, se voc√™ deseja usar algo semelhante na produ√ß√£o, por exemplo, gerar imagens de determinados objetos para um designer, voc√™ pode treinar e personalizar o sistema de acordo com seus requisitos, o que pode ser bastante rigoroso. <br><br>  Para cada descri√ß√£o de texto, voc√™ pode gerar muitas op√ß√µes de imagem (incluindo as irreais), para que sempre haja muito por onde escolher. <br><br><h3>  Detalhes t√©cnicos </h3><br>  Neste trabalho, usei uma GPU de baixa pot√™ncia para prototipagem e um servidor do Google Cloud com o Tesla K80 instalado durante a fase de treinamento. <br><br>  O c√≥digo fonte foi retirado do reposit√≥rio dos autores do artigo e passou por uma refatora√ß√£o s√©ria.  O sistema foi testado no Python 3.6 com o Pytorch 0.4.1 <br><br>  Obrigado pela aten√ß√£o! <br><br>  <i>Artigo original: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AttnGAN: gera√ß√£o de texto refinado para gera√ß√£o de imagens com redes</a> adversas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">generativas de aten√ß√£o</a> , 2018 - Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, Xiaodong He.</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt424957/">https://habr.com/ru/post/pt424957/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt424945/index.html">Smartphone est√° dirigindo um carro de brinquedo.</a></li>
<li><a href="../pt424947/index.html">Reconhecimento de gestos com APDS-9960</a></li>
<li><a href="../pt424949/index.html">PHP Digest No. 140 (17 a 30 de setembro de 2018)</a></li>
<li><a href="../pt424951/index.html">Viva! N√£o era paran√≥ia</a></li>
<li><a href="../pt424955/index.html">O resumo de materiais frescos do mundo do front-end da √∫ltima semana n ¬∞ 332 (24 a 30 de setembro de 2018)</a></li>
<li><a href="../pt424961/index.html">MTA-STS para Postfix</a></li>
<li><a href="../pt424963/index.html">Zuckerberg Funding: Construindo Ferramentas para a Ci√™ncia Juntos</a></li>
<li><a href="../pt424965/index.html">Reagir o desenvolvimento de aplicativos usando ReasonReact</a></li>
<li><a href="../pt424967/index.html">Atalhos de JavaScript para iniciantes</a></li>
<li><a href="../pt424969/index.html">Guia Node.js, parte 9: Trabalhando com o sistema de arquivos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üò∫ üìÜ üòÖ Comment se faire des amis PyTorch et C ++. Utilisation de TorchScript üöÖ üí™üèΩ üéÇ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il y a environ un an, les d√©veloppeurs de PyTorch ont pr√©sent√© la communaut√© TorchScript , un outil qui vous permet de cr√©er une solution ali√©nable √† ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment se faire des amis PyTorch et C ++. Utilisation de TorchScript</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/480328/"><p>  Il y a environ un an, les d√©veloppeurs de PyTorch ont pr√©sent√© la communaut√© <strong>TorchScript</strong> , un outil qui vous permet de cr√©er une solution ali√©nable √† partir d'un pipeline en python en quelques clics de souris qui peuvent √™tre int√©gr√©s dans un syst√®me C ++.  Ci-dessous, je partage l'exp√©rience de son utilisation et j'essaie de d√©crire les pi√®ges rencontr√©s le long de ce chemin.  Je porterai une attention particuli√®re √† la mise en ≈ìuvre du projet sur Windows, car bien que la recherche en ML soit g√©n√©ralement effectu√©e sur Ubuntu, la solution finale est souvent (soudainement!) Requise sous les ¬´fen√™tres¬ª. </p><br><p>  Un exemple de code pour exporter un mod√®le et un projet C ++ √† l'aide du mod√®le se trouve dans le <a href="https://github.com/IlyaOvodov/TorchScriptTutorial">r√©f√©rentiel sur GitHub</a> . </p><br><p> <a href="https://habr.com/ru/company/ods/blog/480328/"><img src="https://habrastorage.org/webt/3k/u1/ub/3ku1ubmzigl3j016ezncczdonqm.jpeg"></a> </p><a name="habracut"></a><br><a name="continue"></a><br><p>  Les d√©veloppeurs de PyTorch ne sont pas dupes.  Le nouvel outil vous permet vraiment de transformer un projet de recherche dans PyTorch en code int√©gr√© dans un syst√®me C ++ en quelques jours ouvrables, et avec un peu de comp√©tence plus rapidement. </p><br><p>  TorchScript est apparu dans PyTorch version 1.0 et continue d'√©voluer et de changer.  Si la premi√®re version il y a un an √©tait pleine de bogues et √©tait plus exp√©rimentale, alors la version actuelle 1.3 au moins sur le deuxi√®me point est sensiblement diff√©rente: vous ne pouvez plus l'appeler exp√©rimentale, elle est tout √† fait appropri√©e pour une utilisation pratique.  Je vais me concentrer sur elle. </p><br><p>  Au c≈ìur de TorchScript se trouve son propre compilateur autonome (sans Python) d'un langage de type python, ainsi que des outils pour convertir un programme √©crit en Python et PyTorch, des m√©thodes pour enregistrer et charger les modules r√©sultants, et une biblioth√®que pour les utiliser en C ++.  Pour travailler, vous devrez ajouter plusieurs DLL au projet avec un poids total d'environ 70 Mo (pour Windows) pour travailler sur le CPU et 300 Mo pour la version GPU.  TorchScript prend en charge la plupart des fonctionnalit√©s de PyTorch et les principales fonctionnalit√©s du langage python.  Mais les biblioth√®ques tierces, comme OpenCV ou NumPy, devront √™tre oubli√©es.  Heureusement, de nombreuses fonctions de NumPy ont un analogue dans PyTorch. </p><br><h2 id="konvertiruem-payplayn-na-pytorch-model-na-torchscript">  Convertir le pipeline en mod√®le PyTorch sur TorchScript </h2><br><p>  TorchScript propose deux fa√ßons de convertir le code Python dans son format interne: le tra√ßage et le script (tra√ßage et script).  Pourquoi deux?  Non, c'est clair, bien s√ªr, que deux valent mieux qu'un ... </p><br><p><img src="https://habrastorage.org/webt/lh/xp/ww/lhxpwwynynljq2_sxj35jhpp9yc.jpeg"></p><br><p>  Mais dans le cas de ces m√©thodes, il s'av√®re, comme dans l'aphorisme bien connu, des d√©viations gauche et droite: les deux sont pires.  Eh bien, le monde n'est pas parfait.  Dans une situation sp√©cifique, vous devez choisir celle qui convient le mieux. </p><br><p>  La m√©thode de tra√ßage est tr√®s simple.  Un √©chantillon de donn√©es est pr√©lev√© (g√©n√©ralement initialis√© par des nombres al√©atoires), envoy√© √† la fonction ou √† la m√©thode de la classe qui nous int√©resse, et PyTorch construit et stocke le graphique de calcul de la m√™me mani√®re que d'habitude lors de la formation d'un r√©seau neuronal.  Voila - le script est pr√™t: </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torchvision model = torchvision.models.resnet34(pretrained = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) model.eval() sample = torch.rand(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>) scripted_model = torch.jit.trace(model, sample)</code> </pre> <br><p>  L'exemple ci-dessus produit un objet de la classe ScriptModule.  Il peut √™tre enregistr√© </p><br><pre> <code class="python hljs">scripted_model.save(<span class="hljs-string"><span class="hljs-string">'my_script.pth'</span></span>)</code> </pre> <br><p>  puis chargez-le <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">dans un programme C ++</a> (plus d'informations <a href="https://habr.com/ru/company/ods/blog/480328/">ci</a> - <a href="https://habr.com/ru/company/ods/blog/480328/">dessous</a> ) ou dans du code Python au lieu de l'objet d'origine: </p><br><div class="spoiler">  <b class="spoiler_title">Exemple de code Python √† l'aide d'un mod√®le enregistr√©</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.transforms <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Compose, ToTensor, Normalize transforms = Compose([ToTensor(), Normalize(mean=[<span class="hljs-number"><span class="hljs-number">0.485</span></span>, <span class="hljs-number"><span class="hljs-number">0.456</span></span>, <span class="hljs-number"><span class="hljs-number">0.406</span></span>], std=[<span class="hljs-number"><span class="hljs-number">0.229</span></span>, <span class="hljs-number"><span class="hljs-number">0.224</span></span>, <span class="hljs-number"><span class="hljs-number">0.225</span></span>])]) img = cv2.resize(cv2.imread(<span class="hljs-string"><span class="hljs-string">'pics/cat.jpg'</span></span>), (<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>)) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) x = transforms(img).unsqueeze(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-comment"><span class="hljs-comment"># add batch dimension scripted_model = torch.jit.load('my_script.pth') y = scripted_model(x) print(y[0].argmax(), y[0][y[0].argmax()])</span></span></code> </pre> <br><pre> <code class="plaintext hljs">tensor(282) tensor(12.8130, grad_fn=&lt;SelectBackward&gt;)</code> </pre> </div></div><br><p>  Le <code>ScriptModule</code> r√©sultant peut appara√Ætre n'importe o√π <code>nn.Module</code> est couramment utilis√©. </p><br><p>  De la mani√®re d√©crite, vous pouvez tracer des instances de la classe et des fonctions <code>nn.Module</code> (dans ce dernier cas, une instance de la classe <code>torch._C.Function</code> est <code>torch._C.Function</code> ). </p><br><p>  Cette m√©thode (tra√ßage) a un avantage important: de cette fa√ßon, vous pouvez convertir presque n'importe quel code Python qui n'utilise pas de biblioth√®ques externes.  Mais il y a un inconv√©nient tout aussi important: pour toutes les branches, seule la branche qui a √©t√© ex√©cut√©e sur les donn√©es de test sera m√©moris√©e: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_abs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt;= <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> -x my_abs_traced = torch.jit.trace(my_abs, torch.tensor(<span class="hljs-number"><span class="hljs-number">0</span></span>)) print(my_abs_traced(torch.tensor(<span class="hljs-number"><span class="hljs-number">1</span></span>)), my_abs_traced(torch.tensor(<span class="hljs-number"><span class="hljs-number">-1</span></span>)))</code> </pre> <br><pre> <code class="plaintext hljs">c:\miniconda3\lib\site-packages\ipykernel_launcher.py:2: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs! tensor(1) tensor(-1)</code> </pre> <br><p>  Oups!  Cela ne semble pas √™tre ce que nous aimerions, non?  Il est bon qu‚Äôau moins un message d‚Äôavertissement (TracerWarning) soit √©mis.  Il convient de pr√™ter attention √† ces messages. </p><br><p>  Ici, la deuxi√®me m√©thode vient √† notre aide - le script: </p><br><pre> <code class="python hljs">my_abs_script = torch.jit.script(my_abs) print(my_abs_script(torch.tensor(<span class="hljs-number"><span class="hljs-number">1</span></span>)), my_abs_script(torch.tensor(<span class="hljs-number"><span class="hljs-number">-1</span></span>)))</code> </pre> <br><pre> <code class="plaintext hljs">tensor(1) tensor(1)</code> </pre> <br><p>  Hourra, le r√©sultat attendu est re√ßu!  Le script analyse r√©cursivement le code Python et le convertit en code dans son propre langage.  En sortie, nous obtenons √©galement la classe <code>ScriptModule</code> (pour les modules) ou <code>torch._C.Function</code> (pour les fonctions).  Il semblerait, le voici, le bonheur!  Mais un autre probl√®me se pose: le langage interne de TorchScript est fortement typ√©, contrairement √† Python.  Le type de chaque variable est d√©termin√© par la premi√®re affectation, le type des arguments de fonction par d√©faut est <code>Tensor</code> .  Par cons√©quent, par exemple, un mod√®le familier </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> y = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: y = x <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y my_func = torch.jit.script(my_func)</code> </pre> <br><p>  Le tra√ßage √©chouera. </p><br><div class="spoiler">  <b class="spoiler_title">Une erreur de trace ressemble √† ceci</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">RuntimeError Traceback (most recent call last) &lt;ipython-input-9-25414183a687&gt; in &lt;module&gt;() ----&gt; 1 my_func = torch.jit.script(my_func) d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in script(obj, optimize, _frames_up, _rcb) 1224 if _rcb is None: 1225 _rcb = _gen_rcb(obj, _frames_up) -&gt; 1226 fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj)) 1227 # Forward docstrings 1228 fn.__doc__ = obj.__doc__ RuntimeError: Variable 'y' previously has type None but is now being assigned to a value of type Tensor : at &lt;ipython-input-8-75677614fca6&gt;:4:8 def my_func(x): y = None if x.max() &gt; 0: y = x ~ &lt;--- HERE return y</code> </pre> </div></div><br><p>  Il est √† noter que bien qu'une erreur se produise lors de l' <code>torch.jit.script</code> , l'endroit qui l'a provoqu√©e dans le code script√© est √©galement indiqu√©. </p><br><p>  M√™me les points apr√®s que les constantes commencent √† jouer un r√¥le: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: y = <span class="hljs-number"><span class="hljs-number">1.25</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: y = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y my_func = torch.jit.script(my_func)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">donnera une erreur</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">RuntimeError Traceback (most recent call last) &lt;ipython-input-10-0a5f18586763&gt; in &lt;module&gt;() 5 y = 0 6 return y ----&gt; 7 my_func = torch.jit.script(my_func) d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in script(obj, optimize, _frames_up, _rcb) 1224 if _rcb is None: 1225 _rcb = _gen_rcb(obj, _frames_up) -&gt; 1226 fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj)) 1227 # Forward docstrings 1228 fn.__doc__ = obj.__doc__ d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in _rcb(name) 1240 # closure rcb fails 1241 result = closure_rcb(name) -&gt; 1242 if result: 1243 return result 1244 return stack_rcb(name) RuntimeError: bool value of Tensor with more than one value is ambiguous</code> </pre> </div></div><br><p>  Parce qu'il faut √©crire non pas <code>0</code> , mais <code>0.</code> pour que le type dans les deux branches soit le m√™me!  G√¢t√©, vous savez, avec votre python! </p><br><p>  Ce n'est que le d√©but de la liste des modifications que vous devez apporter au code python afin qu'il puisse √™tre transform√© avec succ√®s en un module TorchScript.  Je vais √©num√©rer les cas les plus typiques plus en d√©tail <a href="https://habr.com/ru/company/ods/blog/480328/">plus tard</a> .  En principe, il n'y a pas de science fus√©e ici et votre code peut √™tre corrig√© en cons√©quence.  Mais le plus souvent, je ne veux pas r√©parer les modules tiers, y compris les modules standard de <code>torchvision</code> , et comme d'habitude, ils ne conviennent g√©n√©ralement pas aux scripts. </p><br><p>  Heureusement, les deux technologies peuvent √™tre combin√©es: ce qui est √©crit est √©crit et ce qui ne l'est pas est en train de tracer: </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> super(MyModule, self).__init__() self.resnet = torchvision.models.resnet34(pretrained = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment">#       torch.jit.script(my_module) #    -   resnet34. #     self.resnet  ScriptModule. self.resnet.eval() # NB:     !  -  ! self.resnet = torch.jit.trace(self.resnet, torch.rand((1,3,224,224), dtype=torch.float)) def forward(self, x): if x.shape[2] &lt; 224 or x.shape[3] &lt; 224: return torch.tensor(0) else: return self.resnet(x) my_module = MyModule() my_module = torch.jit.script(my_module)</span></span></code> </pre> <br><p>  Dans l'exemple ci-dessus, le tra√ßage est utilis√© pour inclure un module qui n'est pas scriptable dans un module o√π il n'y a pas suffisamment de trace et un script est n√©cessaire.  Il y a une situation inverse.  Par exemple, si nous devons t√©l√©charger un mod√®le sur ONNX, le tra√ßage est utilis√©.  Mais le mod√®le trac√© peut inclure des fonctions TorchScript, donc la logique qui n√©cessite des branches et des boucles peut y √™tre impl√©ment√©e!  Un exemple est donn√© dans la <a href="https://pytorch.org/docs/stable/onnx.html">documentation officielle de torch.onnx</a> . </p><br><p>  Les fonctionnalit√©s fournies par PyTorch pour cr√©er des modules TorchScript sont d√©crites plus en d√©tail dans la <a href="https://pytorch.org/docs/stable/jit.html">documentation officielle</a> et le <code>torch.jit</code> .  En particulier, je n'ai pas mentionn√© de moyen pratique d'utiliser <code>torch.jit.trace</code> et <code>torch.jit.script</code> sous la forme de d√©corateurs, sur les particularit√©s du d√©bogage du code script√©.  Ceci et bien plus est dans la documentation. </p><br><h2 id="anchorcppanchorvklyuchaem-model-v-proekt-na-c"><a name="cpp"></a>  Nous incluons le mod√®le dans un projet C ++ </h2><br><p>  Malheureusement, la <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">documentation officielle se</a> limite √† des exemples de la forme "ajouter 2 tenseurs g√©n√©r√©s √† l'aide de <code>torch.ones</code> ".  J'ai pr√©par√© un exemple de <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">projet plus proche de la r√©alit√©</a> qui envoie une image d'OpenCV au r√©seau neuronal et re√ßoit les r√©sultats sous la forme d'un tenseur de r√©ponse, un tuple de variables, une image avec des r√©sultats de segmentation. </p><br><p>  Pour que l'exemple fonctionne, vous avez besoin de scripts de classification enregistr√©s √† l'aide de ResNet34 et d'une segmentation √† l'aide de DeepLabV3.  Pour pr√©parer ces scripts, vous devez ex√©cuter <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/prepare_scripts.ipynb">ce bloc-notes jupyter</a> . </p><br><p>  Nous avons besoin de la biblioth√®que <code>torchlib</code> .  Vous pouvez l'obtenir de plusieurs mani√®res: </p><br><ol><li>  Si PyTorch est d√©j√† install√© √† l'aide de <code>pip install</code> , vous pouvez le trouver dans le r√©pertoire Python: <code>&lt;Miniconda3&gt;\Lib\site-packages\torch</code> ; </li><li>  Si vous avez compil√© PyTorch √† partir des sources, il est l√†: <code>&lt;My Pytorch repo&gt;\build\lib.win-amd64-3.6\torch</code> ; </li><li>  Enfin, vous pouvez t√©l√©charger la <a href="https://pytorch.org/">biblioth√®que</a> s√©par√©ment de <a href="https://pytorch.org/">pytorch.org</a> en choisissant Language = C ++, et d√©compressez l'archive. </li></ol><br><p>  Le code C ++ est assez simple.  Il faut: </p><br><ol><li>  Inclure le fichier d'en-t√™te <br><pre> <code class="plaintext hljs">#include &lt;torch/script.h&gt;</code> </pre> </li><li>  T√©l√©charger le mod√®le <br><pre> <code class="plaintext hljs">torch::jit::script::Module module = torch::jit::load("../resnet34_infer.pth");</code> </pre> </li><li>  Pr√©parer les donn√©es <br><pre> <code class="plaintext hljs">torch::Tensor tensor = torch::from_blob(img.data, { img.rows, img.cols, 3 }, torch::kByte);</code> </pre> </li><li>  Fonction de <code>forward</code> appel et obtenir le r√©sultat <br><pre> <code class="plaintext hljs">auto output = module.forward( { tensor } )</code> </pre> </li><li>  Obtenez des donn√©es du r√©sultat.  La fa√ßon de proc√©der d√©pend de ce que le r√©seau de neurones retourne.  Soit dit en passant, dans le cas g√©n√©ral, il peut √©galement accepter non seulement une image, il est donc pr√©f√©rable de regarder <a href="">le code source de l'exemple</a> entier, il existe diff√©rentes options.  Par exemple, pour obtenir des donn√©es √† partir d'un tenseur unidimensionnel de type float: <br><pre> <code class="plaintext hljs">float* data = static_cast&lt;float*&gt;(output.toTensor().data_ptr());</code> </pre> </li><li>  Il y a encore une subtilit√©.  N'oubliez pas d'ins√©rer l'analogue <code>with torch.no_grad()</code> dans le code afin de ne pas gaspiller des ressources sur le calcul et le stockage des gradients dont nous n'avons pas besoin.  Malheureusement, cette commande ne peut pas √™tre incluse dans le script, vous devez donc l'ajouter au code C ++: <br><pre> <code class="plaintext hljs">torch::NoGradGuard no_grad;</code> </pre> </li></ol><br><p>  Comment construire un projet en utilisant CMake est d√©crit dans le <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">guide officiel</a> .  Mais le sujet du projet dans Visual Studio n'y est pas divulgu√©, je vais donc le d√©crire plus en d√©tail.  Vous devrez modifier manuellement les param√®tres du projet: </p><br><ol><li>  J'ai test√© sur Visual Studio 2017. Je ne peux pas en dire plus sur les autres versions. </li><li>  Le jeu d'outils v14.11 v141 doit √™tre install√© (cochez <code>"VC++ 2017 version 15.4 v14.11 toolset"</code> dans le programme d'installation VS). </li><li>  La plateforme doit √™tre <code>x64</code> . </li><li>  Dans <code>General ‚Üí Platform Toolset</code> s√©lectionnez <code>v141(Visual Studio 2017)</code> </li><li>  Dans <code>C/C++ ‚Üí General ‚Üí Additional Include Directories</code> <code>&lt;libtorch dir&gt;\include</code> <code>C/C++ ‚Üí General ‚Üí Additional Include Directories</code> ajoutez <code>&lt;libtorch dir&gt;\include</code> </li><li>  Dans l' <code>&lt;libtorch dir&gt;\lib</code> <code>Linker ‚Üí General ‚Üí Additional Library Directories</code> ajoutez <code>&lt;libtorch dir&gt;\lib</code> </li><li>  Dans <code>Linker ‚Üí Input ‚Üí Additional Dependencies</code> ajoutez <code>torch.lib; c10.lib</code>  <code>torch.lib; c10.lib</code> .  Sur Internet, ils √©crivent que <code>caffe2.lib</code> peut encore √™tre n√©cessaire, et pour le GPU et quelque chose d'autre de <code>&lt;libtorch dir&gt;\lib</code> , mais dans la version actuelle, l'ajout de ces deux biblioth√®ques me suffisait.  Il s'agit peut-√™tre d'informations p√©rim√©es. </li><li>  Ils √©crivent √©galement que vous devez d√©finir <code>C/C++ ‚Üí Language ‚Üí Conformance Mode</code> = <code>No</code> , mais je n'ai pas vu la diff√©rence. </li></ol><br><p>  De plus, la variable <code>__cplusplus</code> ne doit PAS √™tre d√©clar√©e dans le projet.  Tenter d'ajouter l' <a href="https://docs.microsoft.com/ru-ru/cpp/build/reference/zc-cplusplus%3Fview%3Dvs-2017"><code>  /Zc:__cplusplus</code></a> entra√Ænera des erreurs de compilation dans le fichier <code>ivalue.h</code> . </p><br><p>  Dans le <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">projet joint,</a> les param√®tres de chemin (non seulement pour TorchLib, mais aussi pour OpenCV et CUDA) sont extraits dans le <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/cpp_proj/cpp_proj.props">fichier d'accessoires</a> , avant l'assemblage, vous devez les enregistrer l√†-bas conform√©ment √† votre configuration locale.  En fait, c'est tout. </p><br><h2 id="anchortipsanchorchto-eschyo-sleduet-imet-v-vidu"><a name="tips"></a>  Quoi d'autre √† garder √† l'esprit </h2><br><p>  Si le processus d√©crit vous a paru trop simple, votre intuition ne vous a pas tromp√©.  Il y a un certain nombre de nuances √† prendre en compte pour convertir un mod√®le PyTorch √©crit en Python en TorchScript.  Je vais √©num√©rer ci-dessous ceux que j'ai d√ª affronter.  J'en ai d√©j√† mentionn√© quelques-uns, mais je r√©p√®te de rassembler tout en un seul endroit. </p><br><p><img src="https://habrastorage.org/webt/iv/xy/q-/ivxyq-lqqw8s1aqd_cy4t4uwj5i.jpeg"></p><br><ul><li>  Le type de variables pass√©es √† la fonction est Tensor par d√©faut.  Si dans certains cas (tr√®s fr√©quents) cela est inacceptable, vous devrez d√©clarer les types manuellement √† l'aide d'annotations de type MyPy, quelque chose comme ceci: </li></ul><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calc_letter_statistics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, cls_preds: List[Tensor], cls_thresh: float)</span></span></span><span class="hljs-function">-&gt;Tuple[int, Tuple[Tensor, Tensor, Tensor]]</span></span></code> </pre> <br><p>  ou alors: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calc_letter_statistics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, cls_preds, cls_thresh)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># type: (List[Tensor], float)-&gt;Tuple[int, Tuple[Tensor, Tensor, Tensor]]</span></span></code> </pre> <br><ul><li>  Les variables sont fortement typ√©es et le type, s'il n'est pas sp√©cifi√© explicitement, est d√©termin√© par la premi√®re affectation.  Constructions famili√®res de la forme <code>x=[]; for ...: x.append(y)</code>  <code>x=[]; for ...: x.append(y)</code> devra √™tre modifi√©, car  au moment d'affecter <code>[]</code> compilateur ne peut pas d√©terminer quel type sera dans la liste.  Par cons√©quent, vous devez sp√©cifier le type explicitement, par exemple: </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> typing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> List x: List[float] = []</code> </pre> <br><p>  ou (un autre "par exemple") </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tensor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> typing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dict, Tuple, List x: Dict[int: Tuple[float, List[Tensor], List[List[int]]]] = {}</code> </pre> <br><ul><li>  Dans l'exemple ci-dessus, ce sont les noms qui doivent √™tre import√©s, car ces noms sont cousus dans le code TorchScript.  Approche alternative, apparemment l√©gale </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> typing x: typing.List[torch.Tensor] = []</code> </pre> <br><p>  entra√Ænera une erreur de <em>typage du constructeur de type inconnu.</em> </p><br><ul><li>  Une autre conception famili√®re avec laquelle vous devez vous s√©parer: </li></ul><br><pre> <code class="python hljs">x = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p>  Il y a deux options.  Ou attribuez Tensor les deux fois (le fait qu'il soit de dimensions diff√©rentes n'est pas effrayant): </p><br><pre> <code class="python hljs">x = torch.tensor(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p>  et n'oubliez pas de chercher ce qui se cassera apr√®s un tel remplacement.  Ou essayez d'√©crire honn√™tement: </p><br><pre> <code class="python hljs">x: Optional[Tensor] = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p>  mais alors avec une utilisation suppl√©mentaire de <code>x</code> o√π le tenseur est attendu, nous obtiendrons tr√®s probablement une erreur: <em>Attendu une valeur de type 'Tensor' pour l'argument 'x' mais trouv√© √† la place le type 'Optional [Tensor]'.</em> </p><br><ul><li><p>  N'oubliez pas d'√©crire, par exemple, <code>x=0.</code> lors de la premi√®re affectation <code>x=0.</code>  au lieu de l'habituel <code>x=0</code> , etc., si la variable <code>x</code> doit √™tre de type <code>float</code> . </p><br></li><li><p>  Si quelque part nous avons utilis√© l'initialisation √† l'ancienne du tenseur via <code>x = torch.Tensor(...)</code> , vous devrez vous en s√©parer et le remplacer par une version plus r√©cente avec une petite lettre <code>x = torch.tensor(...)</code> .  Sinon, pendant le script, il volera: <em>Op√©ration interne inconnue: aten :: Tensor.</em>  <em>Voici quelques suggestions: aten :: tensor</em> .  Il semble qu'ils expliquent m√™me le probl√®me et il est clair ce qui doit √™tre fait.  Cependant, il est clair si vous connaissez d√©j√† la bonne r√©ponse. </p><br></li><li><p>  Le code est script√© dans le contexte du module o√π <code>torch.jit.script</code> appel√©.  Par cons√©quent, si quelque part, dans les entrailles de la classe ou de la fonction script√©e, par exemple, <code>math.pow</code> , vous devrez ajouter <code>import math</code> au module de compilation.  Et il est pr√©f√©rable de scripter la classe o√π elle est d√©clar√©e: soit en utilisant le d√©corateur <code>@torch.jit.script</code> , soit en d√©clarant une fonction suppl√©mentaire √† c√¥t√© d'elle qui en fait ScriptModule.  Sinon, nous obtenons un message d'erreur <em>math√©matique de valeur non d√©finie</em> lorsque nous essayons de compiler une classe √† partir d'un module dans lequel, apparemment, l'importation <code>math</code> √©t√© effectu√©e. </p><br></li><li><p>  Si quelque part vous avez une construction de la forme <code>my_tensor[my_tensor &lt; 10] = 0</code> ou similaire, vous obtiendrez une erreur cryptique lors de l'√©criture de scripts: </p><br><pre> <code class="plaintext hljs">*aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -&gt; (Tensor(a!)):* *Expected a value of type 'Tensor' for argument 'values' but instead found type 'int'.* *aten::index_put_(Tensor(a!) self, Tensor[] indices, Tensor values, bool accumulate=False) -&gt; (Tensor(a!)):* *Expected a value of type 'List[Tensor]' for argument 'indices' but instead found type 'List[Optional[Tensor]]'.*</code> </pre> <br><p>  Ce dont vous avez besoin est de remplacer le nombre par le tenseur: <code>my_tensor[my_tensor &lt; 10] = torch.tensor(0.).to(my_tensor.device)</code> .  Et n'oubliez pas a) la correspondance des types <code>my_tensor</code> et du tenseur cr√©√© (dans ce cas, float) et b) about <code>.to(my_tensor.device)</code> .  Si vous oubliez la seconde, tout sera script√©, mais d√©j√† en train de travailler avec le GPU, vous serez contrari√©, qui ressemblera aux mots cryptiques <em>Erreur CUDA: un acc√®s m√©moire ill√©gal a √©t√© rencontr√©</em> , sans indiquer o√π l'erreur s'est produite! </p><br></li><li><p>  N'oubliez pas que par d√©faut <code>nn.Module</code> et, par cons√©quent, les mod√®les de torchvision sont cr√©√©s en "mode train" (vous ne le croirez pas, mais il s'av√®re <a href="https://fooobar.com/questions/16769103/error-when-converting-pytorch-model-to-torchscript/25666033">qu'il existe un tel mode</a> ).  Dans ce cas, Dropout et d'autres astuces du mode train sont utilis√©es, ce qui rompt la trace ou conduit √† des r√©sultats inad√©quats lors de l'ex√©cution.  N'oubliez pas d'appeler <code>model.eval()</code> avant de <code>model.eval()</code> script ou un suivi. </p><br></li><li><p>  Pour les fonctions et les classes ordinaires, vous devez scripter le type, pour nn.Module - une instance </p><br></li><li><p>  Tentative dans une m√©thode script√©e d'acc√©der √† une variable globale </p><br></li></ul><br><pre> <code class="python hljs">cls_thresh = <span class="hljs-number"><span class="hljs-number">0.3</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> ... x = r &lt; cls_thresh ...</code> </pre> <br><p>  entra√Ænera une erreur de script de la forme <em>python. La valeur de type 'float' ne peut pas √™tre utilis√©e comme valeur</em> .  Il est n√©cessaire de faire de la variable un attribut dans le constructeur: </p><br><pre> <code class="python hljs">cls_thresh = <span class="hljs-number"><span class="hljs-number">0.3</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> ... self.cls_thresh = cls_thresh ... x = r &lt; self.cls_thresh ...</code> </pre> <br><ul><li>  Une autre subtilit√© appara√Æt si l'attribut de classe est utilis√© comme param√®tre de tranche: </li></ul><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FPN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, block, num_blocks, num_layers =</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> ... self.num_layers = num_layers <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x)</span></span></span><span class="hljs-function">:</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (p3, p4, p5, p6, p7)[:self.num_layers]</code> </pre> <br><p>  provoque des erreurs de script, les <em>indices de tranche de tuple doivent √™tre des constantes enti√®res</em> .  Il est n√©cessaire d'indiquer que l'attribut num_layers est constant et ne changera pas: </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FPN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> num_layers: torch.jit.Final[int] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, block, num_blocks, num_layers =</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> ...</code> </pre> <br><ul><li>  Dans certains cas, o√π le tenseur s'adaptait normalement, vous devez explicitement transmettre le nombre: </li></ul><br><pre> <code class="python hljs">xx1 = x1.clamp(min=x1[i])</code> </pre> <br><p>  renvoie une erreur lors de l'√©criture d' <em><code>Expected a value of type 'Optional[number]' for argument 'min' but instead found type 'Tensor'.</code></em> script. <em><code>Expected a value of type 'Optional[number]' for argument 'min' but instead found type 'Tensor'.</code></em>  .  Eh bien, ici, √† partir du message d'erreur, il est clair que faire: </p><br><pre> <code class="python hljs">xx1 = x1.clamp(min=x1[i].item())</code> </pre> <br><p>  Les probl√®mes ci-dessus se produisent lors du tra√ßage.  C'est √† cause d'eux qu'il n'est g√©n√©ralement pas possible de simplement compiler des solutions pr√™tes √† l'emploi dans TorchScript, et vous devez soit masser le code source pendant une longue p√©riode (si le code source est appropri√© √† modifier), soit utiliser le tra√ßage.  Mais la trace a ses propres nuances: </p><br><ul><li>  Les constructions du formulaire ne fonctionnent pas dans la trace </li></ul><br><pre> <code class="plaintext hljs">tensor_a.to(tensor_b.device)</code> </pre> <br><p>  Le dispositif sur lequel le tenseur est charg√© est fix√© au moment du tra√ßage et ne change pas lors de l'ex√©cution.  Ce probl√®me peut √™tre partiellement surmont√© en d√©clarant le tenseur membre de <code>nn.Module</code> type <code>Parameter</code> .  Ensuite, lors du chargement du mod√®le, il d√©marrera sur le p√©riph√©rique sp√©cifi√© dans la fonction <code>torch.jit.load</code> . </p><br><h2 id="epilog">  √âpilogue </h2><br><p>  Tout ce qui pr√©c√®de, bien s√ªr, cr√©e des probl√®mes.  Mais TorchScript vous permet de combiner et d'envoyer √† la solution dans son ensemble le mod√®le lui-m√™me et le code Python qui fournit le pr√© et le post-traitement.  Oui, et le temps de pr√©parer la solution pour la compilation, m√™me malgr√© les difficult√©s ci-dessus, est incomparablement inf√©rieur au co√ªt de cr√©ation d'une solution, mais ici PyTorch offre de grands avantages, donc le jeu en vaut la chandelle. </p><br><p><img src="https://habrastorage.org/webt/v0/3m/qt/v03mqtayxdfh5be4ut3nrr0c86q.jpeg"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr480328/">https://habr.com/ru/post/fr480328/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr480316/index.html">Comment r√©duire la consommation de modules wifi de dix fois ou plus</a></li>
<li><a href="../fr480318/index.html">Une s√©lection des prochains √©v√©nements gratuits pour les d√©veloppeurs √† Moscou # 3 (16-24 d√©cembre)</a></li>
<li><a href="../fr480320/index.html">Dix ans d'ONYX en Russie - comment les technologies, les lecteurs et le march√© ont chang√© pendant cette p√©riode</a></li>
<li><a href="../fr480324/index.html">Impl√©mentation du type de cha√Æne dans CPython</a></li>
<li><a href="../fr480326/index.html">F5 Networks Corporation envoie des lettres √† ses clients pour les informer de la situation actuelle avec NGINX</a></li>
<li><a href="../fr480330/index.html">Outil d'√©valuation id√©al des employ√©s</a></li>
<li><a href="../fr480332/index.html">Analyse des donn√©es du vote blockchain 2019 √† la Douma de Moscou</a></li>
<li><a href="../fr480334/index.html">Panneau QtQML / Quick correlation</a></li>
<li><a href="../fr480338/index.html">Fonctionnement du rendu de jeu 3D: pixellisation et lancer de rayons</a></li>
<li><a href="../fr480340/index.html">Je me suis oppos√© √† un gestionnaire incomp√©tent, puis il a √©t√© promu</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
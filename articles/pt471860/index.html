<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõ¥ ü•™ üë®‚Äçüè´ Analisadores de Peg üëÜ ü§æüèª üëáüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Alguns anos atr√°s, algu√©m me perguntou se faz sentido converter Python em um analisador PEG (ou em uma gram√°tica PEG; n√£o me lembro exatamente quem e ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analisadores de Peg</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/471860/"><p>  Alguns anos atr√°s, algu√©m me perguntou se faz sentido converter Python em um analisador PEG (ou em uma gram√°tica PEG; n√£o me lembro exatamente quem e quando era).  Ent√£o olhei para ele um pouco, mas n√£o cheguei a nenhuma conclus√£o e, portanto, abandonei este t√≥pico.  Recentemente, aprendi mais sobre PEG (an√°lise de express√µes de an√°lise de gram√°tica, an√°lise de express√£o de an√°lise de an√°lise) e agora acho que essa √© uma alternativa interessante ao gerador de analisador auto-escrito que foi desenvolvido h√° 30 anos, quando eu estava apenas come√ßando a trabalhar em Python.  Eu chamei de ‚Äúpgen‚Äù, e esse foi provavelmente o primeiro peda√ßo de c√≥digo que escrevi para o Python. </p><br><div class="spoiler">  <b class="spoiler_title">Conte√∫do da s√©rie Ps Parser Python</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Analisadores de Peg</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Implementa√ß√£o do Analisador PEG</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Gera√ß√£o de analisador PEG</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Visualiza√ß√£o do analisador PEG</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Gram√°tica PEG recursiva esquerda</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Adicionando a√ß√µes √† gram√°tica PEG</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Meta gram√°tica para analisador PEG</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Implementando os recursos restantes do PEG</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PEG no Core Developer Sprint</a> </li></ul></div></div><br><p> Atualmente, estou interessado no analisador PEG porque estou um pouco irritado com as limita√ß√µes do pgen.  Ele √© constru√≠do sobre sua pr√≥pria implementa√ß√£o do LL (1), que possui v√°rias suposi√ß√µes.  Por exemplo, eu n√£o gostava de regras gramaticais que pudessem gerar linhas vazias, ent√£o as proibi.  E, assim, simplificou o algoritmo para criar tabelas de an√°lise.  Tamb√©m inventei minha pr√≥pria nota√ß√£o gramatical do tipo EBNF, da qual ainda gosto muito. </p><a name="habracut"></a><br><p> Aqui est√£o alguns problemas com o pgen que me incomodam.  O "1" no nome LL (1) implica que ele apenas analise o pr√≥ximo token, e isso limita nossa capacidade de criar boas regras gramaticais.  Por exemplo, uma instru√ß√£o Python pode ser uma express√£o ou atribui√ß√£o (ou outra coisa, mas todas elas come√ßam com uma palavra-chave destacada, como <code>if</code> ou <code>def</code> ).  Gostaria de descrever a sintaxe usando a nota√ß√£o pgen.  Observe que este √© apenas um exemplo simplificado, que √© um subconjunto do Python, como geralmente √© feito ao descrever o design da linguagem.  Essa ser√° uma gram√°tica de brinquedo que ser√° √∫til para mais demonstra√ß√µes. </p><br><pre> <code class="plaintext hljs">statement: assignment | expr | if_statement expr: expr '+' term | expr '-' term | term term: term '*' atom | term '/' atom | atom atom: NAME | NUMBER | '(' expr ')' assignment: target '=' expr target: NAME if_statement: 'if' expr ':' statement</code> </pre> <br><p>  Algumas palavras sobre nota√ß√£o: <code>NAME</code> e <code>NUMBER</code> s√£o tokens e s√£o predefinidos fora da gram√°tica.  Seq√º√™ncias de caracteres entre aspas do tipo <code>'+'</code> ou <code>'if'</code> tamb√©m s√£o tokens.  (Adiamos falar sobre eles da pr√≥xima vez). As regras gramaticais come√ßam com o nome da regra, seguido por <code>:</code> e, em seguida, uma ou mais alternativas, separadas por <code>|</code>  . </p><br><p>  O problema √© que, se voc√™ descrever a gram√°tica dessa maneira, o pgen n√£o funcionar√°.  Isso se deve ao fato de algumas regras ( <code>expr</code> e <code>term</code> ) serem recursivas, e ele n√£o √© inteligente o suficiente para lidar corretamente com essas situa√ß√µes.  Geralmente, isso √© resolvido reescrevendo apenas essas regras, mantendo as outras regras inalteradas.  Por exemplo: </p><br><pre> <code class="plaintext hljs">expr: term ('+' term | '-' term)* term: atom ('*' atom | '/' atom)*</code> </pre> <br><p>  Isso revela v√°rias possibilidades de EBNF na pgen: voc√™ pode aninhar alternativas entre par√™nteses e criar repeti√ß√µes colocando <code>*</code> ap√≥s o elemento.  Portanto, a regra para a express√£o <code>expr</code> aqui significa "√© um termo seguido por zero ou mais repeti√ß√µes da sequ√™ncia &lt;termo mais ou menos, seguido pelo termo&gt;".  Essa gram√°tica usa o mesmo idioma da primeira vers√£o, mas, novamente, n√£o reflete a inten√ß√£o de design do idioma.  Em particular, isso n√£o mostra que os operadores est√£o ligados √† esquerda, e isso √© importante quando voc√™ est√° tentando gerar c√≥digo. </p><br><p>  Mas h√° outro problema irritante neste exemplo (e tamb√©m no Python).  Devido √† an√°lise de apenas um token, o analisador n√£o pode determinar para o que est√° olhando - o in√≠cio de uma express√£o ou atribui√ß√£o.  No in√≠cio do processamento do operador, o analisador deve decidir apenas o primeiro token, qual alternativa ele analisa.  (Por qu√™? √â assim que a implementa√ß√£o da an√°lise na pgen funciona) Digamos que nosso programa seja o seguinte: </p><br><pre> <code class="plaintext hljs">answer = 42</code> </pre> <br><p>  Este programa √© representado por tr√™s tokens: <code>NAME</code> (com valor de <code>answer</code> ), <code>=</code> e <code>NUMBER</code> (com valor <code>42</code> ).  A √∫nica coisa que sabemos no in√≠cio da an√°lise √© o primeiro token <code>NAME</code> .  A regra que estamos tentando analisar nesse est√°gio √© <code>statement</code> (o caractere inicial da gram√°tica).  Tr√™s alternativas s√£o definidas para ele: <code>expr</code> , <code>assignment</code> e <code>if_statement</code> .  Podemos excluir imediatamente <code>if_statement</code> , porque o token anterior n√£o √© <code>if</code> .  Mas tanto a <code>expr</code> quanto a <code>assignment</code> podem come√ßar com o token <code>NAME</code> e, por isso, a pgen rejeita nossa gram√°tica como amb√≠gua. </p><br><p>  Isso n√£o est√° totalmente correto, j√° que tecnicamente a pr√≥pria gram√°tica n√£o est√°;  N√£o consigo encontrar uma formula√ß√£o mais precisa, ent√£o vamos nos debru√ßar sobre essa.  E como a pgen resolve isso?  Ele calcula algo chamado PRIMEIRO conjunto para cada regra gramatical e, se eles se cruzam, gera uma exce√ß√£o. </p><br><p>  Portanto, n√£o podemos resolver esse problema fornecendo ao analisador um buffer de visualiza√ß√£o maior?  Para o nosso exemplo, um segundo token de visualiza√ß√£o √© suficiente, pois nesta gram√°tica o segundo token de atribui√ß√£o deve ser <code>=</code> .  Mas em uma linguagem mais realista como Python, voc√™ pode precisar de um buffer ilimitado, pois o conte√∫do √† esquerda do <code>=</code> token <code>=</code> pode ser arbitrariamente complexo, por exemplo: </p><br><pre> <code class="python hljs">table[index + <span class="hljs-number"><span class="hljs-number">1</span></span>].name.first = <span class="hljs-string"><span class="hljs-string">'Steven'</span></span></code> </pre> <br><p>  Nesse caso, voc√™ ter√° que analisar dez tokens antes de nos encontrarmos.  Mas garanto-lhe, pode haver express√µes mais longas.  Para resolver esse problema na pgen, alteramos o analisador de gram√°tica para aceitar algumas express√µes incorretas, adicionando uma verifica√ß√£o adicional em uma passagem subsequente.  Ir√° gerar um erro SyntaxError se n√£o puder corresponder aos lados esquerdo e direito.  Para nossa linguagem de brinquedos, tudo se resume a escrever o seguinte: </p><br><pre> <code class="plaintext hljs">statement: assignment_or_expr | if_statement assignment_or_expr: expr ['=' expr]</code> </pre> <br><p>  Os colchetes indicam uma parte opcional.  E ent√£o, na pr√≥xima passagem do compilador (digamos, ao gerar o bytecode), verificamos se <code>=</code> ou n√£o e, nesse caso, verificamos se o lado esquerdo corresponde √† sintaxe de <code>target</code> . </p><br><p>  H√° um problema semelhante para argumentos de chamada de fun√ß√£o.  Gostar√≠amos de escrever algo assim (novamente, em uma vers√£o simplificada da sintaxe do Python): </p><br><pre> <code class="plaintext hljs">call: atom '(' arguments ')' arguments: arg (',' arg) * arg: posarg | kwarg posarg: expr kwarg: NAME '=' expr</code> </pre> <br><p>  Mas o algoritmo de an√°lise, que levaria em considera√ß√£o apenas o pr√≥ximo token, n√£o pode dizer ao analisador se <code>NAME</code> no in√≠cio dos argumentos √© o in√≠cio de <code>posarg</code> (j√° que <code>expr</code> pode come√ßar com <code>NAME</code> ) ou o in√≠cio de <code>kwarg</code> .  Novamente, o analisador Python atual resolve esse problema determinando: </p><br><pre> <code class="plaintext hljs">arg: expr ['=' expr]</code> </pre> <br><p>  e, em seguida, conclui a alternativa em uma passagem subsequente do compilador.  (N√≥s at√© cometemos um pequeno erro e analisamos <code>foo((a) = 1)</code> como <code>foo(a = 1)</code> . Isso foi corrigido apenas no Python 3.8) </p><br><p>  Ent√£o, como um analisador PEG resolve esses problemas?  Usando um buffer de backup infinito!  Sua implementa√ß√£o t√≠pica usa o chamado analisador de packrat, que n√£o apenas carrega o programa inteiro na mem√≥ria antes de analis√°-lo, mas tamb√©m permite que o analisador seja revertido para um n√∫mero arbitr√°rio de tokens.  Embora o termo PEG se refira principalmente √† nota√ß√£o gramatical, os analisadores gerados a partir de gram√°ticas PEG s√£o tipicamente analisadores com descend√™ncia recursiva e retorno ilimitado.  O analisador de packrat torna o ego eficiente lembrando as regras que j√° foram analisadas para posi√ß√µes espec√≠ficas. </p><br><p>  Isso simplifica o algoritmo, mas √© claro que h√° um pre√ßo: mem√≥ria.  Trinta anos atr√°s, eu tinha um bom motivo para usar o LL (1): a mem√≥ria era cara.  Ele (como outras tecnologias, como a LALR (1), famosa pela YACC), usa uma m√°quina de estado e uma pilha para construir com efici√™ncia uma √°rvore de an√°lise. </p><br><p>  Felizmente, os computadores que executam o CPython possuem muito mais mem√≥ria do que h√° 30 anos, e armazenar o arquivo inteiro na mem√≥ria n√£o √© mais um problema.  Por exemplo, o maior arquivo sem teste no stdlib que eu pude encontrar √© <code>_pydecimal.py</code> , que leva cerca de 223kb.  No mundo dos gigabytes, isso n√£o √© essencialmente nada, o que me fez dar uma olhada diferente nos analisadores. </p><br><p>  Mas h√° mais uma coisa no analisador CPython atual que me incomoda.  Compiladores s√£o coisas complexas, e a implementa√ß√£o do CPython n√£o √© uma exce√ß√£o.  Embora o resultado do analisador pgen seja uma √°rvore de an√°lise, ele n√£o √© usado diretamente como entrada para o gerador de bytecode: ele √© primeiro convertido em uma √°rvore de sintaxe abstrata (AST) e somente ent√£o esse AST √© compilado no bytecode.  (Na verdade, √© ainda mais complicado l√°, mas por enquanto n√£o entraremos em detalhes) </p><br><p>  Por que n√£o compilar imediatamente a partir de uma √°rvore de an√°lise?  Era exatamente assim, mas h√° cerca de 15 anos descobrimos que o compilador era muito complicado.  Ent√£o, isolamos o AST e a fase de transforma√ß√£o do AST da √°rvore de an√°lise separadamente.  √Ä medida que o Python evoluiu, o AST permaneceu mais est√°vel que a an√°lise, o que reduziu a probabilidade de erros no compilador. </p><br><p>  O AST tamb√©m √© mais f√°cil de trabalhar com bibliotecas de terceiros que desejam testar o c√≥digo Python.  Pode ser obtido usando o popular m√≥dulo <code>ast</code> .  Tamb√©m permite criar n√≥s a partir do zero e modificar os existentes, al√©m de compilar pe√ßas no bytecode.  Este √∫ltimo permitiu a cria√ß√£o de toda uma ind√∫stria de extens√µes de linguagem para Python.  (A √°rvore de an√°lise tamb√©m √© acess√≠vel aos usu√°rios do Python atrav√©s do m√≥dulo de an√°lise, mas trabalhar com ela √© muito mais dif√≠cil; portanto, n√£o √© t√£o popular) </p><br><p>  Agora, quero combinar essas coisas e ver se podemos criar um novo analisador para o CPython, que usa o PEG e o packrat para criar o AST diretamente durante a an√°lise.  Assim, ser√° poss√≠vel omitir a gera√ß√£o da √°rvore intermedi√°ria de an√°lise, o que pode economizar mem√≥ria, mesmo com o uso de um buffer infinito para tokens.  Ainda estou no processo de implementa√ß√£o, mas j√° tenho um prot√≥tipo que pode compilar um subconjunto do Python no AST na mesma velocidade do analisador atual do CPython.  No entanto, ele usa mais mem√≥ria e parece-me que expandir o subconjunto para o idioma completo desacelerar√° o analisador PEG.  Mas at√© agora n√£o pensei em nenhuma otimiza√ß√£o, por isso continuarei trabalhando. </p><br><p>  A √∫ltima vantagem de mudar para o PEG √© que ele oferece mais flexibilidade para a evolu√ß√£o adicional do idioma.  No passado, dizia-se que as restri√ß√µes LL (1) no pgen mantinham a gram√°tica Python simples.  Isso pode muito bem ser verdade, mas temos muitos outros processos para impedir o crescimento descontrolado de idiomas (principalmente o processo PEP, que √© auxiliado por requisitos muito rigorosos de compatibilidade com vers√µes anteriores e uma nova estrutura de gerenciamento).  Ent√£o, eu n√£o estou preocupado com isso. </p><br><p>  Eu gostaria de falar muito mais sobre o PEG e minha implementa√ß√£o, mas ele estar√° nos pr√≥ximos posts depois que eu limpar o c√≥digo. </p><br><p>  Licen√ßa para este artigo e c√≥digo citado: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CC BY-NC-SA 4.0</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt471860/">https://habr.com/ru/post/pt471860/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt471844/index.html">5 raz√µes para visitar EPAM INSIDER no Cazaquist√£o</a></li>
<li><a href="../pt471852/index.html">Not√≠cias do mundo do OpenStreetMap n¬∫ 481 (01/10/2019 - 07/10/2019)</a></li>
<li><a href="../pt471854/index.html">Calor Morte 5G</a></li>
<li><a href="../pt471856/index.html">Resolvemos todas as 42 vers√µes do quebra-cabe√ßa de po√ß√µes de Harry Potter</a></li>
<li><a href="../pt471858/index.html">RabbitMQ vs. Kafka: Failover e alta disponibilidade em clusters</a></li>
<li><a href="../pt471862/index.html">Implementa√ß√£o do Analisador PEG</a></li>
<li><a href="../pt471864/index.html">Gera√ß√£o de analisador PEG</a></li>
<li><a href="../pt471870/index.html">Uso efetivo do libdispatch</a></li>
<li><a href="../pt471872/index.html">Interfaces no C # 8: suposi√ß√µes perigosas na implementa√ß√£o padr√£o</a></li>
<li><a href="../pt471876/index.html">PDU e Tudo-Tudo-Tudo: Distribui√ß√£o de Energia em Rack</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
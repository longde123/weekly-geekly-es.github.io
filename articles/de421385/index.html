<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤹🏾 ♉️ 🈷️ Lerne OpenGL. Lektion 5.10 - Umgebungsokklusion des Bildschirmbereichs 🐽 🚦 📴</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="SSAO 
 Das Thema Hintergrundbeleuchtung wurde von uns in einer Lektion über die Grundlagen der Beleuchtung angesprochen, jedoch nur nebenbei. Ich möch...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Lerne OpenGL. Lektion 5.10 - Umgebungsokklusion des Bildschirmbereichs</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/421385/"><img align="left" src="https://habrastorage.org/web/c9e/9b2/a3b/c9e9b2a3baf749ab8e2b385c6d93d966.png" alt="OGL3" width="300"><h2>  SSAO </h2><br>  Das Thema Hintergrundbeleuchtung wurde von uns in einer Lektion über die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Grundlagen der Beleuchtung</a> angesprochen, jedoch nur nebenbei.  Ich möchte Sie daran erinnern: Die Hintergrundkomponente der Beleuchtung ist im Wesentlichen ein konstanter Wert, der zu allen Berechnungen der Szenenbeleuchtung hinzugefügt wird, um den Prozess <i>der Lichtstreuung</i> zu simulieren.  In der realen Welt erfährt das Licht viele Reflexionen mit unterschiedlicher Intensität, was zu einer ebenso ungleichmäßigen Beleuchtung indirekt beleuchteter Teile der Szene führt.  Offensichtlich ist eine Fackel mit konstanter Intensität nicht sehr plausibel. <br><br>  Eine Art der ungefähren Berechnung der Schattierung durch indirekte Beleuchtung ist der <i>Umgebungsokklusionsalgorithmus (AO</i> ), der die Dämpfung der indirekten Beleuchtung in der Nähe von Ecken, Falten und anderen Oberflächenunregelmäßigkeiten simuliert.  Solche Elemente überlappen sich im Allgemeinen erheblich mit der angrenzenden Geometrie und lassen daher weniger Lichtstrahlen nach außen entweichen, wodurch diese Bereiche verdeckt werden. <br><br>  Nachfolgend finden Sie einen Vergleich des Renderns ohne und unter Verwendung des AO-Algorithmus.  Achten Sie darauf, wie die Intensität der Hintergrundbeleuchtung in der Nähe der Ecken der Wände und anderer scharfer Brüche in der Oberfläche abnimmt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6s/8z/kv/6s8zkvpob8nbgaails8mtfutgw8.png"></div><br>  Obwohl der Effekt nicht sehr auffällig ist, fügt das Vorhandensein des Effekts in der gesamten Szene Realismus hinzu, da durch kleine Details des Selbstschattierungseffekts eine zusätzliche Tiefenillusion entsteht. <br><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Inhalt</b> <div class="spoiler_text">  Teil 1. Erste Schritte <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Opengl</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fenstererstellung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hallo Fenster</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hallo Dreieck</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Shader</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Texturen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Transformationen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Koordinatensysteme</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kamera</a> </li></ol><br>  Teil 2. Grundbeleuchtung <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Farben</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Grundlagen der Beleuchtung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Material</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Texturkarten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lichtquellen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mehrere Lichtquellen</a> </li></ol><br>  Teil 3. Laden Sie 3D-Modelle herunter <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Assimp-Bibliothek</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mesh-Polygon-Klasse</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">3D-Modellklasse</a> </li></ol><br>  Teil 4. Erweiterte OpenGL-Funktionen <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tiefentest</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schablonentest</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Farbmischung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gesichter schneiden</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bildpuffer</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubische Karten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erweiterte Datenverarbeitung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erweiterte GLSL</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Geometrischer Shader</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Instanz</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Glätten</a> </li></ol><br>  Teil 5. Erweiterte Beleuchtung <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erweiterte Beleuchtung.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Blinn-Fong-Modell.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gammakorrektur</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schattenkarten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Omnidirektionale Schattenkarten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Normale Zuordnung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Parallaxenabbildung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HDR</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Blüte</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aufgeschobenes Rendern</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SSAO</a> </li></ol><br>  Teil 6. Züchterrechte <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Theorie</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Analytische Lichtquellen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">IBL</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Diffuse Bestrahlung.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">IBL</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spiegelbelichtung.</a> </li></ol><br></div></div><br>  Es ist erwähnenswert, dass die Algorithmen zur Berechnung von AO ziemlich ressourcenintensiv sind, da sie eine Analyse der umgebenden Geometrie erfordern.  In einer naiven Implementierung wäre es möglich, einfach an jedem Punkt der Oberfläche viele Strahlen zu emittieren und den Grad der Abschattung zu bestimmen. Dieser Ansatz erreicht jedoch sehr schnell die für interaktive Anwendungen akzeptable ressourcenintensive Grenze.  Glücklicherweise veröffentlichte Crytek 2007 ein Papier, in dem sein eigener Ansatz zur Implementierung des in der Release-Version von Crysis verwendeten <i>SSAO-</i> Algorithmus <i>(Screen-Space Ambient Occlusion</i> ) beschrieben wurde.  Der Ansatz berechnete den Grad der Abschattung im Bildschirmbereich, wobei nur der aktuelle Tiefenpuffer anstelle von realen Daten über die umgebende Geometrie verwendet wurde.  Eine solche Optimierung beschleunigte den Algorithmus im Vergleich zur Referenzimplementierung radikal und lieferte gleichzeitig meist plausible Ergebnisse, was diesen Ansatz der ungefähren Berechnung der Hintergrundschattierung zu einer Standard-De-facto-Industrie machte. <br><br>  Das Prinzip, auf dem der Algorithmus basiert, ist recht einfach: Für jedes Fragment eines Vollbild-Quad wird der <i>Okklusionsfaktor</i> basierend auf den Tiefenwerten der umgebenden Fragmente berechnet.  Der berechnete Schattierungskoeffizient wird dann verwendet, um die Intensität der Hintergrundbeleuchtung zu reduzieren (bis zum vollständigen Ausschluss).  Um einen Koeffizienten zu erhalten, müssen Tiefendaten von mehreren Proben aus dem das betreffende Fragment umgebenden sphärischen Bereich gesammelt und diese Tiefenwerte mit der Tiefe des betreffenden Fragments verglichen werden.  Die Anzahl der Proben mit einer Tiefe, die größer als das aktuelle Fragment ist, bestimmt direkt den Schattierungskoeffizienten.  Schauen Sie sich dieses Diagramm an: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/y5/yh/8o/y5yh8oeqvguchqopeu7nz0g-tsy.png"></div><br>  Hier liegt jeder graue Punkt innerhalb eines bestimmten geometrischen Objekts und trägt daher zum Wert des Schattierungskoeffizienten bei.  Je mehr Proben sich in der Geometrie der umgebenden Objekte befinden, desto geringer ist die Restintensität der Hintergrundschattierung in diesem Bereich. <br><br>  Offensichtlich hängt die Qualität und der Realismus des Effekts direkt von der Anzahl der entnommenen Proben ab.  Bei einer kleinen Anzahl von Abtastwerten nimmt die Genauigkeit des Algorithmus ab und führt aufgrund abrupter Übergänge zwischen Regionen mit sehr unterschiedlichen Schattierungskoeffizienten zum Auftreten eines <i>Streifen-</i> oder " <i>Streifen</i> " -Artefakts.  Eine große Anzahl von Samples beeinträchtigt einfach die Leistung.  Die Randomisierung des Kerns der Proben ermöglicht etwas ähnliche Ergebnisse, um die Anzahl der erforderlichen Proben geringfügig zu verringern.  Eine Neuorientierung durch Rotation eines Satzes von Abtastvektoren auf einen zufälligen Winkel ist impliziert.  Die Einführung der Zufälligkeit bringt jedoch sofort ein neues Problem in Form eines wahrnehmbaren Rauschmusters mit sich, das die Verwendung von Unschärfefiltern erfordert, um das Ergebnis zu glätten.  Nachfolgend finden Sie ein Beispiel für den Algorithmus (Autor - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">John Chapman</a> ) und seine typischen Probleme: Streifenbildung und Rauschmuster. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/r_/ay/l3/r_ayl3jjozsa6fyuni69ejkwpei.jpeg"></div><br>  Wie zu sehen ist, wird eine merkliche Streifenbildung aufgrund der geringen Anzahl von Proben durch Einführen einer Randomisierung der Orientierung der Proben gut entfernt. <br><br>  Cryteks spezifische SSAO-Implementierung hatte einen erkennbaren visuellen Stil.  Da Crytek-Spezialisten einen kugelförmigen Kern der Probe verwendeten, wirkte sich dies sogar auf flache Oberflächen wie Wände aus und machte sie schattiert, da die Hälfte des Volumens des Kerns der Probe unter die Geometrie getaucht war.  Unten sehen Sie einen Screenshot einer Szene aus Crysis in Graustufen, basierend auf dem Wert des Schattierungsfaktors.  Hier ist der Effekt von "Grauheit" deutlich sichtbar: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/j9/zr/r8/j9zrr81dluj-5eobuqcgst48om8.jpeg"></div><br>  Um diesen Effekt zu vermeiden, bewegen wir uns vom kugelförmigen Kern der Probe zu einer Halbkugel, die entlang der Normalen zur Oberfläche ausgerichtet ist: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/br/pf/3v/brpf3vfbmzd9pmna58ub5x7-age.png"></div><br>  Bei der Probenahme von einer solchen <i>normal ausgerichteten Halbkugel müssen</i> wir bei der Berechnung des Schattierungskoeffizienten keine Fragmente berücksichtigen, die unter der Oberfläche der angrenzenden Oberfläche liegen.  Dieser Ansatz beseitigt unnötige Schattierungen und führt im Allgemeinen zu realistischeren Ergebnissen.  Diese Lektion verwendet den Hemisphäre-Ansatz und etwas verfeinerten Code aus der brillanten SSAO-Lektion von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">John Chapman</a> . <br><br><h2>  Rohdatenpuffer </h2><br>  Die Berechnung des Schattierungsfaktors in jedem Fragment erfordert die Verfügbarkeit von Daten über die umgebende Geometrie.  Insbesondere benötigen wir folgende Daten: <br><br><ul><li>  Positionsvektor für jedes Fragment; </li><li>  Normaler Vektor für jedes Fragment; </li><li>  Diffuse Farbe für jedes Fragment; </li><li>  Der Kern der Probe </li><li>  Ein zufälliger Rotationsvektor für jedes Fragment, das bei der Neuorientierung des Probenkerns verwendet wird. </li></ul><br>  Mithilfe von Daten zu den Koordinaten des Fragments im Artenraum können wir die Halbkugel des Probenkerns entlang des im Artenraum für das aktuelle Fragment angegebenen Normalenvektors ausrichten.  Dann wird der resultierende Kern verwendet, um Proben mit verschiedenen Offsets aus einer Textur zu erstellen, die Daten auf den Koordinaten von Fragmenten speichert.  Wir machen viele Proben in jedem Fragment und vergleichen für jede Probe, die wir machen, seinen Tiefenwert mit dem Tiefenwert aus dem Fragmentkoordinatenpuffer, um das Ausmaß der Schattierung abzuschätzen.  Der resultierende Wert wird dann verwendet, um den Beitrag der Hintergrundkomponente bei der endgültigen Beleuchtungsberechnung zu begrenzen.  Mit einem fragmentweisen zufälligen Rotationsvektor können wir die erforderliche Anzahl von Proben erheblich reduzieren, um ein anständiges Ergebnis zu erzielen. Dies wird dann demonstriert. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wv/xo/aj/wvxoajroexwvjgq77n81-fjhats.png"></div><br>  Da SSAO ein im Bildschirmbereich realisierter Effekt ist, ist es möglich, eine direkte Berechnung durch Rendern eines Vollbild-Quad durchzuführen.  Dann haben wir aber keine Daten zur Geometrie der Szene.  Um diese Einschränkung zu umgehen, werden alle erforderlichen Informationen in der Textur gerendert, die später im SSAO-Shader verwendet werden, um auf geometrische und andere Informationen über die Szene zuzugreifen.  Wenn Sie diese Lektionen sorgfältig befolgt haben, sollten Sie im beschriebenen Ansatz bereits das Erscheinungsbild des Algorithmus für verzögerte Schattierung kennen.  Dies ist vor allem der Grund, warum der SSAO-Effekt als Native im Rendering mit verzögerter Schattierung angezeigt wird - schließlich sind Texturen, die Koordinaten und Normalen speichern, bereits im G-Puffer verfügbar. <br><br><blockquote>  In dieser Lektion wird der Effekt zusätzlich zu einer leicht vereinfachten Version des Codes aus der Lektion über <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verzögerte Beleuchtung</a> implementiert.  Wenn Sie sich noch nicht mit den Prinzipien der verzögerten Beleuchtung vertraut gemacht haben, empfehle ich Ihnen dringend, sich dieser Lektion zuzuwenden. <br></blockquote><br>  Da der Zugriff auf Fragmentinformationen über Koordinaten und Normalen aufgrund des G-Puffers bereits verfügbar sein sollte, ist der Fragment-Shader der Geometrieverarbeitungsstufe recht einfach: <br><br><pre><code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core layout (location = 0) out vec4 gPosition; layout (location = 1) out vec3 gNormal; layout (location = 2) out vec4 gAlbedoSpec; in vec2 TexCoords; in vec3 FragPos; in vec3 Normal; void main() { </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//        gPosition = FragPos; //       gNormal = normalize(Normal); //    -   gAlbedoSpec.rgb = vec3(0.95); }</span></span></span></span></code> </pre> <br>  Da der SSAO-Algorithmus eine Auswirkung auf den Bildschirmbereich hat und der Schattierungsfaktor basierend auf dem sichtbaren Bereich der Szene berechnet wird, ist es sinnvoll, Berechnungen im Ansichtsbereich durchzuführen.  In diesem Fall <i>speichert</i> die vom Vertex-Shader erhaltene <i>FragPos-</i> Variable die Position genau im Ansichtsfenster.  Es lohnt sich sicherzustellen, dass die Koordinaten und Normalen im G-Puffer im Ansichtsraum gespeichert sind, da alle weiteren Berechnungen darin durchgeführt werden. <br><br><blockquote>  Es besteht die Möglichkeit, den Positionsvektor nur auf der Grundlage einer bekannten Fragmenttiefe und einer bestimmten Menge mathematischer Magie wiederherzustellen, die beispielsweise in Matt Pettineos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Blog beschrieben wird</a> .  Dies erfordert natürlich einen hohen Rechenaufwand, macht jedoch das Speichern von Positionsdaten im G-Puffer überflüssig, was viel Videospeicher beansprucht.  Der Einfachheit halber werden wir diesen Ansatz jedoch dem persönlichen Studium überlassen. </blockquote><br>  Die <i>gPosition-</i> Farbpuffertextur ist wie folgt konfiguriert: <br><br><pre> <code class="cpp hljs">glGenTextures(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;gPosition); glBindTexture(GL_TEXTURE_2D, gPosition); glTexImage2D(GL_TEXTURE_2D, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB16F, SCR_WIDTH, SCR_HEIGHT, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB, GL_FLOAT, <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);</code> </pre> <br>  Diese Textur speichert die Koordinaten von Fragmenten und kann verwendet werden, um Tiefendaten für jeden Punkt aus dem Kern der Proben zu erhalten.  Ich stelle fest, dass die Textur ein Gleitkomma-Datenformat verwendet - dadurch können die Koordinaten von Fragmenten nicht auf das Intervall [0., 1.] reduziert werden.  <i>Beachten Sie auch</i> den Wiederholungsmodus - <i>GL_CLAMP_TO_EDGE</i> ist eingestellt.  Dies ist erforderlich, um die Möglichkeit auszuschließen, dass der Bildschirmbereich nicht absichtlich überabgetastet wird.  Wenn Sie über das Hauptintervall der Texturkoordinaten hinausgehen, erhalten Sie falsche Positions- und Tiefendaten. <br><br>  Als nächstes werden wir uns mit der Bildung eines halbkugelförmigen Kerns der Proben und der Schaffung einer Methode zur zufälligen Orientierung befassen. <br><br><h2>  Schaffung einer normal ausgerichteten Hemisphäre </h2><br>  Die Aufgabe besteht also darin, eine Reihe von Probenpunkten zu erstellen, die sich innerhalb einer Halbkugel befinden, die entlang der Normalen zur Oberfläche ausgerichtet ist.  Da die Erstellung eines Beispielkerns für alle möglichen Richtungen der Normalen rechnerisch nicht erreichbar ist, verwenden wir den Übergang zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tangentenraum</a> , in dem die Normalen immer als Vektor in Richtung der positiven Halbachse <i>Z dargestellt werden.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/br/pf/3v/brpf3vfbmzd9pmna58ub5x7-age.png"></div><br>  Unter der Annahme, dass der Radius der Halbkugel ein einzelner Prozess ist, sieht die Bildung eines Kerns einer Stichprobe von 64 Punkten folgendermaßen aus: <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//      0.0 - 1.0 std::uniform_real_distribution&lt;float&gt; randomFloats(0.0, 1.0); std::default_random_engine generator; std::vector&lt;glm::vec3&gt; ssaoKernel; for (unsigned int i = 0; i &lt; 64; ++i) { glm::vec3 sample( randomFloats(generator) * 2.0 - 1.0, randomFloats(generator) * 2.0 - 1.0, randomFloats(generator) ); sample = glm::normalize(sample); sample *= randomFloats(generator); float scale = (float)i / 64.0; ssaoKernel.push_back(sample); }</span></span></code> </pre> <br>  Hier wählen wir zufällig die <i>x-</i> und <i>y-</i> Koordinaten im Intervall [-1., 1.] und die <i>z-</i> Koordinate im Intervall [0., 1.] aus (wenn das Intervall das gleiche wie für <i>x</i> und <i>y ist</i> , würden wir einen sphärischen Kern erhalten Probenahme).  Die resultierenden Probenvektoren sind auf Halbkugeln beschränkt, da der Kern der Probe letztendlich entlang der Normalen zur Oberfläche ausgerichtet ist. <br><br>  Im Moment sind alle Stichprobenpunkte zufällig im Kern verteilt, aber aus Gründen der Qualität des Effekts sollten die Stichproben, die näher am Ursprung des Kernels liegen, einen größeren Beitrag zur Berechnung des Schattierungskoeffizienten leisten.  Dies kann durch Ändern der Verteilung der gebildeten Probenpunkte durch Erhöhen ihrer Dichte in der Nähe des Ursprungs realisiert werden.  Diese Aufgabe kann einfach mit der Beschleunigungsinterpolationsfunktion ausgeführt werden: <br><br><pre> <code class="cpp hljs">scale = lerp(<span class="hljs-number"><span class="hljs-number">0.1f</span></span>, <span class="hljs-number"><span class="hljs-number">1.0f</span></span>, scale * scale); sample *= scale; ssaoKernel.push_back(sample); }</code> </pre> <br>  Die Funktion <i>lerp ()</i> ist definiert als: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">lerp</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> a, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> b, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> f)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> a + f * (b - a); }</code> </pre> <br>  Ein solcher Trick ergibt eine modifizierte Verteilung, bei der die meisten Stichprobenpunkte nahe dem Ursprung des Kernels liegen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/h7/dy/xm/h7dyxm-1zerxg1krzbxszp7kzqi.png"></div><br>  Jeder der erhaltenen Probenvektoren wird verwendet, um die Koordinate des Fragments im Speziesraum zu verschieben, um Daten über die umgebende Geometrie zu erhalten.  Um bei der Arbeit im Ansichtsfenster anständige Ergebnisse zu erzielen, benötigen Sie möglicherweise eine beeindruckende Anzahl von Samples, die sich zwangsläufig auf die Leistung auswirken.  Die Einführung von pseudozufälligem Rauschen oder die Drehung der Abtastvektoren in jedem verarbeiteten Fragment verringert jedoch die erforderliche Anzahl von Abtastwerten mit vergleichbarer Qualität erheblich. <br><br><h2>  Zufällige Drehung des Probenkerns </h2><br>  Die Einführung einer Zufälligkeit bei der Verteilung der Punkte im Kern der Stichprobe kann daher die Anforderung an die Anzahl dieser Punkte erheblich verringern, um einen angemessenen Qualitätseffekt zu erzielen.  Es wäre möglich, einen zufälligen Rotationsvektor für jedes Fragment der Szene zu erstellen, aber der Speicher ist zu teuer.  Es ist effizienter, eine kleine Textur zu erstellen, die einen Satz zufälliger Rotationsvektoren enthält, und sie dann einfach mit dem Wiederholungsmodus <i>GL_REPEAT zu verwenden</i> . <br><br>  Erstellen Sie ein 4x4-Array und füllen Sie es mit zufälligen Rotationsvektoren, die entlang des Normalenvektors im Tangentenraum ausgerichtet sind: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;glm::vec3&gt; ssaoNoise; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; <span class="hljs-number"><span class="hljs-number">16</span></span>; i++) { glm::<span class="hljs-function"><span class="hljs-function">vec3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">noise</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( randomFloats(generator) * </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">2.0</span></span></span></span><span class="hljs-function"><span class="hljs-params"> - </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1.0</span></span></span></span><span class="hljs-function"><span class="hljs-params">, randomFloats(generator) * </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">2.0</span></span></span></span><span class="hljs-function"><span class="hljs-params"> - </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1.0</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.0f</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span></span>; ssaoNoise.push_back(noise); }</code> </pre> <br>  Da der Kern entlang der positiven Halbachse <i>Z</i> im Tangentenraum ausgerichtet ist, belassen wir die <i>z-</i> Komponente gleich Null - dies stellt eine Drehung nur um die <i>Z-</i> Achse sicher. <br><br>  Erstellen Sie als Nächstes eine 4x4-Textur und füllen Sie sie mit unserem Array von Rotationsvektoren.  <i>Stellen</i> Sie sicher, dass Sie den <i>GL_REPEAT-</i> Wiedergabemodus für <i>Texturkacheln verwenden</i> : <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> noiseTexture; glGenTextures(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;noiseTexture); glBindTexture(GL_TEXTURE_2D, noiseTexture); glTexImage2D(GL_TEXTURE_2D, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB16F, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB, GL_FLOAT, &amp;ssaoNoise[<span class="hljs-number"><span class="hljs-number">0</span></span>]); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);</code> </pre> <br>  Nun haben wir alle Daten, die für die direkte Implementierung des SSAO-Algorithmus erforderlich sind! <br><br><h2>  Shader SSAO </h2><br>  Für jedes Fragment eines Vollbild-Quad wird ein Effekt-Shader ausgeführt, der den Schattenkoeffizienten in jedem Fragment berechnet.  Da die Ergebnisse in einer anderen Rendering-Phase verwendet werden, in der die endgültige Beleuchtung erstellt wird, müssen Sie ein weiteres Framebuffer-Objekt erstellen, um das Ergebnis des Shaders zu speichern: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ssaoFBO; glGenFramebuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;ssaoFBO); glBindFramebuffer(GL_FRAMEBUFFER, ssaoFBO); <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ssaoColorBuffer; glGenTextures(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;ssaoColorBuffer); glBindTexture(GL_TEXTURE_2D, ssaoColorBuffer); glTexImage2D(GL_TEXTURE_2D, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RED, SCR_WIDTH, SCR_HEIGHT, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB, GL_FLOAT, <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, ssaoColorBuffer, <span class="hljs-number"><span class="hljs-number">0</span></span>);</code> </pre> <br>  Da das Ergebnis des Algorithmus die einzige reelle Zahl innerhalb von [0., 1.] ist, reicht es für die Speicherung aus, eine Textur mit der einzigen verfügbaren Komponente zu erstellen.  Deshalb wird <i>GL_RED</i> als internes Format für den <i>Farbpuffer</i> festgelegt. <br><br>  Im Allgemeinen sieht der Renderprozess der SSAO-Stufe ungefähr so ​​aus: <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//  :  G- glBindFramebuffer(GL_FRAMEBUFFER, gBuffer); [...] glBindFramebuffer(GL_FRAMEBUFFER, 0); //  G-      SSAO glBindFramebuffer(GL_FRAMEBUFFER, ssaoFBO); glClear(GL_COLOR_BUFFER_BIT); glActiveTexture(GL_TEXTURE0); glBindTexture(GL_TEXTURE_2D, gPosition); glActiveTexture(GL_TEXTURE1); glBindTexture(GL_TEXTURE_2D, gNormal); glActiveTexture(GL_TEXTURE2); glBindTexture(GL_TEXTURE_2D, noiseTexture); shaderSSAO.use(); SendKernelSamplesToShader(); shaderSSAO.setMat4("projection", projection); RenderQuad(); glBindFramebuffer(GL_FRAMEBUFFER, 0); //  :    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); shaderLightingPass.use(); [...] glActiveTexture(GL_TEXTURE3); glBindTexture(GL_TEXTURE_2D, ssaoColorBuffer); [...] RenderQuad();</span></span></code> </pre> <br>  Der <i>shaderSSAO-</i> Shader akzeptiert die benötigten G-Buffer-Texturen als Eingabe sowie die Rauschtextur und den Sample-Kern: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core out float FragColor; in vec2 TexCoords; uniform sampler2D gPosition; uniform sampler2D gNormal; uniform sampler2D texNoise; uniform vec3 samples[64]; uniform mat4 projection; </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//             //      1280x720 const vec2 noiseScale = vec2(1280.0/4.0, 720.0/4.0); void main() { [...] }</span></span></span></span></code> </pre> <br>  Beachten Sie die Variable <i>NoiseScale</i> .  Unsere kleine Textur mit Rauschen sollte über die gesamte Oberfläche des Bildschirms gekachelt werden. Da die <i>TexCoords-</i> Texturkoordinaten <i>jedoch</i> innerhalb von [0., 1.] liegen, geschieht dies nicht ohne unser Eingreifen.  Für diese Zwecke berechnen wir den Faktor für Texturkoordinaten, der sich als Verhältnis der Bildschirmgröße zur Größe der Rauschtextur ergibt: <br><br><pre> <code class="cpp hljs">vec3 fragPos = texture(gPosition, TexCoords).xyz; vec3 normal = texture(gNormal, TexCoords).rgb; vec3 randomVec = texture(texNoise, TexCoords * noiseScale).xyz;</code> </pre> <br>  Da wir beim Erstellen der <i>texNoise-</i> Rauschtextur den Wiederholungsmodus auf <i>GL_REPEAT gesetzt haben</i> , wird er jetzt auf der Bildschirmoberfläche viele Male wiederholt.  Mit <i>randomVec</i> , <i>fragPos</i> und <i>Normalwerten</i> können wir eine TBN-Transformationsmatrix vom Tangenten- zum <i>Artenraum</i> erstellen: <br><br><pre> <code class="cpp hljs">vec3 tangent = normalize(randomVec - normal * dot(randomVec, normal)); vec3 bitangent = cross(normal, tangent); mat3 TBN = mat3(tangent, bitangent, normal);</code> </pre> <br>  Mit dem Gram-Schmidt-Prozess erstellen wir eine orthogonale Basis, die in jedem Fragment basierend auf dem Zufallswert <i>randomVec</i> zufällig <i>geneigt ist</i> .  Ein wichtiger Punkt: Da es in diesem Fall für uns nicht wichtig ist, dass die TBN-Matrix genau entlang der Oberfläche des Dreiecks ausgerichtet ist (wie im Fall der Parallaxenabbildung, ca. Per.), Benötigen wir keine vorberechneten Tangenten- und Bi-Tangenten-Daten. <br><br>  Als nächstes gehen wir durch das Array des Probenkerns, übersetzen jeden Probenvektor vom Tangentenraum in den Speziesraum und erhalten seine Summe mit der aktuellen Position des Fragments.  Dann vergleichen wir den Tiefenwert der resultierenden Menge mit dem Tiefenwert, der durch Abtasten aus der entsprechenden G-Puffer-Textur erhalten wird. <br><br>  Während es verwirrend klingt, gehen wir die Schritte durch: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> occlusion = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; kernelSize; ++i) { <span class="hljs-comment"><span class="hljs-comment">//     vec3 sample = TBN * samples[i]; //      - sample = fragPos + sample * radius; [...] }</span></span></code> </pre> <br>  <i>KernelSize</i> und <i>Radius</i> sind hier Variablen, die die Eigenschaften des Effekts steuern.  In diesem Fall sind sie 64 bzw. 0,5.  Bei jeder Iteration übersetzen wir den Probenkernvektor in den Speziesraum.  Als nächstes addieren wir zum erhaltenen Wert der Verschiebung der Probe im Artenraum den Wert der Position des Fragments im Artenraum.  In diesem Fall wird der Versatzwert mit der Radiusvariablen multipliziert, die den Radius des Kerns der SSAO-Effektprobe steuert. <br><br>  Nach diesen Schritten sollten wir den resultierenden <i>Probenvektor</i> in den Bildschirmbereich konvertieren, damit wir aus der G-Puffer-Textur auswählen können, in der die Positionen und Tiefen von Fragmenten unter Verwendung des erhaltenen projizierten Werts gespeichert werden.  Da sich das <i>Beispiel</i> im Ansichtsfenster befindet, benötigen wir die Projektionsprojektionsmatrix: <br><br><pre> <code class="cpp hljs">vec4 offset = vec4(sample, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); offset = projection * offset; <span class="hljs-comment"><span class="hljs-comment">//     offset.xyz /= offset.w; //   offset.xyz = offset.xyz * 0.5 + 0.5; //    [0., 1.]</span></span></code> </pre> <br>  Nach der Konvertierung in den Clip-Bereich führen wir die Perspektiventeilung manuell durch, indem wir einfach die <i>xyz-</i> Komponenten durch die <i>w-</i> Komponente teilen.  Der resultierende Vektor in normalisierten Gerätekoordinaten ( <i>NDC</i> ) wird in das Werteintervall [0., 1.] übersetzt, damit er als Texturkoordinaten verwendet werden kann: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> sampleDepth = texture(gPosition, offset.xy).z;</code> </pre> <br>  Wir verwenden die <i>xy-</i> Komponenten des <i>Probenvektors</i> , um aus der Textur die Positionen des G-Puffers auszuwählen.  Wir erhalten den Tiefenwert ( <i>z-</i> Komponenten), der dem Probenvektor entspricht, wenn wir ihn von der Position des Beobachters aus betrachten (dies ist das erste nicht abgeschirmte sichtbare Fragment).  Wenn gleichzeitig die erhaltene Abtasttiefe größer als die gespeicherte Tiefe ist, erhöhen wir den Schattierungskoeffizienten: <br><br><pre> <code class="cpp hljs">occlusion += (sampleDepth &gt;= sample.z + bias ? <span class="hljs-number"><span class="hljs-number">1.0</span></span> : <span class="hljs-number"><span class="hljs-number">0.0</span></span>);</code> </pre> <br>  Beachten Sie den <i>Bias-</i> Offset, der zur ursprünglichen Fragmenttiefe hinzugefügt wird (im Beispiel auf 0,025 eingestellt).  Dieser Versatz ist nicht immer erforderlich, aber das Vorhandensein einer Variablen ermöglicht es Ihnen, das Aussehen des SSAO-Effekts zu steuern und in bestimmten Situationen auch Probleme mit Welligkeiten in schattierten Bereichen zu beseitigen. <br><br>  Dies ist jedoch noch nicht alles, da eine solche Implementierung zu auffälligen Artefakten führt.  Es manifestiert sich in Fällen, in denen ein Fragment betrachtet wird, das nahe dem Rand einer bestimmten Oberfläche liegt.  In solchen Situationen erfasst der Algorithmus beim Vergleich der Tiefen unweigerlich die Tiefen von Oberflächen, die sehr weit hinter der betrachteten liegen können.  An diesen Stellen erhöht der Algorithmus fälschlicherweise den Grad der Abschattung erheblich, wodurch an den Rändern von Objekten wahrnehmbare dunkle Lichthöfe entstehen.  Das Artefakt wird durch Einführung einer zusätzlichen Entfernungsprüfung behandelt (ein Beispiel von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">John Chapman</a> ): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/zv/yv/eq/zvyveqh3zc_rjcy6fo-z8d76eme.png"></div><br>  Die Prüfung begrenzt den Beitrag zum Schattierungskoeffizienten nur für Tiefenwerte, die innerhalb des Radius der Probe liegen: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> rangeCheck = smoothstep(<span class="hljs-number"><span class="hljs-number">0.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>, radius / <span class="hljs-built_in"><span class="hljs-built_in">abs</span></span>(fragPos.z - sampleDepth)); occlusion += (sampleDepth &gt;= sample.z + bias ? <span class="hljs-number"><span class="hljs-number">1.0</span></span> : <span class="hljs-number"><span class="hljs-number">0.0</span></span>) * rangeCheck;</code> </pre> <br>  Wir verwenden auch die GLSL-Funktion <i>glattstep ()</i> , die eine reibungslose Interpolation des dritten Parameters zwischen dem ersten und dem zweiten implementiert.  Gleichzeitig wird 0 zurückgegeben, wenn der dritte Parameter kleiner oder gleich dem ersten ist, oder 1, wenn der dritte Parameter größer oder gleich dem zweiten ist.  Wenn der Tiefenunterschied innerhalb des <i>Radius liegt</i> , wird sein Wert im Intervall [0., 1.] gemäß dieser Kurve gleichmäßig geglättet: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jq/9h/p4/jq9hp4-yun_sc277m6pslbjyin0.png"></div><br>  Wenn wir bei der Überprüfung der Tiefe klare Grenzen verwenden würden, würden Artefakte in Form scharfer Grenzen an den Stellen hinzugefügt, an denen die Werte der Tiefenunterschiede außerhalb der Grenzen des <i>Radius liegen</i> . <br><br>  Mit dem letzten Schliff normalisieren wir den Wert des Schattierungskoeffizienten anhand der Größe des Probenkerns und zeichnen das Ergebnis auf.  Wir invertieren den Endwert auch, indem wir ihn von der Einheit subtrahieren, sodass Sie den Endwert direkt verwenden können, um die Hintergrundkomponente der Beleuchtung ohne zusätzliche Schritte zu modulieren: <br><br><pre> <code class="cpp hljs">} occlusion = <span class="hljs-number"><span class="hljs-number">1.0</span></span> - (occlusion / kernelSize); FragColor = occlusion;</code> </pre> <br>  Für eine Szene mit einem uns vertrauten liegenden Nanosuit ergibt die Ausführung des SSAO-Shaders die folgende Textur: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-z/a4/fx/-za4fxhsbref6easc-cgxnsp94q.png"></div><br>  Wie Sie sehen können, erzeugt der Effekt der Hintergrundschattierung eine gute Illusion von Tiefe.  Nur das Ausgabebild des Shaders ermöglicht es Ihnen bereits, die Details des Kostüms zu unterscheiden und sicherzustellen, dass es wirklich auf dem Boden liegt und nicht in einiger Entfernung davon schwebt. <br><br>  Trotzdem ist der Effekt alles andere als ideal, da das durch die Textur zufälliger Rotationsvektoren eingeführte Rauschmuster leicht erkennbar ist.  Um das Ergebnis der SSAO-Berechnung zu glätten, wenden wir einen Unschärfefilter an. <br><br><h2>  Hintergrundschattierung verwischen </h2><br>  Nach dem Erstellen des SSAO-Ergebnisses und vor dem endgültigen Mischen der Beleuchtung muss die Textur verwischt werden, in der Daten zum Schattierungskoeffizienten gespeichert sind.  Dazu haben wir einen weiteren Framebuffer: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ssaoBlurFBO, ssaoColorBufferBlur; glGenFramebuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;ssaoBlurFBO); glBindFramebuffer(GL_FRAMEBUFFER, ssaoBlurFBO); glGenTextures(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;ssaoColorBufferBlur); glBindTexture(GL_TEXTURE_2D, ssaoColorBufferBlur); glTexImage2D(GL_TEXTURE_2D, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RED, SCR_WIDTH, SCR_HEIGHT, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB, GL_FLOAT, <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, ssaoColorBufferBlur, <span class="hljs-number"><span class="hljs-number">0</span></span>);</code> </pre> <br>  Das Kacheln einer Rauschtextur im Bildschirmbereich bietet genau definierte Zufälligkeitseigenschaften, die Sie beim Erstellen eines Unschärfefilters zu Ihrem Vorteil nutzen können: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core out float FragColor; in vec2 TexCoords; uniform sampler2D ssaoInput; void main() { vec2 texelSize = 1.0 / vec2(textureSize(ssaoInput, 0)); float result = 0.0; for (int x = -2; x &lt; 2; ++x) { for (int y = -2; y &lt; 2; ++y) { vec2 offset = vec2(float(x), float(y)) * texelSize; result += texture(ssaoInput, TexCoords + offset).r; } } FragColor = result / (4.0 * 4.0); }</span></span></code> </pre> <br>  Der Shader übergeht einfach Texel der SSAO-Textur mit einem Versatz von -2 bis +2, was der tatsächlichen Größe der Rauschtextur entspricht.  Der Offset entspricht der exakten Größe eines Texels: Für die Berechnung wird die Funktion texturSize <i>()</i> verwendet, die <i>vec2</i> mit den Abmessungen der angegebenen Textur zurückgibt.  T.O.  Der Shader mittelt einfach die in der Textur gespeicherten Ergebnisse, wodurch eine schnelle und ziemlich effektive Unschärfe entsteht: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/5p/0g/i7/5p0gi7qn_v5w738uyindxexally.png"></div><br>  Insgesamt haben wir für jedes Fragment auf dem Bildschirm eine Textur mit Hintergrundschattierungsdaten - alles ist bereit für die Phase der endgültigen Bildreduzierung! <br><br><h2>  Hintergrundschattierung anwenden </h2><br>  Der Schritt der Anwendung des Schattierungskoeffizienten bei der endgültigen Berechnung der Beleuchtung ist überraschend einfach: Für jedes Fragment reicht es aus, den Wert der Hintergrundkomponente der Lichtquelle einfach mit dem Schattierungskoeffizienten aus der vorbereiteten Textur zu multiplizieren.  Sie können einen vorgefertigten Shader mit dem Blinn-Fong-Modell aus der Lektion über <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verzögerte Schattierung nehmen</a> und ein wenig korrigieren: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core out vec4 FragColor; in vec2 TexCoords; uniform sampler2D gPosition; uniform sampler2D gNormal; uniform sampler2D gAlbedo; uniform sampler2D ssao; struct Light { vec3 Position; vec3 Color; float Linear; float Quadratic; float Radius; }; uniform Light light; void main() { </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//    G- vec3 FragPos = texture(gPosition, TexCoords).rgb; vec3 Normal = texture(gNormal, TexCoords).rgb; vec3 Diffuse = texture(gAlbedo, TexCoords).rgb; float AmbientOcclusion = texture(ssao, TexCoords).r; //   -    //   :   -  vec3 ambient = vec3(0.3 * Diffuse * AmbientOcclusion); vec3 lighting = ambient; //    (0, 0, 0)   - vec3 viewDir = normalize(-FragPos); //   vec3 lightDir = normalize(light.Position - FragPos); vec3 diffuse = max(dot(Normal, lightDir), 0.0) * Diffuse * light.Color; //   vec3 halfwayDir = normalize(lightDir + viewDir); float spec = pow(max(dot(Normal, halfwayDir), 0.0), 8.0); vec3 specular = light.Color * spec; //   float dist = length(light.Position - FragPos); float attenuation = 1.0 / (1.0 + light.Linear * dist + light.Quadratic * dist * dist); diffuse *= attenuation; specular *= attenuation; lighting += diffuse + specular; FragColor = vec4(lighting, 1.0); }</span></span></span></span></code> </pre> <br>  Es gibt nur zwei wesentliche Änderungen: den Übergang zu Berechnungen im Ansichtsfenster und die Multiplikation der Hintergrundbeleuchtungskomponente mit dem Wert von <i>AmbientOcclusion</i> .  Ein Beispiel für eine Szene mit einem einzelnen blauen Punktlicht: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/bz/8_/1i/bz8_1in-othscilg_udfyscghg0.png"></div><br>  Der vollständige Quellcode ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br>  Die Manifestation des SSAO-Effekts hängt stark von Parametern wie <i>KernelSize</i> , <i>Radius</i> und <i>Bias ab</i> . Oft ist es für den Künstler selbstverständlich, einen bestimmten Ort / eine bestimmte Szene zu bestimmen.  Es gibt keine „besten“ und universellen Kombinationen von Parametern: Für einige Szenen ist ein kleiner Radius des Probenkerns gut, während andere vom vergrößerten Radius und der Anzahl der Proben profitieren.  In diesem Beispiel werden 64 Beispielpunkte verwendet, was offen gesagt redundant ist. Sie können den Code jedoch jederzeit bearbeiten und sehen, was mit einer geringeren Anzahl von Stichproben passiert. <br><br>  Zusätzlich zu den aufgelisteten Uniformen, die für die Einstellung des Effekts verantwortlich sind, besteht die Möglichkeit, den Schweregrad des Hintergrundschattierungseffekts explizit zu steuern.  Dazu reicht es aus, den Koeffizienten auf einen Grad anzuheben, der von einer anderen Uniform gesteuert wird: <br><br><pre> <code class="cpp hljs">occlusion = <span class="hljs-number"><span class="hljs-number">1.0</span></span> - (occlusion / kernelSize); FragColor = <span class="hljs-built_in"><span class="hljs-built_in">pow</span></span>(occlusion, power);</code> </pre> <br>  Ich rate Ihnen, einige Zeit mit den Einstellungen des Spiels zu verbringen, da dies ein besseres Verständnis der Art der Änderungen im endgültigen Bild ermöglicht. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zusammenfassend lässt sich sagen, dass der visuelle Effekt der Anwendung von SSAO zwar eher subtil ist, in Szenen mit gut platzierter Beleuchtung jedoch zweifellos einen spürbaren Teil des Realismus ausmacht. </font><font style="vertical-align: inherit;">Ein solches Werkzeug in Ihrem Arsenal zu haben, ist sicherlich wertvoll.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Zusätzliche Ressourcen </font></font></h2><br><ol><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SSAO-Tutorial</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Ein ausgezeichneter Unterrichtsartikel von John Chapman, auf dessen Grundlage der Code für diese Lektion erstellt wird.</font></font></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kennen Sie Ihre SSAO-Artefakte</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Ein sehr wertvoller Artikel, der nicht nur die dringendsten Probleme mit der SSAO-Qualität aufzeigt, sondern auch Möglichkeiten, sie zu lösen. </font><font style="vertical-align: inherit;">Empfohlene Lektüre.</font></font></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SSAO mit</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tiefenrekonstruktion: Nachtrag zur wichtigsten SSAO-Lektion von OGLDev über eine häufig verwendete Technik zum Wiederherstellen von Fragmentkoordinaten basierend auf der Tiefe. </font><font style="vertical-align: inherit;">Die Bedeutung dieses Ansatzes beruht auf den erheblichen Speichereinsparungen, da keine Positionen im G-Puffer gespeichert werden müssen. </font><font style="vertical-align: inherit;">Der Ansatz ist so universell, dass er für SSAO gilt, sofern.</font></font></li></ol><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PS</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : Wir haben ein </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Telegramm Conf</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> für die Koordination der Überweisungen. </font><font style="vertical-align: inherit;">Wenn Sie ernsthaft bei der Übersetzung helfen möchten, sind Sie herzlich willkommen!</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de421385/">https://habr.com/ru/post/de421385/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de421375/index.html">Wie Unsicherheit den Handel tötet</a></li>
<li><a href="../de421377/index.html">7 Missverständnisse eines unerfahrenen Projektmanagers in Gamedev</a></li>
<li><a href="../de421379/index.html">Intel toxische Kultur</a></li>
<li><a href="../de421381/index.html">Kostenloser Kurs für Cisco ASA Administrator</a></li>
<li><a href="../de421383/index.html">Epic Growth Conference Herbst 2018 - Produktmarketingkonferenz in Moskau</a></li>
<li><a href="../de421387/index.html">Interview mit Lennart Pottering über Linux Piter über Änderungen in Linux, über systemd und warum Sie an Konferenzen teilnehmen</a></li>
<li><a href="../de421389/index.html">Gewaltenteilung in Zimbra</a></li>
<li><a href="../de421391/index.html">HackThings - ein großer Hackathon im Internet der Dinge vom 7. bis 9. September in Skoltech</a></li>
<li><a href="../de421393/index.html">Verlassener Mailchimp Basket: Ein Leitfaden für die Faulen</a></li>
<li><a href="../de421395/index.html">Bericht des Club of Rome 2018, Kapitel 3.7: „Klima: gute Nachrichten, aber große Probleme“</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
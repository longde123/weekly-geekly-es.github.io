<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêä üß† üë©üèª‚Äç‚öïÔ∏è Aprendizado de m√°quina e desenvolvimento m√≥vel üôçüèΩ üè• üì≤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Como regra, um cientista de dados tem uma vaga id√©ia de desenvolvimento m√≥vel, e os desenvolvedores de aplicativos m√≥veis n√£o se envolvem no aprendiza...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aprendizado de m√°quina e desenvolvimento m√≥vel</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/416477/">  Como regra, um cientista de dados tem uma vaga id√©ia de desenvolvimento m√≥vel, e os desenvolvedores de aplicativos m√≥veis n√£o se envolvem no aprendizado de m√°quina.  <strong>Andrei Volodin</strong> , engenheiro da Prisma AI, mora na jun√ß√£o desses dois mundos e disse ao podcast do Podlodka o que √©. <br><br>  Aproveitando o momento, Stas Tsyganov (Tutu.ru) e Gleb Novik (Tinkoff Bank), em primeiro lugar, deixaram claro de uma vez por todas que <strong>ningu√©m est√° treinando redes neurais em dispositivos m√≥veis</strong> .  E tamb√©m descobri que no aprendizado de m√°quina, infelizmente, n√£o h√° m√°gicos;  discutiram t√©cnicas modernas como <strong>aprendizado profundo, aprendizado por refor√ßo</strong> e redes de c√°psulas. <br><br>  Como resultado, como Podlodka √© um programa de √°udio sobre desenvolvimento m√≥vel, eles foram at√© ela e descobriram como tudo funciona em dispositivos m√≥veis. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fw/ph/db/fwphdbn4sxovfbminez_irgn6pm.jpeg"></div><br>  A seguir, a vers√£o em texto desta conversa e a entrada do podcast est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><a name="habracut"></a><br><h1>  Sobre Andrei Volodin, cocos2d e Fiber2d <br></h1><br>  GLEB: Por favor, conte-nos um pouco sobre voc√™.  O que esta fazendo <br><br>  ANDREW: Sou desenvolvedor m√≥vel, mas fa√ßo muito pouco no desenvolvimento cl√°ssico do iOS.  Minhas responsabilidades praticamente n√£o incluem trabalhar com o UIKit.  Eu sou o desenvolvedor principal do popular mecanismo de jogo Cocos2d no GitHub.  No momento, sou engenheiro de GPU na Prisma.  Minhas responsabilidades incluem a integra√ß√£o de redes neurais em placas de v√≠deo e o trabalho com realidade aumentada, em particular, com o kit VR. <br><br>  GLEB: Legal!  Especialmente interessante sobre o cocos2d.  At√© onde eu sei, esse quadro apareceu h√° muito tempo. <br><br>  ANDREW: Sim, por volta de 2009. <br><br>  GLEB: Voc√™ usou desde o come√ßo? <br><br>  ANDREW: N√£o.  Eu me tornei o principal desenvolvedor apenas em 2015.  Antes disso, eu era um colaborador do Core.  Apportable, que financiou o desenvolvimento, faliu, as pessoas que receberam o dinheiro para o desenvolvimento foram embora, e eu me tornei o l√≠der.  Agora sou administrador do f√≥rum, ajudando os novatos com alguns problemas, as √∫ltimas vers√µes foram lan√ßadas por mim.  Ou seja, eu sou o principal mantenedor no momento. <br><br>  GLEB: Mas o cocos2d ainda est√° vivo? <br><br>  ANDREW: Provavelmente n√£o, principalmente devido ao fato de estar escrito em Objective-C, e h√° muito legado.  Por exemplo, eu apoio meus brinquedos antigos escritos com seu uso, outros desenvolvedores - meus projetos legados.  Dos motores atuais, voc√™ pode ouvir sobre o Fiber2d.  Este tamb√©m √© o meu projeto. <br><br>  O Fiber2d √© o primeiro mecanismo de jogo Swift a ser portado para o Android.  Lan√ßamos um jogo escrito inteiramente em Swift no iOS e no Android.  Tamb√©m sobre isso pode ser encontrado no Github.  Este √© o pr√≥ximo marco no desenvolvimento da comunidade cocos2d. <br><br><h1>  Sobre o aprendizado de m√°quina nos dedos <br></h1><br>  GLEB: Vamos come√ßar a avan√ßar gradualmente em dire√ß√£o ao nosso t√≥pico hoje.  Hoje falaremos <strong>sobre aprendizado de m√°quina e tudo ao seu redor</strong> - conectado e desconectado com telefones celulares.  Primeiro, vamos descobrir do que se trata o aprendizado de m√°quina.  Vamos tentar explicar o m√°ximo poss√≠vel nos dedos, porque nem todos os desenvolvedores de dispositivos m√≥veis est√£o familiarizados com isso.  Voc√™ pode nos dizer o que √©? <br><br>  ANDREW: Com base na defini√ß√£o cl√°ssica, o <strong>aprendizado de m√°quina √© uma pesquisa de padr√µes em um conjunto de dados</strong> .  Um exemplo cl√°ssico s√£o as redes neurais, que agora s√£o muito populares.  Entre eles, existem redes relacionadas √† classifica√ß√£o.  Um exemplo simples da tarefa de classifica√ß√£o √© determinar o que √© mostrado na figura: existe algum tipo de imagem e queremos entender o que √©: um cachorro, um gato ou outra coisa. <br><br>  Escrever isso com c√≥digo padr√£o √© muito dif√≠cil, porque n√£o est√° claro como fazer isso.  Portanto, modelos matem√°ticos s√£o usados, chamados de aprendizado de m√°quina.  Eles se baseiam no fato de que certas leis s√£o extra√≠das de um grande n√∫mero de exemplos e, usando essas leis, √© poss√≠vel fazer previs√µes com certa precis√£o em novos exemplos que n√£o estavam no conjunto de dados original.  Isto √©, em poucas palavras. <br><br>  GLEB: Conseq√ºentemente, est√° aprendendo uma hist√≥ria sobre a mudan√ßa de um modelo usando um conjunto de dados de treinamento? <br><br>  ANDREW: Durante o treinamento, o modelo, em regra, permanece constante.  Ou seja, voc√™ escolhe algum tipo de arquitetura e aprende.  Se tomarmos, por exemplo, redes neurais, que n√£o se limitam a todo aprendizado de m√°quina, inicialmente, grosso modo, todos os pesos s√£o zeros ou outros valores id√™nticos.  √Ä medida que alimentamos nossos dados para a estrutura de aprendizado, os pesos mudam um pouco a cada novo exemplo e, no final, s√£o despejados em uma m√°quina treinada. <br><br>  STAS: O objetivo final deste modelo √© fornecer rapidamente alguns dados que n√£o s√£o da amostra de treinamento, obter o resultado rapidamente? <br><br>  ANDREW: Sim, mas n√£o se trata apenas de velocidade.  Por exemplo, algumas tarefas n√£o puderam ser resolvidas de maneira diferente - digamos, o exemplo de classifica√ß√£o √© muito trivial.  Antes do lan√ßamento das redes de classifica√ß√£o, n√£o havia solu√ß√µes para entender o que √© mostrado na figura.  Ou seja, em algumas √°reas isso √© uma tecnologia diretamente revolucion√°ria. <br><br><h1>  Sobre trabalho manual e aprendizado de m√°quina <br></h1><br>  STAS: Recentemente, contei √† minha av√≥ o que √© aprendizado de m√°quina.  Ela inicialmente pensou que o aprendizado de m√°quina √© quando uma m√°quina ensina algu√©m.  Comecei a explicar a ela que, de fato, estamos tentando ensinar a m√°quina para que ela execute algum tipo de tarefa. <br><br>  Apresentei os problemas que o aprendizado de m√°quina resolve.  A maioria deles, antes do acionamento do aprendizado de m√°quina, era realizada por pessoas.  Al√©m disso, esse trabalho n√£o foi considerado pouco qualificado, mas n√£o muito tecnol√≥gico, digamos assim.  Essas s√£o as opera√ß√µes mais simples que uma pessoa pode executar em grande parte.  Voc√™ consegue imaginar isso? <br><br>  ANDREW: Isso tamb√©m pode ser dito.  De fato, agora esse trabalho ainda √© necess√°rio, mas apenas para preparar conjuntos de dados para o aprendizado de m√°quina.  De fato, em algumas √°reas, por exemplo, na medicina, o aprendizado de m√°quina torna poss√≠vel suavizar um pouco as tarefas rotineiras e facilitar um pouco o processo.  Mas nem sempre.  Eu n√£o diria que o aprendizado de m√°quina se concentra em facilitar o trabalho burro.  √Äs vezes, faz um trabalho bastante intelectual. <br><br>  STAS: Voc√™ pode dar um exemplo desse trabalho intelectual? <br><br>  ANDREW: Por exemplo, nosso aplicativo Prisma - muitos provavelmente o usaram (isso n√£o √© um an√∫ncio!) N√£o se pode dizer que esse √© um trabalho intelectual e as pessoas geralmente redesenham a imagem em imagens, e a rede neural faz isso - voc√™ fornece uma imagem normal e <strong>obt√©m algo novo</strong> .  Al√©m disso, pode-se argumentar se √© bonito ou n√£o, mas o fato √© indiscut√≠vel de que √© algo que uma pessoa n√£o pode fazer ou leva uma quantidade enorme de tempo. <br><br><h1>  Sobre a hist√≥ria <br></h1><br>  GLEB: Sim, acho que este √© um √≥timo exemplo.  Provavelmente vale a pena dar uma olhada na hist√≥ria.  H√° quanto tempo esse t√≥pico √© desenvolvido?  Parece-me que quase desde o in√≠cio da programa√ß√£o, h√° pelo menos muito, muito tempo. <br><br>  ANDREW: Sim, em geral, a maioria dos conceitos agora aplicados j√° foi desenvolvida nos anos 90.  Naturalmente, novos algoritmos surgiram e a qualidade dos algoritmos ent√£o melhorou.  E embora haja a sensa√ß√£o de que um interesse repentino no aprendizado de m√°quina surgiu do nada, na verdade, as pessoas se interessam por isso h√° muito tempo. <br><br>  O progresso nos est√°gios iniciais deveu-se ao fato de serem modelos matem√°ticos, e a matem√°tica h√° muito se estabiliza em termos de descobertas. <br><br>  A explos√£o atual se deve apenas ao fato de <strong>as capacidades de ferro ao nosso redor terem aumentado significativamente</strong> , principalmente devido ao uso de placas de v√≠deo.  Devido ao fato de hoje sermos capazes de fazer uma computa√ß√£o paralela enorme, surgiram novas tecnologias - aprendizado de m√°quina, criptomoeda etc. <br><br>  Na maioria das vezes, o interesse atual e geralmente a onda atual est√£o relacionados ao fato de que <strong>isso s√≥ se tornou poss√≠vel</strong> .  Esses c√°lculos poderiam ser feitos mais cedo, mas catastroficamente longos.  Agora leva um tempo bastante razo√°vel e todos come√ßaram a us√°-lo. <br><br><h1>  Sobre ferro <br></h1><br>  STAS: Atualmente, estou fazendo um curso e, inclusive, preciso treinar todos os tipos de modelos.  Treino alguns deles no meu MacBook em funcionamento.  Sim, em alguns casos, voc√™ precisa esperar, talvez 5 minutos, e os modelos n√£o s√£o os melhores, a precis√£o m√©dia √© de cerca de 85%, mas o principal √© que eles funcionam.  √â claro que na batalha voc√™ deseja ter essa porcentagem melhor e talvez para produ√ß√£o n√£o seja muito adequado. <br><br>  ANDREW: Sim, esses modelos provavelmente n√£o s√£o muito interessantes.  Provavelmente, isso se deve √†s previs√µes mais simples e assim por diante.  Na realidade, por exemplo, uma amostra de treinamento pode pesar 90 GB e tudo isso pode levar uma semana para aprender.  Empresas como a Nvidia se orgulham de lan√ßar uma nova placa gr√°fica Tesla especial e voc√™ pode treinar o Inception V3 em 24 horas!  Isso √© considerado um avan√ßo direto, porque antes levava v√°rias semanas. <br><br>  <strong>Quanto mais conjuntos de dados e mais complexa a estrutura do modelo, mais tempo leva para aprender</strong> .  Mas o desempenho n√£o √© o √∫nico problema.  Em princ√≠pio, se voc√™ realmente precisar, pode esperar um m√™s.  O problema est√° relacionado √† infer√™ncia - como aplicar esta rede neural posteriormente.  √â necess√°rio que durante o seu uso tamb√©m mostre bons resultados em termos de desempenho. <br><br>  STAS: Porque, em particular, quero que tudo funcione em dispositivos m√≥veis e trabalhe rapidamente. <br><br>  ANDREW: Eu n√£o acho que inicialmente ele come√ßou a se desenvolver com o objetivo de trabalhar em aplicativos m√≥veis.  Esse boom come√ßou em algum lugar em 2011 e, mesmo assim, essas foram as solu√ß√µes de desktop.  Mas agora o verdadeiro interesse da comunidade √© apoiado pelo fato de que nos iPhones, inclusive, tornou-se poss√≠vel lan√ßar redes que funcionam em tempo real. <br><br>  GLEB: Stas, voc√™ disse que o resultado final depende da pot√™ncia da sua placa de v√≠deo e do sistema em geral.  Ou seja, n√£o funciona de outra maneira? <br><br>  ANDREW: N√£o √© assim, mas n√£o tenho certeza de que o modelo ser√° treinado em uma m√°quina de baixa pot√™ncia. <br><br>  GLEB: A prop√≥sito, lembro-me de cinco anos atr√°s, quando houve apenas um boom nas redes neurais, nossos professores disseram que tudo que √© novo √© apenas um bom e velho esquecimento.  Tudo j√° estava nos anos 70 e 80 e n√£o deu certo, desde ent√£o n√£o deu certo.  Provavelmente, eles ainda estavam errados. <br><br>  ANDREW: Sim.  Para algumas tarefas, o aprendizado de m√°quina agora √© muito dif√≠cil.  Objetivamente, eles podem funcionar. <br><br><h1>  Sobre o aprendizado profundo <br></h1><br>  GLEB: Existe uma coisa t√£o na moda - aprendizado profundo.  Qual √© a diferen√ßa do que falamos sobre isso? <br><br>  ANDREW: Eu n√£o diria que existem diferen√ßas.  Existem apenas alguns subconjuntos de aprendizado de m√°quina, e h√° um grande n√∫mero deles.  Voc√™ precisa entender que o que √© chamado de <strong>aprendizado profundo √© a parte do aprendizado de m√°quina que √© comumente referida como redes neurais</strong> .  √â chamado de profundo porque existem muitas camadas nas redes neurais e, quanto mais camadas, mais profunda √© a rede neural.  Disto veio o nome. <br><br>  Mas existem outros tipos de aprendizado de m√°quina.  Por exemplo, o aprendizado de m√°quina baseado em √°rvore tem sido usado com sucesso no rastreamento de faces at√© agora, porque √© muito mais r√°pido que os neur√¥nios.  Tamb√©m √© usado para classifica√ß√£o, exibi√ß√£o de an√∫ncios e muito mais. <br><br>  Ou seja, o aprendizado profundo n√£o √© outra coisa.  Na verdade, esse √© um subconjunto de aprendizado de m√°quina que inclui uma tonelada de tudo.  Apenas o aprendizado profundo tornou-se o mais popular hoje. <br><br><h1>  Sobre a teoria das redes neurais <br></h1><br>  STAS: Eu queria falar um pouco sobre a teoria das redes neurais, vou tentar mais facilmente.  Voc√™ disse que eles t√™m muitas camadas.  Em teoria, se tivermos uma camada e houver alguns objetos localizados no plano, com a ajuda de uma camada, podemos realmente dividir esse plano em duas partes, certo? <br><br>  ANDREW: N√£o, na verdade n√£o. <br><br>  STAS: O que nos d√° um grande n√∫mero de camadas, se nos dedos? <br><br>  ANDREW: O que √© uma rede neural?  Vamos esclarecer.  Esta √© apenas uma fun√ß√£o matem√°tica que aceita um conjunto de n√∫meros como entrada e tamb√©m fornece um conjunto de n√∫meros como sa√≠da - √© tudo. <br><br>  O que tem dentro?  Agora, as mais populares s√£o as redes convolucionais nas quais a convolu√ß√£o ocorre - existem simplesmente muitas multiplica√ß√µes de matrizes, os resultados s√£o somados, essas opera√ß√µes s√£o realizadas em cada camada.  Al√©m disso, entre as camadas, h√° a chamada ativa√ß√£o, que apenas permite que as redes neurais sejam profundas. <br><br>  Como a combina√ß√£o de transforma√ß√µes lineares √© uma transforma√ß√£o linear, ap√≥s fazer 10 camadas lineares, elas ainda podem ser representadas como uma camada linear.  Para que as camadas n√£o colapsem, entre elas existem certas a√ß√µes matem√°ticas que tornam a fun√ß√£o n√£o linear.  Isso √© necess√°rio para aumentar o n√∫mero de par√¢metros. <br><br>  Grosso modo, uma rede neural √© apenas uma enorme variedade de n√∫meros, que de alguma forma se aplicam aos nossos dados, por exemplo, a uma imagem.  Mas uma imagem - tamb√©m um conjunto de n√∫meros - √© apenas uma s√©rie de pixels.  Quando treinamos a rede, consideramos, por exemplo, 15 milh√µes de par√¢metros (cada n√∫mero √© um par√¢metro separado), que pode ser ligeiramente deslocado um pouco para a esquerda, um pouco para a direita com a ajuda de algumas heur√≠sticas.  Gra√ßas a um n√∫mero t√£o grande de par√¢metros, s√£o obtidos resultados interessantes. <br><br>  √â necess√°rio um treinamento aprofundado precisamente para que haja muitos desses par√¢metros e tudo n√£o se reduz a uma camada. <br><br>  GLEB: Parece mais ou menos claro. <br><br>  ANDREW: O aprendizado profundo √© um subconjunto do aprendizado de m√°quina.  Mas, por alguma raz√£o, surgiu o hype sobre esse assunto - especialmente h√° algum tempo, devido a todas as falhas, acho que voc√™ pode ouvir sobre o aprendizado profundo.  N√£o sei se √© justificado ou n√£o. <br><br>  GLEB: Eu acho que essa popularidade se deve ao fato de dar resultados impressionantes. <br><br><h1>  Sobre tarefas <br></h1><br>  STAS: Com a ajuda de redes neurais, voc√™ pode resolver a maioria dos problemas de aprendizado de m√°quina, certo? <br><br>  ANDREW: Sim. <br><br>  STAS: Ent√£o, vamos falar sobre quais tarefas podem ser resolvidas usando m√©todos de aprendizado de m√°quina? <br><br>  ANDREW: Na verdade, esse √© um t√≥pico delicado, porque, na realidade, voc√™ precisa parar de idealizar e romantizar o que est√° acontecendo.  Como eu disse, n√£o h√° intelig√™ncia artificial l√°.  <strong>Este √© um modelo puramente matem√°tico e uma fun√ß√£o matem√°tica</strong> que multiplica algo, etc. <br><br>  Pelo lado, parece que agora o aprendizado de m√°quina parou um pouco em determinadas categorias de tarefas.  Por exemplo, classifica√ß√£o (um exemplo sobre o qual falamos no in√≠cio), rastreamento de objetos e sua segmenta√ß√£o.  O √∫ltimo est√° no aplicativo Sticky AI - ele seleciona uma pessoa e o fundo √© removido.  Tamb√©m existe segmenta√ß√£o m√©dica biol√≥gica quando, por exemplo, s√£o detectadas c√©lulas cancer√≠genas.  Existem redes generativas que aprendem com n√∫meros aleat√≥rios e, em seguida, podem criar algo novo.  Existem tarefas de transfer√™ncia de estilo e outras. <br><br>  No momento, por√©m, n√£o h√° plataforma e infraestrutura convenientes para o uso de aprendizado de m√°quina.  Por exemplo, voc√™ tem um problema que voc√™, como pessoa, pode resolver facilmente, mas como programador, voc√™ n√£o pode resolv√™-lo devido √† sua complexidade e porque n√£o pode simplesmente escrever um algoritmo imperativo.  Mas, ao mesmo tempo, tamb√©m n√£o √© poss√≠vel treinar uma rede neural principalmente porque h√° um problema com a falta de dados.  Para treinar um neur√¥nio, voc√™ precisa de grandes conjuntos de dados com muitos exemplos, al√©m de muito formalizados, descritos em um determinado regulamento, etc.  Al√©m disso, voc√™ precisa da arquitetura dessa rede neural. <br><br>  Ou seja, primeiro <strong>voc√™ precisa formalizar os dados de entrada na forma de n√∫meros</strong> , criar a arquitetura do modelo e formalizar os dados de sa√≠da na forma de n√∫meros, de alguma forma interpret√°-los.  Para fazer isso, voc√™ precisa de um aparato matem√°tico bastante poderoso e, em geral, de um entendimento de como tudo funciona.  Portanto, agora me parece que o uso de neur√¥nios fora de empresas especializadas como a nossa est√° diminuindo um pouco. <br><br>  Algumas tarefas que n√£o foram resolvidas antes, os neur√¥nios aprenderam a resolver muito bem.  Mas n√£o existe tal coisa que os neur√¥nios venham e resolvam todo o espectro de problemas n√£o resolvidos. <br><br>  GLEB: Em quais √°reas voc√™ v√™ problemas globais para os quais as redes neurais geralmente n√£o s√£o adequadas? <br><br>  ANDREW: √â dif√≠cil responder imediatamente.  Estamos diante de tarefas nas quais estamos trabalhando e nas quais n√£o √© poss√≠vel treinar uma rede neural.  Por exemplo, agora a ind√∫stria de jogos est√° muito interessada em aprender, e at√© existem alguns neur√¥nios que possuem intelig√™ncia artificial.  Mas, por exemplo, isso ainda n√£o √© usado em jogos AAA, porque, mesmo assim, no momento √© imposs√≠vel treinar a intelig√™ncia artificial de um soldado abstrato para se comportar como uma pessoa, para que pare√ßa natural.  √â dificil <br><br><h1>  Sobre o Dota <br></h1><br>  STAS: Voc√™ j√° ouviu falar que a intelig√™ncia artificial j√° est√° ganhando no Dota? <br><br>  ANDREW: Sim, mas ainda √© um pouco diferente.  Dota √© um jogo bastante matem√°tico, pode ser descrito.  N√£o quero ofender ningu√©m, mas isso √©, de fato, como damas - o jogo √© o mesmo.  Existem certas regras, e voc√™ apenas joga com elas. <br><br>  Mas, ao mesmo tempo, ainda h√° dificuldades para criar algum tipo de comportamento natural, associado principalmente a uma pequena quantidade de dados e a um pequeno n√∫mero de engenheiros que podem fazer isso. <br><br>  Por exemplo, no Google, os engenheiros est√£o usando redes neurais para treinar um modelo humano 3D a andar - apenas para faz√™-lo se mover.  Sempre parece horr√≠vel, as pessoas n√£o andam assim. <br><br><h1>  Sobre o TensorFlow <br></h1><br>  STAS: Voc√™ disse que agora, de fato, n√£o h√° uma maneira f√°cil e barata de resolver problemas de aprendizado de m√°quina sem entender o aprendizado de m√°quina.  De qualquer forma, acontece que isso deve ser atrapalhado.  Eu gostaria de saber sobre o TensorFlow.  Parece que o Google est√° tentando garantir que mesmo pessoas que n√£o sejam muito versadas nisso e que n√£o tenham um hist√≥rico muito grande possam resolver alguns problemas simples.  Diga-me o que √© o TensorFlow e como voc√™ acha que √© poss√≠vel? <br><br>  ANDREW: Venha em ordem.  <strong>TensorFlow</strong> <strong>na verdade n√£o √© a coisa mais f√°cil de todas</strong> .  Essa √© uma das mais conhecidas estruturas de aprendizado - uma estrutura de aprendizado de uso geral, n√£o necessariamente um neur√¥nio.  Essa n√£o √© a estrutura de n√≠vel mais alto dispon√≠vel.  H√°, por exemplo, Keras, que √© uma abstra√ß√£o de n√≠vel superior no TensorFlow.  L√° voc√™ pode fazer o mesmo com muito menos c√≥digo. <br><br>  Tarefas t√≠picas s√£o resolvidas de maneira simples, porque, em particular, o Github j√° est√° cheio de exemplos e reposit√≥rios.  Digamos, se sua empresa faz uma pesquisa de imagens por uma livraria, ent√£o, em princ√≠pio, est√° tudo bem com voc√™.  Voc√™ acessa o Github, h√° exemplos de como voc√™ pode tirar recursos da imagem, escrever uma pesquisa por recursos - est√° pronto! <br><br>  De fato, este √© o caso de um grande n√∫mero de tarefas.                  ,     .     -  , ,   ,     ,     ,     ,  TensorFlow ‚Äî    .    ,     . <br><br> :   ,   Google  ,        ? <br><br> : ,      ,   ,         .    ,  ,      ,       .  ,       ,        . <br><br><h1>   <br></h1><br> :      ,       .   ? -,  . <br><br> : .     ‚Äî     ¬´   ,   ,   ¬ª. ,   . <br><br> : , , ,     ,     .     ?  ,     ,       15   -  iOS ,  - .    ,    .  ,   . <br><br> :   ‚Äî , , -   .    ‚Äî  ‚Äî .      . ,  ,   R&amp;D   ,   : ¬´,   !¬ª ‚Äî - ,  ,     ,     0,5%: ¬´,   ,   !¬ª   .    ,      . <br><br> :         ,  ,  -      , ,    .   ?  .    ,          ‚Äî ,  70%.    ,        ,    .   ,     .     ,    ,     . <br><br> : ,   , ,   .      ,    .   ,   - ,      .    . <br><br> :  ,        . <br><br><h1>    <br></h1><br> :     ,  .    . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wl/fb/eo/wlfbeojhnc13z4_wcooqk5bhu4e.png"></div><br><br> :     ,       ?   ,   ,  ,   ‚Äî  ? <br><br> :     ,    ,      .      ,       . <br><br> -,  ,   <strong>   </strong> .       ,   computer science.      ,             . <br><br>        .       ,    500   Python,   .        .         .     ,      .      ,     ,   . <br><br>   ,     .  -  ,           .     ,         . <br><br> :  ,        Python   -  , ,  C++?       ,    . <br><br> : ,   .     - learning , ,  TensorFlow,        TensorFlow.    ,    <br><br>   ‚Äî    ,     TensorFlow.      TensorFlow ‚Äî      1  ‚Äî  ,   ,  . <br><br>      . ,  iOS    .       ,      learning ,  ,   Caffe, Torch, TensorFlow  .,            . <br><br>      ,        ,  ,   . R&amp;D  - ,  .              .     ()  : ¬´  !¬ª ‚Äî      ,           .         C++. <br><br>      : <br><br><ul><li> ,   .   ,     . <br></li><li>     . <br></li></ul><br><h1>    <br></h1><br> :      .    ,     ,     . <br><br> : ,       ?          , ? <br><br> :  ,     .  ,           ‚Äî   .    :   ,    ,   : ¬´,    ,   ‚Äî ¬ª,  -      .   , , -,        - .      ,      .    . <br><br>         .  ,   ,    ,         . <br><br> :     Google   ,         Google Street Maps. ,    . <br><br> : ,     -     . <br><br><h1>   Data Scientist <br></h1><br> :      .   ,       ‚Äî   ,   ,   ? <br><br> :   ,   . <br><br> : ,   ,    , ,  data scientist'.    ,   -  .    .          ,    ,       .   ‚Äî     ! <br><br>      ,    .      ,      -,      .   . <br><br> :        hype train. <br><br> : ,       ,    data scientist  .     ,      . <br><br> :   ,   .   -   data scientist'? <br><br> :    .    ,  .     ,  ,     ,  Git-     . Data scientist -  ,     .      ,  code review, unit- ‚Äî      .       ,      . <br><br> :    ,      ,     . <br><br> : ,         ,      - , , Kaffe 2, PyTorch ‚Äî   !    : ¬´ Data scientist  TensorFlow¬ª. <br><br><h1>  GPU- <br></h1><br>          .  ,    ,      ,    Swift,      UI-kit,   .  ,     ,       . <br><br>  ,   -  ,      .        ,       .   ,   ,     .          enterprise. <br><br>      - ,  ,     ,      . ,      ,    .     ,   . <br><br> :        ,       .   GPU   -    .      ,     ‚Äî         .   ,      Junior GPU   .    ,  ,         . <br><br><h1>   <br></h1><br> :    ‚Äî   . <br><br> :      ,   ? <br><br> : ,   ,        - . <br><br> :    ‚Äî      ? <br><br> :    , , -, -  . <br><br> :    ,        ? <br><br> :      .     , ,  ,         ,     .          Macbook Air.           ‚Äî -      ,     ,  . <br><br>        ,      Nvidia Titan   ,    .     ,     . <br><br><h1>   <br></h1><br> :     ?    ,    Nvidia     ,   .  ,     ,    .      ? <br><br> :                print   ,        .     NIPS,   ,         ,         .   , ,    .    - ,      ‚Äî    ,      . <br><br>   .    ONNX       ,     .     .   ,     .    ,    ,   .  ,    - ,     <strong>   </strong> .       . <br><br><h1>   <br></h1><br> :    ,    .   ,           ,    ,     ? <br><br> : ,       .   ,        .        ,    .       ,        ‚Äî   ,      .. <br><br>   ,      .  ,    .    ‚Äî  ,        ,        .   .    ,          ,       .         ,         ,   . <br><br><h1>  reinforcement training     <br></h1><br> :         .  ,    ,  , , AlphaGo.  ,    ,   ,    reinforcement training. <br><br> : Reinforcement training ‚Äî   .    ,    . ,   , ,        .    ,           ,      .   ,      . Reinforcement training   ,   ,    ,      ,  : ¬´ !¬ª <br><br> ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AlphaGo</a> ‚Äî   ,    .      ,       .    ,     ,    .          ,       .  AlphaGo    ,    reinforcement training,   ,       . <br><br> ,           ,    ,       ,    . <br><br> :     ,    10 <sup>170</sup>  ‚Äî   .  ,      AlphaGo   .        ,    .   ,  , , .   ‚Äî  , -    ! <br><br>       ,    ,         ,    .          ,       ,       . ,   ! <br><br><h1>    <br></h1><br>  STAS: Quero perguntar sobre algoritmos gen√©ticos.  Segundo a descri√ß√£o, parece que os algoritmos gen√©ticos tamb√©m podem ser atribu√≠dos ao aprendizado por refor√ßo.  Como eu os imagino, h√° uma gera√ß√£o, pegamos cada sujeito em uma gera√ß√£o, realizamos alguma tarefa, avaliamos suas a√ß√µes e, a partir dessas estimativas, selecionamos as melhores.  Em seguida, cruzamos suas propriedades espec√≠ficas, criamos uma nova gera√ß√£o, adicionamos um pouco de muta√ß√£o e agora temos uma nova gera√ß√£o.  E repetimos essas opera√ß√µes, tentando aumentar a utilidade final de cada membro espec√≠fico desta gera√ß√£o.  Isso parece fazer sentido.  Isso √© considerado treinamento de refor√ßo ou n√£o? <br><br>  ANDREW: N√£o, os algoritmos gen√©ticos ainda s√£o um pouco diferentes. <br><br>  STAS: Eles se relacionam com o aprendizado de m√°quina? <br><br>  ANDREW: Eu n√£o diria isso.  N√£o aceito agora, mas passamos pelos algoritmos gen√©ticos da universidade, como todo mundo, e parece-me que isso √© um pouco mais simples e mais desregulado ou algo assim - em suma, imperativo.  Ou seja, √© sabido antecipadamente que o que ser√° inserido, ser√° produzido.  No aprendizado de m√°quina, no entanto, as coisas s√£o um pouco diferentes - h√° alguma probabilidade, precis√£o de previs√µes e tudo nesse esp√≠rito. <br><br>  Talvez eu seja corrigido por pessoas que entendem melhor a terminologia do que eu, mas <em>do alto da minha cabe√ßa</em> eu diria que n√£o. <br><br>  STAS: Acontece que algoritmos gen√©ticos n√£o s√£o usados ‚Äã‚Äãpara resolver os problemas mais reais? <br><br>  ANDREW: Sim, eles s√£o principalmente mais algor√≠tmicos e, na pr√°tica, raramente os encontrei. <br><br><h1>  Sobre redes de c√°psulas <br></h1><br>  GLEB: H√° outro subconjunto de aprendizado de m√°quina - as chamadas redes de c√°psulas.  Novamente, n√£o vamos muito fundo.  Diga-me em poucas palavras o que √© e por que existe essa tend√™ncia agora? <br><br>  ANDREW: Este √© realmente um t√≥pico super novo, com apenas alguns meses de idade.  Jeffrey Hinton divulgou um artigo e disse que as redes convolucionais atuais s√£o um caminho para lugar nenhum, e oferecemos uma nova vis√£o de como isso se desenvolver√°.  A comunidade aceitou essa afirma√ß√£o ambiguamente e dividiu-se em dois campos: alguns dizem que √© um exagero, outros - uma grande coisa e tudo isso. <br><br>  Mas se voc√™ explica diretamente, como funcionam as redes de convolu√ß√£o?  Tomemos, por exemplo, neur√¥nios que trabalham com imagens.  H√° uma convolu√ß√£o - uma coluna de matrizes que percorre a imagem com algum passo, como se a estivesse digitalizando.  A cada itera√ß√£o de tal etapa, toda essa convolu√ß√£o √© aplicada a essa pe√ßa, e cada convolu√ß√£o se transforma em um novo pixel condicional, mas com uma dimens√£o muito maior, essa opera√ß√£o √© repetida para todas as grades. <br><br>  Mas o problema das redes convolucionais √© que todos os dados que chegam √† primeira camada chegam ao fim - talvez n√£o na √≠ntegra, mas todos afetam e atingem o est√°gio final.  Grosso modo, se voc√™ precisar determinar alguma parte da imagem, por exemplo, um gato, n√£o precisar√° digitalizar a imagem inteira.  Em algum momento, √© suficiente localizar a zona onde o gato provavelmente est√° localizado e consider√°-lo apenas como uma pessoa. <br><br>  √â assim que as redes de c√°psulas funcionam.  N√£o me comprometerei a explicar habilmente o interior deles, mas pelo que entendi: h√° certas √°rvores dentro das redes de c√°psulas e cada c√°psula subsequente recebe apenas os dados relevantes para a entrada.  Ou seja, atrav√©s deles n√£o passa tudo o que aceitamos inicialmente para a entrada e, a cada nova camada (n√£o sei como isso pode ser dito na terminologia de redes capsulares), apenas os dados realmente necess√°rios s√£o processados ‚Äã‚Äã- apenas dados importantes .  Essa √© a principal diferen√ßa entre redes convolucionais e capsulares. <br><br>  GLEB: Parece interessante, mas eu n√£o entendo direito - s√£o apenas as imagens em quest√£o? <br><br>  ANDREW: N√£o, √© isso.  Eu usei as imagens apenas para explicar.  A id√©ia principal √© a seguinte: n√£o vamos direcionar todos os dados e todos os recursos, mas apenas aqueles que s√£o relevantes para a pr√≥xima camada. <br><br><h1>  Mais sobre jogos <br></h1><br>  STAS: Ouvi dizer que depois que os caras do AlphaGo v√£o derrotar todos no StarCraft? <br><br>  ANDREW: For√ßado a decepcion√°-lo, mas eu realmente n√£o sigo isso.  N√£o √© que o eSports tenha sido interessante para mim, mas j√° est√° ficando claro o que o futuro est√°.  Por exemplo, j√° existem startups treinadas para jogar Dota.  Eles, como personal trainer, analisam como voc√™ joga e dizem onde voc√™ n√£o √© bom o suficiente, eles t√™m seus pr√≥prios dados treinados em partidas de esportes eletr√¥nicos.  Existem startups de apostas que prev√™em quem vencer√° e muito mais. <br><br>  Muitas pessoas est√£o trabalhando nesta √°rea agora, principalmente porque muito dinheiro est√° girando nela.  Mas, pessoalmente, isso √© completamente desinteressante para mim, ent√£o n√£o acompanho as not√≠cias e tend√™ncias, infelizmente. <br><br>  STAS: O que voc√™ acha que √© a dificuldade de criar uma boa intelig√™ncia artificial especificamente para jogos estrat√©gicos?  Entendo corretamente que basicamente esse √© um n√∫mero muito grande de op√ß√µes? <br><br>  ANDREW: Sim.  De fato, j√° discutimos esse ponto quando expliquei que a intelig√™ncia artificial ainda n√£o √© usada em jogos AAA, mas ao mesmo tempo est√° no AlphaGo e, possivelmente, em outro lugar. <br><br>  O jogo de ir com toda a sua complexidade consiste no fato de que a cada passo voc√™ simplesmente coloca um chip para delinear uma pedra, e o jogo StarCraft √© uma coisa muito complexa.  L√° voc√™ pode enviar suas unidades ao longo de um n√∫mero praticamente ilimitado de trajet√≥rias, construir diferentes conjuntos de suas constru√ß√µes, etc. Tudo isso √© um par√¢metro. <br><br>  Al√©m disso, a dificuldade est√° no fato de que as redes neurais nem sempre pensam como uma pessoa.  Quando, por exemplo, constru√≠mos uma unidade, lembramos disso.  Mas muitos neur√¥nios funcionam todas as vezes.  Obviamente, existem redes recursivas que lembram suas realiza√ß√µes passadas.  Eles s√£o usados ‚Äã‚Äãprincipalmente para tradu√ß√£o e informa√ß√µes textuais, quando, √† medida que a senten√ßa √© gerada, o neur√¥nio usa cada vez mais dados. <br><br>  Existem enormes dificuldades com o fato de que toda a quantidade de informa√ß√µes e op√ß√µes precisa ser formalizada, ou seja, encontrar um conjunto de dados para treinamento, para que ele ainda responda adequadamente √†s a√ß√µes do seu oponente, que tamb√©m pode ser um milh√£o, ao contr√°rio de jogar um jogo de ou xadrez. <br><br>  STAS: Entendo - existem muitos par√¢metros. <br><br>  GLEB: Mas eu n√£o entendo o qu√™, √© claro que o DotA tem menos par√¢metros, mas ainda √© o mesmo no sentido em que foi enviado para qualquer lugar etc. <br><br>  STAS: Aqui, Andrei se reduziu ao fato de que, em primeiro lugar, voc√™ tem uma unidade e o n√∫mero de op√ß√µes √© muito menor. <br><br>  ANDREW: Para ser sincero, nunca joguei um segundo Dota na minha vida, mas no original, at√© onde eu sei, esse √© um jogo super determin√≠stico.  Existem 3 corredores e torres que precisam ser destru√≠dos. <br><br>  GLEB: Sim, mas no StarCraft, apesar de n√£o jogar, tamb√©m existem algumas maneiras e as mesmas unidades.  Voc√™ diz que existem muitos deles, mas √© mais prov√°vel que eles sejam sempre conduzidos em lotes.  Ou seja, aproximadamente a mesma coisa acontece. <br><br>  STAS: Voc√™ ainda precisa organizar corretamente cada unidade separadamente durante a batalha.  No momento em que n√£o s√£o levados em um pacote, mas come√ßam a ser organizados, h√° imediatamente mais par√¢metros. <br><br>  ANDREW: Seu problema √© que voc√™ pensa nessas categorias: coloque uma unidade, etc., mas esquece o tempo todo que um neur√¥nio √© apenas uma matriz - n√∫meros que se multiplicam.  L√° voc√™ deve formalizar, por exemplo, coisas como tarefas.  Digamos que exista um mapa para o StarCraft e que haja algum tipo de tarefa - n√£o importa se voc√™ derrota um jogador ou outra coisa.  Tudo isso precisa ser apresentado na forma de primitivas matem√°ticas, e isso √© precisamente o mais dif√≠cil. <br><br>  Se realmente fosse intelig√™ncia artificial, a diferen√ßa entre Dota e StarCraft seria m√≠nima.  StarCraft pode ser um pouco mais complicado em mec√¢nica, mas ainda assim.  Mas, devido ao fato de operarmos com n√∫meros, √© mais dif√≠cil formalizar. <br><br><h1>  Sobre redes de aprendizagem m√∫tua <br></h1><br>  STAS: Tenho a √∫ltima pergunta que quero fazer antes de irmos para o nosso celular.  N√£o sei como √© chamado corretamente, mas h√° uma maneira em que uma rede neural segue outra e tenta encontrar padr√µes. <br><br>  ANDREW: N√£o vou me comprometer a explicar agora como funciona, mas sei com certeza que existem algoritmos super legais que √†s vezes ou√ßo no trabalho quando duas redes neurais aprendem √† custa uma da outra.  Essa √°rea de especializa√ß√£o j√° √© completamente inacess√≠vel para mim, mas tudo parece legal.  Tanto quanto eu sei, isso √© usado para redes generativas.  Infelizmente, n√£o posso dizer mais nada. <br><br>  STAS: Bom.  Voc√™ deu as palavras-chave mais importantes, o resto √© Gleb e os leitores facilmente pesquisam no Google. <br><br><h1>  Sobre telefones celulares (Apple) <br></h1><br>  GLEB: Vamos para os telefones celulares que estamos acessando h√° muito tempo.  Primeiro de tudo, o que podemos fazer quando falamos sobre aprendizado de m√°quina em dispositivos m√≥veis? <br><br>  ANDREW: A prop√≥sito, voc√™ tem um podcast para desenvolvedores de iOS? <br><br>  GLEB: N√£o somos um podcast para iOS.  Sim Stas? <br><br>  STAS: Sim, para desenvolvedores m√≥veis.  Por que a pergunta? <br><br>  ANDREW: S√≥ porque a situa√ß√£o √© muito diferente.  A Apple, em virtude de sempre ter sido boa em integrar software e hardware, e ser famosa por isso, √© muito elegantemente enganchada em um trem de hype treinado por m√°quina. <br><br>  Em 2014, a Apple lan√ßou a API de gr√°ficos do Metal.  Tudo foi costurado nele, por exemplo, sombreadores de computador etc. Tudo isso permitiu, com o advento do iOS 10, incluir na estrutura do Metal Performance Shaders muitas camadas, ativa√ß√µes e outros operadores de redes neurais, em particular redes neurais convolucionais. <br><br>  Isso deu um grande impulso, porque, em regra, os c√°lculos em uma placa de v√≠deo s√£o muitas vezes mais r√°pidos que em um processador central.  Quando a Apple teve a oportunidade de ler em placas de v√≠deo m√≥veis, e rapidamente, n√£o havia necessidade de escrever seus pr√≥prios operadores matem√°ticos e assim por diante.  Ele disparou diretamente muito forte.  E um ano depois, eles lan√ßaram o CoreML (falaremos sobre isso um pouco mais tarde). <br><br>  A Apple tinha uma base muito boa.  N√£o sei se eles tiveram essa vis√£o, ou se coincidiram, mas agora s√£o l√≠deres objetivamente no setor de aprendizado de m√°quina em dispositivos m√≥veis. <br><br><h1>  Sobre telefones celulares (Android) <br></h1><br>  O que funciona relativamente legal e excelente em tempo real no iOS, infelizmente, n√£o funciona t√£o bem no Android.  Isso se deve n√£o apenas ao fato de o Android ser uma merda.  Existem outros fatores - primeiro, o fato de o Android ter uma infraestrutura muito diversificada: existem dispositivos fracos, outros fortes - voc√™ n√£o consegue entender tudo. <br><br>  Se o Metal √© suportado em todos os dispositivos iOS, no Android j√° √© mais complicado - em algum lugar o OpenGL √© suportado em uma vers√£o, em outro lugar, em algum lugar em que n√£o √© suportado.  Em algum lugar existe Vulkan, em algum lugar n√£o.  Todos os fabricantes t√™m seus pr√≥prios drivers, que, √© claro, n√£o s√£o otimizados de forma alguma, mas simplesmente suportam minimamente o padr√£o.  At√© acontece que voc√™ roda algumas redes neurais no Android na GPU, e elas funcionam em velocidade da mesma maneira que na CPU, porque trabalhar com mem√≥ria compartilhada √© muito ineficiente e tudo mais. <br><br>  No Android, as coisas est√£o ruins agora.  Isso √© bastante surpreendente, porque o Google √© um dos l√≠deres, mas um pouco cedendo a esse respeito.  No Android, h√° claramente uma falta de implementa√ß√£o de alta qualidade dos recursos do aprendizado de m√°quina moderno. <br><br>  Para n√≥s, por exemplo, mesmo no aplicativo, nem todos os recursos funcionam da mesma maneira.  O que funciona mais r√°pido no iOS √© mais lento no Android, mesmo em dispositivos de pot√™ncia compar√°vel.  Nesse sentido, no momento, o Android como plataforma est√° caindo. <br><br><h1>  Sobre o CoreML <br></h1><br>  STAS: Como eles disseram sobre o CoreML, provavelmente seria correto dizer sobre o TensorFlow Lite. <br><br>  ANDREW: O CoreML √© na verdade um azar√£o.  Quando ele saiu no ano passado, todo mundo primeiro disse: "Uau, legal!"  Mas ent√£o ficou claro que este √© apenas um pequeno inv√≥lucro sobre o Metal.  As empresas que est√£o seriamente envolvidas em aprendizado de m√°quina, incluindo a nossa, h√° muito tempo t√™m suas pr√≥prias solu√ß√µes.  Por exemplo, nossas solu√ß√µes de teste mostraram melhores resultados que o CoreML em termos de velocidade e outros par√¢metros. <br><br>  Mas o principal problema com o CoreML era que ele n√£o podia ser personalizado.  √Äs vezes acontece que voc√™ precisa de uma camada complexa em uma rede neural, que n√£o √©, por exemplo, no Metal, e precisa escrev√™-la.  No CoreML, n√£o era poss√≠vel incorporar suas camadas, e voc√™ precisava fazer o downgrade para o Metal para o n√≠vel mais baixo e escrever tudo sozinho. <br><br>  Recentemente, o CoreML adicionou isso, e agora essa estrutura se tornou mais interessante.  Se voc√™ √© um desenvolvedor que n√£o tem nada relacionado ao aprendizado de m√°quina na empresa ou no aplicativo, pode executar algum neur√¥nio em duas linhas e execut√°-lo rapidamente na GPU.  Os resultados, que mostram testes de desempenho para CoreML, s√£o compar√°veis ‚Äã‚Äãa solu√ß√µes personalizadas e bare metal. <br><br>  Ou seja, o CoreML funciona muito bem.  Est√° um pouco √∫mido, tem bugs, mas todos os meses est√° melhorando.  A Apple est√° lan√ßando ativamente atualiza√ß√µes - n√£o da maneira como estamos acostumados, que as atualiza√ß√µes dos frameworks da Apple s√£o lan√ßadas uma vez por ano ou nas vers√µes semi-principais do iOS.  O CoreML est√° sendo atualizado ativamente; nesse sentido, tudo est√° √≥timo. <br><br>  O TensorFlow Lite fornece um conversor no CoreML, o CatBoost tamb√©m suporta um conversor no CoreML.  Em suma, a Apple fez tudo certo de novo.  Eles lan√ßaram um conversor de c√≥digo aberto e disseram: "Vamos escrever todos os conversores no CoreML" - e muitas estruturas de aprendizado suportam isso. <br><br>  No in√≠cio, houve algum ceticismo em rela√ß√£o ao CoreML, na √∫ltima WWDC a pergunta mais comum para os desenvolvedores do CoreML foi: ‚ÄúPor que voc√™ n√£o permite o download de modelos da Internet?  Por que voc√™ n√£o os deixa criptografar?  Foi poss√≠vel obter esses modelos e, ao que parece, roubar propriedade intelectual. <br><br>  Agora, tudo foi reparado, acrescentou funcionalidade e, no momento, o CoreML √© definitivamente a plataforma l√≠der nesse sentido. <br><br>  STAS: Voc√™ pode falar sobre isso com mais detalhes?  Acontece que agora voc√™ n√£o pode mais armazenar o modelo, apenas carreg√°-lo de algum lugar? <br><br>  ANDREW: Sim, j√° √© poss√≠vel.  Anteriormente, quando perguntamos sobre isso, os desenvolvedores sorriram e disseram: "Basta olhar para os cabe√ßalhos".  Realmente havia designers que podiam transferir arquivos e tudo se encaixava. <br><br>  Mas os modelos CoreML s√£o bastante interessantes.  Na verdade, s√£o bin√°rios comuns que armazenam pesos, mas, al√©m disso, s√£o arquivos r√°pidos gerados, que criam classes impl√≠citas.  Voc√™ usa essas classes em seu aplicativo e os compiladores compilam esse modelo em alguns arquivos. <br><br>  Agora, usando certos hacks e abordagens, √© poss√≠vel tornar esse modelo port√°til.  Voc√™ pode proteger sua propriedade intelectual por criptografia e diminuir o peso do aplicativo. <br><br>  Em geral, o CoreML agora est√° se movendo na dire√ß√£o certa.  Nem tudo pode ser feito legalmente do ponto de vista da App Review, nem tudo pode ser feito facilmente, sem hacks, mas √© not√°vel como os desenvolvedores melhoram a estrutura. <br><br>  STAS: Legal!  Eu queria acrescentar que o CoreML se parece com uma solu√ß√£o t√≠pica.  Em termos relativos, √© conveniente quando voc√™ deseja fazer algo simples usando o aprendizado de m√°quina em seu aplicativo.  Parece que, se essa √© uma tarefa t√≠pica, a Apple tentou tornar toda essa rota o mais simples poss√≠vel, se voc√™ encontrar um modelo pronto, conjunto de dados e muito mais.  Esta √© apenas uma hist√≥ria sobre um problema t√≠pico, porque para eles, provavelmente, tudo j√° est√° pronto. <br><br>  ANDREW: Para tarefas t√≠picas, isso geralmente √© super!  Sem hip√©rbole - s√£o necess√°rias duas linhas de c√≥digo para executar o modelo.  Nesse sentido, sim, √© muito legal, especialmente para desenvolvedores independentes ou empresas que n√£o possuem um departamento de P&amp;D na equipe, mas tamb√©m desejam adicionar algo interessante. <br><br>  Mas isso n√£o √© t√£o interessante, porque as tarefas t√≠picas foram resolvidas no Github e no Metal - voc√™ pode copiar esse c√≥digo para si mesmo e coloc√°-lo no farm - embora um pouco mais complicado. <br><br>  √â importante que agora essa estrutura esteja se movendo n√£o apenas para as tarefas cl√°ssicas do dia-a-dia, mas tamb√©m para solu√ß√µes integradas.  Isso √© muito legal! <br><br><h1>  Sobre o treinamento em telefones celulares <br></h1><br>  GLEB: Voc√™ diz que ap√≥s o advento do Metal, tornou-se poss√≠vel treinar modelos em telefones celulares? <br><br>  ANDREW: N√£o, o treinamento em telefones celulares nunca foi poss√≠vel.  N√£o faz sentido, voc√™ s√≥ pode execut√°-lo.  Se eu disse, fiz uma reserva.  Nos telefones celulares, √© claro, ningu√©m ensina nada. <br><br>  STAS: Tamb√©m n√£o ouvi nada sobre o treinamento em um telefone celular. <br><br>  GLEB: Eu tamb√©m n√£o ouvi, mas pensei nisso.  Obviamente, parece intuitivamente que isso √© uma coisa estranha.  Mas definitivamente n√£o h√° tarefas interessantes, quando isso seria relevante? <br><br>  ANDREW: √â dif√≠cil imagin√°-los.  Se houver algo assim, apenas o aprendizado distribu√≠do.  Existem at√© artigos cient√≠ficos sobre como fazer isso, mas pelo que entendi, voc√™ est√° perguntando como aprender com os dados coletados no mesmo telefone?  S√≥ que, mesmo que voc√™ colete tanto (o que n√£o acontecer√°), levar√° tanto tempo para aprender que isso nunca terminar√°, e ningu√©m portar√° o c√≥digo de treinamento para plataformas m√≥veis, por que?  <strong>O treinamento sempre acontece nos servidores e a infer√™ncia nos dispositivos.</strong> <br><br>  STAS: Mas, no final das contas, acontece assim.  Se voc√™ √© uma empresa, deseja ter algo assim, precisa de dados e pode colet√°-los dos seus usu√°rios, ou seja, carreg√°-los periodicamente. <br><br>  ANDREW: Sim, mas funciona um pouco diferente.  Voc√™ coleta dados de todos os usu√°rios em um √∫nico local para o servidor quente, treina l√° e envia o modelo finalizado.  Mas n√£o √© para que todos em casa ensinem alguma coisa. <br><br>  STAS: Por outro lado, o telefone celular esquentaria - e no inverno seria relevante, mas por muito, provavelmente, muito tempo. <br><br><h1>  Sobre telefones celulares e o futuro <br></h1><br>  GLEB: Existem outras coisas interessantes em termos de aplica√ß√£o de aprendizado de m√°quina em dispositivos m√≥veis?  Conversamos sobre o que j√° temos agora.  Seria interessante olhar um pouco para o futuro - para que geralmente gostar√≠amos de receber em nossas plataformas m√≥veis alguns superalimentos e super solu√ß√µes. <br><br> : ,   ,    performance ‚Äî   ,    ,   . ,    - ,       . <br><br>     . ,         style-     ,       .         . <br><br>    CoreML   .  ,  ,      .   ,    ,   :   , ,  ‚Äî  ,       Android,   iOS,       .     ,         ,        iOS    Android. <br><br>   ,     ,    ,  ,      ‚Äî   Android,   iOS,   Github       .   -  ‚Äî   Uber   ,   Horovod.  Apple    ‚Äî      ,    .  ,     ,  ,   ,   ‚Äî          . <br><br> ,       .   , , ,      ‚Äî   ,   ,    - .     ,   . <br><br><h1>     <br></h1><br> :    ,     ,   ?  , ,      ?         . <br><br> :      ,     ‚Äî   (M. Bishop. Pattern Recognition and Machine Learning. Christopher. Springer. 2006),  -  .    ,      ,     3D ,     ,  - .      .   ,       ‚Äî    ,  ‚Äî     . <br><br>    ,     ,        ,    .   ,    -, ,      Andrew Ng  Coursera.       ,        . <br><br>      ,  ,         ,       ‚Äî          MNIST.   Hello World,     . <br><br> ,    ,    , , -    ,  .   -   ,   ,    ,     . <br><br> :   ? <br><br> :    advanced-  Andrew Ng! , ,  Kaggle,   ,       .          ,          ,    ‚Äî        Data Scientist. <br><br>   ‚Äî  ,     , ,     .      ,     ‚Äî        R&amp;D .    ,   .         .       ,      ,    . <br><br>       .    ,    Kaggle,  -  ‚Äî         90%  . <br><br><h1>  Sum√°rio <br></h1><br> :    .  ,           ,     ,   ,        . <br><br><ul><li>  ,    ‚Äî    . ,   ,   ‚Äî      . </li><li>         . </li><li>        . </li><li> -    . </li><li> ,      ,  ,        . <br></li><li>       ,   . , ,    ,  -  - ! </li><li>         ‚Äî  ,    ,  CoreML ‚Äî  ,    . </li></ul><br>      ,     . <br><br><blockquote> ,           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AppsConf 2018</a> ,   8  9   . <br><br>      80 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> ,  Call for Papers   ‚Äî <strong>   3 </strong> . ,   ,         . <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt416477/">https://habr.com/ru/post/pt416477/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt416467/index.html">Quanta mat√©ria escura passa pelo seu corpo a cada segundo</a></li>
<li><a href="../pt416469/index.html">Sincroniza√ß√£o de carteira Bitcoin</a></li>
<li><a href="../pt416471/index.html">Blue Origin de Jeff Bezos planeja pousar na Lua at√© 2023</a></li>
<li><a href="../pt416473/index.html">Interface da cidade: ladrilhos t√°teis nas cal√ßadas</a></li>
<li><a href="../pt416475/index.html">O rover da oportunidade ainda est√° silencioso devido √† tempestade de poeira em Marte</a></li>
<li><a href="../pt416479/index.html">Concatena√ß√£o de cadeias ou bytecode de patch</a></li>
<li><a href="../pt416481/index.html">Yuri Akkermann: ‚ÄúUm dos princ√≠pios fundamentais da Alian√ßa FIDO √© garantir a privacidade‚Äù</a></li>
<li><a href="../pt416483/index.html">Jogo de interpreta√ß√£o de pap√©is - o formato mais antigo de um mundo totalmente gratuito em jogos</a></li>
<li><a href="../pt416485/index.html">A SpaceX est√° trabalhando para criar um pequeno "submarino" para salvar adolescentes de uma caverna na Tail√¢ndia</a></li>
<li><a href="../pt416487/index.html">Radio Astron faz 7 anos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
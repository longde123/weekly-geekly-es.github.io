<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª‚Äçü§ù‚Äçüë®üèæ üöå üë©‚Äçüåæ Eine Billion kleiner Singles üéø üë®üèº‚Äçüé§ üßëüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bildquelle : www.nikonsmallworld.com 


 Anti-Plagiat ist eine spezialisierte Suchmaschine, √ºber die bereits fr√ºher geschrieben wurde . Und jede Suchm...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Eine Billion kleiner Singles</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/antiplagiat/blog/445952/"><p><img src="https://habrastorage.org/webt/hc/qv/ma/hcqvmaxyzdevsbs7cs8lw_fpile.jpeg"></p><br><p>  <sub><em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bildquelle</a> : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.nikonsmallworld.com</a></em></sub> </p><br><p>  Anti-Plagiat ist eine spezialisierte Suchmaschine, √ºber die bereits <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">fr√ºher geschrieben wurde</a> .  Und jede Suchmaschine, was auch immer man sagen mag, um schnell zu arbeiten, ben√∂tigt einen eigenen Index, der alle Funktionen des Suchbereichs ber√ºcksichtigt.  In meinem ersten Artikel √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Habr</a> werde ich √ºber die aktuelle Implementierung unseres Suchindex, die Geschichte seiner Entwicklung und die Gr√ºnde f√ºr die Wahl der einen oder anderen L√∂sung sprechen.  Effektive .NET-Algorithmen sind kein Mythos, sondern eine schwierige und produktive Realit√§t.  Wir werden in die Welt des Hashings, der bitweisen Komprimierung und der mehrstufigen Priorit√§tscaches eintauchen.  Was ist, wenn Sie eine Suche schneller als <b>O (1)</b> ben√∂tigen? </p><br><p>  Wenn jemand anderes nicht wei√ü, wo sich die Schindeln auf diesem Bild befinden, willkommen ... </p><br><p><a name="habracut"></a></p><br><h1>  Schindeln, Index und warum suchen Sie sie </h1><br><p>  Eine Schindel ist ein Textst√ºck mit einer Gr√∂√üe von wenigen W√∂rtern.  Schindeln √ºberlappen sich, daher der Name (Englisch, Schindeln - Schuppen, Kacheln).  Ihre spezifische Gr√∂√üe ist ein offenes Geheimnis - 4 W√∂rter.  Oder 5?  Nun, es kommt darauf an.  Selbst dieser Wert gibt jedoch wenig und h√§ngt von der Zusammensetzung der Stoppw√∂rter, dem Algorithmus zum Normalisieren von W√∂rtern und anderen Details ab, die im Rahmen dieses Artikels nicht von Bedeutung sind.  Am Ende berechnen wir den 64-Bit-Hash basierend auf diesem Shingle, den wir in Zukunft als Shingle bezeichnen werden. </p><br><p>  Entsprechend dem Text des Dokuments k√∂nnen Sie viele Schindeln erstellen, deren Anzahl mit der Anzahl der W√∂rter im Dokument vergleichbar ist: </p><br><p>  <em>text: string ‚Üí schindeln: uint64 []</em> </p><br><p>  Wenn mehrere Schindeln in zwei Dokumenten zusammenfallen, nehmen wir an, dass sich die Dokumente √ºberschneiden.  Je mehr Schindeln √ºbereinstimmen, desto identischer ist der Text in diesem Dokumentpaar.  Der Index sucht nach Dokumenten mit der gr√∂√üten Anzahl von Schnittpunkten mit dem zu pr√ºfenden Dokument. </p><br><p><img src="https://habrastorage.org/webt/ud/th/z_/udthz_wa_avl6zbaij-cydicgx8.jpeg"></p><br><p>  <sub><em>Bildquelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wikipedia</a></em></sub> </p><br><p>  Mit dem Shingles-Index k√∂nnen Sie zwei Hauptoperationen ausf√ºhren: </p><br><ol><li><p>  Indizieren Sie die Schindeln von Dokumenten mit ihren Kennungen: </p><br><p>  <i>index.Add (docId, Schindeln)</i> </p></li><li><p>  Suchen und Anzeigen einer Rangliste von Kennungen f√ºr √ºberlappende Dokumente: </p><br><p>  <i>index.Search (Schindeln) ‚Üí (docId, score) []</i> </p></li></ol><br><p>  Ich glaube, der Ranking-Algorithmus verdient im Allgemeinen einen separaten Artikel, daher werden wir hier nicht dar√ºber schreiben. </p><br><p>  Der Index der G√ºrtelrose unterscheidet sich stark von bekannten Volltext-Gegenst√ºcken wie Sphinx, Elastic oder gr√∂√üer: Google, Yandex usw. Einerseits erfordert es kein NLP und keine anderen Lebensfreuden.  Die gesamte Textverarbeitung wird entfernt und hat keinen Einfluss auf den Prozess sowie die Reihenfolge der Schindeln im Text.  Andererseits ist die Suchabfrage kein Wort oder eine Phrase aus mehreren W√∂rtern, sondern bis zu mehreren hunderttausend <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hashes</a> , die alle zusammen und nicht separat von Bedeutung sind. </p><br><p>  Hypothetisch k√∂nnen Sie den Volltextindex als Ersatz f√ºr den Schindelindex verwenden, aber die Unterschiede sind zu gro√ü.  Dies ist der einfachste Weg, um einen bekannten Schl√ºsselwertspeicher zu verwenden.  Wir s√§gen unsere <s>Fahrradimplementierung</s> , die ShingleIndex hei√üt. </p><br><p>  Warum st√∂ren wir uns so?  Aber warum. </p><br><ul><li>  <u>B√§nde</u> : <br><ol><li>  Es gibt viele Dokumente.  Jetzt haben wir ungef√§hr 650 Millionen von ihnen, und dieses Jahr wird es offensichtlich mehr von ihnen geben; </li><li>  Die Zahl der einzigartigen Schindeln w√§chst sprunghaft und erreicht bereits Hunderte von Milliarden.  Wir warten auf eine Billion. </li></ol></li><li>  <u>Geschwindigkeit</u> : <br><ol><li>  Tags√ºber, w√§hrend der Sommersitzung, werden mehr als 300.000 Dokumente durch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das Anti-Plagiat-System</a> √ºberpr√ºft.  Dies ist ein wenig nach den Ma√üst√§ben der g√§ngigen Suchmaschinen, aber es bleibt im Ton; </li><li>  F√ºr eine erfolgreiche √úberpr√ºfung der Eindeutigkeit von Dokumenten sollte die Anzahl der indizierten Dokumente um Gr√∂√üenordnungen h√∂her sein als die Anzahl der zu pr√ºfenden Dokumente.  Die aktuelle Version unseres Index kann durchschnittlich mit einer Geschwindigkeit von mehr als 4000 mittleren Dokumenten pro Sekunde gef√ºllt werden. </li></ol></li></ul><br><p>  Und alles auf einer Maschine!  Ja, wir k√∂nnen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">replizieren</a> , wir n√§hern uns allm√§hlich dem dynamischen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sharding</a> in einem Cluster, aber von 2005 bis heute konnte der Index auf einem Computer mit aller Sorgfalt alle oben genannten Schwierigkeiten bew√§ltigen. </p><br><h1>  Seltsame Erfahrung </h1><br><p>  Jetzt sind wir jedoch so erfahren.  Ob es Ihnen gef√§llt oder nicht, aber auch wir sind erwachsen geworden und haben im Laufe des Wachstums verschiedene Dinge ausprobiert, an die wir uns jetzt gerne erinnern. </p><br><p><img src="https://habrastorage.org/webt/nx/l4/jx/nxl4jxkzhzumxh91qyds84byk70.jpeg"></p><br><p>  <sub><em>Bildquelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wikipedia</a></em></sub> </p><br><p>  Zun√§chst m√∂chte ein unerfahrener Leser eine SQL-Datenbank verwenden.  Sie sind nicht die Einzigen, die dies glauben. Die SQL-Implementierung hat uns seit mehreren Jahren gute Dienste geleistet, um sehr kleine Sammlungen zu implementieren.  Trotzdem lag der Fokus sofort auf Millionen von Dokumenten, also musste ich weiter gehen. </p><br><p>  Wie Sie wissen, mag niemand Fahrr√§der, und LevelDB war noch nicht gemeinfrei. 2010 fielen unsere Augen auf BerkeleyDB.  Alles ist cool - eine best√§ndige integrierte Schl√ºsselwertbasis mit geeigneten Btree- und Hash-Zugriffsmethoden und einer langen Geschichte.  Alles mit ihr war wunderbar, aber: </p><br><ul><li>  Im Fall einer Hash-Implementierung fiel sie einfach ab, wenn sie ein Volumen von 2 GB erreichte.  Ja, wir haben immer noch im 32-Bit-Modus gearbeitet. </li><li>  Die Implementierung des B + -Baums funktionierte stabil, aber bei einem Volumen von mehr als einigen Gigabyte begann die Suchgeschwindigkeit erheblich zu sinken. </li></ul><br><p>  Wir m√ºssen zugeben, dass wir nie einen Weg gefunden haben, es an unsere Aufgabe anzupassen.  Vielleicht liegt das Problem in .net-Bindungen, die noch erledigt werden mussten.  Die BDB-Implementierung wurde schlie√ülich als Ersatz f√ºr SQL als Zwischenindex verwendet, bevor der Hauptindex ausgef√ºllt wurde. </p><br><p>  Die Zeit verging.  2014 haben sie LMDB und LevelDB ausprobiert, aber nicht implementiert.  Die Leute von unserer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anti-Plagiat-</a> Forschungsabteilung verwendeten RocksDB als Index.  Auf den ersten Blick war es ein Fund.  Aber die langsame Auff√ºllung und die mittelm√§√üige Suchgeschwindigkeit selbst bei kleinen Mengen brachten alles umsonst. </p><br><p>  Wir haben all das getan, w√§hrend wir unseren eigenen benutzerdefinierten Index entwickelt haben.  Infolgedessen konnte er unsere Probleme so gut l√∂sen, dass wir die vorherigen ‚ÄûStecker‚Äú aufgaben und uns darauf konzentrierten, sie zu verbessern, die wir jetzt √ºberall in der Produktion verwenden. </p><br><h1>  Indexebenen </h1><br><p>  Was haben wir am Ende jetzt?  Tats√§chlich besteht der Index der Schindeln aus mehreren Schichten (Arrays) mit Elementen konstanter L√§nge - von 0 bis 128 Bit -, was nicht nur von der Schicht abh√§ngt und nicht unbedingt ein Vielfaches von acht ist. </p><br><p>  Jede der Schichten spielt eine Rolle.  Einige beschleunigen die Suche, andere sparen Platz und andere werden nie verwendet, aber wirklich ben√∂tigt.  Wir werden versuchen, sie zu beschreiben, um ihre Gesamteffizienz bei der Suche zu erh√∂hen. </p><br><p><img src="https://habrastorage.org/webt/sd/y9/ze/sdy9zefei-lyrhgpafxq9viz9pc.jpeg"></p><br><p>  <sub><em>Bildquelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wikipedia</a></em></sub> </p><br><h4>  1. Index-Array </h4><br><p>  Ohne Verlust der Allgemeinheit werden wir nun ber√ºcksichtigen, dass dem Dokument eine einzelne Schindel zugewiesen ist. </p><br><p>  <i>(docId ‚Üí Schindel)</i> </p><br><p>  Wir tauschen die Elemente des Paares aus (invertieren, da der Index tats√§chlich "invertiert" ist!). </p><br><p>  <i>(Schindel ‚Üí docId)</i> </p><br><p>  Sortieren Sie nach den Werten der Schindeln und bilden Sie eine Ebene.  Weil  Die Gr√∂√üe der Schindel und die Kennung des Dokuments sind konstant. Jetzt kann jeder, der die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bin√§re Suche versteht</a> , ein Paar finden, das √ºber die <b>O (logn)</b> -Lesungen der Datei hinausgeht.  Was f√ºr eine Menge, verdammt viel.  Aber das ist besser als nur <b>O (n)</b> . </p><br><p>  Wenn das Dokument mehrere Schindeln aufweist, enth√§lt das Dokument mehrere solcher Paare.  Wenn es mehrere Dokumente mit demselben Schindel gibt, √§ndert sich auch nicht viel daran - es gibt mehrere Paare hintereinander mit demselben Schindel.  In beiden F√§llen wird die Suche f√ºr eine vergleichbare Zeit durchgef√ºhrt. </p><br><h4>  2. Array von Gruppen </h4><br><p>  Wir unterteilen die Elemente des Index aus dem vorherigen Schritt auf bequeme Weise sorgf√§ltig in Gruppen.  Damit sie beispielsweise in <s>den Clustersektor</s> passen <s>, bildet der</s> Zuordnungseinheitsblock (gelesen, 4096 Byte) unter Ber√ºcksichtigung der Anzahl der Bits und anderer Tricks ein effektives W√∂rterbuch.  Wir erhalten eine einfache Reihe von Positionen solcher Gruppen: </p><br><p>  <i>group_map (Hash (Shingle)) -&gt; group_position.</i> </p><br><p>  Bei der Suche nach einem Stein suchen wir nun zuerst nach der Position der Gruppe in diesem W√∂rterbuch, entladen dann die Gruppe und suchen direkt im Speicher.  Der gesamte Vorgang erfordert zwei Lesevorg√§nge. </p><br><p>  Das W√∂rterbuch der Gruppenpositionen ben√∂tigt mehrere Gr√∂√üenordnungen weniger Platz als der Index selbst. Oft kann es einfach in den Speicher entladen werden.  Es wird also nicht zwei, sondern eine Lesung geben.  Insgesamt <b>O (1)</b> . </p><br><h4>  3. Bloom Filter </h4><br><p>  Bei Interviews l√∂sen Kandidaten h√§ufig Probleme, indem sie eindeutige L√∂sungen mit <b>O (n ^ 2)</b> oder sogar <b>O (2 ^ n) herausgeben</b> .  Aber wir machen keine dummen Dinge.  Gibt es <b>O (0)</b> auf der Welt, das ist die Frage?  Versuchen wir es ohne gro√üe Hoffnung auf ein Ergebnis ... </p><br><p>  Wenden wir uns dem Themenbereich zu.  Wenn der Sch√ºler gut gemacht ist und die Arbeit selbst geschrieben hat oder einfach kein Text, sondern M√ºll vorhanden ist, ist ein wesentlicher Teil seiner Schindeln einzigartig und wird nicht im Index gefunden.  Eine solche Datenstruktur wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Bloom-Filter ist</a> in der Welt bekannt.  √úberpr√ºfen Sie vor der Suche die Schindel darauf.  Wenn der Index keine Schindel enth√§lt, k√∂nnen Sie nicht weiter suchen, andernfalls gehen Sie weiter. </p><br><p>  Der Bloom-Filter selbst ist recht einfach, aber es macht keinen Sinn, einen Hash-Vektor f√ºr unsere Volumes zu verwenden.  Es reicht aus, eins zu verwenden: <b>+1</b> Messwert aus dem Bloom-Filter.  Dies ergibt <b>-1</b> oder <b>-2</b> Messwerte aus den nachfolgenden Stufen, falls die Schindel eindeutig ist und im Filter kein falsches Positiv vorhanden war.  Pass auf deine H√§nde auf! </p><br><p>  Die Wahrscheinlichkeit eines Bloom-Filterfehlers wird w√§hrend der Konstruktion festgelegt, die Wahrscheinlichkeit eines unbekannten Schindels wird durch die Ehrlichkeit des Sch√ºlers bestimmt.  Einfache Berechnungen k√∂nnen zu folgender Abh√§ngigkeit f√ºhren: </p><br><ul><li>  Wenn wir der Ehrlichkeit der Menschen vertrauen (d. H. Tats√§chlich ist das Dokument original), nimmt die Suchgeschwindigkeit ab. </li><li>  Wenn das Dokument klar zusammengef√ºgt ist, erh√∂ht sich die Suchgeschwindigkeit, aber wir ben√∂tigen viel Speicher. </li></ul><br><p>  Mit dem Vertrauen in die Sch√ºler haben wir das Prinzip ‚ÄûVertrauen, aber √ºberpr√ºfen‚Äú, und die Praxis zeigt, dass der Bloom-Filter immer noch einen Gewinn bringt. </p><br><p>  Da diese Datenstruktur auch kleiner als der Index selbst ist und zwischengespeichert werden kann, k√∂nnen Sie den Shingle im besten Fall ohne Datentr√§gerzugriff l√∂schen. </p><br><h4>  4. Schwere Schw√§nze </h4><br><p>  Es gibt Schindeln, die fast √ºberall zu finden sind.  Ihr Anteil an der Gesamtzahl ist gering, aber wenn der Index im ersten Schritt erstellt wird, k√∂nnen im zweiten Schritt Gruppen von zehn und Hunderten von MB erhalten werden.  Wir werden sie separat speichern und sie sofort aus der Suchabfrage entfernen. </p><br><p>  Als dieser triviale Schritt 2011 zum ersten Mal verwendet wurde, halbierte sich die Gr√∂√üe des Index und die Suche selbst wurde beschleunigt. </p><br><h4>  5. Andere Schw√§nze </h4><br><p>  Trotzdem kann eine Schindel viele Dokumente haben.  Und das ist normal.  Zehn, Hunderte, Tausende ... Wenn sie im Hauptindex bleiben, wird dies unrentabel. Sie passen m√∂glicherweise auch nicht in die Gruppe. Dadurch wird das Volumen des W√∂rterbuchs der Gruppenpositionen aufgeblasen.  Platzieren Sie sie in einer separaten Reihenfolge mit effizienterer Speicherung.  Laut Statistik ist eine solche Entscheidung mehr als gerechtfertigt.  Dar√ºber hinaus k√∂nnen verschiedene bitweise Pakete die Anzahl der Festplattenzugriffe und das Volumen des Index verringern. </p><br><p>  Aus Gr√ºnden der Wartungsfreundlichkeit drucken wir alle diese Ebenen in einem gro√üen Dateiblock.  Es gibt zehn solcher Schichten.  Ein Teil wird jedoch nicht f√ºr die Suche verwendet, ein Teil ist sehr klein und wird immer im Speicher gespeichert. Ein Teil wird nach Bedarf / M√∂glichkeit aktiv zwischengespeichert. </p><br><p>  Im Kampf kommt es bei der Suche nach einem Stein meistens auf ein oder zwei zuf√§llige Dateimessungen an.  Im schlimmsten Fall m√ºssen Sie drei machen.  Alle Schichten sind effektiv (manchmal bitweise) gepackte Arrays von Elementen konstanter L√§nge.  Das ist Normalisierung.  Die Zeit zum Auspacken ist im Vergleich zum Preis des Gesamtvolumens w√§hrend der Lagerung und der F√§higkeit, besser zwischenzuspeichern, unbedeutend. </p><br><p>  Beim Konstruieren werden die Gr√∂√üen der Schichten haupts√§chlich im Voraus berechnet und nacheinander geschrieben, so dass dieses Verfahren ziemlich schnell ist. </p><br><h1>  Wie sind Sie dorthin gekommen, wussten nicht wo </h1><br><p></p><blockquote><code>     2010         ,                .    ,          .  ,      .</code> </blockquote> <br><p><img src="https://habrastorage.org/webt/2x/f7/-f/2xf7-fs8nt4rmfx7cvmeyyb_ftq.jpeg"></p><br><p>  <sub><em>Bildquelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wikipedia</a></em></sub> </p><br><p>  Anf√§nglich bestand unser Index aus zwei Teilen - einer oben beschriebenen Konstante und einer tempor√§ren, deren Rolle entweder SQL oder BDB oder ein eigenes Aktualisierungsprotokoll war.  Gelegentlich, zum Beispiel einmal im Monat (und manchmal im Jahr), wird die tempor√§re Datei sortiert, gefiltert und mit der Hauptversion zusammengef√ºhrt.  Das Ergebnis war ein einheitliches, und die beiden alten wurden entfernt.  Wenn der tempor√§re nicht in den RAM passen konnte, wurde die Prozedur extern sortiert. </p><br><p>  Dieses Verfahren war ziemlich m√ºhsam, es wurde im halbmanuellen Modus gestartet und erforderte das Umschreiben der gesamten Indexdatei von Grund auf neu.  Hunderte von Gigabyte f√ºr ein paar Millionen Dokumente umschreiben - na ja, so lala Vergn√ºgen, sage ich Ihnen ... </p><br><p></p><div class="spoiler">  <b class="spoiler_title">Erinnerungen aus der Vergangenheit ...</b> <div class="spoiler_text"><blockquote> <code>       SSD.        ,  31    SSD          wcf-       .  ,          . ,  .</code> </blockquote> </div></div><br><p>  Damit die SSD nicht besonders belastet ist und der Index h√§ufiger aktualisiert wird, haben wir 2012 eine Kette von mehreren Teilen, Chunks nach folgendem Schema, eingebunden: </p><br><p><img src="https://habrastorage.org/webt/v4/5s/xo/v45sxoctvil0bhwkf2pfp7vamrs.png"></p><br><p>  Hier besteht der Index bis auf die allererste aus einer Kette derselben Art von Chunks.  Das erste Addon war ein Nur-Anh√§ngen-Protokoll mit einem Index im RAM.  Nachfolgende Brocken nahmen bis zum letzten Mal an Gr√∂√üe (und Alter) zu (Null, Haupt, Wurzel, ...). </p><br><p></p><div class="spoiler">  <b class="spoiler_title">Hinweis f√ºr Radfahrer ...</b> <div class="spoiler_text">  Manchmal sollten Sie nicht ratlos sein, Code zu schreiben und nicht einmal nachzudenken, sondern ihn nur gr√ºndlicher googeln.  Bis zur Notation √§hnelt das Diagramm dem aus dem Artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûDer logarithmisch strukturierte Zusammenf√ºhrungsbaum‚Äú von 1996</a> : <img src="https://habrastorage.org/webt/1z/r2/yh/1zr2yhxxboh0syuyfozcujnm5hm.png"></div></div><br><p>  Beim Hinzuf√ºgen eines Dokuments wurde es zuerst zu einem Addon gefaltet.  Wenn es voll war oder nach anderen Kriterien, wurde ein permanenter Block darauf gebaut.  Falls erforderlich, wurden die benachbarten mehreren Bl√∂cke zu einem neuen zusammengef√ºhrt, und die urspr√ºnglichen wurden gel√∂scht.  Das Aktualisieren oder L√∂schen eines Dokuments hat auf die gleiche Weise funktioniert. </p><br><p>  Zusammenf√ºhrungskriterien, Kettenl√§nge, Bypass-Algorithmus, Ber√ºcksichtigung gel√∂schter Elemente und Aktualisierungen, andere Parameter wurden optimiert.  Der Ansatz selbst war an mehreren √§hnlichen Aufgaben beteiligt und nahm als separates internes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LSM-</a> Framework auf einem sauberen .net Gestalt an.  Etwa zur gleichen Zeit wurde LevelDB popul√§r. </p><br><p></p><div class="spoiler">  <b class="spoiler_title">Kleine Bemerkung zum LSM-Baum</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LSM-Tree ist ein</a> ziemlich interessanter Algorithmus mit guter Begr√ºndung.  Aber meiner Meinung nach gab es einige Unsch√§rfen in der Bedeutung des Begriffs Baum.  Im urspr√ºnglichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel ging</a> es um eine Baumkette mit der F√§higkeit, √Ñste zu √ºbertragen.  In modernen Implementierungen ist dies nicht immer der Fall.  So wurde unser Framework schlie√ülich als LsmChain bezeichnet, dh als lsm-Kette von Chunks. </div></div><br><p>  Der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LSM-</a> Algorithmus hat in unserem Fall sehr geeignete Eigenschaften: </p><br><ol><li>  sofortiges Einf√ºgen / L√∂schen / Aktualisieren, </li><li>  reduzierte Belastung von SSDs w√§hrend des Updates, </li><li>  vereinfachtes Chunks-Format, </li><li>  selektive Suche nur nach alten / neuen St√ºcken, </li><li>  triviales Backup </li><li>  was die Seele sonst noch will. </li><li>  ... </li></ol><br><p>  Im Allgemeinen ist es manchmal n√ºtzlich, Fahrr√§der zur Selbstentwicklung zu erfinden. </p><br><h1>  Makro-, Mikro-, Nano-Optimierung </h1><br><p>  Und schlie√ülich werden wir technische Tipps dazu geben, wie wir im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Antiplagiat</a> solche Dinge auf .Net tun (und nicht nur darauf). </p><br><p>  Beachten Sie im Voraus, dass oft alles sehr stark von Ihrer spezifischen Hardware, Ihren Daten oder Ihrem Nutzungsmodus abh√§ngt.  Nachdem wir uns an einer Stelle verdreht haben, fliegen wir aus dem CPU-Cache heraus, an einer anderen - wir sto√üen auf die Bandbreite der SATA-Schnittstelle, an der dritten - beginnen wir, im GC zu h√§ngen.  Und irgendwo in der Ineffizienz der Implementierung eines bestimmten Systemaufrufs. </p><br><p><img src="https://habrastorage.org/webt/gl/pq/sp/glpqspyystghvhhemtthxysivp0.jpeg"></p><br><p>  <sub><em>Bildquelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wikipedia</a></em></sub> </p><br><h1>  Mit Datei arbeiten </h1><br><p>  Das Problem mit dem Zugriff auf die Datei ist bei uns nicht eindeutig.  Es gibt eine gro√üe <s>Terabyte-Exabyte-</s> Datei, deren Volumen um ein Vielfaches gr√∂√üer ist als die RAM-Gr√∂√üe.  Die Aufgabe besteht darin, die Millionen verstreuter kleiner Zufallswerte zu lesen.  Und das schnell, effizient und kosteng√ºnstig.  Wir m√ºssen viel quetschen, messen und nachdenken. </p><br><p>  Beginnen wir mit einem einfachen.  Um das gesch√§tzte Byte zu lesen, ben√∂tigen Sie: </p><br><ol><li>  Datei √∂ffnen (neuer FileStream); </li><li>  Bewegen Sie sich zur gew√ºnschten Position (Position oder Suche, kein Unterschied); </li><li>  Lesen Sie das gew√ºnschte Byte-Array (Lesen); </li><li>  Schlie√üen Sie die Datei (Entsorgen). </li></ol><br><p>  Und das ist schlecht, weil es lang und trostlos ist.  Durch Versuch, Irrtum und wiederholtes Treten auf den Rechen haben wir den folgenden Aktionsalgorithmus identifiziert: </p><br><ul><li><p>  <b>Einfach offen, mehrfach gelesen</b> </p><br><p>  Wenn diese Sequenz f√ºr jede Anforderung an die Festplatte in der Stirn ausgef√ºhrt wird, werden wir uns schnell biegen.  Jedes dieser Elemente geht in eine Anfrage an den Betriebssystemkern ein, was teuer ist. </p><br><p>  Nat√ºrlich sollten Sie die Datei einmal √∂ffnen und nacheinander alle Millionen unserer Werte daraus lesen, was wir auch tun </p></li><li><p>  <b>Nichts extra</b> </p><br><p>  Das Abrufen der Dateigr√∂√üe und der aktuellen Position ist ebenfalls recht schwierig.  Auch wenn sich die Datei nicht ge√§ndert hat. </p><br><p>  Fragen wie das Abrufen der Dateigr√∂√üe oder der aktuellen Position sollten vermieden werden. </p></li><li><p>  <b>Filestreampool</b> </p><br><p>  Weiter.  Leider ist FileStream im Wesentlichen Single-Threaded.  Wenn Sie eine Datei parallel lesen m√∂chten, m√ºssen Sie neue Dateistreams erstellen / schlie√üen. </p><br><p>  Bis Sie so etwas wie Aiosync erstellen, m√ºssen Sie Ihre eigenen Fahrr√§der erfinden. </p><br><p>  Mein Rat ist, einen Pool von Dateistreams pro Datei zu erstellen.  So vermeiden Sie Zeitverschwendung beim √ñffnen / Schlie√üen einer Datei.  Und wenn Sie es mit ThreadPool kombinieren und ber√ºcksichtigen, dass die SSD ihre MegaIOPS mit starkem Multithreading ausgibt ... Nun, Sie verstehen mich. </p></li><li><p>  <b>Zuordnungseinheit</b> </p><br><p>  Weiter.  Speicherger√§te (HDD, SSD, Optane) und das Dateisystem arbeiten mit Dateien auf Blockebene (Cluster, Sektor, Zuordnungseinheit).  Sie stimmen m√∂glicherweise nicht √ºberein, aber jetzt sind es fast immer 4096 Bytes.  Das Lesen von ein oder zwei Bytes an der Grenze zweier solcher Bl√∂cke in einer SSD ist etwa eineinhalb Mal langsamer als im Block selbst. </p><br><p>  Sie sollten Ihre Daten so organisieren, dass die subtrahierten Elemente innerhalb der Grenzen des <s>Clustersektorblocks liegen</s> . </p></li><li><p>  <b>Kein Puffer.</b> </p><br><p>  Weiter.  FileStream verwendet standardm√§√üig einen 4096-Byte-Puffer.  Und die schlechte Nachricht ist, dass Sie es nicht ausschalten k√∂nnen.  Wenn Sie jedoch mehr Daten als die Gr√∂√üe des Puffers lesen, wird letzterer ignoriert. </p><br><p>  F√ºr zuf√§lliges Lesen sollten Sie den Puffer auf 1 Byte setzen (es wird nicht weniger funktionieren) und dann ber√ºcksichtigen, dass er nicht verwendet wird. </p></li><li><p>  <b>Puffer verwenden.</b> </p><br><p>  Neben zuf√§lligen Messwerten gibt es auch sequentielle.  Hier kann der Puffer bereits n√ºtzlich werden, wenn Sie nicht alles auf einmal lesen m√∂chten.  Ich rate Ihnen, mit diesem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> zu beginnen.  Welche Gr√∂√üe des Puffers eingestellt werden soll, h√§ngt davon ab, ob sich die Datei auf der Festplatte oder auf der SSD befindet.  Im ersten Fall ist 1 MB optimal, im zweiten Fall sind 4 KB Standard.  Wenn die Gr√∂√üe des zu lesenden Datenbereichs mit diesen Werten vergleichbar ist, ist es besser, ihn sofort zu subtrahieren und den Puffer zu √ºberspringen, wie im Fall des zuf√§lligen Lesens.  Gro√üe Puffer bringen keinen Gewinn in der Geschwindigkeit, treffen aber auf GC. </p><br><p>  Wenn Sie nacheinander gro√üe Teile der Datei lesen, sollten Sie den Puffer f√ºr die Festplatte auf 1 MB und f√ºr die SSD auf 4 KB einstellen.  Nun, es kommt darauf an. </p></li></ul><br><h1>  MMF gegen FileStream </h1><br><p>  Im Jahr 2011 kam ein Tipp zu MemoryMappedFile, da dieser Mechanismus seit .Net Framework v4.0 implementiert ist.  Erstens verwendeten sie es beim Zwischenspeichern des Bloom-Filters, was im 32-Bit-Modus aufgrund der 4-GB-Beschr√§nkung bereits unpraktisch war.  Aber als ich in die Welt der 64-Bits einstieg, wollte ich mehr.  Die ersten Tests waren beeindruckend.  Kostenloses Caching, Freak-Geschwindigkeit und praktische Strukturleseschnittstelle.  Aber es gab Probleme: </p><br><ul><li>  Erstens, seltsamerweise, Geschwindigkeit.  Wenn die Daten bereits zwischengespeichert sind, ist alles in Ordnung.  Wenn nicht, ging das Lesen eines Bytes aus der Datei mit einem ‚ÄûAnheben‚Äú einer viel gr√∂√üeren Datenmenge einher als beim normalen Lesen. </li><li>  Zweitens seltsamerweise Erinnerung.  Beim Erhitzen w√§chst der gemeinsame Speicher, das Arbeitsset - nein, was logisch ist.  Aber dann beginnen sich die benachbarten Prozesse nicht sehr gut zu verhalten.  Sie k√∂nnen in einen Tausch gehen oder versehentlich von OoM fallen.  Die vom MMF im RAM belegte Lautst√§rke kann leider nicht gesteuert werden.  Und der Gewinn aus dem Cache in dem Fall, in dem die lesbare Datei einige Gr√∂√üenordnungen gr√∂√üer ist als der Speicher, wird bedeutungslos. </li></ul><br><p>  Das zweite Problem konnte noch bek√§mpft werden.  Es verschwindet, wenn der Index im Docker oder auf einer dedizierten virtuellen Maschine funktioniert.  Aber das Geschwindigkeitsproblem war fatal. </p><br><p>  Infolgedessen wurde der Geldmarktfonds etwas mehr als vollst√§ndig aufgegeben.  Das Caching im Anti-Plagiat begann in expliziter Form, wobei nach M√∂glichkeit die am h√§ufigsten verwendeten Ebenen mit den angegebenen Priorit√§ten und Grenzen gespeichert wurden. </p><br><p><img src="https://habrastorage.org/webt/qr/em/sd/qremsdrzpkqcxqrbam_finb4dyw.jpeg"></p><br><p>  <sub><em>Bildquelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wikipedia</a></em></sub> </p><br><h1>  Bits / Bytes </h1><br><p>  Nicht Bytes die Welt ist eins.  Manchmal muss man auf die Bitebene gehen. </p><br><p>  Beispiel: Angenommen, Sie haben eine Billion teilweise geordneter Nummern, die h√§ufig gespeichert und gelesen werden sollen.  Wie arbeite ich mit all dem? </p><br><ul><li>  Einfacher BinaryWriter.Write?  - schnell aber langsam.  Gr√∂√üe ist wichtig.  Das kalte Lesen h√§ngt haupts√§chlich von der Gr√∂√üe der Datei ab. </li><li>  Eine andere Variante von VarInt?  - schnell aber langsam.  Konsistenz ist wichtig.  Die Lautst√§rke h√§ngt von den Daten ab, f√ºr deren Positionierung zus√§tzlicher Speicher erforderlich ist. </li><li>  Bitverpackung?  - schnell aber langsam.  Sie m√ºssen Ihre H√§nde genauer kontrollieren. </li></ul><br><p>  Es gibt keine ideale L√∂sung, aber im speziellen Fall wird durch einfaches Komprimieren des Bereichs von 32 Bit auf das zum Speichern der Schw√§nze erforderliche 12% mehr (zig GB!) Als durch VarInt gespart (wobei nat√ºrlich nur der Unterschied der benachbarten gespeichert wird), und das mehrmals Grundoption. </p><br><p>  Ein weiteres Beispiel.  Sie haben einen Link in einer Datei zu einem Array von Zahlen.  Link 64-Bit-Datei pro Terabyte.  Alles scheint in Ordnung zu sein.  Manchmal gibt es viele Zahlen im Array, manchmal wenige.  Oft ein bisschen.  Sehr oft.  Nehmen Sie dann einfach das gesamte Array und speichern Sie es im Link selbst.  Gewinn  Sorgf√§ltig verpacken, aber nicht vergessen. </p><br><h1>  Struktur, unsicher, Dosierung, Mikrooptionen </h1><br><p>  Gut und andere Mikrooptimierung.  Ich werde hier nicht √ºber das Banale schreiben: "Lohnt es sich, die L√§nge des Arrays in einer Schleife zu speichern?" Oder "Was ist schneller, f√ºr oder f√ºr jeden?". </p><br><p>  Es gibt zwei einfache Regeln, an die wir uns halten werden: 1. "Alles messen", 2. "Mehr Benchmark". </p><br><ul><li><p>  <b>Struct</b> .  √úberall verwendet.  GC nicht versenden.  Und wie es heute in Mode ist, haben wir auch unsere eigene mega-schnelle ValueList. </p></li><li><p>  <b>Unsicher</b> .  Erm√∂glicht die Zuordnung (und Nichtzuordnung) von Strukturen zu einem Array von Bytes, wenn diese verwendet werden.  Daher ben√∂tigen wir keine separaten Serialisierungsmittel.  Es gibt zwar Fragen zum Fixieren und Defragmentieren des Haufens, aber bisher wurde dies nicht gezeigt.  Nun, es kommt darauf an. </p></li><li><p>  <b>Batching</b> .  Die Arbeit mit vielen Elementen sollte √ºber Packs / Gruppen / Bl√∂cke erfolgen.  Datei lesen / schreiben, zwischen Funktionen √ºbertragen.  Ein separates Problem ist die Gr√∂√üe dieser Packs.  Normalerweise gibt es ein Optimum, und seine Gr√∂√üe liegt h√§ufig im Bereich von 1 KB bis 8 MB (CPU-Cache-Gr√∂√üe, Cluster-Gr√∂√üe, Seitengr√∂√üe, Gr√∂√üe von etwas anderem).  Pumpen Sie durch die Funktion IEnumerable &lt;Byte&gt; oder IEnumerable &lt;Byte [1024]&gt; und sp√ºren Sie den Unterschied. </p></li><li><p>  <b>Pooling</b> .  Jedes Mal, wenn Sie "neu" schreiben, stirbt irgendwo ein K√§tzchen.  Einmal neues Byte [ <a href="">85000</a> ] - und der Traktor ritt eine Tonne G√§nse.  Wenn es nicht m√∂glich ist, stackalloc zu verwenden, erstellen Sie einen Pool von Objekten und verwenden Sie ihn erneut. </p></li><li><p>  <b>Inlining</b> .  Wie kann man zwei Funktionen anstelle einer erstellen, um alles zehnmal zu beschleunigen?  Einfach.  Je kleiner der Funktionsk√∂rper (Methode) ist, desto wahrscheinlicher ist es, dass er inline ist.  Leider gibt es in der Dotnet-Welt immer noch keine M√∂glichkeit, partielles Inlining durchzuf√ºhren. Wenn Sie also eine Hot-Funktion haben, die in 99% der F√§lle nach der Verarbeitung der ersten paar Zeilen herauskommt und die verbleibenden hundert Zeilen die verbleibenden 1% verarbeiten, teilen Sie sie sicher in zwei (oder drei), die den schweren Schwanz in eine separate Funktion tragen. </p></li></ul><br><h1>  Was noch? </h1><br><ul><li><p>  <b>Span &lt;T&gt;</b> , <b>Memory &lt;T&gt;</b> - vielversprechend.  Der Code wird einfacher und vielleicht etwas schneller.  Wir warten auf die Ver√∂ffentlichung von .Net Core v3.0 und Std v2.1, um zu ihnen zu wechseln, weil  unser Kernel auf .Net Std v2.0, der normalerweise keine Spans unterst√ºtzt. </p></li><li><p>  <b>Async / warten</b> - bisher umstritten.  Die einfachsten Benchmarks f√ºr zuf√§lliges Lesen zeigten, dass der CPU-Verbrauch tats√§chlich sinkt, aber auch die Lesegeschwindigkeit abnimmt.  Muss aufpassen.  Innerhalb des Index verwenden wir ihn noch nicht. </p></li></ul><br><h1>  Fazit </h1><br><p>  Ich hoffe, dass meine Abgeschiedenheit Ihnen Freude macht, die Sch√∂nheit einiger Entscheidungen zu verstehen.  Unser Index gef√§llt uns sehr gut.  Es ist effizienter, sch√∂ner Code, funktioniert gro√üartig.  Eine hochspezialisierte L√∂sung im Kern des Systems, dem kritischen Ort seiner Arbeit, ist besser als die allgemeine.  Unser Versionskontrollsystem merkt sich Assembler-Einf√ºgungen in C ++ - Code.  Jetzt gibt es vier Pluspunkte - nur reines C #, nur .Net.  Darauf schreiben wir selbst die komplexesten Suchalgorithmen und bereuen es √ºberhaupt nicht.  Mit dem Aufkommen von .Net Core, dem √úbergang zu Docker, ist der Weg in eine gl√§nzende DevOps-Zukunft einfacher und klarer geworden.  Vor uns liegt die L√∂sung des Problems der dynamischen Shardisierung und Replikation, ohne die Effektivit√§t und Sch√∂nheit der L√∂sung zu beeintr√§chtigen. </p><br><p>  Vielen Dank an alle, die bis zum Ende gelesen haben.  F√ºr alle Unstimmigkeiten und sonstigen Inkonsistenzen schreiben Sie bitte Kommentare.  Ich freue mich √ºber jeden vern√ºnftigen Rat und jede Widerlegung in den Kommentaren. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de445952/">https://habr.com/ru/post/de445952/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de445932/index.html">Sicherheit von Clientanwendungen: Praktische Tipps f√ºr einen Front-End-Entwickler</a></li>
<li><a href="../de445936/index.html">Elektronikentwicklung. √úber Mikrocontroller an den Fingern</a></li>
<li><a href="../de445940/index.html">AMA mit Habr, v 7.0. Zitrone, Donuts und Nachrichten</a></li>
<li><a href="../de445946/index.html">MWC: Gebrauchsanweisung</a></li>
<li><a href="../de445948/index.html">Vererbung in C ++: Anf√§nger, Mittelstufe, Fortgeschrittene</a></li>
<li><a href="../de445954/index.html">AI-Beschleuniger von HSE, MTS und Rostelecom</a></li>
<li><a href="../de445958/index.html">SPDS GraphiCS - Fassaden- und Dachsystem</a></li>
<li><a href="../de445962/index.html">Praktikum in IT: Sicht des Managers</a></li>
<li><a href="../de445964/index.html">MEPhI wird eine Olympiade zur Informationssicherheit f√ºr Studenten veranstalten: wie man teilnimmt und was es gibt</a></li>
<li><a href="../de445966/index.html">Anmerkung des Frontend-Architekten Nr. 1. Sie k√∂nnen Redux nicht einfach herunterladen und verwenden.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
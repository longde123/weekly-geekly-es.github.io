<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåª ü§úüèΩ üèâ A arquitetura do balanceador de carga de rede no Yandex.Cloud üåç üëàüèæ üíò</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√°, sou Sergey Elantsev, estou desenvolvendo um balanceador de carga de rede no Yandex.Cloud. Anteriormente, liderei o desenvolvimento do balanceador...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>A arquitetura do balanceador de carga de rede no Yandex.Cloud</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/448588/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/8p/s5/_f/8ps5_f3kanb-pmkeuze4rdd971i.png" width="430"></div><br>  Ol√°, sou Sergey Elantsev, estou desenvolvendo um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">balanceador de carga de rede</a> no Yandex.Cloud.  Anteriormente, liderei o desenvolvimento do balanceador L7 do portal Yandex - meus colegas brincam que, n√£o importa o que eu fa√ßa, eu tenho um balanceador.  Vou dizer aos leitores da Habr como gerenciar a carga na plataforma de nuvem, como vemos a ferramenta ideal para alcan√ßar esse objetivo e como estamos caminhando para a constru√ß√£o dessa ferramenta. <a name="habracut"></a><br><br>  Primeiro, apresentamos alguns termos: <br><br><ul><li>  VIP (IP virtual) - endere√ßo IP do balanceador </li><li>  Servidor, back-end, inst√¢ncia - uma m√°quina virtual com um aplicativo em execu√ß√£o </li><li>  RIP (IP Real) - endere√ßo IP do servidor </li><li>  Healthcheck - verifica√ß√£o de disponibilidade do servidor </li><li>  Zona de disponibilidade, AZ - infraestrutura isolada no data center </li><li>  Regi√£o - a uni√£o de diferentes AZ </li></ul><br>  Os balanceadores de carga resolvem tr√™s tarefas principais: realizam o pr√≥prio balanceamento, melhoram a toler√¢ncia a falhas do servi√ßo e simplificam seu dimensionamento.  A toler√¢ncia a falhas √© garantida pelo controle autom√°tico de tr√°fego: o balanceador monitora o estado do aplicativo e exclui inst√¢ncias do balanceamento que falham no teste de disponibilidade.  O dimensionamento √© garantido pela distribui√ß√£o uniforme da carga entre inst√¢ncias, bem como pela atualiza√ß√£o da lista de inst√¢ncias em tempo real.  Se o balanceamento n√£o for suficientemente uniforme, algumas das inst√¢ncias receber√£o uma carga que excede o limite de capacidade de trabalho e o servi√ßo se tornar√° menos confi√°vel. <br><br>  O balanceador de carga geralmente √© classificado por n√≠vel de protocolo no modelo OSI em que √© executado.  O Cloud Balancer opera no n√≠vel TCP, que corresponde ao quarto n√≠vel, L4. <br><br>  Vamos passar para uma revis√£o da arquitetura do balanceador de nuvem.  Aumentaremos gradualmente o n√≠vel de detalhe.  Dividimos os componentes do balanceador em tr√™s classes.  A classe do plano de configura√ß√£o √© respons√°vel pela intera√ß√£o do usu√°rio e armazena o estado de destino do sistema.  O plano de controle armazena o estado atual do sistema e gerencia os sistemas da classe de plano de dados, que s√£o diretamente respons√°veis ‚Äã‚Äãpela entrega de tr√°fego dos clientes para suas inst√¢ncias. <br><br><h3>  Plano de dados </h3><br>  O tr√°fego cai em dispositivos caros chamados roteadores de borda.  Para aumentar a toler√¢ncia a falhas, v√°rios desses dispositivos funcionam simultaneamente em um data center.  Em seguida, o tr√°fego vai para os balanceadores, que anunciam qualquer endere√ßo IP de broadcast para todos os AZs via BGP para clientes. <br><br><img src="https://habrastorage.org/webt/pc/jl/-n/pcjl-nh1bq9egjh1d0iv3o4u9bc.jpeg"><br><br>  O tr√°fego √© transmitido via ECMP - essa √© uma estrat√©gia de roteamento segundo a qual pode haver v√°rias rotas igualmente boas para o destino (no nosso caso, o destino ser√° o endere√ßo IP de destino) e os pacotes podem ser enviados para qualquer um deles.  Tamb√©m apoiamos o trabalho em v√°rias zonas de acesso, de acordo com o seguinte esquema: anunciamos o endere√ßo em cada uma das zonas, o tr√°fego cai no mais pr√≥ximo e j√° n√£o vai al√©m dele.  Mais adiante, postaremos mais detalhadamente o que acontece com o tr√°fego. <br><br><h3>  Plano de configura√ß√£o </h3><br>  O componente principal do plano de configura√ß√£o √© a API atrav√©s da qual as opera√ß√µes b√°sicas com balanceadores s√£o executadas: criando, excluindo, alterando a composi√ß√£o de inst√¢ncias, obtendo resultados de verifica√ß√µes de sa√∫de, etc. Por um lado, essa √© uma API REST e, por outro, costumamos usar a estrutura na nuvem gRPC, portanto, ‚Äúconvertemos‚Äù o REST em gRPC e, em seguida, usamos apenas gRPC.  Qualquer solicita√ß√£o leva √† cria√ß√£o de uma s√©rie de tarefas idempotentes ass√≠ncronas que s√£o executadas em um pool compartilhado de trabalhadores do Yandex.Cloud.  As tarefas s√£o gravadas de forma que possam ser suspensas a qualquer momento e depois reiniciadas.  Isso fornece opera√ß√µes de escalabilidade, repetibilidade e registro. <br><br><img src="https://habrastorage.org/webt/yb/ru/-c/ybru-c8q6hucu-tdqfybedsjrcu.jpeg"><br><br>  Como resultado, a tarefa da API far√° uma solicita√ß√£o ao controlador de servi√ßo do balancer, escrito em Go.  Ele pode adicionar e remover balanceadores, alterar a composi√ß√£o de back-end e configura√ß√µes. <br><br><img src="https://habrastorage.org/webt/wr/v3/v7/wrv3v7dfm1_k48ztxc9wfzvvq48.jpeg"><br><br>  O servi√ßo armazena seu estado no Yandex Database - um banco de dados gerenciado distribu√≠do que voc√™ poder√° usar em breve tamb√©m.  No Yandex.Cloud, como j√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dissemos</a> , o conceito de comida para c√£es opera: se n√≥s pr√≥prios usamos nossos servi√ßos, nossos clientes tamb√©m ter√£o prazer em us√°-los.  O Yandex Database √© um exemplo da implementa√ß√£o desse conceito.  Armazenamos todos os nossos dados no YDB e n√£o precisamos pensar em manter e dimensionar o banco de dados: esses problemas s√£o resolvidos para n√≥s, usamos o banco de dados como um servi√ßo. <br><br>  Retornamos ao controlador do balanceador.  Sua tarefa √© salvar informa√ß√µes sobre o balanceador, enviar a tarefa de verificar a prontid√£o da m√°quina virtual para o controlador de verifica√ß√£o de sa√∫de. <br><br><h3>  Controlador Healthcheck </h3><br>  Ele recebe solicita√ß√µes para alterar as regras de inspe√ß√£o, as salva no YDB, distribui tarefas para verificar os n√≥s e agrega os resultados, que s√£o salvos no banco de dados e enviados ao controlador do loadbalancer.  Ele, por sua vez, envia uma solicita√ß√£o para alterar a composi√ß√£o do cluster no plano de dados para loadbalancer-node, que discutirei abaixo. <br><br><img src="https://habrastorage.org/webt/qx/p2/ll/qxp2llhomz9slemwamgsylotd4k.jpeg" width="600"><br><br>  Vamos falar mais sobre verifica√ß√µes de sa√∫de.  Eles podem ser divididos em v√°rias classes.  As auditorias t√™m diferentes crit√©rios de sucesso.  As verifica√ß√µes de TCP precisam estabelecer com √™xito uma conex√£o em um tempo fixo.  As verifica√ß√µes de HTTP requerem uma conex√£o bem-sucedida e uma resposta com um c√≥digo de status 200. <br><br>  Al√©m disso, as verifica√ß√µes diferem na classe de a√ß√£o - elas s√£o ativas e passivas.  As verifica√ß√µes passivas simplesmente monitoram o que acontece com o tr√°fego sem tomar nenhuma a√ß√£o especial.  Isso n√£o funciona muito bem no L4, porque depende da l√≥gica dos protocolos de n√≠vel superior: no L4 n√£o h√° informa√ß√µes sobre quanto tempo a opera√ß√£o levou e se a conex√£o foi boa ou ruim.  As verifica√ß√µes ativas exigem que o balanceador envie solicita√ß√µes para cada inst√¢ncia do servidor. <br><br>  A maioria dos balanceadores de carga realiza verifica√ß√µes de anima√ß√£o por conta pr√≥pria.  N√≥s da Cloud decidimos separar essas partes do sistema para aumentar a escalabilidade.  Essa abordagem nos permitir√° aumentar o n√∫mero de balanceadores, mantendo o n√∫mero de solicita√ß√µes de verifica√ß√£o de integridade para o servi√ßo.  As verifica√ß√µes s√£o executadas por n√≥s de verifica√ß√£o de integridade separados, que s√£o usados ‚Äã‚Äãpara fragmentar e replicar destinos de teste.  √â imposs√≠vel fazer verifica√ß√µes de um host, pois isso pode falhar.  Ent√£o n√£o obteremos o estado das inst√¢ncias que ele verificou.  Realizamos verifica√ß√µes em qualquer inst√¢ncia a partir de pelo menos tr√™s n√≥s de verifica√ß√£o de integridade.  Os alvos das verifica√ß√µes dividimos entre n√≥s usando algoritmos de hash consistentes. <br><br><img src="https://habrastorage.org/webt/6u/r4/pp/6ur4pp9sk-nqulkepwvqhvb-kdg.jpeg"><br><br>  A separa√ß√£o entre balanceamento e verifica√ß√£o de sa√∫de pode levar a problemas.  Se o n√≥ de verifica√ß√£o de integridade fizer solicita√ß√µes para a inst√¢ncia, ignorando o balanceador (que atualmente n√£o atende tr√°fego), surge uma situa√ß√£o estranha: o recurso parece estar vivo, mas o tr√°fego n√£o o alcan√ßar√°.  Resolvemos esse problema da seguinte maneira: garantimos o tr√°fego de verifica√ß√£o de sa√∫de atrav√©s de balanceadores.  Em outras palavras, o esquema de mover pacotes com tr√°fego de clientes e de verifica√ß√µes de sa√∫de difere minimamente: em ambos os casos, os pacotes ir√£o para os balanceadores, que os entregar√£o aos recursos de destino. <br><br>  A diferen√ßa √© que os clientes fazem solicita√ß√µes de VIPs e as verifica√ß√µes de sa√∫de se referem a cada RIP individual.  Aqui surge um problema interessante: damos aos nossos usu√°rios a oportunidade de criar recursos em redes IP cinzas.  Imagine que existem dois propriet√°rios de nuvens diferentes que ocultaram seus servi√ßos para balanceadores.  Cada um deles possui recursos na sub-rede 10.0.0.1/24, al√©m disso, com os mesmos endere√ßos.  Voc√™ precisa ser capaz de diferenci√°-los de alguma forma, e aqui voc√™ precisa mergulhar no dispositivo da rede virtual Yandex.Cloud.  Para mais detalhes, assista ao <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">v√≠deo do evento sobre: ‚Äã‚Äãnuvem</a> , √© importante para n√≥s agora que a rede possui v√°rias camadas e possui t√∫neis que podem ser distinguidos pelo ID da sub-rede. <br><br>  Os n√≥s Healthcheck acessam balanceadores usando os chamados endere√ßos quase IPv6.  Um quase-endere√ßo √© um endere√ßo IPv6 no qual o endere√ßo IPv4 e o ID da sub-rede do usu√°rio est√£o protegidos.  O tr√°fego cai no balanceador, extrai dele o endere√ßo IPv4, substitui o IPv6 pelo IPv4 e envia o pacote para a rede do usu√°rio. <br><br>  O tr√°fego reverso segue o mesmo caminho: o balanceador v√™ que o destino √© uma rede cinza dos verificadores de sa√∫de e converte IPv4 em IPv6. <br><br><h3>  VPP - o cora√ß√£o do plano de dados </h3><br>  O balanceador √© implementado na tecnologia de Vector Packet Processing (VPP) - uma estrutura da Cisco para processamento de pacotes de tr√°fego de rede.  No nosso caso, a estrutura √© executada no topo da biblioteca de gerenciamento de espa√ßo do usu√°rio dos dispositivos de rede - Data Plane Development Kit (DPDK).  Isso fornece alto desempenho de processamento de pacotes: h√° muito menos interrup√ß√µes no kernel, n√£o h√° altern√¢ncia de contexto entre o espa√ßo do kernel e o espa√ßo do usu√°rio. <br><br>  O VPP vai ainda mais longe e reduz ainda mais o desempenho do sistema, combinando pacotes em lotes.  O aumento da produtividade se deve ao uso agressivo de caches dos processadores modernos.  Ambos os caches de dados s√£o usados ‚Äã‚Äã(pacotes s√£o processados ‚Äã‚Äãpor "vetores", os dados s√£o pr√≥ximos uns dos outros) e caches de instru√ß√µes: no VPP, o processamento de pacotes segue um gr√°fico, nos n√≥s em que existem fun√ß√µes que executam uma tarefa. <br><br>  Por exemplo, o processamento de pacotes IP no VPP ocorre na seguinte ordem: primeiro, os cabe√ßalhos dos pacotes s√£o analisados ‚Äã‚Äãno n√≥ de an√°lise e, em seguida, s√£o enviados ao n√≥ que encaminha os pacotes ainda mais, de acordo com as tabelas de roteamento. <br><br>  Um pouco de hardcore.  Os autores do VPP n√£o comprometem o uso de caches de processador; portanto, um c√≥digo de processamento de vetor de pacote t√≠pico cont√©m uma vetoriza√ß√£o manual: existe um ciclo de processamento no qual a situa√ß√£o como "temos quatro pacotes na fila" √© processada e, em seguida, a mesma para dois, ent√£o - por um.  Geralmente, s√£o usadas instru√ß√µes de pr√©-busca que carregam dados nos caches para acelerar o acesso a eles nas itera√ß√µes a seguir. <br><br><pre><code class="cpp hljs">n_left_from = frame-&gt;n_vectors; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (n_left_from &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { vlib_get_next_frame (vm, node, next_index, to_next, n_left_to_next); <span class="hljs-comment"><span class="hljs-comment">// ... while (n_left_from &gt;= 4 &amp;&amp; n_left_to_next &gt;= 2) { // processing multiple packets at once u32 next0 = SAMPLE_NEXT_INTERFACE_OUTPUT; u32 next1 = SAMPLE_NEXT_INTERFACE_OUTPUT; // ... /* Prefetch next iteration. */ { vlib_buffer_t *p2, *p3; p2 = vlib_get_buffer (vm, from[2]); p3 = vlib_get_buffer (vm, from[3]); vlib_prefetch_buffer_header (p2, LOAD); vlib_prefetch_buffer_header (p3, LOAD); CLIB_PREFETCH (p2-&gt;data, CLIB_CACHE_LINE_BYTES, STORE); CLIB_PREFETCH (p3-&gt;data, CLIB_CACHE_LINE_BYTES, STORE); } // actually process data /* verify speculative enqueues, maybe switch current next frame */ vlib_validate_buffer_enqueue_x2 (vm, node, next_index, to_next, n_left_to_next, bi0, bi1, next0, next1); } while (n_left_from &gt; 0 &amp;&amp; n_left_to_next &gt; 0) { // processing packets by one } // processed batch vlib_put_next_frame (vm, node, next_index, n_left_to_next); }</span></span></code> </pre> <br>  Portanto, as verifica√ß√µes de sa√∫de est√£o transferindo o IPv6 para o VPP, que os transforma em IPv4.  Isso √© feito pelo n√≥ do gr√°fico, que chamamos de NAT algor√≠tmico.  Para tr√°fego reverso (e convers√£o de IPv6 para IPv4), existe o mesmo n√≥ do NAT algor√≠tmico. <br><br><img src="https://habrastorage.org/webt/ug/ju/n4/ugjun48y3qurodsxpuia5lfbhn0.jpeg" width="400"><br><br>  O tr√°fego direto dos clientes do balanceador passa pelos n√≥s do gr√°fico, que realizam o pr√≥prio balanceamento. <br><br><img src="https://habrastorage.org/webt/p4/eq/uv/p4equvplkheuowkh-ddthjgxeou.jpeg"><br><br>  O primeiro n√≥ s√£o sess√µes persistentes.  Ele armazena um hash de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cinco tuplas</a> para sess√µes estabelecidas.  A tupla 5 inclui o endere√ßo e a porta do cliente a partir do qual as informa√ß√µes s√£o transmitidas, o endere√ßo e as portas dos recursos dispon√≠veis para receber tr√°fego, bem como o protocolo de rede. <br><br>  O hash de cinco tuplas nos ajuda a executar menos computa√ß√£o no n√≥ de hash consistente subsequente e tamb√©m a lidar melhor com a altera√ß√£o na lista de recursos atr√°s do balanceador.  Quando um pacote chega ao balanceador para o qual n√£o h√° sess√£o, ele √© enviado para o n√≥ de hash consistente.  √â aqui que o balanceamento ocorre usando hash consistente: selecionamos um recurso na lista de recursos "ativos" dispon√≠veis.  Em seguida, os pacotes s√£o enviados para o n√≥ NAT, que na verdade substitui o endere√ßo de destino e recalcula as somas de verifica√ß√£o.  Como voc√™ pode ver, seguimos as regras do VPP - semelhantes aos similares, agrupamos c√°lculos semelhantes para aumentar a efici√™ncia dos caches do processador. <br><br><h3>  Hashing Consistente </h3><br>  Por que o escolhemos e o que √© isso tudo?  Para come√ßar, considere a tarefa anterior - selecionando um recurso da lista. <br><br><img src="https://habrastorage.org/webt/ab/ez/jl/abezjle6p5u8g54jthaylj5duhi.jpeg"><br><br>  Com o hash n√£o consistente, o hash do pacote recebido √© calculado e o recurso √© selecionado na lista pelo restante da divis√£o desse hash pelo n√∫mero de recursos.  Enquanto a lista permanecer inalterada, esse esquema funcionar√° bem: sempre enviamos pacotes com as mesmas cinco tuplas para a mesma inst√¢ncia.  Se, por exemplo, algum recurso parar de responder √†s verifica√ß√µes de sa√∫de, uma parte significativa dos hashes mudar√° a op√ß√£o.  As conex√µes TCP ser√£o interrompidas no cliente: um pacote que foi anteriormente para a inst√¢ncia A pode come√ßar a cair para a inst√¢ncia B, que n√£o est√° familiarizada com a sess√£o para esse pacote. <br><br>  O hash consistente resolve o problema descrito.  A maneira mais f√°cil de explicar esse conceito √© a seguinte: imagine que voc√™ tenha um anel no qual distribui recursos por hash (por exemplo, por IP: porta).  A escolha de um recurso √© a rota√ß√£o da roda por um √¢ngulo, que √© determinado pelo hash do pacote. <br><br><img src="https://habrastorage.org/webt/qg/rt/yq/qgrtyq_obonzlczzouq4tcshaqq.jpeg"><br><br>  Isso minimiza a redistribui√ß√£o do tr√°fego ao alterar a composi√ß√£o dos recursos.  A exclus√£o de um recurso afetar√° apenas a parte do anel de hash consistente em que o recurso especificado foi localizado.  A adi√ß√£o de um recurso tamb√©m altera a distribui√ß√£o, mas temos um n√≥ de sess√µes persistentes que nos permite n√£o mudar as sess√µes j√° estabelecidas para novos recursos. <br><br>  Examinamos o que acontece com o tr√°fego direto entre o balanceador e os recursos.  Agora vamos lidar com o tr√°fego reverso.  Ele segue o mesmo padr√£o do tr√°fego de verifica√ß√£o - por meio de NAT algor√≠tmico, ou seja, por NAT 44 reverso para tr√°fego de clientes e por NAT 46 para verifica√ß√µes de integridade.  Aderimos ao nosso pr√≥prio esquema: unificamos o tr√°fego de verifica√ß√µes de sa√∫de e o tr√°fego real do usu√°rio. <br><br><h3>  Montagem do n√≥ do balanceador de carga e componentes </h3><br>  A composi√ß√£o de balanceadores e recursos no VPP √© relatada pelo servi√ßo local - loadbalancer-node.  Ele assina o fluxo de eventos do loadbalancer-controller, √© capaz de criar a diferen√ßa entre o estado atual do VPP e o estado de destino recebido do controlador.  Temos um sistema fechado: os eventos da API chegam ao controlador do balanceador, que define as tarefas do controlador de verifica√ß√£o de integridade para verificar a "vitalidade" dos recursos.  Isso, por sua vez, define tarefas no n√≥ de verifica√ß√£o de integridade e agrega os resultados, ap√≥s o que os envia de volta ao controlador do balanceador.  O n√≥ loadbalancer assina eventos do controlador e altera o estado do VPP.  Nesse sistema, cada servi√ßo sabe apenas o que precisa sobre os servi√ßos vizinhos.  O n√∫mero de conex√µes √© limitado e temos a oportunidade de explorar e dimensionar independentemente os v√°rios segmentos. <br><br><img src="https://habrastorage.org/webt/rk/a0/vi/rka0viu8dbcd7irrdx5m0quwfpw.jpeg"><br><br><h3>  Que perguntas foram evitadas </h3><br>  Todos os nossos servi√ßos no plano de controle est√£o escritos em Go e possuem bons recursos de dimensionamento e confiabilidade.  O Go tem muitas bibliotecas de c√≥digo aberto para criar sistemas distribu√≠dos.  Utilizamos ativamente o GRPC, todos os componentes cont√™m uma implementa√ß√£o de c√≥digo aberto da descoberta de servi√ßos - nossos servi√ßos monitoram o desempenho um do outro, podem mudar sua composi√ß√£o dinamicamente e o associamos ao balanceamento de GRPC.  Para m√©tricas, tamb√©m usamos uma solu√ß√£o de c√≥digo aberto.  No plano de dados, obtivemos um desempenho decente e uma grande reserva de recursos: tornou-se muito dif√≠cil montar um suporte no qual se pudesse descansar no desempenho do VPP, e n√£o em uma placa de rede de ferro. <br><br><h3>  Problemas e Solu√ß√µes </h3><br>  O que n√£o funcionou muito bem?  No Go, o gerenciamento de mem√≥ria √© autom√°tico, mas ocorrem vazamentos de mem√≥ria.  A maneira mais f√°cil de lidar com eles √© lan√ßar goroutines e n√£o se esque√ßa de complet√°-las.  Conclus√£o: monitore o consumo de mem√≥ria dos programas Go.  Muitas vezes, um bom indicador √© a quantidade de goroutina.  H√° uma vantagem nesta hist√≥ria: no Go, √© f√°cil obter dados em tempo de execu√ß√£o - no consumo de mem√≥ria, no n√∫mero de goroutines lan√ßadas e em muitos outros par√¢metros. <br><br>  Al√©m disso, o Go pode n√£o ser a melhor op√ß√£o para testes funcionais.  Eles s√£o bastante detalhados, e a abordagem padr√£o "execute tudo no pacote de IC" n√£o √© muito adequada para eles.  O fato √© que os testes funcionais s√£o mais exigentes em recursos, com eles h√° tempos limites reais.  Por esse motivo, os testes podem falhar porque a CPU est√° ocupada com os testes de unidade.  Conclus√£o: se poss√≠vel, realize testes "pesados" separadamente dos testes de unidade. <br><br>  A arquitetura de eventos de microsservi√ßo √© mais complicada do que um mon√≥lito: pegar logs em dezenas de m√°quinas diferentes n√£o √© muito conveniente.  Conclus√£o: se voc√™ estiver executando microsservi√ßos, pense imediatamente sobre o rastreamento. <br><br><h3>  Nossos planos </h3><br>  Iniciaremos o balanceador interno, IPv6-balancer, adicionaremos suporte aos scripts do Kubernetes, continuaremos a fragmentar nossos servi√ßos (agora apenas o n√≥ de verifica√ß√£o de sa√∫de e o healthcheck-ctrl est√£o sombreados), adicionaremos novas verifica√ß√µes de integridade e tamb√©m implementaremos a agrega√ß√£o de verifica√ß√£o inteligente.  Estamos considerando a possibilidade de tornar nossos servi√ßos ainda mais independentes - para que eles n√£o se comuniquem diretamente, mas usando uma fila de mensagens.  O servi√ßo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Yandex Message Queue</a> compat√≠vel com SQS apareceu recentemente na nuvem. <br><br>  Recentemente, o Yandex Load Balancer foi lan√ßado publicamente.  Estude a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o</a> do servi√ßo, gerencie os balanceadores de maneira conveniente para voc√™ e aumente a toler√¢ncia a falhas de seus projetos! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt448588/">https://habr.com/ru/post/pt448588/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt448574/index.html">Uma tarefa da rotina de SEO: solu√ß√£o em tr√™s etapas</a></li>
<li><a href="../pt448576/index.html">Hist√≥ria do Transistor Parte 2: Do Crisol da Guerra</a></li>
<li><a href="../pt448580/index.html">CQ CQ CQ Boas Festas, R√°dio Amador! #WorldAmateurRadioDay</a></li>
<li><a href="../pt448582/index.html">Criando uma calculadora de dicas no Kotlin: como funciona?</a></li>
<li><a href="../pt448584/index.html">7 erros comuns ao usar preposi√ß√µes em ingl√™s e como evit√°-las</a></li>
<li><a href="../pt448590/index.html">Estranhos familiares ou mais uma vez sobre o uso de padr√µes de design</a></li>
<li><a href="../pt448594/index.html">Antiv√≠rus e firewalls gratuitos (UTM, NGFW) da Sophos</a></li>
<li><a href="../pt448600/index.html">Como o Windows 10 Explore a vulnerabilidade cr√≠tica do DHCP detecta mais dois erros de seguran√ßa</a></li>
<li><a href="../pt448602/index.html">O monitoramento est√° morto? - Monitoramento ao vivo</a></li>
<li><a href="../pt448604/index.html">Gameboy em C #</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
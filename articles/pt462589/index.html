<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üì¢ üå∞ üê∫ Crie um pipeline para processamento de dados de streaming. Parte 2 üßôüèæ üÜî üë®üèø‚Äçü§ù‚Äçüë®üèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√° pessoal. Compartilhamos a tradu√ß√£o da parte final do artigo, preparada especialmente para os alunos do curso de Engenharia de Dados . A primeira p...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Crie um pipeline para processamento de dados de streaming. Parte 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/462589/">  Ol√° pessoal.  Compartilhamos a tradu√ß√£o da parte final do artigo, preparada especialmente para os alunos do curso de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Engenharia de Dados</a> .  A primeira parte pode ser encontrada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br>  <b><i>Apache Beam e DataFlow para pipelines em tempo real</i></b> <br><br><img src="https://habrastorage.org/webt/9t/uy/au/9tuyauggjylmprwx7lxswwbqggi.png"><br><br><h2>  Configura√ß√£o do Google Cloud </h2><br><blockquote>  Nota: usei o Google Cloud Shell para iniciar o pipeline e publicar os dados do log do usu√°rio, porque tive problemas ao executar o pipeline no Python 3. O Google Cloud Shell usa o Python 2, que √© melhor compat√≠vel com o Apache Beam. </blockquote><br>  Para iniciar o transportador, precisamos nos aprofundar um pouco nas configura√ß√µes.  Para aqueles que n√£o usaram o GCP antes, voc√™ deve concluir as 6 etapas a seguir nesta <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">p√°gina</a> . <a name="habracut"></a><br><br>  Depois disso, precisaremos enviar nossos scripts para o Google Cloud Storage e copi√°-los para o Google Cloud Shel.  O upload para o armazenamento na nuvem √© bastante trivial (uma descri√ß√£o pode ser encontrada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ).  Para copiar nossos arquivos, podemos abrir o Google Cloud Shel na barra de ferramentas clicando no primeiro √≠cone √† esquerda na Figura 2 abaixo. <br><br><img src="https://habrastorage.org/webt/su/hz/hq/suhzhqrmyvi6c5hneokqhhhqjuw.png"><br>  <i>Figura 2</i> <br><br>  Os comandos que precisamos para copiar arquivos e instalar as bibliotecas necess√°rias est√£o listados abaixo. <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Copy file from cloud storage gsutil cp gs://&lt;YOUR-BUCKET&gt;/ * . sudo pip install apache-beam[gcp] oauth2client==3.0.0 sudo pip install -U pip sudo pip install Faker==1.0.2 # Environment variables BUCKET=&lt;YOUR-BUCKET&gt; PROJECT=&lt;YOUR-PROJECT&gt;</span></span></code> </pre> <br><h2>  Criando nosso banco de dados e tabela </h2><br>  Depois de concluir todas as etapas de configura√ß√£o, a pr√≥xima coisa que precisamos fazer √© criar um conjunto de dados e uma tabela no BigQuery.  Existem v√°rias maneiras de fazer isso, mas o mais f√°cil √© usar o console do Google Cloud criando primeiro um conjunto de dados.  Voc√™ pode seguir as etapas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">link</a> a seguir para criar uma tabela com um esquema.  Nossa tabela ter√° <b>7 colunas</b> correspondentes aos componentes de cada log do usu√°rio.  Por conveni√™ncia, definiremos todas as colunas como strings (tipo string), com exce√ß√£o da vari√°vel timelocal, e as nomearemos de acordo com as vari√°veis ‚Äã‚Äãque geramos anteriormente.  O layout da nossa tabela deve se parecer com a Figura 3. <br><br><img src="https://habrastorage.org/webt/zw/ts/pz/zwtspziwiubrmz0c860bmvoe3so.png"><br>  <i>Figura 3. Layout da tabela</i> <br><br><h2>  Publicar dados do log do usu√°rio </h2><br>  Pub / Sub √© um componente cr√≠tico do nosso pipeline, pois permite que v√°rios aplicativos independentes interajam.  Em particular, ele funciona como um intermedi√°rio que nos permite enviar e receber mensagens entre aplicativos.  A primeira coisa que precisamos fazer √© criar um t√≥pico.  Basta ir a Pub / Sub no console e pressionar CREATE TOPIC. <br><br>  O c√≥digo abaixo chama nosso script para gerar os dados de log definidos acima e, em seguida, conecta e envia os logs para Pub / Sub.  A √∫nica coisa que precisamos fazer √© criar um objeto <b>PublisherClient</b> , especificar o caminho para o t√≥pico usando o m√©todo <code>topic_path</code> e chamar a fun√ß√£o de <code>publish</code> com <code>topic_path</code> e data.  Observe que importamos <code>generate_log_line</code> do nosso script <code>stream_logs</code> ; portanto, verifique se esses arquivos est√£o na mesma pasta, caso contr√°rio, voc√™ receber√° um erro de importa√ß√£o.  Em seguida, podemos executar isso no console do Google usando: <br><br><pre> <code class="python hljs">python publish.py</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> stream_logs <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> generate_log_line <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.cloud <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pubsub_v1 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time PROJECT_ID=<span class="hljs-string"><span class="hljs-string">"user-logs-237110"</span></span> TOPIC = <span class="hljs-string"><span class="hljs-string">"userlogs"</span></span> publisher = pubsub_v1.PublisherClient() topic_path = publisher.topic_path(PROJECT_ID, TOPIC) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">publish</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(publisher, topic, message)</span></span></span><span class="hljs-function">:</span></span> data = message.encode(<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> publisher.publish(topic_path, data = data) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">callback</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(message_future)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># When timeout is unspecified, the exception method waits indefinitely. if message_future.exception(timeout=30): print('Publishing message on {} threw an Exception {}.'.format( topic_name, message_future.exception())) else: print(message_future.result()) if __name__ == '__main__': while True: line = generate_log_line() print(line) message_future = publish(publisher, topic_path, line) message_future.add_done_callback(callback) sleep_time = random.choice(range(1, 3, 1)) time.sleep(sleep_time)</span></span></code> </pre> <br>  Assim que o arquivo √© iniciado, podemos observar a sa√≠da dos dados de log para o console, conforme mostrado na figura abaixo.  Este script funcionar√° at√© usarmos <b>CTRL + C</b> para complet√°-lo. <br><br><img src="https://habrastorage.org/webt/ho/4c/6n/ho4c6n5yfnnv8pvetgkidvut-q0.png"><br>  <i>Figura 4. Sa√≠da de <code>publish_logs.py</code></i> <i><br></i> <br><br><h2>  Escrevendo c√≥digo para nosso pipeline </h2><br>  Agora que preparamos tudo, podemos prosseguir para a parte mais interessante - escrevendo o c√≥digo do nosso pipeline usando Beam e Python.  Para criar um pipeline de viga, precisamos criar um objeto de pipeline (p).  Depois de criar o objeto de pipeline, podemos aplicar v√°rias fun√ß√µes uma ap√≥s a outra usando o operador <code>pipe (|)</code> .  Em geral, o fluxo de trabalho se parece com a imagem abaixo. <br><br><pre> <code class="python hljs">[Final Output PCollection] = ([Initial Input PCollection] | [First Transform] | [Second Transform] | [Third Transform])</code> </pre> <br>  Em nosso c√≥digo, criaremos duas fun√ß√µes definidas pelo usu√°rio.  A fun√ß√£o <code>regex_clean</code> , que verifica os dados e recupera a linha correspondente com base na lista PATTERNS usando a fun√ß√£o <code>re.search</code> .  A fun√ß√£o retorna uma string separada por v√≠rgula.  Se voc√™ n√£o √© um especialista em express√µes regulares, recomendo que voc√™ leia este <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tutorial</a> e pratique no bloco de notas para verificar o c√≥digo.  Depois disso, definimos uma fun√ß√£o ParDo personalizada chamada <b>Split</b> , que √© uma varia√ß√£o da transforma√ß√£o Beam para processamento paralelo.  No Python, isso √© feito de uma maneira especial - precisamos criar uma classe que herda da classe DoFn Beam.  A fun√ß√£o Split pega uma string analisada da fun√ß√£o anterior e retorna uma lista de dicion√°rios com chaves correspondentes aos nomes das colunas em nossa tabela do BigQuery.  H√° algo que vale a pena notar sobre essa fun√ß√£o: tive que importar a <code>datetime</code> dentro da fun√ß√£o para faz√™-la funcionar.  Eu recebi um erro de importa√ß√£o no in√≠cio do arquivo, o que foi estranho.  Essa lista √© ent√£o passada para a fun√ß√£o <b>WriteToBigQuery</b> , que simplesmente adiciona nossos dados √† tabela.  O c√≥digo para o Trabalho em DataFlow em lote e o Trabalho em fluxo de dados DataFlow √© mostrado abaixo.  A √∫nica diferen√ßa entre o lote e o c√≥digo do fluxo √© que, no processamento em lote, lemos o CSV de <code>src_path</code> usando a fun√ß√£o <code>ReadFromText</code> do Beam. <br><br><h2>  Trabalho DataFlow em lote (processamento de pacotes) </h2><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> apache_beam <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> beam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> apache_beam.options.pipeline_options <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PipelineOptions <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.cloud <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> bigquery <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys PROJECT=<span class="hljs-string"><span class="hljs-string">'user-logs-237110'</span></span> schema = <span class="hljs-string"><span class="hljs-string">'remote_addr:STRING, timelocal:STRING, request_type:STRING, status:STRING, body_bytes_sent:STRING, http_referer:STRING, http_user_agent:STRING'</span></span> src_path = <span class="hljs-string"><span class="hljs-string">"user_log_fileC.txt"</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">regex_clean</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data)</span></span></span><span class="hljs-function">:</span></span> PATTERNS = [<span class="hljs-string"><span class="hljs-string">r'(^\S+\.[\S+\.]+\S+)\s'</span></span>,<span class="hljs-string"><span class="hljs-string">r'(?&lt;=\[).+?(?=\])'</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"(\S+)\s(\S+)\s*(\S*)\"'</span></span>,<span class="hljs-string"><span class="hljs-string">r'\s(\d+)\s'</span></span>,<span class="hljs-string"><span class="hljs-string">r"(?&lt;=\[).\d+(?=\])"</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"[AZ][az]+'</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"(http|https)://[az]+.[az]+.[az]+'</span></span>] result = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> match <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> PATTERNS: <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: reg_match = re.search(match, data).group() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> reg_match: result.append(reg_match) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: result.append(<span class="hljs-string"><span class="hljs-string">" "</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span>: print(<span class="hljs-string"><span class="hljs-string">"There was an error with the regex search"</span></span>) result = [x.strip() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> result] result = [x.replace(<span class="hljs-string"><span class="hljs-string">'"'</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> result] res = <span class="hljs-string"><span class="hljs-string">','</span></span>.join(result) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> res <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Split</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(beam.DoFn)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">process</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, element)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime element = element.split(<span class="hljs-string"><span class="hljs-string">","</span></span>) d = datetime.strptime(element[<span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-string"><span class="hljs-string">"%d/%b/%Y:%H:%M:%S"</span></span>) date_string = d.strftime(<span class="hljs-string"><span class="hljs-string">"%Y-%m-%d %H:%M:%S"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [{ <span class="hljs-string"><span class="hljs-string">'remote_addr'</span></span>: element[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-string"><span class="hljs-string">'timelocal'</span></span>: date_string, <span class="hljs-string"><span class="hljs-string">'request_type'</span></span>: element[<span class="hljs-number"><span class="hljs-number">2</span></span>], <span class="hljs-string"><span class="hljs-string">'status'</span></span>: element[<span class="hljs-number"><span class="hljs-number">3</span></span>], <span class="hljs-string"><span class="hljs-string">'body_bytes_sent'</span></span>: element[<span class="hljs-number"><span class="hljs-number">4</span></span>], <span class="hljs-string"><span class="hljs-string">'http_referer'</span></span>: element[<span class="hljs-number"><span class="hljs-number">5</span></span>], <span class="hljs-string"><span class="hljs-string">'http_user_agent'</span></span>: element[<span class="hljs-number"><span class="hljs-number">6</span></span>] }] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> p = beam.Pipeline(options=PipelineOptions()) (p | <span class="hljs-string"><span class="hljs-string">'ReadData'</span></span> &gt;&gt; beam.io.textio.ReadFromText(src_path) | <span class="hljs-string"><span class="hljs-string">"clean address"</span></span> &gt;&gt; beam.Map(regex_clean) | <span class="hljs-string"><span class="hljs-string">'ParseCSV'</span></span> &gt;&gt; beam.ParDo(Split()) | <span class="hljs-string"><span class="hljs-string">'WriteToBigQuery'</span></span> &gt;&gt; beam.io.WriteToBigQuery(<span class="hljs-string"><span class="hljs-string">'{0}:userlogs.logdata'</span></span>.format(PROJECT), schema=schema, write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND) ) p.run() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: logger = logging.getLogger().setLevel(logging.INFO) main()</code> </pre> <br><br><h2>  Trabalho de fluxo de dados DataFlow </h2><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> apache_beam.options.pipeline_options <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PipelineOptions <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.cloud <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pubsub_v1 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.cloud <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> bigquery <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> apache_beam <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> beam <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> argparse <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re PROJECT=<span class="hljs-string"><span class="hljs-string">"user-logs-237110"</span></span> schema = <span class="hljs-string"><span class="hljs-string">'remote_addr:STRING, timelocal:STRING, request_type:STRING, status:STRING, body_bytes_sent:STRING, http_referer:STRING, http_user_agent:STRING'</span></span> TOPIC = <span class="hljs-string"><span class="hljs-string">"projects/user-logs-237110/topics/userlogs"</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">regex_clean</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data)</span></span></span><span class="hljs-function">:</span></span> PATTERNS = [<span class="hljs-string"><span class="hljs-string">r'(^\S+\.[\S+\.]+\S+)\s'</span></span>,<span class="hljs-string"><span class="hljs-string">r'(?&lt;=\[).+?(?=\])'</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"(\S+)\s(\S+)\s*(\S*)\"'</span></span>,<span class="hljs-string"><span class="hljs-string">r'\s(\d+)\s'</span></span>,<span class="hljs-string"><span class="hljs-string">r"(?&lt;=\[).\d+(?=\])"</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"[AZ][az]+'</span></span>, <span class="hljs-string"><span class="hljs-string">r'\"(http|https)://[az]+.[az]+.[az]+'</span></span>] result = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> match <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> PATTERNS: <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: reg_match = re.search(match, data).group() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> reg_match: result.append(reg_match) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: result.append(<span class="hljs-string"><span class="hljs-string">" "</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span>: print(<span class="hljs-string"><span class="hljs-string">"There was an error with the regex search"</span></span>) result = [x.strip() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> result] result = [x.replace(<span class="hljs-string"><span class="hljs-string">'"'</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> result] res = <span class="hljs-string"><span class="hljs-string">','</span></span>.join(result) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> res <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Split</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(beam.DoFn)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">process</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, element)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime element = element.split(<span class="hljs-string"><span class="hljs-string">","</span></span>) d = datetime.strptime(element[<span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-string"><span class="hljs-string">"%d/%b/%Y:%H:%M:%S"</span></span>) date_string = d.strftime(<span class="hljs-string"><span class="hljs-string">"%Y-%m-%d %H:%M:%S"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [{ <span class="hljs-string"><span class="hljs-string">'remote_addr'</span></span>: element[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-string"><span class="hljs-string">'timelocal'</span></span>: date_string, <span class="hljs-string"><span class="hljs-string">'request_type'</span></span>: element[<span class="hljs-number"><span class="hljs-number">2</span></span>], <span class="hljs-string"><span class="hljs-string">'body_bytes_sent'</span></span>: element[<span class="hljs-number"><span class="hljs-number">3</span></span>], <span class="hljs-string"><span class="hljs-string">'status'</span></span>: element[<span class="hljs-number"><span class="hljs-number">4</span></span>], <span class="hljs-string"><span class="hljs-string">'http_referer'</span></span>: element[<span class="hljs-number"><span class="hljs-number">5</span></span>], <span class="hljs-string"><span class="hljs-string">'http_user_agent'</span></span>: element[<span class="hljs-number"><span class="hljs-number">6</span></span>] }] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(argv=None)</span></span></span><span class="hljs-function">:</span></span> parser = argparse.ArgumentParser() parser.add_argument(<span class="hljs-string"><span class="hljs-string">"--input_topic"</span></span>) parser.add_argument(<span class="hljs-string"><span class="hljs-string">"--output"</span></span>) known_args = parser.parse_known_args(argv) p = beam.Pipeline(options=PipelineOptions()) (p | <span class="hljs-string"><span class="hljs-string">'ReadData'</span></span> &gt;&gt; beam.io.ReadFromPubSub(topic=TOPIC).with_output_types(bytes) | <span class="hljs-string"><span class="hljs-string">"Decode"</span></span> &gt;&gt; beam.Map(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x.decode(<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>)) | <span class="hljs-string"><span class="hljs-string">"Clean Data"</span></span> &gt;&gt; beam.Map(regex_clean) | <span class="hljs-string"><span class="hljs-string">'ParseCSV'</span></span> &gt;&gt; beam.ParDo(Split()) | <span class="hljs-string"><span class="hljs-string">'WriteToBigQuery'</span></span> &gt;&gt; beam.io.WriteToBigQuery(<span class="hljs-string"><span class="hljs-string">'{0}:userlogs.logdata'</span></span>.format(PROJECT), schema=schema, write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND) ) result = p.run() result.wait_until_finish() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: logger = logging.getLogger().setLevel(logging.INFO) main()</code> </pre><br><h2>  In√≠cio do transportador </h2><br>  Podemos iniciar o pipeline de v√°rias maneiras diferentes.  Se quis√©ssemos, poder√≠amos execut√°-lo localmente a partir do terminal, efetuando login remotamente no GCP. <br><br><pre> <code class="python hljs">python -m main_pipeline_stream.py \ --input_topic <span class="hljs-string"><span class="hljs-string">"projects/user-logs-237110/topics/userlogs"</span></span> \ --streaming</code> </pre> <br>  No entanto, vamos lan√ß√°-lo usando o DataFlow.  Podemos fazer isso usando o comando abaixo, definindo os seguintes par√¢metros necess√°rios. <br><br><ul><li>  <code>project</code> - O ID do seu projeto GCP. </li><li>  <code>runner</code> √© um <code>runner</code> pipeline que analisar√° seu programa e construir√° seu pipeline.  Para executar na nuvem, voc√™ deve especificar um DataflowRunner. </li><li>  <code>staging_location</code> - O caminho para o armazenamento em nuvem do Cloud Dataflow para indexa√ß√£o dos pacotes de c√≥digo necess√°rios aos manipuladores de processos. </li><li>  <code>temp_location</code> - o caminho para o armazenamento em nuvem do Cloud Dataflow para hospedar arquivos de tarefas tempor√°rios criados durante a opera√ß√£o do pipeline. </li><li> <code>streaming</code> </li> </ul><br><pre> <code class="python hljs">python main_pipeline_stream.py \ --runner DataFlow \ --project $PROJECT \ --temp_location $BUCKET/tmp \ --staging_location $BUCKET/staging --streaming</code> </pre><br>  Enquanto esse comando estiver em execu√ß√£o, podemos acessar a guia DataFlow no console do Google e visualizar nosso pipeline.  Ao clicar no pipeline, veremos algo semelhante √† Figura 4. Para fins de depura√ß√£o, pode ser muito √∫til acessar os logs e depois o Stackdriver para visualizar os logs detalhados.  Isso me ajudou a resolver problemas com o pipeline em v√°rios casos. <br><br><img src="https://habrastorage.org/webt/7p/ai/vu/7paivucaa-lfkgvfzta6aozjs1q.png"><br>  <i>Figura 4: Transportador de vigas</i> <br><br><h2>  Acesse nossos dados no BigQuery </h2><br>  Portanto, j√° dever√≠amos ter iniciado o pipeline com os dados entrando em nossa tabela.  Para testar isso, podemos acessar o BigQuery e visualizar os dados.  Depois de usar o comando abaixo, voc√™ dever√° ver as primeiras linhas do conjunto de dados.  Agora que temos os dados armazenados no BigQuery, podemos realizar an√°lises adicionais, al√©m de compartilhar dados com colegas e come√ßar a responder perguntas de neg√≥cios. <br><br><pre> <code class="python hljs">SELECT * FROM `user-logs<span class="hljs-number"><span class="hljs-number">-237110.</span></span>userlogs.logdata` LIMIT <span class="hljs-number"><span class="hljs-number">10</span></span>;</code> </pre> <br><img src="https://habrastorage.org/webt/ch/je/x_/chjex_xkpbc61hjrcft2qq06uuo.png"><br>  <i>Figura 5: BigQuery</i> <br><br><h2>  Conclus√£o </h2><br>  Esperamos que esta publica√ß√£o sirva como um exemplo √∫til de cria√ß√£o de um pipeline de dados de streaming, al√©m de encontrar maneiras de tornar os dados mais acess√≠veis.  Armazenar dados neste formato nos oferece muitas vantagens.  Agora podemos come√ßar a responder perguntas importantes, por exemplo, quantas pessoas usam nosso produto?  A base de usu√°rios cresce ao longo do tempo?  Quais aspectos do produto as pessoas mais interagem?  E existem erros onde eles n√£o deveriam estar?  Essas s√£o quest√µes que ser√£o do interesse da organiza√ß√£o.  Com base nas id√©ias decorrentes das respostas a essas perguntas, poderemos melhorar o produto e aumentar o interesse do usu√°rio. <br><br>  O feixe √© realmente √∫til para esse tipo de exerc√≠cio e tamb√©m possui v√°rios outros casos de uso interessantes.  Por exemplo, voc√™ pode analisar os dados dos ticks de troca em tempo real e fazer transa√ß√µes com base na an√°lise; talvez voc√™ tenha dados de sensores provenientes de ve√≠culos e deseje calcular o c√°lculo do n√≠vel de tr√°fego.  Voc√™ tamb√©m pode, por exemplo, ser uma empresa de jogos que coleta dados do usu√°rio e os utiliza para criar pain√©is para rastrear as principais m√©tricas.  Ok, senhores, este t√≥pico j√° √© para outro post, obrigado pela leitura e para quem quiser ver o c√≥digo completo, abaixo est√° um link para o meu GitHub. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://github.com/DFoly/User_log_pipeline</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><br></a> <br><br>  S√≥ isso.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Leia a primeira parte</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt462589/">https://habr.com/ru/post/pt462589/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt462577/index.html">Minha experi√™ncia de desenvolvimento Nim</a></li>
<li><a href="../pt462581/index.html">Como organizamos o primeiro leasing eletr√¥nico e o que isso levou a</a></li>
<li><a href="../pt462583/index.html">Conhe√ßa o ponteiro determinista do coletor de lixo</a></li>
<li><a href="../pt462585/index.html">Cria√ß√£o r√°pida de CRUD com nest, @ nestjsx / crud e TestMace</a></li>
<li><a href="../pt462587/index.html">AirTest IDE e reconhecimento de imagem - Automa√ß√£o de teste de jogos para celular com base no reconhecimento de imagem</a></li>
<li><a href="../pt462593/index.html">Do outro lado do suporte</a></li>
<li><a href="../pt462595/index.html">Auditoria e teste de letras: o que voc√™ deve prestar aten√ß√£o ao layout</a></li>
<li><a href="../pt462597/index.html">Datilografe e reaja</a></li>
<li><a href="../pt462601/index.html">Fazendo backup de servidores Windows na AWS</a></li>
<li><a href="../pt462605/index.html">Tra√ßo italiano em criptografia</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üé∫ üïµÔ∏è üèÇüèø Descripci√≥n general de las soluciones de IA y ML en 2018 y pron√≥sticos para 2019: Parte 1 - PNL, Visi√≥n por computadora ü§ûüèø üßëüèæ‚Äçü§ù‚Äçüßëüèæ üìµ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos! Le presento una traducci√≥n del art√≠culo de Analytics Vidhya con una descripci√≥n general de los eventos de AI / ML en las tendencias 2018...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Descripci√≥n general de las soluciones de IA y ML en 2018 y pron√≥sticos para 2019: Parte 1 - PNL, Visi√≥n por computadora</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439688/"><blockquote> Hola a todos!  Le presento una traducci√≥n del art√≠culo de <i>Analytics Vidhya</i> con una descripci√≥n general de los eventos de AI / ML en las tendencias 2018 y 2019.  El material es bastante grande, por lo que se divide en 2 partes.  Espero que el art√≠culo interese no solo a especialistas especializados, sino tambi√©n a aquellos interesados ‚Äã‚Äãen el tema de la IA.  Que tengas una buena lectura! <br><br><div class="spoiler">  <b class="spoiler_title">Art√≠culo de navegaci√≥n</b> <div class="spoiler_text">  <b>Parte 1</b> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Procesamiento del lenguaje natural (PNL)</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tendencias de PNL para 2019</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Visi√≥n por computadora</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tendencias en visi√≥n artificial para 2019</a> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 2</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Herramientas y bibliotecas</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tendencias de AutoML para 2019</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aprendizaje de refuerzo</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tendencias de aprendizaje de refuerzo para 2019</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">IA para los ni√±os buenos - movimiento hacia la IA "√©tica"</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tendencias √©ticas en IA para 2019</a> <br></div></div></blockquote><br><h2>  Introduccion </h2><br>  Los √∫ltimos a√±os para los entusiastas de la IA y los profesionales del aprendizaje autom√°tico han pasado en busca de un sue√±o.  Estas tecnolog√≠as han dejado de ser nicho, se han convertido en la corriente principal y ya est√°n afectando la vida de millones de personas en este momento.  Los ministerios de IA fueron creados en diferentes pa√≠ses [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">m√°s detalles aqu√≠</a> - aprox.  per.] y los presupuestos se asignan para mantenerse al d√≠a con esta carrera. <br><br>  Lo mismo es cierto para los profesionales de la ciencia de datos.  Hace un par de a√±os, podr√≠a sentirse c√≥modo conociendo un par de herramientas y trucos, pero esta vez ha pasado.  La cantidad de eventos recientes en ciencia de datos y la cantidad de conocimiento que se requiere para mantenerse al d√≠a con los tiempos en esta √°rea son sorprendentes. <br><br>  Decid√≠ dar un paso atr√°s y observar los desarrollos en algunas √°reas clave en el campo de la inteligencia artificial desde el punto de vista de los expertos en ciencia de datos.  ¬øQu√© brotes han ocurrido?  ¬øQu√© pas√≥ en 2018 y qu√© esperar en 2019?  ¬°Lea este art√≠culo para obtener respuestas! <a name="habracut"></a><br><br>  PD Como en cualquier pron√≥stico, a continuaci√≥n est√°n mis conclusiones personales basadas en intentos de combinar fragmentos individuales en la imagen completa.  Si su punto de vista es diferente al m√≠o, me complacer√° saber su opini√≥n sobre qu√© m√°s puede cambiar en ciencia de datos en 2019. <br><br>  Las √°reas que cubriremos en este art√≠culo son: <br><br>  - Procesamiento del lenguaje natural (PNL) <br>  - Visi√≥n por computadora <br>  - Herramientas y bibliotecas <br>  - Aprendizaje de refuerzo <br>  - Problemas de √©tica en la IA <br><br><a name="NLP"></a><h2>  Procesamiento de lenguaje natural (PNL) </h2><br>  Forzar a las m√°quinas a analizar palabras y oraciones siempre parec√≠a un sue√±o imposible.  Hay muchos matices y caracter√≠sticas en los idiomas que a veces son dif√≠ciles de entender incluso para las personas, pero 2018 fue un verdadero punto de inflexi√≥n para la PNL. <br><br>  Vimos un gran avance tras otro: ULMFiT, ELMO, OpenAl Transformer, Google BERT, y esta no es una lista completa.  La aplicaci√≥n exitosa del aprendizaje de transferencia (el arte de aplicar modelos pre-entrenados a los datos) ha abierto la puerta a la PNL en una variedad de tareas. <br><blockquote>  Aprendizaje de transferencia: le permite adaptar un modelo / sistema previamente capacitado a su tarea espec√≠fica utilizando una cantidad relativamente peque√±a de datos. </blockquote>  Veamos algunos de estos desarrollos clave con m√°s detalle. <br><br><h3>  ULMFiT </h3><br>  Desarrollado por Sebastian Ruder y Jeremy Howard (fast.ai), ULMFiT fue el primer marco para recibir el aprendizaje de transferencia este a√±o.  Para los no iniciados, el acr√≥nimo ULMFiT significa "Ajuste del modelo de lenguaje universal".  Jeremy y Sebastian con raz√≥n agregaron la palabra "universal" a ULMFiT: ¬°este marco se puede aplicar a casi cualquier tarea de PNL! <br><br>  ¬°Lo mejor de ULMFiT es que no necesita entrenar modelos desde cero!  Los investigadores ya han hecho lo m√°s dif√≠cil para usted: tomar y aplicar en sus proyectos.  ULMFiT super√≥ a otros m√©todos en seis tareas de clasificaci√≥n de texto. <br><br>  Puedes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">leer el</a> tutorial de Pratek Joshi [Pateek Joshi - aprox.  trans.] sobre c√≥mo comenzar a usar ULMFiT para cualquier tarea de clasificaci√≥n de texto. <br><br><h3>  ELMo </h3><br>  ¬øAdivina qu√© significa la abreviatura ELMo?  Acr√≥nimo de incrustaciones de modelos de idiomas [archivos adjuntos de modelos de idiomas - aprox.  trans.].  Y ELMo llam√≥ la atenci√≥n de la comunidad de ML justo despu√©s del lanzamiento. <br><br>  ELMo utiliza modelos de lenguaje para recibir archivos adjuntos para cada palabra, y tambi√©n tiene en cuenta el contexto en el que la palabra se ajusta a una oraci√≥n o p√°rrafo.  El contexto es un aspecto cr√≠tico de la PNL, en el que la mayor√≠a de los desarrolladores han fallado previamente.  ELMo utiliza LSTM bidireccionales para crear archivos adjuntos. <br><blockquote>  La memoria a largo plazo (LSTM) es un tipo de arquitectura de redes neuronales recurrentes propuesta en 1997 por Sepp Hochreiter y J√ºrgen Schmidhuber.  Como la mayor√≠a de las redes neuronales recurrentes, una red LSTM es universal en el sentido de que, con un n√∫mero suficiente de elementos de red, puede realizar cualquier c√°lculo que sea capaz de hacer una computadora normal, lo que requiere una matriz de peso adecuada que puede considerarse como un programa.  A diferencia de las redes neuronales recurrentes tradicionales, la red LSTM es muy adecuada para la capacitaci√≥n sobre los problemas de clasificaci√≥n, procesamiento y predicci√≥n de series de tiempo en casos donde los eventos importantes est√°n separados por retrasos con duraci√≥n y l√≠mites indefinidos. <br><br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">fuente.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Wikipedia</a> </blockquote>  Al igual que ULMFiT, ELMo mejora significativamente la productividad al resolver una gran cantidad de tareas de PNL, como analizar el estado de √°nimo del texto o responder preguntas. <br><br><h3>  BERT de Google </h3><br>  Muchos expertos se√±alan que el lanzamiento de BERT marc√≥ el comienzo de una nueva era en la PNL.  Despu√©s de ULMFiT y ELMo, BERT tom√≥ la delantera, demostrando un alto rendimiento.  Como dice el anuncio original: "BERT es conceptualmente simple y emp√≠ricamente poderoso". <br><br>  ¬°BERT ha mostrado resultados sobresalientes en 11 tareas de PNL!  Vea los resultados en las pruebas SQuAD: <br><br><img src="https://habrastorage.org/webt/rf/6n/cz/rf6nczjjvbcz1cg4nxfeo-lm7ou.png"><br><br>  ¬øQuieres probarlo?  Puede usar la reimplementaci√≥n en PyTorch o el c√≥digo TensorFlow de Google e intentar repetir el resultado en su m√°quina. <br><br><h3>  Facebook PyText </h3><br>  ¬øC√≥mo podr√≠a Facebook mantenerse alejado de esta carrera?  La compa√±√≠a ofrece su propio marco de PNL de c√≥digo abierto llamado PyText.  Seg√∫n un estudio publicado por Facebook, PyText aument√≥ la precisi√≥n de los modelos de conversaci√≥n en un 10% y redujo el tiempo de entrenamiento. <br><br>  PyText est√° detr√°s de varios productos propios de Facebook, como Messenger.  Por lo tanto, trabajar con √©l agregar√° un buen punto a su cartera y un conocimiento invaluable que sin duda obtendr√°. <br><br>  Puede probarlo usted mismo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">descargue el c√≥digo de GitHub</a> . <br><br><h3>  Google duplex </h3><br>  Es dif√≠cil creer que no haya o√≠do hablar de Google Duplex.  Aqu√≠ hay una demostraci√≥n que durante mucho tiempo apareci√≥ en los titulares: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/NO0-5MuJvew" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Dado que este es un producto de Google, hay pocas posibilidades de que tarde o temprano el c√≥digo se publique para todos.  Por supuesto, esta demostraci√≥n plantea muchas preguntas: desde cuestiones √©ticas hasta cuestiones de privacidad, pero hablaremos de esto m√°s adelante.  Por ahora, solo disfruta de lo lejos que hemos llegado con ML en los √∫ltimos a√±os. <br><br><a name="NLPtrends"></a><h2>  Tendencias de PNL 2019 </h2><br>  ¬øQui√©n mejor que el propio Sebastian Ruder puede dar una idea de hacia d√≥nde se dirige la PNL en 2019?  Aqu√≠ est√°n sus hallazgos: <br><blockquote><ol><li>  El uso de modelos de inversi√≥n en idiomas previamente capacitados se generalizar√°;  Los modelos avanzados sin soporte ser√°n muy raros. </li><li>  Aparecer√°n vistas pre-entrenadas que pueden codificar informaci√≥n especializada que complementa los archivos adjuntos del modelo de lenguaje.  Podremos agrupar diferentes tipos de presentaciones pre-entrenadas dependiendo de los requisitos de la tarea. </li><li>  Aparecer√° m√°s trabajo en el campo de las aplicaciones multiling√ºes y los modelos multiling√ºes.  En particular, confiando en la inclusi√≥n de palabras entre idiomas, veremos el surgimiento de profundas representaciones entre idiomas pre-entrenadas. </li></ol></blockquote><a name="cv"></a><h2>  Visi√≥n por computadora </h2><br><img src="https://habrastorage.org/webt/pu/aj/_c/puaj_c89feaiultos4yynrcj7x4.jpeg"><br><br>  Hoy en d√≠a, la visi√≥n por computadora es el √°rea m√°s popular en el campo del aprendizaje profundo.  Parece que los primeros frutos de la tecnolog√≠a ya se han obtenido y estamos en la etapa de desarrollo activo.  Independientemente de si esta imagen o video, vemos la aparici√≥n de muchos marcos y bibliotecas que resuelven f√°cilmente los problemas de la visi√≥n por computadora. <br><br>  Aqu√≠ est√° mi lista de las mejores soluciones que podr√≠an verse este a√±o. <br><br><h3>  BigGANs Out </h3><br>  Ian Goodfellow dise√±√≥ las GAN en 2014, y el concepto gener√≥ una amplia variedad de aplicaciones.  A√±o tras a√±o, observamos c√≥mo se finaliz√≥ el concepto original para su uso en casos reales.  Pero una cosa permaneci√≥ sin cambios hasta este a√±o: las im√°genes generadas por computadora eran demasiado f√°ciles de distinguir.  Siempre aparec√≠a una cierta inconsistencia en el marco, lo que hac√≠a la diferencia muy obvia. <br><br>  En los √∫ltimos meses, han aparecido cambios en esta direcci√≥n y, con la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">creaci√≥n de BigGAN</a> , estos problemas pueden resolverse de una vez por todas.  Mira las im√°genes generadas por este m√©todo: <br><br><img src="https://habrastorage.org/webt/mo/w7/ow/mow7owldedw4r1jtwex6wbfwwje.png"><br><br>  Sin un microscopio, es dif√≠cil decir qu√© est√° mal con estas im√°genes.  Por supuesto, todos decidir√°n por s√≠ mismos, pero no hay duda de que la GAN cambia la forma en que percibimos las im√°genes digitales (y el video). <br><br>  Como referencia: estos modelos fueron entrenados primero en el conjunto de datos ImageNet, y luego en el JFT-300M para demostrar que estos modelos se transfieren bien de un conjunto de datos a otro.  Aqu√≠ hay un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace a una p√°gina</a> de la lista de correo de GAN que explica c√≥mo visualizar y comprender la GAN. <br><br><h3>  Modelo Fast.ai entrenado en ImageNet en 18 minutos </h3><br>  Esta es una implementaci√≥n realmente genial.  Existe una creencia generalizada de que, para realizar tareas de aprendizaje profundo, necesitar√° terabytes de datos y grandes recursos inform√°ticos.  Lo mismo es cierto para entrenar el modelo desde cero en los datos de ImageNet.  La mayor√≠a de nosotros pensamos de la misma manera antes de que algunas personas en ayuno no pudieran demostrar lo contrario a todos. <br><br>  Su modelo dio un 93% de precisi√≥n con unos impresionantes 18 minutos.  El hardware que utilizaron, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">descrito</a> en detalle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en su blog</a> , consist√≠a en 16 instancias p√∫blicas de nube de AWS, cada una con 8 GPU NVIDIA V100.  Crearon un algoritmo utilizando las bibliotecas fast.ai y PyTorch. <br><br>  ¬°El costo total de ensamblaje fue de solo $ 40!  Jeremy describi√≥ sus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enfoques y m√©todos</a> con m√°s detalle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> .  Esta es una victoria com√∫n! <br><br><h3>  vid2vid de NVIDIA </h3><br>  En los √∫ltimos 5 a√±os, el procesamiento de im√°genes ha avanzado mucho, pero ¬øqu√© pasa con el video?  Los m√©todos para convertir de un marco est√°tico a uno din√°mico resultaron ser un poco m√°s complicados de lo esperado.  ¬øPuedes tomar una secuencia de cuadros de un video y predecir lo que suceder√° en el pr√≥ximo cuadro?  Tales estudios se han realizado antes, pero las publicaciones fueron vagas en el mejor de los casos. <br><br><img src="https://habrastorage.org/webt/hz/ox/hj/hzoxhjbehlnlzl8ivc-bgiz0vh0.png"><br><br>  NVIDIA decidi√≥ hacer p√∫blica su decisi√≥n a principios de este a√±o [2018 - aprox.  per.], que fue evaluado positivamente por la sociedad.  El prop√≥sito de vid2vid es obtener una funci√≥n de visualizaci√≥n de un video de entrada dado para crear un video de salida que transmita el contenido del video de entrada con una precisi√≥n incre√≠ble. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/S1OwOd-war8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Puede probar su implementaci√≥n en PyTorch, ll√©velo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">a GitHub aqu√≠</a> . <br><br><a name="cvtrends"></a><h2>  Tendencias de visi√≥n artificial para 2019 </h2><br>  Como mencion√© anteriormente, en 2019 es m√°s probable que veamos el desarrollo de las tendencias de 2018, en lugar de nuevos avances: autos aut√≥nomos, algoritmos de reconocimiento facial, realidad virtual y m√°s.  ¬øPuede estar en desacuerdo conmigo si tiene un punto de vista diferente o adiciones, comp√°rtelo con nosotros, qu√© m√°s podemos esperar en 2019? <br><br>  El tema de los drones, a la espera de la aprobaci√≥n de los pol√≠ticos y el gobierno, puede finalmente obtener luz verde en los Estados Unidos (India est√° muy por detr√°s en este asunto).  Personalmente, me gustar√≠a realizar m√°s investigaciones en escenarios del mundo real.  Conferencias como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CVPR</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ICML ofrecen una</a> buena cobertura de los √∫ltimos logros en esta √°rea, pero no est√° muy claro qu√© tan cerca est√°n los proyectos de la realidad. <br><br>  "Respuesta a preguntas visuales" y "sistemas de di√°logo visual" finalmente pueden salir con un esperado debut.  Estos sistemas carecen de la capacidad de generalizar, pero se espera que pronto veamos un enfoque multimodal integrado. <br><br><img src="https://habrastorage.org/webt/s5/bn/uy/s5bnuydmsc8hf37vm26icbmwrgc.jpeg"><br><br>  El auto entrenamiento se destac√≥ este a√±o.  Apuesto a que el pr√≥ximo a√±o encontrar√° aplicaci√≥n en un n√∫mero mucho mayor de estudios.  Esta es una direcci√≥n realmente genial: los signos se determinan directamente a partir de los datos de entrada, en lugar de perder el tiempo marcando manualmente las im√°genes.  ¬°Mantengamos nuestros dedos cruzados! <br><br><h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Leer m√°s: Parte 2 - Herramientas y bibliotecas, AutoML, aprendizaje por refuerzo, √©tica en IA</a> </h4></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/439688/">https://habr.com/ru/post/439688/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../439676/index.html">Integraci√≥n React Native y C ++ para iOS y Android</a></li>
<li><a href="../439678/index.html">Enviar al desaf√≠o de F # aplicado</a></li>
<li><a href="../439680/index.html">Alrededor del 50% de los rusos est√°n dispuestos a vender sus datos personales.</a></li>
<li><a href="../439682/index.html">Entrenamiento Cisco 200-125 CCNA v3.0. Especialista certificado en redes de Cisco (CCNA). D√≠a 4. Dispositivos de puerta de enlace</a></li>
<li><a href="../439684/index.html">Solicite el desaf√≠o F # aplicado</a></li>
<li><a href="../439690/index.html">Comparaci√≥n del rendimiento de la m√°quina virtual de 6 plataformas en la nube: Selectel, MCS, I. Cloud, Google Cloud, AWS y Azure</a></li>
<li><a href="../439692/index.html">AT&T demand√≥ por cambiar el √≠cono de red de 4G a 5G E</a></li>
<li><a href="../439694/index.html">Tejido inteligente que responde a los cambios de temperatura corporal</a></li>
<li><a href="../439696/index.html">En la cresta de una ola, o "Quiero integrar", pero ¬øvale la pena?</a></li>
<li><a href="../439698/index.html">Introducci√≥n a la programaci√≥n: un simple juego de disparos en 3D desde cero durante el fin de semana, parte 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
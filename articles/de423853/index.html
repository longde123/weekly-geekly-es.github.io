<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ôÄÔ∏è üì∫ üëº Funktionsweise des S3 DataLine-Speichers ü§∏üèΩ üë®‚Äçüë©‚Äçüë¶ üëí</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! 

 Es ist kein Geheimnis, dass riesige Datenmengen in die Arbeit moderner Anwendungen involviert sind und ihr Fluss st√§ndig w√§chst. Diese ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Funktionsweise des S3 DataLine-Speichers</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dataline/blog/423853/"><img src="https://habrastorage.org/webt/r2/ri/yr/r2riyrsimmtddysut6vvaatcqtw.png"><br><br>  Hallo Habr! <br><br>  Es ist kein Geheimnis, dass riesige Datenmengen in die Arbeit moderner Anwendungen involviert sind und ihr Fluss st√§ndig w√§chst.  Diese Daten m√ºssen gespeichert und verarbeitet werden, h√§ufig von einer gro√üen Anzahl von Maschinen, und dies ist keine leichte Aufgabe.  Um dies zu l√∂sen, gibt es Cloud-Objektspeicher.  In der Regel handelt es sich um eine Implementierung der Software Defined Storage-Technologie. <br><br>  Anfang 2018 haben wir unseren eigenen 100% S3-kompatiblen Speicher basierend auf Cloudian HyperStore gestartet (und gestartet!).  Wie sich herausstellte, gibt es im Netzwerk nur sehr wenige russischsprachige Ver√∂ffentlichungen √ºber Cloudian selbst und noch weniger √ºber die tats√§chliche Anwendung dieser L√∂sung. <br><br>  Basierend auf den Erfahrungen von DataLine werde ich Ihnen heute die Architektur und die interne Struktur der Cloudian-Software erl√§utern, einschlie√ülich der Cloudian SDS-Implementierung, die auf einer Reihe von Apache Cassandra-Architekturl√∂sungen basiert.  Unabh√§ngig davon betrachten wir das interessanteste in jedem SDS-Speicher - die Logik der Gew√§hrleistung der Fehlertoleranz und der Verteilung von Objekten. <br><br>  Wenn Sie Ihren S3-Speicher erstellen oder gerade warten, ist dieser Artikel hilfreich f√ºr Sie. <br><a name="habracut"></a><br>  Zun√§chst werde ich erkl√§ren, warum unsere Wahl auf Cloudian fiel.  Es ist ganz einfach: In dieser Nische gibt es nur sehr wenige w√ºrdige Optionen.  Zum Beispiel gab es vor ein paar Jahren, als wir nur daran dachten zu bauen, nur drei M√∂glichkeiten: <br><br><ul><li>  CEHP + RADOS Gateway; <br></li><li>  Minio <br></li><li>  Cloudian HyperStore. <br></li></ul><br>  F√ºr uns als Dienstleister waren die entscheidenden Faktoren: eine hohe Korrespondenz zwischen der Speicher-API und dem urspr√ºnglichen Amazon S3, die Verf√ºgbarkeit einer integrierten Abrechnung, Skalierbarkeit mit Unterst√ºtzung f√ºr mehrere Regionen und das Vorhandensein einer dritten Reihe von Anbietersupport.  Cloudian hat das alles. <br><br>  Und ja, das Wichtigste (sicherlich!) Ist, dass DataLine und Cloudian √§hnliche Unternehmensfarben haben.  Sie m√ºssen zugeben, dass wir einer solchen Sch√∂nheit nicht widerstehen konnten. <br><br><img src="https://habrastorage.org/webt/cj/mh/_u/cjmh_uot3g8v4spn8vgm4fvvngo.png"><br><br>  Leider ist Cloudian nicht die am h√§ufigsten verwendete Software, und in RuNet gibt es praktisch keine Informationen dazu.  Heute werden wir diese Ungerechtigkeit korrigieren und mit Ihnen √ºber die Funktionen der HyperStore-Architektur sprechen, ihre wichtigsten Komponenten untersuchen und uns mit den wichtigsten architektonischen Nuancen befassen.  Beginnen wir mit dem Grundlegendsten: Was ist Cloudian unter der Haube? <br><br><h1>  Funktionsweise von Cloudian HyperStore Storage </h1><br>  Schauen wir uns das Diagramm an und sehen, wie die Cloudian-L√∂sung funktioniert. <br><br><img src="https://habrastorage.org/webt/8m/_n/0x/8m_n0xtx0vtlx50himh-wxrkjfm.jpeg"><br>  <i>Das Hauptkomponenten-Speicherschema.</i> <br><br>  Wie wir sehen k√∂nnen, besteht das System aus mehreren Hauptkomponenten: <br><br><ul><li>  <b>Cloudian Management Control</b> - <i>Verwaltungskonsole</i> ; </li><li>  <b>Admin Service</b> - <i>internes Verwaltungsmodul</i> ; </li><li>  <b>S3 Service</b> - das <i>Modul, das f√ºr die Unterst√ºtzung des S3-Protokolls verantwortlich ist</i> ; </li><li>  <b>HyperStore-Dienst</b> - der <i>eigentliche Speicherdienst</i> ; </li><li>  <b>Apache Cassandra</b> - ein <i>zentrales Repository f√ºr Servicedaten</i> ; </li><li>  <b>Redis</b> - <i>f√ºr die am h√§ufigsten gelesenen Daten</i> . </li></ul><br>  Von gr√∂√ütem Interesse f√ºr uns wird die Arbeit der Hauptdienste S3 Service und HyperStore Service sein, dann werden wir ihre Arbeit sorgf√§ltig pr√ºfen.  Zun√§chst ist es jedoch sinnvoll herauszufinden, wie die Verteilung der Dienste im Cluster angeordnet ist und wie die Fehlertoleranz und Zuverl√§ssigkeit der Datenspeicherung dieser L√∂sung insgesamt ist. <br><br><img src="https://habrastorage.org/webt/hr/vq/su/hrvqsuhmqgexmgetlc72lsfwhqu.jpeg"><br><br><br>  Mit <i>allgemeinen Diensten</i> in der obigen Abbildung meinen wir die <b>Dienste S3, HyperStore, CMC und Apache Cassandra</b> .  Auf den ersten Blick ist alles sch√∂n und ordentlich.  Bei n√§herer Betrachtung stellt sich jedoch heraus, dass nur ein einziger Knotenfehler effektiv behoben wird.  Der gleichzeitige Verlust von zwei Knoten gleichzeitig kann f√ºr die Clusterverf√ºgbarkeit schwerwiegend sein. Redis QoS (auf Knoten 2) verf√ºgt nur √ºber 1 Slave (auf Knoten 3).  Das gleiche Bild mit dem Risiko eines Verlusts der Clusterverwaltung - Puppet Server befindet sich nur auf zwei Knoten (1 und 2).  Die Wahrscheinlichkeit eines Ausfalls von zwei Knoten gleichzeitig ist jedoch sehr gering, und Sie k√∂nnen damit leben. <br><br>  Um die Zuverl√§ssigkeit des Speichers zu erh√∂hen, verwenden wir jedoch 4 Knoten in der DataLine anstelle der mindestens drei.  Die folgende Ressourcenverteilung wird erhalten: <br><br><img src="https://habrastorage.org/webt/x0/ue/f2/x0uef2dubkivpngycrxidcjvx1u.png"><br><br>  Eine weitere Nuance f√§llt sofort auf - <b>Redis-Anmeldeinformationen werden</b> nicht auf jedem Knoten platziert (wie aus dem obigen offiziellen Schema hervorgeht), sondern nur auf drei von ihnen.  In diesem Fall werden <b>Redis-Anmeldeinformationen</b> f√ºr jede eingehende Anforderung verwendet.  Es stellt sich heraus, dass aufgrund der Notwendigkeit, zu den Redis eines anderen zu gehen, ein gewisses Ungleichgewicht in der Leistung des vierten Knotens besteht. <br><br>  F√ºr uns ist dies noch nicht von Bedeutung.  W√§hrend Stresstests wurden keine signifikanten Abweichungen in der Antwortgeschwindigkeit der Knoten festgestellt, aber bei gro√üen Clustern von Dutzenden von Arbeitsknoten ist es sinnvoll, diese Nuance zu korrigieren. <br><br>  So sieht das Migrationsschema auf 6 Knoten aus: <br><br><img src="https://habrastorage.org/webt/yc/df/1l/ycdf1lkqic3oh2rb6iu-yhyoiyo.jpeg"><br><br>  <i>Das Diagramm zeigt, wie die Dienstmigration bei einem Knotenausfall implementiert wird.</i>  <i>Es wird nur der Ausfall eines Servers jeder Rolle ber√ºcksichtigt.</i>  <i>Wenn beide Server ausfallen, ist ein manueller Eingriff erforderlich.</i> <br><br>  Auch hier war das Gesch√§ft nicht ohne Feinheiten.  Die Rollenmigration verwendet Puppet.  Wenn Sie es verlieren oder versehentlich besch√§digen, funktioniert das automatische Failover m√∂glicherweise nicht.  Aus dem gleichen Grund sollten Sie das Manifest der integrierten Puppe nicht manuell bearbeiten.  Dies ist nicht ganz sicher, √Ñnderungen k√∂nnen pl√∂tzlich ausgefranst sein, da Manifeste √ºber das Cluster-Admin-Panel bearbeitet werden. <br><br>  Aus Sicht der Datensicherheit ist alles viel interessanter.  Objektmetadaten werden in Apache Cassandra gespeichert und jeder Datensatz wird auf 3 von 4 Knoten repliziert.  Replikationsfaktor 3 wird auch zum Speichern von Daten verwendet, Sie k√∂nnen jedoch einen gr√∂√üeren konfigurieren.  Dies gew√§hrleistet die Datensicherheit auch bei gleichzeitigem Ausfall von 2 von 4 Knoten.  Und wenn Sie Zeit haben, den Cluster neu auszugleichen, k√∂nnen Sie mit einem verbleibenden Knoten nichts verlieren.  Die Hauptsache ist, gen√ºgend Platz zu haben. <br><br><img src="https://habrastorage.org/webt/do/oo/ip/doooipch3gctjx0ruteyepc3n2w.jpeg"><br><br>  <i>Dies passiert, wenn zwei Knoten ausfallen.</i>  <i>Das Diagramm zeigt deutlich, dass die Daten auch in dieser Situation sicher bleiben</i> <br><br>  Gleichzeitig h√§ngt die Verf√ºgbarkeit von Daten und Speicher von der Strategie zur Gew√§hrleistung der Konsistenz ab.  F√ºr Daten, Metadaten, Lesen und Schreiben wird es separat konfiguriert. <br><br>  G√ºltige Optionen sind mindestens ein Knoten, ein Quorum oder alle Knoten. <br>  Diese Einstellung bestimmt, wie viele Knoten das Schreiben / Lesen best√§tigen m√ºssen, damit die Anforderung als erfolgreich angesehen wird.  Wir verwenden das Quorum als angemessenen Kompromiss zwischen der Zeit, die f√ºr die Bearbeitung einer Anfrage ben√∂tigt wird, und der Zuverl√§ssigkeit des Schreibens / der Inkonsistenz des Lesens.  Das hei√üt, von den drei an der Operation beteiligten Knoten reicht es f√ºr eine fehlerfreie Operation aus, eine konsistente Antwort von 2 zu erhalten.  Dementsprechend m√ºssen Sie zu einer einzelnen Schreib- / Lesestrategie wechseln, um im Falle eines Ausfalls von mehr als einem Knoten √ºber Wasser zu bleiben. <br><br><h2>  Abfrageverarbeitung in Cloudian </h2><br>  Im Folgenden werden zwei Schemata f√ºr die Verarbeitung eingehender Anforderungen in Cloudian HyperStore betrachtet: PUT und GET.  Dies ist die Hauptaufgabe f√ºr S3 Service und HyperStore. <br><br>  Beginnen wir mit der Verarbeitung der Schreibanforderung: <br><br><img src="https://habrastorage.org/webt/ig/ae/g7/igaeg7v86nw9e1rgxt6xbdlhxb8.jpeg"><br><br>  Sicherlich haben Sie festgestellt, dass jede Anforderung viele √úberpr√ºfungen und Datenabrufe generiert, mindestens 6 Treffer von Komponente zu Komponente.  Von hier aus treten bei der Arbeit mit kleinen Dateien Verz√∂gerungen bei der Aufzeichnung und ein hoher CPU-Zeitverbrauch auf. <br><br>  Gro√üe Dateien werden von Chunks √ºbertragen.  Separate Chunks werden nicht als separate Anforderungen betrachtet und einige √úberpr√ºfungen werden nicht durchgef√ºhrt. <br><br>  Der Knoten, der die anf√§ngliche Anforderung erhalten hat, bestimmt ferner unabh√§ngig, wo und was geschrieben werden soll, auch wenn er nicht direkt darauf geschrieben wird.  Auf diese Weise k√∂nnen Sie die interne Organisation des Clusters vor dem Endclient verbergen und externe Load Balancer verwenden.  All dies wirkt sich positiv auf die Wartungsfreundlichkeit und Fehlertoleranz des Speichers aus. <br><br><img src="https://habrastorage.org/webt/ss/tr/zj/sstrzjuve-nm6oyz2mj0yitmnts.jpeg"><br><br>  Wie Sie sehen k√∂nnen, unterscheidet sich die Leselogik nicht zu stark vom Schreiben.  Darin wird die gleiche hohe Empfindlichkeit der Leistung gegen√ºber der Gr√∂√üe der verarbeiteten Objekte beobachtet.  Aufgrund erheblicher Einsparungen beim Arbeiten mit Metadaten ist es daher viel einfacher, ein fein gehacktes Objekt zu extrahieren als viele separate Objekte mit demselben Gesamtvolumen. <br><br><h2>  Datenspeicherung und Vervielf√§ltigung </h2><br>  Wie Sie den obigen Diagrammen entnehmen k√∂nnen, unterst√ºtzt Cloudian verschiedene Datenspeicherungs- und Duplizierungsschemata: <br><br>  <b>Replikation</b> - Mithilfe der Replikation ist es m√∂glich, eine benutzerdefinierte Anzahl von Kopien jedes Datenobjekts im System zu verwalten und jede Kopie auf verschiedenen Knoten zu speichern.  Bei Verwendung der 3X-Replikation werden beispielsweise 3 Kopien jedes Objekts erstellt, und jede Kopie ‚Äûliegt‚Äú auf einem eigenen Knoten. <br><br>  <b>L√∂schcodierung</b> - Bei der L√∂schcodierung wird jedes Objekt in eine benutzerdefinierte Menge (als K-Nummer bezeichnet) von Datenfragmenten plus eine benutzerdefinierte Menge an Redundanzcode (M-Nummer) codiert.  Jedes K + M-Fragment eines Objekts ist einzigartig und jedes Fragment wird auf einem eigenen Knoten gespeichert.  Ein Objekt kann mit beliebigen K-Fragmenten dekodiert werden.  Mit anderen Worten, das Objekt bleibt lesbar, auch wenn auf M Knoten nicht zugegriffen werden kann. <br><br>  Beispielsweise wird bei der L√∂schcodierung gem√§√ü der 4 + 2-Formel (4 Datenfragmente plus 2 Redundanzcodefragmente) jedes Objekt in 6 eindeutige Fragmente aufgeteilt, die auf sechs verschiedenen Knoten gespeichert sind, und dieses Objekt kann wiederhergestellt und gelesen werden, wenn 4 von 6 Fragmenten verf√ºgbar sind . <br><br>  Der Vorteil der L√∂schcodierung gegen√ºber der Replikation besteht darin, Platz zu sparen, allerdings auf Kosten einer signifikanten Erh√∂hung der Prozessorlast, einer Verschlechterung der Antwortgeschwindigkeit und der Notwendigkeit von Hintergrundprozeduren zur Steuerung der Konsistenz von Objekten.  In jedem Fall werden Metadaten getrennt von den Daten gespeichert (in Apache Cassandra), was die Flexibilit√§t und Zuverl√§ssigkeit der L√∂sung erh√∂ht. <br><br><h2>  Kurz √ºber andere Funktionen von HyperStore </h2><br>  Wie ich am Anfang dieses Artikels geschrieben habe, sind mehrere n√ºtzliche Tools in HyperStore integriert.  Unter ihnen: <br><br><ul><li>  Flexible Abrechnung mit Unterst√ºtzung f√ºr die √Ñnderung des Preises einer Ressource in Abh√§ngigkeit von Volumen und Tarifplan; <br></li><li>  Eingebaute √úberwachung <br></li><li>  Die M√∂glichkeit, die Verwendung von Ressourcen f√ºr Benutzer und Benutzergruppen einzuschr√§nken. <br></li><li>  QoS-Einstellungen und integrierte Verfahren zum Ausgleichen der Ressourcennutzung zwischen Knoten sowie regul√§re Verfahren zum Ausgleichen zwischen Knoten und Festplatten auf Knoten oder beim Eingeben neuer Knoten in einen Cluster. <br></li></ul><br>  Cloudian HyperStore ist jedoch immer noch nicht perfekt.  Aus irgendeinem Grund k√∂nnen Sie beispielsweise kein vorhandenes Konto auf eine andere Gruppe √ºbertragen oder einem Datensatz mehrere Gruppen zuweisen.  Es ist nicht m√∂glich, Zwischenabrechnungsberichte zu erstellen. Sie erhalten alle Berichte erst nach Abschluss des Berichtszeitraums.  Daher k√∂nnen weder Kunden noch wir in Echtzeit herausfinden, wie stark das Konto gewachsen ist. <br><br><h1>  Cloudian HyperStore-Logik </h1><br>  Jetzt werden wir noch tiefer eintauchen und uns das Interessanteste in jedem SDS-Speicher ansehen - die Logik der Verteilung von Objekten nach Knoten.  Beim Cloudian-Speicher werden Metadaten getrennt von den Daten selbst gespeichert.  F√ºr Metadaten wird Cassandra verwendet, f√ºr Daten die propriet√§re HyperStore-L√∂sung. <br><br>  Leider gibt es bisher keine offizielle √úbersetzung der Cloudian-Dokumentation ins Russische im Internet. Daher werde ich unten meine √úbersetzung der interessantesten Teile dieser Dokumentation ver√∂ffentlichen. <br><br><h2>  Die Rolle von Apache Cassandra im HyperStore </h2><br>  In HyperStore wird Cassandra zum Speichern von Objektmetadaten, Benutzerkontoinformationen und Dienstnutzungsdaten verwendet.  In einer typischen Bereitstellung in jedem HyperStore werden Cassandra-Daten auf demselben Laufwerk wie das Betriebssystem gespeichert.  Das System unterst√ºtzt auch Cassandra-Daten auf einem dedizierten Laufwerk auf jedem Knoten.  Cassandra-Daten werden nicht auf HyperStore-Datentr√§gern gespeichert.  Wenn dem Host vNodes zugewiesen sind, werden sie nur an die HyperStore-Speicherknoten verteilt.  vNodes werden nicht dem Laufwerk zugewiesen, auf dem Cassandra-Daten gespeichert sind. <br>  Innerhalb des Clusters werden Metadaten in Cassandra gem√§√ü der Richtlinie (Strategie) Ihres Repositorys repliziert.  Cassandra Data Replication verwendet vNodes folgenderma√üen: <br><br><ul><li>  Beim Erstellen eines neuen Cassandra-Objekts (Prim√§rschl√ºssel und seine entsprechenden Werte) wird es gehasht, und der Hash wird verwendet, um das Objekt einem bestimmten vNode zuzuordnen.  Das System pr√ºft, welchem ‚Äã‚ÄãHost dieser vNode zugewiesen ist, und dann wird das erste Replikat des Cassandra-Objekts auf dem Cassandra-Laufwerk auf diesem Host gespeichert. <br></li><li>  Angenommen, einem Host werden 96 vNodes zugewiesen, die auf mehrere HyperStore-Datenfestplatten verteilt sind.  Cassandra-Objekte, deren Hash-Werte in den Token-Bereich eines dieser 96 vNodes fallen, werden auf diesem Host auf das Cassandra-Laufwerk geschrieben. <br></li><li>  Zus√§tzliche Replikate des Cassandra-Objekts (die Anzahl der Replikate h√§ngt von Ihrer Konfiguration ab) werden vNodes mit der folgenden Sequenznummer zugeordnet und auf dem Knoten gespeichert, dem diese vNodes zugewiesen sind, sofern vNodes bei Bedarf √ºbersprungen werden, sodass jedes Replikat des Cassandra-Objekts auf einem anderen gespeichert wird Host-Maschine. <br></li></ul><br><h2>  Funktionsweise von HyperStore Storage </h2><br>  Die Platzierung und Replikation von S3-Objekten in einem HyperStore-Cluster basiert auf einem konsistenten Caching-Schema, das Ganzzahl-Token-Speicherplatz im Bereich von 0 bis 2 <sup>127</sup> -1 verwendet.  Ganzzahlige Token werden HyperStore-Knoten zugewiesen.  F√ºr jedes S3-Objekt wird ein Hash berechnet, wenn er in den Speicher geladen wird.  Das Objekt wird in dem Knoten gespeichert, dem der niedrigste Wert des Tokens zugewiesen wurde, der gr√∂√üer oder gleich dem Hashwert des Objekts ist.  Die Replikation wird auch implementiert, indem das Objekt auf den Knoten gespeichert wird, denen Token zugewiesen wurden, die einen Mindestwert haben. <br><br>  In einem ‚Äûklassischen‚Äú konsistenten Hash-basierten Speicher wird einem physischen Knoten ein Token zugewiesen.  Das Cloudian HyperStore-System verwendet und erweitert die Funktionalit√§t des in Cassandra in Version 1.2 eingef√ºhrten ‚Äûvirtuellen Knotens‚Äú (vNode). Jedem physischen Host wird eine gro√üe Anzahl von Token zugewiesen (maximal 256).  Tats√§chlich besteht der Speichercluster aus einer sehr gro√üen Anzahl von "virtuellen Knoten" mit einer gro√üen Anzahl von virtuellen Knoten (Token) auf jedem physischen Host. <br><br>  Das HyperStore-System weist jeder Festplatte auf jedem physischen Host einen separaten Satz von Token (virtuellen Knoten) zu.  Jede Festplatte auf dem Host ist f√ºr ihre eigenen Replikate von Objekten verantwortlich.  Ein Festplattenfehler betrifft nur Replikate von Objekten, die sich darauf befinden.  Andere Laufwerke auf dem Host werden weiterhin betrieben und erf√ºllen ihre Aufgaben zur Datenspeicherung. <br><br>  Wir geben ein Beispiel und betrachten einen Cluster von 6 HyperStore-Hosts, von denen jeder 4 S3-Speicherplatten hat.  Angenommen, jedem physischen Host sind 32 Token zugewiesen, und es gibt einen vereinfachten Token-Speicherplatz von 0 bis 960, und der Wert von 192 Token in diesem System (6 Hosts mit 32 Token) betr√§gt 0, 5, 10, 15, 20 usw. bis zu 955. <br><br>  Das folgende Diagramm zeigt eine m√∂gliche Verteilung von Token im gesamten Cluster.  32 Token jedes Hosts sind gleichm√§√üig auf 4 Festplatten verteilt (8 Token pro Festplatte), und die Token selbst sind zuf√§llig √ºber den Cluster verteilt. <br><br><img src="https://habrastorage.org/webt/wa/w2/9c/waw29ckv34avc3fdmqvfq4-a40a.jpeg"><br><br>  Angenommen, Sie haben HyperStore so konfiguriert, dass S3-Objekte 3X repliziert werden.  Lassen Sie uns zustimmen, dass das S3-Objekt in das System geladen wird und der auf seinen Namen angewendete Hash-Algorithmus den 322-Hash-Wert (in diesem vereinfachten Hash-Bereich) ergibt.  Das folgende Diagramm zeigt, wie drei Instanzen oder Replikate eines Objekts in einem Cluster gespeichert werden: <br><br><ul><li>  Mit dem Hashwert 322 wird das erste Replikat des Objekts auf dem 325-Token gespeichert, weil  Dies ist der kleinste Token-Wert, der gr√∂√üer oder gleich dem Hash-Wert des Objekts ist.  325 Token (im Diagramm rot hervorgehoben) sind hyperstore2: Disk2 zugeordnet.  Dementsprechend wird dort die erste Replik des Objekts gespeichert. <br></li></ul><br><ul><li>  Das zweite Replikat wird auf der Festplatte gespeichert, der das n√§chste Token zugewiesen ist (330, orange hervorgehoben), dh auf Hyperstore4: Disk2. <br></li><li>  Das dritte Replikat wird auf der Festplatte gespeichert, der nach 330 - 335 (gelb) das n√§chste Token im Hyperstore3 zugewiesen wird: Disk3. <br></li></ul><br><img src="https://habrastorage.org/webt/xy/0w/k-/xy0wk-hrqt3lgppbyeohdpllsnq.jpeg"><br><blockquote>  <b>Ich m√∂chte einen Kommentar hinzuf√ºgen:</b> Aus praktischer Sicht ist diese Optimierung (die Verteilung von Token nicht nur auf physische Knoten, sondern auch zwischen einzelnen Datentr√§gern) nicht nur erforderlich, um die Zug√§nglichkeit sicherzustellen, sondern auch um eine gleichm√§√üige Verteilung der Daten zwischen den Datentr√§gern sicherzustellen.  In diesem Fall wird das RAID-Array nicht verwendet. Die gesamte Logik der Datenzuweisung auf Festplatten wird vom HyperStore selbst gesteuert.  Einerseits ist es bequem und kontrolliert, wenn eine Festplatte verloren geht, wird alles von selbst neu ausgeglichen.  Andererseits vertraue ich pers√∂nlich mehr guten RAID-Controllern - schlie√ülich ist ihre Logik seit vielen Jahren optimiert.  Aber dies sind alles meine pers√∂nlichen Vorlieben. Bei echten Problemen und Problemen haben wir HyperStore nie entdeckt, wenn wir bei der Installation von Software auf physischen Servern den Empfehlungen des Anbieters folgen.  Der Versuch, Virtualisierung und virtuelle Festplatten auf demselben Speicher des Speichersystems zu verwenden, schlug jedoch fehl. Als das Speichersystem w√§hrend des Auslastungstests √ºberlastet wurde, wurde HyperStore verr√ºckt und verteilte Daten v√∂llig ungleichm√§√üig, wodurch einige Festplatten verstopft und andere nicht ber√ºhrt wurden. </blockquote><h2>  Laufwerkger√§t in einem Cluster </h2><br>  Denken Sie daran, dass jeder Host √ºber 32 Token verf√ºgt und die Token jedes Hosts gleichm√§√üig auf seine Festplatten verteilt sind.  Schauen wir uns hyperstore2: Disk2 genauer an (siehe Abbildung unten).  Wir sehen, dass dieser Platte Token 325, 425, 370 usw. zugewiesen sind. <br><br>  Da der Cluster f√ºr die 3X-Replikation konfiguriert ist, wird Folgendes im Hyperstore2 gespeichert: Disk2: <br><br>  In √úbereinstimmung mit 325 Disk Token: <br><ul><li>  Die ersten Repliken von Objekten mit einem Hashwert von 320 (ausschlie√ülich) bis 325 (einschlie√ülich); </li><li>  Zweite Repliken von Objekten mit einem Hashwert von 315 (ausschlie√ülich) bis 320 (einschlie√ülich); </li><li>  Dritte Replikate von Objekten mit einem Hashwert von 310 (ausschlie√ülich) bis 315 (einschlie√ülich). </li></ul><br>  Laut 425 Disk Token: <br><ul><li>  Die ersten Repliken von Objekten mit einem Hashwert von 420 (ausschlie√ülich) bis 425 (einschlie√ülich); </li><li>  Zweite Repliken von Objekten mit einem Hashwert von 415 (ausschlie√ülich) bis 420 (einschlie√ülich); </li><li>  Dritte Replikate von Objekten mit einem Hashwert von 410 (ausschlie√ülich) bis 415 (einschlie√ülich). </li></ul><br>  Usw. <br><br>    ,       HyperStore      ,           .    hyperstore2:disk2            . <br><br><img src="https://habrastorage.org/webt/hl/rf/dq/hlrfdqwtqhiuwvdrrplv0mxt8dk.jpeg"><br><br>    2   1, 3  4   ,     2   , ..     . <br><blockquote> <b>:</b>  ,   /     HyperStore         Cassandra.  ,    ,       ,     ,   ¬´¬ª  .          .                     .   ,      :        ,    ,     . </blockquote><h2>      </h2><br>   ,   HyperStore       .    -         .      .           ()     ,    . <br>  ,   ,     ,  <b>¬´Multi-Data Center Deployments¬ª.</b> <br><br>   HyperStore   -.   DC1  DC2.   -   3  .      ,      ,    32  (vNodes),        0  960.      -,     192  ‚Äî  32     6  .      . <br><br>  ,    S3          -. <br><br>  ,    S3    942    2 -: <br><br><ul><li>     vNode 945 (     ),    DC2,  hyperstore5:Disk3. <br></li><li>     vNode 950 (  ) DC2,  hyperstore6:Disk4. <br></li><li>  vNode 955   DC2,      ,   vNode . <br></li><li>     vNode 0 () ‚Äî  DC1, hyperstore2:Disk3.  ,       (955)       (0). <br></li><li>  vNode (5)   DC2,      ,   vNode . <br></li><li>       vNode 10 () ‚Äî  DC1, hyperstore3:Disk3. <br></li></ul><br><img src="https://habrastorage.org/webt/uu/vl/ak/uuvlakjhabsho_u_swahrrf8cz4.png"><br><blockquote> <b>:</b>        ,      ,   ,  ,           .     ,      . </blockquote>           Cloudian.   ,      ,            . ,    ,   ,            ,       . <br>       S3   DataLine,         ,          ! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de423853/">https://habr.com/ru/post/de423853/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de423839/index.html">sha256 Test pro ZahnOK f√ºr neuronales Netzwerk</a></li>
<li><a href="../de423843/index.html">Wenn Sie in Kasan oder Nowosibirsk sind und Mikrochips wie in Cupertino entwerfen m√∂chten</a></li>
<li><a href="../de423845/index.html">Firmenkondom</a></li>
<li><a href="../de423847/index.html">Farb- und Lichterkennung mit APDS-9960</a></li>
<li><a href="../de423851/index.html">Einf√ºhrung in Grafanas neues Plugin - Statusmap-Panel</a></li>
<li><a href="../de423855/index.html">Zyxel-Nebel - einfache Verwaltung als Grundlage f√ºr Einsparungen</a></li>
<li><a href="../de423857/index.html">6 Herausforderungen, denen Sie begegnen werden, wenn Sie das Programmieren selbst lernen</a></li>
<li><a href="../de423861/index.html">Solarlaternen - wir brauchen hellere</a></li>
<li><a href="../de423863/index.html">Konfrontation bei PHDays 8 - SOC View</a></li>
<li><a href="../de423865/index.html">Roskomnadzor berichtete √∂ffentlich</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üé´ üôéüèº üë©üèø R√©seaux de neurones et apprentissage profond, chapitre 3, partie 3: comment choisir les hyperparam√®tres de r√©seaux de neurones? üïπÔ∏è üôÖüèΩ ‚ùé</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Table des mati√®res 

- Chapitre 1: utiliser les r√©seaux de neurones pour reconna√Ætre les nombres manuscrits 
- Chapitre 2: comment fonctionne l'algori...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>R√©seaux de neurones et apprentissage profond, chapitre 3, partie 3: comment choisir les hyperparam√®tres de r√©seaux de neurones?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/460711/"><div class="spoiler">  <b class="spoiler_title">Table des mati√®res</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 1: utiliser les r√©seaux de neurones pour reconna√Ætre les nombres manuscrits</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 2: comment fonctionne l'algorithme de r√©tropropagation</a> </li><li>  Chapitre 3: <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 1: am√©liorer la m√©thode de formation des r√©seaux de neurones</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 2: Pourquoi la r√©gularisation contribue-t-elle √† r√©duire le recyclage?</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 3: comment choisir les hyperparam√®tres de r√©seau neuronal?</a> <br></li></ul></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 4: preuve visuelle que les r√©seaux de neurones sont capables de calculer n'importe quelle fonction</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 5: Pourquoi les r√©seaux de neurones profonds sont-ils si difficiles √† former?</a> </li><li>  Chapitre 6: <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 1: Deep Learning</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 2: progr√®s r√©cents dans la reconnaissance d'images</a> </li></ul></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Postface: existe-t-il un algorithme simple pour cr√©er de l'intelligence?</a> </li></ul></div></div><br>  Jusqu'√† pr√©sent, je n'ai pas expliqu√© comment je choisis les valeurs des hyperparam√®tres - le taux d'apprentissage Œ∑, le param√®tre de r√©gularisation Œª, etc.  Je viens de donner de belles valeurs de travail.  En pratique, lorsque vous utilisez un r√©seau neuronal pour attaquer un probl√®me, il peut √™tre difficile de trouver de bons hyperparam√®tres.  Imaginez, par exemple, qu'on vient de nous parler du probl√®me MNIST, et que nous avons commenc√© √† travailler dessus, sans rien savoir des valeurs des hyperparam√®tres appropri√©s.  Supposons que nous ayons eu de la chance par hasard, et dans les premi√®res exp√©riences, nous avons choisi de nombreux hyperparam√®tres comme nous l'avons d√©j√† fait dans ce chapitre: 30 neurones cach√©s, une taille de mini-paquet de 10, une formation de 30 √©poques et l'utilisation de l'entropie crois√©e.  Cependant, nous avons choisi le taux d'apprentissage Œ∑ = 10,0 et le param√®tre de r√©gularisation Œª = 1000,0.  Et voici ce que j'ai vu avec une telle course: <br><a name="habracut"></a><br><pre><code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> mnist_loader &gt;&gt;&gt; training_data, validation_data, test_data = \ ... mnist_loader.load_data_wrapper() &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> network2 &gt;&gt;&gt; net = network2.Network([<span class="hljs-number"><span class="hljs-number">784</span></span>, <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]) &gt;&gt;&gt; net.SGD(training_data, <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10.0</span></span>, lmbda = <span class="hljs-number"><span class="hljs-number">1000.0</span></span>, ... evaluation_data=validation_data, monitor_evaluation_accuracy=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) Epoch <span class="hljs-number"><span class="hljs-number">0</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">1030</span></span> / <span class="hljs-number"><span class="hljs-number">10000</span></span> Epoch <span class="hljs-number"><span class="hljs-number">1</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">990</span></span> / <span class="hljs-number"><span class="hljs-number">10000</span></span> Epoch <span class="hljs-number"><span class="hljs-number">2</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">1009</span></span> / <span class="hljs-number"><span class="hljs-number">10000</span></span> ... Epoch <span class="hljs-number"><span class="hljs-number">27</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">1009</span></span> / <span class="hljs-number"><span class="hljs-number">10000</span></span> Epoch <span class="hljs-number"><span class="hljs-number">28</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">983</span></span> / <span class="hljs-number"><span class="hljs-number">10000</span></span> Epoch <span class="hljs-number"><span class="hljs-number">29</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">967</span></span> / <span class="hljs-number"><span class="hljs-number">10000</span></span></code> </pre> <br>  Notre classification ne fonctionne pas mieux que l'√©chantillonnage al√©atoire!  Notre r√©seau fonctionne comme un g√©n√©rateur de bruit al√©atoire! <br><br>  "Eh bien, c'est facile √† r√©soudre", pourrait-on dire, "il suffit de r√©duire les hyperparam√®tres tels que la vitesse d'apprentissage et la r√©gularisation".  Malheureusement, a priori, vous n'avez pas d'informations sur ce que ces hyperparam√®tres doivent √™tre ajust√©s.  Peut-√™tre que le principal probl√®me est que nos 30 neurones cach√©s ne fonctionneront jamais, quelle que soit la fa√ßon dont les autres hyperparam√®tres sont s√©lectionn√©s?  Peut-√™tre avons-nous besoin d'au moins 100 neurones cach√©s?  Ou 300?  Ou beaucoup de couches cach√©es?  Ou une approche diff√©rente du codage de sortie?  Peut-√™tre que notre r√©seau apprend, mais que nous devons le former √† plusieurs √©poques?  Peut-√™tre que la taille des mini-paquets est trop petite?  Peut-√™tre aurions-nous mieux fait si nous √©tions revenus √† la fonction quadratique de la valeur?  Peut-√™tre que nous devons essayer une approche diff√©rente pour initialiser les poids?  Et ainsi de suite et ainsi de suite.  Dans l'espace des hyperparam√®tres, il est facile de se perdre.  Et cela peut vraiment entra√Æner beaucoup d'inconv√©nients si votre r√©seau est tr√®s grand ou utilise d'√©normes quantit√©s de donn√©es de formation, et vous pouvez les entra√Æner pendant des heures, des jours ou des semaines sans recevoir de r√©sultats.  Dans une telle situation, votre confiance commence √† passer.  Peut-√™tre que les r√©seaux de neurones n'√©taient pas la bonne approche pour r√©soudre votre probl√®me?  Peut-√™tre que vous quittez et faites l'apiculture? <br><br>  Dans cette section, je vais expliquer quelques approches heuristiques que vous pouvez utiliser pour configurer des hyperparam√®tres dans un r√©seau neuronal.  L'objectif est de vous aider √† √©laborer un workflow qui vous permet de configurer assez bien les hyperparam√®tres.  Bien s√ªr, je ne peux pas couvrir tout le sujet de l'optimisation hyperparam√©trique.  C'est un domaine immense, et ce n'est pas un probl√®me qui peut √™tre r√©solu compl√®tement, ou selon les strat√©gies correctes de r√©solution qui font l'unanimit√©.  Il y a toujours la possibilit√© d'essayer une autre astuce pour extraire des r√©sultats suppl√©mentaires de votre r√©seau neuronal.  Mais l'heuristique de cette section devrait vous donner un point de d√©part. <br><br><h3>  Strat√©gie g√©n√©rale </h3><br>  Lors de l'utilisation d'un r√©seau neuronal pour attaquer un nouveau probl√®me, la premi√®re difficult√© est d'obtenir des r√©sultats non triviaux du r√©seau, c'est-√†-dire de d√©passer une probabilit√© al√©atoire.  Cela peut √™tre √©tonnamment difficile, surtout lorsque vous √™tes confront√© √† une nouvelle classe de t√¢ches.  Examinons quelques strat√©gies qui peuvent √™tre utilis√©es pour ce type de difficult√©. <br><br>  Supposons, par exemple, que vous soyez le premier √† attaquer la t√¢che MNIST.  Vous commencez avec beaucoup d'enthousiasme, mais l'√©chec complet de votre premier r√©seau est un peu d√©courageant, comme d√©crit dans l'exemple ci-dessus.  Ensuite, vous devez d√©monter le probl√®me en plusieurs parties.  Vous devez vous d√©barrasser de toutes les images d'entra√Ænement et de support, √† l'exception des images de z√©ros et de uns.  Ensuite, essayez de former le r√©seau pour distinguer 0 de 1. Cette t√¢che est non seulement essentiellement plus facile que de distinguer les dix chiffres, elle r√©duit √©galement la quantit√© de donn√©es d'entra√Ænement de 80%, acc√©l√©rant ainsi l'apprentissage de 5 fois.  Cela vous permet de mener des exp√©riences beaucoup plus rapidement et vous donne la possibilit√© de comprendre rapidement comment cr√©er un bon r√©seau. <br><br>  Les exp√©riences peuvent √™tre encore acc√©l√©r√©es en r√©duisant le r√©seau √† une taille minimale susceptible d'√™tre correctement form√©e.  Si vous pensez que le r√©seau [784, 10] est tr√®s susceptible de classer les chiffres du MNIST mieux qu'un √©chantillon al√©atoire, alors commencez √† l'exp√©rimenter.  Ce sera beaucoup plus rapide que l'entra√Ænement [784, 30, 10], et vous pouvez d√©j√† y arriver plus tard. <br><br>  Une autre acc√©l√©ration des exp√©riences peut √™tre obtenue en augmentant la fr√©quence de suivi.  Dans le programme network2.py, nous surveillons la qualit√© du travail √† la fin de chaque √®re.  En traitant 50 000 images par √©poque, nous devons attendre assez longtemps - environ 10 secondes par √©poque sur mon ordinateur portable pendant la formation r√©seau [784, 30, 10] - avant d'obtenir des commentaires sur la qualit√© de la formation r√©seau.  Bien s√ªr, dix secondes, ce n'est pas si long, mais si vous voulez essayer quelques dizaines d'hyperparam√®tres diff√©rents, cela commence √† ennuyer, et si vous voulez essayer des centaines ou des milliers d'options, cela d√©vaste simplement.  Les commentaires peuvent √™tre re√ßus beaucoup plus rapidement en suivant plus souvent la pr√©cision de la confirmation, par exemple, toutes les 1000 images d'entra√Ænement.  De plus, au lieu d'utiliser l'ensemble complet de 10 000 images de confirmation, nous pouvons obtenir une estimation beaucoup plus rapidement en utilisant seulement 100 images de confirmation.  L'essentiel est que le r√©seau voit suffisamment d'images pour vraiment apprendre et pour obtenir une estimation suffisamment bonne de l'efficacit√©.  Bien s√ªr, notre network2.py ne fournit pas encore ce suivi.  Mais en tant que b√©quilles pour obtenir cet effet √† des fins d'illustration, nous recadrons nos donn√©es d'entra√Ænement aux 1000 premi√®res images MNIST.  Essayons de voir ce qui se passe (pour la simplicit√© du code, je n'ai pas utilis√© l'id√©e de ne laisser que les images 0 et 1 - cela peut aussi √™tre r√©alis√© avec un peu plus d'effort). <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = network2.Network([<span class="hljs-number"><span class="hljs-number">784</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]) &gt;&gt;&gt; net.SGD(training_data[:<span class="hljs-number"><span class="hljs-number">1000</span></span>], <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10.0</span></span>, lmbda = <span class="hljs-number"><span class="hljs-number">1000.0</span></span>, \ ... evaluation_data=validation_data[:<span class="hljs-number"><span class="hljs-number">100</span></span>], \ ... monitor_evaluation_accuracy=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) Epoch <span class="hljs-number"><span class="hljs-number">0</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">1</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">2</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> ...</code> </pre> <br>  Nous obtenons toujours du bruit pur, mais nous avons un gros avantage: le feedback est mis √† jour en quelques fractions de seconde, et pas toutes les dix secondes.  Cela signifie que vous pouvez exp√©rimenter beaucoup plus rapidement avec la s√©lection d'hyperparam√®tres, ou m√™me exp√©rimenter avec de nombreux hyperparam√®tres diff√©rents presque simultan√©ment. <br><br>  Dans l'exemple ci-dessus, j'ai laiss√© la valeur de Œª √©gale √† 1000,0, comme pr√©c√©demment.  Mais puisque nous avons chang√© le nombre d'exemples d'entra√Ænement, nous devons changer Œª de sorte que l'affaiblissement des poids soit le m√™me.  Cela signifie que nous changeons Œª de 20,0.  Dans ce cas, les √©l√©ments suivants se r√©v√©leront: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = network2.Network([<span class="hljs-number"><span class="hljs-number">784</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]) &gt;&gt;&gt; net.SGD(training_data[:<span class="hljs-number"><span class="hljs-number">1000</span></span>], <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10.0</span></span>, lmbda = <span class="hljs-number"><span class="hljs-number">20.0</span></span>, \ ... evaluation_data=validation_data[:<span class="hljs-number"><span class="hljs-number">100</span></span>], \ ... monitor_evaluation_accuracy=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) Epoch <span class="hljs-number"><span class="hljs-number">0</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">12</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">1</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">14</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">2</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">25</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">3</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">18</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> ...</code> </pre> <br>  Ouais!  Nous avons un signal.  Pas particuli√®rement bon, mais il y en a.  Cela peut d√©j√† √™tre pris comme point de d√©part et modifier les hyperparam√®tres pour essayer d'obtenir de nouvelles am√©liorations.  Supposons que nous d√©cidions que nous devons augmenter la vitesse d'apprentissage (comme vous l'avez probablement compris, nous avons d√©cid√© incorrectement, pour la raison que nous discuterons plus tard, mais essayons de le faire pour l'instant).  Pour tester notre supposition, nous tournons Œ∑ √† 100,0: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = network2.Network([<span class="hljs-number"><span class="hljs-number">784</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]) &gt;&gt;&gt; net.SGD(training_data[:<span class="hljs-number"><span class="hljs-number">1000</span></span>], <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">100.0</span></span>, lmbda = <span class="hljs-number"><span class="hljs-number">20.0</span></span>, \ ... evaluation_data=validation_data[:<span class="hljs-number"><span class="hljs-number">100</span></span>], \ ... monitor_evaluation_accuracy=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) Epoch <span class="hljs-number"><span class="hljs-number">0</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">1</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">2</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">3</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">10</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> ...</code> </pre> <br>  Tout va mal!  Apparemment, notre supposition √©tait incorrecte et le probl√®me n'√©tait pas dans la tr√®s faible valeur de la vitesse d'apprentissage.  Nous essayons de resserrer Œ∑ √† une petite valeur de 1,0: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = network2.Network([<span class="hljs-number"><span class="hljs-number">784</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]) &gt;&gt;&gt; net.SGD(training_data[:<span class="hljs-number"><span class="hljs-number">1000</span></span>], <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>, lmbda = <span class="hljs-number"><span class="hljs-number">20.0</span></span>, \ ... evaluation_data=validation_data[:<span class="hljs-number"><span class="hljs-number">100</span></span>], \ ... monitor_evaluation_accuracy=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) Epoch <span class="hljs-number"><span class="hljs-number">0</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">62</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">1</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">42</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">2</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">43</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> Epoch <span class="hljs-number"><span class="hljs-number">3</span></span> training complete Accuracy on evaluation data: <span class="hljs-number"><span class="hljs-number">61</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> ...</code> </pre> <br>  C'est mieux!  Et ainsi nous pouvons continuer plus loin, en tordant chaque hyperparam√®tre et en am√©liorant progressivement l'efficacit√©.  Apr√®s avoir √©tudi√© la situation et trouv√© une valeur am√©lior√©e pour Œ∑, nous proc√©dons √† la recherche d'une bonne valeur pour Œª.  Ensuite, nous allons mener une exp√©rience avec une architecture plus complexe, par exemple, avec un r√©seau de 10 neurones cach√©s.  Ensuite, nous ajustons √† nouveau les param√®tres pour Œ∑ et Œª.  Ensuite, nous augmenterons le r√©seau √† 20 neurones cach√©s.  Un peu de r√©glage des hyperparam√®tres.  Et ainsi de suite, √©valuer l'efficacit√© √† chaque √©tape en utilisant une partie de nos donn√©es de support, et en utilisant ces estimations pour s√©lectionner tous les meilleurs hyperparam√®tres.  En cours d'am√©liorations, il faut de plus en plus de temps pour voir l'effet du r√©glage des hyperparam√®tres, afin que nous puissions r√©duire progressivement la fr√©quence de suivi. <br><br>  En tant que strat√©gie globale, cette approche semble prometteuse.  Cependant, je veux revenir √† cette premi√®re √©tape dans la recherche d'hyperparam√®tres qui permettent au r√©seau d'apprendre au moins en quelque sorte.  En fait, m√™me dans l'exemple ci-dessus, la situation √©tait trop optimiste.  Travailler avec un r√©seau qui n'apprend rien peut √™tre extr√™mement ennuyeux.  Vous pouvez ajuster les hyperparam√®tres pendant plusieurs jours et ne pas recevoir de r√©ponses significatives.  Par cons√©quent, je voudrais souligner une fois de plus que dans les premi√®res √©tapes, vous devez vous assurer que vous pouvez obtenir un retour rapide des exp√©riences.  Intuitivement, il peut sembler que simplifier le probl√®me et l'architecture ne fera que vous ralentir.  En fait, cela acc√©l√®re le processus, car vous pouvez trouver un r√©seau avec un signal significatif beaucoup plus rapidement.  Apr√®s avoir re√ßu un tel signal, vous pourrez souvent obtenir des am√©liorations rapides lors du r√©glage des hyperparam√®tres.  Comme dans de nombreuses situations de la vie, le plus difficile est de d√©marrer le processus. <br><br>  D'accord, c'est une strat√©gie g√©n√©rale.  Voyons maintenant les recommandations sp√©cifiques pour prescrire des hyperparam√®tres.  Je me concentrerai sur la vitesse d'apprentissage Œ∑, le param√®tre de r√©gularisation L2 Œª et la taille du mini-paquet.  Cependant, de nombreux commentaires seront applicables √† d'autres hyperparam√®tres, y compris ceux li√©s √† l'architecture de r√©seau, √† d'autres formes de r√©gularisation et √† certains hyperparam√®tres, que nous apprendrons dans le livre plus tard, par exemple, le coefficient de momentum. <br><br><h3>  Vitesse d'apprentissage </h3><br>  Supposons que nous ayons lanc√© trois r√©seaux MNIST avec trois vitesses d'apprentissage diff√©rentes, Œ∑ = 0,025, Œ∑ = 0,25 et Œ∑ = 2,5, respectivement.  Nous laisserons le reste des hyperparam√®tres tels qu'ils √©taient dans les sections pr√©c√©dentes - 30 √©poques, la taille du mini-paquet est de 10, Œª = 5,0.  Nous reviendrons √©galement sur l'utilisation des 50 000 images d'entra√Ænement.  Voici un graphique montrant le comportement du co√ªt de la formation (cr√©√© par le programme multiple_eta.py): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1ec/dc3/761/1ecdc37614b9207a1f03ce2aad97e61d.png"><br><br>  √Ä Œ∑ = 0,025, le co√ªt diminue en douceur jusqu'√† la derni√®re √®re.  Avec Œ∑ = 0,25, le co√ªt diminue initialement, mais apr√®s 20 √©poques, il est satur√©, de sorte que la plupart des changements se r√©v√®lent √™tre de petites fluctuations et, √©videmment, al√©atoires.  Avec Œ∑ = 2,5, le co√ªt varie consid√©rablement d√®s le d√©part.  Pour comprendre la raison de ces fluctuations, nous rappelons que la descente de gradient stochastique devrait progressivement nous abaisser dans la vall√©e de la fonction de co√ªt: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/37e/5f9/af1/37e5f9af1985610568cba31157e35763.png"><br><br>  Cette image aide √† imaginer intuitivement ce qui se passe, mais n'est pas une explication compl√®te et compl√®te.  Plus pr√©cis√©ment, mais bri√®vement, la descente de gradient utilise une approximation de premier ordre pour la fonction de co√ªt afin de comprendre comment r√©duire le co√ªt.  Pour des Œ∑ plus grands, les membres d'une fonction de co√ªt d'ordre sup√©rieur deviennent plus importants et ils peuvent dominer le comportement en interrompant la descente de gradient.  Cela est particuli√®rement probable √† l'approche des minima et des minima locaux de la fonction de co√ªt, car √† c√¥t√© de ces points, le gradient devient petit, ce qui facilite la domination des membres d'un ordre sup√©rieur. <br><br>  Cependant, si Œ∑ est trop grand, alors les marches seront si grandes qu'elles pourront sauter un minimum, gr√¢ce √† quoi l'algorithme grimpera de la vall√©e.  C'est probablement ce qui fait osciller le prix √† Œ∑ = 2,5.  Le choix de Œ∑ = 0,25 conduit au fait que les √©tapes initiales nous conduisent vraiment vers un minimum de la fonction de co√ªt, et ce n'est que lorsque nous y arrivons que nous commen√ßons √† √©prouver des difficult√©s √† sauter.  Et lorsque nous choisissons Œ∑ = 0,025, nous n‚Äôavons pas de telles difficult√©s au cours des 30 premi√®res √©poques.  Bien s√ªr, le choix d'une si petite valeur de Œ∑ cr√©e une autre difficult√© - √† savoir, il ralentit la descente du gradient stochastique.  La meilleure approche serait de commencer avec Œ∑ = 0,25, d'apprendre 20 √©poques, puis de passer √† Œ∑ = 0,025.  Plus tard, nous discuterons d'un tel taux d'apprentissage variable.  En attendant, arr√™tons-nous sur la question de trouver une valeur appropri√©e pour la vitesse d'apprentissage Œ∑. <br><br>  Dans cet esprit, nous pouvons choisir Œ∑ comme suit.  Premi√®rement, nous √©valuons la valeur seuil Œ∑ √† laquelle le co√ªt des donn√©es de formation commence imm√©diatement √† diminuer, mais ne fluctue pas et n'augmente pas.  Cette estimation n'a pas besoin d'√™tre exacte.  L'ordre peut √™tre estim√© en commen√ßant par Œ∑ = 0,01.  Si le co√ªt diminue au cours des premi√®res √©poques, il vaut la peine d'essayer Œ∑ = 0,1, puis 1,0, et ainsi de suite, jusqu'√† ce que vous trouviez une valeur √† laquelle la valeur fluctue ou augmente au cours des premi√®res √©poques.  Et vice versa, si la valeur fluctue ou augmente dans les premi√®res √©poques avec Œ∑ = 0,01, essayez alors Œ∑ = 0,001, Œ∑ = 0,0001, jusqu'√† ce que vous trouviez la valeur √† laquelle le co√ªt diminue dans les premi√®res √©poques.  Cette proc√©dure vous donnera l'ordre de la valeur seuil Œ∑.  Si vous le souhaitez, vous pouvez affiner votre √©valuation en choisissant la valeur la plus √©lev√©e pour Œ∑, √† laquelle le co√ªt diminue dans les premi√®res √©poques, par exemple, Œ∑ = 0,5 ou Œ∑ = 0,2 (l'ultra-pr√©cision n'est pas n√©cessaire ici).  Cela nous donne une estimation de la valeur seuil Œ∑. <br><br>  La valeur r√©elle de Œ∑ ne doit √©videmment pas d√©passer le seuil s√©lectionn√©.  En fait, pour que la valeur Œ∑ reste utile pendant de nombreuses √©poques, il vaut mieux utiliser une valeur deux fois plus petite que le seuil.  Un tel choix vous permettra g√©n√©ralement d'apprendre de nombreuses √©poques sans ralentir consid√©rablement votre apprentissage. <br><br>  Dans le cas des donn√©es MNIST, suivre cette strat√©gie conduira √† une estimation de l'ordre seuil de Œ∑ √† 0,1.  Apr√®s un certain raffinement, nous obtenons la valeur Œ∑ = 0,5.  En suivant la recette ci-dessus, nous devrions utiliser Œ∑ = 0,25 pour notre vitesse d'apprentissage.  Mais en fait, j'ai trouv√© que Œ∑ = 0,5 fonctionnait bien pendant 30 √©poques, donc je ne craignais pas de le diminuer. <br><br>  Tout cela semble assez simple.  Cependant, l'utilisation du co√ªt de la formation pour s√©lectionner Œ∑ semble contredire ce que j'ai dit plus t√¥t - que nous choisissons des hyperparam√®tres, √©valuant l'efficacit√© du r√©seau en utilisant des donn√©es de confirmation s√©lectionn√©es.  En fait, nous utiliserons la pr√©cision de la confirmation pour s√©lectionner les hyperparam√®tres de r√©gularisation, la taille du mini-paquet et des param√®tres de r√©seau tels que le nombre de couches et de neurones cach√©s, etc.  Pourquoi faisons-nous les choses diff√©remment avec la vitesse d'apprentissage?  Honn√™tement, ce choix est d√ª √† mes pr√©f√©rences esth√©tiques personnelles et est probablement biais√©.  L'argument est que d'autres hyperparam√®tres devraient am√©liorer la pr√©cision de classification finale sur l'ensemble de test, il est donc logique de les choisir en fonction de la pr√©cision de la confirmation.  Cependant, le taux d'apprentissage n'affecte qu'indirectement la pr√©cision de la classification finale.  Son objectif principal est de contr√¥ler la taille du pas de la descente en pente et de suivre le co√ªt de la formation de la meilleure fa√ßon afin de reconna√Ætre une taille de pas trop grande.  Mais c'est toujours une pr√©f√©rence esth√©tique personnelle.  Dans les premiers stades de la formation, le co√ªt de la formation ne diminue g√©n√©ralement que si la pr√©cision de la confirmation augmente, donc dans la pratique, peu importe les crit√®res √† utiliser. <br><br><h3>  Utiliser un arr√™t pr√©coce pour d√©terminer le nombre d'√©poques d'entra√Ænement </h3><br>  Comme nous l'avons mentionn√© dans ce chapitre, un arr√™t pr√©coce signifie qu'√† la fin de chaque √®re, nous devons calculer la pr√©cision de la classification sur les donn√©es justificatives.  Quand il cesse de s'am√©liorer, nous arr√™tons de travailler.  En cons√©quence, la d√©finition du nombre d'√©poques devient une affaire simple.  En particulier, cela signifie que nous n'avons pas besoin de comprendre sp√©cifiquement comment le nombre d'√©poques d√©pend d'autres hyperparam√®tres.  Cela se produit automatiquement.  De plus, un arr√™t pr√©coce nous emp√™che √©galement automatiquement de se recycler.  Ceci, bien s√ªr, est bon, bien que dans les premiers stades des exp√©riences, il puisse √™tre utile de d√©sactiver l'arr√™t pr√©coce afin que vous puissiez voir des signes de recyclage et les utiliser pour affiner l'approche de r√©gularisation. <br><br>  Pour mettre en ≈ìuvre l'OR, nous devons d√©crire plus pr√©cis√©ment ce que signifie ¬´arr√™ter l'am√©lioration de la pr√©cision de la classification¬ª.  Comme nous l'avons vu, la pr√©cision peut aller tr√®s loin, m√™me lorsque la tendance g√©n√©rale s'am√©liore.  Si nous nous arr√™tons pour la premi√®re fois, lorsque la pr√©cision diminue, nous n'atteindrons certainement pas de nouvelles am√©liorations possibles.  La meilleure approche consiste √† arr√™ter l'apprentissage si la meilleure pr√©cision de classification ne s'am√©liore pas pendant longtemps.  Supposons, par exemple, que nous soyons engag√©s dans le MNIST.  Ensuite, nous pouvons d√©cider d'arr√™ter le processus si la pr√©cision de la classification ne s'est pas am√©lior√©e au cours des dix derni√®res √©poques.  Cela garantit que nous ne nous arr√™tons pas trop t√¥t en raison d'un √©chec de la formation, mais nous n'attendrons pas √©ternellement les am√©liorations qui ne se produiront pas. <br><br>  Cette r√®gle ¬´aucune am√©lioration sur dix √©poques¬ª convient bien √† l'√©tude initiale du MNIST.  Cependant, les r√©seaux peuvent parfois atteindre un plateau proche d'une certaine pr√©cision de classification, y rester pendant un certain temps, puis recommencer √† s'am√©liorer.  Si vous devez obtenir de tr√®s bonnes performances, la r√®gle ¬´pas d'am√©lioration sur dix √©poques¬ª peut √™tre trop agressive pour cela.  Par cons√©quent, je recommande d'utiliser la r√®gle ¬´pas d'am√©lioration pendant dix √©poques¬ª pour les exp√©riences primaires, et d'adopter progressivement des r√®gles plus souples lorsque vous commencez √† mieux comprendre le comportement de votre r√©seau: ¬´sans am√©liorations en vingt √©poques¬ª, ¬´sans am√©liorations en cinquante √©poques¬ª, etc. plus loin.  Bien s√ªr, cela nous donne un autre hyperparam√®tre pour l'optimisation!  Mais en pratique, cet hyperparam√®tre est g√©n√©ralement facile √† r√©gler pour de bons r√©sultats.  Et pour les t√¢ches autres que le MNIST, la r√®gle ¬´pas d'am√©lioration sur dix √©poques¬ª peut √™tre trop agressive, ou pas assez agressive, selon les d√©tails d'une t√¢che particuli√®re.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cependant, apr√®s avoir exp√©riment√© un peu, il est g√©n√©ralement assez facile de trouver une strat√©gie d'arr√™t pr√©coce appropri√©e. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous n'avons pas encore utilis√© d'arr√™t pr√©coce dans nos exp√©riences avec MNIST. </font><font style="vertical-align: inherit;">Cela est d√ª au fait que nous avons fait de nombreuses comparaisons de diff√©rentes approches de l'apprentissage. </font><font style="vertical-align: inherit;">Pour de telles comparaisons, il est utile d'utiliser le m√™me nombre d'√©poques dans tous les cas. </font><font style="vertical-align: inherit;">Cependant, cela vaut la peine de changer network2.py en introduisant le RO dans le programme.</font></font><br><br><h3>  Les t√¢ches </h3><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modifiez network2.py pour que le bon de commande y apparaisse selon la r√®gle ¬´pas de changement pour n √©poques¬ª, o√π n est un param√®tre configurable. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pensez √† une r√®gle d'arr√™t pr√©coce autre que ¬´inchang√©e dans n √®res¬ª. </font><font style="vertical-align: inherit;">Id√©alement, la r√®gle devrait rechercher un compromis entre l'obtention d'une pr√©cision avec une confirmation √©lev√©e et un temps d'entra√Ænement assez court. </font><font style="vertical-align: inherit;">Ajoutez une r√®gle √† network2.py et ex√©cutez trois exp√©riences comparant la pr√©cision de validation et le nombre d'√©poques d'apprentissage avec la r√®gle ¬´aucun changement sur 10 √©poques¬ª.</font></font></li></ul><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Plan de changement de vitesse d'apprentissage </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alors que nous avons gard√© la vitesse d'apprentissage Œ∑ constante. </font><font style="vertical-align: inherit;">Cependant, il est souvent utile de le modifier. </font><font style="vertical-align: inherit;">Aux premiers stades du processus de formation, les poids sont plus susceptibles d'√™tre attribu√©s compl√®tement faux. </font><font style="vertical-align: inherit;">Par cons√©quent, il sera pr√©f√©rable d'utiliser une vitesse d'entra√Ænement √©lev√©e, ce qui acc√©l√©rera le changement de poids. </font><font style="vertical-align: inherit;">Ensuite, vous pouvez r√©duire la vitesse de l'entra√Ænement pour effectuer un r√©glage plus fin des √©chelles.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comment esquisser un plan pour changer la vitesse d'apprentissage? Ici, vous pouvez appliquer de nombreuses approches. Une option naturelle consiste √† utiliser la m√™me id√©e de base que dans RO. Nous maintenons la vitesse d'apprentissage constante jusqu'√† ce que la pr√©cision de la confirmation commence √† se d√©t√©riorer. Ensuite, nous r√©duisons le CO d'une certaine quantit√©, disons, deux ou dix fois. Nous r√©p√©tons cela plusieurs fois jusqu'√† ce que le CO soit 1024 (ou 1000) fois inf√©rieur √† celui initial. Et terminer la formation.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un plan pour changer la vitesse d'apprentissage peut am√©liorer l'efficacit√© et ouvre √©galement de grandes opportunit√©s pour choisir un plan. </font><font style="vertical-align: inherit;">Et cela peut √™tre un casse-t√™te - vous pouvez passer une √©ternit√© √† optimiser le plan. </font><font style="vertical-align: inherit;">Pour les premi√®res exp√©riences, je sugg√©rerais d'utiliser une seule valeur constante de CO. </font><font style="vertical-align: inherit;">Cela vous donnera une bonne premi√®re approximation. </font><font style="vertical-align: inherit;">Plus tard, si vous voulez retirer la meilleure efficacit√© du r√©seau, cela vaut la peine d'exp√©rimenter le plan pour changer la vitesse d'apprentissage comme je l'ai d√©crit. </font><font style="vertical-align: inherit;">Un </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">travail scientifique</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> assez facile √† lire </font><a href=""><font style="vertical-align: inherit;">de</font></a><font style="vertical-align: inherit;"> 2010 d√©montre les avantages des vitesses d'apprentissage variables lors de l'attaque du MNIST.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Exercice </font></font></h3><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Modifiez network2.py afin qu'il impl√©mente le plan suivant pour changer la vitesse d'apprentissage: divisez par deux le CR √† chaque fois que la pr√©cision de la confirmation satisfait √† la r√®gle ¬´pas de changement dans 10 √©poques¬ª, et arr√™tez l'apprentissage lorsque la vitesse d'apprentissage tombe √† 1/128 de la vitesse initiale. </font></font></li></ul><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Le param√®tre de r√©gularisation Œª </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je recommande de commencer sans aucune r√©gularisation (Œª = 0,0) et de d√©terminer la valeur de Œ∑, comme indiqu√© ci-dessus. </font><font style="vertical-align: inherit;">En utilisant la valeur s√©lectionn√©e de Œ∑, nous pouvons ensuite utiliser les donn√©es de support pour s√©lectionner une bonne valeur de Œª. </font><font style="vertical-align: inherit;">Commencez avec Œª = 1.0 (je n'ai pas de bons arguments en faveur d'un tel choix), puis augmentez ou diminuez-le de 10 fois afin d'augmenter l'efficacit√© du travail avec les donn√©es de confirmation. </font><font style="vertical-align: inherit;">Apr√®s avoir trouv√© le bon ordre de grandeur, nous pouvons affiner la valeur de Œª plus pr√©cis√©ment. </font><font style="vertical-align: inherit;">Apr√®s cela, il est n√©cessaire de revenir √† nouveau √† l'optimisation Œ∑.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Exercice </font></font></h3><br><ul><li>     ,        ,  Œª  Œ∑.      ,        Œª?      ,        Œ∑? </li></ul><br><h3>        </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si vous utilisez les recommandations de cette section, vous verrez que les valeurs s√©lectionn√©es de Œ∑ et Œª ne correspondent pas toujours exactement √† celles que j'ai utilis√©es pr√©c√©demment. C'est juste que le livre a des limitations de texte, ce qui rend parfois impossible l'optimisation des hyperparam√®tres. Rappelez-vous toutes les comparaisons des diff√©rentes approches de formation sur lesquelles nous avons travaill√© - comparer la fonction de co√ªt quadratique et l'entropie crois√©e, les anciennes et les nouvelles m√©thodes d'initialisation des poids, en commen√ßant par et sans r√©gularisation, etc. Pour donner un sens √† ces comparaisons, j'ai essay√© de ne pas modifier les hyperparam√®tres entre les approches compar√©es (ou de les mettre √† l'√©chelle correctement). Bien s√ªr, il n'y a aucune raison pour que les m√™mes hyperparam√®tres soient optimaux pour toutes les diff√©rentes approches d'apprentissage, donc les hyperparam√®tres que j'utilise sont le r√©sultat d'un compromis.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comme alternative, je pourrais essayer d'optimiser tous les hyper param√®tres pour chaque approche d'apprentissage au maximum. </font><font style="vertical-align: inherit;">Ce serait une approche meilleure et plus honn√™te, car nous tirerions le meilleur parti de chaque approche de l'apprentissage. </font><font style="vertical-align: inherit;">Cependant, nous avons fait des dizaines de comparaisons, et en pratique, cela serait trop co√ªteux en calcul. </font><font style="vertical-align: inherit;">Par cons√©quent, j'ai d√©cid√© de faire un compromis, d'utiliser des options d'hyperparam√®tre assez bonnes (mais pas n√©cessairement optimales).</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Taille du mini pack </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comment choisir la taille du mini-package? </font><font style="vertical-align: inherit;">Pour r√©pondre √† cette question, supposons d'abord que nous sommes engag√©s dans une formation en ligne, c'est-√†-dire que nous utilisons un mini-package de taille 1.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le probl√®me √©vident de l'apprentissage en ligne est que l'utilisation de mini-packages consistant en un seul exemple de formation entra√Ænera de graves erreurs dans l'estimation du gradient. Mais en fait, ces erreurs ne pr√©senteront pas un probl√®me aussi grave. La raison en est que les estimations de gradient individuelles n'ont pas besoin d'√™tre tr√®s pr√©cises. Nous avons juste besoin d'obtenir une estimation suffisamment pr√©cise pour que notre fonction de co√ªt diminue. C'est comme si vous essayiez d'atteindre le p√¥le magn√©tique nord, mais vous auriez une boussole peu fiable, avec chaque mesure erron√©e de 10 √† 20 degr√©s. Si vous v√©rifiez la boussole assez souvent et qu'elle indique en moyenne la bonne direction, vous pourrez √©ventuellement vous rendre au p√¥le magn√©tique nord.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Compte tenu de cet argument, il semble que nous devrions utiliser l'apprentissage en ligne. Mais en r√©alit√©, la situation est un peu plus compliqu√©e. Dans la t√¢che du dernier chapitre, j'ai soulign√© que pour calculer la mise √† jour du gradient pour tous les exemples dans le mini-package, vous pouvez utiliser des techniques de matrice en m√™me temps, plut√¥t qu'une boucle. En fonction des d√©tails de votre mat√©riel et de la biblioth√®que d'alg√®bre lin√©aire, il peut s'av√©rer beaucoup plus rapide de calculer une estimation pour un mini-paquet de, disons, 100 que de calculer une estimation de gradient pour un mini-paquet dans un cycle pour 100 exemples de formation. Cela peut s'av√©rer, par exemple, seulement 50 fois plus lent, et non 100. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Au d√©but, il semble que cela ne nous aide pas beaucoup. Avec une taille de mini-paquet de 100, la r√®gle de formation pour les poids ressemble √†:</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1"><span class="MJXp-mtable" id="MJXp-Span-2"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-3" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-4" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-5"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-6" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Üí </font></font></span><span class="MJXp-msup" id="MJXp-Span-7"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-8" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo MJXp-script" id="MJXp-Span-9" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Ä≤</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-10" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> = </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-11"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-12" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-13"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œ∑ </font></font></span><span class="MJXp-mfrac" id="MJXp-Span-14" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-15"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-16"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">100</font></font></span></span></span></span></span></span><span class="MJXp-munderover" id="MJXp-Span-17"><span class=""><span class="MJXp-mo" id="MJXp-Span-18" style="margin-left: 0.111em; margin-right: 0.167em;"><span class="MJXp-largeop"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àë</font></font></span></span></span><span class=" MJXp-script"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-19" style="margin-left: 0px;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></span></span></span><span class="MJXp-mi" id="MJXp-Span-20"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àá</font></font></span><span class="MJXp-msubsup" id="MJXp-Span-21"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-22" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C</font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-23" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="76.867ex" height="6.154ex" viewBox="0 -1558.2 33095.6 2649.6" role="img" focusable="false" style="vertical-align: -2.535ex; max-width: 638px;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(30815,0)"><g id="mjx-eqn-100" transform="translate(0,157)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-28"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-31" x="389" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-30" x="890" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-30" x="1390" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-29" x="1891" y="0"></use></g></g><g transform="translate(10345,0)"><g transform="translate(-15,0)"><g transform="translate(0,157)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-77" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-2192" x="994" y="0"></use><g transform="translate(2272,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-2032" x="1013" y="583"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-3D" x="3561" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-77" x="4617" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-2212" x="5556" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-3B7" x="6557" y="0"></use><g transform="translate(7060,0)"><g transform="translate(120,0)"><rect stroke="none" width="1621" height="60" x="0" y="220"></rect><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-31" x="560" y="676"></use><g transform="translate(60,-686)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-30" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-30" x="1001" y="0"></use></g></g></g><g transform="translate(9089,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJSZ2-2211" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-78" x="735" y="-1487"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-2207" x="10700" y="0"></use><g transform="translate(11533,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-43" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-78" x="1011" y="-213"></use></g></g></g></g></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> w \rightarrow w' = w-\eta \frac{1}{100} \sum_x \nabla C_x \tag{100} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o√π la sommation passe en revue les exemples de formation dans le mini-package. </font><font style="vertical-align: inherit;">Comparez avec</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-24"><span class="MJXp-mtable" id="MJXp-Span-25"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-26" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-27" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-28"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-29" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Üí </font></font></span><span class="MJXp-msup" id="MJXp-Span-30"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-31" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo MJXp-script" id="MJXp-Span-32" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Ä≤</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-33" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> = </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-34"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-35" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-36"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œ∑ </font></font></span><span class="MJXp-mi" id="MJXp-Span-37"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àá </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-38"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-39" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-40" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="76.867ex" height="2.901ex" viewBox="0 -883.9 33095.6 1249" role="img" focusable="false" style="vertical-align: -0.848ex; max-width: 638px;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(30815,0)"><g id="mjx-eqn-101" transform="translate(0,-30)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-28"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-31" x="389" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-30" x="890" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-31" x="1390" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-29" x="1891" y="0"></use></g></g><g transform="translate(12164,0)"><g transform="translate(-15,0)"><g transform="translate(0,-30)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-77" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-2192" x="994" y="0"></use><g transform="translate(2272,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-2032" x="1013" y="583"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-3D" x="3561" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-77" x="4617" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-2212" x="5556" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-3B7" x="6557" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-2207" x="7060" y="0"></use><g transform="translate(7894,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-43" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-78" x="1011" y="-213"></use></g></g></g></g></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> w \rightarrow w' = w-\eta \nabla C_x \tag{101} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pour l'apprentissage en ligne. </font><font style="vertical-align: inherit;">M√™me s'il faut 50 fois plus de temps pour mettre √† jour le mini-package, la formation en ligne semble toujours √™tre la meilleure option, car nous serons mis √† jour plus souvent. </font><font style="vertical-align: inherit;">Mais supposons, cependant, que dans le cas du mini-package, nous avons augment√© la vitesse d'apprentissage de 100 fois, puis la r√®gle de mise √† jour se transforme en:</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-41"><span class="MJXp-mtable" id="MJXp-Span-42"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-43" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-44" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-45"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-46" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Üí </font></font></span><span class="MJXp-msup" id="MJXp-Span-47"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo MJXp-script" id="MJXp-Span-49" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Ä≤</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-50" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> = </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-51"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-52" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-53"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œ∑ </font></font></span><span class="MJXp-munderover" id="MJXp-Span-54"><span class=""><span class="MJXp-mo" id="MJXp-Span-55" style="margin-left: 0.111em; margin-right: 0.167em;"><span class="MJXp-largeop"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àë</font></font></span></span></span><span class=" MJXp-script"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-56" style="margin-left: 0px;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> x</font></font></span></span></span><span class="MJXp-mi" id="MJXp-Span-57"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àá </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-58"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-59" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-60" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed"><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="76.867ex" height="5.31ex" viewBox="0 -1402.6 33095.6 2286.5" role="img" focusable="false" style="vertical-align: -2.053ex; max-width: 638px;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(30815,0)"><g id="mjx-eqn-102" transform="translate(0,354)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-28"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-31" x="389" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-30" x="890" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-32" x="1390" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-29" x="1891" y="0"></use></g></g><g transform="translate(11275,0)"><g transform="translate(-15,0)"><g transform="translate(0,354)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-77" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-2192" x="994" y="0"></use><g transform="translate(2272,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-77" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-2032" x="1013" y="583"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-3D" x="3561" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-77" x="4617" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-2212" x="5556" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-3B7" x="6557" y="0"></use><g transform="translate(7227,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJSZ2-2211" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-78" x="735" y="-1487"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMAIN-2207" x="8838" y="0"></use><g transform="translate(9672,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-43" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/460711/&amp;usg=ALkJrhiws7K3TWqxGeTjghIY56VRcpvmqw#MJMATHI-78" x="1011" y="-213"></use></g></g></g></g></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-3"> w \rightarrow w' = w-\eta \sum_x \nabla C_x \tag{102} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cela est similaire √† 100 √©tapes distinctes de l'apprentissage en ligne avec une vitesse d'apprentissage de Œ∑. </font><font style="vertical-align: inherit;">Cependant, une √©tape de l'apprentissage en ligne ne prend que 50 fois plus de temps. </font><font style="vertical-align: inherit;">Bien s√ªr, en r√©alit√©, il ne s'agit pas exactement de 100 niveaux d'apprentissage en ligne, car dans le mini-package, tous les ‚àáC </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sont √©valu√©s pour le m√™me ensemble de poids, contrairement √† l'apprentissage cumulatif qui se produit dans le cas en ligne. </font><font style="vertical-align: inherit;">Et pourtant, il semble que l'utilisation de mini-packages plus grands acc√©l√©rera le processus.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Compte tenu de tous ces facteurs, choisir la meilleure taille de mini-pack est un compromis. Choisissez trop petit et ne profitez pas pleinement des bonnes biblioth√®ques de matrices optimis√©es pour un mat√©riel rapide. Choisissez trop grand et ne mettra pas √† jour le poids assez souvent. Vous devez choisir une valeur de compromis qui maximise la vitesse d'apprentissage. Heureusement, le choix de la taille du mini-paquet √† laquelle la vitesse est maximis√©e est relativement ind√©pendant des autres hyperparam√®tres (√† l'exception de l'architecture g√©n√©rale), donc, pour trouver une bonne taille de mini-paquet, il n'est pas n√©cessaire de les optimiser. Par cons√©quent, il suffira d'utiliser des valeurs acceptables (pas n√©cessairement optimales) pour d'autres hyperparam√®tres, puis d'essayer plusieurs tailles diff√©rentes de mini-paquets, en mettant √† l'√©chelle Œ∑, comme indiqu√© ci-dessus.Construisez un graphique de la pr√©cision de la confirmation en fonction du temps (temps r√©el √©coul√©, pas des √©poques!), Et choisissez une taille de mini-paquet qui donne l'am√©lioration des performances la plus rapide. Avec la taille de mini-paquet s√©lectionn√©e, vous pouvez proc√©der √† l'optimisation d'autres hyperparam√®tres.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bien s√ªr, comme vous l'avez sans doute d√©j√† compris, dans notre travail, je n'ai pas effectu√© une telle optimisation. </font><font style="vertical-align: inherit;">Dans notre mise en ≈ìuvre de l'Assembl√©e nationale, une approche rapide pour la mise √† jour des mini-packages n'est pas du tout utilis√©e. </font><font style="vertical-align: inherit;">J'ai simplement utilis√© le mini-paquet de taille 10 sans le commenter ni l'expliquer, dans presque tous les exemples. </font><font style="vertical-align: inherit;">En g√©n√©ral, nous pourrions acc√©l√©rer l'apprentissage en r√©duisant la taille du mini-package. </font><font style="vertical-align: inherit;">Je ne l'ai pas fait, en particulier, car mes premi√®res exp√©riences sugg√©raient que l'acc√©l√©ration serait plut√¥t modeste. </font><font style="vertical-align: inherit;">Mais dans les impl√©mentations pratiques, nous aimerions certainement mettre en ≈ìuvre l'approche la plus rapide pour mettre √† jour les mini-packages, et essayer d'optimiser leur taille afin de maximiser la vitesse globale.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Techniques automatis√©es </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">J'ai d√©crit ces approches heuristiques comme quelque chose qui doit √™tre modifi√© √† la main. L'optimisation manuelle est un bon moyen de se faire une id√©e du fonctionnement de NS. Cependant, et d'ailleurs, il n'est pas surprenant que beaucoup de travail ait d√©j√† √©t√© fait sur l' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">automatisation de</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ce projet. Une technique courante est une recherche de grille qui tamise syst√©matiquement une grille dans l'espace des hyperparam√®tres. Un aper√ßu des r√©alisations et des limites de cette technique (ainsi que des recommandations sur des alternatives faciles √† mettre en ≈ìuvre) peut √™tre trouv√© en </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2012</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . De nombreuses techniques sophistiqu√©es ont √©t√© propos√©es. Je ne les passerai pas en revue tous, mais je veux noter le travail prometteur de 2012, utilisant </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l'optimisation bay√©sienne des</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> hyperparam√®tres. Le code du travail est </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ouvert √† tous</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , et avec un certain succ√®s a √©t√© utilis√© par d'autres chercheurs. </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> R√©sumer </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En utilisant les r√®gles de pratique que j'ai d√©crites, vous n'obtiendrez pas le meilleur r√©sultat possible de votre PS. Mais ils sont susceptibles de vous fournir un bon point de d√©part et une base pour de nouvelles am√©liorations. En particulier, j'ai essentiellement d√©crit les hyperparam√®tres ind√©pendamment. En pratique, il existe un lien entre eux. Vous pouvez exp√©rimenter avec Œ∑, d√©cider que vous avez trouv√© la valeur correcte, puis commencer √† optimiser Œª et constater qu'elle viole votre optimisation Œ∑. Dans la pratique, il est utile de se d√©placer dans diff√©rentes directions, en s'approchant progressivement des bonnes valeurs. Surtout, gardez √† l'esprit que les approches heuristiques que j'ai d√©crites sont de simples r√®gles de pratique, mais pas quelque chose de grav√© dans la pierre. Vous devez rechercher des signes que quelque chose ne fonctionne pas et avoir le d√©sir d'exp√©rimenter. En particuliersurveillez attentivement le comportement de votre r√©seau de neurones, en particulier l'exactitude de la confirmation.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La complexit√© du choix des hyperparam√®tres est aggrav√©e par le fait que la connaissance pratique de leur choix est r√©partie sur de nombreux travaux et programmes de recherche, et n'est souvent que dans la t√™te des praticiens individuels. Il y a √©norm√©ment de travail avec des descriptions de ce qu'il faut faire (souvent en conflit les uns avec les autres). Cependant, il existe plusieurs travaux particuli√®rement utiles qui synth√©tisent et mettent en √©vidence une grande partie de ces connaissances. Dans </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">le</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Joshua Benji de 2012 donne des </font><font style="vertical-align: inherit;">conseils pratiques sur l'utilisation de descente de gradient de r√©tropropagation et de </font><font style="vertical-align: inherit;">formation pour l'Assembl√©e nationale, y compris l'Assembl√©e nationale et profonde. Benjio d√©crit de nombreux d√©tails de mani√®re beaucoup plus d√©taill√©e. Que moi, y compris une recherche syst√©matique d'hyperparam√®tres. Un autre bon travail est le </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">travail.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1998 Yanna Lekuna et autres. Les deux ouvrages figurent dans le livre extr√™mement utile de 2012, qui contient de nombreuses astuces souvent utilis√©es √† l'Assembl√©e nationale: " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R√©seaux de neurones: astuces d'artisanat</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ". Le livre co√ªte cher, mais bon nombre de ses articles ont √©t√© publi√©s sur Internet par leurs auteurs, et ils peuvent √™tre trouv√©s dans les moteurs de recherche.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A partir de ces articles, et surtout de nos propres exp√©riences, une chose devient claire: le probl√®me de l'optimisation des hyperparam√®tres ne peut √™tre qualifi√© de compl√®tement r√©solu. Il y a toujours une autre astuce que vous pouvez essayer d'am√©liorer l'efficacit√©. Les √©crivains ont un dicton selon lequel un livre ne peut pas √™tre termin√©, mais peut seulement √™tre abandonn√©. Il en va de m√™me pour l'optimisation NS: l'espace des hyperparam√®tres est si vaste que l'optimisation ne peut pas √™tre termin√©e, mais ne peut √™tre arr√™t√©e, laissant la NS aux descendants. Votre objectif sera donc de d√©velopper un workflow qui vous permettra de r√©aliser rapidement une bonne optimisation, tout en vous laissant la possibilit√© d'essayer des options d'optimisation plus d√©taill√©es si n√©cessaire.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les difficult√©s de s√©lection des hyperparam√®tres font que certaines personnes se plaignent que les NS n√©cessitent trop d'efforts par rapport aux autres techniques de MO. J'ai entendu de nombreuses variantes de plaintes comme: ¬´Oui, une NS bien r√©gl√©e peut donner la meilleure efficacit√© lors de la r√©solution d'un probl√®me. Mais d'un autre c√¥t√©, je peux essayer une for√™t al√©atoire [ou SVM, ou toute autre technologie pr√©f√©r√©e], et √ßa marche. Je n'ai pas le temps de d√©terminer quelle NA me convient. " Bien s√ªr, d‚Äôun point de vue pratique, il est bon d‚Äôavoir des techniques faciles √† utiliser avec un ami. C'est particuli√®rement bon lorsque vous commencez tout juste √† travailler sur une t√¢che, et il n'est toujours pas clair si le MO peut aider √† la r√©soudre. D'un autre c√¥t√©, s'il est important pour vous d'obtenir des r√©sultats optimaux, vous devrez peut-√™tre essayer plusieurs approches qui n√©cessitent des connaissances plus sp√©cialis√©es. Ce serait g√©nialsi la MO √©tait toujours facile, mais il n'y a aucune raison pour que ce soit a priori trivial.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Autres techniques </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chacune des techniques d√©velopp√©es dans ce chapitre est valable en soi, mais ce n'est pas la seule raison pour laquelle je les ai d√©crites. </font><font style="vertical-align: inherit;">Il est plus important de vous familiariser avec certains des probl√®mes qui peuvent survenir dans le domaine de l'AN, et avec un style d'analyse qui peut aider √† les surmonter. </font><font style="vertical-align: inherit;">D'une certaine mani√®re, nous apprenons √† penser √† la NS. </font><font style="vertical-align: inherit;">Dans la suite de ce chapitre, je d√©crirai bri√®vement un ensemble d'autres techniques. </font><font style="vertical-align: inherit;">Leurs descriptions ne seront pas aussi profondes que dans les pr√©c√©dentes, mais elles devraient transmettre certaines sensations concernant la vari√©t√© des techniques rencontr√©es dans le domaine de la NA.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Variations de descente de gradient stochastique </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La descente du gradient stochastique par r√©tropropagation nous a bien servi lors de l'attaque du probl√®me de la classification des nombres manuscrits du MNIST. </font><font style="vertical-align: inherit;">Cependant, il existe de nombreuses autres approches pour optimiser la fonction de co√ªt, et elles montrent parfois une efficacit√© sup√©rieure √† celle de la descente de gradient stochastique avec des mini-packages. </font><font style="vertical-align: inherit;">Dans cette section, je d√©cris bri√®vement deux de ces approches, la Hesse et l'√©lan.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Hessian </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour commencer, mettons de c√¥t√© l'Assembl√©e nationale. </font><font style="vertical-align: inherit;">Au lieu de cela, nous consid√©rons simplement le probl√®me abstrait de minimisation de la fonction de co√ªt C de nombreuses variables, w = w1, w2, ..., c'est-√†-dire C = C (w). </font><font style="vertical-align: inherit;">Selon </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">le th√©or√®me de Taylor,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> la fonction de co√ªt au point w peut √™tre approxim√©e:</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-61"><span class="MJXp-mtable" id="MJXp-Span-62"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-63" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-64" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-65"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-66" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-67"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-68" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mi" id="MJXp-Span-69"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-70"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-71" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-72" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">= </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-73"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-74" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-75"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-76" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-77" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-munderover" id="MJXp-Span-78"><span class=""><span class="MJXp-mo" id="MJXp-Span-79" style="margin-left: 0.111em; margin-right: 0.167em;"><span class="MJXp-largeop"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àë</font></font></span></span></span><span class=" MJXp-script"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80" style="margin-left: 0px;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> j </font></font></span></span></span><span class="MJXp-mfrac" id="MJXp-Span-81" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mi" id="MJXp-Span-82"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àÇ </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-83"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C</font></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi" id="MJXp-Span-84"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àÇ </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-85"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-86" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-87" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></span></span></span></span></span></span></span><span class="MJXp-mi" id="MJXp-Span-88"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Œî</font></font></span><span class="MJXp-msubsup" id="MJXp-Span-89"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-90" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-91" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></span></span><span class="MJXp-mspace" id="MJXp-Span-92" style="width: 0em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-93" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mfrac" id="MJXp-Span-94" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-95"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-96"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></span></span></span></span></span></span><span class="MJXp-munderover" id="MJXp-Span-97"><span class=""><span class="MJXp-mo" id="MJXp-Span-98" style="margin-left: 0.111em; margin-right: 0.167em;"><span class="MJXp-largeop"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àë</font></font></span></span></span><span class=" MJXp-script"><span class="MJXp-mrow" id="MJXp-Span-99" style="margin-left: 0px;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-100"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-101"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k</font></font></span></span></span></span><span class="MJXp-mi" id="MJXp-Span-102"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî</font></font></span><span class="MJXp-msubsup" id="MJXp-Span-103"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-104" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-105" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></span></span><span class="MJXp-mfrac" id="MJXp-Span-106" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-107"><span class="MJXp-mi" id="MJXp-Span-108" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àÇ</font></font></span><span class="MJXp-mn MJXp-script" id="MJXp-Span-109" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-110"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C</font></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi" id="MJXp-Span-111"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àÇ </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-112"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-113" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-114" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></span></span><span class="MJXp-mi" id="MJXp-Span-115"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àÇ </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-116"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-117" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-118" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k</font></font></span></span></span></span></span></span></span><span class="MJXp-mi" id="MJXp-Span-119"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Œî</font></font></span><span class="MJXp-msubsup" id="MJXp-Span-120"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-121" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-122" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-123" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+</font></font></span><span class="MJXp-mo" id="MJXp-Span-124" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">...</font></font></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-4"> C(w+\Delta w) = C(w) + \sum_j \frac{\partial C}{\partial w_j} \Delta w_j \nonumber \\ + \frac{1}{2} \sum_{jk} \Delta w_j \frac{\partial^2 C}{\partial w_j \partial w_k} \Delta w_k + \ldots \tag{103} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Nous pouvons le r√©√©crire de mani√®re plus compacte </font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-125"><span class="MJXp-mtable" id="MJXp-Span-126"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-127" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-128" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-129"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-130" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-131"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-132" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mi" id="MJXp-Span-133"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-134"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-135" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-136" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">= </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-137"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-138" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-139"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-140" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-141" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mi" id="MJXp-Span-142"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àá </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-143"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-144" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ãÖ </font></font></span><span class="MJXp-mi" id="MJXp-Span-145"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-146"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-147" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mfrac" id="MJXp-Span-148" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-149"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-150"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></span></span></span></span></span></span><span class="MJXp-mi" id="MJXp-Span-151"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Œî</font></font></span><span class="MJXp-msubsup" id="MJXp-Span-152"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-153" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-154" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">T</font></font></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-155"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">H</font></font></span><span class="MJXp-mi" id="MJXp-Span-156"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî</font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-157"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span><span class="MJXp-mo" id="MJXp-Span-158" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+</font></font></span><span class="MJXp-mo" id="MJXp-Span-159" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">...</font></font></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-5"> C(w+\Delta w) = C(w) + \nabla C \cdot \Delta w + \frac{1}{2} \Delta w^T H \Delta w + \ldots \tag{104} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o√π ‚àáC est le vecteur de gradient ordinaire et H est la matrice, connue sous le nom de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">matrice de Hesse</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , √† la place de jk dans laquelle ‚àÇ </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> C / ‚àÇw </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àÇw </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Supposons que nous approchions C en abandonnant les termes d'ordre sup√©rieur se cachant derri√®re les points de suspension dans la formule:</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-160"><span class="MJXp-mtable" id="MJXp-Span-161"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-162" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-163" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-164"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-165" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-166"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-167" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mi" id="MJXp-Span-168"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-169"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-170" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-171" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚âà </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-172"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-173" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-174"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-175" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-176" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mi" id="MJXp-Span-177"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àá </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-178"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C </font></font></span><span class="MJXp-mo" id="MJXp-Span-179" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ãÖ </font></font></span><span class="MJXp-mi" id="MJXp-Span-180"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-181"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-182" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mfrac" id="MJXp-Span-183" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-184"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-185"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></span></span></span></span></span></span><span class="MJXp-mi" id="MJXp-Span-186"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Œî</font></font></span><span class="MJXp-msubsup" id="MJXp-Span-187"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-188" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-189" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">T</font></font></span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-190"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">H</font></font></span><span class="MJXp-mi" id="MJXp-Span-191"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî</font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-192"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w</font></font></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-6"> C(w+\Delta w) \approx C(w) + \nabla C \cdot \Delta w + \frac{1}{2} \Delta w^T H \Delta w \tag{105} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> En utilisant l'alg√®bre, il peut √™tre d√©montr√© que l'expression sur le c√¥t√© droit peut √™tre minimis√©e en s√©lectionnant: </font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-193"><span class="MJXp-mtable" id="MJXp-Span-194"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-195" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-196" style="text-align: center;"><span class="MJXp-mi" id="MJXp-Span-197"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œî </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-198"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-199" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">= </font></font></span><span class="MJXp-mo" id="MJXp-Span-200" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-201"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-202" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">H </font></font></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-203" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-204"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-mn" id="MJXp-Span-205"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></span></span></span><span class="MJXp-mi" id="MJXp-Span-206"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àá </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-207"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C</font></font></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-7"> \Delta w = -H^{-1} \nabla C \tag{106} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Ä strictement parler, pour que ce ne soit qu'un minimum, et pas seulement un extremum, nous devons supposer que la matrice de Hesse est plus d√©finitivement positive. </font><font style="vertical-align: inherit;">Intuitivement, cela signifie que la fonction C est comme une vall√©e, pas une montagne ou une selle. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si (105) est une bonne approximation de la fonction de co√ªt, il est pr√©vu que la transition du point w au point w + Œîw = w - H - 1 ‚àíC devrait r√©duire consid√©rablement la fonction de co√ªt. </font><font style="vertical-align: inherit;">Cela offre un algorithme de minimisation des co√ªts possible:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> S√©lectionnez le point de d√©part w. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mettez √† jour w en un nouveau point, w ‚Ä≤ = w - H </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àí1</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àáC, o√π les H de Hesse et ‚àáC sont calcul√©s en w.</font></font></li><li>  w'   , w‚Ä≤‚Ä≤=w‚Ä≤‚àíH‚Ä≤ <sup>‚àí1</sup> ‚àá‚Ä≤C,   H  ‚àáC   w'. </li><li>  ... </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En pratique, (105) n'est qu'une approximation, et il vaut mieux faire des pas plus petits. Nous le ferons en mettant constamment √† jour w par Œîw = ‚àíŒ∑H - 1‚àáC, o√π Œ∑ est la vitesse d'apprentissage. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cette approche de minimisation de la fonction de co√ªt est connue sous le nom d'optimisation de Hesse. Il existe des r√©sultats th√©oriques et empiriques montrant que les m√©thodes de Hesse convergent vers un minimum en moins d'√©tapes qu'une descente de gradient standard. En particulier, en incluant des informations sur les changements de second ordre dans la fonction de co√ªt, il est possible d'√©viter de nombreuses pathologies rencontr√©es en descente de gradient dans l'approche hessoise. De plus, il existe des versions de l'algorithme de r√©tropropagation qui peuvent √™tre utilis√©es pour calculer la Hesse.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si l'optimisation de la Hesse est si cool, alors pourquoi ne l'utilisons-nous pas dans notre NS? </font><font style="vertical-align: inherit;">Malheureusement, bien qu'il poss√®de de nombreuses propri√©t√©s souhaitables, il en existe une tr√®s ind√©sirable: elle est tr√®s difficile √† mettre en pratique. </font><font style="vertical-align: inherit;">Une partie du probl√®me est la taille √©norme de la matrice de Hesse. </font><font style="vertical-align: inherit;">Supposons que nous ayons un NS avec 10 </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> poids et d√©calages. </font><font style="vertical-align: inherit;">Ensuite, dans la matrice de Hesse correspondante, il y aura 10 </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √ó 10 </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> = 10 </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">14</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √©l√©ments. </font><font style="vertical-align: inherit;">Trop! </font><font style="vertical-align: inherit;">En cons√©quence </font><font style="vertical-align: inherit;">, il s'av√®re tr√®s difficile de </font><font style="vertical-align: inherit;">calculer H </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àí1</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚àáC en pratique. </font><font style="vertical-align: inherit;">Mais cela ne signifie pas qu'il est inutile de la conna√Ætre. </font><font style="vertical-align: inherit;">De nombreuses options de descente de gradient sont inspir√©es de l'optimisation de la Hesse, elles √©vitent simplement le probl√®me des matrices excessivement grandes. </font><font style="vertical-align: inherit;">Jetons un ≈ìil √† l'une de ces techniques, la descente en gradient d'impulsion.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Descente de gradient bas√©e sur les impulsions </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Intuitivement, l'avantage de l'optimisation de Hesse est qu'elle inclut non seulement des informations sur le gradient, mais √©galement des informations sur son changement. La descente de gradient bas√©e sur les impulsions est bas√©e sur une intuition similaire, mais √©vite les grandes matrices des d√©riv√©es secondes. Pour comprendre la technique de l'impulsion, rappelons notre premi√®re image de descente en gradient, dans laquelle nous avons examin√© une balle roulant dans une vall√©e. Ensuite, nous avons vu que la descente en pente, contrairement √† son nom, ne ressemble que l√©g√®rement √† une boule tombant au fond. La technique d'impulsion modifie la descente du gradient √† deux endroits, ce qui la rend plus semblable √† une image physique. Elle introduit d'abord le concept de ¬´vitesse¬ª pour les param√®tres que nous essayons d'optimiser. Le gradient essaie de changer la vitesse, pas "l'emplacement" directement, de la m√™me mani√®re que les forces physiques modifient la vitesse,et n'affectent qu'indirectement l'emplacement. Deuxi√®mement, la m√©thode des impulsions est une sorte de terme de friction qui r√©duit progressivement la vitesse.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Donnons une d√©finition math√©matique plus pr√©cise. </font><font style="vertical-align: inherit;">Nous introduisons les variables de vitesse v = v1, v2, ..., une pour chaque variable correspondante w </font></font><sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (dans le r√©seau neuronal, ces variables incluent naturellement tous les poids et d√©placements). </font><font style="vertical-align: inherit;">Ensuite, nous changeons la r√®gle de mise √† jour de la descente de gradient w ‚Üí w ‚Ä≤ = w - Œ∑‚àáC en</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-208"><span class="MJXp-mtable" id="MJXp-Span-209"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-210" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-211" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-212"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">v </font></font></span><span class="MJXp-mo" id="MJXp-Span-213" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Üí </font></font></span><span class="MJXp-msup" id="MJXp-Span-214"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-215" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">v </font></font></span><span class="MJXp-mo MJXp-script" id="MJXp-Span-216" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Ä≤</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-217" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> = </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-218"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œº </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-219"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">v </font></font></span><span class="MJXp-mo" id="MJXp-Span-220" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-221"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Œ∑ </font></font></span><span class="MJXp-mi" id="MJXp-Span-222"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚àá </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-223"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C</font></font></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-8"> v \rightarrow v' = \mu v - \eta \nabla C \tag{107} </script></p><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-224"><span class="MJXp-mtable" id="MJXp-Span-225"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-226" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-227" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-228"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-229" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Üí </font></font></span><span class="MJXp-msup" id="MJXp-Span-230"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-231" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo MJXp-script" id="MJXp-Span-232" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Ä≤</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-233" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> = </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-234"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-235" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-msup" id="MJXp-Span-236"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-237" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">v </font></font></span><span class="MJXp-mo MJXp-script" id="MJXp-Span-238" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚Ä≤</font></font></span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-9"> w \rightarrow w' = w+v' \tag{108} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans les √©quations, Œº est un hyperparam√®tre qui contr√¥le la quantit√© de freinage ou de friction du syst√®me. Pour comprendre la signification des √©quations, il est tout d'abord utile de consid√©rer le cas o√π Œº = 1, c'est-√†-dire lorsqu'il n'y a pas de frottement. Dans ce cas, l'√©tude des √©quations montre que maintenant la ¬´force¬ª ‚àáC change la vitesse v, et la vitesse contr√¥le le taux de changement w. Intuitivement, la vitesse peut √™tre gagn√©e en y ajoutant constamment des membres de gradient. Cela signifie que si le gradient se d√©place dans environ une direction pendant plusieurs √©tapes de l'entra√Ænement, nous pouvons gagner une vitesse de mouvement suffisamment √©lev√©e dans cette direction. Imaginez, par exemple, ce qui se passe en descente:</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/37e/5f9/af1/37e5f9af1985610568cba31157e35763.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Ä chaque descente de la pente, la vitesse augmente et nous nous d√©pla√ßons de plus en plus vite au fond de la vall√©e. Cela permet √† la technique de vitesse de fonctionner beaucoup plus rapidement que la descente √† gradient standard. Bien s√ªr, le probl√®me est que, ayant atteint le fond de la vall√©e, nous allons la traverser. Ou, si le gradient change trop rapidement, il se peut que nous nous d√©placions dans la direction oppos√©e. C'est le point d'introduire l'hyperparam√®tre Œº dans (107). J'ai dit plus t√¥t que Œº contr√¥le la quantit√© de friction dans le syst√®me; plus pr√©cis√©ment, la quantit√© de frottement doit √™tre imagin√©e comme 1-Œº. Lorsque Œº = 1, comme nous l'avons vu, il n'y a pas de frottement, et la vitesse est compl√®tement d√©termin√©e par le gradient ‚àáC. Et vice versa, lorsque Œº = 0, il y a beaucoup de friction, aucune vitesse n'est gagn√©e et les √©quations (107) et (108) sont r√©duites aux √©quations habituelles de descente de gradient, w ‚Üí w ‚Ä≤ = w - Œ∑‚àáC. En pratique,l'utilisation de la valeur de Œº dans l'intervalle entre 0 et 1 peut nous donner l'avantage de pouvoir gagner en vitesse sans risque de glisser au minimum. Nous pouvons choisir une telle valeur pour Œº en utilisant les donn√©es de confirmation en attente de la m√™me mani√®re que nous avons choisi les valeurs pour Œ∑ et Œª.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jusqu'√† pr√©sent, j'ai √©vit√© de nommer l'hyperparam√®tre Œº. Le fait est que le nom standard de Œº a √©t√© mal choisi: il s‚Äôappelle le coefficient de moment. Cela peut √™tre d√©routant car Œº n'est pas du tout comme le concept de momentum de la physique. Elle est beaucoup plus fortement associ√©e au frottement. Cependant, le terme ¬´coefficient de momentum¬ª est largement utilis√©, nous continuerons donc √† l'utiliser √©galement.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une caract√©ristique int√©ressante de la technique d'impulsion est que presque rien ne doit √™tre fait pour modifier la mise en ≈ìuvre de la descente de gradient pour y inclure cette technique. </font><font style="vertical-align: inherit;">Nous pouvons toujours utiliser la r√©tropropagation pour calculer les gradients, comme pr√©c√©demment, et utiliser des id√©es comme la v√©rification de mini-packs s√©lectionn√©s stochastiquement. </font><font style="vertical-align: inherit;">Dans ce cas, nous pouvons obtenir certains des avantages de l'optimisation de Hesse en utilisant des informations sur les changements de gradient. </font><font style="vertical-align: inherit;">Cependant, tout cela se passe sans d√©fauts et avec seulement des changements de code mineurs. </font><font style="vertical-align: inherit;">En pratique, la technique de l'impulsion est largement utilis√©e et contribue souvent √† acc√©l√©rer l'apprentissage.</font></font><br><br><h3>  Exercices </h3><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Que se passera-t-il si nous utilisons Œº&gt; 1 dans la technique d'impulsion? </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Que se passera-t-il si nous utilisons Œº &lt;0 dans la technique d'impulsion? </font></font></li></ul><br><br><h3>  D√©fi </h3><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ajoutez une descente de gradient stochastique bas√©e sur l'√©lan √† network2.py. </font></font></li></ul><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Autres approches pour minimiser la fonction de co√ªt </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De nombreuses autres approches ont √©t√© d√©velopp√©es pour minimiser la fonction de co√ªt, et aucun accord n'a √©t√© trouv√© sur la meilleure approche. </font><font style="vertical-align: inherit;">En approfondissant le sujet des r√©seaux de neurones, il est utile de se plonger dans d'autres technologies, de comprendre comment elles fonctionnent, quelles sont leurs forces et leurs faiblesses et comment les mettre en pratique. </font><font style="vertical-align: inherit;">Dans le </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">travail que</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> j'ai mentionn√© plus t√¥t </font><font style="vertical-align: inherit;">, plusieurs de ces techniques sont introduites et compar√©es, y compris la descente en gradient appari√© et la m√©thode BFGS (et √©tudient √©galement la m√©thode BFGS √©troitement li√©e avec restriction de m√©moire, ou </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L-BFGS</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font><font style="vertical-align: inherit;">Une autre technologie qui a r√©cemment montr√© des </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r√©sultats prometteurs.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, il s'agit du gradient acc√©l√©r√© de Nesterov, am√©liorant la technique d'impulsion. </font><font style="vertical-align: inherit;">Cependant, la descente de gradient simple fonctionne bien pour de nombreuses t√¢ches, en particulier lorsque vous utilisez l'√©lan, nous allons donc nous en tenir √† la descente de gradient stochastique jusqu'√† la fin du livre.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Autres mod√®les de neurones artificiels </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jusqu'√† pr√©sent, nous avons cr√©√© notre NS en utilisant des neurones sigmo√Ødes. </font><font style="vertical-align: inherit;">En principe, NS construit sur des neurones sigmo√Ødes peut calculer n'importe quelle fonction. </font><font style="vertical-align: inherit;">Mais en pratique, les r√©seaux construits sur d'autres mod√®les de neurones sont parfois en avance sur ceux sigmo√Ødes. </font><font style="vertical-align: inherit;">Selon l'application, les r√©seaux bas√©s sur de tels mod√®les alternatifs peuvent apprendre plus rapidement, mieux se g√©n√©raliser aux donn√©es de v√©rification, ou faire les deux. </font><font style="vertical-align: inherit;">Permettez-moi de mentionner quelques mod√®les alternatifs de neurones pour vous donner une id√©e de certaines options couramment utilis√©es. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La variation la plus simple serait peut-√™tre un neurone tang, rempla√ßant la fonction sigmo√Øde par une tangente hyperbolique. </font><font style="vertical-align: inherit;">La sortie d'un neurone tang avec l'entr√©e x, un vecteur de poids w et un d√©calage b est sp√©cifi√© comme</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-239"><span class="MJXp-mtable" id="MJXp-Span-240"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-241" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-242" style="text-align: center;"><span class="MJXp-mi" id="MJXp-Span-243"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tanh </font></font></span><font style="vertical-align: inherit;"><span class="MJXp-mo" id="MJXp-Span-245" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">( </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-246"><font style="vertical-align: inherit;">w </font></span><span class="MJXp-mo" id="MJXp-Span-247" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;">‚ãÖ </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-248"><font style="vertical-align: inherit;">x </font></span><span class="MJXp-mo" id="MJXp-Span-249" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;">+ </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-250"><font style="vertical-align: inherit;">b </font></span><span class="MJXp-mo" id="MJXp-Span-251" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">)</font></span></font><span class="MJXp-mo" id="MJXp-Span-244" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-245" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-246"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-247" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-248"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-249" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-250"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-251" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-10"> \tanh(w \cdot x+b) \tag{109} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o√π tanh est naturellement </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tangent hyperbolique</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Il s'av√®re qu'il est tr√®s √©troitement li√© au neurone sigmo√Øde. </font><font style="vertical-align: inherit;">Pour voir cela, rappelez-vous que tanh est d√©fini comme</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-252"><span class="MJXp-mtable" id="MJXp-Span-253"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-254" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-255" style="text-align: center;"><span class="MJXp-mi" id="MJXp-Span-256"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tanh </font></font></span><font style="vertical-align: inherit;"><span class="MJXp-mo" id="MJXp-Span-258" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">( </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-259"><font style="vertical-align: inherit;">z </font></span><span class="MJXp-mo" id="MJXp-Span-260" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">) </font></span><span class="MJXp-mo" id="MJXp-Span-261" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;">‚â° </font></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-263"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-264" style="margin-right: 0.05em;"><font style="vertical-align: inherit;">e </font></span></span></span></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-263"><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-265" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;">z</font></span></span></span></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mo" id="MJXp-Span-266" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"> - </font></span></span></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-267"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-268" style="margin-right: 0.05em;"><font style="vertical-align: inherit;">e </font></span></span></span></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-267"><span class="MJXp-mrow MJXp-script" id="MJXp-Span-269" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-270"><font style="vertical-align: inherit;">- </font></span></span></span></span></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-267"><span class="MJXp-mrow MJXp-script" id="MJXp-Span-269" style="vertical-align: 0.5em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-271"><font style="vertical-align: inherit;">z</font></span></span></span></span></span></font><span class="MJXp-mo" id="MJXp-Span-257" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-258" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-259"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-260" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-261" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mfrac" id="MJXp-Span-262" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-263"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-264" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-265" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-mo" id="MJXp-Span-266" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-msubsup" id="MJXp-Span-267"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-268" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-269" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-270"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-271"><font style="vertical-align: inherit;"></font></span></span></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-msubsup" id="MJXp-Span-272"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-273" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-274" style="vertical-align: 0.5em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">z</font></font></span></span><span class="MJXp-mo" id="MJXp-Span-275" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> + </font></font></span><span class="MJXp-msubsup" id="MJXp-Span-276"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-277" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e </font></font></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-278" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-279"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-280"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">z</font></font></span></span></span></span></span></span></span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-11-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-11"> \tanh(z) \equiv \frac{e^z-e^{-z}}{e^z+e^{-z}} \tag{110} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> En utilisant une petite alg√®bre, il est facile de voir que </font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-281"><span class="MJXp-mtable" id="MJXp-Span-282"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-283" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-284" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-285"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">œÉ </font></font></span><span class="MJXp-mo" id="MJXp-Span-286" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-287"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">z </font></font></span><span class="MJXp-mo" id="MJXp-Span-288" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) </font></font></span><span class="MJXp-mo" id="MJXp-Span-289" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">= </font></font></span><span class="MJXp-mfrac" id="MJXp-Span-290" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-291"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 </font></font></span><span class="MJXp-mo" id="MJXp-Span-292" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mi" id="MJXp-Span-293"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tanh </font></font></span><font style="vertical-align: inherit;"><span class="MJXp-mo" id="MJXp-Span-295" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">( </font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-296"><font style="vertical-align: inherit;">z </font></span><span class="MJXp-mrow" id="MJXp-Span-297"><span class="MJXp-mo" id="MJXp-Span-298" style="margin-left: 0.111em; margin-right: 0.111em;"><font style="vertical-align: inherit;">/</font></span></span><span class="MJXp-mn" id="MJXp-Span-299"><font style="vertical-align: inherit;"> 2 </font></span><span class="MJXp-mo" id="MJXp-Span-300" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;">)</font></span></font><span class="MJXp-mo" id="MJXp-Span-294" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-295" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-296"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mrow" id="MJXp-Span-297"><span class="MJXp-mo" id="MJXp-Span-298" style="margin-left: 0.111em; margin-right: 0.111em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-mn" id="MJXp-Span-299"><font style="vertical-align: inherit;"></font></span><span class="MJXp-mo" id="MJXp-Span-300" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"></font></span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mn" id="MJXp-Span-301"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></span></span></span></span></span></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-12"> \sigma(z) = \frac{1+\tanh(z/2)}{2} \tag{111} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">c'est-√†-dire que tanh met √† l'√©chelle le sigmo√Øde. </font><font style="vertical-align: inherit;">Graphiquement, vous pouvez √©galement voir que la fonction tanh a la m√™me forme que le sigmo√Øde: </font></font><br><br><img src="https://habrastorage.org/webt/2d/al/jw/2daljwgmoaw7v8g4bz7jkiy8fwo.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">une diff√©rence entre les neurones tang et les neurones sigmo√Ødes est que la sortie du premier s'√©tend de -1 √† 1, et non de 0 √† 1. Cela signifie que lors de la cr√©ation d'un r√©seau bas√© sur des neurones tang, vous devrez peut-√™tre normaliser vos sorties (et, selon les d√©tails de l'application, peut-√™tre les entr√©es) un peu diff√©remment que dans les r√©seaux sigmo√Ødes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comme les sigmo√Ødes, les neurones tang peuvent, en principe, calculer n'importe quelle fonction (bien qu'il y ait quelques astuces), marquant les entr√©es de -1 √† 1. De plus, les id√©es de propagation arri√®re et de descente de gradient stochastique sont tout aussi faciles √† appliquer √† tang -neurons, ainsi que sigmo√Øde.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Exercice </font></font></h3><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> D√©montrer l'√©quation (111). </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quel type de neurone doit √™tre utilis√© dans les r√©seaux, tang ou sigmo√Øde? La r√©ponse, pour ne pas dire plus, n'est pas √©vidente! Cependant, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">il existe des </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arguments th√©oriques</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et certaines preuves empiriques que les neurones tang fonctionnent parfois mieux. Passons bri√®vement en revue l'un des arguments th√©oriques en faveur des neurones tang. Supposons que nous utilisons des neurones sigmo√Ødes et que toutes les activations sur le r√©seau soient positives. Consid√©rons les poids w </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">jk</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> inclus pour le neurone n ¬∞ j dans la couche n ¬∞ l + 1. Les r√®gles de r√©tropropagation (BP4) nous indiquent que le gradient qui lui est associ√© sera √©gal √† a </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">k</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Œ¥ </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Les activations √©tant positives, le signe de ce gradient sera le m√™me que celui de Œ¥ </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Cela signifie que si Œ¥ </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j est</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> positif, alors tous les poids w </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">jk</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> diminueront pendant la descente du gradient, et si Œ¥ </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">j est</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> n√©gatif, alors tous les poids w </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">l + 1 </font></font></sup> <sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">jk</font></font></sub><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">augmentera pendant la descente du gradient. En d'autres termes, tous les poids associ√©s au m√™me neurone augmenteront ou diminueront ensemble. Et c'est un probl√®me, car vous devrez peut-√™tre augmenter certains poids tout en en r√©duisant d'autres. Mais cela ne peut se produire que si certaines activations d'entr√©e ont des signes diff√©rents. Cela sugg√®re la n√©cessit√© de remplacer le sigmo√Øde par une autre fonction d'activation, par exemple la tangente hyperbolique, qui permet aux activations d'√™tre √† la fois positives et n√©gatives. En effet, puisque tanh est sym√©trique par rapport √† z√©ro, tanh (‚àíz) = ‚àítanh (z), on peut s'attendre √† ce qu'en gros, les activations dans les couches cach√©es soient √©galement r√©parties entre positif et n√©gatif. Cela contribuera √† garantir qu'il n'y a pas de biais syst√©matique dans les mises √† jour des √©chelles dans un sens ou dans l'autre.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans quelle mesure cet argument doit-il √™tre pris au s√©rieux? Apr√®s tout, il est heuristique, ne fournit pas de preuve stricte que les neurones tang sont sup√©rieurs aux neurones sigmo√Ødes. Peut-√™tre que les neurones sigmo√Ødes ont des propri√©t√©s qui compensent ce probl√®me? En effet, dans de nombreux cas, la fonction tanh a montr√© des avantages minimes √† nuls par rapport √† la sigmo√Øde. Malheureusement, nous n'avons pas de m√©thodes simples et rapidement mises en ≈ìuvre pour v√©rifier quel type de neurone apprendra plus rapidement ou se r√©v√©lera plus efficace pour g√©n√©raliser pour un cas particulier. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une autre variante d'un neurone sigmo√Øde est un neurone lin√©aire rectifi√©, ou unit√© lin√©aire rectifi√©e, ReLU. La sortie ReLU avec l'entr√©e x, le vecteur des poids w et le d√©calage b est sp√©cifi√© comme suit:</font></font><br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-307"><span class="MJXp-mtable" id="MJXp-Span-308"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-309" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-310" style="text-align: center;"><span class="MJXp-mo" id="MJXp-Span-311" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">max </font></font></span><span class="MJXp-mo" id="MJXp-Span-312" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font></span><span class="MJXp-mn" id="MJXp-Span-313"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0 </font></font></span><span class="MJXp-mo" id="MJXp-Span-314" style="margin-left: 0em; margin-right: 0.222em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-315"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w </font></font></span><span class="MJXp-mo" id="MJXp-Span-316" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ãÖ </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-317"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x </font></font></span><span class="MJXp-mo" id="MJXp-Span-318" style="margin-left: 0.267em; margin-right: 0.267em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">+ </font></font></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-319"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">b </font></font></span><span class="MJXp-mo" id="MJXp-Span-320" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">)</font></font></span></span></span></span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-13-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-13"> \max(0, w \cdot x+b) \tag{112} </script></p><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La fonction de redressement graphique max (0, z) ressemble √† ceci: </font></font><br><br><img src="https://habrastorage.org/webt/tu/1x/uv/tu1xuvrfyle3eismzxadvwjzjqq.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De tels neurones, √©videmment, sont tr√®s diff√©rents des neurones sigmo√Ødes et tang. </font><font style="vertical-align: inherit;">Cependant, ils sont similaires en ce sens qu'ils peuvent √©galement √™tre utilis√©s pour calculer n'importe quelle fonction, et ils peuvent √™tre entra√Æn√©s √† l'aide de la propagation arri√®re et de la descente de gradient stochastique. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quand devrais-je utiliser ReLU au lieu des neurones sigmo√Ødes ou tang? </font><font style="vertical-align: inherit;">Dans des travaux r√©cents sur la reconnaissance d'image ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) Les avantages s√©rieux de l'utilisation de ReLU ont √©t√© trouv√©s sur presque tout le r√©seau. Cependant, comme avec les neurones tang, nous n'avons pas encore une compr√©hension vraiment approfondie de quand exactement quelles ReLU seront pr√©f√©rables, et pourquoi. Pour avoir une id√©e de certains probl√®mes, rappelez-vous que les neurones sigmo√Ødes cessent d'apprendre lorsqu'ils sont satur√©s, c'est-√†-dire lorsque la sortie est proche de 0 ou 1. Comme nous l'avons vu √† plusieurs reprises dans ce chapitre, le probl√®me est que les membres œÉ 'r√©duisent le gradient qui ralentit l'apprentissage. Les neurones Tang souffrent de difficult√©s similaires de saturation. Dans le m√™me temps, une augmentation de l'entr√©e pond√©r√©e sur ReLU ne la rendra jamais satur√©e, par cons√©quent, aucun ralentissement correspondant de la formation ne se produira. D'un autre c√¥t√©, lorsque l'entr√©e pond√©r√©e sur le ReLU est n√©gative, le gradient dispara√Æt et le neurone cesse d'apprendre du tout.Ce ne sont l√† que quelques-uns des nombreux probl√®mes qui rendent difficile de comprendre quand et comment les ReLU se comportent mieux que les neurones sigmo√Ødes ou tang.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">J'ai bross√© un tableau de l'incertitude, en soulignant que nous n'avons pas encore une solide th√©orie du choix des fonctions d'activation. En effet, ce probl√®me est encore plus compliqu√© que je l'ai d√©crit, car il existe une infinit√© de fonctions d'activation possibles. Lequel nous donnera le r√©seau le plus rapide √† apprendre? Lequel donnera la plus grande pr√©cision dans les tests? Je suis surpris du peu d'√©tudes vraiment approfondies et syst√©matiques sur ces questions. Id√©alement, nous devrions avoir une th√©orie qui nous explique en d√©tail comment choisir (et √©ventuellement changer √† la vol√©e) nos fonctions d'activation. D'un autre c√¥t√©, il ne faut pas se laisser arr√™ter par l'absence d'une th√©orie compl√®te! Nous avons d√©j√† des outils puissants, et avec leur aide, nous pouvons r√©aliser des progr√®s significatifs. Jusqu'√† la fin du livre, j'utiliserai les neurones sigmo√Ødes comme principaux,car ils fonctionnent bien et donnent des illustrations concr√®tes des id√©es cl√©s li√©es √† l'Assembl√©e nationale. Mais gardez √† l'esprit que les m√™mes id√©es peuvent √™tre appliqu√©es √† d'autres neurones, et ces options ont leurs avantages.</font></font><br><br><h3>     </h3><br><blockquote> :          ,      ,   ?         ? <br><br> :   ,      .          ,     .    .      :         ,     ,     ? <br><br> ‚Äî         </blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lors d‚Äôune conf√©rence sur les bases de la m√©canique quantique, j‚Äôai remarqu√© quelque chose qui semblait une dr√¥le d‚Äôhabitude de discours: √† la fin du rapport, les questions du public commen√ßaient souvent par la phrase: ¬´J'aime vraiment votre point de vue, mais ...¬ª Les fondamentaux quantiques ne sont pas tout √† fait mon domaine habituel, et j'ai attir√© l'attention sur ce style de poser des questions parce que lors d'autres conf√©rences scientifiques, je ne me suis pratiquement pas r√©uni pour que le questionneur montre de la sympathie pour le point de vue de l'orateur. √Ä ce moment-l√†, j'ai d√©cid√© que la pr√©valence de telles questions indiquait que les progr√®s dans les fondamentaux quantiques avaient √©t√© r√©alis√©s un peu, et que les gens commen√ßaient tout juste √† prendre de l'√©lan. Plus tard, j'ai r√©alis√© que cette √©valuation √©tait trop s√©v√®re. Les orateurs ont lutt√© avec certains des probl√®mes les plus difficiles que les esprits humains aient jamais rencontr√©s. Naturellement, les progr√®s ont √©t√© lents!Cependant, il √©tait toujours utile d'entendre des nouvelles de la pens√©e des gens sur ce domaine, m√™me s'ils n'avaient rien ou presque.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans ce livre, vous avez peut-√™tre remarqu√© une ¬´tique nerveuse¬ª semblable √† la phrase ¬´Je suis tr√®s impressionn√©¬ª. Pour expliquer ce que nous avons, j'ai souvent eu recours √† des mots comme ¬´heuristiquement¬ª ou ¬´√† peu pr√®s¬ª, suivis d'une explication d'un ph√©nom√®ne particulier. Ces histoires sont cr√©dibles, mais les preuves empiriques √©taient souvent assez superficielles. Si vous √©tudiez la litt√©rature de recherche, vous verrez que des histoires de ce genre apparaissent dans de nombreux articles de recherche sur les r√©seaux de neurones, souvent en compagnie d'une petite quantit√© de preuves √† l'appui. Comment nous relions-nous √† ces histoires?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans de nombreux domaines scientifiques - en particulier lorsque des ph√©nom√®nes simples sont consid√©r√©s - on peut trouver des preuves tr√®s strictes et fiables d'hypoth√®ses tr√®s g√©n√©rales. Mais √† l'Assembl√©e nationale, il existe un grand nombre de param√®tres et d'hyperparam√®tres, et il existe des relations extr√™mement complexes entre eux. Dans de tels syst√®mes incroyablement complexes, il est extr√™mement difficile de faire des d√©clarations g√©n√©rales fiables. La compr√©hension de la NS dans toute sa pl√©nitude, comme les fondements quantiques, teste les limites de l'esprit humain. Souvent, nous devons nous passer de preuves en faveur ou contre plusieurs cas particuliers sp√©cifiques d'une d√©claration g√©n√©rale. En cons√©quence, ces d√©clarations doivent parfois √™tre modifi√©es ou abandonn√©es, √† mesure que de nouvelles preuves √©mergent.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'une des approches de cette situation consiste √† consid√©rer que toute histoire heuristique sur la NS implique un certain d√©fi. Par exemple, consid√©rez l'explication que j'ai cit√©e pour expliquer pourquoi une exception (abandon) du </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">travail en 2012 fonctionne.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">: ¬´Cette technique r√©duit l'adaptation articulaire complexe des neurones, car un neurone ne peut pas compter sur la pr√©sence de certains voisins. En fin de compte, il doit apprendre des traits plus fiables qui peuvent √™tre utiles pour travailler avec de nombreux sous-ensembles al√©atoires diff√©rents de neurones. ¬ª Une d√©claration riche et provocante, sur la base de laquelle vous pouvez construire tout un programme de recherche, dans lequel vous devrez d√©couvrir ce qui est vrai, o√π c'est faux, et ce qui doit √™tre clarifi√© et chang√©. Et maintenant, il y a vraiment toute une industrie de chercheurs qui √©tudient l'exception (et ses nombreuses variantes), essayant de comprendre comment cela fonctionne et quelles sont ses limites. C'est donc avec de nombreuses autres approches heuristiques que nous avons discut√©. Chacun d'eux n'est pas seulement une explication potentielle,mais aussi un d√©fi pour la recherche et une compr√©hension plus approfondie.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bien s√ªr, pas une seule personne n'aura assez de temps pour enqu√™ter suffisamment en profondeur sur toutes ces explications heuristiques. Il faudra des d√©cennies √† l'ensemble de la communaut√© des chercheurs de la Nouvelle-√âcosse pour √©laborer une th√©orie de la formation de la Nouvelle-√âcosse vraiment puissante fond√©e sur des preuves. Est-ce √† dire qu'il vaut la peine de rejeter les explications heuristiques comme laxistes et manquant de preuves?</font></font> Non!<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons besoin d'une heuristique qui inspirera notre r√©flexion. Cela ressemble √† l'√®re des grandes d√©couvertes g√©ographiques: les premiers √©rudits ont souvent agi (et fait des d√©couvertes) sur la base de croyances qui se sont tromp√©es de mani√®re s√©rieuse. Plus tard, nous avons corrig√© ces erreurs, reconstituant nos connaissances g√©ographiques. Lorsque vous comprenez mal quelque chose - comme les chercheurs ont compris la g√©ographie et comme nous comprenons la NS aujourd'hui - il est plus important d'√©tudier hardiment l'inconnu que d'avoir scrupuleusement raison √† chaque √©tape de votre raisonnement. Par cons√©quent, vous devriez consid√©rer ces histoires comme des instructions utiles sur la fa√ßon de r√©fl√©chir sur les SN, en maintenant une bonne conscience de leurs limites et en surveillant attentivement la fiabilit√© des preuves dans chaque cas. En d'autres termes, nous avons besoin de bonnes histoires pour la motivation et l'inspiration, et des enqu√™tes approfondies scrupuleuses - afin depour d√©couvrir des faits r√©els.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr460711/">https://habr.com/ru/post/fr460711/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr460699/index.html">Habr Weekly # 10 / Super services et passeport √©lectronique, smartphones et russes, ¬´gadgets espions¬ª, la vie sans satellites</a></li>
<li><a href="../fr460701/index.html">Cours "Start in Data Science": la premi√®re √©tape de l'utilisation des donn√©es</a></li>
<li><a href="../fr460703/index.html">Blue Ocean of Opportunity: de z√©ro √† 400 mille interviews vid√©o</a></li>
<li><a href="../fr460707/index.html">Est-il temps pour les d√©veloppeurs de jeux de cesser d'√©couter leurs fans?</a></li>
<li><a href="../fr460709/index.html">R√©flexions sur Agile</a></li>
<li><a href="../fr460713/index.html">D√©veloppement d'applications sur SwiftUI. Partie 1: flux de donn√©es et Redux</a></li>
<li><a href="../fr460717/index.html">Nouvelles hebdomadaires: tests du r√©seau satellite OneWeb, interfaces neuronales Ilona Mask et appareils √©lectroniques non espions</a></li>
<li><a href="../fr460719/index.html">Classes de base de l'industrie. Br√®ve introduction</a></li>
<li><a href="../fr460723/index.html">NVIDIA Jetson Nano: tests et premi√®res impressions</a></li>
<li><a href="../fr460725/index.html">Le code d'auto-documentation est (g√©n√©ralement) un non-sens</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèæ‚Äçü§ù‚Äçüë®üèº ‚ò¶Ô∏è üë©üèø‚Äçüç≥ CUDA et GPU √† distance ü¶î ü§¶üèª üòÅ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="CUDA est bon pour tout le monde, tant qu'il y a une carte vid√©o de Nvidia √† port√©e de main. Mais que faire lorsqu'il n'y a pas de carte graphique Nvid...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>CUDA et GPU √† distance</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/416127/"><p>  CUDA est bon pour tout le monde, tant qu'il y a une carte vid√©o de Nvidia √† port√©e de main.  Mais que faire lorsqu'il n'y a pas de carte graphique Nvidia sur votre ordinateur portable pr√©f√©r√©?  Ou avez-vous besoin de r√©aliser le d√©veloppement dans une machine virtuelle? </p><br><p>  J'essaierai d'envisager dans cet article une solution telle que le framework rCUDA (Remote CUDA), qui aidera lorsqu'il y a une carte graphique Nvidia, mais elle n'est pas install√©e sur la machine sur laquelle les applications CUDA sont cens√©es √™tre lanc√©es.  Pour ceux qui sont int√©ress√©s, bienvenue au chat. </p><br><div class="spoiler">  <b class="spoiler_title">TLDR</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rCUDA</a> (Remote CUDA) - un cadre qui impl√©mente l'API CUDA, vous permettant d'utiliser une carte vid√©o √† distance.  Il est dans une version b√™ta fonctionnelle, disponible uniquement sous Linux.  L'objectif principal de rCUDA est une compatibilit√© totale avec l'API CUDA, vous n'avez pas besoin de modifier votre code en aucune fa√ßon, il suffit de d√©finir des variables d'environnement sp√©ciales. </p></div></div><a name="habracut"></a><br><h2 id="chto-takoe-rcuda">  Qu'est-ce que rCUDA </h2><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rCUDA</a> (Remote CUDA) est un framework qui impl√©mente l'API CUDA, vous permettant d'utiliser une carte vid√©o situ√©e sur la machine distante pour l'informatique CUDA sans apporter de modifications √† votre code.  D√©velopp√© √† l'Universit√© Polytechnique de Valence ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©quipe rcuda</a> ). </p><br><h2 id="ogranicheniya">  Limitations </h2><br><p>  Seuls les syst√®mes GNU / Linux sont actuellement pris en charge, cependant, les d√©veloppeurs promettent la prise en charge de Windows √† l'avenir.  La version actuelle de rCUDA, 18.03beta, est compatible avec CUDA 5-8, c'est-√†-dire que CUDA 9 n'est pas pris en charge.  Les d√©veloppeurs ont d√©clar√© une compatibilit√© totale avec l'API CUDA, √† l'exception des graphiques. </p><br><h2 id="vozmozhnye-scenarii-ispolzovaniya">  Cas d'utilisation possibles </h2><br><ol><li>  L'ex√©cution d'applications CUDA dans une machine virtuelle lors du transfert d'une carte vid√©o est g√™nante ou impossible, par exemple, lorsque la carte vid√©o est occup√©e par un h√¥te ou lorsqu'il existe plusieurs machines virtuelles. </li><li>  Ordinateur portable sans carte graphique discr√®te. </li><li>  Le d√©sir d'utiliser plusieurs cartes vid√©o (clustering).  Th√©oriquement, vous pouvez utiliser toutes les cartes vid√©o disponibles dans l'√©quipe, y compris conjointement. </li></ol><br><h2 id="kratkaya-instrukciya">  Br√®ve instruction </h2><br><h4 id="testovaya-konfiguraciya">  Configuration de test </h4><br><p>  Des tests ont √©t√© effectu√©s sur la configuration suivante: </p><br><p>  <strong>Serveur:</strong> <br>  Ubuntu 16.04, GeForce GTX 660 </p><br><p>  <strong>Client:</strong> <br>  Une machine virtuelle avec Ubuntu 16.04 sur un ordinateur portable sans carte graphique discr√®te. </p><br><h4 id="poluchenie-rcuda">  Obtenir rCUDA </h4><br><p>  L'√©tape la plus difficile.  Malheureusement, pour le moment, le seul moyen d'obtenir votre copie de ce cadre est de remplir le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">formulaire de demande</a> appropri√© sur le site officiel.  Cependant, les d√©veloppeurs promettent de r√©pondre dans un d√©lai de 1 √† 2 jours.  Dans mon cas, ils m'ont envoy√© une distribution le m√™me jour. </p><br><h4 id="ustanovka-cuda">  Installer CUDA </h4><br><p>  Vous devez d'abord installer CUDA Toolkit sur le serveur et le client (m√™me si le client n'a pas de carte vid√©o nvidia).  Pour ce faire, vous pouvez le t√©l√©charger sur le site officiel ou utiliser le r√©f√©rentiel.  L'essentiel est d'utiliser une version pas sup√©rieure √† 8. Dans cet exemple, le programme d'installation .run du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">site officiel est utilis√©</a> . </p><br><pre><code class="bash hljs">chmod +x cuda_8.0.61_375.26_linux.run ./cuda_8.0.61_375.26_linux.run</code> </pre> <br><p>  <strong>Important!</strong>  Sur le client, vous devez refuser d'installer le pilote nvidia.  Par d√©faut, la bo√Æte √† outils CUDA sera disponible dans / usr / local / cuda /.  Installez les √©chantillons CUDA, vous en aurez besoin. </p><br><h4 id="ustanovka-rcuda">  Installer rCUDA </h4><br><p>  Nous d√©compresserons l'archive re√ßue des d√©veloppeurs dans notre r√©pertoire personnel sur le serveur et sur le client. </p><br><pre> <code class="bash hljs">tar -xvf rCUDA*.tgz -C ~/ mv ~/rCUDA* ~/rCUDA</code> </pre> <br><p>  Vous devez effectuer ces actions √† la fois sur le serveur et sur le client. </p><br><h4 id="zapusk-demona-rcuda-na-servere">  D√©marrage du d√©mon rCUDA sur le serveur </h4><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> PATH=<span class="hljs-variable"><span class="hljs-variable">$PATH</span></span>/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> LD_LIBRARY_PATH=<span class="hljs-variable"><span class="hljs-variable">$LD_LIBRARY_PATH</span></span>:/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/lib64:/home/&lt;XXX&gt;/rCUDA/lib/cudnn <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/rCUDA/bin ./rCUDAd</code> </pre> <br><p>  Remplacez &lt;XXX&gt; par votre nom d'utilisateur.  Utilisez ./rCUDAd -iv si vous voulez voir la sortie d√©taill√©e. </p><br><h4 id="nastroyka-klienta">  Configuration du client </h4><br><p>  Ouvrons le terminal sur le client, dans lequel nous ex√©cuterons le code CUDA √† l'avenir.  C√¥t√© client, nous devons "remplacer" les biblioth√®ques CUDA standard par des biblioth√®ques rCUDA, pour lesquelles nous ajoutons les chemins d'acc√®s appropri√©s √† la variable d'environnement LD_LIBRARY_PATH.  Nous devons √©galement sp√©cifier le nombre de serveurs et leurs adresses (dans mon exemple, ce sera un). </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> PATH=<span class="hljs-variable"><span class="hljs-variable">$PATH</span></span>/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> LD_LIBRARY_PATH=/home/&lt;XXX&gt;/rCUDA/lib/:<span class="hljs-variable"><span class="hljs-variable">$LD_LIBRARY_PATH</span></span> <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> RCUDA_DEVICE_COUNT=1 <span class="hljs-comment"><span class="hljs-comment">#    (),     export RCUDA_DEVICE_0=&lt;IP  &gt;:0 #    </span></span></code> </pre> <br><h4 id="sborka-i-zapusk">  Assemblage et lancement </h4><br><p>  Essayons de construire et d'ex√©cuter quelques exemples. </p><br><p>  <strong>Exemple 1</strong> </p><br><p>  Commen√ßons par un exemple simple de deviceQuery qui affiche simplement les param√®tres CUDA pour un appareil compatible, c'est-√†-dire, dans notre cas, le GTX660 distant. </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> &lt;YYY&gt;/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery make EXTRA_NVCCFLAGS=--cudart=shared</code> </pre> <br><p>  <strong>Important!</strong>  Sans EXTRA_NVCCFLAGS = - cudart = shared, le miracle ne fonctionnera pas <br>  Remplacez &lt;YYY&gt; par le chemin que vous avez sp√©cifi√© pour les √©chantillons CUDA lors de l'installation de CUDA. </p><br><p>  Ex√©cutez l'exemple assembl√©: </p><br><pre> <code class="bash hljs">./deviceQuery</code> </pre> <br><p>  Si vous avez tout fait correctement, le r√©sultat sera quelque chose comme ceci: </p><br><div class="spoiler">  <b class="spoiler_title">R√©sultat</b> <div class="spoiler_text"><pre> <code class="bash hljs">./deviceQuery Starting... CUDA Device Query (Runtime API) version (CUDART static linking) Detected 1 CUDA Capable device(s) Device 0: <span class="hljs-string"><span class="hljs-string">"GeForce GTX 660"</span></span> CUDA Driver Version / Runtime Version 9.0 / 8.0 CUDA Capability Major/Minor version number: 3.0 Total amount of global memory: 1994 MBytes (2090991616 bytes) ( 5) Multiprocessors, (192) CUDA Cores/MP: 960 CUDA Cores GPU Max Clock rate: 1072 MHz (1.07 GHz) Memory Clock rate: 3004 Mhz Memory Bus Width: 192-bit L2 Cache Size: 393216 bytes Maximum Texture Dimension Size (x,y,z) 1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096) Maximum Layered 1D Texture Size, (num) layers 1D=(16384), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(16384, 16384), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 2048 Maximum number of threads per block: 1024 Max dimension size of a thread block (x,y,z): (1024, 1024, 64) Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535) Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and kernel execution: Yes with 1 copy engine(s) Run time <span class="hljs-built_in"><span class="hljs-built_in">limit</span></span> on kernels: Yes Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Alignment requirement <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> Surfaces: Yes Device has ECC support: Disabled Device supports Unified Addressing (UVA): Yes Device PCI Domain ID / Bus ID / location ID: 0 / 1 / 0 Compute Mode: &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt; deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 660 Result = PASS</code> </pre> </div></div><br><p>  La chose la plus importante que nous devrions voir: </p><br><blockquote>  Device0 = GeForce GTX 660 <br>  R√©sultat = PASS </blockquote><p>  Super!  Nous avons r√©ussi √† construire et ex√©cuter l'application CUDA sur une machine sans carte graphique discr√®te, en utilisant √† cet effet une carte vid√©o install√©e sur un serveur distant. </p><br><p>  <strong>Important!</strong>  Si la sortie de l'application commence par des lignes du formulaire: </p><br><pre> <code class="bash hljs">mlock error: Cannot allocate memory rCUDA warning: 1007.461 mlock error: Cannot allocate memory</code> </pre> <br><p>  cela signifie qu'il est n√©cessaire d'ajouter les lignes suivantes au fichier "/etc/security/limits.conf" sur le serveur et sur le client: </p><br><pre> <code class="bash hljs">* hard memlock unlimited * soft memlock unlimited</code> </pre> <br><p>  Ainsi, vous autoriserez tous les utilisateurs (*) m√©moire de blocage illimit√©e (illimit√©e) (memlock).  Il serait encore mieux de remplacer * par l'utilisateur souhait√©, et au lieu d'un nombre illimit√©, choisissez des droits moins lourds. </p><br><p>  <strong>Exemple 2</strong> </p><br><p>  Essayons maintenant quelque chose de plus int√©ressant.  Nous testerons l'impl√©mentation du produit scalaire des vecteurs en utilisant la m√©moire partag√©e et la synchronisation ("Technologie CUDA dans les exemples" Sanders J. Kendrot E. 5.3.1). </p><br><p>  Dans cet exemple, nous calculons le produit scalaire de deux vecteurs de dimension 33 * 1024, en comparant la r√©ponse avec le r√©sultat obtenu sur le CPU. </p><br><div class="spoiler">  <b class="spoiler_title">dotProd.cu</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdio.h&gt; #define imin(a,b) (a&lt;b?a:b) const int N = 33 * 1024; const int threadsPerBlock = 256; const int blocksPerGrid = imin(32, (N+threadsPerBlock-1) / threadsPerBlock); __global__ void dot(float* a, float* b, float* c) { __shared__ float cache[threadsPerBlock]; int tid = threadIdx.x + blockIdx.x * blockDim.x; int cacheIndex = threadIdx.x; float temp = 0; while (tid &lt; N){ temp += a[tid] * b[tid]; tid += blockDim.x * gridDim.x; } // set the cache values cache[cacheIndex] = temp; // synchronize threads in this block __syncthreads(); // for reductions, threadsPerBlock must be a power of 2 // because of the following code int i = blockDim.x/2; while (i != 0){ if (cacheIndex &lt; i) cache[cacheIndex] += cache[cacheIndex + i]; __syncthreads(); i /= 2; } if (cacheIndex == 0) c[blockIdx.x] = cache[0]; } int main (void) { float *a, *b, c, *partial_c; float *dev_a, *dev_b, *dev_partial_c; // allocate memory on the cpu side a = (float*)malloc(N*sizeof(float)); b = (float*)malloc(N*sizeof(float)); partial_c = (float*)malloc(blocksPerGrid*sizeof(float)); // allocate the memory on the gpu cudaMalloc((void**)&amp;dev_a, N*sizeof(float)); cudaMalloc((void**)&amp;dev_b, N*sizeof(float)); cudaMalloc((void**)&amp;dev_partial_c, blocksPerGrid*sizeof(float)); // fill in the host memory with data for(int i=0; i&lt;N; i++) { a[i] = i; b[i] = i*2; } // copy the arrays 'a' and 'b' to the gpu cudaMemcpy(dev_a, a, N*sizeof(float), cudaMemcpyHostToDevice); cudaMemcpy(dev_b, b, N*sizeof(float), cudaMemcpyHostToDevice); dot&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(dev_a, dev_b, dev_partial_c); // copy the array 'c' back from the gpu to the cpu cudaMemcpy(partial_c,dev_partial_c, blocksPerGrid*sizeof(float), cudaMemcpyDeviceToHost); // finish up on the cpu side c = 0; for(int i=0; i&lt;blocksPerGrid; i++) { c += partial_c[i]; } #define sum_squares(x) (x*(x+1)*(2*x+1)/6) printf("GPU - %.6g \nCPU - %.6g\n", c, 2*sum_squares((float)(N-1))); // free memory on the gpu side cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_partial_c); // free memory on the cpu side free(a); free(b); free(partial_c); }</span></span></span></span></code> </pre></div></div><br><p>  Construire et ex√©cuter: </p><br><pre> <code class="bash hljs">/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin/nvcc --cudart=shared dotProd.cu -o dotProd ./dotProd</code> </pre> <br><p>  Ce r√©sultat nous dit que tout va bien pour nous: </p><br><blockquote>  GPU - 2.57236e + 13 <br>  CPU - 2.57236e + 13 </blockquote><p>  <strong>Exemple 3</strong> </p><br><p>  Ex√©cutez un autre test CUDA-matrixMulCUBLAS standard (multiplication matricielle). </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> &lt; YYY&gt;/NVIDIA_CUDA-8.0_Samples/0_Simple/matrixMulCUBLAS make EXTRA_NVCCFLAGS=--cudart=shared ./matrixMulCUBLAS</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">R√©sultat</b> <div class="spoiler_text"><p>  [Matrix Multiply CUBLAS] - D√©marrage ... <br>  P√©riph√©rique GPU 0: "GeForce GTX 660" avec capacit√© de calcul 3.0 </p><br><p>  MatrixA (640,480), MatrixB (480,320), MatrixC (640,320) <br>  R√©sultat de calcul √† l'aide de CUBLAS ... termin√©. <br>  Performance = 436,24 GFlop / s, temps = 0,451 ms, taille = 196608000 Ops <br>  R√©sultat du calcul √† l'aide du processeur h√¥te ... termin√©. <br>  Comparaison de CUBLAS Matrix Multiply avec les r√©sultats du processeur: PASS </p><br><p>  REMARQUE: Les √©chantillons CUDA ne sont pas destin√©s √† des mesures de performances.  Les r√©sultats peuvent varier lorsque GPU Boost est activ√©. </p></div></div><br><p>  Int√©ressant pour nous: </p><br><blockquote>  Performance = 436,24 GFlop / s, <br>  Comparaison de CUBLAS Matrix Multiply avec les r√©sultats du processeur: PASS </blockquote><br><h4 id="bezopasnost">  La s√©curit√© </h4><br><p>  Je n'ai trouv√© aucune mention d'une m√©thode d'autorisation dans la documentation de rCUDA.  Je pense qu'en ce moment, la chose la plus simple qui puisse √™tre faite est d'ouvrir l'acc√®s au port souhait√© (8308) uniquement √† partir d'une adresse sp√©cifique. </p><br><p>  En utilisant iptables, cela ressemblera √† ceci: </p><br><pre> <code class="bash hljs">iptables -A INPUT -m state --state NEW -p tcp -s &lt; &gt; --dport 8308 -j ACCEPT</code> </pre> <br><p>  Pour le reste, je laisse le probl√®me de s√©curit√© au-del√† de la port√©e de cet article. </p><br><div class="spoiler">  <b class="spoiler_title">Sources et liens</b> <div class="spoiler_text"><p>  [1] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://www.rcuda.net/pub/rCUDA_guide.pdf</a> <br>  [2] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://www.rcuda.net/pub/rCUDA_QSG.pdf</a> <br>  [3] C. Rea√±o, F. Silla, G. Shainer et S. Schultz, ¬´Local and Remote GPUs Perform Similar with EDR 100G InfiniBand¬ª, dans les actes de l'International Middleware Conference, Vancouver, BC, Canada, d√©cembre 2015. <br>  [4] C. Rea√±o et F. Silla, ¬´A Performance Comparison of CUDA Remote GPU Virtualization Frameworks¬ª, dans les actes de la Conf√©rence internationale sur l'informatique en grappes, Chicago, IL, √âtats-Unis, septembre 2015. </p></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr416127/">https://habr.com/ru/post/fr416127/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr416115/index.html">10 petites erreurs de conception que nous faisons encore</a></li>
<li><a href="../fr416119/index.html">Vendredi post mercredi: top des packages NPM les plus ¬´essentiels¬ª</a></li>
<li><a href="../fr416121/index.html">Fujitsu Artificial Intelligence calcule la g√©om√©trie des mat√©riaux magn√©tiques</a></li>
<li><a href="../fr416123/index.html">Reconnaissance de marchandises sur des √©tag√®res √† l'aide de r√©seaux de neurones √† l'aide des technologies Keras et API de d√©tection d'objets Tensorflow</a></li>
<li><a href="../fr416125/index.html">Installation, configuration du syst√®me et contr√¥le des cam√©ras</a></li>
<li><a href="../fr416129/index.html">Comment l'IA apprend √† g√©n√©rer des images de chats</a></li>
<li><a href="../fr416131/index.html">Comment g√©rer la MP dans la F√©d√©ration de Russie et ne pas enfreindre la loi</a></li>
<li><a href="../fr416133/index.html">Centre de donn√©es √† l'√©tranger: Equinix LD8</a></li>
<li><a href="../fr416135/index.html">Application GUI inf√©rieure √† 1 ko</a></li>
<li><a href="../fr416137/index.html">Zabbix comme scanner de s√©curit√©</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
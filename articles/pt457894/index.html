<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèø‚Äçüéì ü§öüèª üåâ Trabalhar com um cluster Proxmox: instala√ß√£o, configura√ß√£o de rede, ZFS, resolvendo problemas comuns üìÉ üëÑ ü§õüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nos √∫ltimos anos, tenho trabalhado muito de perto com os clusters Proxmox: muitos clientes exigem sua pr√≥pria infraestrutura, onde podem desenvolver s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Trabalhar com um cluster Proxmox: instala√ß√£o, configura√ß√£o de rede, ZFS, resolvendo problemas comuns</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457894/">  Nos √∫ltimos anos, tenho trabalhado muito de perto com os clusters Proxmox: muitos clientes exigem sua pr√≥pria infraestrutura, onde podem desenvolver seu projeto.  √â por isso que posso falar sobre os erros e problemas mais comuns que voc√™ tamb√©m pode encontrar.  Al√©m disso, √© claro que iremos configurar um cluster de tr√™s n√≥s do zero. <br><img src="https://habrastorage.org/webt/jz/j-/lq/jzj-lqgwozo7rze1o8ij7bvzday.png"><br><a name="habracut"></a><br>  Um cluster Proxmox pode consistir em dois ou mais servidores.  O n√∫mero m√°ximo de n√≥s em um cluster √© de 32 partes.  Nosso pr√≥prio cluster consistir√° em tr√™s n√≥s em um multicast (no artigo tamb√©m descreverei como aumentar um cluster na exclusividade - isso √© importante se voc√™ basear sua infraestrutura de cluster no Hetzner ou OVH, por exemplo).  Em resumo, o multicast permite a transfer√™ncia de dados para v√°rios n√≥s simultaneamente.  Com um multicast, n√£o podemos pensar no n√∫mero de n√≥s no cluster (focando nas limita√ß√µes acima). <br><br>  O cluster em si √© constru√≠do em uma rede interna (√© importante que os endere√ßos IP estejam na mesma sub-rede), o mesmo Hetzner e OVH podem combinar n√≥s em diferentes datacenters usando a tecnologia Virtual Switch (Hetzner) e vRack (OVH) - sobre o Virtual Switch tamb√©m falaremos no artigo.  Se o seu provedor de hospedagem n√£o tiver tecnologias semelhantes em funcionamento, voc√™ poder√° usar o OVS (Open Virtual Switch), que √© suportado originalmente pelo Proxmox, ou usar uma VPN.  No entanto, nesse caso, eu recomendo usar o Unicast com um pequeno n√∫mero de n√≥s - geralmente surgem situa√ß√µes em que o cluster simplesmente ‚Äúdesmorona‚Äù com base nessa infraestrutura de rede e precisa ser restaurado.  Portanto, tento usar a OVH e a Hetzner em meu trabalho - vi menos incidentes desse tipo, mas antes de tudo, estudo o provedor de hospedagem que ser√° hospedado: ele possui tecnologia alternativa, quais solu√ß√µes oferece, suporta multicast e assim por diante? . <br><br><h3>  Instale o Proxmox </h3><br>  O Proxmox pode ser instalado de duas maneiras: instalador ISO e instala√ß√£o via shell.  N√≥s escolhemos o segundo m√©todo, ent√£o instale o Debian no servidor. <br><br>  Prosseguimos diretamente para a instala√ß√£o do Proxmox em cada servidor.  A instala√ß√£o √© extremamente simples e est√° descrita na documenta√ß√£o oficial aqui. <br><br>  Adicione o reposit√≥rio Proxmox e a chave deste reposit√≥rio: <br><br><pre><code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://download.proxmox.com/debian/pve stretch pve-no-subscription"</span></span> &gt; /etc/apt/sources.list.d/pve-install-repo.list wget http://download.proxmox.com/debian/proxmox-ve-release-5.x.gpg -O /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg chmod +r /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg <span class="hljs-comment"><span class="hljs-comment"># optional, if you have a changed default umask</span></span></code> </pre> <br>  Atualizando reposit√≥rios e o pr√≥prio sistema: <br><br><pre> <code class="bash hljs">apt update &amp;&amp; apt dist-upgrade</code> </pre> <br>  Ap√≥s uma atualiza√ß√£o bem-sucedida, instale os pacotes Proxmox necess√°rios: <br><br><pre> <code class="bash hljs">apt install proxmox-ve postfix open-iscsi</code> </pre> <br>  <b>Nota</b> : O Postfix e o grub ser√£o configurados durante a instala√ß√£o - um deles pode falhar.  Talvez isso seja causado pelo fato de o nome do host n√£o ser resolvido pelo nome.  Edite as entradas dos hosts e fa√ßa o apt-get update <br><br>  A partir de agora, podemos efetuar login na interface da web do Proxmox em https: // &lt;endere√ßo-endere√ßo-externo&gt;: 8006 (voc√™ encontrar√° um certificado n√£o confi√°vel durante a conex√£o). <br><br><img src="https://habrastorage.org/webt/e_/cg/mv/e_cgmvs9rrh3qwq0su222v2j0iw.png"><br>  Figura <b>1.</b> Interface da Web do n√≥ Proxmox <br><br><h3>  Instale o Nginx e vamos criptografar o certificado </h3><br>  N√£o gosto muito da situa√ß√£o com o certificado e o endere√ßo IP, ent√£o sugiro instalar o Nginx e configurar o certificado Let's Encrypt.  N√£o descreverei a instala√ß√£o do Nginx, deixarei apenas os arquivos importantes para o certificado Vamos criptografar funcionar: <br><br><div class="spoiler">  <b class="spoiler_title">/etc/nginx/snippets/letsencrypt.conf</b> <div class="spoiler_text"><pre> <code class="nginx hljs"><span class="hljs-attribute"><span class="hljs-attribute">location</span></span><span class="hljs-regexp"><span class="hljs-regexp"> ^~</span></span> /.well-known/acme-challenge/ { <span class="hljs-attribute"><span class="hljs-attribute">allow</span></span> all; <span class="hljs-attribute"><span class="hljs-attribute">root</span></span> /var/lib/letsencrypt/; <span class="hljs-attribute"><span class="hljs-attribute">default_type</span></span> <span class="hljs-string"><span class="hljs-string">"text/plain"</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">try_files</span></span> <span class="hljs-variable"><span class="hljs-variable">$uri</span></span> =<span class="hljs-number"><span class="hljs-number">404</span></span>; }</code> </pre><br><br></div></div><br>  Comando para emitir certificado SSL: <br><br><pre> <code class="bash hljs">certbot certonly --agree-tos --email sos@livelinux.info --webroot -w /var/lib/letsencrypt/ -d proxmox1.domain.name</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Configura√ß√£o do site no NGINX</b> <div class="spoiler_text"><pre> <code class="nginx hljs"><span class="hljs-attribute"><span class="hljs-attribute">upstream</span></span> proxmox1.domain.name { <span class="hljs-attribute"><span class="hljs-attribute">server</span></span> <span class="hljs-number"><span class="hljs-number">127.0.0.1:8006</span></span>; } <span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">listen</span></span> <span class="hljs-number"><span class="hljs-number">80</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">server_name</span></span> proxmox1.domain.name; <span class="hljs-attribute"><span class="hljs-attribute">include</span></span> snippets/letsencrypt.conf; <span class="hljs-attribute"><span class="hljs-attribute">return</span></span> <span class="hljs-number"><span class="hljs-number">301</span></span> https://<span class="hljs-variable"><span class="hljs-variable">$host</span></span><span class="hljs-variable"><span class="hljs-variable">$request_uri</span></span>; } <span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">listen</span></span> <span class="hljs-number"><span class="hljs-number">443</span></span> ssl; <span class="hljs-attribute"><span class="hljs-attribute">server_name</span></span> proxmox1.domain.name; <span class="hljs-attribute"><span class="hljs-attribute">access_log</span></span> /var/log/nginx/proxmox1.domain.name.access.log; <span class="hljs-attribute"><span class="hljs-attribute">error_log</span></span> /var/log/nginx/proxmox1.domain.name.<span class="hljs-literal"><span class="hljs-literal">error</span></span>.log; <span class="hljs-attribute"><span class="hljs-attribute">include</span></span> snippets/letsencrypt.conf; <span class="hljs-attribute"><span class="hljs-attribute">ssl_certificate</span></span> /etc/letsencrypt/live/proxmox1.domain.name/fullchain.pem; <span class="hljs-attribute"><span class="hljs-attribute">ssl_certificate_key</span></span> /etc/letsencrypt/live/proxmox1.domain.name/privkey.pem; <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> / { <span class="hljs-attribute"><span class="hljs-attribute">proxy_pass</span></span> https://proxmox1.domain.name; <span class="hljs-attribute"><span class="hljs-attribute">proxy_next_upstream</span></span> <span class="hljs-literal"><span class="hljs-literal">error</span></span> timeout invalid_header http_500 http_502 http_503 http_504; <span class="hljs-attribute"><span class="hljs-attribute">proxy_redirect</span></span> <span class="hljs-literal"><span class="hljs-literal">off</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_buffering</span></span> <span class="hljs-literal"><span class="hljs-literal">off</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_set_header</span></span> Host <span class="hljs-variable"><span class="hljs-variable">$host</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_set_header</span></span> X-Real-IP <span class="hljs-variable"><span class="hljs-variable">$remote_addr</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_set_header</span></span> X-Forwarded-For <span class="hljs-variable"><span class="hljs-variable">$proxy_add_x_forwarded_for</span></span>; }</code> </pre> <br></div></div><br>  Depois de instalar o certificado SSL, n√£o se esque√ßa de configur√°-lo para renova√ß√£o autom√°tica via cron: <br><br><pre> <code class="bash hljs">0 */12 * * * /usr/bin/certbot -a \! -d /run/systemd/system &amp;&amp; perl -e <span class="hljs-string"><span class="hljs-string">'sleep int(rand(3600))'</span></span> &amp;&amp; certbot -q renew --renew-hook <span class="hljs-string"><span class="hljs-string">"systemctl reload nginx"</span></span></code> </pre> <br>  √ìtimo!  Agora podemos acessar nosso dom√≠nio via HTTPS. <br><br>  <b>Nota</b> : para desativar a janela de informa√ß√µes da assinatura, execute este comando: <br><br><pre> <code class="bash hljs">sed -i.bak <span class="hljs-string"><span class="hljs-string">"s/data.status !== 'Active'/false/g"</span></span> /usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js &amp;&amp; systemctl restart pveproxy.service</code> </pre> <br>  <b>Configura√ß√µes de rede</b> <br><br>  Antes de conectar-se ao cluster, configure as interfaces de rede no hypervisor.  Vale ressaltar que a configura√ß√£o dos n√≥s restantes n√£o √© diferente, exceto endere√ßos IP e nomes de servidores, portanto, n√£o duplicarei suas configura√ß√µes. <br><br>  Criaremos uma ponte de rede para a rede interna para que nossas m√°quinas virtuais (na minha vers√£o haver√° um cont√™iner LXC por conveni√™ncia); primeiro, elas estejam conectadas √† rede interna do hipervisor e possam interagir umas com as outras.  Em segundo lugar, um pouco mais tarde, adicionaremos uma ponte para a rede externa para que as m√°quinas virtuais tenham seu pr√≥prio endere√ßo IP externo.  Consequentemente, os cont√™ineres estar√£o no momento atr√°s do NAT'om conosco. <br><br>  H√° duas maneiras de trabalhar com a configura√ß√£o de rede Proxmox: atrav√©s da interface da web ou atrav√©s do arquivo de configura√ß√£o / etc / network / interfaces.  Na primeira op√ß√£o, voc√™ precisar√° reiniciar o servidor (ou simplesmente renomear o arquivo interfaces.new para interfaces e reiniciar o servi√ßo de rede atrav√©s do systemd).  Se voc√™ est√° apenas come√ßando a configurar e ainda n√£o h√° m√°quinas virtuais ou cont√™ineres LXC, √© aconselh√°vel reiniciar o hipervisor ap√≥s as altera√ß√µes. <br><br>  Agora crie uma ponte de rede chamada vmbr1 na guia rede no painel da web Proxmox. <br><br><img src="https://habrastorage.org/webt/i3/6k/wp/i36kwpe0ky3khngufngwifulwcs.png"><br>  <b>Figura 2.</b> Interfaces de rede do n√≥ proxmox1 <br><br><img src="https://habrastorage.org/webt/ro/k6/tg/rok6tgyuqyvte_dswvl-0xgvbxe.png"><br>  <b>Figura 3.</b> Criando uma ponte de rede <br><br><img src="https://habrastorage.org/webt/kx/xu/kg/kxxukgzgym97cjezlvrczgtji8g.png"><br>  <b>Figura 4.</b> Configurando a configura√ß√£o de rede vmbr1 <br><br>  A configura√ß√£o √© extremamente simples - precisamos do vmbr1 para que as inst√¢ncias tenham acesso √† Internet. <br><br>  Agora reinicie nosso hypervisor e verifique se a interface foi criada: <br><br><img src="https://habrastorage.org/webt/cx/b9/ga/cxb9ga2zhwn0fefphugyihuj6fg.png"><br>  <b>Figura 5.</b> Interface de rede vmbr1 na sa√≠da de comando ip a <br><br>  Nota: Eu j√° tenho a interface ens19 - essa √© a interface com a rede interna, com base na qual um cluster ser√° criado. <br><br>  Repita essas etapas nos outros dois hipervisores e prossiga para a pr√≥xima etapa - preparando o cluster. <br><br>  Al√©m disso, um est√°gio importante agora √© permitir o encaminhamento de pacotes - sem ele, as inst√¢ncias n√£o ter√£o acesso √† rede externa.  Abra o arquivo sysctl.conf e altere o valor do par√¢metro net.ipv4.ip_forward para 1, ap√≥s o qual inserimos o seguinte comando: <br><br><pre> <code class="bash hljs">sysctl -p</code> </pre> <br>  Na sa√≠da, voc√™ deve ver a diretiva net.ipv4.ip_forward (se voc√™ n√£o a tiver alterado antes) <br><br>  <b>Configurando um cluster Proxmox</b> <br><br>  Agora vamos diretamente para o cluster.  Cada n√≥ deve resolver a si pr√≥prio e outros n√≥s na rede interna, para isso √© necess√°rio alterar os valores nos registros de hosts da seguinte forma (cada n√≥ deve ter um registro sobre os outros): <br><br><pre> <code class="bash hljs">172.30.0.15 proxmox1.livelinux.info proxmox1 172.30.0.16 proxmox2.livelinux.info proxmox2 172.30.0.17 proxmox3.livelinux.info proxmox3</code> </pre><br>  Tamb√©m √© necess√°rio adicionar as chaves p√∫blicas de cada n√≥ aos outros - isso √© necess√°rio para criar um cluster. <br><br>  Crie um cluster atrav√©s do painel da web: <br><br><img src="https://habrastorage.org/webt/vl/rm/rh/vlrmrhkpwn5dle9gcnomfueoega.png"><br>  <b>Figura 6.</b> Criando um cluster por meio da interface da web <br><br>  Depois de criar o cluster, precisamos obter informa√ß√µes sobre ele.  V√° para a mesma guia do cluster e clique no bot√£o "Join Information": <br><br><img src="https://habrastorage.org/webt/gj/ur/t2/gjurt2tqr_pgtlfsxv7l3hrz398.png"><br>  <b>Figura 7.</b> Informa√ß√µes sobre o cluster criado <br><br>  Essas informa√ß√µes s√£o √∫teis para n√≥s ao ingressar no segundo e terceiro n√≥s no cluster.  Estamos conectados ao segundo n√≥ e, na guia Cluster, clique no bot√£o "Join Cluster": <br><br><img src="https://habrastorage.org/webt/fo/8u/zh/fo8uzhx-lzxfyqkapqdqsfuoalq.png"><br>  <b>Figura 8.</b> Conectando a um cluster de n√≥s <br><br>  Vamos analisar os par√¢metros para conex√£o com mais detalhes: <br><br><ol><li>  <b>Endere√ßo Par: Endere√ßo</b> IP do primeiro servidor (√†quele ao qual estamos nos conectando) </li><li>  <b>Senha:</b> senha do primeiro servidor </li><li>  <b>Impress√£o digital:</b> obtemos esse valor das informa√ß√µes do cluster </li></ol><br><img src="https://habrastorage.org/webt/l4/zp/eo/l4zpeodynxiuqubl1fjc4b9iona.png"><br>  <b>Figura 9.</b> Estado do cluster ap√≥s conectar o segundo n√≥ <br><br>  O segundo n√≥ est√° conectado com sucesso!  No entanto, isso nem sempre acontece.  Se voc√™ seguir as etapas incorretamente ou surgirem problemas de rede, a associa√ß√£o ao cluster falhar√° e o pr√≥prio cluster ser√° "dividido".  A melhor solu√ß√£o √© desconectar o n√≥ do cluster, excluir todas as informa√ß√µes sobre o cluster, reiniciar o servidor e verificar as etapas anteriores.  Como desconectar com seguran√ßa um n√≥ de um cluster?  Primeiro, exclua-o do cluster no primeiro servidor: <br><br><pre> <code class="bash hljs">pvecm del proxmox2</code> </pre> <br>  Ap√≥s o qual o n√≥ ser√° desconectado do cluster.  Agora v√° para o n√≥ quebrado e desative os seguintes servi√ßos nele: <br><br><pre> <code class="bash hljs">systemctl stop pvestatd.service systemctl stop pvedaemon.service systemctl stop pve-cluster.service systemctl stop corosync systemctl stop pve-cluster</code> </pre><br>  O cluster Proxmox armazena informa√ß√µes sobre si no banco de dados sqlite, tamb√©m precisa ser limpo: <br><br><pre> <code class="bash hljs">sqlite3 /var/lib/pve-cluster/config.db delete from tree <span class="hljs-built_in"><span class="hljs-built_in">where</span></span> name = <span class="hljs-string"><span class="hljs-string">'corosync.conf'</span></span>; .quit</code> </pre><br>  Os dados sobre a casca s√£o exclu√≠dos com sucesso.  Exclua os arquivos restantes. Para isso, √© necess√°rio iniciar o sistema de arquivos em cluster no modo independente: <br><br><pre> <code class="bash hljs">pmxcfs -l rm /etc/pve/corosync.conf rm /etc/corosync/* rm /var/lib/corosync/* rm -rf /etc/pve/nodes/*</code> </pre><br>  Reiniciamos o servidor (isso n√£o √© necess√°rio, mas estamos seguros: todos os servi√ßos devem estar funcionando corretamente no final. Para n√£o perder nada, reiniciaremos).  Ap√≥s a ativa√ß√£o, obteremos um n√≥ vazio sem nenhuma informa√ß√£o sobre o cluster anterior e poderemos iniciar a conex√£o novamente. <br><br><h3>  Instale e configure o ZFS </h3><br>  O ZFS √© um sistema de arquivos que pode ser usado com o Proxmox.  Com ele, voc√™ pode replicar dados para outro hypervisor, migrar o cont√™iner da m√°quina virtual / LXC, acessar o cont√™iner LXC do sistema host e assim por diante.  A instala√ß√£o √© bem simples, vamos prosseguir com a an√°lise.  Tr√™s SSDs est√£o dispon√≠veis em meus servidores, que ser√£o combinados em uma matriz RAID. <br><br>  Adicione reposit√≥rios: <br><br><pre> <code class="bash hljs">nano /etc/apt/sources.list.d/stretch-backports.list deb http://deb.debian.org/debian stretch-backports main contrib deb-src http://deb.debian.org/debian stretch-backports main contrib nano /etc/apt/preferences.d/90_zfs Package: libnvpair1linux libuutil1linux libzfs2linux libzpool2linux spl-dkms zfs-dkms zfs-test zfsutils-linux zfsutils-linux-dev zfs-zed Pin: release n=stretch-backports Pin-Priority: 990</code> </pre><br>  Atualizando a lista de pacotes: <br><br><pre> <code class="bash hljs">apt update</code> </pre> <br>  Defina as depend√™ncias necess√°rias: <br><br><pre> <code class="bash hljs"> apt install --yes dpkg-dev linux-headers-$(uname -r) linux-image-amd64</code> </pre> <br>  Instale o pr√≥prio ZFS: <br><br><pre> <code class="bash hljs">apt-get install zfs-dkms zfsutils-linux</code> </pre> <br>  Se, no futuro, voc√™ receber um erro fusermount: dispositivo de fus√≠vel n√£o encontrado, tente primeiro 'modprobe fuse' e execute o seguinte comando: <br><br><pre> <code class="bash hljs">modprobe fuse</code> </pre> <br>  Agora vamos prosseguir diretamente para a instala√ß√£o.  Primeiro, precisamos formatar os SSDs e configur√°-los atrav√©s de parted: <br><br><div class="spoiler">  <b class="spoiler_title">Configurar / dev / sda</b> <div class="spoiler_text"><pre> <code class="bash hljs">parted /dev/sda (parted) <span class="hljs-built_in"><span class="hljs-built_in">print</span></span> Model: ATA SAMSUNG MZ7LM480 (scsi) Disk /dev/sda: 480GB Sector size (logical/physical): 512B/512B Partition Table: msdos Disk Flags: Number Start End Size Type File system Flags 1 1049kB 4296MB 4295MB primary raid 2 4296MB 4833MB 537MB primary raid 3 4833MB 37,0GB 32,2GB primary raid (parted) mkpart Partition <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>? primary/extended? primary File system <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>? [ext2]? zfs Start? 33GB End? 480GB Warning: You requested a partition from 33,0GB to 480GB (sectors 64453125..937500000). The closest location we can manage is 37,0GB to 480GB (sectors 72353792..937703087). Is this still acceptable to you? Yes/No? yes</code> </pre><br></div></div><br>  A√ß√µes semelhantes devem ser executadas para outras unidades.  Depois que todos os discos estiverem preparados, prossiga para a pr√≥xima etapa: <br><br>  zpool create -f -o ashift = 12 rpool / dev / sda4 / dev / sdb4 / dev / sdc4 <br><br>  Escolhemos ashift = 12 por raz√µes de desempenho - esta √© a recomenda√ß√£o do pr√≥prio zfsonlinux, voc√™ pode ler mais sobre isso em seu wiki: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github.com/zfsonlinux/zfs/wiki/faq#performance-considerations</a> <br><br>  Aplique algumas configura√ß√µes ao ZFS: <br><br><pre> <code class="bash hljs">zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> atime=off rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> compression=lz4 rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> dedup=off rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> snapdir=visible rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> primarycache=all rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> aclinherit=passthrough rpool zfs inherit acltype rpool zfs get -r acltype rpool zfs get all rpool | grep compressratio</code> </pre><br>  Agora precisamos calcular algumas vari√°veis ‚Äã‚Äãpara calcular zfs_arc_max, fa√ßo o seguinte: <br><br><pre> <code class="bash hljs">mem =`free --giga | grep Mem | awk <span class="hljs-string"><span class="hljs-string">'{print $2}'</span></span>` partofmem=$((<span class="hljs-variable"><span class="hljs-variable">$mem</span></span>/10)) <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">$setzfscache</span></span> &gt; /sys/module/zfs/parameters/zfs_arc_max grep c_max /proc/spl/kstat/zfs/arcstats zfs create rpool/data cat &gt; /etc/modprobe.d/zfs.conf &lt;&lt; EOL options zfs zfs_arc_max=<span class="hljs-variable"><span class="hljs-variable">$setzfscache</span></span> EOL <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">$setzfscache</span></span> &gt; /sys/module/zfs/parameters/zfs_arc_max grep c_max /proc/spl/kstat/zfs/arcstats</code> </pre> <br>  No momento, o pool foi criado com sucesso, tamb√©m criamos um subconjunto de dados.  Voc√™ pode verificar o status do seu pool com o comando zpool status.  Esta a√ß√£o deve ser executada em todos os hipervisores e, em seguida, prossiga para a pr√≥xima etapa. <br><br>  Agora adicione o ZFS ao Proxmox.  Vamos √†s configura√ß√µes do data center (a saber, e n√£o a um n√≥ separado) na se√ß√£o "Armazenamento", clique no bot√£o "Adicionar" e selecione a op√ß√£o "ZFS", ap√≥s o qual veremos os seguintes par√¢metros: <br><br>  ID: Nome dos cem.  Eu dei o nome de local-zfs <br>  Pool ZFS: criamos rpool / data e adicionamos aqui. <br>  N√≥s: especifique todos os n√≥s dispon√≠veis <br><br>  Este comando cria um novo pool com as unidades que selecionamos.  Em cada hypervisor, um novo armazenamento deve aparecer chamado local-zfs, ap√≥s o qual voc√™ pode migrar suas m√°quinas virtuais do armazenamento local para o ZFS. <br><br><h3>  Replicando inst√¢ncias para um hypervisor vizinho </h3><br>  O cluster Proxmox tem a capacidade de replicar dados de um hipervisor para outro: essa op√ß√£o permite alternar a inst√¢ncia de um servidor para outro.  Os dados ser√£o relevantes no momento da √∫ltima sincroniza√ß√£o - seu tempo pode ser definido ao criar a replica√ß√£o (15 minutos s√£o definidos como padr√£o).  H√° duas maneiras de migrar uma inst√¢ncia para outro n√≥ do Proxmox: manual e autom√°tico.  Vamos examinar a op√ß√£o manual primeiro e, no final, fornecerei um script Python que permitir√° criar uma m√°quina virtual em um hipervisor acess√≠vel quando um dos hipervisores estiver indispon√≠vel. <br><br>  Para criar replica√ß√£o, acesse o painel da web Proxmox e crie uma m√°quina virtual ou um cont√™iner LXC.  Nos par√°grafos anteriores, configuramos a ponte vmbr1 com o NAT, o que nos permitir√° acessar a rede externa.  Vou criar um cont√™iner LXC com MySQL, Nginx e PHP-FPM com um site de teste para testar a replica√ß√£o.  Abaixo est√° uma instru√ß√£o passo a passo. <br><br>  Carregamos o modelo apropriado (v√° para storage -&gt; Content -&gt; Templates), um exemplo na captura de tela: <br><br><img src="https://habrastorage.org/webt/sd/bd/57/sdbd579lmmzxefsigiivaftvpce.png"><br>  <b>Imagem 10.</b> Armazenamento local com modelos e imagens de VM <br><br>  Clique no bot√£o "Modelos" e carregue o modelo de cont√™iner LXC que precisamos: <br><br><img src="https://habrastorage.org/webt/qx/ug/he/qxughewqdsfniccmaamka9idie0.png"><br>  Figura <b>11.</b> Selecionando e carregando um modelo <br><br>  Agora podemos us√°-lo ao criar novos cont√™ineres LXC.  Selecione o primeiro hipervisor e clique no bot√£o "Criar CT" no canto superior direito: veremos o painel para criar uma nova inst√¢ncia.  As etapas de instala√ß√£o s√£o bastante simples e darei apenas o arquivo de configura√ß√£o para este cont√™iner LXC: <br><br><pre> <code class="bash hljs">arch: amd64 cores: 3 memory: 2048 nameserver: 8.8.8.8 net0: name=eth0,bridge=vmbr1,firewall=1,gw=172.16.0.1,hwaddr=D6:60:C5:39:98:A0,ip=172.16.0.2/24,<span class="hljs-built_in"><span class="hljs-built_in">type</span></span>=veth ostype: centos rootfs: <span class="hljs-built_in"><span class="hljs-built_in">local</span></span>:100/vm-100-disk-1.raw,size=10G swap: 512 unprivileged:</code> </pre><br>  O cont√™iner foi criado com sucesso.  Voc√™ pode conectar-se aos cont√™ineres LXC atrav√©s do comando pct enter. Tamb√©m adicionei a chave do hipervisor SSH antes da instala√ß√£o para conectar-se diretamente via SSH (existem alguns pequenos problemas com a exibi√ß√£o do terminal no PCT).  Eu preparei o servidor e instalei todos os aplicativos necess√°rios, agora voc√™ pode continuar criando a replica√ß√£o. <br><br>  Clicamos no cont√™iner LXC e vamos para a guia "Replica√ß√£o", onde criamos o par√¢metro de replica√ß√£o usando o bot√£o "Adicionar": <br><br><img src="https://habrastorage.org/webt/ub/ac/si/ubacsivqghyu5w9np8dlnjdqe3g.png"><br>  <b>Figura 12.</b> Criando replica√ß√£o na interface Proxmox <br><br><img src="https://habrastorage.org/webt/ea/mb/48/eamb489i0yqndxdcknvr2f1vefi.png"><br>  <b>Imagem 13.</b> Janela de cria√ß√£o de tarefas de replica√ß√£o <br><br>  Eu criei a tarefa de replicar o cont√™iner para o segundo n√≥, como voc√™ pode ver na pr√≥xima captura de tela, a replica√ß√£o foi bem-sucedida - preste aten√ß√£o ao campo "Status", ele notifica sobre o status da replica√ß√£o, tamb√©m vale a pena prestar aten√ß√£o ao campo "Dura√ß√£o" para saber quanto tempo a replica√ß√£o de dados leva. <br><br><img src="https://habrastorage.org/webt/wr/hd/t7/wrhdt7uk4szufdqrvboovxwr6t0.png"><br>  Figura <b>14.</b> Lista de sincroniza√ß√£o da VM <br><br>  Agora tente migrar a m√°quina para o segundo n√≥ usando o bot√£o "Migrar" <br><br>  A migra√ß√£o do cont√™iner ser√° iniciada, o log poder√° ser visualizado na lista de tarefas - haver√° nossa migra√ß√£o.  Depois disso, o cont√™iner ser√° movido para o segundo n√≥. <br><br>  <b>Erro "Falha na verifica√ß√£o da chave do host"</b> <br><br>  √Äs vezes, ao configurar um cluster, um problema semelhante pode surgir - impede que as m√°quinas migrem e criem replica√ß√£o, o que elimina as vantagens das solu√ß√µes de cluster.  Para corrigir esse erro, exclua o arquivo known_hosts e conecte-se via SSH ao n√≥ conflitante: <br><br><pre> <code class="bash hljs">/usr/bin/ssh -o <span class="hljs-string"><span class="hljs-string">'HostKeyAlias=proxmox2'</span></span> root@172.30.0.16</code> </pre><br>  Aceite o Hostkey e tente digitar este comando, ele deve conect√°-lo ao servidor: <br><br><pre> <code class="bash hljs">/usr/bin/ssh -o <span class="hljs-string"><span class="hljs-string">'BatchMode=yes'</span></span> -o <span class="hljs-string"><span class="hljs-string">'HostKeyAlias=proxmox2'</span></span> root@172.30.0.16</code> </pre><br><h3>  Recursos das configura√ß√µes de rede no Hetzner </h3><br>  V√° para o painel Robot e clique no bot√£o "Virtual Switches".  Na pr√≥xima p√°gina, voc√™ ver√° um painel para criar e gerenciar interfaces do Virtual Switch: primeiro voc√™ precisa cri√°-lo e depois "conectar" servidores dedicados a ele.  Na pesquisa, adicione os servidores necess√°rios para conectar-se - eles n√£o precisam ser reinicializados, apenas precisam esperar 10 a 15 minutos para que a conex√£o com o Virtual Switch esteja ativa. <br><br>  Depois de adicionar os servidores ao Virtual Switch por meio do painel da web, nos conectamos aos servidores e abrimos os arquivos de configura√ß√£o das interfaces de rede, onde criamos uma nova interface de rede: <br><br><pre> <code class="bash hljs">auto enp4s0.4000 iface enp4s0.4000 inet static address 10.1.0.11/24 mtu 1400 vlan-raw-device enp4s0</code> </pre> <br>  Vamos dar uma olhada mais de perto no que √©.  Na sua ess√™ncia, √© uma VLAN que se conecta a uma √∫nica interface f√≠sica chamada enp4s0 (pode variar para voc√™), com um n√∫mero de VLAN - esse √© o n√∫mero do Virtual Switch que voc√™ criou no painel da web do Hetzner Robot.  Voc√™ pode especificar qualquer endere√ßo, desde que seja local. <br><br>  Observo que voc√™ deve configurar o enp4s0 como de costume; na verdade, ele deve conter um endere√ßo IP externo que foi emitido para o servidor f√≠sico.  Repita essas etapas em outros hipervisores e, em seguida, reinicie o servi√ßo de rede neles, execute ping em um n√≥ vizinho usando o endere√ßo IP do Virtual Switch.  Se o ping foi bem-sucedido, voc√™ estabeleceu com √™xito uma conex√£o entre os servidores usando o Virtual Switch. <br><br>  Tamb√©m anexarei o arquivo de configura√ß√£o sysctl.conf, ser√° necess√°rio se voc√™ tiver problemas com o pacote de encaminhamento e outros par√¢metros de rede: <br><br><pre> <code class="bash hljs">net.ipv6.conf.all.disable_ipv6=0 net.ipv6.conf.default.disable_ipv6 = 0 net.ipv6.conf.all.forwarding=1 net.ipv4.conf.all.rp_filter=1 net.ipv4.tcp_syncookies=1 net.ipv4.ip_forward=1 net.ipv4.conf.all.send_redirects=0</code> </pre><br>  <b>Adicionando sub-redes IPv4 ao Hetzner</b> <br><br>  Antes de iniciar o trabalho, voc√™ precisa solicitar uma sub-rede no Hetzner, pode fazer isso atrav√©s do painel Rob√¥. <br><br>  Crie uma ponte de rede com o endere√ßo que ser√° desta sub-rede.  Exemplo de configura√ß√£o: <br><br><pre> <code class="bash hljs">auto vmbr2 iface vmbr2 inet static address ip-address netmask 29 bridge-ports none bridge-stp off bridge-fd 0</code> </pre> <br>  Agora v√° para as configura√ß√µes da m√°quina virtual no Proxmox e crie uma nova interface de rede que ser√° anexada √† ponte vmbr2.  Eu uso o cont√™iner LXC, sua configura√ß√£o pode ser alterada imediatamente no Proxmox.  Configura√ß√£o final para o Debian: <br><br><pre> <code class="bash hljs">auto eth0 iface eth0 inet static address ip-address netmask 26 gateway bridge-address</code> </pre> <br>  Observe: eu especifiquei 26 m√°scaras, n√£o 29 - isso √© necess√°rio para que a rede funcione na m√°quina virtual. <br><br>  <b>Adicionando endere√ßos IPv4 ao Hetzner</b> <br><br>  A situa√ß√£o com um √∫nico endere√ßo IP √© diferente - geralmente Hetzner nos fornece um endere√ßo adicional da sub-rede do servidor.  Isso significa que, em vez de vmbr2, precisamos usar vmbr0, mas no momento n√£o o temos.  A conclus√£o √© que vmbr0 deve conter o endere√ßo IP do servidor iron (ou seja, use o endere√ßo que usou a interface de rede f√≠sica enp2s0).  O endere√ßo deve ser movido para vmbr0, a seguinte configura√ß√£o √© adequada para isso (aconselho voc√™ a solicitar o KVM, nesse caso, para retomar a opera√ß√£o de rede): <br><br><pre> <code class="bash hljs">auto enp2s0 iface enp2s0 inet manual auto vmbr0 iface vmbr0 inet static address ip-address netmask 255.255.255.192 gateway ip-gateway bridge-ports enp2s0 bridge-stp off bridge-fd 0</code> </pre><br>  Reinicie o servidor, se poss√≠vel (caso contr√°rio, reinicie o servi√ßo de rede) e verifique as interfaces de rede via ip a: <br><br><pre> <code class="bash hljs">2: enp2s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master vmbr0 state UP group default qlen 1000 link/ether 44:8a:5b:2c:30:c2 brd ff:ff:ff:ff:ff:ff</code> </pre><br>  Como voc√™ pode ver aqui, o enp2s0 est√° conectado ao vmbr0 e n√£o possui um endere√ßo IP, pois foi redesignado ao vmbr0. <br><br>  Agora, nas configura√ß√µes da m√°quina virtual, adicione a interface de rede que ser√° conectada ao vmbr0.  Para o gateway, especifique o endere√ßo anexado ao vmbr0. <br><br><h3>  No final </h3><br>  Espero que este artigo seja √∫til quando voc√™ configurar o cluster Proxmox no Hetzner.  Se o tempo permitir, expandirei o artigo e adicionarei instru√ß√µes para a OVH - l√° tamb√©m nem tudo √© √≥bvio, como parece √† primeira vista.  O material acabou por ser bastante volumoso, se voc√™ encontrar erros, por favor escreva nos coment√°rios, eu os corrigirei.  Obrigado a todos pela aten√ß√£o. <br><br>  <i>Postado por Ilya Andreev, editado por Alexei Zhadan e Live Linux Team</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt457894/">https://habr.com/ru/post/pt457894/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt457876/index.html">Tradu√ß√£o: Padr√£o IEEE 802.15.4z. O que nos espera no futuro?</a></li>
<li><a href="../pt457884/index.html">Internet Soberana - esclarecendo ordens</a></li>
<li><a href="../pt457886/index.html">Autentica√ß√£o de dois fatores no site usando um token USB. Agora para Linux</a></li>
<li><a href="../pt457888/index.html">Teste de muta√ß√£o: testes de teste</a></li>
<li><a href="../pt457892/index.html">Professor de Roleta</a></li>
<li><a href="../pt457896/index.html">Zimbra e prote√ß√£o contra sobrecarga de servidor</a></li>
<li><a href="../pt457900/index.html">Comiss√£o Federal de Comunica√ß√µes dos EUA Contra Meteorologistas</a></li>
<li><a href="../pt457902/index.html">Mitap para ci√™ncia de dados</a></li>
<li><a href="../pt457904/index.html">R√°dio at√¥mica - a primeira transmiss√£o musical de todos os tempos</a></li>
<li><a href="../pt457906/index.html">Os m√©dicos acreditam que, em um futuro pr√≥ximo, os dispositivos de vacina√ß√£o aparecer√£o em resid√™ncias e farm√°cias</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
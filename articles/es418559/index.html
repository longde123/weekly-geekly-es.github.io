<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòí üßú üëãüèæ NL2API: Creaci√≥n de interfaces de lenguaje natural para la API web üë®üèª‚Äçüíº ü§Ø üòà</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola Habr! M√°s recientemente, hablamos brevemente sobre las interfaces de lenguaje natural. Bueno, hoy no tenemos brevemente. Debajo del corte, encont...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NL2API: Creaci√≥n de interfaces de lenguaje natural para la API web</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/microsoft/blog/418559/">  Hola Habr!  M√°s recientemente, hablamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">brevemente</a> sobre las interfaces de lenguaje natural.  Bueno, hoy no tenemos brevemente.  Debajo del corte, encontrar√° una historia completa sobre la creaci√≥n de NL2API para la API web.  Nuestros colegas de Research han intentado un enfoque √∫nico para recopilar datos de capacitaci√≥n para el marco.  √önete ahora! <br><br><img src="https://habrastorage.org/webt/ry/bd/kj/rybdkjnazdjarwxlrggugof4pja.jpeg"><a name="habracut"></a><br><br><h2>  Anotaci√≥n </h2><br>  A medida que Internet evoluciona hacia una arquitectura orientada a servicios, las interfaces de software (API) son cada vez m√°s importantes como una forma de proporcionar acceso a datos, servicios y dispositivos.  Estamos trabajando en el tema de crear una interfaz de lenguaje natural para la API (NL2API), centr√°ndonos en los servicios web.  Las soluciones NL2API tienen muchos beneficios potenciales, por ejemplo, ayudan a simplificar la integraci√≥n de servicios web en asistentes virtuales. <br><br>  Ofrecemos la primera plataforma integral (marco) que le permite crear NL2API para una API web espec√≠fica.  La tarea clave es recopilar datos para el entrenamiento, es decir, los pares "comando NL - llamada API", lo que permite a NL2API estudiar la sem√°ntica de ambos comandos NL que no tienen un formato estrictamente definido y llamadas API formalizadas.  Ofrecemos nuestro propio enfoque √∫nico para recopilar datos de capacitaci√≥n para NL2API utilizando crowdsourcing, atrayendo a muchos trabajadores remotos para generar varios equipos de NL.  Optimizamos el proceso de crowdsourcing para reducir costos. <br><br>  En particular, ofrecemos un modelo probabil√≠stico jer√°rquico fundamentalmente nuevo que nos ayudar√° a distribuir el presupuesto para el crowdsourcing, principalmente entre las llamadas API que son de alto valor para aprender NL2API.  Aplicamos nuestro marco a API reales y mostramos que le permite recopilar datos de capacitaci√≥n de alta calidad a un costo m√≠nimo, as√≠ como crear NL2API de alto rendimiento desde cero.  Tambi√©n demostramos que nuestro modelo de crowdsourcing mejora la eficiencia de este proceso, es decir, los datos de capacitaci√≥n recopilados dentro de su marco proporcionan un mayor rendimiento de NL2API, que supera significativamente la l√≠nea de base. <br><br><h2>  Introduccion </h2><br>  Las interfaces de programaci√≥n de aplicaciones (API) desempe√±an un papel cada vez m√°s importante tanto en el mundo virtual como en el f√≠sico, gracias al desarrollo de tecnolog√≠as como la arquitectura orientada a servicios (SOA), la computaci√≥n en la nube y el Internet de las cosas (IoT).  Por ejemplo, los servicios web alojados en la nube (clima, deportes, finanzas, etc.) a trav√©s de la API web proporcionan datos y servicios a los usuarios finales, y los dispositivos IoT permiten que otros dispositivos de red utilicen su funcionalidad. <br><br><img src="https://habrastorage.org/webt/tc/kd/fb/tckdfbxc1i4zg4km413wnducl_4.png"><br>  <i>Figura 1. Los pares "comando NL (izquierda) y llamada API (derecha)" ensamblados</i> <i><br></i>  <i>nuestro marco y comparaci√≥n con IFTTT.</i>  <i>GET-Messages y GET-Events son dos API web para encontrar correos electr√≥nicos y eventos de calendario, respectivamente.</i>  <i>Se puede llamar a API con varios par√°metros.</i>  <i>Nos centramos en llamadas API completamente parametrizadas, mientras que IFTTT se limita a API con par√°metros simples.</i> <br><br>  Por lo general, las API se utilizan en una variedad de software: aplicaciones de escritorio, sitios web y aplicaciones m√≥viles.  Tambi√©n sirven a los usuarios a trav√©s de una interfaz gr√°fica de usuario (GUI).  La GUI ha hecho una gran contribuci√≥n a la popularizaci√≥n de las computadoras, pero a medida que la tecnolog√≠a inform√°tica ha evolucionado, sus muchas limitaciones se manifiestan cada vez m√°s.  Por un lado, a medida que los dispositivos se vuelven m√°s peque√±os, m√°s m√≥viles e inteligentes, los requisitos para la visualizaci√≥n gr√°fica en la pantalla aumentan constantemente, por ejemplo, con respecto a los dispositivos port√°tiles o dispositivos conectados a IoT. <br><br>  Por otro lado, los usuarios tienen que adaptarse a varias GUI especializadas para diversos servicios y dispositivos.  A medida que aumenta el n√∫mero de servicios y dispositivos disponibles, tambi√©n aumenta el costo de la capacitaci√≥n y la adaptaci√≥n del usuario.  Las interfaces de lenguaje natural (NLI), como los asistentes virtuales Apple Siri y Microsoft Cortana, tambi√©n llamadas interfaces conversacionales o de di√°logo (CUI), demuestran un potencial significativo como una herramienta inteligente √∫nica para una amplia gama de servicios y dispositivos de servidor. <br><br>  En este art√≠culo, consideramos el problema de crear una interfaz de lenguaje natural para la API (NL2API).  Pero, a diferencia de los asistentes virtuales, estos no son NLI de prop√≥sito general, <br>  estamos desarrollando enfoques para crear NLI para API web espec√≠ficas, es decir, API de servicios web como el servicio multideporte ESPN1.  Tales NL2API pueden resolver el problema de escalabilidad de las NLI de prop√≥sito general al permitir el desarrollo distribuido.  La utilidad de un asistente virtual depende en gran medida de la amplitud de sus capacidades, es decir, de la cantidad de servicios que admite. <br><br>  Sin embargo, la integraci√≥n de servicios web en un asistente virtual de uno en uno es un trabajo incre√≠blemente laborioso.  Si los proveedores de servicios web individuales tuvieran una forma econ√≥mica de crear NLI para sus API, los costos de integraci√≥n se reducir√≠an significativamente.  Un asistente virtual no tendr√≠a que procesar diferentes interfaces para diferentes servicios web.  Ser√≠a suficiente para √©l simplemente integrar NL2API individuales, que logran uniformidad gracias al lenguaje natural.  Por otro lado, NL2API tambi√©n puede simplificar el descubrimiento de servicios web y sistemas de recomendaci√≥n y asistencia de programaci√≥n para API, eliminando la necesidad de recordar la gran cantidad de API web disponibles y su sintaxis. <br><br>  <b>Ejemplo 1.</b> En la Figura 1 se muestran dos ejemplos. Se puede llamar a la API con varios par√°metros.  En el caso de la API de b√∫squeda de correo electr√≥nico, los usuarios pueden filtrar el correo electr√≥nico por propiedades espec√≠ficas o buscar correos electr√≥nicos por palabras clave.  La tarea principal de NL2API es asignar comandos NL a las llamadas API correspondientes. <br><br>  <b>Desaf√≠o</b>  La recopilaci√≥n de datos de capacitaci√≥n es una de las tareas m√°s importantes asociadas con la investigaci√≥n en el desarrollo de interfaces NLI y su aplicaci√≥n pr√°ctica.  Las NLI utilizan datos de entrenamiento controlados, que en el caso de NL2API consisten en pares de "comando NL - llamada API" para estudiar la sem√°ntica y asignar inequ√≠vocamente comandos NL a las representaciones formalizadas correspondientes.  El lenguaje natural es muy flexible, por lo que los usuarios pueden describir la llamada a la API de formas sint√°cticamente diferentes, es decir, se lleva a cabo la parafraseaci√≥n. <br><br>  Considere el segundo ejemplo en la Figura 1. Los usuarios pueden reformular esta pregunta de la siguiente manera: "¬øD√≥nde se llevar√° a cabo la pr√≥xima reuni√≥n?" O "Encuentre un lugar para la pr√≥xima reuni√≥n".  Por lo tanto, es extremadamente importante recopilar suficientes datos de capacitaci√≥n para que el sistema reconozca a√∫n m√°s esas opciones.  Las NLI existentes generalmente se adhieren al principio de "mejor posible" en la recopilaci√≥n de datos.  Por ejemplo, el an√°logo m√°s cercano de nuestra metodolog√≠a para comparar comandos NL con llamadas API utiliza el concepto de IF-This-Then-That (IFTTT) - "si es as√≠, entonces" (Figura 1).  Los datos de capacitaci√≥n provienen directamente del sitio web de IFTTT. <br><br>  Sin embargo, si la API no es compatible o no es totalmente compatible, no hay forma de solucionar la situaci√≥n.  Adem√°s, los datos de entrenamiento recopilados de esta manera no son aplicables para admitir comandos avanzados con varios par√°metros.  Por ejemplo, analizamos registros de llamadas an√≥nimos de API de Microsoft para buscar correos electr√≥nicos durante el mes y descubrimos que aproximadamente el 90% de ellos usan dos o tres par√°metros (aproximadamente la misma cantidad), y estos par√°metros son bastante diversos.  Por lo tanto, nos esforzamos por proporcionar soporte completo para la parametrizaci√≥n de la API e implementar comandos avanzados de NL.  El problema de implementar un proceso activo y personalizable de recopilaci√≥n de datos de entrenamiento para una API espec√≠fica actualmente sigue sin resolverse. <br><br>  Los problemas del uso de NLI en combinaci√≥n con otras representaciones formalizadas, como bases de datos relacionales, bases de conocimiento y tablas web, se han resuelto bastante bien, mientras que casi no se prest√≥ atenci√≥n al desarrollo de NLI para API web.  Ofrecemos la primera plataforma integral (marco) que le permite crear NL2API para una API web espec√≠fica desde cero.  En la implementaci√≥n de la API web, nuestro marco incluye tres etapas: (1) Presentaci√≥n.  El formato original de la API web HTTP contiene muchos detalles redundantes y, por lo tanto, que distraen desde el punto de vista de la NLI. <br><br>  Sugerimos utilizar una representaci√≥n sem√°ntica intermedia para la API web, para no sobrecargar el NLI con informaci√≥n innecesaria.  (2) Un conjunto de datos de entrenamiento.  Ofrecemos un nuevo enfoque para obtener datos de entrenamiento controlados basados ‚Äã‚Äãen crowdsourcing.  (3) NL2API.  Tambi√©n ofrecemos dos modelos NL2API: un modelo de extracci√≥n basado en lenguaje y un modelo de red neuronal recurrente (Seq2Seq). <br><br>  Uno de los resultados t√©cnicos clave de este trabajo es un enfoque fundamentalmente nuevo para la recopilaci√≥n activa de datos de capacitaci√≥n para NL2API basada en crowdsourcing: utilizamos ejecutivos remotos para anotar llamadas de API al compararlas con comandos de NL.  Esto le permite alcanzar tres objetivos de dise√±o al proporcionar: (1) Personalizaci√≥n.  Debe poder especificar qu√© par√°metros para qu√© API usar y cu√°ntos datos de capacitaci√≥n recopilar.  (2) Bajo costo.  Los servicios de los trabajadores de crowdsourcing son un orden de magnitud m√°s barato que los servicios de especialistas especializados, por lo que deber√≠an ser contratados.  (3) de alta calidad.  La calidad de los datos de entrenamiento no debe reducirse. <br><br>  Al dise√±ar este enfoque, surgen dos problemas principales.  Primero, las llamadas API con parametrizaci√≥n avanzada, como en la Figura 1, son incomprensibles para el usuario promedio, por lo que debe decidir c√≥mo formular el problema de anotaci√≥n para que los empleados de crowdsourcing puedan lidiar f√°cilmente con √©l.  Comenzamos desarrollando una representaci√≥n sem√°ntica intermedia para la API web (ver secci√≥n 2.2), que nos permite generar llamadas API sin problemas con los par√°metros requeridos. <br><br>  Luego, pensamos en la gram√°tica para convertir autom√°ticamente cada llamada de API en un comando NL can√≥nico, que puede ser bastante engorroso, pero ser√° claro para el empleado promedio de crowdsourcing (consulte la secci√≥n 3.1).  Los artistas solo tendr√°n que reformular el equipo can√≥nico para que suene m√°s natural.  Este enfoque le permite evitar muchos errores en la recopilaci√≥n de datos de capacitaci√≥n, ya que la tarea de reformulaci√≥n es mucho m√°s simple y m√°s comprensible para el empleado promedio de crowdsourcing. <br><br>  En segundo lugar, debe comprender c√≥mo definir y anotar solo aquellas llamadas API que son de valor real para aprender NL2API.  La "explosi√≥n combinatoria" que surge durante la parametrizaci√≥n conduce al hecho de que el n√∫mero de llamadas incluso para una API puede ser bastante grande.  No tiene sentido anotar todas las llamadas.  Ofrecemos un modelo probabil√≠stico jer√°rquico fundamentalmente nuevo para la implementaci√≥n del proceso de crowdsourcing (ver secci√≥n 3.2).  Por analog√≠a con el modelado de lenguaje con el fin de obtener informaci√≥n, asumimos que los comandos NL se generan en funci√≥n de las llamadas API correspondientes, por lo que el modelo de lenguaje debe usarse para cada llamada API para registrar este proceso "generativo". <br><br>  Nuestro modelo se basa en la naturaleza compositiva de las llamadas API o representaciones formalizadas de la estructura sem√°ntica en su conjunto.  En un nivel intuitivo, si una llamada API consiste en llamadas m√°s simples (por ejemplo, "correos electr√≥nicos no le√≠dos sobre un candidato para el t√≠tulo de ciencias" = "correos electr√≥nicos no le√≠dos" + "correos electr√≥nicos para un candidato a un t√≠tulo de ciencias", podemos construirlo modelo de idioma a partir de llamadas API simples, incluso sin anotaciones, por lo tanto, al anotar una peque√±a cantidad de llamadas API, podemos calcular el modelo de idioma para todos los dem√°s. <br><br>  Por supuesto, los modelos de lenguaje calculados est√°n lejos de ser ideales, de lo contrario ya habr√≠amos resuelto el problema de crear NL2API.  Sin embargo, tal extrapolaci√≥n del modelo de lenguaje a llamadas API sin anotar nos da una visi√≥n hol√≠stica de todo el espacio de llamadas API, as√≠ como la interacci√≥n del lenguaje natural y las llamadas API, lo que nos permite optimizar el proceso de crowdsourcing.  En la Secci√≥n 3.3, describimos un algoritmo para anotar selectivamente las llamadas API para ayudar a que las llamadas API sean m√°s distinguibles, es decir, para maximizar la discrepancia entre sus modelos de lenguaje. <br><br>  Aplicamos nuestro marco a dos API implementadas desde el paquete Microsoft Graph API2.  Demostramos que se pueden recopilar datos de capacitaci√≥n de alta calidad a un costo m√≠nimo si se utiliza el enfoque propuesto3.  Tambi√©n mostramos que nuestro enfoque mejora el crowdsourcing.  A costos similares, recopilamos mejores datos de capacitaci√≥n, superando significativamente la l√≠nea de base.  Como resultado, nuestras soluciones NL2API proporcionan una mayor precisi√≥n. <br><br>  En general, nuestra contribuci√≥n principal incluye tres aspectos: <br><br><ul><li>  Fuimos uno de los primeros en estudiar los problemas de NL2API y propusimos un marco integral para crear NL2API desde cero. </li><li>  Propusimos un enfoque √∫nico para la recopilaci√≥n de datos de capacitaci√≥n utilizando crowdsourcing y un modelo probabil√≠stico jer√°rquico fundamentalmente nuevo para optimizar este proceso. </li><li>  Aplicamos nuestro marco a API web reales y demostramos que se puede crear una soluci√≥n NL2API suficientemente efectiva desde cero. </li></ul><br><img src="https://habrastorage.org/webt/t4/fs/vl/t4fsvlxndjmziwbvzjh2rwqut2c.png"><br>  <i>Tabla 1. Par√°metros de consulta de OData.</i> <br><br><h2>  Pre√°mbulo </h2><br><h4>  API RESTful </h4><br>  Recientemente, las API web que cumplen con el estilo arquitect√≥nico REST, es decir, la API RESTful, se est√°n volviendo cada vez m√°s populares debido a su simplicidad.  Las API RESTful tambi√©n se usan en tel√©fonos inteligentes y dispositivos IoT.  Las API Restful trabajan con recursos dirigidos a trav√©s de URI y proporcionan acceso a estos recursos para una amplia gama de clientes mediante comandos HTTP simples: GET, PUT, POST, etc. Trabajaremos principalmente con la API RESTful, pero se pueden utilizar los m√©todos b√°sicos. y otras API. <br><br>  Por ejemplo, tome el conocido Protocolo de datos abiertos (OData) para la API RESTful y dos API web del paquete API de Microsoft Graph (Figura 1), que, respectivamente, se utilizan para buscar correos electr√≥nicos y eventos de calendario de usuario.  Los recursos en OData son entidades, cada una de las cuales est√° asociada con una lista de propiedades.  Por ejemplo, la entidad Mensaje (un correo electr√≥nico) tiene propiedades como asunto (asunto), desde (desde), isRead (leer), recibidoDateTime (fecha y hora de recepci√≥n), etc. <br><br>  Adem√°s, OData define un conjunto de par√°metros de consulta, lo que le permite realizar manipulaciones avanzadas en los recursos.  Por ejemplo, el par√°metro FILTER le permite buscar correos electr√≥nicos de un remitente espec√≠fico o cartas recibidas en una fecha espec√≠fica.  Los par√°metros de solicitud que utilizaremos se presentan en la Tabla 1. Llamamos a cada combinaci√≥n del comando HTTP y la entidad (o conjunto de entidades) como una API, por ejemplo, GET-Messages, para buscar correos electr√≥nicos.  Cualquier solicitud parametrizada, por ejemplo, FILTER (isRead = False), se llama par√°metro, y una llamada a la API es una API con una lista de par√°metros. <br><br><h4>  NL2API </h4><br>  La tarea principal de NLI es comparar una declaraci√≥n (un comando en un lenguaje natural) con una cierta representaci√≥n formalizada, por ejemplo, formas l√≥gicas o consultas SPARQL para bases de conocimiento o API web en nuestro caso.  Cuando es necesario enfocarse en el mapeo sem√°ntico sin distraerse con detalles irrelevantes, generalmente se usa una representaci√≥n sem√°ntica intermedia para no trabajar directamente con el objetivo.  Por ejemplo, la gram√°tica categ√≥rica combinatoria se usa ampliamente en la creaci√≥n de NLI para bases de datos y bases de conocimiento.  Un enfoque similar a la abstracci√≥n tambi√©n es muy importante para NL2API.  Muchos detalles, incluidas las convenciones de URL, los encabezados HTTP y los c√≥digos de respuesta, pueden "distraer" al NL2API de resolver el problema principal: el mapeo sem√°ntico. <br><br>  Por lo tanto, creamos una vista intermedia para las API RESTful (Figura 2) con el nombre de marco de API; esta vista refleja la sem√°ntica del marco.  El marco API consta de cinco partes.  HTTP Verb (HTTP Command) y Resource son los elementos b√°sicos para una API RESTful.  El tipo de retorno le permite crear API compuestas, es decir, combinar varias llamadas API para realizar una operaci√≥n m√°s compleja.  Los par√°metros obligatorios se utilizan con mayor frecuencia en las llamadas PUT o POST en la API, por ejemplo, la direcci√≥n, el encabezado y el cuerpo del mensaje son par√°metros obligatorios para enviar correos electr√≥nicos.  Los par√°metros opcionales a menudo est√°n presentes en las llamadas GET en la API, ayudan a reducir la solicitud de informaci√≥n. <br><br>  Si faltan los par√°metros requeridos, serializamos el marco API, por ejemplo: GET-messages {FILTER (isRead = False), SEARCH ("PhD application"), COUNT ()}.  Un marco API puede ser determinista y convertirse en una llamada API real.  Durante el proceso de conversi√≥n, se agregar√°n los datos contextuales necesarios, incluida la identificaci√≥n de usuario, la ubicaci√≥n, la fecha y la hora.  En el segundo ejemplo (Figura 1), el valor ahora en el par√°metro FILTER ser√° reemplazado por la fecha y hora de ejecuci√≥n del comando correspondiente durante la conversi√≥n del marco API en una llamada API real.  Adem√°s, los conceptos de un marco API y una llamada API se utilizar√°n indistintamente. <br><br><img src="https://habrastorage.org/webt/zq/ya/1s/zqya1s2fappwxv0soevosjshp6o.png"><br>  <i>Figura 2. El marco API.</i>  <i>Arriba: equipo de lenguaje natural.</i>  <i>En el medio: Frame API.</i>  <i>Abajo: llamada API.</i> <br><br><img src="https://habrastorage.org/webt/d1/4j/br/d14jbrsdzhethdl8tpvjlf0v7bq.png"><br>  <i>Figura 3. Transportador de crowdsourcing.</i> <br><br><h2>    </h2><br>                NL2API   .     API        ,     ( 3.1),          ( 3).     API,       ( 3.2),      ( 3.3). <br><br><img src="https://habrastorage.org/webt/-m/hx/zh/-mhxzhnfom3w3n8cck-nkazfwiu.png"><br> <i> 4.   . :   . :  .</i> <br><br><h4>  API    </h4><br>    API     API.   ,       ,        API,   API  .      ,  Boolean,     (True/False). <br><br>      ,  Datetime,     ,  today  this_week  receivedDateTime.  ,        API           (,    )    API    API. <br><br>     ,        API .        . ,     TOP,         ORDERBY.  ,   Boolean,  isRead,  ORDERBY   .    ¬´ ¬ª         API   API. <br><br>      API.       API   .     API     API  ( 4).            ( HTTP, ,    ). ,   ‚ü®sender ‚Üí NP[from]‚ü© ,     from  ¬´sender¬ª,    ‚Äî   (NP),     . <br><br>       (V),   (VP),  (JJ), - (CP),   ,       (NP/NP),    (PP/NP),  (S)  . . <br><br>  ,       API     ,           RESTful API    OData ‚Äî ¬´ ¬ª    . 17     4     API,     ( 5). <br><br>   ,          API.     ‚ü®t1, t2, ..., tn ‚Üí c[z]‚ü©,  <img src="https://habrastorage.org/webt/h5/rj/n2/h5rjn28vmc1twejoa5459flx0gm.png">    , z    API,  cz ‚Äî   .     4.   API    ,     S,     G4,     API   . C    ,          ,               - ¬´that is not read¬ª. <br><br>  ,      . ,  VP[x = False]     B2,   B4,       x.  x     VP,   B2 (, x is hasAttachments ‚Üí ¬´do not have attachment¬ª);    JJ,    B4 (, x is isRead ‚Üí ¬´is not read¬ª).       (¬´do not read¬ª or ¬´is not have attachment¬ª)       . <br><br><h4>   </h4><br>  Podemos generar una gran cantidad de llamadas API utilizando el enfoque anterior, pero anotar todas ellas mediante crowdsourcing no es econ√≥micamente factible.  Por lo tanto, proponemos un modelo probabil√≠stico jer√°rquico para crowdsourcing que lo ayude a decidir qu√© llamadas API se deben anotar.  Hasta donde sabemos, este es el primer modelo probabil√≠stico de usar crowdsourcing para crear interfaces NLI, lo que nos permite resolver la tarea √∫nica e intrigante de modelar la interacci√≥n entre representaciones de lenguaje natural y representaciones de estructura sem√°ntica formalizadas.  Las representaciones formalizadas de la estructura sem√°ntica en general y las llamadas API en particular son de naturaleza compositiva.  Por ejemplo, z12 = GET-Messages {COUNT (), FILTER (isRead = False)} consiste en z1 = GET-Messages {FILTER (isRead = False)} y z2 = GET-Messages {COUNT ()} (estos ejemplos son m√°s detallados discutir m√°s a fondo). <br><br><img src="https://habrastorage.org/webt/fa/w0/eh/faw0ehohhnasifwgtragzrqwg3o.png"><br>  <i>Figura 5. La red sem√°ntica.</i>  <i>La capa i-√©sima consiste en llamadas API con par√°metros i.</i>  <i>Las costillas son composiciones.</i>  <i>Las distribuciones de probabilidad en los v√©rtices caracterizan los modelos de lenguaje correspondientes.</i> <br><br>  Uno de los resultados clave de nuestro estudio fue la confirmaci√≥n de que dicha composici√≥n se puede utilizar para modelar el proceso de crowdsourcing. <br><br>  Primero, definimos la composici√≥n basada en un conjunto de par√°metros de llamada API. <br><br>  <b>Definici√≥n 3.1 (composici√≥n).</b>  Tome una API y un conjunto de llamadas API <br><img src="https://habrastorage.org/webt/jp/nd/rx/jpndrxembixwz20-sym5vtxyhaq.png">  si definimos r (z) como un conjunto de par√°metros para z, entonces <img src="https://habrastorage.org/webt/zq/ih/u5/zqihu5tkga6iigokecjod-cg5um.png">  es una composici√≥n <img src="https://habrastorage.org/webt/_a/1x/jv/_a1xjvs9yduvatefhmfdk6xumq8.png">  si y solo si <img src="https://habrastorage.org/webt/0e/oy/hw/0eoyhwaahe8xlrbplt1nqajeego.png">  es parte <img src="https://habrastorage.org/webt/np/q5/sy/npq5syhh47uv3yvyba_t1_4tqc0.png"><br><br>  Seg√∫n las relaciones de composici√≥n de las llamadas a la API, puede organizar todas las llamadas a la API en una sola estructura jer√°rquica.  Las llamadas a la API con el mismo n√∫mero de par√°metros se representan como los v√©rtices de una capa, y las composiciones se representan como <br>  costillas dirigidas entre capas.  Llamamos a esta estructura una red sem√°ntica (o SeMesh). <br><br>  Por analog√≠a con el enfoque basado en el modelado de lenguaje en la recuperaci√≥n de informaci√≥n, asumimos que las declaraciones correspondientes a una llamada API z se generan utilizando un proceso estoc√°stico caracterizado por un modelo de lenguaje <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  .  Para simplificar, nos centramos en las probabilidades de las palabras, por lo tanto <img src="https://habrastorage.org/webt/on/eh/p5/onehp5mxamc9ehgpsl1u4pbkfr4.png">  donde <img src="https://habrastorage.org/webt/a-/v8/rh/a-v8rh1ddeh_ai-eawq8udhqe80.png">  denota un diccionario. <br><br>  Por razones que se har√°n aparentes un poco m√°s tarde, en lugar del modelo est√°ndar de unigrama de lenguaje, sugerimos usar un conjunto de distribuciones de Bernoulli (Bag of Bernoulli, BoB).  Cada distribuci√≥n de Bernoulli corresponde a una variable aleatoria W, que determina si la palabra w aparece en la oraci√≥n generada en base a z, y la distribuci√≥n BoB es un conjunto de distribuciones de Bernoulli para todas las palabras <img src="https://habrastorage.org/webt/k0/gw/fj/k0gwfjeikxqircdxhndamv6xbba.png">  .  Usaremos <img src="https://habrastorage.org/webt/j1/vn/qm/j1vnqmhyhigxbdpj7s5irirmxae.png">  como una notaci√≥n corta para <img src="https://habrastorage.org/webt/ub/xi/rx/ubxirxha2um6wer3obznfezis7w.png">  . <br><br>  Supongamos que hemos formado un conjunto (m√∫ltiple) de declaraciones <img src="https://habrastorage.org/webt/m5/nb/sr/m5nbsrzyyxpfpzc6isj_qrjjxbs.png">  para z <br>  La estimaci√≥n de m√°xima verosimilitud (MLE) para la distribuci√≥n BoB le permite seleccionar sentencias que contienen w: <br><br><img src="https://habrastorage.org/webt/ix/gv/2q/ixgv2qua9ifqtxbp1mi3hf58izc.png"><br><br>  <b>Ejemplo 2.</b> Con respecto a la llamada API z1 anterior, supongamos que tenemos dos declaraciones u1 = "buscar correos electr√≥nicos no le√≠dos" y u2 = "correos electr√≥nicos que no se leen", luego u = {u1, u2}.  pb ("correos electr√≥nicos" | z) = 1.0, ya que "correos electr√≥nicos" est√° presente en ambas declaraciones.  Del mismo modo, pb ("no le√≠do" | z) = 0.5 y pb ("reuni√≥n" | z) = 0.0. <br><br>  En la red sem√°ntica, hay tres operaciones b√°sicas a nivel de v√©rtice: <br>  Anotaci√≥n, dise√±o e interpolaci√≥n. <br><br>  <b>ANOTAR</b> (anotar) significa recopilar declaraciones <img src="https://habrastorage.org/webt/m5/nb/sr/m5nbsrzyyxpfpzc6isj_qrjjxbs.png">  parafrasear el comando can√≥nico del v√©rtice z usando crowdsourcing y evaluar la distribuci√≥n emp√≠rica <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  m√©todo de m√°xima verosimilitud. <br><br>  <b>COMPOSE</b> (componer) intenta derivar un modelo de lenguaje basado en composiciones para calcular la distribuci√≥n esperada <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  .  Como mostramos experimentalmente, <img src="https://habrastorage.org/webt/zq/ih/u5/zqihu5tkga6iigokecjod-cg5um.png">  Es una composici√≥n para z.  Si procedemos del supuesto de que las declaraciones correspondientes se caracterizan por la misma conexi√≥n compositiva, entonces <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  debe presentarse en <img src="https://habrastorage.org/webt/xe/zj/vd/xezjvdelmyapzpsz-c-ubbyrowq.png">  : <br><br><img src="https://habrastorage.org/webt/1j/kw/gy/1jkwgy2cjdyy2tkd9fd94_vdtf0.png"><br><br>  donde f es una funci√≥n compositiva.  Para la distribuci√≥n BoB, la funci√≥n de composici√≥n se ver√° as√≠: <br><br><img src="https://habrastorage.org/webt/-j/yo/yc/-jyoycveazjjahzb2va3w26sfv0.png"><br><br>  En otras palabras, si ui es una declaraci√≥n zi, u es una declaraci√≥n <img src="https://habrastorage.org/webt/lr/ls/g_/lrlsg_9r0ga50mjkj47anmczlga.png">  composicionalmente forma u, entonces la palabra w no te pertenece.  Si y solo si no pertenece a ninguna interfaz de usuario.  Cuando z tiene muchas composiciones, Œ∏e x se calcula por separado y luego se promedia.  El modelo est√°ndar de unigrama de lenguaje no conduce a una funci√≥n compositiva natural.  En el proceso de normalizaci√≥n de las probabilidades de palabras, la longitud de las oraciones est√° involucrada, lo que, a su vez, tiene en cuenta la complejidad de las llamadas API, violando la descomposici√≥n en la ecuaci√≥n (2).  Es por eso que ofrecemos distribuci√≥n BoB. <br><br>  <b>Ejemplo 3.</b> Supongamos que preparamos una anotaci√≥n para las llamadas API mencionadas anteriormente z1 y z2, cada una de las cuales tiene dos declaraciones: <img src="https://habrastorage.org/webt/zy/pr/yx/zypryx-8unafep9q1_lu2bnwewi.png">  = {"Buscar correos electr√≥nicos no le√≠dos", "correos electr√≥nicos que no se leen"} y <img src="https://habrastorage.org/webt/7n/4a/74/7n4a746gi-pf2_nf0ocy0dohdqm.png">  = {"¬øCu√°ntos correos electr√≥nicos tengo?", "Encuentra el n√∫mero de correos electr√≥nicos"}.  Calificamos modelos de lenguaje <img src="https://habrastorage.org/webt/7a/uj/od/7aujod7s9qek21mw3zemkcgaake.png">  y <img src="https://habrastorage.org/webt/vp/so/fn/vpsofnkfxhjn38dfcjpm6bqzzio.png">  .  La operaci√≥n de composici√≥n est√° tratando de evaluar <img src="https://habrastorage.org/webt/qt/tm/ud/qttmudo6ekcwmdeptxfjigmmcck.png">  sin preguntar <img src="https://habrastorage.org/webt/hx/6c/sn/hx6csng8_0l_yqxgvteefbapkm0.png">  .  Por ejemplo, para la palabra "correos electr√≥nicos", pb ("correos electr√≥nicos" | z1) = 1.0 y pb ("correos electr√≥nicos" | z2) = 1.0, por lo que se deduce de la ecuaci√≥n (3) que pb ("correos electr√≥nicos" | z12) = 1.0, es decir, creemos que esta palabra se incluir√° en cualquier declaraci√≥n de z12.  Del mismo modo, pb ("find" | z1) = 0.5 y pb ("find" | z2) = 0.5, entonces pb ("find" | z12) = 0.75.  Una palabra tiene una buena probabilidad de ser generada a partir de cualquier z1 o z2, por lo que su probabilidad para z12 deber√≠a ser mayor. <br><br>  Por supuesto, las declaraciones no siempre se combinan compositivamente.  Por ejemplo, varios elementos en una representaci√≥n formalizada de una estructura sem√°ntica se pueden transmitir en una sola palabra o frase en un lenguaje natural, este fen√≥meno se llama composicionalidad subl√©xica.  Un ejemplo de este tipo se muestra en la Figura 3, donde los tres par√°metros: TOP (1), FILTER (inicio&gt; ahora) y ORDERBY (inicio, asc), est√°n representados por la sola palabra "siguiente".  Sin embargo, es imposible obtener dicha informaci√≥n sin anotar la llamada API, por lo que el problema en s√≠ se parece al problema de los huevos y la gallina.  En ausencia de dicha informaci√≥n, es razonable adherirse al supuesto predeterminado de que las declaraciones se caracterizan por la misma relaci√≥n de composici√≥n que las llamadas API. <br><br>  Esta es una suposici√≥n plausible.  Vale la pena se√±alar que esta suposici√≥n se usa solo para modelar el proceso de crowdsourcing con el objetivo de recopilar datos.  En la etapa de prueba, las declaraciones de usuarios reales pueden no corresponder a esta suposici√≥n.  La interfaz de lenguaje natural podr√° hacer frente a tales situaciones no compositivas si est√°n cubiertas por los datos de capacitaci√≥n recopilados. <br><br>  <b>INTERPOLATE</b> (interpolaci√≥n) combina toda la informaci√≥n disponible sobre z, es decir, declaraciones anotadas z e informaci√≥n obtenida de las composiciones, y obtiene una estimaci√≥n m√°s precisa <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  por interpolaci√≥n <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  y <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  . <br><br><img src="https://habrastorage.org/webt/s4/qk/00/s4qk00v3xupp-nglc-ge-mmgwxa.png"><br><br>  El par√°metro de equilibrio Œ± controla las compensaciones entre anotaciones <br>  picos actuales que son precisos pero suficientes, y la informaci√≥n obtenida de las composiciones basadas en el supuesto de composici√≥n puede no ser tan precisa, pero proporciona una cobertura m√°s amplia.  En cierto sentido <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  tiene el mismo prop√≥sito que el suavizado en el modelado de lenguaje, lo que permite una mejor estimaci√≥n de la distribuci√≥n de probabilidad con datos insuficientes (anotaciones).  Mas que <img src="https://habrastorage.org/webt/xt/ml/w5/xtmlw5p16zioqn1amioucvjhe5o.png">  cuanto m√°s peso en <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  .  Para un v√©rtice ra√≠z que no tiene composici√≥n, <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  = <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  .  Para un top sin anotar <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  = <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  . <br><br>  A continuaci√≥n, describimos el algoritmo de actualizaci√≥n de red sem√°ntica, es decir, c√°lculos <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  para todos los z (algoritmo 1), incluso si solo se anotara una peque√±a parte de los v√©rtices.  Suponemos que el valor <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">  Ya actualizado para todos los sitios anotados.  Bajando de arriba a abajo, calculamos secuencialmente <img src="https://habrastorage.org/webt/j6/i1/vm/j6i1vmdddqj_xfet6a9uhyzcdt0.png">  y <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  para cada v√©rtice z.  Primero, debe actualizar las capas superiores para poder calcular la distribuci√≥n esperada de los v√©rtices del nivel inferior.  Anotamos todos los v√©rtices ra√≠z, por lo que podemos calcular <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  para todos los v√©rtices <br><br>  <i>Algoritmo 1. Actualizar distribuciones de nodos de malla sem√°ntica</i> <br><br><img src="https://habrastorage.org/webt/wd/ja/xx/wdjaxx4oqk_1rqniul9rnbc-fno.png"><br><br><h4>  3.3 Optimizaci√≥n del crowdsourcing </h4><br>  La red sem√°ntica forma una visi√≥n hol√≠stica de todo el espacio de llamadas API, as√≠ como la interacci√≥n de declaraciones y llamadas.  Seg√∫n esta vista, podemos anotar selectivamente solo un subconjunto de llamadas API de alto valor.  En esta secci√≥n, describimos nuestra estrategia de distribuci√≥n diferencial para optimizar el crowdsourcing. <br><br>  Considere una red sem√°ntica con muchos v√©rtices Z. Nuestra tarea es determinar un subconjunto de v√©rtices dentro del proceso iterativo <img src="https://habrastorage.org/webt/ti/9x/ac/ti9xacqha0b1hbtkyeejh30f3sk.png">  para ser anotado por los trabajadores de crowdsourcing.  Los v√©rtices anotados anteriormente se denominar√°n estado estado, <br>  entonces necesitamos encontrar la pol√≠tica pol√≠tica <img src="https://habrastorage.org/webt/9i/oc/9m/9ioc9mao9yuvhq7uhkiemeqet4g.png">  para evaluar cada v√©rtice no anotado en funci√≥n del estado actual. <br><br>  Antes de profundizar en la discusi√≥n de los enfoques para calcular pol√≠ticas efectivas, supongamos que ya tenemos una y damos una descripci√≥n de alto nivel de nuestro algoritmo de crowdsourcing (Algoritmo 2) para describir los m√©todos que lo acompa√±an.  M√°s espec√≠ficamente, primero anotamos todos los v√©rtices ra√≠z para evaluar la distribuci√≥n de todos los v√©rtices en Z (l√≠nea 3).  En cada iteraci√≥n, actualizamos la distribuci√≥n de v√©rtices (l√≠nea 5), ‚Äã‚Äãcalculamos <br>  una pol√≠tica basada en el estado actual de la red sem√°ntica (l√≠nea 6), seleccione el v√©rtice no anotado con la calificaci√≥n m√°xima (l√≠nea 7) y anote el v√©rtice y el resultado en el nuevo estado (l√≠nea 8).  En t√©rminos pr√°cticos, puede anotar m√∫ltiples v√©rtices como parte de una iteraci√≥n para aumentar la eficiencia. <br><br><img src="https://habrastorage.org/webt/va/tz/hs/vatzhsjcogvaktg8wh4h0a8al70.png"><br>  <i>Figura 6. Distribuci√≥n diferencial.</i>  <i>z12 y z23 representan el par de v√©rtices en estudio.</i>  <i>w es una estimaci√≥n calculada sobre la base de d (z12, z23), y se propaga iterativamente de abajo hacia arriba, duplicada en cada iteraci√≥n.</i>  <i>La estimaci√≥n para el v√©rtice ser√° la diferencia absoluta de sus estimaciones de z12 y z23 (por lo tanto, diferencial).</i>  <i>z2 obtiene una puntuaci√≥n de 0 porque es la entidad principal com√∫n para z12 y z23;</i>  <i>La anotaci√≥n en este caso ser√° de poca utilidad para garantizar la distinci√≥n de z12 y z23.</i> <br><br>  En un sentido amplio, las tareas que resolvemos pueden atribuirse al problema del aprendizaje activo, nos fijamos el objetivo de identificar un subconjunto de ejemplos para anotaciones con el fin de obtener un conjunto de capacitaci√≥n que pueda mejorar los resultados del aprendizaje.  Sin embargo, varias diferencias clave no permiten la aplicaci√≥n directa de los m√©todos cl√°sicos de ense√±anza activa, como la "incertidumbre del muestreo".  Por lo general, en el proceso de aprendizaje activo, el estudiante, que en nuestro caso ser√≠a la interfaz NLI, intenta estudiar el mapeo f: X ‚Üí Y, donde X es el patr√≥n de espacio de entrada, que consiste en un peque√±o conjunto de muestras marcadas y una gran cantidad de marcas sin marcar, y Y generalmente es un conjunto de marcadores clase <br><br>  El alumno eval√∫a el valor informativo de los ejemplos no etiquetados y selecciona el m√°s informativo para obtener una marca Y de los trabajadores de crowdsourcing.  Pero dentro del marco del problema que estamos resolviendo, el problema de la anotaci√≥n se plantea de manera diferente.  Necesitamos seleccionar una instancia de Y, un gran espacio de llamada API, y pedir a los trabajadores de crowdsourcing que lo etiqueten especificando patrones en X, el espacio de oraci√≥n.  Adem√°s, no estamos vinculados a un alumno en particular.  Por lo tanto, proponemos una nueva soluci√≥n al problema en cuesti√≥n.  Nos inspiramos en numerosas fuentes sobre aprendizaje activo. <br><br>  Primero, determinamos el objetivo, en base al cual se evaluar√° el contenido de informaci√≥n de los nodos.  Obviamente, queremos que se puedan distinguir diferentes llamadas a la API.  En la red sem√°ntica, esto significa que la distribuci√≥n <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  diferentes picos tienen diferencias obvias.  Para comenzar, presentamos cada distribuci√≥n <img src="https://habrastorage.org/webt/hn/r0/ww/hnr0wwjntvtnl8pymcmhkfjsawc.png">  como un vector n-dimensional <img src="https://habrastorage.org/webt/nv/ky/pn/nvkypndwq-7j6xnikrteas3oiq4.png">  donde n = | <img src="https://habrastorage.org/webt/a-/v8/rh/a-v8rh1ddeh_ai-eawq8udhqe80.png">  El |  - El tama√±o del diccionario.  Por una cierta m√©trica de la distancia del vector d (en nuestros experimentos usamos la distancia entre los vectores pL1) queremos decir <img src="https://habrastorage.org/webt/jc/z9/de/jcz9demx4drw0fsgz1niisgavd0.png">  , es decir, la distancia entre dos v√©rtices es igual a la distancia entre sus distribuciones. <br><br>  El objetivo obvio es maximizar la distancia total entre todos los pares de v√©rtices.  Sin embargo, la optimizaci√≥n de todas las distancias por pares puede ser demasiado complicada para los c√°lculos, e incluso esto no es necesario.  Un par de picos distantes ya tiene suficientes diferencias, por lo que un mayor aumento de la distancia no tiene sentido.  En cambio, podemos centrarnos en los pares de v√©rtices que causan la mayor confusi√≥n, es decir, la distancia entre ellos es la m√°s peque√±a. <br><br><img src="https://habrastorage.org/webt/of/tp/sl/oftpslo2cmmijyxtccepbyqsmsc.png"><br><br>  donde <img src="https://habrastorage.org/webt/1g/-h/nh/1g-hnhpklydkghmo4z7pq7ujouu.png">  se√±ala los primeros K pares de v√©rtices si clasificamos todos los pares de nodos por distancia en orden ascendente. <br><br>  <i>Algoritmo 2. Anotar iterativamente una malla sem√°ntica con una pol√≠tica</i> <br><br><img src="https://habrastorage.org/webt/5p/j2/2r/5pj22rp_c5npknusixp4k4ulfli.png"><br><br>  <i>Algoritmo 3. Pol√≠tica de c√°lculo basada en propagaci√≥n diferencial</i> <br><br><img src="https://habrastorage.org/webt/s5/ee/zb/s5eezb7ls03ly9nfndyotsqhlva.png"><br><br>  <i>Algoritmo 4. Propagar recursivamente un puntaje de un nodo fuente a todos sus nodos principales</i> <br><br><img src="https://habrastorage.org/webt/m9/ge/vt/m9gevt8-vlgwxxulaxyfxkovdmk.png"><br><br>  Los v√©rtices con mayor contenido de informaci√≥n despu√©s de la anotaci√≥n aumentan potencialmente el valor de Œò.  Para la cuantificaci√≥n en este caso, proponemos utilizar una estrategia de distribuci√≥n diferencial.  Si la distancia entre un par de v√©rtices es peque√±a, examinamos todos sus v√©rtices principales: si el v√©rtice principal es com√∫n para un par de v√©rtices, deber√≠a obtener una calificaci√≥n baja, ya que la anotaci√≥n conducir√° a cambios similares para ambos v√©rtices. <br><br>  De lo contrario, el v√©rtice debe tener una calificaci√≥n alta, y cuanto m√°s cerca est√© el par de v√©rtices, mayor ser√° la calificaci√≥n.  Por ejemplo, si la distancia entre los v√©rtices de "correos electr√≥nicos no le√≠dos sobre la aplicaci√≥n de doctorado" y "cu√°ntos correos electr√≥nicos son sobre la aplicaci√≥n de doctorado" es peque√±a, entonces anotar sus v√©rtices principales "correos electr√≥nicos sobre la aplicaci√≥n de doctorado" no tiene mucho sentido desde el punto de vista de distinguir estos v√©rtices.  Es m√°s recomendable anotar los nodos principales que no ser√°n comunes para ellos: "correos electr√≥nicos no le√≠dos" y "cu√°ntos correos electr√≥nicos". <br><br>  Un ejemplo de tal situaci√≥n se muestra en la Figura 6, y su algoritmo es el algoritmo 3. Como estimaci√≥n, tomamos el rec√≠proco de la distancia del nodo delimitada por una constante (l√≠nea 6), por lo que los pares de v√©rtices m√°s cercanos tienen el mayor impacto.  Cuando trabajamos con un par de v√©rtices, asignamos simult√°neamente una evaluaci√≥n de cada v√©rtice a todos sus v√©rtices principales (l√≠nea 9, 10 y algoritmo 4).  Una estimaci√≥n de un v√©rtice no anotado es la diferencia absoluta en las estimaciones del par de v√©rtices correspondiente con la suma de todos los pares de v√©rtices (l√≠nea 12). <br><br><h2>  Interfaz de lenguaje natural </h2><br>  Para evaluar el marco propuesto, es necesario entrenar los modelos NL2API utilizando los datos recopilados.  Por el momento, el modelo NL2API terminado no est√° disponible, pero estamos adaptando dos modelos NLI probados de otras √°reas para aplicarlos a la API. <br><br><h4>  Modelo de lenguaje Modelo de extracci√≥n </h4><br>  Basado en desarrollos recientes en el campo de NLI para bases de conocimiento, podemos considerar la creaci√≥n de NL2API en el contexto del problema de extracci√≥n de informaci√≥n para adaptar el modelo de extracci√≥n basado en el modelo de lenguaje (LM) a nuestras condiciones. <br><br>  Para decir u, necesita encontrar una llamada API z en la red sem√°ntica con la mejor coincidencia para usted.  Primero transformamos la distribuci√≥n de BoB <img src="https://habrastorage.org/webt/rq/qs/9-/rqqs9-qn12-qsdd7mahxx5tg-si.png">  cada llamada de la API z al modelo de unigrama de lenguaje: <br><br><img src="https://habrastorage.org/webt/lr/4f/pt/lr4fptel7voyxz2pelzjinbyu14.png"><br><br>  donde usamos suavizado aditivo, y 0 ‚â§ Œ≤ ‚â§ 1 es el par√°metro de suavizado.  Mayor valor <img src="https://habrastorage.org/webt/rh/1e/wc/rh1ewczas_fvleaxd5za0qvury0.png">  , mayor es el peso de las palabras que a√∫n no se han analizado.  Las llamadas a la API se pueden clasificar por su probabilidad logar√≠tmica: <br><br><img src="https://habrastorage.org/webt/3c/sf/fu/3csffus3jr7h6kpxq6czdyvhdtm.png"><br><br>  (sujeto a una distribuci√≥n de probabilidad uniforme a priori) <br><br><img src="https://habrastorage.org/webt/0s/xu/y-/0sxuy-xon3k12zlsbn2f41wzyco.png"><br><br>  La llamada de API mejor calificada se utiliza como resultado de la simulaci√≥n. <br><br><h4>  M√≥dulo de reformulaci√≥n Seq2Seq </h4><br>  Las redes neuronales se est√°n generalizando como modelos para NLI, mientras que el modelo Seq2Seq es mejor que los dem√°s para este prop√≥sito, ya que le permite procesar naturalmente secuencias de entrada y salida de longitudes variables.  Adaptamos este modelo para NL2API. <br><br>  Para la secuencia de entrada e <img src="https://habrastorage.org/webt/sl/zv/2w/slzv2wvhssrsrt-2cehxkcosmr0.png">  , el modelo estima la distribuci√≥n de probabilidad condicional p (y | x) para todas las secuencias de salida posibles <img src="https://habrastorage.org/webt/zz/ar/74/zzar74ttz1utynmp2qpkuprrhwc.png">  .  Las longitudes T y T 'pueden variar y tomar cualquier valor.  En NL2API, x es la declaraci√≥n de salida.  Puede ser una llamada API serializada o su comando can√≥nico.  Utilizaremos comandos can√≥nicos como secuencias de salida de destino, lo que en realidad convierte nuestro problema en un problema de reformulaci√≥n. <br><br>  Un codificador implementado como una red neuronal recurrente (RNN) con unidades de recurrencia controlada (GRU) representa primero x como un vector de tama√±o fijo, <br><br><img src="https://habrastorage.org/webt/_l/vv/ht/_lvvhtq3g73uajiwibi7r5xzspc.png"><br><br>  donde RN N es una breve representaci√≥n para aplicar GRU a toda la secuencia de entrada, marcador por marcador, seguido de la salida del √∫ltimo estado oculto. <br><br>  El decodificador, que tambi√©n es un RNN con GRU, toma h0 como estado inicial y procesa la secuencia de salida y, marcador por marcador, para generar una secuencia de estados, <br><br><img src="https://habrastorage.org/webt/eo/lg/9l/eolg9ljwlyskjfurunypvlmswaa.png"><br><br>  La capa de salida toma cada estado del decodificador como un valor de entrada y genera una distribuci√≥n de diccionario. <img src="https://habrastorage.org/webt/a-/v8/rh/a-v8rh1ddeh_ai-eawq8udhqe80.png">  como el valor de salida.  Simplemente utilizamos la transformaci√≥n af√≠n seguida de la funci√≥n log√≠stica multivariable softmax: <br><br><img src="https://habrastorage.org/webt/qr/ty/c9/qrtyc9lsayvqiczswbr-837_pba.png"><br><br>  La probabilidad condicional final, que nos permite evaluar qu√© tan bien el comando can√≥nico y reformula la declaraci√≥n de entrada x, es <img src="https://habrastorage.org/webt/l5/yt/wn/l5ytwnga_iegxtspqogvabwe5g0.png"><img src="https://habrastorage.org/webt/ul/7k/ny/ul7knyk1imjwc0p_hrjisfmy8-e.png">  .  Las llamadas a la API se clasifican seg√∫n la probabilidad condicional de su comando can√≥nico.  Le recomendamos que se familiarice con la fuente, donde se describe el proceso de aprendizaje modelo con m√°s detalle. <br><br><h2>  Los experimentos </h2><br>  Experimentalmente, estudiamos los siguientes temas de investigaci√≥n: [PI1]: ¬øPodemos usar el marco propuesto para recopilar datos de capacitaci√≥n de alta calidad a un precio razonable?  [PI2]: ¬øLa red sem√°ntica proporciona una evaluaci√≥n m√°s precisa de los modelos de lenguaje que la evaluaci√≥n de m√°xima verosimilitud?  [PI3]: ¬øUna estrategia de distribuci√≥n diferencial mejora la eficiencia del crowdsourcing? <br><br><h4>  Crowdsourcing </h4><br>       -API  Microsoft ‚Äî GET-Events  GET-Messages ‚Äî              .       API,    API ( 3.1)      .   API    2.      ,  Amazon Mechanical Turk.    ,     API    . <br><br>             .   API  10 ,       10 .    201 ,        .          44 ,     82       ,    8,2 , ,   ,  .    ,    400    ,     17,4 %. <br><br>         (,     ORDERBY  a COUNT parameter)     (,    ,        ).       .            NLI.  ,  ,    [1] .           . <br><br>  ,      ,         ,   ,  API    (. 3).   API       .        ,    .     61  API  157   GET-Messages,   77  API  190   GET-Events.        ,  ,    API (,    )     , ,     . <br><br><img src="https://habrastorage.org/webt/dc/yk/nv/dcyknvmod2su0cutkru02tpklti.png"><br> <i> 2.   API.</i> <br><br><img src="https://habrastorage.org/webt/x9/dm/_b/x9dm_bbbgyua7xe0cl1fzjloc5o.png"><br> <i> 3.   :  ().</i> <br><br><h4>   </h4><br>       ,     ,      .    ,   Œ± = 0,3,    LM Œ≤ = 0,001.    K,    ,  100 000.    , ,      Seq2Seq ‚Äî 500.           (  ). <br><br>                  NLI,     .          . <br><br><h4>    </h4><br>  .         ,  ,            .         LM:   ,   .     ,     . ROOT ‚Äî   . TOP2 = ROOT +    2;  TOP3 = TOP2 +    3.            . <br><br>     4.      LM      (MLE)    ,     <img src="https://habrastorage.org/webt/u4/o6/hw/u4o6hwaxkucqpz_fmcsbca0eqqo.png">    ,      . ,    ,      ,  MLE       . <br><br>    MLE,      <img src="https://habrastorage.org/webt/rz/hi/nv/rzhinvau9uyozj1iphz8idarw9m.png">   ,  <img src="https://habrastorage.org/webt/1d/h2/o8/1dh2o8om1hinyzi3r41ipp4pd3e.png"> -    ,    .     API    .    16   API (ROOT)   LM  SeMesh        Seq2Seq       API (TOP2)    ,   500   API (TOP3). <br><br>    ,   ,     ,  ,     ( 3.2)   .  ,    GET-Events    ,   GET-Messages.   ,  GET-Events  <br>  ,    ,        ,         . <br><br><img src="https://habrastorage.org/webt/pb/ym/e4/pbyme4xdpxcqabwlawu_bmkefkg.png"><br> <i> 4.    .        LM,       Seq2Seq,      .  ,        .</i> <br><br>  LM +  ,      ,       <img src="https://habrastorage.org/webt/1d/h2/o8/1dh2o8om1hinyzi3r41ipp4pd3e.png">     Œ∏em with <img src="https://habrastorage.org/webt/rz/hi/nv/rzhinvau9uyozj1iphz8idarw9m.png">  .    <img src="https://habrastorage.org/webt/1d/h2/o8/1dh2o8om1hinyzi3r41ipp4pd3e.png">  y <img src="https://habrastorage.org/webt/rz/hi/nv/rzhinvau9uyozj1iphz8idarw9m.png"> ,    ,    ROOT,          <img src="https://habrastorage.org/webt/1d/h2/o8/1dh2o8om1hinyzi3r41ipp4pd3e.png">  y <img src="https://habrastorage.org/webt/rz/hi/nv/rzhinvau9uyozj1iphz8idarw9m.png">  .    ,        ,    .             MLE.  ,  ,    [2] . <br><br>        0,45  0,6:    ,           NLI   .    ,            API.        API (.   7)     ,    RNN   ,     .       . <br><br>  .        :   |u |    Œ±.   -     LM ( 7).    ,  |u | &lt; 10,         10  .     GET-Events,  GET-Messages  . <br><br> ,         ,   ,    . ,    ,    .   ,       Œ±,        ([0.1, 0.7]).   Œ±      ,   ,      . <br><br><h4>   </h4><br>            (DP)   .       API  .       50  API,    ,    NL2API      . <br><br> ,     .     LM,      .             .           ,       ( 5.1),          API   . <br><br><img src="https://habrastorage.org/webt/lg/xz/z9/lgxzz9zznpwnk0c4vdqfnfaurrg.png"><br>  7.  . <br><br><img src="https://habrastorage.org/webt/ak/5p/da/ak5pda8vlogeadhfjphy-t33dcg.png"><br>  8.    . : GET-Events. : GET-Messages <br><br>       breadth first (BF),          .    .     .  API    ,       API  . <br><br>      8.    NL2API   API  DP      .     300    API,    Seq2Seq, DP      7 %   API.       ,  .  ,  DP    API,      NL2API.  ,  ,    [3] . <br><br><h2>    </h2><br> - .   -  (NLI)     .  NLI    . ,   ,       .                . <br><br>      NLI    ,    -,    API   .  NL2API     :      API ,   - ,   .      .      API    REST           . <br><br> <b>    NLI.</b>        NLI    ¬´  ¬ª. ,         Google Suggest API,        API   IFTTT.         NLI,       .        ,   . <br><br>          NLI,                  .        NLI   ,          .           ,           ,        . <br><br>                  API  .         ,          -API.                  . <br><br> <b>   -API.</b>     ,   -API. ,   -API      API,         -API   .  NL2API     , ,          API. <br><br><h2>      </h2><br>     -   -API (NL2API)       NL2API  .                NL2API   .       : (1)  .            , , ? (2)  . <br><br>      ? (3)  NL2API. ,               API. (4)  API.         API? (5)    :    NL2API        ? </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es418559/">https://habr.com/ru/post/es418559/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es418547/index.html">Programaci√≥n asincr√≥nica con ejemplos: reconstrucci√≥n de m√©todos java.util.concurrent.CompletableFuture</a></li>
<li><a href="../es418549/index.html">Crear un bot para participar en AI mini cup 2018 basado en una red neuronal recurrente (parte 3)</a></li>
<li><a href="../es418551/index.html">¬øCu√°nto debe saber un programador de matem√°ticas?</a></li>
<li><a href="../es418553/index.html">Kotlin + React vs Javasript + React</a></li>
<li><a href="../es418557/index.html">C√°lculo de procesos ondulatorios en una l√≠nea hidr√°ulica utilizando el m√©todo de caracter√≠sticas.</a></li>
<li><a href="../es418561/index.html">M√°quinas de estado al servicio de MVP. Conferencia de Yandex</a></li>
<li><a href="../es418563/index.html">El resumen de materiales interesantes para el desarrollador m√≥vil # 263 (23 de julio - 29 de julio)</a></li>
<li><a href="../es418565/index.html">En el camino al 100% de cobertura de c√≥digo con pruebas en Go usando sql-dumper como ejemplo</a></li>
<li><a href="../es418567/index.html">Dell dejar√° de ser una empresa privada y, por primera vez en 5 a√±os, colocar√° acciones en la bolsa de valores.</a></li>
<li><a href="../es418569/index.html">Nuevos sat√©lites - nuevos errores: el sensor infrarrojo satelital GOES-17 no se enfr√≠a bien</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
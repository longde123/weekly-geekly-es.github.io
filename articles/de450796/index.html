<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§òüèº üçê ‚ù£Ô∏è Wie Tesla Autopilot lehrt üö° üë®üèª‚Äçüíº üèØ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Entschl√ºsselung des 2. Teils des Tesla Autonomy Investor Day. Autopilot-Trainingszyklus, Datenerfassungsinfrastruktur, automatische Datenkennzeichnung...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie Tesla Autopilot lehrt</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/450796/"> <em><img src="https://habrastorage.org/webt/vc/ch/lx/vcchlxqf5blytupr3nsndhmmgay.png"><br><br></em>  <em>Entschl√ºsselung des 2. Teils des Tesla Autonomy Investor Day.</em>  <em>Autopilot-Trainingszyklus, Datenerfassungsinfrastruktur, automatische Datenkennzeichnung, Nachahmung menschlicher Fahrer, Videoentfernungserkennung, Sensor√ºberwachung und vieles mehr.</em> <br><a name="habracut"></a><br>  <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der erste Teil ist die Entwicklung des Full Self-Driving Computer (FSDC)</a> .</em> <br><br>  <strong>Host:</strong> FSDC kann mit sehr komplexen neuronalen Netzen f√ºr die Bildverarbeitung arbeiten.  Es ist Zeit dar√ºber zu sprechen, wie wir Bilder erhalten und wie wir sie analysieren.  Wir haben einen leitenden KI-Direktor bei Tesla, Andrei Karpaty, der Ihnen das alles erkl√§ren wird. <br><br>  <strong>Andrei:</strong> Ich trainiere seit ungef√§hr zehn Jahren in neuronalen Netzen und jetzt seit 5-6 Jahren f√ºr den industriellen Einsatz.  Einschlie√ülich bekannter Institutionen wie Stanford, Open AI und Google.  Dieser Satz neuronaler Netze dient nicht nur der Bildverarbeitung, sondern auch der nat√ºrlichen Sprache.  F√ºr meine Doktorarbeit habe ich Architekturen entworfen, die diese beiden Modalit√§ten kombinieren. <br><br>  In Stanford unterrichtete ich einen Kurs √ºber dekonvolution√§re neuronale Netze.  Ich war der Hauptlehrer und entwickelte den gesamten Lehrplan f√ºr ihn.  Anfangs hatte ich ungef√§hr 150 Studenten, in den n√§chsten zwei oder drei Jahren wuchs die Zahl der Studenten auf 700. Dies ist ein sehr beliebter Kurs, einer der gr√∂√üten und erfolgreichsten Kurse in Stanford. <br><br>  <strong>Ilon:</strong> Andrey ist wirklich einer der besten Bildverarbeitungsspezialisten der Welt.  Vielleicht das Beste. <br><br>  <strong>Andrew:</strong> Danke.  Hallo an alle.  Pete hat Ihnen von einem Chip erz√§hlt, den wir speziell f√ºr neuronale Netze in einem Auto entwickelt haben.  Mein Team ist f√ºr das Training dieser neuronalen Netze verantwortlich.  Dies umfasst die Datenerfassung, Schulung und teilweise Bereitstellung. <br><br>  Was machen neuronale Netze in einem Auto?  Es gibt acht Kameras im Auto, die Videos aufnehmen.  Neuronale Netze sehen sich diese Videos an, verarbeiten sie und machen Vorhersagen dar√ºber, was sie sehen.  Wir interessieren uns f√ºr Stra√üenmarkierungen, Verkehrsteilnehmer, andere Objekte und deren Entfernungen, Fahrbahn, Ampeln, Verkehrszeichen und so weiter. <br><br><img src="https://habrastorage.org/webt/lu/-b/-u/lu-b-ufhozioprg2nvebadsk4zs.png"><br><br>  Meine Pr√§sentation kann in drei Teile unterteilt werden.  Zun√§chst m√∂chte ich Ihnen kurz die neuronalen Netze vorstellen und wie sie funktionieren und wie sie trainiert werden.  Dies muss getan werden, damit im zweiten Teil klar wird, warum es so wichtig ist, dass wir eine riesige Flotte von Tesla-Autos (Flotte) haben.  Warum ist dies ein Schl√ºsselfaktor beim Training neuronaler Netze, die effizient auf der Stra√üe arbeiten?  Im dritten Teil werde ich √ºber Bildverarbeitung, Lidar und das Sch√§tzen der Entfernung nur mit Video sprechen. <br><br><h2>  Wie funktionieren neuronale Netze? </h2><br>  <em>(Es gibt hier nicht viel Neues, Sie k√∂nnen √ºberspringen und zur n√§chsten √úberschrift gehen)</em> <br><br>  Die Hauptaufgabe, die Netzwerke im Auto l√∂sen, ist die Mustererkennung.  F√ºr uns Menschen ist dies eine sehr einfache Aufgabe.  Sie sehen sich die Bilder an und sehen ein Cello, ein Boot, einen Leguan oder eine Schere.  Sehr einfach und unkompliziert f√ºr Sie, aber nicht f√ºr den Computer.  Der Grund ist, dass diese Computerbilder nur eine Anordnung von Pixeln sind, wobei jedes Pixel der Helligkeitswert an diesem Punkt ist.  Anstatt nur das Bild zu sehen, empf√§ngt der Computer eine Million Zahlen in einem Array. <br><br>  <strong>Ilon:</strong> Matrix, wenn du willst.  Wirklich Matrix. <br><br><img src="https://habrastorage.org/webt/x7/sy/zq/x7syzqa6mvf_64j6nsk8dovzyww.png"><br><br>  <strong>Andrew:</strong> Ja.  Wir m√ºssen von diesem Raster aus Pixeln und Helligkeitswerten zu √ºbergeordneten Konzepten wie Leguan usw. √ºbergehen.  Wie Sie sich vorstellen k√∂nnen, hat dieses Bild eines Leguans ein bestimmtes Helligkeitsmuster.  Leguane k√∂nnen jedoch auf unterschiedliche Weise, in unterschiedlichen Posen, unter unterschiedlichen Lichtverh√§ltnissen und auf unterschiedlichem Hintergrund dargestellt werden.  Sie k√∂nnen viele verschiedene Bilder des Leguans finden und wir m√ºssen es unter allen Bedingungen erkennen. <br><br>  Der Grund, warum Sie und ich damit leicht umgehen k√∂nnen, ist, dass wir ein riesiges neuronales Netzwerk haben, das Bilder verarbeitet.  Licht tritt in die Netzhaut ein und wird in den hinteren Teil Ihres Gehirns zum visuellen Kortex geleitet.  Die Gro√ühirnrinde besteht aus vielen Neuronen, die miteinander verbunden sind und eine Mustererkennung durchf√ºhren. <br><br>  In den letzten f√ºnf Jahren haben moderne Ans√§tze zur Bildverarbeitung unter Verwendung von Computern auch begonnen, neuronale Netze zu verwenden, in diesem Fall jedoch k√ºnstliche neuronale Netze.  K√ºnstliche neuronale Netze sind eine grobe mathematische Ann√§herung an den visuellen Kortex.  Hier gibt es auch Neuronen, die miteinander verbunden sind.  Ein typisches neuronales Netzwerk umfasst Dutzende oder Hunderte von Millionen von Neuronen, und jedes Neuron hat Tausende von Verbindungen. <br><br>  Wir k√∂nnen ein neuronales Netzwerk nehmen und ihm Bilder wie unseren Leguan zeigen, und das Netzwerk wird eine Vorhersage machen, die es sieht.  Erstens werden neuronale Netze vollst√§ndig versehentlich initialisiert, alle Gewichte der Verbindungen zwischen Neuronen sind Zufallszahlen.  Daher ist die Netzwerkprognose auch zuf√§llig.  Es kann sich herausstellen, dass das Netz denkt, dass es wahrscheinlich ein Boot ist.  W√§hrend des Trainings wissen und bemerken wir, dass der Leguan auf dem Bild ist.  Wir sagen einfach, dass wir m√∂chten, dass die Wahrscheinlichkeit eines Leguans f√ºr dieses Bild zunimmt und die Wahrscheinlichkeit, dass alles andere abnimmt.  Dann wird ein mathematischer Prozess verwendet, der als R√ºckausbreitungsmethode bezeichnet wird.  Stochastischer Gradientenabstieg, der es uns erm√∂glicht, das Signal entlang der Verbindungen zu verbreiten und ihre Gewichte zu aktualisieren.  Wir werden das Gewicht jeder dieser Verbindungen ziemlich stark aktualisieren, und sobald die Aktualisierung abgeschlossen ist, steigt die Wahrscheinlichkeit eines Leguans f√ºr dieses Bild leicht an und die Wahrscheinlichkeit anderer Antworten nimmt ab. <br><br>  Nat√ºrlich machen wir das mit mehr als einem einzelnen Bild.  Wir haben einen gro√üen Satz von markierten Daten.  Normalerweise sind dies Millionen von Bildern, Tausende von Tags oder so.  Der Lernprozess wird immer wieder wiederholt.  Sie zeigen dem Computer ein Bild, es sagt Ihnen seine Meinung, dann sagen Sie die richtige Antwort und das Netzwerk ist leicht konfiguriert.  Sie wiederholen dies millionenfach und zeigen manchmal hunderte Male dasselbe Bild an.  Das Training dauert normalerweise mehrere Stunden oder mehrere Tage. <br><br>  Nun etwas Kontraintuitives an der Arbeit neuronaler Netze.  Sie brauchen wirklich viele Beispiele.  Es passt nicht nur in deinen Kopf, sondern sie fangen wirklich von vorne an, sie wissen nichts.  Hier ist ein Beispiel - ein s√º√üer Hund, und Sie kennen ihre Rasse wahrscheinlich nicht.  Dies ist ein japanischer Spaniel.  Wir betrachten dieses Bild und sehen einen japanischen Spaniel.  Wir k√∂nnen sagen: "OK, ich verstehe, jetzt wei√ü ich, wie der japanische Spaniel aussieht."  Wenn ich Ihnen weitere Bilder von anderen Hunden zeige, finden Sie unter ihnen auch andere japanische Spaniels.  Sie brauchen nur ein Beispiel, Computer jedoch nicht.  Sie ben√∂tigen viele Daten √ºber japanische Spaniels, Tausende von Beispielen, in verschiedenen Posen, verschiedenen Lichtverh√§ltnissen, auf verschiedenen Hintergr√ºnden usw.  Sie m√ºssen dem Computer zeigen, wie der japanische Spaniel aus verschiedenen Blickwinkeln aussieht.  Und er braucht wirklich all diese Daten, sonst kann der Computer die gew√ºnschte Vorlage nicht lernen. <br><br><h2>  Bildlayout f√ºr Autopiloten </h2><br>  Wie h√§ngt das alles mit autonomem Fahren zusammen?  Wir sind nicht sehr besorgt √ºber Hunderassen.  Vielleicht k√ºmmern sie sich in Zukunft darum.  Aber jetzt interessieren uns Stra√üenmarkierungen, Objekte auf der Stra√üe, wo sie sind, wohin wir gehen k√∂nnen und so weiter.  Jetzt haben wir nicht nur Etiketten wie Leguan, sondern auch Stra√üenbilder, und wir interessieren uns beispielsweise f√ºr Stra√üenmarkierungen.  Eine Person betrachtet das Bild und markiert es mit der Maus. <br><br><img src="https://habrastorage.org/webt/eq/wa/wo/eqwawo_3ky3vffm_hkkheyrhmlq.png"><br><br>  Wir haben die M√∂glichkeit, Tesla-Autos zu kontaktieren und noch mehr Fotos anzufordern.  Wenn Sie zuf√§llige Fotos anfordern, erhalten Sie Bilder, auf denen das Auto in der Regel nur die Autobahn entlang f√§hrt.  Dies wird ein zuf√§lliger Datensatz sein und wir werden ihn markieren. <br><br>  Wenn Sie nur zuf√§llige Mengen markieren, lernt Ihr Netzwerk eine einfache, allgemeine Verkehrssituation und funktioniert nur darin gut.  Wenn Sie ihr ein etwas anderes Beispiel zeigen, sagen wir ein Bild einer Stra√üe, die in einem Wohngebiet abbiegt.  Ihr Netzwerk liefert m√∂glicherweise das falsche Ergebnis.  Sie wird sagen: "Nun, ich habe schon oft gesehen, die Stra√üe geht geradeaus." <br><br><img src="https://habrastorage.org/webt/_9/4u/x2/_94ux28ucicihvbggphmoqc5i0y.png"><br><br>  Das ist nat√ºrlich v√∂llig falsch.  Aber wir k√∂nnen das neuronale Netzwerk nicht beschuldigen.  Sie wei√ü nicht, ob der Baum links, das Auto rechts oder die Geb√§ude im Hintergrund von Bedeutung sind.  Das Netzwerk wei√ü nichts dar√ºber.  Wir alle wissen, dass die Markierungslinie wichtig ist und dass sie sich ein wenig zur Seite dreht.  Das Netzwerk sollte dies ber√ºcksichtigen, aber es gibt keinen Mechanismus, mit dem wir dem neuronalen Netzwerk einfach sagen k√∂nnen, dass diese Striche der Stra√üenmarkierungen wirklich wichtig sind.  Das einzige Werkzeug in unseren H√§nden sind beschriftete Daten. <br><br><img src="https://habrastorage.org/webt/e5/ew/d3/e5ewd3fhqw_ebegpk0heamyjafk.png"><br><br>  Wir nehmen Bilder auf, bei denen das Netzwerk fehlerhaft ist, und markieren sie korrekt.  In diesem Fall markieren wir das Wende-Markup.  Dann m√ºssen Sie viele √§hnliche Bilder in das neuronale Netzwerk √ºbertragen.  Und im Laufe der Zeit wird sie Wissen sammeln und lernen, dieses Muster zu verstehen, um zu verstehen, dass dieser Teil des Bildes keine Rolle spielt, aber dieses Markup ist sehr wichtig.  Das Netzwerk lernt, wie man die Fahrspur richtig findet. <br><br>  Nicht nur die Gr√∂√üe des Trainingsdatensatzes ist wichtig.  Wir brauchen mehr als nur Millionen von Bildern.  Es muss noch viel Arbeit geleistet werden, um den Raum der Situationen abzudecken, denen ein Auto auf der Stra√üe begegnen kann.  Sie m√ºssen einem Computer beibringen, nachts und im Regen zu arbeiten.  Die Stra√üe kann Licht wie ein Spiegel reflektieren, die Beleuchtung kann in weiten Grenzen variieren, die Bilder sehen sehr unterschiedlich aus. <br><br><img src="https://habrastorage.org/webt/k4/og/1f/k4og1fzgiwwt6jy_rwcefm3fndm.png"><br><br>  Wir m√ºssen dem Computer beibringen, wie man mit Schatten, Gabeln und gro√üen Objekten umgeht, die den gr√∂√üten Teil des Bildes einnehmen.  Wie man mit Tunneln oder in einem Stra√üenreparaturbereich arbeitet.  In all diesen F√§llen gibt es keinen direkten Mechanismus, um dem Netzwerk mitzuteilen, was zu tun ist.  Wir haben nur einen riesigen Datensatz.  Wir k√∂nnen Bilder aufnehmen, markieren und das Netzwerk trainieren, bis es beginnt, ihre Struktur zu verstehen. <br><br>  Gro√üe und vielf√§ltige Datenmengen helfen Netzwerken, sehr gut zu funktionieren.  Dies ist nicht unsere Entdeckung.  Experimente und Recherchen Google, Facebook, Baidu, Deepmind von Alphabet.  Alle zeigen √§hnliche Ergebnisse - neuronale Netze m√∂gen Daten, wie Quantit√§t und Vielfalt.  F√ºgen Sie mehr Daten hinzu und die Genauigkeit neuronaler Netze w√§chst. <br><br><h2>  Sie m√ºssen einen Autopiloten entwickeln, um das Verhalten von Autos in einer Simulation zu simulieren </h2><br>  Eine Reihe von Experten weisen darauf hin, dass wir die Simulation verwenden k√∂nnten, um die erforderlichen Daten im richtigen Ma√üstab zu erhalten.  Bei Tesla haben wir diese Frage wiederholt gestellt.  Wir haben unseren eigenen Simulator.  Wir verwenden h√§ufig Simulationen, um Software zu entwickeln und zu bewerten.  Wir haben es ziemlich erfolgreich f√ºr das Training verwendet.  Aber am Ende kann beim Training von Daten f√ºr neuronale Netze nichts echte Daten ersetzen.  Simulationen haben Probleme bei der Modellierung des Aussehens, der Physik und des Verhaltens der Teilnehmer. <br><br><img src="https://habrastorage.org/webt/ob/he/xw/obhexwtzhagxn7n_z0ildcfzyl8.png"><br><br>  Die reale Welt wirft uns eine Reihe unerwarteter Situationen auf.  Schwierige Bedingungen mit Schnee, B√§umen, Wind.  Verschiedene visuelle Artefakte, die schwer zu modellieren sind.  Stra√üenreparaturbereiche, B√ºsche, Plastikt√ºten h√§ngen im Wind.  Es k√∂nnen viele Menschen, Erwachsene, Kinder und Tiere durcheinander sein.  Das Verhalten und die Interaktion all dessen zu modellieren, ist eine absolut unl√∂sbare Aufgabe. <br><br><img src="https://habrastorage.org/webt/2k/3r/7a/2k3r7as1159puh5ad4bf3fwrltc.png"><br><br>  Hier geht es nicht um die Bewegung eines Fu√üg√§ngers.  Es geht darum, wie Fu√üg√§nger aufeinander reagieren und wie Autos aufeinander reagieren, wie sie auf Sie reagieren.  All dies ist sehr schwer zu simulieren.  Sie m√ºssen zuerst einen Autopiloten entwickeln, um nur das Verhalten von Autos in einer Simulation zu simulieren. <br><br>  Das ist wirklich schwer.  Es k√∂nnen Hunde sein, exotische Tiere, und manchmal ist es nicht einmal etwas, was Sie nicht vorgeben k√∂nnen, es ist etwas, das Ihnen einfach nie in den Sinn kommt.  Ich wusste nicht, dass ein LKW einen LKW tragen kann, der einen LKW tr√§gt, der einen anderen LKW tr√§gt.  Aber in der realen Welt passieren dieses und viele andere Dinge, die schwer zu finden sind.  Die Vielfalt, die ich in den Daten sehe, die von den Autos kommen, ist einfach verr√ºckt in Bezug auf das, was wir im Simulator haben.  Obwohl wir einen guten Simulator haben. <br><br>  <strong>Ilon:</strong> Simulation ist, als ob Sie Ihre eigenen Hausaufgaben f√ºr sich selbst erfinden w√ºrden.  Wenn Sie wissen, dass Sie so tun werden, als w√ºrden Sie sich nat√ºrlich darum k√ºmmern.  Aber wie Andrei sagte, wissen Sie nicht, was Sie nicht wissen.  Die Welt ist sehr seltsam, es gibt Millionen von Sonderf√§llen.  Wenn jemand eine Fahrsimulation erstellt, die die Realit√§t originalgetreu wiedergibt, ist dies an sich eine monumentale Leistung f√ºr die Menschheit.  Aber das kann niemand.  Es gibt einfach keinen Weg. <br><br><h2>  Flotte ist eine wichtige Datenquelle f√ºr das Training </h2><br><img src="https://habrastorage.org/webt/8u/kj/h7/8ukjh7k3qw7-sv469pyhnnbwhi0.png"><br><br>  <strong>Andrei:</strong> Damit neuronale Netze gut funktionieren, ben√∂tigen Sie einen gro√üen, vielf√§ltigen und realen Datensatz.  Und wenn Sie eines haben, k√∂nnen Sie Ihr neuronales Netzwerk trainieren und es wird sehr gut funktionieren.  Warum ist Tesla in dieser Hinsicht so besonders?  Die Antwort ist nat√ºrlich die Flotte (Flotte, Tesla-Flotte).  Wir k√∂nnen Daten von allen Tesla-Fahrzeugen sammeln und f√ºr Schulungen verwenden. <br><br>  Schauen wir uns ein konkretes Beispiel f√ºr die Verbesserung der Funktionsweise eines Objektdetektors an.  Auf diese Weise erhalten Sie eine Vorstellung davon, wie wir neuronale Netze trainieren, wie wir sie verwenden und wie sie mit der Zeit besser werden. <br><br>  Objekterkennung ist eine unserer wichtigsten Aufgaben.  Wir m√ºssen die Abmessungen von Autos und anderen Objekten hervorheben, um sie zu verfolgen und zu verstehen, wie sie sich bewegen k√∂nnen.  Wir k√∂nnen Leute bitten, die Bilder zu markieren.  Die Leute werden sagen: "Hier sind Autos, hier sind Fahrr√§der" und so weiter.  Und wir k√∂nnen das neuronale Netzwerk auf diese Daten trainieren.  In einigen F√§llen macht das Netzwerk jedoch falsche Vorhersagen. <br><br><img src="https://habrastorage.org/webt/7h/st/qk/7hstqk7ygew-tfoo_ibersaw86s.png"><br><br>  Wenn wir beispielsweise auf ein Auto sto√üen, an dem hinten ein Fahrrad angebracht ist, erkennt unser neuronales Netzwerk zwei Objekte - ein Auto und ein Fahrrad.  So hat sie gearbeitet, als ich ankam.  Und auf seine Weise ist es richtig, denn diese beiden Objekte sind hier wirklich pr√§sent.  Dem Autopilot-Planer ist es jedoch egal, dass dieses Fahrrad ein separates Objekt ist, das sich mit dem Auto bewegt.  Die Wahrheit ist, dass dieses Fahrrad fest mit dem Auto verbunden ist.  In Bezug auf Objekte auf der Stra√üe ist dies ein Objekt - ein Auto. <br><br><img src="https://habrastorage.org/webt/ms/d0/oi/msd0oiytsgapqj3dczs6s_hpocc.png"><br><br>  Jetzt m√∂chten wir viele √§hnliche Objekte als ‚Äûein Auto‚Äú markieren.  Unser Team verfolgt den folgenden Ansatz.  Wir nehmen dieses Bild oder mehrere Bilder, in denen ein solches Modell vorhanden ist.  Und wir haben einen Mechanismus f√ºr maschinelles Lernen, mit dem wir die Flotte bitten k√∂nnen, uns Beispiele zu liefern, die gleich aussehen.  Und die Flotte sendet Bilder als Antwort. <br><br><img src="https://habrastorage.org/webt/yt/xh/uj/ytxhujmzul8r8dpqwido3fr_rns.png"><br><br>  Hier ist ein Beispiel f√ºr sechs empfangene Bilder.  Sie alle enthalten Fahrr√§der, die an Autos befestigt sind.  Wir werden sie korrekt markieren und unser Detektor wird besser funktionieren.  Das Netzwerk beginnt zu verstehen, wann das Fahrrad am Auto befestigt ist und dass es sich um ein Objekt handelt.  Sie k√∂nnen das Netzwerk darin trainieren, vorausgesetzt, Sie haben gen√ºgend Beispiele.  Und so l√∂sen wir solche Probleme. <br><br>  Ich spreche viel dar√ºber, Daten von Tesla-Autos zu erhalten.  Und ich m√∂chte gleich sagen, dass wir dieses System von Anfang an unter Ber√ºcksichtigung der Vertraulichkeit entwickelt haben.  Alle Daten, die wir f√ºr Schulungen verwenden, sind anonymisiert. <br><br>  Die Flotte schickt uns nicht nur Fahrr√§der auf Autos.  Wir sind st√§ndig auf der Suche nach vielen verschiedenen Modellen.  Zum Beispiel suchen wir nach Booten - die Flotte sendet Bilder von Booten auf den Stra√üen.  Wir wollen Bilder von Stra√üenreparaturgebieten, und die Flotte sendet uns viele solcher Bilder aus der ganzen Welt.  Oder zum Beispiel M√ºll auf der Stra√üe, das ist auch sehr wichtig.  Die Flotte sendet uns Bilder von Reifen, Kegeln, Plastikt√ºten und dergleichen auf der Stra√üe. <br><br><img src="https://habrastorage.org/webt/aa/ne/2x/aane2xostifrgw-xjzwcklq-zbm.png"><br><br>  Wir k√∂nnen genug Bilder bekommen, sie richtig markieren und das neuronale Netzwerk wird lernen, wie man mit ihnen in der realen Welt arbeitet.  Wir brauchen das neuronale Netzwerk, um zu verstehen, was passiert, und um richtig zu reagieren. <br><br><h2>  Die Unsicherheit des neuronalen Netzes l√∂st die Datenerfassung aus </h2><br>  Das Verfahren, das wir immer wieder wiederholen, um das neuronale Netzwerk zu trainieren, ist wie folgt.  Wir begannen mit einer zuf√§lligen Reihe von Bildern, die von der Flotte empfangen wurden.  Wir markieren die Bilder, trainieren das neuronale Netz und laden es in Autos.  Wir haben Mechanismen, mit denen wir Ungenauigkeiten im Betrieb des Autopiloten erkennen.  Wenn wir feststellen, dass das neuronale Netzwerk nicht sicher ist oder ein Eingriff des Fahrers oder andere Ereignisse vorliegen, werden die Daten, f√ºr die dies geschehen ist, automatisch gesendet. <br><br><img src="https://habrastorage.org/webt/zl/ze/az/zlzeazzv1wrzsxbntqq5wtw0-50.png"><br><br>  Beispielsweise werden Tunnelmarkierungen schlecht erkannt.  Wir stellen fest, dass es ein Problem in den Tunneln gibt.  Entsprechende Bilder fallen in unsere Unit-Tests, sodass das Problem sp√§ter nicht wiederholt werden kann.  Um das Problem zu beheben, ben√∂tigen wir viele Schulungsbeispiele.  Wir bitten die Flotte, uns weitere Bilder der Tunnel zu senden, sie korrekt zu markieren, sie dem Trainingsset hinzuzuf√ºgen, das Netzwerk neu zu trainieren und sie dann in Autos zu laden.  Dieser Zyklus wiederholt sich immer wieder.  Wir nennen diesen iterativen Prozess die Daten-Engine (Daten-Engine? Daten-Engine?).  Wir schalten das Netzwerk im Schattenmodus ein, erkennen Ungenauigkeiten, fordern weitere Daten an und nehmen sie in den Trainingssatz auf.  Wir tun dies f√ºr alle Arten von Vorhersagen unserer neuronalen Netze. <br><br><h2>  Automatisches Datenmarkup </h2><br>  Ich habe viel √ºber das manuelle Markup von Bildern gesprochen.  Dies ist sowohl zeitlich als auch finanziell ein kostspieliger Prozess.  Es kann zu teuer sein.  Ich m√∂chte dar√ºber sprechen, wie Sie die Flotte hier nutzen k√∂nnen.  Die manuelle Kennzeichnung ist ein Engpass.  Wir wollen nur die Daten √ºbertragen und automatisch markieren.  Daf√ºr gibt es mehrere Mechanismen. <br><br>  Eines unserer j√ºngsten Projekte ist beispielsweise die Wiederherstellung der Erkennung.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie fahren auf der Autobahn, jemand f√§hrt links oder rechts und er baut auf Ihre Fahrspur um. </font></font><br><br><img src="https://habrastorage.org/webt/jk/-g/y4/jk-gy4iyujnhhwpmzb0lcwpggci.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier ist ein Video, in dem der Autopilot eine Neuerstellung erkennt. Nat√ºrlich m√∂chten wir es so schnell wie m√∂glich entdecken. Der Ansatz zur L√∂sung dieses Problems besteht darin, dass wir keinen Code wie folgt schreiben: Die linke Fahrtrichtungsanzeige leuchtet, die rechte Fahrtrichtungsanzeige leuchtet, unabh√§ngig davon, ob sich das Auto im Laufe der Zeit horizontal bewegt hat. Stattdessen verwenden wir flottenbasiertes Auto-Learning.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wie funktioniert es </font><font style="vertical-align: inherit;">Wir bitten die Flotte, uns Daten zu senden, wenn ein Umbau auf unserer Fahrspur aufgezeichnet wird. </font><font style="vertical-align: inherit;">Dann spulen wir die Zeit zur√ºck und stellen automatisch fest, dass dieses Auto in 1,3 Sekunden vor Ihnen wieder aufgebaut wird. </font><font style="vertical-align: inherit;">Diese Daten k√∂nnen verwendet werden, um das neuronale Netzwerk zu trainieren. </font><font style="vertical-align: inherit;">Somit extrahiert das neuronale Netzwerk selbst die notwendigen Zeichen. </font><font style="vertical-align: inherit;">Zum Beispiel scheuert ein Auto und baut es dann wieder auf, oder es hat einen eingeschalteten Blinker. </font><font style="vertical-align: inherit;">Das neuronale Netz erf√§hrt dies alles anhand automatisch beschrifteter Beispiele.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Schattencheck </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir bitten die Flotte, uns die Daten automatisch zu senden. Wir k√∂nnen ungef√§hr eine halbe Million Bilder sammeln, und Neuaufbauten werden auf allen markiert. Wir trainieren das Netzwerk und laden es in die Flotte. Aber bis wir es vollst√§ndig einschalten, aber im Schattenmodus ausf√ºhren. In diesem Modus macht das Netzwerk st√§ndig Vorhersagen: "Hey, ich denke, dieses Auto wird wieder aufgebaut." Und wir suchen nach falschen Prognosen. </font></font><br><br><img src="https://habrastorage.org/webt/x0/zy/zx/x0zyzxkrebaxgrqwu3xdxuldf9u.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier ist ein Beispiel eines Clips, den wir aus dem Schattenmodus erhalten haben. Hier ist die Situation nicht wenig offensichtlich, und das Netzwerk glaubte, dass das Auto auf der rechten Seite gerade wieder aufgebaut werden w√ºrde. Und Sie werden vielleicht bemerken, dass er leicht mit der Markierungslinie flirtet. Das Netzwerk reagierte darauf und schlug vor, dass das Auto bald auf unserer Fahrspur sein w√ºrde. Dies ist jedoch nicht geschehen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Netzwerk arbeitet im Schattenmodus und erstellt Prognosen. Unter ihnen sind falsch positiv und falsch negativ. Manchmal reagiert das Netzwerk fehlerhaft und manchmal √ºberspringt es Ereignisse. Alle diese Fehler l√∂sen eine Datenerfassung aus. Daten werden ohne zus√§tzlichen Aufwand markiert und in das Training integriert. Und wir gef√§hrden dabei keine Menschen. Wir trainieren das Netzwerk neu und verwenden wieder den Schattenmodus. Wir k√∂nnen dies mehrmals wiederholen und Fehlalarme unter realen Verkehrsbedingungen auswerten. Sobald die Anzeigen zu uns passen, klicken wir einfach auf den Schalter und lassen das Netzwerk das Auto steuern.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben vor ungef√§hr drei Monaten eine der ersten Versionen des Wiederherstellungsdetektors auf den Markt gebracht. </font><font style="vertical-align: inherit;">Wenn Sie feststellen, dass die Maschine den Wiederaufbau viel besser erkennt, ist dies ein Training mit der Flotte in Aktion. </font><font style="vertical-align: inherit;">Dabei wurde keine einzige Person verletzt. </font><font style="vertical-align: inherit;">Es ist nur eine Menge Training von neuronalen Netzen basierend auf realen Daten, unter Verwendung des Schattenmodus und Analyse der Ergebnisse. </font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ilon:</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tats√§chlich trainieren alle Fahrer st√§ndig das Netzwerk. </font><font style="vertical-align: inherit;">Es spielt keine Rolle, ob der Autopilot ein- oder ausgeschaltet ist. </font><font style="vertical-align: inherit;">Das Netzwerk lernt. </font><font style="vertical-align: inherit;">Jede Meile, die von einer Maschine mit HW2.0 oder h√∂her zur√ºckgelegt wird, bildet das Netzwerk aus.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> W√§hrend Sie fahren, markieren Sie tats√§chlich die Daten </font></font></h2><br><br><img src="https://habrastorage.org/webt/-g/1h/i8/-g1hi870mojfe0cnotbafoab73u.png"><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrei:</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ein weiteres interessantes Projekt, das wir im Flottenschulungsprogramm verwenden, ist die Vorhersage des Weges. Wenn Sie fahren, markieren Sie tats√§chlich die Daten. Sie sagen uns, wie man in verschiedenen Fahrsituationen f√§hrt. Hier biegt einer der Fahrer an der Kreuzung links ab. Wir haben ein vollst√§ndiges Video aller Kameras und kennen den Weg, den der Fahrer gew√§hlt hat. Wir wissen auch, wie schnell und drehwinkel das Lenkrad war. Wir bringen alles zusammen und verstehen den Weg, den eine Person in dieser Verkehrssituation gew√§hlt hat. Und wir k√∂nnen dies als Unterricht mit einem Lehrer nutzen. Wir erhalten nur die erforderliche Datenmenge von der Flotte, trainieren das Netzwerk auf diesen Trajektorien und danach kann das neuronale Netzwerk den Pfad vorhersagen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dies nennt man Nachahmungslernen. Wir nehmen die Flugbahnen von Menschen aus der realen Welt und versuchen, sie nachzuahmen. Und wieder k√∂nnen wir unseren iterativen Ansatz verfolgen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier ist ein Beispiel f√ºr die Vorhersage eines Pfades unter schwierigen Stra√üenbedingungen. Im Video √ºberlagern wir die Netzwerkprognose. Gr√ºn markiert den Pfad, den das Netzwerk verschieben w√ºrde. </font></font><br><br><img src="https://habrastorage.org/webt/vq/_5/h-/vq_5h-j22m3xlryz5aszlqqwls8.png"><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ilon: Der</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wahnsinn ist, dass das Netzwerk einen Pfad vorhersagt, den es nicht einmal sehen kann. Mit unglaublich hoher Pr√§zision. Sie sieht nicht, was sich um die Kurve befindet, glaubt jedoch, dass die Wahrscheinlichkeit dieser Flugbahn extrem hoch ist. Und es stellt sich als richtig heraus. Heute werden Sie es in Autos sehen, wir werden Augmented Vision einschlie√üen, damit Sie die Markierungen und Flugbahnvorhersagen sehen k√∂nnen, die dem Video √ºberlagert sind. </font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrei:</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tats√§chlich passiert unter der Haube das meiste und</font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ilon:</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Eigentlich ist es ein bisschen be√§ngstigend (Andrey lacht). </font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew:</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Nat√ºrlich vermisse ich viele Details. M√∂glicherweise m√∂chten Sie nicht alle Treiber hintereinander zum Markieren verwenden, sondern das Beste imitieren. Wir verwenden eine Reihe von M√∂glichkeiten, um diese Daten vorzubereiten. Interessanterweise ist diese Prognose tats√§chlich dreidimensional. Dies ist ein Pfad im dreidimensionalen Raum, den wir in 2D anzeigen. Das Netzwerk verf√ºgt jedoch √ºber Informationen zur Steigung, was f√ºr das Fahren sehr wichtig ist.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vorhersage der Art und Weise, wie derzeit in Autos funktioniert. </font><font style="vertical-align: inherit;">√úbrigens, als Sie vor ungef√§hr f√ºnf Monaten die Kreuzung auf der Autobahn passierten, konnte Ihr Auto damit nicht fertig werden. </font><font style="vertical-align: inherit;">Jetzt kann es. </font><font style="vertical-align: inherit;">Dies ist die Vorhersage des Weges in Aktion in Ihren Autos. </font><font style="vertical-align: inherit;">Wir haben es vor einiger Zeit eingeschaltet. </font><font style="vertical-align: inherit;">Und heute k√∂nnen Sie sehen, wie es an Kreuzungen funktioniert. </font><font style="vertical-align: inherit;">Ein wesentlicher Teil des Trainings zur √úberwindung von Kreuzungen wird durch automatisches Markieren von Daten erzielt. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es gelang mir, √ºber die Schl√ºsselkomponenten des neuronalen Netzwerktrainings zu sprechen. </font><font style="vertical-align: inherit;">Sie ben√∂tigen einen gro√üen, vielf√§ltigen Satz realer Daten. </font><font style="vertical-align: inherit;">In Tesla bekommen wir es mit der Flotte. </font><font style="vertical-align: inherit;">Wir verwenden die Daten-Engine, den Schattenmodus und das automatische Markup von Daten mithilfe der Flotte. </font><font style="vertical-align: inherit;">Und wir k√∂nnen diesen Ansatz skalieren.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tiefenwahrnehmung per Video </font></font></h2><br><img src="https://habrastorage.org/webt/oc/ft/4s/ocft4sltp3pprppnnk5y0jsj0rs.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Im n√§chsten Teil meiner Rede werde ich √ºber das Wahrnehmen von Tiefe durch Sehen sprechen. Sie wissen wahrscheinlich, dass Autos mindestens zwei Arten von Sensoren verwenden. Eine ist Helligkeit Videokameras, und die andere ist Lidar, die viele Unternehmen verwenden. Lidar gibt Punktmessungen der Entfernung um Sie herum. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich m√∂chte darauf hinweisen, dass Sie alle nur mit Ihrem neuronalen Netzwerk und Ihrer Vision hierher gekommen sind. Du hast nicht mit Lasern aus deinen Augen geschossen und bist trotzdem hier gelandet.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es ist klar, dass das menschliche neuronale Netzwerk Distanz extrahiert und die Welt ausschlie√ülich durch Sehen als dreidimensional wahrnimmt. Sie benutzt eine Reihe von Tricks. Ich werde kurz √ºber einige von ihnen sprechen. Zum Beispiel haben wir zwei Augen, sodass Sie zwei Bilder der Welt vor sich haben. Ihr Gehirn kombiniert diese Informationen, um eine Sch√§tzung der Entfernungen zu erhalten. Dazu werden Punkte in zwei Bildern trianguliert. Bei vielen Tieren befinden sich die Augen an den Seiten und ihr Sichtfeld ist leicht gekreuzt. Diese Tiere verwenden Struktur (Bewegung). Sie bewegen ihren Kopf, um viele Bilder der Welt von verschiedenen Punkten aus zu erhalten, und k√∂nnen auch Triangulation anwenden.</font></font><br><br><img src="https://habrastorage.org/webt/gl/sq/-q/glsq-qyu337vx5gcd3bycvqaffu.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Selbst wenn ein Auge geschlossen und v√∂llig bewegungslos ist, behalten Sie ein gewisses Gef√ºhl der Wahrnehmung von Distanz bei. Wenn Sie ein Auge schlie√üen, scheint es Ihnen nicht, dass ich zwei Meter n√§her oder hundert Meter weiter gekommen bin. Dies liegt daran, dass es viele leistungsstarke monokulare Techniken gibt, die auch Ihr Gehirn anwendet. Zum Beispiel eine gemeinsame optische T√§uschung mit zwei identischen Streifen auf dem Hintergrund der Schiene. Ihr Gehirn wertet die Szene aus und erwartet, dass eine von ihnen gr√∂√üer ist als die andere, da die Eisenbahnlinien in der Ferne verschwinden. Ihr Gehirn macht vieles automatisch, und k√ºnstliche neuronale Netze k√∂nnen das auch. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich werde drei Beispiele geben, wie Sie die Wahrnehmung von Tiefe im Video erreichen k√∂nnen. Ein klassischer Ansatz und zwei basierend auf neuronalen Netzen.</font></font><br><br><img src="https://habrastorage.org/webt/ns/ld/x0/nsldx0ejkyg1fvxoy-_7id-uds4.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir k√∂nnen in wenigen Sekunden einen Videoclip aufnehmen und die Umgebung mithilfe von Triangulations- und Stereovisionsmethoden in 3D neu erstellen. </font><font style="vertical-align: inherit;">Wir wenden √§hnliche Methoden im Auto an. </font><font style="vertical-align: inherit;">Die Hauptsache ist, dass das Signal wirklich die notwendigen Informationen hat, die einzige Frage ist, sie zu extrahieren.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Entfernungsmarkierung mit Radar </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wie gesagt, neuronale Netze sind ein sehr leistungsf√§higes visuelles Erkennungswerkzeug. Wenn Sie m√∂chten, dass sie die Entfernung erkennen, m√ºssen Sie die Entfernungen markieren. Anschlie√üend lernt das Netzwerk, wie dies zu tun ist. Nichts schr√§nkt Netzwerke in ihrer F√§higkeit ein, Entfernungen vorherzusagen, au√üer Daten markiert zu haben. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir verwenden ein nach vorne gerichtetes Radar. Dieses Radar misst und markiert die Entfernung zu Objekten, die das neuronale Netzwerk sieht. Anstatt den Leuten zu sagen, dass dieses Auto etwa 25 Meter entfernt ist, k√∂nnen Sie die Daten mithilfe von Sensoren viel besser markieren. Radar funktioniert in dieser Entfernung sehr gut. Sie markieren die Daten und trainieren das neuronale Netzwerk. Wenn Sie √ºber gen√ºgend Daten verf√ºgen, kann ein neuronales Netzwerk die Entfernung sehr gut vorhersagen.</font></font><br><br><img src="https://habrastorage.org/webt/ih/pp/je/ihppjemgjkcaefowadynpdtu5le.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In diesem Bild zeigen die Kreise die vom Radar empfangenen Objekte, und die Quader sind die vom neuronalen Netzwerk empfangenen Objekte. </font><font style="vertical-align: inherit;">Und wenn das Netzwerk gut funktioniert, sollten in der Draufsicht die Positionen der Quader mit der Position der Kreise √ºbereinstimmen, die wir beobachten. </font><font style="vertical-align: inherit;">Neuronale Netze eignen sich sehr gut f√ºr die Entfernungsvorhersage. </font><font style="vertical-align: inherit;">Sie k√∂nnen die Gr√∂√üe verschiedener Fahrzeuge lernen und anhand ihrer Gr√∂√üe auf dem Bild die Entfernung ziemlich genau bestimmen.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Selbst√ºberwachung </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der letzte Mechanismus, √ºber den ich sehr kurz sprechen werde, ist etwas technischer. Es gibt nur wenige Artikel, haupts√§chlich in den letzten ein oder zwei Jahren, √ºber diesen Ansatz. Es hei√üt Selbst√ºberwachung. </font></font><br><br><img src="https://habrastorage.org/webt/ll/vt/qy/llvtqyhtg50ssityr07udz-ssqs.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Was ist hier los? Sie laden unbeschriftete Rohvideos in das neuronale Netzwerk hoch. Und das Netzwerk kann immer noch lernen, Entfernungen zu erkennen. Ohne auf Details einzugehen, besteht die Idee darin, dass ein neuronales Netzwerk die Entfernung in jedem Bild dieses Videos vorhersagt. Wir haben keine Tags zur √úberpr√ºfung, aber es gibt eine Ziel-Zeit-Konsistenz. Unabh√§ngig davon, welche Entfernung das Netzwerk vorhersagt, muss sie im gesamten Video konsistent sein. Die einzige M√∂glichkeit, konsistent zu sein, besteht darin, die Entfernung korrekt vorherzusagen. Das Netzwerk sagt automatisch die Tiefe f√ºr alle Pixel voraus. Wir haben es geschafft, es zu reproduzieren, und es funktioniert ziemlich gut.</font></font><br><br><h2>    ‚Äî     </h2><br>  Zusammenfassend.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Menschen benutzen Vision, keine Laser. Ich m√∂chte betonen, dass eine leistungsstarke visuelle Erkennung f√ºr autonomes Fahren unbedingt erforderlich ist. Wir brauchen neuronale Netze, die die Umwelt wirklich verstehen. </font></font><br><br><img src="https://habrastorage.org/webt/5q/aq/b0/5qaqb0qjwt-a7c6tpihpswc_zba.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Daten aus dem Lidar sind viel weniger mit Informationen ges√§ttigt. Ist diese Silhouette unterwegs, ist es eine Plastikt√ºte oder ein Reifen? Lidar gibt Ihnen einfach ein paar Punkte, w√§hrend die Vision Ihnen sagen kann, was es ist. Blickt dieser Typ auf einem Fahrrad zur√ºck, versucht er die Spur zu wechseln oder f√§hrt er geradeaus? Was bedeuten diese Schilder in der Stra√üenreparaturzone und wie soll ich mich hier verhalten? Ja, die gesamte Stra√üeninfrastruktur ist f√ºr den visuellen Verbrauch ausgelegt. Alle Schilder, Ampeln, alles ist zum Sehen da, hier sind alle Informationen. Und wir m√ºssen es benutzen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dieses M√§dchen ist leidenschaftlich am Telefon, wird sie auf die Stra√üe treten? </font><font style="vertical-align: inherit;">Antworten auf solche Fragen k√∂nnen nur mit Hilfe des Sehens gefunden werden und sind f√ºr Autopilot Level 4-5 erforderlich. </font><font style="vertical-align: inherit;">Und genau das entwickeln wir bei Tesla. </font><font style="vertical-align: inherit;">Wir tun dies durch umfangreiches Training f√ºr neuronale Netze, unsere Daten-Engine und Flottenunterst√ºtzung. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In dieser Hinsicht ist Lidar ein Versuch, den Weg zu beschneiden. </font><font style="vertical-align: inherit;">Es umgeht die grundlegende Aufgabe der Bildverarbeitung, deren L√∂sung f√ºr das autonome Fahren notwendig ist. </font><font style="vertical-align: inherit;">Es gibt ein falsches Gef√ºhl des Fortschritts. </font><font style="vertical-align: inherit;">Lidar eignet sich nur f√ºr schnelle Demonstrationen.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Der Fortschritt ist proportional zur H√§ufigkeit von Kollisionen mit komplexen Situationen in der realen Welt. </font></font></h2><br><img src="https://habrastorage.org/webt/1t/io/en/1tioensdyfmt5eei36zaezrk1py.png"><br><br>  Wenn ich alles, was gesagt wurde, auf eine Folie passen wollte, w√ºrde es so aussehen.  Wir ben√∂tigen Level 4-5-Systeme, die in 99,9999% der F√§lle alle m√∂glichen Situationen bew√§ltigen k√∂nnen.  Das Streben nach den letzten Neunen wird schwierig und sehr schwierig sein.  Dies erfordert ein sehr leistungsf√§higes Bildverarbeitungssystem. <br><br>  Hier sehen Sie Bilder, die Ihnen auf dem Weg zu den gesch√§tzten Dezimalstellen begegnen k√∂nnen.  Zuerst fahren nur Autos vorw√§rts, dann sehen diese Autos etwas ungew√∂hnlich aus, auf ihnen erscheinen Fahrr√§der, Autos auf Autos.  Dann st√∂√üt man auf wirklich seltene Ereignisse wie umgekehrte Autos oder sogar Autos im Sprung.  Wir treffen viel von allem in den Daten, die aus der Flotte stammen. <br><br>  Und wir sehen diese seltenen Ereignisse viel h√§ufiger als unsere Konkurrenten.  Dies bestimmt die Geschwindigkeit, mit der wir Daten erhalten und Probleme durch Training neuronaler Netze beheben k√∂nnen.  Die Geschwindigkeit des Fortschritts ist proportional zur H√§ufigkeit, mit der Sie in der realen Welt mit schwierigen Situationen konfrontiert sind.  Und wir begegnen ihnen √∂fter als jeder andere.  Daher ist unser Autopilot besser als andere.  Vielen Dank. <br><br><h2>  Fragen und Antworten </h2><br><br>  <strong>Frage:</strong> Wie viele Daten sammeln Sie durchschnittlich von jedem Auto? <br><br>  <strong>Andrew:</strong> Es geht nicht nur um die Datenmenge, es geht um Vielfalt.  Irgendwann haben Sie bereits genug Bilder vom Fahren entlang der Autobahn, das Netzwerk versteht sie, es ist nicht mehr notwendig.  Daher konzentrieren wir uns strategisch darauf, die richtigen Daten zu erhalten.  Und unsere Infrastruktur mit einer ziemlich komplizierten Analyse erm√∂glicht es uns, die Daten zu erhalten, die wir gerade ben√∂tigen.  Hier geht es nicht um gro√üe Datenmengen, sondern um sehr gut ausgew√§hlte Daten. <br><br>  <strong>Frage:</strong> Ich frage mich, wie Sie das Problem des Spurwechsels l√∂sen werden.  Immer wenn ich versuche, mich wieder in einen dichten Strom zu verwandeln, haben sie mich abgeschnitten.  Menschliches Verhalten wird auf den Stra√üen von Los Angeles irrational.  Der Autopilot m√∂chte sicher fahren, und Sie m√ºssen es fast unsicher machen. <br><br>  <strong>Andrew:</strong> Ich habe √ºber die Daten-Engine als Training f√ºr neuronale Netze gesprochen.  Aber wir machen dasselbe auf Software-Ebene.  Alle Parameter, die sich auf die Auswahl auswirken, z. B. wann neu erstellt werden soll, wie aggressiv.  Wir √§ndern sie auch im Schattenmodus und beobachten, wie gut sie funktionieren, und passen die Heuristik an.  Tats√§chlich ist es eine schwierige Aufgabe, solche Heuristiken f√ºr den allgemeinen Fall zu entwerfen.  Ich denke, wir m√ºssen Flottentraining nutzen, um solche Entscheidungen zu treffen.  Wann wechseln die Leute die Spur?  In welchen Szenarien?  Wann empfinden sie einen Spurwechsel als unsicher?  Schauen wir uns einfach eine gro√üe Datenmenge an und bringen Sie dem Klassifikator f√ºr maschinelles Lernen bei, zu unterscheiden, wann die Wiederherstellung sicher ist.  Diese Klassifizierer k√∂nnen viel besseren Code schreiben als Menschen, da sie auf einer gro√üen Datenmenge zum Verhalten von Treibern beruhen. <br><br>  <strong>Ilon:</strong> Wahrscheinlich werden wir den Modus "Verkehr in Los Angeles" haben.  Irgendwo nach dem Mad Max-Modus.  Ja, Mad Max w√ºrde es in Los Angeles schwer haben. <br><br>  <strong>Andrei</strong> muss Kompromisse eingehen.  Sie m√∂chten keine unsicheren Situationen schaffen, sondern nach Hause kommen.  Und die T√§nze, die Menschen gleichzeitig auff√ºhren, sind sehr schwer zu programmieren.  Ich denke, das Richtige ist maschinelles Lernen.  Wo wir uns nur die vielen M√∂glichkeiten ansehen, wie Menschen dies tun, und versuchen, sie nachzuahmen. <br><br>  <strong>Ilon:</strong> Jetzt sind wir ein wenig konservativ und wenn unser Vertrauen w√§chst, wird es m√∂glich sein, ein aggressiveres Regime zu w√§hlen.  Benutzer k√∂nnen es ausw√§hlen.  In aggressiven Modi besteht beim Versuch, im Stau die Spur zu wechseln, eine geringe Wahrscheinlichkeit, dass der Fl√ºgel faltig wird.  Keine Gefahr eines schweren Unfalls.  Sie haben die Wahl, ob Sie einer Chance ungleich Null zustimmen, den Fl√ºgel zu zerdr√ºcken.  Leider ist dies der einzige Weg, um auf der Autobahn im Verkehr zu stecken. <br><br>  <strong>Frage:</strong> K√∂nnte es bei einer dieser Neunen nach dem Dezimalpunkt passieren, dass Lidar n√ºtzlich ist?  Die zweite Frage ist, wenn Lidars wirklich wertlos sind, was wird mit denen geschehen, die ihre Entscheidungen darauf aufbauen? <br><br>  <strong>Ilon:</strong> Sie werden alle Lidars loswerden, das ist meine Prognose, die Sie aufschreiben k√∂nnen.  Ich muss sagen, ich hasse Lidar nicht so sehr, wie es scheinen mag.  SpaceX Dragon verwendet das Lidar, um zur ISS zu gelangen und anzudocken.  SpaceX hat daf√ºr ein eigenes Lidar von Grund auf neu entwickelt.  Ich habe dieses Projekt pers√∂nlich geleitet, weil Lidar in diesem Szenario Sinn macht.  Aber in Autos ist es verdammt dumm.  Es ist teuer und nicht notwendig.  Und wie Andrei sagte, wird der Lidar unbrauchbar, sobald Sie das Video bearbeiten.  Sie haben teure Ausr√ºstung, die f√ºr das Auto unbrauchbar ist. <br><br>  Wir haben ein Vorw√§rtsradar.  Es ist kosteng√ºnstig und n√ºtzlich, insbesondere bei schlechten Sichtverh√§ltnissen.  Nebel, Staub oder Schnee, das Radar kann durch sie hindurchsehen.  Wenn Sie die aktive Photonenerzeugung verwenden m√∂chten, verwenden Sie nicht die Wellenl√§nge des sichtbaren Lichts.  Denn mit passiver Optik haben Sie sich bereits um alles im sichtbaren Spektrum gek√ºmmert.  Jetzt ist es besser, eine Wellenl√§nge mit guten Durchdringungseigenschaften wie Radar zu verwenden.  Lidar ist einfach die aktive Erzeugung von Photonen im sichtbaren Spektrum.  M√∂chten Sie aktiv Photonen erzeugen, tun Sie dies au√üerhalb des sichtbaren Spektrums.  Mit 3,8 mm gegen√ºber 400-700 nm k√∂nnen Sie bei schlechten Wetterbedingungen sehen.  Deshalb haben wir ein Radar.  Sowie zw√∂lf Ultraschallsensoren f√ºr die unmittelbare Umgebung.  Das Radar ist in Bewegungsrichtung am n√ºtzlichsten, da Sie sich direkt sehr schnell bewegen. <br><br>  Wir haben das Thema Sensoren schon oft angesprochen.  Gibt es genug davon?  Haben wir alles was wir brauchen?  M√ºssen Sie noch etwas hinzuf√ºgen?  Hmmm.  Genug. <br><br>  <strong>Frage:</strong> Es scheint, dass die Autos eine Art Berechnung durchf√ºhren, um zu bestimmen, welche Informationen Sie senden sollen.  Wird dies in Echtzeit oder basierend auf gespeicherten Informationen durchgef√ºhrt? <br><br>  <strong>Andrey:</strong> Berechnungen werden in Echtzeit in den Autos selbst durchgef√ºhrt.  Wir vermitteln die Bedingungen, die uns interessieren, und die Autos f√ºhren alle notwendigen Berechnungen durch.  Wenn sie dies nicht tun w√ºrden, m√ºssten wir alle Daten hintereinander √ºbertragen und in unserem Back-End verarbeiten.  Das wollen wir nicht. <br><br>  <strong>Ilon:</strong> Wir haben vierhundertf√ºnfundzwanzigtausend Autos mit HW2.0 +.  Dies bedeutet, dass sie √ºber acht Kameras, ein Radar, Ultraschallsensoren und mindestens einen nVidia-Computer verf√ºgen.  Es reicht zu berechnen, welche Informationen wichtig sind und welche nicht.  Sie komprimieren wichtige Informationen und senden sie zur Schulung an das Netzwerk.  Dies ist ein enormer Grad an Datenkomprimierung aus der realen Welt. <br><br>  <strong>Frage:</strong> Sie haben dieses Netzwerk aus Hunderttausenden von Computern, das einem leistungsstarken verteilten Rechenzentrum √§hnelt.  Sehen Sie die Anwendung f√ºr andere Zwecke als den Autopiloten? <br><br>  <strong>Ilon:</strong> Ich nehme an, das k√∂nnte f√ºr etwas anderes verwendet werden.  W√§hrend wir uns auf den Autopiloten konzentrieren.  Sobald wir es auf das richtige Niveau gebracht haben, k√∂nnen wir √ºber andere Anwendungen nachdenken.  Bis dahin werden es Millionen oder Dutzende Millionen Autos mit HW3.0 oder FSDC sein. <br><br>  <strong>Frage:</strong> Verkehr berechnen? <br><br>  <strong>Ilon:</strong> Ja vielleicht.  Es k√∂nnte so etwas wie AWS (Amazon Web Services) sein. <br><br>  <strong>Frage:</strong> Ich bin ein Model 3-Fahrer in Minnesota, wo es viel Schnee gibt.  Die Kamera und das Radar k√∂nnen die Stra√üenmarkierungen durch den Schnee nicht sehen.  Wie werden Sie dieses Problem l√∂sen?  Verwenden Sie hochgenaues GPS? <br><br>  <strong>Andrew:</strong> Schon heute verh√§lt sich der Autopilot auf einer schneebedeckten Stra√üe ziemlich gut.  Selbst wenn die Markierungen bei starkem Regen verborgen oder ausgefranst oder mit Wasser bedeckt sind, verh√§lt sich der Autopilot immer noch relativ gut.  Wir haben die verschneite Stra√üe mit unserer Daten-Engine noch nicht speziell bew√§ltigt.  Aber ich bin sicher, dass dieses Problem gel√∂st werden kann.  Denn wenn Sie in vielen Bildern einer verschneiten Stra√üe eine Person fragen, wo die Markierungen sein sollen, wird sie es Ihnen zeigen.  Die Leute sind sich einig, wo Markierungslinien gezogen werden sollen.  Und w√§hrend die Leute Ihre Daten vereinbaren und markieren k√∂nnen, kann das neuronale Netzwerk dies lernen und funktioniert gut.  Die Frage ist nur, ob das urspr√ºngliche Signal gen√ºgend Informationen enth√§lt.  Genug f√ºr einen Personenanmerker?  Wenn die Antwort ja lautet, funktioniert das neuronale Netzwerk einwandfrei. <br><br>  <strong>Ilon: Das</strong> Quellensignal enth√§lt mehrere wichtige Informationsquellen.  Also Markup, das ist nur einer von ihnen.  Die wichtigste Quelle ist die Auffahrt.  Wohin Sie gehen k√∂nnen und wohin Sie nicht k√∂nnen.  Wichtiger als Markup.  Die Stra√üenerkennung funktioniert sehr gut.  Ich denke, besonders nach dem kommenden Winter wird es unglaublich funktionieren.  Wir werden uns fragen, wie das so gut funktionieren kann.  Das ist einfach verr√ºckt. <br><br>  <strong>Andrew:</strong> Es geht nicht einmal um die F√§higkeit von Menschen, sich zu markieren.  Solange Sie als Person diesen Abschnitt der Stra√üe √ºberwinden k√∂nnen.  Die Flotte wird von Ihnen lernen.  Wir wissen, wie Sie hierher gefahren sind.  Und Sie haben offensichtlich Vision daf√ºr verwendet.  Sie haben das Markup nicht gesehen, aber Sie haben die Geometrie der gesamten Szene verwendet.  Sie sehen, wie sich die Stra√üe biegt, wie sich andere Autos um Sie herum befinden.  Das neuronale Netzwerk hebt automatisch alle diese Muster hervor. Sie m√ºssen nur gen√ºgend Daten dar√ºber abrufen, wie Menschen solche Situationen √ºberwinden. <br><br>  <strong>Ilon:</strong> Es ist sehr wichtig, sich nicht fest an GPS zu halten.  GPS-Fehler k√∂nnen sehr bedeutend sein.  Und die tats√§chliche Verkehrssituation kann unvorhersehbar sein.  Es kann eine Stra√üenreparatur oder ein Umweg sein.  Wenn das Auto zu stark auf GPS angewiesen ist, ist dies eine schlechte Situation.  Sie bitten um √Ñrger.  GPS ist nur als Hinweis zu verwenden. <br><br>  <strong>Frage:</strong> Einige Ihrer Konkurrenten sprechen dar√ºber, wie sie hochaufl√∂sende Karten verwenden, um die Wahrnehmung und die Pfadplanung zu verbessern.  Verwenden Sie etwas √Ñhnliches in Ihrem System? Sehen Sie darin einen Nutzen?  Gibt es Bereiche, in denen Sie mehr Daten haben m√∂chten, nicht aus der Flotte, sondern so etwas wie Karten? <br><br>  <strong>Ilon:</strong> Ich denke, hochaufl√∂sende Karten sind eine sehr schlechte Idee.  Das System wird extrem instabil.  Sie k√∂nnen sich nicht an √Ñnderungen anpassen, wenn Sie an GPS und hochaufl√∂sende Karten angeschlossen sind und der Sicht keine Priorit√§t einr√§umen.  Vision ist das, was alles tun sollte.  Markup ist nur eine Richtlinie, nicht das Wichtigste.  Wir haben versucht, Markup-Karten zu verwenden, und schnell festgestellt, dass dies ein gro√üer Fehler war.  Wir haben sie komplett aufgegeben. <br><br>  <strong>Frage: Es</strong> ist sehr n√ºtzlich zu verstehen, wo sich die Objekte befinden und wie sich die Autos bewegen.  Aber was ist mit dem Verhandlungsaspekt?  W√§hrend des Parkens, an Kreisverkehren und in anderen Situationen, in denen Sie mit anderen Autos interagieren, die Menschen fahren.  Es ist mehr eine Kunst als eine Wissenschaft. <br><br>  <strong>Ilon:</strong> Es funktioniert ziemlich gut.  Wenn Sie Situationen mit Umlagerungen usw. betrachten, kommt der Autopilot normalerweise zurecht. <br><br>  <strong>Andrew:</strong> Jetzt verwenden wir viel maschinelles Lernen, um eine Vorstellung von der realen Welt zu bekommen.  Dar√ºber hinaus haben wir einen Planer und Controller sowie viele Heuristiken zum Fahren, zur Ber√ºcksichtigung anderer Autos usw.  Und genau wie bei der Mustererkennung gibt es hier viele F√§lle, die nicht dem Standard entsprechen. Es ist wie ein Spiel mit Falken und Tauben, das Sie mit anderen Menschen spielen.  Wir sind zuversichtlich, dass wir letztendlich flottenbasiertes Training einsetzen werden, um dieses Problem zu l√∂sen.  Handschriftheuristiken ruhen schnell auf einem Plateau. <br><br>  <strong>Frage:</strong> Haben Sie einen Platooning-Modus?  Ist das System dazu in der Lage? <br><br>  <strong>Andrei:</strong> Ich bin absolut sicher, dass wir ein solches Regime schaffen k√∂nnen.  Aber noch einmal, wenn Sie nur das Netzwerk trainieren, um Menschen zu imitieren.  Die Leute werden angeheftet und fahren vor dem Auto, und das Netzwerk erinnert sich an dieses Verhalten.  Es ist eine Art Magie darin, alles passiert von selbst.  Verschiedene Probleme sind eins. Sammeln Sie einfach den Datensatz und trainieren Sie damit das neuronale Netzwerk. <br><br>  <strong>Ilon:</strong> Drei Schritte zum autonomen Fahren.  Die erste besteht darin, diese Funktionalit√§t einfach zu implementieren.  Das zweite ist, es so weit zu bringen, dass eine Person in einem Auto √ºberhaupt nicht auf die Stra√üe achten muss.  Und das dritte ist, die Zuverl√§ssigkeit zu zeigen, die die Regulierungsbeh√∂rden √ºberzeugt.  Dies sind drei Ebenen.  Wir erwarten, in diesem Jahr das erste Niveau zu erreichen.  Und wir gehen davon aus, dass wir irgendwann im zweiten Quartal n√§chsten Jahres ein gewisses Ma√ü an Selbstvertrauen erreichen werden, wenn eine Person ihre H√§nde nicht mehr am Lenkrad halten und auf die Stra√üe schauen muss.  Danach erwarten wir bis Ende n√§chsten Jahres zumindest in einigen L√§ndern eine beh√∂rdliche Genehmigung.  Das sind meine Erwartungen. <br><br>  Bei Lastkraftwagen ist es wahrscheinlich, dass das Konvoi-Regime fr√ºher als alles andere von den Aufsichtsbeh√∂rden genehmigt wird.  Vielleicht k√∂nnen Sie f√ºr lange Fahrten einen Fahrer im Kopfwagen und 4 Sattelschlepper im Konvoimodus hinter sich einsetzen. <br><br>  <strong>Frage:</strong> Ich bin sehr beeindruckt von der Verbesserung des Autopiloten.  Letzte Woche bin ich auf der rechten Spur der Autobahn gefahren und es gab eine Einfahrt.  Mein Modell 3 konnte zwei Autos erkennen, die auf die Autobahn fuhren, und wurde langsamer, so dass ein Auto leise vor mir und das andere hinter mir gebaut wurde.  Dann dachte ich, verdammt, das ist verr√ºckt, ich wusste nicht, dass mein Modell 3 dazu in der Lage ist. <br><br>  Aber in der gleichen Woche fuhr ich wieder auf der rechten Spur, und es gab eine Verengung, meine rechte Spur verschmolz mit der linken.  Und mein Model 3 konnte nicht richtig reagieren, ich musste eingreifen.  K√∂nnen Sie sagen, wie Tesla dieses Problem l√∂sen kann? <br><br>  <strong>Andrew:</strong> Ich habe √ºber die Datenerfassungsinfrastruktur gesprochen.  Wenn Sie eingegriffen haben, haben wir h√∂chstwahrscheinlich diesen Clip bekommen.  Er ging zum Beispiel in die Statistik ein, mit welcher Wahrscheinlichkeit wir korrekt in den Strom flie√üen.  Wir schauen uns diese Zahlen an, schauen uns die Clips an und sehen, was falsch ist.  Und wir versuchen, das Verhalten zu korrigieren, um eine Verbesserung im Vergleich zu den Benchmarks zu erreichen. <br><br>  <strong>Ilon:</strong> Nun, wir haben eine weitere Pr√§sentation √ºber Software.  Wir hatten eine Pr√§sentation √ºber Ger√§te mit Pete, dann neuronale Netze mit Andrey und jetzt folgt Software mit Stuart. <br>  ... </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de450796/">https://habr.com/ru/post/de450796/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de450784/index.html">Wie verwaltet Netflix seine Zuschauer so gut?</a></li>
<li><a href="../de450786/index.html">Unterschiede zwischen Fluent und gettext</a></li>
<li><a href="../de450788/index.html">Abh√§ngigkeitsinjektion mit DITranquillity</a></li>
<li><a href="../de450790/index.html">Hydrogel, Blaubeeren und eine Prise Kurkuma: K√ºnstliches Gef√§√üsystem</a></li>
<li><a href="../de450794/index.html">Wahl ist b√∂se</a></li>
<li><a href="../de450798/index.html">Maschinelles Lernen in der mobilen Entwicklung: Perspektiven und Dezentralisierung</a></li>
<li><a href="../de450800/index.html">Entwicklung von Microservices mit BDD und IOD</a></li>
<li><a href="../de450802/index.html">Legacy-Ausfall</a></li>
<li><a href="../de450804/index.html">3D-Metalldruck in der Automobilindustrie: klein anfangen</a></li>
<li><a href="../de450806/index.html">Wenn eine Umgebungsvariable den Prozess um das 40-fache beschleunigt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤘🏼 🍐 ❣️ Wie Tesla Autopilot lehrt 🚡 👨🏻‍💼 🏯</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Entschlüsselung des 2. Teils des Tesla Autonomy Investor Day. Autopilot-Trainingszyklus, Datenerfassungsinfrastruktur, automatische Datenkennzeichnung...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie Tesla Autopilot lehrt</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/450796/"> <em><img src="https://habrastorage.org/webt/vc/ch/lx/vcchlxqf5blytupr3nsndhmmgay.png"><br><br></em>  <em>Entschlüsselung des 2. Teils des Tesla Autonomy Investor Day.</em>  <em>Autopilot-Trainingszyklus, Datenerfassungsinfrastruktur, automatische Datenkennzeichnung, Nachahmung menschlicher Fahrer, Videoentfernungserkennung, Sensorüberwachung und vieles mehr.</em> <br><a name="habracut"></a><br>  <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der erste Teil ist die Entwicklung des Full Self-Driving Computer (FSDC)</a> .</em> <br><br>  <strong>Host:</strong> FSDC kann mit sehr komplexen neuronalen Netzen für die Bildverarbeitung arbeiten.  Es ist Zeit darüber zu sprechen, wie wir Bilder erhalten und wie wir sie analysieren.  Wir haben einen leitenden KI-Direktor bei Tesla, Andrei Karpaty, der Ihnen das alles erklären wird. <br><br>  <strong>Andrei:</strong> Ich trainiere seit ungefähr zehn Jahren in neuronalen Netzen und jetzt seit 5-6 Jahren für den industriellen Einsatz.  Einschließlich bekannter Institutionen wie Stanford, Open AI und Google.  Dieser Satz neuronaler Netze dient nicht nur der Bildverarbeitung, sondern auch der natürlichen Sprache.  Für meine Doktorarbeit habe ich Architekturen entworfen, die diese beiden Modalitäten kombinieren. <br><br>  In Stanford unterrichtete ich einen Kurs über dekonvolutionäre neuronale Netze.  Ich war der Hauptlehrer und entwickelte den gesamten Lehrplan für ihn.  Anfangs hatte ich ungefähr 150 Studenten, in den nächsten zwei oder drei Jahren wuchs die Zahl der Studenten auf 700. Dies ist ein sehr beliebter Kurs, einer der größten und erfolgreichsten Kurse in Stanford. <br><br>  <strong>Ilon:</strong> Andrey ist wirklich einer der besten Bildverarbeitungsspezialisten der Welt.  Vielleicht das Beste. <br><br>  <strong>Andrew:</strong> Danke.  Hallo an alle.  Pete hat Ihnen von einem Chip erzählt, den wir speziell für neuronale Netze in einem Auto entwickelt haben.  Mein Team ist für das Training dieser neuronalen Netze verantwortlich.  Dies umfasst die Datenerfassung, Schulung und teilweise Bereitstellung. <br><br>  Was machen neuronale Netze in einem Auto?  Es gibt acht Kameras im Auto, die Videos aufnehmen.  Neuronale Netze sehen sich diese Videos an, verarbeiten sie und machen Vorhersagen darüber, was sie sehen.  Wir interessieren uns für Straßenmarkierungen, Verkehrsteilnehmer, andere Objekte und deren Entfernungen, Fahrbahn, Ampeln, Verkehrszeichen und so weiter. <br><br><img src="https://habrastorage.org/webt/lu/-b/-u/lu-b-ufhozioprg2nvebadsk4zs.png"><br><br>  Meine Präsentation kann in drei Teile unterteilt werden.  Zunächst möchte ich Ihnen kurz die neuronalen Netze vorstellen und wie sie funktionieren und wie sie trainiert werden.  Dies muss getan werden, damit im zweiten Teil klar wird, warum es so wichtig ist, dass wir eine riesige Flotte von Tesla-Autos (Flotte) haben.  Warum ist dies ein Schlüsselfaktor beim Training neuronaler Netze, die effizient auf der Straße arbeiten?  Im dritten Teil werde ich über Bildverarbeitung, Lidar und das Schätzen der Entfernung nur mit Video sprechen. <br><br><h2>  Wie funktionieren neuronale Netze? </h2><br>  <em>(Es gibt hier nicht viel Neues, Sie können überspringen und zur nächsten Überschrift gehen)</em> <br><br>  Die Hauptaufgabe, die Netzwerke im Auto lösen, ist die Mustererkennung.  Für uns Menschen ist dies eine sehr einfache Aufgabe.  Sie sehen sich die Bilder an und sehen ein Cello, ein Boot, einen Leguan oder eine Schere.  Sehr einfach und unkompliziert für Sie, aber nicht für den Computer.  Der Grund ist, dass diese Computerbilder nur eine Anordnung von Pixeln sind, wobei jedes Pixel der Helligkeitswert an diesem Punkt ist.  Anstatt nur das Bild zu sehen, empfängt der Computer eine Million Zahlen in einem Array. <br><br>  <strong>Ilon:</strong> Matrix, wenn du willst.  Wirklich Matrix. <br><br><img src="https://habrastorage.org/webt/x7/sy/zq/x7syzqa6mvf_64j6nsk8dovzyww.png"><br><br>  <strong>Andrew:</strong> Ja.  Wir müssen von diesem Raster aus Pixeln und Helligkeitswerten zu übergeordneten Konzepten wie Leguan usw. übergehen.  Wie Sie sich vorstellen können, hat dieses Bild eines Leguans ein bestimmtes Helligkeitsmuster.  Leguane können jedoch auf unterschiedliche Weise, in unterschiedlichen Posen, unter unterschiedlichen Lichtverhältnissen und auf unterschiedlichem Hintergrund dargestellt werden.  Sie können viele verschiedene Bilder des Leguans finden und wir müssen es unter allen Bedingungen erkennen. <br><br>  Der Grund, warum Sie und ich damit leicht umgehen können, ist, dass wir ein riesiges neuronales Netzwerk haben, das Bilder verarbeitet.  Licht tritt in die Netzhaut ein und wird in den hinteren Teil Ihres Gehirns zum visuellen Kortex geleitet.  Die Großhirnrinde besteht aus vielen Neuronen, die miteinander verbunden sind und eine Mustererkennung durchführen. <br><br>  In den letzten fünf Jahren haben moderne Ansätze zur Bildverarbeitung unter Verwendung von Computern auch begonnen, neuronale Netze zu verwenden, in diesem Fall jedoch künstliche neuronale Netze.  Künstliche neuronale Netze sind eine grobe mathematische Annäherung an den visuellen Kortex.  Hier gibt es auch Neuronen, die miteinander verbunden sind.  Ein typisches neuronales Netzwerk umfasst Dutzende oder Hunderte von Millionen von Neuronen, und jedes Neuron hat Tausende von Verbindungen. <br><br>  Wir können ein neuronales Netzwerk nehmen und ihm Bilder wie unseren Leguan zeigen, und das Netzwerk wird eine Vorhersage machen, die es sieht.  Erstens werden neuronale Netze vollständig versehentlich initialisiert, alle Gewichte der Verbindungen zwischen Neuronen sind Zufallszahlen.  Daher ist die Netzwerkprognose auch zufällig.  Es kann sich herausstellen, dass das Netz denkt, dass es wahrscheinlich ein Boot ist.  Während des Trainings wissen und bemerken wir, dass der Leguan auf dem Bild ist.  Wir sagen einfach, dass wir möchten, dass die Wahrscheinlichkeit eines Leguans für dieses Bild zunimmt und die Wahrscheinlichkeit, dass alles andere abnimmt.  Dann wird ein mathematischer Prozess verwendet, der als Rückausbreitungsmethode bezeichnet wird.  Stochastischer Gradientenabstieg, der es uns ermöglicht, das Signal entlang der Verbindungen zu verbreiten und ihre Gewichte zu aktualisieren.  Wir werden das Gewicht jeder dieser Verbindungen ziemlich stark aktualisieren, und sobald die Aktualisierung abgeschlossen ist, steigt die Wahrscheinlichkeit eines Leguans für dieses Bild leicht an und die Wahrscheinlichkeit anderer Antworten nimmt ab. <br><br>  Natürlich machen wir das mit mehr als einem einzelnen Bild.  Wir haben einen großen Satz von markierten Daten.  Normalerweise sind dies Millionen von Bildern, Tausende von Tags oder so.  Der Lernprozess wird immer wieder wiederholt.  Sie zeigen dem Computer ein Bild, es sagt Ihnen seine Meinung, dann sagen Sie die richtige Antwort und das Netzwerk ist leicht konfiguriert.  Sie wiederholen dies millionenfach und zeigen manchmal hunderte Male dasselbe Bild an.  Das Training dauert normalerweise mehrere Stunden oder mehrere Tage. <br><br>  Nun etwas Kontraintuitives an der Arbeit neuronaler Netze.  Sie brauchen wirklich viele Beispiele.  Es passt nicht nur in deinen Kopf, sondern sie fangen wirklich von vorne an, sie wissen nichts.  Hier ist ein Beispiel - ein süßer Hund, und Sie kennen ihre Rasse wahrscheinlich nicht.  Dies ist ein japanischer Spaniel.  Wir betrachten dieses Bild und sehen einen japanischen Spaniel.  Wir können sagen: "OK, ich verstehe, jetzt weiß ich, wie der japanische Spaniel aussieht."  Wenn ich Ihnen weitere Bilder von anderen Hunden zeige, finden Sie unter ihnen auch andere japanische Spaniels.  Sie brauchen nur ein Beispiel, Computer jedoch nicht.  Sie benötigen viele Daten über japanische Spaniels, Tausende von Beispielen, in verschiedenen Posen, verschiedenen Lichtverhältnissen, auf verschiedenen Hintergründen usw.  Sie müssen dem Computer zeigen, wie der japanische Spaniel aus verschiedenen Blickwinkeln aussieht.  Und er braucht wirklich all diese Daten, sonst kann der Computer die gewünschte Vorlage nicht lernen. <br><br><h2>  Bildlayout für Autopiloten </h2><br>  Wie hängt das alles mit autonomem Fahren zusammen?  Wir sind nicht sehr besorgt über Hunderassen.  Vielleicht kümmern sie sich in Zukunft darum.  Aber jetzt interessieren uns Straßenmarkierungen, Objekte auf der Straße, wo sie sind, wohin wir gehen können und so weiter.  Jetzt haben wir nicht nur Etiketten wie Leguan, sondern auch Straßenbilder, und wir interessieren uns beispielsweise für Straßenmarkierungen.  Eine Person betrachtet das Bild und markiert es mit der Maus. <br><br><img src="https://habrastorage.org/webt/eq/wa/wo/eqwawo_3ky3vffm_hkkheyrhmlq.png"><br><br>  Wir haben die Möglichkeit, Tesla-Autos zu kontaktieren und noch mehr Fotos anzufordern.  Wenn Sie zufällige Fotos anfordern, erhalten Sie Bilder, auf denen das Auto in der Regel nur die Autobahn entlang fährt.  Dies wird ein zufälliger Datensatz sein und wir werden ihn markieren. <br><br>  Wenn Sie nur zufällige Mengen markieren, lernt Ihr Netzwerk eine einfache, allgemeine Verkehrssituation und funktioniert nur darin gut.  Wenn Sie ihr ein etwas anderes Beispiel zeigen, sagen wir ein Bild einer Straße, die in einem Wohngebiet abbiegt.  Ihr Netzwerk liefert möglicherweise das falsche Ergebnis.  Sie wird sagen: "Nun, ich habe schon oft gesehen, die Straße geht geradeaus." <br><br><img src="https://habrastorage.org/webt/_9/4u/x2/_94ux28ucicihvbggphmoqc5i0y.png"><br><br>  Das ist natürlich völlig falsch.  Aber wir können das neuronale Netzwerk nicht beschuldigen.  Sie weiß nicht, ob der Baum links, das Auto rechts oder die Gebäude im Hintergrund von Bedeutung sind.  Das Netzwerk weiß nichts darüber.  Wir alle wissen, dass die Markierungslinie wichtig ist und dass sie sich ein wenig zur Seite dreht.  Das Netzwerk sollte dies berücksichtigen, aber es gibt keinen Mechanismus, mit dem wir dem neuronalen Netzwerk einfach sagen können, dass diese Striche der Straßenmarkierungen wirklich wichtig sind.  Das einzige Werkzeug in unseren Händen sind beschriftete Daten. <br><br><img src="https://habrastorage.org/webt/e5/ew/d3/e5ewd3fhqw_ebegpk0heamyjafk.png"><br><br>  Wir nehmen Bilder auf, bei denen das Netzwerk fehlerhaft ist, und markieren sie korrekt.  In diesem Fall markieren wir das Wende-Markup.  Dann müssen Sie viele ähnliche Bilder in das neuronale Netzwerk übertragen.  Und im Laufe der Zeit wird sie Wissen sammeln und lernen, dieses Muster zu verstehen, um zu verstehen, dass dieser Teil des Bildes keine Rolle spielt, aber dieses Markup ist sehr wichtig.  Das Netzwerk lernt, wie man die Fahrspur richtig findet. <br><br>  Nicht nur die Größe des Trainingsdatensatzes ist wichtig.  Wir brauchen mehr als nur Millionen von Bildern.  Es muss noch viel Arbeit geleistet werden, um den Raum der Situationen abzudecken, denen ein Auto auf der Straße begegnen kann.  Sie müssen einem Computer beibringen, nachts und im Regen zu arbeiten.  Die Straße kann Licht wie ein Spiegel reflektieren, die Beleuchtung kann in weiten Grenzen variieren, die Bilder sehen sehr unterschiedlich aus. <br><br><img src="https://habrastorage.org/webt/k4/og/1f/k4og1fzgiwwt6jy_rwcefm3fndm.png"><br><br>  Wir müssen dem Computer beibringen, wie man mit Schatten, Gabeln und großen Objekten umgeht, die den größten Teil des Bildes einnehmen.  Wie man mit Tunneln oder in einem Straßenreparaturbereich arbeitet.  In all diesen Fällen gibt es keinen direkten Mechanismus, um dem Netzwerk mitzuteilen, was zu tun ist.  Wir haben nur einen riesigen Datensatz.  Wir können Bilder aufnehmen, markieren und das Netzwerk trainieren, bis es beginnt, ihre Struktur zu verstehen. <br><br>  Große und vielfältige Datenmengen helfen Netzwerken, sehr gut zu funktionieren.  Dies ist nicht unsere Entdeckung.  Experimente und Recherchen Google, Facebook, Baidu, Deepmind von Alphabet.  Alle zeigen ähnliche Ergebnisse - neuronale Netze mögen Daten, wie Quantität und Vielfalt.  Fügen Sie mehr Daten hinzu und die Genauigkeit neuronaler Netze wächst. <br><br><h2>  Sie müssen einen Autopiloten entwickeln, um das Verhalten von Autos in einer Simulation zu simulieren </h2><br>  Eine Reihe von Experten weisen darauf hin, dass wir die Simulation verwenden könnten, um die erforderlichen Daten im richtigen Maßstab zu erhalten.  Bei Tesla haben wir diese Frage wiederholt gestellt.  Wir haben unseren eigenen Simulator.  Wir verwenden häufig Simulationen, um Software zu entwickeln und zu bewerten.  Wir haben es ziemlich erfolgreich für das Training verwendet.  Aber am Ende kann beim Training von Daten für neuronale Netze nichts echte Daten ersetzen.  Simulationen haben Probleme bei der Modellierung des Aussehens, der Physik und des Verhaltens der Teilnehmer. <br><br><img src="https://habrastorage.org/webt/ob/he/xw/obhexwtzhagxn7n_z0ildcfzyl8.png"><br><br>  Die reale Welt wirft uns eine Reihe unerwarteter Situationen auf.  Schwierige Bedingungen mit Schnee, Bäumen, Wind.  Verschiedene visuelle Artefakte, die schwer zu modellieren sind.  Straßenreparaturbereiche, Büsche, Plastiktüten hängen im Wind.  Es können viele Menschen, Erwachsene, Kinder und Tiere durcheinander sein.  Das Verhalten und die Interaktion all dessen zu modellieren, ist eine absolut unlösbare Aufgabe. <br><br><img src="https://habrastorage.org/webt/2k/3r/7a/2k3r7as1159puh5ad4bf3fwrltc.png"><br><br>  Hier geht es nicht um die Bewegung eines Fußgängers.  Es geht darum, wie Fußgänger aufeinander reagieren und wie Autos aufeinander reagieren, wie sie auf Sie reagieren.  All dies ist sehr schwer zu simulieren.  Sie müssen zuerst einen Autopiloten entwickeln, um nur das Verhalten von Autos in einer Simulation zu simulieren. <br><br>  Das ist wirklich schwer.  Es können Hunde sein, exotische Tiere, und manchmal ist es nicht einmal etwas, was Sie nicht vorgeben können, es ist etwas, das Ihnen einfach nie in den Sinn kommt.  Ich wusste nicht, dass ein LKW einen LKW tragen kann, der einen LKW trägt, der einen anderen LKW trägt.  Aber in der realen Welt passieren dieses und viele andere Dinge, die schwer zu finden sind.  Die Vielfalt, die ich in den Daten sehe, die von den Autos kommen, ist einfach verrückt in Bezug auf das, was wir im Simulator haben.  Obwohl wir einen guten Simulator haben. <br><br>  <strong>Ilon:</strong> Simulation ist, als ob Sie Ihre eigenen Hausaufgaben für sich selbst erfinden würden.  Wenn Sie wissen, dass Sie so tun werden, als würden Sie sich natürlich darum kümmern.  Aber wie Andrei sagte, wissen Sie nicht, was Sie nicht wissen.  Die Welt ist sehr seltsam, es gibt Millionen von Sonderfällen.  Wenn jemand eine Fahrsimulation erstellt, die die Realität originalgetreu wiedergibt, ist dies an sich eine monumentale Leistung für die Menschheit.  Aber das kann niemand.  Es gibt einfach keinen Weg. <br><br><h2>  Flotte ist eine wichtige Datenquelle für das Training </h2><br><img src="https://habrastorage.org/webt/8u/kj/h7/8ukjh7k3qw7-sv469pyhnnbwhi0.png"><br><br>  <strong>Andrei:</strong> Damit neuronale Netze gut funktionieren, benötigen Sie einen großen, vielfältigen und realen Datensatz.  Und wenn Sie eines haben, können Sie Ihr neuronales Netzwerk trainieren und es wird sehr gut funktionieren.  Warum ist Tesla in dieser Hinsicht so besonders?  Die Antwort ist natürlich die Flotte (Flotte, Tesla-Flotte).  Wir können Daten von allen Tesla-Fahrzeugen sammeln und für Schulungen verwenden. <br><br>  Schauen wir uns ein konkretes Beispiel für die Verbesserung der Funktionsweise eines Objektdetektors an.  Auf diese Weise erhalten Sie eine Vorstellung davon, wie wir neuronale Netze trainieren, wie wir sie verwenden und wie sie mit der Zeit besser werden. <br><br>  Objekterkennung ist eine unserer wichtigsten Aufgaben.  Wir müssen die Abmessungen von Autos und anderen Objekten hervorheben, um sie zu verfolgen und zu verstehen, wie sie sich bewegen können.  Wir können Leute bitten, die Bilder zu markieren.  Die Leute werden sagen: "Hier sind Autos, hier sind Fahrräder" und so weiter.  Und wir können das neuronale Netzwerk auf diese Daten trainieren.  In einigen Fällen macht das Netzwerk jedoch falsche Vorhersagen. <br><br><img src="https://habrastorage.org/webt/7h/st/qk/7hstqk7ygew-tfoo_ibersaw86s.png"><br><br>  Wenn wir beispielsweise auf ein Auto stoßen, an dem hinten ein Fahrrad angebracht ist, erkennt unser neuronales Netzwerk zwei Objekte - ein Auto und ein Fahrrad.  So hat sie gearbeitet, als ich ankam.  Und auf seine Weise ist es richtig, denn diese beiden Objekte sind hier wirklich präsent.  Dem Autopilot-Planer ist es jedoch egal, dass dieses Fahrrad ein separates Objekt ist, das sich mit dem Auto bewegt.  Die Wahrheit ist, dass dieses Fahrrad fest mit dem Auto verbunden ist.  In Bezug auf Objekte auf der Straße ist dies ein Objekt - ein Auto. <br><br><img src="https://habrastorage.org/webt/ms/d0/oi/msd0oiytsgapqj3dczs6s_hpocc.png"><br><br>  Jetzt möchten wir viele ähnliche Objekte als „ein Auto“ markieren.  Unser Team verfolgt den folgenden Ansatz.  Wir nehmen dieses Bild oder mehrere Bilder, in denen ein solches Modell vorhanden ist.  Und wir haben einen Mechanismus für maschinelles Lernen, mit dem wir die Flotte bitten können, uns Beispiele zu liefern, die gleich aussehen.  Und die Flotte sendet Bilder als Antwort. <br><br><img src="https://habrastorage.org/webt/yt/xh/uj/ytxhujmzul8r8dpqwido3fr_rns.png"><br><br>  Hier ist ein Beispiel für sechs empfangene Bilder.  Sie alle enthalten Fahrräder, die an Autos befestigt sind.  Wir werden sie korrekt markieren und unser Detektor wird besser funktionieren.  Das Netzwerk beginnt zu verstehen, wann das Fahrrad am Auto befestigt ist und dass es sich um ein Objekt handelt.  Sie können das Netzwerk darin trainieren, vorausgesetzt, Sie haben genügend Beispiele.  Und so lösen wir solche Probleme. <br><br>  Ich spreche viel darüber, Daten von Tesla-Autos zu erhalten.  Und ich möchte gleich sagen, dass wir dieses System von Anfang an unter Berücksichtigung der Vertraulichkeit entwickelt haben.  Alle Daten, die wir für Schulungen verwenden, sind anonymisiert. <br><br>  Die Flotte schickt uns nicht nur Fahrräder auf Autos.  Wir sind ständig auf der Suche nach vielen verschiedenen Modellen.  Zum Beispiel suchen wir nach Booten - die Flotte sendet Bilder von Booten auf den Straßen.  Wir wollen Bilder von Straßenreparaturgebieten, und die Flotte sendet uns viele solcher Bilder aus der ganzen Welt.  Oder zum Beispiel Müll auf der Straße, das ist auch sehr wichtig.  Die Flotte sendet uns Bilder von Reifen, Kegeln, Plastiktüten und dergleichen auf der Straße. <br><br><img src="https://habrastorage.org/webt/aa/ne/2x/aane2xostifrgw-xjzwcklq-zbm.png"><br><br>  Wir können genug Bilder bekommen, sie richtig markieren und das neuronale Netzwerk wird lernen, wie man mit ihnen in der realen Welt arbeitet.  Wir brauchen das neuronale Netzwerk, um zu verstehen, was passiert, und um richtig zu reagieren. <br><br><h2>  Die Unsicherheit des neuronalen Netzes löst die Datenerfassung aus </h2><br>  Das Verfahren, das wir immer wieder wiederholen, um das neuronale Netzwerk zu trainieren, ist wie folgt.  Wir begannen mit einer zufälligen Reihe von Bildern, die von der Flotte empfangen wurden.  Wir markieren die Bilder, trainieren das neuronale Netz und laden es in Autos.  Wir haben Mechanismen, mit denen wir Ungenauigkeiten im Betrieb des Autopiloten erkennen.  Wenn wir feststellen, dass das neuronale Netzwerk nicht sicher ist oder ein Eingriff des Fahrers oder andere Ereignisse vorliegen, werden die Daten, für die dies geschehen ist, automatisch gesendet. <br><br><img src="https://habrastorage.org/webt/zl/ze/az/zlzeazzv1wrzsxbntqq5wtw0-50.png"><br><br>  Beispielsweise werden Tunnelmarkierungen schlecht erkannt.  Wir stellen fest, dass es ein Problem in den Tunneln gibt.  Entsprechende Bilder fallen in unsere Unit-Tests, sodass das Problem später nicht wiederholt werden kann.  Um das Problem zu beheben, benötigen wir viele Schulungsbeispiele.  Wir bitten die Flotte, uns weitere Bilder der Tunnel zu senden, sie korrekt zu markieren, sie dem Trainingsset hinzuzufügen, das Netzwerk neu zu trainieren und sie dann in Autos zu laden.  Dieser Zyklus wiederholt sich immer wieder.  Wir nennen diesen iterativen Prozess die Daten-Engine (Daten-Engine? Daten-Engine?).  Wir schalten das Netzwerk im Schattenmodus ein, erkennen Ungenauigkeiten, fordern weitere Daten an und nehmen sie in den Trainingssatz auf.  Wir tun dies für alle Arten von Vorhersagen unserer neuronalen Netze. <br><br><h2>  Automatisches Datenmarkup </h2><br>  Ich habe viel über das manuelle Markup von Bildern gesprochen.  Dies ist sowohl zeitlich als auch finanziell ein kostspieliger Prozess.  Es kann zu teuer sein.  Ich möchte darüber sprechen, wie Sie die Flotte hier nutzen können.  Die manuelle Kennzeichnung ist ein Engpass.  Wir wollen nur die Daten übertragen und automatisch markieren.  Dafür gibt es mehrere Mechanismen. <br><br>  Eines unserer jüngsten Projekte ist beispielsweise die Wiederherstellung der Erkennung.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie fahren auf der Autobahn, jemand fährt links oder rechts und er baut auf Ihre Fahrspur um. </font></font><br><br><img src="https://habrastorage.org/webt/jk/-g/y4/jk-gy4iyujnhhwpmzb0lcwpggci.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier ist ein Video, in dem der Autopilot eine Neuerstellung erkennt. Natürlich möchten wir es so schnell wie möglich entdecken. Der Ansatz zur Lösung dieses Problems besteht darin, dass wir keinen Code wie folgt schreiben: Die linke Fahrtrichtungsanzeige leuchtet, die rechte Fahrtrichtungsanzeige leuchtet, unabhängig davon, ob sich das Auto im Laufe der Zeit horizontal bewegt hat. Stattdessen verwenden wir flottenbasiertes Auto-Learning.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wie funktioniert es </font><font style="vertical-align: inherit;">Wir bitten die Flotte, uns Daten zu senden, wenn ein Umbau auf unserer Fahrspur aufgezeichnet wird. </font><font style="vertical-align: inherit;">Dann spulen wir die Zeit zurück und stellen automatisch fest, dass dieses Auto in 1,3 Sekunden vor Ihnen wieder aufgebaut wird. </font><font style="vertical-align: inherit;">Diese Daten können verwendet werden, um das neuronale Netzwerk zu trainieren. </font><font style="vertical-align: inherit;">Somit extrahiert das neuronale Netzwerk selbst die notwendigen Zeichen. </font><font style="vertical-align: inherit;">Zum Beispiel scheuert ein Auto und baut es dann wieder auf, oder es hat einen eingeschalteten Blinker. </font><font style="vertical-align: inherit;">Das neuronale Netz erfährt dies alles anhand automatisch beschrifteter Beispiele.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Schattencheck </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir bitten die Flotte, uns die Daten automatisch zu senden. Wir können ungefähr eine halbe Million Bilder sammeln, und Neuaufbauten werden auf allen markiert. Wir trainieren das Netzwerk und laden es in die Flotte. Aber bis wir es vollständig einschalten, aber im Schattenmodus ausführen. In diesem Modus macht das Netzwerk ständig Vorhersagen: "Hey, ich denke, dieses Auto wird wieder aufgebaut." Und wir suchen nach falschen Prognosen. </font></font><br><br><img src="https://habrastorage.org/webt/x0/zy/zx/x0zyzxkrebaxgrqwu3xdxuldf9u.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier ist ein Beispiel eines Clips, den wir aus dem Schattenmodus erhalten haben. Hier ist die Situation nicht wenig offensichtlich, und das Netzwerk glaubte, dass das Auto auf der rechten Seite gerade wieder aufgebaut werden würde. Und Sie werden vielleicht bemerken, dass er leicht mit der Markierungslinie flirtet. Das Netzwerk reagierte darauf und schlug vor, dass das Auto bald auf unserer Fahrspur sein würde. Dies ist jedoch nicht geschehen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Netzwerk arbeitet im Schattenmodus und erstellt Prognosen. Unter ihnen sind falsch positiv und falsch negativ. Manchmal reagiert das Netzwerk fehlerhaft und manchmal überspringt es Ereignisse. Alle diese Fehler lösen eine Datenerfassung aus. Daten werden ohne zusätzlichen Aufwand markiert und in das Training integriert. Und wir gefährden dabei keine Menschen. Wir trainieren das Netzwerk neu und verwenden wieder den Schattenmodus. Wir können dies mehrmals wiederholen und Fehlalarme unter realen Verkehrsbedingungen auswerten. Sobald die Anzeigen zu uns passen, klicken wir einfach auf den Schalter und lassen das Netzwerk das Auto steuern.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben vor ungefähr drei Monaten eine der ersten Versionen des Wiederherstellungsdetektors auf den Markt gebracht. </font><font style="vertical-align: inherit;">Wenn Sie feststellen, dass die Maschine den Wiederaufbau viel besser erkennt, ist dies ein Training mit der Flotte in Aktion. </font><font style="vertical-align: inherit;">Dabei wurde keine einzige Person verletzt. </font><font style="vertical-align: inherit;">Es ist nur eine Menge Training von neuronalen Netzen basierend auf realen Daten, unter Verwendung des Schattenmodus und Analyse der Ergebnisse. </font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ilon:</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tatsächlich trainieren alle Fahrer ständig das Netzwerk. </font><font style="vertical-align: inherit;">Es spielt keine Rolle, ob der Autopilot ein- oder ausgeschaltet ist. </font><font style="vertical-align: inherit;">Das Netzwerk lernt. </font><font style="vertical-align: inherit;">Jede Meile, die von einer Maschine mit HW2.0 oder höher zurückgelegt wird, bildet das Netzwerk aus.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Während Sie fahren, markieren Sie tatsächlich die Daten </font></font></h2><br><br><img src="https://habrastorage.org/webt/-g/1h/i8/-g1hi870mojfe0cnotbafoab73u.png"><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrei:</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ein weiteres interessantes Projekt, das wir im Flottenschulungsprogramm verwenden, ist die Vorhersage des Weges. Wenn Sie fahren, markieren Sie tatsächlich die Daten. Sie sagen uns, wie man in verschiedenen Fahrsituationen fährt. Hier biegt einer der Fahrer an der Kreuzung links ab. Wir haben ein vollständiges Video aller Kameras und kennen den Weg, den der Fahrer gewählt hat. Wir wissen auch, wie schnell und drehwinkel das Lenkrad war. Wir bringen alles zusammen und verstehen den Weg, den eine Person in dieser Verkehrssituation gewählt hat. Und wir können dies als Unterricht mit einem Lehrer nutzen. Wir erhalten nur die erforderliche Datenmenge von der Flotte, trainieren das Netzwerk auf diesen Trajektorien und danach kann das neuronale Netzwerk den Pfad vorhersagen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dies nennt man Nachahmungslernen. Wir nehmen die Flugbahnen von Menschen aus der realen Welt und versuchen, sie nachzuahmen. Und wieder können wir unseren iterativen Ansatz verfolgen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier ist ein Beispiel für die Vorhersage eines Pfades unter schwierigen Straßenbedingungen. Im Video überlagern wir die Netzwerkprognose. Grün markiert den Pfad, den das Netzwerk verschieben würde. </font></font><br><br><img src="https://habrastorage.org/webt/vq/_5/h-/vq_5h-j22m3xlryz5aszlqqwls8.png"><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ilon: Der</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wahnsinn ist, dass das Netzwerk einen Pfad vorhersagt, den es nicht einmal sehen kann. Mit unglaublich hoher Präzision. Sie sieht nicht, was sich um die Kurve befindet, glaubt jedoch, dass die Wahrscheinlichkeit dieser Flugbahn extrem hoch ist. Und es stellt sich als richtig heraus. Heute werden Sie es in Autos sehen, wir werden Augmented Vision einschließen, damit Sie die Markierungen und Flugbahnvorhersagen sehen können, die dem Video überlagert sind. </font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrei:</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tatsächlich passiert unter der Haube das meiste und</font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ilon:</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Eigentlich ist es ein bisschen beängstigend (Andrey lacht). </font></font><br><br> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew:</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Natürlich vermisse ich viele Details. Möglicherweise möchten Sie nicht alle Treiber hintereinander zum Markieren verwenden, sondern das Beste imitieren. Wir verwenden eine Reihe von Möglichkeiten, um diese Daten vorzubereiten. Interessanterweise ist diese Prognose tatsächlich dreidimensional. Dies ist ein Pfad im dreidimensionalen Raum, den wir in 2D anzeigen. Das Netzwerk verfügt jedoch über Informationen zur Steigung, was für das Fahren sehr wichtig ist.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vorhersage der Art und Weise, wie derzeit in Autos funktioniert. </font><font style="vertical-align: inherit;">Übrigens, als Sie vor ungefähr fünf Monaten die Kreuzung auf der Autobahn passierten, konnte Ihr Auto damit nicht fertig werden. </font><font style="vertical-align: inherit;">Jetzt kann es. </font><font style="vertical-align: inherit;">Dies ist die Vorhersage des Weges in Aktion in Ihren Autos. </font><font style="vertical-align: inherit;">Wir haben es vor einiger Zeit eingeschaltet. </font><font style="vertical-align: inherit;">Und heute können Sie sehen, wie es an Kreuzungen funktioniert. </font><font style="vertical-align: inherit;">Ein wesentlicher Teil des Trainings zur Überwindung von Kreuzungen wird durch automatisches Markieren von Daten erzielt. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es gelang mir, über die Schlüsselkomponenten des neuronalen Netzwerktrainings zu sprechen. </font><font style="vertical-align: inherit;">Sie benötigen einen großen, vielfältigen Satz realer Daten. </font><font style="vertical-align: inherit;">In Tesla bekommen wir es mit der Flotte. </font><font style="vertical-align: inherit;">Wir verwenden die Daten-Engine, den Schattenmodus und das automatische Markup von Daten mithilfe der Flotte. </font><font style="vertical-align: inherit;">Und wir können diesen Ansatz skalieren.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tiefenwahrnehmung per Video </font></font></h2><br><img src="https://habrastorage.org/webt/oc/ft/4s/ocft4sltp3pprppnnk5y0jsj0rs.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Im nächsten Teil meiner Rede werde ich über das Wahrnehmen von Tiefe durch Sehen sprechen. Sie wissen wahrscheinlich, dass Autos mindestens zwei Arten von Sensoren verwenden. Eine ist Helligkeit Videokameras, und die andere ist Lidar, die viele Unternehmen verwenden. Lidar gibt Punktmessungen der Entfernung um Sie herum. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich möchte darauf hinweisen, dass Sie alle nur mit Ihrem neuronalen Netzwerk und Ihrer Vision hierher gekommen sind. Du hast nicht mit Lasern aus deinen Augen geschossen und bist trotzdem hier gelandet.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es ist klar, dass das menschliche neuronale Netzwerk Distanz extrahiert und die Welt ausschließlich durch Sehen als dreidimensional wahrnimmt. Sie benutzt eine Reihe von Tricks. Ich werde kurz über einige von ihnen sprechen. Zum Beispiel haben wir zwei Augen, sodass Sie zwei Bilder der Welt vor sich haben. Ihr Gehirn kombiniert diese Informationen, um eine Schätzung der Entfernungen zu erhalten. Dazu werden Punkte in zwei Bildern trianguliert. Bei vielen Tieren befinden sich die Augen an den Seiten und ihr Sichtfeld ist leicht gekreuzt. Diese Tiere verwenden Struktur (Bewegung). Sie bewegen ihren Kopf, um viele Bilder der Welt von verschiedenen Punkten aus zu erhalten, und können auch Triangulation anwenden.</font></font><br><br><img src="https://habrastorage.org/webt/gl/sq/-q/glsq-qyu337vx5gcd3bycvqaffu.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Selbst wenn ein Auge geschlossen und völlig bewegungslos ist, behalten Sie ein gewisses Gefühl der Wahrnehmung von Distanz bei. Wenn Sie ein Auge schließen, scheint es Ihnen nicht, dass ich zwei Meter näher oder hundert Meter weiter gekommen bin. Dies liegt daran, dass es viele leistungsstarke monokulare Techniken gibt, die auch Ihr Gehirn anwendet. Zum Beispiel eine gemeinsame optische Täuschung mit zwei identischen Streifen auf dem Hintergrund der Schiene. Ihr Gehirn wertet die Szene aus und erwartet, dass eine von ihnen größer ist als die andere, da die Eisenbahnlinien in der Ferne verschwinden. Ihr Gehirn macht vieles automatisch, und künstliche neuronale Netze können das auch. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ich werde drei Beispiele geben, wie Sie die Wahrnehmung von Tiefe im Video erreichen können. Ein klassischer Ansatz und zwei basierend auf neuronalen Netzen.</font></font><br><br><img src="https://habrastorage.org/webt/ns/ld/x0/nsldx0ejkyg1fvxoy-_7id-uds4.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir können in wenigen Sekunden einen Videoclip aufnehmen und die Umgebung mithilfe von Triangulations- und Stereovisionsmethoden in 3D neu erstellen. </font><font style="vertical-align: inherit;">Wir wenden ähnliche Methoden im Auto an. </font><font style="vertical-align: inherit;">Die Hauptsache ist, dass das Signal wirklich die notwendigen Informationen hat, die einzige Frage ist, sie zu extrahieren.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Entfernungsmarkierung mit Radar </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wie gesagt, neuronale Netze sind ein sehr leistungsfähiges visuelles Erkennungswerkzeug. Wenn Sie möchten, dass sie die Entfernung erkennen, müssen Sie die Entfernungen markieren. Anschließend lernt das Netzwerk, wie dies zu tun ist. Nichts schränkt Netzwerke in ihrer Fähigkeit ein, Entfernungen vorherzusagen, außer Daten markiert zu haben. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir verwenden ein nach vorne gerichtetes Radar. Dieses Radar misst und markiert die Entfernung zu Objekten, die das neuronale Netzwerk sieht. Anstatt den Leuten zu sagen, dass dieses Auto etwa 25 Meter entfernt ist, können Sie die Daten mithilfe von Sensoren viel besser markieren. Radar funktioniert in dieser Entfernung sehr gut. Sie markieren die Daten und trainieren das neuronale Netzwerk. Wenn Sie über genügend Daten verfügen, kann ein neuronales Netzwerk die Entfernung sehr gut vorhersagen.</font></font><br><br><img src="https://habrastorage.org/webt/ih/pp/je/ihppjemgjkcaefowadynpdtu5le.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In diesem Bild zeigen die Kreise die vom Radar empfangenen Objekte, und die Quader sind die vom neuronalen Netzwerk empfangenen Objekte. </font><font style="vertical-align: inherit;">Und wenn das Netzwerk gut funktioniert, sollten in der Draufsicht die Positionen der Quader mit der Position der Kreise übereinstimmen, die wir beobachten. </font><font style="vertical-align: inherit;">Neuronale Netze eignen sich sehr gut für die Entfernungsvorhersage. </font><font style="vertical-align: inherit;">Sie können die Größe verschiedener Fahrzeuge lernen und anhand ihrer Größe auf dem Bild die Entfernung ziemlich genau bestimmen.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Selbstüberwachung </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der letzte Mechanismus, über den ich sehr kurz sprechen werde, ist etwas technischer. Es gibt nur wenige Artikel, hauptsächlich in den letzten ein oder zwei Jahren, über diesen Ansatz. Es heißt Selbstüberwachung. </font></font><br><br><img src="https://habrastorage.org/webt/ll/vt/qy/llvtqyhtg50ssityr07udz-ssqs.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Was ist hier los? Sie laden unbeschriftete Rohvideos in das neuronale Netzwerk hoch. Und das Netzwerk kann immer noch lernen, Entfernungen zu erkennen. Ohne auf Details einzugehen, besteht die Idee darin, dass ein neuronales Netzwerk die Entfernung in jedem Bild dieses Videos vorhersagt. Wir haben keine Tags zur Überprüfung, aber es gibt eine Ziel-Zeit-Konsistenz. Unabhängig davon, welche Entfernung das Netzwerk vorhersagt, muss sie im gesamten Video konsistent sein. Die einzige Möglichkeit, konsistent zu sein, besteht darin, die Entfernung korrekt vorherzusagen. Das Netzwerk sagt automatisch die Tiefe für alle Pixel voraus. Wir haben es geschafft, es zu reproduzieren, und es funktioniert ziemlich gut.</font></font><br><br><h2>    —     </h2><br>  Zusammenfassend.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Menschen benutzen Vision, keine Laser. Ich möchte betonen, dass eine leistungsstarke visuelle Erkennung für autonomes Fahren unbedingt erforderlich ist. Wir brauchen neuronale Netze, die die Umwelt wirklich verstehen. </font></font><br><br><img src="https://habrastorage.org/webt/5q/aq/b0/5qaqb0qjwt-a7c6tpihpswc_zba.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Daten aus dem Lidar sind viel weniger mit Informationen gesättigt. Ist diese Silhouette unterwegs, ist es eine Plastiktüte oder ein Reifen? Lidar gibt Ihnen einfach ein paar Punkte, während die Vision Ihnen sagen kann, was es ist. Blickt dieser Typ auf einem Fahrrad zurück, versucht er die Spur zu wechseln oder fährt er geradeaus? Was bedeuten diese Schilder in der Straßenreparaturzone und wie soll ich mich hier verhalten? Ja, die gesamte Straßeninfrastruktur ist für den visuellen Verbrauch ausgelegt. Alle Schilder, Ampeln, alles ist zum Sehen da, hier sind alle Informationen. Und wir müssen es benutzen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dieses Mädchen ist leidenschaftlich am Telefon, wird sie auf die Straße treten? </font><font style="vertical-align: inherit;">Antworten auf solche Fragen können nur mit Hilfe des Sehens gefunden werden und sind für Autopilot Level 4-5 erforderlich. </font><font style="vertical-align: inherit;">Und genau das entwickeln wir bei Tesla. </font><font style="vertical-align: inherit;">Wir tun dies durch umfangreiches Training für neuronale Netze, unsere Daten-Engine und Flottenunterstützung. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In dieser Hinsicht ist Lidar ein Versuch, den Weg zu beschneiden. </font><font style="vertical-align: inherit;">Es umgeht die grundlegende Aufgabe der Bildverarbeitung, deren Lösung für das autonome Fahren notwendig ist. </font><font style="vertical-align: inherit;">Es gibt ein falsches Gefühl des Fortschritts. </font><font style="vertical-align: inherit;">Lidar eignet sich nur für schnelle Demonstrationen.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Der Fortschritt ist proportional zur Häufigkeit von Kollisionen mit komplexen Situationen in der realen Welt. </font></font></h2><br><img src="https://habrastorage.org/webt/1t/io/en/1tioensdyfmt5eei36zaezrk1py.png"><br><br>  Wenn ich alles, was gesagt wurde, auf eine Folie passen wollte, würde es so aussehen.  Wir benötigen Level 4-5-Systeme, die in 99,9999% der Fälle alle möglichen Situationen bewältigen können.  Das Streben nach den letzten Neunen wird schwierig und sehr schwierig sein.  Dies erfordert ein sehr leistungsfähiges Bildverarbeitungssystem. <br><br>  Hier sehen Sie Bilder, die Ihnen auf dem Weg zu den geschätzten Dezimalstellen begegnen können.  Zuerst fahren nur Autos vorwärts, dann sehen diese Autos etwas ungewöhnlich aus, auf ihnen erscheinen Fahrräder, Autos auf Autos.  Dann stößt man auf wirklich seltene Ereignisse wie umgekehrte Autos oder sogar Autos im Sprung.  Wir treffen viel von allem in den Daten, die aus der Flotte stammen. <br><br>  Und wir sehen diese seltenen Ereignisse viel häufiger als unsere Konkurrenten.  Dies bestimmt die Geschwindigkeit, mit der wir Daten erhalten und Probleme durch Training neuronaler Netze beheben können.  Die Geschwindigkeit des Fortschritts ist proportional zur Häufigkeit, mit der Sie in der realen Welt mit schwierigen Situationen konfrontiert sind.  Und wir begegnen ihnen öfter als jeder andere.  Daher ist unser Autopilot besser als andere.  Vielen Dank. <br><br><h2>  Fragen und Antworten </h2><br><br>  <strong>Frage:</strong> Wie viele Daten sammeln Sie durchschnittlich von jedem Auto? <br><br>  <strong>Andrew:</strong> Es geht nicht nur um die Datenmenge, es geht um Vielfalt.  Irgendwann haben Sie bereits genug Bilder vom Fahren entlang der Autobahn, das Netzwerk versteht sie, es ist nicht mehr notwendig.  Daher konzentrieren wir uns strategisch darauf, die richtigen Daten zu erhalten.  Und unsere Infrastruktur mit einer ziemlich komplizierten Analyse ermöglicht es uns, die Daten zu erhalten, die wir gerade benötigen.  Hier geht es nicht um große Datenmengen, sondern um sehr gut ausgewählte Daten. <br><br>  <strong>Frage:</strong> Ich frage mich, wie Sie das Problem des Spurwechsels lösen werden.  Immer wenn ich versuche, mich wieder in einen dichten Strom zu verwandeln, haben sie mich abgeschnitten.  Menschliches Verhalten wird auf den Straßen von Los Angeles irrational.  Der Autopilot möchte sicher fahren, und Sie müssen es fast unsicher machen. <br><br>  <strong>Andrew:</strong> Ich habe über die Daten-Engine als Training für neuronale Netze gesprochen.  Aber wir machen dasselbe auf Software-Ebene.  Alle Parameter, die sich auf die Auswahl auswirken, z. B. wann neu erstellt werden soll, wie aggressiv.  Wir ändern sie auch im Schattenmodus und beobachten, wie gut sie funktionieren, und passen die Heuristik an.  Tatsächlich ist es eine schwierige Aufgabe, solche Heuristiken für den allgemeinen Fall zu entwerfen.  Ich denke, wir müssen Flottentraining nutzen, um solche Entscheidungen zu treffen.  Wann wechseln die Leute die Spur?  In welchen Szenarien?  Wann empfinden sie einen Spurwechsel als unsicher?  Schauen wir uns einfach eine große Datenmenge an und bringen Sie dem Klassifikator für maschinelles Lernen bei, zu unterscheiden, wann die Wiederherstellung sicher ist.  Diese Klassifizierer können viel besseren Code schreiben als Menschen, da sie auf einer großen Datenmenge zum Verhalten von Treibern beruhen. <br><br>  <strong>Ilon:</strong> Wahrscheinlich werden wir den Modus "Verkehr in Los Angeles" haben.  Irgendwo nach dem Mad Max-Modus.  Ja, Mad Max würde es in Los Angeles schwer haben. <br><br>  <strong>Andrei</strong> muss Kompromisse eingehen.  Sie möchten keine unsicheren Situationen schaffen, sondern nach Hause kommen.  Und die Tänze, die Menschen gleichzeitig aufführen, sind sehr schwer zu programmieren.  Ich denke, das Richtige ist maschinelles Lernen.  Wo wir uns nur die vielen Möglichkeiten ansehen, wie Menschen dies tun, und versuchen, sie nachzuahmen. <br><br>  <strong>Ilon:</strong> Jetzt sind wir ein wenig konservativ und wenn unser Vertrauen wächst, wird es möglich sein, ein aggressiveres Regime zu wählen.  Benutzer können es auswählen.  In aggressiven Modi besteht beim Versuch, im Stau die Spur zu wechseln, eine geringe Wahrscheinlichkeit, dass der Flügel faltig wird.  Keine Gefahr eines schweren Unfalls.  Sie haben die Wahl, ob Sie einer Chance ungleich Null zustimmen, den Flügel zu zerdrücken.  Leider ist dies der einzige Weg, um auf der Autobahn im Verkehr zu stecken. <br><br>  <strong>Frage:</strong> Könnte es bei einer dieser Neunen nach dem Dezimalpunkt passieren, dass Lidar nützlich ist?  Die zweite Frage ist, wenn Lidars wirklich wertlos sind, was wird mit denen geschehen, die ihre Entscheidungen darauf aufbauen? <br><br>  <strong>Ilon:</strong> Sie werden alle Lidars loswerden, das ist meine Prognose, die Sie aufschreiben können.  Ich muss sagen, ich hasse Lidar nicht so sehr, wie es scheinen mag.  SpaceX Dragon verwendet das Lidar, um zur ISS zu gelangen und anzudocken.  SpaceX hat dafür ein eigenes Lidar von Grund auf neu entwickelt.  Ich habe dieses Projekt persönlich geleitet, weil Lidar in diesem Szenario Sinn macht.  Aber in Autos ist es verdammt dumm.  Es ist teuer und nicht notwendig.  Und wie Andrei sagte, wird der Lidar unbrauchbar, sobald Sie das Video bearbeiten.  Sie haben teure Ausrüstung, die für das Auto unbrauchbar ist. <br><br>  Wir haben ein Vorwärtsradar.  Es ist kostengünstig und nützlich, insbesondere bei schlechten Sichtverhältnissen.  Nebel, Staub oder Schnee, das Radar kann durch sie hindurchsehen.  Wenn Sie die aktive Photonenerzeugung verwenden möchten, verwenden Sie nicht die Wellenlänge des sichtbaren Lichts.  Denn mit passiver Optik haben Sie sich bereits um alles im sichtbaren Spektrum gekümmert.  Jetzt ist es besser, eine Wellenlänge mit guten Durchdringungseigenschaften wie Radar zu verwenden.  Lidar ist einfach die aktive Erzeugung von Photonen im sichtbaren Spektrum.  Möchten Sie aktiv Photonen erzeugen, tun Sie dies außerhalb des sichtbaren Spektrums.  Mit 3,8 mm gegenüber 400-700 nm können Sie bei schlechten Wetterbedingungen sehen.  Deshalb haben wir ein Radar.  Sowie zwölf Ultraschallsensoren für die unmittelbare Umgebung.  Das Radar ist in Bewegungsrichtung am nützlichsten, da Sie sich direkt sehr schnell bewegen. <br><br>  Wir haben das Thema Sensoren schon oft angesprochen.  Gibt es genug davon?  Haben wir alles was wir brauchen?  Müssen Sie noch etwas hinzufügen?  Hmmm.  Genug. <br><br>  <strong>Frage:</strong> Es scheint, dass die Autos eine Art Berechnung durchführen, um zu bestimmen, welche Informationen Sie senden sollen.  Wird dies in Echtzeit oder basierend auf gespeicherten Informationen durchgeführt? <br><br>  <strong>Andrey:</strong> Berechnungen werden in Echtzeit in den Autos selbst durchgeführt.  Wir vermitteln die Bedingungen, die uns interessieren, und die Autos führen alle notwendigen Berechnungen durch.  Wenn sie dies nicht tun würden, müssten wir alle Daten hintereinander übertragen und in unserem Back-End verarbeiten.  Das wollen wir nicht. <br><br>  <strong>Ilon:</strong> Wir haben vierhundertfünfundzwanzigtausend Autos mit HW2.0 +.  Dies bedeutet, dass sie über acht Kameras, ein Radar, Ultraschallsensoren und mindestens einen nVidia-Computer verfügen.  Es reicht zu berechnen, welche Informationen wichtig sind und welche nicht.  Sie komprimieren wichtige Informationen und senden sie zur Schulung an das Netzwerk.  Dies ist ein enormer Grad an Datenkomprimierung aus der realen Welt. <br><br>  <strong>Frage:</strong> Sie haben dieses Netzwerk aus Hunderttausenden von Computern, das einem leistungsstarken verteilten Rechenzentrum ähnelt.  Sehen Sie die Anwendung für andere Zwecke als den Autopiloten? <br><br>  <strong>Ilon:</strong> Ich nehme an, das könnte für etwas anderes verwendet werden.  Während wir uns auf den Autopiloten konzentrieren.  Sobald wir es auf das richtige Niveau gebracht haben, können wir über andere Anwendungen nachdenken.  Bis dahin werden es Millionen oder Dutzende Millionen Autos mit HW3.0 oder FSDC sein. <br><br>  <strong>Frage:</strong> Verkehr berechnen? <br><br>  <strong>Ilon:</strong> Ja vielleicht.  Es könnte so etwas wie AWS (Amazon Web Services) sein. <br><br>  <strong>Frage:</strong> Ich bin ein Model 3-Fahrer in Minnesota, wo es viel Schnee gibt.  Die Kamera und das Radar können die Straßenmarkierungen durch den Schnee nicht sehen.  Wie werden Sie dieses Problem lösen?  Verwenden Sie hochgenaues GPS? <br><br>  <strong>Andrew:</strong> Schon heute verhält sich der Autopilot auf einer schneebedeckten Straße ziemlich gut.  Selbst wenn die Markierungen bei starkem Regen verborgen oder ausgefranst oder mit Wasser bedeckt sind, verhält sich der Autopilot immer noch relativ gut.  Wir haben die verschneite Straße mit unserer Daten-Engine noch nicht speziell bewältigt.  Aber ich bin sicher, dass dieses Problem gelöst werden kann.  Denn wenn Sie in vielen Bildern einer verschneiten Straße eine Person fragen, wo die Markierungen sein sollen, wird sie es Ihnen zeigen.  Die Leute sind sich einig, wo Markierungslinien gezogen werden sollen.  Und während die Leute Ihre Daten vereinbaren und markieren können, kann das neuronale Netzwerk dies lernen und funktioniert gut.  Die Frage ist nur, ob das ursprüngliche Signal genügend Informationen enthält.  Genug für einen Personenanmerker?  Wenn die Antwort ja lautet, funktioniert das neuronale Netzwerk einwandfrei. <br><br>  <strong>Ilon: Das</strong> Quellensignal enthält mehrere wichtige Informationsquellen.  Also Markup, das ist nur einer von ihnen.  Die wichtigste Quelle ist die Auffahrt.  Wohin Sie gehen können und wohin Sie nicht können.  Wichtiger als Markup.  Die Straßenerkennung funktioniert sehr gut.  Ich denke, besonders nach dem kommenden Winter wird es unglaublich funktionieren.  Wir werden uns fragen, wie das so gut funktionieren kann.  Das ist einfach verrückt. <br><br>  <strong>Andrew:</strong> Es geht nicht einmal um die Fähigkeit von Menschen, sich zu markieren.  Solange Sie als Person diesen Abschnitt der Straße überwinden können.  Die Flotte wird von Ihnen lernen.  Wir wissen, wie Sie hierher gefahren sind.  Und Sie haben offensichtlich Vision dafür verwendet.  Sie haben das Markup nicht gesehen, aber Sie haben die Geometrie der gesamten Szene verwendet.  Sie sehen, wie sich die Straße biegt, wie sich andere Autos um Sie herum befinden.  Das neuronale Netzwerk hebt automatisch alle diese Muster hervor. Sie müssen nur genügend Daten darüber abrufen, wie Menschen solche Situationen überwinden. <br><br>  <strong>Ilon:</strong> Es ist sehr wichtig, sich nicht fest an GPS zu halten.  GPS-Fehler können sehr bedeutend sein.  Und die tatsächliche Verkehrssituation kann unvorhersehbar sein.  Es kann eine Straßenreparatur oder ein Umweg sein.  Wenn das Auto zu stark auf GPS angewiesen ist, ist dies eine schlechte Situation.  Sie bitten um Ärger.  GPS ist nur als Hinweis zu verwenden. <br><br>  <strong>Frage:</strong> Einige Ihrer Konkurrenten sprechen darüber, wie sie hochauflösende Karten verwenden, um die Wahrnehmung und die Pfadplanung zu verbessern.  Verwenden Sie etwas Ähnliches in Ihrem System? Sehen Sie darin einen Nutzen?  Gibt es Bereiche, in denen Sie mehr Daten haben möchten, nicht aus der Flotte, sondern so etwas wie Karten? <br><br>  <strong>Ilon:</strong> Ich denke, hochauflösende Karten sind eine sehr schlechte Idee.  Das System wird extrem instabil.  Sie können sich nicht an Änderungen anpassen, wenn Sie an GPS und hochauflösende Karten angeschlossen sind und der Sicht keine Priorität einräumen.  Vision ist das, was alles tun sollte.  Markup ist nur eine Richtlinie, nicht das Wichtigste.  Wir haben versucht, Markup-Karten zu verwenden, und schnell festgestellt, dass dies ein großer Fehler war.  Wir haben sie komplett aufgegeben. <br><br>  <strong>Frage: Es</strong> ist sehr nützlich zu verstehen, wo sich die Objekte befinden und wie sich die Autos bewegen.  Aber was ist mit dem Verhandlungsaspekt?  Während des Parkens, an Kreisverkehren und in anderen Situationen, in denen Sie mit anderen Autos interagieren, die Menschen fahren.  Es ist mehr eine Kunst als eine Wissenschaft. <br><br>  <strong>Ilon:</strong> Es funktioniert ziemlich gut.  Wenn Sie Situationen mit Umlagerungen usw. betrachten, kommt der Autopilot normalerweise zurecht. <br><br>  <strong>Andrew:</strong> Jetzt verwenden wir viel maschinelles Lernen, um eine Vorstellung von der realen Welt zu bekommen.  Darüber hinaus haben wir einen Planer und Controller sowie viele Heuristiken zum Fahren, zur Berücksichtigung anderer Autos usw.  Und genau wie bei der Mustererkennung gibt es hier viele Fälle, die nicht dem Standard entsprechen. Es ist wie ein Spiel mit Falken und Tauben, das Sie mit anderen Menschen spielen.  Wir sind zuversichtlich, dass wir letztendlich flottenbasiertes Training einsetzen werden, um dieses Problem zu lösen.  Handschriftheuristiken ruhen schnell auf einem Plateau. <br><br>  <strong>Frage:</strong> Haben Sie einen Platooning-Modus?  Ist das System dazu in der Lage? <br><br>  <strong>Andrei:</strong> Ich bin absolut sicher, dass wir ein solches Regime schaffen können.  Aber noch einmal, wenn Sie nur das Netzwerk trainieren, um Menschen zu imitieren.  Die Leute werden angeheftet und fahren vor dem Auto, und das Netzwerk erinnert sich an dieses Verhalten.  Es ist eine Art Magie darin, alles passiert von selbst.  Verschiedene Probleme sind eins. Sammeln Sie einfach den Datensatz und trainieren Sie damit das neuronale Netzwerk. <br><br>  <strong>Ilon:</strong> Drei Schritte zum autonomen Fahren.  Die erste besteht darin, diese Funktionalität einfach zu implementieren.  Das zweite ist, es so weit zu bringen, dass eine Person in einem Auto überhaupt nicht auf die Straße achten muss.  Und das dritte ist, die Zuverlässigkeit zu zeigen, die die Regulierungsbehörden überzeugt.  Dies sind drei Ebenen.  Wir erwarten, in diesem Jahr das erste Niveau zu erreichen.  Und wir gehen davon aus, dass wir irgendwann im zweiten Quartal nächsten Jahres ein gewisses Maß an Selbstvertrauen erreichen werden, wenn eine Person ihre Hände nicht mehr am Lenkrad halten und auf die Straße schauen muss.  Danach erwarten wir bis Ende nächsten Jahres zumindest in einigen Ländern eine behördliche Genehmigung.  Das sind meine Erwartungen. <br><br>  Bei Lastkraftwagen ist es wahrscheinlich, dass das Konvoi-Regime früher als alles andere von den Aufsichtsbehörden genehmigt wird.  Vielleicht können Sie für lange Fahrten einen Fahrer im Kopfwagen und 4 Sattelschlepper im Konvoimodus hinter sich einsetzen. <br><br>  <strong>Frage:</strong> Ich bin sehr beeindruckt von der Verbesserung des Autopiloten.  Letzte Woche bin ich auf der rechten Spur der Autobahn gefahren und es gab eine Einfahrt.  Mein Modell 3 konnte zwei Autos erkennen, die auf die Autobahn fuhren, und wurde langsamer, so dass ein Auto leise vor mir und das andere hinter mir gebaut wurde.  Dann dachte ich, verdammt, das ist verrückt, ich wusste nicht, dass mein Modell 3 dazu in der Lage ist. <br><br>  Aber in der gleichen Woche fuhr ich wieder auf der rechten Spur, und es gab eine Verengung, meine rechte Spur verschmolz mit der linken.  Und mein Model 3 konnte nicht richtig reagieren, ich musste eingreifen.  Können Sie sagen, wie Tesla dieses Problem lösen kann? <br><br>  <strong>Andrew:</strong> Ich habe über die Datenerfassungsinfrastruktur gesprochen.  Wenn Sie eingegriffen haben, haben wir höchstwahrscheinlich diesen Clip bekommen.  Er ging zum Beispiel in die Statistik ein, mit welcher Wahrscheinlichkeit wir korrekt in den Strom fließen.  Wir schauen uns diese Zahlen an, schauen uns die Clips an und sehen, was falsch ist.  Und wir versuchen, das Verhalten zu korrigieren, um eine Verbesserung im Vergleich zu den Benchmarks zu erreichen. <br><br>  <strong>Ilon:</strong> Nun, wir haben eine weitere Präsentation über Software.  Wir hatten eine Präsentation über Geräte mit Pete, dann neuronale Netze mit Andrey und jetzt folgt Software mit Stuart. <br>  ... </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de450796/">https://habr.com/ru/post/de450796/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de450784/index.html">Wie verwaltet Netflix seine Zuschauer so gut?</a></li>
<li><a href="../de450786/index.html">Unterschiede zwischen Fluent und gettext</a></li>
<li><a href="../de450788/index.html">Abhängigkeitsinjektion mit DITranquillity</a></li>
<li><a href="../de450790/index.html">Hydrogel, Blaubeeren und eine Prise Kurkuma: Künstliches Gefäßsystem</a></li>
<li><a href="../de450794/index.html">Wahl ist böse</a></li>
<li><a href="../de450798/index.html">Maschinelles Lernen in der mobilen Entwicklung: Perspektiven und Dezentralisierung</a></li>
<li><a href="../de450800/index.html">Entwicklung von Microservices mit BDD und IOD</a></li>
<li><a href="../de450802/index.html">Legacy-Ausfall</a></li>
<li><a href="../de450804/index.html">3D-Metalldruck in der Automobilindustrie: klein anfangen</a></li>
<li><a href="../de450806/index.html">Wenn eine Umgebungsvariable den Prozess um das 40-fache beschleunigt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
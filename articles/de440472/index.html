<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üå¥ üò• üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø Implementierung von seq2seq-Modellen in Tensorflow üìú üë®üèº‚Äç‚öñÔ∏è üõÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Datengenerierung mithilfe eines wiederkehrenden neuronalen Netzwerks wird immer beliebter und wird in vielen Bereichen der Informatik eingesetzt. ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Implementierung von seq2seq-Modellen in Tensorflow</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440472/"><p>  Die Datengenerierung mithilfe eines wiederkehrenden neuronalen Netzwerks wird immer beliebter und wird in vielen Bereichen der Informatik eingesetzt.  Seit dem Beginn der Geburt des seq2seq-Konzepts im Jahr 2014 sind nur f√ºnf Jahre vergangen, aber die Welt hat viele Anwendungen gesehen, angefangen bei klassischen Modellen der √úbersetzung und Spracherkennung bis hin zur Erstellung von Beschreibungen von Objekten in Fotografien. </p><br><p> Andererseits gewann die von Google speziell f√ºr die Entwicklung neuronaler Netze ver√∂ffentlichte Tensorflow-Bibliothek im Laufe der Zeit an Popularit√§t.  Nat√ºrlich konnten Google-Entwickler ein so beliebtes Paradigma wie seq2seq nicht ignorieren, daher bietet die Tensorflow-Bibliothek Klassen f√ºr die Entwicklung innerhalb dieses Paradigmas.  Dieser Artikel beschreibt dieses Klassensystem. </p><a name="habracut"></a><br><h2 id="rekurentnye-seti">  Wiederkehrende Netzwerke </h2><br><p>  Gegenw√§rtig sind wiederkehrende Netze einer der bekanntesten und praktischsten Formalismen f√ºr den Aufbau tiefer neuronaler Netze.  Rekursive Netzwerke sind f√ºr die Verarbeitung serieller Daten ausgelegt. Daher enth√§lt eine rekursive Zelle im Gegensatz zu einer normalen Zelle (Neuron), die Daten als Eingabe empf√§ngt und das Ergebnis von Berechnungen ausgibt, zwei Eingaben und zwei Ausgaben. </p><br><p>  Eine der Eingaben repr√§sentiert die Daten des aktuellen Elements der Sequenz, und die zweite Eingabe wird als <i>Zustand bezeichnet</i> und als Ergebnis der Zellenberechnungen f√ºr das vorherige Element der Sequenz √ºbertragen. </p><br><img src="https://habrastorage.org/getpro/habr/post_images/684/601/aa6/684601aa63886d86a1b4dafcf8ab079c.png" width="100" alt="Bild"><br><p>  Die Abbildung zeigt Zelle A, f√ºr die die Daten eines Sequenzelements eingegeben werden <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhgqKLpekqlgSn68vBtd-J2OHEuKUg#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhgqKLpekqlgSn68vBtd-J2OHEuKUg#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-1"> x_t </script>  sowie den hier nicht angegebenen Zustand <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>s</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mo>&amp;#x2212;</mo><mn>1</mn></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.017ex" height="1.937ex" viewBox="0 -520.7 1729.5 834" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhgqKLpekqlgSn68vBtd-J2OHEuKUg#MJMATHI-73" x="0" y="0"></use><g transform="translate(469,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhgqKLpekqlgSn68vBtd-J2OHEuKUg#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhgqKLpekqlgSn68vBtd-J2OHEuKUg#MJMAIN-2212" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhgqKLpekqlgSn68vBtd-J2OHEuKUg#MJMAIN-31" x="1140" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-2"> s_ {t-1} </script>  .  Bei der Ausgabe gibt Zelle A den Zustand an <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>s</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.916ex" height="1.817ex" viewBox="0 -520.7 825.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhgqKLpekqlgSn68vBtd-J2OHEuKUg#MJMATHI-73" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhgqKLpekqlgSn68vBtd-J2OHEuKUg#MJMATHI-74" x="663" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>s</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> s_t </script>  und das Ergebnis der Berechnung <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>h</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.165ex" height="2.419ex" viewBox="0 -780.1 932.1 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhgqKLpekqlgSn68vBtd-J2OHEuKUg#MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhgqKLpekqlgSn68vBtd-J2OHEuKUg#MJMATHI-74" x="815" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>h</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-4"> h_t </script>  . </p><br><p>  In der Praxis wird die Datensequenz normalerweise in Teilsequenzen einer bestimmten festen L√§nge unterteilt und von ganzen Teilmengen (Chargen) an die Berechnung √ºbergeben.  Mit anderen Worten, Teilsequenzen sind Beispiele f√ºr das Lernen.  Die Ein-, Ausg√§nge und Zellzust√§nde eines rekursiven Netzwerks sind Folgen von reellen Zahlen.  Zur Eingabeberechnung <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mn>1</mn></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.384ex" height="1.696ex" viewBox="0 -520.7 1026.4 730.2" role="img" focusable="false" style="vertical-align: -0.487ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhgqKLpekqlgSn68vBtd-J2OHEuKUg#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/post/440472/&amp;usg=ALkJrhgqKLpekqlgSn68vBtd-J2OHEuKUg#MJMAIN-31" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mn>1</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-5"> x_1 </script>  Es ist erforderlich, einen Status zu verwenden, der nicht das Ergebnis einer Berechnung f√ºr eine bestimmte Datensequenz war.  Solche Zust√§nde werden Anfangszust√§nde genannt.  Wenn die Sequenz lang genug ist, ist es sinnvoll, den Kontext der Berechnungen f√ºr jede Teilsequenz beizubehalten.  In diesem Fall ist es m√∂glich, den zuletzt berechneten Zustand in der vorherigen Sequenz als Ausgangszustand zu √ºbertragen.  Wenn die Sequenz nicht so lang ist oder die Teilsequenz das erste Segment ist, k√∂nnen Sie den Anfangszustand mit Nullen initialisieren. </p><br><p>  Derzeit wird f√ºr das Training neuronaler Netze fast √ºberall der Algorithmus der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">R√ºckausbreitung von Fehlern verwendet</a> .  Das Ergebnis der Berechnung f√ºr den √ºbertragenen Satz von Beispielen (in unserem Fall den Satz von Teilsequenzen) wird mit dem erwarteten Ergebnis (markierte Daten) verglichen.  Die Differenz zwischen dem tats√§chlichen und dem erwarteten Wert wird als Fehler bezeichnet, und dieser Fehler wird in entgegengesetzter Richtung auf die Netzwerkgewichte √ºbertragen.  Somit passt sich das Netzwerk an beschriftete Daten an und das Ergebnis dieser Anpassung funktioniert in der Regel gut f√ºr die Daten, die das Netzwerk in den ersten Trainingsbeispielen nicht erf√ºllt hat (Generalisierungshypothese). </p><br><p>  Im Fall eines rekursiven Netzwerks haben wir mehrere Optionen, um den Fehler zu ber√ºcksichtigen.  Wir werden hier zwei Hauptpunkte beschreiben: </p><br><ol><li>  Sie k√∂nnen den Fehler ber√ºcksichtigen, indem Sie die Ausgabe der letzten Zelle der Teilsequenz mit der erwarteten Ausgabe vergleichen.  Dies funktioniert gut f√ºr die Klassifizierungsaufgabe.  Zum Beispiel m√ºssen wir die emotionale F√§rbung eines Tweets bestimmen.  Dazu w√§hlen wir Tweets aus und markieren sie in drei Kategorien: negativ, positiv und neutral.  Die Ausgabe der Zelle besteht aus drei Zahlen - dem Gewicht der Kategorien.  Der Tweet wird auch mit drei Zahlen markiert - den Wahrscheinlichkeiten des Tweets, die zur entsprechenden Kategorie geh√∂ren.  Nachdem Sie den Fehler f√ºr eine Teilmenge der Daten berechnet haben, k√∂nnen Sie ihn nach Belieben √ºber die Ausgabe oder den Status weitergeben. </li><li>  Sie k√∂nnen den Fehler sofort an den Ausg√§ngen der Zellenberechnung f√ºr jedes Element der Teilsequenz lesen.  Dies ist gut geeignet f√ºr die Aufgabe, das n√§chste Element einer Sequenz aus vorherigen vorherzusagen.  Ein solcher Ansatz kann beispielsweise bei dem Problem der Bestimmung von Anomalien in Zeitreihen von Daten oder bei der Vorhersage des n√§chsten Zeichens in einem Text verwendet werden, um es sp√§ter zu generieren.  Die Fehlerausbreitung ist auch √ºber Zust√§nde oder Ausg√§nge m√∂glich. </li></ol><br><p>  Im Gegensatz zu einem regul√§ren vollst√§ndig verbundenen neuronalen Netzwerk ist ein rekursives Netzwerk tief in dem Sinne, dass sich der Fehler nicht nur von den Ausg√§ngen des Netzwerks zu seinen Gewichten, sondern auch nach links durch Verbindungen zwischen Zust√§nden ausbreitet.  Die Tiefe des Netzwerks wird somit durch die L√§nge der Teilsequenz bestimmt.  Um den Fehler durch den Zustand des rekursiven Netzwerks zu verbreiten, gibt es einen speziellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Algorithmus</a> .  Sein Merkmal ist, dass sich die Gradienten der Gewichte miteinander multiplizieren, wenn sich der Fehler von rechts nach links ausbreitet.  Wenn der anf√§ngliche Fehler gr√∂√üer als Eins ist, kann der Fehler infolgedessen sehr gro√ü werden.  Wenn umgekehrt der anf√§ngliche Fehler kleiner als eins ist, kann der Fehler irgendwo am Anfang der Sequenz verschwinden.  Diese Situation in der Theorie der neuronalen Netze wird als Karussell des Standardfehlers bezeichnet.  Um solche Situationen w√§hrend des Trainings zu vermeiden, wurden spezielle Zellen erfunden, die solche Nachteile nicht aufweisen.  Die erste derartige Zelle war <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LSTM</a> , jetzt gibt es eine breite Palette von Alternativen, von denen die beliebteste <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GRU</a> . </p><br><p>  Eine gute Einf√ºhrung in Wiederholungsnetzwerke finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in diesem Artikel</a> .  Eine weitere bekannte Quelle ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein Artikel</a> aus dem Blog von Andrey Karpaty. </p><br><p>  Die Tensorflow-Bibliothek verf√ºgt √ºber viele Klassen und Funktionen zum Implementieren rekursiver Netzwerke.  Hier ist ein Beispiel f√ºr die Erstellung eines dynamischen rekursiven Netzwerks basierend auf einer Zelle vom Typ GRU: </p><br><pre><code class="python hljs">cell = tf.contrib.rnn.GRUCell(dimension) outputs, state = tf.nn.dynamic_rnn(cell, input, sequence_length=input_length, dtype=tf.float32)</code> </pre> <br><p>  In diesem Beispiel wird eine GRU-Zelle erstellt, mit der dann ein dynamisches rekursives Netzwerk erstellt wird.  Der Eingangsdatentensor und die tats√§chlichen L√§ngen der Teilsequenzen werden an das Netzwerk √ºbertragen.  Eingabedaten werden immer durch einen Vektor reeller Zahlen angegeben.  F√ºr einen einzelnen Wert, zum Beispiel einen Symbolcode oder ein Wort, das sogenannte  Einbetten - Zuordnung dieses Codes zu einer Folge von Zahlen.  Die Funktion zum Erstellen eines dynamischen rekursiven Netzwerks gibt ein Wertepaar zur√ºck: eine Liste der Netzwerkausgaben f√ºr alle Werte der Sequenz und den zuletzt berechneten Status.  Als Eingabe nimmt die Funktion eine Zelle, Eingabedaten und einen Teilsequenzl√§ngen-Tensor. </p><br><p>  Ein dynamisches rekursives Netzwerk unterscheidet sich von einem statischen dadurch, dass es kein Netzwerk von Netzwerkzellen f√ºr die Teilsequenz im Voraus erstellt (in der Phase der Bestimmung des Berechnungsdiagramms), sondern die Zellen an den Eingaben dynamisch w√§hrend der Berechnung des Diagramms auf den Eingabedaten startet.  Daher muss diese Funktion die L√§nge der Teilsequenzen der Eingabedaten kennen, um zum richtigen Zeitpunkt anzuhalten. </p><br><h2 id="porozhdayuschie-modeli-na-osnove-rekurentnyh-setey">  Generieren von Modellen basierend auf Wiederholungsnetzwerken </h2><br><h3 id="porozhdayuschie-rekurentnye-seti">  Wiederholungsnetzwerke generieren </h3><br><p>  Zuvor haben wir zwei Methoden zur Berechnung der Fehler rekursiver Netzwerke betrachtet: bei der letzten Ausgabe oder bei allen Ausgaben f√ºr eine bestimmte Sequenz.  Hier betrachten wir das Problem der Erzeugung von Sequenzen.  Das Generator-Netzwerk-Training basiert auf der zweiten Methode der oben genannten Methode. </p><br><p>  Im Detail versuchen wir, ein rekursives Netzwerk zu trainieren, um das n√§chste Element einer Sequenz vorherzusagen.  Wie oben erw√§hnt, ist die Ausgabe einer Zelle in einem rekursiven Netzwerk einfach eine Folge von Zahlen.  Dieser Vektor ist f√ºr das Lernen nicht sehr praktisch, daher f√ºhren sie eine andere Ebene ein, die diesen Vektor am Eingang empf√§ngt und am Ausgang das Gewicht der Vorhersagen angibt.  Diese Ebene wird als <em>Projektionsebene bezeichnet</em> und erm√∂glicht es Ihnen, die Ausgabe der Zelle f√ºr ein bestimmtes Element der Sequenz mit der erwarteten Ausgabe in den beschrifteten Daten zu vergleichen. </p><br><p>  Betrachten Sie zur Veranschaulichung die Aufgabe, Text zu generieren, der als Folge von Zeichen dargestellt wird.  Die L√§nge des Ausgabevektors der Projektionsebene entspricht der Gr√∂√üe des Alphabets des Quelltextes.  Die Gr√∂√üe des Alphabets √ºberschreitet normalerweise nicht 150 Zeichen, wenn Sie die Zeichen der russischen und englischen Sprache sowie die Satzzeichen z√§hlen.  Die Ausgabe der Projektionsebene ist ein Vektor mit der L√§nge des Alphabets, wobei jedes Symbol einer bestimmten Position in diesem Vektor entspricht - dem Index dieses Symbols.  Beschriftete Daten sind auch Vektoren, die aus Nullen bestehen, wobei man an der Position des Zeichens steht, das der Sequenz folgt. </p><br><p>  F√ºr das Training verwenden wir zwei Datensequenzen: </p><br><ol><li>  Eine Folge von Zeichen im Quelltext, an deren Anfang ein Sonderzeichen hinzugef√ºgt wird, das nicht Teil des Quelltextes ist.  Es wird normalerweise als <em>go bezeichnet</em> . </li><li>  Die Zeichenfolge des Quelltextes wie sie ist, ohne Zus√§tze. </li></ol><br><p>  Beispiel f√ºr den Text "Mama hat den Rahmen gewaschen": </p><br><pre> <code class="python hljs">[<span class="hljs-string"><span class="hljs-string">'&lt;go&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span> <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span> <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">'] ['</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>]</code> </pre> <br><p>  F√ºr das Training werden normalerweise Minibatches gebildet, die aus einer kleinen Anzahl von Beispielen bestehen.  In unserem Fall sind dies Zeichenfolgen, die unterschiedlich lang sein k√∂nnen.  Der unten beschriebene Code verwendet die folgende Methode, um das Problem unterschiedlicher L√§nge zu l√∂sen.  Aus den vielen Zeilen in diesem Minipaket wird die maximale L√§nge berechnet.  Alle anderen Zeilen sind mit einem Sonderzeichen (Polsterung) gef√ºllt, sodass alle Beispiele im Minipaket gleich lang sind.  Im folgenden Codebeispiel wird die <em>Pad-</em> Zeichenfolge als solches Zeichen verwendet.  F√ºgen Sie zur besseren Generierung am Ende des Beispiels das Ende des Satzsymbols hinzu - <em>eos</em> .  In der Realit√§t sehen die Daten aus dem Beispiel also etwas anders aus: </p><br><pre> <code class="python hljs">[<span class="hljs-string"><span class="hljs-string">'&lt;go&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span> <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span> <span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span>&lt;eos&gt;<span class="hljs-string"><span class="hljs-string">', '</span></span>&lt;pad&gt;<span class="hljs-string"><span class="hljs-string">', '</span></span>&lt;pad&gt;<span class="hljs-string"><span class="hljs-string">', '</span></span>&lt;pad&gt;<span class="hljs-string"><span class="hljs-string">'] ['</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span><span class="hljs-string"><span class="hljs-string">', '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;eos&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'&lt;pad&gt;'</span></span>]</code> </pre> <br><p>  Die erste Sequenz wird dem Netzwerkeingang zugef√ºhrt, und die zweite Sequenz wird als markierte Daten verwendet.  Das Vorhersage-Training basiert auf der Verschiebung der urspr√ºnglichen Sequenz um ein Zeichen nach links. </p><br><h3 id="obuchenie-i-porozhdenie">  Training und Laichen </h3><br><h4 id="obuchenie">  Schulung </h4><br><p>  Der Lernalgorithmus ist recht einfach.  F√ºr jedes Element der Eingabesequenz berechnen wir den Ausgabevektor seines Projektionspegels und vergleichen ihn mit dem markierten.  Die Frage ist nur, wie der Fehler berechnet wird.  Sie k√∂nnen den quadratischen Mittelwertfehler verwenden, aber um den Fehler in dieser Situation zu berechnen, ist es besser, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kreuzentropie zu verwenden</a> .  Die Tensorflow-Bibliothek bietet mehrere Funktionen f√ºr ihre Berechnung, obwohl nichts die Implementierung der Berechnungsformel direkt im Code aufh√§lt. </p><br><p>  Zur Verdeutlichung f√ºhren wir eine Notation ein.  Mit symbol_id bezeichnen wir die Kennung des Symbols (seine Seriennummer im Alphabet).  Der Begriff Symbol ist hier eher willk√ºrlich und bedeutet einfach ein Element des Alphabets.  Das Alphabet enth√§lt m√∂glicherweise keine Symbole, sondern W√∂rter oder sogar einige komplexere S√§tze von Attributen.  Der Begriff symbol_embedding wird verwendet, um den Vektor von Zahlen zu bezeichnen, die einem bestimmten Element des Alphabets entsprechen.  In der Regel werden solche Zahlengruppen in einer Gr√∂√üentabelle gespeichert, die der Gr√∂√üe des Alphabets entspricht. </p><br><p>  Tensorflow bietet eine Funktion, mit der Sie auf die Einbettungstabelle zugreifen und Zeichenindizes durch ihre Einbettungsvektoren ersetzen k√∂nnen.  Zuerst definieren wir eine Variable zum Speichern der Tabelle: </p><br><pre> <code class="python hljs">embedding_table = tf.Variable(tf.random_uniform([alphabet_size, embedding_size]))</code> </pre> <br><p>  Danach k√∂nnen Sie die Eingangstensoren in Einbettungstensoren konvertieren: </p><br><pre> <code class="python hljs">input_embeddings = tf.nn.embedding_lookup(embedding_table, input_ids)</code> </pre> <br><p>  Das Ergebnis des Funktionsaufrufs ist ein Tensor derselben Dimension, der an die Eingabe √ºbertragen wurde. Infolgedessen werden jedoch alle Zeichenindizes durch die entsprechenden Einbettungssequenzen ersetzt. </p><br><h4 id="porozhdenie">  Spawn </h4><br><p>  Zur Berechnung ben√∂tigt eine Zelle eines rekursiven Netzwerks einen Status und das aktuelle Zeichen.  Das Ergebnis der Berechnung ist ein Exit und ein neuer Zustand.  Wenn wir die Projektionsstufe auf die Ausgabe anwenden, k√∂nnen wir einen Vektor von Gewichten erhalten, bei dem das Gewicht an der entsprechenden Position (sehr bedingt) als die Wahrscheinlichkeit betrachtet werden kann, dass dieses Symbol an der n√§chsten Position in der Sequenz erscheint. </p><br><p>  Verschiedene Strategien k√∂nnen verwendet werden, um das n√§chste Symbol basierend auf dem von der Projektionsebene erzeugten Gewichtsvektor auszuw√§hlen: </p><br><ul><li>  Gierige Suchstrategie.  Jedes Mal, wenn wir das Symbol mit dem h√∂chsten Gewicht ausw√§hlen, d.h.  am wahrscheinlichsten in dieser Situation, aber nicht unbedingt am geeignetsten im Kontext der gesamten Sequenz. </li><li>  Strategie zur Auswahl der besten Sequenz (Strahlensuche).  Wir w√§hlen nicht sofort ein Symbol aus, sondern erinnern uns an mehrere Varianten der wahrscheinlichsten Symbole.  Nachdem alle diese Optionen f√ºr alle Elemente der generierten Sequenz berechnet wurden, w√§hlen wir die wahrscheinlichste Zeichenfolge unter Ber√ºcksichtigung des Kontexts der gesamten Sequenz aus.  √úblicherweise wird dies mittels einer Matrix implementiert, deren Breite gleich der L√§nge der Sequenz und die H√∂he der Anzahl der Strahlerzeugungsbreiten ist.  Nachdem die Erzeugung der Sequenzvarianten abgeschlossen ist, wird eine der Varianten des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Viterbi-</a> Algorithmus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verwendet</a> , um die wahrscheinlichste Sequenz auszuw√§hlen. </li></ul><br><h2 id="sistema-tipov-seq2seq-v-biblioteke-tensorflow">  System vom Typ Tensorflow-Bibliothek seq2seq </h2><br><p>  In Anbetracht dessen ist es klar, dass die Implementierung von generativen Modellen, die auf Wiederholungsnetzwerken basieren, eine ziemlich schwierige Aufgabe f√ºr die Codierung ist.  Daher wurden nat√ºrlich Klassensysteme vorgeschlagen, um die L√∂sung dieses Problems zu erleichtern.  Eines dieser Systeme hei√üt seq2seq, dann beschreiben wir die Funktionalit√§t seiner Haupttypen. </p><br><p>  Aber zuallererst ein paar Worte zum Namen der Bibliothek.  Der Name seq2seq ist die Abk√ºrzung f√ºr Sequenz zu Sequenz (von Sequenz zu Sequenz).  Die urspr√ºngliche Idee, eine Sequenz zu erzeugen, wurde zur Implementierung eines √úbersetzungssystems vorgeschlagen.  Die Eingabesequenz von W√∂rtern wurde der Eingabe eines rekursiven Netzwerks zugef√ºhrt, das in diesem System als Codierer bezeichnet wird.  Die Ausgabe dieses rekursiven Netzwerks war der Zustand der Zellenberechnung f√ºr das letzte Zeichen der Sequenz.  Dieser Zustand wurde als Anfangszustand des zweiten rekursiven Netzwerks, des Decoders, dargestellt, der darauf trainiert wurde, das n√§chste Wort zu erzeugen.  Die W√∂rter wurden in beiden Netzwerken als Symbole verwendet.  Fehler am Dekorator wurden durch den √ºbertragenen Zustand an den Codierer weitergegeben.  Der Zustandsvektor selbst wurde in dieser Terminologie als Gedankenvektor bezeichnet.  Die Zwischenpr√§sentation wurde in traditionellen √úbersetzungsmodellen verwendet und war in der Regel ein Diagramm, das die Struktur des f√ºr die √úbersetzung eingegebenen Textes darstellt.  Das √úbersetzungssystem erzeugte Ausgabetext basierend auf dieser Zwischenstruktur. </p><br><p>  Tats√§chlich geh√∂rt die Implementierung von seq2seq in Tensorflow zum Decoderteil, ohne den Encoder zu beeinflussen.  Daher w√§re es richtig, die 2seq-Bibliothek zu nennen, aber die St√§rke der Tradition und die Tr√§gheit des Denkens √ºberwiegen hier offensichtlich gegen√ºber dem gesunden Menschenverstand. </p><br><p>  Die beiden Hauptmetatypen in der seq2seq-Bibliothek sind: </p><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Helferklasse</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Klassendecoder</a> . </li></ol><br><p>  Die Bibliotheksentwickler identifizierten diese Typen anhand der folgenden √úberlegungen.  Betrachten wir den Lernprozess und den Generierungsprozess, die wir oben beschrieben haben, aus einem etwas anderen Blickwinkel. </p><br><p>  F√ºr das Training ben√∂tigen Sie: </p><br><ol><li>  Geben Sie f√ºr jedes Zeichen die Berechnung des aktuellen Status und die Einbettung des aktuellen Zeichens weiter. </li><li>  Merken Sie sich den f√ºr die Ausgabe berechneten Ausgabestatus und die Projektion. </li><li>  Holen Sie sich das n√§chste Zeichen in der Sequenz und fahren Sie mit Schritt 1 fort. </li></ol><br><p>  Danach k√∂nnen Sie beginnen, Fehler zu z√§hlen, indem Sie die Ergebnisse der Berechnungen mit den folgenden Zeichen der Sequenz vergleichen. </p><br><p>  Um es zu generieren ist notwendig: </p><br><ol><li>  Geben Sie f√ºr jedes Zeichen die Berechnung des aktuellen Status und die Einbettung des aktuellen Zeichens weiter. </li><li>  Merken Sie sich den f√ºr die Ausgabe berechneten Ausgabestatus und die Projektion. </li><li>  Berechnen Sie das n√§chste Zeichen als Maximum der Projektionspegelindizes und fahren Sie mit Schritt 1 fort. </li></ol><br><p>  Wie aus der Beschreibung ersichtlich ist, sind die Algorithmen sehr √§hnlich.  Aus diesem Grund haben die Entwickler der Bibliothek beschlossen, das Verfahren zum Abrufen des n√§chsten Zeichens in der Helper-Klasse zu kapseln.  F√ºr das Training wird lediglich das n√§chste Zeichen aus der Sequenz gelesen und zum Generieren das Zeichen mit dem maximalen Gewicht ausgew√§hlt (nat√ºrlich f√ºr die gierige Suche). </p><br><p>  Dementsprechend implementiert die Helper-Basisklasse die next_inputs-Methode, um das n√§chste Zeichen aus dem aktuellen und dem aktuellen Status abzurufen, sowie die Beispielmethode, um Zeichenindizes von der Projektionsebene abzurufen.  F√ºr die Implementierung des Trainings wird die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TrainingHelper-</a> Klasse bereitgestellt, und f√ºr die Implementierung der Generierung durch die Greedy-Suchmethode wird die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GreedyEmbeddingHelper-</a> Klasse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bereitgestellt</a> .  Leider passt das Strahlensuchmodell nicht in dieses Typsystem, daher ist hierf√ºr eine spezielle Klasse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BeamSearchDecoder</a> in der Bibliothek implementiert.  Helper nicht verwenden. </p><br><p>  Die Decoder-Klasse bietet eine Schnittstelle zum Implementieren eines Decoders.  Tats√§chlich bietet die Klasse zwei Methoden: </p><br><ol><li>  initialisieren, um zu Beginn der Arbeit zu initialisieren. </li><li>  Schritt, um einen Lernschritt oder eine Generation zu implementieren.  Der Inhalt dieses Schritts wird vom entsprechenden Helfer bestimmt. </li></ol><br><p>  Die Bibliothek implementiert die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">BasicDecoder-</a> Klasse, die sowohl f√ºr das Training als auch f√ºr die Zucht mit den Assistenten TrainingHelper und GreedyEmbeddingHelper verwendet werden kann.  Diese drei Klassen reichen normalerweise aus, um Generierungsmodelle zu implementieren, die auf Wiederholungsnetzwerken basieren. </p><br><p>  Schlie√ülich werden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dynamic_decode-</a> Funktionen verwendet, um den Durchgang durch eine Eingabe oder eine generierte Sequenz zu organisieren. </p><br><p>  Als n√§chstes betrachten wir ein veranschaulichendes Beispiel, das Methoden zum Erstellen von Generierungsmodellen f√ºr verschiedene Arten von seq2seq-Bibliotheken zeigt. </p><br><h2 id="illyustrativnyy-primer">  Illustratives Beispiel </h2><br><p>  Zun√§chst sollte gesagt werden, dass alle Beispiele in Python 2.7 implementiert sind.  Eine Liste zus√§tzlicher Bibliotheken finden Sie in der Datei require.txt. </p><br><p>  Betrachten Sie als anschauliches Beispiel einen Teil der Daten f√ºr den Wettbewerb <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Text Normalization Challenge - Russian Language</a> , der 2017 von Kaggle by Google durchgef√ºhrt wurde.  Ziel dieses Wettbewerbs war es, den russischen Text in eine lesbare Form umzuwandeln.  Der Text f√ºr den Wettbewerb wurde in typisierte Ausdr√ºcke unterteilt.  Die Trainingsdaten wurden in einer CSV-Datei des folgenden Formulars angegeben: </p><br><pre> <code class="plaintext hljs">"sentence_id","token_id","class","before","after" 0,0,"PLAIN","","" 0,1,"PLAIN","","" 0,2,"PLAIN","","" 0,3,"DATE","1862 ","    " 0,4,"PUNCT",".","." 1,0,"PLAIN","","" 1,1,"PLAIN","","" 1,2,"PLAIN","","" 1,3,"PLAIN","","" 1,4,"PLAIN","","" 1,5,"PLAIN","","" 1,6,"PLAIN","","" 1,7,"PLAIN","","" 1,8,"PLAIN","","" 1,9,"PUNCT",".","." ...</code> </pre> <br><p>  Im obigen Beispiel ist ein Ausdruck vom Typ DATE interessant; darin wird "1862" in "eintausendachthundertzweiundsechzigstes Jahr" √ºbersetzt.  Zur Veranschaulichung betrachten wir Daten vom Typ DATE nur als Paare der Form (Ausdruck vor, Ausdruck nach).  Beginn der Datendatei: </p><br><pre> <code class="plaintext hljs">before,after 1862 ,     1811 ,    12  2013,      15  2013,      1905 ,    17  2014,      7  2010 ,      1 ,  1843 ,     30  2007 ,      1846 ,     1996 ,     9 ,  ...</code> </pre> <br><p>  Wir werden das generierende Modell unter Verwendung der seq2seq-Bibliothek erstellen, in der der Codierer auf Symbolebene implementiert wird (d. H. Die Elemente des Alphabets sind Symbole), und der Decodierer verwendet die W√∂rter als Alphabet.  Beispielcode ist wie Daten im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Repository von Github</a> verf√ºgbar. </p><br><p>  Die Trainingsdaten sind in drei Untergruppen unterteilt: train.csv, test.csv und dev.csv f√ºr Training, Test und √úberpr√ºfung der Umschulung.  Die Daten befinden sich im Datenverzeichnis.  Im Repository sind drei Modelle implementiert: seq2seq_greedy.py, seq2seq_attention.py und seq2seq_beamsearch.py.  Hier sehen wir uns den Code f√ºr das grundlegende Modell der gierigen Suche an. </p><br><p>  Alle Modelle verwenden die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Estimator-</a> Klasse zur Implementierung.  Mit dieser Klasse k√∂nnen Sie die Codierung vereinfachen, ohne von Nichtmodellteilen abgelenkt zu werden.  Es ist beispielsweise nicht erforderlich, einen Daten√ºbertragungszyklus f√ºr Schulungen zu implementieren, Sitzungen f√ºr die Arbeit mit Tensorflow zu erstellen, Daten an Tensorboard zu √ºbertragen usw.  Estimator ben√∂tigt f√ºr seine Implementierung nur zwei Funktionen: f√ºr die Daten√ºbertragung und f√ºr die Erstellung eines Modells.  In den Beispielen wird auch die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dataset-</a> Klasse verwendet, um Daten f√ºr die Verarbeitung zu √ºbergeben.  Diese moderne Implementierung ist viel schneller als herk√∂mmliche W√∂rterb√ºcher zum √úbertragen von Daten der Form feed_dict. </p><br><h3 id="formirovanie-dannyh">  Datengenerierung </h3><br><p>  Betrachten Sie einen Datengenerierungscode f√ºr Training und Generierung. </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parse_fn</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(line_before, line_after)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Encode in Bytes for TF source = [c.encode('utf8') for c in line_before.decode('utf8').rstrip('\n')] t = [w.encode('utf8') for w in nltk.word_tokenize(line_after.decode('utf8').strip())] learn_target = t + ['&lt;eos&gt;'] + ['&lt;pad&gt;'] target = ['&lt;go&gt;'] + t + ['&lt;eos&gt;'] return (source, len(source)), (target, learn_target, len(target)) def generator_fn(data_file): with open(data_file, 'rb') as f: reader = csv.DictReader(f, delimiter=',', quotechar='"') for row in reader: yield parse_fn(row['before'], row['after']) def input_fn(data_file, params=None): params = params if params is not None else {} shapes = (([None], ()), ([None], [None], ())) types = ((tf.string, tf.int32), (tf.string, tf.string, tf.int32)) defaults = (('&lt;pad&gt;', 0), ('&lt;pad&gt;', '&lt;pad&gt;', 0)) dataset = tf.data.Dataset.from_generator(functools.partial(generator_fn, data_file), output_shapes=shapes, output_types=types) dataset = dataset.repeat(params['epochs']) return (dataset.padded_batch(params.get('batch_size', 50), shapes, defaults).prefetch(1))</span></span></code> </pre> <br><p>  Die Funktion input_fn wird verwendet, um eine Sammlung von Daten zu erstellen, die Estimator dann an Training und Generierung weitergibt.  Der Datentyp wird zuerst festgelegt.  Dies ist ein Paar der Form ((Codierersequenz, L√§nge), (Decodersequenz, Decodersequenz mit einem Pr√§fix, L√§nge)).  Die Zeichenfolge "" wird als Pr√§fix verwendet, jede Encodersequenz endet mit einem speziellen Wort "".  Aufgrund der Tatsache, dass die Sequenzen (sowohl Eingabe als auch Ausgabe) eine ungleiche L√§nge haben, wird auch das F√ºllsymbol mit dem Wert "" verwendet. <br></p><p>  Der Datenvorbereitungscode liest die Datendatei, unterteilt die Encoder-Zeichenfolge in Zeichen und die Decoder-Zeichenfolge in W√∂rter, wobei die nltk-Bibliothek verwendet wird.  Eine auf diese Weise verarbeitete Zeile ist ein Beispiel f√ºr Trainingsdaten.  Die generierte Sammlung ist in Minipakete unterteilt, und die Datenmenge wird entsprechend der Anzahl der Trainingsperioden geklont (jede Epoche besteht aus einem Datenpass). </p><br><h3 id="rabota-so-slovaryami">  Arbeiten Sie mit W√∂rterb√ºchern </h3><br><p>  W√∂rterb√ºcher werden als Liste in Dateien gespeichert, eine Zeile f√ºr ein Wort oder ein Zeichen.  Verwenden Sie zum Erstellen von W√∂rterb√ºchern das Skript build_vocabs.py.  Die generierten W√∂rterb√ºcher befinden sich im Datenverzeichnis als Dateien des Formularvokabulars. *. Txt. </p><br><p>  Code zum Lesen von W√∂rterb√ºchern: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Read vocabs and inputs dropout = params['dropout'] source, source_length = features training = (mode == tf.estimator.ModeKeys.TRAIN) vocab_source = tf.contrib.lookup.index_table_from_file(vocabulary_file=params['source_vocab_file'], num_oov_buckets=params['num_oov_buckets']) with open(params['source_vocab_file']) as f: num_sources = sum(1 for _ in f) + params['num_oov_buckets'] vocab_target = tf.contrib.lookup.index_table_from_file(vocabulary_file=params['target_vocab_file'], num_oov_buckets=params['num_oov_buckets']) with open(params['target_vocab_file']) as f: num_targets = sum(1 for _ in f) + params['num_oov_buckets']</span></span></code> </pre> <br><p>  Hier ist wahrscheinlich die Funktion index_table_from_file interessant, die W√∂rterbuchelemente aus einer Datei liest, und ihr Parameter num_oov_buckets ist die Anzahl der K√∂rbe au√üerhalb des Wortschatzes.  Standardm√§√üig ist diese Zahl gleich eins, d.h.  Alle W√∂rter, die nicht im W√∂rterbuch enthalten sind, haben denselben Index, der der Gr√∂√üe des W√∂rterbuchs + 1 entspricht. Wir haben drei unbekannte W√∂rter: "", "" und "", f√ºr die wir unterschiedliche Indizes haben m√∂chten.  Setzen Sie diesen Parameter daher auf die Nummer drei.  Leider m√ºssen Sie die Eingabedatei erneut lesen, um die Anzahl der W√∂rter im W√∂rterbuch als Zeitkonstante f√ºr die Einstellung des Modellgraphen zu erhalten. <br></p><p>  Wir m√ºssen noch eine Tabelle erstellen, um die Einbettung - _source_embedding - zu implementieren und Wortzeichenfolgen in Bezeichnerzeichenfolgen zu √ºbersetzen: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># source embeddings matrix _source_embedding = tf.Variable(tf.random_uniform([num_sources, params['embedding_size']])) source_ids = vocab_source.lookup(source) source_embedding = tf.nn.embedding_lookup(_source_embedding, source_ids)</span></span></code> </pre> <br><h3 id="realizaciya-kodirovschika">  Implementierung des Encoders </h3><br><p>  F√ºr den Encoder verwenden wir ein bidirektionales rekursives Netzwerk mit mehreren Ebenen.     ,     ,      . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># add multilayer bidirectional RNN cell_fw = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(params['dim']) for _ in range(params['layers'])]) cell_bw = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(params['dim']) for _ in range(params['layers'])]) outputs, states = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, source_embedding, sequence_length=source_length, dtype=tf.float32) # prepare output output = tf.concat(outputs, axis=-1) encoder_output = tf.layers.dense(output, params['dim']) # prepare state state_fw, state_bw = states cells = [] for fw, bw in zip(state_fw, state_bw): state = tf.concat([fw, bw], axis=-1) cells += [tf.layers.dense(state, params['dim'])] encoder_state = tuple(cells)</span></span></code> </pre> <br><p>       GRU,    MultiRNNCell,   ,   rnn.Cell.    , <br> sequence_length ‚Äî     ,     ,    . </p><br><p> ,       ,       ,           .      ,      128,        256.     ,        ,      128.        . </p><br><p>     .  Weil    , ,    bidirectional_dynamic_rnn,   ,     .           ,      .     , ..       . , ,  .            ,   ,       . </p><br><h3 id="realizaciya-dekodirovschika">   </h3><br><p>     ,    .           . </p><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment"># decoder RNN cell decoder_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(params['dim']) for _ in range(params['layers'])]) decoder_initial_state = encoder_state # projection layer projection_layer = tf.layers.Dense(num_targets, use_bias=False) # embedding table for targets target_embedding = tf.Variable(tf.random_uniform([num_targets, params['embedding_size']]))</span></span></code> </pre> <br><h4 id="obuchenie-1">  Schulung </h4><br><p>    TrainingHelper + BasicDecoder. </p><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment"># target embeddings matrix target, learn_target, target_length = labels target_ids = vocab_target.lookup(target) target_learn_ids = vocab_target.lookup(learn_target) # train encoder _target_embedding = tf.nn.embedding_lookup(target_embedding, target_ids) train_helper = tf.contrib.seq2seq.TrainingHelper(_target_embedding, target_length) train_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, train_helper, decoder_initial_state, output_layer=projection_layer) train_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(train_decoder) train_output = train_outputs.rnn_output train_sample_id = train_outputs.sample_id</span></span></code> </pre> <br><h4 id="porozhdenie-1">  </h4><br><p>        . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># prediction decoder prediction_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper( embedding=target_embedding, start_tokens=tf.fill([batch_size], tf.to_int32(vocab_target.lookup(tf.fill([], '&lt;go&gt;')))), end_token=tf.to_int32(vocab_target.lookup(tf.fill([], '&lt;eos&gt;')))) prediction_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, prediction_helper, decoder_initial_state, output_layer=projection_layer) prediction_output, _, _ = tf.contrib.seq2seq.dynamic_decode(prediction_decoder, maximum_iterations=params['max_iters']) # prepare prediction reverse_vocab_target = tf.contrib.lookup.index_to_string_table_from_file(params['target_vocab_file']) pred_strings = reverse_vocab_target.lookup(tf.to_int64(prediction_output.sample_id)) predictions = { 'ids': prediction_output.sample_id, 'text': pred_strings }</span></span></code> </pre> <br><p>     GreedyEmbeddingHelper       "",     "".        . , ,    dynamic_decode      .    ,    ,   . ,     ,        . <br><br></p><h4 id="funkciya-poter-i-optimizaciya">     </h4><br><p>     ,        seq2seq. </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># loss masks = tf.sequence_mask(lengths=target_length, dtype=tf.float32) loss = tf.contrib.seq2seq.sequence_loss(logits=train_output, targets=target_learn_ids, weights=masks)</span></span></code> </pre> <br><p>    ,     ,      sequence_mask. </p><br><p>     Adam   ,   . </p><br><pre> <code class="python hljs">optimizer = tf.train.AdamOptimizer(learning_rate=params.get(<span class="hljs-string"><span class="hljs-string">'lr'</span></span>, <span class="hljs-number"><span class="hljs-number">.001</span></span>)) grads, vs = zip(*optimizer.compute_gradients(loss)) grads, gnorm = tf.clip_by_global_norm(grads, params.get(<span class="hljs-string"><span class="hljs-string">'clip'</span></span>, <span class="hljs-number"><span class="hljs-number">.5</span></span>)) train_op = optimizer.apply_gradients(zip(grads, vs), global_step=tf.train.get_or_create_global_step())</code> </pre> <br><h4 id="rezultaty-obucheniya">   </h4><br><p>         .     0.9   . , ,     ,    .   ,    . </p><br><pre> <code class="plaintext hljs">24  1944                 1  2003              1992 .           11  1927               1969            1  2016             1047          1863            17      22  2014              </code> </pre> <br><p>        .   ‚Äî   ,   ‚Äî  ,   ‚Äî  . </p><br><p>  ,    ‚Äî   .             .    ,    ( ),       .       .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a>        ,     . </p><br><h2 id="zaklyuchenie">  Fazit </h2><br><p>            seq2seq.      ,          ,     .    ,  . </p><br><p>           .  Tensorflow   ,   ,     .   ,         ,   .        ,        . ,      ,   padding  ,   embedding     ?       , ,       .         ‚Äî     . ,    ,    . ,    ,    ,    . ,       . ,          , , ,        . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de440472/">https://habr.com/ru/post/de440472/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de440462/index.html">Top 7 Content-Marketing-Strategien, die Sie 2019 nicht verpassen sollten</a></li>
<li><a href="../de440464/index.html">Arbeiten Sie mit dem Dienst Digital Ocean Managed Databases in .NET Core</a></li>
<li><a href="../de440466/index.html">Web-UART-Fernbedienung</a></li>
<li><a href="../de440468/index.html">2 mal mehr, 10 mal schneller, rund um die Uhr - alles zum Wohle der Menschen</a></li>
<li><a href="../de440470/index.html">Betten Sie einen Python-Interpreter mithilfe des Panama-Projekts in eine Java-Anwendung ein</a></li>
<li><a href="../de440474/index.html">SVG-Filtereffekte. Teil 4. Zweifarbige Bilder mit feComponentTransfer</a></li>
<li><a href="../de440476/index.html">"Beginnen Sie mit Mitaps" oder Ben√∂tigen Sie √ºberhaupt Programmierkurse?</a></li>
<li><a href="../de440478/index.html">3CX v16 Beta 1 mit Raspberry Pi-Unterst√ºtzung ver√∂ffentlicht</a></li>
<li><a href="../de440486/index.html">Qualit√§tspreis: 7 Prinzipien zur Optimierung der Testkosten</a></li>
<li><a href="../de440488/index.html">Reflektierende Schattenkarten: Teil 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
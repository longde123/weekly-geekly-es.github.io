<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßïüèø üòê üï¥üèø 21 de octubre an√°lisis de incidentes en github ü§¶üèΩ üë©üèª‚Äçüé§ üî¨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="43 segundos fatales, que causaron la degradaci√≥n diaria del servicio 

 La semana pasada ocurri√≥ un incidente en GitHub que degrad√≥ el servicio durant...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>21 de octubre an√°lisis de incidentes en github</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428409/"> <b>43 segundos fatales, que causaron la degradaci√≥n diaria del servicio</b> <br><br>  La semana pasada ocurri√≥ un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">incidente</a> en GitHub que degrad√≥ el servicio durante 24 horas y 11 minutos.  El incidente no afect√≥ a toda la plataforma, sino solo a unos pocos sistemas internos, lo que llev√≥ a la visualizaci√≥n de informaci√≥n obsoleta e inconsistente.  Finalmente, los datos del usuario no se perdieron, pero la reconciliaci√≥n manual de varios segundos de escritura en la base de datos todav√≠a est√° en progreso.  Durante la mayor parte del bloqueo, GitHub tampoco pudo manejar webhooks, crear y publicar p√°ginas de GitHub. <br><br>  A todos en GitHub nos gustar√≠a disculparnos sinceramente por los problemas que todos ustedes han encontrado.  Conocemos su confianza en GitHub y estamos orgullosos de crear sistemas sostenibles que respaldan la alta disponibilidad de nuestra plataforma.  Lo hemos decepcionado con este incidente y lo lamentamos profundamente.  Aunque no podemos solucionar los problemas debido a la degradaci√≥n de la plataforma GitHub durante mucho tiempo, podemos explicar las razones de lo que sucedi√≥, hablar sobre las lecciones aprendidas y las medidas que permitir√°n a la compa√±√≠a protegerse mejor de tales fallas en el futuro. <br><a name="habracut"></a><br><h1>  Antecedentes </h1><br>  La mayor√≠a de los servicios de usuario de GitHub funcionan en nuestros propios <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">centros de datos</a> .  La topolog√≠a del centro de datos est√° dise√±ada para proporcionar una red fronteriza confiable y expandible frente a varios centros de datos regionales que proporcionan el trabajo de los sistemas inform√°ticos y de almacenamiento de datos.  A pesar de los niveles de redundancia incorporados en los componentes f√≠sicos y l√≥gicos del proyecto, todav√≠a es posible que los sitios no puedan interactuar entre s√≠ durante alg√∫n tiempo. <br><br>  El 21 de octubre, a las 10:52 p.m. UTC, los trabajos de reparaci√≥n programados para reemplazar el equipo √≥ptico defectuoso de 100G resultaron en una p√©rdida de comunicaci√≥n entre el nodo de red en la costa este (costa este de los EE. UU.) Y el principal centro de datos en la costa este.  La conexi√≥n entre ellos se restableci√≥ despu√©s de 43 segundos, pero esta corta desconexi√≥n provoc√≥ una cadena de eventos que condujo a la degradaci√≥n del servicio durante 24 horas y 11 minutos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c1e/fd8/71b/c1efd871b9017afe95d9605703ba7734.png"><br>  <i><font color="gray">La arquitectura de red de alto nivel de GitHub, que incluye dos centros de datos f√≠sicos, 3 POP y almacenamiento en la nube en varias regiones, conectados a trav√©s del emparejamiento</font></i> <br><br>  En el pasado, discutimos c√≥mo usamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MySQL para almacenar metadatos de GitHub</a> , as√≠ como nuestro enfoque para proporcionar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">alta disponibilidad para MySQL</a> .  GitHub gestiona varios cl√∫steres MySQL que var√≠an en tama√±o desde cientos de gigabytes hasta casi cinco terabytes.  Cada cl√∫ster tiene docenas de r√©plicas de lectura para almacenar metadatos que no sean Git, por lo que nuestras aplicaciones proporcionan solicitudes de grupo, problemas, autenticaci√≥n, procesamiento en segundo plano y caracter√≠sticas adicionales fuera del repositorio de objetos Git.  Diferentes datos en diferentes partes de la aplicaci√≥n se almacenan en diferentes grupos utilizando segmentaci√≥n funcional. <br><br>  Para mejorar el rendimiento a gran escala, las aplicaciones escriben directamente en el servidor primario apropiado para cada cl√∫ster, pero en la gran mayor√≠a de los casos delegan solicitudes de lectura a un subconjunto de servidores de r√©plica.  Usamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Orchestrator</a> para administrar topolog√≠as de cl√∫ster MySQL y conmutar por error autom√°ticamente.  Durante este proceso, Orchestrator tiene en cuenta una serie de variables y se ensambla en la parte superior de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Raft</a> para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">mantener la</a> coherencia.  Orchestrator puede implementar potencialmente topolog√≠as que las aplicaciones no admiten, por lo que debe asegurarse de que su configuraci√≥n de Orchestrator cumpla con las expectativas de nivel de aplicaci√≥n. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/686/ea1/657/686ea165750913fa41b771482266b887.png"><br>  <i><font color="gray">En una topolog√≠a t√≠pica, todas las aplicaciones leen localmente con baja latencia.</font></i> <br><br><h1>  Cr√≥nica del incidente. </h1><br><h4>  10.21.2018, 22:52 UTC </h4><br>  Durante la separaci√≥n de red mencionada anteriormente, Orchestrator en el centro de datos principal comenz√≥ el proceso de deseleccionar el liderazgo de acuerdo con el algoritmo de consenso Raft.  El centro de datos de la costa oeste y los nodos de la nube p√∫blica Orchestrator en la costa este lograron llegar a un consenso, y comenzaron a resolver las fallas de los cl√∫steres para enviar registros al centro de datos occidental.  Orchestrator comenz√≥ a crear una topolog√≠a de cl√∫ster de base de datos en Occidente.  Despu√©s de reconectarse, las aplicaciones enviaron inmediatamente tr√°fico de escritura a los nuevos servidores primarios en el oeste de los EE. UU. <br><br>  En los servidores de bases de datos en el centro de datos del este, hubo registros por un per√≠odo corto que no se replicaron en el centro de datos del oeste.  Dado que los grupos de bases de datos en ambos centros de datos ahora conten√≠an registros que no estaban en el otro centro de datos, no pudimos devolver de manera segura el servidor primario al centro de datos oriental. <br><br><h4>  10.21.2018, 22:54 UTC </h4><br>  Nuestros sistemas de monitoreo interno comenzaron a generar alertas que indicaban numerosas fallas en el sistema.  En este momento, varios ingenieros respondieron y trabajaron en ordenar las notificaciones entrantes.  A las 23:02, los ingenieros del primer grupo de respuesta determinaron que las topolog√≠as para numerosos grupos de bases de datos estaban en un estado inesperado.  Al consultar la API de Orchestrator, se mostraba la topolog√≠a de replicaci√≥n de la base de datos, que conten√≠a solo servidores del centro de datos occidental. <br><br><h4>  10.21.2018, 23:07 UTC </h4><br>  En este punto, el equipo de respuesta decidi√≥ bloquear manualmente las herramientas de implementaci√≥n internas para evitar cambios adicionales.  A las 23:09, el grupo estableci√≥ el sitio en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">amarillo</a> .  Esta acci√≥n asign√≥ autom√°ticamente a la situaci√≥n el estado de un incidente activo y envi√≥ una advertencia al coordinador del incidente.  A las 23:11, el coordinador se uni√≥ al trabajo y dos minutos despu√©s decidi√≥ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cambiar el estado a rojo</a> . <br><br><h4>  10.21.2018, 23:13 UTC </h4><br>  En ese momento, estaba claro que el problema afectaba a varios grupos de bases de datos.  Desarrolladores adicionales del grupo de ingenier√≠a de la base de datos estuvieron involucrados en el trabajo.  Comenzaron a examinar el estado actual para determinar qu√© acciones deb√≠an tomarse para configurar manualmente la base de datos de la costa este de los EE. UU. Como primaria para cada grupo y reconstruir la topolog√≠a de replicaci√≥n.  Esto no fue f√°cil, porque en este punto el cl√∫ster de la base de datos occidental hab√≠a estado recibiendo registros del nivel de aplicaci√≥n durante casi 40 minutos.  Adem√°s, en el grupo oriental, hubo varios segundos de registros que no se replicaron hacia el oeste y no permitieron la replicaci√≥n de nuevos registros hacia el este. <br><br>  Proteger la privacidad e integridad de los datos del usuario es la principal prioridad de GitHub.  Por lo tanto, decidimos que m√°s de 30 minutos de datos registrados en el centro de datos occidental nos dejan con una sola soluci√≥n a la situaci√≥n para guardar estos datos: transferir hacia adelante (fallar hacia adelante).  Sin embargo, las aplicaciones en el este, que dependen de escribir informaci√≥n en el cl√∫ster MySQL occidental, actualmente no pueden manejar el retraso adicional debido a la transferencia de la mayor√≠a de sus llamadas a la base de datos de un lado a otro.  Esta decisi√≥n conducir√° al hecho de que nuestro servicio ser√° inadecuado para muchos usuarios.  Creemos que la degradaci√≥n a largo plazo de la calidad del servicio vali√≥ la pena garantizar la consistencia de los datos de nuestros usuarios. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a66/119/b52/a66119b52dbb23111ddfe47bca1194d8.png"><br>  <i><font color="gray">En la topolog√≠a incorrecta, se viola la replicaci√≥n de oeste a este, y las aplicaciones no pueden leer los datos de las r√©plicas actuales, porque dependen de una baja latencia para mantener el rendimiento de la transacci√≥n.</font></i> <br><br><h4>  10.21.2018, 23:19 UTC </h4><br>  Las consultas sobre el estado de los cl√∫steres de bases de datos mostraron que es necesario detener la ejecuci√≥n de tareas que escriben metadatos, como solicitudes push.  Hicimos una elecci√≥n y deliberadamente fuimos a una degradaci√≥n parcial del servicio, suspendiendo los webhooks y el ensamblaje de las p√°ginas de GitHub, para no comprometer los datos que ya recibimos de los usuarios.  En otras palabras, la estrategia era priorizar: la integridad de los datos en lugar de la usabilidad del sitio y la recuperaci√≥n r√°pida. <br><br><h4>  22/10/2018, 00:05 UTC </h4><br>  Los ingenieros del equipo de respuesta comenzaron a desarrollar un plan para resolver inconsistencias de datos y lanzaron procedimientos de conmutaci√≥n por error para MySQL.  El plan consist√≠a en restaurar los archivos de la copia de seguridad, sincronizar las r√©plicas en ambos sitios, volver a una topolog√≠a de servicio estable y luego reanudar los trabajos de procesamiento en la cola.  Actualizamos el estado para informar a los usuarios que vamos a realizar una conmutaci√≥n por error administrada del sistema de almacenamiento interno. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eb4/cb7/a34/eb4cb7a34add07f272b99fc93f161d56.png"><br>  <i><font color="gray">El plan de recuperaci√≥n implicaba avanzar, restaurar desde las copias de seguridad, sincronizar, retroceder y solucionar el retraso antes de volver al estado verde</font></i> <br><br>  Aunque las copias de seguridad de MySQL se realizan cada cuatro horas y se almacenan durante muchos a√±os, se encuentran en un almacenamiento remoto en la nube de objetos blob.  La recuperaci√≥n de varios terabytes de una copia de seguridad tom√≥ varias horas.  La transferencia de datos desde el servicio de copia de seguridad remota llev√≥ mucho tiempo.  La mayor parte del tiempo se dedic√≥ a desempaquetar, verificar la suma de verificaci√≥n, preparar y cargar grandes archivos de respaldo en servidores MySQL reci√©n preparados.  Este procedimiento se prueba a diario, por lo que todos ten√≠an una buena idea de cu√°nto tiempo tomar√≠a la recuperaci√≥n.  Sin embargo, antes de este incidente, nunca tuvimos que reconstruir completamente el cl√∫ster completo a partir de una copia de seguridad.  Otras estrategias siempre han funcionado, como las r√©plicas diferidas. <br><br><h4>  22/10/2018, 00:41 UTC </h4><br>  En este momento, se hab√≠a iniciado un proceso de copia de seguridad para todos los cl√∫steres MySQL afectados, y los ingenieros siguieron el progreso.  Al mismo tiempo, varios grupos de ingenieros estudiaron formas de acelerar la transferencia y la recuperaci√≥n sin una mayor degradaci√≥n del sitio o el riesgo de corrupci√≥n de datos. <br><br><h4>  22/10/2018, 06:51 UTC </h4><br>  Varios grupos en el centro de datos del este completaron la recuperaci√≥n de las copias de seguridad y comenzaron a replicar nuevos datos de la costa oeste.  Esto condujo a una desaceleraci√≥n en la carga de p√°ginas que realizaron una operaci√≥n de escritura en todo el pa√≠s, pero leer p√°ginas de estos grupos de bases de datos arroj√≥ resultados reales si la solicitud de lectura ca√≠a en una r√©plica reci√©n restaurada.  Otros grupos de bases de datos m√°s grandes continuaron recuper√°ndose. <br><br>  Nuestros equipos han identificado un m√©todo de recuperaci√≥n directamente desde la costa oeste para superar las limitaciones de ancho de banda causadas por el arranque desde el almacenamiento externo.  Se hizo casi 100% claro que la recuperaci√≥n se completar√° con √©xito, y el tiempo para crear una topolog√≠a de replicaci√≥n saludable depende de la cantidad de replicaci√≥n de recuperaci√≥n.  Esta estimaci√≥n se interpol√≥ linealmente en funci√≥n de la replicaci√≥n de telemetr√≠a disponible, y la p√°gina de estado se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">actualiz√≥</a> para establecer la espera de dos horas como el tiempo de recuperaci√≥n estimado. <br><br><h4>  22/10/2018, 07:46 UTC </h4><br>  GitHub public√≥ una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">publicaci√≥n informativa en el blog</a> .  Nosotros mismos utilizamos las p√°ginas de GitHub, y todas las asambleas se detuvieron hace unas horas, por lo que la publicaci√≥n requiri√≥ un esfuerzo adicional.  Pedimos disculpas por el retraso.  Tenemos la intenci√≥n de enviar este mensaje mucho antes y en el futuro proporcionaremos la publicaci√≥n de actualizaciones en las condiciones de dichas restricciones. <br><br><h4>  22/10/2018, 11:12 UTC </h4><br>  Todas las bases de datos primarias se transfieren nuevamente al Este.  Esto llev√≥ al sitio a ser mucho m√°s receptivo, ya que los registros ahora se enrutaron a un servidor de base de datos ubicado en el mismo centro de datos f√≠sicos que nuestra capa de aplicaci√≥n.  Aunque esto mejor√≥ significativamente el rendimiento, todav√≠a hab√≠a docenas de r√©plicas de lectura de la base de datos que estaban varias horas detr√°s de la copia principal.  Estas r√©plicas retrasadas han llevado a los usuarios a ver datos inconsistentes al interactuar con nuestros servicios.  Distribuimos la carga de lectura en un gran conjunto de r√©plicas de lectura, y cada solicitud a nuestros servicios tiene buenas posibilidades de ingresar a la r√©plica de lectura con un retraso de varias horas. <br><br>  De hecho, el tiempo de recuperaci√≥n de una r√©plica retrasada se reduce exponencialmente, no linealmente.  Cuando los usuarios en los EE. UU. Y Europa se despertaron, debido al aumento de la carga en los registros en los grupos de bases de datos, el proceso de recuperaci√≥n tom√≥ m√°s tiempo de lo previsto. <br><br><h4>  22/10/2018, 13:15 UTC </h4><br>  Nos est√°bamos acercando a la carga m√°xima en GitHub.com.  El equipo de respuesta discuti√≥ los siguientes pasos.  Estaba claro que el retraso de la replicaci√≥n a un estado constante est√° aumentando, no disminuyendo.  Anteriormente, comenzamos a preparar r√©plicas de lectura MySQL adicionales en la nube p√∫blica de la costa este.  Una vez que estuvieron disponibles, se hizo m√°s f√°cil distribuir el flujo de solicitudes de lectura entre varios servidores.  La reducci√≥n de la carga promedio en las r√©plicas de lectura aceler√≥ la recuperaci√≥n de la replicaci√≥n. <br><br><h4>  22/10/2018, 16:24 UTC </h4><br>  Despu√©s de sincronizar las r√©plicas, volvimos a la topolog√≠a original, eliminando los problemas de demora y disponibilidad.  Como parte de una decisi√≥n consciente sobre la prioridad de la integridad de los datos sobre una correcci√≥n r√°pida de la situaci√≥n, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">mantuvimos el estado rojo del</a> sitio cuando comenzamos a procesar los datos acumulados. <br><br><h4>  22/10/2018, 16:45 UTC </h4><br>  En la etapa de recuperaci√≥n, era necesario equilibrar el aumento de la carga asociada con el trabajo atrasado, sobrecargando potencialmente a nuestros socios del ecosistema con notificaciones y volviendo a la eficiencia al cien por cien lo m√°s r√°pido posible.  M√°s de cinco millones de eventos de gancho y 80 mil solicitudes para crear p√°ginas web permanecieron en la cola. <br><br>  Cuando volvimos a habilitar el procesamiento de estos datos, procesamos alrededor de 200,000 tareas √∫tiles con webhooks que excedieron el TTL interno y se eliminaron.  Al enterarnos de esto, dejamos de procesar y comenzamos a aumentar el TTL. <br><br>  Para evitar una disminuci√≥n adicional en la confiabilidad de nuestras actualizaciones de estado, dejamos el estado de degradaci√≥n hasta que terminemos de procesar toda la cantidad acumulada de datos y nos aseguremos de que los servicios hayan regresado claramente al nivel normal de rendimiento. <br><br><h4>  22/10/2018, 11:03 p.m. UTC </h4><br>  Se procesan todos los eventos de webhook incompletos y los ensambles de p√°ginas, y se confirma la integridad y el funcionamiento correcto de todos los sistemas.  El estado del sitio se ha <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">actualizado a verde</a> . <br><br><h1>  Otras acciones </h1><br><h4>  Resolviendo el desajuste de datos </h4><br>  Durante la recuperaci√≥n, arreglamos registros binarios de MySQL con entradas principalmente del centro de datos, que no se replicaron en el occidental.  El n√∫mero total de tales entradas es relativamente peque√±o.  Por ejemplo, en uno de los grupos m√°s activos, solo hay 954 registros en estos segundos.  Actualmente estamos analizando estos registros y determinando qu√© entradas se pueden conciliar autom√°ticamente y cu√°les requieren asistencia del usuario.  Varios equipos participan en este trabajo, y nuestro an√°lisis ya ha determinado la categor√≠a de registros que el usuario repiti√≥, y se guardaron con √©xito.  Como se indic√≥ en este an√°lisis, nuestro objetivo principal es mantener la integridad y la precisi√≥n de los datos que almacena en GitHub. <br><br><h4>  Comunicaci√≥n </h4><br>  Intentando transmitirle informaci√≥n importante durante el incidente, realizamos varias estimaciones p√∫blicas del tiempo de recuperaci√≥n en funci√≥n de la velocidad de procesamiento de los datos acumulados.  Mirando hacia atr√°s, nuestras estimaciones no tuvieron en cuenta todas las variables.  Pedimos disculpas por la confusi√≥n y nos esforzaremos por proporcionar informaci√≥n m√°s precisa en el futuro. <br><br><h4>  Medidas t√©cnicas </h4><br>  En el curso de este an√°lisis, se identificaron varias medidas t√©cnicas.  El an√°lisis contin√∫a, la lista se puede complementar. <br><br><ul><li>  Ajuste la configuraci√≥n de Orchestrator para evitar que las bases de datos primarias se muevan fuera de la regi√≥n.  Orchestrator funcionaba de acuerdo con la configuraci√≥n, aunque la capa de aplicaci√≥n no admit√≠a dicho cambio de topolog√≠a.  Elegir un l√≠der dentro de una regi√≥n generalmente es seguro, pero la aparici√≥n repentina de un retraso debido al flujo de tr√°fico en todo el continente se ha convertido en la causa principal de este incidente.  Este es un comportamiento emergente y nuevo del sistema, porque antes no encontramos la secci√≥n interna de la red de esta magnitud. </li><li>  Hemos acelerado la migraci√≥n al nuevo sistema de informes de estado, que proporcionar√° una plataforma m√°s adecuada para discutir incidentes activos con formulaciones m√°s precisas y claras.  Aunque muchas partes de GitHub estuvieron disponibles durante todo el incidente, solo pudimos seleccionar los estados verde, amarillo y rojo para todo el sitio.  Admitimos que esto no da una imagen precisa: qu√© funciona y qu√© no.  El nuevo sistema mostrar√° los diversos componentes de la plataforma para que conozca el estado de cada servicio. </li><li>  Unas semanas antes de este incidente, lanzamos una iniciativa de ingenier√≠a a nivel corporativo para respaldar el servicio del tr√°fico de GitHub desde m√∫ltiples centros de datos utilizando la arquitectura activa / activa / activa.  El objetivo de este proyecto es soportar la redundancia N + 1 a nivel del centro de datos para resistir la falla de un centro de datos sin interferencia externa.  Esto es mucho trabajo y llevar√° alg√∫n tiempo, pero creemos que varios centros de datos bien conectados en diferentes regiones proporcionar√°n un buen compromiso.  El √∫ltimo incidente impuls√≥ esta iniciativa a√∫n m√°s. </li><li>  Tomaremos una posici√≥n m√°s activa al verificar nuestras suposiciones.  GitHub est√° creciendo r√°pidamente y ha acumulado una considerable cantidad de complejidad durante la √∫ltima d√©cada.  Cada vez es m√°s dif√≠cil capturar y transmitir a la nueva generaci√≥n de empleados el contexto hist√≥rico de compromisos y decisiones tomadas. </li></ul><br><h4>  Medidas organizativas </h4><br>  Este incidente influy√≥ mucho en nuestra comprensi√≥n de la fiabilidad del sitio.  Aprendimos que ajustar el control operativo o mejorar los tiempos de respuesta no son garant√≠as suficientes de confiabilidad en un sistema de servicios tan complejo como el nuestro.  Para respaldar estos esfuerzos, tambi√©n comenzaremos una pr√°ctica sistem√°tica de probar escenarios de fallas antes de que realmente ocurran.  Este trabajo incluye la resoluci√≥n de problemas deliberada y el uso de herramientas de ingenier√≠a del caos. <br><br><h1>  Conclusi√≥n </h1><br>  Sabemos c√≥mo conf√≠a en GitHub en sus proyectos y negocios.  Nos preocupamos m√°s que nadie por la disponibilidad de nuestro servicio y la seguridad de sus datos.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> El an√°lisis de este incidente continuar√° encontrando una oportunidad para servirle mejor y justificar su confianza. </font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es428409/">https://habr.com/ru/post/es428409/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es428393/index.html">Seminario web "Probar entornos 2.0 en la nube y c√≥mo aprender a cocinarlos"</a></li>
<li><a href="../es428395/index.html">El libro "M√≠nimo te√≥rico para Big Data. Todo lo que necesitas saber sobre big data ‚Äù</a></li>
<li><a href="../es428401/index.html">Procesos de desarrollo a trav√©s de los ojos de la explotaci√≥n. Una mirada desde el otro lado de la barricada.</a></li>
<li><a href="../es428403/index.html">El resumen de eventos para profesionales de recursos humanos en el campo de TI para noviembre de 2018</a></li>
<li><a href="../es428407/index.html">6 tramas t√≠picas de la literatura mundial</a></li>
<li><a href="../es428411/index.html">Radar tecnol√≥gico: lista de idiomas, herramientas y plataformas que pasaron por Lamoda</a></li>
<li><a href="../es428413/index.html">Sistemas de enfriamiento en centros de datos Selectel</a></li>
<li><a href="../es428415/index.html">Descripci√≥n general del controlador de nube TP-Link Omada OC200</a></li>
<li><a href="../es428417/index.html">Aprendizaje autom√°tico en MatLab / Octave: ejemplos de algoritmos admitidos por f√≥rmulas</a></li>
<li><a href="../es428419/index.html">Arrastra y desliza en RecyclerView. Parte 2: arrastrar y soltar controladores, cuadr√≠culas y animaciones personalizadas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>